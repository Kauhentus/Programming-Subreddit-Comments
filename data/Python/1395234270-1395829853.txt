I would like to disagree, I develop at work on a crappy little laptop with an i3, 4 GB ram and a single slow laptop drive. At home I use an i7 with 32GB ram, and a 4 SSD raid array You don't need a behemoth of a machine to run Pycharm. It works just as well without it for 99% of the features. The only part that would be a lot better on bigger machines is code inspection of a full project at once. as opposed to just open files.
Thanks, I updated it with a deep vs shallow copy section to avoid confusing people. I like this Python weirdness (a is b), do you have a explanation for it?
Python Weekly is going on in full swing. It's just that the archive has not been updated. Will try to update it soon. 
It's pretty amazing that a post like this gets 7 in rank while my posting of a working and fairly ambitious open source python project gets 3.
At least you can auto log in with google, facebook, etc. 
Ah, awesome — thanks. I haven't had need for a time series database just yet, but when I do, that's exactly what I'll need to know.
Ahh, It uses python 3.3. I really need to make the switch soon.
Thanks for the reply! I did get it working and your idea is really good I didnt think of thay. I have to keep it as is though because this is part of a class assignment and my professor specifically wants those columns for this.
Thanks! The site looks pretty sweet, so I'm glad it has 2.7 support.
I use closures a lot in recursion. That way I can feed a static value into the recursive loop and reference it again without having to pass it directly as an argument and without making it global. Is this correct usage? 
Advance apologies for being a pundit, but this seems a little silly. Why not just invest your time upgrading what you have and be done with it? There's no reason to shoehorn the use of py3 features into py27 projects just for the sake of doing it. If there's something in python3 that will benefit you, then you probably already know it..
Keep in mind, that Blender uses Python 3.3 and not 2.7, when looking for tutorials. Also, as far as I know you can already do a lot in Blenders game engine without needing Python. For Blender specific Python tutorials try blendercookie.com. I believe they have some, although I'm not sure if they are up to date (the Python API changed a lot between Blender 2.5 and 2.55 or so).
I'm actually a citizen member on cgcookie and so I will definitely be looking at everything there. And I had no idea that blender used 3.3. You just saved me a shit load of pointless work. So thanks!
Don't quit your job. It's for your own good. You can still do it in your own time sure. But don't quit your job.
This is a *very* good site; kudos to the one who created it!
I don't think I saw [Interactive Python](http://interactivepython.org/runestone/static/thinkcspy/index.html), an interactive version of How to Think Like a Computer Scientist? I met the Runestone group at SIGCSE this year, really great fellows. I can't wait to see how much this interactive textbook project takes off.
Since you are a citizen member you should know they also make Unity tutorials, and given their quality, I doubt you would have a hard time getting into it. Your modelling/texturing/etc. can still be done in Blender, Unity as good support for Blender as far as I know. You would have to learn a different programming language, but since you don't know Python yet, thats not wasted time. But for that you would get a way more fleshed out game engine (and let's face it, the game engine is not one of Blenders killer features).
Especially with no programming experience!
http://www.lfd.uci.edu/~gohlke/pythonlibs/#backports
Seriously, I would say you're going about this the wrong way. Before you quit your job or decide to dedicate a good chunk of your life to game development, get some initial experience. See if you can create Pong, Breakout, Pac-Man first and most important of all, finish them. Actually finishing a game is hard, most people bail out or start something new, as it soon gets to be a challenge to stay focused. Once you complete a few games, you will know if its for you or not.
Whole !updrade? of a codebase AND the runtime? Wow, that could take months. Backports allow for gradual upgrade over time.
Many organizations have a huge investment in a big in-house system written in Python 2 that they are completely dependent on for their daily operations. The costs of upgrading and testing everything (as well as the disruption and business costs of the things they will inevitably miss in testing) are higher than the costs of supporting Python 2 for 5 or even 10 more years. Got any convincing arguments for them for why they should upgrade?
Good call. The latest Python Cookbook (that he is a co-author of) is great.
This looks really awesome. Ill probably use if for a project if it holds what it promises (metrics dashboard + alerts). Write me a pm if youre interested and/or want to help 
great stuff thx!
Oh yeah I guess I shouldve said this. I have worked some games before purely as a game designer and modeller. So my only hang up at this point is programming. But I do see what you're saying. I'm thinking of actually just biting the bullet and learning unity.
Oh don't worry about that. My wife will be making plenty of money. I can't work and focus on game developing at the same time. 
He probably wants to spend his free time with his wife, I don't think it's such a bad thing.
There's nothing *wrong* with looking for backports.. I'm just saying that they won't get you very far. Most of the features offered by py3 that are backportable are pretty minor, and will do very little to help "develop[ing] a python2.7/python3.4 codebase". If you want to write py3 code that runs on py27, that's obviously an admirable goal. Don't start by looking for backports, though, unless you already know you want them for something specific. Start instead by, well, doing exactly what you want: writing code that runs on py27 and py3. I'd say a better place to start would be: - run the 2to3 filters that generate py27 friendly code on your codebase regularly to correct yourself whenever you use "py2-isms" ex: 2to3 -nw -f has_key ./ 2to3 -nw -f except ./ 2to3 -nw -f idioms ./ 2to3 -nw -f execfile ./ ...etc (there are others that generate py27 &amp; py3 friendly code, I wish they would explicitly list them somewhere) - become familiar with [`six`](https://pythonhosted.org/six/), and use it! - spend some time here and there either upgrading old dependencies, or weeding them out (if the maintainers have no py3k plan) If you start doing this stuff iteratively as opportunity arises, you'll eventually find that the only thing holding you back from py3 is simply taking the leap. Again, finding a way to backport `pbkdf2` may be nice.. but make no mistake - it won't go very far at all towards making your code any more py3 ready.
oh, wasn't aware of that. I did dabble in blender a bit and really enjoy my time with it and never heard about that feature for some reason.
My condolences on the business (been there, lived through that). Some good, advanced Python 3 books include: [Programming in Python 3: A Complete Introduction to the Python Language (2nd Edition)](http://www.amazon.com/Programming-Python-Complete-Introduction-Language/dp/0321680561/ref=sr_1_1?ie=UTF8&amp;qid=1395257012&amp;sr=8-1&amp;keywords=mark+summerfield+python) A subset of the above - [Advanced Python 3 Programming Techniques](http://www.amazon.com/Advanced-Python-3-Programming-Techniques-ebook/dp/B001U9S9Z8/ref=sr_1_6?ie=UTF8&amp;qid=1395257012&amp;sr=8-6&amp;keywords=mark+summerfield+python) [Python in Practice: Create Better Programs Using Concurrency, Libraries, and Patterns](http://www.amazon.com/Python-Practice-Concurrency-Libraries-Developers/dp/0321905636/ref=sr_1_2?ie=UTF8&amp;qid=1395257012&amp;sr=8-2&amp;keywords=mark+summerfield+python) 
I was actually going to get rid of that part though. Referencing the top where everything was actually divided into sections here!
Done, now I have 3.4.0 as version
2.7 is a disaster. I said so back then and I'm being proven right every day. Best case in point: the Linux distros that use Python as a systems language. OMFG, what a circus! There was never anything wrong with simply supporting 2.6 and letting everybody who wants to move forward go to 3.x. Want the features in 3.x? Here's an idea you lazy bastards... update your code to support it! Don't want to update your code? FINE. Stay with 2.6! 2.6 works GREAT! See how easy that was?
&gt; See if you can create Pong, Breakout, Pac-Man first and most important of all, finish them. Or: How to lose all motivation to develop games
 Mac
This is really helpful. What does RDP mean?
Does anyone know if any of these particularly focus on Flask for web development? Seems like a lot of the web development resources rely on Django.
Yes because it's hard to write something that is more in-depth than the official documentation for a micro-framework where the main selling point is that you can choose your own architecture and details. You might be able to find something for a more specific use-case but for flask in general, you "just" need a good knowledge of web technology and grasp of python..
I thought the video part of the stream was done with traditional broadcast software like OBS or XSplit? I've never used these before so not sure if/how you can start them from the command line. For the text on screen you could probably start with a terminal and have the broadcasting software capture the part you want to display (at least as a start).
My final objective would be to be able to superimpose text on a camera feed and broadcast that on twitch, while being able to dynamically change the text with a running python script.
ffmpeg/avconv can be used to output a flv stream to twitch. I setup a basic script here: https://github.com/NetGnome/LinuxStreamer just put your stream key in .twitch_key and you should be good to go.
How would I go about overlaying text on the stream? And dynamically manipulating it?
Well, all this script does is take the X11 screen buffer and send it to twitch. So if you use tkinter or another GUI framework to draw to the screen that'll "work" to a degree.
Yeah, as I said, it's not the most praised feature and apart from recording physical interactions between objects its use for a 3D artist is basically non-existant, so no wonder you didn't notice it. I first thought you were just basing your opinion on ignorance. Glad i was wrong. :-)
I agree. 2.7 may have been the worst thing to happen to python.
I love Editra, and it uses Python 2. Sadly it hasn't been updated in over a year :(
its fixed now :)
Thanks, that's a lot better :).
Commenting just to save the links
try import antigravity edit. spelling on phone
Really? Im new to arduino. How does it stink so bad?
In 250 lines... Plus mongo. 
There is a save button under the links as well. Both ways work just fine though.
/r/learnpython /r/learnprogramming ***** ^This ^is ^an [^automated ^bot](http://github.com/WinneonSword/LFB)^. ^For ^reporting ^**problems**, ^contact ^/u/WinneonSword. ^The ^parent ^commenter ^may [^remove](http://www.np.reddit.com/message/compose?to=LinkFixerBotSnr&amp;subject=Comment%20Deletion&amp;message=%2Bdelete+cg75ero) ^this ^comment ^if ^they ^wish.
Thank you!
You also might consider [Panda3D](http://www.panda3d.org/). It's a 3D engine with a Pyton API. It has a reasonable-sized community and [good documentation](http://www.panda3d.org/manual/index.php/Main_Page).
Everything is always built on, with or including something else unless you are hand writing binary code, why bitch about it?
Save the links? Whenever you see a list of 50+ programming resources, that means some intern spent the afternoon on Google. Most of their work was filtering out other lists of 50+ resources.
&gt; become familiar with six, and use it! Python &gt;= 2.6 and &gt;= 3.3 did a lot to become more compatible with each other. Now, a lot of the things `six` does can also be done more quickly and cleanly with `__future__` imports. If you use lots of functions that changed in 3.x, or if you use language features that changed entirely such as metaclasses, six is still important. But if you just want your Python 2 code to be more future-proof, here's a great way to start: # coding: utf-8 from __future__ import print_function, division, unicode_literals 
I'm not saying it's not the right didactical approach, but I know from experience trying to do everything according to the manual will suck the life out of you. Maybe that's just me though. 
Fault-tollerant and relies on MongoDB :)
Understand not all are the same, and there is no single way to do anything. But its a tried and tested path taught over and over, and that way for reason Its a bit like when you learn to draw, you start with primitives (spheres, cubes etc). Its not as fun as drawing dragons, but in the long run all the boring stuff pays off, a lot. Without the key foundations, you would otherwise need to go back and relearn away all the bad habits you have gathered. But then again, if it worked for you, I won't be arrogant enough to try claim to know better then your own experience. 
 import logging logging.warn("foo") How much easier are you looking for? What are the various reasons you have a hard time getting your head around it?
I learned to make this in about 3 hours from scratch, that is not knowing any python at all, a friend had a request and so I decide to learn this awesome language by helping a friend.
These days, a library like [requests-futures](https://pypi.python.org/pypi/requests-futures/) will bundle all that logic up for you! 
[This](http://www.shutupandship.com/2012/02/how-python-logging-module-works.html) really helped me get my head around the logging module when I first started using it. Hope this is helpful.
Thanks, I'll check it out!
Why not just watch the video [Become a logging expert in 30 minutes](http://www.youtube.com/watch?v=24_4WWkSmNo). ;)
That would be because python's logging module is exceptionally bad. I never used an alternative seriously, to my regret, but here are a few that seems like nice options: * https://github.com/mitsuhiko/logbook * https://github.com/MHordecki/LogPy * https://github.com/wearpants/twiggy
[CasparCG](http://www.casparcg.com/) is an open source video graphics system by a state broadcaster in Sweden, it works mostly off flash, and controlling the text in the flash documents is controlled through an API. The broadcaster makes C# control systems to interact with the API. I am going to bet that this is probably too complex of a solution though. 
I applaud your efforts. The thing is, though, I have no idea what it does. Yes, I could wade through the code to figure it out, but I'm not going to. So you *might* consider documenting it. No need to go overboard with it, just enough so that someone knows what the program actually does, and a bit about how it does it. See [PEP 8](http://legacy.python.org/dev/peps/pep-0008/). Other than that, again, I applaud you.
vsajip, I appreciate the effort that went into the logging module, but honestly for a long time I simply didn't get it. Now, I'm not the sharpest knife in the block but i'm not the dullest either, but it took a good while for it to make sense, perhaps its the documentation, perhaps its the fact that it can do a lot, I honestly don't know. I grok the logging module now, but every now and then when people ask questions like this, I wonder what the issue is, now it seems so simple and down right obvious. but, I remember the many hours of frustration spent trying to understand why i had no log output, somewhere in a past almost forgotten...
Sure man, I will get on updating GIST with comments right away. But here's what happens: 1). Get current execution location, set it to 'take' variable. 2). Create a folder named 'cleanedUp', and a folder inside of it by means of os.path.basename(take), allocate this location to 'give' variable. 3). Traverse through 'take' directory, and create new folder's inside 'give' path according to found file extensions by calling make_dir(dirname) function I made which just checks if directory exists or not, and if not makes one 4). When directory has been made move the file to the location preserving the name, using move_file(fr, to) which also checks if there is a file already or not, due to windows quirks the system would throw an exception if there was a file already, so if there is nothing then move, otherwise ignore. 5). Report the new location. 6). Repeat from step 3 till traversed whole folder, that is, not including any other possible folder's on the screen. Also, the part of folder os.path.basename(take) was my friends special request, please ignore it and/or remove if wanted.
The fun-sucking libraries ;)
I'm not a python guru, but there are a few things that pop to mind: * `if &lt;condition&gt; == True:` is awkward and unnecessary, just go with `if &lt;condition&gt;:`, or `if not &lt;condition&gt;:` rather than `== False`. * [os.path.splitext](http://docs.python.org/2/library/os.path.html) exists for what you're doing, but better still, consider using [mimetypes](http://docs.python.org/2/library/mimetypes.html), which will allow you to, for instance, identify all video files, rather than having a dir for each of .mov, .mp4 etc. * I'd be inclined to make a single stand-alone function to do the right thing to one file, then run it for each appropriate file in the dir 
I might aswell make v2 :) All suggestions are always appreciated.
Any reason to use this over jedi-vim/YouCompleteMe ?
With broadcast software it does that for you. You put a rectangle over the thing you want to capture and then it displays it. So you would capture the main game window, then have a small rectangle over your text display (start with a terminal). OBS, XSplit, or other broadcasting software would show both captures as one video stream. Get the basic functionality behind the project done. Don't worry about all the specifics right away. I've also seen people use the broadcasting software to have scrolling banners, but not sure if you can programmatically change the text.
I was just messing with mimetypes, and it's not all that clean. For a lot of stuff it gives "application/foo", where foo is not very user-friendly. Not sure what you want, but a combo of the two might work out: mimetypes (type.split('/')[0]), unless it's application/foo, then use extension. def dirname_from_file(pathname): """Generate a dirname to put pathname into """ result, _ = MimeTypes().guess_type(pathname) if result is None: result = "unknown" else: result, second = result.split('/') if result == "application": result = os.path.splitext(pathname)[1] return result Python is fun though - and the learning process always seems to involve making progressively simpler and cleaner code. Definitely consider putting docstrings in every function. check out list comprehensions, for example files = [f for f in os.listdir(".") if not os.isdir(f)] 
This article is from 2008.
Cool. The main thing I'd like to know upon encountering it, though, is what it does. When you say, 'clean your folder,' what does that mean? Does it delete files? Move them somewhere else? And I don't want to have to dig through the code to find that out. So a comment at the top of the file might read something like this: ''' Creates a folder and moves all files from a designated folder to it. ''' Or something like that. Then I would know if it even interests me, and if so, I'd be more inclined to look at the code to see how you do it. But please, don't take this as criticism. Your first product is way, way more impressive than my first product was.
[Documented in the cookbook](http://docs.python.org/2/howto/logging-cookbook#using-file-rotation). I still don't see what's especially complicated to understand, but if you give me some specifics I'll see if any improvements can be made.
[Another useful learning resource](http://eric.themoritzfamily.com/learning-python-logging.html).
Multi-Threading is not a very effective means of achieving performance increases in Python due to the GIL. It even says so in the sidebar of the linked article. Not sure what the point of this is. 
Victor Lin wrote a great reference on how logging works a while back. [Check it out and see if it lends any clarity.](http://victorlin.me/posts/2012/08/26/good-logging-practice-in-python)
Just as a heads up, this version seems to have borked hard with my current Eclipse install; the default PyDev perspective isn't loading any project contents (giant red exclamation point stop sign where project content would otherwise be expected). Guess I'll try LiClipse until I can figure it out.
[I made a second version if you want to look,](https://gist.github.com/ZetaHunter/9664531) oh and I credited both of you in code for helping me. I changed the code by your suggestions. I to be honest don't know about mimetypes though, but I believe you are more experienced than I am, so I will trust ya its better that way. 
The 'URL fetch threaded' example, with there happening to be 5 threads + the length of the URL list being 5, then with each thread signalling self.queue.task_done() within their "while True" loop is going to grossly confuse newbies as to 'why the hell did the example work' when / if they adapt this pattern to M tasks / N workers.
[Structlog](http://www.structlog.org/) is worth checking out.
Please downvote the main post too... 
I hate these losers who pump their reddit karma with random python articles and projects...
I chose to use MongoDB because of the simplicity of setting up a replica set that makes fault tolerance so easy. This doesn't use MongoDB's "fire and forget" mode. You should definitely use `w='majority'` and `j=True` as write concern options for a replica set (which is noted in the readme).
Only one module is supposed to do the configuration right? Everything else just does import logging and logs? Where do you put the configuration and set up? Where in your opinion is the best place for it?
Is there now decent documentation for setting up a logging configuration file?
I like to use a logging configuration file so in the python code you simply do: logFile = "logconfigfile.conf" logging.config.fileConfig(logFile) logger = logging.getLogger("xconnect_db_logger") logger.info('Log file opened') I had to find the log config file documentation elsewhere, what was on the python site at the time didn't give any details.
True... Mongo definitely did help me keep it simple, which was my goal.
Yeah. This is more of an issue of familiarity. Have you taken the time it requires to get something working with rotating files? Then, did you try and simplify it down to the (seemingly) simplest form? That'd be a very good learning experience. Whenever I've ever not wanted to use a library residing in stdlib it has been an issue of understanding. In very uncommon/infrequent situations, I'll have logical and reasonable beefs with something in stdlib, but most times there's already an effort to try and resolve it in the community -- or its stuff like breaking compatibility between Py3 and Py2x that's just how its going to be, according to the BDFL.
~~Nope!~~ Actually, [yeah](http://docs.python.org/2/howto/logging-cookbook#an-example-dictionary-based-configuration).
The most confusing parts for me tend to be: 1) I want a module, submodule, etc to all have different logging levels, and go to different Handlers based on differing severities. E.g. a flask app, for example. I want the DEBUG and higher info from my app to go to these 2 handlers, but I want only the CRITICAL and higher from werkzeug to go to the same 2 handlers (because werkzeug overuses INFO, IMO). Where is the right place to define all of those? A log config file? How / where should I instantiate a Logger? In every module? Should it inherit from the importing module? A specific suggestion: More *pictures* about the flow (like here: http://www.shutupandship.com/2012/02/how-python-logging-module-works.html) would be fantastic. If you want to see a system I think is *more* intuituive, see Logbook: https://pythonhosted.org/Logbook/features.html 
Because contrary to the title, you leave that video with only superficial knowledge that some stuff exists in the logging module.
THe logging config file is not too painful, at least the bits I know. The real pain was looking on the Python site and trying to parse the "documentation". I am always sad when the top hits on a python search point me to the official python site, I know I am in for a slog.
Like you, it also took me a long time to truly understand the logging module, but I get most of it now (still not too clear on what filters are for). Some concepts that tripped me up were: * hierarchical loggers - `foo.bar` propagates log messages to `foo`; *everything* propagates to the root logger, `''` (empty string); third party libraries' logs can be acquired if you understand this * the difference between loggers and handlers (especially with regards to the logging level, which must be set for each) * what the hell `logging.basicConfig` actually does, and that it is not needed for every application I think the documentation does explain everything, but in too many words. Most programmers only skim through it until they find the parts that they need. I know... people will say to RTFM, but really, nobody has the patience to read the entire thing. edit: Actually, the logging cookbook was one of the things that made it easier to understand logging, in case /u/vsajip reads this.
I recently made [this](http://www.github.com/daneah/basiclogging) module for quick and dirty module-level logging across an application. Doesn't do rolling file logs, but could probably be extended easily to do so.
OK
I saw that, I need to try it for sure. I didn't realize there was a dictConfig() in the logging.
Are you planning on selling your game, or this is just a hobby project you want to take on?
try this www.depthcharged.us ? The sites not running on port 80 so maybe its something on your end
Questions: Do people pass logging objects around or do you import them from a single location? If the latter, how do you send data to two different log files (e.g. one for each instance of a class). If you try to avoid having massive classes and global variables (e.g. functional programming), how do you use logging? How do you stop &amp; start a logging object and just update the path to the log file?
Coming from someone whose previous development tool's documentation was almost entirely a set of class references, I find the Python documentation amazingly awesome. 
Psychology is important.
Using [logbook](http://pythonhosted.org/Logbook/) here. So far, so good, and it's an improvement on the basic logging module.
It a little bit of both. The logging example that vsajip wrote works well unless you want to change a minor thing, then suddenly you no longer can use basicConfig and have to write several statements to get to at least do same thing that basicConfig did. The documentation is complicated because the module is complicated. Also I remember having issues (didn't remember the details now) with using it with syslog, I think it did not print the messages right or something.
I am confused w.r.t asyncio and this new Redis client library. What is it doing differently and better than https://github.com/andymccurdy/redis-py? I use the latter with my Redis setup and it works just fine.
That is actually what I was looking for! Thanks!
That's nice! Welcome to Python, and it really looks like you are enjoying it :). I made some brief revisions if you don't mind (https://gist.github.com/rasbt/9669548/revisions) - maintaining the function, but just some sugar to make it look like more Pythonic: e.g., - if os.path.isdir(dirname) != True: + if not os.path.isdir(dirname): - if os.path.isfile(to) != True: + if not os.path.isfile(to): - if (os.path.isdir(name) != True) and (name != os.path.basename(__file__)): + if not os.path.isdir(name) and name != os.path.basename(__file__): - print(name, "Moved to " + os.path.join(give, splited[len(splited)-1], name)) + print('{} Moved to {}'.format(name, os.path.join(give, splited[len(splited)-1], name))
Sure man, enjoy, btw I have made a variation of the script its on my gists and there is a link to it here, also I am doing http://www.pythonchallenge.com (got to the level 4 so far)
Don't do multi-threading stuff in Python. Multi-process? Yes. Microthreads? Yes. But not multi-threading. This is actually a *good thing* because threads are a suboptimal solution to a very complicated problem. Multi-processing with a simple IPC or microthreads solve a lot of the problems that threads have.
 itertools.chain.from_iterable(yourlists) don't try to be clever.
Under ten lines is trickly, have plenty of modules I have been happy with. It would either have to be regex to validate all valid windows paths to MSDN specs: re.compile(r'^(?:[a-zA-Z]:\\|\\\\?|\\\\\?\\|\\\\\.\\)?(?:(?!(CLOCK\$(\\|$)|(CON|PRN|AUX|NUL|COM[1-9]|LPT[1-9]| )(?:\..*|(\\|$))|.*\.$))(?:(?:(?![&gt;&lt;:/"\\\|\?\*])[\x20-\u10FFFF])+\\?))*$') That or turning the standard config parser output into a standard dictionary in a single expression that is python 2.6 compatible: dict((section, dict((k, v) for (k, v) in cfg_parser.items(section))) for section in cfg_parser.sections()) 
I like the idea but don't think this usecase justifies using django + flask. I'd either use flask-login, build my own login (it's suprisingly easy to build your own login and after you build it once you can use it again and again) or use django + djangorestframework. Interesting post nonetheless. 
a python3 quine: quote, quine = '"""', """quote, quine = '{0}', {0}{1}{0} print(quine.format(quote, quine))""" print(quine.format(quote, quine)) that, and a minimal png encoder (50 lines though): https://bitbucket.org/rndblnch/opengl-programmable/src/tip/png.py 
Are you going to let Blender handle the monstrous rendering or are you going to use something else? (pyglet, PyOpenGL)
proud is a strong word but I use this little snipped I've coded in almost every web project import random def rstr(length=5, special_chars=True, numbers=True, upper_case=True): chars_lower = 'a b c d e f g h i j k l m n o p q r s t u v w x y z' chars = chars_lower.split() chars += chars_lower.upper().split() if upper_case else [] chars += '1 2 3 4 5 6 7 8 9 0'.split() if numbers else [] chars += '! $ &amp; / ( ) * + - _ &lt; &gt; = ? #'.split() if special_chars else [] return ''.join([chars[random.randint(0, len(chars)-1)] for i in range(length)]) I use this to create random strings for salts and such edit: new version thanks to therealfakemoot(awesome username) and indosauros def rstr(length=5, special_chars=True, numbers=True, upper_case=True): chars = string.ascii_lowercase chars += string.ascii_uppercase if upper_case else '' chars += string.digits if numbers else '' chars += string.punctuation if special_chars else '' return ''.join(random.choice(chars) for i in range(length)) ran timeit on both t1 = timeit.timeit(rstr_old, number=1000000) &gt;&gt;&gt; 41.53192969999509 t2 = timeit.timeit(rstr_new, number=1000000) &gt;&gt;&gt; 26.02017455000896 almost twice as fast. awesome. &lt;3 /r/Python 
FFT implementation that is just... elegant. pi = 3.14159265 import math def exp(z): if not isinstance(z,complex): return math.exp(z) return math.exp(z.real)* (math.cos(z.imag)+complex(0,math.sin(z.imag))) def _fft(x): N = len(x) if N &lt;= 1: return x even = fft(x[0::2]) odd = fft(x[1::2]) return [complex(even[k]) + exp(-2j*pi*k/N)*odd[k] for k in range(N//2)] + \ [complex(even[k]) - exp(-2j*pi*k/N)*odd[k] for k in range(N//2)] def fft(x,f=0): """Fast fourier transform.""" if f: return _fft(x) else: return [abs(n) for n in _fft(x)]
Awesome!
 import random def random_string(length=8): chars = 'abcdefghijklmnopqrstuvwxyz0123456789' return ''.join(random.choice(chars) for _ in range(length)) I actually wrote this one yesterday for a work project. Not as configurable as yours as-is but it uses random.choice() instead of direct index access. It also avoids using extraneous .split() calls because strings are indexed sequences themselves.
To throw out one more tip, the `string` module has a few useful sets of characters if you don't feel like typing out the whole alphabet: &gt;&gt;&gt; import string &gt;&gt;&gt; string.ascii_letters 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' &gt;&gt;&gt; string.ascii_uppercase 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' &gt;&gt;&gt; string.ascii_lowercase 'abcdefghijklmnopqrstuvwxyz' &gt;&gt;&gt; string.punctuation '!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~' &gt;&gt;&gt; string.digits '0123456789' &gt;&gt;&gt; string.hexdigits '0123456789abcdefABCDEF'
I think the main problem with Python logging is that there are so many options that it's often a nightmare for someone to find the 5% that they actually care about. The simple example is fine for a trivial program. But suppose your program isn't trivial, so you'd like a few fields in the log file (date, module, how about a batch id?), maybe you'd like to control log rotation, or have different log levels for different modules? What if you'd like to implement a kafka log consumer? So, the simple logging example is deceptive - while that's easy, almost immediately people need to step beyond it and then they fall straight into the deep end of the pool.
Nice :)
For League of Legends 3rd party API: grabs 5 player's in-game Mastery page selections at the same time and places them in a json file labeled for the team. def outputTeamCurrentMasteryPage(region, summoners, team): urls = [("https://teemojson.p.mashape.com/player/%s/%s/mastery" % (region, summoner)) for summoner in summoners] with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: futures = [executor.submit(load_url, url) for url in urls] for future in concurrent.futures.as_completed(futures): contents = future.result().content result = json.loads(contents.decode("utf-8")) for talentEntries in result['data']['bookPages']['array']: if talentEntries['current'] == True: write_json("json/masteries/%s/" % team, "%s_currentmasterypage.json" % result['player']['name'], talentEntries)
I basically followed these instructions, replacing 3.3 with 3.4 whenever needed http://askubuntu.com/questions/244544/how-do-i-install-python-3-3
Ooh, this is way cleaner than what I've been doing. I've found it useful to keep a dict of timers around so I can run different timers on different steps, thereby determining where in the code is most ripe for optimization. (Also keep in mind that the timer being turned on or off takes time as well.)
Isn't this what twod.wsgi is for
I work for publishing company, to prove a point to my boss, I wrote a script to automatically grab Amazon Bestsellers ranks for all of our titles. I was pleased with how simple it worked out. This was before I learnt about regexes or xpath, so this task has now been subsumed by my all singing all dancing web scraping device. Context: My boss used to do web scraping with VBA for Excel. Made my eyes puke frosted blood all over my monitor. import sqlite3,csv,urllib2 database=sqlite3.connect('amazonrankscom.db') cursor=database.cursor() for isbn in [[row[0],row[1]] for row in csv.reader(open('isbns.csv','rb'),delimiter=',')]: try: therank=urllib2.urlopen('http://www.amazon.com/dp/'+isbn[1]).read().split(' in Books ')[0][-10:].replace('\n','').replace(',','').replace('#','') database.execute('insert into ranks values("'+isbn[1]+'","'+time.strftime("%Y-%m-%d",time.gmtime())+'","'+therank+'")') except: print isbn[0]+' messed up' database.commit() database.close()
I don't remember *where* I found this but it helps oh so much when working with threaded code: def print_thread_stacks(logger): import traceback,sys logger.warn("\n*** STACKTRACE - START ***\n") code = [] for threadId, stack in sys._current_frames().items(): code.append("\n# ThreadID: %s" % threadId) for filename, lineno, name, line in traceback.extract_stack(stack): code.append('File: "%s", line %d, in %s' % (filename, lineno, name)) if line: code.append(" %s" % (line.strip())) for line in code: logger.warn(line) logger.warn("\n*** STACKTRACE - END ***\n") (yes its 11 lines, but you can strip two or three down depending on your imports and if you care for the start/end warnings)
For dict'ing a ConfigParser: dict((section, dict(cfg_parser.items(section))) for section in cfg_parser.sections())
I realised the above is 11 lines, and also not every elegant. So here's a little thing I wrote to help out in my web scraper: takes an arbitrary json style object (full of key/valuepairs and lists) and performs a function on every string/unicode/integer value in there: def parse_thing(object, function): simples = [int, float, str, unicode] cases = { dict: lambda x: {a: parse_things(b, function) for a, b in x.items()}, list: lambda x: [parse_things(a, function) for a in x], } if type(object) in simples: return function(x) else: return case[type(object)](object) This thing has ended up being very utilitous. *Edited to actually run!!
I'm just an intermediate programmer at best. I have done like 60 Project Euler problems, which really made me like prime numbers and really want to look into generating a list of prime numbers quickly. def sievePrimes(maximum): primes = dict.fromkeys(range(3,maximum+1,2),True) sieveList = [2] for num in sorted(primes): if primes[num] == True: sieveList.append(num) j = num ** 2 while j &lt; maximum: if j in primes: primes[j] = False j += num return(sieveList) So, that's 13 lines, but I'm still pretty proud of implementing a sieve method that runs quickly in Python. I can get all primes up to 1,000,000 in a second on my very slow computer at work. On my speedy home computer, I can get the same almost instantly. 
The [deadsnakes ppa](https://launchpad.net/~fkrull/+archive/deadsnakes) has 3.4 but it's RC3 - not sure if RC3 is actually the final ... 
Smells like a design problem. You can compensate for poor design with more and better organized documentation and yet another cookbook and tutorial but it's a waste of resources. The good news is that bad design has value. It acts as a filter. Only the brightest/most motivated can get past it. Once over the steep learning curve then the design is no longer a roadblock. The end result is you have managed to collect a group of the best and brightest to defend your product.
Need to parse [Intel HEX](http://en.wikipedia.org/wiki/Intel_HEX) files? import sys with open(sys.argv[1],"r") as fp: inputtext = fp.readlines() data = [ (int(line[1:3],16) , int(line[3:7],16), int(line[7:9],16), ((sum([int(line[i:i+2],16) for i in range(1,len(line)-1,2)])%256)==0), line[9:-2]) for line in [line.strip() for line in inputtext if line.startswith(":")]] If you want it to automatically raise an exception when a record has a bad checksum: data = [ (int(line[1:3],16) , int(line[3:7],16), int(line[7:9],16), 1/((sum([int(line[i:i+2],16) for i in range(1,len(line)-1,2)])%256)==0), line[9:-2]) for line in [line.strip() for line in inputtext if line.startswith(":")]] 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Intel HEX**](http://en.wikipedia.org/wiki/Intel%20HEX): [](#sfw) --- &gt; &gt;__Intel HEX__ is a [file format](http://en.wikipedia.org/wiki/File_format) for conveying binary information for applications like programming [microcontrollers](http://en.wikipedia.org/wiki/Microcontroller), [EPROMs](http://en.wikipedia.org/wiki/EPROM), and other kinds of chips. In a typical application, a [compiler](http://en.wikipedia.org/wiki/Compiler) or [assembler](http://en.wikipedia.org/wiki/Assembly_language#Assembler) converts a [program's](http://en.wikipedia.org/wiki/Computer_program) [source code](http://en.wikipedia.org/wiki/Source_code) (such as in [C](http://en.wikipedia.org/wiki/C_(programming_language\)) or [assembly language](http://en.wikipedia.org/wiki/Assembly_language)) to [machine code](http://en.wikipedia.org/wiki/Machine_code) and outputs it into a HEX file. That file is then imported by a [programmer](http://en.wikipedia.org/wiki/Programmer_(hardware\)) to "burn" the machine code into a [ROM](http://en.wikipedia.org/wiki/Read-only_memory), or is transferred to the target system for loading and execution. &gt; --- ^Interesting: [^SREC ^\(file ^format)](http://en.wikipedia.org/wiki/SREC_\(file_format\)) ^| [^EPROM](http://en.wikipedia.org/wiki/EPROM) ^| [^Binary-to-text ^encoding](http://en.wikipedia.org/wiki/Binary-to-text_encoding) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg7p4jw) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg7p4jw)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I can't tell if you're joking or not...
I am quite a newbie to the world of programming in general and I find this very beautiful, elegant and (largely) self-explanatory - three things I desperately aspire to do in my code. Thank you for this snippet. Now if you'll excuse me, I have go and rewrite some chunks of my code... :(
Don't do that. Python comes with profiling tools. In fact, you can just do `python -m cProfile myscript.py` to get per-call timing inforation. Install `line-profiler` if you want to to consolidate per original line of code nicely.
Python comes with a timer that works pretty much the same way. http://docs.python.org/2/library/timeit.html
The biggest problem I have with logging is that sometimes it just doesn't work in larger applications with multiple 3rd party libraries and I cannot figure out why. In almost every instance the [logging_tree debugging tool](https://pypi.python.org/pypi/logging_tree) solved the problem by showing where the messages were being blocked by some errant bit of configuration. Seriously, logging_tree is where it's at.
That did it! Thanks! And just a heads up for everyone else, in order to be able to run "py &lt;filename&gt;.py" from any directory, I made a symbolic link to the python3.4 executable. sudo ln -s /opt/python3.4/bin/python3.4 /bin/py
Neat. I like this a lot. It's clean and straightforward.
I made a similar function for Project Euler problems (sieves are super interesting to me for some reason). I'm not sure if starting with num**2 is accurate though? def primes(maxp): sieve = [True for x in xrange(maxp)] prime_lst = [1] prime_set = set(prime_lst) for i in xrange(2, maxp): if sieve[i]: prime_lst.append(i) prime_set.add(i) for j in xrange(2*i, maxp, i): sieve[j] = False return prime_lst, prime_set
Obviously, everybody will have done this before, but I think the lambda function for checking a palindrome is great. Simple stuff, I know, but it's clean and consise. is_palindrome = lambda s: s == s[::-1]
But what if you want a low-precision approximation of pi? Then you have to roll your own. :D
I'm pretty sure it'll be faster if you make primes a list rather than a dict. Random access into a list is guaranteed to always be O(1), whereas for a dict it's amortized O(1) and probably has a bit more overhead too. It'll also save you from sorting the dict's keys. Also, it is sufficient to loop num up to sqrt(maximum) rather than all the way to maximum. This will be a huge speed up.
The first two class functions we're of great use working with symmetric ciphers (usage in the last two functions): def pad(self, bfile): return bfile + (self._BLOCK_SIZE - len(bfile) % self._BLOCK_SIZE) * chr(self._BLOCK_SIZE - len(bfile) % self._BLOCK_SIZE) def unpad(self, bfile): return bfile[0:-ord(bfile[-1])] def encrypt(self, crypto, data): print('encrypting...') cdata = crypto.encrypt(self.pad(data)) return cdata def decrypt(self, crypto, data): print('decrypting...') ddata = self.unpad(crypto.decrypt(data)) return ddata
Well good, I'm glad that will work for you, they have several videos about how to set up the flash documents on YouTube if you haven't already found them. I tried to figure it out a couple years ago, except the program refused to work with my lack of a proper video card.
Ah, yeah, should have shortened it to that. I removed the part that does keyword lookups and name sanitization with each items is why I need them seperate in my code, but thought that wasn't worth adding here. Good catch! 
 import sys r = int(sys.argv[1]) for y in xrange(-r*1.3,r*1.3,2): for x in xrange(-r*1.3,r*1.3): sys.stdout.write('#$@%&amp;0*;:,. '[min(abs(r*r - (x*x+y*y))/(r/2), 11)]) print Prints pretty ASCII circles e.g. for r=10, ,;*0&amp;&amp;&amp;0*;, ,*%$#@%%%%%@#$%*, ,*@#%0;:,...,:;0%#@*, ,0$@0;. .;0@$0, .*$@0: :0@$*. ,&amp;#%;. .;%#&amp;, ,&amp;#%;. .;%#&amp;, .*$@0: :0@$*. ,0$@0;. .;0@$0, ,*@#%0;:,...,:;0%#@*, ,*%$#@%%%%%@#$%*, ,;*0&amp;&amp;&amp;0*;, 
Less than 10 lines of actual code def memoize(f): """ Memoization decorator. &gt;&gt;&gt; @memoize ... def fib(n): ... return 1 if n &lt; 2 else fib(n-1) + fib(n-2) ... &gt;&gt;&gt; fib(100) 573147844013817084101 """ cache = {} def helper(*args): if args not in cache: cache[args] = f(*args) return cache[args] return helper 
Just wrote something very similar to this today: from string import ascii_lowercase, ascii_uppercase def create_slug(profile): pool = list(ascii_lowercase) + list(ascii_uppercase) + [str(i) for i in range(10)] slug = "".join([random.choice(pool) for i in range(7)]) return slug 
Generating all valid clauses of a CFG specified as BNF from itertools import chain, product from re import match, findall GRAMMAR = ''' &lt;sentence&gt; ::= &lt;noun phrase=""&gt; &lt;verb phrase=""&gt; &lt;noun&gt; ::= "boy " | "troll " | "moon " | "telescope " &lt;transitive verb=""&gt; ::= "hits " | "sees " &lt;intransitive verb=""&gt; ::= "runs " | "sleeps " &lt;adjective&gt; ::= "big " | "red " &lt;adverb&gt; ::= "quickly " | "quietly " &lt;determiner&gt; ::= "a " | "that " | "each " | "every " &lt;pronoun&gt; ::= "he " | "she " | "it " &lt;noun phrase=""&gt; ::= &lt;determiner&gt; &lt;noun&gt; | &lt;determiner&gt; &lt;adjective&gt; &lt;noun&gt; &lt;verb phrase=""&gt; ::= &lt;intransitive verb=""&gt; | &lt;transitive verb=""&gt; &lt;noun phrase=""&gt; ''' def parse(g): return dict([(w.strip(), [findall(r'(&lt;.+?&gt;|".+?")', s) for s in m.split('|')]) for w, m in [d.split('::=') for d in g.strip().splitlines()]]) def generate(term): return findall(r'"(.*?)"', term) if match('".*', term) else chain(*[map(''.join, product(*map(generate, p))) for p in syntax[term]]) syntax = parse(GRAMMAR) print list(generate('&lt;sentence&gt;'))
Selecting an optimal next move in Nim def nextMove(g): for p in xrange(len(g)): for n in xrange(1, g[p]+1): if reduce(int.__xor__, g[:p] + [g[p]-n] + g[p+1:]) == 0: return p, n return None, None
Hmm. Doesn't work for me.
I love this.
I'm a python beginner, but it's giving me a syntax error in the func=print of the init function, any idea what this is?
Wow. Exploded my laptop but I got a load of sentences that MADE SENSE
The way a sieve works you can be sure that all non-prime numbers below num^2 are already removed. We can demonstrate this pretty easily. In my code I start at 3 with no even numbers, but let's look at it starting at 2 and having even and odd numbers. We'll choose a max of 25. &gt;[**2**,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25] We know that 2 is prime, so we leave that as is. Since, 2^2 is 4, we start there, noting that 3 is prime. Scratch 4 off the list, then adding 2, scratch each off number off the list. This gets rid of all the even numbers. &gt;[2,**3**,5,7,9,11,13,15,17,19,21,23,25] Now we find the next number, which is 3. So, 3^2 is 9. We can verify that the numbers left between 3 and 9, (5 and 7) are prime. We know that 9 is not prime because it has 3 as a factor, so it and every other multiple of 3 gets removed. &gt;[2,3,**5**,7,11,13,17,19,23,25] The next number is 5. Again, we can go to 5^2, or 25, we can verify that each number between 5 and 25 left in our list is already prime. So, we remove 25 and stop, as it's the only other multiple of 5 left in our list. This works for any number, ***if and only if*** we started the sieve from the beginning and went in order. Otherwise we can't guarantee that all of the numbers between were removed.
Memoizes recursive functions so outputs are only calculated once for each input. Useful when you want the efficiency of dynamic programming without unfolding the recursion.
Also thanks :)
I'm really glad you like it!
Cool! I love little things like this. I'd maybe spell it like chars = ''.join(chr(x) for x in range(ord('a'), 1 + ord('z'))) chars += [c.upper() for c in chars] if upper_case else [] Either way the `split()`s aren't needed because strings are themselves iterable.
 pass I'm most proud of the code I didn't have to write.
I ended up using a dict because I'm unable to modify a list as I'm looping over it. In a sieve, you have to remove numbers from the list, but still iterate over that list. If there's a way to use a list in this way, I'd love to learn it! And I certainly agree with you about only going up to sqrt(maximum) but because I'm appending the resulting primes to a list I have to loop over all of the numbers over sqrt(maximum) so that I put all of the primes into the resulting list. It would be much much faster, for sure, if I could just modify the list as I'm iterating over it. Since I'm removing elements, though, python gets a little angry at me when I tried that. 
So `fs` is a list of functions, and `compose` returns a function that accepts `x`. Then, `x` is appended to the list of functions? Isn't `x` the initial value that should be the third argument to `reduce`?
You need to run this code using Python 3 where print is a function.
You can modify a list as you loop through it. Just loop over its indices as opposed to its items. Also, you shouldn't need to remove items from it, only mark elements as true and false. My implementation that I use for Euler (note that after about problem 200, you start requiring faster primality algorithms): def primes_to(n): """List of sorted primes in [2,n]. &gt;&gt;&gt; primes_to(10) [2, 3, 5, 7] &gt;&gt;&gt; primes_to(11) [2, 3, 5, 7, 11] """ isPrime = [True for i in range(0, n+1)] for i in range(2, int(n**0.5)+1): if not isPrime[i]: continue for j in range(i*i, n+1, i): isPrime[j] = False return [x for x in range(2,len(isPrime)) if isPrime[x]]
 (True, False) = (False, True) Confuses everybody every time ;)
That works too, and it's neater. I didn't know about the optional third argument to reduce. Edited, thanks.
Just be careful of memory leaks, as the cache will never be cleared for the lifetime of the program.
Yeah, I only use this for little scripts and Project Euler problems.
I plan on selling my eleventh game. (No joke)
Here's a nice flatten routine to iterate through the base elements of lists of lists of lists ... import collections def flatten(iter): for elem in iter: if isinstance(elem, collections.Iterable) and not isinstance(elem, basestring): for sub in flatten(elem): yield sub else: yield elem 
Hardly ingenious by any means though
This is the prime number sieve I used back when I was doing project euler problems. Instead of removing elements, I just set them to zero, then build my list from non-zeroed values. def sieve(maximum): if maximum == 2: return [2] elif maximum &lt; 2: return [] # odd numbers from 3 to maximum numbers = range(3, maximum+1, 2) max_root = maximum ** 0.5 length = len(numbers) pos=0 value=3 while value &lt;= max_root: if numbers[pos]: # location of value^2 in numbers start = (value**2-3)/2 count = len(range(start, length, value)) numbers[start:length:value] = [0]*count pos += 1 # next odd number value = 2*pos + 3 return [2]+[prime for prime in numbers if prime]
**3.14159265**35... Nope, checks out.
I feel kinda bad that my [highest ranked](http://www.reddit.com/r/programming/comments/am0ot/the_greatest_program_ever_written/c0iafzp) programming submission is this: import base64,bz2 a = ("QlpoOTFBWSZTWTrEDs0AAD7/gH/wQABA+4AYCAAABOKA" "jEVAAbxtmGDU2qemiZTE/VPUaeoBpoGmISKeppo9TTaE" "aepoGGCYEwENGTTASalNGpGaNQ0GjE8pp7dB5tJARkGK" "kWAUkphDafs1nxNZtNZtN09zJJDfhDfwa49LWeTjPoQR" "vBTajxdsU4ASFeXf+tzImLJCHd8MCQXhlaxg8pfiQyWg" "ROubFUr99Krmr2QUg7MPaUyASUNsABUKRYgFNjCK6YQ0" "lPq9GTPLLPdsecHTFTHG2CeaUz1bsyL1fcl3BSlS6GaD" "Yrxg11crkriTDQj6E0JoTLgRAzTNHWuryR1Q6NY69963" "E6Bt4uUoQy3qpKzQbVkObd+ECUDc55YqFKUvTF86vyiB" "2Bzs2rMxJ5FeihbqBEpDK0iBFBu031JTBN2+nHi+H4EI" "Jfm4Yhn+cIQzbhCHXrIkQUygxBMyhDjWqJUI9ptR1vxi" "L1qJaxoFBJqgmiJTgzBH3a6CVVJ/baj+LuSKcKEgdYgd" "mg==") print bz2.decompress(base64.b64decode(a)) 
&gt; You can modify the value of an item in a list, but you can't make modifications that change the length of the list. Not true. Proof: primes = [i for i in range(3, max + 1, 2)] prime_count = len(primes) i = 0 while i &lt; prime_count: number = primes[i] j = number**2 while j &lt; maximum: if j in primes: primes.remove(j) prime_count -= 1 j += number i += 1
&gt; As a side note, I've read that just having a pre-generated list of primes is the fastest, but for Project Euler that feels like cheating to me. :P This is actually not that much faster. The Eratosthenes sieve runs in O(n log n) and generates primes in memory. Even for, say, n=10^7 , the sieve will only be about 23 times slower than a solution that already has primes precomputed in memory. But then you have to consider that loading primes from disk is much much slower. There are about 80MB of primes up to 10^7 and loading 80MB of integers from disk will be really slow. Maybe slower than generating with a sieve. And then there's the fact that most actual Proj Euler solutions run slower than O(n log n), so the bottleneck is unlikely to be the prime generation process.
I agree. 
It was more of a pride thing. I spent hours mulling over how to properly implement it and what it meant. I'm just glad it worked!
I love doing hideous one-statement versions of things for fun. Here's what I came up with: sieve = lambda mx: filter( lambda x,is_prime=[1]*(mx+1):is_prime[x] and all( not is_prime.__setitem__(i,0) for i in xrange(2*x,mx+1,x)), xrange(2,mx+1)) Surprisingly, that version still works ok, took about a second for a million on my computer. That doesn't mean you should ever, ever use something like this though, haha.
in the same vein, indexing with bools: &gt;&gt;&gt; ['foo', 'bar'][True] 'bar' &gt;&gt;&gt; ['foo', 'bar'][False] 'foo' (also on the same level of 'non-usefulness'. you should just write `'bar' if boolvar else 'foo'`)
Ahh, I should've been familiar with the cooler functions of 3.x! 
Do you have some error in the error log? Can you report it at https://sw-brainwy.rhcloud.com/tracker/PyDev/ ?
I posted that response because the OP was not very specific. When he mentioned file rotation, I pointed to a cookbook recipe covering just that. There are similar documentation entries for other topics. Your comment isn't much help either, by talking of nightmares. Do you have a specific problem? Ask on one of the places I mentioned, or log issues about specific areas of the documentation that need clarification. Other people have done this, and have improved the documentation *for everyone*. People who just complain in general terms might be suiting themselves, but they don't help anyone else :-( I'm not sure why you think it's a problem for software to have lots of options. The options in logging are there because they have (in my experience) been useful. Maybe most of them are of no use to you - but then it isn't *just* for you.
If you don't mind me asking, how does my code compare to yours or his (on the same hardware, hence the post)? def primes(depth=10**6): primes = [2] length = depth//2 list = [True for i in range(length)] # 3, 5, 7... might be prime i, n = 0, 3 # i=index, n=num=2*index+3 j = i + (n&gt;&gt;1)*n # the index of n^2 == (n^2-3)/2 == (n^2-n + n-3)/2 == (n-1)/2*n+i while j &lt; length: # while n^2 &lt; depth if list[i]: # n is prime primes.append(n) # start sieving from n^2 (smaller multiples would be eliminated earlier) while j &lt; length: list[j] = False # sieved k*n, now sieve (k+2)*n ('cause (k+1)*n is even) j += n i += 1 n += 2 j = i + (n&gt;&gt;1)*n # all necessary sieving is done, read the rest of the list while i &lt; length: if list[i]: primes.append( (i&lt;&lt;1)+3 ) i += 1 return primes It is of course the exact same algorithm as GoldyOrNugget, but the loops and data-tracking is different, so I'm wondering if there's any significant difference between them.
i was quite proud of https://github.com/andrewcooke/simple-crypt/blob/master/src/simplecrypt/__init__.py - i tried to make it very simple so that it could be audited by people who weren't that good with python. but then someone said it was terrible code that looked like it had been generated by a machine!
I think printing the multiplication table has everything I love in python at once. print("\n".join("%s x %s = %s" % (a, b, a * b) for a in range(1, 11) for b in range(10)))
I should have thought of that. Thanks! It's a good thing I didn't, though. From this I also learned that list.remove(num) is waaaay slower than just setting the value and making a new list later. (Due to remove having to change all of those indexes.) On further contemplation, maybe that's how I ended up going to a dict in the first place. It's been a while since I wrote that function :) Interesting! Thanks! edit: For those interested, I did some speed testing. With WBudd's method, it take 135 seconds to get primes up to 10,000. GoldyOrNugget's does this in .05 seconds, and mine does it in .1 seconds. Whoa.
Needs more single letter vars.
&gt; Where is the right place to define all of those? A log config file? A log config is generally the right way to go, via a dictionary (which can come from a JSON file, or a literal dict in a module), and using the dictConfig() API to do the configuration. &gt; More pictures about the flow Have you looked at the [logging flow diagram](http://docs.python.org/2/howto/logging#logging-flow)? After I added that to the documentation, someone on Twitter complained that if you have to draw pictures, you've already lost. You can't please some people, eh ? ;-) &gt; see Logbook Why don't you show me the configuration you asked about, that's really easy to set up using Logbook? I'll see if I can come up with an equivalent configuration using stdlib logging.
The end result is that f(g(h(x))) is equivalent to compose(f, g, h)(x) correct?
I can shrink that ;) import functools @functools.lru_cache(None) def fib(n): return 1 if n &lt; 2 else fib(n-1) + fib(n-2)
I've no idea what you would regard as "decent". Your comment about the general quality of Python documentation seems snarky, and points to you possibly having an unreasonably high expectation of a volunteer project that people contribute to for free. If you would like to contribute some specific improvements in areas you think are defective, I'd be happy to listen to those specifics. Certainly I know it's usable, since lots of people use it. For example, anyone who configures logging in Django uses `dictConfig()`, and even if you don't use Django, most people will tell you its documentation is excellent, so you might learn something there even if the Python docs don't cut it for you.
ITT: People beating PEP8's line length limit to a bloody pulp.
&gt; But my time in .NET has given me quite a distaste for configuration files. .NET configuration files are XML. The Python community mostly have an aversion to XML configuration files, though of course Python has excellent support for XML.
Good job then! This only works for powers of 2, for an even more satisfying task, try figuring out how to change the code so it works for powers of 3 instead.
Interesting stuff. I sort of had a script to do it. Right now i was looking at dealing with soft and hard links. Might be i will extend what you have done. 
Max of 1,000,000 primes. Pirsqed: 1.0201301574707031 GoldyOrNugget 0.6120789051055908 Bunslow 0.46805906295776367 Very nice! Well done :)
I hate print(), only because I've used a lot of python 2.x and I still end up typing "print x, y, z" statements, out of habit. This despite mainly being a C++ developer; my brain enters python mode when I start pythoning. (And then I end up typing "if (x): " in C++)... 
I'm gonna be that guy to point out that a regex isn't really Python code, strictly speaking (even though the re module provides support for them). Cool though ;) 
2D list would work: numlist = [[x1, True], [x2, True], ...] for item in list: if condition: item[1] = False Use a list comprehension to initialize (instead of your dict.fromkeys()): listitems = [[x, True] for x in range(...)] 
It doesn't work here, since it returns a list rather than a string. &gt;&gt;&gt; reversed('foo') == 'oof' False I suppose `is_palindrome = lambda s: list(s) == reversed(s)` is decent, though (while obviously slower). I personally find Sackboii's code clearer. EDIT: As sushibowl points out, `reversed(s)` returns an iterator rather than a list, so that doesn't work either.
You could also use csv ! import csv for splited_line in csv.reader(open(filename)): print (splited_line) #or whatever you want
Seems overly complex for: alias top10='ls -lSh | head -n10' 
How does that deal with sharing sessions?
 du -Phd 0 .[!.]* * | sort -hr | head -n 10 will show directory sizes too
I did this a forever ago, but: def seive(maxx): a = xrange(2, maxx) for b in xrange(2,int(maxx**0.5)+1): a = [i for i in a if not i%b==0 or i==b] return a It's not very fast, but then it usually only has to go to less than 2 million in less than a minute to fit Project euler's standards. 
That's the only genuinely bizarre one -- adding two bools to get an int (you can check that with `type(True + True)`)
 with open(filename, "r") as f
If L is truly a list of lists, then you can just do reduce(lambda x,y:x+y, L, []) If you want a list comprehension, then [y for x in L for y in x] 
Your double underscores got changed to bold, so just to clarify for others it's: from __future__ import print_function And an additional detail to help others out: I think the interpreter will error if it's not before any other python statement other than a comment or another future import (so it needs to be before non-future imports).
I seem to recall using that line profiler on this, and looking at the results, saying "that's basically what I expected", then didn't put any further thought to optimizing it.
Yep
sounds suspiciously like a homework problem.... Use raw_input() to get the number of laps use the int() function to convert that input to an integer use a for loop with a range() method to make the loop happen that many times. 
Yes, I know that bool inherits from int. I'm not sure why you think that makes this behaviour non-bizarre, though; it's like if 'foo'+'bar' would return ['f','o','o','b','a','r'] Adding together two values of the same type and getting an output of a different type.. This is the only case I know of where it happens, in core Python.
To be fair, OP never specifically asked for Python code :P 
XML is a one part of the problem. The second part is thinking you configured something, it doesn't work, and you have no idea why not. The third part is not knowing what you can put in the configuration file. The last two parts are universal to configuration files, in my experience.
Efficient eight queens solution using constraint programming. def f(board, sol): if not board: return set((sol,)) return reduce(or_, imap(f, imap(place, board[0], repeat(board[1:])), imap(lambda x: sol + (x,), board[0])), set()) def place(index, board): return map(lambda offset, row: row - {index + offset, index - offset, index}, range(1, len(board) + 1), board) 
How bout you make them solve a problem that requires them to use existing tools instead of making them re-invent the standard library wheel?
I can check at work tomorrow; in the end I ended up removing the PyDev perspective, uninstalling PyDev, and then installing cleanly. This seems to have fixed the issue, and the new version works great! Thank you!
It's not that I dislike the standard library, or that I want to see them reinvent the wheel. It's that I want to see how their minds work. This is never an approach I would suggest taking when writing real code for real projects. But when you're interviewing people who are applying for programming jobs, you want to see that they can think algorithmically and approach problem-solving in multiple ways. I've had many people completely at a loss for how to solve this problem. YMMV. I'm never expecting perfect functions when I ask this question. But someone who can think through how to solve this when using basic constructs can think through how to solve tougher problems using more elegant solutions like `reversed`.
Here's my ~10-minute attempt (not rigorously checked). def isPalindrome_iter (sample): l = 0 r = len(sample) - 1 while l &lt; r: if sample[l] != sample[r]: return False l += 1 r -= 1 return True def isPalindrome_recur (sample): if len(sample) &lt; 2: return True if sample[0] == sample[-1]: return isPalindrome_recur(sample[1:-1]) return False
This is good! I didn't check that rigorously either, but it works for me. Thanks for posting.
my god...
I haven't found a one great source, this is my list: * http://infohost.nmt.edu/tcc/help/pubs/tkinter/index.html * http://www.tkdocs.com/tutorial/index.html * http://zetcode.com/gui/tkinter/introduction/ * http://www.python-course.eu/python_tkinter.php Searching StackOverflow is a good resource for specific questions Read about ttk, makes good looking tkinter apps; the first two sites cover it pretty well.
Can't call these bash utils if they're coded in Python...
If it is a simply homework problem, this should help: __, ___ = lambda _: chr(_), lambda _: _ + True for _ in (70, 110, 110, 102, 107, 100, 31, 104, 115, 32): print(__(___(_))) If that doesn't work, use what everyone else relies on to code, stackoverflow. 
... for small values of pi.
I'll throw something new into the mix - a sieve that uses slice assignment: def primes(n): primes = range(n + 1) primes[0] = primes[1] = None p = 2 while p*p &lt;= n: if primes[p]: num = (n - p*p) // p + 1 primes[p*p::p] = (None,)*num p += 1 return filter(None, primes) On my laptop it took about 180ms to compute the primes from 1 to 1,000,000.
I was really proud of this, our programming teacher assigned us a challenge problem and challenged anyone to do this in less than 8 lines (It was an intro class) The idea was you'd give it a string and a number, and it would print the string diagonally filling in empty space with periods and going down as many lines as the number you gave it. So "Peter piper picked a peck of pickled peppers" becomes P.........r......... .........i.........p... .e......... .........p.........c.........e.. ..t.........p.........e.........k.........r. ...e.........i.........c.........l.........s ....r.........c.........k.........e......... ..... .........k......... .........d........ ......P.........e.........o......... ....... .......i.........d.........f.........P...... ........p......... ......... .........e..... .........e.........a.........p.........p.... I was able to do it in two (arguably 3) lines. def print_diagonal(string, number): lst = [string[x::number].replace("","."*(number-1)) for x in range(number)] for place, line in enumerate(lst): print line[(len(lst)-1)-place:((len(lst)-1)-place)+len(string)] Very un-pythonic, but I was really happy when I was able to come up with a super condensed version like this.
Do you not think readability is sacrificed here?
Thanks for the great list. I appreciate it and it will be looking at them.
Here's a short and sweet implementation of the discrete Fourier Transform. Of course I would normally use a FFT, but this was for a class. import numpy as np def dft(signal, window='centered'): N = len(signal) m = np.arange(-N/2,N/2,1) if window=='centered' else np.arange(0,N,1) M,K = np.meshgrid(m,m) spectrum = np.dot(np.exp(-2j * np.pi * M * K / N), signal) return spectrum
I needed a way to keep my hands *warm in the winter. Came up with this: while True: pass
 def procrastination(): pass
and now for a really slow is_prime function in one line, with a bonus factorial function to boot! `factorial, is_prime = lambda n: n * factorial(n - 1) if n &gt; 1 else 1, lambda m: factorial(m - 1) % m == m - 1` ty wilson's theorem edit: thought i should mention that this won't even work past 994 [with default recursion limit], and it's hilariously slow
pi = 3
lemme blow you away &gt;&gt;&gt; bool() == int() True 
Best I can do. If you hate parens, try ruby? &gt;&gt;&gt; prin = type('', (), {'__add__': lambda _,o: print(o)})() &gt;&gt;&gt; prin+ "hello" hello 
import time
&gt; If you want a list comprehension, then &gt; [y for x in L for y in x] Ah, just like the very first example in the article, that motivated the whole blog post. :)
While I actually agree the logging module is hard/complex, I think its just a matter of reading the documentation to find what you want in my opinion. I recently had to implement a few logging things (using RotatingFileHandler and QueueHandler) and I had a few issues because I was just skimming through the documentation. Its a matter of reading and trying - I know logging can do much more than what I did with it, but for my use it was pretty simple/just took some reading. Although I really think the code doesn't look like the most pretty one I've ever written.
Even if it's not the prettiest hack in the world, that's quite clever.
Obfuscation is one of the few things that python makes *harder*. So, yeah. I'm proud of my japh.
I saw a tail recursive version import functools class tail_recursive(object): def __init__(self, func): self.func = func self.firstcall = True self.CONTINUE = object() functools.update_wrapper(self, func) def __call__(self, *args, **kwd): if self.firstcall: func = self.func CONTINUE = self.CONTINUE self.firstcall = False try: while True: result = func(*args, **kwd) if result is CONTINUE: # update arguments args, kwd = self.argskwd else: # last call return result finally: self.firstcall = True else: # return the arguments of the tail call self.argskwd = args, kwd return self.CONTINUE @tail_recursive def fib(n, a=1, b=1): return a if n == 0 else fib(n - 1, b, a + b) print fib(10000)
Late to the party, but, http://HumbleDB.readthedocs.org
It's goatse, according to the link. Sorry for the spoiler.
 print ("#%s" % ("!%s" % ("/%s" % ("u%s" % ("s%s" % ("r%s" % ("/%s" % ("b%s" % ("i%s" % ("n%s" % ("/%s" % ("p%s" % ("y%s" % ("t%s" % ("h%s" % ("o%s" % ("n%s" % ("\n%s" % ("d%s" % ("e%s" % ("f%s" % (" %s" % ("f%s" % ("o%s" % ("o%s" % ("(%s" % (")%s" % (":%s" % ("\n%s" % (" %s" % (" %s" % (" %s" % (" %s" % ("p%s" % ("r%s" % ("i%s" % ("n%s" % ("t%s" % (" %s" % ("\"%s" % ("H%s" % ("e%s" % ("l%s" % ("l%s" % ("o%s" % (" %s" % ("W%s" % ("o%s" % ("r%s" % ("l%s" % ("d%s" % ("\"%s" % ("\n%s" % ("i%s" % ("f%s" % (" %s" % ("_%s" % ("_%s" % ("n%s" % ("a%s" % ("m%s" % ("e%s" % ("_%s" % ("_%s" % ("=%s" % ("=%s" % ("\"%s" % ("_%s" % ("_%s" % ("m%s" % ("a%s" % ("i%s" % ("n%s" % ("_%s" % ("_%s" % ("\"%s" % (":%s" % (" %s" % ("\n%s" % (" %s" % (" %s" % (" %s" % (" %s" % ("f%s" % ("o%s" % ("o%s" % ("(%s" % (")%s" % "\n")))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) 
I don't have experience with this exact problem, but might be able to lead you in the right direction if you provide some more info. Do you expect it to guess the name by filtering out English words or have it compare words with a dictionary of names? I'd personally find a text file dictionary of some sort with all English words, or at least the most common words and simply add words from the book that are not in the dictionary to a separate list. Or if you're really patient, start creating your own dictionary, and do as above, manually checking the list for any missed English words, and building your dictionary that way. I haven't done any actual web based Python programming yet, but if you're willing to go down that route, you could possibly grab/compare words data from various online dictionaries. It'd be a pretty simple loop: book_text = [text, of, book, comma, seperated] #(^^ I'm sure there's a built-in that will do this for you ^^) dictionary_words = [another, comma, delineated, list] name_list=[] for x in book_text: if x not in dictionary_words: name_list.append(x) print(x)
Well, I wanted an explanation that is even more abstract. I could not figure out what this was about without reading the code. I would say: Moves files and folders from the execution directory into subfolders of a 'cleanedUp' based on the file extension. A couple of tips; check out os.path.splitext, and read up on list slicing. my list[-1] will get the last item without knowing the length of the list. Keep on dreaming up things that you can do in code. And applauds for finding something practical to make. That's always a big hurdle when getting started with programming. Just keep making stuff. Thanks for sharing. 
Thanks, that is actually the approach I am on right now. I started out with /usr/share/dict/words but found that my book has words from old english! So now I am on the hunt for a list of old english words :)
Wow, I get it now. The autowikibot is pretty f'n cool.
Nice! Python's a lovely language. Feel free to check my YouTube page under this same nickname, should you want to see the little rogue-like (yeah yeah, been done, but it's fun to create) game I'm attempting to make, built in image editor and all. I'm loving the internet for all it's free education. **Also: I'm sure there's an even faster way to process/compare two lists, I know I've seen a couple vids on YouTube about the subject, just don't remember the exact way; it might be possible to use heapq in some form to speed up the process, or create a set() with the book text to remove doubles.
This isn't anything unique but it's perhaps my single most reused piece of code: class Cache: def __init__(self, func): self.mem = {} self.func = func def __call__(self, *args): if args not in self.mem: self.mem[args] = self.func(*args) return self.mem[args] You can use it as a decorator like this: @Cache function recursivefibonacci(n): if n in [0,1]: return 1 return recursivefibonacci(n-1) + recursivefibonacci(n-2) It makes the bad and slow fibonacci code fast like the wind. A plug and play tool to transform most poorly written recursions instantly into smart dynamic programming.
K.
It's not the same -- `random.sample` will return unique elements, while repeated calls to `random.choice` will choose independently random elements, so you can get duplicates.
is_palindrome is perfectly readable to me.
I think one has to choose between two mutually exclusive conclusions when considering this article: 1. This article is unnecessary for the reasons you mentioned 2. There is a larger problem amongst the Python web frameworks Maybe I'm biased, being a pretty diehard Python web guy, but I'm inclined to lean towards the former.
/r/learnpython /r/learnprogramming ***** ^This ^is ^an [^automated ^bot](http://github.com/WinneonSword/LFB)^. ^For ^reporting ^**problems**, ^contact ^/u/WinneonSword. ^The ^parent ^commenter ^may [^remove](http://www.np.reddit.com/message/compose?to=LinkFixerBotSnr&amp;subject=Comment%20Deletion&amp;message=%2Bdelete+cg837rw) ^this ^comment ^if ^they ^wish.
Good call! Thanks for that. This only happens when the maximum happens to be a perfect square. 
cd is used to set current directory. In your terminal type: cd "/user/Larry/downloads/" The part in quotes is an example directory. Put in the folder that you download swampy to (no quotes)
That looks really useful spaztiq. Do you know if there is a way to filter a set? 
You can make it more configurable easily just by making `chars` an argument. The one I wrote somewhat recently was almost exactly the same except for having it as an optional argument: def randstr(length, alphabet='abcdefghijklmnopqrstuvwxyz0123456789'): """Return a string made up of random chars from alphabet.""" return ''.join(random.choice(alphabet) for _ in xrange(length))
You could also check the newer version which I made after fellow redditors pointed me in right direction: https://gist.github.com/ZetaHunter/9664531 Ps. It doesn't move folders, neither this version or the new one, none ever touches folders, they are ignored.
Another way would be to use [pyenv](https://github.com/yyuu/pyenv), Its what I use (I run Ubuntu 12.04 too), I have projects that require different versions of python (2.6.6, 2.7, 3.3) which for various reasons (e.g RHEL) I cant migrate to newer versions. Pyenv makes it possible for me to have all those versions on my system without conflict (In the past I ran multiple VM's and vagrant or not it was a pain). 
This is called a [context manager.](http://docs.python.org/2/reference/datamodel.html#with-statement-context-managers)
Yeah, it seems to be right in line with what you want to achieve, even if it isn't the /exact/ code you'll likely use. As for filtering a set, not entirely sure off the top of my head. I'd honestly just hit up google with "python filter set" or some variation of that. I know there's some pattern matching built-in somewhere. Stackoverflow has so many helpful answers, and interesting ways to approach these things. The beauty of Python is that there are many ways to solve the same problem, and there are often some beautiful one or two liners that will "magically" do everything you need. Many built ins that I haven't even fully explored yet. If you haven't played with lamda or exec functions yet, definitely look into them; they can be fun, if you're a code/logic nerd like myself. I get a kick out of reducing my code size by dumping a lot of repetitive calls and such into a list of command strings, looping through the list and using exec('command') to execute the code. Though, it's easy to get lost in your code if you don't comment it well, lol. I also found it a quick and easy way to put a console into a program; you just type literal python code into a text input of some sort, and exec() it. 
Shouldn't `fib(0) == 0`?
[`functools.lru_cache`](http://docs.python.org/3/library/functools.html#functools.lru_cache) has you covered.
&gt; ls -lSh | head -n10 It's not the same thing... Did you compare the two outputs? I try to find the top 10 largest files in the current directory recursively.
&gt; du -Phd 0 .[!.]* * | sort -hr | head -n 10 Not the same thing. You show the top 10 largest directories. I show the top 10 largest files, even if they are somewhere in a subdirectory.
Fine. Then call them python scripts...
what's the difference between logging.warning and logging.debug?
I think the idiom for `reversed`'ing a string is `''.join(reversed(s))`, which is not very pretty :(
 I'd probably try and use a more direct method: def print_diagonal(phrase, lines): for line in range(lines): print("".join(char if i % lines == line else "." for i, char in enumerate(phrase))) 
Why python-based? It's not necessary to make os core libs on python to make programs on python. Take a look at Maemo/etc, many programs for it is written in python.
I worked at Palm and Nokia. Speed was always our biggest hurdle. I love python, but it's a lot slower than the current set of commonly used languages. That said, the Palm Pre's applications were javascript, so it's certainly possible given enough resources. 
Whatever you say. That's probably a good way of weeding out bad programmers, but for the sake of clean code, I'd still use what I posted. EDIT: My quick solution, just for fun and games. def is_palindrome(string): f, l = 0, len(string) - 1 while f &lt; len(string) // 2: if string[f] != string[l]: return False f, l = f + 1, l - 1 return True
How about this: def pd(string, number): for line in range(number): print "".join(c if i % number == line else '.' for i, c in enumerate(string)) Edit: /u/Veedrac beat me to it.
Thanks for clarifying the underscores. And you are correct, about future imports having to be on top. But the interpreter is very good at telling you what the error is if you place it anywhere else
Who said anything about readability? Neat tricks don't have to be readable.
pi = None
I feel python 3 has a bad reputation. When it was announced and very fresh there were a lot of libraries without support, some changes that did not make sense (at the time) and was pretty much shunned. I have used it for 9 months now and I love it. Python 3 is actually so developed now that it will be the standard python distribution in fedora 21 (coming H2 2014)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Named-entity recognition**](http://en.wikipedia.org/wiki/Named-entity%20recognition): [](#sfw) --- &gt; &gt;__Named-entity recognition__ (NER) (also known as __entity identification__, __entity chunking__ and __entity extraction__) is a subtask of [information extraction](http://en.wikipedia.org/wiki/Information_extraction) that seeks to locate and classify elements in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. &gt;Most research on NER systems has been structured as taking an unannotated block of text, such as this one: &gt;And producing an annotated block of text that highlights the names of entities: &gt; --- ^Interesting: [^Information ^extraction](http://en.wikipedia.org/wiki/Information_extraction) ^| [^Knowledge ^extraction](http://en.wikipedia.org/wiki/Knowledge_extraction) ^| [^Entity ^linking](http://en.wikipedia.org/wiki/Entity_linking) ^| [^List ^of ^states ^with ^limited ^recognition](http://en.wikipedia.org/wiki/List_of_states_with_limited_recognition) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg84z5k) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg84z5k)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Yeah, me too. My academic qualifications are nowhere related to the world of programming but I'm learning-though-experimenting and so far, it's been a fun ride! As for the username, I fell in love with his music AFTER I started working with the web framework. I checked and was surprised to find it available on reddit, so I grabbed it right away - seemed the right thing to do... :D
Oh, ok. I think find . -type f -print0 | du -h --files0-from=- | sort -hr | head -n 10 is what you want
I was pretty sure that the idiom for 'reversed string' was, in fact, what Sackboii wrote: `s[::-1]` My post actually originally contained `''.join(reversed(s))`, but then I realized joining is not necessary when you can convert the other item into a list instead.
That's also misleading: &gt;&gt;&gt; type(bool()) &lt;class 'bool'&gt; &gt;&gt;&gt; type(int()) &lt;class 'int'&gt; All it actually means is that bools are an int subclass, and that False == 0, which is [demonstrated in my earlier example](http://www.reddit.com/r/Python/comments/20x61y/share_the_code_youre_most_proud_of/cg7ua3n). Unless you have some evidence that this is directly related to the type mutating unexpectedly?. The key point here is that while `isinstance(bool(), int)` is True, `type(bool()) == int` is False, and the logical extension of this is that `True + True` should raise a TypeError or some other exception, rather than returning int(2) There are probably historical reasons for this that are not obvious to me. Or, you know, just being able to go `httpcount = sum([(True if 'http://' in url else False) for url in urls])`.
That's how I thought about it. It is close to what you did here. But I took first half and second half of the string. than reverse the second half and check if it is equal def is_palindrom(st): l = len(st) / 2 # integer division # return st[:l] == st[-l::-1] # That does not work somehow return st[:l] == st[-l:][::-1] if __name__ == '__main__': print is_palindrom('abba') My original thought was the first commented returned value. But some how it does not work so I had to slice the list first than reverse it. Can anybody do it in one step? Maybe I should have just reverse the first half. --typo fixes
Just refactored everything from 1.4 to 1.6, *sigh* ill wait for 1.8
:o I have *got* to try Py3 now. 
This can be improved a bit: def parse_thing(object, function): cases = { dict: lambda x: {a: parse_things(b) for a, b in x.items()}, list: lambda x: [parse_things(a) for a in x], } cases.update({k: function for k in (int, float, str, unicode)}) return cases.get(type(object), lambda x:None)(object) 
I remember they asked Guido why Python was not chosen as the language of choice for developing on Android (on some Google keynote; look it up on Youtube) He said something like 'the management decided that strategically Java was better' (more developers available, etc). Btw, I think Ubuntu Phone came close to it.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Perceptron**](http://en.wikipedia.org/wiki/Perceptron): [](#sfw) --- &gt; &gt;In [machine learning](http://en.wikipedia.org/wiki/Machine_learning), the __perceptron__ is an algorithm for [supervised](http://en.wikipedia.org/wiki/Supervised_classification) [classification](http://en.wikipedia.org/wiki/Classification_(machine_learning\)) of an input into one of several possible non-binary outputs. It is a type of [linear classifier](http://en.wikipedia.org/wiki/Linear_classifier), i.e. a classification algorithm that makes its predictions based on a [linear predictor function](http://en.wikipedia.org/wiki/Linear_predictor_function) combining a set of weights with the [feature vector](http://en.wikipedia.org/wiki/Feature_vector). The algorithm allows for [online learning](http://en.wikipedia.org/wiki/Online_algorithm), in that it processes elements in the training set one at a time. &gt;The perceptron algorithm was invented in 1957 at the [Cornell Aeronautical Laboratory](http://en.wikipedia.org/wiki/Cornell_Aeronautical_Laboratory) by [Frank Rosenblatt](http://en.wikipedia.org/wiki/Frank_Rosenblatt). &gt;==== &gt;[**Image**](http://i.imgur.com/P8S8eOE.png) [^(i)](http://commons.wikimedia.org/wiki/File:Linear-svm-scatterplot.svg) --- ^Interesting: [^Multilayer ^perceptron](http://en.wikipedia.org/wiki/Multilayer_perceptron) ^| [^Kernel ^perceptron](http://en.wikipedia.org/wiki/Kernel_perceptron) ^| [^Perceptrons ^\(book)](http://en.wikipedia.org/wiki/Perceptrons_\(book\)) ^| [^Perceptron ^Inc](http://en.wikipedia.org/wiki/Perceptron_Inc) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg85mk4) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg85mk4)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
This one is very good, Question: &lt;intransitive verb=""&gt; here ="" part is not being parsed right. it is in the name of the BNF rule. Is there a specific reason you put it there?
That thing is called a docstring, and is usually put in three (double) quotes.
Noob here. Why are you using lambda instead of just is_palindrome = s == s[::-1]
 filter(lambda x: x &gt; 5, set(range(10)))
Because yours is not callable. You define a variable which is True if at the time of calling `s` is a paldindrome. &gt;&gt;&gt; s = 'anna' &gt;&gt;&gt; is_palindrome = s == s[::-1] &gt;&gt;&gt; print(is_palindrome) True When using lambda you define a function called `is_palindrome`, which then can be used like a normal function &gt;&gt;&gt; s = 'anna' &gt;&gt;&gt; is_palindrome(s) True &gt;&gt;&gt; is_palindrome('hello') False
I would write the code in the sidebar differently: ... while True: ... `while 1` is so C-ish... **Edit:** I sent a message to the moderators and they changed it.
Thanks for your input!
Cool project. It would be great if you accepted nanosecond timestamps.
why not? Because tying a mobile OS to any particular language benefits no one in the long run and only causes more fragmentation which we already have enough of. Nowadays if you are a serious business you have to make your software once for the web, once for Android, once for iOS and once for Windows Phone. And don't even dare telling me how you can use half-assed-project-X that will kinda convert your shit from one platform to the other. We've done it over and over again. "Hey here's X ... it's magic ... you do it once, it runs everywhere". "Cool! We'll jump all over it this is what we have needed all this time" ... "Well ... fuck ... I guess it's not good enough, let's just go native for each platform" So yeah ... no we don't need yet another X-based mobile OS and app store. Give me a mobile OS that doesn't *know* and doesn't *care* which programming language I use, because that should not be relevant. You don't buy a car because a particular great brand of hammer was used to create it. You buy it because it's nice safe reasonably priced robust and beautiful, so in the same way, ideally, the consumer should not care what I used to create the application, as far as they are concerned it's software, and as long as it works the way it should, who cares which language or hammer was used? That's how we get autonomy and harmony in a platform that everyone will benefit from for a long time. Similar examples that represent the same principal are the underlying internet protocols such as TCP/IP, HTTP, SMTP/POP/IMAP that have been serving us well for many years.
factorize a number ''' &gt;&gt;&gt;factorize(20) [2, 2, 5] ''' def isPrime(n): i=3 limit=math.sqrt(n) if (n==2) | (n==3): return True if (n&lt;2) | (n%2==0) | (n%3==0): return False while (i&lt;=limit): if n%i==0: return False i+=2 return True def factorize(n): i=1 l=[] while not n==1: if isPrime(i) &amp;(n%i==0): n/=i l.append(i) i=0 i+=1 return l
1.7 has core support for migrations. So long South, you will be missed.
me neither, I think I leveled up in google-fu!
The only one I've ever used myself is [regexp-opt](http://www.emacswiki.org/emacs/RegexpOpt) for Emacs, but of course, it only works with Emacs regexen, so you might be better off with something else!
By that logic, isn't it wrong to define it using any decimal representation? `math.pi` isn't much more correct, you know.
You really shouldn't design important hardware drivers/interfaces in Python. You need to code closer to the metal to get what is possible out of a phones hardware. There are plenty of ways to code in python on top of a phones OS, but there is no point in designing a smart phone (OS) in Python, it is a waste of all those hardware resources.
This was always the thing that made me resist starting a project with Django
Yeah, it seemed totally insane to me that they were arguing "it is documented therefore it is correct", there is so much code that will break because of this misfeature.
that doesn't work either, reversed doesn't return a list but an iterator: &gt;&gt;&gt; reversed("foo") &lt;reversed object at 0x7fd8b12ab0d0&gt; &gt;&gt;&gt; reversed("foo") == list("oof") False You'd have to do something like `list(s) == list(reversed(s))`. This creates even more copies so at that point `s == s[::-1]` is probably more efficient. If you really wanted to avoid the extra copy you'd probably do something like: is_palindrome = lambda s: all(x == y for x,y in izip(s, reversed(s))) Not very pretty. Another cute one: def is_palindrome(s): return not s or (s[0] == s[-1] and is_palindrome(s[1:-1])) also not very pretty to read, and not very efficient either.
the version `lambda s: s == s[::-1]` works fine if the length of the string is odd
 derp = lambda k, v=None: derp.__dict__.get(k) if derp.__dict__.update({k: derp.__dict__.get(k) if v is None else v}) is None else None derp("derp", "derp") print derp("derp") Yay... I Python'd!
be advised though, i would convert the files to csv, before loading them in pandas. that way you will have much more flexibility in converting data types for each column than you would have with read_excel.
reading docs is hard.....
The length of the field would be something like "%(asctime)-25s", have you tried embedding tabs in the formatter? This is where I got the string length: http://docs.python.org/2/howto/logging-cookbook.html#adding-contextual-information-to-your-logging-output
Good point. In any case `s == s[::-1]` should always be most efficient, since it only constructs one object in the course of the check, that object is a scalar, and the actual comparison is essentially Unicode-supporting strcmp(). 
FWIW, the new core support for migrations *is* South.
I have one too, but it was only fast for about 1 million and I wanted more primes and more speed. I read that on C you can implement the sieve as a boolean array. I though "sure, I can do that". [It was just a naive algorithm and naive C implementation](https://github.com/boarpig/sieve) and I can do 4 billion primes, single core, in little over 3 minutes. My mind was blown.
The API looks so stable to me. Can I ask what you had to change?
I have a git clone of django's repo in my work folder, I pull on a daily basis just to keep and eye of what's happening, is amazing how much care they give to docs and tests, is a well done process. Just take a pick here.. docs/releases/1.0-beta-2.txt | 6 +- docs/releases/1.0.txt | 6 +- docs/releases/1.3-alpha-1.txt | 7 +- docs/releases/1.3.txt | 7 +- docs/releases/1.4-alpha-1.txt | 8 +- docs/releases/1.4-beta-1.txt | 8 +- docs/releases/1.4.6.txt | 2 +- docs/releases/1.4.txt | 8 +- docs/releases/1.5.2.txt | 2 +- docs/releases/1.6.txt | 2 +- docs/releases/1.7.txt | 19 ++- docs/releases/1.8.txt | 174 +++++++++++++++++++++ 
The core migrations support was added by Andrew Godwin, who wrote South in the first place. So it's more like, "South is dead. Long live South." [Video source](https://www.youtube.com/watch?v=JXGW56CGsCM)
Oh hahaha woops I didn't even realize it was a link post.
In this case - did you think about packaging and distributing your game? As far as I understand Blender is not well suited for that, especially if you don't want your game to be released under GPL.
If you refrain from making dongle jokes, you'll enjoy it.
Please stop misinterpreting what I am saying. I'll now quote myself: &gt;*When working with containers*, `if foo` is just shorthand for `if foo is not None and len(foo) != 0` Emphasis in original. My point is this: `if foo` does have meaning independent of `if foo is not None`. However, that meaning is basically a property of `foo`'s type, which places it in the same category as syntax like `foo[bar]` or `foo()`. Would you do either of those in a *general* case, when you don't even know the type of `foo`? Of course not!
exactly , i remember too , and Guido said : what is this ? is this serious question ?
The new migrations by Andrew Godwin is like South 2 only integrated.
Here's one of my favorites -- a markov chain in 5 lines. import re, collections, random words = re.findall(r'\b\S+\b', open("mobydick.txt", "r").read()) d = collections.defaultdict(lambda: collections.defaultdict(int)) for i in range(len(words) - 1): d[words[i]][words[i+1]] += 1 def m(n, w): print w; return not n or m(n-1, max(d[w], key=lambda x: d[w][x])) Example output from Moby Dick: &gt;&gt;&gt; m(10, "old") old man who had been a little negro But the whale 
Oh, nice! I like that method a lot more. Compact *and* far more legible. 
We just did the same thing. It looks like a lot more changed between 1.4 - 1.6 than 1.6 - 1.7 so it should be an easier migration.
Not quite as neat, but doesn't make a copy of the string: is_palindrome = lambda s: all((s[i] == s[len(s) - i - 1] for i in xrange(0, len(s))))
Not really. It's by the same author, but it's a fresh approach.
What about a recursive solution that is a one-liner? def is_palindrome(string): return len(string) &lt;= 1 or (string[0] == string[-1] and is_palindrome(string[1:-1]))
I like this for reformatting time: datetime.datetime.strptime(date_string, "%b %d, %Y").strftime("%Y-%m-%d") I also have some beautiful soup one-liners that I love, but they are specific to an HTML document.
This is a great list!
I use timeit all of the time when I want to find out what is the fastest solution for little things. I mostly use this for testing response times of api requests combining it with analysis code on the server end to benchmark database queries and processing time to find the bottlenecks.
I'm working on a space sim using pyglet. Good to hear someone else will be knee deep in their docs.
Are you a programmer? Do you enjoy talking about programming related things with smart people? Are you extroverted enough (or adventurous enough) to enjoy yourself and meet new people? The expo hall and "hallway" track are fun. There are after hours social events, and the talks are all going to be posted online anyway
This is the answer I am looking for. Thank you. Yes, I'm a software developer. While I'm stronger in languages like C++/C# and Java, I did use Python for some applications I worked on. I do like meeting new people and networking. What's the "hallway" track? What's included in the Expo Hall besides Exhibit booths for companies and organizations? Thanks for the talks notice! I didn't know that and I'm excited that they're recorded and posted online afterward. I really wanted to go to the Twisted one. 
I have a huge nerd bonder for fast prime generators and in case your interested, I timed (10 Loops, average of best 3) the posted algorithms with n=1M: name ms rwh_primes2 24,2 rwh_primes 37,8 /u/Veedrac 73,2 /u/scanner88 104 /u/gegde 153 /u/Bunslow 161 /u/Pirsqed 657 /u/GoldyOrNugget 730 /u/faceplanted 1240 def rwh_primes(n): # http://stackoverflow.com/questions/2068372/fastest-way-to-list-all-primes-below-n-in-python/3035188#3035188 """ Returns a list of primes &lt; n """ sieve = [True] * n for i in xrange(3,int(n**0.5)+1,2): if sieve[i]: sieve[i*i::2*i]=[False]*((n-i*i-1)/(2*i)+1) return [2] + [i for i in xrange(3,n,2) if sieve[i]] def rwh_primes2(n): # http://stackoverflow.com/questions/2068372/fastest-way-to-list-all-primes-below-n-in-python/3035188#3035188 """ Input n&gt;=6, Returns a list of primes, 2 &lt;= p &lt; n """ correction = (n%6&gt;1) n = {0:n,1:n-1,2:n+4,3:n+3,4:n+2,5:n+1}[n%6] sieve = [True] * (n/3) sieve[0] = False for i in xrange(int(n**0.5)/3+1): if sieve[i]: k=3*i+1|1 sieve[ ((k*k)/3) ::2*k]=[False]*((n/6-(k*k)/6-1)/k+1) sieve[(k*k+4*k-2*k*(i&amp;1))/3::2*k]=[False]*((n/6-(k*k+4*k-2*k*(i&amp;1))/6-1)/k+1) return [2,3] + [3*i+1|1 for i in xrange(1,n/3-correction) if sieve[i]] /u/gedge /u/Pirsqed /u/GoldyOrNugget /u/faceplanted /u/scanner88 /u/veedrac /u/bunslow 
Yes, you're right. I guess what I meant to say was, here's how to get a string back if you insist on letting `reversed` do the work.
The "hallway" track is just the ad-hoc conversations that occur in the hallways. Many times it occurs between scheduled talks but often it occurs at any time during the conference. Some say the "hallway" track is better than the talks.
You should check out the "match" macro in Racket. It's essentially this. In Python, it might look like: match x: ["add", *args] : print "this list said to add" (a, b) : print "a tuple. second item was", b anything: print "something else" It's also extensible to user defined types. 
In some sense your example makes sense, but addition is not really a defined operation for bool, only an operation for int. So it not really analogous to your example.
Just to be clear, it isn't actually for only perfect squares that this bug is reproduced, for example: 21, and 33 also show up as primes if used as maximum. The issue seems to arise when maximum has a factor that is prime (and no other pair of non-prime factors), after you square it and go through adding each increment (consider the case of 21, where it is going to be found from 3^2 + 3 + 3 + 3 + 3), not comparing the last number means it will never be found, as 4^2 + 4 + 4 is already over 21. I know its an easy solution, but just for your information!
I would think that speed increases would be the primary goal of a so called static Python compiler. Followed by type constraints making it possible to catch certain types of bugs more quickly, and possibly as a replacement for things like py2exe for deployment w/o requiring a full Python install. Then again, py2exe is pretty mature at this point, so there would have to be some other compelling reasons to go for the compiler. Pypy is working hard on the performance front without sacrificing Pythons dynamic features.
Most of the new features will be back ported to south for people stuck using older versions of Django. It's still south.
I'm one of those people! I started my time with the Python community at PyOhio 2012. I attended through work, and was planning on going to several of the talks - but I ended up sitting in the commons areas, talking with people and tossing around ideas. This ended up lasting far longer than the conference's hours, and I ended up finding myself at a bar in Columbus at 1 or 2 in the morning, mentally exhausted from all the ideas that were generated and things I'd learned. In the midst of all this, I learned that the people I'd fallen in with were actually the same people who had written the libraries that I had been using at work, and whose code I'd been looking to for inspiration for months prior. Two years later, I've grown a beard, moved halfway across the country and am writing exclusively open source software, 95% of which is in Python. I can confidently say that the talks are the *least* important part of a Python conference :)
I feel sorry for anyone responsible for maintaining your code. Holy crap. how about this: count = int(sys.stdin.readline().replace("\n", "").strip()) for x in xrange(count): print "loop #{x}".format(x=x) 
Oh but they did... VBA on Excel my friend, and yes, It is the devil in a woman's dress. (Un?)fortunately I won't be dealing with that this time I have to generate a new sheet from scratch from outside excel and hope it works. Thanks for the pointer to xlwt, I'll try that :)
 TypeError: unsupported operand type(s) for +: 'object' and 'object' The way `fib` is written there isn't tail recursive.
Is `timeit.timeit("run_test()")` so bad? I guess you can't fight a preference. If you do roll your own, you should consider adding a couple handy things `timeit` has, like temporarily turning off garbage collection and nicely handling exceptions.
It's `s/2/3/`, isn't it? /s
So what you are saying is if I wanted to get results from Redis and send it out I am blocking the server and ultimately the return to the user by waiting for the results. With async io I would return right away (faster) but when the results are ready return again with just the results?
[XlsxWriter](https://xlsxwriter.readthedocs.org/) is great and released under a BSD license! Simple as OpenPyxl.
Yes, however, the real question is why he's not just using a regular `def`. Using a lambda and assigning it directly a name is a crippled version of `def` (e.g., you can't add a docstring). It's also not quite what you mean -- whereas `def is_palindrome(s): ...` means define a named function.
&gt; There are probably historical reasons for this that are not obvious to me. Way back, Python didn't have a `bool` type, and things like `==` returned `1` or `0`, much like C. People often did things like: True = 1 False = 0 for convenience, but it was still all integers. So when they added `bool`, they made sure `True` and `False` behaved exactly like `1` and `0` did in almost every context (I think `repr` and `type` may be the only exceptions), for backwards compatibility. Also: `httpcount = sum(1 for url in urls if 'http://' in url)`.
Very interesting! Thanks for taking the time. The two from StackOverFlow are great! I'm able (mostly) understand rwh_primes, but rwh_primes2 is a little beyond my comprehension. Likely just because of the math they're using. Obviously they're aware of some properties of primes that I am not aware of. Thanks again!
Yeah, give cantremembermypasswd's code a second look. Maybe run it real quick.
This reference is old, but I've found it quite useful: http://effbot.org/tkinterbook/
I've used a lambda expression since a lambda yields a function object. I think you're getting confused about what `is_palindrome` actually is in my example -- it's not a boolean, it's a function object. What I mean by this is that you can call it for any arbitrary string and have it return the results of the palindrome check for that specific string. In the above example, we can use the function yielded by our lambda to check other strings. For example: &gt;&gt;&gt; is_palindrome("racecar") True &gt;&gt;&gt; is_palindrome("hello world") False In essence, the `is_palindrome` is a name referring to a function object, not a boolean. As such, we can call the function object and have it return a value for whether a string is a palindrome or not. That's what the `s == s[::-1]` expression is -- it's the return value for the function object yielded by the lambda, given 's'. I hope that was in some way helpful. :)
It'll still work. `s == s[::-1]` is an expression returning a boolean for whether the original iterable is equal to the iterable reversed. As such, giving it an odd string length would still work just as it would with an even string length.
This is a reference to a well-publicized instance of a [conflict at PyCon 2013](http://arstechnica.com/tech-policy/2013/03/how-dongle-jokes-got-two-people-fired-and-led-to-ddos-attacks/).
I don't think so -- I think it's a quite easily recognisable piece of code. Other than that, it is fairly logical: 1. `is_palindrome = lambda s: ...`, assigning a lambda expression to `is_palindrome` which takes `s` as an argument. 2. `s == s[::-1]`, returning a boolean from a boolean expression comparing whether `s` is equal to `s` reversed.
Remember that you are not going to PyCon to see the talks. You are going there to meet people and make connections. All the talks will be posted online. If you don't meet people at PyCon, you are doing it wrong. General networking advice applies: Remember to bring business cards, and hand them out. But an even easier way to get to know people is to get their Twitter handles and follow them. Make sure your business cards have your Twitter handle on them. If you're kind of shy about approaching people and make small talk, just make a mental goal for yourself of "I'm going to talk to *every single person* wearing a green/blue/whatever shirt." This is my favorite trick, and it assures that I end up talking with a variety of people instead of people in my own age/gender/ethnic group.
This is beautiful &lt;3
Yeah, I suppose not. I'll look some more into timeit at some point. I do mostly web programming so it's generally server response times that affect users, less than speed of a section of python code.
I believe this can do what you're saying. He chose a poor example doing a strong match only.
Used this to check for a win condition in a programming assignement for hangman not long ago. has_won = lambda guessed, correct: set(correct) &gt;= set(guessed)
There is a ton of stuff going on that isn't the conference proper. There are evening sessions that are organized on the fly and no badge is required. For example, the testing BOF usually has enormous amounts of pizza and beer.
&gt; One of the most heavily uses packages Source? First time I hear about it.
I would love to see the finished result of that!
Sweet! Do you know when they give you your badge thingie? Do you pick it up when you arrive there?
Don't even get me started on VBA. My friend, the devil isn't even wearing a dress. It's a full on BDSM gimp suit, complete with all manner of accessories designed to give you "pleasure." My ass still hurts from the reaming VBA gave it. I'll never be the same.
There is a check-in desk where you get your badge. If you get there early you can often get your badge early.
I've never heard of it either, but it appears to be #21 most-downloaded package from PyPI, and previously #3 that hadn't gained Python 3 support. Source: [http://python3wos.appspot.com/](http://python3wos.appspot.com/)
no, that's the price we pay for having computers do our math, there's no true real numbers, but if you're going to define a number it should be the closest possible representation, which math.pi does, probably giving you 8 more digits, or a 100 million times more accurate, which isn't a small difference
i hate to be that guy but... .so you wrapped websockets ?
I've used it quite a bit. I believe fabric depends on it. It or maybe something like pexpect are the must haves if you want to do administrative server tasks or manage clusters or some such.
Currently 28th. Source: http://pypi-ranking.info/alltime
No TiP BOF this year :(
In fact, it's Fabric's *only* dependency!
[Here's a link to a screen snippet of it](http://imgur.com/25Z0aQE). I had to zoom out to 10% view in Excel. The tiny dots are the actual numbers, it's being conditionally formatted based on range.
Hallway track a totally informal thing. It is all the people hanging out NOT in a talk who chat and program and whatever else. In Santa Clara, lunch was in the expo hall, as was the poster track session. I don't know exactly what the expo pass covers. 
hahaha, that's brilliant. Sorry cantremembermypassword!
Don't know how heavily paramiko is used, but I remember reading a recipe about it in the Python Cookbook 2nd Edition which I have (dead tree version). That could indicate that it is used at least some. 
Tasty! I copied it from memory in the original post, thank you for pointing out my own sillliness.
Yes. You are blocking your service. Depends -- if your results must be used within that micro-thread, then yes. That micro-thread will be suspended and resume when the result is ready, meaning you can do other work. If you're not using the result or doing something else with it that is out of sync with the micro-thread that dispatched it, you'll want to check into the event loop a callback for that async operation. 
All PyPI ranking sites are presenting outdated information. [PyPI download counts are deprecated](https://mail.python.org/pipermail/distutils-sig/2013-May/020855.html). As far as I know, we don't have accurate download statistics from May 2013 up to today. For example, the last version of paramiko tracked by pypi-ranking.info is 1.10.1, which was released on 2013-04-05; since them, version 1.10.2 was released on 2013-07-26; the current version is 1.13.0, released on 2014-03-14.
Pretty much any time you're using ssh or a package that uses ssh with Python, you're using paramiko.
How about for i in xrange(10**100): ...
about time! Fabric on py3 should be close behind...
I am *so* glad that was what PyCon ended up being entirely about last year. And I am so much *more* glad that there are people like you making sure PyCon will *always* be about that, every year. Thank you, thank you so much for your help to this community.
Wow! Thank you so much, that is awesome.
An easy speedup would be to change the i=0 line at the bottom to i-=1. Here's my own version, which includes a prime generator. def isprime(primes, n): root = n**.5 for p in primes: if n % p == 0: return False elif p &gt; root: return True def genprimes(n): L = [2] for i in xrange(3,int(n)+1,2): if isprime(L,i): L.append(i) return L def factor(primes, n): F = [] for p in primes: while n % p == 0: F.append(p) n/=p if p &gt; n**.5: break if n &gt; 1: F.append(n) return F n = 20 primes = genprimes(n**.5) print factor(primes, n)
It's cool, glad you figured it out, I swear my production code doesn't (all) look like that. Nice of you to provide an actual solution :)
We do have accurate download stats now. This email from Donald has been superceded, fastly now ships us logs which we process.
I'm hoping.
well, the pypi page gives nearly the same example. the only thing I could find that was remotely close to what I was thinking would be cool is this... https://github.com/machinalis/refo/blob/master/examples/path.py And I'm not really sure it's doing what I think it's doing. And unfortunately I'm not interested enough to run the code, i am merely reacting to the information easily available. 
if you can't understand it, how do you know you want to use it?
Dang, nice. It uses a bunch of syntaxes that I didn't recall (I mean, I "knew" about them, but I've never used them in any of my code, so it's as if I didn't know). I imagine a bunch of the speedup is having fixed sized lists, compared to my `primes.append` call. Edit: Perhaps it would be very mildly faster to track `step` in the loop, since it would be just `step += 2` instead of `step = 2*i+1` (avoiding a mul per loop).
True. So to clarify for any third parties here: True+True returns an int() because the int() implementation of + is what is being used.
The big thing there is that Python has a lot of overhead. Calling `this.that()` 100 000 times has a lot of overhead even if each call is cheap. Further, `compress` will have C-level optimisations impossible in pure Python.
open-source + beard, story checks out. The question remaining... Arch or Ubuntu? I'm guessing Ubuntu.
Fantastic idea. The book is one of the best Python books I've read. 
To me, `if foo` is always unclear unless `foo` is a number, boolean, container, or something with similarly obvious truthy/falsey semantics. In particular, those semantics should be something other than "always truthy" (because if that's the case, why didn't you just write `if foo is not None`? Is saving three keywords really that big of a deal compared to running into subtle bugs like in the OP?). EDIT: The worse problem, of course, is subclassing. Suppose you write a bunch of code with `if foo` everywhere, on the assumption that actual `Foo` instances are always truthy, which works because `Foo.__bool__` does not exist. But then someone subclasses `Foo` and gives it different truthy semantics. Now, you could argue that this is a violation of [substitutability](http://en.wikipedia.org/wiki/Liskov_substitution_principle), but in that case, *every* class which implements `bool()` is a similar violation since they don't have the same truthy semantics as `object`. And since that's obviously not the case, this kind of subclass shenanigans cannot be a substitutability violation, so Good Code (TM) should support it. That, in turn, means not using `if foo` unless you actually know you want something other than `if foo is not None`.
i'm beginning to think this sub is not really representative of the python community as a whole. 
migrations wooo!!!!, now how about a real asset pipeline. more like rails please. 
besides they said theyre going to get south on 1.8 so woot
Not only that, but, where's the WSGI? All I see is Django and Twisted, and something about how it can be "extended" to WSGI apps.
Arch, without question. OSX for productivity and compatibility with my coworkers, though. 
Linkedin? Don't settle for anything less than a reality television show!
For most uses, it *is* a small difference. I have no idea where you got the idea that it's "100 million times more accurate", it's just the closest approximation which your platform allows.
&gt; Yes, as I stated above: too many features for the format of the documentation. That is a general comment - it's not describing what I would call a specific problem.
The error between the true value of pi and math.pi will be about 100 million times smaller than the error between pi and his constant above. That's a very non trivial improvement in any situation where you can accumulate error.
It has to be better than creating an instance of plink using subprocess. What a hacky script that was...
Well in that case I meant append()ing to a list thousands of times usually means a lot of list expanding, i.e. memory reallocation, which is expensive no matter what language you use. But yes what you said is true as well.
Interesting. Is this data publicly available? How can we know the download stats for recent versions of packages?
its probably integrated into things that you use every day but never knew about it its probably in server related things (django et all), maybe requests for when there is no native openssl available, its in bzr and probably hg, (for the same reason)
&gt;PyCharm randomly stopped accepting keyboard input in some windows And your post was near the top of google search results for this issue :/
Wait, so you fly to a conf, get a hotel then sneak into the talks? So the airlines and hotels are worthy of your money, but the PSF isn't?
Compare: &gt;&gt;&gt; python -m timeit -s "lst = [None]*100000" "for i in range(1000): lst.append(i)" 10000 loops, best of 3: 85.3 usec per loop &gt;&gt;&gt; python -m timeit "lst = []" "for i in range(1000): lst.append(i)" 10000 loops, best of 3: 83.8 usec per loop The first will have no copying due to overallocation and the second will have a fair amount. If the dynamic size was a significant overhead, the first would be faster. Rather, they are within error of each-other. Ergo, having dynamically sized arrays is not very expensive in Python terms, largely because Python is slow.
[A slightly fancier version by Steven D'Aprano](http://code.activestate.com/recipes/577896-benchmark-code-with-the-with-statement/?in=user-4172944).
Correct me if Im wrong, but Sublime Text is a text editor. WingIDE and PyCharm are IDE's, which is something completely different. Just run any Python script in Wing or PyCharm and set a breakpoint, and you'll learm the difference pretty fast
No one has even explained what paramiko does and why it should matter to me
Learn to take a joke, please. But, I guess you are right, since that PyCon was ONE year ago, and since I mentioned it this year too... yes, you are right, PyCon is ALWAYS about that.
Yes, why would we want to talk about things like all the financial-aid grants and new-coder workshops and outreach efforts that get more people than ever into Python and excited about it, or the great talks and tutorials, or the startup row and expo hall giving attention to Pyhon-using companies, or the people you get to meet and hang out with, who put in their time and effort not only on the conference but on making Python awesome in general, or... well, *anything* other than an internet shitstorm that blew up until it overshadowed everything else? It's obviously *much* better to just bring that up every single chance we get, in order to make sure that's what people think of when they think of PyCon, and then belittle anyone who thinks there's more we could talk about.
Basic python concepts: * generators * list comprehensions General purpose (standard library modules): * itertools * collections Scientific libraries: * numpy * scipy * matplotlib * scikit-learn (don't use this personally so not sure, but I see it mentioned a lot) GUI: * PyQt4/Pyside (personally prefer Qt vs other frameworks) * PyGTK * wxPython Otherwise if you have something in mind google for "python &lt;topic&gt;" or search PyPI or github and you'll probably find someone who did what you want already. Edit: Formatting
Now you are starting to sound like Adria Richards. All I'm saying is that we should wait a couple of years to see if anyone remembers this incident as more than a joke. Cut down with the vitriol, please, you are going to burn yourself.
Decide what you want to do first. Learn numpy intuitively - vectorizing things instead of using loops is critical, but it's not specific to python, it works the same way in Matlab or R. There are multiple options for most things, so there's no easy way to pick a universal best web app or event loop framework. Read about the concepts and play with one. Use the ipython notebook. It will make a ton of things much easier and eliminate the need for a lot of simple GUIs.
I might have to write a blog on it soon...
Three years? Pssh, [that's nothing. How about 13?](https://bugzilla.mozilla.org/show_bug.cgi?id=63895) Just closed today, heh.
Sorry, I forget to use tail recursived `fib`. Now it should do the job.
In the day of higher res displays, what's the point of the PEP8 length limit? I've seen lots of respectable pythonistas use a longer length.
&gt; To grasp at straws, is it possible that Python has some sort of lazy allocation such that the first one doesn't actually allocate 10e5 entries? Lazy implementations of languages like Python are really hard and would probably be slower. Even in the cases where it seems relatively simple to have this kind of treatment, CPython (the standard Python implementation) tends to not do it. Anyhow, I'm pretty sure it doesn't.
did you google the comments in this thread? because it has already been explained. edit: Here, I went to the pypi page for you and cut and paste... https://pypi.python.org/pypi/paramiko/1.13.0 paramiko 1.13.0 Download paramiko-1.13.0.tar.gz SSH2 protocol library This is a library for making SSH2 connections (client or server). Emphasis is on using SSH2 as an alternative to SSL for making secure connections between python scripts. All major ciphers and hash methods are supported. SFTP client and server mode are both supported too. Required packages: pyCrypto Would you like someone to google crypto and ssh for you too? How about computers? 
For the record, Python 2 is now supported.
yeah its a text editor but a beautiful one. 
im going to continue to use PyCharm. I need to wipe/reinstall Win 7 so perhaps that will speed things up. 
I agree with Megatron: mostly don't approach it this way, but learn more on a need to know basis (based on your programming goals). Why would you want to learn Beautiful Soup unless you're parsing HTML? That said, sys and os seem like modules used often, no matter what you're doing. And itertools does seem pretty handy.
I'm aware of those stats, but they are unrelated to the stats shown on all the PyPI ranking sites. I'm still convinced that nobody knows how many times each package have been downloaded since May 2013. This information _could_ be inferred from the stats you just mentioned if someone would fetch them regularly and do the math, but I don't see anyone doing that. Also, the email I linked before is still linked from the [only "python.org sponsored" app that used to track this kind of information](http://py3ksupport.appspot.com/). Someone said the email was superseded, but didn't mentioned any source. With all that in mind, at this point I find hard to believe in any PyPI ranking information.
Not to complain, but my version runs three times as fast on the version it was written for, Python 3. [Here's a paste of the timer script](https://gist.github.com/Veedrac/9700563). Results: ||Python 2|Python 3| |:-:|:-:|:-:| |vprimes|74.8|20.0| |vprimes_2_switch|31.9|19.8| |rwh_primes|32.9|43.5 (patch) |rwh_primes2|21.3|34.7 (patch) `vprimes_2_switch` just adds another codepath for Python 2. The patches to `rwh_primes` and `rwh_primes2` are mine and as simple as `/`→`//`, `xrange`→`range`. Basically, my results on Python 3 are the best of the lot, but on Python 2 his second version beats mine. --- Also, I think it's neat we independently came up with near-identical code. 
I have completed a few of these. Fun stuff
Some really good suggestions elsewhere in this thread. The best library to learn to use though, plain and simple, is the standard library. It's huge, it does a lot of stuff most people don't realize it does, and tends to do those things very well. The docs might be a bit dry but are pretty damned good too. Spend a good deal of time going through all that it can cover, and only dive into other packages when you have a definite need. When starting out, develop a habit of double checking if the standard lib does what you want before grabbing another package that does it. If so, check the advantages and disadvantages of each before deciding on one. (Using Requests for HTTP, as suggested by /u/geekyme is a good example of a package that greatly improves what the standard lib provides. You'll find other packages though that just try to reinvent the wheel - sometimes poorly.) Additionally, develop a good workflow with virtualenv and pip early on so that you can tinker with extra packages easy without too many headaches or cluttering up your system python. Finally, have fun and pick packages that sound intersting, rather than trying to pick the ones that may or may not have value down the road. Actually using python will keep your skills improving more than forcing yourself to work on packages you don't need/aren't interested in. There's plenty of valuable skills to be honed before domain specific packages become important knowledge (iterators/generators for example.)
Very good explanation
the community is toxic when they have reactions such as above When you ask why something is so damn important to 'everyone' some community people don't usually want to be apart of with shit like that.
Needed to generate a segfault (don't ask why) in a 3rd party application that had an embedded python interpreter: from ctypes import POINTER, c_int def segfault(): POINTER(c_int)(c_int.from_address(1))[0] Not sure if proud or ashamed.
When I need to flatten a uh non-kosher list of lists..... def flatten(l): for el in l: if isinstance(el, collections.Iterable) and not isinstance(el, basestring): for sub in flatten(el): yield sub else: yield el &lt;brace for incoming.../&gt; 
I must have expressed myself wrongly. I do understand what the capabilities are and I do know the concepts behind. What I'm looking for are concrete examples explaining, for instance, why I should call run_forever and close the loop right after run_until_complete whereas there's no real sense in it from the synchronous point of view (the task is over, what is there to "run forever" anyway?). It's things like these I want to learn. I believe, I'm not alone.
I know, it's a terrible state of affairs! Reading them isn't too bad, but if you've got to write them much there will be much gnashing of teeth!
Thanks for the info. I have probably formed my request poorly. I know the theory, I've read through the docs, etc. What I (and IMHO other regular pythonistas) want to know, are practical recipes: a web server, a command executor, a crawler, etc. I think node.js has gotten so popular because of the practical examples you can learn by; this is still missing with asyncio.
This is great news. I think we're finally passing the tipping point where we can expect active packages to be on Python 3. Some other packages that have historically been red on https://python3wos.appspot.com/, but may not be for long: * **Fabric** (system administration tool): Its only dependency is paramiko, so it's almost there! * **supervisor** (a process manager): has a [fairly active Python 3 porting project](https://github.com/Supervisor/supervisor/tree/feature.py3) going on. * **Sentry** (log aggregator and viewer): its [client library](https://github.com/getsentry/raven-python) has been ported to Python 3. The server is something you can just run, and don't have to integrate with other code, so this may not be a real blocker. * **nltk**: the development version, 3.0a, supports Python 3. I've been using it with no problems. The big one that's going to take a lot of effort is **boto** (an interface to Amazon Web Services). Its [attempted Python 3 branch](https://github.com/boto/boto/tree/py3kport) seems to be months out of date. I think boto's development is getting mired in complexity in more ways than Python 3. The project to rewrite boto, called [boto3](https://github.com/boto/boto3), is a ray of hope. Many of the other red packages up there are just old, and can be replaced with better-supported alternatives. It seems like half of them are Web frameworks, where Python 3 already has several great options. 
[This talk is pretty easy to follow. From Guido himself.](http://www.youtube.com/watch?v=1coLC-MUCJc)
tastypie
Wow. Thanks, I will check this out
Can you elaborate on vectorizing please or give a good link to this concept?
Thanks for the suggestions. Right now what I am doing is a bit hacky - I am using an english dictionary to filter out Sanskrit proper nouns. Maybe I need to make different training models, I will start digging into this!
-o. G-O-O-G-L-E G-O-O-G-L-E G-O-O-G-L-E and Google is his name-o.
&gt; No one has even explained what paramiko does and why it should matter to me If it looks like a statement, reads like a statement, is written like a statement, then it probably isn't a question.
Good, helping the community reach critical mass.
I think this is really good advice. If I had to tag on a few packages you are almost certainly going to need, I would suggest you take a look into requests, Beautiful Soup and lxml because you'll almost certainly have to parse a document or web page at some point. Other than that... learn things as they are needed. 
ipython notebooks, and ipython itself. It's the greatest thing ever :)
The problem I had for the longest time was figuring out how the levels, loggers and handlers interacted. Messages would appear that I thought shouldn't and vice versa. The new flowchart in the basic tutorial looks like a *massive* help in that regard.
Try working through some of the problems on Project Euler. They're mostly math-related, but that's how I learned most of the Python I know. It's a really great learning resource and provides more challenging problems than sites like CodeCademy, which serve to teach you the basics of programming languages.
the website you posted (https://python3wos.appspot.com/) has paramiko as red. Not sure how its being updated. 
this is hardly an example of good python use. the `any`-expression would just work if you left the `[]` away -- no need for abstruse uses of next. moreover, the example is completely unsuitable: mime types are not compared with `startswith`, and sacrificing readability for the sake of iterating-through-5-items performance is something i wouldn't recommend either. an example that shows the use of any with a generator: &gt;&gt;&gt; any(True for x in count() if x &gt; 10) True &gt;&gt;&gt; any(True for x in range(5) if x &gt; 10) False (of course, if you have an infinite set and don't have a termination condition, it's an endless loop, nothing will save you from that. if we're talking about finite sets like the accepted mime types, and they are really big, i'd recommend sanitizing the needle and using a `set()` as a haystsck and the `in` operator, for it can look up based on hashes).
Because 3.0 was released more than five years ago.
you will find this QA very interesting on StackOverflow: **Python progression path - From apprentice to guru** (http://stackoverflow.com/q/2573135/617185)
A friend of mine has recently blogged about how he used asyncio to write a webcrawler. http://compiletoi.net/fast-scraping-in-python-with-asyncio.html
I find this topic really interesting, I only starting learning Python not that long ago and have found it really hard to consider 3, if even just because package availability seems to be that much higher on 2.x that I'm kind of stuck using it. I kind of wish that we weren't stuck like this, what are other peoples thoughts on using 3 and is there any sort of middle point? (Using 3x with 2x modules or something - it just kind of feels that this would be the only way to gain traction for the language - the 2to3 conversion process seems clumsy from what I've seen. What's your thoughts on it?
I guess because it's a showcase of a single LOC. You'd probably do it your way in production (that way, you could handle exceptions and stuff as well, and you could add functionality for eg numbers and similar)
`True if comparison` is redundant, just use the result of the comparison. Also, why `startswith` instead of just `==`? Rewritten: ALLOWED_MIME_TYPES = ('application/json', 'text/plain', 'text/html') def is_valid_mimetype(mime_type): return any(allowed == mime_type for allowed in ALLOWED_MIME_TYPES) 
What packages are you attached to that haven't been ported? Been working with Py3 for a couple years now and have yet to find anything I need that only exists in Py2. If anything I find I need far less 3rd party packages in Py3, since concurrency and async I/O have become truly batteries included along with the rework of urllib. Dead honest I find Py2 far more difficult to work with whenever I'm assisting people who are still stuck on it more for tradition reasons than anything else.
Thanks.
It's usually easier to maintain cross-compatible 2x and 3x code now than constantly check 2to3 works. What crucial packages have you found that are 2 only?
I live and die in iPython, no matter what project I work on. It's the library that keeps on giving.
It's basically the approach that 90% of library maintainers take. Apply a liberal dose of [six](https://pypi.python.org/pypi/six) or [future](https://pypi.python.org/pypi/future) to make life easy. 
by the trove classifier “Programming Language :: Python :: 3”, which paramiko didn’t have until around yesterday. the timestamp says paramiko was last indexed on march 17.
I'm like 20,000% sure if you had said, "Google says paramiko is an ssh client, but why is that so useful?" you'd have gotten a number of useful replies.
The standard ones: http://docs.python.org/3/library/ Here's some of my favorites: * Collections * Itertools * Argparse * pdb * os Some non-standard favorites that are worth knowing, no matter your subject matter: * IPython &amp; ipdb * Py.test || nose * virtualenv From there, you'll want to decide what you're working with.
Python devs are usually pretty strong on backwards compatibility, and only break it when the alternative is worse. There are AFAIK currently no plans for a Python 4.0, which should tell you something, since Python 3 wasn't an over-nighter. Py3K was in the works since at least 2004. 3.0 was released four years after that, and they already took a five-year window after that to let the users migrate. 3.0 fixes a lot of warts that stem from the early days of Python. The complete break with backwards compatibility means that there is a lot less to fix now. I wouldn't even expect _plans_ for a 4.0 for another four years at the very least.
So, the plan is that the real life applications for this are the same tools and libraries which already do async processing, but with the added benefit that they will now all work together, instead of each reinventing the event dispatch wheel in some incompatible ways. The point is to factor "async" out of libraries like twisted and into the standard library.
I started using Python 3 not long after it came out. In my case I saw no reason to learn an older language and it was fully capable of doing everything I needed done. This has really paid off as I've become more familiar with the community because the more advanced stuff is slowly being ported over. Even ipython is good on 3.3 and that means a lot of other packages are good. 
&gt; What's your thoughts on it? The actions of the community speak for themselves. Python 3 offers clearly not enough improvements to justify backward incompatibility and is therefore rejected by the majority of the developers. 
thx i thought that would have been 2014-03-14 which was the latest updated date of the tar. 
Don't give it a shot, go all in! Seriously Python 3 has hit the point where it really is usable in most contexts. There maybe exceptions of course but by switching now you set yourself up for mosT likely a decade or more of smooth sailing. 
Python 3.4 is so sweet I'm seriously looking to switch over finally. If you are just in the beginning of your Python journey, go straigth to 3.4...
that's a bad example by itself: as soon as you are in the domain of equality, you can `return mime_type in allowed` and be done with it; if performance is a consideration, make `ALLOWED_MIME_TYPES` a set, and you can have countless allowed mime types.
If you are a beginner learn the core language first (Python 3). Seriously don't underestimate how important this is. Any other suggestion is just foolish in my mind. &gt;As a beginner in python, I'd like to know beforehand what are the most used and useful packages I could be studying. Ultimately it will depend upon who you ask as Python is widely used in a variety of fields. Some users may be intimate with a web framework while others are focused on genome processing or statistics. If iPython fits in with the way you work I'd have to recommend that as a decent avenue but it isn't so much a package as it is a way to use Python. I often use it as a scripting tool, in this regard all you really need to do is to leverage the standard library. For a beginner learning the standard library along with the core language should keep you busy for months. &gt;It could be for general purposes, math, science, networking, game creation, GUI, whatever. You don't really expect anybody to offer up decent advice with a wide array of interests like that do you? Ultimately you and only you can decide what is important to you. When and if you do, focus on packages associated with that interest. More so try out several packages to see what works good for you. For example there are many web frameworks to learn about if your sails are set in that direction. &gt;So... what are the most important packages available? Silly question!!!! What is important to you may be of no interested to somebody else. If you can't define your interests no body here can give you useful comments. Sure they can throw out a bunch of names but few will be all that aware of the different packages in a depth that is useful. You would be better off asking people which packages they use for certain problems and why. You will then get a variety of answers that you can digest and apply to your context. 
Some feedback for you, from the documentation it is really hard to understand what this is doing or why it matters. Even with the example all I am seeing is there has been files added to a directory. Also it does not seem to be particularlly relivant to python in any way unless I missed something?
It seems to be written in Python (not to say that I believe that makes it remarkably relevant).
 &gt;what is python main backwards compatibility policy ? Why are you asking here? That is what Python.org and the development lists are for. &gt;everytime new release come , they will break compatibility ? Probably not. However don't expect a new release anytime soon. &gt;or python2/3 problem was only a clean up and will never happen again. How is it possible to even answer that question. Nobody can predict the future but in this context I highly doubt there will be the great breakage that was seen in the 2-3 transition. Why? Because the whole point of Python 3 was a clean break that fixed up many issues that had been in Python for years, it was a smart move on the part of the developers because it solidifies a platform for what will likely be decades. &gt;is there any insurance for python programmer ?? There is never really any insurance for any programmer is there. Even C++, with its rigorous standardization process leaves old versions of C++ far behind. &gt;* JDK's are (usually) forward compatible. &gt;* JRE's are (usually) backward compatible. Look at it like this, MicroSoft has tried to maintain backwards compatibility for years and as a result has turned Windows into crap. Apple on the other hand has cut the cord with the past several times and now has one of the most impressive and stable platforms out there. Which one would you rather be developing against? Frankly your questioning leaves one with the impression that you are a lazy programmer that doesn't keep up with technology. The fact of the matter is that old languages often leave much behind to drive adoption of modern concepts. For example I will look again at C++ which while backwards compatible supports new language features that will never build on old compilers. This is to the point that a new programmer trained to write idiomatic modern C++ would not have code suitable for a compiler built even a couple of years ago. In a nut shel as a programmer you either move forward or you get stuck in the past. So why did you even ask this question? 
3.3 is pretty nice also
Rather amazed that no one is mentioning Pandas http://pandas.pydata.org/ . Arguably the most useful Lib ever for any sort of data analysis. 
 &gt;&gt; That is a general comment - it's not describing what I would call a specific problem. &gt;If you're going to keep ignoring general problems and only address specific tiny fixes - then you'll never address the fundamental problem with the logging module: too much complexity for what should often be a simple solution. He wasn't ignoring anything, if he was ignoring you there would have been no posting in this thread. As for complexity, you are suppose to be an educated person with a focus on computer science, if a logging facility causes you grief how in the hell do you get any work done? Seriously. As a programmer the rational thing to do is to offer up a solution that you think abstracts away the complexity in a rational manner. The other possibility here is to enlist the use of another logging package that suits your ability to grasp it. &gt;And since you appear to have no interest in addressing this - it might be best to not keep trying to prevent others from coming up with simple logging solutions. This is one asinine comment as the maintainer has offered several times to address any short comings that can be detailed in the documentation. Believe it or not maintainers can not read minds, you actually have to express in English what is causing you problems (something no one has done yet in this thread). Further the maintainer has done absolutely nothing to prevent others from coming up with alternative logging solutions. It is pretty shitty of you to suggest that he has, because as a third party all I see is a guy trying to help. I'm sorry to have to even respond to this thread in the way I have, but it I see this thread as nothing but garbage. It appears that we have a few people with an inability to understand logging trying to beat up on the maintainer for no good reason. Maybe these attacks are a way to mask ones own shortcomings as a programmer, I really don't know, all I do know is that somebody offering help was trashed for actually offering that help. If there are problems the avenue to improving things is to work with the maintainer not against him. 
Just my personal opinion of course: Proficient enough so that the majority of the "framework-code" that you write does not seem or feel like magic. So for example you understand that is a function, that is a class, that is an instance of the class, that is a member of that instance of the class, those are function arguments, that is a decorator, and things of that kind, so you understand the basic building blocks and the fundamentals. It's ok if the internals of the framework are still magic to you. Having said that I think if the timing doesn't work out exactly for that you'd be fine if you just jumped straight into it and learned bit by bit. Regardless of the method, the key is to understand the language and the framework and the underlying technologies well enough that it does not feel like magic at all, you understand what happens and how it is happening, you just use the framework for convenience, not because you don't understand how to do X and Y. 
You can do that with [cgi.parse_header](http://docs.python.org/3.5/library/cgi.html#cgi.parse_header), by the way.
wxPython is 2.7 only. 
WHAT?!
+/u/ubernostrum has every right to speak out. I can assure you he's earned it.
OP, you framed your question beautifully. You want cookbook recipes to study. I'm in the same boat: I can call goroutines on golang all day long but can't wrap my head around how to use asyncio for basic concurrency. Also is it possible to use multi ores with asyncio?
What is your choice of OS for this?
Apart from the 2-&gt;3 transition, backward incompatible changes are rare and localised (like the recent date truthyness change where no-one is expected to be relying on the old behaviour because it was so crazy).
You should be quite comfortable with OO and Python's syntax. You should have syntax errors very rarely, even after writing large amounts of untested code. 
&gt; Actually the only reason I can see for a static compiler would be to deliver an easily distributable executable that has no dependencies. I'm not sure if any of the "exe" solutions truly do this. Let's face it if speed is an issue then programming in Python is a mistake. Frankly I don't think execution speed is an issue for most users. You're not wrong, although complaints about Python's speed are, in my opinion, misplaced. While you can write video processing code in Python, you probably shouldn't. Similarly, you could write a bunch of text processing stuff in c++, which while fast, the Python version would've done processing before you can write std::cout ≤≤ "The results are” ≤≤ std::endl;! It's also indispensable for protyping and fledging out ideas without getting caught up in memory management or coaxing the type system to do what you want. &amp;gt; The thing is PyPy has been a works in progress for how long now. On the other hand you have modern C++ which is a dramatically different language than even a couple of years ago. These difference in C++ bring it closer to the interpreted languages in ease of use though the gap at times is still huge. In any event it sometimes amazes me that people struggle so much to try to change Python into something it isn't. This may very well be what Guido alluded to. Pypy, for its part, started as a "yo dawg we heard you like python so we wrote python in python so you can code while you code" and then took off into JIT compilation land and beyond. If pypy ever managed to get compatibility with CPython good enough I'd like to see it be a replacement for Cpython, and those who really need the power can write c code for CPython. That way, 80% of projects could benefit from the jit speed increases and c extensions are available for those who really need it. &amp;gt; Python was never meant to be a replacement for C/C++, Java, fortran or any of a number of other compiled languages. I'd go so far as to say that the only reason Python has the wide usage it currently has is that modern hardware is so fast Pythons "slowness" doesn't matter. This modern hardware allows for a focus on programmer productivity which in many cases is the most important factor in a project. I would argue that the slowness, by and large, doesn't matter much anyway. As you say, programmer time is usually far more valuable than time spent waiting for results. There is also work ongoing on languages that are something of a mix between high level languages like python and lower level ones like c or c++. Go, for instance, is statically compiled, strongly typed, and includes other features inspired by dynamic languages. Granted, no one is using it, but the effort to get nice syntax and performance is on going. Edit: formatting
&gt; the embedded cell text editor doesn't have all the features I like to use in my everyday text editor (Sublime Text 3). But then someone brought [IPythong Notebooks editing to SublimeText](https://sublime.wbond.net/packages/IPython%20Notebook) 
I learned Python by starting with the django tutorial.
I'm not the OP, why did you reply to my comment?
I would imagine it's the standard Debian Wheezy variant that most RPi's use; I don't know if the "RPi.Gpio" package has been ported to any of the alternative RPi OSes.
You just blew my mind with the vectorizing thing man.
I have a few projects that rely on M2Crypto. There *might* be a usable alternative out there but finding it and re-writing everything to use it is more hassle than I have time for at the moment. Similar with python-ldap. The NLTK is basically one-of-a-kind AFIAK and they're only still releasing alphas for Python 3. Still waiting for a Twisted port, too.
Work through these exercises and you should be pretty good at vectorizing calculations: http://www.loria.fr/~rougier/teaching/numpy.100/index.html
&gt; This is usually much faster Specifically, it's faster because if you express it in terms of "do this to each of these" instead of "for each one of these, do this to it", a smart enough runtime environment can use things like special processor instructions and automatic parallelization to make the code run much faster.
Others have mentioned the standard library. If you're looking for a gentler introduction to it than reading the python.org docs, check out [Python Module of the Week](http://pymotw.com/2/contents.html).
After you have the standard ones, BS4 and Requests can be good to know. Tkinter is good to know but significantly harder to learn.
Version guarantees are what make using libraries feasible. See, for instance, https://docs.djangoproject.com/en/1.3/internals/release-process/#internal-release-deprecation-policy and http://semver.org/ .
 * http://legacy.python.org/dev/peps/pep-0004/ * http://legacy.python.org/dev/peps/pep-0005/ * http://legacy.python.org/dev/peps/pep-0006/ * http://legacy.python.org/dev/peps/pep-0101/ * http://legacy.python.org/dev/peps/pep-0290/ * http://legacy.python.org/dev/peps/pep-0291/ * http://legacy.python.org/dev/peps/pep-0387/
Pprint is a godsend when trying to figure out what's going on with complex nested data types.
This is the list of project I like. they are the most useful imho :) #Web : * Django * Flask * gunicorn #http: * requests * beautifulSource4 #GUI : * Kivy (does game too ) * wxPython #science : * Gensim * nltk * scikit-learn * theano * numpy * matplotlib * pandas * ipython #Others * RQ * pygal * Pymongo * pickle 
&gt;SQLAlchemy for ORM / data management. If I end up turning this thing into a service I'll want to do the data mapping stuff only once. I looked through the SQLAlchemy tutorial a bit and it struck me as being very similar to hibernate. Am I right about this? Any alternatives I should be considering? No, SQLAlchemy is a solid choice and probably the best data mapper ORM available. If you want an active record ORM django has probably the most popular python one, and if you want a website bolted on the side it might be worth using. It's solid, but probably not *quite* as good as SQLAlchemy on the whole. HOWEVER, if you want to at some point have a nice website, especially one with an admin that takes about 10 lines of code to set up - http://www.djangobook.com/en/2.0/chapter06.html - it might be worth using this instead. Django makes that stuff really easy. &gt; I have no idea what to use for build tools, logging and unit testing (perhaps nose and mock?)! I was planning on using Jenkins for continuous deployment though. I use jenkins too. Python has built in logging and unit testing - yes mock and nose are both good, use those. For building I'm not sure. There isn't a lot of building necessary with python (no manual compiling). I generally just use shell scripts for the few bits and pieces I might need after. Building isn't so much of a chore anyway. Use pip, virtualenv and requirements.txt to manage python packages/versions/dependencies, though. &gt;I'm not sure if there's anything for dependency management ala spring or even if it's necessary. There's a spring for python, but I don't know anybody who uses it. I hate the IoC pattern anyhow. I was never very convinced of the usefulness of it (especially not taking account of the extra work involved and the limited gains). &gt;Just for reference, everything is running on a debian virt (not sure if this make a difference), but I might end up switching to CentOS or RHEL at some point. I'd probably stay away from CentOS or RHEL. Yum's dependency on python makes it a pain to upgrade - http://joshuakehn.com/2011/2/4/Upgrading-Python-on-CentOS.html
Here's something I wrote a while ago to append a random zero or one. You could use this to create your test/training sets if applied to the db export. import random import csv def flip(): x = random.randint(0,1) return x with open ('file1.csv','rb') as f: csv = csv.reader(f, delimiter=',', quotechar='\'') header = csv.next() header.append('Randomiser') print header for row in csv: var = flip() row.append(str(var)) print row 
 def procrastination(): raise NotImplementedError()
I have purchased the book and can definitely see value to the community with a series of videos too. Some people learn better that way, and if he reaches $10k they will be free to watch. 
&gt; I'd probably stay away from CentOS or RHEL. Yum's dependency on python makes it a pain to upgrade - http://joshuakehn.com/2011/2/4/Upgrading-Python-on-CentOS.html It's hard to avoid CentOS and RHEL completely - they're the most common linux distribution on servers. So, for home development, I agree - I'd rather work on Ubuntu/Debian myself. But for work, I've used Redhat &amp; CentOS for years. And it really isn't that bad. The posting that you provided is pretty clear about the need to use an alternate install. That's all.
Untrue.
Multi-cores—I doubt it. There's still GIL. Asyncio is about delegating tasks to threads or processes, not about multi-core.
Ya, I prolly need to get more familiar with syntax haha
Thanks for linking that! Very interesting stuff
its just python dunders, it runs fine on my machine!
That could be done, after I have solved some non-python related OS software issues...
awesome. Thanks, this was just the kind of feedback I was looking for
&gt; Also it does not seem to be particularlly relivant to python in any way unless I missed something? I would venture to guess it would be relevant for web development. it seems to follow the same strategy as rails asset pipeline FWIW 
I got that it should help you render and compress scss an javascript, which whould be neat on web development. You got a plethora of tools like this madre un ruby ti be usted with rails and such. It's quite underdocumented and unintuitive. True.
May I suggest adding the user's *current* password hash to the HMAC you generate in get_auth_code? That way it also prevents the generated digest being used multiple times.
\**sigh*\* Project Phoenix [replaces wxPython](http://wiki.wxpython.org/ProjectPhoenix) and [is stable enough for production](https://groups.google.com/forum/#!searchin/wxpython-users/phoenix/wxpython-users/LNAJ7JZZwjA/VNQHahKdpmYJ).
Don't bother with anything map-reduce, especially for machine learning. This isn't just a Python thing, it's a computing in general thing. Map-reduce is only good for solving *very easy* problems on *very large* amounts of data. Otherwise, it will be slower and more expensive than not map-reducing. For almost all machine learning, you should use an individual computer to compute with. That's what it's good at.
&gt; If you're going to keep ignoring general problems It's not a question of ignoring anything - general problems can't be easily addressed, as one has a hard time figuring what specific changes need to be made. &gt; And since you appear to have no interest in addressing this - it might be best to not keep trying to prevent others from coming up with simple logging solutions. I've no idea what you're talking about - I'm not trying to prevent anything, and even if I wanted to (which I don't), how would that even work? 
&gt; I've no idea what you're talking about - I'm not trying to prevent anything, and even if I wanted to (which I don't), how would that even work? By continually insisting that the logging module's basic config is just as simple as alternative logging solutions. Which is deceiving since the logging module's basic config is nearly worthless for anything non-trivial. Once you go beyond the basic config you are stuck having to wade through all the details. And this happens almost instantly.
If you're happy with some other logging solution, go ahead and use it. Otherwise, since you know best how to solve your own problems, you can roll your own solution. Offering to fix a specific problem isn't evading anything, it's trying to be helpful - too bad if you can't see that.
I learnt Django on the job before knowing any Python. I don't think I actually suffered that much from it, in hindsight, although at the time I definitely worried that it was the wrong way to go about things. Looking back I don't think I'd change that.
Umm. def check_passreset(payload, auth_code): new_code = get_auth_code(payload) if new_code != auth_code: raise PassResetError("Invalid password reset request") This leaves you vulnerable to a timing attack. new_code and auth_code are compared character by character, after first checking the lengths are the same. This means that you can loop over lengths to find the length (not needed?), then you can loop over first characters, then second, etc. Reduces the search space from 16^hexdigits to 16 * hexdigits.
2.7.x ^is^pretty^sweet 
I'm a bit confused what you want to achieve (and not familiar with IPython) ? Do you want to embed a web browser in PyQt to intereact with a webframework ?
Well I guess you need a web framework, and there are loads of them eg bottle, flask, pyramid, django et all. For my projects i use flask as server, and clients of pyqt for desktop, extjs4 for website and sencha touch for mobile; all chatting away over AJAX
I'm talking about a way to find the secret key! Suppose you have a message `m` you wish to find the key for. Send m with a secret key of char and 31 zeroes, for all characters in [0-9a-z]. One of those will have a larger latency to a failure response than the others. Congratulations, you have now figured out the first character! Repeat with characters 2-32. Yes, this works even with noise in the response latency. Yes, this works even if noise is added to the response latency.
This! I didn't know that existed (awesome), and like I said it was fun to play with.
It's linked from the original blog post you cited...
I don't think it is a way to find the secret code (i.e., the one passed into the HMAC function), but it may be theoretically possible to break an auth code this way. I'm not sure how the statistics work out, but I think it would have to be a massive attack to get to statistical significance, because the network latency (and noise therein) is several orders of magnitude larger than a single character comparison on the CPU. I'd love to be corrected on this one though, as this would be good knowledge to have. Can you point me to a paper or otherwise that proves me wrong?
Ahh, yes, I see it now. I just mixed it up.
nice! could you load up your project in PTVS &amp; let us know if you find any bugs/issues? much appreciated! +1 for ironpython!
Ah, I see what you're saying. The validation process will take, say, 100ms, plus 1ms per character that matches. Therefor you can determine how many characters match. I have two questions, then. First, is it practical to crack a key with this method, assuming normal network latency and noise? I mean, there will be a variable time before the script even runs if the thread is busy, or if it only polls for new connections every 10ms, then you will have 10ms of noise... Second, what's the best way to prevent this? I would think always checking all of the characters, even if there is a mismatch early on, so that it takes a constant about of time...
&gt; I don't think it is a way to find the secret code Correct. &gt; but it may be theoretically possible to break an auth code this way. Correct &gt; I'm not sure how the statistics work out Crosby et al., *Opportunities And Limits Of Remote Timing Attacks* &gt;We have shown that, even though the Internet induces significant timing jitter, we can reliably distinguish remote timing differences as low as 20µs. A LAN environment has lower timing jitter, allowing us to reliably distinguish remote timing differences as small as 100ns (possibly even smaller). These precise timing differences can be distinguished with only hundreds or possibly thousands of measurements. 
&gt; First, is it practical to crack a key with this method... Yes. Crosby et al., *Opportunities And Limits Of Remote Timing Attacks* &gt;We have shown that, even though the Internet induces significant timing jitter, we can reliably distinguish remote timing differences as low as 20µs. A LAN environment has lower timing jitter, allowing us to reliably distinguish remote timing differences as small as 100ns (possibly even smaller). These precise timing differences can be distinguished with only hundreds or possibly thousands of measurements. . &gt; Second, what's the best way to prevent this? I would think always checking all of the characters, even if there is a mismatch early on, so that it takes a constant about of time... Good try, but that doesn't work, surprisingly enough. Modern CPUs do branch prediction, which will reintroduce the timing discrepancy. Either do something along the lines of the following: correctMac = self.Sign(msg) if len(correctMac) != len(sig_bytes): return False result = 0 for x, y in zip(correctMac, sig_bytes): result |= ord(x) ^ ord(y) return result == 0 (This still leaks the length of the MAC, which generally isn't a problem. Although note that a smart interpreter / compiler could very well optimize this function to take non-constant time!) Or figure out the worst case time to do the string comparison, and add a `sleep(worst case time - actual time)` at the end of the comparison. (Or add the response to a queue that you only send items out of once the delay is up.) Although note that that has other issues.
Thank you!
That's correct. This was back in 2007. I haven't really looked at the tutorial since then, but I imagine it has only improved significantly. I continued to build websites with django since that time. While working on those sites, I started to pick out the bits that were django magic and the bits that were straight Python. Then I got several jobs writing Python code. Learned a lot of non-django stuff.
If I'm understanding your question correctly (you wish to use QT but for the web) you can use [QtWebKit](https://trac.webkit.org/wiki/QtWebKit) for that. It compiles and runs on Linux, Windows and Mac OS X. I do not have any experience of this myself though so you will have to do a bit of research. My advice to you is to learn either the [Flask](http://flask.pocoo.org/) or the [Django](https://www.djangoproject.com/) web frameworks due to the fact that there are more resources and tutorials available going down this route than on running QT applications on the web.
&gt; I wonder how long an integer comparison takes on a modern processor? Best guess, an order of magnitude or more longer than 20 microseconds? You're joking, right? CMP on almost all modern processors is a single clock cycle. 2.5GHz processor works out to something like 0.4 *nano*seconds per clock cycle. But you're working in Python. A comparison is a lot more than a simple cmp. So... I don't know. Amusingly enough, on my machine, running Python 3.4, string comparison seems to be consistently *slower* when the two strings are different.
Words can not adequately express my relief that this uses a non-exponential-time algorithm to do the matching. If only more would follow your good example! (Why yes, I *have* run into real-world cases of regular expression matching taking a crazy long time. Way too often.)
Honestly, despite academia showing that Internet-based timing attacks on standard string comparisons are technically feasible, in reality the odds of someone being able to take advantage of it on an Internet-facing production server more than a few hops away is *extremely* low. Attackers are going to go for the simple and easy things, not something that may or may not work and may take tens of thousands of requests and days at a time, in exchange for a relatively unvaluable reward.
And if you want to compare in constant time, with fairly strong guarantees that no implementation will do anything clever, here's a small library to do just that: https://pypi.python.org/pypi/streql/
I'd love to, but PyOhio falls on my daugther's birthday. I moved to Virginia last May, and work for the Center for Open Science. We had people at PyOhio last year, and there will be people there this year as well. I've not decided yet if I'll be able to make it. My daughter will be 6, so she's still a bit young to fully participate.
For my high school programming assignments, I wrote this nifty function to validate input: def read(parse, prompt='', error=None): while True: try: return parse(input(prompt)) except ValueError: if error is not None: print(error) Use like so: num = read(int, 'Enter a number: ') With the `compose` function [mentioned elsewhere](http://www.reddit.com/r/Python/comments/20x61y/share_the_code_youre_most_proud_of/cg7quv4), we can do some pretty clever validation: def in_range(lo, hi): def validate(x): if x &lt; lo or hi &lt; x: raise ValueError return x return validate # See &lt;https://gist.github.com/lfairy/5033356&gt; guess = read(compose(in_range(1, 100), int), 'What is your guess? ')
learn to be pep8 compliant first. pep8 (the tool) and pylint will help with that learn to write tests for your code. nose/pytest/coverage.py will help with that when you are comfortable, learn the stdlib (the things that aren't in any module, but are available by default) after that, jump straight into itertools. it's a complex module, but you will pick a lot of great habits from the start and won't try to rewrite to python the patterns you used to implement in other programming languages (unless those other ones were some hardcore functional languages) everything else is for a particular task
Perhaps because small strings are cached, so it just notices that both objects have the same address and doesn't have to compare at all?
&gt; These precise timing differences can be distinguished with only hundreds or possibly thousands of measurements. You can throttle that. The same account gets more than 10 bad reset requests in an hour? Lock out resets for an hour. Now you have a lower bound of ~10 hours to brute force an account. Of course, I imagine you could simultaneously try to brute force a lot of accounts at once. Per-client-IP throttling could help with that, but the *real* black hats use huge botnets anyway. So throttling doesn't actually work. It might be better to just hash both strings with SHA-512 and compare the hashes (and then compare the actual strings if and only if the hashes match). I imagine a timing attack on that would be, at the very least, extremely complex.
Python 1.0.0 for life.
But you're explicitly doing the wrong thing! Implicitly right is better than explicitly wrong. You're testing if the value is None, while the original code tested the value for truth. In Python, all objects have a concept of 'truthieness', i.e. any value can be reduced to one of True and False. It might have been more explicit to require an explicit conversion in order to test for truthiness: if truthy(myFancyObject): ... There actually is such an operator that you can use in Python, namely the constructor for the bool type: if bool(myFancyObject): ... Regardless, the 'is None' test is the wrong thing since it does something completely different. It is true that many people is 'if foo' when they should use 'if foo is not None', but that is hardly the majority of cases. There are a huge number of cases where 'if foo' truly is what the code meant. In the end, I guess the logic if not having an expicit truthieness operation is that the if statement in itself is an expicit indication that you're going to want something with a boolean context, and that adding a second explicit cast to bool wouldn't be more explicit, only redundant. YMMV.
Have a look at django, this is how it does password resets too
Using the same secret for every user seems risky to me. You should combine the the secret key with a per user secret such as their existing password hash (ideally with something like HKDF but HMAC(secret_key, current_password) would probably do) so that an attacker can't turn knowing a single secret into being able to hijack any account on the site.
Also, please use jinja instead of this horrible mess of python format strings!! 
Pretty interesting. You can try integrating with https://github.com/twbs/ratchet for better interface.
Very nice. I have wanted this to exist for a long time, not quite enough to try to make it myself :)
Obligatory PEP8 speech.
There's also this project. https://github.com/JonApps/imgur-screenshot
A few tiny things you could consider changing. It's superfluous to compare a boolean value to true or false - for instance if boolean_variable == True: do_stuff() is the same as if boolean_variable: do_stuff() Another thing is the parentheses around the values you compare with in your if-statements. In the code below, the parenthesis is not necessary, and removing it means less clutter. if some_variable == ("hello"): do_stuff() Generally, for some useful guidelines for how to write "pythonic" code, have a look at the [PEP8 here](http://legacy.python.org/dev/peps/pep-0008/).
It does look a bit as if whitespace would cost money for OP. But the thing is still very readable, so what's your problem?
There's also this script https://github.com/LuRsT/Setup/blob/master/bin/shoot
Nice for you terminal fans. For GUI people: KSnapshot has plugins, a imgur one among them. Just select it once, and uploading to imgur is one “Print Screen” keypress and a click away.
I agree with you. The lack of whitespace is a bit awkward, and it wouldn't take a genius to knock a bit of spacing it, but the code's still readable. I wouldn't say there's much of an issue here. Developers like to throw bricks at those who don't follow standards, especially ones that are though of to be important like PEP8.
I've taken a quick stab at reformatting some of it. Haven't tried running it since I don't have Python 3 at this computer. [Check it out here](http://pastebin.com/WRhFknMa). Another thing is that you have implemented it as a class, but you don't really use the features of a class, since the whole thing just runs from the init method. For a program such as this one, a class is really not necessary and you would be fine with just separating your logic into some functions and calling them at the main entry point like this. if __name__ == "__main__": do_this() do_that()
You only get 1250 uploads a day with a single per-application api key. I see you can specify your own key as a param but don't really check for the `X-RateLimit-ClientRemaining` in the HTTP response, which may be useful to grab and print or take actions on. [More info in the docs](https://api.imgur.com/#limits).
&gt; Developers like to throw bricks at those who don't follow standards Which is why I used the more sarcastic form "Obligatory .... " instead of "OMFG you totally didn't follow the standard." 
&gt; with fairly strong guarantees Try, with no guarantees. I've seen that solution posted many places (and indeed, posted it myself elsewhere in this comment tree), but there is no guarantee the compiler / interpreter / JITter won't replace the following code: result = i = 0 for i in xrange(len(x)): result |= ord(x[i]) ^ ord(y[i]) return result == 0 With this: for i in xrange(len(x)): if ord(x[i]) != ord(y[i]): return False return True Also, it isn't constant time in the general case: as I mentioned elsewhere, streql still leaks the length of the string.
So you're saying don't fix a known vulnerability because people likely won't bother to exploit it? Also, what's a "relatively unvaluable reward" to you is not necessarily a "relatively unvaluable reward" to everyone.
No, hence the terms "mini project", and "starting point" in the article. ;-) I want to make this a platform for a home monitor bot that I am building. The complexity is in the software you build on top of this, in any case.
Yes. I've written about my basic set up here: http://electronut.in/starting-raspberry-pi-wifi-ssh-and-gpio/
Thanks!
You can probably get better feedback on /r/learnpython, but from a design perspective, besides what other people have said, it's generally bad practice to create a class and then run the entire program in the init function. What you've done is create a function and just call it a class - it's a design decision that would confuse someone responsible for maintaining your code in the future and might convey that you had intended for the program to function in a different way than it does. This would actually be a good exercise for you to gain more proficiency with classes. Try implementing a class CoinToss so that you could do things like c.set_snark_level() c.flip_coin() and then integrate it into your main function! 
KSnapshot, KDE's snapshot tool has support for upload to various sites including imgur. However I think few people know of this.
I like that it uses the new v3 API.
File should have a proper .py extension, also, your #! Should be /usr/bin/env python2 On checking for scrot installation, you could perform that much faster without trying to execute it, using something like os.path.isfile().. You're already using os.path.exists(FILENAME), so same idea
FYI, it’s green now.
&gt; streql still leaks the length of the string. Which is one reason we hash our passwords, right? A hash is always the same length, so if you limit your x to hashed passwords, it does indeed run in constant time, relative to the user input, which is the important part for maintaining secrecy.
Oh Cool. Had a great time chatting with them at PyOhio last year, and snagged a great t-shirt at PyTennessee this year. It was green, so I wore it to all my St. Paddy's day activities and pitched your mission to anybody that asked about it.
Like this: def error(text): print "[-]\t"+text raise Exception(text) def takeScreenshot(): printv("Checking if scrot is installed...") resp = subprocess.check_output(["scrot","-v"], stderr=subprocess.PIPE).strip() if not re.search(r"^scrot version \d+\.\d+",resp): error("Error: scrot not installed (command scrot -v failed)") printv("Success: scrot is installed!") prints("Taking screenshot...") if args.delay: for _ in range(args.delay, 0, -1): writev(str(d)+"... ") time.sleep(1) if args.filename: filename = args.filename else: filename = time.strftime("%Y.%m.%d.%H.%M.%S.png",time.localtime()) subprocess.check_call(["scrot", filename]) if not os.path.exists(filename): error("Error: The screenshot file seems to have dissapeared... what did you do???") with open(filename,"rb") as f: data = f.read() if args.clean: printv("Deleting screenshot") os.remove(filename) return data 
Very interesting read man!
This feels like one third of a very interesting article.
My own two cents I think the 17k options itself is untenable. Some options for that of course could be a series of selects that allow the user to narrow down that list by selecting ever more specific categories. Like drop down #1 could maybe be a very general category or even the first letter or something, and so on. Sorry I don't otherwise have any code like that or what you're looking for but a recent project I did at https://github.com/th0ma5w/rtl_fm_python uses Flask for REST services which return JSON. Then a React based web app renders the drop downs. Best of luck! Making information findable is the challenge of our age.
I hope you can make some progress :) maybe email Guido and see what he thinks too?
Try installing an equally old Linux distro in a VM. I've done that to get old software working. 
32-bit VM too much like hard work? Don't get me wrong, an x64 port would be interesting, but at least show the thing running!
I just compiled and installed it on modern arch 64bit (with just the getline to _getline change and it works..no segfault)
 [user@localhost bin]$ file python python: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=b4f6a4c5acf24052017197402cad417960d8a6f9, not stripped [user@localhost bin]$ ./python Python 1.0.1 (Mar 23 2014) Copyright 1991-1994 Stichting Mathematisch Centrum, Amsterdam &gt;&gt;&gt; print "Hello world" Hello world 
Fair critique. I've gotten in the bad habit of writing half blog posts and never publishing them, so I'm trying to counter that by getting stuff out there. I'll work on finding a balance.
Try building it with some debug flags and running it through gdb, find out where the segfault is coming from.
If you got a shirt at PyTN, you most likely met me :) I was the fat bearded guy at the COS booth. 
This is a debacle. People will never move off of Python 0.x.
Use 0to1 to transition your code today.
Same here, except I just sort of stopped writing blog posts altogether. Half a post published is better than a whole post that's never published.
That thread shows pretty clearly that Phoenix is *not* yet stable enough for production - a number of modules have not even been ported yet. However, it looks like there is constant progress ongoing, so things are looking good.
Please post the rest of the story as well. I'd really like to read the whole thing.
17K options? Sounds like a job for an auto-completing search box, not a pure drop-down select. I did something similar for an account# entry (for about 5,000 possible account#'s) 
Also, how long does it take to be a good python programmer?
I guess I'm trying to figure out if I can use it like go routines in golang. Where it spawns new light threads that you can then tell to run on more than one core or not. I.e. Still just concurrency but spread over multi cores. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Comparison of open-source configuration management software**](http://en.wikipedia.org/wiki/Comparison%20of%20open-source%20configuration%20management%20software): [](#sfw) --- &gt; &gt;This is a comparison of notable [free](http://en.wikipedia.org/wiki/Free_software) and [open source](http://en.wikipedia.org/wiki/Open-source_software) [configuration management software](http://en.wikipedia.org/wiki/Software_configuration_management), suitable for tasks typically performed by a [system administrator](http://en.wikipedia.org/wiki/System_administrator). &gt; &gt; --- ^Interesting: [^Puppet ^\(software)](http://en.wikipedia.org/wiki/Puppet_\(software\)) ^| [^Configuration ^management](http://en.wikipedia.org/wiki/Configuration_management) ^| [^CFEngine](http://en.wikipedia.org/wiki/CFEngine) ^| [^Project ^management](http://en.wikipedia.org/wiki/Project_management) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg9vyrp) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg9vyrp)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
http://competency-checklist.appspot.com http://en.wikipedia.org/wiki/Continuous_integration#Principles http://www.reddit.com/r/Python/comments/1drv59/getting_started_with_automated_testing/#c9tfxgd
You might check out [select2](http://ivaynberg.github.io/select2/), there's an infinite scroll example on their site.
http://conda.pydata.org/docs/ http://docs.continuum.io/anaconda/install.html
Configuration Management tools written in Python for desktop support / system administration. https://en.wikipedia.org/wiki/Time_management * https://en.wikipedia.org/wiki/Comparison_of_issue-tracking_systems * https://en.wikipedia.org/wiki/Forge_(software) * http://www.worldcat.org/title/time-management-for-system-administrators/oclc/63170812
Moar. 
1250 pictures isn't enough per day? XD 
Just pushed changes to accommodate that. I am assuming the header value just drops to 0 when you run out.
I'll work on this now, thanks for the suggestion! EDIT: Pushed changes
I miss python 1...
I highly recommend Learn You a Haskell although Real World Haskell is equally as good.
Pushed changes so that it conforms to pep 8.
Well this won't work. QT is a framework for desktop applications. You can't use it to render web frontends. In webapps HTML/CSS/Javascript is used to build the frontend "inside" the browser. There are some JS-Frameworks that can help you build "desktop like" apps in the browser (e.g. [Sencha Ext JS](http://www.sencha.com/products/extjs/)) but using those is not trivial (much less so for a beginner). I would suggest you have a look at a few python web frameworks (e.g. Flask, django, etc.) and then go from there. 
Actually the exception was already taken into account, hence the try, except. It wouldn't generate a specific error message though, just a generalized "Error: Couldn't upload image"
&gt; I have no idea what to use for build tools, logging and unit testing (perhaps nose and mock?)! Logging is alreay built into the standard library and I would suggest you take the time to understand it (it makes dealing with 3rd party library logging, etc. a lot easier) since you seem to be coming from java it should feel somewhat familiar to you as it's API was originally based on log4j (which makes using it also not very pythonic and not very well liked in the community) Once you've understood that you can move on to [logbook](http://pythonhosted.org//Logbook/) for a much nicer experience. For unit testing I would suggest the excellent [pytest](http://pytest.org/latest/). If you want / need to support multiple python versions you should also take a look at [tox](https://testrun.org/tox/latest/) to automate running the unittests under the various versions you require.
I read that link differently. That development is ongoing does not counter that it's *stable*, just that it's yet to completely reach feature parity. Namely, if over half a year ago @Robin Dunn &gt;In addition to Kevin's and Andrea's comments let me add that the C++ extension modules are very close to being done. The only major things left are the propgrid and richtext modules, perhaps a module that has some classes that are only available on Windows, and wxAUI if somebody can convince me that it is needed given that we have Andrea and wx.lib.agw.aui. Other than those items and some things in the wx.lib that will need some work, **I'm inclined to say that Phoenix is already in much better shape (smaller, faster, better: pick any three) than Classic.** then imagine what it's like now!
 CPython !== Cython Still it's mostly related to CPython being interpreted vs JIT compiled. 
Almost, yeah! But I think I might revise it when I am done.
Thank you very much for your answer! &gt; beautifulSource4 I could not find beautifulSource4. Could you point me to a link for it, please? :)
This is awesome! Thank you.
Oh, this looks very promising. I originally used Chosen because we use that in an unrelated project at work (only done in Java and JSF2... brr...). This looks like it could replace Chosen for me. Thank you very much :) EDIT: Unfortunately it is not compatible with IE7, and I am probably going to need that. On the other hand, perhaps I can squeeze this through. EDIT 2: It also for bootstrap 2, and I'm using bootstrap 3...
Here's a copy of [python 0.9.1](http://pastelink.me/dl/7d7a4c) which should build perfectly out of the box (it's a pre-autotools build, so maybe you'll run into something). Incidentally, I've never had a problem with building 1.0.1 either (I've also run into the thing with the getline function and you should definitely rename it rather than try to use the one from stdio... this function is python-specific). Tried it just now... ~/python-1.0.1$ ./python Python 1.0.1 (Mar 23 2014) Copyright 1991-1994 Stichting Mathematisch Centrum, Amsterdam zsh: segmentation fault (core dumped) ./python Hmm... ~/python-1.0.1$ strace ./python [...] fstat(3, {st_mode=S_IFREG|0644, st_size=5283, ...}) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f5b3e962000 read(3, "# encoding: utf8 \n# vim:set ft=p"..., 4096) = 4096 --- SIGSEGV {si_signo=SIGSEGV, si_code=SEGV_MAPERR, si_addr=0} --- +++ killed by SIGSEGV (core dumped) +++ zsh: segmentation fault (core dumped) strace ./python Wait, that looks like my `PYTHONSTARTUP` script in that `read` call. ~/python-1.0.1$ PYTHONSTARTUP= ./python Python 1.0.1 (Mar 23 2014) Copyright 1991-1994 Stichting Mathematisch Centrum, Amsterdam &gt;&gt;&gt; list("tada") Traceback (innermost last): File "&lt;stdin&gt;", line 1 NameError: list &gt;&gt;&gt; Anyway, you were so close. **edit:** I also want to mention that I think this is a great way to learn how python works. This is how I worked my way up to reading the fairly large codebase of modern python too. These old versions (minus working build scripts) are also available in the cpython mercurial repository, just fyi. You can run `hg checkout v1.0.1` if you're just interested in reading the source. Also, if you're working with 1.0.1, you should be able to get away with just running python from the build directory if you do something like `PYTHONSTARTUP= PYTHONPATH=$(pwd)/Lib ./python` 
If this was a one-off data dump, you're probably best off converting the xml directly into html without going through a relational database, since it's already in a similarly-structured markup anyways. If you're going to be doing this conversion repeatedly or want more flexible views, you should look into using a web framework like Flask or Django to set up the viewing portion since they're basically designed to interface between browsers and databases. It might be worth including an upload page that will parse uploaded xmls into the db so you don't have to do it yourself on the backend every time.
I was given an xml file and need to write two scripts: one to parse the data and put it into mySQL and another script to take that table and output it to HTML. I have already written the first. 
i would just use pandas. pandas.io.sql to get the data into a dataframe and then pandas.to_html to get the table html code
Any interest in using the [requests](http://docs.python-requests.org/en/latest/) library? It would help trim up that urllib code.
wow great effort put into this article.
Thanks, I'll check into this.
JRE's and PyPy both are JIT systems ( http://en.wikipedia.org/wiki/Just-in-time_compilation ) which seems counter intuitive ( you'd think doing all the work up front would == faster runtime execution ) that also include a lot of additional tricks made possible by postponing the compilation phase. From the linked wiki on JIT &gt;One possible optimization, used by Sun's HotSpot Java Virtual Machine, is to combine interpretation and JIT compilation. The application code is initially interpreted, but the JVM monitors which sequences of bytecode are frequently executed and translates them to machine code for direct execution on the hardware. And I prefer the second answer to this SO question "PyPy — How can it possibly beat CPython?" - http://stackoverflow.com/a/8797731/9908 
Just retrieve the information from the database and write the tabular data in an HTML table. Or just parse the XML file and write the information directly and skip the database entirely. If you need to do this often and have it viewable from a web browser you should look into using something like Flask and templates.
I'm going to assume you meant CPython, the reference implementation of Python. One of the goals of CPython is that the implementation remain *simple*. Go ahead and explore the source code. If you know C, you'll find it very approachable and it's not hard at all to learn how parts of it work. (other parts are a bit more complicated, sure; it's a big project after all. But in general the code isn't as bad as it could be by a long shot) This is intentional because people have to maintain it, and Python development is primarily a volunteer effort. Adding in more optimizations or adding a JIT compiler into it would raise the complexity significantly, which raises the barrier for new people to contribute and raises the amount of effort it takes volunteers to maintain it. That's one of the reasons why the [Unladen Swallow](https://code.google.com/p/unladen-swallow/) project wasn't merged into CPython and probably never will be. (The main reason, though, was probably that the project lost momentum because PyPy exists) So to answer your question directly, adding more optimizations or a JIT to the implementation is possible, but is probably never going to happen. Similarly, removing the [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) is probably never going to happen. Personally, I'm okay with it, since speed is not usually a requirement for Python programs. But when it is, there are options out there in the form of alternate implementations or C libraries (numpy).
Dang! PYTHONSTARTUP is exactly what my problem is. Thanks for the pointer. I was actually a day or two away from getting to some blog posts on strace in a blog in my feed reader. Thanks so much. This is super helpful. 
Thanks for the compilation!
I created a 'suite' of sorts using python when I was in desktop support. You enter the hostname of the target machine, or the userID of the target associate. If you enter a valid hostname, it displays IP address, last boot date, last image date, last blue screen date (if windows), hard drive space, total memory, etc. and then gives you the option to Remote connect, reboot, unmute/mute, computer management, psexec and other options. If you enter a valid userID, it gives you the ability to unlock/lock the account in AD, also it lists the groups the userID is apart of, what PCs the associate is currently logged into, and what PCs the associate has logged into in the past. 
How would you do window commands in python? 
No compilation needed, Python is a scripting language *wiggles thumbs*
 print (lambda A,D,B,C,E,F,G,H,Q:"\n".join(["".join([(Q[int( __import__("math").log((reduce(lambda x,y:abs(x[1])&lt;=D and (x[0]+1,x[1]**2+y[1]) or x,[(0,complex(r/B,i/B))]*A))[0]+1) )%len(Q)]) for i in range(F*B,G*B,H)]) for r in range(C*B, E*B,H)]))(1500,4,100.0,-2.25,1.5,-1.25,1.25,4,".^:/I&amp;@*%$#") Old code, goes back to Python 2.2 or 2.3; uses ASCII art. 
&gt; Seriously, what the hell is Johnny doing with 32 Apples and perhaps its a sign of mental illness that Sally ate like 10 of them in a row, never mind that there's 22 apples left. Lol! Very true. I agree with the immersion. That's how I learned Spanish. 
Yeah, they're both good. LYAH is a little more beginner-friendly and entertaining. I recommend it often!
I have a shorter (and more evil, and *much* slower but also IMO prettier) prime sifter that I banged out for a learnpython thread a few weeks ago - didn't occur to me to submit it the first time around: import itertools def primes(): stream = itertools.count(2) while True: result = next(stream) yield result stream = filter(result.__rmod__, stream) # test list(itertools.islice(primes(), 0, 100)) # on my machine it takes about 11.5 seconds for 10,000 primes. Definitely not ideal. The idea is that by using the low-level iterator interface with a while loop, you can replace the thing being iterated over. I do so in order to wrap the original `itertools.count` object (a stream of integers) in `filter` iterators, each implementing one "sieve" in the algorithm.
I didn't know it was a contest! Otherwise, I would have submitted a one-line fizzbuzz solver: print [(num, ["", "fizz"][num % 3 == 0] + ["", "buzz"][num % 5 == 0]) for num in range(1,16)]
 &gt;Version guarantees are what make using libraries feasible. See, for instance, https://docs.djangoproject.com/en/1.3/internals/release-process/#internal-release-deprecation-policy and http://semver.org/ . Which supports my post, you have no certainty that any feature will be around forever. Django does have a strict policy but that policy permits a feature going missing in a minor release. It is and always has been up to the user to adapt to the changing software landscape. What people need to realize this that this is a major release for Python, which by the way isn't a library. The developers didn't stop maintaining the old release because they realized that this was a major update to Python. For the life of me I really don't know what the problem is with some of you people out there, Python 3 is a major improvement to Python and sets up the language for probably another decade of improvements. The transition has been long but nobody expected instant adaptation to the new version. In the end I still liken this to the use of modern C++. If you write modern idiomatic C++ drawing on the lathes test standardized features your software will not build on older compilers nor should it. You can't implement new ideas or concepts in a language without the use of those features tying the source code to the new compilers. In the same vain you can't write python3 code, using the latest features and expect old versions of Python to process the code. In both cases we are talking about dramatic improvements to the languages that have evolved and firmed up over years. It isn't like Somebody rolled out of bed one morning and said hey let's release a New version of Python, let's call it Python 3, and surprise everybody. Anybody with a clue in the development community should have realized what was up and why 7 years ago. If not they really shouldn't be whining now!!! 
Ah, I've seen some implementations to use reduce, and in retrospect that may have been a better idea. The inline import is pretty dang impressive too! I was striving for a few things in my implementation: * True iteration values stored in a data structure (rather than just ASCII output) * No imports. I've only just glanced over this, but you can't do floating point ranges anymore, so that "range(F*B..." where F=-1.25 wouldn't work. My implementation is meant for python 2.7. But, sweet!
*wiggles thumbs*? What gesture is that meant to be?
I reserve it for only the most cheesy puns.
Yeah I've been learning unity for the Past few days and I'm starting to think that's the way to go? Do you know of any good resources for C#?
Damn, that is clever. Took me a second to figure out what it was doing. Really nice! 
Thanks for this
That's some out of the box thinking there, nice. Also, as a comment to OP, writing prime sieves is a pretty common task, especially in the world of (e.g.) Project Euler and related things. Pirsqed was merely the first to post his implementation (see the resulting comment threads for various others from more people).
http://www.reddit.com/r/Python/comments/20x61y/share_the_code_youre_most_proud_of/cg7odo4
 **Abed**: *[Pointing at map]* Here. Right next to the truck stop with three thumbs. **Dean Pelton**: *(to himself, ashamed)* ... those aren't thumbs.
Yeah, it's something I wrote up years ago. The timestamp on the file goes back to 2009 but I'm pretty sure it's even older than that - maybe even as far back as 2003.
The second fastest sieve of know of is [this](http://sourceforge.net/p/yafu/code/HEAD/tree/trunk/top/eratosthenes/soe.c#l141) [one](https://sites.google.com/site/bbuhrow/home): &gt;As of version 1.32, YAFU also has one of the fastest sieve of Eratosthenes implementations I am aware of for modern 64 bit processors. Kim Walisch's primesieve is faster in most cases, but YAFU is its closest competitor. Dan Bernstein's Primegen is also a fast prime sieve with asymptotic complexity lower than the sieve of Eratosthenes (via the sieve of Atkin), but slower in practice.
This code is really impressive, I freaking love it (L). Thank you so much.
I'm in! He seems like a sharp guy. Can't wait to see the videos.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Wheel factorization**](http://en.wikipedia.org/wiki/Wheel%20factorization): [](#sfw) --- &gt; &gt;__Wheel factorization__ is a graphical method for manually performing a preliminary to the [Sieve of Eratosthenes](http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) that separates [prime numbers](http://en.wikipedia.org/wiki/Prime_number) from [composites](http://en.wikipedia.org/wiki/Composite_number). Start by writing the natural numbers around circles as shown below. Prime numbers in the innermost circle have their multiples in similar positions as themselves in the other circles, forming spokes of primes and their multiples. Multiples of the prime numbers in the innermost circle form spokes of composite numbers in the outer circles. &gt;==== &gt;[**Image from article**](http://i.imgur.com/XI5bfFT.png) [^(i)](http://commons.wikimedia.org/wiki/File:Wheel_factorization-n%3D30.svg) --- ^Interesting: [^Sieve ^of ^Eratosthenes](http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) ^| [^Sieve ^of ^Atkin](http://en.wikipedia.org/wiki/Sieve_of_Atkin) ^| [^Integer ^factorization](http://en.wikipedia.org/wiki/Integer_factorization) ^| [^Lyndon ^word](http://en.wikipedia.org/wiki/Lyndon_word) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cgaaj9y) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cgaaj9y)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Hmm... the performance differences are striking, because in all cases the operators used are identical, yet the performance is so different... Edit: New challenge. Can we write an n=6 wheel sieve in Python 3 that is faster than rwh2?
last footnote: &gt; And for readability, I probably don’t want a function with state, I want a class that implements __call__ or a generator. Those are ways to telegraphing “State! State! I have icky, grubby, bug-hiding state associated with me!” ↩ and what is the difference really? functions are objects, classes are objects and class instances are object. I find the function with state to be elegant and concise. A class would be more verbose, more baggage, harder to read.
Even though a function could have state, the difference is that by default I expect it not to. By following that convention, it's easier to understand code without reading it closely, or even without understanding that functions are objects. I'm really excited about first class functions, but meant this post to be about communicating ideas with Python code to programmers of all sorts.
I've actually looked at it but due to the specifics I don't think any optimisation would pass over, so there would be no meaningful difference between the programs. --- I did, however, just write a Cython version, where generating the list at the end takes the vast majority of the time: cimport cython from cpython cimport array from cpython cimport Py_INCREF, Py_DECREF from cpython cimport PyList_New, PyList_SET_ITEM, PyInt_FromSsize_t from cpython.object cimport Py_SIZE from libc.string cimport memset cdef array.array sieve_proto = array.array('b') cdef array.array primes_proto = array.array('L') cdef inline void set_all(array.array self): """ set all elements of array to True. """ memset(self.data.as_chars, True, Py_SIZE(self) * self.ob_descr.itemsize) @cython.boundscheck(False) cpdef list cprimes(unsigned long maximum=10**6): cdef: Py_ssize_t maxidx = maximum//2 Py_ssize_t i, ixi, j, number_prime char[::1] sieve list primes sieve = array.clone(sieve_proto, maxidx, False) set_all(sieve.base) with nogil: ixi = 0 for i in range(1, &lt;int&gt;(maxidx**0.5)+1): ixi += 4*i if sieve[i]: for j from ixi &lt;= j &lt; sieve.shape[0] by 2*i + 1: sieve[j] = False primes = [i*2+1 for i in range(maxidx) if sieve[i]] primes[0] = 2 return primes 
I have a few fun 1 line fizzbuzzes: python 2: you can make use of integer division, bitshifts, and shenanigans for i in range(100):print i%3/2*"Fizz"+i%5/4*"Buzz"or-~i python 3: for i in range(100):print(i%3//2*"Fizz"+i%5//4*"Buzz"or-~i) for i in range(1,101):print("FizzBuzz"[4-(i%3==0)*4:8-(i%5&gt;0)*4] or i) these were originally for hackerrank codegolf, I'm currently tied for first with a few hundred others for fizzbuzz in python. And in python 2, you can pull this bit of beauty off: i=1;exec"print'FizzBuzz'[i%-3&amp;4:12&amp;8-i%5]or i;i+=1;"*100 although I take no credit for it. 
I'm really digging Kickstarter for Open Source projects. I've contributed to a number of them for developing new features, and a few more for creating great documentation such as this one. I don't really have the time, or honestly, the skill required to contribute code. But $20-$50 every few months? No problem. It's money well spent and goes to enhancing the community.
Hmm, sorry I learnt it a million years ago. All I can recommend is that you try to make something really small to start. Like make a pong game or flappy bird or similar just to get your feet wet then go from there. It always seems overwhelming at the start. The only solution is to keep building things until you work stuff out (like how the language itself works, how to best structure your code, how to develop and manage an asset pipeline, etc). Keep at it though, man! :)
Idly, cython can be orders of magnitude more performant than cpython just by compiling the raw and unchanged python code in some cases. It's specifically worth noting that CPython doesn't inline repeated function calls; so: def foo(): ... def bar(): for i in range(1000): foo() Is *significantly* slower on cpython than it is in cython, or pypi (for the same reason). Although, not as dramatically different to: def bar(): for i in range(1000): ... # Manually inline the code here
Integer division! Super clever.
Here's a ~50% reduction. While it doesn't use list indexing at boolean values, it does exploit text multiplication. print [(x,("fizz"*(1-x%3))+("buzz"*(1-x%5))) for x in range(1,16)] EDIT: Just realized this does not support negative values! That's an important consideration. EDIT2: Actually, I was wrong. The implementation of mod in python supports negative numbers in the way I wanted. Even so, I wrote an alternative implementation which limits the range of the mod output. print[(x, "fizz"*(1-bool(x%3)) +"bang"*(1-bool(x%5)) ) for x in range(1, 16)]
I'd considered multiplication, but I didn't think to try multiplying by a negative number. Nice one!
I hope you never make tests for Codility. That would probably ruin my day.
The thing is, if you learn python and suddenly you find everyone around you is using ruby or perl or something, it won't be that hard to just pick another language up. The most important thing to learn in your first language is the basics of programming (which are shared across almost every language) and why/what you want to program (which will lead you into what other languages you want to learn) To be honest you probably won't get far enough in your first language to where the differences really become /that/ apparent.
[here's a tutorial](http://palewi.re/posts/2008/04/26/python-recipe-connect-to-mysql-database-execute-a-query-print-the-results/)
 #!/bin/sh set -e mkdir python-0.9.1 cd python-0.9.1 for i in 0.10 4.47 0.11 4.31 4.32 4.33 4.34 4.35 4.36 4.37 4.38 4.39 4.40 4.41 4.42 4.43 4.44 4.48 4.45 4.49 4.46 ; do wget http://ftp.fi.netbsd.org/pub/archive/alt.sources/volume91/Feb/91022$i.gz -O - | gunzip | awk '/: This is a shell archive/,EOF' | sh done cd .. find python-0.9.1 | xargs touch --date="19 Feb 91 17:35:26 GMT" # Usenet post time tar --owner=0 --group=0 -zcf python-0.9.1.tar.gz python-0.9.1/ 
I think this is well dead, but I'll clarify once again I do not want to write Qt! I want to move on to some other framework, most likely in JS. I was just wondering what segues nicely, as opposed to being a complete game-changer.
If you wanna be even faster, you only need to check until len(s)/2
Fair point, thanks
Just a note that your parameter name is iterable implying it can work for any iterable, but reversed only works for things with _reversed_ or things with both _len_ and _getitem_. This makes sense because you can't do this in constant memory for e.g. generators, similarly to how you can't do it with a DFA :)
Got it. As someone who is new to all of this, prime sieves like this are really elegant, and the particular one I mentioned was the fastest, as I recall.
I LOVE FAKE INTERNET POINTS
Brill. Excellent.
 def foo(x=tuple([])): Why does this help? First, it's the same as `def foo(x=()):`, second, the whole point was mutable default arguments, so you'd still have to do `x = list(x)` before you use `x`, right? BTW, thanks for Ned Batchelder’s terrific post on names in Python, I hadn't seen that yet. I've written a [similar article](https://dl.dropboxusercontent.com/u/2000007/namesvalues/namesvalues.html), it seems at around the same time! Ned's article is better, though.
Some Python web framework, like Django + REST API like django-rest-framework + ember.js for the frontend. ember may not be easy or obvious but for Qt/PyQt4 working with event/property driven applications and promises should be more natural.
Concerning your "Invalid Parameter - 4" error in MoviePy. It's a common error on Windows apparently. The reason is that the binary of ImageMagick is called 'convert', but windows also ships with a binary of its own called 'convert'. The fix: download the source code, for instance on github https://github.com/Zulko/moviepy Find the file moviepy/conf.py and in this file change the path to ImageMagick to something that will be like "C:\Program Files\ImageMagick-6.8.8-Q16\convert" Then install with "python setup.py install". Tell me if you have other difficulties. 
YAFU is public domain (as can be found at the top of any source file, and I believe in the various doc files as well).
Now I got it. Thanks. One little thing I was experimenting on it and it turn out that I also must use "l" instead of "-l" when index is negative. like this In [6]: st[:l] == st[:l:-1] Out[6]: True 
Pitsqed's sieve can be reduced to 8 lines: def sievePrimes(maximum): primes, sieveList = dict.fromkeys(range(3,maximum+1,2),True), [2] for num in sorted(primes): if primes[num]: sieveList.append(num) for j in range(num**2, maximum, num): primes[j] = False return(sieveList) (or 9 if you don't like the second line) 
well I'd hate to do *your* laundry in 1994. look at this madness... Python 1.0.1 (Mar 23 2014) Copyright 1991-1994 Stichting Mathematisch Centrum, Amsterdam &gt;&gt;&gt; def x(y): ... y ... &gt;&gt;&gt; x(123) 123 &gt;&gt;&gt; 
Dark times indeed.
I skip introductory part of Python, and directly develop Flask application using Heroku quick start. At the same time, I learnt Python. Point is, just go with your new Django course. It'll be fun!
Because sometimes when I have a list as a default values, I _don't_ want a mutable default argument, I just want an iterable. I was thinking of the general case (whatever the list is, wrap it with a tuple) so didn't put the tuple literal `()`. I'll fix this, I think you're right that it's unclear on both counts.
Can you feed this back to the developers?
Ah, okay, that makes more sense.
HTMLgen has been dead for 15 years. No one will fix it. No one will read it. It's amazing you can still get it somewhere. Also a lone `&lt;p&gt;` is not plain wrong, it's a very 90s way of generating a one-line-high margin. The development of HTMLgen stopped **before IE6** and quite possibly **before IE5**. The only browsers that existed were IE4 and Netscape4. Opera 2/3 if you're adventurous. &amp;nbsp; You may have your hands on one of the last remaining python 1.5 relics, don't lose it.
Where is the analysis part? I must have missed it.
In my experience as someone who has used Perl, Ruby and Python, the communities differ in the following way (please note with a bit of tongue-in-cheek and sweeping generalisations): The Perl community is largely the unix community with fun and joking, often at your expense. Also used by security professionals and anarchists. Slogan: TIMTOWTDI (Tim-Toady) - There is more than one way to do it. The Ruby community makes a point of being nice, even at the cost of being nice. Also a lot of with agilistas and new-work-ethic proponents. Slogan (unofficial): Designed for programmer productivity and fun The Python community is comp-sci oriented, take the language seriously and are a little strict about following the rules of coding in Python and doing things the right way. Slogan: There should be one-- and preferably only one --obvious way to do it. (there's more: look for The Zen of Python) Not sure whether it is just the language or the community too, but I'll probably never go back to using Perl and Ruby. In the end they are all great languages, each community with it's own idiosyncrasies that you only learn about when spending significant time coding in each. HTH
Python has the broadest scope of any language in its space. I began using it for scripting dynamic geometries in Rhino via a [python Grasshopper component](http://www.grasshopper3d.com/group/rhinopython). With a background in web development I researched Python use for web...and low and behold found Django, Flask, Pyramid, etc. I know of no use of Ruby or Perl in the same context. I have found that there is really no area that Python can not be used...which makes it a great language for someone who worked in a lot of different foci in regards to what they are using programming to solve. Additionally it leads to a much greater imaginative scope of what can be done due to the very large range of libraries. MIT has some nice resources for learning the language from rudimentary to advanced uses. http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/
This is a reasonably simple solution (but even this solution can be improved and simplified). Suggestions to use additional libraries or frameworks are not necessary unless you need them as part of a larger solution.
Well done, I didn't think of looking in the source files. Thanks :)
A better solution would be to use [Dominate](https://pypi.python.org/pypi/dominate) for generating HTML.
 for i in range(1,11): print(i) print(i) # 10 Whoa. I had no idea. This was the entry in the list that's most relevant to me. And doing most of my coding in Java it was quite surprising.
How much slower is that with generator expressions? 
Looking for parts 1-12 yielded a list of parts 3-12 with tags. I eventually found part 1 and 2, but heads up (since I think this is OP's blog from comment history). That said, the first few parts of this series are perfect for a friend of mine who's just picking up web development. Thanks for the post!
[I actually compared them](http://www.reddit.com/r/Python/comments/20x61y/share_the_code_youre_most_proud_of/cg8by2a?context=3) ;) 
Here's a few thoughts: * Consider the use of Kafka - a distributed messaging system. It can easily scale horizontally to handle your volume, and it allows your database to be offline for upgrades, crashes, etc, and can just continue to collect data until you consume it and push it into the database. It's not difficult to use. It can help with data reliability in a real-time scenario. * An alternative to using kafka is to continue to use batch files. They can dramatically simplify the architecture in some ways. Like...your recovery plan could be to reload these batch files, and if something crashes you've still got the batch file to analyze and retry without worrying that you're losing data while down. If you don't need to be real-time this is almost always the best way to go. * There's 86400 seconds per day, so you're looking at 5m rows / month, maybe per sensor. If you want 12 months and have 100 sensors that's 6 billion rows. And MySQL performs very poorly for complex queries. Postgresql will be faster for complex queries. And you'll want range partitioning, and aggregate tables (aka summary tables or materialized views). But still - 6B is a lot. * Back to aggregation tables - with sensor data this typically works very well. Imagine hourly &amp; daily aggregations of a variety of your dimensions plus counts. Then do your graphing on this rather than the raw data. You can shrink your data volumes enormously this way. 
It's actually not bad [compared](http://www.reddit.com/r/Python/comments/20x61y/share_the_code_youre_most_proud_of/cg8by2a) to the ones posted. `166ms` for your algorithm.
 def minval(alist): return min(alist) Why?
I don't think it can be done with a generator expression, because the 'generator' needs to be modified iteratively. I couldn't use a `for` loop for the same reason.
A slightly nicer way of writing it might be: is_palindrome = lambda s: all(a==b for a,b in zip(s, reversed(s))) (Or use itertools.izip if in python2)
I was thinking of having it so older data gets consolidated and averaged. So after a month, the previous month's data would be condensed into six-hour averages or something. Previous years would be condensed to days, perhaps. Just now downloading PostgreSQL and gonna start learning how to use it. It seems a lot better than MySQL from reading on their website.
Jesus, this is terrible. &gt;&gt;&gt; remove_evens([2, 2, 1]) [2, 1] And the function both mutates the parameter and returns it, which is a no-no in the Python world; do one or the other, not both. Why are they reinventing already existing things like `max()`, `zip()`, and `map()`? This is just hideous. 
I'm wondering if this hasn't changed since Python 3. Might want to double check.
 def foo(x=None): if x is None: x = [] ... I write this: def foo(x=None): x = x or [] Usually does the trick nicely enough. Though obviously if you did: a = [] foo(x=a) expecting for instance that the list is modified by the function. It wouldn't work as expected since `x = x or []` would assign the second list, not the one provided to the function.
Yes, yes it is. Most of the functions are at least one of: * reimplementations of builtins * horribly algorithmically inefficient * just plain wrong * pointless * reinventing the wheel. The last one has its uses when learning programming or a specific language, but that's generally something you do for yourself, not something you'd wanna share with the world.
Perl is the old school scripting language. Those who remember the mid-90s remember Perl as the language of the web (with CGI/1.0). It was the scripting language of all the unix grey beards (grudgingly or otherwise) and it was heavily influenced by sh, grep, sed and awk. Perl tended to be used to glue things together. Python is pretty much the logical successor of perl in the unix world. It has as much power, better syntax and a broader scope. Python is much more likely to be embedded in something else and the language is much more consistent and coherent then perl. It's very readable but strict about code formatting (perl in contrast has few syntax rules.) The scientific community has chosen Python as winner (SciPy, Numpy and a billion other frameworks/tools). Of the 3, it has the best windows support as well which helps market penetration a lot. Ruby is somewhere in between the two. Ruby's main advantage is the flexibility of the interpreter and the ease with which you can create a new specialized "language" while remaining within the ruby rules. Ruby on Rails totally dominated the ruby world for a long time and even now, select stacks/apps dominate that universe. That's what I think anyway.
Is there Web interface Flask or something now? Edit: Looked at the source...Django.
They use [Dojo](http://dojotoolkit.org/) and [Django](https://www.djangoproject.com/). Heck, they even use [Dojango](https://github.com/klipstein/dojango/) :-).
Well, then it didn't change. I thought it had.
the problem you describe is solved by stream processing. in theory you can do this in python. http://highlyscalable.wordpress.com/2013/08/20/in-stream-big-data-processing/
Ruby itself isn't in Japanese (it uses English words like `print`, `class` and `each` as is standard) but the developer only speaks Japanese, wrote the spec and documentation in Japanese, started a Japanese mailing list for it, etc. It took ~10 years for an English-language book on it to be published, which is when it started to gain use outside Japan.
I'm new to Python, so maybe this question is a little dumb. But what's the benefit of using a lambda expression in this context? Wouldn't: def is_palindrome (s) : return s == s[::-1] work as well? Is it just a matter of style or is there some performance benefit? 
I don't get it, what happens here? Is "y" the return value? If yes, what's the problem with this approach? Other scripting languages implicitly return the last variable in a function as well. 
Actually, the behavior seems to be that bare expressions are printed (in scripts too, not just the REPL). Python 1.0.1 (Mar 23 2014) Copyright 1991-1994 Stichting Mathematisch Centrum, Amsterdam &gt;&gt;&gt; def f(x): ... x ... &gt;&gt;&gt; z = f(10) 10 &gt;&gt;&gt; z &gt;&gt;&gt; Implicit return would have been useful, but something something zen.
No problem. Never do validation in the UI that you also don't enforce in the backend.
 def map(f,alist): res = [] for x in alist: res.append(eval(str(f(x)))) return res This evals for no particularly strong reason. It also breaks on things where the string representation isn't equivalent to Python syntax (e.g. a str): &gt;&gt;&gt; map(lambda x: x, "Hello World") Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 4, in map File "&lt;string&gt;", line 1, in &lt;module&gt; NameError: name 'H' is not defined 
thanks, great info!!
why?
Since it's difficult to tune reporting performance with indexes, we usually tackle that with partitioning, parallelism, and aggregation. More about partitioning: * Use range partitioning to split your table into monthly or daily partitions. This way any queries selecting only a subset of the rows (like last 60 days) will only scan that much data. It also means you can roll data that falls out of the retention window by simply dropping a partition, rather than deleting millions of rows. * Monthly is simplest, but doesn't gain you as much performance benefit if you're often selecting just a few days of data. * Daily is pushing the number of partitions, but works well. And you can roll days up into weeks, months, quarters, and years. * However, you need to create the partitions in advance. That means a separate job that should be scheduled. The partitioning statement isn't too complicated - just need to monitor if it fails or if you're running out of partitions. And more about summary tables: * I find that these days people seldom want to wait until the end of the month to see how a process is working. So, I normally suggest creating your daily aggregate after you've collected all the data for the prior day. * Then you can easily show a rolling last-30 days, month-to-date, or reporting for any full month directly off the daily table. * And you can also roll the daily summaries up to the full month as well at the end of the month. Or with more work you can roll the dailies up to the month at the end of every day, with the most recent month just showing month-to-date.
Ok, that's indeed quite strange ...
Or [webelements](http://www.webelements.in/Home)
Any plans to support Hack as well?
I've got little experience in this kind of thing but I assume you could use Digital Ocean for this kind of thing or maybe invest in a Raspberry Pi
bencoding? funny, i have a lib for that: http://flying-sheep.github.io/bcode/
I don't know. Let's see where hack ends up in a bit of time.
You mean like `wtforms-alchemy`? This already exists. This couples a SQLAlchemy model to a form object. If you want something that generates the actual boiler plate in Jinja just make your own macro - it'll take you all of 15 minutes - or google for one. The only thing to remember when using `flask-wtf` and `wtforms-alchemy` is to initialize the Form object using the special factory in wtforms-alchemy: from flask_wtf import Form from wtforms_alchemy import model_form_factory ModelForm = model_form_factory(Form) ... or you won't get Flask-WTF's "validate_on_submit()" etc. 
Assuming the ecosystem is (mostly) MS/Windows , you should dive into Powershell.
We're gonna need some more information about your requirements. You've said you want to build a "directory" that needs to parse vcard data out of SMS. How are the SMS getting sent? What is receiving the SMS? It's not clear what you mean by "directory". There are a lot of SMS services out there, but I'm not sure what sort of features you need.
I plan on doing that too but they still want people with some programming knowledge
Sure! Thanks for all your hard work guys! &lt;3
Not sure what you mean by "treat it as an equation" but if you are looking for something simple, eval() might be enough? http://stackoverflow.com/questions/9383740/what-does-pythons-eval-do 
Not sure if impressive or [lolphp](/r/lolphp)
In the end, I want to be able to send a VCard, via SMS, to a phone that requests it. I would store a VCard entry for every employee at the company I work for, (less than 100 people) and if someone wants the contact info on another, all they would need to do is text the number associated with the program, and it would spit the VCard back at them. Making the program take an input, and spitting out the right result is the easy part. Working with API's is the part that doesn't make sense to me yet.
http://docs.python.org/2.7/library/functions.html#input
Please ask code questions in /r/learnpython 
I was hoping that this was an easy way to interpret PHP from Python.
Both.
So the PHP interpreter written in Python is faster than stock PHP written in C? That's...something. Tell me, does it support all of PHP's "features" as well?
can you use something (python/SQL) to aggregate the data, before storage?
Yeah, I'm just so afraid of the case of falsy values that I don't want to get in the habit.
No
By no means is this meant to be advanced, its a small script inside of a larger program; see the http://qtbot.net/ project here. All Haikus are sent too https://twitter.com/RealShitHaikus If you want to make this script better just submit a pull https://github.com/Codeusa/QTHaikus
Sorry I guess I wasn't very clear, I was in a hurry earlier. Let's say I want to create a randomized population of objects with each object containing variables that are populated with data that depends on a particular equation. So let's say for A, B, C objects, they have a variable within them, X, which is defined by some value k which is then manipulated by the equation to be input by the user. Also, I intend on having different "types" of objects. So let's say for objects A and B, they are of type "1", and for this type, the user inputs the equation, X=k^2. For object C, it is type "2", and the user inputs X=(k*3)-(k-1). (Sorry for my lack of python-centered vocabulary and lack of syntactical knowledge/methods, I am noob to it as mentioned before and going to use this to develop my skillset with it). So, I have something like A.k = 2, B.k = 3, C.k = 4 (just some random values of k per object) And this would evaluate to A.getX() = 4, B.getX() = 9, C.getX() = 7 Which took the equation for each type of object and calculated its value based off of the equation given for its type and the value of the integer k for the object in question. I'll then do more from there, but that all will be the easy part. The hard part is trying to figure out how to evaluate a string to make sure it can be used mathematically based off of a variable within it, and then implementing it. That's where I don't know what to do and am sort of just looking for pointers in the right direction, I guess.
It looks like this is more recently maintained than hurry.filesize, but python3 only: https://pypi.python.org/pypi/hfilesize/0.1.0 / https://github.com/simonzack/hfilesize .
What you're looking for is an API that can send binary messages (**edit** and supports two-way messaging). There are a lot of those. Clickatell comes up first in a quick Google search, and it looks like they have all the features you need, but I've never used them and can't personally vouch for them. Another option is to tether an old android phone to the server and send messages through that. A couple Google searches will show you that others are doing the same, and there is some software out there that might make this easier for you.
Yeah this was my justification when I posted it. Guess I should have clarified.
Wow, thanks so much /u/thepeculiarform - this is the kind of answer I was hoping to squuuueeeeeze out of ya'll :) I really like to know the breadth of a thing.
Thanks for that insight, /u/Octopuscabbage. I"ll make note of that in my logs :)
Thanks for the input~!
Not sure what you mean. Storing as text files is really the only way to go from the big picture, production standpoint.
Thank you for the link.
I really love that solution, but I can't see the end... I've had to do it with a list comprehension, don't know if it's slower or fastest, but I love to see it like that.. return [x for x in range(2,len(isPrime)) if isPrime[x]] 
As someone who writes PHP for a living, this does not surprise me. It's like the original founders attribute their success to diploma mills.
I don't know what "features" really means but it claims 100% compatibility syntactically I think.
[i'll just leave this here](http://doge2048.com/)
it's written in RPython, which is what PyPy is written in as well.
Best argument you guys can make is "Better than HHVM". Seriously, I am beyond amazed with PyPy's flexibility and efficiency.
&gt; If your solution is CPU bound, DO NOT switch to anything that does not start up other Python processes. That's not quite true. It's impossible to execute more than one piece of Python code at a time (if you use CPython, the most common runtime), but if most of the work is happening in functions that are written in C, those functions can execute simultaneously.
Very good points.
Get a Linux VPS.
You neglected to mention that you have to release the global interpreter lock. Explicitly. That is why I did not go into using C code for concurrency – if someone writes their code in Python, it most likely is not stuck in calling C, and if it is, they need to add a few lines to fix that. Furthermore, if you're going to open up the "What if you're in C" genie bottle, I am going to ask, "Why are you even bringing that up?" This is about Python code, not things you can do in NotPython code. Starting up a bunch of pthreads in C is most likely *not* what the OP had in mind.
Awesome, thanks! :)
This is awesome and horrible and I really like it.
&gt;It notably won't do so if they have user-defined `__del__` methods, as it doesn't know what order is safe to execute those methods in. This is [not true in 3.4+](http://legacy.python.org/dev/peps/pep-0442/).
My apologies I didn't know that subreddit existed I will post my questions there now
new to python, can someone explain to me (ELI5) why the method is called __del__ and not just 'del' ? Im still trying to wrap my head around methods and classes.
Specialness should look special. It's not just del of course, it's init, int, str, unicode, add, subtract, etc, etc. It also enables you to make a method on your class called "init". If python didn't have the surrounding double underscore that name would be taken.
To explain a bit more (by linking to some docs), lots of the things we take for granted in making python look "nicer" are actually ["magic methods"](http://docs.python.org/3.4/reference/datamodel.html#special-method-names) (eg `__init__` or double-undersore init, sometimes spoken as "dunder(sp?) init") for example, have a custom class and you want your objects to support a custom `thingy in foo`? thats `__contains__(self,item)` for you. (here, item would == thingy) The docs are a bit to get your head around in the beginning but once you do they tend to have the answer to every question of "why is it like this?" ^(The more you know!~~~)
Why make one of the core technologies of the internet faster? Or what is the question?
All of the things that keep /r/lolphp so busy (e.g. `$a = "1d9"; $a++; $a++;`).
In many object-oriented languages, there is some way to implement particular "special" behaviors which need to affect the way the language itself handles your code. A common example is writing a class whose instances are iterable; there are a lot of uses for this. In, say, Java, you would write a class that implements the `Iterable` interface, and Java notices the `implements Iterable` in the class, checks that it does in fact implement the required methods, and then lets you iterate over it. In Python, you just implement a method named `__iter__` (you can also implement some other methods to allow additional sequence-like behavior, but you don't have to). And this points to the general convention in Python: when something triggers special behavior, typically at the level of the language itself, it gets a name which begins and ends with double underscores. There are [quite a few of these](http://docs.python.org/2/reference/datamodel.html).
* Syntax Errors segfault instead of raising exceptions * Bare expressions get printed. * No list comprehensions * No `True` or `False`. * standard library is small and more hackish. Naming conventions are weak; e.g., a module called imghdr can identify the type of image file by the first few bytes of the file. The main exports of this module are `imghdr.what`, `imghdr.test`, and imghdr.testall`.
one is a warning message and the other is a debugging message. as for what to put in which, that's up to the user to decide.
Hmm..... this sounds very promising. Thanks for the lead.
It's not a PHP interpreter written in Python as you'd probably understand it. It's written in a subset of Python called RPython, which is then heavily optimised and compiled to native code. It's basically "Python-flavoured C". PyPy is also written in RPython, and is faster than stock CPython written in C.
I was honestly pretty surprised they used django. I'm primarily a django developer, and even I feel like something more low level would have worked better (I use freenass a lot too).
Hi nomadismydj. When we started to develop telegraphy we realized we needed to use some sort of event subscription. Socket.IO seem to be the obvious solution to this task, but Python implementation of the standard were behind the 0.9 spec. That was when we stumbled upon WAMP (wamp.ws), a RFC6455 registered protocol (https://www.iana.org/assignments/websocket/websocket.xml) that provides PubSub and RPC over websocekts. It seemed attractive since it provides authentication which we're integrating with Djang's auth module. Thanks for the feedback!
 def countdown_from_infinity(i = 0): try: countdown_from_infinity(i+1) except RuntimeError as r: print(i) if i &gt; 0: raise r
ahh thanks. 
pje, you're right we planned a WSGI level architecture that ended up being too Django specific. We'll remove it from the docs.
You answered it thanks.
To load the images, I would create an array called faces, then append each image to it in a for loop. You can use the str() function to convert numbers to strings. Something like this: faces = [] for I in range(1,10): #range goes up to! but does not include 10 in this case filename = "face" + str(i) + ".png" faces.append(pg.image.load(filename)) Then you could simply pick three random numbers from 0-8 and display faces[randomnum]. Hopefully that helps.
Also what is going on in your generator? faces = [pg.image.load("face{}.png".format(i)) for i in range(1,10)]
A list is an array. faces = [] initializes faces as a list.
All the same, `__del__` is still a finalizer and you still shouldn't rely on it.
your title is shit. you're not going to get much help with click-bait type titles. import random faces = [] for i in range(1, 10): faces.append(pg.image.load("face" + str(i) + ".png")) threefaces = [] while True: X = random.randint(9) if X not in threefaces: threefaces.append(X) if len(threefaces)&gt;2: break for thing in range(threefaces): offset = 174+(thing*100) screen.blit(faces[thing], (offset, 300))
any examples?
The first thought is "OMG matplotlib is ugly".
I was thinking the exact same thing. If you want to use Node.js for it's socket.io capabilities, why don't you just build the whole application in Node.js?
Because node.js was so much hyped for their event driven approach, some people think it's the only framework that fits this use case.
awesome
I'm the author of the blog post and the answer to why we chose node.js is because of the following reasons: - There was already somebody using it in such manner (there's a cite to the article on the post). - There's evidence that node.js performs well under load. - There's a lot of hype around node.js. Although people consider hype to be a bad thing, it is in fact quite good, because it means that the community is large and the chances of the project being abandoned is minimal. - Socket.io provides a good WebSocket abstraction and can fallback to other means of real-time communications. (We had to support IE8). We didn't have much time to spend trying other event-based frameworks, so we had to go with the safest bet. That being said, I'm tempted to write the a similar blog post using Tornado.
I'd highly recommend starting out with [Learn Python the Hard Way](http://learnpythonthehardway.org/book/) (LPTHW). LPTHW will help her understand the basics of Python programming and start her off with the correct mindset for programming. LPTHW will help her understand how to approach code analytically and break down problems into manageable subproblems. LPTHW should only take you 2-5 at most in my experience. After she has completed that, I'd highly suggest the [Bioinformatics course](https://www.coursera.org/course/bioinformatics) on Coursera. If she is really dedicated she can probably finish at least the Part I course before her 5 weeks are up. The Rosalind resource that /u/Zhyl referenced is also very good (it's actually referenced by the Coursera course).
&gt; At least a debate is possible. At least Django is modular enough that, if you want, you can rip out big chunks and completely replace them with something else. I'm pretty sure that this isn't an example of that, though I could be misunderstand how this works. 
Alternatively, you could do something similar to this using python 3.4's asyncio library, allowing you to write purely python. Some great async libraries are beginning to emerge, the node.js portion of this example could be replaced with this [async websockets library](https://github.com/aaugustin/websockets), and this [async redis library](https://github.com/jonathanslenders/asyncio-redis). 
I agree. I should have written that the node.js community is quite large and that the packages used in the examples are mature.
Instead if node, check out gevent which has a socket.io implementation. No more callbacks, and you can integrate w/ Django directly if you choose. 
I have re-structured the template according to your suggestion, adjusted the article correspondingly, and created a git repo with the template: https://github.com/jgehrcke/python-cmdline-bootstrap
What are you talking about? The title is fine, and completely relevant to his post. What isn't helping is you being a jerk right out the gate. You also just "did his homework for him" without explaining what you did. It might be fine to be a dick (somehow this is just accepted practice in the programming world, no idea why) as long as you actually help answer the question meaningfully.
[**+Ólafur Arason**](https://plus.google.com/113901280667512186151) [_2014-03-25T01:57:20.327Z_](https://plus.google.com/113901280667512186151/posts/fCmaosPgmwN) &gt; &gt;**If You Are Designing Your Own REST backend You're Doing It Wrong** &gt; &gt;The only reason why I know this is because I've been guilty of that my self. This is meant to start a dialogue so please comment. &gt; &gt;Let me walk though first what you are probably doing. You pick your favourite programming language and framework and get going. Whether that's node.js and restify, python and django or ruby and rails. &gt; &gt;Then you are going to pick your database. Whether that it's tried and tested of MySQL or shiny and new of MongoDB. This choice is probably going to affect how you scale. Also how well you know some of the different databases and approaches. &gt; &gt;Then you start coding. You hopefully care about how the URL schema looks like so you make a really nice interface for developers to work from like this: &gt; &gt;GET /users - will get you all of your users &gt; &gt;GET /users/olafur - will get you one user &gt; &gt;POST /users - will make a new user &gt; &gt;PUT /users/olafur - will update the user &gt; &gt;DELETE /user/olafur - will delete the user &gt; &gt;You will go through all of your objects mapping to REST like this and hopefully you will end up with something sane. This is really nice to hook up with jQuery and mobile interfaces. &gt; &gt;Now you have to scale. You hope that writing data to the server isn't going to kill it, so you hope you don't get too much traffic like that. You know how to handle reads at least. You have something like Nginx and Varnish, with Memcached, then you try finding bottlenecks and seeing if some more caching doesn't solve that. It's truly amazing to see the difference it makes. &gt; &gt;Now you hit an API that has to do some async behaviour and now your screwed. There are some solutions for that but they make the code really complex, even Node.js. &gt; &gt;But every one of these steps I've described are incorrect, now let me tell you why. Let's work our way back. &gt; &gt;The first problem is that you have a lot of moving parts going on before the data you're trying to put into the database ends up there. There are problems with your APIs losing data because of errors or downtime. A lot of the Internet is going over unreliable wireless technologies. So your beautiful REST calls are now riddled with exception handling, because there are so many ways of things going wrong. &gt; &gt;So what do you do. Of course you stick a REST database in front of your API. What does that accomplish, let's first talk about speed, we are talking about 4x writing speed improvements. You don't lose data when writing to the APIs. Databases are probably more solid than code you write. CouchDB is truly a speed freak when it's dealing with REST, it has security built in and validation. When you need to scale you have a multi master database so you stick one closest to your users and they all sync with each others. So we have covered scaling and dealing with the speed of writes and the reads. &gt; &gt;How do you deal with writing to the REST APIs if the clients have bad Internet connections? You don't. You write to the native implementation in your browser[1][2] or mobile [3][4]. Then you sync with them when you have a connection. This also cuts down on traffic you have to get from the server. Trust me: it's an order of magnitude difference. You might say, "Why not implement syncing in your framework of choice?" If you did this, then you probably have to rewrite them because syncing works in CouchDB by keeping track of revisions and what has changed. This is hard to retrofit to a framework. &gt; &gt;So then you don't have beautiful URLs right. It might be a valid use case for some simple API you have to maintain to have nice looking URLs but not for anything that has to scale. And it's possible in CouchDB with rewrite rules. &gt; &gt;I personally like the model of a staging database and main database. You can create a rewrite rule so all writes go to staging and all reads come from main. What this gives you is a record of all the incorrect API calls without polluting your main database. What makes sense is to have types of documents you putting into the database and using views with map functions to sort them out. You don't have to do it like that but if you gain a lot from that. &gt; &gt;So this is all fine and dandy for stuff that doesn't require processing but what if you actually want to do something more than just to store data? &gt; &gt;You can do what I did and write a service that watches for changes in a database and then put those changes through plugins, in a flow like structure. Or you can use my implementation[5], currently only in python. This abstract the CouchDB from you code some your receiving information and sending back a response. I've written it in Tornado, but who knows asyncio looks pretty good. &gt; &gt;With that kind of architecture you don't need to handle as much load as is being written to your servers you just handle as much load as you want. Balancing responsiveness with cost of the machines. But the reads are still going to be fast. &gt; &gt;So why isn't everybody doing this then? We are still learning how to structure things well so I'm only able to write about this because of the awesome work of databases like CouchDB that are not afraid of being misunderstood and people that have formed the best practices from all the mistake they have done. I've done plenty of mistakes and will do plenty of mistakes in the future. The important thing is to learn from them. &gt; &gt;I have to say that I really love REST and I love beautiful URLs but life is about doing the right thing, as often as you can get away with. &gt; &gt;[1] [https://github.com/olafura/sundaydata](https://github.com/olafura/sundaydata) &gt; &gt;[2] [https://github.com/daleharvey/pouchdb](https://github.com/daleharvey/pouchdb) &gt; &gt;[3] [http://www.couchbase.com/mobile](http://www.couchbase.com/mobile) &gt; &gt;[4] [https://cloudant.com/product/cloudant-features/sync/](https://cloudant.com/product/cloudant-features/sync/) &gt; &gt;[5] [https://github.com/olafura/sundaytasks-py](https://github.com/olafura/sundaytasks-py) &gt; &gt;[#Python](https://plus.google.com/s/%23Python) [#CouchDB](https://plus.google.com/s/%23CouchDB) [#NodeJS](https://plus.google.com/s/%23NodeJS) [#Programming](https://plus.google.com/s/%23Programming) [#RubyOnRails](https://plus.google.com/s/%23RubyOnRails) [#REST](https://plus.google.com/s/%23REST) 
[Python 0.9.1](http://pastelink.me/dl/7d7a4c) or nothing.
&gt;Provide some help to a beginner? Because that let someone know what kind of help he needs. &gt;What isn't helping is you being a jerk right out the gate. How much have you contributed to the thread beside name-calling? &gt;You also just "did his homework for him" without explaining what you did. I posted that after he posted the 'solved' edit as a way of showing another way he could have tackled the problem, so if that counts as 'doing his homework for him' I am guilty as charged. &gt; It might be fine to be a dick take you for example. &gt; as long as you actually help answer the question meaningfully. are you disputing the accuracy of my solution, or want to contribute but lack the skills to do so technically, so you resort to name-calling and stereotypes? edit: I like how you went from [extremely new to programming](http://www.reddit.com/r/learnpython/comments/20ryow/evaluate_my_python_text_rpg/cg6ge7j) to providing a social critique of the culture in less than a week. perhaps you are suffering from a perception bias, you see everybody as acting like a dick because every programmer you interact with treats you like shit. It probably has something to do with both the quality of your contributions and your unfounded smugness, as I highlighted earlier in this comment.
i think you have to actually indicate which modules u are sorting... because network.sortModules() will put a random value in all conectors.
That was great. Are there any other videos/talks that have the same demeanor that you know of?
This is my site: http://ProgramArcadeGames.com We also have students do bioinfomatics. Having a first semester course with a lot of graphics can help with understanding the visualization side.
$ curl https://www.npmjs.org/install.sh | sudo sh _Never_ ever do that. I also think that the article spends way too much time explaining how to set up django instead of just explaining the concept and linking to an example implementation on github (or similar).
thats not unexpected, an operator invocation is a lot cheaper than a method call
What's funny about his "watch the db for changes" and "have a staging and main database" for writes and reads (respectively) -- it doesn't scale. Not to mention that watching the db for changes is harder than it looks. Either you've got a plugin to the db to get it to tell you when things happen (basically to get the data store to do more than it should be doing: storing data). Or, you poll -- in which case you tend to overload the db if you want near-real-time processing. In either case its sub-optimal.
If you're interested in keeping node and other unnecessary deps out of your stack, you should look into Autobahn which has a very nice python library based on twisted.
My advice (having tutored Python professionally for a few years): start with Python 3. Pick a project that interests her that you think *you* could complete in about an hour. Start out with you writing code and explaining. Slowly transition to her writing code with you guiding. It's somewhat difficult teaching total novice programmers, as they have trouble keeping track of the "shape" of data, due to their unfamiliarity with data structures. Keep on banging home Python's built-in data structures, gloss over OO programming, and keep the assignments interesting.
thanks for the article and your thoughts on different scenarios. This sub is great because of people like you. I'll take a look at these different methods detail.
struggling to see why its a 'hackers' guide?
It is not quite obvious for me whether is it about Python 2.x or 3.x Also what does exactly mean: "The code source used to distribute this e-book." You mean the code examples coming with the book either? Or something else? 
https://github.com/ekalinin/nodeenv Came across a virtualenv-like solution for dealing with node and related packages. Loving it
But you might be right that I don't explain my point well enough in the article. Everyone I've talked to about this model has adopted it, though only after doing there own research.
If you are NOT designing a REST API your application will probably be irrelevant in a decade. That is fine for most applications.
Heh, I just noticed the weird XML-ish syntax. I think I know what happened: I posted this code on my blogger blog a long time ago, and I copied it from the blog to the comment. Presumably blogger automatically fixes the syntax of things that look like HTML. Since the grammar looks like HTML, blogger probably assumed that all words after the tag name are attributes, so it must have inserted `=""` to make it valid HTML. The findall term does exactly what you said -- transforms a string like `"he " | "she " | "it "` into the list `['he ', 'she ', 'it ']`. This is used to parse a BNF definition into the terminals that it derives.
It's how you justify a price-tag on something that can be found 100 times over for free.
Nah, probably the former.
- Start from somewhere. The #1 most important skill programmers need is to be able to read code *and understand what it does*. If that's you writing a few hundred lines of code to get her started, so be it. If it's a ten thousand line project she wants to contribute to, even better. If it takes her 20 hours to understand 10 lines of code, that's 20 hours well spent. - Focus on tools. You can't program without knowing how to write a file and how to run it. You can't really program without understanding source code control. So don't neglect tools. Choose a good tool set for her and have her learn it cold. When she gets good, she can experiment with other tool sets, but you want to eliminate that variable as quickly as possible. - Teach her how to look things up and learn for herself. GIYF! Python is a very small language. After learning how to find the documentation and read it, where to find different things (syntax over there, libraries here) she will be able to remind herself as often as she needs to. - Keep task-focused. Make sure she knows what she should be studying, what she should be doing, what the big goals and little goals are, etc... Try to approach programming as the big task it really is. You wouldn't send her in to dig a ditch without proper gear, a supervisor to make sure she doesn't do something stupid, and all the other things you will find at a work site. Don't ask her to dig programming ditches without the same kind of support.
This probably poor form but this snippet was poorly written: min_salary_cutoff = 500 max_salary_cutoff = 800000 responses_all = responses_all[responses_all['salary_usd'] &gt; min_salary_cutoff] responses_all = responses_all[responses_all['salary_usd'] &lt; max_salary_cutoff] responses_usa = responses_usa[responses_usa['salary_usd'] &gt; min_salary_cutoff] responses_usa = responses_usa[responses_usa['salary_usd'] &lt; max_salary_cutoff] And can be simplified as such: within_valid_range = lambda resp: min_salary_cutoff &lt; resp['salary_usd'] &lt; max_salary_cutoff responses_all = filter(within_valid_range, responses_all) responses_usa = filter(within_valid_range, responses_usa) 
Agreed, was quite dissapointed after seeing summary and table of contents. Best I have read yet is Violent Python, but even that is more like "recreate basic versions of common tools." To be fair though, most usage beyond that will be very use case specific. While we're here, anyone have any good suggestions for 'hacking with python' books / references?
Further up the page says &gt;The sample code provided with the book is the code used on this Web site to send out sample chapters, and to sell the book using Coinbase. It's a complete Python package which applies some of the tips and methods described in the book. You can learn from it and use it as a reference or boilerplate template. 
I'm going to give kivvy another try.
Thanks for responding! I just noticed that someone posted the exact same question above, so I should have read a little more thoroughly before asking. Your explanation totally makes sense though, and the more I look at it, the prettier lambda expressions get to me haha! 
Try this instead then: http://autobahn.ws/python/
&gt;hacker You keep using that word. I do not think it means what you think it means.
http://www.checkio.org/ It provides you challenges, and asks you to write some Python to solve the challenge. The code you write gets executed and tested. You can also look at the solutions written by other people. As you solve challenges, it gives you points, you level up and unlock more challenges, which makes it fun in my opinion. Edit: Spelling.
There is a difference between having a REST API like with a REST based database and designing your own REST API. The problem when you design your own you aren't going to have some of the things that are vital to a successful API. Which are bulk sending and receiving, keeping a track of changes and not being vulnerable to what you what you haven't checked for. Of course the most important thing is speed and being able to distribute the load across multiple locations. If you tell me how to easily do that with excising framework then I will be in awe of you.
there are tons of resources in the sidebar. personally I found "learn python the hard way", followed by "dive into python" (but for python 2) quite useful
coursera
This is.... strange. He has already written a book about the topic. I believe he has the know-how to create the video series, but why is there a kickstarter campaign??? He says he needs the money to buy video equipment to make the series, although he obviously has enough already to make the intro video! He doesn't mention production costs or anything like that. There also this: https://www.youtube.com/watch?v=OSGv2VnC0go A very, very good presentation that would be hard to beat. Seriously, every budding Python user should watch that video at least once.
Or use gevent-socketio and get SocketIO on the client with Python and Django on the server. 
&gt; It's impossible to execute more than one piece of Python code at a time That's not quite true. Multiple threads in the same interpreter will spin on the GIL. However if you use multiprocessing, which is what /u/Synackaon advocated, you bypass that limitation as each process has its own interpreter and hence GIL. The short story is: * I/O bound - use threads * CPU bound - use multiprocessing 
Wrong thread?
The internets, co-worker pull requests, and needing to learn for my job.
High school. I've heard good things about Learn Python The Hard Way as a resource for beginners, though.
I started with the code academy course for the basics. 
Terminology notes: - Python has what it calls `list`s and `dict`s. A Python list is a container that holds arbitrary objects in a certain order. A Python dictionary is a container that connects "keys" (usually strings) to "values" (whatever you want stored). Python dictionaries have no particular order associated with them and don't promise to return things in the order you stored them, alphabetical order, or anything else. - In Javascript, an "array" is very similar to a Python list but with a few minor differences. - PHP has a type it calls `array`. It is very misleadingly misnamed. It is a combination of a Python list and a Python dictionary in one data type, so you can store objects in an order or pull them out by key. Javascript also lets you use its objects like PHP "arrays". This seems convenient, but turns out to be a pain in the long run. - In most languages, an "array" is a structure like a Python list, but all the objects have to have the same type—all strings, all integer numbers, all whatever. It also sometimes has a fixed size and can't be made longer after it's created. - In most languages, a "list" is a structure like a Python list, but with a very different implementation. In Python doing `my_list[1]` and `my_list[10]` are equally fast, but in other languages (LISP is the most famous one) the further you go into a "list" the longer it takes to pull the item out. On the flipside, a LISP-style "list" can add and remove items from the end very quickly, which is sometimes useful. - What Python calls `list` is closer to what C++ calls a "vector": a resizable array. - What Python calls a `dict` is also called a "map" or a "hash" in other languages. Some languages are more strict that the types of all the things in the dictionary are the same, such as only have strings for keys and only have numbers for values, or whatever. - "Numpy" is a library for doing numeric calculations in Python. It has a type that it calls an array, which lets you do math more quickly than with a `list`.
I learned by doing a simple project. Lots of googling and 2/3 of the CodeAcademy course.
That surprises me - almost all of my intro programming that wasn't language-specific was in C, not because I was ever expected to use C, but because learning to use malloc, handle strings and pass around pointers is really valuable to understanding how programming languages are doing what they do under the surface. How do you cover core programming concepts (pointers, memory, etc.) when Python abstracts away so many of them for you?
The internet, i started with C thou which was from books and doom .wad files
What the...? The average US salary is $106k? Median is $95k? No. The data is skewed. There was clearly only one respondent with more than 16 years experience (from the plot in line [26]), and they reported $600k. Liar. I've been hacking it out for 6 years in the US with a master's degree, and I'm still well below the median reported here. Edit: clarity
I started by reading other people's code at my company. Then, I started googling (how to use dictionaries, lists, etc.), looking at the list of new Python features, finding out about new libraries, flipping through their examples and change logs. I read about obscure Python hacks because I was bored at work, tried them out, and now I use them.
Brilliant Google Python class from a Stanford lecturer. Got me into it! It also has exercises and Nick Parlante is just a great lecturer. https://www.youtube.com/watch?v=tKTZoB2Vjuk
Yup, wrong thread. Sorry dude.
[Posting in the correct thread this time] This is.... strange. He has already written a book about the topic. I believe he has the know-how to create the video series, but why is there a kickstarter campaign??? He says he needs the money to buy video equipment to make the series, although he obviously has enough already to make the intro video! He doesn't mention production costs or anything like that. There also this: https://www.youtube.com/watch?v=OSGv2VnC0go A very, very good presentation that would be hard to beat. Seriously, every budding Python user should watch that video at least once. 
You learn them later, using different languages. They are important, but for the basic understanding of how programming works something like Python gives way faster successes to the students, and and interpreted language makes try and error even faster.
A nice way to learn pyton is through [Python koans](https://github.com/gregmalcolm/python_koans). What you do is making unit tests succeed by filling in blanks. It's an active way of learning, it is quite fun and as you learn programming by doing, effective. You also get acquinted with unit tests, a good thing for beginning programmers.
EDx 6.00x Could not recommend it too highly, it is amazing!
The interwebs, mostly out of curiosity as I wanted to automate away tasks at work (financial advising). That lead me into quitting my job and working my butt off to be a developer a year later. As far as toying with a raspberry pi, python isn't at all a necessity. You can do most languages, it's just a Linux platform (arm proves some considerations, however). Python is a great language though, its awesome how quickly it allows an idea to become a prototype (and subsequently a great performing application).
Sitting on my couch, while recovering from getting my wisdom teeth removed.
but, but ... starting with C abstracts away accumulators, segment registers, stack frames, the stack pointer, opcode prefixes, cycle-counting to find how fast the loop will run, interrupt handling, overlapped I/O, ... Just teasing you a little. Bet you got into that later, if at all, and it'll be the same for Python/JS/Ruby beginners.
At home. Python is one of the easiest programming languages to grasp at the beginning, so just decide on a project and start coding with the python.org documentation at hand.
I learnt it by myself my first book was Dive into Python. 
I watched some class on Youtube created by Google+Stanford which came with all of the course materials. I did all of the exercises but never really retained the practice to memory. It wasn't until about a year later where I started applying it to everything I could at work and with personal projects. I'm still pretty hacky with it, but I feel that I have a pretty firm grasp on its capabilities and how to apply them.
I was re-introduced to Python by Chris Shenton while we were both working at NASA. I went through a tiny tutorial and then, being really broke at the time, luckily got my greasy hands on a used 2nd or 3rd edition of Learning Python by Mark Lutz. Within a few weeks I was writing scripts and forming a 'Python Underground' at NASA HQ with Chris. We weren't approved to use Python, but we wrote handy scripts for project managers at 5x to 10x the speed of the Java, .Net, and ColdFusion developers. Then I had a Java project that wasn't going to make the deadline in a few weeks, so rewrote it in Python in 90 minutes. I got that one into production, decided I really needed to make Python my career, so took on the monikor 'pydanny'. Fun times. :-)
Would passing a lambda function work? If the input must be stored / supplied as a string (is this certainly the case?), then the user could pass a string defining a lambda function, and `eval` could be used to turn that into a function object inside your code. Something like this: # User defines this string / passes it through `input` func_string = "lambda x=0, y=0: x**2 + y" # Your code turns it into a function, and uses it to compute things func = eval(func_string) print(func(x=5, y=2)) # prints 27 
It's probably location dependent as well. FWIW I'm above the median as a college new hire, but I'm paying out the wazoo for cost of living and state income tax.
[The tutorial](http://docs.python.org/2.7/tutorial/index.html). I had to implement something for a college class, and decided that Pascal wasn't powerful enough. I had been reading about python for a while, but hadn't really coded anything with it yet. So I grabbed the tutorial, and the specs for my assignment, and here I am, almost 6 years later, actually writing python for a living.
Ditto.
Slippery slope. Are you content with every post being someone hawking their books? What about Python merchandise ? You cool with that?
I started with the [Flask tutorial](http://flask.pocoo.org/docs/tutorial/introduction/).
I learned it doing Project Euler problems. Learned Haskell too
At home with too much free time and no gf. Also, I got fed up with java and after failing with perl I tried python and liked it a lot.
A Brazilian dude taught me everything I know.
I started with the Rogue Basin [Roguelike Tutorial](http://www.roguebasin.com/index.php?title=Complete_Roguelike_Tutorial,_using_python%2Blibtcod)
nice site design
Very cool. Thanks for the post.
I've often struggled with the concept of lambda functions. I guess because I never saw the utility except for the instance of one-off custom array_map type functions to save space and I guess you would enhance readability in that case. Other than that, when would you prefer lambda functions?
Django
Believe me -&gt; CodeAcademy! It is awesome and simple, every lesson is stuck in my brain! :)
I used Zed Shaw's Learn Python the Hard Way guide http://learnpythonthehardway.org/book/ quick and straightforward
From the python tutorial, and eventually got lots of help from reading StackOverflow questions.
I used MIT Open courseware: 6.00 Intro to Computer Science. Since then I've practiced with Sphere Online Judge. They're great resources, if you can stand to work through them.
through goofing around with pygame
I learned in my apartment my senior year of undergrad. I was taking a mechanics of composite materials class where we built a progressive ply failure analysis code throughout the semester and since I didn't have internet, I couldn't VPN to campus for a matlab license. Turns out, numpi/scipi is totally capable of handling the simple matrix math that was required and I didn't have to deal with tethering to jailbroken iphone -&gt; vpn -&gt; lose my work when matlab timed out. I miss it, I'm trying to get back to using python at work and I think I just came up with a project to use as my guinea pig.
I wanted to make a script to upload some files for me, but I didn't want to make it in PHP or Perl that I already knew, then I made it in Python just by googling "action + python" (ex.: "send POST with file Python") and then I dropped Python. Some months later I found Learn Python The Hard Way and then I sent an application to a job only with the knowledge acquired with this book because I was upset with my old PHP job, they gave a copy of Learning Python and I made a test 2 weeks later and they accept me and here I am.
On the street. 
Learn Python 5th Edition - Lutz is what really solidified it for me. 
A more perfect book? Learning Python with Raspberry Pi Alex Bradbury (Author), Ben Everard (Author) http://www.amazon.com/Learning-Python-Raspberry-Alex-Bradbury/dp/1118717058/ref=sr_1_1?ie=UTF8&amp;qid=1395812735&amp;sr=8-1 
Yeah, it's becoming common to teach it to first year programmers (I was the first incoming class at my school to learn it). The white space forces good style and abstracting away a lot of the technical stuff allowed us to more easily learn more basic things like what a loop is, what can we do with operators, how do we do file i/o, the behavior of passing by value vs passing by reference, what are some basic collection structures, what are some basic graphics we can draw in a window, how do we define a simple class, etc. Our classes after that had us use C++ and de-mystified the process of what we were doing (what pointers are, what was really going on when we passed by reference, how memory is allocated, what an array is and how to use it, etc.)
It does less for you in terms of integration with your asset pipeline, compiling haml/sass/etc. by default, its template language is intentionally less powerful than something like erb, migrations you almost never have to write by hand with South, the auto-admin is much better than Rails scaffolding, but overall it's pretty much the same shit: you declare some models which gives you an okay-ish ORM, you declare some url's that map to callables, in the callables you take a request, do something, and return some output, either in json or by rendering a template, they both have big communities and libraries for this and that and the other, it's actually kind of useless to learn one if you know the other unless it's for job purposes, they fill pretty much the exact same niche.
They are fairly similar (in a way, ddjango was inspired by a lot of the ideas in rails). A lot of the concepts are very similar, you have models, views, controllers etc
We learned Java first, then C after we knew the basics of OO design and programming in general. Anyone who was good understood C right away after that, and the ones who did not still learned reasonably well. Learning to program while also learning C sounds like a nightmare. Best to get the basics on an easier language. 
Django is for customization in RAD. Rails is for convention for RAD.
I was quite bored in high school. At the time I attended a school for math and science, and I was sitting around one day during a free block after completing my homework, and the computer science teacher was sitting a few rows ahead. I said to my classmate that I was quite bored after doing my homework, and the teacher looked up and said, "well, learn python then." I had a bit of experience with C/C++ at the time, and at first the lack of curly braces made me quite upset, but I've found python to be my favorite language now. 
As a Rails developer, I couldn't imagine voluntarily switching to Django. Ruby really lends itself well to writing web back-ends, and Rails is so perfect in so many ways. If you want to use Python, why don't you use it where it really shines? Maybe you could use some of the scientific computing libraries. 
I am currently working on a product similar to what the Smooshbox was supposed to be. It's basically a raspberry pi with a GSM arduino module on it it works on the AT language to send and receive SMS messages. I then have then hooked up to a simple django app that queries a database for users numbers and sends out messages based on the subscribers keyword subscription. You could do this with an old android phone. But I have chosen to use a raspberry pi instead.
Nope, I don't even know the author at all. I just sumbled onto it via a Python ML and thought it could be of interest for /r/python. 
Hi. Highly experienced Django developer who moonlights in Rails here. 2 of my clients are Django/Python the other one is Ruby/Rails/iOS. First off, I really love to hear it when Ruby/Rails devs have some interest in Python/Django and vice versa. I think there should be more cross pollination. Second, if you want to learn more about Django checkout the [PyOhio Conference](http://www.pyohio.org) taking place in July. It is a free weekend conference with 300+ attendees and around 40 sessions on all things Python including all day bootcamps. A lot of people compare Django and Rails like it's the same framework with the same philosophy, etc, etc. Django is after all, Python's answer to Rails. That couldn't be further from the truth. Django was built specifically to build content heavy applications. Particularly news websites. It veers more and more into common web applications these days but it's roots are in content management. You can read more about that here: https://docs.djangoproject.com/en/dev/misc/design-philosophies/ Coming from a Rails background here are the top things that are going to immediately trip you up when looking into Django and Python. I say this as someone who genuinely prefers Django and Python over Rails. 1) The Django asset pipeline is very naive and basic compared to something like sprockets. Fortunately we have the [Gears](https://github.com/gears/gears) and Django-Gears projects to make up for it. Gears as it's name implies is a clone of Sprockets for Python. It is a separate project and must be installed and configured manually. 2) Django's ORM more closely resembles [Datamapper](http://datamapper.org/why.html) than it does ActiveRecord. ActiveRecord and Data Mapper are actually the names of design patterns. Django's ORM is based off of SQLAlchemy which implements the data mapper pattern in Python. 3) You cannot create your own DSLs in Python. Usually this is a good thing, sometimes you wish you could though. Python doesn't have an rspec equivalent and our testing frameworks resemble Java more than they do Ruby. The Nose and Sure packages make testing easier but you're going to hate the verbosity of some of the tests you write. 4) The Python community has three key philosophies that are diametrically opposed to that of the Ruby community. One, we believe there should be one, and preferably only one obvious way to accomplish a certain task. The Ruby community believes that the language should not dictate how you solve a problem. (Your frameworks dictate it instead). Two, we believe that things should be as explicit as possible. (Python doesn't have implicit return statements for example). and Three, Python programmers believe that most magic should be easily exposed and navigable by programmers, whereas Rails tends to hide as much as it can. (Readability counts) 5) Django doesn't impose restrictions on how you form your URLs. It doesn't support RESTful interfaces out of the box in the same way that ActiveResource can. (If you want to write a restful webservice use Django Rest Framework or Tastiepie). Django's conventions end at MVC. It doesn't decide how you should name your files. It doesn't expect you to write empty controllers. It doesn't dictate how you should name things. This is a good thing. 6) Integrating JavaScript into a Django project is very, very messy unless you use something like Gears or Compressor. Django's "media" and "widget" system is ugly and unwieldy. Most django developers still write their html with HTML and their CSS with CSS. I use HAMLpy and LESScss. HAMLpy is HAML implemented in Python and LESS is node's alternative to SCSS. It is often easier (and quicker) to use node with Python instead of Ruby with Python. 7) Python's truth tables are different than in Ruby. Generally speaking 0, False, [], "", and {} all evaluate to False although any object can define it's own truth table by overriding \_\_bool\_\_ In Ruby you have False and Nil and True. Here are the upsides: 1) The Python libraries are vast, fast, and almost as complete as Java's. Two notable holes still exist, namely in distributed databases, and in machine learning. Nearly everything you want to be able to accomplish you can do with Python. 2) Django doesn't penalize you if you "break from the mold" and try to do something differently. Generally speaking, if you want to do something your own way, you'll be able to get away with it. 3) Python has standards for most things. Want to get the length of a string? Use len. Length of a list. Use len. Length of a dict. Use len. Understanding this [page](http://docs.python.org/3.3/library/functions.html) and the double underscore(dunder) methods will open the inner beauty of Python to you. 4) Well written Python code is **beautiful**. Not just in a well crafted, well tested way. It also tends to take on a physical sexiness to it's form. After awhile you will begin to see even the more elegant portions of Ruby to feel ugly or dirty compared to the code you will write in Python. The one exception to this IMHO is Ruby's block syntax. 5) Python's meta programming capabilities, although more restrictive than Ruby are still pretty awesome and are much more readable and easier to comprehend while being harder to override willy nilly like you can in Ruby. Here is some advice: 1) Stay away from the class based views. They rarely offer anything more than the function based view alternatives. They hide meaningful magic from you, obsfucating your code. I've seen several class based views that when refactored to the functional style cut out several lines of code while opening the code up to change. It was a mistake for Django to ever implement them. 2) Django forms are awesome ways to validate POST data. Big thumbs up and you'll love them. 3) For the love of all things holy work your way through the [Django tutorial](https://docs.djangoproject.com/en/dev/intro/tutorial01/) It has been refined over and over again to hit on every major feature, caveat, philosophy and exception when building Django applications. It is one of the best tutorials you'll ever read. (Read everything) It will save you tons and tons of time down the road. Trust me on this. In closing, Django is VERY different from Rails but in my experience Django is a lot less fragile than Rails, promotes the creation of much cleaner code, and is easy to grasp for both beginners and advanced web developers. Lastly, welcome to the Django community. If you hit any snags send me a PM and I'll do my best to help you.
Django has 3 million downloads, and Rails has 33 million, probably because Rails is a better framework. On the other hand, numpy has 500,000 downloads and SciRuby has 1,000, because numpy is better. 
Django is to Arch what Rails is to Ubuntu.
I needed to learn it for work because we were transitioning our code base from Perl to Python. I started with Learn Python the Hard Way, didn't actually finish, then jumped into writing some of my Perl code in Python. I made the effort to use python for everything that I could use it for and it really helped make learning it easy. 
Mine was a similar story but now where near as glamorous as working for NASA! I had a C++ application that wouldn't make the deadline i stumbled on python while looking for a perl tutorial and the rest is history. Love your book, bought it (1.5) even though i don't use DJango anymore
I'd rather leave the language/framework dick waving contest somewhere else. Both Rails and Django are excellent tools for developing web applications with vastly different backgrounds and philosophies. Also, you should take a look at [this](http://www.nizkor.org/features/fallacies/appeal-to-popularity.html)
MATLAB? What was the justification for that?
There are other options also: &gt; web2py was inspired by Ruby on Rails form [here](http://www.web2py.com/init/default/what). It's said that it "favors convention over configuration approach", so it *might* be more familiar for you.
I fancied ditching PHP, tried Ruby and RoR which didn't fit with me, then came across Django from a recommendation. Learnt as much as I needed to 'on the job' then have supplemented it since. Python is now my language of choice, I find it very hard not to use it in most situations.
Upvote because actually funny.
Thanks! I'm still getting used to the whole "pythonic" thing, having transferred from C++ and Lua.
Here's a free book for complete beginners that gives the source code for small games (Tic Tac Toe, Hangman, etc.) and uses them to explain programming concepts: http://inventwithpython.com And you don't need a Raspberry Pi to learn Python. Any computer will do.
The official docs on their website. e.g. http://docs.python.org/3/
I learned it at home, sitting in front of my laptop. One day i decided that i should be involved in web-dev, so i started to choose what to use for it (php, ruby or python) and i found python fit all my requirements perfectly.
Online with libraries and examples of other people's code. When I made a mistake search stack overflow for answers. If it was not there I would look through google. After half an hour or longer I would ask a question. Never used any book for a long time it was too slow.
Great post. About Python's apperent lack of machine learning however, are you aware of scikit-learn? If yes, whats wrong with it? I'm genuinely curious.
According to the professor the college needed another language and already had MATLAB as an intro course for electrical engineering students so they clumped us in. Its mostly data analysis and stuff though, 90% of the work with the language is something a cs major will never do. Also its closed source and we have to provide out own copy :/
i've heard good things about [learn python the hard way](http://learnpythonthehardway.org/) but i pretty much taught myself by writing games in pygame.
Bucky: https://www.youtube.com/watch?v=4Mf0h3HphEA
For the sake of a stupid joke: &gt;&gt;&gt; from random import randint &gt;&gt;&gt; randint(3,7)
Great post. You might want to adjust the ORM part however since it's definitely not based on SQLAlchemy.
Gray hat python is apparently pretty good: http://www.amazon.com/Gray-Hat-Python-Programming-Engineers/dp/1593271921 (pdf - http://news.asis.io/sites/default/files/Gray-Hat-Python.pdf)
Check the side bar for the online books; LPTHW is a good place to start learning the basics. CodeAcademy is cool because it's interactive, but I didn't really like the Python course and I didn't feel like I learned more than some basic syntax. The ruby one is better, but not by much. I've been using this textbook to teach myself: http://www.amazon.com/Python-Programming-Absolute-Beginner-Edition/dp/1435455002 It was recommended to me by a friend who took CSCI 101 at PSU with it. He does it project-based; every chapter you complete a working game program, and he steps you through all of it with example programs. Very easy to follow, and the programs are fun to write. I've tried learning coding from textbooks in the past without much success, and I really feel like I'm getting somewhere with this one. Plus, it's python3, which is probably what we beginners should be working with.
I transitioned from Gamemaker and AutoIT3 to Python by mainly staring at the code of some guy who went by the name IceFire or Xuzz and learned from his work. After that i tried my hand at making things at my own, and only needed to read up a bit on classes to get going. I ended up reinventing the wheel for a lot of things, but that only gave me a deeper understanding. Since then I've learned myself how to use Twisted, Pygame, Panda3D, Numpy and more, mainly from the docs available on their pages.
Give us a *minimal* example, and preferably post to /r/learnpython next time.
As part of the BSc astronomy degree I started, first years learn C++ in a basic programming course together with mathematics, physics and computer science students. From there on python is **strongly** recommended in all kinds of courses involving the data reduction involved in observational astronomy. We had an hour long brief introduction to Python and were encouraged to work everything else out on our own. I still believe the best way to learn something is to really **need** something to work. Edit: Hehe, cake day. 
Reddit is written in Python. 
Thanks for this. I'm still learning django and am struggling with the class based views. Lots of magic happening I don't quite understand yet. Is this really the consensus though? I just thought I had to stick with it and they would eventually make sense.
Tutorials on python.org are enough to get started. For my thesis I built a manipulator and needed an app to control it via serial port. I have been already employed as a software engineer and people at work recommended Python + wxWidgets. I have finished it in one week without any prior knowledge of both. Today I recommend Python as easy language to learn on your own. You don't need many features to write something simple.
Great post. Would disagree with CBV's as they have their place, especially when coupled with the DRF, for example. Take a look at [Django Vanilla Views](http://django-vanilla-views.org/) (by the same guy that brought us DRF) for an alternative implementation.
Uhm. One of the things where Python is really good is precisely in science and machine learning. Numpy, Scipy, scikit-learn, pandas, ipython, matplotlib and many others are very used and appreciated. 
At work