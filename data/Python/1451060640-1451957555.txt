yes
Sorry not sure so, when I have had problems before with Scipy it has turned out to be a Numpy issue. Hope you manage to work it out.
I agree with you. However, I do recommend at least including: ... """ :param int x :param int y """ ... For doc generation
besides you clearly liking wheels over eggs, what is your point exactly? 
Have you tried to capture traffic to the website when you input the answer and press send? It might give you an idea how to craft a proper response. Or you can use Selenium with headless browser, that will work 100%.
Ok, a bad guess then :( The "on win32" part in the first line and the "Win32 application" made me curious... to me it sounded like numpy tries to load a 32bit DLL when importing multiarray
Do you think I should post there?
Go there, read the side bar, search for posts about beginner ideas, then post if you find nothing. Delete this post. 
This is excellent! Well done. I do question, though the immense use of docstrings. Your naming is excellent making most of these docstrings redundant and making the code messy and personally annoying to read. Is there some convention or code-to-doc thing you're using that requires all these docstrings?
I'd try asking over on the [Anaconda mailing list...](https://groups.google.com/a/continuum.io/forum/#!forum/anaconda)
Invest in a raspberry pi and learn how to write scripts that can automate your home!
Is there anything else you recommend? I started with pandas coming from Excel. Pandas is critical for me. I also have automated downloads from ftp servers, and sharing files on the network. I am aware of scikit learn and in playing around with that. I have not done anything with gui at all. I mainly use pandas to process files, add columns, filter, etc. Then I load the output into tableau for visualization. I wonder what the next thing is that I should learn or look into. 
&gt; a fully functional application I like to make applications that are only 37% functional. Python isn't really suitable for big applications because it is missing 63%
I already have it.... And idea tuo what can i do?
I have started a couple on my blog www.rememberhacks.com But the ideas are endless. i.e. You can use your pi as a web server and make an api that you can query for data
Awesome
I've done a few specialist business apps for customers with Python and it was a pleasure. All of them run natively on Windows, OSX and Linux without change. Python is very mature, it's been around longer than Java and a lot longer than C#. There's plenty of advantages. Development speed is the biggest. Succinctness is power in this day and age and frankly, Python is just a more powerful language than the other two you mention by that measure. I can run rings around most Java devs in my field using Python, wxPython and emacs, and I'm not that great a programmer by any means. 
Any good sources you have on using Python with excel? I have a decent handle on Python and I'd like to start parsing some data for work. 
If you are doing GUI, the actual GUI will probably run natively (Qt for example is C++). Python is just the glue putting the GUI together. And unless it's a game or something, python's speed will be enough for a GUI application.
Set goal, what do you want with python? for example web app, data analyst, sysadmin scripts, etc. Then find tutorial for that particular goal.
running at boot requires root, using pip outside of a virtualenv is not really considered best practice. you might want to consider packaging an rpm or deb instead of relying on setuptools alone in this case.
Op is referring to https://en.m.wikipedia.org/wiki/Functional_programming.
Very educational article, although your blog's landing page is a little weird in that its not an index of posts, makes it harder to skim your posts.
That's good to know. I thought about doing this for some additional income. I was worried that all of the gigs would be too much work for to little cash. Reading your description sounds like a large portion of my python scripts and makes me wish I tried it sooner. 
Do you mind if I ask you to explain how they run the program? Did you make it an executable? Sorry if this seems basic, I'm mostly used to python in academia, not production
Meet py2exe, and others like it. Not going to claim I know exactly how they work, but essentially they bundle a Python interpreter and the exact libraries needed together into the executable which can be run on a Windows machine. On OSX, its even easier as the OS ships with a Python interpreters. In fact, there's a somewhat decent chance you have a bundled Python app on your computer right now without knowing it. Use Dropbox? Their client software is Python.
I use Linux myself so python is already included (yay *nix), but was wondering whether the code was inherently cross platform or just using py2exe like you mentioned and just saying "here use this for windows"
Generally the code would be cross platform. Py2exe just gives you Python on any windows machine. Without package manages, dependencies are the real issue. Thus on windows, you bundle everything in. 
Fucking of course not
Yes, I give them a standalone executable produced with [pyinstaller](http://www.pyinstaller.org/). 
What did you use for the GUI developing? QtPy? 
It's indeed the experience I was after :) I do have a good full-time job, but it feels very different when people pay for you work directly.
&gt; This is a cool way to make some side money with code. If it continues going well for you, I'd love to read a follow-up or how-to article with more details. What kind of a follow-up would you like to see? Unfortunately I don't plan on continuing the freelancing, not right now anyway, I have too much work on my hands :) &gt; Out of curiosity, what skill level would you say you've needed with the jobs you've been doing? It sounds like you're getting an eclectic mix. From my point of view -- very minimal. It may be eclectic, yes, but as long as you know your basic Python, you'll just google the rest. There are modules for everything.
It is, you're right, I'm using the [Poole](https://github.com/poole/poole) jekyll theme and although I really like the minimalism, the landing page is iffy. I'll get to it, eventually! :) And thank you! :)
&gt; How did you fight tiredness / burnout with doing "two" jobs? By only doing it for the 10 days :) I'm also used to working on my projects after work, so this replaced the projects for a while. &gt; Edit: oh, and how did you come up with your pricing? Guesswork. I undervalued the first gig ($15), overvalued the second ($35, didn't hear back from the buyer) and then just winged it by how much value it seemed to create for the buyer.
Again, you don't have to do anything. You could have 1-space + 1-tab + 3-spaces + 2 tabs for each indentation for all anyone cares. The point is this is the convention. You follow it, it'll be easier for other people to read and interact with your code. If you don't, that's it, you just don't.
Doesn't quite match minimum wage here, but better than earning nothing. I wonder how I'd go offering a $5 discount for projects that could be open sourced afterwards.
How does Rollbar compare to the error tracking in Opbeat? https://opbeat.com/errors/
Google indentation style.. I never liked it. ( https://www.quora.com/Why-does-Google-use-2-spaces-for-Python-indentation )
That's good style today, yeah. The object class and the hmac module were both added in Python 2.2, so this code was almost certainly written before that was even an option.
Does it really need to be at boot, or is at login good enough? On Linux distros, `~/.profile` is run (by a shell) when the user logs in, so you can invoke a Python command from there. There isn't a good way to do this on a pip install, though. There are hackish ways to do just about anything from a pip install (because, if you only make an sdist, it will run the setup.py file), but the Python world is moving away from that with wheels.
It depends on your programming knowledge. You can do a remote manager for your smartphone. I suggest you to use the library RemI (http://github.com/dddomodossola/remi) for the remote interface. AndroidHelper library (included in QPython) will help you interfacing with Android API.
I wouldn't assume it must be closed source by default.
How did you get gigs? Just the typical " I will code anything in python " pitch?
No, the typical "I've been a software engineer for X years." :)
Thx! Ive got python experience, and a remote Manager seems like a neat idea.
:D That is what I use now along with New Relic and both are awesome. Would love something like New Relic that I can host in house. I was mainly asking as I always love playing around with alternatives in my spare time. p.s. thanks for your work on both projects! :D
Apologies if you already know this. A single decision tree isn't going to be very robust here. You're better off using some ensemble technique and/or, say, convolutional neural networks for good results on image recognition tasks.
Flask and Bottle are very similar, and OP should definitely go for one of them to maximize learning.
Thank you!
I know. There are lot of solution online which uses neural. I wanted to challenge myself. I asked is it possible? How far can I go?
Did you get any bad or trashy requests? I've heard stories from people on freelancer sites that often they received requests for outlandish or laughably large projects for too little money.
I'm really unconvinced by his reasoning about reinventing generic dispatch, especially if the number of node types needs to grow. For that matter, we still have a massive if/return structure. Maybe this will turn out better than it looks, but it seems really weird to me.
I'm an independent software developer these days with clients. Fireteam and Sentry being two of them.
[openpyxl](https://pypi.python.org/pypi/openpyxl) For reading and writing to .xls/.xlsx files
I've been working on this on and off for a few weeks, and I think it's time to let it out into the world and get some feedback. Any feedback or feature requests are appreciated!
Its really really hard to read uncommented code with variable names in Spanish. The best code is self documenting, that becomes pretty hard when its written in two languages. If I were you I would translate the variable names and comments to English then ask again in /r/learnpython.
Totally agree with your comment about non-trivial sites. I do my web dev in Ruby, but we have a similar problem - a lot of times if you start with Sinatra, added features over time will basically force you to migrate to Rails. I would reserve microframeworks for micro-sites.
It's nice to choose your own pieces to some degree, but since most people end up setting up very similar things I just use a local "seed" project if I do flask that pretty much emulates a light django 
I never see anyone talking about Tornado in these threads. I've been using it for years and it's excellent. Async is a good model for webserver design for maximizing concurrency, and if you want to use websockets Tornado's support is top notch.
I was giving the benefit of the doubt...
Btw.... It's "aaron", not "aron". 
Flask, bottle, and pyramid are basically on the same field IMO. Then you have django. Django is very "high level," where the others are pretty low level. Flask and the other lower level frameworks allow you do things JUST the way you want to do them, but you're highly likely to do them in not the best way. Django forces you to do things in the Django way, which can be frustrating, but this way is most likely to be better than anything you were going to come up with. In the end, they all are capable of producing any website you want, and certainly can do anything the other can do. It just comes down to personal preference. Django will force you to be organized from the start, leaving you less likely to need to do as many serious overhauls. Personally, I prefer Flask, due simply to the speed with which I can push out exactly what I want. With Django, you usually have to learn something new, or figure out the Django way, which I find tedious and annoying when wanting to develop something. Still though, the quality of my projects would most likely be higher if I was using Django.
I'd say Tornado is probably feature-equal to flask (from my limited experience porting flask apps to tornado in 2014) for web-specific features. Tornado also provides an async stack for writing highly concurrent single-threaded applications (although we have asyncio for that too, now). It is my opinion that anything flask does Tornado can do better, at the cost of a more steep learning curve. Tornado used to be really hard to mentally organize when doing async thanks to callback hell, but nowadays as long as you're using the coroutine feature it's a breeze (preferably with Python 3.3+).
&gt; But the thing to watch for with microframeworks is that you'll often end up implementing the parts of a larger framework by the time you're done setting up a non-trivial site This is not a problem with micro frameworks but with the programmer. The first thing you should do is look for some package or extension before trying to implement something yourself. Flask has so many extensions that for most large scale projects you will end up having all the functionality of django without being tied to the django version of that feature. 
Id start with Django. It saves you from having a patched together security hole-ridden peice of shit from the start. Lets face it, you want to get a site up and running and learn on the way. If you want to get into another more hands-on setup later then fine, but start with a framework that will save your ass a couple times first.
And note that sometimes the two are mixed -- it's easy enough to have the second, plus a few relatively fixed pages served the first way. Or a mix because of historical reasons (app was moved to the second model, but not all of it yet). Or, say, a React app working on REST (second way) but using the Django admin interface because it's there (which was built the first way).
Is there any support for some kind of template language in WSGI? Probably the n1 reason I use frameworks in the first place.
I can not comment on Bottle or web2py but in a Django vs Flask fight I have some relevant advice. I converted from Django to Flask. Why? Django tries to do everything and it does all it sets out to do reasonably well. However, Flask does one thing, SQLAlchemy does one thing, Jinja2 does one thing. They all specialize on one task. They all improve independently of one another. Building a stack with flask can be challenging. Choosing libraries and learning how to implement them can be a real challenge. But once you find and learn your own Flask stack, you can be very productive and take advantage of the latest and greatest python libraries.
You also have [importd](http://importd.readthedocs.org/en/latest/) (the D is for Django), which is basically like Flask but full Django, i.e. the minimalism of Flask with all the tools of Django. - Bottle: nothing inside. You have to pick your ORM, your test runner, etc. I don't recommend it. - Flask: not much per default, lots of plugins. You have to wire up your test runner, your test DB, your admin panel, etc. I don't like that. - Web2py: quite much inside, not so popular, not python3. It has its ORM, a great admin interface (with which you can even edit code, config and apps), a few starter projects. - Django: lots of tools, lots of plugins, more difficult at first. I think it pays off quickly.
Oh, sorry, that's just a term I came up with on the spot, not an industry term or anything. Basically, to me, use a microframework when you know that for the foreseeable future, you only have a few features on your site - probably not more than four, depending on how you define a feature. If you expect to add more features down the line, then it's probably worth sitting down and seriously deciding if a full-fledged framework is the better choice initially, rather than having to change it later.
I find my appreciation for django keeps growing over time. It is so productive, you can just hammer out nice and complete apps so quickly. But it is a lot of stuff to take in and integrate. Worth it, very pleasant too.
Wouldn't this be counter intuitive for Microsoft? They have WPF, SQL Server, ASP.NET, C#, etc on Windows and provide products and services built around that. If Python got popular on Windows because it was bundled with the OS, then devs would use less MS stuff, so less revenue. However, I would like to see python3, gtk+ / qt and c compilers bundled with the OS. (Wishful thinking LOL). Because installing these on Windows currently is a pain! You got to install Cygwin. Then Msys. And these are different depending on if you decide to use Python2 or 3. And these are hosted on SourceForge. Then you got to use the package manager to install the package. Sometimes this means using the command line and Pacman. And compiling requires GCC, etc. Not fun.
Flask and django are the backend of the website. Html /css /Javascript are used for the front end. They are used in tandem 
Adding to the above-- Django and web2py have database layers. Flask you have to make your own. Bottle I don't know.
Thanks!
https://xkcd.com/927/
*sigh.*. sorry 
I've only used anaconda, but I have a friend who used canopy. Both of us have been doing computational fluid mechanics and are both fairly new to Python (I didn't know anything about it prior to September, and he's really only used it since May). That said, in generally I seem to have an easier time navigating and learning anaconda then he does with canopy. It's layout is cleaner and more intuitive, and conda makes managing it super easy, even with my limited skills in bash.
Seriously, all the post n blog too impressed me. Will try this one too. .
Take [PCPartPicker](http://pcpartpicker.com/parts/partlist/). I read a comment from the author recently that it started as a Django learning attempt. The below is guess work on his implementation: You could think of the site as having three levels of programming, client side, server side and DB side. Client side will be your standard HTML/CSS/JS stuff. The vast majority of the logic of the site will be built in Django which would then hit the database through sqlalchemy or psycopg2 or some variant. In another example, Django doesn't display the credit card field on your sites checkout, that's the clients job. Nor does it store the last 4 of the cc for your customer service to use in customer contact, that's the DBs job. Django would have the API for your payment company, and would hold the functions necessary to insure the veracity of that credit card transaction. Django would define the database transaction on your own db to ensure that items are reserved and accounting is handled when authorize.net or whoever gives you a thumbs up or down on the card.
&gt; Can someone explain the ruby results to me? Are you looking at some link not in the OP?
&gt; Also, on an unrelated tangent: also consider Pyramid. Has Pyramid been updated in a while? Last I checked, development seemed to have slowed considerable.
https://www.reddit.com/r/programming/comments/3y6tly/the_top_starred_repositories_in_github_have_been/
[I answered this](https://www.reddit.com/r/compsci/comments/3xpvwt/how_do_you_properly_set_up_an_environment_that/cy6pxff) on the deleted question in /r/compsci- did that help?
Ah, very nice. 
As a beginner I tred using django and personally found it overly cumbersome (for a beginner). I then tried flask and found it easier but somewhat lightweight and not a production web server. I ended up using flask and Apache/SSL. Linking them was very simple and I had the makings of a production worthy setup. http://pastebin.com/48G4MS8E
Interesting question! When starting the project, I wasn't yet aware of Swagger, so I obviously didn't consider it at that point. Now, obviously, I should take a look at that spec to determine if I should adopt that instead of the format I've arrived at (which is also still in progress). Subjectively, and obviously I'm speaking from a biased position, one reason I see off the bat to not immediately jump on the Swagger bandwagon is actually one of the main reasons I started this project in the first place- endpoints in the Swagger spec seem to be treated as "first class citizens", when really, what we actually want to be working with is the object that's being accessed by the API, which could exist across many different endpoints (or, in the case of APIs like Wikipedia or SugarCRM, all objects and actions might exist on a single endpoint, which could obviously get to be a huge pain). In other words, at first glance, Swagger produces an entirely accurate and (seemingly) comprehensive picture of what an endpoint looks like and what arguments it takes, but the philosophy of Beekeeper is slightly to the left of that; we want to abstract the endpoint away and instead look at the objects in the system and what we can do with them. I definitely appreciate the question/comment; I'll be spending some more time with the Swagger spec over the next few days. Just on an initial readthrough, I can see that they dealt with a lot of the things I've thought about. Even if I don't decide to adopt it, I can still learn a lot from their work. 
&gt; I don't recommend it. At least, provide some rationale then.
I dont know about that. It might not be rails, but Django feels like Android/iOS development, and seems quite opinionated to me. "Put urls in this file. Register your databases in this part of this file, and model them like this. For every URL, you can point it to a view like this. For every view, you're probably going to want a template file. Set up your configuration stuff this way. This is where you put these files, and this is where you put those files, and assets should be here. Oh, and if you need to change any of this structure we've created for you, there's a very specific/non-intuitive way to do it which will probably require multiple trips to stack overflow." Etc. Obviously, everything isn't necessarily all that ironclad, but it feels very directed and methodical, especially when going through tutorials or learning. Flask is very laissez-faire by comparison. Import a few libraries, throw some decorators on a function or two, and voila! You can have something that receives a post request, does some SQL, and returns a json or html response in no time flat and however you please. Organization emerges as your app grows, and that freedom to choose when and how to logically organize your app is so much less self-consuming as a developer.
What you consider a fault is actually an advantage for some people. I have had to use Django in a project that didn't fit its datamodel and it was a painful experience. I then moved to CherryPy and could write every bit of the software in the right way. Granted it was more initial work but paid off largely on the long run. 
pass the -x tag to extract the audio only.
It's both. Like Flask, it is fairly minimal. It also includes a lot of things (such as templating) without requiring additional dependencies.
Just install wheel then you only have to build each package once
Looking at the commits on GitHub Pyramid looks active to me with a beta for a new version out there. Tell you the truth I wish more people would consider Pyramid over Flask. To me its seems to have a better future roadmap than Flask especially as Flask's creator has no interest in Python 3 whilst Pyramid was funded by the PSF to add python 3 support.
If you can write software solutions to a specific problem type then you can sell the solution on https://algorithmia.com/ without writing a whole program. Its an interesting way to make money programming. Sounds like you are on your way. Good luck!
&gt; Creating and selling software with Python. Is this a viable business strategy? Yes, it definitely is! However, here are some things to keep in mind when going this route: **Version** Use Python 3. This should be "obvious," but many tutorials out there are still aimed at Python 2. Additionally, many people on here still prefer Python 2. However, the reality is that support for Python 2 **officially** ends in 2020. So unless you need a module that is only supported on version 2, then use Python 3. **Graphical User Interface** Python comes with a standard GUI toolkit called tkinter, [TkDocs](http://www.tkdocs.com/tutorial/index.html) is a good tutorial. Make sure to set "Python" as the language on that website as the examples there can be viewed in multiple languages. PyQT and PySide are two other GUI toolkits that support Python 3. **Distribution** Use tools like [cx_Freeze](http://cx-freeze.sourceforge.net/) and [PyInstaller](http://www.pyinstaller.org/) to create frozen/compiled executables for your programs. The advantage to this is that your users will not have to manually install Python themselves in order to use your applications.
Looks interesting, I've bookmarked it as a possibility. 
Fabric plus SCP are a nice simple combo that should get the jobe done.
Essentially, the html css js is loaded on the user's computer when they visit your site from their browser. The python server runs on your computer. The site on their computer communicates to your server what the user is doing, and then 'serves' stuff based on that communication. Understand?
i thought that ipython notebooks allow you to write uncommented text outside of the code to be executed for better readability?
I developed some projects with qpython, you can see them on my blog http://latanadelgurzo.blogspot.it/
&gt; manually copies any binaries that aren't very version tracker friendly and shouldn't be in the repository anyway What type of binaries are we talking about here, and why aren't they already on the destination/prod system? &gt; Then, I manually change the commited config file to alter any file paths etc. Since you don't have root on the destination (more powerful) machine, I'd assume you're using local (in homedir) config files, such as /home/onewugtwowugs/.myapp.conf, or something. Why would you be version controlling the config file anyway? In a configuration management (or system administration) standpoint it makes sense, but not if you're moving the app between different systems with different setups, and the file needs to change. &gt; I looked into Docker which seems to solve some of the problems I don't like how people default to docker because managing app deployments is hard. I could see using Docker if you needed an entirely different userland than what you are getting, but for cases where you need to alter config files, grab a few binaries, etc it seems overkill. The suggestion to look at using makefile and autoconf seems like a good idea here. But, I'm going to go out on a limb here and guess you care about the science experiments and the results more than application deployment practices, so just find a healthy common ground with your system guys that produces the least amount of work for everyone.
But then you all would know how fast I drink.... *Insert Confession Bear*.
Because Kivy is extremely unwieldy at best. From what I've read, Jython isn't possible on Android because of the way Dalvik/ART works. I think the best you're going to get is through SL4A, which isn't exactly ideal, but will give you a Python interpreter as you're used to on the desktop. 
The reality is that there are some well known disadvantages of using kivy (sometimes slow startup time, large APKs, non-native widgets...), and that for many people these are important. There's also the fact that, although it does have a fairly active community, there's far less discussion about it online than for native development or some other frameworks. On the other hand, one reason you see 'just use Kivy' is that it is mostly *the* choice for Python apps on Android, I think it's much more broadly capable for app development than anything else currently available. Mostly it's up to you whether the disadvantages are a problem - some people don't mind and even use Kivy commercially, including several of the core developers, but as you've seen other people consider the idea ridiculous. I'm a Kivy core developer myself (in fact, probably the main developer of [python-for-android](https://github.com/kivy/python-for-android) at the moment), and personally I mostly use it for the fun and convenience of bringing smaller python scripts and applications to android, in ways that would be much less convenient if I had to rewrite e.g. my scientific visualisations in Java. I think Kivy is very convenient and capable for this, and more broadly I've also been pushing python-for-android more towards being able to use other backends like Vispy or pysdl2. If I decided I wanted to make money on a productivity-type app I'd be more likely to look into java, as kivy's disadvantages are more important here, but on the other hand I'd certainly go with kivy for simpler 2d games or scientific applications for which I consider the standard disadvantages less important. Of course, I'm probably biased, there are many other good (but non-python) tools and frameworks for these things. I've recently seen some activity on some (in my opinion) very nice Kivy apps, particularly [kognitivo](https://play.google.com/store/apps/details?id=org.kognitivo.kognitivo&amp;hl=en_GB) and [barly](https://play.google.com/store/apps/details?id=org.topbanana.barly). These both demonstrate quite well what Kivy is capable of in ways that the normal tutorials and simple apps usually don't, e.g. taking the time to theme it more (this is always possible, just most people use the defaults). You might find them interesting examples.
Sort of an aside, but people make Django API driven apps with something else for the client.
I am definitely not a C expert. Most of it was using sublime's 'find in files' feature, combined with some knowledge of python. You should try it yourself :) Anyway, I think it would really help to watch the two YouTube videos I have mentioned in the post before diving into CPython.
This belongs in /r/learnpython Though I will say regex in python is not my favorite implementation of regex. It also sounds like you don't know what regex is, nor is your code actually using the module in your example. I'd suggest learning what regular expressions are before you start coding your assignment: http://www.regular-expressions.info/tutorial.html
You should start using from __future__ import print_function And use string formatting, instead of hard to read concatenation. 'Found {} corks'.format(len(corks)) Also removes the manual need to `str` something :-)
The problem with python is deployment. It's quite difficult to freeze something into a portable, easily-installable binary in all cases, and when you do it's easy to decompile it so your code can be copied or reverse engineered easily. Webapps are much easier in python (but that's not really what you asked). However, as well as algorithmia which was suggested by another poster, there's bountysource, where you can resolve issues on open-source projects for a small reward. Edit: a good intermediate between the expressiveness of python and the speed/ deployability of C is Java. It's very common in enterprise, Java 8 has some very modern language features, and while static typing and arbitrarily putting everything in classes are annoying and awkward, it's not too tricky and there's none of the memory management/ compiler optimisation nonsense that you get with C. 
&gt; setting up a django website requires jumping through a lot of hoops I could never understand this. Django already sets up everything for you, while when using Flask you have to find all the packages you need, figure out which are no longer supported, figure out a way to configure them without any conflicts etc. Also Flasks utilizes thread locals very much, which may lead to code that is hard to maintain.
Those apps are pretty much as complex as what I'd need at this stage. Really good examples. Can you elaborate on the "scientific applications" that you mentioned? It sounds like Python/Kivy is fine for smaller projects... Do you have any concrete guidelines for when a project is beyond the scope of what Kivy is capable of or practical for? 
Are you aware of (your own or from other devs) Android apps currently on the Play Store that use Python / Kivy? Just want to try out some apps to see how good the responsiveness is.
You* could deploy your application on a host or computer that is always on, e.g Google App Engine or your smartphone. 
Funny you should ask this. For this exact reason I am considering writing a framework for making apps. The idea is that one would write in Python and a declarative xml language (like c#'s xaml) and then you could transpile it to qml, which would then allow you to run on any platform Qt supports (Windows, Mac, Linux, Android, iOS, ?maybe even the web?). Very cross platform. I haven't gotten to writing it, but I plan on starting it soon.
Looks great! Too bad it's only for Python 2 though.
Well you have to set everything up the django way. For small projects this can take a while. Whereas if you are using flask you can quickly spin up a page without really doing anything. Personally, I prefer having more free reign
Would Kivy be a decent option to try making games? (I.e. not dependent on Native widgets) and could something written in kivy python be ported to ios also relatively easily?
im not a gpu/cpu expert, but afaik, anything that isn't unity or native android is slow as hell compared to those two. Unity, because they have partnerships setup to make sure their sdk properly utilizes the hardware of android or ios devices. However, if you're not looking for ultra speed stuff (like a candy crush game) then there's no problem with using other stuff.
I imported several helper functions from Flask-Security, and overrode many of the defaults. The main feature, however, is a route decorator that all API requests pass through that filters on group membership and roles/permissions, which are passed in via keyword arguments. Keeping things simple and centralized, and using imported components and needed was the key!
warehouse, the next gen pypi think from the pypa is using the beta pyramid version, if anyone wants to see what a modern well thought out pyramid project looks like.
See [a list of awesome python libs ](https://github.com/vinta/awesome-python) !
[requests](http://docs.python-requests.org/en/latest/) for http requests. this module should be taught as a case-study in good API design. pretty much everything in [itertools](https://docs.python.org/2/library/itertools.html) and [functools](https://docs.python.org/2/library/functools.html) is incredibly useful once you learn how to use them. makes for much more expressive code and easier use of functional style idioms. 
I made an Android app with Kivy, won an app of the month contest and they sent me a Kivy shirt. I guess that's a success story. 
Will do. :D
Well the entire Python standard library is excellent, but these are some highlights (in no particular order): * [re](https://docs.python.org/3/library/re.html) for regular expressions * [datetime](https://docs.python.org/3/library/datetime.html) and [calendar](https://docs.python.org/3/library/calendar.html) for manipulating times and dates * [enum](https://docs.python.org/3/library/enum.html) for creating useful enumerations * [getpass](https://docs.python.org/3/library/getpass.html) for securely requesting passwords from users via the command line * [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) for high-level concurrency, plus [threading](https://docs.python.org/3/library/threading.html) and [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) for lower-level interfaces * [asyncio](https://docs.python.org/3/library/asyncio.html) for asynchronous I/O and event loops * [argparse](https://docs.python.org/3/library/argparse.html) for writing command-line tools
It does. http://praw.readthedocs.org/en/stable/pages/code_overview.html
Easier yet, type python into the cmd prompt then drag the file into the cmd prompt. This will put the full path link in there. Then execute it.
Build your own? It will teach you more than learning another tool and it will do what you want it to exactly.
If it is simple use [Requests](http://docs.python-requests.org/en/latest/) and [Beautifulsoup](http://www.crummy.com/software/BeautifulSoup/), if it is difficult/many many pages use [Scrapy](http://scrapy.org/). If it requires logging in (not simple logging in as that can be done in requests) or Javascript use Selenium and [Beautifulsoup](http://www.crummy.com/software/BeautifulSoup/). P.S. if you end up needing to use Selenium you can turn off all images, CSS and other things to speed it up.
By the way, pmotw is a site that I found invaluable for learning the standard library. https://pymotw.com/2/genindex.html
I'm a skeptic, so to me the positive claim "requests is an awesome API," has the burden of proof -- not me questioning it. All I've seen is that the package has excellent marketing and PR and there's a dogma in the Python community that it's a good API and it's well written. I'm open to having my mind changed. But mostly I just don't like how it bundles packages.
ah okay I guess I missed that. Thanks :)
&gt; has the burden of proof thats absurd. I expressed an opinion about a matter of personal taste. I don't have to provide proof for my taste to you or anyone. I like it. A lot of people seem to feel the same way. meanwhile, you have made a critical remark with no apparent cause. you object to "PR and marketing"? what does that even mean? you trying to be edgy or something?
Scrapy just released their v1.0.3 update.
I'm using Kivy for business application development, ERP software to be more precise. I use Go for writing the backend and Kivy for the mobile apps (and desktop, although it's a temporary measure until a web frontend is done, testament to Kivy's flexibility that this is possible). The one thing that made me want to stay off Kivy is the lack of good-looking widgets for mobile interfaces, since the default is a bit ugly IMO. To solve that, a swedish developer I met on Kivy's IRC and I have been building Material Design widgets for use with Kivy. The repo is over [here](https://github.com/kivymd/kivymd) if you want to take a look. As for start-up times, yes, they're a problem. But if I understood correctly, the new port to SDL2 should help with that.
Because if someone wants to do something awesome with Python on Android and/or cross-platform, they are likely to start with Kivy. Or make a notebook that runs on whatever runs iPython notebook format on Android, i.e. with narrow column margins for the graphs, or at least graphs that render well in a narrow format.
That's a fair point, though you can [change that default by including the `certifi`package](http://docs.python-requests.org/en/latest/user/advanced/#ca-certificates) (which they should probably just depend on if they want to do it this way).
Awesome work. Looks real simple to use too. I was looking to do something similar
I've done all my scraping using requests and beautiful soup 4. Never needed Scrapy or Selenium. Scrapy is good if you need to do it on a larger scale and want to manage multiple scrapers that run for a logn time. Selenium is good if you have to interact with JavaScript but I cannot comment on how easy it is to use. That's one thing I haven't had a need for yet. Even sites that make use of heavy ajax can easily be faked just by capturing the JSON that is sent behind the scenes and replaying that using requests, but that a takes a little reverse engineering.
Auth is using HTTP Basic, which accepts Username+Password [(by design)](https://en.m.wikipedia.org/wiki/Basic_access_authentication).
I came here to suggest arrow as well. Great library that makes life much easier for anyone doing lots of calculations with datetime stuff. The standard libraries aren't bad, but arrow makes most things into a one liner.
Can I just say that I prototyped an arcade cabinet interface with Kivy and it was an absolute breeze? Loved it. I had to go in a different direction, but I'm pretty impressed by Kivy.
I'll take a crack at it.
It's not realistic to expect the same script to work on multiple sites, unless you work out a Python project design that would be abstracted enough to allow you to plug in various parsing definitions for each site you plan on scraping. To answer your bulleted questions, it's best to use BeautifulSoup over regular expressions. Below is some sample code to use as a reference. It grabs the item description, price and msrp. import requests import sys from bs4 import BeautifulSoup, Tag headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit 537.36 (KHTML, like Gecko) Chrome"} rootUrl = "http://www.zara.com/uk/en/sale/woman/dresses/view-all-c731533.html" reload(sys) sys.setdefaultencoding('utf8') session = requests.Session() req = session.get(rootUrl, headers=headers) soup = BeautifulSoup(req.text, 'html.parser') results = soup.findAll("div", {"class": "product-info"}) for result in results: itemName = None itemPrice = None itemMSRP = None for item in result.contents: if not isinstance(item, Tag): continue if item["class"][0] == "name" and item["class"][1] == "item": itemName = item.get_text() elif item["class"][0] == "price": for price in item.contents: if not isinstance(price, Tag): continue if price["class"][0] == "sale": itemPrice = price["data-ecirp"].replace(" ", " ") elif price["class"][0] == "crossOut": itemMSRP = price["data-ecirp"].replace(" ", " ") print "{} {} (MSRP {})".format(itemName, itemPrice, itemMSRP)
Cool. Feel free to Pm/file issue/whatever if you have ideas, etc.
I'm fairly sure some of FB is written in React Native. 
Oh yea, the website, but you dont see them putting all their trust into it, they still hire android devs to make apps like riff. I think the point im trying to make is, if you have the money to get the best, native is the way to go, because it utilizes the hardware the best
In that case use that SO link and use pickle.dumps instead of their datetime if statement. then you would have json that could be loaded up, but would need something to unpickle the values, perhaps prepend something to dumps.
from a specific section of awesome-python: &gt; **Functional Programming** &gt; *Functional Programming with Python.* &gt; * [CyToolz](https://github.com/pytoolz/cytoolz/) - Cython implementation of Toolz: High performance functional utilities. * [fn.py](https://github.com/kachayev/fn.py) - Functional programming in Python: implementation of missing features to enjoy FP. * [funcy](https://github.com/Suor/funcy) - A fancy and practical functional tools. * [Toolz](https://github.com/pytoolz/toolz) - A collection of functional utilities for iterators, functions, and dictionaries. and I'd also like to add on https://pypi.python.org/pypi/whatever All of that makes python so much nicer and more usable for mucking around with data - - - In addition, [pathlib](https://docs.python.org/3/library/pathlib.html) is really nice file = Path(__file__).with_name('1.txt').open().read() # open a script-local file and read it
If it's numpy, just use np.savetxt()
Why not? Let's go!
I'm in
The one in the standard library is a good bet: https://docs.python.org/2/library/queue.html
and printing in colour!!
What's wrong with package bundling? Lots of third party libs do that. Requests is a wrapper around urllib3. You can choose to use regular urllib3 if you want. They could make it a dependency rather than bundle it, but how does that affect its API, or even affect end users at all?
I tried to find a good answer for you, but I came up empty. It *does* strike me as kind of strange that the module includes IntEnum and not an equivalent for string. That said, it is extremely easy to create derived enumerations as detailed [here](https://docs.python.org/3/library/enum.html#derived-enumerations). The provided IntEnum class is implemented in only two lines of code: class IntEnum(int, Enum): pass If I had to guess I'd say they included IntEnum because programmers coming from C-like languages are used to enums being wrappers around integers. If you want to create your own StrEnum base class, it's as simple as class StrEnum(str, Enum): pass Same goes for enums derived from any other type; just include the desired mix-in type before Enum in the list of bases and you're good to go.
I hadn't heard of arrow until your comment and I gotta say, it looks awesome! Thanks for the tip.
Been using requests in a new scraper that I'm building, and it's pretty neat! Might toy with grequests to make async http requests as well; got any experience with that offshoot? 
+1, this library is supremely useful and I love the syntactic sugar it provides for calling external binaries.
In Python; fp = webdriver.FirefoxProfile() fp.set_preference('permissions.default.stylesheet', 2) fp.set_preference('permissions.default.image', 2) driver = webdriver.Firefox(firefox_profile=fp) I normally specify a Firefox profile that I have already created that has Memory Fox if it running for a long period of time and I also do other things here is the function I use to open the browser in one of my programs; def open_browser(): "Open the browser" # Use premade and prelogged in profile fp = webdriver.FirefoxProfile(r'PROFILE PATH') # Disable images fp.set_preference('permissions.default.image', 2) # Disable CSS fp.set_preference('permissions.default.stylesheet', 2) # Disable spellcheck fp.set_preference('layout.spellcheckDefault', 0) fp.set_preference('extensions.spellcheck.inline.max-misspellings', 0) # Reduce number of pages in RAM fp.set_preference('browser.sessionhistory.max_entries', 3) # Disabling javascript may mess up some stuff be careful if # copy pasting this function fp.set_preference('javascript.enabled', 'false') # Avoid timeouts fp.set_preference("http.response.timeout", 60) fp.set_preference("dom.max_script_run_time", 60) driver = webdriver.Firefox(firefox_profile=fp) # Move the window to position x/y driver.set_window_position(-2000, 200) driver.set_window_size(300, 500) # Reduce time to find elements from 30 seconds to 5 driver.implicitly_wait(15) driver.set_page_load_timeout(30) # Return driver so it can be used return driver The last bit is basically opening the browser off screen, you do see a flash but I found no way to open it already minimised. I also atop Autoscroll, smooth scroll, check spelling (and much more) and limit the cache to 6MB cache
I have not used Mechanize, but I have used Selenium. In Selenium I was able to access forms several different ways. It's been a couple years, but IIRC, I think I was able to use XPATH or XML or the HTML. Maybe check the Mechanize docs to see if you can do it any other way. Otherwise, maybe you can right click in chrome to Inspect Element of the instagram login form and see what they're doing behind the scene there. Hope that could help a little, good luck. 
The standard library has a few different ones, which will give you almost all you need. And almost forgot, deque: https://docs.python.org/3.4/library/collections.html#collections.deque
Link?
So true. 
If you're going to make game bots, be warned that this is probably against the terms of service, so cover your tracks/hold the user accountable in case you get banned.
Isn't this just a try: json dump except: pickle dump four-line snippet?
Opencv is a fun exercise in watching an installer waste 15 hours of your life.
how about awesome-python https://github.com/vinta/awesome-python
[Image](http://imgs.xkcd.com/comics/automation.png) **Title:** Automation **Title-text:** 'Automating' comes from the roots 'auto-' meaning 'self-', and 'mating', meaning 'screwing'. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1319#Explanation) **Stats:** This comic has been referenced 267 times, representing 0.2851% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cydoyfq)
really want this kind lib, but nothing acceptable
https://play.google.com/store/apps/details?id=org.andriapps.pithon
*Buuuuuuuurn*
Your best bet is to take a look at [Python cookiecutters](https://github.com/audreyr/cookiecutter#python). In particular, check out [audrey's setup.py](https://github.com/audreyr/cookiecutter-pypackage/blob/master/%7B%7Bcookiecutter.project_slug%7D%7D/setup.py)
Looked at Arrow and saw that it mentioned ISO8601. But very disappointed in the parsing. First two things I tried it failed miserably at: In [2]: arrow.get('2001-01-01') Out[2]: &lt;Arrow [2001-01-01T00:00:00+00:00]&gt; Parsing a date should yield a date, not a datetime. In [3]: arrow.get('2001W02-01') Out[3]: &lt;Arrow [2001-02-01T00:00:00+00:00]&gt; That string is "monday, the second week of 2001", but it just happily mis-parses it as the first of february. Sadface.
Scrapy also supports CSS selectors which many web developers are already familiar with (or want ot get familiar with, to become better at CSS). That's totally fine to use Scrapy and BS together though.
aiohttp is pretty awesome as well.
As a network engineer myself, the Python modules I use the most are: * [re](https://docs.python.org/2/library/re.html) - for matching regular expressions. Note: Not a Python module, but an absolute must when debugging regex: https://regex101.com/ * [requests](http://docs.python-requests.org/en/latest/) - for restful APIs typically. * [pexpect](https://pexpect.readthedocs.org/en/stable/) - for interactive CLI scraping. 
You want https://packaging.python.org/en/latest/distributing/#setup-py. The example file https://github.com/pypa/sampleproject/blob/master/setup.py should provide you a template to work on.
What's wrong with just running `pacman -S opencv` It's in the repository on my system. 
Must depend on your background (*nix cmd line, vim) and what you are developing. I certainly use them daily (in code). I use them every couple minutes as "developer tool". I agree, how can you not know regex? It's like not knowing abstract data structures, or not knowing how to use editor/IDE.
Look at click http://click.pocoo.org/ 
Pip is a hack, IMO. Packages should be managed by the system package manager, not some external one. 
I prefer [click](http://click.pocoo.org/5/). I really don't like code in comments and python is expressive enough where you really shouldn't need it. 
For manipulating fs paths I've been using and appreciating path.py for several years now. https://github.com/jaraco/path.py
I have a template that I use to bootstrap a setup.py file based on the link that /u/reubano gives. I also rather enjoy [flit](https://flit.readthedocs.org/en/latest/) as an alternative to using setuptools.
You're likely using python 2, where `print` is not a function but a statement. Using it inside a `lambda` is like trying to use a `for` loop, it's not gonna work. In python 3 where `print` is indeed a function (or alternatively writing `from __future__ import print_function` in python2) it should work fine.
holy crap, you're a savior!
Why would you ever want to do that? if you want a function that takes a function which prints, just provide print. Else make a lambda that handles the **simple** logic and call print afterwards
One common use for concurrency I've had is network requests. Say I want to query several dozen remote computers and wait for all the results to come back simultaneously.
Xpath is easy, it just takes practice.
Good recommendation, I had forgotten about Nuitka. For anyone else reading this, Nuitka can still be decompiled (as pretty much anything can if it's on a user's computer), but it would be a lot harder to do than decompiling cx_Freeze and PyInstaller.
I use [lxml](http://lxml.de/) and love it.
Since i'm a data scientist : pandas, numpy, scipy, requests, itertools, functools, csv, re, matplotlib
I'd just stick with plain setuptools. You don't need requirements.txt in your python package
The second parsing example I've not seen, you should contribute if you have the time! Regarding the date vs datetime return, you should use the [`date()` method](http://crsmithdev.com/arrow/#arrow.arrow.Arrow.date) to get the date object.
If you're referring to just Basic Authentication then you'll want to make sure you follow these [guidelines](https://en.wikipedia.org/wiki/Basic_access_authentication) and make sure you that have this header in every HTTP request your script is sending out. The mitmproxy example I showed you is basically the same thing as the link above, showing you how to make sure your requests are authenticating into the proxy.
One reason might be the lack of use cases for a StrEnum in the code that implements the standard library. In what scenario are you imagining using it, specifically?
You can customize the authentication provider, see [here](http://docs.python-requests.org/en/latest/user/authentication/).
ok yea nvm, that makes sense lol :P
IO (network, disk, GUIs, etc) 
That's what drew me to Kivy originally: audiostream support.
I was just confronting this question at work this past week. Where do dependencies go? `setup.py`, `requirements.txt`, both? I realized that I followed your advice here with a library I was working on, but it had been done almost unconsciously. I wasn't sure what the recommended practice for this was or where to find out. What is your source for this convention? The requests library? I'd like to share it with my fellow developers.
Im going to be following this project! It seems great, and Ill definately be including it in my current project! :)
As a core developer, perhaps you could take the time to fix the getting started tutorial. I just went through with my son and it errors. Details are in the [issue](https://github.com/kivy/kivy/issues/3876) I raised over on Github
For all new projects I started to use [d2to1](https://pypi.python.org/pypi/d2to1). And here is example of setup.py with d2to1: https://github.com/django-haystack/celery-haystack/blob/develop/setup.py The idea to move everything from setup.py to setup.cfg: https://github.com/django-haystack/celery-haystack/blob/develop/setup.cfg
Hasn't been mentioned here before, but for retrying a method till it passes or till you deem it so is the [retrying](https://pypi.python.org/pypi/retrying) library. Examples are retrying on a url timeout with the requests library that has been mentioned here. 
**print("Your name is ", name)** should work edit: make sure you put quotation marks (") around Tom.
Thank you!
Pip install opencv, from inside a virtualenv, on an Ubuntu 14.04 LTS VM, hardly an esoteric setup.
This is exactly the answer I was looking for. Thank you for clarifying the difference for dependencies between setup and requirements!
[reddit_silver.jpg](http://imgur.com/vRk8x8W)
&gt;Nuitka can still be decompiled ... but it would be a lot harder to do than decompiling cx_Freeze and PyInstaller. Yeah, that is true. But it would probably be about as hard as decompiling C++ generated exe, so...
I like Plumbum, but I'd really like the ability to define commands in Python and then stick them into the pipeline. For example, sometimes I want to replace grep with something that uses Python-native regexps. Or maybe I want to filter on filenames that are this big or this old. Unless that's been added recently. It's been a while since I've used it...
https://caremad.io/2013/07/setup-vs-requirement/
A good read: http://blog.ionelmc.ro/2014/05/25/python-packaging/ Also check the other posts tagged "packaging".
Hmm. Perhaps if you created a class that extends `plumbum.commands.BaseCommand`, and then override the run() function? Seems like that might be enough to hook into the rest of the Plumbum functionality.
I guess we are on our own here. I've discovered that conda sets up a bunch of symlinks when cloning an environment. This is good news, as it tempers my concerns regarding the duplication of data. How much is symlinked is still not clear to me. You might try doing a ls -lR /path/to/folder | grep ^l on one of your ~/.conda/envs/ directories to see this. Optimistically, I'd like to think these symlinks will keep the cloned env on the global upgrade path, but I have yet to test this. I'll let you know what I find out.
If your goal is to get everyone to switch from 2.7 to 3, then anything you do to help support ongoing use of 2.7 just prolongs its inevitable death and increases the chances that it will take 3 down with it, IMO. Honestly I'm not sure what your solution accomplishes that virtualenvs/conda don't. Can you expand on that? And how is it significantly different that using a shebang line on a properly configured system? I think this comment is more confrontational than I intend, so sorry about that. I would like to hear your thoughts.
The problem with 3 adoption is not that people don't have it installed, it's translating the source. This does nothing to help or motivate people to do that. 
As usual, the standard lib provides. I didn't realize it was thread-safe, though, thanks!
Just a heads up!! You can tell pycharm which python interpreter to use for a given project. Likely your system has python 2.7 installed by default. You may have also installed a python 3 distribution at some point. PyCharm may be defaulting to python 2.7 but you can set the interpreter you want to use in the settings. So for different projects in pycharm you can use different interpreters or different virtual environments which each have their own set of libraries associated with them.
Someone made https://github.com/dddomodossola/remi, which might be doing something very similar.
Well, the fact is, there is no *one single tool called Python*. It's two different interpreters with two kind-of completely different standard libraries. Even if there is only one interpreter that knows both dialects, you'd still have to ship it with *both* standard libraries - which basically ends up being the same as if you'd just installed python2 and python3 separately, which - at least under linux - isn't a problem.
https://pypi.python.org/pypi/check-manifest is great for getting a handle of what is, and what is not included in the final package and offers suggestions. 
&gt; I might be working on a legacy code that should be working as 2.6 while another project on the same machine should be working as 3.5 by taking advantage of the latest features. So how many versions of Python should the `use xxx` support? You could just install all the different versions of Python, hopefully with a script that handles Python 2.4-3.5 (good luck on anything large) and run whatever Python you want. Python 2.4 is still being used. Shoot, I used it two weeks ago. It's not being maintained in anyway, so I backported docopt and pandas, which I need. The language changes and you need to accept that. Your code probably isn't going to work unless it's not doing much.
Thank you! I just started your book and this fits nicely!
&gt; The second parsing example I've not seen, you should contribute if you have the time! It's on the wikipedia page for ISO8601. &gt; Regarding the date vs datetime return, you should use the date() method to get the date object. That's icky. If you don't know what you're parsing, you should get the correct type back. If you DO know what you're parsing (say, a time) and then you get something that isn't valid (say a date) then that kind of approach will bring you a world of hurt. Data should be strongly typed when it can be.
Thank you!
You're awesome! - love, everyday casual programmer
To backward compatibily replace magic string arguments, the same way tuples were replaced with named tuples. For instance error handling schemes in encode/decode https://docs.python.org/2/library/codecs.html#codec-base-classes I'm not sure how many of these there are in the stdlib but I'm sure there are at least a couple. Plus many more in third party libraries. It could also be useful with for ideas and the new type annotations. It would also be nice if it was possible to initialize the StrEnum members with only thier name and not have to repeat each one twice.
Thank you! I already had plans to start your book mid/late January, and this is perfect timing for me.
Awesome! I'll give this a go!
What's wrong with # !/usr/bin/python27 
If the script is running, it doesn't matter.
Nothing wrong with it; and it's python2.7 by the way ;)
&gt; Also, what happens when you don't add a use line? Does it just crash? Nope; it defaults to the latest available by language release, be it 3.5, 4.7, and so on, unless you specify otherwise with your default configuration inside .pythonrc.
Why should the python developers be responsible for developers who use older versions of unsupported Python? Do we still hold MS responsible for bugs found in DOS? Do we expect bugs to be fixed in the VB6 runtime? Of course not, we expect people to either maintain their outdated build environment themselves or for them to upgrade to newer versions. I would say that COBOL and Fortran are special cases where the code can't be touched for security reasons, there are not likely to be any banks running their transaction systems in Python 1.0. Legacy code will always have issues, making the Python executable responsible for maintaining compatibility with every legacy feature would be a nightmare, and would lead to Python installations exploding in size. Just think of the massive amount of work that would be needed to have the python executable be capable of supporting every version of Python ever. There are probably hundreds of releases, if someone specifies that they need Python 2.2.4, how do you ensure that they get that version of Python? Does every Python version need to be installed when Python is? Instead, would a specific version get installed with a thin wrapper over it? How do you manage these different installs? Many tools install these in non-standard places (conda, virtualenv, etc), how do you ensure that this gets handled properly? This is not an easy or simple fix, and it makes much more sense to use secondary tools to ensure that you have the right version. Conda can do this, although they do not go much before 2.7, if at all. If it's too much work to activate the right conda environment before running your code, then make a script to automate it, shouldn't be too much work. Besides, this problem only exists because people do not take the time to upgrade legacy systems. I don't think that the Python devs should be wasting the majority of their time supporting a tiny portion of their user base that doesn't want to have to think about checking the versions themselves.
My linux machine supports both. Aliases are great. Shoot, my linux box supports `ptyhon`. Still, I'm a Windows kind of guy, so I don't add bash lines to the top of my scripts. It seems unnecessary.
That's why I suggested what I have suggested. I went to an interview for a Python position and the department would follow an old, legacy code and prefer stability (2.7) over fancy features (3.5); It's a banking system services and I understand their concerns. So, that's why I mentioned the concept of use built-in mechanism. This way the code should behave as you want it to behave; there's no need to have installed separate two or N-versions installed and use each version for every project separately. 
https://pypi.python.org/pypi/pbr
&gt;There should not be multiple version of Python language, but rather a single one that would let developers choose how their code should be interpreted, that's all. I think this is the issue right here with what you're saying. The difference between 2.7 and 3 is actually much larger than how the source is interpreted. While externally they are very similar, there are a lot of substantial differences underneath the hood that a change of interpreter does not fix.
&gt; Just think of the massive amount of work that would be needed to have the python executable be capable of supporting every version of Python ever. There are probably hundreds of releases, if someone specifies that they need Python 2.2.4, how do you ensure that they get that version of Python? What you say here does not make any logical sense, because it's not better than having multiple versions of Python installed on your system, whereas a single version would be able to support all you need. So, to give you an example, inside my /usr/lib/ I have the following: pymodules/ pyshared/ python2.6/ python2.7/ python3/ python3.4/ python3.5/ Is this chaos necessary? Seriously now mate...
Of course after I bought it during the day after thanksgiving day sale lol. Oh well! It's an awesome class and hopefully the creators appreciate it. 
Numpy pandas pytables
&gt; While externally they are very similar, there are a lot of substantial differences underneath the hood that a change of interpreter does not fix. So, indeed we are dealing with a serious issue here that Guido should either address with the introduction of 2.8 or Python2.7-NG that would play the role of a bridge to bring support a step closer to Python 3.x series; that's how I interpret your response.
As I've already said, check out conda. I don't have Python installed through my system anymore (on windows), I just have conda manage it for me. If I want to use Python 3.3, I can just do conda create -n py33_env python=3.3 activate py33_env and now the `python` executable and all appropriate environment variables point at this environment in my conda installation folder. It also has a ton of scientific libraries pre-compiled for you so that you don't need a complex build system set up no matter what system you're on. If I want it in 2.7, I just specify my python version as 2.7. I can switch between these sandboxed environments with a single command, and once I don't need it anymore I can just delete the environment. It works with pip and virtualenv still, if you need those. This prevents one version of Python breaking another version, you can export an environment with all dependencies (including pip installed dependencies) to a file that can be used to create an identical environment when distributing it to others, like a requirements.txt file on steroids. This means that if I need to pull up an old project, I just activate that environment and run the code. This has actually been a big deal to me, since in one case I was using a fast moving library that had API breaking changes between some releases, so being able to leave that environment completely separate from every other Python 2.7 environment I had was necessary. It goes beyond managing different Python versions and manages all dependencies.
I got my pal working there as an algorithm engineer, he says their policy on privacy and performance is really good. I'm thinking to try it some time. 
You know what, scratch that. Give me some script and I'll make it work somehow.
I've seen people use Pygame in non-game scripts to read keypresses. You can also use [curses](https://docs.python.org/2/howto/curses.html#user-input)
You put 2 types of framework in this question, full stack and micro framework Full Stack (Django and Web2py): Framework that comes with everything (theoretically) you'll need to develop your web project, ORM, form, template engine and pre defined architecture. Micro Framework (Bottle and Flask): Framework for software engineer, where you need to make the decision of software architecture and which library will be used (which form library, orm, template engine, form and etc, if necessary for your project), they come with the minimum necessary to develop a web application. Today I prefer to choose a micro framework, like the work of software architecture, and not always need all a full stack framework brings with it leave my slimmer design.
Python 2 or Python 3? I feel like people should distinguish between them at this point.
I would suggest [this script](http://raspberrypi.stackexchange.com/a/28306) as an example then.
Bought the book and signed up free the last time you offered it. Thanks for the awesome videos and prompt discussion responses. I now know how to web scrape a bit and have set up a laptop to run task scheduler on a batch file to pull fx rates every 5 mins :) Any plans on doing slightly more advanced stuff like simple data analysis and visualizations? I know there are other courses but I like that you keep it simple and relevant
Looks to be 3.
No, it's not going to upgrade packages for you, but it certainly makes it easy to switch between python versions to make sure it works on all of them before using conda to [build and upload packaged distributions](https://www.continuum.io/blog/developer-blog/conda-build-system-and-happy-holidays) for every version between 2.7 and 3.5 across 5 major platforms (win/linux 32/64 bit and osx 64 bit). In my opinion, that helps out with upgrading packages to 3.X about as much as a tool can.
It's an assertion of a negative claim. It requires that you know the definition of "awesome API" (whatever that may be), and that the properties of this API do not meet the definition. It's like the assertion "the car is not parked in the driveway." *Anyone making an assertion*, whether positive or negative, has a burden of proof. A negative claim can easily be proven (in these examples--by looking at the driveway, or by showing that at least one property required to be an "awesome API" is missing or that a property which is present is contradictory of a property of an "awesome API").
Remember to enable and distribute universal wheels
I think a lot of the criticism was leveled because of the perceived technical infeasibility and/or inefficacy of your proposed solution. I think we can all agree that it would be pretty nice if it could have been backwards compatible, but it just isn't. And frankly, anything that makes that less painful just encourages people to not port their code anyway, so I'm not sure I would support it. Anyway, story time, since I read some of your blog and it's relevant to your comment: I am fortunate enough to find myself working at a financial institution with zero Python codebase. When they brought me in as a (just barely not-junior) developer I found myself explaining the tools and technologies to the upper-level IT people, because nobody (well, not nobody, but few) above me understands how Python works. It's why I ended up delving into how the interpreter and language actually work even though I was trained as a mathematician and not a computer scientist. Long story short, I convinced them that it was less risky to build a new codebase in Python 3 than it was to build a new codebase in Python 2.7, because Python 2.7 is set to be deprecated and they are thankfully thinking long term. It's actually quite nice, because I can dictate a lot of my environment and tools to the people above me because I'm the one teaching them how to do it.
Have you raised issues on the [web2py Google Group](https://groups.google.com/forum/#!forum/web2py)? Generally support is excellent and bugs get fixed quickly. What problems have you had specifically?
I wish I could say the same. I'm unemployed since July and here, Cyprus companies are demanding NASA's knowledge and pay peanuts. If you don't know all the languages you can imagine and be a front-end guru, there's no way you will make it out there. Plus, they follow whatever is the latest trend; who's telling them to do so I have no idea. All I wish is to find a company that would invest on its personnel and think long-term ROI, not draining the heck out of their people's potential and then replace them like a pair of clean socks. That's just sad.
Thanks!
Python 3. Though it will mostly work with Python 2.7 as well. Whenever you get an unexpected error you should first check if it's a Python 2/3 issue though.
For smaller-scale or quick prototyping, your library's code might be more succinct - it would take more lines of code in RemI for the hello world and button increment examples. But of course, for now, RemI seems to be more powerful.
Thank you!
Good luck!
Did you get the chance to look at it?
Could you elaborate on what you mean? An example might help.
I think in general people would be more looking for this kind of solution: https://github.com/jlesquembre/autopilot 
Lets say we have 5 columns of data and all of them are of 'int64' data type but I want to convert the data type to 'category'. How do I do that? I've so far used Data_file['column_name']=Data_file['column_name'].astype('category') But this only changes one column. How do I convert all other columns without writing down one statement for each of the columns? 
Another important tip for dependencies (in any language, any project) is to explicitly nail down the exact version of each library you're using. Some libraries will deprecate functionality, change class hierarchies, even change interfaces between major versions. If such an upgrade happens and your requirements aren't pinned, your app stops working as designed. So instead of: install_requires=['requests'] use: install_requires=['requests==2.9.1']
Thank you very much! This is great.
I want to kiss you on the mouth.
I'm not that familiar with this aspect of pandas, and it doesn't seem like there's a dataframe-level call for this. Sounds like you could either do a for-loop, or an apply: df2 = df.apply( lambda column: column.astype('category'), axis=0 )
Well, I always use lxml but if I would want reliability and HTML generation I'd use BeautifulSoup instead. You use `lxml` because it is simply 10x faster than BeautifulSoup.
Except that there's an entirely new data type in 3. No one should be using python 2 anymore
Recommendation for sending notifications by email: use [yagmail](https://github.com/kootenpv/yagmail). Great for attachments, html, simple one liners etc.
Found the guy who doesn't maintain enterprise Python scripts 
Thanks!
Well a new issue is 3.5 vs 3.4, I've started using async/await and could see this being an issue when I blindly put `#!/usr/bin/env python3`. I very much prefer those to the `@asyncio.coroutine` and `yield from` of 3.4, not to mention percent formatting on bytearrays. Iirc there is a symlink for the minor version number, E.g. `#!/usr/bin/env python3.5` I love python and that they are both fixing errors and improving the language overall, but damn is it hard to share code sometimes!
Cool! I actually got it for free the first time around, I'm about halfway through! It is definitely the easiest way to go about learning a programming language. I actually bought a copy and gifted it to my bosses kids just because I felt like it was worth it! Hope you make some money off it!
I've heard about Beautiful Soup too! I'll look into it as I need to scrape XML for a future project as well, but I think I probably used the term 'scraper' unorthodoxly in my original comment in reference to my current project; I meant that I was hitting up JSON APIs like FourSquare or Instagram, and building a CLI to make it easy for cron jobs to run my modules depending on different needs. Doesn't seem like what Beautiful Soup is meant for exactly, If I understand it correctly...
Thank you kind human.
Hey Al, I want to thank you personally for creating this resource. I learned some basic python through three main routes: 1. Codecombat, just as an introduction and got up to the third level or so before it got too mathy and complicated. 2. Googling and reading the python 3 documentation while trying to make a cell phone app with Kivy. I failed but learned a lot. and 3. Reading your book, and that is where I really took off. I ended up making 5-6 fairly powerful text and number based programs after reading your book. They are bug free and rapidly do the jobs I need them to do. This is all with minimum effort. I had just completely quit video games and was looking for a fun hobby and starting reading your book and I was astonished at how fast I was able to progress. This is because you deploy a very simple kind of logic and once it is understood, it is very natural to execute. I plan on continuing on with studying your book thoroughly over the next year or so. I think there is enough in that to do most of what I need to do. I plan on learning how to create a GUI of many useful, personal programs that are going to help me personally, so I can just click on a button and start the program. I think there are enormous possibilities even with what is just in that book, and with some of the other programs you made like pyperclip. Even if it just for making a Facebook conversation more interesting or being able to quickly convey information that I repeatedly tell people all the time. Really it can help me become a more informative speaker that is getting very important information to people that is based on fact and science. And really this is just the beginning of what is possible. Truly incredible stuff man.
You likely don't have the path to the Python executable in your path. Your path is a variable that includes all the places that your command interpreter will "look for" an executable of that name. So if your python.exe is in C:\Python27\bin\python.exe that's what you would want there in your command line. Next, it doesn't know where Rbot.py is. Maybe it's not in your current working directory, I dunno. You can get around this problem by feeding it the full path to the Rbot.py file, remembering that if there's a space in that (like C:\Program Files\Some Directory, where there's a space between the words Program and Files) then you'll have to enclose the entire file path in double quotes (like "C:\Program Files\Some Directory\Rbot.py") because the command line thinks that a space means you're done typing the file's path out without the quotes. So, in recap, you would want something like "C:\Python27\bin\python.exe" "C:\Program Files\Some Directory\Rbot.py". Even if you don't need the quotes they might be helpful to avoid mishaps. Finally, this should be run from the cmd prompt directly, not from the Python REPL. The REPL is the prompt you get when you run python from the run command in Windows, and won't easily allow you to run a script, as it's meant for running snippets of Python interactively. 
Just a quick note. I did something very loosely related, and I think building the html with bootstrap tags will make it look much more 'professional' and 'user friendly'. Also it gives you the benefit of this being usable on any size device. Specific example of tempting python info into bootstrap templates: https://gist.github.com/imoran21/fe273628cd4409977bd9 Here is an example implementation i attempted (there are bugs, just a test) http://192.241.197.18/ Besides the above advice, thanks for sharing this is really interesting and I have learned from the comments above. 
Best way is to build a portfolio on GitHub. Start or join any open source project where you feel you can contribute your technical and/or functional skills. 
Try something like this: for column in df: df[column] = df[column].astype('category') 
Well, why do *you* feel Python is a better choice? Let's start with that, and then we can expand on it.
Thank you for offering this! Would you recommend this class/book to someone looking to get into Data Science? I have started the class 'The complete Python Bootcamp' on UDEMY, but I am not sure if it is right for me. 
Wow, thanks, that's awesome to hear. I'm glad that my stuff has been useful. Really makes all the effort worth it. :) Thanks!
Wow, thanks! That's great to hear. :)
Hahaha. :)
I haven't read it, but I've noticed that [Data Science from Scratch](http://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/149190142X/) has been selling pretty well on Amazon. You might want to take a look.
 **Data Science from Scratch: First Principles with Python** |||| --:|:--|:-- Current|$33.99|Amazon (New) High|$33.99|Amazon (New) Low|$23.99|Amazon (New) |Average|$33.71|30 Day [Price History Chart and Sales Rank](http://i.imgur.com/eoqQaFN.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
My main reasons are: * Pandas. Easy way to import data from .csv files, manipulate data, write to databases etc. * Not strongly typed. * Easier to read/maintain. * Python is better for data analysis, so integrating the pipelining tasks and analysis tasks should be easier. 
There is no magic being performed by Unity that cannot be duplicated in Python in order to 'properly utilize the hardware' of mobile devices (or for that matter desktop devices). While GPU-programming is often not within the realm of the python programmer, there is no reason it cannot be. This really all comes down to efficient organization and submission of rendering data to the GPU. Unity does not have unique code running on android or ios compared to desktop platforms, GPUs have the same concerns everywhere. The big issue is that libraries like Pygame are not at all designed to properly make use of such hardware. The [kivent game engine](http://kivent.org) has been in continuous development for the last 3 years now to directly address this deficiency.
Hm, "Bootstrap tags" -- do you mean that I should use [`bootstrap-tags`](https://github.com/maxwells/bootstrap-tags), or just that I should consider using Bootstrap in the generated HTML?
Some things to think about: 1) How much code is there in the existing pipelines? 2) What is the timeline you have to complete the work? 3) How long do you expect the code to be useful? If the existing codebase is large or you do not have much time to complete the work it may not be the right choice to redo it; however, if the answers are in the other direction perhaps it is. Finally, if you do not expect to be using the pipelines for that long it also would seem to be a bad idea to invest so much in a full conversion, whereas if they are a longterm thing and you do have a compelling case for it being easier to maintain down the line perhaps it is. Also, consider the cost of either replacing yourself or hiring additional help in your area. It may be that there is a much steadier supply of Java developers that Python developers or that they are cheaper. There are always more concerns than just the purely technical which language is prettier for a task type deals. Your project must exist and be useful in an amount of time and any persuasive argument should cover practical concerns as well as theoretical.
the second one sorry. didnt know 'bootstrap-tags' is another thing
That wasn't there when he commented ;)
Thanks! :)
You mentioned it in your paragraphs, but it is worth having a separate numbered item: 4) Who will maintain the code?
That seems about right, maybe 30 or 40 hours if you include time to sit down and play around in the interactive shell and reading through the book (free on https://automatetheboringstuff.com )
:)
Oh yes. This course &amp; book are aimed at total beginners who have no programming experience. It basically just assumes you know how to do basic computer stuff like surf the web and copy files to a flash drive and copy &amp; paste and what not.
Sorry. That is what I meant.
Your mobile design has some issues on my nexus 9. Specifically, the page seems to display elements at about 80% page width.
I found something that looks even better: https://realpython.com/blog/python/face-recognition-with-python/ 25 lines of code. 
One thing I like to do is to separate out `requirements.txt` from `dev-requirements.txt`. I put packages needed for testing and developing the project into `dev-requirements.txt`, it usually looks something like this: -r requirements.txt coverage==4.0.3 flake8==2.5.1 manage.py==0.2.10 nose==1.3.7 pep8==1.5.7 `requirements.txt` then just needs packages required to *run* the project, e.g., requests==2.9.0 Then in `setup.py` I add the lines: ... setup( install_requires=requirements, tests_require=dev_requirements,` ...) Where `requirements` is the result of parsing `requirements.txt` and `dev_requirements` is the result of parsing `dev-requirements.txt`: ... setup( install_requires=['requests==2.9.0'], tests_require=['requests==2.9.0', 'coverage==4.0.3', 'flake8==2.5.1', ...],` ...) 
Really cool... TIL `setup_requires`!
Thanks for bringing that up. I haven't run into any issues so far, but I think I may need to integrate [`setup_requires`](https://pythonhosted.org/setuptools/setuptools.html). UPDATE: I've just published a new module on pypi [1] (which uses `pkutils` in its `setup.py`) and successfully installed it into a clean virtualenv. It worked with no problems :). [1] https://github.com/reubano/pygogo
Thanks a lot! 
It's in the making: https://github.com/jlesquembre/autopilot/issues/3
I don't know for sure, but *maybe* pygame?
You can do quite some neat things with the formatting mini-language that you can't easily do with %-formatting. E.g.: precision = 5 x = 12.3 y = 5 print("x={:.{precision}f}, y={:.{precision}f}".format(x, y, precision=precision)) 
It hard to switch when most of the Linux distributions are still loaded with 2.6. Much easier just to program in 2.X than working with multiple versions of Python.
There is no feeling like it. What feels really good is when you quit your highly paid job because your business is going well enough to pay for your food and rent.
That's not what I said. Speed is a nice benefit of lxml, but its ease of use in parsing complex HTML and XML reliably is why I use it. Consider for example, submitting an HTML form. With lxml, I can ask it for the forms in a document, find the one I want, modify the current values, and then submit the form, all while using lxml provided APIs. I don't have to care about form fields I don't know about, CSRF tokens, etc. This is crucial for reliable scraping. I have never been able to find this functionality in the BS documentation. Why do you consider BS to be better for reliability? As for generation, it's actually XML I've done mostly, and lxml has provided a nice pythonic API for it. I'll be honest I haven't used BS for this much. Is there a reason why you find it better for generation?
If your company has the kind of programmer who loves Python 3 but cannot possibly do any meaningful work on a Python 2 codebase, then you have a problem bigger than a large legacy codebase. Unlike classic ASP or Cobol, Python 2 has a decent successor, and porting your code to it, as painful as it may occasionally become, is entirely feasible, and nowhere near the kind of effort you need in order to rewrite a Cobol application in, say, Java. It's still a risk, but not a "OMG we're all doomed" kind of risk, more like a "bummer, we better start migrating stuff now, otherwise we might have to work some mild overtime a few months down the road".
Sounds like the kind of reasons a new developer will come up with. There are thousands of Java installations out there which churn insane amounts of data every day (and having worked on one of those). Easier to maintain is debatable and as a previous Java programmer I would like to disagree. Also as /u/JKovac points out, choosing a new language decision depends partly on the languages and largely on the other meta factors. As much as I love Python (using it everyday), I would be careful with pushing Python to replace Java.
I am not aware of.
You could use ```environ``` from the ```os``` module to retrieve the keys for use in the package like: from os import environ AWS_SECRET_KEY = environ["AWS_SECRET_KEY"] and retrieve your key that way (I don't quite know how AWS works, so I'm assuming there would be a secret key here). It would be a good idea as well to check the length of the key retrieved from environment variables, making sure it actually has a key, so ```if len(AWS_SECRET_KEY) == 0:``` In terms of security, I don't know if AWS can generate keys with restricted permissions, which might be a good idea in the event the keys for your application are compromised. Let me know if I can help in any other way, or you have any questions
&gt; Python 2 has a decent successor, and porting your code to it, as painful as it may occasionally become, is entirely feasible, and nowhere near the kind of effort you need in order to rewrite a Cobol application in, say, Java. Yes, this! It makes me laugh when I see people claiming that it's too hard to migrate their code from Python 2 to Python 3, so they're going to migrate it to a completely different language instead. Fair enough if you get something else out of it, say, a major performance increase, but if you re-write your Python app in another language just to avoid Python 3, well, that's like burning your entire house down and rebuilding it from scratch because you don't like the tiles in the bathroom. 
Who still uses 3.4?
Wouldn't trying to retrieve a nonexistent env var using os.environ result in an KeyError? In which case you could catch that error and handle it as you want. Otherwise I think os.environ.get returns None for a none existent key.
Thank you very much! 
Coming from a Ruby background myself so I know what you mean. This just happened to be something I looked at yesterday while porting some code :)
Not the person you're asking, but if they're like me, the saw it posted on here.
Agreed, if at all possible use IAM roles in place of keys, for other credentials just stick them in S3 buckets that are restricted via IAM roles. See previous poster's link above. However, this really only addresses the issue of secret storage, which generally speaking is only half the problem that OP is referring too? If you have keys in a .py config file, they're only exposed if someone can do evil things (RCE) to your app. If someone has RCE on your node, IAM roles (or anything else) will generally not help against that, as an attacker with RCE can simply repeat the process your app does to authenticate itself against other services. (There are possibly some powerfully tricky ways around this? Not certain.) So while, yes, IAM roles are great, the real trick is writing an app that doesn't have huge vulnerabilities like RCE.
You shouldn't pip freeze your requirements in a package you should use wide version ranges of only your direct dependencies
&gt;on windows/python3.4 but not for raspberrypi Just to check - you mention 3.4 on windows - is it possible the pi could be using python2? If so, truncating division might be related to your problem. On python3, dviding an integer by another integer will give a float, but on py2, it'll always give an integer, so 10/100 gives 0 rather than 0.1. If you do something like this in calculating your rgb values, you may end up with integer zeros for them all. To get the same behaviour in python2.7, you can put `from __future__ import division` at the top of your file, or else make sure that at least one of the values are already floats before dividing (ie. `10.0/100` or `float(x)/100` will give the right result).
Tip 1: Look on pypi (the central python package repo) for the top 10 downloads. Tip 2: Read the standard library docs. Tip 3: Look on github @ the top 10 projects similar to your idea. See what libs they have.
I think you need to consider the operational requirements, though. Sure Python has some great libraries, and there are some benefits to being a dynamic language (also drawbacks!) - but do you need a server running many threads/processes to handle incoming pipes -&gt; data munging -&gt; outgoing pipes? If yes, how would that be in Python verses Java? Guessing that you answer as I would, that would be a strong case for Java in my mind (even though I prefer to write python).
I'm betting this is the answer. Let me try it and I'll update. 
This looks like a great resource, thanks.
How quickly could you get the work done in Java? How quickly in Python? How much maintenance time will be required for a Java implementation? a Python implementation? If you need extra information to answer those questions satisfactorily, spend a little time building a prototype.
What made you come to Python ( seeing how people keep posting that they migrated to Go every few days)? First time i read about someone coming from Go to Python. 
Ya I found the problem was with the documentation for setup.py was a little bit of everywhere, I get so annoyed sometimes and just give up trying to have pip and proper packaging for a single module (I literally just got done trying), I could also just not be doing it right but I've looked through a lot of documentation don't you have to have a subdirectory holding your modules/packages in pip? I completely understand the concept of scripts, packages, and py_modules, what I don't understand is how to import multiple packages at once so I wouldn't have to go import module.module. Where the first module is really a package. 
Thanks for pointing that out. The Spark notebook is a little dated, I assembled it back when I first started using Spark with 1.2. I'll file an issue to refresh it in the near future. Our tools evolve so fast I find it's getting tougher to stay completely up-to-date :)
"we should re-write this in a different language" the words every boss wants to hear. /sarcasm
It seems there is one in vtk which has python bindings. http://www.vtk.org/Wiki/VTK/Examples/Python/IterativeClosestPoints
I was a Go user for a while, but started to lose faith in it for several reasons: dependency management - Go's way of getting dependencies is just awful to me, I think it's going a step backwards, in comparison to say, Pip / PyPI, which I find much more extensible and usable. The other factor of the top of my head, was Go's error handling, IIRC, it was mostly if err != nil, etc, which got rather repetitive after time, and I also got lazy with my code ;) I'm quite fond of Python at the moment, at first the indenting was alien to me, coming from languages like Go where you've got { and } to define blocks, but after a bit of tweaking of Emacs, it got better. I might have even more reasons, but I've got so much going at the moment, it's really just a skim of my reasons. :D
I will definitely do this.
Try Jython
You're welcome! :)
It was mostly for simplicity. I didn't want to go into choosing an editor and going into download &amp; install instructions for Windows/Mac/Linux, and then configuring the editor to work with Python. IDLE is a godsend in that regard. And it's also super simple: it doesn't have a ton of refactoring features &amp; project folders &amp; a billion menu options. So for programming education, it's a great tool and I really do think that any language that has a GUI toolkit in its standard library should also include a simple IDE like IDLE.
Thanks for sharing !!!
I'm asking, but any time I've needed to do similar, I've used a metaclass instead. What's the "pythonic" way?
What one thing? It's at least two: total disregard for proper typing and broken parsing. I guess it depends on your definition of "broken" I guess. I think it is in fact totally broken. I also think the very idea that you can just close your eyes and pretend that all time of days, dates, timestamps, etc are the same is naive in absurdum. Let me ask you this: would you trust a person that said that "midnight", "1970", "first of january" were all the same? :P
Gotcha! Yeah, Bootstrap would be an excellent addition. Thanks!
Yeah, the uppercase requirement for functions/etc from packages made little sense to me too. That's another thing I love about Python actually, being able to import certain things from a module instead of the whole thing. Moving to Python and discovering that feature was like bliss.
The author posted a link to r/Python a few months ago.
I don't. But that's how I feel. I'm not making a claim. ;) I also don't feel the tooth fairy exists, but I wouldn't make the claim that she doesn't exist. Instead I'd say a person claiming she does exists has the burden of proof.
You could try http://duktape.org/ Super easy to make a python module from it. I did this some time ago for testing (sorry I don't have the code anymore) and it took about 10 lines of C code (you could do it with Cython also) to get a working python module that you could just import duktape duktape.run("some js code...") https://docs.python.org/3.5/extending/extending.html static PyObject *spam_system(PyObject *self, PyObject *args) { const char *command; int sts; if (!PyArg_ParseTuple(args, "s", &amp;command)) return NULL; sts = system(command); return PyLong_FromLong(sts); } You can start by editing the example above to call `duk_eval_string` instead and then go from here.
Like I said, great that the stdlib is pretty good too. Use that. Thank god it's not like the JavaScript one...!
even top baseball fielders don't reach this far
:D
I'd definitely put `collections` over `itertools`. I don't use the latter on a daily basis, but there are so many helpful classes in `collections` that are overlooked and it's one of my most used modules 
xpath is literally just copy and pasting from Chrome's inspection. Ironically `BeautifulSoup` doesn't support xpath, so that shouldn't be a problem 
Ah! You ASSUMED. My feeling toward this particular negative claim does have a connection to reality. I don't say the negative claim is the case, but it's the lack convincing of evidence for the positive claim that have me *feeling* that the negative claim is the case. I would gladly accept convincing proof of the positive claim or proof of the negative claim to make me accept either.
If you ask for permission the answer will always be no as there's no incentive for the boss to take on risk. Python teaches us to do then ask for forgiveness (the whole deal with exceptions, rather than checking before hand). So just write to code on some weekend off. If it doesn't work, forget about it. If it does it work, then you show it. The question now becomes much easier for the boss. Obviously don't push it to live :-) I don't know why I have to say that. I probably shouldn't. Anyone who can't understand that probably shouldn't be employed as developer anyway so I'm protecting myself from having to use someone else's shit software by not mentioning it.
A lot of commercial software (including games) is done in Python. &gt; a program which stops users from losing their work or what they just typed should they accidentally press the back button on their browser In that specific case you want a Javascript plugin for the browser that disables the backspace key. I was going to write one for myself but then I noticed Firefox has a config setting for it and I don't like reinventing the wheel. There's probably quite a few plugins for this for Chrome already.
Java has a bad reputation in the gaming RPG community who are likely the OP's customers. "Game is java, avoid" is a popular meme there (check with Google). I don't know why. It makes no sense. I guess that as developers we probably have a better understanding of technology and no longer see Java as "the thing that fucked up my browser with a shitty web app back in 2005, and is actively trying sabotage the PC gaming community's $1000 gaming rigs by bringing us Console-quality graphics in Minecraft". (No I don't know where they get that crap from but Steam forums are full of it). BTW unless you obfuscate the code, Java's not exactly hard to reverse engineer either. Even the IDEs are starting to ship decompiliers as standard. They get a few variable names wrong, but it only took me one weekend to get a buildable version of the commercial Java game 'Wurm Unlimited'. I had not touched Java until that game came out (I knew OOP from C++ [not meaning i only know c++, but it was the first OOP language I was exposed to: I use Python these days], and Interfaces from Go) but I didn't even know how to tell it which main() function was the entry point), so a developer with more experience with the language will likely do it in a few hours. Considering this game is a full sandbox MMO, that's not saying much about the difficulty of decompilation. Granted, though, this was unobfuscated code: the developer/publisher of Wurm Unlimited say they deliberately made this decision to attract game modders. The irony of it is that most of us modders know any mods we make will be invalidated when the game updates, so we just use bytecode injection :-)
So you have no idea whether it is an awesome API, and contributed nothing by sharing your feelings that have no basis in reality. Let me also comment on the API: I like the color green.
The thing is "stuff-having-a-rep" is a valid "is-a" relationship in IT. 
There aren't really any "packages" for directly accessing model data. Do you already have direct access to model GRIB/netCDF output? Are you able to access it locally, or only remotely (possibly via THREDDS)? What are you going to be doing with the data - what sort of mapping/analysis? Answers to these questions will help us point you in the right direction with respect to what packages will be most useful for you. My GCM analysis stack uses the following two tools as its basic components: 1. [xray](http://xray.readthedocs.org/en/stable/) - A well-stocked, high-level netCDF reader and multi-dimensional extension to [pandas](http://pandas.pydata.org/pandas-docs/stable/). It has all sorts of nifty things in it, but I find it the most convenient package for writing expressive, semantic code which clearly documents how I manipulate and analyze model output. 2. [cartopy](http://scitools.org.uk/cartopy/docs/latest/) - Don't use basemap; use this instead. Cartopy is a mapping toolkit developed at the UK Met Office. It wraps powerful geospatial analysis libraries underneath the hood, and seamlessly links with numpy so that you can use it with xray. I've found it simpler to use than basemap and that it makes much nicer plots. Beyond this, we can probably recommend more specialized tools if you give us a more thorough use case you're envisioning.
Similarly, I wrote [Represent](http://pythonhosted.org/Represent/). There is [automatic generation](http://pythonhosted.org/Represent/usage/automatic/) and a [declarative method](http://pythonhosted.org/Represent/usage/helper/). It also supports `IPython.lib.pretty.pprint`
It looks like RStudio
I'd like to avoid that one
Web Scraping? PDF/Excel/Word files? EMAIL? GUI???? Far and beyond most Udemy Python Courses (which is how I learned the basics and OOP). I'm extremely excited to take this course.
 ImportError: No module named career
Yep, things like `Counter` or `defaultdict` I use in every other project. `deque` and `namedtuple` also come useful pretty often.
I want to say thank you. I work a lot with ArcGIS and have wanted to learn some python basics for a while, but never knew where to start. In the first lesson block I am starting to understand some of the key terms. Thanks so much for this. Once I get a bit more money, I plan to buy your books to further my knowledge as well as say thank you.
Thank you for the tips - Basically, the data will be used in exploration/analysis (hopefully) in two veins: * After-the-fact analysis of historical weather data and time-series energy data from the EIA API (found here: http://www.eia.gov/opendata/qb.cfm). This information is easily imported to a pandas dataframe and contains identifying geographic information (lat/lon, region, etc.). Ultimate aim is to eventually apply machine learning/classification for tests for predictive power, etc. (way down the road). * Forecasts and forward looking information (10 day forecasts/forward looking models like the one found here: http://www.ecmwf.int/en/forecasts/datasets/set-i or https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs) As far as access goes, I may be able to access the GRIB output for the ECMWF pending authorization, which from what I understand, is superior than the NOAA models. 
It really does; RStudio certainly set a good precedent for capturing code and visuals in a simple interface.
A lot of other languages it seems an error ends execution. Well, an exception can do that too but in learning other languages errors are to be avoided. They often follow the thought of LBYL. This is to make sure you don't do something you can't often because it will cause the program to break or need an error handled... which in the beginning is equivalent... So you check first or are taught too. It really is a dichotomous relationship. And the way python is written its easier to fix if it had a problem then trying to check if you are going to have a problem first. The whole thing around error handling is really in the source code. Like a multi-pronged chicken and egg question. Except the chickens are ways to best handle error states and the eggs are what's already built into the source code of the language. So since exceptions are really all that is used in python source code that is how you should handle error states. But in node.js they use promise or in c++ they check first because to do otherwise you might get lost in some deep dark whole. Basically they are all good ways to handle errors or prevent them, but you should follow the path of least resistance with the language you are using. 
Not well actually, I never liked the C/C++/Python approach which often feels like "if then" clauses. Actually sometimes they feel worst than checking a return value. I'm beginning to like the approach Swift and other modern languages take. The question is: are exceptions always the right answer. 
This discusses `long` types, but then uses python 3.5 which doesn't have them. Only python 2.x has them, python 3.x merges `int` and `long` into a single `int` type.
Thanks a lot! I'm starving for playtesters, so if you do use it even a little bit, it'd mean a lot to hear what you think of either the package or the documentation.
Have you tried https://code.google.com/p/pyv8/ ? It should do what you are trying to do. 
Actually, its looks like exactly what I need. I even found PyExecJS lib https://pypi.python.org/pypi/PyExecJS which can use It or anther available engine. So, now Im choosing between PyExecJS and PyV8. Is there any critical differences except engine choosing ? 
&gt; https://code.google.com/p/pyv8/ PyV8 is kind of outdated (and abandoned)... Last release Sep 2012. It might be worth doing some tests first to see if it still works for what you need before committing to it.
There's no way the boost in performance is worth the cost in readability for me.
Complete, more readable version, using a generator function: def collatz_series(n): if not isinstance(n, int): raise TypeError("n must be an integer") if not n &gt;= 1: raise ValueError("n must be &gt;= 1") while True: # as long as n is even, it is definitely &gt; 1 while n % 2 == 0: n //= 2 yield n if n == 1: break n = 3 * n + 1 yield a # n is now even, so no need to check before the first division by 2 n //= 2 yield n
Might as well... def collatz(n): return (n // 2) if (n % 2 == 0) else (3 * n + 1) (parenthesis not required, used to improve readability)
True. I think my problem is with his question rather than your answer. I prefer to ask "Is this efficient enough?"
Yeah totally valid, but I am not a fan of this style of expression, I think it is called ternary expression. Also I don't like `n&amp;2 == 0`, since I learnd that bools are a subclass of ints I try to avoid `==` when I am dealing with integers. Either I'd use `if n%2:` and swap the branches or I'd negate the comparision `if not n%2:`... Just my personal style conventions ;)
I think they are confused because it can have nothing in it. I feel like these were written by someone who learned python a year ago and now wants to be a data scientist.
Can you use apt inside a venv? I'm used to using pip, and it's important to sandbox all code properly.
Is adding `__slots__` necessary? Even if it is, the docs should mention this explicitly, since this changes the behavior of the class significantly.
Hi, what about virus scanners? I know that creating software in AutoIT gives a ton of false positives on VirusTotal.com even if it is the simplest of script. Is it the same for Python? Is the only answer to simply email the source code to all of these virus scanners or can I do anything else?
In my case, because the repr is then accessible to subclasses. I have about 20 classes in a big project, I just add this mixin to two classes, and then all subclasses will inherit it. Also, mixins are simpler than metaclasses and class decorators to defined.
&gt; 4) Is all the memory freed when Python exits? How the answer can be true, if an OS destroys the python process and releases the memory?
&gt; 17) You are given a list of N numbers. Create a single list comprehension in Python to create a new list that contains only those values which have even numbers from elements of the list at even indices. Aren't they missing a ":" in the solution, to get the step &gt; [x for x in list [: 2] if x%2 == 0]
I can see why this was posted here, kinda, but I think it's useless for Python enthusiasts, it's more interesting to Data Science enthusiasts. I think there should be a sub /r/ThingsInWhichPythonWasUsed
I suppose it really just depends on the virus scanner that your customer is using. I've never had an issue when a customer used my frozen/compiled scripts on Windows (or any other operating system for that matter). However, one thing that may help in this area (for Windows) is to [digitally sign](https://technet.microsoft.com/en-us/library/cc962053.aspx) your software. Though that is an option, it might be more practical just to let the customer know a false-positive is just a false-positive and that it can safely be ignored (if their virus scanner even generated one that is).
Sometimes checking the return is the right answer. But I find that because exceptions are loud and dangerous to execution, you're forced to deal with them. At work we had an issue with sporadically not being able to connect to salesforce, which is integral to our application. So I wrapped up our salesforce connector in a class that'll either connect to salesforce or create a NullSalesforce that raises an exception and then registered a handler with Django. The wrapper also maintains the connection details and can try to reauthenticate if asked. The original NotConnected is caught down by it's caller and if reauth fails, it's reraised out of the caller to Django, where a nice error message is presented apologizing for the issue instead of an unusable 500 INTERNAL SERVER ERROR.
It must just be an AutoIt thing then. A lot of malware is supposedly created in Autoit.
I read various sources, and after understanding how of all the pieces worked, thought things through myself and stuck to common conventions as much as possible. If you're writing a library, it will be installed using `pip` (or equivalent), which will use what is found in `setup.py`. So library dependencies need to be in `setup.py`. Also, in order to avoid version clashes, they need to be as permissive as possible regarding supported versions of these dependencies. Tools used only for development, such as tools used for testing (e.g. `unittest2`, `mock`, `py.test`, `tox`, `coverage`), need to be defined separately. Sometimes you'll want to separate tools needed just for testing from other development tools (e.g. if using Tox and/or TravisCI for testing). This is usually as complex as you'll need to go. It is possible to put development-only dependencies into a separate list in `setup.py`, but the common convention is to have these in `requirements.txt`. For a great, concise explanation, see [this post about Python repository structure](http://www.kennethreitz.org/repository-structure-and-python/) by Kenneth Reitz, author of the `requests` library.
Using [pkutils](https://github.com/reubano/pkutils) requirements = list(pkutils.parse_requirements('requirements.txt'))
For 10, I assume they're going for 'assignment, not evaluation'.
The problem with the decorator is that the added behavior doesn't get inherited in a subclass. Unless you do some slow and awful runtime introspection like reprmixin does.
The file needs to be called `__init__.py` to be recognised (double underscores) as the 'special' file that tells python 'this directory is a package', meaning its contents can be imported.
The only difference between PyExecJs and PyV8 when I used them was engine choosing with PyExecJs and sending anything Python (variables, classes, functions, etc) to JavaScript. There might be other differences but I didn't notice any. 
These are bad and you should feel bad. This is exactly the kind of list a smug self-sufficient grad student would come up with because he's proud he learned programming but he only knows the gotchas in Python.
Yeah they are!
If you're writing a library I would argue that you should always have a `__repr__` as it can make debugging much easier for your users.
Their provided answer is "A name error will occur when this statement is executed in Python." It's an awful question.
I used all of them, in Django and non-Django Python apps, and I finally settled on py.test. Its fixtures are really nice, and I love writing tests with `assert`.
Hi, i am 33. I am interested in coding since so many years but i only learned HTML so far because i get bored so easily, i believe this course will be the start of my adventure in python as it does not bore when it teaches. Thank you for this. 
Yes! Absolutely. Flask will likely be the easiest way to do this, there are dozens of tutorials so I won't repeat instructions here but you're totally on the mark. It sounds like you're implementing a JSON API more than a traditional templated web app, which is fine, but that's just one way to do it. If you're comfortable on the js side great
Question 2 and already the answer is SO WRONG!!! Well, most of the answer.
You don't say why though. Because you think it is inelegant? I think it's very elegant. Wrap it in a class if you don't like looking at it. Then you can do something like `result= JSExecuter.exec(my_js)` Though really a class might be overkill and a helper function is all you'd want.
Post this on stackoverflow. This isn't a q&amp;a forum.
`print 4`
That's not really recognition. It's "detecting" faces. Recognition is when you can distinguish your mom from other people in the world.(obligatory op mother reference 😃)
So presumably it's asking something like "are all destructors called on exit".
You need to open the files before trying to parse them: with open(filename, 'r') as f: parser = CiscoConfParse(f.readlines()) Link to CiscoConfParse object documentation: [CiscoConfParse](http://www.pennington.net/py/ciscoconfparse/api_CiscoConfParse.html)
One more "I know the right answer to things" post, a thousand more to come. 
Yeah, honestly I think that 99% of cases should be mixins, 0.9% should be class decorators, and 0.1% should be a metaclass. Class decorators solve the majority of cases where people want to use metaclasses while having the advantages of simplicity and explicitness. For example, if I were writing Django's ORM from scratch, models.Model would be a class decorator instead of a magical metaclass because using a metaclass to register means you have to jump through crazy hoops to monkeypatch at runtime.
so true
Pytests are indeed different, but in a good way IMO. There's also a Django version of Pytest which works very well. Pytest can also handle unittest tests (I'm not sure about nose tests), so your unittests tests are not wasted effort.
OP's account only has four posts, all linked to the same company. Obviously a spammer, and not a very good one. Reported to /r/spam.
Well, wait- you use classes when you want reusable encapsulated modules. You use inheritance to extend those capsules. You use metaclasses to generate those capsules, and you use decorators to inject functionality into those capsules without altering the underlying implementation. And that's a big part of why I don't use inheritance very much at all- composition provides similar functionality without the strong coupling inherent in inheritance. Now, I admit, this comes from a background using strongly-typed languages, but I see no reason why the thinking shouldn't apply to Python. I much prefer Ruby's approach to handling mixins, as module includes are fundamentally different from inheritance.
It is in very primary phase. There are lot other staffs are there to added. Your suggestion / criticism regarding contents, structure, style are highly welcome. Thanks.
The '**Exception handling is slow**' section makes no sense. The method `eggs` never has an exception, so the timing example is utterly pointless (proving exceptions aren't slow, yet not raising an exception?). For what it's worth, throwing an exception in the `eggs` method actually makes things almost ten times slower... %timeit eggs() 10000000 loops, best of 3: 86.8 ns per loop def eggs_with_exception(): try: return 2 / 0 except Exception: return 0 %timeit eggs_with_exception() 1000000 loops, best of 3: 816 ns per loop
Not exactly clear to me what this does. Does it just archive/serve the news? So it doesn't scrape them?
It scrapes, stores and serves raw text, thanks to gevent, goose-extractor, requests and flask-restful.
I tried to click the downvote on this, but couldn't. What gives? The list is subpar, maybe 3 of these are questions that you actually might get in an interview from a decent company. The rest are really not that important that the typical employee has to heart. ...also... this list was not 100 data science interview questions. It was 24. For that, you deserved the downvote that I apparently cannot give for some reason.
I am not sure what your are doing, I use Angularjs for my frontend and Python for my backend, I serve my Angularjs app with Nginx and python app with uwsgi, instructions for the same are on my project https://github.com/Leo-G/Flask-Scaffold, I also do headless testing with protractor, selenium and xvfb on Linux instructions for that are at https://github.com/Leo-G/Flask-Scaffold/wiki/Headless-Testing-Angularjs-apps-with-Protractor-and-Selenium-on-Ubuntu-14.04, Edit: Use API so you js can talk to python
I'm a programmer and these are bad. No rational programmer with any real computer science training touts language gotchas in an age where StackExchange exists. "I know a thing that can be searched on Google in 10 minutes. I'm better than you and if you don't memorize them for an interview, I'll never hire you."
Including the contents of `__init__.py`, where any symbols in that file are importable from the module.
Which is clearly wrong. It raises an `IncompatibleFruit` warning.
I would end the interview process if someone asked me these questions for a Data Science position. Questions like this are a huge red flag.
For number 9, aren't lists and dictionaries data structures? Because I was under the assumption data types were int, float, string, etc. and data structures were things like lists, trees, tuples, dicts, etc.
Why would using `assert` result in better failure message?
They *are* data structures, but `type` is a more general concept in python. Here's a list of the different types: https://docs.python.org/2/library/types.html
&gt; 18) Explain the usage of decorators. &gt; &gt; Decorators in Python are used to modify or inject code in functions or classes. Using decorators, you can wrap a class or function method call so that a piece of code can be executed before or after the execution of the original code. Decorators can be used to check for permissions, modify or track the arguments passed to a method, logging the calls to a specific method, etc. Saying that decorators "inject" code is pretty misleading. Also, I can't think of a good use case for decorating a class, if that's even possible. A decorator is just a function that takes a function as an argument, and _is typically used to_ assign the name of the original function to the newly wrapped one. edit: clarified explanation for accuracy
Absolutely. As Catholic3652 said, Flask is a great way to do it. Just another one to mention, Django and the Django Rest Framework make it pretty easy to create a REST JSON API. 
Do people actually complain about exceptions in python? The idea that, "exceptions are slow" isn't false. It's just irrelevant. If you're writing performant code, you don't use exceptions. If you're writing Python code, you are by definition not writing performant code. So the idea that "exceptions are slow" doesn't come into play.
What on earth does this have to do with data science? I would expect data science questions to discuss topics like statistics, visualization, etc.
Yeah there's a parser in there for regular pages though it will work better if you use RSS URLs.
That's better than no upgrade at all.
...are you banned from /r/Python? I got a temporary ban from /r/WTF (submitted a screenshot, whoops) and I couldn't vote.
Yeah, I used this way before for another reason and I gonna have this i if willnot find another way. But I just guess that I can miss something that already made sultions not, just becouse thats not my priority 
Ok, last time i checked pyexecjs, its csn use esmascript 6 powered by nodejs, so ill check some features in pyv8 and made my desition. Thx u 
py.test uses some magic so that you can write assert f() == g() + h() and if it fails, py.test will not only tell you that the assertion failed, but also what value f(), g() and h() have and what the value of `g() + h()` is. Same for things like `assert 'foo' in bar`, it will tell you the elements of `bar`. Basically, instead of unittest's specialized assertions, you simply always use `assert` in py.test. It's pretty neat.
actually, the decorator itself does no such assigning. it merely takes a function and returns another function/callable. the `@` notation is the syntactic sugar that does the actual assignment. (e.g., you're free to write `def f(): pass` and then `f = decorator(f)`)
It's entirely common practice. That's why services like easypost exist in the first place. I've worked at companies whose entire business is based around using third-party APIs in new and valuable ways. It helps you get something working much faster than if you had to reinvent the wheel. Having said that, if your software is important to you, and especially if you have customers you value -- make sure you have a plan B ready. Whether that's talking to the API provider and making sure you have a partnership agreement / you're on their mailing list and know how they announce updates / etc -- or starting to work on integrations in parallel in case they go down. I'd recommend supporting their business rather than trying to compete with it - but I'm biased because the last company I worked for was an API provider doing a similar thing in a different space, and our customers rarely understood quite how much work it took to keep all our different integrations up to date.
Was this done for just the fun of it or is it because you have not heard of snmp? I dont have metrics but I would bet that running snmp and putting your logic in a monitoring server would be a better design. 
I use easypost's free API in production and it's always been reliable. Using the actual shipping service: I would in a heartbeat. Not enough resources to implement. Their work is pretty solid.
Anybody care to comment on the difference between this, PySpyder and Rodeo? They all look very similar. 
Well thank you mate I will try it out very soon you really helped me 
&gt; I'd imagine their API is a more modern and consistent wrapping layer of all the individual carriers. Frankly, it's beautiful. It's as simple as this: import easypost easypost.api_key = 'my_key' tracker = easypost.Tracker.create(tracking_code='123456789', carrier="Fedex") print(tracker.status) &gt; It shouldn't be too bad to just ping individual carriers for tracking status Fedex offers a nice Python wrapper, but then it failed inexplicably on tracking numbers that work fine on the website... Rather than digging, I took the easy way out &gt; As they say, do what you do best, and buy the rest. Thanks :-p
Mostly for fun. But that's a good option to work into this also. I'm in a mixed environment of windows and linux, so we tend to stay away from snmp and use on-host checks. (Becaues windows sucks and its depreciating snmp) 
no
If you know what the size of the list is going to be, even approximately, then yes. But I don't believe that that is the case here.
I remember looking into it when I was trying to determine which runner to use, and it looked a little awkward to me. I also didn't love unittest (even though it is built in, which I usually try to default to if I can) because doing weird `self.assertEquals` and stuff didn't seem like it belonged as a method on a test class.
&gt; It helps you **get something working much faster than if you had to reinvent the wheel.** Folks who come out of business school spend a lot of time talking about *business cases*. There are all sorts of things that go into making a business case including: * what is the life cycle of the product? (will it be in the field for 20 years? Will it likely be gone in 6 months because the market place is changing rapidly?) For many jobs, time to market (getting that first working version in the field) is paramount. Likewise, if the expected lifetime of the product is short reinventing the wheel to avoid dependency risks increases the chance that you don't finish in time. 
&gt; I can't stand nose always finding tests I don't want to run. I use multiple test files in a sub-module and then I import that file from another larger test directory, so I can run whatever I want. I don't know if I follow. Do you mean you usually only run a subset of your full test suite at a time and choose which one by manually editing a file? Whenever I've wanted to run a limited number of my tests I would just execute nose with the name of the module(s), class(es), or even specific function(s).
Captain Sisko?
You shouldn't have to put Guido's personal profile up as that's irrelevant to the technical topics. I too thought that was pretty creepy.
Requiring 3.5 is just asking for trouble when 3.6 and subsequent versions get released though, right?
Are you using pip inside a virtualenv? If so, you can do `pip freeze &gt; requirements.txt` and it'll autogenerate the file including pinning version numbers. Conda probably offers something similar, though I'm unsure. Edit: completely misread your post. I'll keep mine because I think it's still good advice. Edit 2: I'm not a user, so I'm unsure, but setup.py potentially contains an issue. It runs `sys.version_info[2:] &lt; (2, 7)` to check python compatibility, but this should allow *any* Python 3 version in the door. There's stuff in 2.7 that's not in 3.0, 3.1 and probably 3.2. But I'm not able to comb through to see if those are used or not or if it's even actually a real issue.
Same information from any wikipedia page on any person (actually far less, it isn't detailing his parents/children after all!)
for a noob: whats the advantage over django?
If it'd documented, you've done right.
Ok, but assuming each of those `test*.py` files includes test cases, I would do something like ``` nosetests package_name/module1 ``` or ``` nosetests package_name/module2/test3.py ``` or if I wanted to get really specific (e.g. some test is hanging; I do a lot of async stuff) ``` nosetests package_name.module2.test3:MyTestCase.test_that_is_failing ``` 
Use ffmpeg and bash or a wrapper for it in Python.
So what is nose buying you other than you get to type nosetests instead of python? Why not just use what is builtin? I normally don't run all of the tests in my package. I usually do module tests and I like that it's the same name (`all_tests.py`). I don't need to think about what package I'm in. I also have tests that fail and don't want them to run, but there good tests that I need to fix at some point, so I keep them around. I just comment out the import. Nose would require me to rename my file, which I dislike.
Just have the function return the list. You should also post these types of questions in /r/learnpython, where the community is probably more likely to help you out. 
Thanks! I'll do that for all future posts. Which undoubtedly be many XD
Good. But you are now returning your inventory2 but not assigning it to anything. But you don't really need those additional inventory variables. And your `inventory += inventory2` is wrong too. **+=** for lists is equivalent to **extend**, not **append**.
My concern is it discovers tests I don't want to run. If test is anywhere in the name (e.g. all_tests.py), it'll find it. Then, it will run duplicate tests. What works well for automation testing doesn't work well for more hands on testing. I have CI going for my open source project on travis-ci. I have no problems with CI or coverage. Nose just tries to be too smart.
What a gigantic load of bullshit. How misinformed and one-sided the author's post is going to be is visible straight from the introduction, but "examples" like this &gt; in code reading chunks out of a file, reaching the end of the file is exceptional. are hilariously bad. Sure. It's completely outside the norm for a file to actually *end*. Right. There isn't even anything to discuss here in the first place. **Exceptions exist outside of normal code flow.** That's the very reason they work. That's why you can have a `ZeroDivisionError` rather than your program just going up in flames on the line that says 1 / 0 - because execution stops, normal code flow is abandoned, and exception handling it entered. That's why an unhandled exception can take down your entire program, even if there are a thousand lines left to execute - because exception handling is not part of normal code flow. It's not a question of "liking Python", it's a question of understanding basic principles of programming. And the fact that Python fanboys would rather write an apologist rant to justify a bad practice than to sit down and think about what is actually happening is one of the reasons stupid conventions like that are so entrenched in the Python hive mind. Yes, abusing exceptions works. Yes, unfortunately, Python does the same internally. That doesn't mean it's good, that doesn't mean it's correct, and the fact that I don't like writing shitty code doesn't mean I don't like exceptions and it doesn't mean I don't like Python. Maybe the author should've actually looked into the subject matter of his post before he wasted the world's time with his drivel. &gt; Exceptions are a means of breaking out of the normal flow of control of a code block in order to handle errors or other exceptional conditions. Straight from the god damn [Python language reference](https://docs.python.org/3.5/reference/executionmodel.html#exceptions). There is no discussion here and there is no opinion involved: Exceptions are not part of the normal code flow. To pretend that they are, to use them for regular execution flow control, is **just plain wrong**. Whether the fanboys can accept that or not. It's no coincidence the entire segment keeps referring to "errors" and not to "some regular condition that the programmer might want to react to". &gt; An exception is raised at the point where the error is detected &gt; The Python interpreter raises an exception when it detects a run-time error (such as division by zero). &gt; Python uses the “termination” model of error handling: an exception handler can find out what happened and continue execution at an outer level, but it cannot repair the cause of the error and retry the failing operation (except by re-entering the offending piece of code from the top). Exceptions are meant for *errors*, not for regular code flow. And as if that wasn't enough, take note of the warning at the bottom: &gt; Exception messages are not part of the Python API. Their contents may change from one version of Python to the next without warning and should not be relied on by code which will run under multiple versions of the interpreter. Does that sound like something that's designed to be relied upon for regular programming? If you like secondary sources: On the page on exception handling, Wikipedia qualifies exceptions as *"anomalous or exceptional conditions requiring special processing"*. Not as "regular flow control mechanisms on the same level as `if` and `for`". It is regrettable that the Python community continues to teach people that abusing code outside of normal code flow for flow control is somehow "good, clean code" and that those who have learned proper programming are stick-in-the-muds who need to be pitied. I love Python as a language. Both the language itself and the standard library are fantastic. But people like the post's author embody everything that is wrong with the religion around it.
Thanks for checking it out! Good luck!
~~Sorry to respond to a 5 month old post, but I've used the same command (Except it's "C:\Users\ElNamano\AppData\Local\Programs\Python\Python35-32\Scripts\pip install pyautogui" with Python 3.5) and it still gives my the error. The \Lib\site-packages folder for pyautogui doesn't exist, even though it says it's using a cached copy every time I run the pip command.~~ Nevermind, fixed it by doing pip install pillow
Guido is a good guy, but to be frank I hate the celebrity worship that goes on in open source sometimes. If you made "Pythonpedia" and Guido had his own page that might be appropriate. But something tells me Guido doesn't even take himself *this* seriously.
Where does it give you that error? It sounds like you're using some CI system...
nice website and robot!
I use py.test, it has been simple and easy to use.
Thanks! I appreciate it :D
Things I'd particularly like: * Ability to build up complex patterns programmatically, as opposed to writing functions that do a bunch of tricky string manipulation (I mean things like `'|'.join('(?:{})'.format(re.escape(a)) for a in alternatives)`) * Aggressive use of keyword-only arguments
I don't think this is too creepy since Guido is a celebrity who has a Wikipedia profile, and the private details were quite minimal. Just about everything else are professional accomplishments.
How long does that battery last with the rpi?
Unfortunately there isn't anything like NPM for python. We have pip but it doesn't compare. Your best bet would be pip + [virtualenv](http://docs.python-guide.org/en/latest/dev/virtualenvs/)
Can we please have failed matches return something other than None so we can do re.match(...).group(1) without dying when it's not found? I'd like to be able to use regexes in lambdas and list comprehensions without writing a helper function to assign a variable. Just return an object that evaluates to false with `__nonzero__/__bool__`.
isn't subprocess recommended over sys ?
try: with open(os.path.join(root, filename), 'r') as f:
This is a time saving tool for developers using Flask. You would only use this if you had made the choice between Flask and Django. For choosing between these two frameworks, I would start here https://www.google.com/search?q=flask+vs+django
Conda is really nice, and allows you to install pip packages as well.
I really wish python had some syntax to support assignment in if statement, constructs like: if foo = re.match(): foo.dosomething # only when match occurs if foo = re.match.group(1): only if group(1) is non-false.
few times I wished the same, but more times I think it's more clear to read to declare that variable beforehand
could you explain what is wrong with the current re module? not being PCRE doesn't seem like a big deal since every language out there has its own regexp flavor. [edit] the page says: &gt; * Zero-width matches are handled like in Perl and PCRE: &gt; * .split will split a string at a zero-width match. &gt; * .sub will handle zero-width matches correctly. &gt; * Inline flags apply to the end of the group or pattern, and they can be turned off. &gt; * Nested sets and set operations are supported. &gt; * Case-insensitive matches in Unicode use full case-folding by default. is that all? it isn't a change of syntax but only behavior of a few things.
I have used this with good success. It has many useful features beyond "re". The "fuzzy match" feature is amazing; it is a superset of the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) algorithm and lets you e.g. "find every word that differs from this word by at most 2 edits." It supports all the [Unicode property tests](http://php.net/manual/en/regexp.reference.unicode.php) that link is to a PCRE syntax reference. The only problem with regex is that the doc is scattered as hell: you start with the Python re doc but then fumble through the pypi page doc with is "organized" if you can call it that, by the sequence in which issues were raised, and then finally go to a PCRE reference. edit [this here](http://pcre.org/current/doc/html/pcre2syntax.html) would be a better PCRE cheat-sheet.
&gt; it is a superset of the Levenshtein distance algorithm and lets you e.g. "find every word that differs from this word by at most 2 edits." wooooooooo...I had no idea
I really have no expertise on this. I've been using Python for about a year and have just been using the `re` module. Then I came across this 2011 presentation about Unicode across the languages and it describes `re` as "deficient" when it comes to Unicode: https://www.azabani.com/pages/gbu/#slide30 Read the next couple of slides and it goes into more detail of what the regex module contains...apparently it's more fully-featured than any other regex processing of contemporary languages...well, at least in 2011. I think Perl 6 is probably the new leader.
I'm a python noob, what exactly does this do?
Thanks for sharing! The content looks very useful but the presentation makes this a non-start for me. Look into why your audio is severely clipping (likely requires just a basic audio level adjustment) and try to improve that for future videos.
&gt; .split will split a string at a zero-width match. You sure about that? In [1]: text = """This is the string that never ends ...: ...: Yes it goes on and on my friends""" In [2]: import re In [3]: re.split(r'^$', text, flags=re.MULTILINE) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-3-770ec4d3f633&gt; in &lt;module&gt;() ----&gt; 1 re.split(r'^$', text, flags=re.MULTILINE) /usr/lib/python3.5/re.py in split(pattern, string, maxsplit, flags) 201 and the remainder of the string is returned as the final element 202 of the list.""" --&gt; 203 return _compile(pattern, flags).split(string, maxsplit) 204 205 def findall(pattern, string, flags=0): ValueError: split() requires a non-empty pattern match. 
suppose you have a list of random strings ['893319', 'e7041e', '2ca18e', '49127a', 'e69785'] Now you wanna filter them with a pattern: Start char must not be a number but extract the number characters in them: It's best to do so in Regular Expressions, so, in one liner: [x for x in (getattr(re.search(r'^\D(\d+)', s), 'group', lambda x:None)(1) for s in ['893319', 'e7041e', '2ca18e', '49127a', 'e69785']) if x] you get: ['7041', '69785'] 
Tango with django is a nice place to get started after finishing the official tutorial ofcourse, here's the link - http://www.tangowithdjango.com/book17/ , Two scoops of django is a nice book to follow.
That said, I'd really prefer that APIs don't hand me `None` when there's a perfectly good 'null object' that could be used instead (e.g. `''` when the normal return is a string).
Lambdas always accept one argument?
You'll get only the match object part. You need `group(1)` to get the numbers part.
Haha I was upstairs when you sent it, could just make it out. :D
that's what the library says however the part I quoted references the new behavior, I see you're testing the current module.
Haven't tested fully yet but seeing as the pi will only draw what it needs, I imagine quite some time! The speaker has its own internal battery so the raspberry pi is just powering the wifi mainly. With 13400mah, I imagine quite some time :D
This is pretty neat, but at what point does he refactor rather than rewrite?
Python 3.6 will ([possibly](https://www.python.org/dev/peps/pep-0505/)) have None-aware operators, which should give us something nice like re.match(...)✊🍆group(1)
And `ax = ...` as well.
There's also a proposal for an inline try-catch, if I recall. (re.match(...).group(1) except AttributeError: None)
Yes, it is. But you know. Old dog, new tricks ...
My reddit app made your code into emoji .. Damn
Try to use Tornado as Backend Server. This will allow you to use websockets and to have a connection between client and server, where server and client can communicate. 
Here is an example how to use websockets with tornado: http://www.codestance.com/tutorials-archive/python-tornado-web-server-with-websockets-part-i-441
It was emoji. It's a reference relating to the PEP, where they use those unicode as a placeholder so that the concept is debated and not the specific operator. Edit: Here's the reason straight from the PEP: &gt; As a quick preview, consider an alternative rewrite using a new operator 💩 . (This spelling of the operator is merely a placeholder so that the concept can be debated without arguing about spelling . It is not intended to reflect the public's opinion of said operator. It may, however, bring new meaning to the phrase "code smell".): &gt; This code might be improved, though, if there was a syntactic shortcut for this common need to supply a default value. We'll assume the fictitious operator ✊🍆 to avoid a premature debate about the spelling of said operator: Pretty silly.
How can anyone type with fingernails that long! :)
Sadly it is necessary or we'd be up to our armpits in bikesheds.
I understand the motivation, I just fear that the emoji makes it seem less serious than it actually is. I'd personally just use `(None operator)` as a placeholder. PEPs aren't really the place for brevity and silliness (outside of April Fools jokes, that is.)
No, its just a protocol interface for talking with compliant webservers.
I'm generally very skeptical of any home-rolled security system. Unless your somewhat of an expert in security auditing, DIY security is not recomended.
https://docs.python.org/3.5/faq/design.html#why-can-t-i-use-an-assignment-in-an-expression
Really needs a better microphone. Its hard to follow when theres so much clipping muffling the sound.
Is it worth building a wrapper around the easypost functionality and referencing that from your code, so that when and if you have replace easypost, you can do it in one place and have a small test surface to worry about? 
Agreed. Wanted this for a long time
Glad I saw this... I use `nose` and didn't even know it was no longer maintained. Will be switching to `py.test` now.
I'm guessing this is Python 2 which suggests that the memory usage is related to the `range()` call itself which creates a full list with the start/stop/step values. Check out [`xrange()`](https://docs.python.org/2/library/functions.html#xrange) if you don't need the entire list in memory at once (e.g. if you're just iterating over it). In Python 3; the `range()` built-in actually adopted Python 2's `xrange()` behavior.
I doubt it will happen because it's not generic enough. Many API behave in different ways : - empty object - raising an exception - returning None - etc. I'm still a string supporter of the inline except (https://www.python.org/dev/peps/pep-0463/): m = re.match(...) res = m.group()[1] except (AttributeError, IndexError): "default" It's completly generic, match the ternary operator and is very handy. Make some noise for it to happen !
Tornado's asynchronous scheduling is all handled by the IOLoop. It's basically just a round robin of all scheduled callbacks (Which are scheduled when a future is resolved). This is the code of the loop itself: while True: # Prevent IO event starvation by delaying new callbacks # to the next iteration of the event loop. with self._callback_lock: callbacks = self._callbacks self._callbacks = [] # Add any timeouts that have come due to the callback list. # Do not run anything until we have determined which ones # are ready, so timeouts that call add_timeout cannot # schedule anything in this iteration. due_timeouts = [] if self._timeouts: now = self.time() while self._timeouts: if self._timeouts[0].callback is None: # The timeout was cancelled. Note that the # cancellation check is repeated below for timeouts # that are cancelled by another timeout or callback. heapq.heappop(self._timeouts) self._cancellations -= 1 elif self._timeouts[0].deadline &lt;= now: due_timeouts.append(heapq.heappop(self._timeouts)) else: break if (self._cancellations &gt; 512 and self._cancellations &gt; (len(self._timeouts) &gt;&gt; 1)): # Clean up the timeout queue when it gets large and it's # more than half cancellations. self._cancellations = 0 self._timeouts = [x for x in self._timeouts if x.callback is not None] heapq.heapify(self._timeouts) for callback in callbacks: self._run_callback(callback) for timeout in due_timeouts: if timeout.callback is not None: self._run_callback(timeout.callback) # Closures may be holding on to a lot of memory, so allow # them to be freed before we go into our poll wait. callbacks = callback = due_timeouts = timeout = None if self._callbacks: # If any callbacks or timeouts called add_callback, # we don't want to wait in poll() before we run them. poll_timeout = 0.0 elif self._timeouts: # If there are any timeouts, schedule the first one. # Use self.time() instead of 'now' to account for time # spent running callbacks. poll_timeout = self._timeouts[0].deadline - self.time() poll_timeout = max(0, min(poll_timeout, _POLL_TIMEOUT)) else: # No timeouts and no callbacks, so use the default. poll_timeout = _POLL_TIMEOUT if not self._running: break if self._blocking_signal_threshold is not None: # clear alarm so it doesn't fire while poll is waiting for # events. signal.setitimer(signal.ITIMER_REAL, 0, 0) try: event_pairs = self._impl.poll(poll_timeout) except Exception as e: # Depending on python version and IOLoop implementation, # different exception types may be thrown and there are # two ways EINTR might be signaled: # * e.errno == errno.EINTR # * e.args is like (errno.EINTR, 'Interrupted system call') if errno_from_exception(e) == errno.EINTR: continue else: raise if self._blocking_signal_threshold is not None: signal.setitimer(signal.ITIMER_REAL, self._blocking_signal_threshold, 0) # Pop one fd at a time from the set of pending fds and run # its handler. Since that handler may perform actions on # other file descriptors, there may be reentrant calls to # this IOLoop that update self._events self._events.update(event_pairs) while self._events: fd, events = self._events.popitem() try: fd_obj, handler_func = self._handlers[fd] handler_func(fd_obj, events) except (OSError, IOError) as e: if errno_from_exception(e) == errno.EPIPE: # Happens when the client closes the connection pass else: self.handle_callback_exception(self._handlers.get(fd)) except Exception: self.handle_callback_exception(self._handlers.get(fd)) fd_obj = handler_func = None finally: # reset the stopped flag so another start/stop pair can be issued self._stopped = False if self._blocking_signal_threshold is not None: signal.setitimer(signal.ITIMER_REAL, 0, 0) IOLoop._current.instance = old_current if old_wakeup_fd is not None: signal.set_wakeup_fd(old_wakeup_fd) src: https://github.com/tornadoweb/tornado/blob/master/tornado/ioloop.py#L746 In summary the Tornado IOLoop has three types of stuff it schedules: - General callbacks - Timed callbacks - File callbacks (Primarily for sockets) For the general callbacks Tornado works through a list of callbacks its been given and calls all the functions. As an example each time you call `raise gen.Return(var)` it will resolve the future that's being waiting on the result of that coroutine. When a future is resolved all the callbacks waiting on it are called: def _set_done(self): self._done = True for cb in self._callbacks: try: cb(self) except Exception: app_log.exception('Exception in callback %r for %r', cb, self) self._callbacks = None In the case of coroutines (i.e. when you `yield some_future()`) this callback will be a closure that schedules the coroutine to be resumed on the next iteration of the ioloop. The other types work very similarly. The timed callbacks are run when their timer reaches zero. The file callbacks have special error handling around them to handle files being closed etc.
I believe pip freeze also lists sub-dependencies (stuff required by the stuff you require). This may or may not be what you want. Like for distribution you may want to only list your direct dependencies, while for a production deploy you might want to pin everything down.
[yagmail](https://github.com/kootenpv/yagmail) might serve your purpose. Messages are always HTML while setting the text alternative. Good with attachments, too.
After thinking about how I could fix that I started searching for a program to do what I needed. For just cutting the silence out of these files I finally use Audacity and it's totally fine. Such a good solution Thanks to everyone who helped me with my question
I'm a new dog, trying to learn to fly a spaceship :) Thanks.
[removed]
The idea is to make typing a part of our reflexes, which i guess cannot be done using actual words. As for muscle memory to kick in you need to practice random keystrokes repeatedly. Practice mode is specially designed for actual words.
You're welcome :) &gt; I really wish that the documentation for python in general had return types immediately after the function Not only the return types. IMO also the parameters need to be documented more obviously. Prose text is nice if you're starting out with a language but if you're already fammiliar what you need is a reference.
It's not odd. Shadowing a built in is actively discouraged by the community and I assume that most people avoid it. But yes, it's strange that it takes that much memory. I can see several possibilities : immutable typtes being recreated, references on created objects being held, etc. Try to do: txt.config(state="normal") txt.insert("end", "\n".join(str(x) for x in range(999999))) txt.config(state="disabled") And check if you got the same result. 
Doesn't Pandas have a group by functionality?
Yeah, agreed re: function parameters. Just annotate the functions with the py3 type hinting syntax and I'd be a happy man.
[It does and it is really good](http://pandas.pydata.org/pandas-docs/stable/groupby.html), but I don't want to pull in Pandas as a dependency just for this. 
I was curious. In 3, I see the following: DICTIONARY = {Word(w) for w in open('enable1.txt')} Does this close the file once the dict comprehension is finished?
I will try next time :(
Just a totally off topic/non-Python side note: I find it psychologically interesting that this seems creepy to you and at least about 20 people. It's the same sort of information that might appear in a major magazine--in fact, any profile on a person would be rejected by a good editor without the basics of name, age, origin, and current employer, and often magazines will provide sidebars with either a traditional bibliography or, nowadays, online links. GvR is, easily arguably, a "newsworthy" figure in the world of computer programming. And it's not like this site has paparazzi photos of him on the beach or stats about his personal life, medical history, undergarments preferences, realtime GPS coordinates, etc. And yet you find it creepy. My hypothesis is that one unknown person (the OP), who is not "authorized" to compile such a page (unlike a "real" journalist, who is authorized by virtue of working for a "real" magazine with a "real" editor), has thought GvR important enough to bother to invest his time in creating this page, which suggests he *cares too much*, and yet should not have reason to care that much--whereas the paid journalist would just be doing it as an assignment, because the editor thinks GvR is newsworthy.
Not my project. Thanks, anyway!
Yeah that's much better! Edit: actually the that wont include Nones in the list. [m.group(1) if m else None for l in lines for m in [regex.search(l)]]
No, it's the format. A wiki can be modified by the community. And the topic is "all things Guido". So even though the personal info is currently minimal, there's nothing suggesting that paparazzi photos, PII, rumors, or gossip are off-limits. And this isn't Wikipedia which has a certain level of standards and quality control, it's just some side project.
back in the day I used to load [this functional form of try-catch](https://code.activestate.com/recipes/491270-exceptional-final-functional-exception-handling/).
They are not related at all. The continuum.io Anaconda is an editor-agnostic Python environment that bundles a package/environment manager (`conda`) along with a number of Python tools like numpy and Pandas. The other one is apparently a plugin for Sublime. 
I really am looking forward to the release of Warehouse, PyPi feels so antiquated. 
How about this? [m.group(1) for l in lines for m in [regex.search(l)] if m]
I've considered proposing a syntax like this: if re.match.group(1) as foo: # Do something with foo... and something similar for while loops.
I wonder what do you think could happen as a result of it "seeming less serious than it actually is". Also, where do you get that "PEPs aren't really the place for brevity and silliness", I mean, do you know that Python was not actually named after a snake?
This looks very nice. But: &gt; If no version is specified, the regex module will default to regex.DEFAULT_VERSION. In the short term this will be VERSION0, but in the longer term it will be VERSION1. This strikes me as a Really Bad Idea. Why is VERSION 0 behaviour currently the default? I imagine this is so people can switch from re to regex easily, without breaking existing code. However, *the explicit intent is to break their code in the future* -- without them changing anything. A far better way to do it is to default to VERSION 1 behavior *now*. If a developer wants to switch from re to regex easily, then they can explicitly enable the VERSION 0 behavior, and be confident that their code will not break at some unspecified point in the future. Maybe at some later point they will switch their code to VERSION 1. OTOH, if a developer wants to use the new syntax right now, they can do that, too.
Check out D3.js too. 
Spot on for what I need! Have a dataset with coords in a local area that I want to quickly visualise to get a feel for the distribution and this looks like it should do the job!
clever.
I like that UI with the split sources
&gt; I wonder what do you think could happen as a result of it "seeming less serious than it actually is". I think that it could be dismissed by community members at first glance and never gain the traction it needs to actually be accepted. &gt; I mean, do you know that Python was not actually named after a snake? Yes, I know all about the origin of the name. I'm not saying there's no room for joking around and silliness, I'm just saying that the place to do it isn't in formal proposals for language enhancement. That'd be like using emoticons on a CV. It doesn't hurt anyone, but it certainly hurts your chances of getting the job.
 I have done some work with there static image API, but nothing with markers or coordinate points. I will certainly look into it. Thanks for the feedback!
Wow, this was actually an interesting thing to learn about, in terms of how standards are debated and constructed.
not bad, but it's super over-engineered for its purpose.
Uh, what? The Anaconda Python installer from continuum.io is not related to continuum.io's Anaconda Python? I'm not following you.
Thank you! This will be what I am using as it seems simple to grasp. 
Anaconda, the installation framework for Fedora, CentOS, and RHEL
Agreed - in the case of the existing `re` module, it would probably be "better" behavior to return a Match object that specifies 0 matches instead of None.
Yeah, I misinterpreted what was being said in a very silly way.
I jumped into this comments section to say "Automate the Boring Stuff With Python" but it turns out it's the very first thing mentioned in TFA :) BTW it's free to view online, as is all of u/alsweigart's books https://automatetheboringstuff.com/
Anybody have anything like this for node???
Stop with the trolling man. Your comment history is a shitshow.
You can easily get around that with bluemix (or anything else that aCF based) with a proper CNAME. and CF adds a ton of value to make apps easier to run compared to basic hosting companies.
Also Openlayers3 while you're at it.
Not really interested in stack overflow or reddit. I view those websites via other sources anyway. I'd like to see github trending and pypi combined though. With pypi you could show updates of packages sorted by number of downloads or something.
Mainly written in python
I think it does, yes. 1. You can still use connection pooling by using proxy authorization. Web server connects to database as a single user, then calls SET ROLE to switch to the actual user, as per http://stackoverflow.com/questions/2998597/switch-role-after-connecting-to-database/19602050#19602050 2. You can authenticate users pretty easily too (Spring example: http://blog.databasepatterns.com/2015/03/database-authentication-with-spring.html , or you can even sync PG with LDAP and use LDAP authentication: https://github.com/larskanis/pg-ldap-sync 3. I've yet to see a web security framework that supports column security. Postgres does. 4. A lot of web security frameworks seem to grab all the rows then filter AFTER, which is pretty bad performance-wise and screws up pagination 5. Having the db know the actual user makes auditing a lot easier 6. Lots of users is feasible: https://dba.stackexchange.com/questions/89275/feasible-to-have-thousands-of-users-in-postgres/89307#89307
None of these questions have anything to do with data science. Awesome
Fair enough
This is actually pretty sweet :)
Yep. The good days of py*this* and py*that* are gone, it seems.
27 Oct 2013 was when tqdm was created, not 2015
Effective Python has been my favourite educational book of all time. It's just perfect for someone who generally knows Python and wants to understand the when and where of use. 
Awesome work! I am starting a new project and started it in `aiohttp.web` instead of `tornado`, did you evaluate both and, if I may ask, why did you choose tornado?
Crap, guess it's uncool that I call my library pymyshitisawesome. Do I just call it SiliconBadassLib?
One thing that Python does not teach well (at least until you get further down) is the idea of an "interface", which exposes no implementation details but instead simply exposes a contract. You **can** build in interfaces if you use [abstract base classes](https://docs.python.org/2/library/abc.html) (which not tons of libraries do). In my opinion, this makes object oriented design much more simple to understand as solid OO is much more geared toward the "contract" than the "implementation" (the name is a little deceptive). Granted, composition should be favored in general, but your interface can abstract the composed pieces together to make an easy to use "object". Don't you love how all the names are pretty generic?
I was tracking with you right up until you implied documentation can compensate for poor design. In my experience, you can't trust code documentation. Even when you have a very intentionally packaged and documented library, you will invariably find bugs or out-of-date docs. Documentation can help point you in the right direction and understand the big picture, but you always need to read (or execute/test) the actual code to know what it's actually doing. I also think writing documentation that covers the minutia of the implementation is guaranteed to drift from the actual implementation, which further degrades trust in the rest of your docs. So, yes, you have a duty to document, but it's crucial to learn what is important and helpful to document vs what is a waste of time to document. In the meantime, OP, OO code that is hard to follow is a sign of poor design. Or simply over-application of OO ideas. Inheritance should be used strictly for polymorphism and you shouldn't abstract everything simply because you can. Abstraction has a very real cognitive cost, as you are finding, and is rarely actually necessary (when it is, you know it!). Having over-abstracted many things in my career, I now find myself rarely abstracting and, when I do, it's generally a few interfaces that are implemented by a few classes - so like 1 level deep in each "hierarchy". Of course, YMMV based on what you're actually coding.
you probably missed the point that it is open-sourced on Github, which means anybody can suggest an edit, can have discussion on the matter of "personal" info in question, can have multiple maintainer, etc. whereas a magazine article would zero suggestibility or editability even from GvR. Yet, magazine is ok, this open-source project is not? just strange. 
I'm not using Python 2 for any new code.
Thanks :)
How do you view Reddit currently if I may ask? As far PyPi, I guess we're looking for "big increase in number of downloads in short time", really trending... otherwise it would always be the most popular packages. But it's good to hear someone being interested in PyPi; I did not hear that yet.
I have used `aiohttp` here: https://github.com/kootenpv/sky. But I cannot say I really liked it. Then again, I haven't really solved all the puzzles of tornado, either. I guess trying out `aiohttp` is good for aiming for the future, but be prepared to suffer a bit (mostly doing async stuff in Python is annoying). Make sure you use the new syntax introduced in Python 3.5.
Get a short domain name, like a .io domain which would be easy to remember, 
Aah okay! thanks!
http://scipy.org/docs.html ?
I don't understand the need for interfaces in Python (or most other dynamic languages) because of duck typing and introspection. When would you use an interface, and why would it be better than not doing it?
The whole phrase is "***Favour*** composition over inheritance." Composition is not always the best choice. Many times, but not always. 
Interfacing is useful so clients know what services to expect from an child (implementation) of the interface without knowing the implementation details, and implementations of the interface (I.e. child classes who inherit from the interface) know what services they need to render without having to know who's calling them or how they will be used. This design is useful because now the client who calls the interface doesn't need to know the person who builds an implementation of the interface, vice versa, and you can even have multiple people building different implementations of the interface that don't have to know about each other. This is all thanks to all actors depending only on the contract that is the Abstract Interface (Abstract Base Class in Python). 
&gt; Interfacing is useful so clienti know what services to expect/provide ... without knowing implementation details. So this is an alternative to documentation? I accept that is a use for it but why is it *needed*?
I think a great improvement would be to make the feeds auto updating. The simplest kludgy method is a meta refresh in the html. But the "cool, but non-trivial" way to do it is to is to serve up the jsonlist files as either json or rss (why not both) and update the page's html from that data. http://designshack.net/articles/javascript/build-an-automated-rss-feed-list-with-jquery/ http://json2html.com/ This would let someone leave the page open and new trending items would appear automatically. You could define how often the feeds get updated, and include a pause button. You can even update based on [page visibility](http://www.html5rocks.com/en/tutorials/pagevisibility/intro/). The tricky part is that you'd probably still want to render the page initially much like you're doing today - jinja templates to straight html. This means that people running noscript or otherwise disabling javascript would still be able to view the page. The downside of attempting to support that is at some point, you'll have duplication between javascript and jinja templating. Again, it already looks great. These are just my thoughts. I know first hand it's easy to sink a lot of time into getting javascript bits to work gracefully. It may or may not be worth the time investment. 
did you, they look pretty similar to me in what they are trying to do.
What tyrionlannister said. Also, you're probably not getting a lot of help with this because it requires extra work to assemble the sample code and imports into something we could run, and most importantly, it doesn't include the sample data. So other than eyeballing for errors, it's hard to help. I have some familiarity with NLTK and saw the first post several days ago, but because of the above, didn't reply. If you're willing to repost some code that is completely self-contained, you'll probably get more help. I'd certainly take a look. For that, I'd suggest eliminating any of the imports that aren't used for what you're debugging, and pasting in a dozen or so tweets directly into a list (without pandas and the dataset) since the first goal is just to get the process working. Once it is, you can train it with your larger data set for accuracy.
It was what I was looking for! Thank you!
Sucks with else if, the declaration is off somewhere else. Trade off between polluting name space with var used once.
Great article!
The fuck? &gt; pyenv lets you easily switch between multiple versions of Python. vs. &gt; autovenv will figure out that the folder you’re in is a python project, create a virtualenv for that project automatically, and activate/deactivate that virtualenv when you cd in/out of the project folder.
What are you trying to achieve with a reverse geocoder? Just the locality information? (e.g. city state zip) I just can't imagine many times where I've had lat/longs for a household and need an address. 
Question: This is coming from someone who's tried to setup a single node cluster in hadoop several times, but never actually implemented it, have you looked at spark? As soon as you get it installed its much much easier to work with (it works right in jupyter) and does a lot of the complex architectural backend stuff for you and has a native Python API. That being said how did you like Mr. Job? Thats amazon's mapreduce right? The way spark works I don't think its technically mapreduce, everything is sort of static till the end then its done in one step. https://www.youtube.com/watch?v=bJouNc1REno This video convinced me and could articulate it much better then I could. 
Looking back on it I think your problem is probability sir, you've got a 1000 second sleep on the thing, if you have 20 going at once and the other one is iterating through every second eventually your going to face long periods of large time where all the processes are "sleeping" or at least caught in that logic. In the time you make one process wait it should in probability terms get hit 50 times by all the processes. Each one of those that gets hit is stuck for that same time.
So. I agree... That code snippit is just an example of the problem I am facing. For each iteration each of my workers has a n probability of hanging (waiting on a service beyond my control). After some number of iterations all of my worker processes are locked up, and I have to manually clear them. My goal is to remove the manual clearing step so that the experiment can run unattended. 
Great resources 
Yeah so far I am mixed on `aiohttp.web`, unfortunately the 3.5 syntax has caused quite a few headaches (but I have been putting in PRs to try and work on cases I find).
employ a crude counter or something like it to give logic that says if this has lasted for this long kill it: (I'm not sure how but I know it could be done) like adding a count and then saying and count&lt;20: 
It is. But the secret to how to eat an entire elephant is one bite a time :) so dont worry about all the info, just start with a tiny bit, like watching some interesting youtube videos on the subject.
I appreciate it. I dont have the funds to study this at university or time (have a 1 year old) so you guys writing blogs and the whole open source community are a godsend. Who knows, in the future I may be able to and thanks to you guys I'll have a solid understanding
I haven't tried it yet, just looked at a couple of tutorials. It's on my list, but I'm currently experimenting with Theano, Lasagne and nolearn. I've found Theano a bit tricky to work with (that's why I've been using Lasagne &amp; nolearn, which provides abstractions), so I'm hoping TensorFlow is a bit more intuitive.
Any advice for somebody trying to learn ml or neural networks in a week. Not really sure where to start. 
IMO, Neural nets are explained as way more complex things than they are. It is true that backprop is not simple. but the basics of a neural net are very simple (if you have a background in mathematics/optimization). Moreover, machine learning packages do the backprop automatically. I recommend theano. (I have tried tensorflow but I find theano easier to use especially when experimenting new things) Moreover, people tend to see a very limited application of neural net while they are truly very flexible tools. Generic neural net: z_0 = x # for hidden units a_i = z_(i - 1) * w_i + b_i z_i = hidden_activation(a_i) # last layer z_n = output_activation(a_n) predict = z_n cost_function(predict, target) Most, people see neural nets as: hidden_activation = sigmoid(x) output_activation = sigmoid(x) or softmax(x) # for classification cost = cross_entropy =&gt; (- target log( predict) ) target is 0 or 1 (onehot encoded) a better one would be: hidden_activation = max(x, 0) # &lt;= easier to train output_activation = softmax(x) # for classification cost = cross_entropy =&gt; (- target log( predict) ) finally, you can do non-linear regression using nnet too: hidden_activation = max(x, 0) output_activation = x cost = (target - predict) ^ 2 target is a Real value here. Here is the result I got when trying to learn simple 1D function (with 20 neurons), http://imgur.com/DA0Plev You use whatever function you want as activation function and cost (Well, if you put some non-sens function it will most likely be very hard to train) You can use nnet with one hidden layer to approximate any given function. 
Fundamentally, you need another thread/process running that will monitor the pool processes. Unfortunately, `multiprocessing.Pool` provides no way to terminate the processes it manages. As a result, you're probably going to have to write your own pool to manage a bunch of `multiprocessing.Process` objects. You'll have to keep track of how long they've been running yourself, and call their `terminate()` methods as appropriate. 
Neural networks has been a huge fascination of mine. I have loved the concept and implementation of it and honestly if you know all the prior stuff before it I.E logistic regression and linear regression, and you take sometime to read the books and maybe the machine learning course on coursera, you will be able to code the basic in about two weeks. It's gets harder after that but writing the forward propagation steps and backward propagation steps is relatively easy That being said awesome article OP
Nice list, some great libraries on there. Curious though, what metric was used to determine if a library is 'most popular' and should be in the Top 10?
uh im not even sure, ive looked at so many, il give it a try though! thanks
It was an interesting problem, and I need to do something similar in a project I'm currently working on, so I had a go myself. Here's a very basic (but apparently working) implementation. The important bit is the `while True` loop in `Pool.map()`. #!/usr/bin/env python from multiprocessing import Process, Queue, cpu_count import random import time TIMEOUT = 5 class Pool(object): """Very basic process pool with timeout.""" def __init__(self, size=None, timeout=15): """Create new `Pool` of `size` concurrent processes. Args: size (int): Number of concurrent processes. Defaults to no. of processors. timeout (int, optional): Number of seconds to wait before killing the process. """ self.size = size or cpu_count() self.timeout = timeout self.pool = [] self._counter = 1 self._q = Queue() def map(self, func, it): """Call `func` with each element in iterator `it`. Args: func (callable): Function/method to call. it (iterable): List of arguments to pass to each call of `func`. Returns: list: The results of all the calls to `func`. """ while True: if len(it) and len(self.pool) &lt; self.size: arg = it.pop(0) self._start_process(func, (arg,)) continue if len(self.pool) == len(it) == 0: # Finished break pool = [] for proc in self.pool: if not proc.is_alive(): print('{} done.'.format(proc.name)) continue age = time.time() - proc.start_time if age &gt;= self.timeout: print('{} killed.'.format(proc.name)) proc.terminate() continue pool.append(proc) self.pool = pool time.sleep(0.01) results = [] while not self._q.empty(): results.append(self._q.get()) return results def _start_process(self, target, args): """Call `target` with `args` in a separate process. The result of the call is returned via `self._q`. Args: target (callable): Function to call in new process. args (it): Tuple/list of arguments to pass to `target`. """ def _wrapper(): """Closure around the callable.""" result = target(*args) self._q.put(result) proc = Process(target=_wrapper, name='Process#{}'.format(self._counter)) proc.start() print('{} started.'.format(proc.name)) proc.start_time = time.time() self.pool.append(proc) self._counter += 1 def worker(key): """Demo function to call via `Pool`. Each call has a 1/3 chance of running for 1 second, running for more than 1 second but less than `TIMEOUT` and for longer than `TIMEOUT`, i.e. it will be killed by `Pool`. """ # Some process which occassionally takes a long time coin = random.randint(0,2) if coin == 0: seconds = random.randint(TIMEOUT+1, 1000) elif coin == 1: seconds = random.randint(2, TIMEOUT) else: seconds = 1 print('Process#{} will run for {} second(s).'.format(key, seconds)) time.sleep(seconds) print('Process#{} ran for {} second(s).'.format(key, seconds)) return seconds if __name__ == '__main__': keys = range(1, 1000) p = Pool(20, TIMEOUT) results = p.map(worker, keys) print(results) EDIT: Fix bugs; tidy up code.
I think the Internet is littered with ill-tested installation instructions for Hadoop. I really hope I can keep the instructions in this blog post up-to-date and accurate for Ubuntu as I too have wasted a lot of time in the past getting everything running before I could even begin to do some productive work. I have looked at Spark. It's fantastic. It installs easily. The API is extremely simple to work with. The documentation and feature set make huge leaps with every minor release. I did one blog post on it a little over a year ago and I've been meaning to do more. Mrjob was built by developers at Yelp so I'd say it's there's before anyone else. It doesn't strictly need to run against Amazon's EMR as local and 'hadoop' (read private cluster) runners are also supported. The work I was doing this year was mostly going over Common Crawl's dataset on Amazon. I started the project with mrjob and ran it on EMR as the S3 traffic to fetch CC's data was free and I only needed to pay for the compute time. The work I was doing fit nicely into the Map Reduce paradigm Hadoop offers so I never took the time to consider doing the jobs with Spark. I see Spark as a system that can run DAGs well and avoids I/O on disks by holding as much in memory as possible. Neither of those features were required for the project I was working on. EMR supports Spark so technically I could look at it.
Should start right with that, imo.
Yes
CC does around 1 to 2 billion pages every few weeks. Google says they index 50B pages so for a charity project CC isn't too bad. It's never the same set of pages exactly each time either. For example, Airbnb say they have 1.5M places to stay but to even collect 80K of those places pages you need to look through 10-11 crawls to collect them. I suspect CC is a lawsuit waiting to happen but being a charity with little funds hopefully they're left alone. It's generous of AWS to offer them so much compute and storage for free.
Jupiter.
Thought the speaker was excellent, originally it was meant to be a four way presentation with the guys from sierra leone but they couldn't get visa's. Also I'd imagine after working 12-14 hours a day for months and doing so *much* it would be easy to forget part of what you did, astounding people.
if you just wanna do some cool analysis [Jupiter](http://jupyter.org/) is beautiful it makes it actually fun to do data analysis like telling a story. I was always partial to sublime Pycharm had a lot of really good tools when I tried it but theirs something about the feel of sublime that I like the most. (except when it autocompletes pandas that pisses me off) Your using Google Drive for what? A local backup for repositories not on GitHub? Why would you need break up a file to put on Google Drive? I can give a little more insight when I know what your doing or trying to do. Don't be overwhelmed its a hobby, I've found when I get burnt out I have a go to something I know I'll like that I've been avoiding using. (e.g. Jupiter) Be aware you have a lot to learn but don't think about it in the looming sense, think about the things you could do with it and how cool it could be. Take a break, go for a walk, even for 5 minutes you'd be amaze how stupid some of the problems I've had are and its mainly just because I'd been doing it for so long I wasn't really thinking about what I was doing. 
yeah i found a link of somebody thoroughly explaining the code with treeview. i think im going to use this one from here on out. Thanks! (: 
Why 2.7 :(
Thanks for the post! I'm not at the point where I can even GRASP machine learning yet, but it's helpful to have easy-to-understand resources. Anyone ever take the Johns Hopkins data science series on Coursera &amp; have any input on THEIR machine learning course? I haven't bored through it yet because their R class is too ridiculously fast for a beginner, but I plan on going through the track to the end.
I'm really loving the courses on Coursera from University of Michigan, so I'm wondering if anyone here's taken both &amp; has some compare/contrasting input. And I hear that a large reason why people teach in 2.7 because the libraries for 3 are limited. I can't see why you can't learn it initially in 2.7 &amp; then make the switch.
You can use Dynaconf http://rochacbruno.github.io/dynaconf/ store sensive values in REDIS or Environment Variables
90% the same. You should have no problems whatsoever. 
IMO the repo host is not very important, since thanks to DVCS the code can still be mirrored in as many places as one likes, and moving to different main repos is not difficult. What is key here is that they are *not* moving the bugtracking. The bug trackers is where companies like Github and Atlassian really get a chokehold on a project and make it extremely difficult to move between providers, since there is no standard format to issue trackers nor do the various providers generally let you import issues from elsewhere while maintaining real dates and original usernames as first class attributes (rather than "imported from XYZ" types of messages embedded in the comments). Issue tracking data is really an extension of the code and repository of a project itself, since when one traverses through the history of changes for software, it's the bug tracker issues linked to commits that really provide the most in-depth documentation for a change. It's a very unfortunate state of affairs at the moment that while everyone agrees that DVCS is a key technique, there's very little interest or current work being done on distributed, or at least very portable, issue tracker formats. Most OSS projects seem to look upon their issue tracker as some kind of mailing-list / "to-do" list whose history isn't as important as the repository history itself.
I forgot to include this one, which helped me alot with the Ttk components: [TkDocs - Tk Tutorial - Tree](http://www.tkdocs.com/tutorial/tree.html) If the link you found is something else, please post it.
Are references like this to Guido and BDFL all just a tongue in cheek joke? Like him liking it isn't actually a key reason, right?
This came up with PostgreSQL recently. It was turned down, harshly. Why? Open Source projects should use Open Source platforms, period. This is not a slam on Github. They are a good service but at any moment they can change direction and put a lot of FOSS projects in a world of hurt.
There's certainly common aspects that all issue trackers can agree upon. What you see in a tool like Jira is all kinds of features like "hipchat integration" and "agile workflow" that are all about selling software and business workflows, not actually the central job of "tracking issues". i would argue that moving issues between different OSS-oriented systems (e.g. not loaded with business case bloat), such as Trac, Bitbucket's tracker, bugzilla, and Github is not any harder than moving repositories between SVN, Hg, or Git. I've worked with the nuts and bolts of both, not only moving many projects through different SCM and issue tracking systems but also writing [software](https://bitbucket.org/zzzeek/hggitonce) to [do so](https://bitbucket.org/zzzeek/trac2bitbucket) and the mechanics of HG and Git are easily as mismatched as that of rudimental issue tracker formats. The bugtracking analogue to DVCS would be an open source issue tracking system that is not originated as the hosted-only/commercially licensed vehicle for a commercial enterprise, and exists as a format that can be consumed by any number of front ends, including commandline or web-based, not unlike git itself. There are a handful of mostly defunct projects out there which do something like this, many of them using git repositories themselves as the backing store (which I think is a good idea as it provides an existing transport and persistence model. Database-like queries on top are easy enough to implement using a separate index with sqlite or other indexing approaches) - and what is interesting about most that I've looked is that interest in them seems to fall off about when github started becoming popular and essentially "taking over". I don't like the idea of any commercial enterprise having this dominant of a position within the open source world, e.g. that the literal documentation of the development and construction process for the majority of OSS projects is non-portably controlled by a single private company. The biggest problem would be making this system enough of a killer-app that the commercial ventures would be forced to adopt it, the way Bitbucket had no choice but to support Git as well as Mercurial. Unfortunately I don't see how mindshare would ever accumulate outside of this realm to enough of a degree to change things, but from a technical standpoint the problems are very solvable, definitely not any more difficult than the work that went into creating git.
Thanks. I do plan to take a machine learning course in the future, this was just something interesting to do in my free time. 
So many open-source projects splinter and fragment and then fizzle out. Nice to see that we are all converging on git. Mercurial is pretty good, but so is git, and I find switching between them really frustrating. 
Something that might be a bit more tractable in a week: learn the basics of graph analytics and tinker with the networkx library. Download your facebook friends network and play with that.
A lot of Tkinter examples say to use the star imports, but it's not a good idea. I import them like this: import Tkinter as tk import ttk Based on your lower-case module names, it looks like you're using Python 3, so try this instead: import tkinter as tk from tkinter import ttk Then every Tkinter identifier needs to be prefixed with "tk" and ditto for "ttk": def MakeLog(self): frame = ttk.Frame(self.notebook) self.logView = ScrolledText.ScrolledText(frame) self.logView.pack(side=tk.LEFT, fill=tk.BOTH, expand=True) self.logView.configure(font=("Consolas", 8, "")) 
&gt; put a lot of FOSS projects in a world of hurt. Can they? The code is already out there, so what can anyone do? Wouldn't you just jump ship again if something stinks?
alright, thanks!
eh, the only difference is print statements at that level of comprehension. It's not like a es5 -&gt; es6 change 
Could someone explain what it means for "python" to move to github? What is being moved exactly?
Brett was talking about this at a Python meetup last month. He said that he has been working on updating the Python workflow for a while. He was going back and forth between the two and said to expect some change soon.
Do you have the HN link? I wonder why the downvotes...
The core Python project. The email was from the Python dev mailing list.
The change in the behavior of things like &gt;1/2 Would also come up.
I started out in 2.7 and switched pretty seamlessly to 3. There are some pitfalls to be aware of though, so make sure you read about the major basic differences when you change over.
They could do something like sourceforge. https://www.reddit.com/r/linux/comments/37h4x5/sourceforge_hijacking_project_accounts_gimp/
Amazing talk. Thank you for the link!
I'm asking about changes on the syntax, which are the main issue among the different flavors of regexp. bugfixes are ok, I don't think a new module is necessary for that.
Oh, the actual code of the actual python language. Basically doesn't affect anyone that is just a user of the language, right?
If you read the post it wasn't a major point but it was taken into consideration in addition to the other more impactful points.
Python is done with mercurial, not git. :-) Mercurial is also written in Python. EDIT: Sorry, I didn't read the PEP. OMG they're moving to GIT - the DVCS of the Finn with anger management issues!! They're abandoning THE DVCS WRITTEN IN PYTHON!!! This is just HORRIBLE! It's like Satya Nadella buying an iPhone or Tim Cook a Surface Pro. THIS IS MADNESS. 
WAIT - WHAT?!? No one put this in the title! They didn't just move to Github - they abandoned MERCURIAL! The DVCS that's written in Python! That's not created by a sociopathic Finn with anger management issues! This is TERRIBLE! We've abandoned Mercurial and Bitbucket and now they could die off because the shining example that is Python has abandoned them. The whole rationale of this PEP is - everyone else is using it. Everyone else is using C# and Java too, but we use Python. Now Python has sided with the Borg Collective. :-( :-( :-( :-( :-( Next development will only be allowed on Windows, communication only via Skype, passwords will be changed to characters from Game Of Thrones and PyCon 2016 videos will only be viewable on Netflix. :-( :-( This is terrible; I feel betrayed. :-( Maybe Mercurial will port to Ruby now out of revenge. :-(
IT'S A BETRAYAL is what it is.
And that's a horrible thing. Python would never have achieved any success that way. Python can keep it from becoming the de facto DVCS by remaining loyal TO THE DVCS WRITTEN IN PYTHON. 
Do we need more contributors? It's not like Python has 17 users, sits on SourceForge and hasn't seen an update since 2011. 
That bites both ways - Python isn't the most popular programming language. If we used things just because they're popular, Guido should be coding in Java right now. 
Linus torvald is somewhere around there, not quite as extreme though 
Richard M. Stallman is the Jobs comment, Linus Torvalds is the suicide comment, and Eric S. Raymond is the arming comment.
Will they accept pull requests?
Nice!! Thanks for letting us know!
You learned programming in 5 months?
You almost certainly DO NOT want to do this. The loss in fidelity will be considerable.
If you're planning on doing analytics or machine learning with python, it's strongly recommended that you use the anaconda distribution, in which case it comes with the base installation. Otherwise you can install it just like most any other package via pip pip install networkx https://networkx.github.io/documentation/latest/install.html https://pip.pypa.io/en/stable/installing/ EDIT: haha, oh I just realized you mean your facebook friends graph. I've never done it myself, but I'm sure there are loads of tools and tutorials around to show you how.
I'm pretty sure two versions of the lectures for this course have been free through MIT's opencourse database for a while. A third set of lectures won't hurt, of course, and edX is more interactive than MIT opencourse. Being able to get in touch with the professors will probably be a major benefit. 
In the midst of all the git-ward movement, I really wish something as cross-platform and well fleshed out as TortoiseHg would appear for git. I like mercurial and all, but could switch to git... except for that.
GitHub doesn't support Mercurial, only git, so that is implied. 
[Dash (osx only)](https://kapeli.com/dash) comes to mind
Git and DVD won, Mercurial and Blu-raylost. Just accept it.
Previous poster seems a little... out there. But from my perspective, I really like how easy it is to extend Hg with extra features, interface with it programmatically, and also, I really enjoy being able to use TortoiseHg, and would genuinely love to find an equivalently powerful replacement in git-land. But most answers seem to be "doing it from a text interface is just as a good" or "why do you need cross-platform?", neither of which makes me very impressed with the ecosystem surrounding the core git tool. 
&gt; WAIT - WHAT?!? No one put this in the title! They didn't just move to Github - they abandoned MERCURIAL! That's right, and that's the major news today. The title should have included it.
Python creator. https://en.wikipedia.org/wiki/Guido_van_Rossum
Have you looked at Geohashing then creating a table for the features that exist inside of the square, (e.g. roads, points,features you'd like to access on the map) regioning off elements is good for performance when mapping anyway, thats sort of Google's Secret Sauce. I recently implemented regioning in one of my modules or you'd never normally be able to do things like [this](https://cloud.githubusercontent.com/assets/10904982/12067142/a373df96-afc2-11e5-9d8e-69d13b70731b.gif) in GE. (large set of points) I've written modules to geohash in tabular form but the module I based mine off (wrote my abstraction on top of) of is [here] (https://github.com/hkwi/python-geohash) Its definitely fast enough to be used in aggregation in heat map pipeline.
I've always found the TortoiseX clients awful, but isn't there a TortoiseGit too?
Which is why they might as well be teaching the version that has a future. 
Great suggestion!
Well I know now. 
The one where we `from __future__ import` ?
It's totally fine to not know; it doesn't affect your ability to use the language in the slightest. 
TortoiseGit is Windows-only and not that good to boot. What don't you like about TortoiesHg? I find that I can do things with it just as easily as from the command line (with a few rare exceptions).
&gt; We've abandoned Mercurial and Bitbucket and now they could die off because the shining example that is Python has abandoned them. Actually bitbucket has abandoned Mercurial first, relatively long time ago. They still support it for legacy projects, but the default option for new repos is git. And good riddance, to be honest. Funny how you didn't know about it, I guess like a proper stereotypical fanboy you don't actually use them =)
Don't worry, the changes are really minor in terms of syntax. However, it is somewhat important to know about them to write Py 2 &amp; 3-safe code (e.g., using `from __future__ import` or `x = 1; x / 2.0` instead of `x = 1; x / 2`if don't want integer division etc.) Maybe just glance over the key differences in one of the articles and you'll be fine - [The key differences between Python 2.7.x and Python 3.x with examples](http://sebastianraschka.com/Articles/2014_python_2_3_key_diff.html) - [Python 2 or Python 3](https://wiki.python.org/moin/Python2orPython3)
Git is mostly hard _to learn_, not to use as such, and when you're forced to learn it anyway because a lot of people use it, it's no longer an obstacle obviously. On the other hand, having to remember Mercurial's interface in addition is inconvenient. Plus, Mercurial just sucks compared to git in several respects.
That is very misleading. The biggest differences are : - rework of the stdlib namespace; - total rework of the text handling including literals and most API; - moving most iterable processing functions to be generators. But the good news is that if you know 2.7, it's very easy to transition to 3. The reverse is not True.
This. And they all use OOP while it's not necessary at all. You can create small tkinter scripts without writting a single class.
Same can be said about git. 
I was always annoyed by the way it gets in my way without any good reason even. Why do I have to find and edit the configuration file to enable the `fetch` command? Are they afraid that newbies might somehow type it by accident, so I have to jump through hoops to prove that I know what I'm doing? And if they do, why do they care about newbies more than about me? And it's even worse when combined with general low popularity of Mercurial and therefore scarcity of manpower available for improving or even maintaining things, for example recently I wanted to find something like gitk, well, there's a bundled extension but its wiki page told me that it's an "unloved feature" and to go install hgview instead, which ended up being incompatible with the installed version of Mercurial so after twenty minutes fucking around I went and learned how to run hg-fast-export instead. Git was developed because Linus had an itch to scratch and it scratches that itch well, with all batteries included, most settings set and so on. It takes time to learn to use it the Linus way, if you have to use it differently it would be much less pleasant, it's wildly inconsistent in places because it was grown rather than designed, and so on, but at least there's one person who is happy with it and if you use it similarly you'd be happy too. With Mercurial I get this feeling that it was made not as a tool for themselves but _for other people_, according to some vague ideas of what those other people would really need. 
&gt; "OMG git is hard to use" Who are these people? Git is the most intuitive version control I've ever used, by a very very VERY wide margin. That's before we move away from the CLI.
Yes, we will accept pull requests.
You can, but once it gets beyond a certain size, it's very helpful to put it into a class to keep things together and not be managing scores of global variables. In my MakeLog snippet above, ScrolledText is another class that comes with Tkinter which wraps a text widget and a scrollbar. It's much more convenient to have them encapsulated in their own class than to have another handful of globals in your own script to deal with.
Thanks a lot for the great advice :)
Just enrolled, huge thanks for sharing this! Hoping completing this will strengthen my masters application since I come from a different technical background. 
I agree, unfortunately they (the aiohttp authors) don't always implement the necessary magic methods, for example `__aenter__` and `__aexit__`
Awesome. Albeit at an expense of people downvoting me like I'm some crazy maniac. :)
You read the PEP not the mailing list post which OP linked to.
Nonono, Torvalds is way too sane for the first and the last one. He's an asshole sometimes, but very predictably so.
I don't know why that poster came on so strong, but I do much prefer hg. I've used both hg and git/github extensively on a bunch of projects, and git took a lot more getting used to, and continues to be more complex. It's *very* powerful and works well, but I find I wished it were simpler and more limited... Or at least had more understandable core principals (remotes, detached heads, undo commits or merges, etc). It's not a bad system. I just much prefer hg. The fact that it's written in (and is extended by) python is a huge plus. And last, git support on windows has been *awful*.
The initial release supported only the CLI app. I removed it on this version since I rewrote the whole thing. Will add it up on the next release. Thanks for your time :)
I am using py.test. Every time I write tests for a new project I am in awe of the insanely genius way of parameterizing tests. You need 1/10 the code as with other tools and can quickly build and expand n-dimensional test matrices while keeping everything readable.
cool hook it up
It's a school for licensing.
^ this. Conda makes it trivial. Just install the whole anaconda package, you can be up and running as fast as you can download it. 
Of course, what I mean is that it has zero added value for hello world tutorials and confuse the hell out of beginers.
My advice is don't. Just take the time to read a book on JavaScript. You'll fill in a lot of the "why does this do that when I change this?" questions you've built up by just copy-pasting-tweaking other people's JS, you'll get another bullet point for your resume (Languages: Python 2, Python 3, Javascript…), and you'll get the knowledge you're going to need to debug Brython when something goes wrong with it.
Well Guido is the BDFL that makes the final decision on everything. So yeah he is pretty important, and opinionated.
&gt; We've abandoned Mercurial and Bitbucket and now they could die off because the shining example that is Python has abandoned them. If Mercurial is so weak that one project not using it will kill it then they made the right choice by picking something else.
The core developers think so. But really, *every* open-source project needs more contributors. 
&gt; Github lets you delete projects, so this shouldn't be an issue. For now. If github ever starts to struggle financially, they could change their terms to make all sorts of annoying things happen.
Would it be a good idea to purchase the certificate? Would I be able to put this on a resume without purchasing it?
Looks like the system python version may be causing some head ache, you should consider using brew to install python and then in a virtualenv try installing and using matplotlib. I generally try to avoid using (and installing packages to) the system default python on OSX.
Check out https://github.com/atsepkov/RapydScript
Appears no body is interested by our product manager /u/FocusOnLocus. These are really good suggestions. 
Ohhh, i thought that was the standard dictionary, i was like, dafuq
How about ass hole? 
Its a mechanical problem , not a personal one. Dont feel bad about it! There should be plenty of decent tutes on youtube about setting up an optimal audio recording environment and how to be postproduce video for perfect sound.
I think it's always worked with python3.5. Do you mean building python3.5 for Android? If so, python-for-android should support it in a couple of days.
Copying and pasting the error into google yields [this](http://stackoverflow.com/questions/19961239/pelican-3-3-pelican-quickstart-error-valueerror-unknown-locale-utf-8) :)
This sounds like the LaTeX math font is not found, and matplotlib falls back to a regular font. In the math font, Greek letters take the place of other characters, which is why they show up as =, * and @ in a regular font.
Would anyone recommend Kivy to an amateur? I've been looking towards making my first GUI stuff but never really got into it
I've tried it and it's surprisingly reliable on basic operations. Where it falls down is when you try to import more exotic stdlib modules, as you're wont to do out of habit. Development is fairly active and quite a few people actually depend on it for production sites, apparently. A bug I reported got fixed in a few weeks. The problem is that, like all *-on-js compilers, when abstractions inevitably break down, you have yet another layer to troubleshoot. If the overhead of dealing with this (and with the layer's own quirks) is not offset by dramatic productivity gains, then it's not worth it and you might as well just bite the JS bullet.
From the point of view of learning a gui framework, I think it's fine. Whether it's the best one to choose depends on what you want to do and what things you're worried about, though. For instance, if you want to make an Android app in python then it's the main choice you have, or if you want to make a 2D game it's quite flexible and performant, but if you want to make other kinds of app you may find the non-native widgets undesirable (you can change the default appearance easily, but it's always very hard to actually fully match native widgets).
What I never understood about neutral networks is, what are the inputs? Say you're trying to classify images, is each pixel an input, or do you do some kind of feature recognition first and then use the results of that as input?
Yeah, with a normal neural network each of the pixel is an input which takes a value on the grey scale (0-256) given that its a black&amp;white image.
Sorry for not pushing to pypi. I want to get some feedback before initial release.
Both libraries documentation are extense, just search for them on google a d start by tinkering with them, either with a small script or ipython. What you've been asked to do is documented in the pillow library documentation, uou shouldn't have any problems. 
I'll add that it depends a little bit on your approach to writing code. I tend to do a combination of a ton of Googling/Stack to look up "do XYZ in Python", and keeping a Terminal window open with the Python interactive shell running so that can quickly check that a line of code is going to do what I think it's going to do. So for my style of coding it's not a huge deal because, sure, sometimes I lose a couple of minutes trying to mentally keep straight the differences between 2.7 and 3.x, but in general I don't notice it since I'm always thinking more in pseudocode and then double-checking all the specifics regardless. Honestly my biggest PITA when trying to quickly churn out some code or test something is when I jump back to 3.x after having had to work in 2.7 for a while, because I inevitably keep autopiloting my way through writing print statements instead of print functions and then get yelled at by the Python interpretor. Or worse, I'll be testing some code in the interactive shell and then realize my mistake RIGHT as I'm hitting enter on the line, and with my luck it'll be the final line in a loop I was looking to verify the behavior was (it's annoying since I then have to cycle through multiple lines of my code history to do everything again). 
* PIL: http://effbot.org/imagingbook/ * Pillow: http://pillow.readthedocs.org/en/3.0.x/ * Numpy: http://docs.scipy.org/doc/ Beginner questions go to /r/learnpython, please read the sidebar :-).
It's more. For example the new regex module supports shorthand unicode classes like \p{L}, which will match all letters including German, Polish and others. The new module also supports variable width lookbehind (previously if you tried something like '(?&lt;=a|bb)' you would get an error).
No, Kivy is pure python/cython, displaying a gui using opengl. It works on mobile platforms by compiling the python interpreter for the target architecture/platform and using a native bootstrap (e.g. java on Android) to create an app and an opengl context, then starts kivy via a C script initializing the python interpreter. Nowadays we use SDL2 for this backend stuff. Kivy itself exposes the same API on all platforms, apps should work the same way on each of them, although interaction with platform-specific APIs is possible even on mobile. As for whether it's recommended, I gave a full answer in a [recent reddit post](https://www.reddit.com/r/Python/comments/3yf4hy/any_success_stories_about_python_on_android/cycwx1h). Converting python to java would be another approach, and actually Russell Keith-Magee recently started the [VOC project](https://github.com/pybee/voc) to make Android apps this way. It's in an early stage, but should in principle allow creating apps with native widgets (and has a POC already showing this). I think the main problem is the difficulty of being able to transpile all of python efficiently (i.e. without the result being too slow).
Abandoned in favor of?
There are several alternatives to client-side Python. Most of them try to hit some balance between performance and Python compatibility. [Pypy.js](http://pypyjs.org/) is pretty promising.
electron is good to build cross-platform application, which rodeo use.
Thanks for your kind words. Are you referring to the CLI interface? If yes, then I will be adding it in the next release :). 
Hey, are you thinking of this as a possible example of code for future resumes? If so, I would recommend turning this into a more idiomatic python project, maybe implement some kind of CLI tool via [click](http://click.pocoo.org/5/). Add unit tests too, upload the package to pypi, etc. It's an opportunity to demonstrate to a potential employer that you're capable of writing shippable python packages with English documentation. It's also a chance to learn how to do those things if you don't already know, because for most python jobs, they'll be requirements (at least I hope so).
Dude thanks alot for the criticism.. I was honestly hoping to get that when i uploaded the code. When I wrote this I just wanted to keep my mind busy so that I didn't have to keep on contemplating on my situation. I never thought of anything beyond that. But I am up for the challenge and take it to the next level and make the code way more efficient than it is right now.
This is a long shot but would you want to join up and make it bigger
Github is amazing. The next day after we put up Jython mirror on github we had a pull request submitted. No announcements were made, yet someone just contributed!
I'm not big on command line, maybe package it into a web app instead of using raw_input? The world of software engineering loves people that can build web apps. Plus it'd be pretty easy. Just my two cents :)
More for the backend. I do a lot of GIS stuff, and I'm curious about the data sources you used to build the backend. I run a lot of simulations and build a lot of statistical models, and it's the kind of stuff where I need to access lots of random data at particular times. Being able to host a local copy of this backend would be really useful to me (and a lot of other people I'm sure). 
And please answer his question, what is the roadpath for spacy.io, what is your plan for 2016, what will you also add on it? Thanks for your effort.
Click is not bad to learn. I suggested it to a co-worker for his python script and he picked it up not even being a traditionally trained programmer. 
If I may add to the list of advices. Why not throwing in a readthedoc and TravisCI autobuilds. You could as well add issues and milestones with tag names. It does feel lonely for a while, but it will increase the chances to get outside interaction and it counts as a github contribution. This way you demonstrate also other skill-sets. Edit: look at this [project](https://github.com/sqmk/huejay) for instance (it's not me!): it's mostly a one man gig, but there is a clear discipline demonstrated behind it. 
hey dude/tte I am really interested in trying to turn a program I made in Python into something that anyone can download and install. It seems that this would require packages to autoinstall. I'd love it if I could turn it into a "product." In other words, something a person could download and install without having to actually work with Python, or at the very minimum without having to install the libraries that I used. Unit tests. Pypi. English documentation. CLI tool (click. Idiomatic python project. I have to say, your comment is very helpful. I intend to look these things up. Thanks.
django, flask, etc. start getting complicated if you have to worry about setting up a db, deployment, and general other annoying infrastructure work. If you just want something to show off to future employers I'd recommend Google App Engine. Sure you have to play in their sandbox but it takes care of alot of the infrastructure headache for you so you can just worry about coding. Not saying infrastructure isn't an important skill to learn, it's just generally not a whole lot of fun :)
At this moment, this module requires you to have internet connectivity as it uses API's provided by Google and Ziptastic for serving the results. You can view the [source code](https://github.com/prodicus/pyzipcode-cli/blob/master/pyzipcode/pyzipcode.py) here
Oh, nice! Didn't realize it was pinging Google and others. Thanks!
http://gitxiv.com/posts/dQxgWraeWgvpKJXLG/musical-audio-synthesis-using-autoencoding-neural-nets
Perhaps this is easier to implement in the worker's code. * Are they waiting for a network request? Put a timeout in there and have the worker terminate itself when it hits it. * Are you processing large data sets? Put in a counter and/or timer that checks the time spent every X iterations and have the worker abort the processing if it hits the limit. This way you also get to clean up open sockets, file descriptors etc. before terminating the worker which is nice.
I would like to recommend Python Anywhere: https://www.pythonanywhere.com/. Fantastic site that matches perfectly along with your scalability.
C gives you a better understanding of how your computer works. For example, one day you might want to program low level stuff, python won't get you far there. You don't have to learn C, definitely not if you are just a hobby programmer, but it might be helpful one day. 
If you're learning to program then feel free to stick with Python. Eventually, though, you are likely to need another language - not necessarily C - for a number of reasons. Maybe you're coming in to a project and it already uses some other language, maybe you're in an environment where the Python interpreter isn't available, maybe your coworkers simply prefer another language because they have more experience with it. Python is very capable but it's not right for all contexts and other languages are also very capable as well. For a beginner whose learning to program, don't let any of that bother you for now. When it comes time to learn another language, you'll know because you'll really want to or you'll be required. Until then learning another language is more likely to distract from learning how to program.
&gt; Since _asdict() is a protected method I shouldn't use it. No it's not. It's part of the [documented interface](https://docs.python.org/3/library/collections.html#collections.namedtuple). It's meant to be used. Its name begins with an underscore to minimize the chances of clashing with the name of a user-defined field. It has nothing to do with being internal.
Sorry, meant Blu-ray.
I'm willing to bet the getattr method is much slower than my list comprehension. I would also argue that the list comprehension is much more readable and more pythonic. Edit: Since I'm interested in this kind of stuff I tested it. Here are the results: | Python Version | List comprehension | Getattr | |:---------------|-------------------:|:-------:| | Python 2.7.9 | 17.4s | 24.6s | | Python 3.4.2 | 15.8s | 19.7 | | PyPy 2.4.0 | 3.2s | 3.4s | As you can see, Python 3 with the List comprehension is very roughly twice as fast as the slowest method, Getattr with Python 2. Actually I'm impressed by the Python 3 results, it seems they made significant performance improvements. Also, *holy shit pypy is seriously fast*! This is the code I used: Getattr method: import re l = ['893319', 'e7041e', '2ca18e', '49127a', 'e69785'] for i in range(0, 20): l.extend(l) l2 = [x for x in (getattr(re.search(r'^\D(\d+)', s), 'group', lambda x:None)(1) for s in l) if x] List comprehension method: import re l = ['893319', 'e7041e', '2ca18e', '49127a', 'e69785'] for i in range(0, 20): l.extend(l) l2 = [m.group(1) for s in l for m in [re.search(r'^\D(\d+)', s)] if m] 
Because Python (at least CPython) is written in C. I gained a much deeper understanding of Python when I started writing C extensions.
That makes sense, I'm just wondering what the benefit of programming into the lower levels is? Are we talking about using GPU power to accelerate tasks like Adobesuite does? I'm just a hobby programmer but I'd love to know more about how my computer works, would you say that it's worth the effort to learn C for the benefits it offers?
I'm a total beginner so I'm not needing to switch contexts just yet! What kind of environments is python nor right for?
C will teach you to be a better programer, but first it will kick your arse. You'll need to learn about toolchains, pointers, how to deal with memory, and so on. However, at the end you'll probably want to come back to python. I use C occasionally for either optimizing a really really tight algorithm, or if I want to bridge a library into python. 
I'm interested in being a 'better programmer', especially after a bunch of people in this thread mentioned it but I'm not all that sure what it actually means! Are we talking about fitting with recommended styles or about using OOP more effectively... or something else entirely?
There are definitely a lot of cool applications for python and C. One of my friends had to program the visualization of the mandelbrot set for school stuff and he accelerated the calculation with some C and let python only manage the visual stuff. pretty neat, but I am neither really good at python nor C, so I don't know how you mix that easily ;)
There are many. For example: * There is only one language which can run in a browser, JavaScript, and so if you're going to make an interesting web app you will need to use JavaScript * Your program may be running on Windows systems and for users with little computer knowledge. Python does not come preinstalled on Windows and so a language like C# may be better since it's more common to have .Net installed. * Your program may need to run on an embedded system where Python is not installed and cannot be installed due to space requirements. A language like C may be better here. * You may need to build against libraries which do not have language bindings for Python or at least where it is significantly more effort to use Python. For example, you may need to publish an app on the Windows Store, the App Store, or have it run on Android.
Programming concepts are more or less naturally expressed in different languages. Learning a new language thus forces you to think in terms of new paradigms. This expands your algorithmic vocabulary and teaches you new solutions to old (and new) problems. Learning a new language is therefore always worth it, even if you end up never using the new (or old) language in practice. It is equally valuable to learn one "primary" language well, though, and you should not trade depth for breadth. Learn one thing well, and enough things well enough to know when to use them. In the long run, external forces will pre-select your language very often. Knowing more than one language/platform/technology will prepare you for that. 
First, I created [bitarray](https://pypi.python.org/pypi/bitarray) and learned a lot about the Python C-API. Then, I created [bsdiff4](https://pypi.python.org/pypi/bsdiff4) and [pycosat](https://pypi.python.org/pypi/pycosat).
Don't just show us the art man, post some code as well. People on here may be critical but trust me it's a good way to rid yourself of nasty habits.
Programming is like handicraft. You learn as you go and problems that at one point seemed complicated become more simple with time. Perhaps you learn to recognize patterns and known solutions, or you simply learn the best tool for a specific problem. Over time, not only do you learn how to approach problems, but you also learn how to cope with complications that occur in the process. Part of this is ofc fitting with recommended styles, but it also involves knowing when *not* to follow the style. Or more common perhaps, knowing *which* standard to follow. C in this case will give you a much deeper understanding of how a computer works, this will in turn help you understand many of the decisions done in Python. 
Not only is it slower, but some concepts such as const and type safety don't really exist in python and usually help immensely once your projects start to grow and more developers are added.
This sounds like a bug in Twisted. Perhaps you should report it at twistedmatrix.com?
you dont
Thanks man I will keep on dreaming.. Something will eventually give and it wont be me
Yeah I have always used PyCharm for the convenience of having a simulated command prompt as well as the ide available. It works well with most of the stuff I do with it..
Will do. Thanks.
I love it!
&gt; via click. I really like docopts. I picked it up last week and it's made making one off CLI scripts amazingly simple *with* documentation.
The same reason you'd learn another language. Learn German if you want to talk to the Germans. Learn French if you want to talk to the French. I've been on Python for about a year. That's on top of 15 years of PHP, 12 years of Matlab, 10 years of C and Javascript and if you count "How do I ____" years of Bash/script. They all have their spot.
I liked it so much that I forgot that I used it (crap, need to mention that in the doc) Seriously though, that's a compliment to the developer. I found it very straightforward to use. 
Because learning C would expand you programming culture greatly. You'll have a way better knowledge of what a microprocessors and operating systems really do. You'll appreciate how much work high level languages (like Python) do for you, and why it is ok using them inspite of they are so slow. You'll have a way to speed-up (x100 or even x1000) the performance-critical parts of your Python programs (I love the ctypes module of the standard library), whenever you need it.
Hey! This is beautiful work, and as a beginner Pythonista this is exactly the sort of project that I was interested in trying out myself. I forked it on GitHub, I hope you don't mind, and would love to keep picking at it and asking you questions. Are there any good tutorials or books you could recommend to start understanding the pieces? I think my biggest question is how the scraping gets done, and parsing that data. Where could someone go looking for the method that was used here?
I have taken both and written my experience [here before.](https://www.reddit.com/r/learnpython/comments/3gxjgm/how_i_learned_python_without_any_previous_coding/)
I read the post as suggesting you try it out as a demo, not to rely on it in any functional program. In any event, this looks like a great feature. I use format() for now, but I agree that it is unnecessarily verbose.
i think it's because it makes you better understand what is happening under the hood. Try writing a word frequency counter for example. You probably use a dictionary in python and be done in a couple of lines. In c you create a resizeable array, a hash function to generate indexes and a linked list for the collisions you get. It's the same thing and when you did that you'll be wondering if you can change the hash function in python for some specific input you have. You could use libraries in c to do all that but then you wouldn't have fun. Doing it manually makes you think about these few lines in python in a different way.
&gt; Explicit is better than implicit. &gt; Readability counts. &gt; Special cases aren't special enough to break the rules. &gt; There should be one-- and preferably only one --obvious way to do it. Hate it. We don't need another string format method, and this seems to spit in the face of pep 20.
Any extra resources on best practices on making your own exception?
I've heard that the Anaconda distribution makes installing Python and many common packages much easier. Worth checking out.
Most of the time, a custom exception doesn't need more than `class MyException(Exception): pass`. It'll support a string message as a first argument by default, and usually you're just looking for the type to introduce a new `except MyException:` capability for your caller. Check out how `requests.exceptions` introduces 10 or so exception types related to HTTP, but most of them have no implementation: https://github.com/kennethreitz/requests/blob/master/requests/exceptions.py Also notice the smart subclassing of the built-in `IOError` and `ValueError` types when that made sense.
I spent most of my winter break going through your course and I am halfway done. The videos are easy to follow and the pace is perfect for me. I can see a lot of this being very helpful for my office job. Well done, and thank you for making it free. I am planning on buying this course for my daughter who also wants to learn Python. 
Does it basically do a = 'Hello' b = 'World' '{a} {b}'.format(**locals()) (Typing this was more trouble than it was worth on my phone...)
Where are you located and what are you looking for?
+1. I hate JS, but it's better to go with it than to hide it.
I'm sure people will find this helpful since every other tutorial I've seen only addresses nginx. Personally I prefer nginx after using both for several years and would encourage anyone to look into it to see if it better meets their needs.
No,not according to the PEP. &gt; Guido stated [5] that any solution to better string interpolation would not use locals() or globals(). 
It could be that the Installer needs admin access. Sometimes the Admin prompt doesn't pop up automatically. Check to see if it is in your taskbar.
ive tried its still stuck on initializing 
&gt; In other words, something a person could download and install without having to actually work with Python, or at the very minimum without having to install the libraries that I used. pyInstaller + inno setup
"Squashed 195 (experimental) commits between 2015-10-28 and 2016-01-03." Why? It would be nice to have all those commits to see how the project matured.
I don't use Windows, but my coworkers do and found Anaconda much more manageable than vanilla Python.
&gt; Readability counts I find string interpolation a lot more readable than the format() or % methods. &gt; Explicit is better than implicit Better here too. Our strings now look like `"{var}"` instead of `"%s"` or `"{}"`. Yes, you could do this with format() and keyword args, but that's very verbose. &gt; There should be one obvious way to do it. I think this will become the new obvious way. It's very intuitive on the surface, and nicely matches what many other languages already do, while still being fully featured.
When people ask me why I dislike the Zen of python I point to comments like this. The ZoP is not a weapon to be used to attack progress and change.
&gt; Better here too. Our strings now look like `"{var}"` instead of `"%s"` or `"{}"`. Yes, you could do this with format() and keyword args, but that's very verbose. My format strings have always looked like that because extra characters do not cost me money. This also allows me to name the format() kwarg a name that makes sense for string readability, and my variable names can make sense for the code. "Hello {name}!".format(name=user.preferred_name) It's not a great example, but I hope you get what I mean. Edit: Fixed strong/string type
Essentially yes, that's what it accomplishes. The implantation is different.
Don't use your own exception for anything that is a standard exceptions. Espacially, a lot of things can be a IOError, ValueError or TypeError. If you do need an exception, try to have: - one general exception for your whole lib. MyLibError(Exception). - smalls exceptions inhériting from MyLibError matching a specific cas such as DontDoThatError(MyLibError). - make very clear error messages. Give the maximum of informations you can give. If you can't fit all but you know it's important, print a URL pointing to a page helping you to debug. - exception text can't hold non ASCII characters. Call repr(). - group all exceptions in an exceptions.py module, so they are easy to find and import for the people than will need to catch it.
What IDE is that?
Evennia and Eve Online are complex online games using Python. What you want depends on your programming skill. 
Speed could be a concern in some situations, but we'll keep improving that. Thanks for the idea of having different shortcuts for each client. (We'll remember that for the future.) Unicode key bindings should already work (I think), Python extensions will come in a following release.
The [PEP mentions](https://www.python.org/dev/peps/pep-0502/#reference-implementation-s) that you can use this functionality today as part of the [say library](https://pypi.python.org/pypi/say/). From the [project README](https://pypi.python.org/pypi/say/): from say import * x, nums, name = 12, list(range(4)), 'Fred' say("There are {x} things.") say("Nums has {len(nums)} items: {nums}") say("Name: {name!r}") Output: There are 12 things. Nums has 4 items: [0, 1, 2, 3] Name: 'Fred' This library is called out in the PEP as the reference implementation.
I trusted you Python, you said .format() was the future, % will be deprecated.
Hey that sounds great, I'm game! I could make us a slack so we could discuss new changes we want to make, and add more people as the project grows! 
Use subprocess.check_output or the new subprocess.run. I like f"", its just as safe and .format is the number one reason for too long lines.
hey sorry for the delay. Yeah go a head and make it yours and if you feel like you may want to contribute once you feel ready you can just PM me over here and we can def work something out. As for learning parsing, I would honestly suggest you start with the beautiful soup documentation and just browse it. Then Also the Urllib2 documentation. Honestly, learning how to parse by itself is relatively easy. But understanding what happens behind the scenes in my opinion is way more crucial. So what i did was learn HTML and a python framework just to get the gist of how the sites operate. Then after that, when i came back to beautiful soup it was second nature. For learning python, Coursera is my best friend. You tube is my mistress and esp the youtuber called sentdex.. he def took me out of my comfort zone.
In case you want a similar formatting function now (it doesn't support format specifiers): import re import inspect def f(s): pframe = inspect.currentframe().f_back def replace(match): ins = match.group(1) if ins is None: return '' else: return str(eval(ins, pframe.f_globals, pframe.f_locals)) return re.sub(r'\{(.*?)\}', replace, s) Example: def foo(x): def bb(x): return x*2 a = 33 b = 42 return f("a is {a} a+b is {a+b} bb(x) is {bb(x)}") print(foo(42)) # a is 33 a+b is 75 bb(x) is 84 Hacked in 5 minutes, so probably buggy.
Thank you! I look forward to seeing what else you create, and I hope you find a job!
A BDFL doesn't deal in absolutes. 
Yes, but not as the DRF documentation example describes passing "Token" via "Authorization" http header.
See I didn't. I knew .format was "too much" and % was the right trade off. And that they would back down from deprecation. So, I never have bothered with.format(). The new interpolated strings seem to bring .format back into the right trade off territory and I'll probably start using that.
Is there anything more you get out of click vs something like argparse?
Not anymore, I think it is laziness on the teachers part to continue with 2.7
Blog entry.
Or a replacement: https://github.com/berdario/pew
Part of your question wasn't answered: Yes Jython let's you use addons coded in Java. You can even use regular classes written in Java
It is a trivial difference, but now that expressions can happen in the string you cannot overlook the string when reading code for errors of function. Without this, strings are literals in which nothing can happen. (of course you can make things happen by parsing it with a function like format) Now one must look for meaning within the string itself. Old habits die hard but I usually treat strings like I can look right over them, or at least look straight to the the format parameters to make sure the correct vars got in to it. I don't know. I'll come around. 
You *really* want to use [`blessings`](https://pypi.python.org/pypi/blessings/) which is an abstraction layer on top of `curses`. Won't work on windows if that's a problem. something like: import blessings term = blessings.Terminal() with term.fullscreen(): while True: term.move(0, 0) # move to top of screen print('fish simulation') os.sleep(1) should work ok. 
Sorry, I had trouble understanding what you're asking with this post: are you asking for code review? If so, what immediately jumps out is that lines 28, 31, and 34 aren't assigning any values to the **message** variable. Also you could move that logic into a function and consider putting the messages into a data structure, such as a dict, for better access and maintainability. &gt; Also, anyone know how I can set it to run on a time schedule? Have you tried using [cron (linux)?](https://en.wikipedia.org/wiki/Cron). 
Benevolent Dictator For Life
Although I would leave perl til last, and perhaps not even bother. There may be a lot of legacy perl out there, but not a lot of new projects in the last decade.
This would be something cool to have. If you find it let me know.
They've defined a function `f("")` that mimics `f""`. It takes the current frame (the executing `f()` function itself), then jumps up the call stack to the code that called it in order to obtain the visible variables at that point. It then uses a regular expression to replace variables in the string with their values. It's limited – for instance, it only handles straight replacements, not embedded expressions – and it could probably be simplified/improved by using `format()` which would avoid regular expressions and support `__format__()`. Probably best to look at it as a limited demo of the future functionality rather than something you should rely on. 
The amount of code deprecating % is going to break - I don't think they're going to be able to do it even on their long timeline.
Or Windows scheduler if you are running it on Windows.
I know. /u/roger_ originally wrote BFDL not BDFL
First of all it's not a Python question. I don't have any experience with Oracle DB, but I'm 100% sure you can set up your database to allow access from hosts other than localhost, then connect to it from your application just like you would to any other database over the network.
&gt;Do you think it makes sense to point to these repositories? Seeing as there's no commit messages and it seems to be a testing ground more than anything: no :)
It's running off of 2.7. Is it really that much slower? Do you think it would be worth it to roll my own implementation?
I was happy that it seemed like % wouldn't be deprecated (as opposed to just being "bad form"). I'm a bit shocked that this went through: having three different ways of doing the same way in Python is inelegant as fuck. But I like it: this new method seems to have solved all the previous problems (% being too manual and .format being too verbose).
I just realized this formatting is similar to jinja2 templating language. So here's a crazy idea: why don't we use jinja2 for string templating? 
Box2d and Chipmunk are the major 2d physics engines on the market. There is no such thing as a 'network-friendly' physics engine as the simulation will always require you to simulate the physics on the server and report the results to all other players. I personally prefer Chipmunk as I like the cut of its jib, but, whenever you decide to give control of movement and collision logic to a physics simulation you will gain much complexity in terms of coming up with an 'in simulation' solution to certain problems. Physics simulations solve over time so they must absolutely influence nearly all parts of your game that involve movement of objects as anything that is introduced from outside the simulation will destabilize it.
i sort of wish that they fully generalized this instead. So that one could define arbitrary interpretation time prefixes to do whatever.' def prefix(str, **kwargs): return str.format(**kwargs) builtin_add_string_iterpolator(prefix) prefix'woah {} woah {}' == 'woah wat woah wat # not that any of the above code would really make sense from a realistic standpoint granted I haven't thought about this for more than the time that it took me to write this, but I feel like this could be used to do something like "compile" time checked syntax checking for strings that contain SQL statements or whatever else kind of structured data that one puts into string literals.
Oh I promise if I could get rid of the recursion I would. I'm fairly certain there's a flat math equation behind GetLRCoefficient that would be SO much better, but I can't figure out what it is. Also I forgot to mention I can only use the modules that come with Python.
which version of Python and why? You can download conda or WinPython or that come with numpy or use Portable Python (no install required), so depending on how you define that... &gt; I'm fairly certain there's a flat math equation behind GetLRCoefficient Can you source the equation?
Stuck on 2.7 for the time being, unfortunately. Yeah, I read up on the differences. So it doesn't look like that's going to be something I can optimize unless their version isn't cached (or memoized, whichever you prefer). Maybe I'll give that a shot. Edit: That said, of the time spent in my program on a very minute fraction is spent in the factorial function. 
With regards to app prototyping, or building an MVP before fully commiting to developing a Java app, how kivy ? how big of advantage is with regards to productivity ? to ease of learning for a new programmer and the possibility of getting talent ? 
Thank you for linking that! I just finished the first course in the set of "Programming for Everybody" [98%! &amp; the verified certificate] &amp; am really pleased with how much I know already. I'm signing up for the next one immediately! If you haven't started Codecademy yet, I hiiiiighly recommend it. It keeps my mind nice &amp; fresh on all of the concepts. It moves through them differently but I think it's nice to switch things up when you're learning... Keeps you from simply "memorizing" information, yanno? I really can't wait for the point I can finally get through PythonChallenge &amp; the Project Euler problems... Pretty difficult for me at this point, though, lol.
I'm running 2.7. It's for something of a coding challenge, so that can't be changed. And I'm only allowed one file. &gt; Can you source the equation. Unfortunately that I'm aware of there isn't one. Basically GetLRCoefficient gives me the number of permutations of a binary set of a given length whose members are arranged in a particular order. RRRR RLRRRR RRLRRR RRRLRR RLRLRRRR RLRRLRRR RLRRRLRR RRLLRRRR RRLRLRRR RRLRRLRR RRRLLRRR RRRLRLRR RLRLRLRRRR RLRLRRLRRR RLRLRRRLRR RLRRLLRRRR RLRRLRLRRR RLRRLRRLRR RLRRRLLRRR RLRRRLRLRR RRLLRLRRRR RRLLRRLRRR RRLLRRRLRR RRLRLLRRRR RRLRLRLRRR RRLRLRRLRR RRLRRLLRRR RRLRRLRLRR RRRLLLRRRR RRRLLRLRRR RRRLLRRLRR RRRLRLLRRR RRRLRLRLRR So there's one valid permutation with a length of four (`GetLRCoefficient(0,5) == 1`), three permutations with a length of 5 (`GetLRCoefficient(1,5) == 3`), 8 permutations with a length of 7 (`GetLRCoefficient(2,5) == 8`), and so on... (I can post the code to generate valid sets, if you like) If you look at the valid sets for square_space = 4, the equation could flatten to a simple `2 ** i`. But that's as far as that goes. Additionally, if you like (if you're a mathematician, maybe you see a pattern I (not a mathematician) am not aware of), here's a table of all the coefficients for i from 0 to 9 and square_space from 3 to 12: 0 1 2 3 4 5 6 7 8 9 +--------------------------------------------------------------------------------+ 3 |1 1 1 1 1 1 1 1 1 1 | 4 |1 2 4 8 16 32 64 128 256 512 | 5 |1 3 8 21 55 144 377 987 2584 6765 | 6 |1 4 13 40 121 364 1093 3280 9841 29524 | 7 |1 5 19 66 221 728 2380 7753 25213 81927 | 8 |1 6 26 100 364 1288 4488 15504 53296 182688 | 9 |1 7 34 143 560 2108 7752 28101 100947 360526 | 10 |1 8 43 196 820 3264 12597 47652 177859 657800 | 11 |1 9 53 260 1156 4845 19551 76912 297275 1134705 | 12 |1 10 64 336 1581 6954 29260 119416 476905 1874730 | +--------------------------------------------------------------------------------+
1) Why in the world would you ever write the 2nd and 3rd examples that you give? 1B) Why even write the first one? Watch this... remember your good old Pascal. Assume the location is in variable "world": print("Hello", world) No need for an f-string (and you know people are going to forget the "f", leading to printing errors). If your print requirement is so simple it can use f-strings, you can just put the variables in the print statement itself. Whatever happened to "there should be one - and preferably only one - obvious way in which to do it?" 
 print("String", var_name) Same thing, no new syntax, no 3rd way to print things. I'm beginning to worry a bit about what's going on up at Python HQ. 
Looks interesting! It's always bugged me that virtualenvwrapper uses different commands instead of subcommands
My first thought is that this feels more like Perl or Matlab syntax than Python. I suppose I'll get used to it.
Because it could eventually turn into this: print("Hello ", firstname, " ", lastname, " you are at a ", location, " where the time is ", sometime) It should be simpler. It should be more readable. What if the variable you're passing in is not a string? What if you want decimal values. What if you need more than one thing to insert into the string. There's so much more that's needed. It could be: print(f'Hello {firstname} {lastname} you are at a {location} where the time is {sometime}') Now tell me which one you'd like better. 
Not quite, string interpolation is more along the lines of (str(a) + ' ' + str(b)) which also will get non-locals, which was the major problem with using `locals`
Do you just need the oracle database or is there a bunch more on there I'm not aware of? If it's just the db, look into docker and expose the correct port.
Int makes it pretty clear at a glance, and since it doesn't have runtime implications I would favor the ease of readability. Anyone working with `async def`s around should know that it's a generator like construct. 
according to you, not according to the owner of the language if I remember, the bdfl response to the zen being brought up in the mailing list was roughly "stfu"
Both of your examples: They are the same thing with a little f and curly brackets instead of quotes and commas. What happened to ONE way... Explicit is better than implicit. 
I'm going for what works better for my workflow. Right now formatting strings is a pain in the ass. It makes me miss Perl's string formatting. 
That's really a good way to look at this question. After all we all need to eat. 
https://www.youtube.com/watch?v=_RSSsT6Uzow
Isn't the equivalent built into Python now?
Sorry, yeah. GetPermutations would be better renamed to GetPermutationCount. In any event, yeah, I would LOVE a formula. Would make the GetLRCoefficient function much simpler. As of yet though, I can't figure out or find a formula that doesn't use recursion. Edit: I'm looking at permutation of multisets and that does get me close to a correct answer, unfortunately past i=1, the answers are over the correct answer by a bit. Edit2: Just a bit of preliminary data, if you're interested: **Correct Coefficients** 0 1 2 3 4 5 6 7 8 9 +--------------------------------------------------------------------------------+ 4 |1 2 4 8 16 32 64 128 256 512 | 5 |1 3 8 21 55 144 377 987 2584 6765 | 6 |1 4 13 40 121 364 1093 3280 9841 29524 | 7 |1 5 19 66 221 728 2380 7753 25213 81927 | 8 |1 6 26 100 364 1288 4488 15504 53296 182688 | 9 |1 7 34 143 560 2108 7752 28101 100947 360526 | 10 |1 8 43 196 820 3264 12597 47652 177859 657800 | 11 |1 9 53 260 1156 4845 19551 76912 297275 1134705 | 12 |1 10 64 336 1581 6954 29260 119416 476905 1874730 | +--------------------------------------------------------------------------------+ **Using `((n - 4) + (i * 2))! / (i! * (((n - 4) + (i * 2)) - i)!)`** 0 1 2 3 4 5 6 7 8 9 +--------------------------------------------------------------------------------+ 4 |1 2 6 20 70 252 924 3432 12870 48620 | 5 |1 3 10 35 126 462 1716 6435 24310 92378 | 6 |1 4 15 56 210 792 3003 11440 43758 167960 | 7 |1 5 21 84 330 1287 5005 19448 75582 293930 | 8 |1 6 28 120 495 2002 8008 31824 125970 497420 | 9 |1 7 36 165 715 3003 12376 50388 203490 817190 | 10 |1 8 45 220 1001 4368 18564 77520 319770 1307504 | 11 |1 9 55 286 1365 6188 27132 116280 490314 2042975 | 12 |1 10 66 364 1820 8568 38760 170544 735471 3124550 | +--------------------------------------------------------------------------------+ **Difference of the Two** 0 1 2 3 4 5 6 7 8 9 +--------------------------------------------------------------------------------+ 4 |0 0 2 12 54 220 860 3304 12614 48108 | 5 |0 0 2 14 71 318 1339 5448 21726 85613 | 6 |0 0 2 16 89 428 1910 8160 33917 138436 | 7 |0 0 2 18 109 559 2625 11695 50369 212003 | 8 |0 0 2 20 131 714 3520 16320 72674 314732 | 9 |0 0 2 22 155 895 4624 22287 102543 456664 | 10 |0 0 2 24 181 1104 5967 29868 141911 649704 | 11 |0 0 2 26 209 1343 7581 39368 193039 908270 | 12 |0 0 2 28 239 1614 9500 51128 258566 1249820 | +--------------------------------------------------------------------------------+
If you have the freedom to use [only Python 3.3 or newer](https://docs.python.org/3/library/venv.html).
There are different ways you could go about it, depending on how you model the problem and what kind of user-feedback data you assume is available. One way to model the situation is to assume that there exists some unknown utility function *U*(**x**) on the vector parameter space. This function represents the person's subjective judgement about the sound quality, i.e., it is the function returning the person's rating values. (It could be multi-modal or unimodal, depending on what assumptions are made.) You would like to at least locally optimize points (presets) within their particular regions of the parameter space. You also want to generate new points (locally or globally) which are likely to be good. The user provides data in some form which is used to estimate *U*, either directly or indirectly. This estimate is then used to generate new points to test. There are different ways to do that, such as by gradient ascent from a given point, by treating *U* as a likelihood and sampling from it, or just generating a collection of random points and taking the estimated best one. There are different kinds of feedback data the user can provide. For example: * An absolute *U* value, such as a continuous rating scale from 1-10. * A relative *U* value, the estimated difference in *U* between two points (A/B comparison). * A relative ranking, where the user simply says whether the *U* rating value is higher or lower than the *U* value of another point. * A binary good/bad value. One approach is to adaptively estimate *U* via some function estimation technique. If your problem involves *n*=2000 parameters (features), though, you may have problems with techniques that require *n*^2 space and time. Fully-connected neural nets with *O*(*n*) neurons and basic second-order statistical methods (covariance matrices) fall into that category. In those cases you could use alternative functional estimation techniques or feature reduction methods on the feature vectors. A simple function-estimation approach, given absolute rating data, would be to train a backpropagation network to learn the function *U*. The network should produce a single output value *U*(**x**) when presented with an input feature vector **x**. You would need to choose the number of neurons *m* in the input layer small enough so that *nm* is manageable. One downside is that you cannot easily sample from this function. Nevertheless, you could generate a bunch of candidate points (maybe within some fixed distance) and use the one with the largest predicted rating value. You may or may not want separate rating-estimators for the different types of parameter vectors (presets). You might want a linear activation function on the output node. You could also consider using a genetic algorithm, taking the function *U* as the fitness value for a parameter vector. As a simple starting point, you might play around with weighted averages, weighted by rating values. Or maybe sample a few training data points based on their rating values and then combine them in some way. It's an interesting problem, but I'll leave it at that. Good luck with it, and I hope this helped.
Personally I would rather the second string with `.format(**locals())`
I'm fine with this proposal as long as `f'{hey}' == '{hey}'.format(hey=hey)` There is value in constructing a template separately from the string formatting and having them be the same implementation (i.e. not with their own separate gotchas and idiosyncracies). This is something I've had trouble finding in other languages that have had string interpolation for a long time.
If this is progress, I really don't like where Python is going. I liked Python 2.2 to 2.7. And I loved the move to Py3 because *it made sense*. Backtracking on some of those changes also made sense, once it was clear some well-meaning restrictions were a bit too strict for the ecosystem at large. But this is really unpythonic. It will make it harder to figure out which variable is pulled from where. It introduces yet another literal prefix, and literal prefixes have always been a hack that degrades readability (it's *so* easy to miss ONE LETTER). And the thought of having to read yet another small-and-badly-specified DSL *inside output strings* is sickening. Honestly, this looks like a Perl/PHP format, not a Python one. I hope it doesn't gain traction, I'll stick to format(), thank you.
what's the command you use to give that dashboard thing in the upper left hand pane in the first picture?
First off thanks for your great post. &gt; You could also consider using a genetic algorithm, taking the function U as the fitness value for a parameter vector. Thats what im currently working on. The way a ga works (atleast how i build it, with the user rating as fitness) makes it be kind of stupid. Its stupid in a way that it can not know that if lets say one oscillator was a sine wave, and the pitch was down at c2 that I also liked distortion. thats the kind of thing I hoped I could get an ann to do. sadly the python interface in the digital audioworstation crashes when I want to use numpy (wich also means lots of the nice librarys for this stuff are gone) ill first have to sort this stuff out or maybe run the ann from outside. Also thanks for the reminder about the o notation. my current test subject has about 250 parameters, I also had one with 2k tho and already noticed a difference using functions that are O(1). I already have a feature reduction implemented if its necsessary I can use that in the ann too. Anyways your post opened my eyes a bit. I thought it will be like a genetic algorithm where i just did and did until it worked and kinda figured it all out, wich wasnt that hard. A ann is a whole different story that requires more planning and knowledge. Ill still try the 200 input 200 output nodes thing (that I first imagined), just for fun. Theres endless possibilities. For now I go through the scikit-learn tutorials until I fully understand your post. Thanks very much so far!
Glad you figure it out. Perhaps you should be happy to know that we (i.e. Continuum) are working in a new project (not public yet) to ease the use of environments with Spyder and the Jupyter Notebook :-)
But it says it's entirely open source and self hosted. That's the part that I don't understand.
There is no difficulty seeing where variables come from unless your functions are absolutely massive. Also I find `format` to be much more verbose compared to f strings. I'll be glad to have this concise notation. 
The f is explicit. Again people are using ZoP as some kind of weapon akin to "God is on our side so we must be right!".
I actually use [cymunk](https://github.com/tito/cymunk) instead of pymunk, which is a cython wrapper over the chipmunk library. I prefer the cython approach as it makes it much easier to write lower level / more performant code and integrates better with packaging tools such as python-for-android. Nothing wrong with pymunk and it is definitely more established, but cython is key to developing great games in python I think.
Or Mark Shu... Never mind.
Your app just seems to call out for an interactive environment. I'm not really that good of a Python programmer, I just use it as a tool from time to time. Maybe after catching up on other stuff I will give it a deeper look this winter. I've been interested in solar power for a very long time but never really found it cost effective. That is changing slowly but it is changing. 
&gt;Because it could eventually turn into this: print("Hello ", firstname, " ", lastname, " you are at a ", location, " where the time is ", sometime) Which is perfectly simple and readable and in fact if we change "print" to "WriteLn" and add a semicolon at the end it's executable Delphi today. :-) &gt;What if the variable you're passing in is not a string? That works just fine (you're using a comma, not a plus, between strings and variables). &gt; What if you want decimal values. We have format for that already. The counter is that f-string saves us characters for simple examples. My point is those same simple examples are just as simple in the above style, which leaves no example where f-strings bring any significant benefit. &gt; What if you need more than one thing to insert into the string. There's so much &gt;more that's needed. There's no f-string example I can conceive of where it's simpler than both the format style and the "Pascal style" if you will I used above. No one making libraries like "say" is using a convincing example in their documentation either so far. &gt;Now tell me which one you'd like better. No difference in readability, except it's incredibly likely to miss the "f". This, however, will still let the code run without error, which is no fun at all. 
https://github.com/boxed/instar is based on a similar problem space. In clojure this type of thing is all everyone does all the time. 
Oh yea and check out pyrsistent. It has an instar-like transformation system
Has anyone ever really said "I've got this great new module idea for the standard library but.... eeeeew, Mercurial? NO THANKS. Hello Ruby!"??? Both Git and Mercurial have plugins to talk to the other so someone who wanted to stick with one could still do so, so I'm not seeing hypothetical new contributors as a realistic reason to go through a change like that.
htop
No, when Linus' daughter needed superuser privilege to install a printer driver in a version of OpenSUSE a few years ago, Torvalds specifically told the OpenSUSE security team that they should go kill themselves. This was about two years after a bullied teen in New Jersey, USA jumped off a bridge and a national movement began against bullying and obviously suicide. http://www.theregister.co.uk/2012/02/29/torvalds_tantrum_opensuse/ 
Are you using Kivy?
If UnknownBrandOfHam is raised by: ham.select('spam', foo=bar) I'm ok with it. If it's raised by: ham['spam'] with ham having __getitem__ overrided, it may be overkill. But that's not a BIG deal. I wouldn't do it, but I would not hate you if you did.
Plus pew works under windows with just a pip install.
keyword is "preferably". Also "Simple is better than complex", "practicality beats purity" and "Readability counts". The zen is not the bible, you don't get to cherrypick the stuff you want to make your case. Plus, they are just guide lines, in the end, you have a debate in the python dev mailing list with reasonable people making their case.
This is why it went through. Everybody agreed it sucks to have so many ways to format, but it's not a pragmatic reason to put such a good feature on hold and live in the past (as most modern languages have this).
More like: ({:pattern"}".format(a) + ' ' + {:pattern"}".format(b)) Because you need to account for the special syntax of format() markers.
Because : https://www.reddit.com/r/Python/comments/3z9qsa/new_string_formatting_in_python/cylc432
I don't think that syntax is quite correct (missing quotes), but, for future reference regardless: `format(a,a_pattern)` will work to apply a format pattern to a variable
At least the logging module should have used format.
Thanks. I tried it and collected some notes about its usage here: https://github.com/jabbalaci/MyPew .
Thanks nerdwaller. Yeah i had the same issue most of the tutorials were for nginx and even the ones for apache dont go it very detail. When i tried deploying an app to digital ocean i literally wanted to bang my head on the wall haha. Anyways hope it helps others and they dont have to come close to going mad lol.
The logging module should be re worked to actually follow the python coding standards. It would be fine to just add aliases to not break backwards compatibility but provide a more consistent interface. I hate littering pieces into my code for `getLogger` when everything else is snake case (`get_logger`).
Seems pretty evil to me to make python code look like shell code :P
I thought what Pew did was to build virtualenvs, just keeping them all in a centralized directory? If that's the case, PyCharm should be able to handle it fine -- you can specify a venv outside of the main project dir.
Sweet, thanks for doing that!
Yes, lamba is not needed here. Thank you for noticing it
&gt; OP, you're delusional. jeez
One of the projects I'm working on, is juggling thousands of jobs. Each job handles downloading files from clients, transforming them, and uploading to internal service. In perfect world no such tools would be needed, but in reality... There are various problems along the way. Connection problems, internal services crashes, client services crashes etc. Some stupid reasons comes up once in a while, and server needs to be ready for those. Timeout helps with some rare corner cases eg. once client gave streaming HTTP response which never ends :) And retry is useful to prevent some silly failures. If error persist few times in a row - it is quite reasonable to notify team about that 
If I am not wrong, you are better off using numpy. But if you don't want to use numpy, you can use list comprehension. You should store your coordinates in two lists, like this: X = [[1,2,3,4,5], [2,4,6,8,10]] The first list item is your x coordinates, the second is your y coordinates. X[1] = [2*a for a in X[1]] The above code will change all the y coordinates and replace them by 2* the last old y. I am a beginner too... I am sure there are more elegant ways to do it. 
I'll look into numpy but good idea on the structure either way I reckon. Thanks
If you are reading from a CSV file, I have a code which does the import and creates lists for x,y,z.... coordinates. I can share with you if you want
Why not simply sort the output?
It definitely does have better exception handling than my quick stab- the main difference is that it opens the file in exclusive mode- which doesn't work on NFS.
I wrote about it in the blog post: most of the time I am not the author of the output code I am using and I do not want to start modifying it.
 import requests def request_ws(request): with open(archivo_request,"r") as archivo: request_data = archivo.read() target_url = "http://127.0.0.1/testws?wsdl" headers = {'Content-type':'text/xml'} data_response = requests.post(target_url, data=request_data, headers=headers) First I open and read the file I use to make the request(Is a pre-formatted xml file). Important: specified the headers for your request. Send the request using the library [Requests](http://docs.python-requests.org/en/latest/) You can get the response as json,text or raw. If you have any doubt I will bring you a file with my views and functions and a more detailed explanation. I am not a expert with Web services and Python, but like you I struggle to make my app work with SOAP web services. I first I try to use SUDS, but I have some issues and I try REQUESTS and works for me 
:P true, but the library is based around pipelines, and piping output from one task to the next, and if there is one thing shells get right it's that. So I naturally jumped to using the `|` operator, and I still maintain that it looks better than the more Pythonic version. But I can see the argument against that, I will offer both in the documentation :) I also need some more examples!
I do like how simple it is to get applications written in pygame working on Android using pygame_sdl2, although there are a few much needed features in pygame which I haven't been able to get working using pygame_sdl2, such as the Mixer module, and certain methods for Rect objects. A lot of it has been just trail and error to see what works and what doesn't. 
thanks for the followup :)
can the credits for this course be accepted at a university if i buy the verified certificate? i want to work towards a degree in cs and it would be nice to know if these credits can be counted.
&gt; That's a handful of companies, and most of them only write a fraction of their code in Python. If you like Python? You should know how Python is used in the programming world. If you don't believe me then search in internet how Python powered the Youtube, Dropbox, Instagram, etc. There's many big company that used Python in everything.
Miniconda is just conda + python. I think you're thinking of Anaconda which is conda + large collection of python packages (scientific stack plus extras), bundled into a single installer or available as a metapackage. conda itself is common to both and is just the package/environment manager.
I love conda, but it solves a problem that not everyone in the python world has, namely external non-python dependencies. This is a major issue for those of us working in the scientific computing/datascience space, but perhaps not so much for people working in a world filled with pure python packages. Given that virtualenvs pre-date conda, I wouldn't expect people to jump technologies (especially one with wide adoption), unless they see a compelling reason, even if there is feature parity between the two.
Interesting, seems like it could work nicely with something more manual than SQLite, managing my own files (hell, if I feel really frisky one of these days I might download SQLite source and try to hack something). Thanks for the link, seems very useful.
Ah ok. Im new to Python (and programming) but I had an idea for an Android App (basic data entry and calculations/displaying of data) and was wondering of the best way of trying to get it working. If I write in Python and get it working, if it then that much more work to get it working through Kivy? Im really not sure how to approach it. Any advice welcome :) 
This is solved by having an editor that gives a different syntax highlighting to f-literals.
Conda is an ugly hack around that Windows doesn't ship with a C compiler. It sort of works if you stick to their distribution, but it shouldn't be the default.
Hey! I'd like to help out with building into this project as well if you don't mind!
I will take a look at that and have a solution up by tomorrow morning
https://github.com/search?utf8=%E2%9C%93&amp;q=code.google.com&amp;type=Issues&amp;ref=searchresults&amp;l=go No, importing from sites is not good. The distinction is nicely described here: https://caremad.io/2013/07/setup-vs-requirement/ 
Its pretty easy to get a raspberry pi up and running with an attached camera module (be that the official camera module or a usb webcam) and the opencv python bindings. This shouldn't bee too difficult even for people with little experience coding or using the Rpi. However, that's only like 1% of the work ahead of you. Implementing facial recognition using Opencv has been done before and there are probably a number of blog posts about it - however for someone with little to no coding experience, this is certainly going to be a challenge. Next the problem is that you aren't just needing to detect a face but then compare that image to a database of known images and check for a match. Again, this can (and has) all been done before but to implement it is absolutely not straightforward for someone with little to know coding experience. You'll need to know a lot about what it means to 'compare two images' You're essentially needing to detect a still shot of someones face, then search your data base and compare your captured image to each known image, run some type of comparison algorithm, and then make a decision based on the outcome of the matching algorithm. The code which interfaces the RPi to the keypad should be the easiest part assuming that keypad can be interfaced with the raspberry pi GPIO bus(general purpose input output). There's a python library RPi.GPIO which handles the brunt of the work for you, its just a matter of wiring up the circuit and connecting the buttons to various pins on the GPIO then writing some logic to handle what happens when a button is pressed. If I were you I would start with the GPIO stuff and amke sure you get a grasp of basic python programming, how to use the GPIO,how to handle button presses with the GPIO, etc ... That will be the easier part of the project. Everything else using Opencv is going to require an immense amount of work if you are new to coding. There is likely to be some mathematics involved that may be over your head in the algorithms for image comparison. There is a lot to learn but nothing you mentioned seems impossible. However, I just wanted you to realize the extent of the project you're trying to do. To my knowledge there's no simple package you can import to do all the facial recognition and image comparison of you. You'll instead need to read a lot of blog posts about using opencv and then find a way to adapt their code to your project. edit: some sources to check out - http://www.open-electronics.org/raspberry-pi-and-the-camera-pi-module-face-recognition-tutorial/ https://www.raspberrypi.org/forums/viewtopic.php?f=37&amp;t=34235 http://openmicros.org/index.php/articles/94-ciseco-product-documentation/raspberry-pi/217-getting-started-with-raspberry-pi-gpio-and-python http://razzpisampler.oreilly.com/ch07.html https://www.raspberrypi.org/learning/push-button-stop-motion/
Hopefully the f" prefix and an editor with good syntax highlighting should mean that the majority of strings can still be skimmed over.
It's not for real use, just an experiment. I've also mentioned `Please don't use it` on github.
I don't want to waste a time creating a set of functions. Somebody has created a tool, so let's use it.
Ug, Raspberry Pi cameras don't show up as v4l(2) devices? That seems like something that a kernel module should handle and make it register as a standard device, not the program consuming the camera feed.
1: Python is a language. It can (in principal) do anything a computer can do. 2: The language is free. Dev time is not. Costing of setting up such an application, and running it would be dependent on too many factors to give a guesstimate from the data provided. The last scraping project I did indexed a forum with ~30,000 users. It took me roughly 10 hours to write, and about 20 hours to run. Using my price per hour, and what I paid for the servers that would be less than ~$500 of which only $0.14 was server rental (Since it was my time, and I didn't have to pay for it my actual money spent on the project was in the ~$0.14 range). Have a look at projects like fiverr (https://www.fiverr.com/) for cheap dev work. People typically charge $5-$10 for solving "smallish" problems. I would break this problem down to several "smallish" problems, then farm out what I was unwilling/unable to write. 3: Scrapy, BeautifulSoup, requests, selenium, phantomJS, the list is boundless. Typically unless I *need* a full browser I use requests and BeautifulSoup. All of that covers getting the information out of the application. Consuming the information into the target application would be entirely dependent on the target application. Very quick example: from bs4 import BeautifulSoup import requests def get_page(url): try: raw = requests.get(url) return(raw) except Exception as e: raise(e) def parse_page(raw): try: soup = BeautifulSoup(raw.text) #... do something with the soup object ie interesting_data = soup.find(id="link3") return(interesting_data) except Exception as e: raise(e) try: interesting_data = parse_page(get_page('https://www.google.com')) except Exception as e: print(e) I hope that was helpful.
I can use scrapy, a flexible and reliable scraping tool writen in python. http://scrapy.org/
It took me like 10 minutes to move what I was doing manually into a function though, so didn't waste much time. I used to use virtualenvwrapper, when I started with Python. But I couldn't figure out how to have virtualenvwrapper put my virtualenvs in the current working directory. That's exactly what my functions do, no more, no less.
&gt;I've tried out and configured a few linters (in order to help everyone in the project to conform to code standards). I'll probably push for more or less unmodified PEP8, but I'm flexible on this. If you do end up following pep8 (which, barring maybe tweaking the 79 character line length limit, you should), I recommend using [flake8](https://pypi.python.org/pypi/flake8) for linting. It packages a number of useful linters and supports file exclusion via a comment header (# flake8: noqa) which is useful for excluding things like migrations, url routing configurations, settings, constants etc. &gt;I'm used to writing docstrings, but I've never used any tools to generate documentation. Is there a specific tool that I ought to use? [Sphinx](http://sphinx-doc.org/) is *the* python documentation generator. You mark up your docstrings and write your documentation using reStructuredText (RST) and it generates fully indexed and hyperlinked documentation. See also: [sphinx_rtd_theme](https://github.com/snide/sphinx_rtd_theme) for readthedocs.org style &gt;vim+tmux+zsh Whatever works best for you is fine really. I do however highly recommend [PyCharm](https://www.jetbrains.com/pycharm/). 
Yeah, you'll need sep="", then alter the spaces at the end of the strings. Houra for f-strings !
Also, add beforeEach(function() { browser.driver.manage().window().setSize(1280, 1024); }); Just in case this is a silly responsive design quirk
Linked channels documentation to ASGI spec, I see you're part of that as well, is this the same thing? I didn't even see the links in the closing until after [posted!](https://channels.readthedocs.org/en/latest/asgi.html).
You *can* make the Raspberry Pi work with the V4L2 driver, but I personally haven't had much luck with it. When I tried it, I had to compile the module by hand and it was often buggy with the `cv2.VideoCapture` function. Perhaps my experience was an anomaly. But in either case, there are many Raspberry Pi developers who prefer to use `picamera` simply because of the simplicity.
This is related to [THIS](https://www.reddit.com/r/Python/comments/3zg036/wsgi_20_round_2_requirements_and_call_for_interest/?ref=share&amp;ref_source=link) post. They are looking for help!
have a look at beautiful soup for parsing the html
I believe the reason he's telling you to try numpy is because the numpy library comes with a built-in class called an "array" that functions nearly identically to a list. However, you can perform operations on the array such as scalar multiplication without running a loop, but you'd still need two separate lists/arrays for x and y. X = numpy.array([1, 3, 5]) Y = numpy.array([2, 4, 6]) ------------------------------------------------------------- 2*X --&gt; numpy.array([2, 6, 10]) -1*Y --&gt; numpy.array([-2, -4, -6]) list(zip(2*X,-1*Y)) --&gt; [[2, -2], [6, -4], [10, -6]] Honestly, though, for your case, you might be better off just doing the one-line list-gen like /u/tortxof did.
In general, I'm partial to keep coordinates together in a tuple. If you ever need to separate them, you can just `zip(*coords)` to get them. That being said, numpy is indeed a better method. In [1]: import numpy as np In [2]: coords = np.array([(1,2),(3,4),(5,6)]) In [3]: coords Out[3]: array([[1, 2], [3, 4], [5, 6]]) In [4]: coords[:, 0] *= 2 In [5]: coords Out[5]: array([[ 2, 2], [ 6, 4], [10, 6]])
[Domain-Specific Language](https://en.wikipedia.org/wiki/Domain-specific_language)
have you seen this in real life? every project is unique and an "Universal DB API" would be an overhead, I guess
CRUD while on the backend might be very different, could be made similar on the outside. It's the layer how it is presented to the user (by the python binding implementer) that is different. That said, having a unified interface is still going to be difficult.
I think the documentation for ASGI is nice as a reference, good for starting a discussion of what Django should do, and even good for creating non-python protocol servers, but I don't see it becoming a spec. I feel WSGI as a spec has failed. It gained wide adoption but there are too few middlewares for it and hardly any use cases where framework interoperability is important. I don't know if people want to go down that road again with a new spec. It becomes too limiting with not enough upside. I would much rather just focus on the basics; a good and fast socket library, HTTP parser, HTTP serializer, URI parser. For channel architectures, a fast JSON decoder/encoder. Then framework and library authors can just form their own requests and responses like they do now, but with support for more protocols.
&gt; but perhaps not so much for people working in a world filled with pure python packages. …or a world that has access to a working C compiler.
I've used SQLite3 and NumPy (and a bunch of other scientific computing libraries) before. I've played around with Flash and Bottle, but haven't gone much past Hello World in Django yet. It's definitely what I should be going for if I want future jobs though. Regarding performance: how common is it to use other implementations such as PyPy? I mean, you'll get a 2-4x speed boost without changing a single line of code, right? I haven't heard much about it, so it seems like most still use the reference implementation (CPython). Is it to avoid potential bugs?
You should use CPython until you have a good reason not to. It's one of those things where if you have to ask, you're probably not ready.
&gt; conda, anaconda and other "install every library in the world in one go" setups miniconda doesn't install anything except Python and itself by the way. Oh, and pip, which you totally can use to install stuff into conda environments (and conda would be aware of it) (but you'd want to use `conda install` by default, because binary packages and dependencies).
In my experience, not very common. People use PyPy to experiment, rather than for performance. I've not done a whole lot of performance critical work though. Often tweaking the application design, use of database, etc. will have more effect than a faster interpreter.
you won't be able to download the code, but you can put it together by just copying from the article, a bit of work, but possible.
yeah i read it in my head as anaconda, and thought he didnt want to install the full anaconda.
Thanks for the link! Apparently I need to brush up on my reading skills a little more before making assumptions. I stand corrected.
And, did you commit your `.pyc` on purpose ? I doubt their place is on git.
I wrote a plugin loader for our web software, here at work, which will inject arbitrary git repositories into a Tornado+Flask application, giving them sandboxed access to the underlying connections and parameters. Would there be interest in open sourcing just this functionality? Without looking at the code too deeply, I imagine they work similarly.
&gt; sandboxed access to the underlying connections and parameters Sounds interesting.
1. I've never seen anyone use TABS and SPACES for their indentation, especially on the same line ;) convention is 4 spaces. 2. Decorators, the `@` functions on top of `def` functions, should be touching. Lines [44-46](https://github.com/photous/gpio_web_control/blob/master/app.py#L44-L46) 3. I usually align my comments with the code, not of character 0 on the current line. 4. Inline styles are generally frowned upon (`&lt;style&gt;` in the `&lt;head&gt;`) 5. Food for thought, would it be better to have two forms, or one form with different parameters in the `action` endpoint? 6. You're missing a `&lt;title&gt;` :) Great start!! Especially if it works. 
If you're comfortable with the idea of a map (like in linear algebra) python provides a function which does that. For example myList = [(1,2),(3,4),(5,6)] def cartesian_double(p): return (2*p[0], p[1]) map(cartesian_double, myList) 
This is so horrific and so amazing at the same time.
Wow that's really impressive! Eve seems mindblowingly complex from what I gather, thanks!!
&gt; I feel WSGI as a spec has failed. &gt; It gained wide adoption ^ --- the above is the very definition of a successful spec. edit: also, it was very influential on web stacks in other programming languages. Rack and Ring are just 2 that I know about. If that's not success then I guess I just dont know how to talk fucking english.
I installed Python 2.7.10 recently and it had pip when installation was complete. The installation was on windows (in case that matters).
In my case it's building a centos7 based docker container
Post your code. You probably need to do smarter processing when you're stripping the HTML so the concept of rows is maintained.
I'm not at the computer right now, but what is this just a matrix?