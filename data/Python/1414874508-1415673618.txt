&gt;You might be missing the point. I think other people are imagining all sorts of nefarious things when there's no evidence they exist. &gt; This is not about ungrateful developers refusing donations, And yet the post did feature a developer asking people to stop collecting tips for him. &gt; leaving some or all of the donated money with the third parties and not the &gt;developers. Did I miss something in the original complaints? I didn't see a single statement from Armin accusing the website of fraud, only being upset that he didn't opt in, about receiving e-mails, and an odd complaint about tax compliance (which in most countries wouldn't be an issue unless he's going to receive very substantial amounts of money). 
Flask-User, Flask-SQLAlchemy, and Flask-Admin. Not long.
So is /u/alcalde affiliated with this charity scheme, or is he just a troll?
I prefer setting up a Flask app and then using Flask-Frozen to turn it into static pages.
Do you *need* it? Probably not, but page speed always matters. 
never thought about that!
So you should be able to tell me what happens with the money if no contributor claims it? I'm gonna answer this one for you : tip4commit keeps the money.
Hey, I realized this after the fact, I should've just deleted the post, but I left it up so I could come back to reference the suggestions made by Ben347, my mistake! Thanks for being kind on me!
If I slap you then give you a dollar can I dismiss your complaints becase I gave you money? The guy does not want to be *associated* with the site. Period. Please stop ignoring the facts. They have no moral ground to go against his wishes. Maybe it is his religion, maybe he is crazy, maybe he has a good reason. He asked to have *his* project removed from their service and they refused. Does he not have the right to disassociate himself from assholes?
Its really a per project basis. At one point my project was giving out $200 per commit.
If only gratipay were to accept bitcoin, have some low transaction fees on it, auto-sell them in whatever mitsuhiko currency he want and give it back to him, everyone would be happy.
In a lot of cases he really doesn't. It would be one thing if they were profting from his likeness, but in many circumstances even that is permissable. Non profits do things like this all the time, collect money, take a percentage for "costs", then just donate the money to an organization or a series of organizations that actually do the work. It might be of questionable ethicality, but it is far from illegal. Your example is a non-sequitur. He didn't slap him, he was offered a donation for his work, he declined, this website refunds the money to people that tried to donate to him, he gets mad that the site doesn't make an exception for him and create a new feature to cater to what amount to demands. Using someone's name or likeness is permissable in *tons* of circumstances. How do you think tabloids stay in business?
The point of this post is instruction on *how* to do something. He didn't say "the point is to save as much money as possible". He said he wanted to deliver a Pelican site as quickly as possible using S3 and CloudFont. Must everything you learn have a specific purpose that suits your exact needs?
Can someone explain wtf is going on here?
Disassociate (as in distance himself), sure, as he has already done. Gratuitously censor public information? I would hope not.
There's no maybe about it.
Just as a fair warning: I'm sure it's not exactly in agreement with their TOS. You want to look at the [requests](http://docs.python-requests.org/en/latest/) module to make HTTP requests, store cookies etc. and at [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) to parse the HTML responses and extract data. If you need good JavaScript execution support take a look at the [Selenium](http://docs.seleniumhq.org/) WebDrivers to fully automate a browser such as [PhantomJS](http://phantomjs.org/) (completely headless) or even just simply Mozilla Firefox. [Charles](http://www.charlesproxy.com/) is really useful to actually analyze the HTTP requests sent by your browser when you play the game. I also recently saw [this](http://www.reddit.com/r/selenium/comments/2ea86i/using_python_requests_library_transparently_with/) in the Selenium subreddit which should allow you to combine Selenium and the requests module transparently if the need should arise.
Why is this thread in /r/Python ? It contributes nothing.
Of course. As a matter of personal preference, I'd still prefer if you deleted the post, so it doesn't encourage off-topic questions. You can still save the answers.
Unfortunately not at the moment. It has just became public so we need to wait for some time until some courses will appear. This tutorial https://www.jetbrains.com/pycharm-educational/quickstart/getting_started_educators.html describes how to create a course. At the end there is an instruction of how to upload a custom course to the pycharm`s repository so it will be available for everybody. https://github.com/JetBrains/pycharm-courses 
Gratipay has an option for Bitcoin, but it's opt-in. See [my profile](https://gratipay.com/lyndsysimon/), bottom right, under "other giving opoptions"
One does not have a legal right to not be offended. If there is material harm, as others have said - that's a tort claim. 
I know.
Sorry I just got reddit when I posted the reddit post.
I don't think this is especially off topic.
You want the [Pyserial]( http://pyserial.sourceforge.net/shortintro.html) library.
This should be a built-in by now
To me, it doesn't relate to the language itself, but rather it is a question on how to use a particular library. It feels like something that belongs in /r/learnpython. Either way, it's certainly not &gt;news about the dynamic, interpreted, interactive, object-oriented, extensible programming language Python
This. The documentation is quite straightforward, if you know about serial ports. I actually use PySerial for your very purpose - to read from an electronic balance.
Great, thanks to both of you.
What are you trying to accomplish here? Also- post the actual error. There's not enough code here for me to run to see it for myself. 
What kind of object is k? I see you're using a dec2bin function to turn it from what is presumably a decimal number to a binary number. Is that number then stored as an int, string? To me, it looks like you're trying to iterate over a string of a binary representation of an integer. You can use Python's bin() builtin to help with this: &gt;&gt;&gt; bin(121)[2:] '1111001' bin() takes an int and returns a string representing that number in binary. You can then just iterate over it as you wish.
How long do you think it will take to move out of a cardboard box on millionth of a cent tips?
Pyramid takes a bit more effort to master, but its well worth it.
Why is he the bad guy for not trusting them to represent him and collect money on his behalf? Why is it okay for them to ignore his request for them to stop? After he asked they refused to acknowledge that they weren't representing his project and persisted to lie to the public by using his project as an excuse to take money.
But at 1,000 hits per day and a static website, really how slow is the blog in the first place? The title suggested the post should have been about why Pelican and S3cmd were killer features, yet almost nothing in the post addressed those claims. I, too, was left wondering what the point was when I was done reading the post.
Trust me, they can already load the pages quickly. The speed-ups you're talking about aren't going to be human-perceptible.
I was not making a legal argument. I was arguing against the notion that he *has* to be grateful to them and that they are somehow doing him a favor. That notion is ridiculous.
Have you ever gotten money from your family? Perhaps a birthday card or allowance. Imagine your mother wants to send you a $5000 gift for your wedding/marriage. I tell her that she can give it to me and I'll give it to you. You never gave me permission to do that, you've never met me and neither has your mother. I can give you any amount of money I want and you'd never know the difference unless you explicitly asked your mother. If you can't see what's wrong with situation, then I'll be glad to accept your paychecks on your behalf.
Honestly, I just lost track of what sub I was on. It wouldn't be a tangent in /r/Bitcoin.
I agree with you completely there.
the death of github. 
Wow, what a greedy piece of shit. I REALLY want to go punch this fucking dude in the face for being ignorant and greedy. Seriously he must be fucking retarded to not understand how this works. He's essentially getting paid for other peoples work and refusing requests to take their project down. Fuck that guy and I really hope someone sues him into the fucking ground. 
They're ignoring it on purpose because it generates him money.
It's not Reddit :P
[I tried out your decorator idea](https://gist.github.com/joshfriend/68e08c05c652518f60d0) and was generally pleased with the results. The only thing that bothers me (besides how Flask doesn't already do it this way) is having to catch the unused stuff in `**kwargs` everywhere.
If someone has bitcoins, and wants to create a bounty for commits, you are saying they shouldn't be able to do so without the explicit permission of the owner of the repository?
As someone whose done this (if you played tribalwars, you probably know me actually), selenium+some work is a good way to go. Modelling the world isn't actually that hard, its minimaxing with things like quests that's difficult. Even a sub-par building AI with robotic intelligence and precision for farming would soon overtake all but the top echelon of players. EDIT: Also yes this is against their TOS, morthy will be angry with you.
That's not what this does, though...
I wouldn't do personal projects at the expense of work. But I'm always *very* impressed when someone does a personal project that looks very good. Especially since it's usually a solo project. Being a part of a big firm means you can have impressive resume stats when all you did was fix a few bugs. Making a neat project solo shows you did it all (idea, prototype, bug fixing, delivery, writeup). That sometimes shows a lot more. Good luck. Think of it as your portfolio.
Based on the fact that in this very function you've overridden the default `list` class with your own variable, I think it's a safe guess that you have defined a variable in the global scope (i.e. at the module-level) named `str` which has overridden the builtin `str` class with a string literal. As Fundatio mentioned, you should not define variables that override builtins. To get a list of builtins, you can do this: import __builtin__ print dir(__builtin__) If you setup linting or pep8-checking in your IDE (eclipse, sublime, etc) it will display warnings when you do so. 
I've been thinking of doing something like this and I don't have any major projects at the moment so I'd love to help you, feel free to PM me. 
Came here to agree with everyone. . . screw urlib2. Long live Requests.
Worth noting that os.popen has been deprecated since 2.6: https://docs.python.org/2/library/os.html#os.popen The subprocess equivalent: result = subprocess.check_output(command).decode("utf-8") 
Oh phew. Given the title and the site, this link had me worried that Armin was pulling a Mark Pilgrim, burning out and deleting his projects.
 kstr = str(k) if kstr[l] == 1: What are you expecting to happen comparing a string to an integer?
&gt; this guy's just being difficult, they don't have any reason to comply with what he's asking for This is the part that I was taking issue with. Is he "being difficult" for not wanting to be associated with people whom he doesn't trust? I was stating that they had a moral obligation to honor his request. Considering they should have asked his permission to represent him to begin with and they refused to stop when he explicitly asked them, they don't have any moral ground to stand on. Insulting/blaming him for wanting to protect his hard work is ridiculous.
the only aspect i mentioned was legal, not ethical nor moral nor strategic. they could've handled it a lot of different ways, but they chose to do it this way and the only reason you're reading the drama is because this person knows that making a big deal about it is about all they can do. i'm not condoning it, i'm not advocating it, but i am saying that it's likely not illegal. but yeah fuck me for being pragmatic.
Thank you very much that worked!!!
Hence why he uses CloudFlare (it's in the 3rd paragraph). Maybe work on your reading skills before you try to smart ass around?
i shouldn't have worded it that way, but i don't want to be the guy that edits it out to save face. i say he's being difficult because if he had an actual legal case he would've sued, but instead he decides to be a crusader against something that is arguably meant to be beneficial to people like him. sounds to me like someone's song being posted on youtube without permission. the copyright owner or their legal representation contacts the host, they take it down, and that's the end of it. what he wanted was the equivalent of banning a search term just because it includes a trademark. furthermore my comment was intended only to address the legality, but there are plenty of other businesses that employ a similar business model offline and are successful at it.
I'm too tired for this shit. Here's the paragraph since you can't seem to read. "I've been blogging since 2001 and I've used a number of different platforms and hosting options. For the past few years I've been using a small droplet (1 GB of memory, 1 CPU, 30GB of SSD Disk capacity and 2TB of bandwidth a month) on Digital Ocean that has always been more than enough for all the different sites I host on it. The droplet costs $10 a month which is cheap enough that I never felt motivated to try and lower that cost." For years he used a server in Amsterdam to serve a primarily American audience. The logic behind that choice is extremely questionable. A change was long overdue. Before you bitch at someone else to read shouldn't you try it out yourself? Otherwise you just look like a moron.
Why does it matter if he can sue or not? Maybe he cannot afford a lawyer due to time or money constraints. The point is he was reasonably asking them to stop using his hard work for their own gain without his permission and they were being assholes when refusing to do that. Saying it is meant to be beneficial is your opinion. I think it isn't trustworthy and therefore the certain risk isn't worth the potential benefit. He feels it is harmful and they are only proving his fears with the way they handled his reasonable request. He wasn't asking them to ban a search term. He was asking them to remove the page and then not make the page again without his permission (by putting it on a blacklist so they wouldn't forget which people opted out... similar to a do not call list for telemarketers for people who do not want to be harassed, he just didn't want to have to deal with their bullshit every time they created a new page pretending to represent his project without his permission).
Cool! didn't know flask-frozen.
 getName('C:\\Users\\Guest\\secrets.txt')
Yeah, to me this sounds more like a way to scam people than anything else. Tons of projects won't know about this at all and there is no transparency whatsoever in their project. Easy to siphon money from users who think they support open ource into their own pockets.
If it is not a task to create function from scratch, this can help: *nix &gt;In [7]: import posixpath &gt;In [8]: posixpath.basename("~folder/folder2/file.txt") &gt;Out[8]: 'file.txt' Windows &gt;In [9]: import ntpath &gt;In [10]: ntpath.basename("c:\\folder\\folder2\\file.txt") &gt;Out[10]: 'file.txt' Platform independent &gt;In [11]: import os &gt;In [12]: os.path.basename or you can use trivial function: `import os` `get_name = lambda p: p.split(os.sep)[-1]` 
Glob
 contents = urllib2.urlopen('http://www.reddit.com/').read() What's wrong with that?
I am sorry about the music , the link to the code was added in the description box: https://github.com/yask123/Auto-MP3-Lyrics-Tagger
really curious to know this as well.
It looks like pyglet may be having trouble with the RaspberryPI due to the RasPI only supporting OpenGL ES where pyglet needs OpenGL. Annoying. Have you looked into [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/)? 
I'm aware this would be against their TOS. Thank you for all these tips, when I have some more time I'll look into them!
there ya go: def getName(path): return path.split("/")[-1] # split the string by "/" into a list and return the last string item I leave the boundary conditions of path = "/" or "" to yourself as an exercise 
I'm afraid I don't know you, probably because I played on .nl servers. For doing what could I know you? Also, thank you for the in-depth tips. 
Somebody in the github issue they claimed that they are in Australia.
My favorite free setup: gh-pages + Pelican + Travis CI trio.
Although it’s undocumented (meaning: you shouldn’t use this) it already is there since Python 3.4: &gt;&gt;&gt; from pip._vendor import requests &gt;&gt;&gt; requests.get('http://redd.it/2kzmbk') &lt;Response [200]&gt;
whoa! TIL!
http://lmgtfy.com/?q=python+write+to+files There are other resources apart from the python docs.
Whoa wtf
It's not exactly pythonic. What does it mean by read? When you use requests you actually know what you're doing. Sending GET or POST requests. What kind of response you're getting and other stuff which is a part of the process. So it's more clear and easier to work with. 
Make sure that money goes to who you think it does.
I assume you want to pass each tuple as an argument to your function. You can do that with a *. Basically, this takes all of the arguments to your function and makes it accessible as a tuple. def foo(*some_tuples): for e in some_tuples: assert isinstance(e, tuple) # Ensure that e is of type tuple. assert len(e) == 2 # Assert that e is of length 2 print tuple # I'm just printing it; you'll want to do something with each tuple here. foo((1,2), (3,4), (5,6)) &gt;&gt;&gt; (1,2) &gt;&gt;&gt; (3,4) &gt;&gt;&gt; (5,6) foo("foo") &gt;&gt;&gt; AssertionError (because "foo" is type str, not type tuple.) foo(("foo","bar")) &gt;&gt;&gt;("foo","bar") Edit: I forgot you wanted a `class.__init__()`. Updated version: class Foo(object): def __init__(self, *some_tuples): for e in some_tuples: assert isinstance(e, tuple) # Ensure that e is of type tuple. assert len(e) == 2 # Assert that e is of length 2 print tuple # I'm just printing it; you'll want to do something with each tuple here. Foo((1,2), (3,4), (5,6)) &gt;&gt;&gt; (1,2) &gt;&gt;&gt; (3,4) &gt;&gt;&gt; (5,6) Foo("foo") &gt;&gt;&gt; AssertionError (because "foo" is type str, not type tuple.) foo(("foo","bar")) &gt;&gt;&gt;("foo","bar")
https://www.coursera.org/course/pythonlearn is a free course I'm taking. It teaches 2.7 and the box is free in ebook form. On the ibook version all the video lectures are included. 
ok thanks!
I think you should take a look at cx_Freeze. http://cx-freeze.sourceforge.net/index.html http://cx-freeze.readthedocs.org/en/latest/index.html [Edit]: What is it with people in this thread? Almost everything is down-voted to -1...
Google. I bet there is an endless number of tutorials about it.
Thanks, i'll look into it now :)
Perhaps he or she is just young and willful and cannot see distinctions between this and finding money on the street.
https://www.reddit.com/r/Python/comments/2hleh5 Something can be discouraged without being against the rules and just because other people do it doesn't mean you can too. /r/learnpython has plenty of people helping to answer questions, including me. People needn't fear their question will go unanswered.
Try googling: "python3 to exe." There's a lot. Edit: You're probably not the first person in the world since 3.* that is trying to do this.
&gt; please consider not a rule. its more like "if you like". again if it was against any rules the mods would remove it and since they dont its fine. hide the post and move on.
Why would anyone downvote this? This subreddit is in a permanent state of Eternal September.
Please post this in /r/learnpython. https://www.reddit.com/r/Python/comments/2hleh5 
Well, their account is deleted or banned, now.
This actually belongs in /r/domyhomeworkpleasepleasepleasepleaseplease 
Username still shows up on the comments in this thread = banned. Good riddance to bad shill.
&gt; What does it mean by read? ... the same thing as file.read? It's reading from the socket. You don't always want to have the whole response in RAM right away. I don't disagree that requests has a nicer API overall, but the simple case is simple with any module.
If you arbitrarily select a cause and start a funding campaign at your work or your neighborhood, then you might not realize it might be illegal. To be able to make fundraising in any place or scale I assume there'd be legislation in place to require you to present certificates that you're legally allowed to do so. It has nothing to do with your actual intentions, the problem is that otherwise anybody could claim raising funds for a cause and defraud people. Fund raising organizations are obliged to be transparent, their actions are being monitored by some jurisdictional authority. This is why the aforementioned project can't use real currency for the donations at the moment. The other big flaw is that it brings the incentive of monetary profit to the amount of code contributions. This is something very much against the spirit of many FOSS projects and this was mitsuhiko's main concern with his project being listed in tip4commit. The complaint about the notifications was just an extra annoyance he had to deal with but effectively worked as redherring. I think accusing the creators of being fraudulent is a bit strong and premature. More probably they are in a state of denial, that their project has fundamental flaws and it's not the brilliant idea they think it is. They'll have to either change their business model to opt-in or give up. Their problem is if they go for an opt-in model, they won't be original and it can't go viral without a huge marketing effort. 
You are right that is a possibility. I thought a personal interest in tip4commit was more likely due to how he expressed his views and how vociferously he defended all their actions while condemning all of mitsuhiko's at the same time.
Whoops D: Oh well, we can hope
please don't use that hahaha
I have spoken on this many times — I don't want it in the standard library :) Effectively, the standard library is where a module goes to die — and Requests continues to evolve on a daily basis. That's why it's such a good module :)
Hi, thanks for tutorial! When is the angular part coming?
Never said it was a rule!? It says: consider. That implies thinking for yourself. /r/learnpython is a beginner sub, this is a beginner question. People are trying to learn programming and being insanely lazy in the process. Not being able to read the forum guidelines and googling simple questions.
Did you try those projects and not like their ui? Or you don't consider django an easy graphic solution?
check out this video using cx_freeze youtube.com/watch?v=XHcDHSWRCRQ
Have you looked at [Pyke](http://pyke.sourceforge.net/) for the back end? &gt; Pyke introduces a form of Logic Programming (inspired by Prolog) to the Python community by providing a knowledge-based inference engine (expert system) written in 100% Python. &gt; Unlike Prolog, Pyke integrates with Python allowing you to invoke Pyke from Python and intermingle Python statements and expressions within your expert system rules. You would still need to build a front end for it.
They don't have UIs.
I have looked at it, and it has nothing to do with the problem or solution domain. Pyke is for proving theorems within its knowledge base. I'm not looking for inference, I'm looking to capture and reply process-oriented knowledge.
Yep, this works really well..... **source** def foo(): return 0 def bar(): return 1 def foobar(): return foo() + bar() **output** def foo ():#line:1 return 0 #line:2 def bar ():#line:4 return 1 #line:5 def foobar ():#line:7 return foo ()+bar () Obfuscation is very difficult to accomplish in Python even if you do something like start messing with opcodes because the interpreter is still expected to function in a certain way for the most part. Just rearranging source code or renaming things is not going to slow anyone down. Generally speaking, obfuscation only slows a reverse engineer down it will never really protect the program regardless of language (Python just makes it easier). So long as your program can be executed it can be reverse engineered. It may not be exactly the same as the original source code but that secret sauce will probably not be as secret anymore.
If you want to obfuscate module level function names, you should define a public api list, so obfuscator can preserve these api and rename others. source __all__ = ['foobar'] def foo(): return 0 def bar(): return 1 def foobar(): return foo() + bar() output __all__ =['foobar']#line:1 def O000OOO0O0OOO0O0O ():#line:3 return 0 #line:4 def O000OO0O000O00O00 ():#line:5 return 1 #line:6 def foobar ():#line:7 return O000OOO0O0OOO0O0O ()+O000OO0O000O00O00 () 
If you're working with a larger organization, I believe plotly offers private installs of their engine. But of course that costs $.
Ok so that's a little better but it still essentially tells someone "start here" and does not make it much harder to reverse. I get this is a very simple example but it still seems useless to obfuscate at this level rather than at the opcode/syntax level.
No, it's not. The post got mostly downvotes.. Period. And so does this: https://www.reddit.com/r/Python/comments/2l20lm/how_can_i_read_and_write_to_text_files/ People have already told you this. And being a redditor for only a couple of hours, I assume you know nothing about this or the /r/learnreddit sub.
&gt;What knowledge or legal consent do you imagine is needed to collect money for someone? If I see a news story about someone in town whose home burnt down and I start a collection at my place of employment for that person, I'm not breaking the law. Only if I never give the person the money I collected would I be guilty of anything (fraud). It depends on how you represented yourself. If you said, "Give me money and *maybe*, at some vague uncertain point in the future, *some* of it *might* get to the person you really want to give it to", then I'd agree, you wouldn't be breaking the law. But that's not what these guys are saying. They're implying, "Click this button, and X currency you send **will** go to the project you send it to". Since that's literally not what's happening, nor can they gaurantee that, that's mispresentation. It's fraud and it's illegal, and I hope someone shuts them down. [Charity fraud](http://en.wikipedia.org/wiki/Charity_fraud) is actually a huge problem, because most people don't bother to research the charity they're giving to, much less the actual person they're giving the money to. And this is some random website run by a couple of no-name developers with no legal entity behind them. There's no way to audit the funds they're collecting, much less prove they're going to the people they say they're collecting for. &gt;What does that mean and what does it matter? Does it make any difference to the donator whether the coder asked for the donation or not? It's a way for someone to say thank you, period. It's irrelevant whether or not they signed up for it. Yes, absolutely. First, you're assuming these guys are legit and aren't trying to con people, which is a huge assumption. In my experience, when dealing with someone asking for money on the Internet, it's prudent to be cautious. Second, maybe the developers don't have a bitcoin wallet and don't want one because they don't want to deal with yet another online financial service, but also don't want the tip4commit devs pocketing money that someone wanted to send them. Or maybe the tip4commit devs are random douchebags you don't want representing you directly or indirectly. Either way, I don't understand their reluctance to remove the projects from their system. How hard would it have been to send them an email saying, "Someone wants to make a donation to your project using tip4commit. This is a free project built to foster open source development. If you wish to accept this donation, please click here"? That would have been more transparent, allowed the project maintainers time to research the site and vet it and assauged their concerns.
How wide is a tab? That should be your answer
urllib2? There is no such thing anymore, only urllib and asyncio.
Not really. Some pulls were good, I just rejected the trivial ones. 
Or like 1/3 my uses for plotting data: POC demonstrations where I have no internet or such.
Still a higher learning curve than having Python installed out of the box though. 
sure, or where it can’t be *guaranteed*
no, it runs on any modern browser.
There's a startup i stumbled upon some time ago that does exactly that(a system that enable non experts to build expert systems, and users o use that) , would it solve your problem , or your problem IS to build such a tool ? et me know if it would help, i'd try to look it up. 
The key is to fill your capacity with well estimated DEV tasks - There wont be any time for QA. Pro Tip: Write a [few] unit test(s) and commit it to the repo - it will satisfy any request to "regression test" - which as a developer, I hate - and it will impress your technical lead. If there are already unit tests created, run them and sit back and watch the green roll in. edit: because it's sunday
Yeah, I tried Hyde and similar, but I like this much better. Feels a lot more flexible, integrates with some existing flask plugins and has a good API. I use it with s3cmd in a simple little deploy script to create http://esd.io/
I'm writing [a vim clone](https://github.com/stefanoborini/vai)... if you want to join... But keep in mind I am in the process of relocating, so I am a bit busy. I can, however, give you a general overview, and you can get started with trivial stuff. I am in dramatic needs of tests and a more extensive attack on layouts for the terminal toolkit I am writing as well.
Yeah, this is simply not true.
&gt; reverse check this example: [before](https://gist.github.com/weijar/ded24f0b6949b8f502f8) [after](https://gist.github.com/weijar/377e463fbee60e243f02) 
If you're interested in Genealogy I'd like to suggest the [Gramps Genealogy Project](https://gramps-project.org/wiki/index.php?title=Portal:Developers). The project has a list of [Gramps Enhancement Proposals (GEPS)](https://gramps-project.org/wiki/index.php?title=Category:GEPS) you may be interested in looking at. *Disclaimer: I'm a moderator for /r/gramps
Right. I'll do the standard schpeel. 3D printing might be one of the most important battles open source is facing right now. Sure, we're winning, marginally, but the enemy forces are gathering at the gate. 3D printing is a massive source of *money* for the open source community. Something that's in sort supply. A few good open source apps have been launched servicing the rapidly growing 3D printing market. Modern FFF based 3D printing owes it's existence to the reprap movement. But the general open source culture of 3D printing is slowly seeping away. A rather large part of that is the shining beacon that was makerbot going dark. I mean they still exist, but they were purchased, kicked out one of the co-founders, started using price discrimination techniques, allegedly patented an open-source user contribution, went closed source, started using "embrace extend extinguish" on the 3D printer communication spec, started filing very vague patents, and a fair bit else. I'm not going to list it all. Basically, they went from strong open source company to a company willing to use whatever anti-competitive practices they could think up. And for a lot of people, that's their first experience with 3D printing. I moderate /r/3Dprinting, so I've gotten to see this process in real time, and I've had a front and center seat to the changes in user attitude towards open source. One of the big reasons for that change is that makerbot owns [thingiverse](http://www.thingiverse.com/). The go-to place to download file for 3D printing. That's a ton of free advertising for them, and it creates a problem since so many open source projects are uploaded and they have a sketchy EULA. Myself and another programmer have been working on an alternative for a little over a year. There's only one other open source option, [bld3r](http://www.bld3r.com/), and as you can see it's not very good. **[Rhombik](http://alpha.rhombik.com/)** is my attempt to shift 3D printing more towards open source. I think with that influx it could do *very* well. We have a long list of features, covering a wide range of topics, and I could definitely make use of them. Presuming they don't mind picking up a bit of python. Our github is [here](https://github.com/Rhombik/rhombik-object-repository). --- A few features that could be fun to pick up. * Web scraping with scrapy * Sync project with git (git hooks, etc) * Support for importing from more sources * Tracking import (celery task queue) progress * A general API * Oauth service. Integration with gratipay, flattr, etc * Stripping out QT dependencies on openSCAD, compiling it to the javascript with emscripten * "Workroom" project editing/branching or, more arduously * Converting our system to use version control as a file backend * editing openSCAD files in the browser (maybe using [droplet](http://youtu.be/PGDj1IzOtoo)) * testcases * Automatic tag suggestions * Search-engine(haystack)/CDN/caching optimization --- So yeah, that's my project. I'd appreciate any help I can get. Especially since my job has been requiring a lot more time then I'd like.
Title is misleading, the site appears to be a guide to interviewing python developers hosted by a company that offers python developers for hire. 
ok, well you need a graphics card, too. but it really only needs WebGL + Canvas + SVG support, which is in any modern browser.
Depends on your platform, but something like this 1. at a command line type 'python'. If it is installed go to 3. otherwise 2. download and install python 2.7 from https://www.python.org/downloads/ 3. You may need to install pip, run "python get-pip.py" (http://docs.python-guide.org/en/latest/starting/install/win/) 4. at a terminal (as per their instructions) type: $ pip install -e 5. Now at a terminal type (as per their instructions): python json_to_csv_converter.py yelp_academic_dataset.json 6. the file yelp_academic_dataset.json needs to be in your current location.
If you're doing analysis in python, why not use pandas. That way you can read directly from json (with [`pd.read_json`](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.io.json.read_json.html)).
also: for val1, val2 in some_tuples: # implicit check for tuple/list of size 2 print(val1, val2)
If all arguments are positional, no tuple is involved (direct load from the call stack). 
Sorry, but your claims are still not holding up. Or is FF 33.0.2 not "any modern browser?" 
One project that can use some love is Pandas, this is the quintessential python/open source project for data analysis. https://github.com/pydata/pandas Check the number of open issues.
I'm not sure what the point of the really long function/variable names is, but they look like they're a trivial script away from far more readable names. Once you get that out of the way, it doesn't look any worse than the perl one-liners that used to end up in usenet signatures. If you don't want people to read your source code, distribute it as compiled (.pyc) files. This is a oneliner away. $ python -m compileall helloooo.py Compiling helloooo.py ... $ python helloooo.pyc hello world
i’m using it, it is, and things work for me. maybe you have some addon reverting it to a non-modern browser, like noscript.
Well, they have the adimistrative backend, right? Also, writing a view and template would be trivial if it gives you exactly what you want. This assumes these projects give you exactly what you want, which I can't speak to.
It will prevent someone from reading the source code assuming they don't just use an available tool or write something to convert a pyc file back into source code.
If you want to do 3d printing, I'd also look into http://openvsp.org/ VSP is an amazingly powerful tool
Huh, neat. I mostly use openSCAD, haven't heard of that one before. I'll have to take a look. Thanks.
Technically, no, they won't be reading the source code. At best, they'll generate equivalent code. The only thing the tool the OP presents seems to offer over just compiling is the variable renaming and removal of docstrings, both at the expense of imposing quite serious limitations on how the code can be written in the first place, and both quite trivial obstacles for someone moderately interested in using your code.
&gt; Technically, no, they won't be reading the source code. At best, they'll generate equivalent code. Correct, but I said it would convert it back into source code (which is still useful) just not the original source code. You still have a fair point however. Comments won't carry either since the interpreter strips those out and you might not get assertions or anything under \_\_debug__ if you're reversing the optimized files. Anything in native code would have to be reversed separately. OP's tool is still probably a pretty cool toy depending on how it was written. At the very least it was probably a good opportunity to learn how Python parses the syntax tree...hopefully [s]he's not actually evaling the code though. Even then I personally would not host a service like this because there's probably still ways you could use the interpreter on the remote end...
[DataGristle](https://github.com/kenfar/DataGristle) needs a competent web front-end in flask to assist in managing metadata and analyzing csv/json profiling data. 
Interesting your project.
Well, hard to say. I am more interested in supporting an overall goal as opposed to working with a specific set of tools. If I had to choose one specific area it would be TESTING. Writing unit tests is a good use of my limited time. edit: testing is fine, an obvious entry point. I am very open minded
This is great! I will definitely read through the code and add it to my watch list - I really enjoy text editors and extensions - mostly VS and Notepad++ extensions and plugins for me though.
Wow, thank you - this is exactly the kind of response I was looking for. I'll have to give this some serious thought, much appreciated. edit: below I found this [Bld3r thread](http://www.reddit.com/r/3Dprinting/comments/1g4dy6/another_redditor_and_i_have_been_working_on_a_3d/) to be really interesting. Never seen Reddit come through as a life cycle management tool before.
Ok the other project I sent, pandas, already has plenty of tests most major projects already have extensive testing as well. The only mature project I can think of that may be in need is the ipython/jupyter project, which is going thru a massive overhaul and would need testing. https://github.com/jupyter https://github.com/ipython/ipython
Almost every language can. At the heart of it, most languages can write bytes to system I/O devices
It is. Generally, though, you want a microcontroller to actually handle the hardware, but python is an excellent interface language for using a PC to talk to that microcontroller. And these days, things like the Raspberry Pi go a long way towards removing the need for the microcontroller, so you can do a lot of hardware interfacing direct from the Raspberry Pi in python.
http://weedtech.com/ The serial protocol is pretty straightforward. I have used one of these boards to control stuff under python using the serial module: http://pyserial.sourceforge.net/
I think part of the reason this is inelegant is that you're trying to stick to a too haskell-like style. Python can be neat and elegant too (even if not with so few keystrokes), but it's a little different, and you probably want to try to work with its iterators instead of fighting them with `list` all the time. For instance, I think the following is much nicer (though not the only option, e.g. reversed could be [::-1] to taste). Polynom(reversed([index * item for index, item in enumerate(self.data) if index &gt; 0)])) Again, it's not so syntactically concise, but it expresses the same idea in (IMO) a much more pythonic way. More generally, the `itertools` module has several very nice functions for performing powerful operations on iterators, which you may find very useful - there may even be some super short itertool chaining that's more philosophically similar to the haskell example. I also did it this way to keep it in one line so as to match your original example; depending on context, I wouldn't be afraid to split across two lines in whatever way seemed clearest, especially if it fit nicely into two 80-character lines that way. I could certainly agree that this is not so convenient and powerful as haskell's syntax, but it doesn't pretend to be either - it's optimising for a different kind of experience, and I've come to find it a lot more pleasant and powerful than it initially seemed. Edit: Also, I don't know the nature of your Polynom class (or function?), but does it really need a list rather than a generator/iterator? Even if it does, if it's your own class then maybe it could handle this internally, avoiding the need to mess with the extra list call every time and making it useful with a wider class of reasonable, valid inputs. Edit2: Actually, maybe I miss something about your haskell - do you mean `tail` rather than `tails`? If not, I'm unclear on the nature of the data and what multiplication means on the list of tails returned by `tails`. Also, you can replace `[1..length tails]` with just `[1..]`.
How do you interface Raspberry Pi to something like a 110 wall outlet to cycle a heating lamp (or similar)?
THanks. Looks like I have a lot more research to do with getting the end result. 
Wish bld3r had of been open source from the beginning. It's worth noting that it's [dead](http://www.reddit.com/r/3Dprinting/comments/2l30on/is_the_3d_printing_social_site_bld3rcom_dead/) now, more or less. Let me know if you want any more background info. I'm more then happy to answer any questions. Especially about the code base, which is honestly a little bit scruffy at this point.
Thanks - I'll poke around a bit. 
I can't run the code of Metaclasses.ipynb in my environment. (python2.7.6 centos6.5) When I typed "class fun(metaclass=go):" , it always raise a error: Invalid syntax.
/r/learnpython 
thank you!
That's because they changed the syntax in Python 3. I didn't cover Python 2 in that presentation. As far as I know, the current recommendation is that new projects use 3.
Nope. Im on my laptop which is just a clean, unmolested win7 Pro install with all default apps. There is something required for this that is not default.
I've been thinking about this question too -- especially as it relates to data workflows. Function composition notation is particularly tedious when one is trying to work with a lot of transformations. In R, there is a package named **magrittr** that overloads an operator "%&gt;%" to let you do function compositions in an elegant manner. For instance: f(g(h(x))) would be written as: x %&gt;% f() %&gt;% g() %&gt;% h() With this notation, the data flow is simple and clear. (multi argument functions are trivially handled too, but I'll omit the notation for that to keep this short). I'd like for Python for that an operator like %&gt;%, but my feeling is Python's operators aren't as easily overloaded. There have been some attempts at writing a pipe operator. None of them seem to be as elegant as magrittr, but they present some interesting ideas. https://wiki.python.org/moin/FlowBasedProgramming 
Yeah, an awful lot of ugliness comes from not using comprehensions; if you have to write out a `map` or `filter` call every single time, the code is going to get cluttered with parentheses :)
I have some experience using python on the RPi as a controller for scientific experiments. You can very easily write code to control the RPI GPIO bus via python. You can connect a switch or relay to an input pin (defined in your code) and then use generic loop control methods to toggle the status of the switch/relay. The relay could be connected to anything but in principle could switch your mains power(120 or 240v or whatever) if you have any more questions about the actual set up or circuit work, let me know. I'd be happy to try and help out if possible.
sssup
[Open edx](http://code.edx.org/)
I attended the cofounder's presentation at data summit SFO last week. Amazing potential. There is enterprise version which lets you host your stuff yourself. 
It's not random, it's pseudorandom: http://en.wikipedia.org/wiki/Pseudorandom_number_generator If you want true random numbers, use os.urandom or random.SystemRandom (the first warning at https://docs.python.org/2/library/random.html also recommends this). But note that those are significantly slower, so make sure you really need truly random numbers.
That makes perfect sense. Thank you!
Looks like your graphs are flawed and are showing patterns where none exist. Whatever tool you used to graph the data is just drawing the 50 different y axis values poorly which is resulting in the stripes. If you want to graph random data plot individual pixels on a 10000x10000 grid.
While Python does use a PRNG, it does use [a very very good one](http://en.wikipedia.org/wiki/Mersenne_twister). Unless you've stumbled upon a very large bug in the implementation, the frequency distribution Mersenne twister is known to be even. I'd imagine this is more a case of the sampling in your plot engine resulting in funky artifacts than an underlying problem with the PRNG.
I agree with Justinsaccount. The patterns you are observing seem to be due to aliasing of the plotting method. This kind of plots cannot reliably show possible patterns in pseudo random number sequences. To visually test for patterns in a sequence of numbers draw histograms of the original sequence and the its "derivatives". The more the histograms conform to the expected PDFs, the better the random number generator. If you really want to know the quality of the RNG, do a statistic test such as [Kolmogorov-Smirnov test](http://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test).
&gt;The Open edX Platform &gt; &gt;Open edX is implemented mostly in Python for the server, and of course Javascript for the browser. The code is being made available under an AGPL license. &gt;The main repository is edx-platform which includes both the LMS and the authoring tool, Studio
That's so awesome of you. I'm trying to make sure what I want to is possible (and it seems like it is) before I get all wrapped up in this endeavor. I guess I'm having trouble visualizing a completed set up. It seems like the end result is kind of bulky. 
Works for me, too (Arch Linux 64bit, Firefox 33.0.2), though I had to tell NoScript to permit several sites before it worked.
I've been avoiding letting go of %s for so long, but recently I had a need to use a variable multiple times, but didn't want to use a fully fledged templating engine. Having this """%(samevar,samevar,var2,samevar,samevar) looks really dumb. .format(samevar=samevar,var2=var2) is so much cleaner &amp; logical. What a foolish fool I've been. Long live str.format
It's definitely genuine (love turtles/tortoises) and the added information makes it even better. Too awesome. If you do it, please PM me with a link to a video of it in action. That will be one lucky tortoise(s)!
Indeed. Unless you're doing cryptography, you nearly always want the MT PRNG. Larry Hastings did [a talk on randomness vs PRNGs at Pycon UK](http://youtu.be/5QhLccwOMrU) that might help explain. 
Yesterday I was looking into creating an image composed of pixels with color selected by the random module. First I made a [1024x768 image](http://i.imgur.com/m57DBVt.png), then I made a 10000x10000 image (which I'm not going to upload because it's 326MB, feel free to generate it on your own if you have &gt;8GB ram and 64-bit OS/python/numpy/PIL), and there's honestly no discernable pattern. Woohoo randomness. from PIL import Image import numpy.random imarray = numpy.random.rand(768,1024,3) * 255 im = Image.fromarray(imarray.astype('uint8')).convert("RGBA") im.save("test.png")
Does numpy use random.randint?
[Relevant XKCD](http://xkcd.com/353/)
[Image](http://imgs.xkcd.com/comics/python.png) **Title:** Python **Title-text:** I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=353#Explanation) **Stats:** This comic has been referenced 89 times, representing 0.2270% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_clrlfsf)
why? you can have a CSPRNG that is faster than Mersenne Twister. for example: [ISAAC](http://burtleburtle.net/bob/rand/isaacafa.html).
I think numpy uses a similar implementation based in C, but I don't know because I can't read C :P https://github.com/numpy/numpy/tree/master/numpy/random/mtrand
TCP doesn't really care whether it's a client or a server once you get past the initial connect or accept calls. I've made clients and servers with asyncore and they work just fine. &gt; Do I need to settle for low-level socket polling to check if my ever-changing servers have any data for me? No, asyncore provides a notification when data is ready. You said you'd played with asyncore so I'm not sure how you could miss this. Twisted does something similar but I don't use it. &gt; Can twisted or asynchat achieve this &amp; still perform well w/ many server connections? Of course, though you're going to have to define 'many'. A simple select/poll based approach will be fine for up to a thousand connections if the rest of your code is efficient. You'll probably be best off running several of these processes in parallel to get the best use out of your CPU, however. &gt; Or are message queuing tools like zeromq a better fit for this client &lt;--&gt; many server configuration? The "client &lt;--&gt; many server" thing is a distraction; the topology you describe is no different to any other, really. Calling one end a client and one end a server makes no difference. zeromq may work better for you, if you can see how to set it up to suit, but asyncore will also do just fine. 
It's like you've been inside my head and stole my thoughts and coded it for me. Looks good, will definitely give this a go.
Looks great, nice one! How much work has been put in so far?
This answer is as wise as true.
There is even a microcontroller that runs python: http://micropython.org But personally I'm using [Arduinos](http://arduino.cc/) to interface with sensors and relays/motors/actuators etc. because there are tons of ready made libraries for all kind of hardware. Then connect it through wifi, or a serial cable (or Bluetooth serial). 
Do you know there is an online converter that can do this at [json-csv.com](https://json-csv.com)?
&gt; At lease getting rid of all those to list cast because map and reversed returns generators. And what's your problem with that?
PyCharm Educational Edition synchronises with github repository https://github.com/JetBrains/pycharm-courses So you could create course and share it with a community via pull request to this repo. Please check https://www.jetbrains.com/pycharm-educational/quickstart/getting_started_educators.html to get more information about course creation process.
&gt; automating some environmental controls for our tortoise tank For a moment there I thought you meant [one of these.](http://en.wikipedia.org/wiki/Tortoise_heavy_assault_tank#mediaviewer/File:Bovington_146_Tortoise_1.jpg)
[First commit is from 12 Sept. 2013](https://github.com/balloob/home-assistant/commit/d55e4d53cccc9123d03f45c53441e7cbfc58e515) so I guess roughly a year.
You'd just make your functions extern C and call them the same way. I'd really recommend reading the docs for the ctypes module, there's lots of examples. Rather unsurprisingly python does not do type conversions for you, it's much too complicated to want that automatic, so you end up doing casting, but wrapping each c function in a python function that encapsulates the conversions can clean up your api. 
What /u/Fundatio said
https://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_.28.22Revised_BSD_License.22.2C_.22New_BSD_License.22.2C_or_.22Modified_BSD_License.22.29 * Neither the name of the &lt;organization&gt; nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. Unintended consequences, I'm sure.
http://choosealicense.com/licenses/ https://github.com/github/choosealicense.com
Unfortunately, PySide seems to be not actively maintained anymore (3 years since the last commit). It also does not have Qt5 support. PyQt has the license disadvantage, but is actively maintained and works well.
Whats the framework youre using?
It totally is. Try Pandas, matplotlib, and reportlab for your data needs. The standalone package part is a little harder, how are you planning to redistribute it? py2exe might work, but I haven't used it in a long time and I can't vouch for how up-to-date it is.
unfortunately the files are about 150mb each.
Honestly I found using the [Python documentation](https://docs.python.org/2/extending/extending.html#extending-python-with-c-or-c) to be easier and more customizable than the top voted solution.
I am currently taking this Python class as a non-major. At this point, an entirely separate Python programming class for non-majors seems inevitable. The intro class is getting way too big. I know this comment is 3 months old but it was too relevant to ignore.
I would like to be able to easily run the program on any windows based machine. Preferably nothing to install. I have to make it as idiot resistant as possible, the end users won't be computer experts. Pop in the SD card, start the program, select the file, run analysis, and generate a report with as little user input as possible. 
have you tried FHEM (http://fhem.de/fhem.html) before working on that? how does it compare? (other than not needing to write perl ;)
Thank you!
Thank you for the reply! I have quite a bit of read up on related to randomness.
Not bad. You should get it listed on this list of [python starter templates](https://github.com/audreyr/cookiecutter/blob/master/README.rst#available-cookiecutters)
minor simplification: Polynom(reversed([index * item for index, item in enumerate(self.data, 1)]))
Ha, I wish. 
So Arduinos run python, then? This feels slightly more complicated than I originally expected.
No insteon support?
IMHO, [xorshift*](http://xorshift.di.unimi.it/) is better for non-cryptographic stuffs.
Everything here can be done in Python, no problem. However the main caveat is you want to compile the code to a .exe. I have used py2exe pretty extensively and it can get tricky when you want to package in modules that are not pure python (ie. numpy). Check out http://www.py2exe.org/index.cgi/WorkingWithVariousPackagesAndModules for help when you are working with various modules including numpy and matplotlib. Also I would suggest you check out Brandon Rhodes video this year about other options for creating .exe's with Python https://www.youtube.com/watch?v=wsczq6j3_bA
Could you make this a web application? I commented about Py2exe and about how it can get a little tricky with _non_pure_python_ modules. Could you give your users a web portal to upload their data to and you then generate the reports on your server and return a PDF?
No, you don't run python on Arduino's. You just interface them trough a serial cable or something else and on a computer you run python that talks to your Arduino. So the Arduino is only a way to interface a physical device, but the controlling part can be done in python.
This is really good. I learned some new tricks for my favorite CLI tool!
Thanks for your work. Hopefully I will be able to contribute. Have my own product api that I might port over.
Awesome project! I am definitely going to try this out at home this week. And possibly contribute Nest API support.
This is amazing and exactly what I have been looking for. I'm installing this on my raspberry pi right now. Thanks for sharing this!
You can write a function that performs something similar. #compose would simply reverse the arguments def pipeline(*funcs): """Returns a function that pipes the returns values through funcs""" def operate_on(*args, **kwargs): rval = funcs[0](*args, **kwargs) for func in funcs[1:]: rval = func(rval) return rval return operate_on polynom_pl = pipeline(map, reversed, list, Polynom) polynom_val = polynom_pl(self.data[1:], range(1, len(self.data))) 
This needs to be at the top of Python for the day. Anyone that wants their socks blown off, just go to this link... https://tmpnb.org
|TCP doesn't really care whether it's a client or a server once you get past the intitial connect or accept calls I would go one step further and say there is no client nor server once the connection is made.
The better way to do it is to use a beagle bone black that is a small embeded computer that can run Linux or windows CE. If what you need is a ON/OFF control the better way to do it is to use a relay and a transistor BJT (Bipolar Junction Transistor) or MOSFET to trigger the relay and activate the device. if you want your project to be very cheap, better ditch python and use microcontroller with C programming and a serial cable to monitor the microcontroller using a computer. 
I would totally do this with a bash script
&gt; fixed PEP8 oh, was it broken? ;) 
Fair enough
Haven't thought of a web portal... That would also asked me to track my users. Would there be any issues running numpy and other python modules through the web interface?
Cool! If you feel like writing your own component, I have written up [a guide how to make your own](https://github.com/balloob/home-assistant#further-customizing-home-assistant).
This could be doable via bash script but if you want to use python, I would recommend a few libraries... First - the glob module. Will get all file names matching a certain string and store them into a list. from glob import glob png_files = glob('*.png') Secondly, I like using the os library to run commands via cmnd line, some people like using the subprocess library. import os os.system('rm -rf *') In your case, you could do something like png_files = glob('*.png') dest_folder = '/here/is/a/great/path/into/the/unknown/' cmd = 'mv {} {}' for file in png_files: os.system( cmd.format(file, dest_folder) ) If you want to be cool then you can do import os from glob import glob as gthang for file in gthang('*.png'): os.system('mv {} {}'.format(file, '/here/we/go/again/traveling/to/the/deep/unknowns/of/the/file/system/')) If i'm not mistaken that should take all files with a .png extension in the current directory, loop over each one, and for each iteration, move the file to dest_folder. Hope that is enough to get you started! This does seem like a good fit for bash scripting, but I myself have even lost my bash skills and do everything now in python. Bad habit I guess but hey it works! 
Exactly. The application developer might have some mental model that divides the two, but usually the only difference is that a server has a known public address and a client does not, and that ceases to be relevant once the connection is accepted - the 2 sides are equivalent in networking terms past that point (hence functions with names like 'getpeername').
This is awesome. I'm a Crestron and AMX programmer, so finding something opensource with this much work already done is great. Will definitely be adding to this. :)
Yes, and secrets there are encrypted, or using Heroku.
Thanks isrardogar
Thanks, that's exactly what I wanted! Could you walk me through how glob works maybe?
Well, my ultimate problem is to deploy the expert system builder to make a working expert system to transfer process-oriented knowledge. If there's something which already does, that's very interesting. Thank you!
thanks! :D
I'm going to side with /u/Pink_on_Inside here, despite the downvote train he's facing in each thread. Just last week we had yet *another* (which should be called our "monthly" at this point) thread which talked about /r/python being flooded by questions like this. Yet, when anyone actually suggests that the questions go in the subreddit that is *for* questions, downvotes ensue. Point being, a gentle throat clearing, and a nudge in the right direction should not warrant such scorn. OP, ya posted in the wrong place. Go to the question place. This is the discussion place. 
Maybe you can make use of a hashing algorithm. If you would use sha256 to make a hash of an initial seed and you keep hashing the result of the previous sum, the outcome would be pretty random. This way of using sha256 is not cryptographically secure, but in your case it would be fine I think. In theory this will eventually loop, but the chance that you'll ever encounter this is pretty low (would be awesome if it happened though, never heard of sha256 hash collision).
I've search but couldn't find it.But i stumbled upon neota logic , which builds something that looks like a high quality expert system for legal services but might fit your need. But it look expensive. Also there's exsys ithink. 
&gt; OP, ya posted in the wrong place. Go to the question place. This is the discussion place. The issue is that _every_ place is now becoming 'the question place'. Every place is for beginners now. And this is what bothers me.
I don't keep actual server configs in source control - it'll either be an example configuration file that will be modified and placed in /etc/, or something to be built via puppet/chef/ansible/salt/etc.
Ah got it. I thought that Arduino was more like a Raspberry Pi. Thanks for clearing that up.
I'm not necessarily concerned with it being the cheapest, just the easiest for me to work with since I'm starting from scratch with knowledge.
Yeah, that would be awesome! Much appreciated.
Thanks again, very useful.
Are you using PyNest from [here](https://github.com/smbaker/pynest)?
Is it possible to share(if you prefer in private message) , what kind of industry/solution this system is going to ? 
Thanks for having a look at it :) I wouldn't really say that the tutorial makes use of Node.JS. Things like NPM and Bower (package management utilities) require Node to work, but other than that I don't thing Node is used anywhere. There is a box to leave your email in on the right side of my website:http://jamesbrewer.io/ Also, if you feel compelled, I would love your feedback on the tutorial so far: http://bitly.com/109tJe1 
If you want to control real world stuff through python in easy way, beaglebone is the way to go. It has digital I/O ports, analog to digital converter, PWM, timers, event counter, I2C, SPI and serial ports. It's like a electronic laboratory running Linux. However you must use interface and protection circuits to ensure that the circuit board works properly. For example, to control a 110/220 V you need a relay and a MOSFET, a led must have a resitor in serie with BJT transitor because the board cannot supply enough current to drive the LED. The analog to digital converters needs low tolerance voltage-divider resistors to have an accurate measurement and its maximum voltage level is about 1.8 V, you cannot exceed this or you will loose your board. By: an Engineer
It was actually undeprecated in 3.x where it uses subproces underneath anyway. Maybe the 2.7.x docs should be fixed
A friend let me know about [random number generation via HNRG](http://scruss.com/blog/2013/06/07/well-that-was-unexpected-the-raspberry-pis-hardware-random-number-generator/) on a Raspberry Pi via a related conversation on Facebook. I'm going to give this a try tonight.
Should I delete it from here? I posted it there, as well, but I assumed that the readers of this sub may be more advanced. I supposed that /r/learnpython was for people like me who are still learning and /r/python was for those who are already python developers.
I've never used `communicate`, but the docs state: &gt; Similarly, to get anything other than None in the result tuple, you need to give stdout=PIPE and/or stderr=PIPE too. You are only giving `stdout=PIPE`, so `err` will probably always be `None`. Furthermore, keep in mind that `err` will contain everything written to `stderr`; most UNIX tools actually write errors to stderr, but some programs do not. Also, `stderr` is unbuffered, therefore, some tools abuse it to show progress bars and such. So definitely pass `stderr=PIPE` and go from there (test it with the tools you want to use it with).
Here's a quick and dirty script that should do what you're asking in pure Python (i.e. no system() calls). import os import shutil import time WATCHED_DIR = '/home/thegermansarecoming/Downloads' EXT_TARGET_DIRS = { '.png': '/home/thegermansarecoming/Pictures', '.zip': '/data/zipped', } PAUSE_TIME = 300 # in seconds def move_files(directory): for root, dirs, files in os.walk(directory): for file in files: name, ext = os.path.splitext(file) if ext in EXT_TARGET_DIRS: shutil.move(os.path.join(root, file), EXT_TARGET_DIRS[ext]) def main(): while True: move_files(WATCHED_DIR) time.sleep(PAUSE_TIME) if __name__ == '__main__': main() It's pretty straightforward, but here's what you need to know to understand how it works: * [os.walk](https://docs.python.org/2/library/os.html#os.walk) lets you easily browse a directory tree for all files and subdirectories. * [os.path.splitext](https://docs.python.org/2/library/os.path.html#os.path.splitext) is the recommended, portable way to get a file extension. * [shutil.move](https://docs.python.org/2/library/shutil.html#shutil.move) is used to move a file. It's "better" than the standard [os.rename](https://docs.python.org/2/library/os.html#os.rename) because it works even if moving the file to a different drive. * EXT_TARGET_DIRS is a dictionary that associates file extensions to their respective destination directories. * [time.sleep](https://docs.python.org/2/library/time.html#time.sleep) will pause for a given time in seconds. This is very barebones. Here are a few possible improvements, as homework ;) 1. Add [logging](https://docs.python.org/2/library/logging.html) 2. Take parameters from command line instead of constants (use [argparse](https://docs.python.org/3/library/argparse.html)) 3. Error / exception handling (what if one of the directories does not exist?) 4. Instead of checking the whole directory at fixed times, just check the directory once at startup, then get notified of new files asynchronously. If you're running Linux, you'll want to use [pyinotify](http://pyinotify.sourceforge.net/). On Windows, you'll probably have to wrap a call to the [FindFirstChangeNotification](http://msdn.microsoft.com/en-us/library/aa364417%28VS.85%29.aspx) API using [ctypes](https://docs.python.org/2/library/ctypes.html). 5. Properly "daemonize" the process. As it is, the only way to end it is to interrupt it via Ctrl+C or kill the Python interpreter.
The other option would be to wrap the C/C++ code using Cython. A number of projects, such as pysam and pyvcf do this.
And use VBA to automate the data import and analysis process. I could, haven't thought of that. 
This is an example on how to use tls client authentication to connect to a server. It took me forever to figure this out, so I'm sharing this in the hope it's useful for someone else. I'm no tls/ssl expert, but feel free to shoot questions if you have any :)
Thanks, I tried adding logging but it just writes onto the one line which is quite annoying. I managed to write the script for now: from glob import glob import os import shutil import time extensions = ['jpg', 'exe', 'ico', 'png','webm', 'gif', 'iso', 'txt', 'psd', 'wmv', 'mp4','xlsx','doc','msi','m4v','wav','mkv','rar','mid','mp3','zip','epub', 'folders'] def move_files(x, extension): dest_folder = '/Users/thegermansarecoming/Downloads/%s' % extension if os.path.isdir(dest_folder) == False: os.mkdir(extension) print x, dest_folder for files in x: try: shutil.move(x, dest_folder) except: pass def move_folders(extensions): list_of_folders = os.listdir(".") print list_of_folders common = [i for i in list_of_folders if i in extensions] print common for n in range(0,len(common)-1): for m in range(0,len(list_of_folders)-1): if common[n] == list_of_folders[m]: if list_of_folders[m]!="zip": del list_of_folders[m] else: pass print list_of_folders if os.path.isdir('/Users/thegermansarecoming/Downloads/folders') == False: os.mkdir("folders") for folder in list_of_folders: dest_folder = '/Users/thegermansarecoming/Downloads/folders/%s' % folder dest_folder_main = '/Users/thegermansarecoming/Downloads/folders' if os.path.exists(dest_folder) == True and os.path.exists(dest_folder_main) == True: os.remove(folder) try: log = open("log.txt",'r+') except IOError: log = open("log.txt", "w") log.write("%s removed at %s " % (n, str(time.asctime(time.gmtime())))) log.write("") log.close() elif folder != "log.txt" and folder != "DownloadFolderMove.py": move_files(folder, "folders") else: pass def running_for_each_extension(exts): for ext in exts: files = glob('*.%s' %ext) for n in files: dest_item = '/Users/thegermansarecoming/Downloads/%s' % n dest_folder = '/Users/thegermansarecoming/Downloads/%s/%s' % (ext,n) if os.path.exists(dest_item) == True and os.path.exists(dest_folder) == True : os.remove(n) try: log = open("log.txt",'r+') except IOError: log = open("log.txt", "w") log.write("%s removed at %s " % (n, str(time.asctime(time.gmtime())))) log.write("") log.close() elif n != "log.txt": move_files(n, '%s' % ext) else: pass while True: move_folders(extensions) running_for_each_extension(extensions) time.sleep(300) Big, chunky, messy but I'm kind of proud of it. However, it keeps moving the bottom folder into the "folders" folder. No clue why, it has left me stumped. Here's is my fresh download folder: http://prntscr.com/52rt46
My preferred approach is to create a small install.sh script that sets up a virtualenv inside your project. Then pip install all deps in the virtualenv. I then create a env.sh file that is sourced to set up the environment for the program to run. It usually contains some path settings and a sourcing of pyenv/bin/activate. 
For a beginner, I would recommend the Raspberry Pi over the BeagleBone purely for the community support. I personally much prefer the BeagleBone, but the Pi has the advantage of a million people already having been there, done that, and blogged about it.
It looks good to me. You might consider writing some tests (and breaking the code up a bit to be more testable).
This isn't the right place to post this. Presumably, something is wrong with decoding - You could ask about that over at /r/learnpython, for example. If this is an actual bug, you should report it to the developers: https://bugs.python.org/ Downvoted.
&gt; Should I delete it from here? Please do. &gt; I supposed that /r/learnpython was for people like me who are still learning and /r/python was for those who are already python developers. Exactly. /r/python isn't for help in learning the language, it's for articles and news about the language, in short, things that help improve your skills as a python developer if you already are one. 
It would have to be Polynom(reversed([index * item for index, item in enumerate(self.data[1:], 1)])) and personally the original was better (mostly because it works for arbitrary iterables).
It depends what type you want back. Normally an iterable is fine so you should use `reversed`. When it is not, the first is normally better.
My project [Pynsist](http://pynsist.readthedocs.org/en/latest/) builds Windows installers that include Python, your application code, and whatever libraries it needs. There's no portable installation option, though - it's intended for classic installation onto one target machine.
&gt; As you can see it's really ugly syntax. I wouldn't blame the syntax but the fact you're trying to make everything use lists. If you make a `map` that returns a list instead, more similarly to Haskell, you have from itertools import count from operator import mul def lmap(*args): return list(map(*args)) which allows Polynom(lmap(mul, self.data[1:], count(1))[::-1]) Compare: Polynom . reverse $ zipWith (*) (tail data) [1..] The Python code might be a bit more parenthesis-y but the concepts expressed are the same. FWIW I suggest writing `Polynom` to accept an arbitrary iterable. It shouldn't be accepting lists without copying anyway because of mutation risks. 
I don't get it, am I missing something? An immutable list is a tuple, an immutable dict is a ImmutableDict, and immutable set is frozenset. Why use this?
Y axis is a random number between 1 - 50 and X is incremental starting at 1 and going to 1,000,000. I am working on Pandas. And I'm going to use a new technique for generating random content. Results a soon as I finish paying the bills.
&gt; simplify the reasoning about what a program does since no hidden side effects ever can take place to these data structures. You can rest assured that the object you hold a reference to will remain the same throughout its lifetime and need not worry that somewhere five stack levels below you in the darkest corner of your application someone has decided to remove that element that you expected to be there.
You're right, of course.
with the for n in range(0,len(common)-1): for m in range(0,len(list_of_folders)-1): if common[n] == list_of_folders[m]: if list_of_folders[m]!="zip": del list_of_folders[m] I was trying to remove all the items of the list that the common and the list_of_folders list had in common
I do enjoy the idea of having large community support but the beaglebone does sound like a good option too. Maybe a good option is to start with the raspberry pi then migrate over later on.
Hardware wise, the beaglebone is absolutely better, especially the Rev C. But even a Pi is overkill for this, so throwing a BBB at it is expensive, difficult, and unwarranted :) The Pi is easier than an arduino, because it gives you inbuilt networking, high level languages, it's just that much easier. But the BBB doesn't give you anything more - even if you can wrap your head around the PRU (realtime hardware modules) you don't need them. Your project is not going to stretch the capabiities of the Pi, the BBB is frankly wasted.
This sounds like a very in-depth piece of hardware. I am not sure if it's a little more involved than raspberry pi in getting it set up and running. Maybe i can transition over after I get used t orunning everything.
Yep. If you don't know what the BeagleBone is, then the Pi is going to be the easiest way to get this working, I'd say :)
Up until 7.5 minutes ago, I'd never heard of it! Have heard of the Pi though, and kind of knew what it was about. So shorthand for the BeagleBone is BBB?
Ah, yes. The Beagle series started with the Beagle Board in various versions, and then the Beagle Bone, of which the latest is the Beagle Bone Black - BBB. It's a direct competitor to the Pi in the "SoC" space - System On Chip. It has a similar ARM core, but different peripherals. It's a more serious piece of kit than the Pi in many ways, but slightly less user friendly. There is an active community, but they tend to be more technical.
Got it. I obviously have a lot more research to do with my idea for this project. In my head it seems pretty straightforward but it does seem like the more I look into it, the more I don't know!
Hah, yes, always the way. 
Adding an element to the end of a tuple takes `O(n)` time. With a list you want this to be close to `O(1)`. Immutable lists close the gap. The same thing applies for the others, sets and dicts. With a `frozenset` adding an element is `O(n)`. With `ImmutableSet` the aim is that it's much less.
I ran with the excel idea, developed a good working system. It loads, formats, processes, and saves a PDF report on the users desktop. I am still interested in a python version, will be a good learning exercise. That's for talking it through with me and the fresh ideas. 
So basically I have my own ipython notebook server? What packages are available? Sorry I'm not too familiar with docker technology, my rudimentary understanding is that it allows you to create mini virtual OS. Maybe if someone could do a ELI5. Looks exciting though. 
Python isn't a pure functional programming language. It's okay if this is an intellectual experiment, but one shouldn't fool himself into thinking that fitting something like this into Python will "simplify the reasoning about what a program does since no hidden side effects".
&gt; I don't get what your point is. Just that in the context of what you were replying to, the wording of your statement could be confusing. Similarly, if someone were to say "Adding an element to the end of a list", that could also be confusing (for other reasons). &gt; You can do this: tup = (1, 2, 3) tup += (4,) Code is, of course, the least ambiguous way of describing these things. But, for your example, imo it's much clearer to describe this as "concatenating two tuples" (especially as the re-assignment to tup has no bearing on your point about big-O complexity). Your point stands (and is worth understanding) that even though new tuples need to be constructed, if the internals of immutable python data structures could incorporate existing immutable structures internally, it could potentially save a lot of copying of object pointers, and reduction of big-O behavior.
Yeah...I agree with you. I clicked on it expecting a new abstraction to data serialization.
The two main things I would look at are [Incanter](http://incanter.org/) ("Incanter is a Clojure-based, R-like platform for statistical computing and graphics") and [core.matrix] (https://github.com/mikera/core.matrix) ("core.matrix provides array programming as a language extension for Clojure, with a focus on numerical computing").
Yeah, but you'd need to change your range...is there a reason you picked 250 or was it just a big number? If you lower it to the amount that would put the thingy back at its starting point, the problem would be solved.
The API looks pythonic :)
Very cool! Thanks
&gt; MAIL_LIST_SEPARETOR = ', ' tic Looks really clean though! I don't see the builder pattern like this much in Python, but it makes some sense here over the telescoping constructor alternative, despite the line continuation characters. Example for easy reference: from fluentmail import FluentMail mail = FluentMail('smtp.gmail.com', 587, TLS) mail.credentials('you@gmail.com', 'pwd')\ .from_address('you@gmail.com')\ .to('other@gmail.com')\ .subject('FluentMail')\ .body(u'&lt;h2&gt;Hi, I\'m FluentMail.&lt;h2&gt;', 'utf-8')\ # Body charset is optional. .as_html()\ .attach('photo.png')\ .attach('description.txt', 'utf-8')\ # Charset is optional, and only for Text files. .send()
They don't mean "Adding an element to the end of a tuple" in the sense of, "Sticking a new element into a tuple", they mean it in the sense of "Adding three to five", i.e. producing a new object by adding an element to the end of a tuple.
Do note that the ssl module is not very secure though, this talk has some useful information: [The Sorry State of SSL - PyCon 2014](https://www.youtube.com/watch?v=SBQB_yS2K4M#t=1853)
But you don't produce a new object by adding an "element" to the end of a tuple, you produce a new tuple by adding a tuple to the end of a tuple. Or similarly stated, you produce a new tuple by adding to tuple to the *beginning* of a tuple. Maybe more precisely stated as "concatenation resulting in a new tuple". 
This was quite a good, motivating read. I believe there is a book of this sort waiting to be written (perhaps by the OP?). I am a big fan of this approach.
You're being sarcastic, right?
It was inspired by C#, not JavaScript. If you dislike you can always split the statement in many lines, works too.
But is still as ugly as hell. I would expect something like a "Mail" class (or simply a function), with "to", "subject" and "body" as positional args and the rest as kwargs.
I feel like using a dict or kwargs would be cleaner than all the `.from_address().to_address()` etc. It's very *LINQ*y but I'm a fan of following language conventions so for me it seems out of place in Python. However, it does look like a nice, concise email library.
Agreed, having to depend on line continuation is pretty horrific. Offensively so.
It's a really fun thing to implement. I think dutc beat you to it https://gist.github.com/dutc/3f2c79048d95287be138 :-) He also went for the more pervasive, scary as hell solution: https://github.com/dutc/didyoumean
I did notice that after I decided to give it a try (I found his C solution which I haven't understood yet - I didn't know he had done a Python solution too). Funny thing is that I started with NameError and he focused on AttributeError. I thought I'd learn things by working on this (and I definitly did) but that it might be of interest for others (and I might be a chance for me to learn even more).
Winpython is one binary, and you could fork it to change the packages. It installs into a folder, and creates a completely isolated stack. You'd have to trim away tons of the good stuff it comes with. But, it would fit on a USB. Ninja Edit: Will only work on windows, so may not what you want.
You missed an opportunity there. Instead of changing state and returning ``self`` every time, make your mail object immutable and return a new instance for each change. That way you could easily prepare an email and send it with different details to different recipients. prepared_mail = Mail().sender('Example Support &lt;support@example.com&gt;')\ .signature("Please don't sue us,\n Example Enterprises")\ .text('Hi %NAME%')\ .html('&lt;h1&gt;Hi %NAME%&lt;/h1&gt;')\ .attachment('./agb.txt')\ .server('mail.example.com', 25)\ prepared_mail.to('Alice &lt;alice@example.com&gt;').replace('%NAME%','Alice').send() prepared_mail.to('Bob &lt;bob@example.com&gt;').replace('%NAME%','Bob').send() 
Just because python isn't a pure functional language doesn't mean we have to have horror in all our code :P
It's the accepted term though.
Sounds interresting. I'll take a look. Could you open an issue for this?
I haven't looked at the code either but generally that is the point of these "persistent data structures" (the author mentions Clojure whose data structures definitely do this). For instance creating a new vector by concatenation uses a tree structure behind the scenes with the previous vector and new item.
The only way we'll get something like Requests for email is if people keep trying to nail an API that the community likes.
Waste memory in what way? If you have a vector of (1, 2, 3) and concat a 4 to it: behind the scenes you'd have a memory location m1 for the first vector. Then the structure in m2 would be more like (m1, 4). Since the structures are immutable, they can mostly share memory instead of copying things. So you avoid the issue with strings where things would slow down and have a lot of temp memory allocations when concat a bunch of strings in a loop without using a stringbuilder type object. 
Yep, it is a hard work, but why not? :)
pretty unfortunate collision of vocab terms. in application development persistence nearly always means "saving to a non-volatile datastore". 
MY prefered method is a little old school- but there's rhyme to my reason. I work primarily in linux- so ymmv. I build python from source, but I prefix it. ./configure --prefix=/path/to/my/installation I then install whatever packages I need to that installation. 
I don't know if the creators of the repo will see this here, but I think the readme could use a better upfront description of why these data structures are useful. Especially since people in Python probably aren't as familiar with it. The main benefit of these things (besides what deadwisdom mentions of being able to easily concat collections, "delete" members, etc and get a new collection back) is that they try to implement things behind the scenes to minimize memory use and maximize speed. If you think of the case of concatenating a bunch of strings together, that tends to cause slowness and a lot of memory shuffling due to copying the immutable strings around. So in Java there is StringBuilder and in Python you might keep a list of strings and join them at the end to avoid those issues. A persistent structure instead would treat the structure internally more like a linked list or tree, sharing the previous strings' values in the new concat versions. One reason this is especially helpful in the case of a language like Clojure that gives extra support in the language for concurrency is that it helps you get a consistent state of the world. Like an example from a presentation I saw had an ant simulation. There is a grid which is the "world". Food is placed in random locations. Ants start from their home and go off in search of the food. They leave scent trails that decrease with time which influences where others go. So if there's a bunch of food in one spot, they tend to go back there sooner to get more until it runs out. And this is shown graphically on the screen. The neat thing is that they implement each of the ants on their own thread, as well as a separate graphics thread to paint the screen. Normally this kind of thing would be difficult because the grid is shared state between all the threads and the graphics thread needs a consistent look at the world. If it paints from left to right and top to bottom, what happens if an ant moves down a row just as it is painting those two rows? You'd see the same ant appear on two rows at the same time. Clojure can modify or examine shared state with transactions or actors. So the graphics thread can open a transaction and look at the world grid and paint it. As it does that, the grid never changes. It has a consistent snapshot of the world it can draw from freely for as long as it takes. As it is painting, the ant threads are modifying the grid, but the graphics thread is still looking at that old copy that still exists. Once it is done, the system can see that the old version isn't being used anymore and any of the data in it that isn't used in the newer copies can be garbage collected. This also fixes the issue of multiple ants trying to move to the same spot at the same time. So they both might try at the same time and be looking at the same old copy of the grid. One succeeds in moving and a new version of the grid is created. The second ant thread tries to modify the grid but fails since the grid was modified the meantime and it auto-retries, now getting the new version of world. It sees that spot is occupied and tries to move somewhere else instead. It all works because there's always the old "persistent" versions of the shared state around that things can work with while other things are still free to go and "modify" it at the same time. 
Hey, this should really go in /r/learnpython or /r/learnprogramming If you post in there you'll get better responses and you won't get flamed for asking this question :)
&gt; plt.autoscale(tight=True) This is the culprit. For some reason scaling causes the artifacts, maybe rounding errors or something. If you remove this line the graph becomes a completely filled black rectangular shape without any visible patterns.
I think I'll add `kwargs` to `send` to be more pythonic.
Well, to be fair, I mostly wrote it thinking "would that be possible to..." ? Then, as my fingers and my brains are not as good as I'd like them to be, I tend to find it a bit useful. A non-exhaustive list of mistake I'd do and where the suggestions can be useful : - misc typos on variables/modules/method names - missing import for snippets copied from wherever - trying to call things like "my_list.len()" instead of "len(my_list)" - forgetting "self" Nothing that I normally wouldn't be able to fix by focusing a bit more on my code or by looking at some documentation. Also, it can be quite convenient when working on some unusual libraries.
I love these kinds of decorators. Makes debugging a hell of a lot easier. For anyone else who likes this sort of thing; https://github.com/ajalt/fuckitpy I love fuckit.py but it should be noted that these should not be used in production unless absolutely necessary.
i find it amazing that something so useful hasn't warranted a proper hook in the Python interpreter itself. The fact that the code "[finds] the function, unprotect its memory page, then clobber first few assembly instructions with a jump" is awesome, but indeed, scary as hell. Like using modified HIV to find and kill cancer cells, scary. Then again, is there a PEP for this?
This is great!
Hey, I appreciate the heads up. I'm subbed here but don't browse the extended network often, I'll check it out. Thanks.
I used the word 'pythonic' as neat, clean, python way. Does the word mean something bad?
No, Pythonic is good. But this API is far from Pythonic. I'd recommend you read [Writing Idiomatic Python](https://www.jeffknupp.com/writing-idiomatic-python-ebook/) if you can. It's well worth the price.
`next` is a function that returns the next item from an iterator. In your case, `start` is just an int, hence the error. I don't know why you think anything else should be happening, you need to explain why you think it should work if the problem is not clear. Also, please post questions like this in /r/learnpython.
I had to mention Haskell had something like that by default. This is pretty cool.
Thank you for your recommendation. I didn't fully understand what python way means. I'm not familiar with python idioms yet. I have been used send_mail API of django. This API looks more neat, cleaner for me than django's. But as you said, it can be far from python way.
Elasticsearch as a data store? Heh, hope that data wasn't super valuable.
This can lower the learning curve. It is extremely useful for those learning the language, beside it is extremely useful for those experimented pythonitas eye tired programming at 3:00 A.M.
Ok let's compare [fluentmail](https://github.com/alexandrevicenzi/fluentmail) to [smtplib](https://docs.python.org/2/library/smtplib.html) which is included in the Python stdlib. Below are the relevant parts (with the code that would actually create the message contents missing). # From: https://docs.python.org/2/library/smtplib.html#smtp-example import smtplib ... server = smtplib.SMTP('localhost') server.sendmail(fromaddr, toaddrs, msg) server.quit() # fluentmail equivalent from fluentmail import FluentMail mail = FluentMail('localhost') ... mail.credentials('you@gmail.com', 'pwd')\ .from_address(fromaddr)\ .to(toaddrs)\ .subject('FluentMail')\ .body(msg)\ .send() I'll readily amdit that smtplib isn't the most Pythonic library out there, but it's interfacing with a subsystem whose rules you have to play by so it gets a pass on being a little ugly. That said, it's actually hard to point to how you could make it much better. Fluentmail on the other hand seems to add a level of complexity and ambiguity that's unhelpful and it's really hard to see how it adds any value to this space.
Is there any place where Guido says "don't use method chaining"? Because we should tell that to the guys behind Django QuerySets, SQLAlchemy and Peewee (among others). You're saying "this is **far** from Pythonic". This might be not the common style used in Python. But I wouldn't call it "far" from Pythonic. I think this has a decent API and the OP deserves some respect.
this is most likely better suited to [/r/learnpython ] However, what you **should** do is first make an honest attempt at the assignment. Then when you are stuck come back with some more specific questions. You can't just say 'here's a homework assignment I have...how do I approach this assignment.' If its your final assignment but you have no idea how to even approach the problem then it seems you haven't learned much. I suggest you write some code first and then come back with specific questions (to r/learnpython) concerning the parts you can't figure out.
This is just as silly as C-code obfuscation challenges... "Sparse is better than dense." "Readability counts." there are a few more... http://legacy.python.org/dev/peps/pep-0020/
Apologies in advance for the wall of text. Here's something different which I have not been able to find the time to do. It would involve writing a simple module (a basic version has been written by another programmer) with a whole bunch of tests which would involve writing tests (which you mention as an area of interest). About a decade ago, I wrote a "karel the robot" clone in Python called [rur-ple](https://code.google.com/p/rur-ple/). This is a desktop program which has been downloaded many times (more on the original sourceforge site than on the googlecode one). One very useful feature was the highlighting of lines of code being executed. You can have a look at [this blogpost](http://aroberge.blogspot.ca/2006/05/rur-ple-getting-closer-to-10.html), more specifically at the image at the end to see what it looked like. In order to make it work reliably, I used some method calls specific to CPython. Fast forward many years. I now focus my time on a web version called [Reeborg's World](http://reeborg.ca/world.html) which 1) does not require to install anything and can thus be more readily used in schools; 2) does not require logins; 3) does a lot more than rur-ple did with one exception: no line highligthting of code is done as the code gets executed. Reeborg's World supports programming in Python, Javascript and CoffeeScript (with possibly others in the future) ... but everything is done in the browser with nothing communicated to a server. The Python code is executed using [Brython](http://brython.info). Ideally, I would like line highlighting to be available in all languages ... but, seriously, I would be 99.9% satisfied if I could get it at least working with Python as this feature is most useful for absolute beginners (or for teachers) who should start with Python. Because I am not using CPython, I can not use the method call (sys.trace) to implement the desired functionality. A possible approach, which I had tried to use first with rur-ple and ... sort of worked but was brittle, was to parse the code prior to execution, an insert a special instruction [let's call it `set_line_number(n)`] before each line of code, with the proper indentation (so that it did not break the code). When executing the program, each time `set_line_number()` would be called, the corresponding line of code would be highlighted in the editor - just like it is done with rur-ple. An internet friend of mine has implemented a first version of such a "parser" which [can be found here](https://code.google.com/p/pseudo-pdb/) I have not incorporated it inside Reeborg's World yet nor played with it much. It is on my (long) todo list. Your mission, if you accept it, would be to take the existing first version of the "parser", extend it and write many test cases to ensure that it works properly. It actually may not take a huge amount of time to do so... but countless beginners, as wel as myself, would be very grateful if this became a feature of Reeborg's World.
The more I think about it - this isn't as simple as I originally thought. Especially if you are unfamiliar with basic circuitry. One issue is that the RPi GPIO is very limited in how much current it can draw (the RPi is a low power device). So that makes driving a relay problematic if you just want to directly connect to the GPIO. The work around is to connect your GPIO pin to a transistor which will amplify the signal form the GPIO pin so that it can properly drive the relay. There is a good blog post on the subject here: http://www.susa.net/wordpress/2012/06/raspberry-pi-relay-using-gpio/ However they are suing c-code at the end as opposed to python. And the circuit is rather complex if you have not dealt with relays and transistors before so this is likely over your head. I'll try to think of a simpler way to work on this problem 
You should ask in /r/learnpython, or read the documentation. /r/python isn't the place to post questions.
no prob :)
Hey, I never said you were disrespectful. That'd be really bad. Maybe the word I was trying to use was "recognized". "The OP should be recognized by his/her work". I don't want to start a hate conversation here, so let me apologize first if that wasn't clear enough. Now, back to code... What I am reading now from you, is that "it makes more sense" on SQLAlchemy. Then, it's just a matter of taste and design. But again, that doesn't mean that it's not Pythonic, as you were saying before. Now I'll get subjective (sorry to do that, but just for reference) and say that I do like the API in fluentmail (actually I'd prefer it to be immutable). 
You should ask in /r/learnpython. /r/python isn't the place to post questions.
&gt; these should not be used in production unless absolutely necessary. Ever. These should never ever be used in production.
That's true.
You could always just get it as a float and then convert it into a string afterwards by doing something like follows: numAsString = str(num) 
Thanks PHP. @This is your fault.
I trust you don't have much Job Security then. ;)
Nice! Is was really short and clear code on extracting and decrypting the passwords. 
Start with the book [Learn Python the Hard Way](http://learnpythonthehardway.org/). After that, check out [this project on Github](https://github.com/sixohsix/twitter) which provides a nice command line twitter client and some excellent functionality.
Never say never. I can imagine fuckit making it somewhere non necessary. Its basically a big try/except:pass block. The former... Not so sure.
When porting of pattern to python 3, this script was interesting to see what I should b targeting next.
If I remember right, things greatly improved in python 3.4. Thanks for the link though! Going to watch it later.
Can't be that hard to upload via curl, having digest http authentication. You need to extract the csrf token first I think.
 with fuckit: my_job()
In fact, this should never be used in any code that any other human will read. 
then you'd just get people chaining functions to avoid setting variables when they could be more understandable with variables. the fact of the matter is, the jumps you make to create lower character count translates to other innovative thoughts, where reducing the work required might be a valuable optimization to a program. 
Not sure I understand the point of the question. `raw_input` returns string. Just use `float` or `int` to get numerical equivalent (if possible) e.g. S = raw_input() F = float(S) I = int(S) 
I like it accept thse use of the Variable "Pass" Needs to be changed to something else. pass is reserved for looping.
Love the idea for the API - but I wonder if this could be taken down by Nintendo? Maybe not if they don't charge?
Here is a nice ipython notebook of someone trying to implement simple assembler. You can use networkx to make the de bruijn graphs. http://nbviewer.ipython.org/github/cschin/Write_A_Genome_Assembler_With_IPython/blob/master/Write_An_Assembler.ipynb
Hey! I made the PokéAPI. I'm never going to charge for it, and all the data is freely available online, so it should not be an issue.
Does it use Levenshtein word distance?
So an update: I managed to get a virtually hosted system with the restrictions of the actual remote access and there was no problem using Python so now Statistics Finland has agreed to provide it. Yay! Thanks for all the suggestions.
Great walkthrough but I'm not using blasr. I'm pretty much starting from scratch with raw reads which I've broken up into kmers and stored into a frequency table. Now I'm just looking for a way to create some sort of graph to weave out an ancestral sequence.
Fork it from http://bitbucket.org/jurko/suds, make changes, install from your fork. You may make a pull request with your fixes.
You misunderstood my comment. I meant symbol length not number of variables, for wildly arguable definition of what a variable is.
No, concatenation is a fundamentally different thing. It's just that Python has only concatenation built in. There's nothing theoretically important about that choice. The concept of adding an element to the end of a tuple is well-defined and valid. It would be very easy for tuples to have some variety of 'append' function that just returned a new tuple rather than modifying in-place. In Python, it happens they don't. But that Python made that choice about what behavior to build-in doesn't really mean anything at all about the fundamental properties of immutable lists.
Nice! Once chosen the language, thou, no way to change it.
Give me fuzzy tab-complete for methods and attributes in the REPL. This would make the trial, tab and error method of learning a new API much nicer ;)
Hi! I'm probably not very good at ELI5, my children are all &lt;3 and I need coffee. Here goes nothing. Basically, a brand new file system and programming environment is setup for you with the full python scientific computing stack, Julia, and R. After some time after you leave, your personal server is destroyed along with the notebooks. When you initially hit tmpnb.org, it creates a fake new user for you, grabs an available IPython notebook server, and proxies all requests to your personal setup. The packages installed for Python are: Cython==0.20.1post0 Jinja2==2.7.2 Mako==0.9.1 MarkupSafe==0.18 Pillow==2.3.0 Pygments==1.6 Sphinx==1.2.2 argparse==1.2.1 backports.ssl-match-hostname==3.4.0.2 certifi==14.05.14 chardet==2.0.1 colorama==0.2.5 decorator==3.4.0 dill==0.2.1 docutils==0.11 gyp==0.1 h5py==2.3.1 html5lib==0.999 invoke==0.9.0 ipython==3.0.0-dev jsonschema==2.4.0 matplotlib==1.4.1 mistune==0.4.1 mock==1.0.1 mpi4py==1.3.1 networkx==1.9.1 nose==1.3.4 numpy==1.9.0 numpydoc==0.5 pandas==0.15.0 patsy==0.3.0 pycurl==7.19.3 pygobject==3.12.0 pyparsing==2.0.1 python-apt==0.9.3.5 python-dateutil==1.5 pytz==2012c pyzmq==14.4.0 requests==2.2.1 roman==2.0.0 rpy2==2.4.4 scikit-image==0.10.1 scikit-learn==0.15.2 scipy==0.14.0 seaborn==0.4.0 six==1.5.2 statsmodels==0.5.0 sympy==0.7.5 tornado==4.0.2 urllib3==1.7.1 vincent==0.4.4 wsgiref==0.1.2 wxPython==2.8.12.1 wxPython-common==2.8.12.1 xlwt==0.7.5 yt==3.0.2 For Julia: $ ls /home/jupyter/.julia/v0.3/ ArrayViews DataStructures ImmutableArrays Reexport BinDeps Dates Iterators REPLCompletions Codecs Distances JSON REQUIRE Color Distributions KernelDensity SHA Compat FixedPointNumbers Loess Showoff Compose Gadfly METADATA SortingAlgorithms Contour GZip Nettle StatsBase DataArrays Hexagons PDMats URIParser DataFrames IJulia RDatasets ZMQ For R: $ ls /home/jupyter/.R/ acepack evaluate IRdisplay munsell RCurl stringr base64 Formula IRkernel plyr reshape uuid colorspace ggplot2 jsonlite proto reshape2 whisker devtools gtable labeling randomForest rstudioapi XML dichromat Hmisc latticeExtra RColorBrewer rzmq digest httr memoise Rcpp scales Note: Just about anything can change on the prototyped hosted copy. The Jupyter/IPython team would like to get a formal version of this running, with a better name than tmpnb (you can blame me for that!).
I'm on a normal UK Mac Keyboard. alt+e adds an accent to letters: é á :) The data I got was already on github here: https://github.com/veekun/pokedex
&gt; No, concatenation is a fundamentally different thing. Can you explain further? What should the Python docs be calling the '+' operation on two sequences? &gt; It would be very easy for tuples to have some variety of 'append' function that just returned a new tuple rather than modifying in-place. That would directly violate the "there should be one—and preferably only one—obvious way to do it" philosophy of python, so I'm glad they chose not to. Furthermore, tuple().append *couldn't* "modify in-place", so I'm not even sure what you mean by "rather than". Are you suggesting that there are immutable tuple implementations with an append() that *do* modify in place, and that Python chose not to do so?
When will python 3 be available?
Thanks for the responses! I was concerned that the notion of client/server would drive the design but it sounds like it shouldn't, at least not after a connection is established. 
Now, I will use my raspberry pi to build a portable pokedex.
For a moment I thought that Nintendo issued official API...
The [Twython](http://twython.readthedocs.org/en/latest/) library is excellent and really easy to get started with. Makes working with Twitter a breeze.
In future it would be better to use /r/learnpython for these sorts of questions. I'll answer this time though. Two possible ways. Firstly from math import sqrt sqrt(4) &gt;2 Or a square root can be expressed as a fractional power where 1 / root number is the power to raise the base by (e.g 1/2 for square root, 1/3 for cube root) For example: 4 ** 0.5 &gt;2 8 ** (1/3) &gt;2
Check out py2exe.
Very awesome. Mixing this with [identification of a Pokemon using a smartphone camera](http://www.pyimagesearch.com/2014/05/19/building-pokedex-python-comparing-shape-descriptors-opencv/) would be a cool next step.
A quite useful tutorial and a fun project. Well written. 
Hey man, I've done the same thing literary a year ago and still have no idea what are you trying to do. Very few people know what a de brujin graph is without googling.
should be part of python command prompts like iPython. Not much use in scripts, indeed.
&gt; I'll answer this time though. Personally I don't think that's a good idea. If you answer questions, you encourage the lazy behaviour of disregarding the instructions on the side, and contribute to the trend of making every forum a beginner's forum. Just a link to /r/learnpython would probably be better.
Create nodes from your k-mers. Connect the nodes by k-1 overlaps. Then traverse your graph in whatever method you like. Use networkx.
In my setup.py I read the file (wherever it is) use Pandoc to covert it to RST (usually from md) and set that new RST as the long_description. This is automatically executed when you do any setup.py command (including register) Here is a [setup.py](https://github.com/kpurdon/dateconvert/blob/master/setup.py) for one of my projects that does this.
You should be asking this question in /r/learnpython, not in /r/python. If it's a "how do I X" question, it belongs in /r/learnpython. I don't see how this is a python question at all, though. Make a script to post the stuff you want? Shouldn't be difficult. If you want to know _how_ to make that script, ask at /r/learnpython.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**De Bruijn graph**](https://en.wikipedia.org/wiki/De%20Bruijn%20graph): [](#sfw) --- &gt; &gt;In [graph theory](https://en.wikipedia.org/wiki/Graph_theory), an *n*-dimensional __De Bruijn graph__ of *m* symbols is a [directed graph](https://en.wikipedia.org/wiki/Directed_graph) representing overlaps between sequences of symbols. It has *m*^*n* vertices, consisting of all possible length-*n* sequences of the given symbols; the same symbol may appear multiple times in a sequence. If we have the set of *m* symbols then the set of vertices is: &gt;&gt; &gt;If one of the vertices can be expressed as another vertex by shifting all its symbols by one place to the left and adding a new symbol at the end of this vertex, then the latter has a directed edge to the former vertex. Thus the set of arcs (aka directed edges) is &gt;==== &gt;[**Image**](https://i.imgur.com/9I0aMml.png) [^(i)](https://commons.wikimedia.org/wiki/File:DeBruijn-3-2.svg) --- ^Interesting: [^De ^Bruijn–Erdős ^theorem ^\(graph ^theory)](https://en.wikipedia.org/wiki/De_Bruijn%E2%80%93Erd%C5%91s_theorem_\(graph_theory\)) ^| [^De ^Bruijn ^sequence](https://en.wikipedia.org/wiki/De_Bruijn_sequence) ^| [^Line ^graph](https://en.wikipedia.org/wiki/Line_graph) ^| [^De ^Bruijn ^torus](https://en.wikipedia.org/wiki/De_Bruijn_torus) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+clt4mzs) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+clt4mzs)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Seconded. Already love click and picked up some cool tricks.
Sorry guys! But i needed an answer fast and i though this place would be the right place for me. *did not know that /r/learnpython is out there* But otherwise thank you for the answer i will go there from now on! :D
I created a quick and dirty [quantile regression forest](http://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdf) class as an extension of scikit learn's RandomForestRegressor. The closest thing I have been able to find is the quantregForest in R, so I wanted to bring it to python. It takes pandas dataframes as target and predictor inputs, and will output the defined quantiles of the conditional distribution. One of the key differences in a a regression of the mean and quantile regression is the need to store every training observation on the individual leaf rather than just the running average. sklearn _tree seems to obscure the sample list on each leaf, so I implemented this in the fitting process myself. My knowledge of numpy isn't amazing, so this storage is implemented mostly using tradition python dictionaries and arrays. Because of this, performance seems rather limited for large trees or many observations. I'm curious if anyone has suggestions on how to numpyify these objects - in particular "tree_weights" and "tree_leaf_dicts". Otherwise, feel free to use it.
Are you talking about the entrance test? I don't know about that. Anyhow, it should be solvable even if you've chosen a language you're unfamiliar with. Once you've registered, you have access to katas in all the supported languages.
I've been using 'sender' lately and it's simple and nice: https://github.com/fengsp/sender
I stand corrected, I read "But, without using something like Cloudflare's CDN service all requests to this blog in particular would have to travel all the way from where each of my readers are to the data centre in Amsterdam that this blog is hosted in." as that he's actually using Cloudflare. I'll try to be more careful and more friendly the next time.
Something I've been using recently is pipe, thread_first, thread_last, and compose functions from the Toolz library. These do exactly what you want to do. https://github.com/pytoolz/toolz/
You should be asking this question in /r/learnpython, not in /r/python. If it's a "how do I X" question, it belongs in /r/learnpython.
I think all comments here are valid, sometimes I don't agree but I'm not proposing a new standard, it's just a small project for personal use, but I can change to be more pythonic or more clarity. Any help or suggestion or PR is welcome. If I need to change something to get more people using it I can do this. A more clarity way I think can be done like this: from fluentmail import * mail = FluentMail('smtp.gmail.com', security=SSL, credentials=('user', 'pwd')) mail.body(u'&lt;h2&gt;Hi, I\'m FluentMail.&lt;h2&gt;', 'utf-8', True) mail.send(from_address='you@bar.com', to=['other@bar.com', 'me@bar.com'], cc=[], bcc=[], reply_to=[], subject='FluentMail')
Anyone had any luck installing and using PyCrypto on a Windows machine? I'm running into some roadblocks with the install and would appreciate any wisdom.
You are correct! Thank you! [Graph without autoscale](http://i.imgur.com/sDeUEAW.png)
Great talk, but the Go language spec clearly states that Goroutines are implemented as system threads that are handled by the Go manager allowing Goroutines to be scheduled cross thread as well as handle different low level threading models on various system implementations. There are numerous write ups of this on the web and Dmitri Vyukov has published several articles on this topic (and is an expert on the topic). Go wouldn't be able to achieve its concurrency without eventually delegating to system threads and saying it doesn't is a fundamental misunderstanding of system architecture.
A big try/except:pass block should not be used in production either.
^ This is the correct reply.
The homepage of golang.org has a concurrent pi example program. It spawns 5000 goroutines. Copy, compile and run it. If you don't screw with GOMAXPROCS, it will spawn two threads - 1) the go runtime and 2) the 5000 goroutines. If goroutines == threads as you claim, then there should be 5000 threads. 
I think you should do Portuguese 😜 
Maybe delete this thread?
Is there a German version already? I'm relatively new to python, but I have translation experience.
Nope. No one has started a German version yet. Go ahead and email me. al@inventwithpython.com And having language or translation skills would be much more important than Python or programming skills. :)
Will write you tomorrow! Maybe a good opportunity to work on both things.
&gt; You're slightly mixing up what how Python chooses to do things and the fundamental theoretical concepts are. You’ll notice that in my post that you responded to, I said "in Python" quite clearly. So if it helps clarify things for you, substitute the term "Python object" everywhere I said "object" in the post after your first response to me. &gt; The '+' operator is concatenation, and concatenation is what is built-in for tuples in Python. But it is not the same thing as "adding an element". Which was *exactly* my claim. That the Python concatenation operator performs (wait for it) concatenation, not "adding an element". &gt; Can you do it in Python with tuples? Yes Your function is "conceptually" equivalent to: def add_an_element_to_a_tuple(e, t): return tuple(t) + (e,) (but yours is probably slower). I agree that one can directly construct a *new* tuple with whatever sequence of elements one wishes, but that’s hardly news. It doesn’t (imo) illustrate anything about "fundamental theoretical concepts". &gt;&gt; there are immutable tuple implementations with an append() that do modify in place &gt; Actually this is true. For example, a persistent data structure. From Wikipedia: “persistent data structures… are effectively immutable, as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure.” Better update that description, I suppose.
IPython doesn't do fuzzy tab completion, as far as I am aware: In [1]: foo = open('/proc/cpuinfo') In [2]: foo.red &lt;tab&gt; &lt;tab&gt; &lt;tab&gt; # Nothing In [2]: foo.rea &lt;tab&gt; foo.read foo.readinto foo.readline foo.readlines This is the latest on pypi: $ ipython --version 2.3.0
Oh, didn't know what fuzzy tab completion is. Thanks.
Walkthrough with pictures: https://confluence.atlassian.com/display/BITBUCKET/Fork+a+Repo,+Compare+Code,+and+Create+a+Pull+Request Steps 2 &amp; 3 are windows specific, but you can do the same in linux command line (hg clone &lt;your repo&gt;;hg commit -m "commit msg"; hg push)
i will help
Disclaimer: I find this site is pretty useful, concept is good and it has some interesting tasks Only one example - this solution is top rated for finding most frequent elements http://www.codewars.com/kata/most-frequent-elements/solutions/python def find_most_frequent(l): return set(x for x in set(l) if l.count(x) == max([l.count(y) for y in l])) This is literally one of the worst things I've ever seen 
Not a fan of the crazy method chaining.
Here is another alternative of the same nature. http://maebert.github.io/jrnl/
Thank you so much for taking the time to do this! Any chance we can get yhat ggplot added? If not, no worries already a good set of available packages. Definitely deserves more attention. 
Tossing in a gmail user/pass is an terrible idea. Somebody with half a brain cell will hijack the email. I'd use Gorillamails' API for anonymous email if you want to email yourself info in your program. 
I volunteer to translate it to C#
&gt; The PyPy GC works by allocating new objects in the young object area (the nursery), simply by incrementing a pointer. After each minor collection, the nursery has to be cleaned up. For simplicity, the GC used to do it by zeroing the whole nursery. Why was it originally done by zeroing the nursery instead of just resetting the pointer? Since it's all under GC control there should be very little fear of reusing garbage no? Was it to have a way to debug the GC?
Excellent!
Do you have a Klingon edition because if you don't pm me.
That would basically be a brand new book, but I'd say go for it if you have the time. I didn't really know much about writing before I wrote these books, but have learned a lot. A "Invent with C#" book would be nice. (I had been thinking about doing, at various times, "Invent with Java", "Invent with Dart", "Invent with Minecraft Mods" books.) By tips: * I attribute my success to having a Creative Commons license and making the book free to download. Otherwise, it would have been gathering cobwebs on Amazon with no one knowing or talking about it. * I think people really like seeing the complete source code to complete (but small) programs. Way better than snippets. Keep the initial programs under 50 lines of code, and all of them under 250 lines. This will force you to simplify. * Have the code carved in stone before writing the chapters on them. If you have to change even a line of code, you waste effort when you have to rewrite parts of the chapter. Have someone review your code. * Have someone else edit your writing after you've gone through a couple rounds of editing yourself. (I would edit the book on screen, then print it out and edit it again with red pen. Something about reading it on paper helps me get a fresh look at it.) Here's a good copyediting tutorial blog: http://editinghacks.wordpress.com/copyediting-tutorials/ * The shorter the book the better. For the translations, I'm cutting out five of the later, super-long chapters at the end for the translation, saving the translators 100 pages of work before publishing translated hard copies. (Unless they want to take it on as well.) A huge tome is intimidating, and a sign you haven't been making enough hard decisions about what is actually valuable and what to cut. * I'd be happy to help: al@inventwithpython.com
Great to see the improvements are still coming strong :).
Looks great. How does it compare to Sikuli (http://www.sikuli.org/) - GUI aside?
You should never use PyCrypto for new applications; it provides crypto primitives, not a full cryptosystem. Much better to use [PyNaCl](https://pynacl.rtfd.org/) or [Cryptography](https://cryptography.io/) which provide a sensible API for secure handling of key material, padding, etc. The only reason to use PyCrypto is if you're writing code that has to be compatible with an existing cryptosystem.
:D
That sounds reasonable. That's `pip install ggplot` right? Want to submit a [PR against this line](https://github.com/jupyter/tmpnb/blob/master/images/demo/Dockerfile#L14)?
Mail sent :)
Specify the relative folder in `FOLDER`. Warning, this will overwrite existing images already in the integer range (you can add some overwrite protection stuff). import os import glob FOLDER = './' path = os.path.join(FOLDER, '*.jpg') for ii, file in enumerate(glob.glob(path)): os.rename(file, os.path.join(FOLDER, str(ii+1) + '.jpg'))
Thanks for the tips. However, I meant my comment as a joke, playing on 'languages'. I guess that kind of joke doesn't work that well in text form.
In addition to /u/Fitzoh answer Clojure has easy access to everything in Java
In addition to /u/Fitzoh answer Clojure has easy access to everything in Java
What does 'ii' represent here? I've never seen this before.
There is already https://www.reddit.com/r/progether but it's not super active.
It doesn't suck that much, I am disappointed. A few remarks. I am not sure the "else: pass" statement lines 27-28 is necessary. You should put parenthesis to all your print statements: print("some text"), so that it will work with Python 2 and Python 3. And when you are inside parenthesis you don't need the '\' to break lines, for instance the one at line 66 is unnecessary.
`ii` is the [enumeration](https://docs.python.org/2.3/whatsnew/section-enumerate.html) variable. It represents the numbered sequence that the files are going to be renamed as. 
A linter (for PEP8 and more) would tell you that the variable scan on line 16 is assigned to but unused, that the check for None should be "is None", not "== None" (line 53), and will suggest over a dozen whitespace / indentation / readability things. If you find that useful, use one.
'wurst' joke ... urs
[I don't get it](http://i.imgur.com/M9Gm7G7.jpg)
did someone showed interest for "Bangla(BN)" translation? i am seeing a folder created for BN on Github repo.
You have no docstrings in functions. This is fine as long as you don't mind it so, while you're the only one looking at that code. But you're already past that point, you're already sharing the source. More than that - you want others to read it. Don't skip writing docstrings, don't develop this bad habit, it will be hard to break.
I tried submitting this to /r/learnpython but got no responses. I hope people here are more interested. Please let me know of any suggestions or improvements.
the problem with reusing the garbage is that you need to zero GC pointers as you allocate a new object, otherwise your GC can find garbage and crash. Since this can be done in quite a few places (e.g. the JIT), it required the removal of the assumption that fields are zeroed a bit all over the place, hence quite a bit of work.
Thanks for letting me know, I was not aware a similar subreddit already existed.
&gt; Better update that description, I suppose. *sigh* Trust me, I know what persistent structures are. I have used my own implementations, in fact. Many times. See that word "effectively"? You could have just kept reading the article and found out why it is there, but no, you're just trying to win an argument. Let me explain: Persistent structures are EFFECTIVELY immutable, from the point of view of the user. But they are MUTABLE under the hood. Here is one way for it to work. A persistent list can be one of two things. Either it is a pointer to a MUTABLE list, or it is a pointer to another persistent list. If it is a pointer to another persistent list, then it also has the information "How am I different from that one?" If you use a persistent list that is pointing to a real list, it just behaves like that list. If instead you use a persistent list that is NOT pointing to a list, this happens: The persistent lists are making a linked list that eventually points to one that points to a REAL list. So, that real, mutable list gets propagated backwards through the linked list, flipping the direction of every link it passes through, and getting modified at every step, until the node you tried to access has it under control and the way it wants it to be. Then, it just behaves like that list for a while. This means that each persistent list ACTS LIKE it has always been, and always will be just that one configuration of the list. That is, effectively immutable. But in truth, it is constantly changing state between what it points to, in which direction and with what additional information, *whether you use them directly or not*. One way this helps: It means you can generate the immutable list that represents "add this element to this immutable list" in *constant time*, whereas `t+(1,)` is O(len(t)). They are thus *clearly different in implementation*, but are still implementations of the *same conceptual operation*, which is why it is important to understand the difference between the two!
Seriously. There is a get_pi function. I kept thinking about the number 3.14... Also, optparse kinda sucks. Docopt is soooo much better.
Oops, found this immediately after I posted: it's also [here](http://legacy.python.org/dev/peps/pep-0472/).
aah! This makes a lot of sense. Thank you! Also, I managed to write the program using a slightly different approach - I'll post what I wrote above. editing: spelling
Yes. I'm creating folders as people contact me offering to translate. But I'm looking for translators for any language.
https://aws.amazon.com/public-data-sets/ https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public
http://www.data.gov/
Doing something similar currently using pyhook
I see. Thanks.
we're trying! our subscriber count is actually jumping up . . . but yeah, not totally active.
i just remembered stack exchange has data. http://data.stackexchange.com/
https://www.google.com/publicdata/directory
Cool stuff, OP. I had a very similar project called [PyRobot](https://github.com/chriskiehl/pyrobot) awhile ago, but never got around to getting the OS coverage that you have. Truth be told, I got super-duper frustrated working with the Quartz stuff on OSX. It never seemed to work right on my virtualized system, so I kind of lost interest after awhile. If I may be so bold, I'd suggest adding the ability to read/write from the clipboard. Usually, when I've needed to dip into this brute force style program automation, it's because the target program provides no API or sane means of communicating with it. Thus, to get around the limitation, the clipboard can be used as a pipe between Python and the target program. I used it as a fallback technique a lot when I worked in a video shop and had to shovel data into and out of Adobe Premiere from Python. Anywho, great work! 
Haha, not a bad idea. I'm also the author of Pyperclip, which is a cross-platform clipboard module for Python. I could add it to PyAutoGUI as well. :) https://pypi.python.org/pypi/pyperclip
&gt; Trust me, I know what persistent structures are. I have used my own implementations, in fact. Many times. Ok, I believe you. &gt; but no, you're just trying to win an argument. There is no argument. This started because I claimed Python concatenates tuples, and you got confused and disagreed (but then stated exactly the same thing). &gt; But they are MUTABLE under the hood. One last nitpick, and correct me if I'm wrong, but that's not a necessary condition for a "persistent data structure". Look, you are trying to argue points that were never in contention.
Definitely file a bug upstream. Until the bug is fixed you could also monkeypatch the offending code in the library. I usually find this to be less of a hassle than vendoring a whole library.
Hahaha, ok, let's back up. You see, this comment &gt; "Adding an element to the end of a tuple" doesn't happen in Python (just to be clear). doesn't sound like you're critiquing his language; it sounds like you're just confused about what is being said, and are arguing against the ideas rather than the wording. This comment: &gt; Just that in the context of what you were replying to, the wording of your statement could be confusing. changes my opinion of that. So I apologize for that! However, this &gt;&gt;&gt; there are immutable tuple implementations with an append() that do modify in place &gt;&gt; Actually this is true. For example, a persistent data structure. &gt; From Wikipedia: “persistent data structures… are effectively immutable, as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure.” &gt; Better update that description, I suppose. I really can't see this as anything other than you saying, "No, persistent data structures are not an example of 'immutable list representations with an append() that do modify in place'." You have suggested that what I have said does not match the definition, which is simply false. This is *definitely* a point under contention. While indeed immutable structures are trivially persistent, if there weren't persistent structures that weren't immutable, then there would be no point in having the word. So, yes, they are. And moreover the ones in the OP link are. One last point that yet again *is* under contention is &gt;&gt; Can you do it in Python with tuples? Yes &gt; Your function is "conceptually" equivalent to: &gt; def add_an_element_to_a_tuple(e, t): return tuple(t) + (e,) &gt; (but yours is probably slower). *Definitely* slower! (Though I guess technically, that could be changed if you made a silly Python implementation with really expensive tuple construction). But anyway, they're *not* conceptually the same. One involves creating a new one element tuple; the other does not. They have the same final result: *of course*, because they are implementing the same operation. But, they are not conceptually the same in implementation. It was meant to be a trivial example of this, with the persistent approach being a much more significant example. It just !*sounded*! like you were dismissing the possibility of adding an element to a tuple without leveraging tuple concatentation out of hand, which equivalently sounded like implicitly arguing that persistent structures can't exist/aren't useful.
looks great for making simple bots to play games
Very cool! But a shame that it is on Python 2 instead of Python 3 ; - ;.
Yes, one day I'd like to write a tutorial like [How to Build a Python Bot That Can Play Web Games](http://code.tutsplus.com/tutorials/how-to-build-a-python-bot-that-can-play-web-games--active-11117) using it.
/r/datasets
This is amazing! I am just in love with the way you used Polymer. Huge props for me! As a side note - Has anyone found a way to shut off certain devices, or put them to sleep, through something like this? For example - we have two Rokus in the house. It would be great if we could shut them off when we are gone to conserve some power.
You could achieve turning anything off when you are out of the house by using remote switches, ie Wemo Switch. Wemo switches are supported by Home Assistant. If you also use the Home Assistant presence detection you can write a custom component easily to set it up to turn off all WeMo switches when there is no one home. It will take a lot of years till you hit break even with the cost of WeMo switches compared to the money you will save on electricity..
Woohoo, my donations at work :) I donate $5 from every paycheck -- it's not a lot, but I really want to see PyPy succeed in places where the standard implementation falls short. Everyone wins with each improvement.
The author of this tutorial is in this thread, its /u/audionautics ! Indeed, he's tutorial is very fun!
Oh, man! I wrote that! Almost forgot about that thing... That's some super embarrassing code! I think I wrote that after I'd been programming for all of a few months. Look at dem `if` branches \*shudder\* Maybe I should do a follow up where I walk through refactoring that awfulness. 
It depends on the calculations. If you have some type of calculations which can ran parallel such as MapReduce then I will also recommend IPython parallel. To set it up and to get started is really easy and you don't have to understand exactly what's happening behind the scene. 
Your tutorial on Sushi Go Round was one (maybe the) best tutorial I read, it was a great inspiration! Very fun ; ). I tried your PyRobot, but it gives me an error on Windows/Python3: from pyrobot import * Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "C:\Dev\Python34\lib\site-packages\pyrobot\__init__.py", line 3, in &lt;module&gt; from .browser import RoboBrowser File "C:\Dev\Python34\lib\site-packages\pyrobot\browser.py", line 12, in &lt;module&gt; from .forms.form import Form ImportError: No module named 'pyrobot.forms' Pillow + PyAutoGUI worked fine though, so I'll be using it for automating things through Python3 (I could not install Pillow + PyAutoGUI on PyPy3 though : ( )
It was a fantastic tutorial! I adapted your code when I went through it, but it was very cool. You should be proud instead of ashamed ; )
I'd stick with OP's PyAutoGui ;) Can't beat those cross platform features. I could be wrong, but I think you have a name collision with the PyRobots. I think Python's trying to import this guy: https://github.com/jmcarp/pyrobot My version of PyRobot (Should have done more name research!) was just a flat file. So no `forms` to import. Edit: Also, Thanks for the kind words, man! I'm glad you liked the tutorial! 
I've actually found that using celery and a local task broker makes multiprocessing really easy. It automatically utilized all available processes. 
You're right, it was a collision. I'm used to pip install, I did not saw it was just a single file. Oops. Works fine now, heh.
Thanks for the response! I have looking at WeMo switches. Hopefully they will drop in price soon enough. They are great in theory, but just slightly too expensive for my tastes - unfortunately.
Hahaha, yeah, but the tutorial itself was awesome. I've always wanted to write a similar one.
That's a great heads-up chub79 thanks!
I think this will be helpful to you: http://snap.stanford.edu/data/
Try www.data.gov
So it's parallel testing. I was hoping for some sweet optimization or something. Still though, I'll check it out.
Are you asking for help? Posting this because you think others will be interested? What's going on here?
[thanks for your productive comment!](http://i.imgur.com/sy9lVl4.jpg)
Yeah I'm pretty sure you're taking the piss there but in any case, use requests instead of urllib and use beautifulsoup instead if regexs. 
Yeah- I don't get what you're asking for either. 
I tried using `pytest-xdist` and my tests hung. Thinking it might be due the [`testing.postgresql`](https://pypi.python.org/pypi/testing.postgresql/1.0.2) library i'm using.
I use the [ystockquote](https://pypi.python.org/pypi/ystockquote) module (for easily accessing Yahoo Finance stock data) to test crazy stock-market strategies. My code gets slow real fast when I start testing large numbers of randomly generated stock portfolios against years of historical data. 
It all depends. If you are mostly io-bound, waiting for a network socket or a database, the the GIL is of no consequence. If you don't like dealing with threads, twisted or similar async approaches makes your program pretty. If you have a cpu bottleneck or you're using a c-library that crashes if used with threads, then use multiprocessing. (yeah imagemagick I'm looking at you!) You might even like better to use zmq and just spawn a bunch of workers in your start script.
&gt; and are arguing against the ideas rather than the wording. I actually was arguing against the idea in that post. &gt; I really can't see this as anything other than you saying, "No, persistent data structures are not an example of 'immutable list representations with an append() that do modify in place'." Or that the description could be clarified, since it’s use of "in-place" was at odds with yours. &gt; But anyway, they're not conceptually the same. We disagree on this point. &gt; which equivalently sounded like implicitly arguing that persistent structures can't exist/aren't useful. That’s your imagination. Like you, I use persistent data structures all the time, and find them very useful. Python tuples are immutable structures, and as you stated are therefore a persistent data structure. And I wouldn't argue that they can't exist and aren't useful.
Instead of click take a look at the sublime docopt!
we're happy with every $5 :-) I would be more than happy to just live from donations and work on pypy full time, unfortunately this is not quite possible just yet :/
cheers, left you a bunch of comments as if I was reviewing your code for a commit on my projects.
Wow, the formatting is messed up here. I'm bored, though, so I'll do your homework. Consider the following: shift = None while shift is None: raw_shift = input("please enter a shift") try: shift = int(raw_shift) except ValueError: print("really? Try entering a number") shift %= 26 ... for ch in message: if ch.isalpha(): &lt;your code here works fine&gt; else: cipher_message += ch #you forgot this part [edit] also, you might want to think a bit harder about how this program will deal with capital letters.
def caesar(msg, amt): shifted = '' for c in msg: if not c.isalpha(): shifted += c else: n = ord(c) + amt if (c.isupper() and n &gt; ord('Z')) or \ (c.islower() and n &gt; ord('z')): n -= 26 shifted += chr(n) return shifted message = str(input('Please enter a message: ')) req = '' while not (req.isdigit() and 0 &lt;= int(req) &lt;= 25): req = str(input('Please enter an integer from 1-25: ')) amount = int(req) output = caesar(message, amount) print(output)
Looks great, I'd definitely consider using this. I'd like to see a couple of things (which may or may not have already been implemented...): Firstly, if you don't have fixed seating you might still want to minimise the amount that everyone has to move (for a sports tournament where pitches can be hundreds of metres away from each other). Secondly, in some high-scoring sports you want to cap the maximum points difference between two teams, otherwise teams who are lucky enough to play a particularly bad team end up with an inflated score compared to those who play just as well but didn't play that single bad team. May fork this myself as neither if those things would be too tricky, I don't think. 
Yeah you're going to have a bad time using regexes to parse html. As others have said. Use requests and beautifulsoup.
I'd suggest `"ssh {}@{}".format(username, pi_ip)` which has been allowed since python 2.7. It makes it easier to reformat strings if you need to change them. Nothing sucks like having to add an additional expansion before `{0}` and having to renumber them all.
I've provided the link in the original post. The little blue "talk"? Anyway, it's http://www.infoq.com/presentations/dynamic-static-typing/. 
God I'd love tests that only take a couple of seconds. My day job is developing for OpenStack, where out unit tests take a 20secs to minutes (per environment, py26, py27, pep8, sometimes more), functional tests are coming, and integration tests take hours and hours. The slow unit tests could be sped up with some optimization I think(already parallel by default), and breaking integration testing into integration and functional will certainly speed up the gate, but we're still looking at 10s of minutes :(
Worlds are colliding here.
Even better, `"ssh {user}@{host}".format(user=username, host=pi_ip)` so you don't need to worry about the order of the arguments.
As most credentials will be passed over SSL, you would have to put yourself in the browser process in order to get at the plain text data sent to the remote host. Probably easier to hook the keyboard and only record when the GUI active window is a browser instance. If you can enumerate the browser instance's URL you could refine collection time even further. 
You probably meant something like this: #!bash trap "kill 0" EXIT python -m mystuff Note that each line is indented by at least four spaces. you can also stick code inline with bacticks: `like = "this"` == \`like = "this"\` Also backslashes can be used to escape markdown formatting characters: \#tada == \\#tada
you could probably use something like this http://www.adafruit.com/product/268 Its a power cord for a 120v source (standard house plug assuming you are in USA) with a built in relay to switch it on and off. The RPi has a 3.3V output on the GPIO. The above power cord seems to suggest it needs ~3mA to switch the relay. That should be well within the range of the RPi GPIO. so in python you would do something like import RPi.GPIO as GPIO GPIO.setmode(GPIO.BCM) switchpin = 23 GPIO.setup(switchpin, GPIO.OUT) Then to turn the relay on or off you just toggle the status of the output \#turn on relay: GPIO.output(switchpin, TRUE) \#turn off relay: GPIO.output(switchpin, FALSE) Even more importantly " New! The Power Switch Tail II now is opto-isolated so you don't need a transistor or protection diode. The input acts like an LED so its safe for use with any microcontroller or logic pin." This seems like your best bet - even though its ~$30 If you're using an arduino to do the controlling you'd write the code in C, however, the basic flow of the program is the same though. Import the library for the GPIO bus, define an output pin, (make sure your output pin is physically connected to the relay), then toggle the status of the pin (ON or OFF) to switch your relay and thus in turn switch the 120V mains power; maybe theres a way to use python with the arduino. I never bothered to look becasue I gave up on the arduino once I bought an RPi. I found using the RPi as a micro-controller to be very intuitive especially since it natively supports python. 
I did come across this but haven't had a chance to research it in depth, yet. Would there be a way to put together a small, wireless module to plug into this thing? How do you control this if it plugs into the wall and the Pi isn't close to it?!
Doing it wirelessly would be quite complex and over my head. I know there are other modules that allow remote control switching of power (via a physical remote) and I saw someone post that you could open up the remote and wire your GPIO to the remote's circuit board to trigger the remote and in turn switch the power. However again thats over my head and unless you are really good at analyzing circuits it'd be a tough project as you'd need to figure out precisely how to splice into the remotes circuit board with your GPIO pins. As long as you make the cables long enough the RPi doesn't need to be right next to the power module. Also Since the power module is formatted for a normal 3prong plug, you could attach it to a very long extension cord on both sides. So you have a long extension cord coming out of the wall socket that terminates in the power module with built in relay. The RPI connects to the relay then another long extension cord comes from the other side of the power module with relay and runs off to power whatever it is you need to be switching the power for.
To second this It isn't telling you a lot about the functionality of your code but it really helps you get in the habit of making your code just a tab more readable / formatted correctly. I started using one built into the text editor I use (Sublime Text) I find it quite helpful. That way if I breakdown and have to ask a friend for help on a part of my code I can make sure its decently formatted first so its easy for him/her to read. Finally, as was mentioned in another reply, there are no comments or docstrings in this code. While this is fine if you are the only one who will ever use the code - it helps to put them in there any way just so you can get in the habit of always writing them. Especially if you are asking for help and posting your code online docstrings are good to include just to clarify your functions
How do I run it through a browser?
&gt; our unit tests take a 20secs to minutes I'm sorry sir, but those aren't unit tests. 
I think you could use OpenOffice/LibreOffice API http://api.libreoffice.org/ . You can use to connect to each document, export data to other document and generate the PDF As an example, I use this to connect to an excel document, select a range, and get a value evaluating a function over the range: file_name = sys.argv[1] file_url = uno.systemPathToFileUrl(os.path.abspath(file_name)) url = "uno:socket,host=localhost,port=2002;urp;StarOffice.ComponentContext" ctxLocal = uno.getComponentContext() smgrLocal = ctxLocal.ServiceManager resolver = smgrLocal.createInstanceWithContext("com.sun.star.bridge.UnoUrlResolver", ctxLocal) ctx = resolver.resolve(url) smgr = ctx.ServiceManager desktop = smgr.createInstanceWithContext("com.sun.star.frame.Desktop", ctx) inProps = PropertyValue("Hidden", 0 , True, 0), doc = desktop.loadComponentFromURL(file_url, "_blank", 0, inProps) if not doc: raise UnoException("can't open!", None) sys.exit(1) sheet = doc.getSheets().getByIndex(0) if not sheet: raise UnoException("no sheet in 0!", None) sys.exit(1) cursor = sheet.createCursor() cursor.gotoEndOfUsedArea(False) rangeaddress = cursor.getRangeAddress() last_row = rangeaddress.EndRow column = "H" cell_range = sheet.getCellRangeByName("{0}{1}:{2}{3}".format(column, 1, column, last_row + 1)) # selects range sum_enum = 2 #~ https://www.openoffice.org/api/docs/common/ref/com/sun/star/sheet/GeneralFunction.html#SUM val = cell_range.computeFunction(sum_enum) print("filename: {0}, val: {1}".format(file_name, abs(int(val)))) sys.exit(0) 
buzzwords that killed the company
That is the exact problem! I was just googling and saw this library and thought it might be able to help me. Do you know if it can add page numbers to the files once they are concatenated?
Not coming from .net or js RX background I really need a python specific tutorial or multiple examples in python for this.
Thanks a lot, I am going to look into getting one.
Got it, comments and docstrings will be a must from now on. Thank you.
awesome thanks a lot I will remember this for next time
thanks for adding that
lol sorry to disappoint you. From now on, I will include parenthesis to all my print statements for sure. I really appreciate that feedback.
Thanks, I will be sure to include docstrings with my functions... Especially for situations like this.
Nice im going to check Docopt out
Awesome thanks a lot, I am going to head over and check it out right now.
Thanks a lot man, I really appreciate you taking the time to do that... I am sure its going to help me quite a bit, I'm going to check it out right now.
I think the idea of a peer-reviewed academic publication that can include the actual, runnable code used in the research paper is a huge step forward. IPython Notebook may not be the ideal format, but just the idea of submitting the code as part of the paper, and documenting it inline no less, is an incredibly useful concept. Hopefully someone will take it and run with it to build a tool more optimized for that.
I first heard about tmpnb from a friend at Strata and then again on /r/python two days ago. They are not just publishing the html like nbviewer or wakari, but instead are publishing the notebook connected to an isolated docker container that is executable directly in the browser without any login! IMHO this a game changer. Anyone can visit the url, execute the code, modify the paramaters, and reproduce the results without any setup required. That means: NO Python install, NO Python module dependencies, NO 2v3 hastle, NO LOGIN, NO Windows vs UNIX. All you need is a link and your environment is ready to inspect the information that is being shared with you. Here we even see the executable notebook embedded on nature.com! So a couple questions. What security concerns do you have making these links public? This will get expensive quickly, what are the thoughts on this? 
As a person who worked in academia, I can guarantee you this is never going to happen, unless journals force you to do so. When this happens, people will probably publish on journals not requiring it. Of course it depends on the discipline, but from what I've seen in my field, the quality and portability of academic code is so poor that publishing it is basically 1) worthless 2) will throw a lot of suspicion on the quality of research 3) nobody's got time to document the code to make it presentable for publication. you spend 3 months doing calculations and 6 months writing the paper, nobody's got time to cleanup the stinky implicit names and convert all variables named xyqsr and qhxdy into more understandable names. In addition, you will have copyright problems. Research code may be under stricter guidelines than papers from the universities, because it could become a product. In the current research-&gt;spinoff climate and with starving universities always looking for potential sources of revenue, I don't see it going down easily.
I just want to point out what is actually happening here and it has little to do with how IPython notebooks are formatted or how they share code. The linked page does not just contain the notebook in HTML, it is completely executable just as it would be on your desktop. That means researchers don't just share their code, but they share their ENVIRONMENT! Reproducibility depends just as much on environment as it does on code.
Very interesting points. Thank you
The more they demand this kind of things, the more a researcher/postdoc will spend most his/her time doing publishing and less doing science and discoveries. In academia you are evaluated by the number of papers you have, meaning that the more fancy publishing you want, the more ph.ds have to be sacrificed to these non-scientific tasks to the advantage of that lone guy who built his visibility on the shoulder of these ph.ds, spending all his time directing a scientific publishing platform, instead of doing science. Academic research has become extremely inefficient. The reason why it is still competitive is that its main workforce is cheap, gullible and easy to obtain.
http://elinux.org/RPi_Low-level_peripherals#General_Purpose_Input.2FOutput_.28GPIO.29 That gives a good description of the GPIO interface. You can look up plenty examples of how to access it via python; my code in the earlier post should be a good start as well Note, you may have to run your python code as root user to access the GPIO on the RPi. so if you have your code to ustilise the GPIO to fip your relay as 'GPIO_Relay_Interface.py' you would then need to run it as 'sudo python GPIO_Relay_Interface.py' and then enter the password. I think any code using the GPIO needs root access on the RPi
Ahh, those both make more sense, but would require significant changes to how this currently seats players/handles points. Right now players with the most points are paired starting at the top most table.
They're publishing docker containers, so you can download it and let it run wherever you want.
&gt;it just feels a little black box-y to me If you really want to inspect the environment just throw the following into the first cell. import platform import pip print(platform.platform()) modules = pip.get_installed_distributions() for m in modules: print(m)
On a [cursory search](http://playground.arduino.cc/CommonTopics/PyMite), it appears that it will be possible to use python to control / pass data back and forth between the Arduino. Maybe my little project isn't quite as impossible as I have been starting to think! On a little side note, the non-python languages seem very in depth and intimidating!
How slow are you talking about? 
I find that is getting too verbose. You've repeated each named element three times now. Named parameters can be good for larger strings, but if it all fits on one line, a simple order-based substitution is just as readable, if not more so.
As someone who writes open source code for a living, it terrifies me that it is acceptable in science to base results/papers on code that one doesn't trust enough to let others see. If you can't write readable/maintainable code, you shouldn't trust that code. If your code would throw suspicion on the quality of your research, then maybe your research should be of better quality?!
&gt;Anyone can visit the url, execute the code, modify the paramaters, and reproduce the results without any setup required. That means: NO Python install, NO Python module dependencies, NO 2v3 hastle, NO LOGIN, NO Windows vs UNIX. Is that a good thing? Doesn't that turn the paper author into low level tech support for a bunch of totally clueless researchers tinkering with their code? In my experience, the ratio of people interested in the results of an academic computational analysis typically exceeds the number of people capable of performing (and understanding) the analysis by at least an order of magnitude. Imagine that you had to distribute an easy to use (and not necessary to understand) Docker instance of all of your code to all of the managers, department heads, etc... where you work and support that instance in perpetuity. Would that help you or your company be more productive?
We're very grateful to Rackspace for this - it's because of their support that we can run things like this demo, which is now on a cluster of five high-end servers. They also give us free hosting for [nbviewer](http://nbviewer.ipython.org/), which is a simpler challenge, but gets more traffic.
There's no reason that 'sharing your environment' needs to involve a black box. Sure, sharing a pre-built VM image isn't ideal, but you could share something like a Docker file (or in Python packaging land, a `requirements.txt` file). That's a transparent, text based file that will conveniently rebuild your environment elsewhere. I used to have a similar gut feeling - shouldn't reproducing a result involve working through the steps manually and checking them? Isn't it bad to make it too convenient? I changed my mind because of two things: 1. Making it convenient to re-run exactly the same thing in exactly the same way doesn't prevent anyone redoing those steps manually - it actually makes it easier to work out whether a difference is a technical or conceptual problem, because you can modify the vanilla environment from the author one step at a time until the answer changes. Having their environment is a baseline check - if I re-run it exactly the same, I *know* it should produce the same answer. 2. If reproducing a result is inconvenient, nobody will bother to do it anyway. Except for a few high profile papers and controversial fields, hardly anyone has the time to manually follow instructions to reproduce something. If it's as simple as 'click this button, run the notebook, start tweaking it', there's a better chance that someone will take the time to look into it. IPython itself isn't doing anything about storing the environment - we just deal with code, output and annotations. But we're very keen to see people integrating the notebook with tools that do deal with the environment, like [HashDist](https://hashdist.github.io/) and [ActivePapers](http://www.activepapers.org/).
Thanks!
To some extent, I think it's OK to relax the expectations for published code. I hope we never reach a point where we have to format code and name functions according to journal style guidelines in order to get a paper accepted. But the flip side is that we should absolutely expect scientific code to be reasonably clear and understandable. If the code is so horrible that the reasearcher doesn't want to publish it, why do they feel comfortable publishing results that depend on that code? You say 'nobody's got time'. We have the time to do long painstaking experiments, to write papers that will satisfy editors, and to tweak them endlessly to placate reviewers. When it becomes the norm to publish code, I'm absolutely sure people will find time to clean their code up. And I definitely don't consider that time wasted.
It makes a lot of problems that currently slow down research collaboration go away. Right from simple things of explaining how to plot some results to a grad student to presenting details on how one arrives at the results. It is going to be an initial pain for cases where someone takes the data, massages them manually, runs some models, and arrives at results. But, within reason, these requirements will do so much more good than the inconvenience or lost time. The worry about "fancy presentation" is almost as on par with the worry about "I need to write it in a Journal format" -- you pick up the recommended template and fill in the details.
&gt; As a person who worked in academia, I can guarantee you this is never going to happen, unless journals force you to do so. When this happens, people will probably publish on journals not requiring it. I disagree. The current state of scientific development is clearly based on coding in many fields of research. Journals and publications used to be the way to disseminate knowledge before computer programs and they have remained the main way to do so mainly because the administration surrounding academia is incredibly conservative to adapt to technology changes. With the coming of Internet and social coding platforms like github, it's clear that we now have vastly superior ways to check and update codes. It's a very natural evolution of research to move towards those social coding platform to review our research products and change our focus from journal articles to web models, live plotting, runnable notebooks. Journals are trying to catch up with the new trends, buts let's be realistic. They are a dying breed. They have become useless in the scientific process and are mostly parasites that need to be getting ride of. If you want to be a real modern scientist, put all your research product file: report with associated make files, source code and datasets on github, and publish a version of it on Zenodo and get a DOI. Then contact your reviewers directly and ask them to use the issue tracking system of github to review your files. When the reviewers are satisfied, release a new GitHub version and publish the new version on zenodo. Over time new uninvited reviewers will raise issues, and your article will see different updates. No need to have journals anymore.
&gt; Is that a good thing? Yes. Although knowing about basic dev ops is an important skill (and I would argue these are basic dev ops skills), it is a barrier of entry that holds back wider programming adoption into new fields (not just the sciences). &gt; Doesn't that turn the paper author into low level tech support for a bunch of totally clueless researchers tinkering with their code? For the first dozen researchers that that clone the github repo and try to host themselves... probably. However I would expect a set of best practices and more stream-lined services to pop up pretty quickly if it does prove to be successful. There are more and more providers offering Docker support and it is nice to see Rackspace sponsoring this early on. I also agree that managing Docker instances within the enterprise will be challenging at first, especially within quasi-tech teams (analytics, research, BI, etc.) However I would argue that Docker offers these teams the most benefit as they already use a wide array of tools but generally don't have the experience to manage all of them as they are shared between environments. Docker puts the responsibility of configuration on the creator not the user, who you admit are often times not as skilled to begin with.
pdftk will be easiest way.
I maintain a list of a wide range of freely available geographic data - see http://www.freegisdata.rtwilson.com. The data is in a range of formats, but pretty-much all of them should be readable in Python using various external modules.
You may try generate pdf with ReportLab: http://stackoverflow.com/questions/16041397/python-reportlab-clickable-toc-with-x-of-y-page-numbering
When I ask someone, "Do you understand complex numbers?" and they answer "I use real numbers all the time!", I heavily suspect that they do not in fact understand complex numbers and furthermore don't actually see the use for them. When you say you use and understand persistent structures, but you only mean the immutable ones, that comes across in exactly the same way.
IPython to be named [Jupyter](http://jupyter.org/) which means you can use: EDITED takluyver's [list](https://github.com/ipython/ipython/wiki/IPython-kernels-for-other-languages) * IJulia * IHaskell * IFSharp * IRuby * IGo * IScala * IMathics * IAldor * Calico Project * Lua Kernel * Simple example kernel * IRKernel (for the R language) * IErlang * IOCaml * IForth * IPerl * IOctave * IScilab * ICSharp * Bash * Clojure Kernel I know that IPython is being renamed after IPython 3.0 but I can't wait for this to happen ASAP.
&gt; Is that a good thing? Doesn't that turn the paper author into low level tech support for a bunch of totally clueless researchers tinkering with their code? Considering that most code is actually quite buggy, this probably is a good thing. I would imagine that any code ending up in the publics' hand will be much higher quality than whatever is currently being used to generate less transparent papers. &gt; Would that help you or your company be more productive? When you consider the amount of scientific work that is done based on faulty premises from results that can't be replicated, I would think that there would be net efficiency gains (to the global system of "science") from more quickly identifying invalid premises. If their counterparts are equally transparent, those gains will eventually accrue to the original researchers.
Not seeing `subset_of` as one of the built-in functions. Which package is it in?
Seems a bit harsh with your wording if that wasn't your intent.. But yeah I agree, I'd go with possibly OAuth2 if you can do that.
What is your field?
And when they answer "Yes. I talking about Real analysis, though.", do you then make the effort to say "Trust me, I know what Complex numbers are. I have used them myself. Many times."?
I wish other projects would give the project I maintain (the Spyder IDE) a little bit more of credit :-) The new numpy array viewer (with colors and all) seems almost a copy (of the interface, of course) of ours: http://pythonhosted.org/spyder/variableexplorer.html PyDev also introduced in one of their last versions a module reloader with the exact same name as ours (UMD or User Module Deleter). Come on guys, referencing your inspiration won't hurt you but it surely will help us to gain more visibility :-) PS: I'm not complaining about possible copies of our code (because we are MIT after all), just about not mentioning us at all...
`set.issubset` is the built-in function
Anyone want to enlighten me as to what this has to do with java? 
&gt; Closure I assume you mean clojure, which in that case, awesome!
This is basically some simple rules of pythonic vs "non-pythonic" use of Python (that too it self-contradicts with the last example). Comparison with Java (or C++) is unfair for two reasons: (a) newer collection libraries/STL versions provide fairly succinct and clear representations, and (b) some of the pythonic code may add a performance overhead that can be a too steep a price. I have done the round-trip of "use vectorized representations in Numpy/Pandas" to "use loops in Numba/pypy" for performance improvements. The lesson I learned is to not take as gospel thumb anything (much less something based on a few toy examples). In this case, the succinct representations and clear code mostly highlight style (readability, etc.) and can sometimes lead to a sense of false confidence and lead to an overdose of "pythonic"[TM] (which is almost opposite of pythonic). The last example shows how easy it is to fall into this trap -- I would rather use the "bad" representation with a lambda in there. The explicit hash.get approach is difficult to read, and way too clever for its own good. The parallel I can think of is reading Strunk and White on how to write (rather, how not to write). The style part is just an icing on the cake -- and will be silly if the underlying foundations are not strong. Many people write wonderful prose without ever having clever constructs. I've seen great code in many languages, so "smells like" is a bad phrase to use. I've seen clever code like the last example quickly degenerate into 40 line statement that smells like badly written lisp.
I've been looking for something like this. +1
I agree with you that the last example is not good.
&gt; # Bad print 'Hello ', name, '. You are ', age, ' years old' # Good. Reflects the structure of the intended output print 'Hello {name}. You are {age} years old'.format(name=name, age=age) What's wrong with the first? If it had 5 arguments, it's a little hard to read, but that one has 2. Also why not use %s? It's faster than using format. # Bad if case_sensitivity.lower() == 'sensitive': matcher = fnmatch.fnmatchcase elif case_sensitivity.lower() == 'insensitive': def matcher(fname, pattern): return fnmatch.fnmatchcase(fname.lower(), pattern.lower()) else: matcher = fnmatch.fnmatch # Good. The match code can be moved to a different file matchers = { 'sensitive': fnmatch.fnmatchcase 'insensitive': lambda fname, pattern: fnmatch.fnmatchcase(fname.lower(), pattern.lower()) }.get(case_sensitivity.lower(), fnmatch.fnmatch) Those are both hideous. Why is it good that the matcher can be moved to a different file and what's preventing the first from being moved? It can be a function.
Why didn't you use that in the example then?
Technically format appears slower due to the method call. When measured on the same level (replace `%` with regular `__mod__` method call) you'll see that format is actually faster. (edit: yes, it's irrelevant, haha)
For your first question, you wouldn't want to use %s if the string needed to be 're-ordered' for some reason. Either because you want to change the string (ie: "Who turned {age} today? {name} did!"), and not have to remember to change the order of the vars. The other common use is for translation to other languages.
 $ python -m timeit -s "name='Fred'" -s "age=23" "print 'Hello {name}. You are {age} years old'.format(name=name, age=age)" 10000 loops, best of 3: 66.8 usec per loop # $ python -m timeit -s "name='Fred'" -s "age=23" "print 'Hello ', name, '. You are ', age, ' years old'" 10000 loops, best of 3: 79.7 usec per loop If you actually tested it you'd find that `format` is faster anyway. It's even faster than`%` in my tests, but not by much. python -m timeit -s "name='Fred'" -s "age=23" "print 'Hello %(name)s. You are %(age)d years old' % {'name':name, 'age':age}" 10000 loops, best of 3: 70.4 usec per loop 
You can use dict keys for percent formatting (not that it's better than `.format`): `"Who turned %(age)d?" % {"age": 22}`
The example was defining subset for lists by converting each list to a set and then using the set's subset method.
Edited it. Thanks
I love Spyder! Whenever people ask about IDEs on here I try to mention it.
I was looking at pdftk today, but I don't think it can add page numbers can it? If it can, this would definitely be the easiest way. It also seems to have a cheap command line tool that I could automate with autohotkey or python!
yeah, I was thinking about that option when looking at another stack overflow post. 
Yeah, I understand you approach but that seems like it would take a lot of work. What sucks is that I already have a program (Acrobat Standard) that is fantastic at making and editing PDFs. I just don't have a way to talk to it... Forgive me, as I have only been programming for 6 months, but is there not some way for me to talk to Acrobat but through Python? Is there not like an Acrobat API or something?
Thank you. When I read through it the first time I didn't notice that `subset_of` was being defined. Since the counter example wasn't defining a function it threw me off.
`explicit is better than implicit`; if you want the interpolation to be based off the `locals()`, then that's exactly what you do - `.format(**locals())`. This is still considered a bit of a hack, though. But I mean, do you really need the local names in the first place? print("Person {name} is {age}".format(name='John', age=42)) is already perfectly explicit.
Hahaha, I'm sorry, I'm sorry, I don't know about you but I'm having fun here. Let's take the analogy all the way. Here's the conversation as I see it: &gt;&gt;"blah blah blah ... we square a number and get negative one." &gt; "To be clear, floats don't square to negative one." "But numbers do, for example complex numbers." &gt; "*cite definition of complex numbers*. Real numbers are complex numbers. Real numbers don't square to negative one." "Trust me, I know what complex numbers are. And they can square to negative one. Here's how: ..." &gt; "I know and use complex numbers too. Stuff like 1 and 2 and 3." "..." We should be able to agree on the following: 1. Tuples are immutable in Python! 2. You *can* "add an element" to a tuple in Python, but it is a poor choice of words! 3. Structures can be effectively immutable - i.e., their properties and actions don't change - even while the underlying data itself is changing! 4. There is use to such a scheme!
Apparently the keyword is necessary to create controversy/views.
My example is of course contrived for brevity and clarity- more realistic scenarios where you want to do interpolation come up all the time where you don't have such easily substituted constants. I think it's already quite explicit to be referencing the name of the variable which is offset within the string itself. Resolve it as you would any other variable: locals, enclosed, globals, built-ins. I'm not convinced that you should need to call a function on the string that you've created at all, but if so maybe it should just be an `"I am {name}".interpolate()` call that does the obvious thing. And worth noting: the only thing listed above **explicit is better than implicit** in the Zen is **beautiful is better than ugly**... `"Person {name} is {age}".format(name=name, age=age)` is incredibly ugly, it's triply verbose, and it's the main reason I'm still strongly preferring %s for everything, despite its obvious limitations during refactoring.
You're actually mainly benchmarking `print` there. In particular, that makes the second result very wrong. Corrected versions, with my timings: python -m timeit -s "name='Fred'" -s "age=23" "s='Hello {name}. You are {age} years old'.format(name=name, age=age)" 1000000 loops, best of 3: 1.13 usec per loop python -m timeit -s "name='Fred'" -s "age=23" "s='Hello ' + name + '. You are ' + str(age) + ' years old'" 10000000 loops, best of 3: 0.612 usec per loop python -m timeit -s "name='Fred'" -s "age=23" "s='Hello %(name)s. You are %(age)d years old' % {'name':name, 'age':age}"` 1000000 loops, best of 3: 1.52 usec per loop
issubset is NOT a [builtin function](https://docs.python.org/2/library/functions.html) it is a member function of a [set](https://docs.python.org/2/library/stdtypes.html#set.issubset), however.
http://opendata.stackexchange.com is good too.
How are you going to circumvent the bot check captcha that comes up once in a while?
Thanks!
You can, of course, build this sort of thing with `eval`, but... it's `eval`.
&gt; As someone who writes open source code for a living, it terrifies me that it is acceptable in science to base results/papers on code that one doesn't trust enough to let others see. If you can't write readable/maintainable code, you shouldn't trust that code. If your code would throw suspicion on the quality of your research, then maybe your research should be of better quality?! &gt;&gt; Let's be clear, if your publication cannot be relatively easily reproduced. It's of poor scientific quality. I'm saying this in the sense of the scientific process. If it's difficult to reproduce. It is difficult to judge its validity and to build upon that research. Therefore a paper provided with all the research materials used to construct it, including well commented code and datasets will always be of higher scientific value AND quality compared to just a paper. +1. If there's no code and no data, it's neither repeatable nor reproducible; and - in absence of supporting evidence - invalid.
Well, good. Snakes smell terrible.
This looks like a really great tool.
I have a fairly popular one, that works for Win, Linux and OSX: https://github.com/gurgeh/selfspy It encrypts the text and has a wide assortment of methods to search your data. Pull requests are welcome, if it lacks something you need!
&gt; why not use %s? It's faster than using format. Why not use format? It's clearer than using %s.
I was under the impression that IPython will remain as a Python language front end and Jupyter is the name of the language agnostic kernel and protocol definition used to talk to other language front ends? 
I love that tutorial! If you ever do "Part 2: Redux" or something I'd love to read it!
That's what the common lore says. In practice I can guarantee you that while the criteria may be satisfied, it's really open to discussion how much effort is needed to achieve that, meaning they may make a method completely well described mathematically, and you are free to reimplement it if you want to reproduce these results, but the code won't be published. And even if it's published, if you depend on an engine (say, mathematica) that is not free nor open, what's the point anyway? Any code you may write and make public will most likely not run in 5 years' time. bits rot, knowledge doesn't. Referees don't reproduce your evaluation. Referees check if you are on topic with the journal, if you are not saying bollocks and if there's enough material in the article to support your claims. Everything else is left to future generations. 
&gt; I'm absolutely sure people will find time to clean their code up. And I definitely don't consider that time wasted. 7 years banging on this drum with all my supervisors let me think it's a lost battle. 
The limited lambda expression in Python could be a real pain for this coding style.
I mean using pdftk for pdf concatenation. Unfortunately, pdftk itself can't add a page numbers.
Heh, I think that may actually be his strategy -- or he just *reeeaaaalllly* hates Java. 3/4 of the related articles had some form of Java V Python titling. * Why is Python more fun than Java? * Python Is Not Java * Why I prefer Python to Java * Write Beautiful Python Not a bad strategy for drumming up views, honestly. 
If this is the way that we get people to actually show how the computation steps look/work, then I'm all for it. Fucking finally. I HATE when I read a paper that says "and then we used program (x) to get this result" and they're referencing a program that uses beyesian inference and about 50 priors
Same here. Im not writing pythonic, im writing java in python
well, that was a bad experience in just about every way. first, there was no $8 (CAD, presumably) discount when i went to kickstarter 7 hours ago, even though "?ref=reddit" was in the kickstarter url and this page should have been in the http referer header (otherwise not sure how kickstarter would award discounts to "Reddit reader"). i thought i would revisit this later and it might be fixed. nope, it's still not showing a discount (compared to visiting the kickstarter page in another browser without using the reddit referrer url). second, i thought i would buy the book (with the javascript one) anyways and follow up later about the discount as there was only 1 left. by the time i entered all my payment information i was informed it was sold out. so, i hope this post wasn't expecting any upvotes.
funny, I was just thinking of writing a joke Hello World in "Javarific" python. Fully Framework Enabled, and starting with a HelloWorldFactoryFactory :P
Codecademy is a great place to learn the basics, and it has more than just Python. 
PLEASE COPY THE DESCRIPTION OF WHAT THE FUCK YOUR PROJECT IS INTO THE SUBMISSION BECAUSE IT IS RUDE TO ASSUME EVERYONE CARES
A good place to start is bucksysroom.org. I'll assume you can figure out how to navigate to his tutorials from there. He used to be known as the new Boston. Knowing what you know you may want to skip the first 10 or so tutorials as they're very introductory. I'm 17 in high school as was in your boat less than a month ago. Currently writing scripts that speed up my homework :p (take that ib and your stupid uncertainties and sample calculations) 
* it's not my project * every time you post something you assume everybody cares (that's why there are up/down-votes) 
Academia moves very slowly in some ways. Until *2012*, a scientist wanting to formally name a new plant species had to write a description in Latin (since 2012, English is an option). It's not a lost battle, but it's a battle that will take more than 7 years, and more than one person. We need a sea change in the expectations that journals and funding agencies have about scientific software, which will take at least another decade. In many disciplines, we need scientists to be much more code literate, so they're comfortable sharing and reading code. That might take a generation. If you haven't already, [sign this petition](https://www.change.org/p/everyone-in-the-research-community-we-must-accept-that-software-is-fundamental-to-research-or-we-will-lose-our-ability-to-make-groundbreaking-discoveries) about the importance of software in science. And consider volunteering with projects like [Software Carpentry](http://software-carpentry.org/), which teaches researchers practical software skills. I've helped with a few of their workshops; it's good fun.
The frontends, like the notebook interface, are language agnostic, so they will be part of Jupyter. The 'kernel', which is the backend process that runs the user's code, is specific to Python, so it will remain as IPython. There are other kernels for R, Julia, etc. ([here's a list](https://github.com/ipython/ipython/wiki/IPython-kernels-for-other-languages)). So once the renaming happens, Jupyter will be the main name that users see.
There was definitely some confusion about "builting function" vs. something that's just part of the standard library.
[Look at this picture of the latest developer edition of IPython ](https://twitter.com/jessenoller/status/525858089652977664/photo/1) Basically you just click under kernel and you can select Python 2, Python3, Julia or R for your kernel the rest is all the same. So to me IPython the name will be around BUT it really is just Jupyter that will run any of these languages. That is why I am saying we need the switch ASAP before people put iPython = Python first class citizen, WHICH it is not. 
Never tried openHAB. I only found out about it after I started on Home Assistant so never felt compelled to give it a try. If you run into any issues with replicating your setup, reach out to the [dev mailing list](https://groups.google.com/forum/#!forum/home-assistant-dev) and I'll probably be able to help you. Also would love to hear feedback if there is any functionality from openHAB that you are missing.
part 25?! Flask is a microframework! ;)
Is there any difference between: path in ('js', 'css', 'img', 'font', 'fonts') and path in ['js', 'css', 'img', 'font', 'fonts'] ? 
It only converted the first one to a set. The whole point of `issubset` is to avoid converting both to a set. If you prefer converting both to a set you should be using `set(array1) &lt; set(array2)`.
The former is a tuple, the latter is a list. The real solution should be path in {'js', 'css', 'img', 'font', 'fonts'} Since that is a set, checking for existence of a member is going to be more efficient. [Read more about Python data structures here](https://docs.python.org/2/tutorial/datastructures.html)
As another alternative you can try GUI Automation, translate the manual process you do into a recipe like "click here, for each name on the list do this and this..." See in this automation tutorial: https://medium.com/@thechriskiehl/how-i-use-python-for-windows-automation-697d2c968a2f I recommend Pillow + PyAutoGui 
They should be functionally equivalent. One creates a tuple, the other creates a list, but both are iterable. I guess the tuple might use less memory? But that really shouldn't be a concern. I suppose you could argue that the tuple form is more reminiscent of the SQL IN clause, so it might be easier for people to read. 
Thanks, I didn't know you could use curly braces to create a set. In terms of performance, are the tuple and list going to be about the same (worse than a set) in this example? 
With length 5, it won't matter.
Hrm. Time is a tricky thing - it has many interesting little corner cases. More importantly, the use of time representations has many ways in which a programmer can make mistakes. Any time representation then should be very clear about the approach it takes in any of those corner cases. For example, your code offers an "increment" function, but does not say whether the increment occurs in local time or UTC, which is a very important thing to know. Your documentation should also be clear about what equality means. In your case you seem to have decided that two time representations are equal if they have the same underlying UTC, however this design decision (made by a number of other modules as well) tends to be a poor choice - the use of the wrong timezone is a common error in time-related programming and forcing the programmer to be explicit about which tz they're operating in helps prevent this. You accept None as a tz equivalent of UTC. This has similar issues - any number of coding errors can result in None where a real time zone was expected, making the assumption that these errors should return UTC results in difficult to identify bugs in the software that is using the object. Don't overuse @property. It really is something that should be avoided in most cases and can imply things to the programmer using your interface that aren't true - for example that a serialization of the object will contain that property, or that they can set it. None of your uses of @property are good choices in my opinion. Finally, there is little consideration for localisation - you have a couple of formatting functions but they're not well thought through. TL;DR: * Document how you handle corner cases * Document the assumptions your functions make. * Write your interface to assume the programmer will make mistakes * It's nice to see someone with type annotations in docstring. Strong approval. As an aside, having implemented a similar representation for our own use, there are a number of scenarios you might want to consider that we ended up handling: * Dates and different from Datetimes, dramatically so in some cases. They really need their own object and don't necessarily need a timezone at all (that is, you can do date math without a tz so long as you remember that you can't turn the result into a datetime without being explicit about how). * Having your own delta representation is useful. We based ours off relativedelta * Truncating datetimes is a common requirement - we have a method "start_of(self, period, first_day_of_week='monday')" that lets the programmer truncate a datetime to the second, minute, hour, day etc. * Everyone needs strftime in the end * Date parsing and unixtime are important * Shortcuts to get today() and now() are important * Having a mechanism to calculate working days is useful (but it's tricky and not easily generalised) Also, I think you should reconsider the name. Citytime implies that things are related, somehow, to cities. But it isn't. Hope that helps. Update: Also, two other things to cover: 1. When producing a new anything, it is a useful thing to add documentation to the README.md or similar that provides a quick comparison against existing well known solutions. You should compare against standard datetime and against Arrow for example, so that potential users are aware of what you cover and how you differ. 2. Make sure you've read http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time - not all of it is something that can be handled, there is something to be said for "good enough", but you should be aware of it all and preferably document relevant design decisions whereever possible.
Post your code using Gist and try again. 
[pydub](https://github.com/jiaaro/pydub/) will do milliseconds, if that works for you.
I won't go into any language specific things but instead will give you some general programming advice. Comment your code: The function name ***get_pi*** doesn't communicate what it does. I have to read the entire function get an idea what it does. You're an Architect: Design clean, beautiful code. The function ***get_pi*** (as far as I decyphered), scans a given address range and builds a data structure based on the discovered hosts. Split this up in two functions: ***scan_range*** and ***create_pi_info*** (second function name sucks because I don't really know what you're doing, comments!). Why split this function? Now you can't really test your code. To know whether or not your data structure is built correctly you actually need to scan a network range and know what hosts you find. If you use ***create_pi_info*** you can feed it mock input in your tests and ensure it's working as expected. Granted, this is a trivial script but remember: you're a craftsman in training. 
The page numbers are actually added by me in Acrobat. I need them because these are 30 to 50 page decks showing loan pricing related metrics. It sounds stupid, but page numbers are essential so I can tell everyone to go to page 10 or whatever. I think I can actually talk to Acrobat using Python and COM/OLE. I have found some documentation on it from Adobe. Let's hope I can figure it out! 
I use PyPDF2 for slicing &amp; dicing pages out of a "master" PDF document. Works great.
Nice write up... I also wrote about this a bit on my own blog: http://paulsolin.com/2014/06/27/scraping-pdfs-with-python/
A few years ago I built a system that had to inject data into PDF forms, but there wasn't a Python library available to do it, so I ended up using pdftk. It wasn't fun.
&gt; It's not a lost battle, but it's a battle that will take more than 7 years, and more than one person. We need a sea change in the expectations that journals and funding agencies have about scientific software, which will take at least another decade It's refreshing to know that I blew my career in academia by being too innovative, which is what academia is supposed to be. 
There is a /r/learnpython subreddit, it's linked in the sidebar. Direct your questions there.
Previous discussion http://www.reddit.com/r/Python/comments/2lins0/third_pycharm_4_eap_numpy_array_viewer_ipython/
Major props to Fernando Perez.
Okay. Thanks for that. Have a great weekend.
You should be posting in /r/learnpython, not /r/python. Read the sidebar, and you'll see this isn't the place to get help, but that there is one - /r/learnpython.
You should read the sidebar and ask your questions on /r/learnpython. Also, refer to SQLAlchemy's documentation.
I don't think it's mentioned, but there's a Python 3 port of PDFminer, [pdfminer3k](https://pypi.python.org/pypi/pdfminer3k).
I'm sure people over at /r/learnpython would be glad to help you. Please read the sidebar.
Sorry, I'm new to reddit and forgot to check the sidebar as you pointed out. I'll post it there now, thank you very much for letting me know.
Oh god, I thought those were foreign links to similar posts across the net. That's... a lof of ranting about Java.
checkio.org has tons of challenges, and has an online editor/interpreter. You can also publish your solution and look at other peoples solutions. It is also some kind of game, you gain points as you solve tasks and unlock achievements and level up, then you unlock new tasks. Pretty satisfying really. Also try /r/dailyprogrammer, there are tons of challenges there. 
Sorry but the current state of peer review is just not good enough. It's mostly a creaming process where they filter out all the crazies from the most respectable journals. The real peer review takes way too much time compared to what we could do with the tools at hand. We have inherited tools -- the journal concept with editors and reviewers -- from the previous century, where science was analytical and there wasn't Internet. Now that many fields of research are based on source codes and complex datasets, the peer review is not enough to filter out the crap and the aposteriori peer review through citation is way too ineffective. Your argument about proprietary coding is not good enough as well. An author has the responsibility to make his research reproduced by somebody else, not just reproducible. He actually has a responsibility to make sure that his research matters and is used by somebody else. Otherwise he is wasting societal resources, and is not contributing effectively to the scientific progress. I'm sick and tired of self proclaimed geniuses that code crappy closed source code that claim to have "the best model ever" but nobody can understand their theory because they are arguably so much smarter than everybody else. Well if nobody can reproduce your results you are a shitty scientist all the same, it doesn't matter how brilliant you think you are. &gt;Everything else is left to future generations. That's what happen most of the time, but this is not good enough. We live in the dark ages of numerical science. We are an embarrassment for the future generations. 
I don't know that experiment, but if it can't be reasonably reproduced it's merely an observation "point". If there are others "points" available you might be in a position to make hypothesis and build some predictive tools out of them, maybe even using source codes. And then you can join the discussion we are having here :-)
&gt; Sorry but the current state of peer review is just not good enough. It's probably not good enough for science, but it's good enough for editors and reviewers. &gt; It's mostly a creaming process where they filter out all the crazies from the most respectable journals. The real peer review takes way too much time compared to what we could do with the tools at hand. We have inherited tools -- the journal concept with editors and reviewers -- from the previous century, where science was analytical and there wasn't Internet. Now that many fields of research are based on source codes and complex datasets, the peer review is not enough to filter out the crap and the aposteriori peer review through citation is way too ineffective. I made this exact point during a conference in Cambridge UK, when the speaker was a renowned professor in the field of chemistry interoperability. I have almost being laughed at, but the actual non-condescending answer was "no, it's still relevant". &gt; Your argument about proprietary coding is not good enough as well. An author has the responsibility to make his research reproduced by somebody else, not just reproducible. He actually has a responsibility to make sure that his research matters and is used by somebody else. My argument is not what I believe. My argument is how the scientific community actually behaves. We are on the same side. This is one of the reasons why I left academia. It's terribly inefficient, terribly unreliable, terribly "casual", and terribly unreproducible, and when you point out these things, you are considered a weirdo. &gt; Otherwise he is wasting societal resources, and is not contributing effectively to the scientific progress. I'm sick and tired of self proclaimed geniuses that code crappy closed source code that claim to have "the best model ever" but nobody can understand their theory This is not true. The theory is generally well understood and presented. I have come across plenty of papers with a host of formulas. If you try to publish a purely methodological paper, the article will be rejected for lack of actual evaluations of the effectiveness of the method. Ok, so you take out your 30 years code that everybody is using and is written in Fortran 65, choose a system that you believe interesting as a testcase, and start adding your method to the code, adding more mud to old mud. Of course, you add code that solves only that specific system, because doing otherwise would be a waste of time. You hardcode things such as number of electrons, number of atoms, size of the matrices and so on. So now bam, you have your calculations, make some nice plots, and send the paper to the journal where the article is finally approved. The journal is happy, you have another paper, and the code you produced stay in a directory called journal-veryabsolutefinalversion, where it will stay to rot until 10 years later a colleague will want to try it out on his system and you will send him the code, that of course won't compile with his compiler. This is not hypothetical. This is stuff I've seen personally. &gt; because they are arguably so much smarter than everybody else. Well if nobody can reproduce your results you are a shitty scientist all the same, it doesn't matter how brilliant you think you are. Again, reproducibility is not "here is the code". reproducibility means that anyone, armed with enough knowledge of the topic, has all the tools to understand and redo what you did, but it's not a requirement that you make his life easier. Academia is not a bunch of hippies. It's a highly competitive field where things are kept close to the chest in some cases, and released in other cases, depending on convenience, visibility, political needs, copyright restrictions and so on. &gt; That's what happen most of the time, but this is not good enough. We live in the dark ages of numerical science. We are an embarrassment for the future generations. We've been for the last 50 years, and we will be for much longer. The only field where things are going in a better direction, from my experience, is system biology and bioinformatics, but unfortunately they have the strong tendency to use a completely doomed and unreadable technology: perl. 
&gt; Yeah this happens and its a big shame, but let's be honest here. The chances that your knowledge products (code, data) rot are much higher if they stay on your hard disk than if you put them on a social repository like github The problem is that in some cases it's not even possible. Take the example I gave above. The changes were made to a code that is not free, but it's opensource because researchers get their hands on it. There's a kind of "insider opensource" community for these things. So the only thing you could do is to publish a patch, but that is close to useless, because it will not apply to all versions of the software, and it's specific to your problem. &gt; If you do let them rot, that's probably because they were not so interesting in the first place. Sometimes it takes time for a technique to take hold, and sometimes it takes time to find a system for which any other technique is simply not good enough, and someone wants to try yours. &gt; Except they don't necessarily have the tools to reproduce your results. Math is technically the only tool you need. Otherwise you could apply the same point to a computer, or to lab equipment. If I have a fancy new plasma spectrometer and publish data with it, I cannot certainly make sure you also have one so that you can reproduce my data. &gt; when we could actually share those codes. There's no incentive in keeping this interoperability and sharing. This effort costs human labor, and this kind of human labor is considered wasted time and not worth the investment in academia. For this reason, it's generally handed out to a ph.d. or a postdoc, each that will leave in 3 years time and with different hopes for his career. In addition, if you want to make this code usable, readable, etc. then you will find resistance from the scientists, that now they want to add a new thing but "the code is all different, I can't do anything anymore now". Heard this complain many time. &gt; This situation is created by the administration surrounding research, the key performance indicators etc... They should give us incentive to collaborate and share our research products instead of letting them rote on our hard disk. We need a different model for scientific research. Again, I've been banging on this drum for years, but there's no incentive to do so. It must be done at a higher level, or cleaned up and started anew with a different model, but as usual, it's a political problem, and too many people depend on the status quo to stay relevant and in business. 
&gt; Well I don't know which field you work with I used to work in quantum chemistry. Now I am a scientific developer for a quantum physics company. &gt; but in mine you won't be able to reproduce our results if math is the only skill you have. Again, it's not the point. Nobody wants to reproduce your results when it's review time. What they want to know is if it's possible, given the information provided in the paper, to perform the same evaluation. In practice, this is hardly true. I've seen plenty of papers where the initial starting guess for a convengence is never detailed, yet when you actually do try to reproduce the evaluation it's an important point. That, you say, should have been addressed by the reviewers, yet some reviewers may consider it "trivial matter that you should know yourself". &gt; My computations run on cluster for days, weeks. Mine too. What do you work ok? &gt; You won't be able to take a pen and reproduce those results on the back of an envelop even if you had many envelops and a few thousands years at your disposal.. No, and you are not meant to. But _if_ you had the time, computer power and programming skills, you can reimplement the explained method from its mathematical presentation. Again, what I am saying is not what I believe to be true. I am playing devil's advocate in saying what the scientific community thinks and how it operates. &gt; If you think that only math is needed in science you live in the pre-computer age. well, if you want to develop a new method, math is what you technically need. Putting that math into practice, it's another thing. &gt; We need to kill the publish or perish concept and the associated parasites: journals, scientific editing companies. It's a battle I fought and gave up fighting. &gt; That has been solved during the last decade by the open source community. Never heard of the forking/commit/pull request concept introduced by the git system? It's very compatible with scientific updating. I use git daily, but if you hope that a scientist spends time understanding how git works, you are going to be heavily disappointed. I fought for years (and lost) just to promote svn (which has a much simpler conceptual model) instead of renaming files with names like method-20041230, method-20041231, method-20041231-almostworking, method-20041230-new, method-20041230-newnew. Heck, one day they come up that they want to exchange their data, and want to do so in XML, because they are in a project with some supercomputing center. _but_ they want to write wrappers to convert their old I/O into XML. I say: python. Response: "nobody's got time to learn that, please write a library that allows us to read and write XML from fortran 77". So I did. And then I quit. Nobody used it because the project folded on itself. 
Running info: * As a precaution, all our infrastructure has been taken offline. * If you depend on Django, installing from PyPI will still work. * Our PyPI uploads and GitHub release tags are GPG-signed by key ID 0x2d9266a6808fe067 for verification purposes. [An explanation is now up](http://www.reddit.com/r/Python/comments/2lqia3/django_project_website_downtime_explained/).
[**@ubernostrum**](https://twitter.com/ubernostrum): &gt;[2014-11-08 11:41:23 UTC](https://twitter.com/ubernostrum/status/531048837406662657) &gt;We are investigating a claim of unauthorized access to the Django project's servers. More info as we have it. ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2lo402%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
We have restored access to the Django Project servers. At this time, we do not believe any of our infrastructure was compromised. We'll continue to post updates as we have more information.
help("modules ")
Import * brings in everything which means you can get unexpected values, but you can use it safely. I've got a project with multiple status codes so I do from status import *, the variables are all STATUS_COMPLETE, STATUS_PENDING, STATUS_CHOICES = (STATUS_COMPLETE, STATUS_PENDING) etc so it is not polluting the namespace (since the values are constants, there isn't any problem with mutating the values either)
So...you're namespacing by manually doing name mangling instead of just using the language's built-in feature for it?
That is actually entirely untrue! A sqlalchemy Session supports multiple database connections at once and will even coordinate with 2pc if feasible. There are of course complexities and caveats, and quite often using multiple sessions is the best approach. But it is possible (and documented).
You can also do "import status" and then use status.COMPLETE, status.PENDING, etcetera. 
If you need to get tables from PDFs [Tabula](http://tabula.technology/) is great for that. It's java but works great.
It's a pretty straight forward project. Labjack supplies a python module that makes it simple to capture data, timers, counters, etc off the device. That said, I'd like to see what you do with it. 
Don't worry, it's just the NSA checking in some code. I mean to say hello!
&gt; Heck, one day they come up that they want to exchange their data, and want to do so in XML, because they are in a project with some supercomputing center. _but_ they want to write wrappers to convert their old I/O into XML. I say: python. Response: "nobody's got time to learn that, please write a library that allows us to read and write XML from fortran 77". So I did. And then I quit. Nobody used it because the project folded on itself. Ahah! sounds like we have been confronted with similar challenges. I agree with most of what you say except the reproducibility. The scientific process requires reproducibility by independent parties. Until your work has been shown to be reproduced and useful it has a very low scientific value. Our responsibility as scientist is to get our knowledge out there, checked and used. If we actively or passively don't do our best, we are shitty scientists. I haven't given up the fight myself. 10 years I fight those retarded wannabe scientist puppies. I actually had some success in converting most of the new generation to Python, and using source revision systems. Every year we progress. Since the appearance of Zenodo.org and the big push of EU project towards open science, I actually think that we are at a tipping point. I can actually today publish my articles and associated research products on Zenodo, make them reviewed on github, and have several versions for them. We technically don't need journals at this point. Only the academic administration is the last bottleneck. 
Please don't use wildcard imports. If you do, you're a terrible person.
fun story about this... I adopted some code where one of the previous owners defined their own "sleep" function. They were setting globals, and then using those globals for logic within the sleep. The param was basically the `if true` condition.... And by looking at the code where it's used you wouldn't even think to look whether it's the same sleep in time. You just take it for granted that it's *that* sleep. So when I was trying to figure out why my increase sleep time wasn't working I was pulling out my fucking hair. It took some time for it to dawn on me that maybe I should check the definition.... Lesson learned: import time; use time.sleep() to be perfectly clear... Be explicit, always. I don't even like using `from A import B` for this reason. Being able to instantly see where something is being pulled from, without having to break your flow and control-f, is rather nice. And, your naming scheme should help make it clear what's happening. Instead of calling `fetch()` you should be calling `redditapi.comments.fetch()` or the likes. Then you don't need to bother looking what the fetch() method is supposed to accomplish then, which helps future readability a ton. ... it takes nothing, just be explicit. 
I was going to be kind of (really) mean and tell you to learn how to Google, but then I tried, and I totally see your conundrum: searching for "Python win32crypt" returns a whole lotta nothin. I just happened to have done some win32api stuff in the past, so I recognized the ActiveState link when I googled, which then lead me to the project that houses Win32Crypt. Without that, I'd have been lost too! Win32Crypt is part of the PyWin32 package. you can download it from SourceForge. The docs are [here](http://timgolden.me.uk/pywin32-docs/contents.html). Do a search on that page for "win32crypt" and you'll see that it's one of the modules. Alternatively, since PyWin32 is just a wrapper around the Win32API, you could just use `ctypes` and call the `win32crypt` stuff directly if you don't need the whole PyWin32 suite (Which is pretty huge). The Microsoft API docs are generally pretty good, IMHO. 
Nearly all DAQ hardware can be scripted in python, with the aid of ctypes. At my workplace we have a mostly complete wrapper for the NI NI-DAQmx API. Sadly, it not something I can release as open-source but it doesn't do anything magical: just wrap the ni-daqmx api into a sane python class. We did something similar with UeiDaq products a few years back but these bits of hardware are poor compares to NIs stuff. It you want open-source hardware, use an Arduino Due and hook it up to some ADCs (or whatever other devices you want) via SPI-bus. Then stream the data over USB to the PC. Use libusb (with the libusb1 python wrapper). You can easily do 100s KS/s this way. Probably 1MS/s is possible. This is the lowest cost route but you need to get some PCBs made. USB is awsome as an interface and very easy to script with python/libusb. Something in between is AccesIO's hardware. They're cheaper than NI but the devices are generally less flexible.
Firstly take a look at the sample rate of the audio file. For CD audio with a sample rate of 44.1 kHz, each sample is roughly 23 microseconds, so you will never get truly microsecond precision. In any case, you will end up with something like setting the first 10*sampleRate/1000000 samples to 0, then leaving the next 20*sampleRate/1000000 samples as they are, and so on. Also be careful with the difference between float and int division when getting your sample indices - I'd say it is easiest to work with floats all the way through and then round() at the last step, but that is a matter of personal preference and others may tell you differently.
You can do pretty much anything with it. Web Apps, GUIs, whatever. Some of the more fun stuff I've done (especially since Python has a bad rep for parallelism): Render Farm. Back when I worked in a video shop, I connected all of our old unused computers to a switch and turned them into what I dubbed the Worlds Crappiest Render Farm. Even though the machines were older, they still had decent enough cpus that it was worth spreading the work across them. So, I could spin up these 3-4 computers and assemble all of our movies out in the farm rather than bogging down my edit station. Twas a fun project! 
Just wait until some bozo replaces a builtin and it mostly works the same way... but does in fact break some corner case of expected behavior. Unfortunately in my case, that bozo was former me :(
What was the original claim and how did they claim to notice?
Wrote a web app to to aggregate information from other sites (Flask, requests, BeautifulSoup). Wrote a build service for Visual Basic 6 projects (subprocess, pywin32, logging). Edit: And an invoice creation web app (django, wkhtmltopdf).
Look at [Martyr2’s Mega Project List](http://www.dreamincode.net/forums/topic/78802-martyr2s-mega-project-ideas-list/).
science work. because of the way python is built (and the supporting libraries) I can do something like... download web-based dataset open data in pandas / numpy process it / do analysis / clean it save results as clean dataframe use matplotlib for a quick plot save json data to plot using d3 or other js charting libraries all in one script - and very often (after you get the hang of it) this code will be like 80-100 lines long. And the python code can look very clean if some effort and thought is put into it.
It's great for you that you are learning Python and managed to write a functional program, but why are you sharing this ?
Just to share it. 
Good point. You could do the same analysis in C if you wanted to, and the execution would be like 100 times faster. Like you said the difference is the ecosystem. I can open up a table with 5 million rows of weather data and find the mean temperature (or mean whatever) in under 10 lines, and it takes like 5/10 minutes to get a good 'first try' running... Say big_ol_table.csv is a clean dataframe with columns like station_id, date, min_temp, max_temp, rainfall... import pandas as pd df = pd.read_csv('big_ol_table.csv') for id in df['station_id'].unique(): mean_min_temp = df[df['station_id'] == id]['min_temp'].mean() print "Station {} had an average min temp of {}\n".format( id, mean_min_temp ) Python and the scientific packages make scientific analysis super easy!!
I use import * for my tests. There are legitimate reasons for it.
it's an interesting way to solve the problem. but I don't feel like it's the *correct* solution. I don't know what would be, but this just feels like a hack. I wonder what other interesting hacks you could do with this method though.
I understand you're proud... but this is literally lesson #1 in every programming class ever... it's a genuine waste of bandwidth.
:-) Yes, I'll concede that point. Personally, I feel the ideal and most elegant solution would be for PyPy to become the main interpreter, and not require CPython at all. Unfortunately, there are too many modules that simply don't work with cffi yet. This approach doesn't feel like much more of a hack than the recommended Python way of using multiprocessing. But to me that's always just felt like a poor man's solution around the GIL and its inability to do multi-threading.
This looks really cool. Does it have to be only for SQLite? I'd love something like this for an existing database server, too.
Awesome! The resultset of a query is of type Pandas dataframe. Very nice! 
The reason I focused only on SQLite was because it seemed to me there are already some really well-regarded and powerful tools out there for Postgres and MySQL. Here is a [massive list of Postgresql tools](https://wiki.postgresql.org/wiki/Community_Guide_to_PostgreSQL_GUI_Tools). For MySQL, I'm most familiar with [phpMyAdmin](http://www.phpmyadmin.net/home_page/), but I've also heard [MySQL Workbench](http://dev.mysql.com/downloads/workbench/) is really slick. SQLite doesn't have nearly as many features, so it would be easier to build. Plus, I use SQLite for almost all my own projects, so it was also to "scratch an itch".
The *implementation* is adding tuples, and that is what you'd tend to do in code, but not what you HAVE to do. In fact for example you could import ctypes and do some direct memory hackery and you'd *really*, *really* not be adding tuples. The *effect* is that you have a tuple, and then you have a tuple which is the previous one *with an element added to the end*, and this is entirely independent of how you choose to do it.
Hey, thank you. I should just post on /r/learnpython. I am not protective of my bits because I have a unlimited plan. LOL. But thanks again. -RedExplosives 
I use it to change my desktop background to NASAs APOD every morning. Nice to wake up to a new picture of the cosmos every morning.
Great idea! Flawless install on OSX. I will use this one.
If I do this I hit the 80 char limit real fast. How to avoid?
I didn't put down a specific engineering field to make this question applicable to multiple disciplines not just the multiple fields that apply to me.
May be a little a late but I keep getting syntax errors when I try to run this
pyNastran, vtk, anything on conda, winPython, or Python(x,y)
Bah, import error on python 3.4. After the fix below it seems to work fine though. This is really awesome, and just what I need for some work I'm doing! Thanks! diff --git a/sqlite_browser/sqlite_browser.py b/sqlite_browser/sqlite_browser.py index 934ad34..9d42603 100644 --- a/sqlite_browser/sqlite_browser.py +++ b/sqlite_browser/sqlite_browser.py @@ -10,7 +10,10 @@ import time import webbrowser from collections import namedtuple, OrderedDict from functools import wraps -from StringIO import StringIO +if sys.version_info[0] == 3: + from io import StringIO +else: + from StringIO import StringIO from flask import ( Flask, abort, escape, flash, redirect, render_template, request, edit: scratch that, there are a few other errors. Exporting to csv seems broken. Not sure if this is your fault or a problem in the dependency. If I have time I may look into it and submit a pull request. Traceback (most recent call last): File "/home/&lt;...&gt;/env34/lib/python3.4/site-packages/werkzeug/serving.py", line 177, in run_wsgi execute(self.server.app) File "/home/&lt;...&gt;/env34/lib/python3.4/site-packages/werkzeug/serving.py", line 168, in execute write(data) File "/home/&lt;...&gt;/env34/lib/python3.4/site-packages/werkzeug/serving.py", line 148, in write assert type(data) is bytes, 'applications must write bytes' AssertionError: applications must write bytes 
This is great. Mind if I mention/include it in my python IRC [bot](http://bits.zero9f9.com/pybot) pybot?
Well done! This will be a great tool to have around when working on any flask + sqlite application!
maybe someone just having a bit of fun .
You might want to try exercism: http://exercism.io/about Then there is always the codecademy site: http://www.codecademy.com/en/tracks/python
... i make a living.
I've never tried matplotlib before (much less, heard of it). How does it match up against Matlab? Is it a similar interface? Whatever info you could share would be highly appreciated. 
I made a number of changes today, including adding strftime, today() and now(), but I spend most of my time vastly expanding the documentation. I put an explanation of why I created this object and why it's called CityTime in the readme on GitHub, along with an explanation of each of the methods. I'll continue to go over your suggestions and add and update as much as I can. It's been extremely helpful. Thanks again, and belated happy cakeday! 
Cython, Pythran, Hope, Numba for importable C/C++ and Jit Optimizations into Cpython
matplotlib is a library/module that allows you to plot data in python. It is somewhat comparable to the plotting capability in MATLAB. However it is definitely not as polished as MATLAB's plotting is, especially with the 2014 MATLAB release. So far matplotlib is the best python plotting module that I have found.
You should probably make it so that it can be called recursively, since this makes it a lot easier. So compare(localDir, remoteDir): for each entry, if it is a directory, call compare(localFile, remoteFile). Probably the easiest way to do it, is to use a set, so set(localFiles), set(remoteFiles) addedLocally = localFiles - remoteFiles, addedRemotely = remoteFiles - localFiles, then compare the files in the union of localFiles and remoteFiles to see if any changed.
&gt; [...] So the only thing you could do is to publish a patch, but that is close to useless, because it will not apply to all versions of the software, and it's specific to your problem. [Ten Simple Rules for Reproducible Computational Research](http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1003285) (PLOS): * *Rule 3: Archive the Exact Versions of All External Programs Used* * *Rule 4: Version Control All Custom Scripts*
Asking artists to do programming is kinda nuts. I mean, sure, it can be a nice way to expand your horizons, but FFS, art is hard enough without expecting you to turn your brain inside out with logic.
The next version of the Seaborn plotting library will have functions that should make plotting labeled heatmaps and doing clustering much easier: http://stanford.edu/~mwaskom/software/seaborn-dev/tutorial/dataset_exploration.html
I do online moderation, so often I have to file out forms on web pages. When dealing with spambots, I used to have to fill out a form for each and every one of those bots, even when they came in the hundreds. These days, not only have I automated the detection of them (instead of hunting them manually), I can also just press a button to deal with all of them automatically. Saves me hours every day.
Nice. So you do a fair bit of machine learning with it?
Oh, not at all. No machine learning at all. I figure out the parameters which qualify a spambot, make the script look for them, and take action when it finds them.
It's been so many years since I decided the wildcard import shouldn't exist that I have kind of forgotten that it does. And then I ended up using my IDE to manage my dependencies like a Java/.NET coder. If you actually look at some of my import headers, you'd probably be appalled. They work, but they aren't pretty, so it's a good thing that they're normally folded. When you have to use tuple syntax on your import statements, your module is too large, the external interfaces are too complex, or you aren't using all of those imports anymore! If only '\_\_all\_\_' + modular design had more cultural inertia and python hackers weren't so busy trying to build things that work on real-world budgets. And unicorns, that would be cool, since we already have antigravity.
Wow. Thats impressive.
They should unchain Django to help.
Do you know [Awesome-Python](https://github.com/vinta/awesome-python) ? It's a very long list of Python modules with short descriptions, organized by field, and updated regularly. It should give you a pretty good picture.
 def sleep(secs): for x in range(1000000000 * secs): # Takes 1s on my machine x = 1
Parenthesize the imports. from A import (B, C, D, E)
&gt; Ten Simple Rules for Reproducible Computational Research Yes but bioinfo is different. It's a more modern field where they got the problem and forced a solution at the journal level. The fact that you must have an accession number and a visible genbank for all the published sequences is an example. computational chemistry didn't move. It's still stuck in the past.
Even if a compiler was guaranteed to be available, this is a complete non-starter. Modules that interface C libraries often have non-Python dependencies, which are not tracked at all and vary one a case-by-case basis. For example, if you try to build the lxml Python module, you will fail even if you have a C compiler installed unless you have already compiled and installed libxml2 and libxslt, two C libraries that have nothing whatsoever to do with Python. There is *no way* to automate this other than by manually trying to build every package and then reading the README when it fails. And *even if* you could automatically detect these dependencies somehow, there is no standard build system for C libraries. Every library is different, and has a different set of commands necessary to build it, particularly on Windows. The best PyCharm would be able to do is scrape Gohlke's site and automatically download and install from there. But please don't do that, because the site seems to have anti-scraping measures in place which means he probably does not have the bandwidth to support being an automated repository. The worst possible outcome would be for that site to be closed in frustration due to what's effectively a DDoS attack from some IDE.
did not know this, thanks for the info! they could mirror the site themselves and have IDE's fetch those from there. But that then requires network infrastructure and all sort of effort that could be better used to improve the IDE instead 
How about in the body of the code itself? One or two function calls + list of arguments + indentation fills up the whole line!
You can do the same thing with function calls etc, as [discussed here](http://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation-in-python). You could also import a module using a shorter local name, which will also reduce line lengths (for example, numpy is often imported as np). Finally, you can always go over 80 characters - that's a guideline rather than an absolute rule and you shouldn't sacrifice readability simply to comply with it.
Regarding importing `*` from modules and packages: http://www.reddit.com/r/Python/comments/2lo260/importing_in_python/
Thank you! I'll check out your recommendations!
Yes, except that Python optimizes for the 10-LoC case, in favor of larger codebases. Your 10-liner is easy in Python, especially for the "happy case", but when your scope it multiplied by 100, and you need robust error handling, static typing really starts to shine.
No. Post it in /r/learnpython. Read this subreddit's sidebar. Also, this smells like homework. 
Gotcha, I'll post there. And no, I'm just very interested in making games. I'm doing Assembly in school and doing python on my own.
I'd probably only use one class for such a small game (unless you wanted to split it into Board, Player) - it's just a matter of allowing for variables not in the global scope.
Why bother actually attacking them, when you can take the site down for all the effort of posting a tweet! Perhaps call it a TDoS?
A decorator is, under the hood, a function which accepts a function and returns a function as its result. Its purpose is to literally *decorate* another function, wrapping said function's core functionality inside of its own modifications. The textbook example of where they're useful is declaring properties, right? @property def foo(self): return self._foo @foo.setter def foo(self, value): self._foo = value You can create your own decorators any time you have some functionality that *has nothing to do with the actual operation*, but is a useful aspect anyway. Tracing/auditing is a common use. I used them to implement lazy loading from a file- I made a "loaded" decorator and applied it to methods that needed to have a file loaded before they could provide good output (thus avoiding loading the file until I actually needed it).
Sure!
Thanks for letting me know, I'll work in getting that fixed. **Edit** should be fixed in master.
&gt; IMHO this a game changer. Anyone can visit the url, execute the code, modify the paramaters, and reproduce the results without any setup required. :D Thank you so much for writing such kind words about our prototype as well as engaging in multiple threads about tmpnb + IPython. &gt; So a couple questions. What security concerns do you have making these links public? Network is (now) turned off from within the containers. The most striking issue I can think of would be escaping the Docker container. We don't give people root access, but that doesn't necessarily prevent them from escalating privileges and then working their way up through Linux kernel bugs. This is purely speculation from me though and I think the Docker and Linux folks are doing an incredible job of locking things down while giving out extreme usability. Honestly, we're taking a risk here with the tradeoff that we can let lots of people try out the IPython/Jupyter notebook. Note that each tmpnb node (in the backend) does *not* have access to any secrets or keys in case of compromise. SSL termination happens in advance on a separate server with nginx. &gt; This will get expensive quickly, what are the thoughts on this? Now that the first wave has already hit, this demo isn't too bad at all. We: * recycle the user's container when they're done with the notebook \* * split across many hosts and can dynamically resize * hosts are packed so that each user gets 512MB (like /u/kingkilr/ said), which ends up being more economical on a bigger box - 512GB of memory goes a long way. In effect we got to serve full scipystack environments to &gt; 10,000 people in a short amount of time while keeping costs fairly low by spinning servers down when the rush was over. I'm painting this like it was easy, but we actually ended up having an outage for a short bit. Min quickly wrote a load balancer called tmpnb-redirector so that we could redirect to the nearest available node while Ash Wilson and I worked on spinning out more servers underneath. It was a rush. Originally we were only going to handle 512 concurrent connections/notebooks but then decided we'd go ahead and expand that a bit. In addition to that, the servers ended up staying alive if open in a tab (whether on mobile or desktop), so we have inactive users consistently. I really need to write about some more of this soon, as we're still prototyping, learning, and deploying.
First we need to get the concept of higher-order programming. This is when we treat functions as just more things to work with; we can write functions which take other functions as arguments, return new functions, etc. So, for example, suppose we have this simple function: def add(x, y): return x + y But let's say there's something in our codebase that often requires adding 2 -- and not any other number -- to something. So we could do something like: def add2(x): return add(x, 2) This is a technique that's called *currying* -- we're making a new function which has fewer arguments, because the arguments that have disappeared now have fixed values on every call (in the case of `add2`, one of the arguments of `add` is now fixed as 2, instead of potentially varying on every call). We could even write a function which generates specific "adder" functions: def make_adder(number): def _adder(x): return add(x, number) return _adder This works because the value of `number` gets "closed over" (the usual term is that this relies on a *closure*) -- Python remembers that value, and so whenever we call the function returned by `make_adder` we'll get the value of `number` from that specific time we called `make_adder`. So, for example, we could do: add2 = make_adder(2) add3 = make_adder(3) and so on. Now, decorators. Decorators are just another example of higher-order programming. A decorator is a function which takes a function as an argument (and may take other arguments, too), and returns a new function. The simplest case for decorators is when you have an existing function, and you want to make a new function that does some extra stuff before or after. Like, say, if you need to debug by printing out the arguments a function was called with, you could write this: def argument_printer(func): def _wrapper(*args, **kwargs): print "Called with positional arguments: %s" % list(args) print "And with keyword arguments: %s" % kwargs return func(*args, **kwargs) return _wrapper Now, suppose we want to always know what arguments our original `add` function gets called with. We could do: add = argument_printer(add) Or, using the decorator syntax: @argument_printer def add(x, y): return x + y And now any call to `add` will print out the arguments it was called with, before actually calling `add` and returning the correct result. And... that's it. That's a decorator. But that's just the tip of the iceberg as far as what they can do. Decorators can do pre- and/or post-processing, as in this example. Or they can implement more complex logic, or choose what to do based on what arguments the function gets called with, or... well, all sorts of things, really.
That explains a lot. That's also a very interesting idea of loading a file when you need it using decorators. As not to steal your actual code, could you write the pseudo code of how that might work? I assume it's to import a module or file at the time that you call a certain function but how would you know where the module is in your directory, etc...
&gt; I think it is just better to set up a git repo with a readme and an easy to tweak configuration file so people can generate new results, which is what I'm planning to do soon. Nothing wrong with that. In fact, the linked demo here is supposed to be an accompaniment to [an article about the IPython notebook](http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261) itself. We're providing this so people could try out the notebook. The title here is a bit misleading as this was meant to demonstrate the power of IPython notebooks and the Python scientific software stack to scientists at large. Some people are releasing their code+notebooks, as listed in the original article and linked to within the list of [Reproducible academic publications](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#reproducible-academic-publications). The notebook (and some of the deployment pieces) are in the https://github.com/jupyter/nature-demo repo.
Awesome, Keep it up.
You can search for what you're looking for [here](https://creativecommons.org). I'm not sure there's a license for what you're specifically asking for but I may be wrong so it's worth a look
Cool, very well laid out. That really explains it, at least at a basic level. Thanks so much!
Do these licencse prohibit military usage? 
I'm not a copyright lawyer so this may be completely wrong, but as I understand things, licenses only specify conditions under which people can *redistribute* your software, not conditions under which they can *use* it. I guess you can add your own terms that try to restrict how people can use the software, but I'm not sure you'll find any of the common free software licenses with such terms. Also I'm not sure on how legally valid they would be. Besides that, this site was just linked in another topic and seems to summarize the common licenses pretty well: http://choosealicense.com/
The US military, at least, won't use your code. It's not secure. They would much rather pay for code they can trust. The Chinese military, on the other hand, will do what they like regardless of license.
Have you seen http://choosealicense.com/ ? It's what I use for when I hate to pick a license and research it. 
You're confusing one license's feature (the GPL) with all license's. Use absolutely plays into a license. 
Wow, I really like it. I'm gonna have a closer look at the codebase when I get back to to my place, but there are a couple of things I'd like to mention first. * Split up the file into it's components. Code is very readable, but it's hard reading over that one huge flask file. * Found a bug. It looks like. For some reason application crashes when you try sorting rows. [http://i.imgur.com/qXtGuJq.png] (http://i.imgur.com/qXtGuJq.png)
We like hearing that, of course--I'm vice president of the tiny company that's supported PyPDF2 since (before, actually) its origin. Our support is frankly rather erratic; PyPDF2 simply is not my highest priority, in large part because I'm ambivalent about how much value it truly provides. It matters to me every time someone says, "yes, I depend on PyPDF2". There's a LOT more we can do to improve PyPDF2. The biggest constraint is our own decisions about what matters.
FSF will consider that license not-free, [just like the JSON license](https://www.gnu.org/licenses/license-list.en.html#JSON).
Huh, I always thought they were "copyright" licenses because they explicitly grant you rights to *copy* the software under certain conditions, which is a step up from not being allowed to copy at all with no license. I'm not sure how, if you're giving the software away, what laws would protect any "usage" licenses if you're not doing any copying. How would one sue someone for misuse? It obviously couldn't be copyright law.
[https://tldrlegal.com/](https://tldrlegal.com/) is a great site for searching/comparing software licences and their features.
Thank you very much for this explanation. One more question - what is a *wrapper*?
Well they clearly using Linux but if the license would prohibit t they wouldn't be allowed to do it. And yes it is a rather academical question - I would or could never know if they do it and if I knew if how would I enforce the license? I don't care if they would but I don't want to allow them the use of my software. There always be criminal organisations who don't care for license or copyright - they may also decompile code and crack windows license but they are not allowed to and thats the point.
A wrapper is, usually, a function that wraps another function, in order to handle some special cases: errors, failures and fixed arguments. Edit: i.e. in the previous example, the wrapper prints the argument and then launch the function as usual.
 &gt;So I wrote a small program and I want to license it. It should be free as in freedom of speech and as in free beer. But it should prohibit military, military related and espionage related usage. BSD! Stay away from GPL because you loose to much freedom supporting that license. As for military or government related, the government doesn't have to respect copyright laws or patent laws. &gt;Even if I don't think my program is in any way usefull for military stuff, I want to make a statement. That is actually a bit foolish in my estimation. First; it indicates that you don't have a clue as to the world order and natural human tendencies. Second; they will do whatever they want with your code. Third; trying to use an open source license and then restricting any one group from using your software flies in the face of freedom. Would it make sense to restrict the Irish from using your software for example? &gt;Iam aware that this could be conflicting with the freedom of speech idea. You think? You need to accept the good with the bad here. What would you think is a bunch of drug dealers where to use your software to murder people in Mexico. The fact is there are bad people out there that just don't care, if you make your software publicly available you will have people using it that you'd rather not be associated with. &gt;So which license would you suggest and had anyone similar concernce towards their software and software license BSD? As for your concerns I think it would be best to grow up. You have only two choices. One is to keep the code to yourself the other is to accept the idea that bad actors will use it if made public. 
Likewise, the Open Source Initiative would consider it not open source under the "no discrimination against persons or groups" and "no discrimination against fields of endeavor" clauses. EDIT: The link I meant to include. http://opensource.org/osd-annotated
This is very neat. SQlite needs an interface like this, I probably would have tried something like this had you not! Supporting this project
 &gt;I really like the creative common license and I use them for most of my non programming texts. But it won't address the problem of software usage in military and espionage related enviroments. You can always write your own. It won't do any good but you would get what you want. &gt;I really despite the thought that software I wrote could be used to spy on people or even kill them. You really need to get over this non sense. Sometime the most rational way to deal with people is to kill them. Look at the current mess in the Middle East as an example of what not to do. 
I see `def _wrapper` and its functionality, but what is *wrapping another function*? This example of a wrapper doesn't seem to handle errors, failures, or fixed arguments. (And where does it even get *args etc. if it's not passed in with the original function?) What is the purpose of a wrapper vs a decorator? If i wanted to be able use *+* on a class i made, would i make a *decorator* to handle my new class, or would i make a *wrapper*? They both seem to modify existing functions to add new functionality. I can't seem to differentiate what the different use cases are.
Theese are very good points and should be taken into consideration. On the other side: The goverment considers themselfs as the good ones. They also respect the copyright of microsoft and pays for the use of windows. I always favored the BSD license and the FSF but on the other hand I feel responsible in the use of my software. 
Depending on the volume of your library I am unsure, I used to oscillate between these licenses then realized it would take me weeks reading all of them, and the probability of one benefiting from one over another is usually unlikely, few are very different from one another.
I totaly understand your argument but Iam not a [Wernher von Braun](http://www.youtube.com/watch?v=QEJ9HrZq7Ro) type of person
[You can use it](https://github.com/RemyPorter/Bundler/blob/master/bundle.py). "loadguard" is the decorator. I used it because I have to parse the file, which is itself pretty expensive.
The easiest way to understand decorators is to think of it as a way to wrap an object so that you can do something before or after the object is used. It needs to return the object you wrap, so the code you use doesn't change. 
Wow, can't believe I forgot this. MIT added.
I've come to the conclusion that if you're nesting that deeply then you're over-engineering it. Generally speaking if I have that problem AND there's no way around deep nesting, then I'll split out that portion into it's own function. 
Hmm, sorting is working on my end. If you add --debug when running the app you'll be able to see the traceback, and it'd be great if you could share it with me (via [github issue](https://github.com/coleifer/sqlite-browser/issues/new) if you don't mind!).
Few other tips after looking at the client: - Make a module, maybe TicTacToe_utils.py, and put all the shared code in there. This would be a good place for the Board class. In general try not to repeat code. - Try not to use '-' in module names. Then they are hard to import from. Python thinks you're trying to subtract something if you have `from TicTacToe - Host.py import board`. - Depending on your comfort with Exceptions, you could try to catch an ImportError with importing winsound. You can do this when an import is optional, like the sound is here. Some more sample code: try: import winsound except ImportError: print "Sound not supported" winsound = None ... def play_sound(soundpath): if winsound is not None: winsound.PlaySound(...) ... 
I have recently started using http://sympy.org/en/index.html and I love it. Saves me so much time, even though I love derriving formulas.
Well, let me answer in order: my examples about failures or errors were general cases, not strongly related to the decorators. For instance, I'd use a wrapper in case I'd need to call a function many times, checking for errors on each execution. A wrapper (that call the function and check the errors) would made my code more simple, clean and elegant. Furthermore, they are often used in "rough" languages, such as C. Then, but I could be wrong here, the *args argument are automatically passed to the function call. Someone could explain it better than me anyway :) About wrapper vs decorators: a wrapper is something like a "general purpose pattern", that can be used no matter the chosen programming language. Instead decorators are "syntactic sugar", they're wrapper, but they are used in a more straight forward and comfortable way. For the *+* instead, that is a completely different case. Specifically, you should implement: __add__(self, other) For that, take a look at python's magic methods :) http://www.rafekettler.com/magicmethods.html#operators
Goosegoosepress is correct. Software copyright covers the right to use the software as well. I once worked at a shop that was very very careful about licenses and required us to verify with our lawyers before clicking through any license on any software install. I had one program that I was allowed to use but not copy, and another that I was allowed to copy but not use until we had an appropriate agreement in place. I had long back and forth discussions with these same lawyers when it came time to write our own license for a library we were giving to customers. they wanted to be overly cautious and restrict everything, I wanted it to be more generous to encourage people to actually use it!
Thanks for your help :)
&gt; As for military or government related, the government doesn't have to respect copyright laws or patent laws. Having worked for the Department of Defense myself, I can assure you that this is actually not the case. Software licensing costs Uncle Sam a pretty good chunk of change, and in fact at my job we were starting to move to Python (from Matlab/Simulink) when possible for just that reason. All that said, and though I admit pro-military bias, I do think a "military-free" license is probably not a great idea. It conflicts with "free as in speech", and could conceivably cause software thus licensed to be useless in the cross-pollination that military research efforts have with peaceful civilian work - for instance, the invention of the internet itself.
this is what i love about Python ... even the top-devs come to help out us, noobs ... awesome ! thank /u/ubernostrum :)
Who assigned you this task if not a professor or teacher? You described this as "coursework:" we're assuming you have some kind of instructor. Also, you can ask classmates.
I meant teacher sorry, Yes I do have classmates, and I've contacted them through facebook, but the class I'm in have different coursework... There was 3 to pick from, and the one I picked has the least amount of people doing it.
No military that would use your code would care about your licence on it. Copyleft licences (GPL etc) guarantee user freedom while restricting developer freedom. Permissive open source gives the developer more freedom, including the right to not pass on the freedom to the user. It's up to you which you prefer.
Well, if you know who those other people are, you should form a study group.
Well, thanks for the help :/, I only really asked help for a little thing.
I think you underestimate how bad the problem is in China. Also good and evil are relative. Why is someone using your software for a military application to help keep you safe bad? I write an open source project that does have a strong military application and is actively being used by a decent sized group of people in the defense industry. It's about how you use it. When I got out of undergrad, my first project was to work on a hypersonic missile design program. Aerodynamics are aerodynamics regardless of what vehicle is flying. Structural analysis is also the same, so is propulsion. All that's different is the pretty picture.
&gt; As for military or government related, the government doesn't have to respect copyright laws or patent laws. What about someone like me who works in the private sector, but sells to the military? We take licenses very seriously and actively avoid GPL. BSD is not a big deal.
Why do they fear the GPL license? I heared it is some kind of virus license using it all modifications on the code also have to be GPL 
Actually, you didn't. You claim you want "help" but you haven't shown any attempt to solve the problem yourself or expressed any specific confusions with the problem. You're asking me to do your work for you. And you're also in violation of subreddit rules. Now go get help from your teacher/classmates instead of trying to get strangers online to do your homework for you. If you have specific questions, try /r/learnpython, but *show them what you have tried* first. Don't try to get them to do your work for you.
What does this do? Where are the files stored? The first example appears to backup a local folder to (where?). And the restore takes a folder ID. Where does that come from? It says "from the database", but never explains what that means. More importantly; what's the goal of this program? What are the features? What's the performance compared to other methods, and what benefits does this have over other backup programs (including just an rsync)? A bit about the backend might be nice; how are the files stored, is there versioning, is this all blobs in a db, etc.
Your formatting is off, you should put 4 spaces before every line here on Reddit so that it keeps your original formatting: import turtle dict_1 = {} dict_2 = {} dict_3 = {} def read_coords(file): dict_three = {} new = [] for line in file: #print(line) line = line.split(" ") #print(line[0]) dict_1[line[3]] = ([line[0]],[line[1]]) #print(dict_1) dict_2[line[3]] = ([line[4]]) if len(line) &gt;= 7: lines = line[6:] lines = " ".join(lines) lines = lines.split(";") dict_three[lines[0]] = 0 for instance in dict_three: dict_3[instance] = line[3] #print(dict_1) return(dict_1, dict_2, dict_3) def plot_plain_stars(picture_size, coordinates_dict): s = turtle.Screen() s.bgcolor('black') listt = [] for item in coordinates_dict: listt += coordinates_dict.values() #print(listt) for item in listt: turtle.up() #turtle.goto(item) turtle.pd() print(dict_1) So, you're creating 3 dictionaries. Then you define 2 functions. Then you print one of those dictionaries. You never actually did anything in any of the functions. You have to *call* a function after defining it.
Sorry if I didn't make it clear. I have completed up parts of the code, up to the point where the code will print the license plate number which is over the speed limit onto a text file, however I need the code to read from an excel spreadsheet. Please view my code below: from datetime import datetime, timedelta t = datetime.strptime("00:12:00","%H:%M:%S") elapsed = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second) startTime2 = input("What time did the car pass the first sensor?") startTranslate2 = datetime.strptime(startTime2, '%H:%M:%S') finishTime2 = input("What time did the car pass the second sensor?") finishTranslate2 = datetime.strptime(finishTime2, '%H:%M:%S') speed = (finishTranslate2 - startTranslate2) License = input("What is the number plate characters?") #This will ask the if speed &gt; elapsed: print ("Your car is under the speed limit AND therefore you will not be placed in the 'speedsdatabase.txt'") else: print ("You are over the speed limit, please refer to allocated text file for the Licence plate that is over speed limit") printtoFile = open("Speedsdatabase.txt","a") printtoFile.write(License) printtoFile.write('\n') #This allows the ouput to be clearer and on a new line. printtoFile.close()
Wow, this is really great idea! I used one of those sourceforge windows GUI's, but it had a somewhat strange UI. I'll definitely have to come back &amp; try this when I get into my projects again. It'd be nice to have a good web-based UI for sqlite stuff, like phpMyAdmin was way back.
Think about it for a second: how exactly are "Good" or "Evil" to be enforced by a court? We don't have an algorithm to tell us whether any particular usage is "Evil", so at best this is an ineffective restriction that doesn't convey the license-holder's intention. Worse, it reads like a vague joke, rather than something to be actually enforced; it's exceedingly unlikely that anything "Good" would come of it. On the other hand, what's the worst thing that this clause could make happen? Opportunists (particularly parties with deep pockets) can try to use it as an excuse to try to shut down users or developers of the software. Said users or developers need not *actually* be using it for "Evil"; the mere threat of a lawsuit is chilling enough unless you happen to be filthy rich. So, at best, the restriction does nothing, and at worst, it can be used to stifle freedoms. You can't seriously consider it to be a free, or even a "Good" thing.
Okay... Thanks.
Why do you avoid GPL?
Close enough, in my opinion. "One right way" isn't exactly the way I'd sum up Pythonic code, although it is definitely part of it. I'd recommend the [Zens of Python](http://legacy.python.org/dev/peps/pep-0020/) to describe the *way* Python code should be written.
Well thoose damned lawyers but point taken 
That's the explanation I heard most often. I personally think it's bullshit, but I'm not a lawyer.
Hmm, was ms sql server support just [added](https://github.com/yhat/db.py/pull/22)? That was quick!
I don't know if its true or not but I would like to know why GPL is avoided in the first place
&gt; *wrapping another function`? &gt; &gt; This example of a wrapper doesn't seem to handle errors, failures, or fixed arguments. (And where doed it even get *args etc. if it's not passed in with the original function?) As someone who has never understood decorators this is the best explanation I have seen. Thankyou!
I'm ambivalent about which interpreter is considered the "main" interpreter. it's just that cpython includes a horrible way to extend python which probably was a bad idea.
Ugh, it doesn't matter. It's the wrong question. It doesn't matter what programming language you use as long as you use it correctly. When I bash Java it's not because Java is complete shit. It's complete shit for **me**. Much more important than your language is your interface. To quote Doug McIlroy &gt;This is the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface. 
You need the modulus operator, `%`, which gives the remainder after division. e.g. `5 % 2` evaluates to `1`, since 5 = 2*2 + 1. Your own code really doesn't make any sense - I guess you mean `3 &lt; 2**100 &lt; 6`, but this does not help you answer the question, it only tells you if 2**100 is between 3 and 6 (which it obviously isn't). Still, there's something to learn here, you can play with this in the python prompt - enter different combinations of x &lt; y &lt; z or similar, and see what the result is to help you understand what the operations do and what order they may be applied in. Also, please raise such questions at /r/learnpython.
Of course, it's a lot less repeatable.
Going with the Unix philosophy analogy -- depending on what the startup does, it is possible that multiple languages/systems may be needed. If it is a web-based interactive system, you would need JS + something for backend (can be node.js but is flexible). If it is high performance stuff, you may end up with some major chunks of C/C++ code in there. Reddit started with Python and moved to C++; a startup I was with long time ago started with prototypes in Perl, core engine in C++ and moved to Java + JSP. There has been this trend in "I can do it in 4 lines in Scala instead of 40 lines in Java, so let's move to Scala" type push around. Missing are all the critical pieces like test cases, documentation, etc., which are the bigger piece of work anyway -- and usually have similar amount of code in most major languages. All of this within reason, and with the assumption that we don't overplay the logic with, we are "polyglot", but we need this new "framework"! There is no one answer. May be one option is to write for handling a scale of 10x (or 100x); longetivity of 5 y or 10 y; performance of X? 
Oh, how about [this](http://hammerprinciple.com/therighttool)? Particularly: * [C#](http://hammerprinciple.com/therighttool/items/c-3) * [Java](http://hammerprinciple.com/therighttool/items/java) * [Python](http://hammerprinciple.com/therighttool/items/python) * [Ruby](http://hammerprinciple.com/therighttool/items/ruby) * [PHP](http://hammerprinciple.com/therighttool/items/php) * [JavaScript](http://hammerprinciple.com/therighttool/items/javascript)
Thanks for the examples. The @time is specifically helpful in terms of using it in a real life situation. Cheers!
Wow, ok... Didn't realize how much of a pain it *would* be... Still nice to dream though =P
This is a good explanation. I'll add to this. One important use case that decorators fulfill has nothing to do with actually wrapping the original function. So, they're decorators that do essentially this: def register(f): .... return f That doesn't seem to do anything at all but actually can be very useful. This way decorators can be used for *registering* functions with some framework. It's actually nice in this case that the decorator leaves the original function alone, so that if you use: @register def my_function(): pass you actually know that my_function is unchanged and can still be used exactly as you read it. So what could you do in a register decorator? Something like this: registry = [] def register(f): registry.append(f) return f Now any function marked with @register ends up adding this function to the list. More useful registration decorators actually take arguments themselves. This way you can actually say a bit more about how you want to register things: @register(name='foo') def my_function(); .... How would you go and implement this? One way is to use nested functions: def register(name): def decorate(f): registry.register(name, f) return f return decorate So here @register *returns* a decorator function. But since in the last example we *call* register that does exactly what we do: the result is the decorator, which then will be used to register the function f with some registry. This registration use case for decorators has not all that much to do with higher order programming, but more with framework development. In the end the framework will of course end up calling these functions. It's a framework so "don't call us; we'll call you" applies. I'll note that class decorators (decorator that decorate a class) are also often used this way. A web framework like Flask makes use of this pattern a lot. Pyramid also has a way of using them this way, and so does a web framework I created (Morepath). There's a library called Venusian that takes this pattern to a higher level: http://docs.pylonsproject.org/projects/venusian/en/latest/ It allows you to defer the registration actions until *after* the module has done importing, avoiding work done during import time as much as possible (which can lead to various problems concerning import errors). This library can be used with Pyramid, and I use it with Morepath as well. 
Well that is the shittest language comparison website I have ever seen.
This is really great work. I actually need this for something I'm working on! Thanks for sharing it with us! Super sweet looking too.
They let you do something with the parameters given to a function before the function gets them, and then do something with the return value of said function, before the caller gets it.
What exactly do you mean by 'shared code'?
I've only just started playing with this kind of software (bought some easybulbs a couple days ago) so I have played with both your software and openhab a little, so I can tell you some bits that I miss on home-assistant that are present in openhab :) First, I have easybulbs, these sadly aren't supported in home-assistant, although it'd probably be very easy to add them. [There's a library for them](https://github.com/joaquincasares/python-wifi-leds) Second and I think most importantly, openhab has a sort of rules/events system called Rules. Maybe worth having a look over https://github.com/openhab/openhab/wiki/Rules I don't think home-assistant has anything like this. It'd also be cool to have an IRC channel for the project :) Not trying to put down home-assistant though, it's awesome and does lots of things that openhab doesn't. These are just a couple of things that I can see myself using in openhab, that aren't present in home-assistant. :) 
Nothing wrong with the Python blurb *per se*, but the premise of the article is silly. In practice, nobody sits down and says "hmm we have to program, but which language should we use?" Language choice is dictated by the problem at hand, and the available solutions in a subset of languages. The article isn't wrong, but it sure is useless...
check out /r/learnpython but also you can't combine two Bools with a Not. You have to say and/or as well.
`*args` and `**kwargs` denote the positional and keyword arguments that have been passed to a function. The way it works is that `args` is a tuple which contains the positional arguments in the same order they were supplied to the function, while `kwargs` is a dictionary and has the names of the keyword arguments as its keys, and the values passed for those arguments as the values of the dictionary. So you can do things like: &gt;&gt;&gt; def foo(*args, **kwargs): ... print(args) ... print(kwargs) &gt;&gt;&gt; foo(1, 'a', bar='baz') (1, 'a') {'bar': 'baz'} You can also unpack an iterable or a dictionary-like type using the same notation. &gt;&gt;&gt; pos_args = (1, 'a') &gt;&gt;&gt; kw_args = {'bar': 'baz'} &gt;&gt;&gt; foo(*pos_args, **kw_args) (1, 'a') {'bar': 'baz'} You can also use this for functions which don't use variable-length argument lists, provided your inputs match what the function expects: &gt;&gt;&gt; def add(x, y): ... return x + y &gt;&gt;&gt; nums = (3, 4) &gt;&gt;&gt; print(add(*nums)) 7
Yup. Agreed.
Do you have any comparisons with OpenERP, now Odoo, available? Is also Pyyhon. 
&gt; Checked whether it was properly installed with: &gt; $ python &gt; \&gt;\&gt;\&gt; import PyMySQL &gt; Oops, didn't work. I then tried: &gt; \&gt;\&gt;\&gt; import pymysql &gt; That did work. this epitomizes why i hate blog submissions in this subreddit. fucking seriously? O_o
For NI it is PyDAQmx! It works very well.
I see your point and I agree with you. However, it is a tradeoff with the risk of forgetting to import something from the \_\_init\_\_.py file. Your tests *probably* cover that since they import the name, but it's hard to check that some names are not wrongly imported from submodules.
What's wrong with mysql.connector?
Create file objects, which have name, size, date modified, and crc values (for the content). The crc should only be calculated if needed (ie for the difference between the 2 sets, it is not needed, but when doing the union you can generate the crc if there is another file of the same size).
I have read through your tests and most of the controller and layout code. If you could provide the general overview, then what would be your first request, good sir?
Nothing other than the name. It was pretty trivial to upgrade that adapter to be tornado friendly.
this kinda smells like homework. is this your homework?
&gt;the name Come on m8 import mysql.connector as mysql This is Python.
awesome thank you this was just what I needed!
Please delete this thread and repost in a more appropriate subreddit. Although, this is clearly a homework problem.
def f(n): 
Awesome, awesome post. As a PyNoob, this helped me a lot. 
having both client and host use the same file/module as opposed to having code like show_board() in both places.
Note that if the decorator has arguments @decorator(arg) def blah ... the equivalent is blah = decorator(arg)(blah) # 'decorator' return a decorator and not blah = decorator(arg, blah) 
In case this helps anyone else, this is a "cheat sheet" I made myself for decorators as I could never remember exactly how the chain of functions were structured depending on what I wanted to accomplish. No args/kwargs on either the decorator or the function def outer(some_func): # code here runs when declared def inner(): ret = some_func() return ret + 1 return inner @outer def makeone(): return 1 @outer def maketwo(): return 2 makeone() (returned) &gt; 2 maketwo() (returned) &gt; 3 With args/kwargs on the decorat**ed** function def outer(some_func): # code here runs when declared def inner(*args, **kwargs): print('{0}, {1}'.format(args, kwargs)) ret = some_func(*args, **kwargs) return ret return inner @outer def add(x, y): return x + y @outer def multiply(x, y): return x * y add(5, 6) (printed) &gt; (5, 6), {} (returned) &gt; 11 multiply(7, 7) (printed) &gt; (7, 7), {} (returned) &gt; 49 With args/kwargs on both (note the extra layer): def outerest(n): #decorator parameters go here #code in this block runs when the function is declared def outer(some_func): #this just holds the function being decorated #code in this block also runs when function is declared def inner(*args, **kwargs): #function parameters here print('Decorator Params: {0}'.format(n)) print('Inner Params: {0}, {1}'.format(args, kwargs)) ret = some_func(*args, **kwargs) print('Inner return value: {0}'.format(ret)) return ret + n #this is return value return inner #this returns the function itself up one level return outer #this returns the function itself up to the top level @outerest(4) def add(a, b): return a + b add(6, 1) (printed) &gt; Decorator Params: 4 (printed) &gt; Inner Params: (6, 1), {} (printed) &gt; Inner return value: 7 (returned) &gt; 11 
http://stackoverflow.com/questions/23376103/python-3-4-0-with-mysql-database 
Solve equations, engineering calculations, scrap data and financial data. Clone Matlab functions. Automation and software exploring. Python is AWSOME !!! 
If you want pip to automatically install your package dependencies for you, just list `install_requires=['flask', 'pewee'],` in your `setup.py`.
Why are you lecturing me? I've modified the damn driver, so of course I know it's a non issue. That said, determining which package to use on PyPI often hinges on using the right keyword and another selection algorithm other than "one with highest weight". It's searchability (discoverability) that limits the adoption of many good packages. Edit: Just another footnote in why I hate the open source community. You're allowed to erroneously "correct" someone but god forbid they call you on your bullshit. /r/python is the ass cancer of the Python community.
Pycharm can do something like this. If you use the virtualenv integration there is a gui for installing/managing packages within a virtualenv. And there is a free edition of pycharm that kick ass - i use it every day for python work when i'm not ssh'ing into a linux machine. Might as well take advantage, it has all the desireable IDE features, I especially like the vim mode.
why SSH for programming? Do businesses do that for security?
Also virtualenv?....do i need anything other than pycharm to install and manage packages?
what is a crc value? does it have anything to do with the bytes in the file?
Have an upvote, because it's true. But, well, even though I understand why it works that way (the decorator line just specifies a expression that returns a function to be applied to the decorated function), that seems quite broken.
Because you need to use raw_input not input. input( ... ) is equivalent to eval(raw_input(prompt)) 
This really helped me. Having it explained from a couple different perspectives is great. Thank you! I am aware of the `__add__()` method. Thanks
/r/learnpython
Yeah that was pretty much the idea I had except I was planning on using an ARM core just due to my background. Also as much as I love NIs hardware the point of this project is to get away from it. This board when done should cost less than $100 to make and should be better than say a USB-6009. 
/r/learnpython
Yeah what they have is straight forward and lovely to use. They really have a great product. I would just like to bring something out that's powerful and people can mod. 
I've messed around with the library (never used in application) and its pretty good. The whole point of this is open source hardware. The software is a components as well but not the center of the project. 
Also if anyone has any ADC suggestions that would be great. There are on board 12bit but I want higher. I've started a list but if anyone has had experience I'd love to have input
Keep in mind that there are a lot of programs that receive military funding. I work on training novices in high-pressure situations -- primarily firefighters -- but my lab receives quite a bit of our funding from the military. You may not want to restrict this kind of access. A lot of university programs get some kind of military funding. 
Well. Say you have a Linux server set up somewhere, and you are sitting on a beach in Hawaii with some wifi connection. On my mac I can ssh into the server and start doing stuff there. 
virtualenv is a tool that creates self contained environments so you can pip install stuff without affecting t he main 'puter. Try a pip install virtualenv
Well, some of the examples I'm most familiar with come from Django, where you're writing web applications. In Django, you're routing each possible URL to a *view*, which is some sort of callable thing (most often a function, but can also be a callable class). So you have your view, let's call it `my_awesome_view`. It gets passed an object representing the HTTP request and returns an object representing the HTTP response. So it might look like this: def my_awesome_view(request): # Do your stuff here return HttpResponse('Whatever HTML we return is here') Now, suppose you want to restrict access to this view only to people who are logged in. You *could* go write out all the logic to do that check in your view, redirect to a login view if they're not logged in, and then redirect back to your actual view. But that's tedious. Better to write that logic once, and re-use it over and over. So Django has a function which implements that logic, and does it as a decorator. It's called `login_required`. So now you can just do: from django.contrib.auth.decorators import login_required @login_required def my_awesome_view(request): # Same code as before, but now people have to be logged in! Or suppose you want to control how the output of that view gets cached. Well, there's a decorator for that -- it's called `cache_page`, and you tell it how long, in seconds, the output of the decorated view should be cached: @cache_page(60 * 5) # 5 minutes of caching def my_awesome_view(request): # We still don't have to change the code here... Turns out there are tons of uses for doing pre- or post-processing (or both) in web applications, so Django comes with quite a few decorators to control this type of behavior. There are also decorators that do more complex things, but that should give you some ideas about how useful decorators can be. Pretty much every non-trivial toolkit or framework I'm familiar with in Python has some decorators lurking in it.
Copyright absolutely deals with use. The GPL lets you use and modify as you please, provided you don't redistribute the software. Read a EULA sometime. They will specifically discuss exactly how you're allowed to use something. 
This makes sense and is pretty handy. But why not have a AuthenticatedResponse or CachedResponse subclass and use that instead of decorating it?
&gt;Really? Yes. Arbitrary terms are hard to enforce. If I personally stumbled upon your software and read the license I would never use it on the off chance that you consider my use "evil". Also how do you define "military environment"? If you make an alarm clock app are military personnel allowed to use it? &gt;Well maybe I dont want to write free software anymore If you only write software to be able to distribute it under specific licenses because you "want to make a statement" then perhaps your time would be better spent doing something else...
iirc it's for managing packages for interpreters also, so not only stuff in virtualenvs.
very well explained! great work mate!
Yes there is: https://github.com/perone/stallion 
Two screencasts that explain the concept quite well, with examples http://neckbeardrepublic.com/tagged/decorators
Documentation here: http://docs.sqlalchemy.org/en/latest/orm/session.html#partitioning-strategies
Well, it's a direct consequence of the translation I gave, and [currying](http://en.wikipedia.org/wiki/Currying) is a natural and well established technique.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Currying**](https://en.wikipedia.org/wiki/Currying): [](#sfw) --- &gt; &gt;In [mathematics](https://en.wikipedia.org/wiki/Mathematics) and [computer science](https://en.wikipedia.org/wiki/Computer_science), __currying__ is the technique of translating the evaluation of a [function](https://en.wikipedia.org/wiki/Function_(mathematics\)) that takes multiple [arguments](https://en.wikipedia.org/wiki/Parameter_(computer_science\)) (or a [tuple](https://en.wikipedia.org/wiki/Tuple) of arguments) into evaluating a sequence of functions, each with a single argument ([partial application](https://en.wikipedia.org/wiki/Partial_application)). It was introduced by [Moses Schönfinkel](https://en.wikipedia.org/wiki/Moses_Sch%C3%B6nfinkel) and later developed by [Haskell Curry](https://en.wikipedia.org/wiki/Haskell_Curry). &gt;__Uncurrying__ is the [dual](https://en.wikipedia.org/wiki/Duality_(mathematics\)) transformation to currying, and can be seen as a form of [defunctionalization](https://en.wikipedia.org/wiki/Defunctionalization). It takes a function *f*(__x__) which returns another function *g*(__y__) as a result, and yields a new function *f*′(__x__,__y__) which takes a number of additional parameters and applies them to the function returned by function *f*. The process can be iterated if necessary. &gt; --- ^Interesting: [^Currier](https://en.wikipedia.org/wiki/Currier) ^| [^Worshipful ^Company ^of ^Curriers](https://en.wikipedia.org/wiki/Worshipful_Company_of_Curriers) ^| [^Function ^\(mathematics)](https://en.wikipedia.org/wiki/Function_\(mathematics\)) ^| [^Haskell ^Curry](https://en.wikipedia.org/wiki/Haskell_Curry) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cly87py) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cly87py)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
&gt; Also how do you define "military environment"? If you make an alarm clock app are military personnel allowed to use it? Thats all this lawyer speech - if you ask yourself could this be a military enviroment it is a damn good indicator that you are in one. &gt;If you only write software to be able to distribute it under specific licenses because you "want to make a statement" then perhaps your time would be better spent doing something else... I also don't want my own programs spying on me because they ended up in Prism. 
Yes, You absolutely right, shame on me. I was sure that its impossible. I wonder how session object will behave if connection with one of the databases will be timed out.
Thanks for the link... I looked around a little and found additional stuff. Here is a more detailed presentation (from 2013): http://talks.golang.org/2013/go4python.slide). Also may be of interest -- 2014 talks with go-for-{java,c} at http://talks.golang.org/2014/ Nice information but really does not make a strong case for different types of use cases (e.g. packages similar to scipy, numpy, django, ...)
&gt;Thats all this lawyer speech - if you ask yourself could this be a military enviroment it is a damn good indicator that you are in one. Except that if you put just "military environment" or "evil" in your license it's not clearly defined and you can sue pretty much anyone you want to. There is a reason EULAs and licenses are so long and well defined when restricting something. There is copyright law and yes licenses are 'lawyer talk'. And companies will never use your software because by using it in their code base they have to guarantee that non of their customers will use the software for anything "evil" either etc etc. You can publish your software under any terms you want, but what you're trying to do is: Publish non-free software with an unenforceable license. &gt;I also don't want my own programs spying on me because they ended up in Prism. But spying and/or intelligence gathering isn't necessarily a part of military environment. See the problem with not so well defined terms in your license?
What I am saying is that bioinfo had the resources and the strength to enforce those rules.
I'm not disputing that. Nor does it make 'your decorator has to return a decorator if it accepts multiple arguments, ie. `@decorator(arg)` effectively applies two levels of decoration.' any less bizarre. That is, the bizarreness is because of Python's way of implementing decorators, not because of currying-in-general. Haskell does not appear to possess this problem, for example; and currying in Python *without* the use of decorators does not either.
You can use [locals()](https://docs.python.org/2/library/functions.html#locals) as a trick for that. print( "Person {name} is {age}".format( locals() ))
Are there any notable situations that this would not work in? I'm trying to think of a time when a variable wouldn't be defined in local scope and I think it's just too early for my brain. :p
Only thing I can think of right now is if a variable is in global scope instead. Or in a different local scope. Python2: &gt;&gt;&gt; GVAL = "Global Scope" &gt;&gt;&gt; locals() {'__builtins__': &lt;module '__builtin__' (built-in)&gt;, '__name__': '__main__', '__doc__': None, 'GVAL': 'Global Scope', '__package__': None} &gt;&gt;&gt; def test_local(): ... local_one = "Local scope one" ... print "Local one", locals() ... def local_inner(): ... local_two = "Local scope two" ... print "Local two", locals() ... local_inner() ... &gt;&gt;&gt; test_local() Local one {'local_one': 'Local scope one'} Local two {'local_two': 'Local scope two'} &gt;&gt;&gt; 
I really like what you've done. The world map generator is a really nice touch.
Another excellent and simple to use python library is [TwitterAPI](https://github.com/geduldig/TwitterAPI).
Cool Idea - in line 18 I think you can omint the list, cause you create them in line 20 again But very very great idea
I always found that argument very forced. As a Python user who did try Go, I found it in no way a similar language, yet they spent a lot of time trying to tell people it was "Like Python for Compiled Languages". Go's pretty OK, I appreciate that it has so much Crypto in the pseudo-standard-library (the stuff in the google code repo that doesn't get installed by default). Their patent nonassertion pledge is a bit weak, but the main reason I didn't go much further was that it seemed too much like "C Done Right" and not enough like something truly new and remarkable. For that, I'm more excited by (and mind-bent by) Rust. Whatever its merits and flaws, I wish it wouldn't try to ride off the successes of the world's most amazing and _genuinely_ community-built language, Python.
I think you can ditch the import of the json module by replacing: json_response = json.loads(r.content.decode('utf-8')) with: json_response = r.json() 
A framework is a type of software library that provides generic functionality which can be extended by the programmer to build applications. Flask and Django are good examples of frameworks intended for web development. A framework is distinguished from a simple library or API. An API is a piece of software that a developer can use in his application. A framework is more encompassing: your entire application is structured around the framework (i.e. it provides the *framework* around which you build your software). **tl;dr** if you can incorporate it in your application, it's a library. If you need to structure all of your code around it, it's a framework.
Neat! We're a small company too and PyPDF2 is *exactly* what we needed for a project. Had no need for any support. It just worked.
sweet - gonna throw this in my irc bot to display global visitors 
This little script looks excellent! Code is very clear and easy to understand. Only nitpick I have to offer: on line 34, I would replace print("{}, {}, {}, {}, {}".format(json_response['ip'], json_response['city'], json_response['country_name'], json_response['latitude'], json_response['longitude'])) With this: print("{ip}, {city}, {country_name}, {latitude}, {longitude}".format(**json_response)) which is shorter and still quite clear, I think. The main other thing I was confused on is why latitudes longitudes are passed around as separate lists, rather than as a single list of `(lat, long)` tuples, which makes more sense to me. But looking at matplotlib it looks like the basemap expects this format so.. nothing much to do about that.
hi @claird, I wrote that little tutorial and I think you're being modest--it is a very nice library and I learned a lot just by reading the code. You've already done a lot to improve on the original pyPDF and still kept backward compatibility. Thank you for all that work! I use PyPDF2 daily and it is very important to my workflow.
Awesome example! 
You can replace "get_ip" function content with a f.readlines(). And that `ip_list = [line.strip() for line in f]` line is not very memory efficient if you have a really big file, maybe you can replace it with a generator. Also I suggest you to read that article about a mutable default arguments: http://docs.python-guide.org/en/latest/writing/gotchas/ Oh, and maybe you can add some cache for freegeoip.net requests, since some lines can be duplicated and so on.
The point of the GPL is that you need to release the source code under the same license. And, depending on how your code is integrated into another product, it (the product) as well. There are lots of documents that describe very clearly what uses would be covered by this. However managers just hear "we will have to give away our product for free" and don't use it. Another thing to consider is that even if you take GPL code, extend it and use it internally, *you don't have to give it to anybody*. If you have some kind of "product", only your customers have the right to it (they, in turn, could just give it away, but don't have to).
Nice, thanks! Though, I am not sure if defining empty lists as default values for arguments is a good idea. For this example, when everything is called once it's Ok, but any other usage, e.g. use this as a module, will share all lats and lons from calls with default values. Our simply saying each call will return not only values from this call, but also all values from all previous calls. 
I just use [gspread](https://github.com/burnash/gspread). It's a great module that makes all of this really easy. 
How hard is it to make a framework without previous experience? I am working with robots and I am thinking of building something which would work with a lot of gesture-recognition devices.
&gt; In practice, nobody sits down and says "hmm we have to program, but which language should we use?" in startup land it happens at least once. usually it's an internal dialog and it may be a very short dialog. 
I have several projects in this vicinity. While I recognize how wonderful matplotlib is, I mostly feed results to [SVG-coded maps](http://www.ibm.com/developerworks/library/x-svgclientside/), which are marvelously programmable and thoroughly "Web-ready". Also, among several useful geolocator services, I principally rely on [Google](https://developers.google.com/maps/documentation/javascript/examples/map-geolocation).
Well, it's not always easy to determine when a framework is the appropriate choice, but most of the time it's not. The problem is, you're constraining the structure of application developed with a framework *a lot*. That means you must think very hard about the structure that you're forcing upon them, because it must be appropriate for a lot of use-cases. So generally it's preferable and easier to make a library as it allows its users to be more flexible. A library is just a set of functions and classes containing some particular functionality. You could build a library that unifies a lot of gesture-recognition devices under a single interface, so all of them can be used in the same way. That would be pretty rad.
That is the intention! And then I want to find the WASD of gestures. Is a library similar to an API?
Ok, here I am. First of all, thank you for the interest! So the overall design is the following: - vaitk: an independent toolkit with an interface as close as possible to Qt, but oriented toward the terminal. - vai: the vim-alike editor built on top of vaitk. vaitk is divided into a core part (which handles non-"gui" stuff, mostly the object hierarchy, timers, and other low level concepts) and the gui part (which handles widgets, windows, and so on). If you know Qt, you should find yourself at home. At the moment, what happens is that the VApplication has an exec_method. There, the event loop happens: keyboard events are fetched, converted into VKeyEvents, and delivered to the focused widget. This triggers stuff that enqueues other events (e.g. show/hide) and eventually reaches the point where the widgets are marked as "need update". Finally, the event loop checks the full widget tree, and sends paint events to each widget that needs update, plus all the widgets that may be damaged by it (e.g. if a widget is hidden, the underlying one needs to update). On vaitk, what is needed is the following: - More porting of Qt functionalities. In particular, layout management (the layout manager resizes and repositions the widgets before issuing a repaint), and other widgets (dialogs, comboboxes, and so on). - Tests for all this stuff. - general performance improvements. - secondary: get rid of ncurses, because it interacts badly with threading. Eventually get rid of the Threading approach to get the keyboard events, but then a proper select() strategy is needed to handle timers, and it must be portable. so, not easy thing. For vai, it's mostly MVC. I do a lot of experiments there because I am writing a book on MVC in parallel, so it's also a platform for experimentation. The idea is that you have the logic in the controllers, and they are in charge of performing actions on the models. All the models are visual-component independent, and contain the textdocument, the state of the GUI, etc. It's plain and simple MVC, nothing fancy. The TextDocument contains the text, but it's "surrounded" by additional classes for metainformation. This stuff is in progress, but I have LineMetaInfo as a successful implementation. The idea is that Linters, git, and other stuff that scout the document can put meta information on the document itself. You have three types of metainfo: per document, per line, and per character. Of course the big issue is to keep everything in sync. Textdocument Metainformation (but not only) is added by two types of analyzer: synchronous and asynchronous. This is not implemented yet, but there's an initial design. Synchronous happen as you type (e.g. tokenization). Asynchronous are "in the background" (e.g. they periodically scout the code for new autocompletion files, or run the unittests as you are working on them, so you see if the test or function under test you are working on right now is actually passing). Another async could scout the code for TODO comments and mark them in a lateral pane. You name it. I am very open to better design suggestions. As I said, I am mostly doing experiments in some cases. At the moment, I am working on release 1.4, mostly addressing bugs and performance issues. Things that are needed right now are - unittests, in particular of vaitk. it would be a good introduction to the overall code structure. - A more specialized thing I need is a merkle tree metainformation, - a better autocompleter, possibly giving complete information about the signature. I've seen something for python already, but I don't know other languages. - If you feel adventurous, you can start thinking how to make a better parser for the commandbar (the current one is very basic), or how to structure a plugin downloader/installation. - Of course, you can always take some command from vim and implement it (generally as a command, see the commands package dir) or any of the already present issues, but ask me first because some of them may be outdated and badly explained. Please create issues on github, so we can keep track of them. My approach is that I implement stuff that works, and refactor it merciless as I go and see that a common design emerges. I have no problems rewriting a whole subsystem if needed. If something stinks, I change it. 
These days I see people sometimes say "API" when they mean "HTTP API". I really dislike that confusing practice, but it's useful to be aware of it in discussions where people use the word "API". 
When it comes to Excel, Pandas has a great [excel reading capability](http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel) You can graph with Pandas in excel, but this might work after a quick google: https://xlsxwriter.readthedocs.org/
Maybe use nuitka for the exe
Understood. Thank you, and good night. I'll look at the stuff in more detail tomorrow.
Yes. This will work. I have done essentially the same thing myself. But, there may be a little difficulties here and there. First of all, a "macro" is a set of instructions within Excel using Microsoft VBA (Visual Basic for Applications). A "script" refers to the Python program, in this case. In order to read from Excel files, you would need the third-party library called xlrd. To plot the results, some kind of plotting library, like matplotlib (wxPython has a very simple plot widget as well). To make the program runnable without Python being installed on the coworkers' computers, some kind of packaging library, like py2exe, pyInstaller, or cx_freeze. If you want your program to have a nice GUI (as opposed to just a commandline interface), then a GUI widget library as well, like wxPython or pyQT. I have done all of this, but I used Python 2.5, which is now three versions out of date. But, it still got the job done, so my attitude is, at least for that purpose: who cares? To get this all going well is not trivial if you are new to all of it. The actual program you write may wind up being 50 lines of Python code, but getting there may take weeks, some of which is just installing and making versions play nice with each other, but weeks in which you'd learn much. Take good notes in a dedicated notebook.
I don't think nuitka is ready yet, and OP has much better uses for his time than fighting to get that to work, if ever at this point (but it's on a mission to be ready at some point, so no disrespect to nuitka).
What do you mean by, "I didn't want to do this in VBA since I want to improve my programming skill." Do you mean algorithms or understanding documentation? Like the others have said, if you choose python the actual coding will be minimal but you'll spend a lot of time setting everything up. To be honest, what you want to be doing sounds perfect for vba. Especially in a professional situation, many companies allow users to run macros but not they can't run .exe. If you want the programming task to increase your knowledge then maybe you can include user forms in some of the macros? They can often make simple macros appear more professional and can be very useful if you need complicated user input. Maybe you could ask the user what kind of graph they would like to export? 
You may want to check out the decorator module which helps in creating decorator functions: http://micheles.googlecode.com/hg/decorator/documentation3.html
Playing the devil's advocate but you *can* reference other sheets and external sheets within an Excel cell. I'm not sure what's happening VBA script-wise but if the script is performing processes that are outside of the native capabilities of Excel then the script is not redundant in its use, and you can ignore this statement. It's just that my IT sense is throwing up red flags at "wonky shitty VBA scripts" being a hacky workaround for pulling data from other sheets.
Dude, we heard you the first time...
Why "ever"?
It's good to hear from you, /u/esdio and /u/tiarno. One of the enhancements we're considering is to make [a targeted Twitter feed](https://twitter.com/PyPDF2) useful. Would that interest you?
Same idea, different implementation. So what?
Have you considered that you're unpopular because you're being a dick, not because of your opinions?
Grab a proper gitignore from https://github.com/github/gitignore as you have committed .pyc files. Really work on your commit messages, because this is unfortunately nonsense: commit 7d164c34400061ce901631f2502e82009e393f2b ... Updated README, setup.py bin/lback-server | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) Your setup.py is making os.system() calls embedding `sudo`... Edit - Nothing here really makes any sense. You have .exe binaries in your ./dist/ folder, for a utility supposedly targetting linux? You have a ./bin/storage.db SQLite database containing typo-d table names? Edit - The linked repo's majority language is Tcl and it's tagged Tcl on github. Amazing?
I used to work in a reporting group that relied heavily on excel, vba, python, C#, etc. all in a Windows environment. I would say from my experience this is not an easy task from a python perspective. The problem is the other users not having python, it will be a pain unless you can use some powershell to deploy python to the machines you want. This isn't too hard unless group policy forbids it. I've never had much luck myself with the python--&gt;.exe utilities. I just seem to always have issues. Another option would be building a small utility in C# that the user could use to point at all of the sheets and create this output you want. C# is a decent language and has hooks into excel, so it will be very friendly between the two. I would go for the this option myself, the coding will be more but it will deploy much easier. Also, once you have them using something like that, it's much easier to add too it and get more hooks into what they're doing.
&gt; After no hope of finding my '.photolibrary' file It's cleverly hidden in your Pictures folder. Go to the App Store, install iPhoto, and there basically is no step three.
I meant "if ever" for the OP *given the current state of nuitka*. That is, he could work for three months straight to get it to work, and it won't until Kay releases a new version that works with the OP's needs. E.g, right now it doesn't work with wxPython, but it probably will at some point.
I have a few criticisms of this: 1) This is opinion, but as someone working on a medium-sized team, you should follow PEP8 guidelines. This means underscore_casing rather than camelCasing for your functions. 2) Your API is pretty unusable because you don't use classes to encapsulate state requiring you to pass around the client. You should at the very least be encapsulating the ability to list and get documents with the client. You should probably have a Spreadsheet or Document class that encapsulates the clear and write functions. 3) Your install.py shouldn't have to be called explicitly. Your script should check for the existence of the config file and, if it's not there, run the logic in install.sh. 4) You should allow the user to use more than one config file by using a command line argument with a default. Look at the argparse module. 5) helpers.py is your actual module. \_\_init\_\_ is just an example and would have worked better as an example.py file. Your \_\_init\_\_ should probably be where the config file is loaded and a client instantiated. Your code could either go into \_\_init\_\_ (a bit messy) or in something named client.py rather than helpers.py. Again, those aren't helpers. Those are your module. 6) You create an empty list to hold your data and then append the header row. There's no need to do this in two steps.
Hey thanks for the thorough feedback, this was only really intended as a kind of walkthrough to people getting started, not as an acutal scaffold for a project.
Totally, COMPLETELY inappropriate for reddit, breaking main reddit rules. Sucks for you, but please delete this post immediately.
You also can convert matlab functions or octave functions easily to python. I am converting the NIST water steam tables that I found in the Xsteam matlab/octave package. So the idea is to look for the matlab code you want and convert to python or you can call the matlab or octave function from python. If the code is not available you can reverse engineer the matlab function or package. I am reversing engineering the fuzzy logic toolbox by the black-box testing. In addition to Python, I would use octave to test matlab code and functions and WxMaxima symbolic package that is excellent for algebraic and symbolic computation. 
&gt;Stallion is a Python Package Manager interface created to provide an "easy-to-use" visual and also a command-line interface for Pythonistas. Today we have many nice distribution utilities like pip, distribute, etc, but we don't have a nice visual approach to inspect current installed packages, show projects metadata, check for PyPI updates, etc. 
Which rules? Genuinely curious.
I feel like Go is interesting, but it's not very much like Python and any comparisons are pretty forced. * There are no generics. You'll sometimes be writing the same function twice to handle different type inputs. This is nice because it's explicit, it sucks because you have to write, essentially, boilerplate. * There are no classes. Long inheritance chains suck, but encapsulation and duck-typing are core concepts to Python. Without them, you get back to having to writing the same code more than once. * I know it's beaten to death in Go discussions, but having to catch an error on every method call isn't very Pythonic. There's a difference between errors not passing silently and being required to deal with possible errors on every function call. I think Go's a great language for building concurrent software, but I'd never use it for personal projects. I don't think it's "fun" to program and I don't think it was designed to be fun. It was designed for large teams and the decisions like removing inheritance and classes and forcing you to handle errors immediately point to that purpose. Even after 6 years, I still have fun with Python and use it, at the least, to prototype most ideas I have for personal projects.
Packing is a seriously underused and under implemented idiom in modern langs.
All of the information I've supplied is public information, as referenced by his Freelancer profile of the same name: https://www.freelancer.com/u/brendanrossdev.html
For starters, as a subreddit, this has literally nothing to do with Python except for the fact that the project was in Python. Second, this is why: &gt; So just a beware to anyone who might google his name looking for references, watch out for this guy! He's just using reddit defame an individual, including giving the individuals home city. Pretty sure that would fall under witch hunt rules.
How much are you prepared to pay?
A crc is a number that represents the contents of a file (think of it as the hash code of the file), if you use an integer value that means the entire contents of the file are stored in 4 bytes, this means you can check if 2 files are the same without having to check the entire contents. If 2 hash codes are the same, then the contents MAY be the same (there is a random chance of 1 in 4 billion that 2 files will have the same crc value), of course if you have 10,000 files you may find 3 or 4 files share the same crc value, but it reduces the amount of work to check them from 10,000 to 3) 
Correct, to expand a bit: def get_lat_lon(ip_list=[], lats=[], lons=[]): ... should be: def get_lat_lon(ip_list=None, lats=None, lons=None): ip_list = ip_list or [] lats = lats or [] lons = lons or []
Thanks for your help but I installed iPhoto from the Mac App Store and it just created a new photo library :( 
For one who doesn't know how the file-system is constructed; could you explain further how the low-res and high-res names are sorted? Low-res | High-res file000979 | file000978 You could always make a program to check the various file-names, compare the names, could always use regex for that, and then continue using pillow to get the ratio. When the program finds what you are looking for: make it save the file in a different folder. I recommend, during trial, that you add a piece that stops the code after ten images, in case it doesn't work perfectly on first go. 
Thanks for the reply man. It's just standard file system but there are up to three duplicates. It just happens to be organised so as the first file is the highest res and the second and third are lower if that helps? Your info on Regex and Pillow are really useful thanks for that :)
I really like pip but when i start working on a project i always end up using zc.buildout + mr.developer.
Decorators with arguments don't return decorators, they return wrapped ("decorated") functions. The arguments passed to a decorator "set up" the function when the decorator is applied to the function (on import) while the arguments passed to the decorated function are the arguments actually passed to the decorated function (at calltime). Here's a simple example: def hotkey(key, **kwargs): def wrapper(func): HOTKEYS[key] = functools.partial(func, **kwargs) return func return wrapper @hotkey('+', value=5) @hotkey('-', value=-5) def change_volume(value): player.volume += value This creates two hotkey functions in a registry (HOTKEY). + will increase the volume by 5, - will decrease it by the same. You can still call change_volume with whatever values you want. There's only one level of decoration and you aren't returning a decorator but a wrapped function.
The script defaults to the current directory. Add a path as a command line argument to check another directory.
What is the sequence in the names? low | high file000968, file000969 file000978, file000979 Trying to figure out how the number-sequence is, then you can easily check for that sequence and sort them by that. Even start by adding all to a list, so the program can work in peace and quiet after you got all the names. import os, re path = '/some/path/' for root, dirs, files in os.walk(path): for file in files: #Check vs regex, add to list. I do not know exactly how the files are named, but you might need to check the first or second number before searching which one might be high- or low-res. Python's regexp is rather simple to use. https://docs.python.org/2/library/re.html#regular-expression-objects http://pythex.org/ I'm unsure that if I have the energy to write the program for you this evening, but at least I can give you the pointers in case you, or someone else, are up for the task. :)
* You're abusing globals in the worst way. Your countLines function shouldn't use globals at all. It should use locally scoped variables and return the results. You went through the trouble of putting your logic into a function, but that function will always appear broken if you just import countLines and expect it to do anything useful. Also, the global for exclude isn't necessary. __global__ isn't needed for reading. * I don't see a use for the main if you have a \_\_main\_\_ and it's always felt unpythonic to me to structure a script in that way. Just put the main logic in \_\_main\_\_. You've already put the actual logic of your script into a function which is good, so this doesn't net you anything other than more lines of code. * Your lines 14-24 are as unpythonic as it comes. Use the __in__ keyword to check membership instead of looping through and doing comparisons. Those 11 lines reduce to 2: if filename[0] == '.' or filename[-1] == '#' or os.path.splitext(filename)[1] in exclude: continue * Because sets are faster than lists for checking membership, exclude should either be set([..]) or use curly brackets instead of square brackets for your list of excluded file extensions. This isn't a big deal since your exclusion list is small, but it's good practice. set([0, 1, 2, 3]) == {0, 1, 2, 3} * countLines should be count_lines. Try learning PEP8 guidelines early and follow them often. * Line 30's weird. ```numlines += len(list(open(.., 'r')))``` is cleaner. * If you use string formatting you won't need to cast ints to strings for printing like you are. It's handled automatically when using formatting. Either of these works. The second is the more modern Pythonic way of doing things. print "[+] %s LOC %s files." % (numlines, numFiles) print "[+] {} LOC {} files.".format(numlines, numFiles)
Using PILLOW: check the ratio. The high-ress should have a larger ratio. Check width and height for both landscape- and portrait-orientation, since the width and height will be in reverse at those points. (If I'm not mistaken.) if (landscape[0] == width and landscape[1] == height) or (portrait[0] == width and portrait[1] == height): Perchance not an exact example, but you get the idea. :) Go for it! Just give me a shout if you get stuck and I'll see if I can help you. Just send me whatever you got and I'll see what I can do then. :)
Well damn dude. I'm not a python guy. I was just looking for a quick solution to a problem and threw this together. I thought some people might find it slightly useful. I'll take it down if it's **that** bad
It's probably worth mentioning that frozenset, an immutable set, is also a thing in the standard library.
From one person who speaks plainly and bluntly to another: Dude, tone it down a few notches. You've exemplified the worst way of critiquing a person's efforts. 
Why post if it's either not very good because you don't know what you're doing (not that useful to others for learning) or don't want feedback (useful to yourself)? And the global stuff transcends Python. You shouldn't be using globals like that in any language. [edit] And as I mentioned to the other commenter, what about my critique was so harsh? It's simply a review. If you can't take that level of review considering I had no ad homs and didn't insult anything (other than maybe calling something unpythonic, which isn't an insult), you'll never make it in the industry.
&gt; There's only one level of decoration and you aren't returning a decorator but a wrapped function. If you 'aren't returning a decorator but a wrapped function', how do you justify the line `return wrapper`? `hotkey()` does not return a wrapped function, it returns a *function that returns a wrapped function* (ie. a decorator). 
If you go back on github I have created a Utils.py file, have I done this correctly? Also I changed TicTacToe - Host.py and TicTacToe - Client.py to Host.py and Client.py respectively. 
Fair enough. But I would say that your comment also shuts down any further conversation. If it were me, I would have lead off with "I can see some room for improvement, would you like some pointers?". Most of the time they will jump at the chance to improve their coding skills. However, your bluntness sounds a bit like a job or a school review, which is something I feel the OP wasn't necessarily looking for, although it is helpful. Please be considerate to those who are not as skillful. I'm sure you were terrible at Python in the beginning, and probably spent a lot of time to get a program to work like you wanted. I'm sure the OP spend some time on this, which is what we should encourage.
&gt; Assuming that the square brackets represent they're the same image Do you determine a set of files are the same image based on the file name or by examining the image?
This article made me realize that managing dependencies in Python sucks. Finding and updating outdated packages, removing unused dependencies and using a different set of dependencies for different environments is are sutations I often got in and are not as easy to manage as I think it should. 
I'm surprised this was basically built from scratch, it seems like the perfect lib to build on top of something like the SQLAlchemy Core layer. You'd get multiple database support and likely other things for essentially free
&gt; So when we increase the count of values an order of magnitude, the time Python takes to calculate membership in the list increases *about* an order of magnitude. It's worth noting that `range` isn't a list in Python 3 and integer lookup in `range`s is `O(1)`. Any other type seems to still be `O(n)`, though.
&gt;in startup land it happens at least once. Right, but it takes the form I described, namely: "Language choice is dictated by the problem at hand, and the available solutions in a subset of languages." You work from the problem towards the language. Not the other way around.
&gt; if filename[0] == '.' or filename[-1] == '#' or os.path.splitext(filename)[1] in exclude: Alternately, since endswith can take a tuple of strings, change exclude to a tuple, and change this line to: if filename[0] == '.' or filename.endswith(exclude): continue That may be a matter of taste, but I find it a bit cleaner. And, as is, yours breaks strict PEP8 compliance for being over 79 characters.
Try using pfrank to rename the files, you could use a pattern of DATE-TIME xsize-ysize.jpg You can download it from http://www3.telus.net/pfrank/ 
The problems most (web) startups are trying to solve are all pretty much the same with respect to language. C#, Python, Java, Ruby, Perl, PHP, JavaScript, Go, Clojure, all of them work fine. There's no "right tool for the job" here aside from the one you already know.
I am beginner to Python and when searching in the internet I got an excellent list of python resources listed at http://www.cotutorial.com/ 
There are definitely problems with Python packaging (scientific libs not really listing their deps consistently for example) but I think the solution is 90% discipline and 10% tooling. Most of the tools listed are unnecessary if your devs really think about their dependencies as costs. pip freezing to create a requirement file is easy but error prone and I don't think we should encourage that workflow as a community. My team has around 40 python projects, 10 of which are packages. Some things I've learned to avoid: * Pulling in heavy deps for a single function that you could rewrite to your needs * Hard pinning deps in your packages so they are brittle and require a chain of bumps in your apps when they're updated (and also decrease compatibility) * Listing top level packages as well as all of their deps in your requirements files. pip freeze does this. * Not hard pinning deps in your apps to a specific version * Assuming your team will arrive at a workflow organically without conversation * Pinning to git hashes (especially in your packages, dependency_links doesn't really work) 
http://effbot.org/imagingbook/pil-index.htm in particular check out the section on [Image Module](http://effbot.org/imagingbook/image.htm) and look at the method named 'paste'. 
You were the one who treated me like some idiot who can't use fucking "as" in an import. Misinterpreting others is condescending assholery.
Ouah… of course I heard about unpacking before, but this example is striking! And the best is that Python matches the correct element of `json_response` with the element between curly bracket you want to print… really impressive! Thanks for the tip I'll add that!
You complained about the name of the mysql python wrapper _written by the dudes who maintain mysql_. I stand by my original assessment of your character. &gt;m8
&gt; You can replace "get_ip" function content with a f.readlines(). That was my original code, but it creates a list where each element ends with `\n`, that's why I use the `strip()` function on each line before putting them in the list. &gt; And that ip_list = [line.strip() for line in f] line is not very memory efficient if you have a really big file, maybe you can replace it with a generator. You're right! However the original idea of this script was to be used with a limited list of IPs (such as the users from a BBS). I will have a look at generators, thanks for the tip!
Thanks, that sounds like a good idea indeed. Originally I didn't put empty lists as the function arguments, but then I was thinking in a new future I might want to use an existing list of IPs and append to that list… however my current implementation is not super smart indeed. I'll look into that!
Like MaturinTheTurtle said, you're modifying the list as you iterate over it. You can avoid this problem by iterating over a copy of the list instead: ```for i in mylist```**[:]**```:``` The '[:]' creates a copy of your list using the list slice feature, you then can modify the original list without causing the iteration to act in an unexpected way. 
I was addressing *why it wasn't more popular*! Using what I've seen as organizational and personal antipatterns at WORK. Fuck yourself, you fucking dense tool.
Since you wanted to know why it was happening, I will expand on what /u/MaturinTheTurtle said. More than likely the interpreter isn't really stepping through the list like you would expect for a c style linked list, rather it is using an internal counter to step through the list by element reference. Then it is rebuilding the list as soon as it removes an element. Here is a meta breakdown: counter = 0 while counter &lt; in mylist.length: if mylist[counter] &lt;= 5: copy all list elements except the current element into newlist delete mylist rename newlist to mylist increment counter So before the first pass through the list it looks like this: counter = 0 mylist = [2, 4, 6, 8, 10] During the first iteration through the if statement mylist[0] equals 2 so the element is removed. Then at the beginning of the second pass it looks like this: counter = 1 mylist = [4, 6, 8, 10] So on the second pass you are now evaluating against mylist[1] which equals '6' and thus skip the value '4'
Because i is value not key，when i = 2 my_list will remove it.
Having done things very similar to this, no, it probably won't work the way you've described. Every aspect is possible, it's just not practical. There are two ways this could work out: 1. You can do all the data processing and data distribution from a single computer you own, and everyone else simply consumes it. At a simple level, that might mean getting all the data sent to you, processing all the data nightly or on a schedule, and putting it in a shared folder or Dropbox for people to view. 2. You use tools that are native to Windows and this context. VBA is an option, so is PowerShell. Then you can try distributing it to each person. Distributing, teaching people to use, and supporting is often exponentially more work than actually creating a script that does the job and that's WITHOUT throwing in complications like getting your Python app to behave on strange Windows machines. If you have no experience with Python in this respect, I would strongly consider VBA or PowerShell. Even if you go with #1. Their existence is to automate tasks like this on Excel/Windows. The reason why you'd ever do them with Python isn't because Python is somehow superior, but because you are somehow invested in using Python for technical or human reasons.