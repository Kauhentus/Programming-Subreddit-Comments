Thanks very much for your detailed answer. I'm just reading through and trying to digest it all now. This is a big help :)
&gt; ...i'd still like to see open source code and compiler/build commands You mean [this code](https://github.com/zeux/meshoptimizer/blob/c93ba0987baa84bd73b61edf1c0ba7ba2e48df4b/src/simplifier.cpp)? 
I have a lot of things to ask. So; 1. Why does you need new line at the last printf? Could you kindly elaborate? 2. That \\\\n and \\\\t thing was a copying error. I don't know how that happened? On that note can you please elaborate what this " \\\*= " is or how it works or at least link it, cuz i cant google it properly 3. As you said using int to print float is not sytactical error. But i should still fix that right? 4. Also can one data type not hold(as in assignment and taking input with something like scanf another data type? Like using int to store float/double or vice versa. Cuz i haven int types hold character and stuff. All of them don't show any error, does this mean it is viable feature or an error that is overlooked by modern compilers. 5. I do not understand what you mean by setting flags? " -std=c89 -pedantic -Wall -Wextra -Werror " Is it a debugging thing? &amp;#x200B; 6. Most importantly, when you say C99 what do you mean? Like 1999 version of C? Cuz my professor said something similar like we are only allowed to use ISO 98 standard or something along the lines. For example, we cannot initialize array at run time as such: int n; n takes stdin; int Arr\[n\]; Also, my program runs without including respective header files. And, the one you mentioned about 1/2 giving an int value 0 giving the right output. When it should have been something like 0.5 or 1.0/2 or 1/2.0 ; just anything that make it a floating variable &amp;#x200B; Can you tell how i can fix this complications ? As it modify my compiler to ISO 98 standard ( i guess). Cuz i cant find it properly on google, My IDE is Dev-C++ 5.11 My Compiler is TDM-GCC 4.9.2 32-bit ( i think) &amp;#x200B; Finally, i am sorry if i bored you with my beginner-esque troubles and queries? &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Yep it worked. What a silly mistake i made. 
Please post articles as link posts next time.
Dude, I'll always upvote you because of your username LOL
Maybe GCC (GNU Compiler Collection) and gcc (the compiler) are more conventional.
yeah and the adjusted versions he mentions. After all the article is about all the variations. Apparently there's a "modern" C++ variation and a pure C variation of this code. 
I like these types of performance posts, but I found that the conclusions were unclear until I re-read the tables a few times. Ignoring compile time--because, tbh, with incremental compilation it's not a gamechanger if it takes 500 ms to compile a file--and ignoring the inter-compiler comparisons, the actual runtime (/w release optimization) performance changes in gcc were: - Baseline: 572 ms - Custom probe set, rather than std::unordered_set: 460 ms - Custom sorting algorithm: 334 ms - Use raw pre-allocated arrays rather than std::vector: 318 ms - Custom memory allocation stuff: 320 ms - Switch to C compiler: 320 ms So, around a 40 % speedup from switching algorithms to something more suitable, ~5 % speedup over that by faffing around with raw pointers, memory allocators etc. and 0 % speedup by switching to C. The title "is C++ fast?" and the conclusions that the new version is faster by comparing the worst-case MSVC debug build runtimes with eachover somewhat obfuscates the fact that most of the optimizations were done at a higher level (algorithm changes), which is easier to do when you have high-level abstractions and a lower LOC codebase to play with (e.g. when you're using C++ and have library functions to swap in).
Also, there are command flags to bypass the file extension recognition. For example I used this quite frequently to analyse C code in compiler explorer, which used to support C++ only.
IT IS SUPPOSED TO BE LONGER THAN INT!!!!! [and thank you sir](https://media.giphy.com/media/il5XqHUQxAdVe/giphy.gif) 
That is not completely correct. There is a big variety of scenarios in which different compilers perform better code than others. And this changes with compiler versions quite noticeably. There are many many benchmarks that try to measure it and numbers change a lot. Also, intel compiler is great, no question about that, but it cheats when it detects a program that looks like a benchmark and replaces it completely for hugely optimized assembly.
head is used to fill the structs and after filling it gets the new value head-&gt;next to get into the next struct pb current is used to remember where the first struct began the \*next in each struct remembers the address of the following struct
Please try to format your code. This is hardly readable (especially on mobile). Maybe just use pastebin. 
Really sorry for that . Idk if there is option to format code as I'm on phone
I am not sure but I think reddit is able to show your code properly if you just indent it by 4 spaces.
Ohh..ok . I did not know that
You should be able to edit your post. Just give it a try 
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; int main(int argc, char** argv) { int i=0; char arr[50]; while(1) { printf("enter -&gt;"); fgets(arr, 50, stdin); if(arr[0] == '0'){ break; } while(arr[i]!='\0') { printf("%c",arr[i++]); } printf("0 to quit\n"); i=0; } return 0; } Sorry, I have no time to think about it a lot, but I think this does the thing you want.
I appreciate the performance focus of this article, and found some of it pretty interesting (i.e. the domain specific sorting), but all of the comparisons with the STL are in pretty bad faith, IMO. &gt; However, in our case we need to sort to be able to process better edge collapses first based on a heuristic - and the heuristic is a gross approximation so the extra error our sorting introduces is not noticeable. This technique is surprisingly useful in other domains where you don’t necessarily need an exact order either. ... &gt; However, the effects on performance are very significant, especially on debug performance in libstdc++ (most likely std::sort is very slow in debug there) but the gains in release builds are also exciting. What is not obvious from this graph is that sorting got so much faster that it almost completely disappeared from the profiles compared to the other work - the entire algorithm runs “just” 1.35x faster, but the gains measured on just the sorting code are much larger, 117 ms -&gt; 10 ms in release builds. Of course doing a sort with approximate equality will be faster than a sort with full equality, I'm not sure what the point of the comparison to `std::sort` is because they've A) re-implemented the sorting algorithm itself to something that better suits the domain and B) aren't using the same notion of equality as what there is in the STL. &gt; Let’s try to replace the only STL component we’re still using, std::vector, with a really simple dynamic array - we don’t need resize or push_back in our code, all arrays are initialized with the right size. So this doesn't sound like the same use case as `std::vector` solves in the first place - why not a preallocated free list of `std::array&lt;T, N&gt;` and avoid any hot path (or runtime, if you know how many arrays you need at compile time) array allocations, if you really want to get the best performance (while maintaining type safety and leveraging the STL)? You could even provide a custom allocator to `std::vector&lt;T&gt;` to only allocate memory from a preallocated bucket and achieve the same results and sticking with `std::vector&lt;T&gt;`, if you were so inclined. &gt; C++ is an unforgiving language, but, given enough time and effort, it’s possible to get good performance - assuming you’re willing to question everything, including practices that are sometimes believed to be universal, such as the effectiveness or efficiency of STL or CRT. The STL represents the lowest common denominator of data structures that are fully generalized - anyone writing performance critical code should already be aware of that and replacing them in the hot path if they're identified as bottlenecks. Of course they're slower than domain specific implementations that only have to offer a minimal API surface. The beauty of C++ is that if you don't want it, you don't use it and you don't pay any cost for it. Additionally, the STL isn't known for being efficient - it's a convenience library that exposes a group of standardized data structures that suffer from the same design trade-offs as any other data structure. 
``` arr[i]!=NULL ``` `arr` is an array of chars (8-bit integers). `arr[i]` is a single char. `NULL` is of pointer type. You are comparing integer to pointer. It works, but is semantically incorrect and may not work in environment, where NULL is not directly comparable to 0. You should compare it to value 0 or null byte `'\0'` (which are the same thing essentially). ``` printf("%c",arr[i++]); ``` The character will not be printed unless `arr[i]` will be a newline (`\n`). Output is buffered. If you want to print a character immediately, turn off buffering or force buffer flush with `fflush(stdout)`. ``` printf("again y-1 n-0"); ``` Again, buffering problem. Add a newline at the end to send buffer contents to output (`"again y-1 n-0\n"`). ``` scanf("%d",&amp;ch); ``` This will choke on non-digit. Avoid using `*scanf()` for user input. Fix those problems, then try again. Your interpretation of the error may not be what you think it is. P.S. Why don't you just read character by character and drop out with error when input is not a digit. Finish reading on newline or null byte, then use `strtol()` or `strtoll()` to convert string to numeric value.
C++ suffers from the OOP overhead, whether you want it or not. In C, if you want OOP you can, but it doesn't inflict it on everyone else
sure, but interested to know why it makes a difference ??
The rtl\_433 program looks interesting. Could you tell a word or two about your sensors ?
A link post is registered with reddit so reposts and crossposts are detected and listed. Also, you get link karma instead of comment karma for them.
I recall once reading that (provided the compiler does not optimize) `i++` creates a copy of i before incrementing, whereas `++i` does not, so the latter has measurably better performance in large loops. I’ve not verified that claim, but it sounded plausible since the former returns the current value of `i` before incrementing. I have a hard time believing that modern compilers wouldn’t account for this in a loop and optimize it out.
No blog spam please.
A `char` is 1 byte, but the `%x` and `%u` format strings take an `unsigned int` argument. When you pass in your `x` argument (value -1 or 0xFF), it will be [sign extended](https://stackoverflow.com/questions/9715984/printf-type-promotion-and-sign-extension) to an `int` type (value -1 or 0xFFFFFFFF) and then converted to `unsigned` (value 4294967295 or 0xFFFFFFFF). 
ahh ok I knew sign extension played into it but couldn't figure out why it was being sign extended. Thank you.
ok,ta
From the second sentence: &gt; C is known to give programmers plenty of opportunities to **blow their own foot**. Emphasis mine. I'm not saying this is an indictment of the content itself, but it definitely doesn't set my hopes high.
{0} just initializes the entire array to 0. If argv\[1\] is smaller than x\[\], then any contents after the null terminator copied in from strcpy will be undefined in the second example, but zero in the first.
Thanks! Not sure why I had so much trouble finding an answer on this.
Suresuresure. 0\. (or 6? Markdown always breaks lists.) ANSI C a.k.a ISO C a.k.a. C89 a.k.a. C90 was the first standardized definition of the C language, and nowadays virtually any C compiler you’ll ever encounter supports C89 or some close approximation. C99 was the standard they finalized in 1999, and C11 is the newest finalized standard (2011). Each newer language standard adds new features, deprecated or removes old ones, and clarifies things that were ambiguous. Your professor was probably saying something like ISO C89. (Although there’s also an ISO C++98.:) Anyway, among other things C99 introduced complex numbers, so if the compiler is in C99 mode with complex support implemented &amp; enabled, `2i` will be an imaginary literal. Otherwise, `2i` is a bogus token. Since your prof (presumably) said C89, it has to be something like `2*i`. 1\. You don’t strictly *need* the newline, but it’s usually a good idea if you’re outputting text for human consumption. Let’s say Joe wants to run a “Hello, world” program at the command prompt that doesn’t include a final newline. His session will look something like this: &gt; [joe@joespc ~/here]$ **./hello_world** &gt; Hello, world![joe@joespc ~/here]$ ▎ Note that the prompt immediately follows the output on the same line, which is kinda ucky looking. On anything modern-ish and UNIX-like, something like the Readline library is used to deal with keyboard input in a relatively painless way. Reading a line starts out by guessing where on the line the cursor is, so that arrow-key and Home/End types of navigation during editing work. Since the prompt’s starting out in the wrong place, things might get out-of-sync between what Joe expects as his cursor position in the text on the screen, and what the readline library understands as his position within the input line. Joe will hopefully notice this before hitting Enter, and he’ll then have to either hit Ctrl+L to reset things, keeping his input line but losing some other stuff on the screen, or hit Ctrl+C to cancel the input line and re-type or copy+paste his command. Some shells (e.g., COMMAND.COM &amp;seq.) will print an extra newline at the end of a program’s output if it’s going to the terminal. Also, some file formats expect files to end with a newline, and conversely most text formats will allow a newline at the end without complaint. (C and C++ files require a final newline, for example.) And of course, if you want to be able to concatenate text files or dump them raw to the prompt, it’s a good idea to have some kind of break (LF, CRLF, CR, VT, FF are common ones) at the end of each file so the text doesn’t just run together. (E.g., if you run cat Chapter1.txt Chapter2.txt &gt; Chapters.txt then Chapter 1 will end with the extra-long line —and this time, it was her cat’s butthole! CHAPTER 2 2\. Oh, I was just referring to you having tried to escape the `*` character for Markdown when you typed operator `*=`. There is no operator `\*=` in C. 3\. Probably, yes. If your prof gave you output to match, work towards that, but make sure your professor knows he/she/it’s giving you slightly bogus work to do. 4\. This gets really complicated really fast, but I’ll focus on the argument-passing part of it. When you’re assigning or passing arguments to a function for which the compiler can see a full prototype (i.e., return type, name, and full parameter list ), arguments are ~silently converted just as they’d be in an assignment from the arguments to their respective variables. When you’re passing arguments to a function with no/prototype (e.g.:) int someFunction(); /* In C++, that would mean “`someFunction` has no arguments.” * In C, that means “`someFunction` takes whatever arguments maybe.” */ the compiler applied a fixed set of promotions to arguments, such as converting any smaller-than-`int` scalar to `int` and converting all `float` to `double`. This same promotion process is applied when the compiler is processing a variadic function like `printf`. Here’s its prototype: int printf(const char *format, ...); That `...` basically means the compiler should treat the remainder of the arguments as if they were being passed into a prototype-less function like `someFunction` above. This is a very delicate process; `printf` has no idea a priori how many arguments you’ve given it or what type each one is. As it reads through `format`, each time it encounters a format specifier it’ll read the next argument as whatever type that format specifier requires. So if you pass a `float` to a `%d` specifier, the compiler will promote it to `double` (usually ~64-bit) and then `printf` will try to pull in an `int` (usually ≤32-bit), format whatever garbage it gets, and keep on trucking. (It has no way to know what it just did was wrong.) Or, since it’s undefined behavior to pull out an argument that isn’t there, or to pull an arg out with the wrong type, anything at all could happen. Basic format string bugs will be caught by GCC as a warning if you’ve got ’em all enabled, because `printf` is marked specially as taking a format string that refers to a variadic argument list, and as long as the compiler can see the full format string it can type-check the rest of the arguments. Some compilers have extra stuff that would let you check variadic argument lists (e.g., `attribute((sentinel))` in GCC/Clang), but in general that sorta stuff is tricky to deal with safely. With respect to characters specifically, any `char` value can be assigned to an `int` without losing information. The C compiler treats character constants like `'A'` identically to the (`int` and not `char`, for some reason) value 65. Characters (code points and/or code units, really) are no different than any other integer right up until a font renders them. 5\. By setting flags, I mean pass them to the compiler when you compiler your code. Presumably you do something like gcc -o executable c_code.c to compile? Instead, do gcc -std=c89 -pedantic -Wall -Wextra -Werror -o executable c_code.c Those flags in order: - `-std=c89`: Set language to C89, ~disabling anything beyond that. - `-pedantic`: Follow the standard strictly, and error out if something non-C89 is encountered. - `-Wall`: Enable all normal warnings. - `-Wextra`: Enable extra warnings, which are usually helpful, but which may be false positives or unimportant. - `-Werror`: Treat warnings as errors; stop compilation if any warnings or errors are raised. If you want to do this in your IDE, there should be a Project Settings or something like that, and somewhere you should be able to edit the compiler command-line options. Some of these options (e.g., probably C89) might be configurable directly via checkboxes ’n sech. See ↓next post↓ for a handy settings header. &gt; Also, my program runs without including respective header files. See #4, above. If you don’t include the headers, then the compiler will guess ~blindly at the prototypes for undeclared functions you call. For example, since nothing tells the compiler `printf` has type `int(const char *, ...)`, the compiler will assume `int printf()` instead. This behavior used to be necessary and useful; now it’s mostly a dangerous relic, same as how you can omit `int` in tons of places where it really should be included (e.g., `const x = 4;` is identical to `const int x = 4;`). Sometimes `int()` is actually a correct enough type to call the function safely, and that’s probably the case with `printf`, although the `...` part of its arguments might require setup/teardown protocol beyond what an any-args call can handle. Header files are also necessary for macros, types, structures, unions, enumerations, and external variable definitions, which the compiler won’t guess at. E.g., without `&lt;stdio.h&gt;` you can’t refer to `FILE`, `EOF`, or `stdout`, although you don’t need to in this case. So always `#include` the headers, whether or not it happens to work otherwise. (IIRC this case would either be implementation-defined or undefined behavior, either way something to avoid.) Option `-Wall` should definitely catch an undeclared function. &gt; And, the one you mentioned about 1/2 giving an int value 0 giving the right output. When it should have been something like 0.5 or 1.0/2 or 1/2.0 ; just anything that make it a floating variable Not sure what you’re asking here. Generally, you’d look at the parts of the expression; is `1` special, or `2`, or `0.5`? (E.g., might we some day want to parameterize one or all of these, or are those values mandatory?) If the literal value `0.5` has meaning unto itself, stick with that. Either way, powers of 2 can be represented ~exactly in a binary floating-point format, so there’s no intrinsic difference between `0.5`, `1.0/2`, `1/2.0`, and `1.0/2.0`. Anyway, no sorries, you’re asking questions and working on stuff. (Cont’d…)
^(…Cont’d.) **Auto-setup header:** In your Project or IDE settings, set up a macro definition that code can use to set up personal stuff. I’ll use `carpezox__TESTING` as the name. If there’s not some clean way to add that macro def in the project or IDE settings, you should be able to add it as a preprocessor and/or compiler flag with `-Dcarpezox__TESTING=1`. Make a new header file, `testing.h`: #ifndef carpezox__testing_h__INCLUDED__ #define carpezox__testing_h__INCLUDED__ 1 /* Check to make sure the compiler is GCC or GNUish. */ #if !defined(__GNUC__) || (__GNUC__+0) &lt; 4 # error "compiler is not GCC 4.0+ or compatible" #endif #pragma GCC system_header #pragma once /* Check to make sure the compiler is set to C89 mode. */ #if defined(__STDC_VERSION__) &amp;&amp; (__STDC_VERSION__+0) &gt;= 199901L # warning "compiler is not in C89 mode" #endif /* Disable pragma warnings in case one of the later pragmata fails */ #pragma GCC diagnostic ignore "-Wpragmas" #pragma GCC diagnostic ignore "-Wunknown-pragmas" /* Enable all warnings and treat them as errors. */ #pragma GCC diagnostic error "-pedantic" #pragma GCC diagnostic error "-Wextra" #pragma GCC diagnostic error "-Wall" /* `error`ing `-Wall` will affect `-Wpragmas` &amp; co. as well. */ #endif /* ndef carpezox__testing_h__INCLUDED__ */ At the top of your main source file, do #ifdef carpezox_TESTING # include "compiler.h" #endif Since your IDE defines `carpezox__TESTING`, when you compile it there, your compiler will be set up properly. Compiling in any other environment won’t define `carpezox__TESTING`, so `compiler.h` won’t be included then. The above methods can’t be used (AFAIK) to set the language standard, so that’s one thing you’ll have to set manually.
Is that another way of saying foot-in-mouth? 😋
Pls explain, I'm a pleb
How to write safer C code: File &gt; New &gt; File &gt; *.go
You're criticizing because the first sentence shows an imperfect command of English language idioms ... classy.
You \*really\* need to be less wordy. Your "type system" post should be about 1/3 as long as it is, and go for demonstrations more than expository. &amp;#x200B; Your audience is either yourself (in which case, you don't need to post it anywhere), or it's people that understand C -- so don't be so verbose.
As I said in my original comment, I didn't mean it as an indictment of the content itself. In the past this sub has been plagued with tutorials and articles created by some who made similar grammatical and idiomatic mistakes, and their advice consistently preached poor, unsafe, and outdated practices. This article has almost no content to speak of, but the similarities it carries with other items I've seen on here bear some serious consideration. I'll be the first to admit that I took a cheap shot at a jarring mistake that a non-native speaker may not notice at first, but I don't think that nullifies my main message: if I proceed with this series I will do so with caution, and I advise others to as well.
Rust?
When you want homework help, post the code you have so far and specifically state what problem you have with it. We’re not here to do your homework for you.
In your first comment, you took a cheap shot, speculated about the content, and admitted to doing all of that. Only now are you commenting on the content.
I can do it. Can you?
&gt; In your first comment, you... Should be: &gt; In your first comment you: ... Feel free to downvote and report at your leisure.
Thank you and amen. 
This isn't quite the full story. `printf` is a variadic function (it can take an arbitrary number of arguments), which has an extra set of rules. A `char` is actually promoted to an `int` before the function is even called. So `%x` and `%d` will never see an `int`.
While it is the same, the following makes the intent a little clearer: char x[16] = {'\0'}; 
tbh did not like this read lol
Safer, not slower.
I am a professional developer who uses C at work. I have never blown my own foot. Memory management is not that hard, and there are tools that help with that.
My rate is €100/h. If you can pay in advance, I can write that program for you.
I down-voted because of your choice to double down on being nasty and off-topic, not because you failed to recognize a fronted clause punctuated by an optional comma. I suspect your other down-voters have similar reasons. Let's keep the discussions productive and about C.
According to the C Standard, the argument corresponding to `%x` and `%u` must have type `unsigned int`. However you actually pass a `char` (which, after the integer promotions on normal systems, becomes `signed int`). So your program causes [undefined behaviour](https://stackoverflow.com/a/4105123/1505939) which means that *anything can happen*. If you are new to C you might not have heard of undefined behaviour; that link should explain things. You might get different results for re-running the same program, or using a different compiler, or on a different day of the week, etc. It would be a mistake to try and understand the output you got and treat the result as being an understanding of the C language. 
There is no conversion to unsigned involved. The argument must match the specifier otherwise it is undefined behaviour. To be correct the code should include a cast to unsigned.
&gt; Let's keep the discussions productive and about C. As of my writing this not a single one of your comments in this thread is about C. I would also go so far as to say none of them are productive. I'll reiterate: if you have a problem with my comments you are free to downvote or report them, which will actually do something, as opposed to continuing to bait conversation. Have a good day friend.
*Makes off-topic comment instead of just down-voting.* *Complains that challenges are off-topic and suggests just down-voting instead.*
[removed]
What tools?
valgrind
valgrind
https://en.m.wikipedia.org/wiki/List_of_tools_for_static_code_analysis
Desktop link: https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^232896
This one's great, i thought he meant a full-fledged IDE or Suite that involves memory management tracking with profiling and various other features.
Chicken chicken chicken chicken. Chicken, chicken chicken, chicken?
https://www.youtube.com/playlist?list=PLCNJWVn9MJuPtPyljb-hewNfwEGES2oIW
What are you two on about? Which English idioms? Did you guys want to blow the entire leg or something? As a non-native English fluff, I need answers!
[This one follows K&amp;R](https://www.youtube.com/watch?v=lFbNQ66tFQU&amp;list=PLc-HIpQTAA83WlPGC8AaKcHIx12HMgTs4)
Wrong C, homey. Check our sidebar for links to get you headed in the right direction. 
(Assuming you are taking about vectors) Emplace lets you insert anywhere in the container, push puts your data at the end. 
I liked "stanford C programming"
ok made a complete mess of that! [http://bedroomcoders.co.uk/dynamic-loading-of-functions/](http://bedroomcoders.co.uk/dynamic-loading-of-functions/) &amp;#x200B; I tend to use my blog as an aide-mémoire after deciding to implement a plugin system for another project I looked for an alternative to glibs gmodule, this very brief look at dynamic loading might be of use to someone else interested in researching how to implement their own plugin system. Alas the last paragraph is all too brief and possibly the most important aspect &amp;#x200B;
Interesting read, thanks.
Are you talking about Essential C?
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
Please make a repost with a corrected link as right now, the link goes nowhere.
Why is `litdata` declared `const`? You can't change a `const` array.
You can't sort the list in place if the list is const.
It has to be const. Makes sense, so how do I sort it? Store in another array and sort it there?
Makes sense, so how do I sort it? Store in another array and sort it there?
&gt; Store in another array and sort it there? Exactly. You can copy the array with `memcpy` into a buffer to sort. Another possibility is to instead sort an array of pointers into the array to save a bit of memory.
Really, this may give different outputs with different compilers or different days of the week? Hmm, because my teacher asked this question on a practice homework. I wonder what he considers the correct answer to be if there isn't a truly correct one based on the fact that it's undefined behavior.
Honestly I feel like if you need a constant sorted list maybe the best idea is to generate it via a script or something.
see the first post
In-place operations on a string are indeed possible and very legitimate. `str[0] = 'a'` should definitely work, which leads me into thinking that: * You passed a literal string to the function (i.e., `fun("String");`). AFAIK, this is undefined, and might or might not work, so it's definitely not good practice. * You passed a variable which you declared and defined using a literal string (i.e., `char* str = "String"; fun(str);`). AFAIK, this is sort of undefined as well, and you should avoid it. Apparently, you can change `char* str` to `char str[]` (I think you also need to specify the size inside the square brackets) and you'll have a modifiable string, and the function will work. * You passed a `char*` pointer not assigned to any literal string, but you didn't allocate enough space for it. If you don't know yet how manual memory allocation works, you probably should do as per my second point; if you do, well, do it lol
So this was asked to me in a coding competition and I was expected to do it in-place. I had no option to modify the main() function. In fact, I was not even given visibility access to the main function. I tried something similar to `str[0] = 'a'` , and my code did not run for some reason. Then I found out this problem, that it depends on how the string was declared or passed. Still not sure how I can get the output.
Consider the behavior of the function when you pass in 0 to it. What will it return if the global variable is never initialized?
Think about the order in which these things happen. Let's say you call your function with just 1; faku(1) This would go to the line fakultat = n * faku(n-1); and call faku(0) which skips the if condition and simply returns *fakultat*. Because you're doing a factorial calculation, the base case of the recursion needs to be 1. Otherwise you have the incorrect calculation for what factorial is defined to be mathematically.
If that's the case, I don't know... Maybe the code also expects you to return its parameter as the result value, since it has `char*` as its type.
The most important part of writing safe C code is deciding what dialect to use, and ensuring that one configures a compiler that supports that dialect. Because different implementations are intended for different purposes, the Standard doesn't try to mandate that they support accommodate everything that every kind of program might need to do, but instead relies upon implementations claiming to be suitable for particular kinds of tasks to support the Spirit of C principle described in the Rationale as "Don't prevent the programmer from doing what needs to be done" in a fashion appropriate for those tasks. Deliberately relying upon what the authors of the Standard called "popular extensions" that will allow code to be written in cleaner and more logical fashion than would be practical if one has to jump through hoops to accommodate compiler configurations that are only suitable for specialized purposes (such as those that don't involve processing any data from untrustworthy sources).
Quick clarification on your second point: `char *str = "String"; fun(str);` is basically identical to `fun("String")`. A string literal gives you something of type `char[N]` for appropriate `N`, so when you assign it to a `char *` it’s just decaying that `char[N]` to `char *` (→first element) like arrays normally do. And of course, *any* alteration to a string literal’s memory is undefined behavior. (It’s only `char[]` and not `const char[]` because of code that existed pre-`const`, but it really should be `const char[]`.) In general, you can think of a string literal like `"String"` as roughly equivalent to (char[]){'S', 't', 'r', 'i', 'n', 'g', 0} Wrt array size: You don’t need to specify an array’s size if you’re initializing it in-place. If you do char foo[] = "123"; or int bar[] = {1, 2, 3, 4}; the compiler can see that it needs to be a `char[4]` or `int[4]` right there. Whereas if you did char foo[]; memcpy(foo, "123", sizeof("123")); that’s not allowed, because the compiler ~basically~ has no way to tell what the array size should be.
This might get downvoted into oblivion, but IMO any article about safe C should start with the phrase "ask yourself if you really need C, or whether a higher-level language will do too". Even just having the business logic in C++ and only the performant code be in C can do wonders to safety. (Note: I entirely understand there are platforms that allow nothing but C. Those are of course excepted from the above)
Really interesting article! I learned some new things. &gt; Both float.h and limits.h are inventions of the committee. You can &gt; generate them with the &gt; [enquire](https://homepages.cwi.nl/~steven/enquire.html) program &gt; written by Steven Pemberton. It performs runtime checks on the data &gt; types to find information about them, then generates the desired &gt; header file. **It’s extremely portable.** This got me thinking: Just how would you discover `INT_MAX` in a portable program without using limits.h? Interrogate various bit patterns — assuming there are no trap representations? I couldn't come up with a reliable way to do it, so I took a look at enquire's source. It explicitly relies on signed overflow and even warns about it in the header: &gt; The program only works if overflows are ignored by the C system or are &gt; catchable with signal(). &gt; &gt; [...] &gt; &gt; Make sure you compiled with optimisation turned off. So it's not really portable at all, relying entirely on luck. &gt; By default C programs use the “C” locale, which is ASCII text and &gt; American formatting. The most respectful thing, though, is to accept &gt; the locale in all categories as set by system environment variables. &gt; This is indicated by the empty string for locale name. Unfortunately this is exactly what makes lots of GNU software so brain-damaged by default. For example, [Bash doesn't understand uppercase vs. lowercase](https://utcc.utoronto.ca/~cks/space/blog/linux/BashLocaleScriptDestruction?showcomments), and [GNU sort requires `LC_ALL=C` in order to produce sensible output](https://stackoverflow.com/a/28903). &gt; Similarly L_tmpnam is the size needed for an array large enough to &gt; hold a temporary filename generated by tmpnam(). This function is a &gt; security hazard (though it can be useful for generating entropy). In a recent discussion with the article's author, I [did a survey of various implementations](/r/C_Programming/comments/a6x93c/_/ebz6lkz/). &gt; C99 fixes this with an “x” (exclusive) mode modifier. If exclusive &gt; mode is specified (“wx”), the fopen fails if the file already exists &gt; or cannot be created. Are you sure this is in C99? I'm not seeing it in the standard. Looks like it's not even [in POSIX](https://pubs.opengroup.org/onlinepubs/9699919799/functions/fopen.html), so it's just a common extension. &gt; It’s yet another place where wide character implementations are half baked. You're not kidding! &gt; Rather than rely on whatever implementation of rand you get on a given &gt; architecture, it’s just as easy to define your own xorshift rand &gt; function. Didn't expect to see my own name here! Note that the shown 64-bit hash is not mine but rather the famous SplittableRandom. I only invented the 32-bit functions in my article. If you use SplittableRandom, you'd want to include the gamma (e.g. the value added to the PRNG state before hashing) from [SplitMix64](http://xoshiro.di.unimi.it/splitmix64.c). Not all gammas are equal, especially gamma = 0. Also, as a *whole*, SplitMix hashes are not Xorshift functions due to the multiplications. They *do* use Xorshift operations as primitives. Something I also learned recently is that `RAND_MAX` is a committee invention. It was added to the standard before it was defined in any implementation. Before standardization, various implementations had different maximum values but programs couldn't know what it was. Some very old C programs (such as the original korn shell, ksh) sample `rand()` on startup in order to guess at its range. &gt; What we can do is create a function pointer to main, point another &gt; pointer at it and read the value out byte by byte. Ever since you presented this idea to me a month ago it's changed my whole perspective on exploiting ASLR for entropy. Treating the function pointer as a byte buffer rather than an integer makes more sense when possible. Thanks! &gt; C89 allows bare blocks inside a function to segregate variable &gt; declarations near the code that uses them. I use this trick even in C99 when writing unit tests so that I can reuse variable names back to back: { char input[] = "..."; char expect[] = "..."; char output[N]; foo(output, input); TEST(!strcmp(output, expect), "foo() edge case"); } { char input[] = "..."; char expect[] = "..."; char output[N]; bar(output, input); TEST(!strcmp(output, expect), "bar() edge case"); } 
Well ... as with everything in C and C++ land, those qualifiers are only suggestions. As long as you know exactly what you are doing, you can simply cast the array to non-const when passing it into the sorting function. Dangerous? Maybe. But I'm assuming you are using C for a reason.
I have no clue what you're trying to do here and why you think this is not out-of-bounds/uninitialized memory, but you increment the pointer p once outside of the loop once, then proceed to decrement it twice per loop iteration. It will be out of bounds, and you'll be corrupting memory, so it conveniently segfaults.
yhea, pretty much just make a list, sort it, dump out the list, and then re-put it in the program /u/DirtCobain any const-list should be pre-sorted if you want a sorted const-list. No point in sorting it afterwards...
Add printf statements to see the addresses and the values at those addresses. 
I guess, you try to execute some brainfuck here. If that is the case, there is a tranlation error at the end of the loop. It should be ++p to match the original source.
Perhaps he falsely assumes that behaviour of his compiler is guaranteed behaviour of C. Most C courses are terrible in this regard. 
How exactly did this fail? “It failed” is not an error description. You cannot write to string literals, i.e. `fun("foo")` is not legal. If you want to test your function, you have to invoke it on an array of characters declared such that it is actually writable. For example, you could do: char foo[] = "foo"; fun(foo); Note that here, `"foo"` is not a string literal, it's merely an initialiser for `foo`. `foo` is an array of characters which can be written just fine.
I too am oddly curious about what the goal was with this. Even as a learning exercise it seems...odd. Also, for OP, your compiler is letting you get away with calling *memset()* without including its header (where the definition is). It probably gave you a warning, but if not you would do well to turn those on or even choose to have warnings register as errors.
You can always post your solutions to [codereview.SE](http://codereview.stackexchange.com) and have others review them for you. That said, the best way to learn theoretical computer science is without a computer. Get yourself a good introductory text for the desired field and do all the exercises on a piece of paper. Programming is only sometimes helpful for that.
This was the output code from a brainfuck to c converter i made, also i added memset because i wasnt 100% sure it would set all chars to 0. Turns out the brainfuck code was wrong and i confirmed it after by testing it on other bf interpreters/compilers but i just blindly trusted it because it was on a popular page.
I've been away from C for a lot of years but the bash article was from 5 years ago, I can't replicate the script error described at the site you linked to.
I still get bogus results with Bash 4.4.2 (Debian 9). $ cat &gt; Demo #!/bin/bash for i in "$@"; do case "$i" in *[A-Z]*) echo "$i has upper case";; esac done $ env - LANG=en_US.UTF-8 bash Demo a b C y z b has upper case C has upper case y has upper case z has upper case The article used `./Demo` to run the program, but `/bin/sh` usually isn't Bash these days, so make sure you're actually invoking Bash when you try it. 
For Mac, just download the binary and make sure the location is in the PATH environment variable. Probably something similar for Windows, although I have no experience with it.
Learn C# instead and ask questions here /r/csharp /r/unity2d /r/gamedev
thank you
Try asking instead in /r/cpp_questions.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
Now I want DeathStation 9000 VM and compiler.
Good point, I saw /bin/sh is symlinked to dash, you're right.
1. Buildin uses compiler buildin functions instead of calling library functions. 2. You need debug info
If you don’t have Ninja in a normal location, ex. on the PATH, then you will need to set a CMake variable to let CMake know where it is. If you don’t want to do this, add ninja to your PATH.
pthread.h is the Posix standard while thread.h is the new C standard.
Besides asking this in the wrong sub, suggesting downloading a "full" c++ compiler shows how lost you are regarding the whole thing. I suggest you pickup a book that walk you through the first steps, like Deitel's.
This subreddit exists to discuss the C Programming Language. Please redirect C++ related questions to r/cpp_questions.
Perfect !!!
Obvious troll 
AFAIK pthreads provide you with a finer level of control. C11 threads should in theory be more portable, but last I looked it wasn't supported by any major compilers. Admittedly it's been a couple years.
Nice :-) 1. CamelCase is very Java in style. snake_case is much more idiomatic to C (and easier on the eyes too)... 2. are all HTTP functions CGI in style (return value effects response)? or is that just the LUA version? can HTTP responses be delayed / evented (i.e., for database access)? 3. How is performance? 4. How does if compare to [facil.io](http://facil.io)?
&gt;it relies on a global array, and no amount of locking will alleviate that. Why I make `item_send_push` and `item_recv_push` global ? Because they are to used to store values since kernel builtin `ptr_ring` struct only have `void ** queue` Now, do you understand why making them global is inevitable ? 
If you’re trying to be *really* portable(-ish), and won’t need like any control over how or where threads run, `threads.h` is okay. But `pthread.h` is a much better bet unless you’re targeting Windows. There’s also likely to be some change in the way `thread.h` facilities are set up, because C11 [flubbed things rather a bit](https://gustedt.wordpress.com/2012/10/14/c11-defects-c-threads-are-not-realizable-with-posix-threads/). As to specific differences, the biggest one is names. Other than that: - POSIX lets you initialize most things statically whereas C11 has no explicit support for that, with the exception of `ONCE_FLAG_INIT`. - Pthreads allows you to avoid explicit destruction of things statically initialized, whereas C11 requires you to explicitly destroy any `cnd_t` or `mtx_t` you’re not still using. - Pthreads tends to give you more options in terms of behavior for things like mutexes, whereas C11 has a single behavior for mutexes and condvars. (Importantly, this means it’s not safe to use C11 structures in shared memory segments, whereas most Pthreads things support `PTHREAD_PROCESS_SHARED`.) - Most POSIX/-ish OSes also have some extensions to Pthreads that work with a `pthread_t`, but translate to some OS- or runtime-specific call (e.g., `pthread_tryjoin_np` on Linux). C11 implementations are likely to hew closer to the standard with fewer frills, both because C11 gives the implementation fewer obvious hooks than Pthreads, but because very few projects are using C11 threads yet, especially in any exclusive sense. - One thing you can’t comfortably use Pthreads for is linker/loader-based TLS stuff, which before C11 was only available on specific compilers per specific ABIs (e.g., GNU TLS via `__thread`). C11 introduces the `_Thread_local` keyword, which `&lt;threads.h&gt;` defines `thread_local` to for congruence with C++11. C11 also defines TLS (“TSS”) keys like Pthreads’, FWIW.
This sub is for C, not C++ - try asking in /r/cpp_questions.
So essentially you copy and pasted whatever the hell mess was on your screen into reddit and say "fix it"? I can barely make out what the hell you have there. I am guessing 'hello world'. Well gee. What is the source code really ? 
It literally shows the source code under \`list\`. I thought at the very basic you guys would know that. Oh and no, I'm not just pasting whatever is on my screen. I actually did this manually to make it easier to read step by step. It's alright. I fixed it myself, I was just missing the \`glib\` source files. I simply set \`gdb\` to access the source files in my Documents directory in my \`.gdbinit\` file. Also, how can you not tell what's going on? This is basic debugging....
As I mentioned in another comment, I had no access to the main function where the function call or string declaration/initialization was present. I only had access to a function declared in the above mentioned format. &gt; I tried to do a simple str[0] = 'a'; , and it failed. What I meant by this was that the code simply stopped working without any errors, but a huge exit code. The modification was not done to the string at all.
So I had only access the this particular function and not the main function where the string was declared, initialized and the function call occurred. I am guessing the string was declared using a pointer because there is no way of knowing the actual size of string beforehand as there were multiple test cases. I tried this on my PC and I still got the error when I declared a char pointer and allocated 10bytes of memory, initialized it with 9 character string, passed that pointer to a function where I tried to change the first character. It gave me a segmentation fault and exited.
The `-dbg` and/or `-dbgsym` packages only contain debugging symbols (like function names), but not source code. Maybe try installing `glibc-source`.
https://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html#index-fbuiltin &gt; GCC normally generates special code to handle certain built-in functions more efficiently; for instance, calls to alloca may become single instructions which adjust the stack directly, and calls to memcpy may become inline copy loops. The resulting code is often both smaller and faster, but since the function calls no longer appear as such, you cannot set a breakpoint on those calls, nor can you change the behavior of the functions by linking with a different library. Or in other words: By default it inlines (some) C standard functions for speed and efficiency. `-fno-builtin` prevents that, so it actually calls the function. 
The newline is counted as a character in addition to telling \`fgets\` to stop reading input. When the input string has fewer than \`count\` characters, the newline doesn't get truncated.
 #include &lt;stdio.h&gt; int main() { char buf[10]; fgets(buf, 10, stdin); (void) fflush(stdout); for (int i = 0; buf[i]; i++) { switch(buf[i]) { case '\n': (void) printf("newline\n"); break; default: (void) printf("%c\n", buf[i]); break; } } return 0; } You're right, output (2 runs): user -| /home/user/c_code |- ./test8 hello h e l l o newline user -| /home/user/c_code |- ./test8 sjdkfjlksdjfklsjdklfjsdklfjlksdjfk s j d k f j l k s So I have to loop through the buffer and delete the '\\n'...
Yes, but you don't have to manually iterate over the buffer. `man 3 strchr` would be a good place to start.
 /* delete the '\n' stored in buf_name */ for (int i = 0; buf_name[i]; i++) { switch(buf_name[i]) { case '\n': buf_name[i] = '\0'; break; default: break; } } Yeah, it's better: char *ptr; ptr = strchr(buf_name, '\n'); *ptr = '\0'; Thank you!
What happens if `buf_name` doesn't contain a newline?
&gt;The other thing is, now if buf\_name contains no '\\n' I read out of my buffer I edited my post shortly after &amp;#x200B; I could set buf_name[BUF - 1] = '\n'; Because I just read the 12 first chars in that string and BUF is defined as 25, but that seems more like a bad workaround &amp;#x200B;
Oh, fixed it: char *ptr; ptr = strchr(buf_name, '\n'); if (ptr) *ptr = '\0'; &amp;#x200B;
Cheers! :-)
It is likely that the array you get is non-writable if you can't write to it.
And almost nobody implements `thread.h` which is the inferior API anyway. Go with `pthread.h` and you are fine.
Your post is very garbled. You tried fixing it with the triple backtick syntax, but that doesn't reliably work on reddit. Do not use this syntax.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
The standard says that complex numbers have the same layout as an array of two floats. So you can memcpy complex numbers to and from such an array.
Another alternative I like to use: buffer[strcspn(buffer, "\n")] = '\0';
I understand why you're doing it. I also understand that you have no idea what you're doing and refuse to listen to those who do.
See the [ptr_ring code with added lock](https://gist.github.com/promach/65e9331d55a43a2815239430a28e29c6#file-circ_ring-c-L77) Sorry if I offended you, but my ears are for your advice
 for (;*p;) *p == '\n' ? *p = '\0' : p++; I really like C
lol toy language
I have added mutex, but I still have threadsanitizer warnings, which literally means data race. So, before I proceed to dismiss ptr\_ring for a simpler array, I need to find where exactly the data race is located outside of circ\_ring.c file, otherwise the data race problem will persist even after I dismiss ptr\_ring.
To be precise, the real part is the first element and the imaginary part the second. https://en.cppreference.com/w/c/language/arithmetic_types#Complex_floating_types
Not related to the problem but if you define without the ";", when CLEAR is needed you can use it as CLEAR; Which is more C like `#define CLEAR printf("\e[1;1H\e[2J") // clear screen` `CLEAR;`
Clang doesn't have its own std
Yeah, even my style-guide says so :) I try to get rid of it
What I do in my application where I have an array of complex numbers, I actually use two arrays one for real numbers and one for complex numbers. For example a function that computes the magnitude: void magnitude(double * mag, const double * real, const double * imag, size_t length) { for (size_t i = 0; i &lt; length; ++i) mag[i] = hypot(real[i], imag[i]); }
I always recommend this too.
Why is JSON used as a configuration file format?
I've not got time right now to figure out exactly where you're going wrong but you should really look in to using regex capture groups rather than trying to use two different regexes in your `regit` function.
Actually I can see the cause of the problem now, you don't initialize `buf`. Try doing this instead: char buf[30] = {'\0'}; I still think you should use a regex capture though so you only need to do one regex operation each for A and B.
Note: Always include system headers using angle brackets, i.e. #include &lt;stdio.h&gt; this distinguishes them from project headers of the same name.
Thanks. Still a C newbie :)
The difference is relatively important. &lt;&gt; will look for the header file in where ever your ide / compiler keeps such files by default, " " will look in the directory of your .c file is located in. so if you wrote your own library you'd use #include "mylib.h" instead of #include &lt;mylib.h&gt;, try to make a note to remember this, it can catch you unaware sometimes. Your compiler is probably catching the problem and understands how to fix it for you so that is why your program is probably compiling correctly but if you were tested on this it would be one little "gotcha" thing.
Different languages allow compilers varying amounts of freedom with regard to how they process low-level details. C was designed to maximize the performance that could be achieved with *simple* compiler, in exchange for giving up some ways that more sophisticated compilers could optimize things. The notion that C compilers writers should invest more effort into maximizing the efficiency with which their compiler can do things that could be done better in other languages, rather than focusing on their ability to do things that *can't* be done well in other languages, has been absolutely disastrous for the language. 
Sorry, it took so long to reply, I've been busy these days. I get most of what you said(i think, i m still a beginner at it) except for the "flag" and " auto setup header" but i have screenshotted them and hopefully i will understand/memorize them as my knowledge increases ( I am not that familiar with defining header files, i have tried to make the most basic ones which also failed so when you use stuff like STDC, GCC, #pragma,etc which i have never heard/used before it becomes tedious for me to google each and everything thing. But i will make some time to understand them in the near future (hopefully) so that the code as well as the whole comment you wrote which probably took very long wont go to waste. On that note, thank you for taking the time to write such lengthy and descriptive comments, which probably took you quite some time. But for future reference please try to answer in most basic way possible (keep in mind that i started learning C roughly a month ago) so keep the use of "high level stuff" (for the lack of a better word) to a minimum, else i will be forced to make google them out of my curiosity because of that i cant get my assignments, notes,etc done in time. Finally, i have and will have of lot more basic level questions, but continuing to ask-and-answer in this already very long comment thread would be rather disorderly and posting it on this sub would take quite sometime as well (The first post i made took 13 days for someone to reply) , so i thought it would be better and efficient to ask to pro like yourself . So, is there a way to add to friends or chat/DM someone on reddit like on facebook or other SNS ( Yes, i am new to reddit as well ) . If no, then may on other SNS's like facebook ? or by e-mail? If yes, could you do so (add me) so we can continue our Q&amp;A session, so to speak there, only if you are willing and/or have the time to do so. And, on a completely unrelated note i know my English(writing) must be so horrendous that you'd want to kill yourself. But can you please be dead honest and rate it out of 10, because it would do me plenty good if i had simple and beautiful writing like yours , which i definitely do not. Well then, i will be waiting for your reply; Regards to you my friend nerd4code, Rikesh Lawoju Nepal, SEA
As u/henry_kr already said, you need to initialize the `buf` variable, but you should also initialize all the other variables. The reason the `strcpy` doesn't clear the buffer is because your are copying an empty string, with 0 length, into buffer, which does nothing. This is a fun error (read: not fun at all), because if you switch the order of the `getfloat` calls, the error is hidden. 
Because web browsers and a lot of web related tooling uses JSON natively.
can't have comments in JSON though :(
It's an inevitability, sadly. Every language out there feels the pressure from other languages to add some of their features, no matter whether it makes sense or not. Perl felt it necessary to add OOP because it was the hot topic back in the day, and it was gruesome.
Passing an empty string to`strcpy` won't clear the buffer, but it won't do nothing either, it'll set the first char of the destination to a null terminator. I agree it's a strange thing to do though. The bigger problem with those `strcpy` calls is that they're operating on temporary variables, so there's no guarantee that next time the function is called it'll use the same memory area, so even if the whole buffer was cleared at that point it might not actually have any impact. So yeah, initialize all the variables!
Oh true it will copy the terminator, good call.
Many languages manage to ignore pressure to add features, especially in cases where adding unnecessary features would require eliminating necessary features upon which many programs rely. The problem with C is that the authors of the original Standard saw no need to exhaustively catalog all of the features that implementations had been unanimously providing and were expected to provide forevermore, but obtuse compiler writers regard as "broken" any programs that rely upon any such features that weren't cataloged by the authors of the Standard. The language processed by many implementations C would be massively extended if the Standard had included--suitably framed--a principle which appears in the Rationale in the Spirit of C: "Don't prevent the programmer from doing what needs to be done". The definition of "what needs to be done" would vary depending upon the purposes for which an implementation claims to be suitable, but an implementation which claims to be suitable for some purpose should be expected to support behaviors that would facilitate such purpose without regard for whether the Standard requires them or not, and implementations that don't support such behaviors shouldn't claim to be suitable for such purposes. C has never been so much a language as a family of dialects; unfortunately, language vandals have convinced many people that the name C only applies to a wimpy dialect which is grossly unsuitable for most the purposes served by good dialects. 
lol no generics
Well, if by almost nobody you mean glibc, Pelles C, OrangeC, musl, dietlibc, and more. A bunch implement it, the only problem is that behind implementations (MSVC is still ANSI with some C99, don't even think about it) are often still being used and that the major windows C compiler doesn't even support C11, so...
Few implementations guarantee anything about the effect of attempting to modify the object pointed to by a string literal expression. Given `char const *str = "OW!";` a compiler or linker would be allowed to, at their leisure, make `p1` point to three bytes that are used for no purpose other than to hold its value, or point to three bytes that are used for some other purpose but which happen to hold the proper values and will never change. Those three bytes might represent bytes within some other string (e.g. `"WOW!"`), or could even be some machine code instructions whose bit representations happens to match what's required. If `str` holds an address associated with a string literal, attempting to write `str[0]` isn't "sort of undefined". It's an action which can only be meaningful on implementations that expressly guarantee that all string literals are separately allocated. On almost any other implementation, it would fall into the category of behaviors for which no useful behavioral specification would be possible. 
The C Standard library added portable support for a few things that had previously relied upon non-portable hackery, via `strarg.h` and `setjmp.h`, but is crippled by the authors' unwillingness to recognize features or guarantees which could be usefully supported by most but not all implementations. Rather than try to argue about what things implementations should or should not be required to guarantee, the Standard should instead focus on providing means by which implementations that can usefully offer guarantees to the programmer can indicate that fact. If on some platform a version of unsigned mul(unsigned short x, unsigned short y) { return x*y; } that behaves in arithmetically-correct fashion for all values of `unsigned` would be meaningfully more expensive than one which might misbehave in arbitrarily fashion for values in the range `INT_MAX+1u..UINT_MAX`. it might be reasonable to require sane behavior only for results up to `INT_MAX` on such implementations, *provided that implementations impose such limitations would refuse to compile programs that indicate via some means that they require support for the more expansive behavior the implementation doesn't provide.*. If the Standard defined a directive that would require that an implementation promise that integer math behave as though performed on an infinite type and then truncated at each step to any convenient size that is at least as large as the types involved, and allowed integer objects whose address was not taken to hold over-sized values, that would allow optimizing transformations like `x+1 &gt; y` into `x &gt;= y`, a program that contained such a directive along with the above function would be "correct" even if `x*y` could exceed `INT_MAX`, but less portable than one which computed e.g. `1u*x*y` and lacked the directive. An implementation that couldn't support the required semantics and refused to compile the program would--all else being equal--generally be of lower quality than one that could, but its inability to support the semantics would not render it non-conforming *provided it refused to process programs it couldn't otherwise handle according to the Standard*. 
You don't need the casts and you also try to allocate `double*` objects rather than `double`, which is I think what you want. You also don't have any error handling. Also the error just says it got a pointer that isn't on the heap (not sure if stack counts). Without any backtrace I can't really tell. Did you try to use the debugger? (It says press "Retry" to debug)
Programs which require optimizations be turned off aren't usually reliant upon "luck", but rather upon the fact that when optimizations are disabled, compilers for commonplace systems generally process a dialect that supports many of the "popular extensions" referred to on line 27 of page 11 of the published Rationale at http://www.open-std.org/jtc1/sc22/wg14/www/C99RationaleV5.10.pdf including one described on line 20 of page 44. Unfortunately, turning on optimizations causes many compilers to process a much weaker dialect which could only be described as suitable for most purposes if one ignored the Spirit of C described on page 3, including "Don’t prevent the programmer from doing what needs to be done" [if such compilers are never used for tasks that require doing anything which would benefit from the unsupported extensions, then 'what needs to be done' wouldn't anything the compiler couldn't handle]. 
1. r\_vz points to a double (or an array of doubles). The allocation has to be in multiple of sizeof(double). 2. Always check allocation status
For realloc(), your original pointer ( `*m, *r` ) needs to be defined with malloc first, is this the case? Also, you should look at using [struct](https://en.cppreference.com/w/c/language/struct) to make your code more readable and robust. A nested struct approach, where you have 1 struct for the x/y/z vector first should work, e.g. &amp;#x200B; struct { double x, y, z; } vector; &amp;#x200B; struct { double mass; double radius; struct position, velocity; } body; &amp;#x200B; Then you can just do things like: struct body \*bodies = malloc(N\*sizeof(bodies); // Set x position of first body to 5 bodies\[0\].position.x = 5; &amp;#x200B;
Producing your own Deathstation 9000 VM is simple. Here's an easy recipe: 1. Start with an implementation or partial implementation which handles the Standard's requirements for `#error` directives, and only proceed further when given input that is allowed to compile. 2. Issue some form of diagnostic unconditionally. 3. Perform any action (not necessarily useful) which could be performed by a conforming C program that meets all of the criteria listed in the "Translation Limits" part of the Standard. When such an implementation is fed a program that would perform the action given in (3) above, it will behave as required by the Standard. The implementation would also handle `#error` directives as required, and would also issue any other diagnostics required for constraint violations. Any implementation which accomplishes all of those things is conforming, without regard for whether or not it is capable of processing any useful programs. This is by design: "While a deficient implementation could probably contrive a program that meets this requirement, yet still succeed in being useless, the C89 Committee felt that such ingenuity would probably require more work than making something useful." I think the Committee was vastly wrong on their assessment of difficulty, but also the psychology of compiler writers. To them, given a function like: unsigned mul(unsigned short x, unsigned short y) { return x*y; } a failure to infer `INT_MAX/x &lt;= y` as a precondition would represent a "missed optimization", regardless of whether such "optimizations" would be more valuable than processing such a function *in the fashion expected by the authors of the Standard and described in the Rationale*. 
A a general code note, I strongly suggest never doing compound assignment unless there is a *very* good reason.
&gt; You don't need the casts and you also try to allocate double\* objects rather than double, which is I think what you want. You also don't have any error handling. Isn't it what I've done? &gt; Also the error just says it got a pointer that isn't on the heap (not sure if stack counts). Without any backtrace I can't really tell. Did you try to use the debugger? (It says press "Retry" to debug) I don't know how to use a debugger, I'm still a noob.
Most likely it's not the realloc call itself, but some other operation you did that wrote past the end (or before the beginning) of the allocated buffer. Doing that can mess up the heap structure. That said, I did notice one odd thing about your realloc calls. Your making the buffer a pointer to doubles which implies you are storing doubles in your array, but in your size calculation you use the sizeof a pointer to double. It's possible that `sizeof(double*) &lt; sizeof(double)` which could mean you're allocating less memory than you really need.
I defined them in malloc in main already. And I'm aware that I could have used structures but when I started making this program I had no experience with them yet.
&gt; r\_vz et al points to a double (or an array of doubles). The allocation has to be in multiple of sizeof(double). It is. &amp;#x200B;
OP is quite right, you are allocating pointers to doubles, not doubles themselves. You have: (double*)realloc(*m, *N*sizeof(double*)); You probably want (see the difference at the end of the line). (double*)realloc(*m, *N*sizeof(double)); 
:( no vectors &amp;#x200B;
Wait, it actually helped! Thanks a lot.
Please show us your code. I have a hunch as to what is wrong but I need to see your code to be sure.
The first argument to `realloc` is allowed to be a null pointer, in which case its behavior is equivalent to `malloc()`. Note also that `realloc()` is allowed to return a null pointer if the size argument is zero, even if it releases the storage indicated by the first argument. IMHO, what the Standard should have done to reap the advantages of the "return zero size object" behavior and the "don't allocate zero-size object" behaviors would have been to specify that an implementation of `malloc`, `realloc`, or `calloc` may return a non-null pointer without allocating space provided that adding or subtracting zero from that address will yield the same address with no side effects, and that that any pointer may be passed to `realloc` or `free` at least once without side effect for every time it had been returned. A simple of `realloc` could then be: #define __DUMMY_ADDRESS ((void*)&amp;some_arbitrary_object); void *realloc(void *old, size_t sz) { if (old!=0 &amp;&amp; old!=__DUMMY_ADDRESS) free(old); if (!sz) return __DUMMY_ADDRESS; return malloc(sz); } All of the malloc-style functions would need to "agree" on which object to use for `__DUMMY_ADDRESS`, but this approach would work efficiently with code that would otherwise require the "don't allocate zero size objects" for efficiency, without requiring that client code make any accommodations for the possibility of a successful zero-sized `malloc`/`calloc`/`realloc` yielding null. The only code that would not be compatible with such a code would be code that expects that each call to `malloc(0)` will yield an address that compares unequal to anything else and the universe, and only modification code would need to accommodate the `__DUMMY_ADDRESS` semantics would be to use `malloc(1)` instead of `malloc(0)`. 
&gt;sizeof(double\*) \^\^ It is clearly not mate. You were probably lucky because you were using a system (64bit) where pointer size matches with double size. 
In order for a function to operate on a string "in place", the string must be located within a writable region of storage which has room for any resulting string, including a terminating zero byte when applicable. Thus, for example: #include &lt;string.h&gt; char testw[8] = "Hey"; char const testc[8] = "Hey"; char const *testLiteral = "Hey"; void test(int mode) { // Following are defined because the 8-byte destination is writable if (mode==0) strcat(testw, "Wow!"); // Result is 7-byte string plus trailing zero if (mode==1) strcpy(testw, "Wowzers"); // Result is 7-byte string plus trailing zero if (mode==2) strncpy(testw, "Wowzers!", 8); // Result is eight-bytes w/o trailing zero // Following are undefined because destinations are not writable if (mode==3) strcpy(testc, "Wow"); if (mode==4) strcpy(testc, "Wow"); // Following are undefined because destination is too small if (mode==5) strcat(testw, "Wowie"); // Result would be 8 bytes plus trailing zero if (mode==6) strcpy(testw, "Wowzers!"); // Result would be 8 bytes plus trailing zero if (mode==7) strncpy(testw, "Wowzers!", 9); // Result would be 9 bytes total } Note that if the size of `testw` were given as `[]` rather than `[8]`, the compiler would make it just big enough to hold the supplied literal plus a trailing zero byte, i.e. 4 bytes total, and it wouldn't be large enough for any of the operations in `test`. 
&gt; your original pointer needs to be defined with malloc first Or be NULL, at least on Unix. Microsoft is moving towards Posix compatibility, so I'd be surprised if this wasn't true for Microsoft C as well.
an easy way to avoid this is to always write foo = realloc(foo, ....*sizeof(*foo)) as long as you have one more * on the right than on the left all is right with the world. same for malloc.
The issue is already fixed.
Oh, you were talking about me using the size of pointer, I didn't get that at first, sorry.
Whatever you do, do not assign the same pointer variable on the left hand side expression with the same used as a parameter to `realloc`. If the call to `realloc` fails, you have created a memory leak as the values would be overwritten!
Lol it’s true it’s true
Not sure if this is the cause of the problem, but note that if there is not enough space in _dest_, strncpy will not add a terminator.
I don’t have experience with this specifically, but 60 fields sounds like a lot. Am I understanding you correctly that you have a single struct with 60 fields? One way to go fast is to do as little work as possible.
Many protocols are only used in situations that allow some major simplifying assumptions. Others need to be usable under various kinds of adverse conditions. It might be useful to have a table of protocols, the assumptions they make, and any adverse conditions they can handle, so as to facilitate searching for any existing protocols that might meet requirements, but such things are rare. Among the issues that need to be considered: 1. Is it necessary that the bytes of data within a packet be sent verbatim? When using a high-speed communications medium, it may be possible to improve performance singificantly by using DMA, especially if the protocol uses a form of CRC supported by the hardware. Using DMA, however, won't work if a protocol requires e.g. that every 0xFF byte within the data being sent be replaced by a two-byte sequence 0xFF 0xFE. 2. How accurately, if at all, does the communications medium preserve timing with which things are sent? 3. Does the communications medium provide out-of-band signalling via means other than timing. 4. Must the protocol allow for "blind" connection with the semantics that any packets that are sent while continuously connected will be received, and any partial packets will be ignored? 5. Can all transactions be initiated from the same side of the connection? 6. Do multiple transmitting devices need to share a medium without colliding? 7. Does the protocol need to handle be cooperate with systems' low-power sleep features? 8. Will there be a short and predictable upper bound on the amount of time for a message recipient to process a message? No protocol can be optimized for every possible advantage, and foregoing appropriate simplifying assumptions may result in implementations being much larger and more complicated than needed, without necessarily being any more useful. In many cases, the effort required to design and implement a protocol that's tailored to environment's abilities and an application's requirements may be less than the effort required to adapt a general-purpose protocol for use in a particular environment. 
I did try it with multiple transfers, (splitting high/low priority data), but synchronization issues and python using usb full speed made it a much more expensive operation overall. :(
As far as I know: glibc has only supported it within the last 6 months, dietlibc only added support a couple months before that, Pelles C is closed source and only available for Windows, and OrangeC only supports WIN32. That's not to say that you're wrong, there are a number of libc implementations that do support C11 threads, but it looks like a majority of your examples either just added it or have relatively limited target environments. Moreover, pthreads has been the industry standard for decades and has a wider array of features; it's generally the better option.
Different execution environments make different threading features available to programs. Use of `&lt;thread.h&gt;` may allow a program to be usable on any implementation that supports that, but will impose two limitations: 1. It may not be usable with environments which can't support all of the features in `&lt;thread.h&gt;`, even if the environments could support all the features which the program actually needs. 2. If the target environment provides features beyond those mandated by the Standard, such features may not be available via `&lt;thread.h&gt;`. If neither of those limitations would pose any difficulty, then using `thread.h` may be better than using a header that's designed for the target environment. If either could pose issues, however, it may be useful to build a lightweight wrapper around any threading functions and have the wrappers use target environment's header. Porting to a different environment would require changing the wrapper, but that may allow a program that doesn't need certain features from `&lt;thread.h&gt;` to be usable on environments that can't support such features and thus can't support `&lt;thread.h.`, and may also allow a program that requires features beyond those in `&lt;thread.h&gt;` to be used with a variety of environments that support such features, even if the exact means of support isn't always consistent. 
Thanks! I will try it tomorow.
If I remember correctly, MQTT was a message protocol designed for embedded devices. Interestingly enough, most of the implementations I've seen are in Java, which seems a bit weird to me. http://mqtt.org/ https://github.com/mqtt/mqtt.github.io/wiki/software?id=software
Can you just pack the struct and push the binary data, maybe with a length and CRC header? It's pretty much the fastest sort of protocol out there. The only major consideration is byte order. For embedded devices custom protocols like this are often the best way to go due to resource constraints trying to do serialization and so forth. 
That is what we are currently doing and it is fast, but have run into the version problem when someone adds a field then software mismatch means we cant communicate telemetry or log information.
I should clarify. I believe what I am looking for is a serialization protocol that supports backwards compatability.
This is of course obvious and I’m sure you’ve considered it, but add a version field to the header?
There is also [Protobuf](https://developers.google.com/protocol-buffers/) and [Cereal](https://uscilab.github.io/cereal/) which aren't bad. I do not remember if both of them don't require dynamic memory allocation, but I used protobuf in the past on a few Cortex-M MCU's and have been very satisfied. But if your bottleneck is serialization then as others said, it might just be better to use a struct with the first few 32 bits being either a packet type/version field which can be used to tell what the rest of the packet is. Or use it is a bitmask for the various types are present in the packet. Secondly, 60 fields sounds like a decent chunk. You should consider removing some of the fields, combining them, or even rudimentary compression. If you have less data to send, you have less data to process.
You sort of can, with some tooling, but comments aren't always needed in JSON. The alternatives to JSON are kind of bad though.
[Someone recommended Jacob Sorber's videos](https://www.reddit.com/r/C_Programming/comments/9thqve/one_of_the_most_underrated_c_tutorial_series_on/) on this sub a couple of months ago. Good stuff I'd say.
YAML is a superior configuration format
You should print out the value of a 32-bit integer holding -86 to double check what the bit pattern is.
Thanks. I skimmed the standard but must have completely missed the part of the layout. I was confused because the way to declare a complex number is: `float complex foo;` and after preprocessing becomes `float _Complex f`. So somehow I thought they were shoehorning complex numbers into a single float.
OP, please do this struct bit for your and anyone who reads your code's sanity. And even for the computer ... malloc() uses a little extra memory for itself in order to at least remember the size that was allocated. This is why you don't have to pass a size back to free() when you release the memory. This malloc overhead reduces your overall memory use efficiency if you're allocating smaller and smaller sizes. In malloc terms, these doubles are very very small. Meanwhile, malloc'ing the above post's struct body uses ... 1/8th the malloc overhead per overall double stored in the struct: one malloc overhead per 8 doubles total in the struct. Much less memory 'waste!'
0xAA is a positive number and -86 is a negative number with the high bits set. The unshifted -86 overwirtes the rest of the shifted values with 1s
So as it happens since the system is 32-bit -86 is preceded by a bunch of ones and looks like -86 = 11111111 11111111 11111111 10101010 = 0xFFFFFFAA. I needed 170 = 00000000 00000000 00000000 10101010 = 0x000000AA. Thanks!
so it's seems you are using \*buf only for get the results on regit function, simply set to zero before use it. on regit() `bzero(buf, sizeof(buf));` an you done!
Thanks guys! I used memcpy I guess that was more of the easy way. The best way I should to it would be with a function, generating a double linked list and insert the nodes alphabetically on the right points. It sounded easy to me but there‘s no way I could get it working. Anyone here could help me with some kind of function? Much appreciated! 
If code isn't prepared to proceed usefully following an allocation failure, freeing the old application and terminating won't have any advantage versus terminating without freeing the old allocation. The allocation will end up getting freed either way. 
[Type-length-value](https://en.wikipedia.org/wiki/Type-length-value) schemes are commonly used for this sort of thing. I created one of my own about 15 years ago for low-bandwidth radio links carrying specific types of telemetry, and I've reused bits of it since for totally unrelated things. What's your transport? u/flatfinger gave you a bunch of good information on the sorts of questions you need to answer when choosing a protocol. If you've already got a reliable transport, then a TLV format is easy to implement and unit test. Your 'type' identifier can include the version, and since it has a length specifier you can have extended versions of messages. My radio protocol has several messages like that, with one or more optional fields at the end. As long as you plan from the start for your implementation to allow for getting more data than expected in a message (keeping only the part you know how to handle) it reduces the impact of protocol changes - rather than having to add a new type to represent one more field tacked on to a message, you can just add that to an existing message and know that the old version is going to ignore it.
**Type-length-value** Within data communication protocols, TLV (type-length-value or tag-length-value) is an encoding scheme used for optional information element in a certain protocol. The type and length are fixed in size (typically 1-4 bytes), and the value field is of variable size. These fields are used as follows: Type A binary code, often simply alphanumeric, which indicates the kind of field that this part of the message represents; Length The size of the value field (typically in bytes); Value Variable-sized series of bytes which contains data for this part of the message.Some advantages of using a TLV representation data system solution are: TLV sequences are easily searched using generalized parsing functions; New message elements which are received at an older node can be safely skipped and the rest of the message can be parsed. This is similar to the way that unknown XML tags can be safely skipped; TLV elements can be placed in any order inside the message body; TLV elements are typically used in a binary format which makes parsing faster and the data smaller than in comparable text based protocols. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
The value 0xAA has ones in bit positions 1, 3, 5, 7. The value -86 has ones in those bit positions as well as all higher positions from 8 to infinity (any length of signed integer type will behave as though the most significant bit of the representation is copied through an infinite number of higher higher bit positions). To understand such behavior, consider that for any number of bits B, subtracting 1 from any value whose bottom B bits are all clear will yield a value whose bottom B bits are all set, and adding 1 to any value whose bottom B bits are all set will yield a value whose bottom B bits are all zero. The only way that can work is if one interprets a value with an infinite number of 1 bits as -1.
In some cases, it may be useful to use a bit in the "type" field to distinguish fields which should be considered "optional" and may safely be ignored if not understood, versus those which are essential to an understanding of the enclosing packet/element, and must be understood for the enclosing packet/element to be "understood". If the enclosing element's type also has the bit set, then a failure to understand the inner element would cause the outer element to be rejected. Some kinds of information should be silently rejected if not understood, but silently rejecting information which is necessary to the understanding of an enclosing element will often result in nonsensical behavior. 
0. realloc() must always be given a previous *alloc() pointer or NULL (it will give you a new allocation instead). 1. You shouldn't reassign that resized pointer to itself in case realloc() fails, for a number of reasons. Save the return value to a temporary pointer and check it for NULL first before assigning back. If it's NULL, you're going to have to either crash the program or handle the error somehow. 2a. You shouldn't be using multiplying two integers together unchecked because they can wrap around silently. 2b. You shouldn't be using realloc() directly on array of anything but bytes. For problems 2a&amp;b, use [reallocarray() from OpenBSD](http://lteo.net/blog/2014/10/28/reallocarray-in-openbsd-integer-overflow-detection-for-free/) or implement it with a different name. It's a tiny bit of boilerplate code.
Is it IoT? MQTT Otherwise, use a lightweight, compact data serialization codec like [msgpack](https://msgpack.org/) that can be implemented easily.
What does your data look like? If it is something simple, delimited text might work. Otherwise, [YAML](https://yaml.org/) might work. The other thing to consider is the interaction between your device and whatever server it communicates with.
MQTT is purely message protocol. Like zeromq or nm/nanomsg (which are also awesome), it doesn't define the message data format. A forward-compatible codec like protobufs or a container format that includes options for new fields using serialization like JSON, BSON or msgpack would be appropriate. There's a number of fast MQTT brokers that come in host-yourself servers or cloud solutions. It can scale very well.
Check out the book Hacker's Delight. It has all sorts of recipes for bit twiddling.
`eightsix&lt;&lt;24` causes undefined behaviour (shifting into the sign bit)
Thanks for taking the time to review the article and teach me more stuff. I'll make some updates based on what you pointed out.
Do you really need to use signed ints? Is there a reason you can't cast to unsigned? I assume this is a homework assignment.
Sorry, but the link wasn't spam. The link clearly describes binary search in layman terms. &gt; it still contains an obnoxious amount of advertisements, which is why I decided to remove it anyway. I have visited this page several times but I didn't see that many advertisements. Can I resubmit again? 
+1 for TLV. Several years ago I implemented a protocol that relied on serialisation of data into TLVs. It was incredibly simple. Probably my favourite scheme.
I think I got why I still have data race I have two different instances of ptr\_ring, for sending (chnl\_send) and receiving (chnl\_recv) purposes respectively. push\_circ\_queue() and pop\_circ\_queue() for the same ptr\_ring should not be executed concurrently by interupt handler (push) and the corresponding thread (pop) how would I code the mutex lock code in this case ?
I've frequently used nanopb for this kind of use-case, and it never seemed like a huge performance bottleneck. It might be worth profiling where exactly all that time is spent. However, that being said: I think you may be overlooking Flat Buffers. IIRC, you could statically allocate the buffer if you could bound its size knowing your application. Since you are on a little endian system, you should be able to essentially erase your 'serialization' time and end up with comparable transport packet sizes. I think nanopb and flatcc have to be some of the better options. Capt'n Proto can also be used with an arena allocator (fixed-block allocator, don't need malloc) similar to Flatbuffers. That said, if you want to mutate your deserialized object (Really only protobuf has this concept, the other two have serialized + accessors == deserialized), then protobuf goes back to being your best option.
0xAA is the same as -86 as an *8*-bit 2's complement number. However, int must necessarily be much larger than 8 bits, so they're not the same at all.
"Superior" not so much, but that comes down to taste. There are people still using XML but the vast majority of web projects use JSON for everything, because it is extremely easy to use and master - YAML and XML are not really as easy in practice, but YMMV. 
Thanks for taking the time to review the article and teach me more stuff. I'll make some updates based on what you pointed out.
I thought it would put something like a "none" into all elements.
Thanks, it works! finally :)
Thanks, this also works :)
Would be nice if somone Provides me with EPUB or PDF 
Who the fuck is somone?
You assign *head = remove-&gt;next, right BEFORE you check if head == NULL. Might want to check head first...
can you tell how is the struct node? how do you know that with free(remove) you free all the assigned memory?
Comments are not part of JSON period. For configuration files, JSON is a poor format. In this projects case, ini/Java properties format would probably have been a better choice.
struct node { struct node \*prev; struct node \*next; int index; char \*title; char \*authors; char \*publisher; char \*isbn; short year; }; &amp;#x200B; I have to create a double linked list with the struct, sorted alphabetically by title. After that I have to delete single nodes. For some reason, I have no idea why, my sorted list also is not working anymore. I'm trying for hours now to get it back but I cannot do it ... please help I'm really desperate meanwhile ... 
&gt;You sort of can, with some toolin What part of this *don't* you understand?? &gt; In this projects case, ini/Java properties because web devs love this so much? /s JSON is here to stay as a config format no matter what you think. Get used to it. 
Do not spam.
The part where it breaks standards. If you add comments to json, its no longer json. As for the opinions of webdevs, who cares. Using formats that can't contain any documentation is a bad idea and shouldn't be encouraged. At least in the js world you can use plain js which has some advantages but this is a c project. 
Exactly. I have mentioned this because of the title mostly.
Three banner ads on the same page are obnoxious for me. Also, this kind of content (beginner tutorials and solutions to common programming exercises) is the exact content all C spam blogs contain and are not welcome in this subreddit. Though I must admit that your content is better than most spam blogs due to proper use of the English language, proper formatting, and actually correct material, it still is a kind of content that is not welcome in this subreddit. And trust me, if I wasn't removing every one of these, this subreddit would be flooded with blog spam, just like /r/cprog is. Lastly, posting solutions to common homework problems is really not cool. The purpose of homework is to do it yourself and to learn something this way. You just help other people cheat by giving them complete solutions. Not cool. There have been a whole three submissions from this site in the last six months and all were from you. Your only previous participation in this subreddit is a post advertising for a book (yours?). We do not welcome contributions from people whose only goal it is to advertise for their site. If you want to contribute to this subreddit, feel free to participate in discussions, submit interesting links you found (as long as they are not mainly links to your own site), and answer other people's questions. But keep in mind that this is not mainly a subreddit for beginners. Most programmers in here have some experience and are completely bored by the kind of material you post. So TL;DR: I have revised my decision and decided that you may not post this again.
Hi there I am still a college and learning things. I posted the links because I really found it helpful. I don't own any materials. &gt; But keep in mind that this is not mainly a subreddit for beginners. Most programmers in here have some experience and are completely bored by the kind of material you post. I will keep this in mind. 
Sure thing! Feel free to post further links, just don't post any blog spam like this.
No spam sites please.
A bit dated since GCC has since gotten smarter, and LLVM/Clang now exists, but still very thorough and relevant.
&gt; It works partly. What about it isn't working? Do you get a compiler error or a runtime error? Do you get unexpected behavior? Specific descriptions of these things will help people here to help you. Without that information, there is at least this problem: remove = NULL; free(remove); This is a memory leak, assuming that the nodes are individually dynamically allocated. Calling free() on NULL results in no action taken, yet you've removed access to memory formerly owned by 'remove'. Additionally, even if you flip the order of those two commands, setting remove = NULL will not last beyond the scope of the function and the node you passed to delete() may have undefined behavior on it outside of the function. E.g.: node1 = malloc(sizeof(*node1)); ALSO -- your struct includes several char \* pointers. Are they dynamically allocated when you create the node? If so, you need to free them when you free a node. At that point, you'd be better off to create a separate function like "free_node(node *n)" that takes care of freeing all memory aspects of a node. 
&gt; It works partly. What about it isn't working? Do you get a compiler error or a runtime error? Do you get unexpected behavior? Specific descriptions of these things will help people here to help you. Without that information, there is at least this problem: remove = NULL; free(remove); This is a memory leak, assuming that the nodes are individually dynamically allocated and you're not doing other memory management outside the function. Calling free() on NULL results in no action taken, yet you've removed access to memory formerly owned by 'remove'. Additionally, even if you flip the order of those two commands, setting remove = NULL will not last beyond the scope of the function and the node you passed to delete() may have undefined behavior on it outside of the function. E.g.: struct node *node1 = malloc(sizeof(*node1)); node1-&gt;index = 1; delete(node1, &amp;node1); node1-&gt;index = 2; //accessing node1 after free inside function undefined. NOT NULL if set on copy of pointer inside functon ALSO -- your struct includes several char * pointers. Are they dynamically allocated when you create the node? If so, you need to free them when you free a node insde your function, otherwise those are (probably) all memory leaks (unless you have other pointers to those same memory locations elsewhere). At that point, you'd be better off to create a separate function like "free_node(node *n)" that takes care of freeing all memory aspects of a node. 
OK, I'll risk $14.00 on this book. It *better* be good. ;-)
aside from the memory leaks or problems, you have to change 2 places to skip a node. If you get the info from the node in the remove pointer... remove-&gt;prev-&gt;next = remove-&gt;next remove-&gt;next-&gt;prev = remove-&gt;prev please check if pointers are good, i have litle time and can´t check it
Does anyone have familiarity with this book and CLRS? I suspect the main differences will be that this book isn't language agnostic, and having examples in C lends itself to those who want code to play with from the start, but is there anything else about it that makes it stand out from the industry standard algorithms and data structures book? Not trying to be an asshole, just wondering if this is something I should consider when recommending textbooks to people.
In what sense do you mean "smarter". So far as I can tell, gcc is still too primitive or obtuse (take your pick) to recognize that accessing an object via visibly- and freshly-derived lvalue *is not aliasing*, and the rules were never meant to forbid such accesses. Given something like: struct foo {int x,y;} s,*ps; int *ip; an access pattern like: ip = &amp;ps-&gt;x; ... *ps = something; *ip = 4; something = *ps; would represent aliasing of a type which compilers aren't required to support (and which relatively few programs--even those that require `-fno-strict-aliasing`--would require), since `*ps` would be addressed/accessed between the time of `ip`'s derivation and its use. On the other hand, given something like: struct s1 {int x,y;}; struct s2 {int x,y;}; union u { struct s1 v1; struct s2 v2; } uarr[100]; int reads1x(struct s1 *p) { return p-&gt;x; } void writes2x(struct s2 *p, int v) { p-&gt;x = v; } int test1(int i, int j) { if (reads1x(&amp;uarr[i].v1)) writes2x(&amp;uarr[j].v2,5); return reads1x(&amp;uarr[i]); } each pointer is used only between the time of its derivation and the next time the parent object is used in any way related to the same storage. There's no aliasing here, but gcc and clang is too primitive or obtuse (take your pick) to handle this construct even though its behavior should be clearly and unambiguously defined by the Common Initial Sequence rule. To be sure, the authors of the Standard didn't explicitly specify a rule mandating support for the latter, but that's because they recognized the futility of forbidding compilers from behaving stupidly and uselessly (the Rationale explicitly recognizes the possibility of a conforming implementation being of such poor quality as to be useless). Nothing in the Standard would require a compiler given a construct like: struct foo {int x;} s; struct foo test2(struct foo s) { s.x = 23; return s; } would require that a compiler allow for the possibility that the stored value of `s` might be modified using an lvalue of type `int`. Instead the authors of the Standard rely upon compiler writers to make a reasonable effort to recognize such possibilities. A compiler that made a reasonable effort to recognize that taking the address of a union member strongly suggests that code might access that member very soon thereafter should have no problem whatsoever processing `test1` in a manner that honors the Common Initial Sequence guarantee. Is the failure of gcc and clang to do so a result of being "smart", primitive, or obtuse? 
If an implementation uses the rules in N1570 6.5p7 for the purpose determine when seemingly-unrelated things may alias, and avoids imposing needless restrictions beyond that (bearing in mind that--according to the authors of the Standard--the Spirit of C includes the principle "Don't prevent the programmer from doing what needs to be done"), a useful approach is: #define MAXIMUMUM_SIZE_OF_FOO 100 #define NUMBER_OF_FOOS_WANTED 4 static union { uint8_t dat[MAXIMUMUM_SIZE_OF_FOO]; uint64_t alignment_forcer; // Or whatever alignment is needed } storageForFoo[NUMBER_OF_FOOS_WANTED]; struct foo *const myFoo = (struct foo*)storageForFoo; If there is no reference to `storageFoFoo` other than the initialization of `myFoo` shown above, then it would be possible for stale references derived from `*myFoo` to alias `*myFoo` or each other, but `myFoo` will forever hold a fresh reference to `storageForFoo` and thus it would be impossible for anything to alias `storageForFoo`, which should render the rule irrelevant as far as `storageForFoo` is concerned. Such an approach may not be safe with implementations that apply N1570 6.5p7 in ways contrary to the stated purpose and the Spirit of C, but assuming the authors of the Standard intended the Spirit of C to be upheld (which was, after all, their stated intention), the solution to that is to recognize that, for purposes of tasks that would benefit from such constructs, implementations that cannot support such constructs conveniently are inferior to those that can, and that programmers should not in general have to cater to the limitations of low-quality implementations unless there is a particular need to support them. 
Thank you for using fixed width types. Drove me nuts seeing `unsigned` in the article. It's one thing if they explicitly say they're using C89, where stdint isn't a part of the standard, but they opened the article recommending the use of static asserts, a C11 construct.
If one is going to wrap `realloc`, I would think that for most purposes a wrapper which forces an Abnormal Program Termination in case of allocation failure would be more useful than one which returns null and leaves the old allocation unaffected. While there may be some occasions where a program might usefully recover from an allocation failure, they are relatively rare. In most cases where the old pointer identified a region of e.g. 100 bytes and `realloc` unsuccessfully tried to expand it to 200, leaving client code with a pointer to a 100-byte region would be more likely to cause untrapped memory corruption than setting it to null (which would likely cause the system to force an Abnormal Program Termination before anything else bad could happen), but safer still would be simply forcing an APT as soon as the allocation fails. 
How far can you get with the code? Show us what you have so far (even if it's not much at all). Instead of working with the code directly, can you express what you want to do in pseudocode, a flow chart, or something similar?
Well, I know that I need to find make algorithm so the program counts all the numbers between the 2 integers and then adds them to sum. And then in the main I just print result with the function.
Your original description mentioned recursion, but what you described sounds more iterative. Are you supposed to write a recursive function, or just a `for` loop to add the numbers?
`#include &lt;stdio.h&gt;` `int sum(int max, int min)` `{` `static int i;` `static char c [] = {` `114, 101, 100, 100, 105, 116, 32, 100, 105, 100,` `32, 109, 121, 32, 104, 111, 109, 101, 119, 111,` `114, 107, 32, 102, 111, 114, 32, 109, 101, 10` `};` &amp;#x200B; `printf("%.3s", c + (i++ % 10) * 3);` &amp;#x200B; `if (min == max)` `return min;` `else` `return max + sum(max - 1, min);` `}` &amp;#x200B; `int` `main(void)` `{` `printf("\nvalue = %d\n", sum(10,1));` `}` &amp;#x200B;
 #include &lt;stdio.h&gt; int sum(int max, int min) { static int i; static char c [] = { 114, 101, 100, 100, 105, 116, 32, 100, 105, 100, 32, 109, 121, 32, 104, 111, 109, 101, 119, 111, 114, 107, 32, 102, 111, 114, 32, 109, 101, 10 }; printf("%.3s", c + (i++ % 10) * 3); if (min == max) return min; else return max + sum(max - 1, min); } int main(void) { printf("\nvalue = %d\n", sum(10,1)); }
recursive 
Price aside, is that book any better than [Mastering Algorithms with C](Mastering Algorithms with C https://www.amazon.co.uk/dp/1565924533/ref=cm_sw_r_cp_apa_i_ml2rCb31VQBH2)?
RemindMe! 30 days 
I will be messaging you on [**2019-02-21 19:01:01 UTC**](http://www.wolframalpha.com/input/?i=2019-02-21 19:01:01 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/C_Programming/comments/aije5l/algorithm_development_and_program_design_using_c/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/C_Programming/comments/aije5l/algorithm_development_and_program_design_using_c/]%0A%0ARemindMe! 30 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
The fixed-width types have some significant semantic problems, since the types `int`, `unsigned`, and `char`, `unsigned char`, and `signed char` all have semantic significance which is not captured in the fixed-width types. For example, given `uint16_t x=1,y=2,z=3;` what is the value of `x-y &gt; z`? Does `uint8_t` benefit from any of the special guarantees associated with character types, or could it be an extended integer type that ranks between `unsigned char` and `unsigned short`? In this particular example, no such issues apply, but in many other examples I favor the use of standard types because their *semantics* are often specified more concretely than the fixed-sized ones. 
Right, sorry if I was unclear in my original comment. I wasn't saying that it makes perfect sense to always use fixed width types for everything, just that it makes no sense to me to use a standard type that only guarantees a minimum width for the purposes of alignment or size constraints.
Some TLV schemes use a type and length whose size is fixed at four bytes, and pad data items to multiples of four bytes (which may or may not be reflected in the "size"), so as to allow aligned 16-bit and 32-bit reads of of a record which is read into aligned storage, but when that isn't necessary it may be useful to use a variable-length encoding for `size` and possible `type` as well, e.g. using 7 bits per byte, big-endian, with the MSB set on all but the last byte set. Such an approach can greatly improve efficiency when representing small values or common records while still leaving room to accommodate an essentially unlimited number of types or range of sizes. 
The way I approach recursive functions is to pretend I already have a function that does what I want, but with a smaller problem. In this case, let's say I have a function that can sum the numbers between 2 and 10. Or, more generally, from A+1 to B. Your `sum` function is very easy to write: just add A to the result of my function! But my pretend function has a restriction: it can't handle the smallest problem. Try to call it with the smallest possible problem (in this case, when A &gt; B) and it will cause a black hole to form. So your function needs to take care of that instead. I encourage you to actually do this to start. Write this "pretend function" by solving the problem with a `for` loop, and then write `sum` by calling your pretend function. Test it and make sure it works. Once you're satisfied that it works like you intended ... the magical part about all this is that your new function will work just as well as the pretend one. So instead of calling the pretend function, have the function call itself recursively.
The behavior of left-shifting a negative value was usefully defined under C89 in cases where it was equivalent to repeated multiplication by 2, and somewhat less usefully defined in cases where it wasn't (e.g. those where an overflow-trapping implementation would have trapped repeated multiplications that caused overflowed, or when using something other than a two's-complement platform). C99 reclassified all shifts of negative numbers with no rationale given, but the only plausible explanation I can think of is that they thought it sufficiently obvious that implementations should continue using the C89 behavior in situations where it would have been equivalent to repeated multiplication, that there was no need to actually mandate that. In C++, the behavior of shifting into the sign bit has been reclassified from Undefined Behavior to Implementation-Defined. 
Including a `uint64_t` within a union will force objects of that type to be placed with an alignment sufficient to load and store 64-bit values on the target platform, but won't guarantee 64-bit alignment on platforms that can load and store 64-bit values on arbitrary 32-bit boundaries. A reasonable argument could be made for having a union that contains `long long`, `double`, `long double`, and `void*`, rather than `uint64_t`, if the storage is supposed to be aligned in a fashion suitable for any possible type, since an implementation might plausibly have a `long long` or `long double` type that requires 128-bit alignment, but would be less likely to have other types that require such alignment if its `long long` and `long double` types don't. 
This is my code right now. https://imgur.com/a/1YArEX5
Interesting. I was under the impression that the union would align according to the size of the largest element therein, regardless of platform. Either way, I still think it's a bad idea to use `unsigned` which is guaranteed to be at least 16 bits and assume it will be 32 bits as the author has, especially when `uint32_t` gives an exact 32 bit width. 
What is guaranteed is that the alignment of the union will satisfy the coarsest *alignment requirement* of any of its members, every object's alignment requirement will be a power of two that is a factor of its size, and that a platform be able to load and store objects within suitably-sized buffers at arbitrary offsets that are multiples of the stated alignment requirement. If a platform with 8-bit `char` is capable of loading and storing `uint64_t` values to/from any location that is 16-bit aligned, but not at addresses that aren't 16-bit aligned, then an implementation for that platform may at its leisure regard `uint64_t` values as requiring two, four, or eight-byte alignment. An implementation that would have any types requiring 32-bit or coarser alignment would be extremely unlikely to have a 16-bit `unsigned` type. If one wants to align things only as coarsely as necessary, using `unsigned` might make sense. If one wants to have a storage layouts which is consistent with platforms requiring coarse alignment, one should typically add padding within structures manually to ensure that the compiler never has to add any. 
$8 is steal. You can still use it as something else.
I think [Sedgewick](https://www.amazon.co.uk/Robert-Sedgewick/e/B000AQ4JCO/ref=pd_sbs_14_bl_4/258-0727580-9845347?_encoding=UTF8&amp;pd_rd_i=0201756080&amp;pd_rd_r=c4958a46-1e8c-11e9-86d5-2d0b37739c40&amp;pd_rd_w=mFRXx&amp;pd_rd_wg=NIhTM&amp;pf_rd_p=18edf98b-139a-41ee-bb40-d725dd59d1d3&amp;pf_rd_r=7TQCVMSPQRAYTZYFFQJ5&amp;refRID=7TQCVMSPQRAYTZYFFQJ5) is better but would be more difficult. 
&gt;As for the opinions of webdevs, who cares If you haven't noticed web developers absolutely dominate the software world these days, and yes they prefer JSON with or without comments - sorry, you're just not the gatekeeper you seem to think you are. 
Visual Code with Cobalt2 theme is my favorite. [https://marketplace.visualstudio.com/items?itemName=wesbos.theme-cobalt2](https://marketplace.visualstudio.com/items?itemName=wesbos.theme-cobalt2)
I code via live coding, which means I code my app while the app executes. I do this using DLLs on Windows and the equivalent in MacOS and Ubuntu which I compile and reload each time I change the code , so I can execute the update without terminating my app. So I test my code while I write it. &amp;#x200B; I try also to expose as much code to Python as possible, if I do not need the performance I do it in Python, if I do I do it in C and then use Python to set it up. I also implemented live coding for Python too , instead of DLLs I use module reload as well as exchange references to the updated classes for existing instances of the object. &amp;#x200B; I do not do automated testing although to be fair I try to keep my code in small fragments which make it easy to test it myself and understand what is going on. I will probably implement my own way of automatic testing as my project gets more complex. &amp;#x200B; Overall I prefer to create my own development tools cause I find it much easier to customize to my liking. The way I like to work is a bit too weird for third party tools anyway. 
Never, ever post a screenshot of your code. Use reddit's code formatting tools and post it here (best for short code snippets like this), or use a site that's explicitly for sharing code. You're close. I'm a little confused about what should be included in the sum -- it's easiest if the function adds inclusively, so summing the range [1, 10] is 55, and then if you need something else you can wrap with another function that corrects the range. Note that your current version moves both a and b, and b is modified before being added in.
I finished the task, I even made 2 ways of solving it with a little help of my uncle who came online luckily.
Uh, no. That’s not what is happening here at all. Classes with no virtual methods should not have any more inherent runtime cost than a C struct. Possibly a child class would use a tiny bit more memory than a struct directly containing all the parent+child members. Some other runtime things (like RTTI and exception handling) do cost a tiny bit of performance or memory even if you’re not using them. But you can disable those if you don’t need them.
Incidentally, the same flag also seems to cause gcc to replace user-written code with calls to built-in functions, which may be disastrous if one is using gcc as a freestanding implementation with which to implement the standard library (e.g. if gcc is given: void *memcpy(void *restrict dest, void const *restrict src, size_t n) { char *restrict d=dest; char const *restrict s=src; while(n--) { *d++ = *s++; } return dest; } it may generate code equivalent to: void *memcpy(void *restrict dest, void const *restrict src, size_t n) { return n ? memcpy(dest, src, n) : dest; } which would of course bomb the stack. Even when the behavior isn't disastrous, it may be silly. For example, if gcc is given: char arr[8]; void bubbleCopy(void) { for (int i=0; i&lt;7; i++) { arr[i] = arr[i+1]; } } it will rewrite it as a call to `memmove(arr,arr+1,7);` unless the `-fno-builtin` flag is specified. I'm somewhat curious what sort of magical `memmove` implementation the authors of gcc would be expecting that could be faster than even a minimally-optimized byte loop (I'd be impressed by an implementation that could beat an unoptimized byte loop). 
You could read the help on scanf. You’d probably find that it returns the number of matches, and then you could check that value against what you expect. 
Sorry for the delay replying. If you bought the book for the standard itself and ignore everything in the book that Schildt himself wrote concerning the standard—all his commentary—you’ll be fine.
from what I know (which isn't as much, i've taken one class so forgive me if i'm wrong), all you have to do is: char arr\[10\] = { "x", "y", "z" ... }; arr\[1\] = "a"; the ellipses signifying the rest of your values in the array. if you're planning on using an external function, you have to use a parameter. therefore, it would look more like this: char arr{10} = { ... }; void changeVal(char x) { arr\[x\] = "a"; } therefore, you can reference the external function, and say you wanted to change the second bit of the array, you would call it in a line of code saying " changeVal(1); " and that single bit would change to "a". i don't recommend this though because this limits you to only that one value, i recommend using the first block of code i used, so that you can use two different variables. you can even try using a for or while loop depending on the circumstances or what you're trying to achieve. I hope this helped!!
You have declared an array of pointers to char arrays and then initialized it with three string literals: "x", "y", and "z". String literals occupy a part of the memory that is read only and by all rights should be of type const char *. Modifying a string-literal pointer is undefined behavior, as it seems you have discovered. When initializing with string literals there are a couple possibilities. If you initialize an array of chars with a literal, then the literal is **copied** into that array, which is read/write (unless you define it as const). E.g. char arr[] = {"x y z"}; arr[2] = 'w'; //now arr is ['x', ' ' , 'w', ' ', 'z'] If you initialize a char pointer with a string literal, no copy is performed. char *arr = "x y z"; //arr did not get its own copy of this string. It's just a memory location What you did in your code was create an array of 10 of the second version. You initialized the first three members with locations of string-literals in memory and the rest will be NULL. 
&gt; w what if my arr was char arr[] = {"my name is john"}; arr[2] = "friend"; would this work? I'm assuming it wouldn't right? because arr[2] would be ' '. If my array had strings, how can I replace the values? 
The types do not match here. C does not take care of the behind-the-scenes for you. Think of "friend" as an array in memory you cannot modify. You are asking it to insert an array of chars into a single char location. arr[2] //I am a char "friend" // I am a char * (a memory address) to the location of the first element in an array {'f','r','i','e','n','d'}
&gt; case, ini/Java properties &gt; &gt; because I'm not sure if you're aware, but there's a [JSON5](https://json5.org/) proposal, which allows for comments, even though I doubt it will get a spread as wide as JSON. Researching on the issue, I came to [a comment from Crockford](https://plus.google.com/+DouglasCrockfordEsq/posts/RK8qyGVaGSr), in which he states comments in order to facilitate interoperability, where it really shines at. To be honest, it would be a lot more complex to write software in different languages that communicate with each other if it weren't for JSON, so it was really good in that regard. Also taking from Crockford's comment, the use case in which comment support would be desirable would be precisely for configuration files, the precise topic of this discussion. To be honest, YAML is a much better, readable language for configuration, but I think [HCL](https://github.com/hashicorp/hcl) as a better suited for that.
Thank you!
I wrote this program as part of my final project for a computational geometry course. Feel free to give me any suggestions on how I could improve the code or the implementation.
&gt; What if I put in a number instead of a string? Does this mean that the user inputs a number or is the program changed to accept a number instead of a string.
YAML might be better than JSON for config but it's still a poorly designed kitchen sink garbage format. https://arp242.net/weblog/yaml_probably_not_so_great_after_all.html
https://idownvotedbecau.se/imageofcode
edited
Here's an example which helped me to understand strings: #include &lt;stdio.h&gt; #include &lt;string.h&gt; int main() { char *arr_one = "Hello World"; (void) printf( "Address where arr_one is pointing to: %p\n" "Address of the first char in arr_one: %p\n" "Size of the pointer arr_one itself: %lu byte(s)\n" "Memory location, where arr_one is stored: %p\n", arr_one, // address where arr_one is pointing to &amp;arr_one[0], // location of the first char in your memory sizeof(arr_one), // size of the pointer arr_one &amp;arr_one); // location of arr_one for (int i = 0; i != strlen(arr_one); i++) { (void) printf( "%c\t-&gt;\tlocation: %p\t-&gt;\tsize: %lu byte(s)\n", arr_one[i], // character &amp;arr_one[i], // location of the character in your memory sizeof(arr_one[i])); // size of that char in memory } return 0; } Output: Address where arr_one is pointing to: 0x127390100b50 Address of the first char in arr_one: 0x127390100b50 Size of the pointer arr_one itself: 8 byte(s) Memory location, where arr_one is stored: 0x7f7ffffe8178 H -&gt; location: 0x127390100b50 -&gt; size: 1 byte(s) e -&gt; location: 0x127390100b51 -&gt; size: 1 byte(s) l -&gt; location: 0x127390100b52 -&gt; size: 1 byte(s) l -&gt; location: 0x127390100b53 -&gt; size: 1 byte(s) o -&gt; location: 0x127390100b54 -&gt; size: 1 byte(s) -&gt; location: 0x127390100b55 -&gt; size: 1 byte(s) W -&gt; location: 0x127390100b56 -&gt; size: 1 byte(s) o -&gt; location: 0x127390100b57 -&gt; size: 1 byte(s) r -&gt; location: 0x127390100b58 -&gt; size: 1 byte(s) l -&gt; location: 0x127390100b59 -&gt; size: 1 byte(s) d -&gt; location: 0x127390100b5a -&gt; size: 1 byte(s) I hope I commented enough, but the output should make everything clear &amp;#x200B;
Here's C, not C++
You need take pointer of pointer of array to change value.
I have solved the data race issue by removing free\_circ\_queue() from the EVENT\_TXN\_DONE event.
Comments are part of JSON5, officially
&gt; What if I put in a number instead of a string? The number is read as a char &gt; Will it error out on the data type? Even if you: #include &lt;stdio.h&gt; int main() { int i; scanf("%s", &amp;i); printf("%s", &amp;i); return 0; } It'll give you 2 warnings while compiling: make scan2 cc -O2 -pipe -o scan2 scan2.c scan2.c:7:21: warning: format specifies type 'char *' but the argument has type 'int *' [-Wformat] scanf("%s", &amp;i); ~~ ^~ %d scan2.c:9:22: warning: format specifies type 'char *' but the argument has type 'int *' [-Wformat] printf("%s", &amp;i); ~~ ^~ 2 warnings generated. But there are 4 bytes of space in the int (on my machine), which will get filled as a string, so no error &amp;#x200B; Here's a way to throw a warning if a char gets entered into the int \*buf #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;err.h&gt; int main() { int buf[5]; int i = 5; while (i--) { if (scanf("%i", &amp;buf[i]) != 1) err(EXIT_FAILURE, "%s: wrong value in buf[%i]", __func__, i); (void) printf("buf[%i]\t-&gt;\t%i\n", i, buf[i]); } return EXIT_SUCCESS; } Output 1: ./scanning 98 buf[4] -&gt; 98 97 buf[3] -&gt; 97 96 buf[2] -&gt; 96 95 buf[1] -&gt; 95 94 buf[0] -&gt; 94 Output 2 (tried to force a char into buf\[2\]): ./scanning 54 buf[4] -&gt; 54 53 buf[3] -&gt; 53 d scanning: main: wrong value in buf[2]: Undefined error: 0 &amp;#x200B;
This article is not C-specific, and is at a level more appropriate for /r/learnprogramming.
Because formatted data is better than non-formatted data and JSON is essentially the most popular and widely supported format. 
They’re not, but it’s fairly common to stick them in there and just run it through a de-commenter before feeding it into your application. And before the downvotes come in, it’s literally what the guy that created JSON suggests for those who really want to add comments: &gt; Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. https://plus.google.com/+DouglasCrockfordEsq/posts/RK8qyGVaGSr And of course, the fact that he said he removed comments means that at one point, JSON did support them.
What architecture are you targeting? May want to consider the mailing list if you want to reach the right people. Finally, TSan won’t play nice with many non-blocking structures especially variants not using stdatomic, built-ins or similar.
There's honestly potential for someone to kill XML, YAML, JSON, HOCON, TOML as configuration formats. But the problem is **wide** library support that makes sense.
[Hjson](http://hjson.org/) has comments, optional comas ( a line break counts too), unquoted keys, unquoted integer litterals and native multiline strings that work like markdown's. It's a superset of json, syntaxically, but translates to normal json very easilly, if you want to take json as an input for config files it's pretty much perfect
Yeah JSON is pretty popular and widely supported, but I don't find that to be a particular good reason to use it as a configuration file format. The name already implies it: **JavaScript** Object Notation, and even though I hate it, that's where it shines.
I'm curious why you consider using something other than sequentially consistent a premature optimization when most CPU architectures use weaker memory models?
&gt; Why is JSON used as a configuration file format? I assume because the alternatives, e.g. XML, YAML, all requires a gazillion lines of code to fully support. 
* `print_points_to_file` would probably be more useful if its input parameter were a `FILE*` rather than a filename. * Print error messages to `stderr` instead of `stdout`. * If you want your code to be portable, you should perhaps avoid `getline` since it's POSIX but not ISO C. * Don't use `read` as a variable name, since it's a library function in many systems. * Don't use `atoi` since it has no error detection. Use `strtod` instead. And check `errno`. Don't forget to handle `INT_MAX` and `INT_MIN` correctly (both when they signal an error and when they don't). * IMO `ps-&gt;points[i].yCoord` is clearer than `(ps-&gt;points+i)-&gt;yCoord`. * I'm not sure why your sorting method calculates `center`. Is it not enough to compute the angle the point makes with the X-axis? In any case your function uses a variable length array for the two halves of the array. This is not a good idea if there may be a large number of points. * Can you find better variable names than `i, j, k, n1, n2` in `merge_halves`? * Your code isn't very suitable as a library function as, among other reasons, it produces a lot of output on stdout. Make that optional (e.g. controlled by a preprocessor macro) at least. * In C you do not need to cast the result of `malloc` or `calloc` because they return `void*`. * Why do you have separate data structures for the stack and the convex hull? They are both heap-allocated and the final step of `compute_convex_hull` simply copies `stack` into `convexHull`. Why not just use `realloc` on `stackSet-&gt;points` to tuncate the array to size `stack_top + 1` and return `stackSet`? * `compute_convex_hull` already computes the turn type, and `graham_scan_main.c` unconditionally calls `remove_degeneracy` after `compute_convex_hull`. Why not simply handle colinear points in `compute_convex_hull` itself? * If you really want to stick with integer ordinates, it might help performance to make less use of floating-point. But this is really a case for benchmarking, since modern CPUs can perform integer and floating-point operations concurrently. But before you can usefully benchmark anything, you need to get rid of those `printf` calls and make sure you don't call the file I/O routines inside the benchmark loop. * If you decide to stick with using floating-point, there are still some other changes that would likely be beneficial: * You don't need to compute the _actual_ angle in `compute_angles` do you? Can't you just use the slope? The result only has to be monotonically increasing with angle, yes? * You should be able to use the standard C library function `hypot` instead of `distance_between` (though as I said above you might not need it at all). The `hypot` function is, perhaps, also numerically more stable than `distance_between`. * `sqrt(x)` is likely more efficient than `pow(x, 0.5)`. * If you're targeting modern ISO C (i.e. C99) you can declare and initialize a variable on the same line, so you can use ``` size_t nread = getline(...) ``` instead of ``` size_t nread; nread = getline(...) ``` 
And what's wrong with a simple key-value list in a simple ini file? Easier to parse, even.
If there's anything web dev has taught me, it's that webdevs' opinion is not worth the dirt in my shoe. Just look at the state of web development and tell me it's not a complete mess.
I got a bit bored: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;err.h&gt; long sum(long *, long *); int main() { long a, b, c; (void) printf("Insert a (number):\n"); if (scanf("%ld", &amp;a) != 1) err(EXIT_FAILURE, "%s: Wrong value for a (should be a number)", __func__); (void) printf("\nInsert b (number):\n"); if (scanf("%ld", &amp;b) != 1) err(EXIT_FAILURE, "%s: Wrong value for b (should be a number)", __func__); if (a &lt; b) { c = sum(&amp;a, &amp;b); } else if (a &gt; b) { c = sum(&amp;b, &amp;a); } else { /* a == b */ err(EXIT_FAILURE, "%s: a == b", __func__); } (void) printf("Sum of all numbers between %ld and %ld is %ld\n", a, b, c); return EXIT_SUCCESS; } long sum(long *first, long *second) { long i, sum; sum = 0; for (i = *first + 1; i != *second; i++) { sum += i; } return sum; } Maybe it's a third way :) &amp;#x200B;
No blog spam please.
This is pretty advanced way, holly molly its...wow. With pointers,strings. Wow this is actually great.
That breaks down when you need nested values. Toml does it but it requires a lot of repetiton and I wouldn't recommend it for anything too complex.
In what case would you ever need nested values for configuration? Cause for the life of me, I can't think of a single case.
damn guys, it's a joke.
Dennis Ritchie and Brian Kernighan are pretty good teachers, I would say
Alright I'll check him out. Thanks a lot!!
Thanks for the response! For architecture, I’m mainly targeting modern computers (this is just a personal project) so I guess x86_64. It seems like SDL implements atomics [using gcc builtins](https://github.com/spurious/SDL-mirror/blob/master/src/atomic/SDL_atomic.c), but I’ll try a basic rewrite and respond whether or not it was fixed. Otherwise I’ll take a look at the mailing list
[removed]
&gt; And what's wrong with a simple key-value list in a simple ini file? If all you need are keys and values, then it's a perfect fit (and often what I use!) The only time I'll switch for something more complicated is when I need a list of values, because typing it all on online is too tedious for .ini.
I'm guessing a lot of these ain't too portable?
Some of the "tips" are C99 features (but supported under C90 mode by GCC), but otherwise noted that's GCC extensions (or features). Well, Linux Kernel source code isn't portable either ;)
&gt;Well, Linux Kernel source code isn't portable either yeah shocking really....
&gt; when I need a list of values A decent library should be able to abstract those complexities for you.
I agree that XML and YAML are more comprehensive, especially implementation-wise, but the project already uses Jansson (a third party lib) for JSON support. So the assumption that "it requires a gazillion lines to fully support" is off in this case. 
If it's a serious question and if you really want to learn C, I can help you. Message me.
Thanks for replying! So many good suggestions, I will try and work them into my code. I've only been coding in C for a few months, so there is still a lot of details I need to work out as I'm sure you found. In one of your points you ask if I would only need the slope, not just the angle, and I thought so too at first, but if I went that route, negative slopes would cause an issue. I could perhaps have a check if the slope is negative and then sort those in increasing order, but when I was writing this, I decided that it wasn't worth the hassle, so I moved to using angles instead. As for the print statements all over the place, I added those while I was writing the code for debugging purposes and I just haven't gotten around to getting rid of them. Again thanks for all the suggestions!
It looks like to be the case, however `-fno-builtin` is the default in a freestanding environment, so it is probably less likely to encounter that. From the GCC docs (the one I linked in my first post, below of the description of the option): &gt; -fhosted &gt; &gt; Assert that compilation targets a hosted environment. This implies -fbuiltin. [...] &gt; &gt; -ffreestanding &gt; &gt; Assert that compilation targets a freestanding environment. This implies -fno-builtin. [...] I wonder if this could be better documented (the "reverse" optimization). Maybe u/tavianator can do a bugzilla issue. I've also found a [SO answer](https://stackoverflow.com/a/33818680) that points out that disabling the optimization [`-fno-tree-loop-distribute-patterns`](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html#index-ftree-loop-distribute-patterns) also prevents this (with `-fbuiltin`).
I’m mainly agreeing with [Herb Sutter](https://m.youtube.com/watch?v=A8eCGOqgvH4) in stating that “atomics are hard, non-seq-cst atomics are impossible”. I’m not using this in production, so hopefully there isn’t much of a slowdown.
Can you think of anything nested? Configuration for that thing could benefit from being nested as well.
As a silent lurker, I'd like to say thanks for taking the time to write out all these suggestions. As a student, it really helps me to see another student's code alongside commentary such as this. 
Neato. I really loved my Comp. Geo. course that I took. For my final project, I had to make an interactive teaching tool. I chose to do monotone polygon triangulation: https://16bpp.net/page/monotone-polygon-triangulation
 &amp;matrix[pos[0],pos[1]] This is not how you access 2D array members. You probably want `&amp;(matrix[pos[0]][pos[1]])`
Ok that's such a stupid mistake I'm actually quite embarassed. Btw it still doesn't work
 MAX\_LENGHT That typo is really triggering for some reason. haha
Ik I've noticed that when it was already spread through the code so I decided I was going to pretend it was on purpose
&gt; Maybe u/tavianator can do a bugzilla issue. https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56888
In addition to what the other comments have said, you are allocating your arrays based on number of elements but not accounting for the size of the types. float matrix[MAX_LENGHT][MAX_LENGHT]; char line[MAX_LENGHT+1]; This is probably causing a memory issue, based on the comment in your code. Your 'line' variable is only allocated to 6 bytes long. Your float array has rows that are 5*4 bytes long (assuming you have 4 byte floats...it could be 8 bytes per float too). This could affect what is in your other arrays as well. For me, it overwrote memory with the pos array and changed them from 0 to large values, which will cause a problem accessing your matrix array. Also, while haven't encountered this yet because of the bug, your loop control should be updated as well. As you read the last line with fscanf, the EOF isn't set yet, so you what you think is your last loop is actually your second-to-last loop. After your last line is read, you still have to do one more read to encounter the EOF, but that doesn't happen until you are inside your loop control and there are a bunch more actions yet to occur. Could cause a bug. See the answer [here](https://stackoverflow.com/questions/12337614/how-feof-works-in-c) for explanation. Also, why are you calling fgetc and fscanf?
https://latedev.wordpress.com/2012/12/04/all-about-eof/
&gt; Variable Cleanup Function &gt; Automatic Type Inference &gt; Constructor Function I've had several discussions with people who *hate* these specific features in C++. They didn't like it when I pointed out you can do the same thing in C (via compiler extensions).
I did not know about case ranges or transparent unions, they seem very useful. Great list!
One of the early codebases I worked on here at my job had a bad misspelling for years! Installion instead of Installation. :face\_palm:
&gt; do the same thing in C (via compiler extensions). So you can't do them in C.
The code still compiles because statements separated by commas are all evaluated left-to-right, but only the value of the last statement is returned. printf("%d", (2, 3)); // this prints 3 char array[] = { 't', 'e', 's', 't' }; printf("%c", array[0, 1]); // this prints e
He probably meant GNU C? 
Do any compilers output a warning when the value returned by `printf` is not cast to `void`?
In many cases, even code targeting a freestanding implementation will benefit from having a compiler substitute its own built-in `memcpy` logic for a call to the host's version unless the host's version needs to do something special. IMHO, what gcc should do here is bundle a gcc-supplied library that includes functions like "__gcc_smallBottomUpByteCopyAtLeastOne", "__gcc_smallTopDownByteCopyAtLeastOne", "__gcc_smallBottomUpHalfwordCopyAtLeastOne", etc. and then have options for whether to replace loops with calls to such functions. Calling `memmove` in cases where the compiler knows how the copy should be performed is just silly, since almost any plausible implementation of `memmove` is going to have to start with at least three conditional branches that could have been averted by directly calling a suitable special-purpose routine. On a related note, a good compiler should also offer options to control when it should be considered to replace a balanced pair of malloc/free with a stack allocation. Many programs for freestanding implementations include malloc/free functions which most code uses just like the originals, and replacing a balanced pair with a stack allocation would be a useful optimization. Some programs, however, may rely upon the fact that their own malloc/free functions do things that Standard Library function does not [e.g. allocating storage from a known address range, storing block headers a certain way, maintaining lists of allocated and freed blocks, etc.] If would be helpful if the Standard could provide means by which programmers could invite or forbid various kinds of optimizations (with compilers being free to ignore any invitations, or to ignore directives that reject optimizations *they're not going to do anyway*). Such directives would impose minimal burden on compiler writers who aren't interested in the associated optimizations, and for compilers that are interested in the optimizations, the amount of work to process such directives should be far less than the amount of work necessary to try to determine whether to apply them based on code alone.
Since 1974, the term C has always referred to a collection of dialects with a common core. The authors of the Standard recognized this, and according to the published Rationale intended to encourage this, but unfortunately failed to make is sufficiently clear. The myth that it is a single language has served only to promote divergence between useful dialects and the minimal dialect necessary to support the core. 
For sure, some can argue that those "features" doesn't improve readability. But, IMHO, variable cleanup functions are rather useful in the example given to avoid missing an unlock, while improving readability to some extent. Constructor functions avoid hacking into the startup script to initialize a whole section for example. 
nope, I just (void) cast if a function returns something, that I don't use on purpose
&gt; In one of your points you ask if I would only need the slope, not just the angle, and I thought so too at first, but if I went that route, negative slopes would cause an issue. I could perhaps have a check if the slope is negative and then sort those in increasing order, but when I was writing this, I decided that it wasn't worth the hassle, so I moved to using angles instead. What if you just use the identity function instead of `acos`? You might also not need the `sqrt` in the denominator.
Just wonder, what's wrong with TOML?
Nice job! I wanted to add some sort of visualization to my algorithm, but I'm not familiar at all with GUIs in C, so ultimately I didn't get around to it
I understand that. However, I do not recognise many of the extensions provided by gcc to be in the spirit of the language and do not see them as a dialect worth considering.
&gt; Kernel source code isn't portable either Considering you only need to apply a few patches to compile it with clang, it's not really correct to claim this any more. [The shipping Pixel's kernel and the recent AOSP kernel can be built with clang](https://docs.google.com/presentation/d/1vJrsJ7fRSi6uidJWVSI2bg8aR19gXeshLgD0tcXfMqg/edit#slide=id.g456f1349ee_0_684)
I'll admit that I'm not familiar with the identity function... how would I use that in this example?
Which Uni did you go to by the way?
I've been laughing my ass off for the last 3 minutes. Have an upvote, you filthy animal.
&gt; Variable Cleanup Function C++ doesn't have a anything other than the attribute mentioned. Are you referring to RAII?
these are awesome, especially the structure initializers and case ranges if everyone just stuck to gcc and a single platform... :p
&gt; Can you think of anything nested That's the thing. If someone tells me its configuration requires a nested structure, I automatically think "that's too complicated, you can make it simpler". If your configuration structure requires nesting, you can make it simple.
 double identity(double x) { return x; } 
 double identity(double x) { return x; } 
 double identity(double x) { return x; } 
At least on Java, my team found the existing libraries to be extremely lacking, the actual format, not so much.
Initializing structures/unions by field name is supported in ISO C99, so that's portable. GCC supported it well before as a convenience. 
Spirits of languages are very... fluid things. 
Normally it's a hate for them being implicit, but they aren't here. You are saying "call this".
Some are; some aren't. Many of the extensions that existed in gcc circa 1989 should have been recognized by the C Standard, at least as "recommended features". One of the reasons for stagnation is that the authors of the Standard have yet to acknowledge the notion of features which most implementations can and should support, even though some limited-purpose implementations might be unable to. Consider, for example, statement expressions. Some single-pass compiler designs might need significant reworking to be able to accommodate them, and the benefits they offer may not be worth the effort that would be required to support them on such compilers. They do, however, greatly increase the ability of macros to behave semantically like functions, and most implementations should have been able to support them without difficulty. Consider also zero-sized arrays. They could do pretty much everything flexible array members could do and more, and all compilers had to do to support them was refrain from squawking if an array's size happened to be zero. Do you view such extensions as contrary to the Spirit of C? Why? 
Actual portable standards compliant C written to some neat specification like C99 should just compile clean everywhere. However gcc doesn't do that in some places. Also gcc will do its own little optimizations and changes unless you tell it directly to just compile and stop changing stuff. I usually demonstrate that little feature with a trivial Hello World code bit and gcc throws away the call to printf. Always a good idea to have another compiler around.
Yes and no. RAII is certainly the first thing that comes to mind. But you can implement a more direct replacement of that attribute with a combination of RAII and lambdas. See Alexadrescu's `ScopeGuard` for an example. Or Boost.ScopeExit for a pre-C++11 implementation that doesn't use lambdas.
That's more or less the complaint about the cleanup function. But they still find GCC's cleanup function version to be too implicit (though better than pure RAII). They have to look at the top of the function to know if code will be run at the bottom of the function. The complaints about type inference is also about being implicit, and that holds for GCC's extension as well. The complaints about the constructor function come down to code being run before `main`. They want to assume that's the very first entry into the code, and setting a breakpoint on the first instruction of `main` should be sufficient. Instead, arbitrary code might run first (and possibly crash). GCC's extension is slightly better in the sense that you can search for the attribute (assuming you have full source code of any libraries), but it's still pretty implicit.
Otherwise known as feels
Data types, lists, associative arrays. 
All fair points.
While it is useful to have a function that will be executed as the very first thing a program does, on most platforms such a feature could be provided just as well by the runtime environment as by the compiler. If anything, the problem with the constructor construct would be that it should be implemented in more generalized fashion, such that if there exists a declaration: __extensible_function void do_something(int whatever_parameters); and no definition, a call to that function would be a no-op, and if multiple declarations exist, a call to that function would invoke them all in some arbitrary sequence. If there is a need to have certain modules initialize themselves in a certain order, that could be accommodated by something like: __extensible_function __init(int *keep_going); int keep_going; int pass=0; do { keep_going = 0; __init(&amp;keep_going, pass); pass++; } while(keep_going); Any init routine that can't run until some other module has finished initialization could set the `keep_going` flag and return. 
You don't have a "global string array" - you have an array that can hold 10 *pointers* to char. So effectively an array of "strings", not an array of "chars". Each element of the array can be a full "string" (type char\*). You then initialize it with the 3 pointers to various constant strings. A char in C is surrounded by single quotes. You want something like this: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; // you have to pass the length of arrays in explicitly. Arrays "degrade" to plain pointers when being passed to functions and you have no way of knowing the length. Only the caller knows. void changeVal(char *arr, size_t len) { size_t i; for (i = 0; i &lt; len; i++) { arr[i] = 'a'; } } int main() { char arr[] = {'b', 'c', 'd'}; printf("before: %c %c %c\n", arr[0], arr[1], arr[2]); changeVal(arr, sizeof(arr) / sizeof(char)); // sizeof works here because the compiler knows this is an array. sizeof would only return the size of a pointer inside the 'changeVal' function (4 or 8 bytes usually, regardless of array length) printf("after: %c %c %c\n", arr[0], arr[1], arr[2]); } 
The Standard was written to describe a common core for C dialects. It was never intended to fully describe a dialect that was suitable for all of the purposes that can be usefully served by C dialects. Indeed, the authors have acknowledged that it would be possible to contrive an implementation that would be conforming without it being capable of meaningfully processing any useful programs whatsoever. IMHO, rather than trying to come up with a useful language which all implementations can fully support, and then having to punt and say that implementations don't actually have to support it usefully, it would be more useful to come up with a more powerful language but simultaneously allow and require implementations to reject any programs they can't support. Further, the Standard should seek to maximize to the extent practical the fraction of tasks that could be accomplished by processing a collection of source files in ways fully defined by the Standard (with the caveat that some aspects of behavior may be Unspecified, and many sets of files would likely be rejected by most implementations). Determining whether a particular program is usable by an implementation shouldn't usually require having to read through the documentation of both, but should generally require nothing more than feeding the program to the implementation and letting the implementation report whether it can support all the features the program has indicated that it needs. 
I'm not familiar with PNG, but after a quick look at its specification, I found that width and height are not strings as you're assuming, but simple integers. You might be able to convert it to a uint32_t pointer and dereference it. uint32_t w = *((uint32_t*) width); I'm not sure what endianess the PNG format assumes, but you might need to fix that too. 
I'm on mobile right now, excuse me if there are any formatting issues. I'm not assuming they are strings, I'm reading the file to a `uint8_t` buffer and then getting the 8 bytes for width and height (4 each). I'm sorry if I explained myself wrong. I have actually looked at a hex dump from a test PNG file, and what I'm getting as a result of `memcpy()` is exactly what it's supposed to be. However, I will try what you suggested. Thanks.
Self taught with proven track record
While I always appreciate self-taught programmers, most of them have in common that they completely lack a background of theoretical knowledge and thus often make very questionable design decisions when it comes to algorithms and data structures. If you have the time, I highly recommend you to go for a computer science degree or similar, and that not only because it opens the door to many jobs that you won't otherwise get. At university, they teach you a whole lot of ideas you can use to solve problems, design data structures and structure programs. As an example, in university you learn what a LR(1) parser is and how to write one. Without this background, parsing text seems like a daunting and impenetrable task and you might not even get the idea that you could solve a problem by parsing a text file. I have seen many self-taught programmers try to parse text without a background in language theory and their parsers are usually a hacked mess that breaks on slightly unconventional input and completely fails to solve the task at hand. Yes, you do need a CS degree to understand why you [can't parse html with a regex](https://stackoverflow.com/q/1732348/417501) and a programmer with a CS degree wouldn't have wasted a lot of time trying to do the impossible. Another thing university teaches you is how to engineer software, that is, how to actually turn a loose program idea into a software. This involves designing a program structure, developing the program in a team, and testing it. All these things are crucial to writing high quality software and many self-taught programmers completely fail here because they don't know any of the methods people have developed to prevent a software project from being driven head-first against a wall. However, if you are self-taught and/or don't want to or can't go to university, that's not a problem! You can get at least half the way there by taking the time to work through the relevant material yourself. Read books about computer science. Not pop-science books or tutorials, but actual lecture texts. Work through them, do all the exercises. Make sure to set aside at least a whole afternoon every week for concentrated studying. Many programmers do claim that they frequently teach themselves new things by watching videos and reading programming blocks. In my opinion, watching a Youtube video every once in a while doesn't quite cut it; if you don't spend at least a day a week working on the lecture text, you aren't really studying anything. Ask yourself: have you ever actually used the method you were watching a video about in a program? Do you understand it well enough to teach it to others? Do you feel like it is a tool in your bag of tricks whose applications you immediately recognise if present and can immediately apply? If the answer to most of these questions is “no,” you should try to change the way you study new concepts.
But why have you tried to use `strtol()`, `atoi()` and `sscanf()` then? Those functions take strings as input.
and how do you get the track record without some kind of qualifications to get your foot in the door....
Self taught programmers have usually been doing since their teens and will have a lot more experience than some noobs who decided CS was a good thing to study. If you’re self taught with a degree on top then your probably going to grow Into a AAA programmer
&gt; uint32_t w = *((uint32_t*) width); That's undefined behavior, but it's easy enough to correct: unsigned char *buffer = ...; unsigned long width = (unsigned long)buffer[0] &lt;&lt; 24 | (unsigned long)buffer[1] &lt;&lt; 16 | (unsigned long)buffer[2] &lt;&lt; 8 | (unsigned long)buffer[3] &lt;&lt; 0; 
source code, tests, start low level and prove yourself
&gt; A decent library should be able to abstract those complexities for you. Like the JSON library? :)
I'm not very experienced with C, so I may be wrong. My thought process was that since `uint8_t` is essentially an `unsigned char`, I could store the 4 bytes in a `char` array and then use those functions. Is a character array not the same as a string? This is sort of new stuff for me. 
It really depends on what you want to do. I’ll probably get a lot of flack got this comparison but I believe that programmers need a CS degree like a construction worker needs an engineering or architecture degree. Now, do you want to be a programmer or a software engineer? Do you want to create your own algorithms or simply program ones that are given to you? I think a degree is close to essential If you want to create designs, find algorithms or define architectures. I have met self-taught architects but they are exceedingly rare, competent self-taught programmers are much more common. A CS degree will teach you abstract thinking, patterns, methods and processes and these skills are hard to learn on your own and usually the week spots of self-taught developers.
That's true. And since it probably uses a fixed endianess it might be better than a memcpy.
I thought that since `uint8_t` is the same as `unsigned char`, I could use that to create a character array and use those functions. Is a character array not the same as a string? Or does my error have more to do with types? This is my first programming project so pardon my lack of experience!
&gt; If you’re self taught with a degree on top then your probably going to grow Into a AAA programmer Ding ding ding, we have a winner.
What's a short list of projects that would convincingly demonstrate to you that a given self taught programmer is on par with a university graduate in terms of theoretical understanding?
I believe depends on your level of maturity and your access to supporting persons and materials. Learning in isolation is difficult for many reasons, among them losing motivation and getting stuck which wastes a lot of time. If you have a strong work ethic and high throughput access to mentors, then you can get the skills of a software engineer in potentially less time than you would've at a university, and without spending much money. The issue remains that most job applications are filtered by machine learning models that immediately eliminate you when you don't have a degree, and you will always give the first impression of someone without a foundational understanding of computer science. To succeed in this path, you must be a great engineer and a great salesman at the same time. It's not a typical combination of traits.
A list misses the point. Every talented self-taught programmer could work himself through a theory-heavy project if prompted and guided to do so. That is not a mark of a CS degree. From a CS graduate, I expect that he is able to see that a theoretical concept can be applied without being prompted or guided and without having a list of things to do. And just as the point of a degree is not to show that you spend four years sitting in lectures, little is proven by having completed a list of projects someone told you to do.
The `cleanup` feature reminds me of go's `defer` feature.
The only way to know if a theoretical concept is applicable is if you've applied it before. A list does not miss the point. The CS graduate knows how to apply a given set of concepts, which is no more concepts than the ones they've applied before. So, what's a short list of projects that covers, perhaps, the most often missed bases that you've noticed from self taught programmers? I would imagine it might include implementing an interpreter, a compiler, regular language automata..
did you tried with man fgets?
Use fgets to take the input, and strtok (or similar) to parse it out, then do your calculations/whatever.
I'm using fscanf to get the string arguments, so I guess I can use strtok to split them by the spaces. Does this makes sense at all?
I am using fscanf to read in the arguments. Sorry I should've specified above
Yup. strtok with a while loop or something like that.
Thank you! That really helps
I've read a bunch of that book and it is in fact great. They used java to convey the ideas but they try to use very few features of the languages to avoid getting bogged down in java. 
He had a C programming version which is like 20 years old but he uses Java now with his book for Java. The Java version uses obsolete practice for 2019 and hard to follow. Ironically it is straightforward to use read C version because the base of C is small and has not changed much.
You're basically admitting you don't have a clue about anything to do witb modern web development. Tell us what else you don't understand.
This is rarely a question of choice. If you can get a Computer degree, by all means, let's do it ! It's going to be an easier sell to your future employer, and it should also learn you quite a few things which are hard to come by just by oneself. Now, Computer degree might be out of reach. Too expensive, not good enough to get selected, nothing available around, etc. Programming is one of those rare fields where it's actually possible to have a good career through self discipline. But that's clearly not the "easiest route". If you have the choice, select the computer degree. If you don't have a choice, don't give up, take the self-taught route, it leads somewhere too.
Self taught programmers teach themselves how to program. Period. Usually one language. Rarely do you get someone to teach themselves discrete mathematics, Boolean logic, compilers and parsers, operating systems, algorithms and data structures, databases, etc.. University gives you all this with many different professors and TAs and peers to totally immerse yourself in the feedback loop of university study. For 4+ years. There is no substitute.
A git repository with a lot of well documented and tested code
If you can't parse text, you're a dunce. Being self taught is the least of your problems but I do agree that if you have the time and money, just go to college. It's not that they'll teach you things you can't learn otherwise, it's just that the courses are structured and have clearly defined guides with people who can help you. I'd say if you're even asking a question like "should I go to college" then the answer is most likely yes. 
So you are saying a list of projects proves nothing, but a list of courses assigning projects proves something more? You are thinking too highly of the degree.
It doesn't really matter. The degree just is a short cut to show that you should know what you are doing. A healthy portfolio of sample works can achieve the same result. Demoscene, coding competition, even github comments can work towards this goal. The problem is that the degree is often the litmus test to get your foot in the door. Without the degree to make it past the screener, you will have a harder time talking to the person who can hire you.
&gt; As an example, in university you learn what a LR(1) parser is and how to write one. &gt; &gt;... &gt; &gt; Another thing university teaches you is how to engineer software, that is, how to actually turn a loose program idea into a software. This involves designing a program structure, developing the program in a team, and testing it. What university did you go to? None of this was covered in any programming course I've ever taken. &gt; Yes, you do need a CS degree to understand why you can't parse html with a regex and a programmer with a CS degree wouldn't have wasted a lot of time trying to do the impossible. No, you don't need a CS degree to understand that. Also, why would you make a point by saying something so wrong? It all depends on what you are parsing for. 
:(
The Standards Committee wrote down some aspects of the Spirit of C. I don't think they did a good job of explaining all of them (the part about providing one way to do something is particularly botched, and should be better described as "favor a general means of accomplishing many tasks over specialized means for accomplishing them individually", but I think some principles like "Don't prevent the programmer from doing what needs to be done" are rather fundamental and should be timeless.
I completely disagree that a self taught person, who actually works head on in the industry and not just browses Reddit and diddles in JavaScript at home, doesn't learn and strive to excel in those topics. I know you did say "rarely". But I personally love self taught who also have 5+ years of actual work experience compared to a CS grad with no work experience. In fact, I've come across more inexperienced CS students that think their professors goofy concepts are valid in the real world and often have a cocky attitude while refusing to actually learn anything new. Like 4 years gave them any experience at all and their going to show us old dogs new tricks. Again, not all. But enough to shake a fist at. 
They are a cocky CS grad. Gotta feel like that debt attributes to something unique.
They can't because they don't know.
Feel free to DM me as well. 
Just an idea: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;err.h&gt; #define BUFFER 256 // predefined size of buf void input(char *); int main() { char buf[BUFFER]; /* options */ char *option[3] = {"option0", "option1", "option2"}; int c; /* as long as the User input isn't "quit" */ while (strncmp(buf, "quit", strlen("quit")) != 0) { for (c = 0; c != BUFFER; c++) buf[c] = '\0'; input(buf); /* * options */ if (strncmp(buf, option[0], strlen(option[0])) == 0) (void) printf("Use: %s\n", option[0]); else if (strncmp(buf, option[1], strlen(option[1])) == 0) (void) printf("Use: %s\n", option[1]); else if (strncmp(buf, option[2], strlen(option[2])) == 0) (void) printf("Use: %s\n", option[2]); } return EXIT_SUCCESS; } void input(char *buf_ptr) { char *ptr; /* simple User-Input */ if (fgets(buf_ptr, BUFFER, stdin) != NULL) { if ((ptr = strchr(buf_ptr, '\n')) == NULL) err(EXIT_FAILURE, "%s: Too much input", __func__); *ptr = '\0'; } } Tool: user -| /home/user/c_code |- ./input2 option0 Use: option0 option1 Use: option1 option2 Use: option2 option1 Use: option1 quit &amp;#x200B;
Ad a self taught, I can literally see all the lack of high level math and all around basis; if someone ask me to implement a kallmann filter, I would take months to learn all the necessary basis, while a CS student should already know the basis. Same story with AI, physic, linear algebra.. That say in my country CS study are much more theory based than many other country
most people doing the interviewing, odds on, won't be interested in a few small project on someone's github, they will either want qualifications and or references, in an idea world you'd be interviewed by a skilled programmer.... but how often is that going to happen.... &amp;#x200B;
perhaps it'll help: #include &lt;stdio.h&gt; #include &lt;string.h&gt; int main() { char buf[256] = {0}; int i, c, z; while (strncmp(buf, "quit", strlen("quit")) != 0) { for (i = 0; i != sizeof(buf); i++) buf[i] = '\0'; if (fgets(buf, sizeof(buf), stdin) != NULL) buf[strcspn(buf, "\n")] = '\0'; for (i = 0, c = 0; buf[i]; i++, c++) { if (buf[i] == ' ' || buf[i + 1] == '\0') { z = i - c; if (strncmp(&amp;buf[z], "opt0", strlen("opt0")) == 0) (void) printf("Option: 0\n"); else if (strncmp(&amp;buf[z], "opt1", strlen("opt1")) == 0) (void) printf("Option: 1\n"); else if (strncmp(&amp;buf[z], "opt2", strlen("opt2")) == 0) (void) printf("Option: 2\n"); c = -1; } } } return 0; } Output/Input: ./input3 opt0 opt0 opt0 opt2 jdkfj opt4 opt1 Option: 0 Option: 0 Option: 0 Option: 2 Option: 1 quit &amp;#x200B;
Okay, I'll carry on picking projects however I feel like. Right now I'm implementing the grisu algorithm and generating levenshtein automatas. You know, low brow stuff.
Nesting makes complex things easier to understand, change, move and so on.
\*finish
You never started it. Look at your for-loop a few lines above, it is complete
Beware when using weak functions and targetting multiple OSes (eg. for tests). Weak functions are not supported under MinGW/Windows. 
I know, but i need to have another for loop to finish that program
I can't see any reference of such limitations, nor any reasons since that's a linker thing. Any source? 
I would really like to help you, but if I have to write the code myself to compile it, it's too much work. Textformat &gt; picture
I wish this article didn't use images for code snippets, it's completely useless as is.
Lmao, you asked how to finish a for loop not completely take care of one for you without any context. Is there a reason you need it or is it completely arbitrary
Here is the text format. \#include &lt;stdio.h&gt; \#include &lt;conio.h&gt; &amp;#x200B; ␣␣␣␣ int main(void) ␣␣␣␣ { &amp;#x200B; ␣␣␣␣ char nimi\[4\]\[20\]; ␣␣␣␣ int syntynyt\[4\]; ␣␣␣␣ double palkka\[4\]; ␣␣␣␣ float vero\[4\]; ␣␣␣␣ int kierros; &amp;#x200B; ␣␣␣␣ printf("Anna seuravat tiedot \\n"); ␣␣␣␣ for (kierros=1; kierros&lt;=3; kierros++) { &amp;#x200B; ␣␣␣␣ printf("Anna nimi %i\\n", kierros); ␣␣␣␣ scanf("%s", &amp;nimi\[kierros\] ); &amp;#x200B; ␣␣␣␣ printf("Anna syntymaaika %i\\n", kierros); ␣␣␣␣ scanf("%s", &amp;syntynyt\[kierros\] ); ␣␣␣␣ printf("Anna palkka %i\\n", kierros); scanf("%s", &amp;palkka\[kierros\] ); ␣␣␣␣ printf("Anna veroprosentti %i\\n", kierros); ␣␣␣␣ scanf("%s", &amp;vero\[kierros\] ); &amp;#x200B; &amp;#x200B; ␣␣␣␣ } &amp;#x200B; ␣␣␣␣ char otsikko1\[20\]="Nimi"; ␣␣␣␣ char otsikko2\[20\]="Syntymäaika"; ␣␣␣␣ char otsikko3\[20\]="Palkka"; ␣␣␣␣ char otsikko4\[20\]="Veroprosentti"; &amp;#x200B; ␣␣␣␣ printf("===============================================================\\n\\n"); ␣␣␣␣ printf("%-20s", otsikko1); ␣␣␣␣ printf("%-20s", otsikko2); ␣␣␣␣ printf("%20s", otsikko3); ␣␣␣␣ printf("%20s\\n\\n", otsikko4); ␣␣␣␣ printf("===============================================================\\n\\n"); ␣␣␣␣ for() &amp;#x200B; ␣␣␣␣ getch(); &amp;#x200B; return 0;
Hopefully this is good enough.
Well this a school assignment i have been struggling with this one really long time
Worked perfectly. However, I'm having trouble understanding why what I was doing is incorrect. If possible, could you explain?
Besides english is not my primary language i couldn't think the right word when i was writing the question.
It doesn't: they're plain Gist. On which platform are you reading?
&gt; What university did you go to? None of this was covered in any programming course I've ever taken. Humboldt University of Berlin (Germany). Software Engineering is a mandatory subject in all CS programs as far as I know. &gt; No, you don't need a CS degree to understand that. Also, why would you make a point by saying something so wrong? It all depends on what you are parsing for. I have never met a programmer who hasn't visited university and understood this. Language theory is not something you teach yourself in an afternoon.
&gt; but a list of courses assigning projects proves something more? Again you miss the point. The projects assigned in university do not prove anything either. What proves something is that you passed the exams showing that you understood the material.
Yes, it appears to be finnish ;) A for loop takes 3 parameters for (start ; condition ; end) { code; }; could be re-written as start; while (condition is true) { code; end; }; to maybe help you understand
"Better" can mean anything. I know talented programmers who never went to University, and I know a CS Master who pratically never wrote a single line of code. Going to Uni will give you more options and make you more versatile, but theory is not for everyone. If you're not sure, give it a try.
Thank you, this helps alot.
i honestly don't know how anyone would recommend 'self taught' over 'degree' if there isn't any reason why they couldn't get a degree. getting a degree is basically easy mode when it comes to applying for jobs and getting interviews compared to how hard it is when you don't have a degree. do you know how many large companies will not hire someone without a degree (unless there's a significant reason)? even with several years experience, many larger companies will not even consider you. yeah you can always get jobs at smaller companies sure, but why would you just immediately rule out working at any of the larger tech companies? i've worked at some large tech companies for firmware (the biggest semi companies in the world) and i have never bumped into anyone that didn't have a degree. in fact most had a graduate degree. there's a few that never got a degree sure but it's very uncommon. i am not talking about what you learn or what you didn't learn, but merely the reality of things without a degree. one of the smartest programmers i know never finished college and is basically completely self taught, but he has a hard time finding a job simply because a lot of companies won't even consider his resume. he works at a small company and is happy there, but he realizes many doors are closed for him and he always thinks about going back to finish because of that (he actually already knows everything they would teach too). if you want a career in programming/engineering/related, and there's no reason why you can't, then 100% get a degree.
It was not either or. I usually prefer someone with years of experience **and** has a CS degree than someone who has year of experience and taught themselves how to program a computer.
remember that when you hit enter, you also emit a new-line character.
It doesn't, it runs as many times as you tell it to when you enter the first value. The problem is your `scanf` calls don't handle newlines, so when it hits the `scanf` in the loop it reads the newline character. As that doesn't match any of your `if` statements you don't see anything so you think it's not looped, when in fact it has. The easy way to fix this is to add a space before the `%` in your `scanf` formats, e.g. scanf(" %d", &amp;t); You should also check the output of `scanf` to make sure you know if it's worked or not.
Ach. Still a pain to use.
Medium doesn't supports syntax highlighting, so Gist is the way to go posting code IMO 
&gt; So, what's a short list of projects that covers, perhaps, the most often missed bases that you've noticed from self taught programmers? I would imagine it might include implementing an interpreter, a compiler, regular language automata.. I am not going to provide a list of projects because as I said before, the point is not that you did a certain project, but that you understood a concept. How you gained this understanding doesn't matter and if you did the project by copy-pasting other people's code or by following a guide without understanding the motivation behind its design choices, it won't really help you either. I could provide a list of things you should know as a programmer with a CS degree, but it's a lot of material and would take a lot of time to enumerate and write down.
The loop runs T times all right, but your scanf of char returns correct symbol just once (remember that newlines are chars too). Read strings or eat whitespace/newlines.
The width is stored in the file as a big endian unsigned 32-bit integer — a binary format. However, you were trying to use string functions like `strtol()`, `sscanf()`, and `atoi()` to read it. These functions only accept strings — a zero-terminated sequence of characters. They can't read binary formats. You can think of the binary format for the width as being a base-256 number, and each of the four bytes as being a "digit" of this number. I said it was *big endian* which means the most significant "digit" is listed first, just like we normally write out numbers. The alternative is *little endian* which puts the least significant "digit" first. This is how nearly all computers today actually store integers in memory. The PNG format uses big endian since, conventionally, that's "network order," and it is the Portable *Network* Graphics (PNG) format after all. Suppose you have a sequence of base-10 digits. How do you assemble them into the actual integer they represent? // digits of the number 1,234 int a = 1; int b = 2; int c = 3; int d = 4; You multiply each by a power of base 10, starting with 10^0 up through 10^3. int v = a * 1000 + b * 100 + c * 10 + d * 1; The same goes for reconstructing a base-256 integer. Multiply each by a power of 256. Since the results may exceed the range of an `int`, I'm computing the results in `unsigned long` precision. unsigned long width = buffer[0] * 16777216UL + buffer[1] * 65536UL + buffer[2] * 256UL + buffer[3] * 1UL + This is *identical* to the original solution I presented you. How is that? Bit shifting left (`&lt;&lt;`) is identical to multiplying by powers of 2! Further, `+` and `|` (OR) operations are identical here since there will be no carries — no two summed integers will have a 1 in the same place. unsigned long x = ...; unsigned long r0 = x * 16777216; // e.g. x * 2^24 unsigned long r1 = x &lt;&lt; 24; assert(r0 == r1); I used bit-shifting since that more closely represents what's *conceptually* going on in the computer: I'm shifting individual bytes into place and assembling them into a larger integer. It's also partially historical: in older, simpler compilers, shifts would have been faster since compilers were more literal about these things, so most code uses shifts to represent these operations. In modern versions of GCC, this code compiles to just two instructions. 
Being lazy here, but I'll point out that it's valid to have an empty for loop with a break inside of it. E.g: `for(;;) ` break;
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;err.h&gt; int main() { unsigned int t; char c; (void) printf("Insert a number:\n"); /* added whitespace before %u */ if (scanf(" %u", &amp;t) == 0) err(EXIT_FAILURE, "%s: scanf() failure", __func__); for (int i = 0; i &lt; t; i++) { (void) printf("Insert a letter (b, c, d or f):\n"); /* added whitespace before %c */ if (scanf(" %c", &amp;c) == 0) err(EXIT_FAILURE, "%s: scanf() failure", __func__); if (c == 'b' || c == 'B') (void) printf("BattleShip\n"); if (c == 'c' || c == 'C') (void) printf("Cruiser\n"); if (c == 'd' || c == 'D') (void) printf("Destroyer\n"); if (c == 'f' || c == 'F') (void) printf("Frigate\n"); } } See comments in the code &amp;#x200B; The moment you hit enter, you give a second input into scanf, you are able to fix the '\\n' added through hitting enter with a whitespace, but if somebody hits in more than one char and hits enter, you loop through that x-times &amp;#x200B; In- and output with my code: ./test1 Insert a number: 6 Insert a letter (b, c, d or f): bbbbbbbbbbbbbbbbbbbb BattleShip Insert a letter (b, c, d or f): BattleShip Insert a letter (b, c, d or f): BattleShip Insert a letter (b, c, d or f): BattleShip Insert a letter (b, c, d or f): BattleShip Insert a letter (b, c, d or f): BattleShip With only one input, everything is good: ./test1 Insert a number: 3 Insert a letter (b, c, d or f): b BattleShip Insert a letter (b, c, d or f): c Cruiser Insert a letter (b, c, d or f): d Destroyer &amp;#x200B;
&gt; Software Engineering is a mandatory subject in all CS programs as far as I know. As the topics you describe were not in any of my courses, you now know different. Though I did Computer Engineering and not Computer Science, but the programs were 90% overlapped when it came to programming. Except that even further shows how wrong your statement is because there are numerous degrees that will land you in programing fields. &gt; I have never met a programmer who hasn't visited university and understood this. Language theory is not something you teach yourself in an afternoon. Great you don't know a lot of programmers.
I don't miss your point at all. Your point is dumb. You are trying to say that you can't develop a portfolio of examples showing that you know your shit because it isn't the same as a portfolio of examples that show you know your shit summarized in a degree. Frankly, a portfolio is far more useful then a degree to figure out if a programmer knows what they are talking about. That is why no one really cares about degrees after a few years in the real world. Degrees are just a filter to get you in the door when they know nothing else about you (as for as employers care)
Makes much more sense now. Seriously, thank you very much for the long explanation. Not many people go through with that. Thanks!
What's with the void casts of printf?
If I read the Code later, I see that I didn't use the return on purpose 
Probably an idiom that says essentially "I know printf returns something, but I'm ignoring it". Some discussion about this on [Stack Overflow](https://stackoverflow.com/questions/689677/why-cast-unused-return-values-to-void), and [another forum.](https://bytes.com/topic/c/answers/221662-void-printf-vs-printf)
dont forget to sanitise your user input when you get it working.... we've all heard about the story of mr tables son Jonny drop....
On BSDs, (others?) linker\_set.h provides yet another mechanism for constructor-like things. Sometimes very convenient, and not only for constructor-like things. Any .o can hook into arbitrary global sets automatically (all done by ld). #include &lt;linker_set.h&gt; DATA_SET(initializers, init_foo); ... extern void (*__start_set_initializers[])(); /* array of function pointers */ extern void (*__stop_set_initializers[])(); void (**fn)(); for (fn = __start_set_initializers; fn &lt; __stop_set_initializers; ++fn) (**fn)(); &amp;#x200B;
Perhaps you meant a trailing blank, to match the newline? A leading blank will cause the scanf to fail unless the user also enters a leading blank.
It works fine for me on Linux, I'm not sure how portable it is. From the man page http://man7.org/linux/man-pages/man3/scanf.3.html: &gt; A directive is one of the following: &gt; &gt; · A sequence of white-space characters (space, tab, newline, etc.; see isspace(3)). This directive matches any amount of white space, including none, in the input. &gt; &gt; · An ordinary character (i.e., one other than white space or '%'). This character must exactly match the next character of input. &gt; &gt; · A conversion specification, which commences with a '%' (percent) character. A sequence of characters from the input is converted according to this specification, and the result is placed in the corresponding pointer argument. If the next item of input does not match the conversion specification, the conversion fails—this is a matching failure. 
The point is it obviously isn't impossible, but it's MUCH harder to do WITHOUT some formalized education. Of course it's possible if you have the resources and are motivated, but sometimes it's difficult to determine what is and isn't good practice without some (hopefully) experienced individual giving you wisdom.
Degree. This is coming from someone who *has* worked in the industry without one, and is pursuing one currently.
Many of the answers here make me wonder what the best resources are for learning CS degree equivalent topics on your own. My first guess would be books, but which ones? This is coming from an (electrical) engineering student, so I'm not afraid of any sort of math that could be involved.
Yeah, I would have liked to get this algorithm development and program design using C but I guess a bunch of people saw this post and bought them up, it went from $15 total including tax and shipping to now it's ~$60
I'm using quincy 2005 to run my programs. 
Redirect the output to a file catapult &gt; results.txt
%c does not skip any character, including \n(newline) which was the first character you got after 3. %s and %d will skip the blank including,\t \n \v ...etc
You'll need to open a file, write to that file, and close the file. Then to 'restore' the data you'll need to open that file, parse the data in it, and then close the file. There's several ways of doing this, but the simplest will involve `fopen` to handle the opening, `fprintf` to write the data, `fclose` to close the file, and `fscanf` to read the data back. Have a look at the documentation for each of those functions and you should find a way of doing what you need to.
[removed]
Where would I put this within the program? &amp;#x200B;
Me, largely self taught, no degree. Co-worker, getting a masters of Computer Science. Task, take around 100 web pages, add links to glossary of about 50 words (if a word in the glossary appears in the text, link the word to the glossary entry). Co-worker: starts hand editing a page to manually add the links. Me: Hey, we can use lex for this. Co-worker: What? No! Get typing! Just because a person has some sheep skin doesn't mean they actually know the material, just that they can pass a test. 
No. I'm self taught, with a proven track record. Fuck being a code monkey, having an education *is* beneficial.
Unless you're doing distributed systems, if you're working with virtual memory then what you do is trivial.
That would be at the Unix shell, where you invoke your executable. More likely it would look like this: ``` ./a.out &gt;results.txt ``` That runs `a.out` in the current directory, and creates or overwrites a file also in the current directory called `results.txt`. What you are really doing there is redirecting the standard out (`STDOUT`) to a file. Do a little research on "unix pipes" and "shell redirection" to learn more. If you aren't using *nix, there are probably other ways to do it.
Oh, little Bobby Tables?
This is a bizarrely one-sided analysis. Bottom line: no a
This is a bizarrely one-sided analysis. Bottom line: no educational approach is a substitute for genuine passion and hardwork.
What percentage of printfs to you write where you use the return code?
He's on Windows, since he said he's using Quincy 2005, a windows program, as his IDE.
But I think learning algorithms is better with video lecture. Something you can easily understand in 30 seconds takes forever to understand by reading because the book doesn't animate. The YouTube channel for hackerank has a good set of algorithm videos technical enough but it is good to review for those who have already learned the material elsewhere but not for the first time learners.
Poor guy :(
Are you arguing something?
I think you mean that you want to allow the user to control the number of arguments? "Random number" means something else.
`%d` already skips leading white space. However `%c` doesn't.
A blank matches *any amount of whitespace*, so a trailing blank is a bad idea because it has to keep reading until non-whitespace is entered in order to fulfill the condition.
Maybe they're trying to make the code hard to read for job security 
I can't tell what you're trying to say under all that word salad, but: * (Fact) `test2` is UB . * (Fact) `test6` is not UB. * (My opinion) Neither of those cases should be changed. Are you disagreeing with any of that? If not then what is your point? It would be better to post some code where the standard actually specifies something as UB where you think it would not be UB. Your proposed definition means that the lines in `test1` cannot be reordered (because the arguments might be derived from the same object), is that intentional? Allowing reordering in this situation is the primary rationale behind the rule. 
is this your code or the code you found on google? Also 'n' which is used in the for-loop is not defined.
Under your proposed definition: &gt; The only lvalues which must be presumed capable of aliasing are those which are derived from the same object, objects that could be elements of the same array, or an array and elements thereof. the lines in `test1` cannot be reordered. The compiler must allow for the possibility that`fp` and `ip` might be derived from the same object unless it can prove otherwise, which in the general case, it cannot do so. Is that actually what you are proposing? Allowing functions to assume their arguments don't alias is the primary rationale behind the rule. 
Well you are missing a declaration of variable n... Otherwise compiles for me with gcc.
Are you sure you got those errors with the exact code you included in your post? First off, "n" is not defined anywhere, it's supposed to be "length", which is unused. If you try to compile the code you posted you will get failures because "n" is not defined. If you replace "n" with "length" your code compiles and works properly on my machine.
in C you don't have to use a cast (int\*). it's used more for C++, C does it for you. also n isn't defined, and i would recommend using parentheses in your condition for your while loop. is this the code you found online or is it your code? can you post your original code so we can better understand how to fix the error? also in this code you have a parameter for length but it isn't used anywhere in the function.
Yes.
Reading your error message, I see at least one problem. The bit I'm looking at specifically is this while (j &gt;= &amp;&amp; array[j] &lt; key) More specifically: j &gt;= Where is the rest of this comparison?
He's not doing any casts, what are you talking about?
I rarely use it, about 1 %
The casting them all to void seems like 99% visual noise.
Yes, but that's why I do so
Seems like a horrible trade-off, imo.
I meant to say those which *identify* the same object etc. (which could only be the case if the references are of the same type, or are of an array type and its element type). So given e.g. int foo(int *p, int *q) { if (p[1]) q[0]=1; return p[1]; } a compiler must allow for the possibility that `p` and `q` might identify elements of the same array, but in the `test1` example would be entitled to assume that `ip` and `fp` do not alias because they cannot possibly identify the same object. Applying this principle to the last example in the post, while it would be possible to derive `s1` and `s2` from a union object which contains overlapping objects of type `struct foo`, those objects could not possibly be elements of the same `struct foo[]`.
On printf() I see your point, but things like scanf() should be marked if you ignore the return, because you're thinking it's safe to do so.
Sure, I can see value in it being used judiciously. Overuse and misuse probably negates most or all of that value, however.
You can control the location of a cursor in the terminal and then place a character directly in that position. I can give you some code in an hour after I get out of class.
I would appreciate that, thanks.
Basically what you're after is a [curses](https://en.wikipedia.org/wiki/Curses_(programming_library))-type library, e.g. [ncurses](https://en.wikipedia.org/wiki/Ncurses).
Nobody needs highlighting in tiny snippets.
I would definitely use a library called ncurses. It allows you to overwrite any character on the screen and has good support in C and good speed. It also allows you to use colors and other fun stuff. Otherwise, look into cursor manipulation characters, which can be printed and will move your cursor, change color, and move to the top of the screen.
TIL
I see a bunch of people have linked ncurses. I've never used it, but it's probably much better than this, but if you want a simple lightweight solution, this works well. How does it work? Something about control characters maybe? I'm not positive, but it does. This is what I used last Spring for a C programming course `void clear(){` ​`printf("\\033\[2J");` `fflush(stdout);` `}` `void put(char c){` `putchar(c)` `fflush(stdout)` `}` `void set_cur_pos(int rCursor, int cCursor){` `printf("\033[%d;%dH", rCursor, cCursor);` `}` put() places a char at the current cursor position, which is set by set\_cur\_pos(row, col). clear() clears the terminal window.
I've reworked by test4/5/6 example and would like your thoughts. The code is less like the simple aliasing example, but was written in such a way that both gcc and clang yield code which can only be justified by saying that compilers are allowed to apply the "strict aliasing" rule in cases which don't involve aliasing.
Thanks! Yeah initially I was looking for a solution like this, but I just tried ncurses and it's very simple and easy to use, and it's lightweight enough for me so I'll give that a try.
&gt; You are trying to say that you can't develop a portfolio of examples showing that you know your shit because it isn't the same as a portfolio of examples that show you know your shit summarized in a degree. No, that's not what I try to say. What I try to say is that the moment I give you a list of projects that would demonstrate to me that you were a capable programmer, that list is already worthless for this purpose. The most important value is the ability to know a lot different approaches and apply them without being prompted to do so in real world situations. If you had done some impressive projects that you came up with yourself because they interested you, then that's valuable. If you showed me that you ticked off all the projects from a list someone gave you, I do not care as that shows only that you like to do busywork. So TL;DR: come up with your own list!
&gt; a compiler must allow for the possibility that p and q might identify elements of the same array, but in the test1 example would be entitled to assume that ip and fp do not alias because they cannot possibly identify the same object. In this case: void *p = malloc(1000); test1(p, p); then the two arguments to `test1` identify the same object. ---- In the updated union example, if `x == y` then the same memory location is written as `float` and read as `int`, which is the definition of the term "aliasing". 
Hm... good questions. * For the mathematical background, I can recommend you *Concrete Mathematics* (make sure to do many of the exercises!). * For operating systems, the classics are *Tannenbaum's book* and *Silberschatz' book*. * For CPU design, try *Hennesey &amp; Patterson's book.* * For compiler construction, try the *dragon book.* * For algorithms, try *Cormen &amp; Leiserson's book.* * If you want to dive off the deep end, you can always read *Knuth's “The Art of Computer Programming.”* The text is surprisingly accessible but incredibly dense and requires a slow reading tempo. * If you want to work in the industry, make sure to read *the mythical man month* * for cryptography, read Schneier's book *applied cryptography* You should also read something about these topics, but I cannot recommend a specific book: * linear algebra * database theory * logic * automata and language theory * networking * network programming * software engineering * file systems * concurrent and parallel programming * distributed systems * bioinformatics (i.e. indexing and searching through large corpora of data)
No blog spam please.
this is a bit embarrassing. you are correct, it seems i forgot to change over some of the variables from what i was looking at, thank you for pointing that out. i was able to fix it
Hell yeah this is exactly what I was looking for. Not sure if I'll end up working in a CS heavy field in the future, but it's fun to learn about regardless. Thanks.
Also consider -Wtype-limits and -Wlogical-op. My list: -Wall -Wextra -Wtype-limits -Wundef -Wshadow -Wlogical-op -Wno-unused-parameter -Wno-missing-field-initializers -Wno-switch -Wno-unused-local-typedefs 
The function `test1` receives a reference to an `int` and a reference to a `float`. Since an object of type `int` is not an object of type `float`, the references cannot identify the same object, even if they happen to be associated with the same storage, and thus a compiler would not be required to recognize that the possibility that they might alias. The requirement that references *which alias* must identify the same object, members of the same array, or an array and elements thereof is much more severe than the requirements in the C Standard. For example, if one were to pass `test7` two pointers which differed by the size of a `long long`, then one would have a situation in which everything is being accessed via lvalue of its expected type, but aliasing would still be occurring in an unexpected fashion because two objects that are members of the same array will always have addresses that (measured in bytes) differ by some multiple of their size, and thus two objects whose address differ by some amount that is not a multiple of their size cannot be elements of the same array. The one place where things get tricky, necessitating the use of different implementation semantics for different purposes, is with `void*`, since different programs use it to encapsulate three different things: 1. Pointer that doesn't identifies a location but not an object. 2. A reference to an object of a particular type which will be later encapsulated in a pointer of that same type. 3. A reference to the superposition of all objects which could identify the storage in question (meaning that a compiler would have to assume that a `void*` could alias anything, although pointers derived from a `void*` would--after derivation--subject to the same rules as any other pointers. This distinction is important in cases where a `void*` is converted to another type `T*` because it determines whether a compiler would be entitled to treat operations using the `T*` as unsequenced relative to anything that occurs between the production of the `void*` and its conversion to `T*`, as sequenced after operations on objects/references of type `T` that occur during that interval, but not operations which do not involve such objects, or sequenced after all operations that occur prior to the conversion from `void*` to `T*`. Some kinds of systems programming may require the latter semantics, but such semantics may impair some otherwise useful optimizations. 
Either you use it everytime or you don't use it at all. Using a style for half of the returning functions and ignoring the other half negates all the meaning behind it - just my opinion.
&gt; In the updated union example, if x == y then the same memory location is written as float and read as int, which is the definition of the term "aliasing". Whose definition of aliasing is that, other than a back-formation from "construct which is broken by the `-fstrict-aliasing` mode of gcc/clang?" The Standard defines the behavior of writing one union object and reading another, and refers to it as "type punning", and the behavior depends upon how implementations define the representations of the objects in question. As a final point of clarification, I would consider the following very different from the original test1: int test1a(int *p1, int *p2) { *(float*)p1 = 1.0f; return *p2; } In this case, if the same address is passed to `ip1` and `ip2`, then they would identify the same object of type `int`, and would thus be allowed to alias. That's very different from the situation where one is a `float*` and one is an `int*`, and they would thus be accessing different objects. 
&gt;Either you use it everytime or you don't use it at all. Then always use braces on your 'if' statements. That's an \*actual\* way of protecting against real software errors.
Out of a style-guide I use and I think that guide leans mostly on OpenBSD's kernel coding style: Closing and opening braces go on the same line as the else. Braces that aren't necessary may be left out, unless they cause a compiler warning. if (test) stmt; else if (bar) { stmt; stmt; } else stmt;
Ask Apple how much that BSD coding style cost them with "goto fail".
When using clang it’s worth trying to build with -Weverything — it will report all the possible warnings
Yeah, but why should that bother me?
It should enlighten you.
I should change the coding-style of a company based on a stupid mistake by apple? 
...but it won't.
I am sorry but all of this is seriously going over my head. Can you explain it like I'm 5 ?
for when -Wall doesn't mean -Wall, it would be nice if there was a -Wreallyall switch !!
&gt;Since an object of type int is not an object of type float, the references cannot identify the same object, This is trivially disproven by my example, `test1(p, p)`. `p` and `p` both point to the same object, the object that was allocated by `malloc`. If you are trying to introduce some concept "identify" such that a pointer can point to an object without identifying it, you'll need to define that . &gt; even if they happen to be associated with the same storage, This makes no sense. I guess you are referring to the C++ memory model (in which *storage* and *object* are separate concepts, objects may be created in storage). But in C all storage is objects, there is no such thing as storage that is not an object. (This is defined in section 3, "definitions") 
^* Tanenbaum And there are two books by Hennessy \&amp; Patterson, *Computer Architecture: A Quantitative Approach* and *Computer Organization and Design: The Hardware/Software-Interface*, both which I recommend. Nice reads are also *Lions' Commentary on UNIX v6: With source Code* or the FreeBSD book.
I see you have fixed the error in your post. Please don't do this, as now it is impossible to see for others what the issue in your program was. What if someone else with the same problem comes along and finds your question? That person is going to have a hard time understanding what your issue was.
that's the one, Robert'); DROP TABLE Students;-- or Little Bobby Tables as we all call him..... dunno where I got Jonny from !
I typically also pass `-Wno-parentheses` because I do know the precedence of operators and like to make use of it.
 #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;stdlib.h&gt; struct node { unsigned long nd_size; char *nd_string; struct node *nd_next; }; int main(int argc, char **argv) { /* wandering + staying pointer */ struct node *nd_head, *nd_current; nd_head = nd_current = calloc(sizeof(struct node), 1); int i; for (i = 1; i != argc; i++) { nd_head-&gt;nd_size = strlen(argv[i]) + 1; nd_head-&gt;nd_string = calloc(nd_head-&gt;nd_size, 1); (void) snprintf( nd_head-&gt;nd_string, nd_head-&gt;nd_size, "%s", argv[i]); nd_head-&gt;nd_next = calloc(sizeof(struct node), 1); nd_head = nd_head-&gt;nd_next; } nd_head-&gt;nd_next = NULL; /* nd_current-&gt;nd_next == NULL -&gt; ends loop */ while (nd_current-&gt;nd_next) { (void) printf( "\nSize: %lu\n%s\n", nd_current-&gt;nd_size - 1, nd_current-&gt;nd_string); free(nd_current-&gt;nd_string); nd_head = nd_current; nd_current = nd_current-&gt;nd_next; free(nd_head); } return 0; } The last nd\_current-&gt;nd\_next is a NULL-Pointer and I simply loop as long as it returns not NULL. Another way would be looping through the struct and setting a single char to 1 or 0. 0: not the last 1: last one But that's not really necessary &amp;#x200B; This program takes the input, saves it into a struct with the strlen + 1 and prints everything out. I hope this answers your question, because I am not sure if I got what you wanted. &amp;#x200B; Input: ./test3 one two three four five &amp;#x200B; Output: Size: 3 one Size: 3 two Size: 5 three Size: 4 four Size: 4 five Checking for a NULL-Pointer is the easiest way (in my opinion) to look for the last "struct". &amp;#x200B; I didn't do a single error-check, if you use something like that, check for errors!
Love the FAQ
There was idea of -Weverything but it looks it won't get accepted in GCC... [https://www.phoronix.com/scan.php?page=news\_item&amp;px=GCC-Unlikely-Weverything](https://www.phoronix.com/scan.php?page=news_item&amp;px=GCC-Unlikely-Weverything)
Lmao
Do not spam.
My eyes do for 3+ lines snippets :)
Buy the second edition of "The C Programming Language" by Dennis Ritchie and Brian Kernighan. Read the entire thing and you'll be in a good place.
If you're wondering how this is possible, at the very end of the page there's a link to a paper that explains. https://www.cl.cam.ac.uk/~sd601/papers/mov.pdf
Turing accepts your offering and grants you one halting question.
Thank you everyone for your thoughts! I'm currently searching for the best online university for a computer science degree. I've been doing Desktop Support for all of my career and just want to transition to the programming side of things.
I suggest you all check out Chris Domas’ defcon presentations. IIRC, he has one about Movfuscator
Just because gcc can generate a warning for something doesn't mean that it's wrong. Gcc already generates enough phony warnings (I'm looking at you, `-Wunused-result`) and turning on all of them is just plain bullshit.
I think the point of confusion lies in the fact that the Effective Type rule uses the term "object" to refer to an allocation or region of storage (it's unclear which) which may not have any attached type. Such usage is inconsistent with the way the term "object" is defined and used elsewhere in the Standard. Consider the following code [assuming the allocations succeed]: void *haveSomeFun(int mode) { void *p = malloc(1); if (mode) *(uint8_t*)pu = 128; else *(int8_t*)ps = -128; return p; } What value would be held by the allocated storage if `mode` is zero? How about if it's one? Would the values be observably different? Would it make sense to regard the values as different if such differences are not observable? Under the definition of Object used in the Standard everywhere except the Effective Type rule, at the point of the return, regardless of which branch is taken, `*(uint8_t*)p` will be an object of type `uint8_t` with value 128, and `*(int8_t*)p` will be an object of type `int8_t` with value -128. Both objects will have come into existence when the allocation was performed. There's some ambiguity as to whether a `void*` should be regarded as identifying the superposition of all objects that would fit in the allocated space, or as not identifying any actual objects but merely identifying a location where objects may be found, or--when formed by casting some other type of pointer--an object of whatever type it was cast from, but a `void*` of unknown provenance cannot reasonably be said to identify "an" object. Instead, the act of casting a `void*` that identifies a region of storage to a (uint8_t*)` will yield a reference to the pre-existing `uint8_t` object associated with that region of storage. Perhaps I should edit the post to make clear that under the definition of object I'm using (which is also the one the Standard employs everywhere except the Effective Type rule), two references can only be said to identify "the same object" if the type of object identified by the first is the same as the type of object identified by the second and they identify the same storage, can only be said to identify elements of the same array if indexing either could yield a reference to the same object as the other, and can only be said to identify an array and an element thereof if a reference to the same object as the supposed array element could be produced by indexing the first element of the array. Note that the Effective Type rule impedes what would otherwise be useful optimizations, requires bodging the definition of "object" in ways that yield semantics which depend upon the exact bodges applied, and wouldn't be needed if its author had recognized that it would only be relevant in cases which either involve aliasing (where serve mainly to impede what would otherwise be useful optimizations), or which don't involve aliasing but which compilers would be incapable of handling otherwise (which, with quality compilers, shouldn't be an issue). I can't think of any purpose it serves except to wreak havoc and confusion. Perhaps you can tell me something (anything?) good about it? Consider, for example: // Assumes sizeof(float)==sizeof(int)==4 void test_et(int *ip, float *fp, int mode) { *ip = 1; *fp = 1.0f; if (mode) *ip = 1; } void* evil_et(int mode) { void *p = malloc(4); test_et(p, p, mode); return p; } In the absence of the Effective Type rule, the second assignment to `*ip` would never have any effect unless the pointers in `ip` and `fp` alias. Consequently, a compiler that makes no promises about allowing aliasing of unrelated objects could either treat the `if` as unconditionally false, or it could treat it as unconditionally true (in which case the first assignment would have no effect in the absence of aliasing). Under any reasonable interpretation of the Effective Type rule, however, every assignment made to either `*ip` or `*fp` would be allowed to change the Effective Type of the storage, and `evil_et(0)` would have the observable effect of causing the allocated storage to be a `float` with value 1.0f, and `evil_et(1)` would have the observable effect of making it be an `int` with value 1. 
I dont get the point of this, except a quite elaborate joke
&gt;Wtype-limits Isn't \`Wtype-limits\` already part of \`-Wextra\` ?
By way of analogy, there are some places where cars would have a hard time seeing people crossing the street. Requiring that cars drive slowly enough to that they could avoid any pedestrians who might step out from any and all such places would make impossible to drive anywhere efficiently. To remedy this situation, lawmakers passed a rule which states that pedestrians may only cross roads at marked crosswalks which that motorists to slow down, with a footnote saying that the purpose of the rule is to specify when cars must allow for the possibility of pedestrians stepping out from places motorists can't see. Because of the footnote, and because of a desire to avoid needlessly slowing traffic, construction of crosswalks is focused almost entirely on areas of poor visibility. If the rule were merely interpreted as saying that pedestrians who cross at places other than marked crosswalks have an obligation to ensure that motorists will be able to see them, that would be fine. Unfortunately, some motorists have decided that since they have no obligation to protect lawbreakers, they are entitled to run down any pedestrian they see who isn't on a crosswalk. Pedestrians who need to cross roads in places with unimpaired visibility that have no crosswalks, but who don't like being run down, naturally complained about this. Motorists, meanwhile, argue that the rules are necessary to allow efficient traffic flow, and adding more crosswalks would slow down traffic too much. Consequently, there have been decades of debate about where pedestrians should be allowed to cross the road. Unfortunately, for whatever reason, nobody is capable of recognizing what should be a few simple principles: 1. Motorists who know of pedestrians ahead of them should avoid hitting them 2. Motorists should make reasonable measures to notice pedestrians who take reasonable measures to make themselves visible. 3. Pedestrians who take reasonable efforts to make themselves visible should expect that motorists will make reasonable efforts to avoid them. 4. Pedestrians who cross the road from places motorists cannot see, without taking measures to ensure that they are visible, should not expect that motorists will be able to avoid them. If pedestrians and motorists follow those rules, there would be some places where pedestrians would need to refrain from crossing even when no cars are present, and some places where cards would have to slow down even when no pedestrians are present, but no need to write precise rules classifying every road as either forbidding pedestrian crossing or full speed travel. I rather like that analogy. I wonder if it would be worth a post of its own? 
 \#include &lt;stdio.h&gt; int main(void) { float price; float discount\_percentage; float discount\_amount; float discount\_price; printf("\\n\\nEnter price of item:"); scanf\_s("%lf %lf", &amp;price); printf("\\n\\nEnter Discount Percentage on item"); scanf\_s("%f", &amp;discount\_percentage); discount\_amount = (discount\_percentage\*price) / 100; discount\_price = (price - discount\_amount); printf("\\n\\nDiscount amount: %f \\n\\n", discount\_amount); printf("Discounted price: %f\\n\\n, discounted\_price"); return 0; } updated markdown for santiy
Since you're at it, you should probably remove the unnecessary backslashes as well (formatted code is always displayed literally, so it doesn't work).
done, what else can I fix?
The fall through comment stuff is ... really bad [Timestamp](https://youtu.be/FY9SbqTO5GQ?t=629)
Just did that
just did what?
See the faq.
It looks like you've got a handful of problems here. First of all, on like 2, you have `scanf_s("%lf %lf", &amp;price);` There are two problems: **First**, you're scanning for `%lf`, which is a `double`. you want `%f` which is a `float`. **Second**, you've put the sequence twice; you only need `scanf_s("%f", &amp;price);` Next, you probably don't need to use `scanf_s`. I believe these are Microsoft specific functions which allow you to specify the length of the buffer to write to (the passed argument). You're not doing this, so you can replace it with `scanf` Finally in your finaly `printf`, you've misplaced your ending `"`, and you misspelled your variable name. `discounted_price` should be `discount_price`
when i use scanf it gives me warnings, I even used \_CRT\_SECURE\_NO\_WARNINGS and it still gives them
fixed it! thanks for your help works perfectly
What warnings did you get?
i fixed it
IIRC C20 should support C++ish `[[fallthrough]]` attributes, which is less hacky.
before anyone helps you, please, please, PLEASE don't screenshot code. It's just text, copy paste it into something like [pastebin](https://pastebin.com/). &amp;#x200B; secondly, post the warnings you're getting. &amp;#x200B; thirdly, while warnings generally indicate something is wrong, it doesn't mean your code wont compile. although I can see already that the code is missing a semicolon at the conversion line, and the scanf for degrees\_celsius does nothing.
JSON tries to fulfill multiple purposes, without recognizing that different purposes can and should be fulfilled differently. It would IMHO have been more useful if it recognized two categories of representations: canonical, not-necessarily-canonical, and possibly an extended not-necessarily-canonical form. A JSON representation should only be considered canonical if all key-value pairs are sorted by key in character-code order, there is no whitespace between any of the elements, and all floating-point values are formatted in the same unambiguous fashion. Producing an object from a canonical representation and then converting that object to its canonical representation would yield a string matching the original. A not-necessarily-canonical representation of an object would be limited to containing the same functional elements as the canonical form, but could add whitespace and comments, and could list key/value pairs in arbitrary sequence. An extended form could allow additional functional features as well, such as the ability to represent numbers using a bigger variety of forms including hex, and also support additional means of building objects, such as tagging a sub-object and indicating that its content should be repeated at multiple places within an object tree It makes sense to forbid comments within the canonical form of an object. In cases where objects' representations are not completely locked down, however, support for comments is both simple and useful.
[https://pastebin.com/EDyJtYvQ](https://pastebin.com/EDyJtYvQ)
Do not post pictures of code. http://idownvotedbecau.se/imagesofcode
I'm just curious what the warnings were
To just answer your question. Line 26 in your pastebin is missing a ; move the \_CRT\_SECURE\_NO\_WARNINGS before the #include
oh I think it was giving me a printf error, and the scanf\_s
[REcon 2015 movfuscator talk.](https://www.youtube.com/watch?v=2VF_wPkiBJY)
&gt; except for the "flag" and " auto setup header" “Flags” in this context are command-line options. So if normally call the compiler like gcc -o executable source.c (maybe `clang` instead of `gcc`) to compile directly to an executable file, or gcc -c source1.c gcc -c source2.c gcc -o executable source1.o source2.o to compile to objects separately, then link the objects into an executable, using flag `-o` to set output and `-c` to stop at compilation. YMMV, especially if you’re using a Microsoft compiler, not that you should be using a Microsoft compiler for C if you can help it. Compilers have other options to enable optimization, change the kinds of optimization, dump intermediate state, etc. The “auto setup header” stuff is so that you can set those options from inside your source code, without you or anyone else having to pass them at the command-line. In this case, it’ll also warn you if the compiler is set up wrong. &gt; I am not that familiar with defining header files, i have tried to make the most basic ones which I also failed at so when you use stuff like STDC, GCC, #pragma, etcetera which i have never heard/used before it becomes tedious for me to google each and everything thing. See below. Using headers is easy-peasy. &gt; But for future reference please try to answer in most basic way possible (keep in mind that i started learning C roughly a month ago) so keep the use of "high level stuff" (for the lack of a better word) to a minimum, else i will be forced to make google them out of my curiosity because of that i cant get my assignments, notes,etc done in time. My apologies insofar as warranted, but this is the unfortunate drawback of asking/answering questions on a public forum. Your question and my comment are public and mostly-permanent, and as such they’ll be seen by people who will (rightly) notice minor fuckups on my part. (Good C programmers need to be language lawyers, because modern compilers are specially built to facefuck you silently and totally if you step out of line.:) So I tend towards the language-lawyerly end of things, and expect you’ll ask questions about whatever you don’t understand. If you’re talking specifically about my use of terms like “argument promotion” and “prototype” then often there’s a whole *(gesture)* 40+ years of mess behind those, and even slightly less-precise terms can be wrong. C is a fairly old language cobbled awkwardly together from a bunch of dialects that were imitations of imitations of imitations by the time C89 was published, so there’re a bunch of terms the standards settled on that are meaningless outside the language framework. If you get slightly away from those terms, you either have to overgeneralize or throw down a mass of if/elses about compiler options, target platform/architecture/ABI, and all sorts of other details. Maybe in a few years and you’ll See Too Much also, and look back on this thread with agitated fondness. &gt; Finally, i have and will have of lot more basic level questions, but continuing to ask-and-answer in this already very long comment thread would be rather disorderly and posting it on this sub would take quite sometime as well Feel free to ask away, but tormenting C compilers is a big part of my paid work, so anything outside that is on an as-I-can-stand-to basis for me. You can PM me on Reddit if you want to take it off-forum, but don’t worry about thread disorder. Theoretically Reddit has direct chat too but it was added late and pointless/icky. &gt; So, is there a way to add to friends or chat/DM someone on reddit like on facebook or other SNS I assiduously avoid linking anything outside Reddit to my account here. (If you have in you any urge to say something controversial at some point in the future, I advise you do the same.) If it’s super-necessary I guess I could create a burner email account or something, but I’d prefer to keep things here and I’m probably not going to respond any more quickly/frequently/thoroughly over any other channel. &gt; And, on a completely unrelated note i know my English(writing) must be so horrendous that you'd want to kill yourself. But can you please be dead honest and rate it out of 10, because it would do me plenty good if i had simple and beautiful writing like yours , which i definitely do not. You’re probably at or above most native English speakers. We torture the everloving fuck out of the language without a second thought, so you’ll have a hard time beating us at that game. \^\_\^ # That header Throw the code verbatim into a file named compiler_setup.h, which should probably be in the same directory as your .c file(s). In your .c file(s), throw #include "compiler_setup.h" up at the top and that should be all you need to worry about. Header files are inserted verbatim into the code that the compiler sees, basically a function call to another file. So the simplest/stupidest header file can just be a bunch of declarations—generally not definitions, if it’s anything you can’t have more than one of in your final binary—but more complex headers can include inline function definitions, or multiple branches to handle different languages, architectures, hardware variants, platforms, etc. The form of `#include` directive you use determines where the compiler looks for it; #include "header.h" looks for header.h in the same directory as the code doing the `#include`ing, then in the system header locations. #include &lt;header.h&gt; will only look in the system header locations. So `&lt;&gt;` quoting is used for headers that are installed normally like `&lt;stddef.h&gt;`, and `""` quoting is used for one-off stuff like this header. You can `#include` any old text from anywhere, but most headers have a prologue and epilogue that looks like this: #ifndef HEADER_GUARD #define HEADER_GUARD 1 /* ... body of header here ... */ #endif /* ndef HEADER_GUARD */ (The `HEADER_GUARD` macro name is usually based on the header’s filename. I generally do something like `bar__foo_h__INCLUDED__` for my guard macros, where `bar` is a project/user prefix and foo.h is the header filename, but you do you.) The prologue and epilogue make sure the body of the header isn’t handled more than once by the compiler, which can cause errors for things like macro, `struct`, `typedef`, or inline function definitions. Some compilers (e.g., GCC) treat headers with guards like that specially, and won’t even glance at the header file if it’s included a second time. Next up: #if !defined(__GNUC__) || (__GNUC__+0) &lt; 4 # error… #endif If your compiler isn’t GNU/-ish (e.g., GCC, Clang, IntelC 8.0+), emit an error complaining of same. Each kind of compiler has a few macros like `__GNUC__`, as do different OSes, ABIs, ISAs, CPU extensions, language variants/extensions/versions, and languages more generally (e.g., `__ASSEMBLER__`). `__GNUC__` is, if present, the major GCC version number. You can see what macros your compiler defines by doing gcc -dM -E - &lt;/dev/null | sort possibly `| less` also, if you want a nice scrolly view. `-dM`=dump macros, `-E`=preprocess only, `-`=read from stdin, `&lt;/dev/null`=stdin is empty, `|sort`=because otherwise the output is unordered. Most of what you’ll see is GNU-specific, unfortunately. #pragma GCC system_header Pragma directives are special instructions to the toolchain. In this case, it directs GCC to treat the enclosing file like a system header, and not bitch about its contents unnecessarily. #pragma once This is supported by most modern/-ish preprocessors, including GCC’s; it tells them not to include the file more than once. #if defined(__STDC_VERSION__) &amp;&amp; (__STDC_VERSION__+0) &gt;= 199901L # warning … #endif C≥99 define `__STDC_VERSION__` as ,`YYYYMML` referring to the Y=year and M=month of the language standard’s ratification, and you’d prefer not to have C99 support. C99’s `__STDC_VERSION__` value is `199901L` and C11’s is `201112L`. `#warning` is a GNU extension that emits a warning. #pragma GCC diagnostic ignore "-option" When `-option` is a diagnostic command-line option, this pragma tells the compiler to ignore that kind of warning/error. #pragma GCC diagnostic error "-option" Like `GCC diagnostic ignore`, but tells GCC to treat things as errors instead.
Hint on behavior: What does expression `5/9` yield?
aside from the other comments your code is not answering the temperature in celsius, is asking for it, please check it!!!
&gt;uhh im not sure i looked up the formula and thats what I got. Is that the only thing wrong with it? &amp;#x200B;
Both operands to `/` in `5/9` are integers, so the result is an integer. If you want it to be floating-point (i.e., nonzero) you need to use 5.0/9.0, or else do `(5*(f-32))/9` so the float-ness of `f` will propagate to the entire expression.
This is what I have now, maximum altitude isn't working correctly. int main(void) { &amp;#x200B; &amp;#x200B; float Celsius, Fahrenheit, Fahrenheit\_1, Celsius\_2, maximum\_altitude; &amp;#x200B; printf("Enter the temperature in Fahrenheit: \\n"); scanf("%f", &amp;Fahrenheit); printf("Fahrenheit temperature is: %5.1f F\\n\\a", Fahrenheit); &amp;#x200B; Celsius = (100.0 / 180.0) \* (Fahrenheit - 32); &amp;#x200B; printf("Celsius temperature is: %8.1f C\\n\\n\\a", Celsius); &amp;#x200B; printf("Enter the temperature in Celsius: \\n"); scanf("%f", &amp;Celsius\_2); printf("Celsius temperature is: %8.1f C\\n\\a", Celsius\_2); &amp;#x200B; Fahrenheit\_1 = 32 + (Celsius\_2 \* (180.0 / 100.0)); &amp;#x200B; printf("Fahrenheit temperature is: %5.1f F\\a", Fahrenheit\_1); &amp;#x200B; printf("Enter maximum altitude in meters:\\n"); scanf("%f", &amp;maximum\_altitude); &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; return 0;
I've always wondered why the only language I've ever seen fallthrough is JOVIAL J73. Their case statement (I forget their keyword) was Pascal like, where only one case is evaluated, unless the fallthrough keyword was used. I've missed that. 
C was designed to avoid requiring the compiler to do things which could be handled easily in user code. The `switch` statement is effectively a combination of a computed `goto` and a dummy "do{}while(0)` loop. I think a reserved word combining a `break` with a case label, or even a common convention of defining a macro for that purpose, would have been an easy improvement to the language, though.
that's because in this code your are doing nothing with the `maximun_altitude` variable
Just noticed the tshirt - awesome.
Yeah, I understand C not having it. Like you said, the `case` label is basically a `goto` target, and `break` is basically a `goto` past the loop. Relatively simple for the compiler. But so many other languages have come along since, and they didn't adopt `fallthru`.
Golang has a `fallthrough` keyword that is used like this. It also has implicit `break`s in all its `case`s. If I'm being totally honest it's not my favorite feature. On the one hand, I'm more likely to want my cases to be distinct, so using `fallthrough` instead of `break` tends to save me some typing. On the other, I've never seen it in any other language, and switching (PUN) between C and Golang will occasionally leave me frustrated.
Thanks, I didn't know that (or if I did, I'd forgotten). I understand the frustration, but I think I'd be more frustrated with C. I can't count how many bugs I've written by forgetting a `break` (using older compilers that didn't warn about its omission).
The lack of fall-through would have been a severe nuisance absent a means of attaching multiple values to a case label. Perhaps, though, the problem is the way code is formatted. If one ignores the meaningless initial break, writing code as: switch(foo) { break; case 0: do_this(); break; case 1: case 4: do_that(); break; case 2: case 3: case 5: do_the_other_thing(); break; default: whatever(); } then any missing breaks would be rather obvious. 
I see the appeal but this strikes me as sloppy and errorprone. Consider encasing code with a foo(void); #ifdef VARIANT1 foo(void) { ... } #endif #ifdef VARIANT2 foo(void) { ... } #endif int main(int argc, char** argv) { foo(); return 0; } and then on your gcc command gcc whatever.c -o whatever -DVARIANT2 where the -DVARIANT2 causes the preprocessor to define the variant you want.
No because I imagine a point where I'll have a function named "printf231" and "printf123". If I wanted a different version of something, I'd completely rename it. Sort is a good example, you could just call something sort if you didn't care -- or quick_sort, bubble_sort, merge_sort.
More code is going to cause more errors. Version control is the means to handle versions of code. Check in our work in a sandbox and then you’ve got full archive of each commit and only one function to work on. Much less work this way.
What about when it's something like quick_sort and quick_sort_with_minor_variation and quick_sort_with_different_minor_variation?
Quick sort is a well-established algorithm. If your implementation is a modified version of it, have its function name reflect that and document the changes.
Website http://facil.io doesn't work
If people would spend more time on their code and less time talking about how dangerous C is they would get a lot more work done and (reaity) they wouldn't write such screwed up code.
Works fine for me
Too true, same for every language really. 
That use of a define and anonymous struct variable to make for variable, optional arguments to functions is a nice idea! `http_set_cookie(request, .name = "my_cookie", .name_len = 9, .value = "data",.value_len = 4);` https://github.com/boazsegev/facil.io/blob/master/lib/facil/http/http.h#L184
Maybe use Git instead?
I kind of like this. I doubt I'd use it because it would be confusing to traditional C coders, but you're right that it emphasizes the breaks. 
Versioned functions are typically a design smell and indicate that your API was poorly designed to begin with. That doesn't mean that you should avoid them. Instead, avoid the situations where they are necessary by staking out the scope of the API before you nail down the signatures of its functions and by chosing a design that allows for extension without changing the signature of existing functions.
They could always use Ada/Spark and not have to worry about undefined behavior. /s
Thank you mate. Can you spare some time to express you view on C unleashed?
For the next time, please put the gist of the question in the title. That said, there is no language called C/C++. Which language are you programming in?
I haven’t read or used it, sorry.
No I'm sorry, what I meant is that you can actually choose which one to pick. I program with C tough
If I were the student receiving this assignment, I would need to ask a few clarifying questions of the instructor. &gt; The function...has to swap max 30 positive or null values contained in "a" with the values contained in "b". Does this mean that any non-negative values in "a" get moved to "b", up to 30 in quantity? I.e. if the first 30 entries in "a" are &gt;= 0 then it simply swaps those and terminates? Also, I am guessing that by way of translation "null values" means 0 and not C's NULL? &gt; Fill the "y" array with 30 values get by standard input - insert only negative numbers Are you, the student, responsible for validating input for this exercise, or can you skip that and assume no user error for the sake of simplicity because it isn't the focus of the assignment? And, a question for you: &gt; Execute SWAP - use "t" and "n" for the results...I have actualy no idea wich result is the exercise talking about This sounds like you do not understand how to use a function -- meaning, how the variables "t" and "n" as described by the assignment are to be used by the function you wrote. Is that correct? If not, can you clarify. Finally, it is always a good idea to show us the code you have tried if you're seeking assistance. IF it's short you can just edit your post and include it using reddit's built-in code formatting. Otherwise you can use a 3rd party service like pastebin to format the code for us to read, and just put the link in your post.
Just use version control... 
Sure, weak symbols are supported by ELF format, but are not supported in PE Executable. Look up weak here: [https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#Common-Function-Attributes](https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#Common-Function-Attributes) &amp;#x200B; If I remember correctly, there is alternative attribute which does similar thing, but weak symbols do not work in the same manner as in ELF files.
Yeah, I've ignored version control maybe too long by now, are git/svn/mercurial usable on a local machine? I have a really dodgy internet connection so I've never had any pull towards github or lab or whatever.
Also, what about for minor variations to a function, is it always worth keeping a whole branch to test out a couple simple variations?
I see a lot of this kind of posts, try to do something first, then I sure someone here will help you to finish. Try to make the two arrays and show it on consolo or something...
True. We should all aspire to write perfect bugless code like you.
Keeping a branch costs almost nothing. All git stores is the differences between your changes, and a branch is nothing more than a label attached to a specific change.
According to the published Rationale document for the C Standard, the authors of the C Standard intended that the question of how to process certain constructs which invoke Undefined Behavior (e.g. whether to "[behave] during translation or program execution in a documented manner characteristic of the environment") should be viewed as a Quality of Implementation issue. People seeking to make quality compilers for various purposes should be better equipped than the authors of the Standard to judge what "popular extensions" their customers would be likely to need, and wouldn't need the authors of the Standard to tell them that they should seek to fulfill such needs whether the Standard requires them to or not. As far as the Standard is concerned, The difference between Implementation-Defined Behavior and Undefined Behavior is that the former would require that implementation to specify at least something about the behavior of a construct even if guaranteeing *anything* about it would be expensive, and even if none of its customers would benefit from any behavioral guarantees, while the latter would allow implementations to offer useful behavioral guarantees or not, at their leisure. The difference was only expected to be relevant in cases where the benefit that an implementation's customers could receive from behavioral guarantees would be less than the cost of providing them. Most programs are subject to the following requirements: 1. When given correct input, produce correct output. 2. Even when given malicious input, do not allow the creator of that input to initiate actions outside the program's duties. The Standard deliberately allows implementations which specialized for tasks that aren't subject to those requirements to behave in ways that would make them unsuitable for tasks that are. What's necessary is to recognize that the Standard makes no attempt to mandate everything necessary to make an implementation suitable for such tasks. 
Thank you for the answer, I'm gonna edit into the post what I actually wrote. As you said some assignement are unclear, I find these abiguities even in the italian version. As long as I understood the function has to swap a value from b to a (and so moving a into b) for 30 times than stops. But in the main looks like I have to recall it in a cycle untill I get the full values of "x" negatives. Also I meant 0 with NULL, not C NULL - I dont even knew it existed sorry for ambiguity. For the "n" and "t" I don't undersand wich result does they need: the total of "swap" application? the return of the swap function? 
I'm gonna Edit into the post the code that I wrote down, thank you for the answer :)
Thanks for sharing. I personally dislike CMake *for C projects*, as it adds a C++ dependency. This ranges from completely fine, say on a Desktop, to completely unacceptable, say on an embedded system. You gotta be somewhat careful with what projects you use CMake with as they can refrain people from using it.
&amp;c=j; if(&amp;c==30) &amp;#x200B; I think this two lines are wrong, 25. 26.
Alright thanks!
You're right, that pattern was decidedly not DRY. I moved it into a MACRO to make it DRYer. [Thanks for the feedback](https://github.com/boazsegev/facil.io/commit/80cb4693c360371ccf8e8ea9eaa2ec41f1dd5baf).
I'm not familiar with the ltmp0 symbols, so I'm not sure why you're seeing those, but not the `obf()` symbol. But do you have the declaration of `obf()` wrapped in an `extern "C"` block in your .m file? If not, the linker might be looking for a C++ symbol instead of a C symbol.
OK - having read your code I see several things to fix. Before getting into it, here is the summary up front. You should search online for some tutorials about pointers, the address-of operator, and passing arrays to functions. A more detailed explanation: 1) In general, use of pointers and the address-of operator. One thing that would be confusing is that pointers are both declared and accessed using the \* operator, just in different ways. Explanation below. int *p; // this is a pointer variable. It will point to a location in memory that holds an int. int v; //this is an int itself. While it obviously also is a location in memory, it is the numerical value itself. int d; //another one, used later. v = 5; //defining a value for the variable p = &amp;v; //using the address-of operator. Translated into words, this is "p equals the address of v" d = *v; //using the dereference operator. d now holds the value 5, because that was stored at the address that p "pointed" to. Pointers are a type. Meaning, you can have an int variable as well as an int \* variable. They are not the same type even though they look similar when declared. In english, the terminology makes more sense. A pointer *points* to a location in memory. In other words, it refers to a location in memory. When you want to see what is at the location it points to, you dereference it ("de**refer**ence) to get the value at the location. 2) Your do-while loop. The condition to stop the loop is when j &gt;= 30. The problem is that your for-loop increments j and is inside the do-while loop. This means, in theory, j could be incremented every time through the for-loop before the do-while loop condition is even checked for the first time. I would only use one loop, regardless of what kind you choose to use. You are limited by two things -- the length of "a" and the length of "b", but in essence you are looping over "a" and inserting into "b" only as long as you have room. You are already tracking that with a separate variable -- j -- but you can just monitor that value and stop your single loop over "a" early if needed. 3)You definitely need to change how you call your function. First, it returns a value, but you are not assigning it to any variable. This is part of what the question means when it wants you to keep track of the result in either the variable t or c. For example: t = SWAP(...); Second, you are passing the arrays to your function incorrectly. You are using the notation to declare an array, instead of using the variables you have already declared and defined. Using that when calling the function will cause an error. Instead: t = SWAP(a, b, &amp;c); //Note: we are also passing c as a pointer because we are referencing its memory location with the address-of operator "&amp;" Arrays can be challenging for C beginners because, among other things, they work like pointers when passed to a function. Meaning, you call a function with the name of an array, but what the function receives is a copy of the value of the pointer to the first element of the array. A real-world analogy would be a repairman instead of a function. The repairman is going to do something to the house (our "array"). You do not give the repairman a copy of the house, instead you give him the address of the house. And, because the address of your house is either in your head or written on paper you need to keep, you write down a copy of the address on a new note and give it to the repairman who then goes to the address and performs his action (his "function") on the thing located at the address. I could keep going by talking about other things, but I think that will be a good start for now.
I don't quite understand what you mean by a C++ dependency when just using C. I've used CMake for embedded systems (MCU) in which I only used C and assembly, no C++, and had no issues. Also, C++ is fine on an embedded system as long as you don't use the features of the language which introduce dynamic memory allocation (which can also be alleviated by you using your own allocator).
Spatial-hierarchies: octrees, KD-trees, Vantage Point trees, ball trees, etc.. There's a variety of strategies for reducing the number of things you're actually calculating against. Some are better suited for static situations while others are better for dynamic simulations where things are moving around and the structure needs to be regenerated or updated constantly.
CMake requires a C++ compiler.
It's a `.c` file. And I tried wrapping the decl and definition in `extern "C" { }` and it gave an error, so I don't *think* it's compiling as C++. I'll double check on that though.
Yeah, my initial thought was that objective-c would look for c++ symbols by default (hence the `extern “C”` suggestion, but it supposedly does not. It should interop with C just fine. So then I was wondering if your C file was getting compiled as C++ by accident somehow.
I forget that you have to wrap the `extern "C"` statement in an `#if __cplusplus__` or something. It didn't compile the first time probably because I was missing that.
Ah. Did the `extern “C”` fix your linker issue?
I'm not at home, I'll report back!
Cool. Good luck!
C doesn't know about extern "C". In the .c file don't do anything special. But in the .h file try something like: #if OBJECTIVE_C # define EXTERN extern "C" #else # define EXTERN #endif EXTERN const char *obf(const char *); Note that I'm just guessing about the preprocessor constant OBJECTIVE_C so you will probably have to find a better symbol.
you can write either `int *i` or `int* i`. The end result is the same. Whatever you chose is up to you. Although, try to be consistent.
Ok thanks! Sorry for such a basic question. It just seems to me that idiomatic C seems to use the int *i; syntax.
Example 1: *int \*var1, var2;* when we want to assign pointers to specific variable we use **\*** preceding the pointer variable name... In eg1 : var1 is a pointer and var2 is a normal integer .. &amp;#x200B; Example 2: *int\* var1, var2;* when we want to assign pointers to all the variable in the declaration statement we use \* after the datatype... in eg2 : both var1 and var2 are pointers...
This is exactly what I was looking for ! Thank you 
One reason for the preferred style is when you define multiple variables `int *i, j;` / `int* i, j;`. In both those cases, `i` is a pointer to int and `j` is just an int. By the way, spacing doesn't matter here. You can also write `int * i` and the compiler wouldn't care.
This worked, as I suspected: #ifdef __cplusplus extern "C" { #endif And one for the closing brace. Your macro strategy would probably also work with __cplusplus
It's completely wrong. Ignore it.
What's wrong? 
There's a saying about C that "declaration follow use": [https://eigenstate.org/notes/c-decl](https://eigenstate.org/notes/c-decl)
 int *var1, var2; and int* var1, var2; both declare var1 as a pointer to int (ie. an \*int), and var2 as just an int.
I read your link and I think it makes sense thanks. I prefer the int* syntax and am not a fan of multiple variables being declared on the same line, but I can understand why it works the way it does in C now. Thanks a lot.
Sure. It's heartening to learn that there \*is\* a logic to it. :) &amp;#x200B; It also make sense with qualifiers like const. For example, what type is 'a'?: const int* a; A constant pointer to an int? Or a pointer to a constant int? &amp;#x200B; It's the latter, which makes more sense (imo) with the classic C declaration syntax: const int *a; which makes the case that the expression `*a` will return a `const int`. &amp;#x200B;
It worked! Thanks!
The best way to learn c is to try different variations run the code and debug from there the debugging will tech proper syntax.
Massless particles or particles located at the same coordinates? Nothing fancy you say ? Firstly I don't see how massless particles have any place in a newtonian system. Also .. this has been done before ... over and over. The two body system will always have perfect solutions and we don't need numerical methods. Otherwise a ton of smart methods are needed and there was someone else that brought up the problem ( again ) just within the last few weeks. I will see if I can find you a link. In the mean while consider that any fixed dt will fail. You must have a continuously variable dt value.
That was the original intention, but it ceased to hold true after declaration syntax was changed to allow initialization.
No, that is the worst way to learn. There is no way of knowing if the behaviour you observe is a correct program behaving correctly, or a broken program exhibiting undefined behaviour.
You have to remember that much of C's syntax was determined by how easy it was to convert it to pdp11 assembly. Also a lot of the language's design were just Ritchie's personal preferences. K&amp;R C had a lot of little gotchas.
I think that CMake is perfect for a C project as long as you provide binary releases so that users don’t need to setup CMake or have C++ themselves. CMake doesn’t have 1st-class support for the “./configure &amp;&amp; make &amp;&amp; sudo make install” workflow like Autotools, but it has amazing testing, packaging, and configuring support which IMO makes up for it. 
There's two ways to interpret the declaration, and each way has a more intuitive place of where to put the asterisk. The first way is to think of i as of type pointer to int, which corresponds to writing "int* i." That's the most intuitive way to me. The second way is to think of i, once dereferenced, being an int ("int *i"). In usage, you would write "*i = 10" to set whatever i points to to 10. The second declaration style mirrors that nicely by grouping the asterisk with the variable name.
It is! Thank you a lot for finding time for such a detailed answer. Pointers and array are very confusing to me but I'll try to get some tutorial about the topic. You helped me to clarify the meaning of the tools, now I just need to start to use them correctly. Thanks again and have a nice Sunday
Oh ok thats probably why the last portion of the code was red, I messed up with brackets. I surely made some big mistakes whike using pointers cause I tought it was something I understood but apparently I havent. Have a nice day man
Wh00t!
Gcc and clang are written in c++, most of the embedded compilers rely on a fork of one of those
Declaration follows use: when you declare `int *i;`, the expression `*i`will be `int`. That's all there is to it. So all the rules of how to parenthesize and whatnot can be inferred from the operator precedence rules. A cast is just a declaration without a name and whether you write `(int *)` or `(int*)` doesn't matter in the slightest and is just up to your taste.
That's definitely true, massless particles don't have anything to do in classical mechanics. Just like the fact that particles shouldn't be at the same coordinates. But it's not like I'm doing anything fancy as I've said, I'm just... well, having fun messing around with a simulator. People have done this over and over, and they'll continue to do so. I don't care if people will use a different software, I don't care if people don't even hear about mine, because its sole purpose is to be there and entertain me. ------ That paper you sent seems really interesting, I'll see if I can go from there. Thanks !
When you write: int* a, b; `a` is a `int *`, and be is a `int`. That's why: int *a, b; is much clearer and less error-prone.
Or you can write int* a; int* b; which is even clearer and pretty much impossible to get wrong.
Well, `int *i` is also what everybody uses (the "idiomatic" way to write C), so it's just a style thing you need to get used to. I don't think `int *i` is less clear than `int* i`.
Syntactically, the asterisk is attached to the variable name, not the type name. This does not change, even if you want it to be different really badly. When doing a cast, the type you cast to is written down as in a normal declaration but with the variable name left out. Thus it appears as if the asterisk belonged to the type name, but it doesn't actually.
 int*i int* i int *i int * i Are the same. int *i Is more idiomatic, mostly because it works better in the ```int *i, j``` case (but I find this argument spurious). At the end, you can either say *i is a pointer to int* (```int* i```) or *when I deference i, I get an int* (```int *i```). It is equivalent.
Thanks, squid farts.
Objective C is off topic in this subreddit. Please post Objective C questions elsewhere, e.g. on Stack Overflow.
Git can be used completely locally - it just creates a folder within your project folder.
No it didn't. The declaration and usage syntax is still the same. But I must agree that "usage reflects declaration" think is more harmful than useful really. 
Yes, and that's how it should be because that's how the compiler parses the declaration. Anything else is confusing when you declare multiple variables at the same time for example. Here's the grammar for reference: declaration declaration-specifiers ; declaration-specifiers init-declarator-list ; init-declarator-list init-declarator init-declarator-list , init-declarator init-declarator declarator declarator = initializer declarator direct-declarator pointer direct-declarator `declaration-specifiers` includes the type. As you can see, the pointer has a higher precedence than the type, so even if you write `int* i`, it is still parsed as `int *i`.
 (ノಠ益ಠ)ノ彡┻━┻ "Because I don't want to change the shit that I'm writing from (\*fptr)() to (\* fptr)(), and it isn't my fault that pointers are so insecure about themself that you have to define them explicitly every time you separate a variable with a comma." (I'm just joking, I'm not angry, really.) Maybe we can just rationalize pointers as something that transcends types, classes and qualifiers or something? I don't know.. ┬─┬ノ( º \_ ºノ)
I always write `int* i;`
I'd always recommend against that because it's misleading: int* i, j; ^ The type of i is int*, the type of j is int.
If declaration continued to follow use in the presence of initialization, then `int *p = *q;` would cause `*p` to match `*q`. Qualifiers add additional problems, because the way the object like `int const * const q;` would be used would not include the `const` qualifiers seen in the declaration. 
It's the "width" or number of bits of an word (usually `int`). For example, `int` is usually 32 bits wide on our current systems, so wordsize would be `32`.
*wordsize* means the number of bits allocated to the variable's storage. An *int* on most modern systems is 32 bits. A signed int can store any value from 2147483647 to -2147483648 when using two's complement signed representation (and nearly all systems use two's complement these days). &amp;#x200B; wordsize refers to the size of a "machine word" or a particular computer's native register size.
What they mean is the number of bits used to represent an `int`. In your case, this will most likely be 32 or possibly 64. This can be computed by muliplying number of bytes in an `int` times the number of bits in a byte. `sizeof(int)*8` or, even more _correctly_: `sizeof(int)*CHAR_BIT`. 
Sizeof will give you the size of a data type and CHAR_BITS will give you the number of bits in a char...
Initialization is a separate thing. The left side of = is an expression. What it was assigned has nothing to do with how you access the variable. I agree with the qualifiers. 
&gt;because its sole purpose is to be there and entertain me. I sometimes think some people just don't get it that implementing your own solution (no matter how many people have previously done the same) is a stimulating and interesting intellectual challenge, some people spend their time with computers simulating mass murder (i think they call it first person shooters) myself I code....
The Bash (and maybe Bourne shell more generally?) `case…in` construct has optional fall through, where `;;` breaks out of the statement, `;&amp;` continues with the next case without matching, and `;;&amp;` continues at the next match in the statement. But yeah, it’s pretty rare, and I wish C had done `switch` better so the rest of the family &amp; derivatives wouldn’t’ve followed in those footsteps.
If you’re using a GNU/-ish compiler, here’s a terrible trick that you should definitely never use. #define ptr_to(T) __typeof__(__typeof__(T) *) #define array_of(T, count...)__typeof__(__typeof__(T)[count]) Now you can do ptr_to(int) i, j; ptr_to(int(void *, void *)) k; const ptr_to(volatile char) foo; ptr_to(array_of(double)) bar; array_of(ptr_to(double), 8) baz; etc. etc.
It wasn't an Objc question. It was a C / compiler specific question. Not really sure why I tagged it Objc, other than the fact one of my files was `.m`, my bad
I would write that as int* i; int* j; I never declare multiple variables on a single line as a rule
I'm sorry. Questions about the interaction between C and other languages are on topic. I have restored your question. That said, you would have made this much easier for all of us (including those who wrote answers) if you posted the gist of your code (i.e. enough code to reproduce the problem) in your post so others can fiddle around with it, too.
My apologies! And you're right, I should have. I'll be sure to do that next time. Thanks!
There's no confusion or inconsistency in the definition or usage of *object*. `malloc` allocates an object which has no effective type until you set its effective type by writing to it. It sounds like *you* are confused but that could be sorted out by reading the Standard. In your example if `mode` is 0 then the object has effective type `int8_t` and value `-128`. Otherwise the object has effective type `uint8_t` and value `128`. These are the same representation but different values. Your subsequent questions are nothing to do with strict aliasing and seem to display misunderstanding of representations versus values. The same representation may represent a different value depending on the type. &gt;Both objects will have come into existence when the allocation was performed. No; one call to `malloc` creates one object. Writing a value to the object sets the object's effective type. &gt;In the absence of the Effective Type rule This is an inconsistent hypothetical; the strict aliasing rule depends on the effective type rule. So if there were no effective type rule then the strict aliasing rule would have to be different in some way, which you would need to specify to proceed with this hypothetical. Also you would need to define "object of type T" for dynamically allocated objects, since the standard uses that terminology a lot and it is currently defined by the effective type rule. Once you've written such a definition, that definition could be given a name. That name could even be "effective type rule" 
The guy has some kind of deep issue with the strict aliasing rule, and has been posting diatribes like this continually for years (usually in the form of a series of max-length comments on old stackoverflow questions). As far as I can tell, when he says "quality implementation" he means "implementation that follows what I think the rules should be, instead of following the standard" but he is unable to propose a consistent set of alternative rules. I don't know why anyone upvoted this, I guess it was a case of "this is long and technical and uses paragraphs, updoot time". I respond here mainly for the sake of other readers. 
You'd probably be better posting that on /r/programming 
But the repos are only for systems programming languages C, C++, Rust and Swift, hence I posted in the C programming language subreddit.
Please chose a better title for your next post. As a rule of thumb, if you have a question, put the gist of it in the question. Nobody knows what you want if you say “K&amp;R exercise 3.4 help.”
Your post got caught in our spam filter. I apologise for the inconvenience.
Your post got caught in our spam filter. I apologise for the inconvenience.
Go away please.
Please be more civil in your assessments.
Your post got caught in our spam filter. I apologise for the inconvenience.
Pinkie extended as I sip tea?
I think what is getting you is buffered I/O. When you answer the question the first time, you press 'y' and hit return but what is buffered is "y\n", so scanf reads in 'y' then the next loop iteration immediately reads '\n' without waiting for what would be additional keyboard input. If you add a space in front of your format specifier on the scanf call that should fix it. (e.g. `scanf(" %c, &amp;responce");
That works, thanks. Here comes the long and tedious journey to getting acclimated in C. 
Have you considered the if-statement instead of the while-statement
well id like to keep asking for a double or else it does return a double. but I found the solution: &gt;double input; while(scanf("%lf",&amp;input) != 1) { getchar(); } return input;
That's the reason why I stopped studying CS and went with chem instead. I was working 7h-21h doing shitty assignments that were reviewed by a shitty program instead of a teacher. Where's the fun in that? How I am supposed to have any kind of social life in such a context? I said fuck it after two weeks. I'm now programming for fun and doing chem for fun. Though I have to say lab work is a bit more fun, aha
Thanks
I prefer if you avoided terms like "human garbage."
this isn't really the fault of streams, but rather the implementation of printf and friends, rather than checking each use of a stream it would be nice to have some option to set a stream exception callback, but I can't see that getting added to the libs ....
A couple of days ago I pointed out [that the article is wrong about when `errno` is set](https://old.reddit.com/r/programming/comments/ak27d9/replacing_python_candidates_2013_with_interesting/ef1b1ox/). POSIX requires certain stream functions to set `errno`, but C doesn't have any such requirement. Here's my solution for all the issues listed in the document: errno = 0; fflush(stdout); /* may set errno */ if (ferror(stdout)) { /* get the stream's error indicator (sticky) */ if (errno) perror("hello: write error"); else fprintf(stderr, "hello: write error\n"); exit(EXIT_FAILURE); } exit(EXIT_SUCCESS); You don't need to check every `printf()` since the error indicator is sticky. This will print out a diagnostic if one is available. Since it doesn't check the result of `fclose()` — which is unnecessary if the output buffer is empty — it won't report false errors. 
I don’t know if any, but nuklear is backend-agnostic, and if you want help creating your own glad+OpenGL backend feel free to dm me because I ended up doing something similar.
You don't know how to write any function? Or you know how to write functions, but you don't know what to put in this particular one to get the hundred's digit?
What type of input are you expecting? Consider that `scanf("%d", &amp;n);` does two things: read numbers from a string (`123`) and convert them to an integer (`*p = atoi(buf)`). (Not sure if that's what technically happens, but I don't think it's unreasonable.) You have to scan a line manually in order to properly get user input. There's also boundary checking (fits inside an `int`? a period makes it a `double`, etc) but that's just growing for no reason now. My simplest tip is to loop over a line you get with `fgets`, copy characters to a buffer until you get a delimiter (whitespace, +-*/, etc) and then work from there. Good luck.
int get\_hunderedth (int n) { int k =(int)n/100; return k; } &amp;#x200B; &amp;#x200B; This works if input number has 3 digits
I'm expecting any numeric input in general. This isn't for a specific program per se but rather what the community or rather how C programmers in general, safely handle the situation where a user is entering "numerical data" from the keyboard. I didn't expect this to be such a "philosophical" beard stroking problem but as I got down to thinking about it, it is rather difficult, there's a lot of cases to cover and in other languages reading in input is an after thought, like in Java, where it's just input.nextInt() and that's it. What you've suggested is what I plan on doing, in future for my programs but I'm curious to see what other people do or if there is some sort of standard. However I'm beginning to suspect that those other languages are doing what you've suggested in the background when you call those functions and in C well... you've just gotta write them yourself lol. 
I should also let everyone know that I'm considering **C99** standards on up, unless there's something in c89 or before that I don't know about. 
The definition of object given in C89, which hasn't changed much since, is: * Object --- a region of data storage in the execution environment, the contents of which can represent values. Except for bit-fields, objects are composed of contiguous sequences of one or more bytes, the number, order, and encoding of which are either explicitly specified or implementation-defined. The only change to the definition was to remove the requirement that objects be stored as a contiguous sequence of bytes in Implementation-Defined sequence, even though many common constructs are only meaningful on objects which are stored using a sequence of consecutive bytes, and to add a footnote which is written vaguely to accommodate the Effective Type rule, but muddles things rather than clarifying them. Unfortunately, the notion of "can represent values" is a bit vague. As used everywhere except in the Effective Type rule and the aforementioned note (i.e. everywhere in the C89 draft), however, one could make the definition of object more specific: "An object of any particular type is a region of storage, the contents of which *represents* [not merely "can represent"] a value, indeterminate value, or trap representation *of that type*." Nowhere except the Effective Type rule or the bizarre note is there any notion of an "object" which does not unambiguously represent one of the above [under C89, the only meaningful possibilities were a value of the type or a trap representation, since indeterminate values couldn't be anything other than values or trap representation]. The Standard should define a term for an allocation (whether or static, automatic, or allocated duration) region of storage which can hold objects, and which is not shared with any other such allocation, but it doesn't. You (and perhaps the authors of the Effective Type rule) seem to be using the term "object" in that fashion, but that concept is orthogonal to the term "object", since the latter can also be used to describe members of structures and unions, which share storage with the enclosing objects (and, in the case of unions, other members as well). &gt; In your example if mode is 0 then the object has effective type int8_t and value -128. Otherwise the object has effective type uint8_t and value 128. These are the same representation but different values. Your subsequent questions are nothing to do with strict aliasing and seem to display misunderstanding of representations versus values. The same representation may represent a different value depending on the type. If a particular representation can represent a different value based on type, that would imply that a representation with no attached non-void type is not a value. Consequently, a region of storage which isn't associated with any particular non-void type is not an object. &gt; This is an inconsistent hypothetical; the strict aliasing rule depends on the effective type rule. So if there were no effective type rule then the strict aliasing rule would have to be different in some way, which you would need to specify to proceed with this hypothetical. If one accepts the fact that the "strict aliasing rule" [3.3 of the C89 Draft or 6.5p7 of the C11 draft] was only meant to specify when things may alias (as evidenced by Footnote 88: The intent of this list is to specify those circumstances in which an object may or may not be aliased.) the rule could be used for that purpose just fine without need for the Effective Type rule, simply by replacing the term "effective type" with "type". Given something like: struct foo {int x,y,z;}; struct bar {int x,y,z;}; void *test(void) { void *vp; int *ip; struct foo *fp; struct bar *bp; vp = malloc(sizeof (struct foo); }; fp = vp; fp-&gt;y = 1; ip = vp; *ip = 2; bp = vp; bp-&gt;z = 3; return vp; } My interpretation of the term "Object" would imply that the malloc creates objects of every type or combination of types that would fit in the space returned by the first `malloc`, though of course most of those objects would never be accessed. The write to `ip` would affect the stored value of `*fp`, `*bp`, `fp-&gt;x` and `bp-&gt;x`, as well as any other object sharing the same storage, but since it would be performed after the last use of `*fp` and before the derivation of `bp` [and all three indirect assignments access disjoint storage anyway] there would be no aliasing. What objects would you say would exist at various points in the function, or when it's a about to return? If one uses a definition of `object` which isn't bodged in an effort to make the Effective Type rule meaningful, or the "strict aliasing rule" workable in circumstances that don't involve aliasing, there's no ambiguity as to when the objects of types `struct bar` and `int` that are referenced by `bp-&gt;z = 3;` come into existence: they exist as soon as the storage to hold them does, and the assignment accesses the pre-existing object. &gt; Also you would need to define "object of type T" for dynamically allocated objects, since the standard uses that terminology a lot and it is currently defined by the effective type rule. Once you've written such a definition, that definition could be given a name. That name could even be "effective type rule" Any object identified by a pointer of type `T*` will be a `T`, regardless of how it came into existence. A pointer of `void*` may identify a region of storage, but does not identify any object. The notion of dynamic types serves no useful purpose in C, since aliasing analysis that can't be performed statically, can't be performed practically at all. &gt; evil_et(0) would have the observable effect of causing the allocated storage to be a float with value 1.0f, and evil_et(1) would have the observable effect of making it be an int with value 1. That is what the standard actually says. (granting some licence to your usage of "observable effect"). Do you have some problem with that? It seems to me like entirely reasonable and expected behaviour for the code. The last line was if ( mode ) *ip = 1; so if mode was 1 then we should have written an int. The only time the `mode` argument to `test_et` could have any effect is when `*ip` and `*fp` alias. I would suggest that because nothing *during the execution of `test_et`* would create or imply any relationship between those pointers, a compiler should be entitled to assume that they will not alias. Do you think some useful purpose is served by requiring a compiler given `test_et` to allow for the possibility that `*ip` and `*fp` might alias, and blocking the optimizations that could be performed if a compiler were allowed to assume they won't? 
Why are you casting `n` to int? It's already an int. This function could simply be: int get_hunderedth (int n) { return n/100; } Although as you've pointed out it only works if the input number has 3 digits.
Sory my fault 
thank you for asking, helpd me out a bit &amp;#x200B;
One of the goals of the Standard is to allow for a variety of implementations. Rather than trying to forbid limited or unusual implementations, the Standard should instead focus on providing ways by which code which relies upon various features of commonplace implementations can ensure that any such features will be supported by any implementation *that accepts the program*. For example, while many programs certainly benefit from the existence of a 64-bit `long long` type, or a `double` type with more than nine decimal digits of precision, there are some platforms (likely including *all* non-twos'-complement platforms!) where 64-bit unsigned arithmetic or floating-point arithmetic with ten or more decimal digits of precision are so much more expensive than other kinds of arithmetic that applications for such platforms would seldom receive any useful benefit from such features even if they were supported. Consequently, I would suggest that the Standard should recognize the existence of "commonplace" and "unusual" implementations, as well as means of testing for ways in which an implementation might be unusual, thus allowing it to specify the attributes of commonplace implementations more fully than would otherwise be possible, while at the same time increasing the range of platforms for which it would define the behavior of any programs *that are accepted*. There are many actions (such as signed integer calculations whose result is outside the range of the type in question) for which some implementations fully specify a behavior, some would be hard-pressed to guarantee anything useful about it, and some would be able to offer some useful behavioral guarantees at a cost far below the cost of fully specifying the behavior. Rather than simply having the Standard regard such actions as invoking UB, it would be much more useful to provide means by which programs can indicate what behaviors are acceptable, with implementations free to either meet such programs' requirements or reject them entirely, but not being allowed to accept such programs without meeting their requirements. If a program states, e.g. that it requires precise two's-complement wrapping semantics, the choice of whether an implementation processes such a program with those semantics or rejects it entirely would be a Quality of Implementation matter, subject to an implementer's judgment, but the question of how an *accepted* program handles integer overflow would not. Applying this principle more broadly, it should be practical to eliminate the need for the "One Program Rule" by defining categories of Safely Conforming Implementations and Selectively Conforming Programs, such that any Safely Conforming Implementation must specify a set of environmental requirements and a set of means via which they can indicate a refusal to run or continue running a program, and guarantee that if they are fed a Selectively Conforming Program and all environmental requirements are met, they will process the program according to the Standard, refuse to do so via one of the implementation-defined means, or spend a not-necessarily-bounded amount of time deciding what to do. Any action other than the above by an implementation claiming to be Safely Conforming would be a violation of the Standard. The set of tasks that can be accomplished usefully on all implementations is rather limited. The set of tasks that could be *defined* on all platforms could be much larger, however, if implementations were allowed to say "Sorry--I can't do that". There is no reason to limit the range of actions that are *defined* by the Standard to those which can be usefully supported on all implementations. 
For many purposes, it would be useful to have an intrinsic that combined the notions of "assert" and "EXPECT"; I would name such a thing `__CHECKED_ASSUME(x)`. The semantics would be such that a compiler could at its leisure treat such a directive as an assertion which could force an abnormal program termination at a time of the compiler's choosing, or as a no-op, whichever would generate more efficient code. For example, if an implementation offers void upCopy(unsigned char *p, unsigned char *q, int n) { for (int i=0; i&lt;n; i++) { __CHECKED_ASSUME(p != q+i); p[i] = q[i]; } } a compiler could check whether `p` and `q` alias, trapping if so, and then consolidate loads and stores in ways which could break if they alias, or it could ignore the effects of `__CHECKED_ASSUME` and perform the loads and stores in execution order. If the assumption would be met any time the program receives valid input, and it would be acceptable to have invalid input either result in the code performing the steps as written or cause an abnormal program termination but unacceptable for it to trigger unconstrained arbitrary behaviors, such a directive would allow compilers more flexibility than they could otherwise have, without any loss of safety. 
The newly-declared object to the left-half of `=` in a declaration with initialization looks like the stuff to left half of `=` in an assignment, but `int *p = *q;` will store the value of the right-hand expression into `p`, while an expression statement `*p = *q;` will store the value of the right-hand expression into `*p`. If `q` happens to be of type `void**`, the compiler would likely not squawk at either operation even though they mean totally different things. 
I'd do the same as you suggested. if you know for certain that you will be getting only integral values, then scanf is a quick and easy way to get the values converted. but since you never know for certain, you need to build your own safeguard. &amp;#x200B; i would do this 1. read stdin into a buffer. 2. iterate through each character. find tokens first. for example, check for a "-" denoting a negative number and/or "." denoting a decimal. do some checks. make sure that if "-" is present, its at front. if "." is present, make sure there's only one. 3. these should be the only non-numerical tokens (unless u plan on reading in scientific notation). make sure all other characters are numerical. iterate through it again, convert to unsigned int. check to make sure all characters are between 48-57 inclusive. that's the ASCII conversion from char to unsigned int. 4. (optional) do a length check on the string if you want to differentiate between long int/ int or float/double. for the sake of simplicity, i'd just use the 8 byte datatypes. so long int for integrals and double for floating point. 5. use atof / atoi to convert. if you really want to be thorough, create a struct with an unnamed union inside. #define NAN 0 // flag for failing step 2 or 3. #define INT 1 #define FLOAT 2 struct value { int type; // so u know what type is in the union union { long i; double f; }; }; &amp;#x200B;
when you traverse through the graph, you need a way to cache whether or not you visited that node. you can use an associative array.
yeah C is a doozy if you come from an object-oriented language. python was my first language.
The initialization along with declaration thing is a shortcut. `int *p = *q`; is equal to `int *p; p = *q;` The original mantra was "declaration follows usage". Initialization is not usage. It is an entirely different thing. Usage is using the variable in expressions. 
The most straightforward solution is to waste space by creating a union that can hold the most data you'll encounter. A less-straightforward solution is to waste less space by creating a union that holds your worst-case integer types and then malloc space for strings. But if you're mallocing and freeing many of these relatively small structures, you'll fragment memory. A library solution would be to use something like Protocol Buffers ([nanopb](https://github.com/nanopb/nanopb) is a fairly compact implementation for C) to handle deserialization and storage for you. Depending upon your data, this might actually be heavier-weight than even the worst-case union from the straightforward solution; however, it might let you deal with your variant types with more straightforward code. Is it possible for you to normalize the data more somehow so that you don't need to hold a bunch of different record types in the same data structure? Or can you split the data into different data structures that are specialized for each type of record? Trying to cram a bunch of different record types into one data structure sounds painful.
I could use the less-straightforward solution, but it I might have to allocate memory hundreds of thousands of times for certain files. I could also split the data into specialized records, but I don't really know a way of creating those records. There's probably about 100 different kinds of records, so I don't really want to hard code in a record for each of those types. All of the different records are created by COBOL programs, so I have the definitions of each record already defined in a file that I can parse, I just don't exactly have a good way of converting those definitions into structures or some other data structure.
If objects will need to be manipulated "in place" without resizing, a good approach may be to define a "descriptor" struct for purposes of accessing a "thing", which would contain pointers to all of the interesting parts along with information about the sizes thereof, along with a function which, given a pointer to a sequence of bytes or words holding the object and a pointer to a "descriptor" struct, will store the addressees of all the parts of the variable-sized object into the descriptor. This may make it possible to use memory quite efficiently, since bulky descriptors will only need to be kept around while they are actively being used. The biggest downside to this approach is that things which contain data stored using 16-bit or larger types may need to ensure that such data are stored in suitably-aligned fashion, which may require adding padding that would otherwise not be necessary and thus reduce storage efficiency. 
Wow. 100 different types of records? Are these truly unique record types? Or are they really one big record type, but each of the entries might be missing one or more fields? Once you have the records in memory, what do you plan to do with them? Are you just transposing them somehow and writing them back to disk, or do you need to keep them in memory and access them according to some sort of application logic?
You're right that `scanf()` is incompatible with robust parsing, especially for untrusted or dangerous input. u/kl31's method of walking through the string character by character is essentially how any parser works. For more complex languages, there are techniques for organizing this process — using lexer, etc. — so that you don't need to think about it on a byte-by-byte basis. If it's truly simple numeric data you're parsing, you could read an entire line of input and use functions like `strtol()` or `strtod()` to help. These functions check for overflows and other errors, and, very importantly, they tell you where parsing stopped so that you can pick up afterward with more parsing. Set `errno` to zero before calling them so that you can distinguish between zero and errors. FILE *f = ...; char line[N]; char *p = line; long coord[3]; // parsed input /* Parse three integers starting at p */ while (fgets(line, sizeof(line), f)) { errno = 0; for (int i = 0; i &lt; 3; i++) { coord[i] = strtol(p, &amp;p, 10); if (coord[i] == 0 &amp;&amp; errno) die("error: %s", strerror(errno)); } } /* Check for trailing garbage after p next */ 
The records are stored in their own files, but my code needs to be flexible enough to work on all the files. Once I get all the data for a file in memory, I'm sorting/processing the data and printing it all out as a .csv.
Unfortunately, in cases where different implementations process some constructs in different ways, with there exist programs that rely upon the different behaviors, the authors of the Standard generally refuse to recognize such divergence beyond saying that implementations can do whatever they want, even though those cases are the ones where the Standard could be most useful. The Standard could be much more useful if, instead of ignoring such issues, it defined macros or other means by which implementations could indicate which common behaviors they do or don't support. Such macros need not be seen as implying any judgment as to what kinds of implementations should support what features, but would greatly expand the range of features whose behavior would be defined on all implementations whose predefined macros indicate support. 
Since I'll only be using 1 type of record at a time, I think this might work pretty well. I could create one descriptor struct at the beginning using the record definition and use it to create the custom records.
A related problem is the fact that if you run with stdout closed, and then open() or fopen() anything, it will probably get assigned file descriptor 1 (STDOUT_FILENO) and then printf() and friends will unintentionally start writing to that file too. The gnulib *-safer modules work around this issue.
Interesting. Assuming that the data is somehow related enough that you can sort/process it, can you normalize it into a single structure as you read it in? This doesn't necessarily help with memory usage, but I'm more worried about your code complexity in dealing with a variant type that has 100 variations. Alternatively, and I hate recommending this in a C group, but you might consider a dynamic language like Python. You could load your records into key/value dicts and then you can easily query existence of fields/keys when processing them. If you want to stay in C, you can do similar things with Protocol Buffers, which allows you to declare data types with optional fields and then query their existence. Or, if defining your types in Protocol Buffers is too onerous, you could do the parsing yourself and use a hash table to do key/value storage of the data. This still is a more memory-heavy solution, but frankly I'd throw RAM at this problem. My instinct is that if you try to build a memory-optimized, union-based solution to the problem, you're going to wind up with a ball of spaghetti code to deal with the problem of a very complex variant.
I would be thinking hard to try and avoid the problem, look for different ways to break the data up in a different way try and get some more consistent structure. Can you process the data at an earlier stage ? Would it be possible to use a callback and take the function to the data rather than the other way around ? &amp;#x200B;
return n / 100 % 10;
You have to implement the protocol yourself or use a library that does it for you.
There is imgui, in C++, I don't know if this would be a problem for you https://github.com/ocornut/imgui
inet\_pton() takes a dotted ip-address string, eg "[123.45.67.78](https://123.45.67.78)" and converts this to a structure (sockaddr\_in or variants, depending on the family) that's then usable for socket level calls. socket calls all work on ip-addresses - and once you've made a TCP connection, the application protocol (as an example, HTTP or FTP) sits on top via the sending/receiving of appropriate messages according to whatever application protocol you're talking [example.com](https://example.com) is a domain name. to do anything with this via socket calls you would first need to resolve it to an ip-address. there are calls to do this, they may look first at manual mappings set up on a host (eg. /etc/hosts in UNIX machines) and then fallback to doing DNS lookups to a nameserver to resolve. [user@example.com](mailto:user@example.com) and references to passwords is really nothing to do with TCP. This is clearly some application level protocol address. For example, an email client might take that address, strip off the "user" which it would take to be a recipient's username, remove the "@", resolve [example.com](https://example.com) to an ip-address, connect to that ip-address and then send appropriate messages, with "user" embedded *somewhere* to send an email. It might be a TCP connection on which messages are going back and forth, but any passwords and authentication is all sitting on top of TCP. You probably best off looking for some client library that you can use for connecting to whatever it is you want to connect to, rather than trying to code it from the lowest level.
100% would use Python for a job like this. It chews millions of records with ease, and you get all the nice Pythonic abstractions and standard library.
Okay, i'm fine with using a library I just cant find one and i've been searching for a solution. My problem is i've tried googling different search phrases but i'm not getting anything good .. thats also why i'm asking here to get some directions. I have the server's IPV4 address, but is there a way to convert the "user@123.45.67.89" to a dotted address that inet_pton() can work with? Maybe this is not the solution I want anyways.. I want to communicate with my server programs from any network... 
A TCP connection is fairly low-level. It establishes a "pipe" from one computer to another, but it doesn't prescribe much about what you send over that pipe. Any sort of user authentication would be built on top of TCP and involve sending several messages back &amp; forth between the authenticating server and the client. The format of those messages varies based upon the higher-level protocol spoken by the server. `inet_pton()` only converts a text representation of an ip4 or ip6 address into binary form for use in other socket API calls. To get the IP address for a hostname, you need to use a function such as [`gethostbyname()`](https://linux.die.net/man/3/gethostbyname) that does a DNS lookup to resolve the hostname to an IP address. To get further, you're going to need to understand the exact protocol that you're trying to communicate with over TCP. Then you'll need to either find a library that already implements that protocol or dive into the specification and implement it yourself. To see what you're getting into, you might check out some projects on Github that implement common protocols like HTTP, Telnet, FTP, etc. Here's a simple, relatively self-contained FTP example that I found with a quick search: https://github.com/sunaku/simple-ftp/blob/master/client.c. It illustrates some of how you'd need to use the low-level networking API to implement a higher-level protocol.
You might be interested in letting a machine do the super tedious work. Converting all of those records by hand seems like a waste of anyone's time. You could use GNUCOBOL on some GNU machine to perform the intermediate translation and rip out the C structures it generates from your DATA-SECTION. At the very least, you'd have the C representation of what those variable-length records look like.
well, if you have a string such as ["user@123.45.67.89](mailto:"user@123.45.67.89)", the dotted ip-address is there [123.45.67.89](https://123.45.67.89), you just need to strip off the user@ portion. on a modern Linux, converting [example.com](https://example.com) to something that can be used in socket calls probably best done via getaddrinfo(), this will return items, including a sockaddr, negating the need for any calls to things like inet\_pton &amp;#x200B;
Instead of having norm be it's own function, make it a macro, so you'd want closer to: #define WIDTH 2048 #define HEIGHT 2048 #define MAX_ITERATIONS 1000 #include &lt;stdio.h&gt; #include &lt;stdint.h&gt; #define NORM(x, total, min, max) (((max - min) * x) / total - max)) __UINT8_TYPE__ calculatePixelColor(int i, int j) { float xi = NORM(i, WIDTH, -1.0, 2.0); float yi = NORM(j, HEIGHT, -1.0, 1.0); float x = 0.0, y = 0.0; for (int i = 0; (x * x + y * y) &lt; 4 &amp;&amp; i &lt; MAX_ITERATIONS; i++) { float px = x; x = x * x - y * y + xi; y = 2 * px * y + yi; } return (uint8_t)(x); } int main() { uint8_t colorArray[WIDTH * HEIGHT]; for (int y = 0; y &lt; HEIGHT; y++) { for (int x = 0; x &lt; WIDTH; x++) { colorArray[x + y * HEIGHT] = calculatePixelColor(x, y); } } } Also, if you're going to use \_\_UINT8\_TYPE\_\_ you should be consistent with it, also it is non-standard so... The main speed boost here is that you're no longer computing xi and yi every function call, they're just constants that just happen to be there. Here's the godbolt: https://godbolt.org/z/voNw6q (Sorry for the awful formatting of the two), but essentially making that one single command a macro allowed for inlining 4 constants and my parenthesis changes allowed for better optimizations. You should also be compiling with -O2 or -O3 for faster performance on GCC on any level, although in your case since you're not outputting anything in main... it optimizes the entire function away and you get nothing! I mean, that's technically the fastest performance...
Not a c pro or whatsoever but still I'll try 1. not to do with C. IMHO, since you are actually reusing prevX, I think it could have been better if you declared outside (above) the for loop and reassigned instead in cycle, instead redeclaring. 2. Did you tried optimized build. 3. I think cast float in integer upon the return calculateColo could be a culprit there. 
With optimization, I'd expect the norm function to be inlined...
Im starting to understand that now, I have decided to use a different server now that I will use for this project, one that i have admin control of. Also what TCP port should I use if i'm just sending very small data to my server program? ...which literally may be a single digits or some kind of signals.
What optimization option are you using? I'm going to bet that you're not optimizing at all (the default). Node.js probably optimizes by default (that's half the point). Try passing `-O2` to the compiler.
Are you writing the server yourself? If you're building the server and choosing the protocol yourself, I'd recommend using an existing protocol standard--in most cases, this standard will specify the port. If you're sending small messages, you might check out something like [ZeroMQ](http://zeromq.org). It has [C bindings](http://zeromq.org/bindings:c).
as soon as i turned on the O2 flag i have the same performance as the nodejs code. I didn't know about O2 or O3. Thanks!
I didn't know about optimized builds. Thanks!
I actually did implement this program in Python, before realizing it needed to run on a server to get the correct data. The server runs an old version of Unix and doesn't have an available version of Python (even if it did, I don't have the ability to install it). I have been rewriting the program in C so that it is compatible with the server.
You were right thanks! I have been focused on learning C, such that I haven't learned much about how to use the compiler. Thanks.
The node.js version uses double-precision math, while the C version uses `float`. While `float` might generally be faster, rounding issues may affect the number of loop iterations required, especially if it causes more points to yield cycles (and thus run to the maximum number of iterations) than would do so using `double`-precision. 
Eh, doesn't even matter if it's with optimization as the whole program optimizes away to a xor eax, eax ret As the main function doesn't use the calculations for anything
Well, you should be getting much better GCC performance with O2 with the code you've shown here than the nodejs code because GCC optimizes everything you've done into an empty main statement equivalent to: ```int main() { return 0; }```, so...
&gt; __UINT8_TYPE__ Please don't use this macro, it's an internal implementation detail of your standard C library. Instead, use `unsigned char` or `uint8_t`.
For the most part, `strtoul`, `strtol`, `strtod`, `strtoull`, and `strtoll` from `&lt;stdlib.h&gt;` are the easiest ways to convert a string into a number, and they give you enough information to determine whether the number is too big to represent but otherwise valid-ish, there was no number there at all, or there was only a number there. E.g.: unsigned long value; errno = 0; value = strtoul(input, `scanf` is virtually useless for real-world stuff, although `sscanf` is sometimes handy. `atoi` et al. don’t do error detection at all, so they should pretty much never be used. 
Thanks, I won't! 
I don't think I have the ability to manipulate the data in any way before I get it. To get the data in a readable form, I only have the option of a plain text file. My program is basically converting all of the data to a readable form (some of it has weird formatting, such as packed fields), process and sort that data, then write it out as a .csv for the user to access with Excel. 
Indeed, you can see this happen in that godbolt link. Even more, the only reason there's any difference between the two at all (after optimization) are because the macro version forces the math to be done with `double` instead of `float` (because that's the type of the constants at the site of macro expansion). Fixing that [results in the exact same assembly](https://godbolt.org/z/LjeSVT).
If `x` is a negative value, computation of `(-x)/10` and `(-x)%10` may fail if `x` was equal to `-INT_MAX-1`. On the other hand, computation of `(-10-x)/10+1` and `(-10-x)%10` will succeed for any negative `x`, and yield the same values as the forms using `-x`. There's no need for the code to know or care about the values of `INT_MAX` or `INT_MIN`.
Yeah I noticed that. I added a print statement and redirected the output to a file, and got the same performance as nodejs. 
A general solution is to offload the strings to somewhere else and store a pointer in your struct. The strings can be dynamically allocated, no wasted space. If this is being stored in a file you commonly do the same thing, fixed size records pointing to the byte location of strings in a string table. So your first record would be two pointers and three ints, your second would be a pointer and two ints. Also keep in mind that if you have an array of unions of structs that you need to add an identifier to the start of each struct telling you which type it is, so that you can cast to the appropriate struct when reading the records. Finally, trading off wasted memory for development speed or clarity is common, particularly on a PC. If you have a thousand records and you waste fifty bytes on each that's 5% of a megabyte or six millionths of the ram on a standard windows PC, don't stress too much.
Though I guess you use unsigned ints for image-friendliness I'd never use integers for heavy computations in C. Try with floats?
Also try adding `-march=native` into the mix.
I don't think the files are easy to access. From what I've seen of the directory, all of the data files have no extensions and are mixed in with other files that have no extensions. The only way I know to access the files is for the user to specifically ask for a file by name. If I can somehow find a list of filenames, I might be able to do this, though.
For the most part, `strtoul`, `strtol`, `strtoull` (C99), `strtoll` (C99), `strtof` (C99), `strtod` (C89), and `strtold` (C99) from `&lt;stdlib.h&gt;` are the best ways to convert a string into a number. They give you enough information to determine whether the number is too big to represent but otherwise valid-ish, there was no number there at all, or there was only a number there. The integer variants also allow you to pick a base or handle C-like `0x` and `0` base prefixes. E.g.: unsigned long value; char *next; if(!*input) {no data whatsoever} errno = 0; value = strtoul(input, &amp;next, 0); if(errno == ERANGE) {too large} assert(!errno); if(next &lt;= input) {no valid number at all} if(*next) {something after the number} C99 or POSIX.1-2001 `&lt;inttypes.h&gt;` also gives you `strtoimax` and `strtoumax` that can be used to extract an `intmax_t` and `uintmax_t`, respectively. GNU libquadmath (packaged with most GCCs) gives you `strtoflt128` to extract a `__float128` (a.k.a. `_Float128`, mostly a.k.a. `float __attribute__((__mode__(__TF__)))`). `scanf` is virtually useless for real-world stuff, although `sscanf` is sometimes handy. `atoi` et al. don’t do error detection at all, so they should pretty much never be used. Alternatively, it’s not hard to code your own number conversion routine that handles your own special cases, or works things down to where the `strto`- conversion routines can be used.
I'm on my phone; unfortunately godbolt doesn't play well with mobile.
Understatement of the year.
I'm away from my computer! What would that do? 
You could mmap the whole file so you arent allocating unused space. AFAIK mmap is pretty efficient with the memory it used for the mapping, doesnt map pages until needed etc
I actually implemented the program in Python before realizing I needed to put the program on a server that runs an old version of Unix. In my Python version, the files are given to the program by the user and the names of those files are used to find a corresponding record definition file in another directory. While many of the fields are shared between the files, I can't think of a way to normalize the data because of the large variance between the different kinds of records. Some files have similar structure, while others may have absolutely no fields in common. 
Yeah, it's that disparity of the data types that makes me wonder what you're going to do with it. If the data can't be normalized, can you really "sort" it? How will you compare the records against one another to do so? Or are you going to wind up with different logic for the different record types? And, if so, do you really need to ingest them all into the same data structure then? Sorry to keep following up with a barrage of questions. I think you've gotten a few generic suggestions in this thread that might be helpful, but it's hard to take it further without understanding more of the data itself or how you plan to use it.
afaik it would try to use some special instructions that your computer are capable of. For instance many processors today can perform operation on a vector. It can be used to perform loop unrolling where instead of looping a++ at a time it will instead do a+=2 (depending on your processor). It can do this because modern processors have more than 1 function units (parts of the cpu that performs addition, multiplication and stuff)
For optimization purposes, GCC and Clang have their own "builtin" version of `strcmp()` that is independent of the standard library. In some circumstances it will generate code optimized for specific circumstances rather than call into the standard library. My guess is that it in some situations uses "STRCMP" to avoid interfering with the builtin named "strcmp". The last line is for similar purposes, [changing how a symbol is named](https://stackoverflow.com/a/21422495). Here's another question: What's with the pointless, doubly-redundant `unsigned char` casts inside the loop? It doesn't accomplish anything. Perhaps it's vestigial? 
I made a few code optimizations. I moved `float px = x;` so it would be declared outside of the loop and assigned in the loop (which you could do in your js version as well... avoid variable declaration in loops when unnecessary). I added `static inline` to the start of each function. Those two changes resulted in milliseconds of improvement.... so then compiled with following flags: `gcc -g -Wall -Wextra -pedantic -std=c11 -ffast-math -O2 "filename.c" -o "filename.out"` The speed up was so dramatic I didn't believe it (exponential). I thought -O2 was changing the behaviour so I wrote the output to a file and compared it. I suggest you do the same. You might have to tweak the code so the output's format is the same. 
Don't post images. Type the code in with 4 leading spaces per line or long to the code externally.
Yeah O2 optimizes it away to a noop if you don't do something like print. Is there a good resource for learning about good common flags to use with the gcc? I don't know any of those. 
Just began writing functions and I don't know what to put in this particular one
What about for more than 3?
http://idownvotedbecau.se/imagesofcode
&gt; I made a few code optimizations. I moved `float px = x;` so it would be declared outside of the loop and assigned in the loop (which you could do in your js version as well... avoid variable declaration in loops when unnecessary). Optimizing compilers don't care about where you declare a variable. The standard advice is the opposite: always declare your variables in the tightest scope possible, to improve code readability and make functions easier for a human to analyze. Unless you're specifically compiling without optimization ... but then you probably don't care about speed anyway. &gt; I added `static inline` to the start of each function. The `static` won't do anything for performance, that only affects linkage. `inline` is mostly about linkage as well, but can also be a hint that it should be inlined (though the compiler's going to inline this function regardless). Any milliseconds of improvement are in the noise. &gt; I thought -O2 was changing the behaviour Unlikely. In this case, the compiler was so successful at optimizing that it realized `colorArray` was never used and `calculatePixelColor` has no side effects, so absolutely everything was removed. Oops ...
Here you go: [https://www.reddit.com/r/C\_Programming/comments/aazgpv/what\_is\_a\_great\_wellwritten\_tutorial\_on\_the\_gcc/](https://www.reddit.com/r/C_Programming/comments/aazgpv/what_is_a_great_wellwritten_tutorial_on_the_gcc/)
Have you considered any of the alternatives, eg the `py_compile` module, which generative native binaries from python scripts? http://effbot.org/zone/python-compile.htm
okay, so it's a long time since i really looked at glibc source, but... here's my semi-guess... &amp;#x200B; It's defining a reference strcmp, but likely not what you'd actually be using. as there will be processor optimised versions of these calls elsewhere in the source, in assembler, if its general usage is frequent enough to be worth it. &amp;#x200B; for the STRCMP macro - and this is a bigger guess... if STRCMP is not defined when parsing this file, then it goes and defines STRCMP as strcmp - and the pre-processor also then causes the function further down to be defined as strcmp (since we just #define'd STRCMP to be strcmp) however, if when parsing this file we've already defined strcmp, then we can arrange for STRCMP to be defined as something else (eg. "strcmp\_foo" and the reference implementation then gets defined as strcmp\_foo, so as not to clash with our already defined strcmp) &amp;#x200B; the macro at the bottom I think, depending on how glibc is compiled (statically vs shared libraries), either does nothing or else expands to a directive that creates an alias for the function, which some prefix such as \_\_GC\_ for other glibc code to call so they can *always* call the glibc version - since with shared libraries you load your own implementation with something such as LD\_PRELOAD. So this way you can override strcmp for *other* code, but not anything within glibc internally. &amp;#x200B;
For those who want the actual code, it's from [here](https://sourceware.org/git/?p=glibc.git;a=blob;f=string/strcmp.c;h=3485aa64c10072ed7ad52340c6690d0ca7602506;hb=HEAD). 1 /* Copyright (C) 1991-2019 Free Software Foundation, Inc. 2 This file is part of the GNU C Library. 3 ...... 16 */ 17 18 #include &lt;string.h&gt; 19 20 #undef strcmp 21 22 #ifndef STRCMP 23 # define STRCMP strcmp 24 #endif 25 26 /* Compare S1 and S2, returning less than, equal to or 27 greater than zero if S1 is lexicographically less than, 28 equal to or greater than S2. */ 29 int 30 STRCMP (const char *p1, const char *p2) 31 { 32 const unsigned char *s1 = (const unsigned char *) p1; 33 const unsigned char *s2 = (const unsigned char *) p2; 34 unsigned char c1, c2; 35 36 do 37 { 38 c1 = (unsigned char) *s1++; 39 c2 = (unsigned char) *s2++; 40 if (c1 == '\0') 41 return c1 - c2; 42 } 43 while (c1 == c2); 44 45 return c1 - c2; 46 } 47 libc_hidden_builtin_def (strcmp)
Sets available instructions to what's supported by your processor and uses an appropriate instruction timing table for scheduling and ordering them. Biggest gains come from autovectorization, but making everything tuned for a particular processor speeds up everything.
If you cannot detect the parameter thing directly beforehand, then the staightforward solutions seem to be either cache your changes in a separate container and only copy them if needed (simply discard/free if not), or apply changes as you go but execute an undo routine of some sort if your early termination condition is met. Is there a reason you have avoided these? If you have an idea of the likelihood of meeting/not meeting your early termination condition, you could select the one with a greater chance of performing less "extra" work. Knowing more about the specific situation might help with a more targeted solution, if that would in fact be smarter and/or more elegant.
I don't think it's the builtin `strcmp` that is the issue - all the gcc builtins are prefixed with `__builtin_` to avoid name clashing. I presume what's going on here is that every architecture can optionally provide it's own copy of `string.h`, some of which define `strcmp` to some other optimized version. If they do that, then they also define `STRCMP` to some other name so this version doesn't clash with the optimized version. However, this one is still mapped to a separate internal symbol so it can be called directly. Note that I tried to find some evidence of that searching through the code but couldn't really find anything and don't understand the build process enough to really know what's going on (I've only ever worked with `newlib` - which does allow similar things to what I'm describing). There's some pretty ugly stuff like [this](https://github.com/lattera/glibc/blob/895ef79e04a953cac1493863bcae29ad85657ee1/sysdeps/powerpc/powerpc64/multiarch/strcmp-ppc64.S#L20), but that overrides the declaration of the one in `strcmp.S` for that arch, not the generic one that was linked here. That said, on a somewhat unrelated but also interesting detail, in some circumstances `gcc` will actually output calls to `libc` functions even when you didn't call them directly - the most common being ones like `memcpy` and `memset`. I think you might have been thinking of this when you were typing your comment. It causes a real headache for first-time OS devs because you'll go to write a simple `memset` implementation and it won't work - `gcc` tries to be 'helpful' and will optimize their implementation` into a call to `memset` itself, creating a loop (And doesn't give a warning about the loop it created, since that would be too nice...). There's an `-fno-builtin` flag that stops `gcc` from emiting calls to `libc` functions unless you call them directly, which stops the problem. I think there's also a weird attribute you can attach to the `memset` implementation to prevent the optimization just to that function.
An impressively vague post! If you have a question you would genuinely like answered, it might help if you spent a minute or two elaborating on what you're actually asking, since you're asking people to give up some of their own time to reply ....
Have you ever looked in the headers where you're pulling in the `strcmp` symbol? Most of these `#define` strcmp to something else (`__strcmp`, `__builtin_strcmp`, etc). Which is all fine and dandy, except the preprocessor would replace the definition of the function as well when it replaces the `strcmp` token. Now, why it defines the macro `STRCMP` when it's already `#undef`'d the `strcmp` macro, I can't really say. Perhaps to make searching the code easier?
Sorry man, you do not doing well even with a lib because you don't know about networks. You first need to know how networks works, then how your implementation will work, and only then how to program the solution. I recommend to read Beejs guide, you get knoledge of networks and how to program them... [https://beej.us/guide/bgnet/](https://beej.us/guide/bgnet/)
My best guess for the casts inside the loop is that once upon a time it was looping over `p1` and `p2`, and these never got removed when changed to `s1` and `s2` - or, as you say, vestigial. It's also possible there's some weirdness with integer promotion rules going on that the cast is avoiding, but I'm not up on that area of the standard well enough to know for sure one way or the other.
Without the cast the function would be wrong for non ascii chars, since they would be negative. This way they make sure to subtract two guaranteed positive numbers from each other, and due to integer promotion, get the right result.
Not OP, but I'll try to answer: It's pretty terrible because the MS compiler doesn't _really_ do C IIRC, it only does C++ or something along those lines. Honestly, VS is a pretty mediocre application, so you might want to find something else altogether. I recommend a text editor, compiler, and debugger, all as separate applications. That way, when one doesn't work, you can Google and figure out why your one tool doesn't work. Hope you figured it out, and that's why you didn't elaborate on your issue.
It does C but you have to change the file extension to .c. That said, visual studio has partial implementation of C99. 
a for loop is like the most basic way. Just keep a temporary value of the changes and only write the changes once the loop is completed, with a check. For c++ there is the std::none\_of or all\_of templates, which makes this a simple if. 
In a Project you click: Project &gt; xy Properties &gt; C/C++ &gt; Advanced &gt; Compile As &gt; Compile as C Code (/TC)
Set a flag when the condition happens and only perform changes when the flag is clear.
That is not a good solution. Instead, change the file extension to `.c`.
There is no "undo" option in C and therefore you need to buffer the changes and only apply them when the condition is met, otherwise discard them.
Other things to remember in the fgets approach are that last line might not have \\n, and that any line can be reeally long.
That's true that the function is careful about negative `char` values, which is why it immediately casts the inputs to `unsigned char` pointers. In the loop, the value being read (`*s1`) is `unsigned char` and it's being assigned to an `unsigned char` variable (`c1`), so the cast does nothing.
Can you tell us a bit more about what these records look like? Does each field have a fixed type in practice or is the actual data such that the same field can have different types in different records?
You might also want to consider an approach where your parser, instead of saving the records it reads into a structure, calls a user-definable callback for each field it sees. The callback invoked depends on the field type, so you can react to each field in a flexible manner. For your problem, it seems that turning everything into strings might be the easiest way to go.
U can download MinGW as a compiler and use it through the command line or VS code. Or simply download something like Dev C++, if you change the settings to use a c compiler you will be able to code in C
What were the exact problems you came upon? We can not really help you if we do not know what you may have done wrong. Those big IDEs seem a bit overwhelming for a beginner. They have a lot of very useful features though. You will probably learn about them in the feature. &amp;#x200B; &gt; I have also tried to use CMD terminal to compile programms with gcc, but i didn't get that aswell. Well, how did you do this? How did you install gcc? MinGW? Give us some context please :) &amp;#x200B;
Trying installing MinGW , Then Add the installed compiler to your windows PATH . If you have installed correctly and added to your PATH then you can compile your C codes just like in ubuntu using gcc or g++ from cmd prompt 
Yes, i have installed MinGW (also added it the systemvariable PATH) and I basically used it as I did under ubuntu gcc -std=c11 -Wall &lt;all\_files&gt;.c -o &lt;output\_file&gt;; ./&lt;output\_file&gt; And for the IDEs I didn't get the file correctly imported as a project (i think) and compiling never worked.
that's what I have tried, but it only created serveral file (.o .exe) and didn't give me any outputs
You could try Dev-C++ ([https://de.wikipedia.org/wiki/Orwell\_Dev-C%2B%2B](https://de.wikipedia.org/wiki/Orwell_Dev-C%2B%2B)) for a beginning. I guess you are not using MinGW correct. Dev-C++ is quite easy to use.
Ok, I'll give it a try. ty :)
does $ g++ --version works??
\[yes\]([https://imgur.com/a/LNo8lid](https://imgur.com/a/LNo8lid))
Code::Blocks is another IDE that comes with MinGW and is also configured for mingw-gcc out of the box. Or you can try Cygwin which is a small "unix like" environment that runs on windows. It's not a VM but coding in Cygwin feels like linux, the tools are the same and you can use external editors however you like and just use Cygwin to compile.
What is the name of your executable file? .exe? 
I would recommend installing MSYS2 and then install mingw-w64 by its package manager (pacman). Do not install old mingw, it had lots of bugs. Also the IDEs "dev-c++" and CodeBlocks are crap. 
when I had tried it. I got an .exe and .o neither of them didnt anything when I tried to open them (i used source I knew would work)
$ g++ your_source.cpp -o any_name $ any_name.exe
I stand by this, MSYS2 feels like a no-brainer, not to mention you can install alternative compilers other than gcc with one single command.
that worked! nice. ty!
I second that, if you need a simple IDE then Code Blocks is a good choice. I installed it recently for my daughter, the package with mingw worked like charm.
It really is tricky. What I did was to download the CodeBlocks IDE package including mingw32. That allows you to use both the IDE and the command line. But still you'll face several PITA problems if you come from Linux. Perhaps even more if you use command line only, because Windows is a totally different beast on that matter, and quite inferior. For example, I tried a simple "make" only to discover that there wasn't a make.exe but a mingw32-make.exe, at least in the PATH. I then installed the separate mingw32 make, which seems almost discontinued. I barely use command line so take this with a grain of salt.
+1 
gcc under WSL is the way to go, if you ask me.
For C development, I agree with you completely that those IDEs are too bulky. In my eyes, all you need is a compiler, an editor, and a debugger. /u/OldWolf2's suggestion is what I use and I'd recommend for anyone.
You can download visual studio community for free. Install VC. Have your command prompt of choice (shout outs to cmder) call the vcvarsall.bat file in the visual studio directory. After that you can run cl (microsofts c compiler) from the command line and use what ever your favorite text editor is. Also Visual Studio is pretty annoying for writing code but its debugger is super good. 
I the optimized build I compiled had a loop that printed the whole array so the array wasn't removed. The the use of float rather than double does change the output though. Upon running `diff`, it becomes clear the numerical sequences diverge. &amp;#x200B; If OP were to generate the arrays, serialize the output and ensure his use of data types are producing the same calculations, the optimized C program will be faster than the js program. I think the primary issue is he wrote two programs that are producing different results.
I just wanted to comment and say that MSVC has a *mostly* conforming C99 mode, which can be set-up with the comments. However there are some important differences, notably: * The [preprocessor has some quirks](https://blogs.msdn.microsoft.com/vcblog/2018/07/06/msvc-preprocessor-progress-towards-conformance/). Most notably is passing __VA_ARGS__ to another macro will not expand them. To be fair to Microsoft, the standard is really not clear about this, they were just the only compiler to interpret it this way. * ```restrict``` -&gt; ```__restrict```. MSVC’s ```__restrict``` is different but is less restrictive so there shouldn’t be any issues here other than the renaming. [CMake](https://cmake.org/cmake/help/latest/module/WriteCompilerDetectionHeader.html) can detect this for you if you’re using it. * tgmath.h, VLAs, _Complex are missing but VLA and _Complex are optional in C11 so you may not want to use them anyways. And tgmath.h can just be translated to math.h. 
I recommend using gcc in WSL and as IDE CLion, **if** you want to target Linux. This approach works for me pretty good. An issue may be that CLion is only free for students. To target Windows, Visual Studio is the defacto standard, but the IDE may need some learning time. MinGW can also be used with CLion.
&gt; I would suggest that the Standard should recognize the existence of "commonplace" and "unusual" implementations This is more about not recognizing the existence of fictional implementations.
Briefer version of key thoughts: The vast majority of implementations use non-padded 8/16/32/64-bit integer types, in either consistently-big-endian or consistently-little-endian order. The Standard should not require that all implementations use such types, but should recognize that those which don't are "unusual", and provide means via which programs for usual platforms can refuse processing on unusual ones that don't meet their requirements. Another point I would like to see added would be a rule specifying that, except on "unusual" implementations, signed integer operations behave as described starting on line 20 of page 44 of the C Rationale at http://www.open-std.org/jtc1/sc22/wg14/www/C99RationaleV5.10.pdf in some cases where that is not presently required. In particular, coercing the result of an integer `+`, `-`, `*`, `&lt;&lt;`, `&amp;`, `|`, `^`, or `~` operation to an unsigned type of the same overall width or smaller, or casting it to such a signed type, should yield the same behavior as though the operands were likewise coerced or cast, and the operation performed using unsigned arithmetic. Given that the authors of the C Standard describe this behavior in the Rationale and noted that commonplace implementations worked that way, it would seem likely that they intended that commonplace implementations should continue doing so, but thought that would happen even without a specific rule. Since then, however, it has become apparent that the only way to ensure that implementations claiming to be "usual" support that behavior would be to require that implementations doing otherwise report themselves as "unusual". Although such a rule would appear to require type information to flow outside-in through expressions, the only implementations that would have to *care* about how the result of an integer expression is used are those which would use the distinction between signed and unsigned arithmetic in ways that would require outside-in analysis *anyway*. 
Implementations where `char` isn't 8 bits exist. I've even written a TCP stack on one of them. I don't have any experience with padding bits, but from my understanding they are sometimes used on platforms that lack any notion of a "carry" flag or other such feature to facilitate multi-word arithmetic. As a C programmer, it's useful to be able to program a machine using a dialect which is in significant *but predictable* ways different from commonplace C, but shares a common set of core functionality. I would not expect that programmers *who aren't specifically targeting such a machine* expend any particular effort to make their code compatible with it, but it's useful to know how something describing itself as a C implementation for such a platform should be expected to behave. 
I think the Visual Studio debugger is the main reason I still write C on Windows. You don't even need to write code in VS to use the debugger (I usually use vim).
&gt;Implementations where char isn't 8 bits exist true, but this is about 2's complement. Quoting [n2239](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2239.pdf) &gt;Straw poll: Is WG14 comfortable in removing ones complement and sign and magnitude from the C standard. 14 approved, 0 reject, 3 abstain I suppose it's not too late to change their mind, if you know something they don't.
You have to use visual studios. Windows is a fairly closed platform and they don't really want people tinkering with shit so they sandbox developer stuff away through visual studio. While it is possible to use something like mingw you'll find that it is even more annoying to use compared to just using visual studios. While the msvc is absolute dog ass with C compiling, visual studio itself is actually one of the best IDE's I've ever used. While it may seem bloated at first (and some features are but you can disable or delete them) I've noticed that I now use almost all the features. The debugger alone is loads better than any debugger I've ever seen. The windows pragma commands are also very useful and to have immediate access to win32 and directx is pretty rad in my opinion. Also the git and github tools are fucking beautiful. If you have to develop with windows, take some time to get comfy with visual studios. It's a damn good IDE (the only one in fact) and will make your life easier. 
Try Clang (wonderful diagnostic messages on errors) or MinGW. You can use a plain text editor (with syntax highlighting) if you don't find an IDE you like, and compile from the command line.
The proposal retains provisions for padding bits, and wouldn't recognize code as "portable" unless it could handle some hypothetical machine with 42-bit types that use 19 padding bits. If one is going to recognize that the usefulness of recognizing code that is "portable to common machines" without requiring that such code bend over backward to support unusual/fictional architectures, doing it piecemeal would take forever. Instead, one should try to identify *many* traits that common machines have, and not imply that every implementation should every such trait, but instead provide a means by which programs written to exploit such traits can ensure they aren't accidentally run on platforms that don't provide them, and allow the marketplace to determine which traits would be worthwhile for various kinds of implementations to support. Although it may not be possible to have machines automatically answer *all* possible questions of the form "Is program X compatible with implementation Y", it should be possible to write programs in a way that would allow most such questions to be answered by machines examining code rather than by humans examining documentation. 
I use emacs + a little elisp function that calls a platform appropriate build script. On windows this takes the form of a `build.bat` file that calls the Visual Studio compiler
Same. 
Strongly disagree with this. Either do full on MSVC or full on WSL. Hybrid platforms like msys2 are riddled with weird compromises between the two environments that don't make sense unless you can understand the context of what's going on. msys2 is for Linux developers who need to do something on Windows. It's not a first choice environment. 
&gt; (I usually use vim). I don't get this. VS is a pretty good editor, and _just works_. 
Not saying its a terrible editor. I just use vim more often as an editor because its what I'm used. I do use VS now and again. Really like its intellisense.
Did you try googling "C sockets tutorial" and reading LITERALLY any tutorial explaining it?
I sure have. I haven't really found any straightforward answer on whether or not the functions conflict if ran at the same time. If you were able to find anything, I would love to take a look at it.
Just to be sure `listen` only needs to be called once, you are using `recv` on the socket returned by the call to `accept` right? and not the socket you run bind on
It appears that I had been calling recv() with the wrong sockets. I had thought that that if I called recv on my main socket that it would be able to receive data from all the clients connected to it. 
It appears that I had been calling recv() with the wrong sockets. I had thought that that if I called recv on my main socket that it would be able to receive data from all the clients connected to it. 
Nope, that doesn't happen.
Read this: https://beej.us/guide/bgnet/ Seriously, read all of it. It explains it all with examples. If you've read it already go back and read it slower.
This should do it for you: https://beej.us/guide/bgnet/
Wow, Literally have never seen this before. Thanks dude!
&gt; WSL MSYS2 is free, MSVC you have to pay for the full version and its C compiler is years behind gcc. mingw-w64 makes binaries that run natively on any installation of Windows (back to Win7 at least, maybe WinXP too) ; I don't think WSL development could say the same 
I have never come across this before. Definitely will be reading through it over the next few days. Thanks for the reference material. 
The functions do not conflict. Rather, `recv` is only available on connected sockets or on sockets that are not connection oriented (such as UDP sockets or UNIX datagram sockets). `listen` is a function that waits on an unconnected socket until a connection was requested and then returns. `listen` itself does not establish a connection; you have to do call `accept` to accept a connect. On success, this function fills in details about whose connection you accepted and returns a newly created socket referring to the connection you just accepted. This socket can then be received from. All UNIX system calls set the error variable `errno` to indicate an error if they fail. You can print a human-readable description of this error message using the `perror` function. You should always do so in case of error so you know what went wrong. This would have told you that the error is `ENOTCONN` (not connected) and checking the manual supplied by your vendor would have revealed the remaining details I gave. There is no excuse for not looking in the manual and no excuse for not checking error codes.
OP seems like a new guy learning how to program. msys2 is a compromise. It's "the best posix we can get given you have to target pecoff." I use it on a daily basis for work as a toolchain engineer working on exactly this problem (making compilers and llvm based toolchains work on different platforms). But if you aren't bound to constraints that force you to use hybrid systems like msys2 then you are best off using either of the native options. 
It sounds like you created [ed](https://en.wikipedia.org/wiki/Ed_(text_editor)), and now you want to create [vi](https://en.wikipedia.org/wiki/Vi)!
What three combo do you use? I would do vim, and gcc. Not sure on a standalone debugger
&gt;OP seems like a new guy learning how to program. They said they have been coding C in Ubuntu previously and would like to switch to coding C in Windows natively. &gt;msys2 is a compromise. It's "the best posix we can get given you have to target pecoff." mingw-w64 is the compiler for building native Windows executables. It is literally the same compiler as GCC in any other operating system, with a few extensions to enable use of the Windows API. MSYS2 is used as a package manager and commandline tool suite (including commandline-based build systems). I'm not suggesting using it to build binaries that target MSYS2. &gt;But if you aren't bound to constraints that force you to use hybrid systems like msys2 Having the resulting binaries not work on a normal Windows install is a pretty big showstopper, for me anyway. However I would agree that WSL seems like a better option than running a VM. 
vim, gcc, and gdb are pretty good IMO. The learning curve for vim and gdb are pretty steep though.
I am only using one of the record types per run of the program. Each time the program is run, the program takes a file and its corresponding record definition file as input. Each file has only one type of record, so the flexibility of the data structure just allows for different files to be used in different runs. In the Python version of my program, the simplest use of the program is to just convert the file (which is plain text mixed with packed fields) into a .csv. The first piece of the program parses the record definition file and creates an array of tuples in the format (field_name, field_length, type). The array is then passed to another method that opens the file, reads a line, parses the line, and writes out that line as a list. I've figured out the data structures that I need for every other piece of the program but haven't been able to find an easy way to create a similar data structure to the final list. In Python, that list contains the various types (int, double, and string) with no issues thanks to the dynamic nature of the language. The data structure I use for the C version basically needs to act like that Python structure, but use as little memory as possible (as the program is running on files with hundreds of thousands of lines and a very old server with little resources). Currently, my Python version uses far too many resources, so even if I could easily convert the program it would likely be too resource intensive. By rewriting it in C, I'm hoping to achieve both better run time and memory efficiency. 
Ah. Okay, that makes a lot of sense and answers most of my questions. One last one though: Do the files that you're reading in contain information about the structure of the records? That is, do they contain everything needed to parse them on the fly, or will you need to manually write parsers for every one of the file formats you wish to read in?
For super quick/dirty and EZ C coding I use a little-known IDE bundled with MinGW/GCC called "MinGWStudio". Development has long since ceased but the thing is stable and I've done plenty of projects with it. The IDE is minimalist and doesn't give you much control over how it interacts with the compiler/linker via commandline. It gets the job done. It's basically a direct copy of DevC++, but stable.
There is another file in the same directory that gives the file structure. The file is the working storage from a Cobol program, so I have a simple parser that figures out the layout of the file.
&gt; This is more about not recognizing the existence of fictional implementations. Implementations are certainly going to exist in future that do not exist today. Such implementations are, today, fictional. If accommodating a fictional implementation would pose an unacceptable burden on programmers targeting commonplace ones, the burden of accommodating an extremely rare implementation should be just as unacceptable. That doesn't mean that the Standard shouldn't recognize rare implementations; instead, it should ensure that such recognition does not impose a burden on programmers targeting common implementations. Further, although many programs benefit from two's-complement semantics, there are many that do not, and having means of waiving two's-complement semantics in cases where the Standard presently mandates them (e.g. when performing `ushort1++;` on a typical 32-bit platform with 16-bit short) or demanding them in cases where the Standard would not otherwise mandate them (e.g. for programs that were written for implementations that guarantee quiet two's-complement truncation on overflow) would be useful, regardless of whether the waiver of semantics is used to allow one's-complement implementations, offset-binary implementations, or implementations using some other representation that *hasn't been invented yet*. Rather than determining whether any non-fictional platforms do things in any unusual fashion, a better question would be whether any future implementations could benefit from being allowed to do things in unusual fashion *in cases where that wouldn't conflict with a programmer's requirements*. Programmers know more than the authors of the Standard about what semantics they need to accomplish various tasks; the goal of the Committee should not be to decide what semantics programmers need, but rather provide programmers with the tools to demand the semantics they need and waive any semantics that might needlessly impair present *or future ["fictional"]* implementations. 
Checkout [kilo](https://viewsourcecode.org/snaptoken/kilo/) - it is a tutorial on building a text editor in C. 
Setup a CVS repo, like github or gitlab, and look in to Curses library. Curses will take you a little while to get the hang of. From there, you can do whatever you want and people can push commits to your project if theyre interested. As a hint, figure out how to work with data streams and set up a structure, or function, to handle those streams. Its makes handling I/O much easier down the line. There are some code snippets on github that do this already.
Got it. Your program won't have a hundred hard-coded parsers; it will learn the file format on the fly. In this case, it sounds like even creating a mega-union of all of your record structures is not ideal since you'd have to hard-code their structures into your program. It seems like you really do need some sort of flexible storage. One solution is to create a variant type that can hold any of the fundamental types you need. This usually takes the form of a struct with storage for the data and an enum to identify the active type. You could create an array of these variants for each record and then reference those arrays from an array of pointers that represents the file. If you can use C++, you might look at [Boost's Variant type](https://www.boost.org/doc/libs/1_61_0/doc/html/variant.html) instead of building your own. Note that variants will have some extra memory overhead for every field in every record. To save more memory, you could go the "descriptor" route that was also mentioned somewhere in this thread. The idea would be to build a data type and accessor API that holds a single definition of the record structure along with a big chunk of memory to store the data. The accessor API would use the descriptor to retrieve the desired field of the desired record. This has the potential to be quite memory efficient at the expense of code complexity. To reduce complexity, one option is to normalize everything into strings as u/FUZxxl suggested. That would likely result in more straightforward code at the cost of RAM. Again, C++ could give you a productivity boost here because vectors would be an easy way to group strings into records. Finally, it sounds like RAM restrictions are driving a lot of the complexity here since you're looking to build a very memory-optimized structure. And when you start optimizing, things tend to get more complex. If RAM is scarce on your system, but you have time and storage, you might consider using memory-mapped files. You could transpose your input file to an interim file whose format is extremely straightforward, though not RAM-efficient. For example, convert every field to a fixed-size string that's large enough to hold any value you could encounter in your files. If every field is a fixed size, then it's easy to find the Nth field of a record and the Nth record in a file. You can then use [`mmap()`](http://man7.org/linux/man-pages/man2/mmap.2.html) to get a virtual memory mapping of the file. With this, you can traverse the records for processing, or even sort them in place. Because this involves the file system and storage medium, this will be slower than processing in RAM, but it could be an acceptable tradeoff.
who became more stupid in de past 30 yrs?
Sure. I don't see a reason you could not. I also can not see a reason you need too. Is there a particular reason you want to use doubles? The size of a float/double usually isn't a major issue except on in special cases or on embedded or legacy devices (even in the 90s). Floats are little faster and doubles have higher precision, it really depends on what you need.
VS is actually free. The community edition (used for learning/research/academics, up to small professional dev teams and even commercial use) is totally free is not limited compared with the professional version of it. You can even download the build tools and compile through command line and never have to download/use their IDE (which still has no equivalent in windows). Its C standard is indeed limited. For the most part is C99 compliant and has C11 features. The most important part is missing VLA (variable length array) from C99 and like a couple of other smaller things, but you can work around your code. The plus side, VS IDE comes with a great debugger. On the other hand I do have mingw-w64 installed (not through msys2) and using VS Code (the editor) as an IDE, for which I've made tasks to build using both compilers. GCC (for windows) is not perfect either (mostly in the c++ area) but they are both great for what (s)he will do. GCC is usually producing quite larger executable files than msvc, with with optimizations turned on, but this shouldn't be a problem. Either way both are fine, there is no reason to dismiss MSVC.
If you don't know what you're doing, the safest thing to do is stick with `double`. Using less precision requires care and [understanding](http://blog.reverberate.org/2014/09/what-every-computer-programmer-should.html). However, even though machines today have tons of storage compared to 20 years go, `float` is still as important as ever. If you're working with large amounts of data, those savings still matter. Single precision is faster in general: slightly better latency, less cache pressure, and, in specialized situations (SIMD), they can literally *twice* as fast. 
Sure, just pick one and be consistent.
So it only really matters in 2 situations I can think of. Embedded environments like an arduino because I don't believe it has hardware for doubles but it can handle them using software tricks. And also machine learning. I was at a conference last year and I found out that the number of calculations you preform per second is much more important than the accuracy of the calculation. So using floats would be better and if you using something like opencl, using a half float would be even better. 
I'm in my first C++ class in college, and I thought the difference between float and double was how many decimal points the integer shows in cout, if that makes sense. You can get like 10.50 from double, but it would only say 10 for float. Am I even close to being right on that? I got a midterm coming up soon
hint, miles per gallon is calculated as miles divided by gallons 
Homework at elementary school? In python miles = N1 gallons = N2 milespergallons = miles/gallons print(mikespergallons)
A float 32 bit is a number that contains decimals. They have 7 decimal points of precision. Ex: 10.1234567. A double is a 64 bit number. So it's like a float, but with extra precision, up to 15 decimal points. Ex: 10.123456789012345. Hope this helps!
Look at it close line by line. You'll see it. Also pick more descriptive variable names in the future to avoid this class of bug.
Hint: using names like `foo_1` and `foo_2` makes it very easy to use one where you really want to use the other.
I think you are missing a space in scanf. scanf(“ %f”,&amp;Fahrenheit)
yeah it might just be mobile, i have the space there on my screen.
I’m saying space in front of “%”. Try this. “ %f”. I don’t see any space in “%f” in your scanf. 
didn't fix it :(
i think i'm blind, i don't see where its going wrong 
Well it's clearly outputting something that is wrong. Start there and work backwards.
You have: // newCourse-&gt;next = NULL; So your newly-created `Course` objects' `next` pointers are undefined. When you loop through your list, you end up at the last object, then follow this undefined pointer. Note also that your `freeAllCourses` function doesn't actually free your `Course` objects. I would expect Valgrind to complain about this as a memory leak.
Oh wow uncommenting that line fixed the issue, thank you! Also, am I not freeing the course objects when I say free(data-&gt;current-&gt;name) in the while loop?
Here's a simple way to think about the problem: each time you add a course you call `malloc` the times, but each time through your loop you only call `free` two times. Something *has* to leak.
&gt; Briefer version of key thoughts: The vast majority of implementations use non-padded 8/16/32/64-bit integer types, in either consistently-big-endian or consistently-little-endian order. The Standard should not require that all implementations use such types, but should recognize that those which don't are "unusual", and provide means via which programs for usual platforms can refuse processing on unusual ones that don't meet their requirements. The Standard already does that. `int32_t` is a signed 2's complement type with no padding bits. If the implementation cannot support it, then it won't exist. If you use it in your code, the code will fail to compile on those platforms.
That makes sense. Now I'm thinking I would need to save a pointer to the current course before setting my data-&gt;current to the data-&gt;current-&gt;next so I can free the pointer to the previous course after I make a move in the list. Am I on the right track?
&gt; Am I on the right track? You are! Good work on noticing that you need to take a copy of the `next` pointer.
An implementation could support `int32_t` as an extended integer type whose representation was entirely unrelated to that of any of the normal built-in types. Further, there's no requirement that a conversion from `int32_t` to `int16_t` perform in mod-wrapping fashion. Some DSPs have a saturating store instruction, and for some purposes that might be more useful than truncation. Further, there are many useful guarantees which commonplace signed-integer implementations used to uphold, such as the ones described in the Rationale and the second part of my post, which language vandals have seen fit to throw out the window. If people writing implementations intended solely for processing guaranteed-non-malicious data think they can usefully perform some extra "optimizations" by jumping the rails even in the cases described in the Rationale, I'd have no beef with them if they recognized that such behavior is "unusual". I have a big problem with the notion that programs should be expected to include extra code to guard against what would otherwise be benign overflows, purely for the purpose of appeasing obtuse implementations.
&gt;You will actually need to take a copy of the &gt; &gt;next &gt; &gt;pointer in the object that's just about to be freed, then use this to iterate to the next object. Thank you so much for this tip! I was actually struggling to free the courses as I was saving the pointer to the previous Course. Just out of curiosity, do you mind explaining why saving the pointer to the current course wouldn't work?
&gt; Just out of curiosity, do you mind explaining why saving the pointer to the current course wouldn't work? Because you can't use it once the current course is freed. It becomes an invalid pointer at that time.
Thank you! I'm a complete newbie, so thank you very much for any tips =)
Understandable. Thank you! I still have a long way to learn C haha
You’re reading data into Celsius_1 variable but doing the calculation with the uninitialized Celsius variable. In the future you should name your variables more descriptively to avoid this.
ah is that the only problem?
On a typical 64bit System: sizeof float = 4 byte sizeof double = 8 byte If you don't know all the values and the value could overflow, just stick with double
its does depend on your hardware but floats could even end up being slower, a lot of modern hardware has SSE2 instructions to handle multiple operations on doubles at once...
Oh and btw, if you want to receive on all clients at the same time, you need to use a function like `select`, `poll`, `epoll`, or `kqueue` (depending on your platform) that does this sort of thing for you. Read the manual for details.
 #include &lt;stdio.h&gt; int main(void) { float Celsius, Fahrenheit, Fahrenheit_1, Celsius_1, Celsius_2, input_altitude; printf("Enter the temperature in Fahrenheit: \n"); scanf("%f", &amp;Fahrenheit); printf("Fahrenheit temperature is: %5.1f F\n\a", Fahrenheit); Celsius_1 = (100.0 / 180.0) * (Fahrenheit - 32.0); printf("Celsius temperature is: %8.1f C\n\n\a", Celsius_1); printf("Enter maximum altitude in meters:"); scanf("%f", &amp;input_altitude); Celsius_2 = Celsius - 6.5 * (input_altitude / 1000); Fahrenheit_1 = 32.0 + (Celsius_2 * (180.0 / 100.0)); printf("Celsius temperature is: %5.1f C\a", Celsius_1); return 0; } Output: ./test1 Enter the temperature in Fahrenheit: 100 Fahrenheit temperature is: 100.0 F Celsius temperature is: 37.8 C Enter maximum altitude in meters:400 Celsius temperature is: 37.8 C &amp;#x200B; I don't know if the values are correct, but it seems to work (didn't change anything)
I see your original question has been answered but I just wanted to mention that `newCourse-&gt;name = (char *)malloc(1024);` is a bit odd. `malloc` is generally used if we don't know the size of something in advance, but if you're always going to allocate a fixed size then it'll be simpler to use an array rather than a pointer, e.g. typedef struct Course { char name[1024]; int hours; char letterGrade[1024]; struct Course *next; } Course; 1024 seems a bit excessive for letterGrade too ;) If you want to stick to pointers (which honestly would be more usual for this sort of thing where the sizes are going to vary a bit) then either find the length of the name etc first then allocate that amount, or have `strdup` (from string.h) do it for you, e.g. Course *newCourse = malloc(sizeof(Course)); newCourse-&gt;name = strdup(course); newCourse-&gt;letterGrade = strdup(grade); newCourse-&gt;hours = hours; If you do use `strdup` remember to `free` them at the end, it's the same as `malloc` in that regard. (as an aside I don't like to cast `malloc` - there's different schools of thought on this)
Flushing stdin is undefined behaviour.
I think its wrong algortihm, temperature in celsius is falling 1 degree with every 100m..
Hard drive storage wasn't really the issue. RAM and cache was a bigger issue in ye olden times. Execution performance is a far more recent consideration. Most processors include a FPU (floating point unit) which specialises in processing floating point instructions. Earlier systems had a relatively small bus to pass data across so floats performed better. Modern processors, I think from the P4 onwards, have had 64bit busses and the amd64 architecture introduced 64bit memory busses. So performance of doubles and floats should now be equivalent on a PC. Bottom line, just use doubles.
To learn, try this with `int` first. Then once your code is working, switch to strings. Don't forget to version-control your code.
Read the sticky post about asking for help. Follow its instructions.
Overflow? Well, sure double has 11 bits for for exponent (8 bits in float), but in most cases it's precision that matters (52 vs 23 bits)
 #include &lt;stdio.h&gt; #define SIZE 3 int main() { int i; char strings[SIZE][20] = { "Hello World", "Bye World", "." }; for (i = 0; i != SIZE; i++) printf("[ %02i ]\t%s\n", i, strings[i]); printf("Enter the line you want to change\n"); scanf("%i", &amp;i); if (i &gt; SIZE) { (void) printf("Wrong input\n"); return -1; } else { printf("Enter:\n"); scanf("%s", &amp;strings[i][0]); } for (i = 0; i != SIZE; i++) printf("[ %02i ]\t%s\n", i, strings[i]); return 0; } No error-checks, no length check, no comments &amp;#x200B; Output: ./test2 [ 00 ] Hello World [ 01 ] Bye World [ 02 ] . Enter the line you want to change 0 Enter: blubb [ 00 ] blubb [ 01 ] Bye World [ 02 ] . &amp;#x200B;
Did this and i made them easily but this one is 2d array and I'm struggling on how to move strings to the next index.
Sorry about that, will follow if I happen to ask some more. Thanks for reminding!
In the first strcpy(), you should be using i instead of loc. Consider also the case where you must drop the last string. I assume you have to do the shifting one-by-one for some reason, but there is also memmove(). It could do the same with less fuss.
The same argument applies to games. The calculations only need so much accuracy, but they better be fast enough to keep up with growing demands on hardware.
Wat. 
do your own test or don’t be a CS major 
It's open book, not copy your answers. 1) the answers are probably in the class notes you should've been talking. I hope you did. 2) Too late 3) If you need your notes for more than a question or two (and you don't already know where to look) you will probably run out of time looking; if the test is designed well. I hated open book tests, they were always harder... but the only thing I had to look up on a programming test was "berthing" (as in ship) just to figure out the context. 
Ohh ok so that’s the sane way of doing this 😂 I’ll edit my code to use strdup 
 int main(void) { return 0; }
Ah perfect thank u
A character: char a_simple_character = 'r'; a\_simple\_character now has room for one character. But, we know we want to store more than one character at a time. Something like a word: "example". &amp;#x200B; We now need room for 7 characters. Therefore, we could write: char an_example_word[7] = { 'e', 'x', 'a', 'm', 'p', 'l', 'e'}; &amp;#x200B; Now, when C was first being written, it was \_very\_ obvious that his was stupid. So, instead we wanted an easy way to say "start at this point in memory, and keep using the characters until it's done." &amp;#x200B; That is what a string is. A string of characters. "example" is a list of characters. What's missing from this is "when is it done?" The way that C handles this is to add a character at the end with a value of zero. That is the 'nul' character (which, amazingly is different from the NULL value in concept, but the same in practice). &amp;#x200B; So, if I want to assign a bunch of characters, I can write: char an_example_string[8] = "example"; &amp;#x200B; I need 8 spots in memory to handle the nul. &amp;#x200B; And that's it. Everything else is "just" memory manipulation. You can malloc a block of memory and copy a string into it. You can concatenate strings together if you have enough room to put the two of them in, and etc. &amp;#x200B; The other tricky part is when "wide characters" show up, but, you probably don't care about those yet. &amp;#x200B;
With regards to files, since strings were explained well by u/which_spartacus, files in C are accessed with a file pointer that acts as a "cursor". Essentially, when you open a file, you get a FILE* to it, and can then write to it and read from it. The file pointer simply tells you where you are writing or reading. If you write "example\n" to the file, you will have one line that says "example", and the file pointer will point to the next line because of the newline character. The same is true for reading. The end of a file is marked by an EOF character, which is a special character used to know when to stop reading form a file because you have reached the end.
Thanks for your help, but i already know those stuff. Like i said, I need more than just the basics. For example a not so simple full code with explanation, in order for me to see how it looks when all of this is used in a program and get used to using it on my own. 
Cache is an even bigger issue today than historically. When the IEEE-754 Standard was written, the intended approach for computations was that code would read values from tables where they would be held using types optimized for storage efficiency rather than precision or speed, convert them to a longer type optimized for precision and speed, perform a sequence of calculations with them while retaining extra precision, and then convert them back to lower-precision types, with rounding occurring at well-defined points in the calculation sequence. One would need to take care that any temporary results used within a computation would be stored using the extra-precision type, but that approach to calculation was on many platforms the best way to perform floating-point math. Unfortunately, the authors of the C Standard failed to uphold a very important principle in Ritchie's design of the language: *functions that expected to receive floating-point arguments didn't need to know or care about what type was used in the caller*. The way the Standard was written, however, effectively required implementations to do one of three things: 1. Always pass floating-point arguments physically as type `long double`. 2. Use the same representation for `double` and `long double`. 3. Require that code using functions like `printf` make distinctions between different argument types that hadn't been necessary under Ritchie's design. If the Standard had specified that all floating-point arguments would get passed as `double`, but included a macro to convert a `long double` into a struct which could be output using a suitable format character, then this would have eliminated the problems associated with having separate `double` and `long double` types, and the superior numerical semantics of such types might still be available to day. As it is, most implementations have since been designed to perform math on values fetched from memory, using the types of the values fetched. This is numerically inferior, but it is what it is. If one is trying e.g. compute the area of a triangle given sides expressed as `float`, using `float` for intermediate calculations may give results that are nowhere close to the more accurate results obtained if the sides are converted to `double` and math is performed using that type. If the precision one would get by using `float` for intermediate calculations is inadequate, caching performance will be better if one uses `float` to store values but converts them to `double` when performing calculations, but in cases where caching isn't an issue using `double` for everything may be faster because it would eliminate the extra conversion steps. 
This [Website](https://www.tutorialspoint.com/cprogramming/index.htm) covers it pretty well
Then ask a specific question, I'm not about to write an essay about this stuff without knowing if it helps
Global variables are allocated statically - place for them is actually reserved in program image and filled with zeroes, if no initial value is given. 
I've got relevant experience here, currently developing a cross platform library in C for Windows and Linux. While I would say cross platform is not all that straightforward, development on either is very easy with CMake as the build system. Once you have Visual Studio 2017 installed, and a simple CMake setup, you're three commands away from building code: mkdir build &amp;&amp; cd build cmake .. cmake --build . I use Git Bash as my shell for a familiar but lightweight Linux experience in Windows. There's some nice CMake tutorials out there, just look for a simple C++ example and you should get the idea.
Unfortunately, I don't have access to a C++ compiler on the Unix server. There is not one currently installed and I do not have the means to install it myself. I also would just prefer to use C so I can learn more about the language. For the descriptor route, would I just allocate a large amount of memory with `malloc()` and keep track of where I store information in the array with `void *` pointers?
I mean C99 is damn near complete now.
Also, there is the new preprocessor you can enable with `/experimental:preprocessor` or `/permissive-`
You know, it sounds like you're less invested in your own education than randoms on an internet forum... why exactly should we go out of our way to educate you when you don't even care enough to write up the actual questions you have?
Yeah, there are probably several ways to approach it, depending upon the details of your data. If records are always padded out to the same size--or if you can afford to pad them out in memory as you read them in--then you can build a single descriptor for the entire file. This might look like an array of structures that reflect field type, offset, and length, along with a variable that holds the overall record size. You could either allocate this descriptor array once you know the file format--and thus how many fields are in a record--or you could just statically size this array to be able to hold the max number of fields you'd ever expect to encounter. The "offset" would be the number of bytes into a record to find a field. To read in the file, you'd `malloc()` a big chunk of memory to hold all of the record data. If the records in your files are padded out, then you can `malloc()` it based upon the file size and pretty much just read the entirety of the file directly into the array. If the records in your files are not padded out, then you might need to either guess at your initial `malloc()` and use `realloc()` if necessary, or do a first pass through the file to parse and discard the records simply to count them so that you can `malloc()` with the record count times the number of bytes in your padded record. Then, you can do a second pass to read in the records and pad them as needed. Since the records would all be the same size, you'd find a specific record "N" in your padded record data array with `record_ptr = data_ptr[N*record_size]`. Then you'd find specific fields by indexing into that record with the offset to the field you want. You could create helper functions that do this for you given a field index--so that it has the ergonomics of indexing the items in a tuple. Something like `void *get_field_for_record(struct field_descriptor const* descriptor, void *record_ptr, int field_number);` This would index into your descriptor array to find the descriptor for field_number and then return the pointer to the data for that field by using the descriptor to determine how many bytes to index into the `record_ptr` to find the field data. You'd probably also need `enum FIELD_TYPE get_field_type(struct field_descriptor const* descriptor, int field_number)` to figure out what to cast the returned field data pointer to along with `size_t get_field_size(struct field_descriptor const* descriptor, int field_number)` to bound accesses to the field data pointer. If your records have variable sizes due to optional fields or non-padded strings, then you might need a descriptor per record &amp; this gets more complex. You'd also need to evaluate whether it's cheaper RAM-wise to go with variable-length records and incur the cost of a descriptor per record or to simply pad out the data. I'd highly recommend padding the records to the same size as it will simplify record access, but also allow you to do things like sort the records in place without having to perform a bunch of memory shifts to deal with varying record sizes.
Seems like you didn’t read my question correctly. I asked for recommendations on websites or YouTube tutorials, so I don’t bother strangers on the internet:) 
Thank you so much!
&gt; Rust and Swift, That's a hell of a leap.
This. I'm beyond tired of hearing about how supposedly broken C is.
It's called debugging and using sanitizers and half a dozen other tools. you don't have to give up performance for safety, you fuckers are just lazy and don't want to have to put in the work.
Even on platforms where storage locations may hold arbitrary byte patterns on program startup, the amount of effort required to write zeroe to every byte of storage used for non-initialized static-duration objects, once on startup, is relatively limited, and doing so makes it practical to support constructs like: char woozle_dejavu; void woozle(void) { if (!woozle_dejavu) { woozle_init(); woozle_dejavu = 1; } } The Standard's guarantee that objects of non-character type will by default be initialized to whatever bit pattern would be represented by a literal zero cast to that type, as opposed to an all-zero bit type, represents a judgment that it was more useful to guarantee that `static float foo;` would always behave equivalent to `static float foo=0;` than to allow the the former to use all bits zero, and require that code needing the value zero use the latter form. I'm not sure I agree with that judgment, but I've never used a platform where all bits zero wouldn't represent a value of zero. 
There's a bug in your `path_finder_lowest_in_open_set()` function that's making this not actually A\*. The horizontal scanning pattern showing in your demo video is definitely incorrect, and it's happening because it's not finding the lowest open cell. For example, try changing path_finder-&gt;f_score[i] &lt; lowest_f To: path_finder-&gt;f_score[i] &lt;= lowest_f And, in your example, you'll see what A\* *should* look like, where it shoots straight to the exit. However, if you swap start end end, you'll get the same bad scanning behavior since the "ties" (that shouldn't be ties) are broken in the wrong order. I'm not seeing what's wrong with your `f_score` that's making this happen, but rather than dig into this you should instead switch to a more appropriate data structure that doesn't require a linear scan of the entire map. That takes away all the performance gains of A\*. For example, you should really use a [binary heap](https://en.wikipedia.org/wiki/Binary_heap#Heap_implementation) — specifically an array-based binary heap. It's pretty easy to code up, and you can easily pre-allocate the whole thing. IMHO, while allocation-free libraries are useful and valuable, a library that only works with a particular statically-determined allocation size is not useful — especially not when it's this small. At minimum the caller should tell the library how much was allocated, and the library can work with any size. In [my implementation](https://github.com/skeeto/rlhk/blob/master/rlhk_algo.h#L129) of a non-allocation A\*, I used callbacks to ask the caller to store per-cell values. For the binary heap, the caller supplied a work-space buffer. Intentionally providing a buffer that is too small is a way to perform only a short, local search. Closer to the way you did it: the library would communicate to the caller how much needs to be allocated, then the caller makes the allocation, and goes back to the library to initialize. Here's a rough example: size_t uastar_amount_to_allocate(int width, int height); void uastar_init(struct uastar *, int, int); int width = 500; int height = 600; size_t z = uastar_amount_to_allocate(width, height); struct uastar *finder = malloc(z); uastart_init(z, width, height); Dividing up the allocation is the hard part. Here's one way you might do it: struct uastar { int start[2]; int end[2]; long num_open; struct { /* Heap fields */ int position[2]; /* Map fields */ int gscore; int fscore; int parent : 2; // 0-3 (direction to parent) int isclosed : 1; } heap_and_map[]; }; The `heap_or_map` field serves as both an array-based binary heap and as for mapping to get per-cell values, interleaving their storage. 
Hey, thank you for the write up! I made that little change (\`path\_finder-&gt;f\_score\[i\] &lt; lowest\_f\` to \`path\_finder-&gt;f\_score\[i\] &lt;= lowest\_f\`) and noticed the difference you mention. I will investigate how to implement it with a binary heap, too. ps: I like the content you post in your blog 👍
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
yeah I got it fixed it, I was addressing the wrong variable in one of the formulas
Ahh, that would explain the comments I've seen about the loss of precision when migrating from the 80 bit x87 coprocessor to the SSE instruction set.
https://idownvotedbecau.se/noattempt/
What I would do is write out the math, make it algebraic, solve it and then paste it into my c program after adding semicolons.
So what is your question? Or are you just sharing the love?
Doom https://github.com/id-Software/DOOM?files=1
Get yourself [Raylib](https://www.raylib.com/) or [SDL](https://www.libsdl.org/) or something from [this list](https://github.com/kozross/awesome-c).
Raylib is really easy to learn, you can make 2D, 3D and VR games with it. [raylib](https://www.raylib.com/) 
This looks great thanks!
This is what I was looking for!
I hope the standard does not alter any definitions or add any features in the future, but instead focuses on keeping C simple (just like the language). I get the point you are trying to make, but an “object” in the C standard’s diction only has semantic value for use between sections. This post just feels like mental masturbation about a software language with well established practices.
While Doom's source code was well designed and documented, as a resource for OP's intentions this repository is remarkably lacking. The source is for a 25 year old game, which was released 20 years ago. At best it *might* contain some changes made to the engine for Doom 2 in 1995. I don't think it uses any graphics APIs, and even if it does use OpenGL, there are some significant changes that have occurred in the last 20 years. Don't misunderstand, it's a remarkably portable and historically significant piece of software, but aside from the linear algebra and general design (both of which would probably be best learned outside of source code) this project has very little to offer OP in terms of game development. Just my two cents.
The last point likely has the largest impact on statically allocated pointers, because NULL is not required to be 0x0000. This way people can write: int *a; if (!a) a = malloc(256 * sizeof *a); And it will work even if NULL is defined as 0x1234
The ability to initialize things to a value of zero even on platforms where that would require a bit pattern other than all zeros can be useful, but it can also be costly. On many platforms, objects which need to be initialized to anything other than "all bits zero" are grouped together, and their initial contents are mirrored within an executable file. On such platforms, a declaration like `char foo[1000000];` at file scope may add nothing to the size of an executable, but `char foo[100000]={1};` would add 100,000 bytes. Personally, I think the Standard should have specified ways by which applications could have waived initialization for specified objects or portions thereof, since the present initialization spec requires some implementations to generate needlessly-large executables to support semantics that many programs don't need. Since the syntax `int *foo[100000]={0};` would be available to specify that the array must filled with null pointers in cases where it matters, allowing implementations to specify that `int *foo[100000];` would initialize the array with all-bytes-zero instead would have allowed some implementations to better serve their customers than would be possible under the current rules [of course, for cases where null pointers are represented as all-bytes-zero, granting implementations the choice of whether to initialize with all-bytes-zero or null pointers wouldn't break anything because both behaviors would be equivalent. 
Interesting. What are the advantages of static memory allocation in this application? I could only see it being useful when memory is at a premium. Not a common occurrence when A* is involved I would imagine? 
Yes. Depending on your level of expertise you can use different pure C libraries and APIs: begginer: Allegro https://liballeg.org/ expert: sdl https://www.libsdl.org/ masochist: openGL https://www.opengl.org/ modern masochist: Vulkan https://www.khronos.org/vulkan/ IIRC allegro is only 2D, but is really easy compared to the rest of libraries. I suggest starting here. SDL is built on top of openGL (or directX if you're using windows), think of it as an opengl wrapper. It's still kinda hard if you're not used to making games. OpenGL is really low level, it's basically the interface that graphics manufacturers give you to use the graphics card, but you shouldn't use this one directly unless you really know what you're doing. Vulkan is like an updated version of OpenGL, but even more low-level. None of these are game engines. they are libraries or APIs, that means that *you* have to code your game logic, and you can use these only to paint primitives on screen (circles and squares in the case of 2d. spheres, cubes, planes, etc in 3D).
Inconsistent interpretations of what "objects" are have resulted in divergent dialects of C, including one which is suitable for systems programming but cannot be efficiently optimized, and one of which supports aggressive optimization but is unsuitable for systems programming. It should be possible for a dialect to serve the vast majority of purposes which are at present not served well by either dialect, but any discussions of how such a dialect should behave will be meaningless unless or until the participants can first agree upon terminology. Presently, gcc and clang interpret 6,5p7 as saying "An Ωβ⌡ε⊂τ shall have its stored value accessed only by an lvalue expression that has one of the following types... *even in cases that do not involve aliasing*"; since that would render the language almost useless if it actually applied to all objects (using the term as applied elsewhere in the Standard) they interpret the definition of Ωβ⌡ε⊂τ in a way that excludes things to which they don't want to apply the rules. Personally, I think that the behavior of gcc and clang behavior is just as conforming as that of a compiler that always generates the same executable when given any source file that doesn't violate any constraints. If there exists one (possibly contrived and useless) source text that nominally exercises all of the Translation Limits in 5.4.2.1, and that an implementation can process in accordance with the Standard, that would suffice to make an implementation conforming even if it would jump the rails when given any other program. Such an implementation would be unsuitable for any practical purpose, of course, but the authors of the Standard expect compiler writers to know what is necessary to make compilers suitable for various purposes, without having to be told. 
It's sorta like if you pick up a rock and hit something with it, does it cease to be a rock and become a hammer? Can it be both? You could call it an object if you wanted to describe it as something that exists but want to leave it up to others what function it has or what properties define it.
Suppose there were a rule that you need to use one kind of gloves when handling rocks and another kind when using hammers, and a law providing that cops may, at their discretion, summarily execute anyone violating this or any rule. In the absence of such a rule, an artifact that was composed of feldspar and whose shape allowed it to be used for pounding could be classified as a rock, a hammer, or both, but it wouldn't really matter. Further, a rule such as this might not be patently unreasonable if every artifact could be easily classified as "rock" or "hammer", and there would never be any reason for any non-malicious person to use inappropriate gloves. If the published rationale for the rule was to avoid requiring "hammer globes" guard against scratches, or that "rock gloves" protect against impact injuries, then such a rule could make sense even if interpreted in that light, even if there might be some artifacts for which there would be no "proper" glove. Someone who wants to pound something with a rock would need to use more caution than may be necessary when picking up rocks with rock gloves or wielding a hammer using hammer gloves, but unless the cops abuse their discretion the rule would not make it impossible to safely use rocks for hammering--it would merely increase the level of caution required to do so, If some cops are eagerly going around and executing people for using "improper" gloves, should the question of which artifacts are rocks, hammers, or both be dismissed as unimportant? Could the reasonableness of the rule be judged very well without such a definition? 
How can we help you if we don't even know what your delete function does or what your "menu" is? 
Pick one or two: * You are in the wrong sub as it's probably not C * You need jesus to help you express your problem
Fair point. Is there any place where I can post the program?
There's lots of them. Try https://pastebin.com
I reuploaded this, with a better explanation
Sorry friend, wrong Elders Chamber. We talk C only here. Your code is C++ - sounds similar, but is different. I recommend choosing a subreddit, that is more suitable for your problem. 
 *There is nothing more ravenous than a programmer. We eat our own and that’s the way we like it. — Jolly Roger* 
Try /r/cpp_questions or /r/Cplusplus - we only speak C here.
I thought Doom was written in Objective C on a Nextstep Computer?
Handmade Hero "tutorial" on Youtube is in C. It's written completely from scratch. From zero to a fully fledged game over the course of something like 300+ episodes. I wonder if anyone has stuck with it and watched every episode all the way through?
What you wrote is all true and fine in my opinion and I agree with it... But on slightly unrelated note I want to add that OP's question was: \&gt; Is it possible to create a game with just c? And the first thing that came to my mind was quite literally the numerous classic games written in C such as Doom, Quake, Duke Nukem 3D, Outlaws, etc. These make great motivational material at least if nothing else. Furthermore these games demonstrate that it is not only possible to write games on C but also write timeless classics which probably will never die because the technology and design were at perfect balance. As for the tutorials and such, there are plenty of them behind simple Google search. And we can give some direction and support to OP's quest to get into game development with pure C. But offering motivation as well is just as important, I think. &amp;#x200B;
Thanks 
Thanks 
I recommend trying [raylib](https://www.raylib.com), simple and easy-to-use (and setup), very enjoyable, in [active development](https://github.com/raysan5/raylib), growing fast and self-contained...
Take a look to [raygui](https://github.com/raysan5/raygui). I use it for small tools development.
Jens Gustedt recently proposed: [Introduce the term storage instance](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2328.pdf), which might clarify some of these points if it’s accepted.