You are correct.
I agree but in the real world you often see int* like that. 
`-g3` is enables level 3 debugging info
Awesome ty
This is mentioned in the NASM documentation: [https://www.nasm.us/doc/nasmdoc9.html\#section-9.1.1](https://www.nasm.us/doc/nasmdoc9.html#section-9.1.1) You will also need to pay attention to this with regards to how function names are decorated, too.
very helpful. thankyou very much!
STL that comes with gcc was (probably still is) using [introsort](https://en.wikipedia.org/wiki/Introsort) for a long time. That wiki page gives a good explanation: &gt; [Introsort] begins with quicksort and switches to heapsort when the recursion depth exceeds a level based on (the logarithm of) the number of elements being sorted. Introsort is essentially quicksort and rarely goes to heapsort on random or real-world load.
**Introsort** Introsort or introspective sort is a hybrid sorting algorithm that provides both fast average performance and (asymptotically) optimal worst-case performance. It begins with quicksort and switches to heapsort when the recursion depth exceeds a level based on (the logarithm of) the number of elements being sorted. This combines the good parts of both algorithms, with practical performance comparable to quicksort on typical data sets and worst-case O(n log n) runtime due to the heap sort. Since both algorithms it uses are comparison sorts, it too is a comparison sort. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; you are performing a binary search on a list of numbers that always contains them Not true. Due to randomness, the list contains duplicated entries and there is a small chance that a query may be absent from the list.
As an aside, you should change the allocation to Human *this = malloc(sizeof(*this));
`int` is still implicit.
&gt; printf '%s\\x0d\\x0a' foo bar | wine ./example.exe Hi, Thank you for the insightful knowledge. I am not very good in Linux or C. Learning it day by day. So apologies for this absurd doubt. I understand the context of what you said and I want to execute this program. I don't understand what this line is doing. Seems like input to the program but what is " printf '%s\\x0d\\x0a' " doing?
Yes, there are calls to `rand`, which I overlooked. Do note that since the RNG is not seeded, the same random numbers will be used every time. Anyhow, hopefully someone with more knowledge than me can interpret the generated assembly. It really looks like the searches are optimised away, but I do not understand why. 
The first part seems correct, but you're right, its not calling bsearch. I'll see what I can do.
sure, the standard makes complexity guarantees, but doesn't specific an algorithm. 
I don't really see why I'd need that. Also, this looks like it would cause a lot of bloat and slow compile time because the entire library is recompiled in every translation unit and all its functions are duplicated over and over again.
The same could be said regarding most header only libraries, but really most functions will be inlined either way, and considering very small size of the library I wouldn't think it would make that much of a difference. As for it's utility, I suppose that is your opinion, but there are certainly some who like a dynamically growing string, [sds](https://github.com/antirez/sds) being an example.
&gt; The same could be said regarding most header only libraries, but really most functions will be inlined either way, and considering very small size of the library I wouldn't think it would make that much of a difference. 1500 LOC isn't very small, especially for a library that is ostensibly used in every module of a program. I'm not a huge fan of these newfangled header-only libraries in general as they forsake ease of debugging, compilation speed, and binary sizes for very dubious performance gains.
I think the reader said most of that was documentation, the actual number of lines that will be recompile is way less
I've seen both around and I'm slowly but surely confused on what to actually use. My though is, why would I allocate memory with the size of a pointer? sizeof(*this) Doesn't it make sense to allocate enough memory for the struct's actualy members? sizeof(Human) 
Better no never and ever use *assert*. Using this function outside of debugging is a terrible idea. Better to change assertions with if conditions and returning a value, or assigning NULL pointer to output parameter for sake of indicating the failure. 
Ah yes indeed. The other points still stand though.
Your code treats r and c like they refer to the same dimension of the matrix when they don't. Run it under valgrind or address sanitizer and I bet you'll see out of range errors.
The asserts are simply to help debug, it is not behavior to be relied on. `strlen()` doesn't return `0` if you pass in a null pointer, it segfaults. You shouldn't get what you don't pay for. Instead of allowing segfaults to occur, I simply add some asserts to make debugging easier, but I am not willing to make functions more friendly at the expense of performance.
open_memstream looks very cool thank you for mentioning it. 
Ugh. I'm sick of the terrible tutorials being posted these days. Poorly written, invalid examples, don't follow good practice, etc. This one is even posted to the wrong sub!
R and C does refer to the dimension of the matrix. Since they go to the value of the matrix during the loops.
It basically solved all needs to a string library and is fully integrated into stdio, so it also works fine with wide-characters.
 float grade[totrow][totcolumn]; for (...; r &lt; totrow; ...) for (...; c &lt; totcolumn; ...) grade[r][k] &gt; grade[c][k] // etc. You don't see the problem there?
&gt; 1500 LOC isn't very small For C code in the 21st century, yes it is. On my system, GCC compiles `rapidstring.h` in ~15ms on -O3. That's nothing. I've never had issue debugging header libraries. Both GCC and Clang print the correct source file name and line number when displaying warnings and errors. They generate the same quality of debugging information, and GDB handles it all just fine. I'd agree with you about macro-heavy libraries. Debugging those really sucks, and it's normal for GCC to print out the wrong file name and line number when something goes wrong. This is unusual for header libraries through. In exchange for paying 15ms to compile an entire library, I get some real benefits: First, it makes for really simple builds. It doesn't introduce a new translation unit or external dependency. It's almost as first class as the standard library. Second, the library's functions are all very likely to be inlined, never generated as standalone functions. This is exactly what you want from a library like this one. It's like poor man's link-time optimization, except that it actually works really well. Inlining has significant performance benefits beyond just eliminating function call overhead. For example, it allows compilers to see through what may otherwise be aliasing issues. Despite your concerns, in practice header libraries don't actually lead to bloat. A C application using header libraries is *still* going to be among the leanest binaries out there. In fact, header libraries can actually lead to *smaller* binaries compared to traditional, statically linked libraries. Unused functions don't appear at all in the final binary, and when used functions are inlined the compiler doesn't need to generate the code for a function call (marshaling arguments to registers, spills, prologue, epilogue, restore from spills, etc.). 
I am passing this to the main, yes I see whats the matter my r value will never be higher than my c value thank you very much.
Yup, this is exactly the purpose of assertions. Define narrow interfaces, then use asserts to help catch mistakes during development.
&gt; Both GCC and Clang print the correct source file name and line number when displaying warnings and errors. They generate the same quality of debugging information, and GDB handles it all just fine. I'm more concerned that you can't reliably set break points inside these functions as each module has its own copy. There is no possibility for symbol interposition either and profiling with `gprof` is right out. &gt; First, it makes for really simple builds. It doesn't introduce a new translation unit or external dependency. It's almost as first class as the standard library. If you think that an extra translation unit introduces complexity than I conclude that you suck at writing Makefiles. In all serious build systems, an extra translation unit is just an extra line in your config file. Though seriously, I prefer to have my libraries separate if possible and loaded as shared libraries so I can have a single copy of the library on the system and package management can update the library without having to update all the dependent programs. &gt; Second, the library's functions are all very likely to be inlined, never generated as standalone functions. This is exactly what you want from a library like this one. It's like poor man's link-time optimization, except that it actually works really well. Inlining has significant performance benefits beyond just eliminating function call overhead. For example, it allows compilers to see through what may otherwise be aliasing issues. The minor performance gains from inlining across library boundaries are grossly outweighted by the other factors. In many cases, this is a pointless micro-optimization that bites you way down the road. If a function is really performance sensitive, you can declare it as an inline function in the header of the library (best as `extern inline` so there is no code duplication in case it isn't inlined). This should only be reserved for sufficiently simple functions though. &gt; Unused functions don't appear at all in the final binary, To prevent this, libraries generally put each function in a separate translation unit. You can also compile with `-ffunction-sections` and link with `-gc-sections` to get the same effect. Note further that inlining large functions is harmful in that it worsens cache locality for machine code, necessitating more frequent reloads of the code cache and worsening the efficacy of the branch predictor as it cannot know that the branches in multiple copies of the same function go the same way. &gt; and when used functions are inlined the compiler doesn't need to generate the code for a function call (marshaling arguments to registers, spills, prologue, epilogue, restore from spills, etc.). This is pretty much a red herring. The CPU only has a finite amount of registers and whether the data is spilled in a large function with many inlined functions in it or at a call site doesn't make that much of a difference generally. Of course there are cases where it does (e.g. floating-point heavy code) but these are not the cases where single-header libraries are generally used. The SQLite guys actually [report](https://www.sqlite.org/footprint.html) that compiling for size (e.g. inlining less code) does not make their code significantly slower, even though the binary is only 60% as large as the optimized for speed one. They go on to say that the suspect the difference is even smaller due to poorer code cache usage of the speed-optimized code.
C++ is off topic in this subreddit. Please do not post this.
Um... no. You're better off just using `qsort()` instead of trying to muck with sorting it yourself: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define ROWS 4 #define COLS 5 #define SORTCOL 4 int comp_array(const void *va, const void *vb) { const double *a = va; const double *b = vb; // Note: Poor comparision routine for floating point if (a[SORTCOL] == b[SORTCOL]) { return 0; } else if (a[SORTCOL] &lt; b[SORTCOL]) { return -1; } else { return 1; } } void print_array(int rows, int cols, double arr[rows][cols]) { for (int r = 0; r &lt; rows; r++) { for (int c = 0; c &lt; cols; c++) { printf("%.2f ", arr[r][c]); } putchar('\n'); } } int main(void) { double foo[ROWS][COLS] = { { 1, 2, 3, 4, 5}, { 5, 4, 3, 2, 1}, { 3, 4, 5, 1, 2}, { 2, 1, 5, 4, 3} }; print_array(ROWS, COLS, foo); qsort(foo, ROWS, sizeof foo[0], comp_array); puts("Sorted:"); print_array(ROWS, COLS, foo); return 0; } 
Asserts do absolutely nothing in release builds. They mainly help the programmer - during debugging - to validate invariants about the program. 
&gt; I'm more concerned that you can't reliably set break points inside &gt; these functions as each module has its own copy. I hardly ever bother running GDB on optimized code. Far too much information is lost and GDB becomes pretty worthless (e.g. "value optimized out", etc.). So if I'm using GDB, optimizations are mostly or completely disabled, and so the inlining goes away. I've never had reasonable results with `gprof` so don't use it. I either use Linux `perf` or roll my own profiler. &gt; so I can have a single copy of the library on the system and package &gt; management can update the library A big part of what I like about header libraries is that they work well in the absence of a package manager. Sometimes I simply need to support Windows, as awful of a computing environment as it is, since that's where some/most users will be running it. When I use header libraries, I can just `make CC=x86_64-w64-mingw32-gcc` and be done with it. Even compiling with Visual Studio (`cl.exe`) can be reasonable. &gt; To prevent this, libraries generally put each function in a separate &gt; translation unit. A few do (musl comes to mind), but most do not. &gt; You can also compile with `-ffunction-sections` and link with &gt; `-gc-sections` to get the same effect. Exactly what I meant about header files being so simple to build. You get this feature for *free* from *any* compiler without relying on special, compiler-dependent flags. 
&gt; I hardly ever bother running GDB on optimized code. Far too much information is lost and GDB becomes pretty worthless (e.g. "value optimized out", etc.). So if I'm using GDB, optimizations are mostly or completely disabled, and so the inlining goes away. You haven't understood the problem. Because each function in the header file is static, setting a break point on a library function defined in a header-only library either doesn't work or sets a break point to only one instance of the function, leaving all other instances without a break point. There isn't really a way to get around that. Likewise, there is no symbol interposition with static functions so you can't shim these functions with a preloaded shared object to analyze the program's behaviour. &gt; Exactly what I meant about header files being so simple to build. You get this feature for free from any compiler without relying on special, compiler-dependent flags. It's a bit ridiculuous to talk about unused functions being excluded in header-only libraries while at the same time maintaining that the ridiculous amounts of code duplication do not matter. &gt; A few do (musl comes to mind), but most do not. That's because you typically use shared objects so this issue doesn't really matter. Implementations of the libc traditionally do this because dynamic linking wasn't a thing back in the day and the design has proven to be useful. &gt; A big part of what I like about header libraries is that they work well in the absence of a package manager. Sometimes I simply need to support Windows, as awful of a computing environment as it is, since that's where some/most users will be running it. When I use header libraries, I can just make CC=x86_64-w64-mingw32-gcc and be done with it. Even compiling with Visual Studio (cl.exe) can be reasonable. I don't really care about POS systems like Windows, but even there it's easy to just ship a bunch of DLL files with your application.
Note that this subreddit is specifically about programming in C. You might find better resources for programming in general in /r/learnprogramming.
I'd like to test this ... however I will drag it into an Oracle server and see what happens with the Oracle Studio compilers. They can be horrificcally (sp?) strict.
yes. your guess is correct
Thanks will go there
&gt; Edit: I apparently can't do newlines on mobile :( Put 2 spaces at the end of the line Line 1 Line 2 I just did that on mobile 
It's a quick and dirty way to produce two lines of text, each followed by a carriage-return/line-feed pair.
Programming Assembly from a phone keyboard is pretty hardcore :)
declarations before main, definitions after main
That's what I tried :/ Line 1 Line 2 
Oh, that worked. Maybe it doesn't work with backticks
Depending on your compiler version, gcc will give warnings on missing prototypes, if the functions are not static and not defined before calling them. For simple, single source programs it's ok to skip prototypes, but you have to order the functions so that a function is defined before it's used. For anything more complex, you should declare prototypes in header files (.h) and define the functions in source files (.c), including the headers where needed.
It deosn't even support Unicode? Why did you even waste your time?
I'm typically lazy and simply define my functions such that each function is defined before it is called, removing the necessity for separate declarations. Do not rely on calling functions without prototypes, that's bad programming style and can hide a bunch of errors.
This is a simple project that contains generic macros that produce strongly typed HashMaps. I made it to help with another project I'm working on, but I though I'd share this portion in the hopes that someone will find it useful.
&gt; declarations before main, definitions after main @Medww , that's an unnecessary anti-DRY pattern, I avoid it when I can (not that I always can). I much prefer declaring public API functions only (in a separate header) and than writing definitions by order of first use (which helps me avoid separating the declaration from the definition). Also, I consider function declarations as part of the documentation. IMHO, missing prototypes should be considered an error when writing new code. Sure, its _allowed_ for historical reasons and backwards compatibility, but that doesn't make it right. As a side-note, I think most of the functions I write are defined as `static`.
I keep thinking of starting a subreddit just for people to post comments to test formatting. Then, when it's right, it can be copied /pasted. 
from time.h **time\_t** **mktime(struct tm\*** *ptm***)** **double** **difftime(time\_t** *timer2***, time\_t** *timer1***)** 
I enjoyed reading the readme and the benchmarks, I also had fun peeking through the code (very well organized). However... Whenever someone asks me "_why doesn't C have a standard library with Strings and Hashes and Arrays_...?", I point at the standard library in C++ and ask "_do you want everybody using that?!_" Seriously, the standard library in C++ is a generic solution, and as such contains a lot of compromises. I wonder if you couldn't have benchmarked your library against something more relevant, such as the [Simple Dynamic String (SDS) library](https://github.com/antirez/sds)...? 
Nice! But he was asking for 200 to 400 lines on one file, so the separate header doesn´t apply I think.
Wrong sub. This is for C, not C++.
srry moving it over.
If you have a large bunch of values and data that the CPU is going to be dancing around in an unpredictable manner then you simply cannot avoid cache misses. However, you can create your own pool allocator that just grabs a huge chunk of memory and allocates from it like a linear array - always re-using the bottom-most free slot. Then, if you process everything linearly each 'step' from the beginning of your pool to the end you'll be maximizing cache coherency and minimizing misses to near-zero.
You're right. I didn't give enough attention to that last part.
It's not the size of the pointer, it's the size of what the pointer points to. It reduces the risk of forgetting to change the allocation size if you change the type, and it is often much shorter (e.g. `sizeof(*sain)` instead of `sizeof(struct sockaddr_in`).
Just tried it out and yes, I'm dumb, they're obviously both the same size. I'm gonna use the \`sizeof(\*foo)\` syntax from now on, thanks for your clarifications!
While you can't compute different points in time on different threads it would still help to calculate each tick with multiple threads since during a single tick the new positions and velocities are based only off the old ones so you could still see a benefit there.
Another Brandon Sanderson fan who writes C? I wonder how many of us lie in this beautiful section of a Venn diagram.
I would disagree that the STL is in fact performant by design, and nearly all the optimizations done in this library could be adopted in `std::string` implementations, they just haven't been done yet. Either one is still blazing fast, a few nanoseconds for a concatenation beats c strings by a landslide. As for SDS, I originally tried to compare against it, but the library can't be compiled in C++ (no google benchmark), depends on GCC extensions (no testing other compilers), isn't well maintained and the few tests I managed to do were 15x slower than `rapidstring`, making the charts look lopsided, so I excluded it.
You shouldn't really manually cache data because that makes the CPU's own cache less effective. Progress like this: 1. use a profiler like `pprof` from Google to identify the hot spots of your program, i.e. the places where it spends most of its time 2. in your hot spots, try to avoid dynamic memory allocation (i.e. calls to `malloc`). Especially with mathematical code it is usually easy to allocate all the arrays you need once and then reuse them for the rest of the program. `malloc` isn't a fast function and shouldn't be called in hot loops for best performance. 3. as an absolute micro-optimisation, use `__builtin_prefetch()` to prefetch data you are soon going to need. The best place to prefetch is hard to tell and prefetching correctly is an art, not a science. Try to fiddle around with it and profile to find out how effective your prefetching was.
 time_t mktime(struct tm *ptm) double difftime(time_t *timer2, time_t *timer1) FTFY
Probably ought to be a section dedicated to this on coppermind. 
It supports unicode just fine. If you think that wchar_t, TCHAR, or the UNICODE define on windows are necessary to support unicode, you are part of the problem.
Look at FILE\* pointers and fopen() and related functions FILE \*fp; FILE \*fopen(const char \*filename, const char \*mode); //Function prototype for fopen fp=fopen("test.txt", "w"); //This creates an emptyfile named test.txt in the directory. The second argument can be changed depending on your needs w - open for writing (file need not exist) a - open for appending (file need not exist) r+ - open for reading and writing, start at beginning w+ - open for reading and writing (overwrite file) a+ - open for reading and writing (append if file exists) Remember to use fclose() to close the file to switching modes.
https://docs.microsoft.com/en-us/visualstudio/vsto/how-to-programmatically-create-new-documents
Check out this presentation. It's titled C++ but it 100% applies to C. * [CppCon 2014: Mike Acton "Data-Oriented Design and C++"](https://www.youtube.com/watch?v=rX0ItVEVjHc) The most important thing you can for your problem do is back your data into a tight, regular array. Don't use loose, separately-allocated structs like you would in OOP. struct body { float x, y, x; float mass; }; /* Bad */ struct body *bodies[N]; bodies[0] = body_alloc(...); bodies[1] = body_alloc(...); // ... /* Good */ struct body bodies[N]; body_init(bodies + 0); body_init(bodies + 1); // ... /* Also good, very SIMD-friendly */ float x[N]; float y[N]; float z[N]; float mass[N]; // (some other initialization) With this data-oriented layout, using SIMD instructions you could process 4 or even 8 bodies at once. That's essentially a 4x or 8x speedup, still just single threaded. To actually address your question, in general don't bother caching your intermediate values, especially when they're cheap to compute. Just recompute them as needed, since that's much faster than cache misses. 
getPrime/isPrime should be get_prime/is_prime or something like generic_map_get_prime/generic_map_is_prime. For some reason it not matching bugs me.
that's great and all but that uses C# and (I think) windows exclusive stuff. The last part where they add a template based on a local document does make me think that I'm at least not completely wrong with thinking about just copying an existing docx
I if use `assert`s to debug/test *my* code, I don't want to enable the `assert`s in a library because it is another bloody single header 'library'. 
This sub is about C. Perhaps you meant /r/cpp_questions?
Oops! Ya I did thanks 😂
&gt; anything that ONLY teaches me the knowledge I need for this This is hilarious.
I am very lazy
&gt; windows exclusive stuff &gt; docx That's the game you are playing though. Play with Microsoft only file formats and you get to work in Microsoft only environments. You could try something like this: https://github.com/DocxFactory/DocxFactory But I don't know how well it works. 
Why not? This one of the ways that single header libraries really shine. Its assertions are enabled and disabled along with your own, so you reap all the benefits (extra help catching mistakes in your own program) at no cost (no separate debug build of the library). I literally cannot think of a negative to this. 
docx isn't microsoft exclusive, it's an open format. As far as that project goes I found it as well but my issues with it are that it seems to be dead since it hasn't been modified in two years, the website is down and the domain is up for sale. It also from what I found only supports creating docx files from scratch, which is really limiting. It's also a c++ project so still doesn't fit even if the above issues were all gone. docx is just given because that's the file format I'm working with. The answer doesn't necessarily need to revolve around docx, I'm just wondering how does a program go about creating a blank file for a certain file format.
&gt; creating a blank file for a certain file format What do you think a "file format" is? Creating a blank file is trivial. You can just fopen() a file that doesn't exist and tada you have a blank file. &gt; docx isn't microsoft exclusive, it's an open format. [That's just not true](https://en.wikipedia.org/wiki/Office_Open_XML#Licensing). Where have you heard this?
Thank you for posting this. I've been learning C on and off and got to basic macros. I knew there was a way to use macros to write data structures generically, and this code is the perfect blueprint! I just read through this project and was able to make a breakthrough in a for-each loop I'd been stuck on. No matter how I researched generic types in C it was always met with unoriginal responses like "wrong tool for the job" or "read this PDF". Generic types don't have to BE generic, they just have to SEEM generic. When people ask about this, they're really trying to say: "how can I write a generic type algorithm once?". It took me two years of learning C in my free time to find your project, which answers that question. Thank you!
If `a_string` doesn't have a terminating `'\0'`, calling `strlen` on it is undefined behavior. The example you posted only works by accident: `strlen` is going past the end of the array, finding a zero byte somewhere else in memory, and assuming _that's_ the end of the "string".
Hi,
The assertion is fine as long as a_string isn't determined at runtime. If you compile with the NDEBUG flag set, assertions won't be checked and you may end up with undefined behavior because the user typed an extra long string into the console or something.
Except the fact that you didn't add any `'\0'` at the end of `non_string` which make your code having an undefined behaviour as Snarwin said, you can init `non_string` with the function `memset` or with the designated initializers which is a GCC extension(`char non_string[64] = {[0 ... 63] = 'a'}`) 
"Not determined at runtime" is important, indeed. Thanks!
You could change the declaration to take `char const a_string[static 33]`. Then you could write your own length checking function could always safely loop over the string, failing if it reaches `a_string[32]` without finding a `Nul`. Of course, this means callers can't pass it anything with less than 33 chars allocated. Also, to init `non_string` to all `'a'`'s you could use `memset`.
Thanks for the comments. My code will not use runtime generated strings so I'll be fine, but how about cases when you are fetching strings from a file or stdin and need to make sure they are actually \0 terminated strings and are the right length? I guess one would add a /0 at position 32 of the array and go from there. What is a good/usual practice for this? Any code examples/good practices worth looking at? 
 s-&gt;heap.buffer = (char *)RS_REALLOC(s-&gt;heap.buffer, n + 1); Why do you not check for NULL?
Looks really cool. Now I'm tempted to download it and edit a .bas file with it.
Awesome! Go on and make it usable! If you also add support for modern features (eg git/GitHub/cmake/make) I think i would actually could use it!
Seek smarter algorithms, not incremental hacks on the use of the hardware. Research efficient n-body problem simulators, there is plenty of literature on this.
C macros get a lot of crap from some programmers (in school we had a professor who used to tell us to avoid them like the plague for some reason), and I believe that can be true, especially in cases where the programmer isn't skillful enough to make them work properly. However there's cases such as this library, or the kernel's linked lists that work in similar fashion, where their utility really shines through. They might not be as elegant and easy to control as templates or generic constructs in other languages, but at least they are more flexible.
I have been declaring my static functions only in my .c files - right at the top - as I see no need for them to be declared in the .h, as they don't form any part of the public API. Is this bad practise?
Can I ask why DR476 is useful? Sorry if that's a stupid question!
Here is a quote from the documentation: &gt;The simple truth is that nearly all applications brutally fail either way when memory runs out, and rapidstring takes advantage of this by never checking whether allocations succeed. If your application must handle allocation failures, you may set errno to 0 before calling a function that either intializes or grows the heap buffer, and then check errno after this call. All modern compilers will set errno if malloc() fails.
A problem with your implementation is that if there is insufficient memory, the buffer `s-&gt;heap.buffer` is already overwritten with `NULL` before the client can check `errno`. Thus, you have a leak.
It's also a rather impractical limitation. With no information about what you're expected to know, it is impossible to know what is needed and what isn't. As a gross example, the class definition could be class SolveRubiksCube { // omitting tedious stuff that would likely be included void Randomize(); // set an initial random state void Solve(); // show rotations needed to solve }; This could require you know know the rules of Rubk's cube, possibly matrix rotations, etc. Or, the class definition could be class ChessBoard { struct location (int rank, file}; // omitting tedious stuff that would likely be included void MovePiece (location&amp; from, location&amp;to); //ensure legal move } Which would require details on all the moves of chess. 
You’re doing it fine, it’s exactly right... Personally I would avoid declaring the functions at the top of the .c file as well, unless I have to. By placing the functions in order of first use (when possible), it’s possible to merge the declaration stage with the definition stage, so the information doesn’t have to be repeated (keeping the code more DRY). However, this is just my personal preference. Different projects have different conventions and some prefer declarations on top. 
It makes `volatile` be a property of a memory access, not of an object. Thus you can decide when to access objecta as volatile and when not and have defined casts between volatile and non-volatile objects which always worked but were technically a bit undefined.
Okay man take it handy, I’m only trying to pass a test 😂
This is cool, I have so many fond memories of EDIT from back in the day. I do have to ask - pardon my ignorance - if you didn't use ncurses, how did you manage the UI?
This was on my list of projects to make one day but you’ve probably done it better than I would’ve. Well done!
C++ is off topic in this subreddit. Please post C++ questions elsewhere, e.g. in /r/cpp_questions.
Yes, of course. I've done it by building one thing on top of another. First, I needed ANSI functions to paint on the terminal and set the cursor in the right position. Then, I've used a representation of the screen in memory (single linked list) so I could have greater control of the display. This buffer is used as an intermediary step. That way, I can show a pop-up window and then recover what was behind the window. Everything printed on the screen is first updated to the screen buffer and there is a fallback buffer to recover previous screens (another copy in memory). Also, with another linked list I was able to create menus by moving pointers and finally a listbox with scroll - that was fun to think about but also hard. I got a lot of "segmentation fault" messages in the process.
The corresponding standard is a red herring. Microsoft Office does not actually generate documents that follow this standard and implementing the standard won't help you generate or render Office documents. It's a sham, really. If you want to generate documents users can edit in Word, the easiest way is probably to generate RTF documents. That should just work.
Thank you for your comment. It means a lot to me. I'll try to make it usable as soon as possible and think about adding the features you've mentioned.
Thank you, not yet fully functional, though. I'll keep working! 
On using Google to search for "ADT in C", "ADT (Programming)" and other related terms, I have been able to get short and good explanations on what ADT is. Since there is [no such thing as a stupid question](https://en.wikipedia.org/wiki/No_such_thing_as_a_stupid_question), [this link](http://bfy.tw/JBbU) is the best I can help you regarding this. If your question is generic to programming, try r/AskProgramming or r/learnprogramming. Both communities will help you. 
By linked list, do you mean a list of screen buffers? If so, how are terminal resize events handled?
Yes. There are two screen buffers. The first one is the primary and the other one is a copy of the previous one to be used as a fallback buffer. Each "pixel" on screen is represented as a cell that stores the character contained in that cell along with its color properties. These "cells" are the ones linked in a dynamic list in memory. The main loop of the program is running non-stop always asking for the screen dimensions. If these change, the buffer is removed from memory and another one is created with the new screen dimensions. And then the screen is repainted. I have a post in my blog with an image that may be useful to understand: [http://oldstuff286.blogspot.com/2017/09/a-very-simple-screen-double-buffer.html](http://oldstuff286.blogspot.com/2017/09/a-very-simple-screen-double-buffer.html) Thank you for your comment.
So it's basically a memory optimization of classic double buffering?
Thank you very much! I'll look into those issues with BSD. I also have to improve on the keyboard handling. Little by little. I really appreciate your feedback.
Yes, that's the goal I had in mind. It might not be that optimized, though. I'm still learning. Thank you!
@johnnyboyer, Two things: 1. Thank you for the inspiration. 2. Memory concerns. **Thank you for the inspiration** First I wish to thank you for the inspiration. I had a String library as part of a Dynamic Type library (for JSON and network purposes)... but it wasn't independent. You inspired me to extract the code into [a single header core String library](https://github.com/boazsegev/facil.io/blob/8845146cc0c09e4b2cbd9250a4cc98bbb711e24d/lib/facil/core/types/fiobj/fio_str.h), much as I previously did for the [Dynamic Array](https://github.com/boazsegev/facil.io/blob/8845146cc0c09e4b2cbd9250a4cc98bbb711e24d/lib/facil/core/types/fiobj/fio_ary.h) and [Dynamic Hash](https://github.com/boazsegev/facil.io/blob/8845146cc0c09e4b2cbd9250a4cc98bbb711e24d/lib/facil/core/types/fiobj/fio_hashmap.h) libraries... I doubt if it works for C++, but these are C libraries, so hooray and thanks 🙏🏻. Oh... and I don't know, but it might be faster... won't know until we test 😉 **Memory concerns** I couldn't help but notice that your library assumes String growth (by a factor of 2) with developer invoked "shrink". I should probably point out that not all allocators return memory to the system after a `realloc`. In fact, many of them ignore `realloc` under some conditions while others might hold on to the "free" memory at the price of memory fragmentation. Would you consider assuming the developer will pre-allocate a large enough capacity using `rs_reserve` instead of preemptively assuming the developer will relinquish control over this optimization? Also, would you consider that a developer that doesn't observe the String's capacity for manual optimization might not call `rs_shrink_to_fit`...? Just my 2¢.
Do not use assert for checking user input. assert's role in life is to guard against programmer error. If you want to guard against bad user input, you need a proper if-statement for that.
Why in the world would anyone want this?
It might be a good idea to use the termcap interface through its functions `tputs`, `tgoto`, etc. instead of directly emitting control sequences. This allows your editor to work with multiple different terminal emulators. If you have any questions about this, I can help you. Terminals are scary and weird but it's not actually all that difficult.
What is the benefit of making a generic hashmap this way over using a void* style hashmap? I made one and the interface looks like: int hm_hashmap_init(hm_hashmap_map* map, unsigned int data_elem_size, unsigned int initial_size); int hm_hashmap_push(hm_hashmap_map* map, const char* key, unsigned int key_length, void* elem); int hm_hashmap_get(hm_hashmap_map* map, const char* key, unsigned int key_length, void** elem); int hm_hashmap_remove(hm_hashmap_map* map, const char* key, unsigned int key_length, void** elem); And then if you want to store an int with a key you would do something like: hm_hashmap_map map; hm_hashmap_init(&amp;map, sizeof(int), 512); char key_1[] = "key_1"; int val_1 = 1; hm_hashmap_push(&amp;map, key_1, strlen(key_1), val_1); int* val_1_get; hm_hashmap_get(&amp;map, key_1, strlen(key_1), (void**)&amp;val_1_get); Is there any reason to prefer the macro type way of doing things? 
OK, you get the current time in a struct of the kind time\_t, so now you know the system time. Then you get the user input and use the struct tm to load this info, thats your user time. mktime() convert the tm struct to time\_t, so now you have the system time and your user time on same kind of structs. Use difftime to take the difference. Last convert again with ctime to get it on more manageable format. Hope this helps
Yours is going to be slow and waste memory, though the OP's library is actually not much better due to modulo and the unnecessary malloc per element.
Maybe for fun or learning purposes?
If I want to test *my* code, I don't want to have uncontrolled, undocumented, spurious output (or aborts) from a library messing with mine. I don't know, isn't that a simple principle?
The asserts only abort or produce output if you pass invalid arguments. The only alternative is silent, undefined behavior.
I'm not OP. I just tried to help by formatting your code samples correctly. To format code as code, either put it in line surrounded by backticks (`) or put four blanks in front of every line of code (as I did in my previous comment).
In practice, the macro lets you use any type as key, not just a string, which was important to me. It also allows keys and values that aren't pointers. So you can map `const char*` to `int`. On a personal level, I just prefer the type safety that my implementation gives. That being said, the best version is the one that works for you :)
Using this specific algorithm, there isn't any way to avoid the modulo unfortunately, but for my purposes it works fast enough. Could you guide me in the right direction to avoid the malloc though?
&gt; there isn't any way to avoid the modulo unfortunately There is: power-of-2 or [Fibonacci hashing](https://probablydance.com/2018/06/16/fibonacci-hashing-the-optimization-that-the-world-forgot-or-a-better-alternative-to-integer-modulo/). &gt; Could you guide me in the right direction to avoid the malloc though? Use `typeName ## _Cell_* cells;` (one astroid, not two). You might think this wastes memory, but in practice it may reduce memory because 1) heap allocation often has overhead especially when the heap is fragmented and when you allocate from different threads; 2) you are wasting 4 or 8 bytes for occupied buckets. Also, you don't need to cache hash. Users can do that by themselves if they prefer.
&gt;I'm not OP Thanks!!
No, to create a blank file you just dump the internal, emty representation of the file. the .docx format is hella complex tho, first off, it's a zip file, and it contains about half a dozen folders, and those folders contain xml files with whatever the hell schema Microsoft uses. Why not use the OpenDocument format? there are already open source libraries for it.
&gt; ocx isn't microsoft exclusive lel, Microsoft literally invented it, and they're the only ones that use it. &gt; it's an open format. It was pushed on ISO, the specs are literally just a dump of the file structures, and it's like 50 megabytes of shit.
Take the user input, then a\_string\[31\] = '\\0'; finally send the modified string to the function
I'd love to use odf but the reason I'm using docx is because I'm making this program for a specific person who uses docx
again though even of Microsoft invented it that doesn't mean it's used exclusively by them and their tool sets. The specs maybe shit but that doesn't mean the specs aren't open to public use
I can definitely use the fibonacci hashing! I'd heard of it but I didn't know what it really was. How could I tell if a slot is empty using that? The hash doesn't need to be cached, but when an element is removed it has to search for the last element with the same or smaller hash and [swap positions](https://en.wikipedia.org/wiki/Linear_probing#Deletion). So if the hash isn't stored each element would have to recalculate.
Doesn't sound like it but there are many far more useful things he could waste his time with.
&gt; How could I tell if a slot is empty using that? Google dense requires a special key value to mark the slot is empty. Alternatively, you can add a flag to `typeName##_Cell_`. Both will be much better than frequent malloc. &gt; So if the hash isn't stored each element would have to recalculate. You can see that as a trade-off between memory and speed. Quite a few hash table implementations do keep hash. However, I prefer not. If you hard code hash in each bucket, users have no choice but to let it take memory. If you don't hard code a hash field, users can make their own choice. If they prefer caching, they can define a key like `struct hashstring { uint32_t hash; char *str; }; #define eq(a, b) ((a).hash == (b).hash &amp;&amp; strcmp((a),(b))==0)`. Hash caching is a special case.
I decided to keep the cached hash, but I implemented the other two features :)
Sorry for my late reply, different timezone. Mostly for fun. Programming is a hobby for me. Nonetheless, you learn a lot of things a long the way that may prove to be useful later on. Proper memory management, how to develop a rudimentary user interface, how operating systems work at a deep level, etc. For example, I can imagine developing a game and having to create a small graphical menu to interact with the user with a list of items. Thank you for your comment.
Thank you for your suggestion. It sounds really interesting. I'll ask you if I need help!
Do your fucking homework. Also, whoever commented here before me, you're shadowbanned,
No. A library is a collection of objects already. Combining objects is called a library, not an object. You could create one *library* that contains all of the objects of another set of libraries, [see here](https://stackoverflow.com/questions/3821916/how-to-merge-two-ar-static-libraries-into-one). But I would recommend not messing with any of the standard libraries. Because if you upgrade your compiler and forget about your mega library then you'll get bizarre errors due to combining updated stuff and old stuff. 
I think you are better off making the array pointer the same type of the things you want to store in the array. They you dont have to store the elem\_size, you cant get it with sizeof() and you get the compiler helping you with type-safety. Take a look at [https://github.com/rustyrussell/ccan/blob/master/ccan/darray/darray.h](https://github.com/rustyrussell/ccan/blob/master/ccan/darray/darray.h) which I think is quite good but not perfect... You can make the code even cleaner if you allow type-punning with a void\* array. This way your \_resize etc functions can be shared across all types.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [rustyrussell/ccan/.../**darray.h** (master → 55d8142)](https://github.com/rustyrussell/ccan/blob/55d814230f7fb628bb5303cd53498209c7928040/ccan/darray/darray.h) ---- 
It'd be easier to either break down and learn how to make a makefile, or just copy an existing one, set some libraries and ld settings and have make do it for you. I mean technically lib's are just ar files, and you can unarchive an archive, get the objects, put them all into a directory (assuming none of them collide) and just ar them into a giant library, but there really isnt any point in doing that. Thousands of years ago (early 1980's to mid 1990's) Microsoft &amp; Borland would basically do that during install, they would build what was known as combined libraries that would have various memory/math/graphic libraries all combined together so instead of SLIBC/MLIBC/LLIBC/HLIBC you would have each memory model (small/medium/large/huge) and each math model be it 8087, emulation or alternative plus adding in the graphics library so yes you would have quite a few of them. So just to let you know there is actual historical context to your request, it's just really not that relevant these days. Machines are substantially faster these days, so there really is no point building combined libraries. Not to mention things get updates so often these days, you really want things in their component state so that updates will happen, and your giant combined library won't be left with stale or worse insecure bits.
&gt; No. A library is a collection of objects already. Combining objects is called a library, not an object. I'm pretty sure the OP is really asking how to statically link their binary (though they may not have been aware that's what it's called). There's a [parallel discussion](https://redd.it/93ccxj) going on over in /r/gcc.
If you only need a vector for a few types, you can easily adapt the implementation for those types with wrapper functions and get type safety, if you need it for a lot of types and don't want to implement wrappers for every type, either you forego type safety, or you use macros as in the example you linked, but IMO macros are harder to read and harder to debug, they don't really fit my philosophy of "minimal".
Yes, you can. You need to proceed like this: 1. use `ar x library.a` to unpack the objects in `library.a`. This gives you a bunch of object files that make up `library.a`. Let the set of objects in `library.a` be `$objects`. 2. use `ld -r -o library.o $objects` to create one huge object from all the objects in `$objects`. Note that while that works, you loose a couple of advantages. Namely, everything from the library is going to be included in your program whether you need it or not. This can generally increase the size of your program substantially. Another thing is that this forces a static link to the relevant libraries which may not be what you want and is generally a bad idea. Note further that for the libc specifically, there are a number of initialisation stubs named `crti.o` or similar which need to be linked, too. These are not part of `libc.a` and their names differ depending on the implementation, so make sure to add them, too.
&gt; I'm pretty sure the OP is really asking how to statically link their binary, I don't get that out of their text "can I link all the object and libraries that gcc automatically link into a single object so i can just link using `ld` later,". They want to make another call to `ld` later, not statically link their binary now.
&gt; I don't get that out of their text "can I link all the object and libraries that gcc automatically link into a single object so i can just link using ld later,". They want to make another call to ld later, not statically link their binary now. Yeah, but the end result (assuming what they were asking was actually possible) would be that the binary contained "all the object and libraries that gcc automatically link into a single object"... which is precisely what statically linking gives you. But maybe I'm wrong. Hopefully the OP can clarify things a bit.
[This is probably a reasonable alternative](https://github.com/andymac-2/c_vector) to what you describe that has both type safety and (sort of) uses macros to create pseudo-templates in C. This means that the functions are not inserted inline like macros, but are individually created for each type you want.
I'd personally just use the [stb stretchy buffer](https://github.com/nothings/stb/blob/master/stretchy_buffer.h)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [nothings/stb/.../**stretchy_buffer.h** (master → e6afb9c)](https://github.com/nothings/stb/blob/e6afb9cbae4064da8c3e69af3ff5c4629579c1d2/stretchy_buffer.h) ---- 
I'm not saying the other approaches are not reasonable, and this one I especially like, instead, this post is mostly about having a very very simple way to build a vector from scratch when prototyping, as I said in the original post, it's not feature complete, and as has been noted by others there are more robust (and typesafe) alternatives, I just don't think any of them are as simple and minimal as this one. I like this example because it exposes plainly all the crucial components of a vector, the implementation you link basically expands to this with a few extra bells and whistles (and doesn't need to copy memory byte by byte since it can use plain copy-by-assignment). The main point wasn't "here is a good vector implementation" but "here is a simple and short vector implementation", it's easy to understand, reproduce and adapt, it's more of an educational device than anything near production level code. Hope that clarifies the intention!
As far as I know, all [GNU software](https://www.gnu.org/software/software.html) uses autotools.
all of them use auto tools. Every time there is a `configure` script, autotools have been used.
&gt; But regardless of that, I want to know if there any projects using autotools? I just went through my local set of Git clones, so this is a bit of an eclectic mix: * a whole bunch of GNU stuff, obviously * Git * Xorg X server * util-linux * libvirt I'm still quite fond of Autotools. I still think it is better for the _end-user_ than its modern replacements.
&gt; Every time there is a configure script, autotools have been used. That's a bit of a broad assertion. Projects can ([and](https://git.qemu.org/?p=qemu.git;a=blob;f=configure;hb=HEAD) [do](https://perl5.git.perl.org/perl.git/blob/HEAD:/Configure)) have non-Autotools-generated `configure` scripts.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://git.qemu.org/?p=qemu.git;a=blob;f=configure;hb=HEAD) - Previous text "and" [Here is link number 2](https://perl5.git.perl.org/perl.git/blob/HEAD:/Configure) - Previous text "do" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
That's a pretty rare occasion. I know that apart from these two, tcc does it the same way, but that's about it.
Move "active" closer to "hash". Your current struct layout may waste 8 bytes due to memory alignment.
I just did [a crummy search](https://codesearch.debian.net/search?q=AC_OUTPUT+path%3Aconfigure.ac&amp;perpkg=1) on Debian's codesearch and got [this list](https://codesearch.debian.net/results/2c40e7cc2aeffde0/packages.json) (JSON) of packages. There's plenty of well-known projects there.
&gt;Namely, everything from the library is going to be included in your program whether you need it or not. This is incorrect. When you statically link, it only includes the code needed for what you've used. This is how statically linked programs with, for example, musl or bionic can end up *smaller* than the binaries produced by dynamically linking against glibc.
The problem is that the granularity for static linking is a single object file. If you pre-link the entire static libc into a single obejct file, the linker only has the choice to take it wholesale or to not use it at all. You can slightly improve this by providing `-gc-sections` to `ld`, but even that is mostly ineffective as `ld -r` actually merges sections as it would do in a normal link, leaving you with a single text section with all functions in it. Note further that due to shared text segments, the binary size being smaller for statically linked binaries is a red herring: when linking statically, the operating system has no way to share different instances of the same library across different process images (text sharing with multiple instances of the same program of course still works), overall increasing memory usage.
Right, I was in the camp that what OP wants is a .a file, rather than a massive .o . Should've made that more clear :)
That video was music to my ears, thank you. There's a philosophy over at the Java community that optimisation is 'not expressive', calve out the fat after you've applied flesh, hair and make-up, the compiler will solve all your problems, pump out immutable objects because why not we have a garbage collector, encapsulate everything because god-forbid anyone knows how anything works. It's nice knowing someone competent thinks that's all total bollocks too.
I would recommend [The Autotools Mythbuster](https://autotools.io/index.html) as a good starting point. The problem is that a lot of the stuff out on the internet about using Autotools is massively out of date, to the point of being flat wrong. 
Ffmpeg and mplayer both have a configure script, but are not using Autotools.
A vast majority of projects use Autotools, a not-so-small minority uses CMake (but luckily part of them kept Autotools in parallel), and a tiny but annoying minority uses crap like Meson. NB: When I say 'luckily', 'annoying', 'crap', that's from a user's (building projects/packages) perspective, not a developer's perspective. 
Autotools is very simple to use if you just need to configure and build. It's moderately simple if you need to create it edit Makefile.am or configure.ac. However, if you need to write a macro from scratch, that's pretty hard. In particular the need to clearly understand the multiple levels of quoting and expansion. But I've only needed to do that maybe 4 times in 20 years.
I see that CMake is horrible from a user's perspective, but what's wrong with meson?
I’m still sorta learning too, but from what I’ve noticed the more you dive into approaching different types of tasks the more familiar you become with what goes around them, like for example in java let’s say you wanna build a game, well first you gotta get the JFrame, then you gotta ask google what the hell a jFrame is, it it all just sorta unravels for ya 
Yes, you are right. I am always trying to Google first before asking people and for the most time, someone else has already answered the question. But for this particular set of problems I could not find the answers I want.
He may have what your looking for he may not, but one youtuber that has a lot of really in depth and sorta advanced C/C++ tutorials is ChiliTomatoNoodle, check him out 
&gt; ChiliTomatoNoodle Alright, thank you! :)
Pretty much all GNU software uses autotools. Personally, I hate it with a burning passion. Autotools is like Sirius Cybernetics Corporation. The satisfaction you get from finally getting it to work obscures the fact that it's as hard to configure and get working as it is to write portable code in the first place. Ordinary makefiles are the worst build system there is — except for all the others. Getting autotools to actually work takes enormous effort building the config files you need to generate the config files to generate the final makefile. And then when you *think* it's working, and you're feeling pretty good about it, that's when you try building on a different architecture and find out that it still needs work. It really is much easier to simply write portable code in the first place, and then a simple Makefile to build it. In extreme cases, I'll write makefiles for different build environments, but usually it's not necessary. I manage a fairly large software package that has to compile under MacOS and Windows both. It took work to get it to compile under either, but it works. Writing portable code is not that hard. There was a time when I was the guy who managed the technical side of Google's open-source initiative (before they went to Google Code). I got it all to build without autotools, although later someone else on the team added the necessary config files, simply because autotools was considered "the standard".
Also another way to just like learn how to do shit is to experiment, like I watched this one tutorial on how to hack a spyro game using C, that’s another cool one 
Autotools configure scripts provide a useful, conventional interface for configuring packages. However, these days *most of what Autotools does for you is obsolete and no longer necessary*. This historical baggage makes for much of the complexity. The features Autotools provides were necessary 20–25 years ago, but, today, unix-like systems are the least diverse and the least buggy they've *ever* been in history. You really don't need to worry that your unix-like system is missing `select()` for whatever reason. Instead of running hundreds of pointless checks for the presence of standard features (GNU Emacs' configure script *literally* checks for `stdlib.h`, `gettimeofday()`, `log2()`, and many more), you can instead confidently rely on the standards and assume they're implemented correctly enough. Document that your software requires, say, C99 and POSIX.1-2001, then assume these features are available without checking. Besides, *most GNU projects don't even use Autotools correctly*. It's so overly complicated that not even the GNU Project itself can wrangle it into submission. Try to configure GNU software in a somewhat unconventional way or environment, and many of them simply fall apart, requiring hacks to get things working properly. One of the best examples of this is the ncurses configure script. It's a huge mess. Unfortunately I don't really have an alternative to recommend. It really depends on the nature of your project. There's CMake, but it has its own unique problems. For small to medium sized projects with simple dependencies (or just no external dependencies), a well-written Makefile is perfectly sufficient, and it doesn't inhibit configuration (e.g. `make CC=... CFLAGS="..." PREFIX=...`). For more complicated projects I've hand-written my own configure scripts, which generates a Makefile from a heredoc and leverages GCC or Clang to discover all the header file dependencies (the tedious part of `make`). It would be quite reasonable to write a configure script in, say, Python if you're not comfortable with shell scripting. 
Sending your own ping packets is a pain so you're probably better off using the built-in ping program, capturing its output, and using scanf to get the ping. You can easily associate the server number with the ping using a struct like this: struct serv_ping { int server; int ping; }; You'll have to declare an array of those, store the ping and server number in each one. your thought process is good, except for the fact that you don't need to sort them, you just want the ONE with the least amount of ping right? You can do that with a single pass over the array, no need to sort it completely. it would look something like this: typedef struct serv_ping { int server; int ping; } serv_ping; int main(){ serv_ping server_array[NSERVER]; char address[50]; for(int i = 1; i &lt;= NSERVER; i++){ server_array.server = i; sprintf(address, "server%d.game.com", i); char *args[] = {"path/to/ping", address, rest_of_ping_arguments}; // do some magic to capture execv's output execv("path/to/ping", args); fscanf(execv_output_stream_handle, format_string, &amp;server_array[i-1].ping); } serv_ping min_ping = server_array[0]; for(int i = 1; i &lt;= NSERVER; i++){ min_ping = min_ping.ping &lt;= server_array[i].ping ? min_ping : server_array[i]; } printf("The server with minimum ping is server %d, with %dms of ping.\n", min_ping.server, min_ping.ping); }
Reminder that the simpler it is, the less point there is in posting it, except when you have a question regarding.
ahh a tool that produces a script 1,000's of lines long, what could possibly go wrong...
Hi. That sounds like a good beginners Programm :) Since you want to learn something and not asking for the simplest answer that may be a little bit of an overkill, but anyway: 1. Have you taken a look into structs now? A struct is basically a complex data type which consists of multiple primitive data types (int, char, pointers etc.). Everything you described just screams for a server struct which holds the server name as a char array, the resulting roundtrip as an int and maybe the ip socket to the server. (I Never done anything like icmp in c so i May be wrong on the IP socket) 2. when you have such a struct you can make an array of structs just like an array of int. 3. have a look into qsort. It’s a library function from the libc where you define a callback function which compair to values. As it just inputs to void pointer you can simply pass your server structs in there and dereference it in the function to make a compairsion on the roundtrip value. This way you learn about structs, pointers and eventually also about memory allocation. That’s many of the important core functionality’s of C. If you want more detailed explanation on a topic feel free to ask. 
This was among the things I've been reading in parallel to the official documentation. I didn't like it. It reads like somewhat structured commentary to the manuals, but yet unrelated. It doesn't even say what misconceptions it is trying to bust. It doesn't have the voice of "Alright, here's what's up with these autotools. It is really simple if you look at it this way and ignore the old stuff". As said in the the preface, at it's core it is a write as you learn guide, although polished over time. I don't know, I didn't get far, so I probably will come back and finish the guide. But it is absolutely not a starting point. I suspect you yourself didn't read it, but just seen a submission on Reddit or HN and now sharing. (I do it all the time...) What autotools really needs is a long project based tutorial covering essential use cases. However, it might not be a good idea to write one, because that would increase the popularity of autotools. I'd rather see tools like Meson have wider adoption because they don't have the burden of legacy.
No. It is not simple! Look at the `configure.ac` and `Makefile.am`s in the [Check](https://libcheck.github.io/check/doc/check_html/check_3.html) testing library tutorial. `configure.ac`: # Prelude. AC_PREREQ([2.59]) AC_INIT([Money], [0.3], [check-devel AT lists.sourceforge.net]) AM_PROG_AR # unique source file --- primitive safety check AC_CONFIG_SRCDIR([src/money.c]) # fairly severe build strictness # change foreign to gnu or gnits to comply with gnu standards AM_INIT_AUTOMAKE([-Wall -Werror foreign 1.11.2]) # Checks for programs. AC_PROG_CC AC_PROG_LIBTOOL # Checks for libraries. PKG_CHECK_MODULES([CHECK], [check &gt;= 0.9.6]) AM_PROG_CC_C_O # Checks for header files. AC_HEADER_STDC AC_CHECK_HEADERS([stdlib.h]) # Checks for typedefs, structures, and compiler characteristics. # Checks for library functions. AC_FUNC_MALLOC # Output files AC_CONFIG_HEADERS([config.h]) AC_CONFIG_FILES([Makefile src/Makefile tests/Makefile]) AC_OUTPUT `Makefile.am`: SUBDIRS = src . tests `src/Makefile.am`: lib_LTLIBRARIES = libmoney.la libmoney_la_SOURCES = money.c money.h bin_PROGRAMS = main main_SOURCES = main.c main_LDADD = libmoney.la `tests/Makefile.am`: TESTS = check_money check_PROGRAMS = check_money check_money_SOURCES = check_money.c $(top_builddir)/src/money.h check_money_CFLAGS = @CHECK_CFLAGS@ check_money_LDADD = $(top_builddir)/src/libmoney.la @CHECK_LIBS@ There's no way I can come with this structure on my own from scratch having only the manuals, the mythbuster and that slidedeck. It is complex. And then it spits out more than a dozen files in the project directory. All with similar names, like `Makefile.in` and stuff. 1. First of all, some of the macro used in `configure.ac` is deprecated. Do you know which one? I forgot. 2. What the hell is `@CHECK_CFLAGS@` and `@CHECK_LIBS@`? Why is it surrounded by `@`? I know it is a special construct that gets substituted by something (what exactly?), but still. I have to know. 3. Why is there a dot in top level `Makefile.am`? Why `src`, then `.`, then `tests`? The tutorial claims order is important. I don't know why. 4. What does `*.la` files mean? It is probably C thing, but I'm still learning. 5. Why do I need exactly these macros? How can I find out in advance that I need to use `AC_FUNC_MALLOC`? I have questions like that in my head. It's not that I don't understand the concepts, it's that it is difficult to imagine myself generating all of this on my own. And this is very basic example. If I wanted to create something consumable by others, it would be a large obstacle to overcome.
I would recommend on using a library for ping (icmp) instead of using execv to a ping binary. Parsing output of a Programm out of your control can break thinks pretty easily. Imagine the output chances after an update or a server goes down and you need to parse the errors. 
Hi, thank you for the comprehensive reply. I have not taken a look at structs, I will immediately check how they work now. Yes, servers have an upper limit. New servers are rarely added but then I can update it manually so a static array sounds good. I do not need to store every information about every server so your suggestion about keeping only the fastest server sounds much better than having them all saved and listed/sorted. Finally, I do not specifically need to sort them. Saving values then sorting it was the first thing to came to my mind because that's how I approached a similar problem before when I was studying Python. Sort then choose the value from the list. Again, updating a pointer sounds better than my solution. I will eventually try to get both ways to work but it feels like making the program optimized, well-written and simple in the first place should be my priority so I make a habit of it :) Thank you again, I will take a look into these.
from my limited understanding you need a raw socket to ping, and that requires superuser privileges, and then you need to manually craft the ping packet and parse the response, that seems a lot more involved all for a little extra stability. I wouldn't consider this as a first approach, seems like OP just wants to whip up something that works, if stability is a concern I'd look into manually pinging using ICMP at a later time.
Thank you so much! Yes, sorting them makes less sense now after I have seen other solutions. I will try to learn and understand structs and how your code works.
feel free to ask any questions, I kind of assumed you had good understanding of most of the language's features since there's are so few (compared to other languages), but in another reply you said you hadn't looked at struct yet so some of this stuff may be too advanced. structs are kind of like classes in python, except they can't have "methods", it's just a way to have multiple pieces of information associated to a single identifier.
Yea doing it by yourself as a beginner is much more complex and error prone way than using exec. But there should be library’s out there, which already implements icmp or a subset of it like ping. Depending on the interface using a library should be a good trade off between stability and complexity. Since the libs probably also need raw sockets the part about „running as superuser“ is still relevant. It’s on you to decide if you want someone else’s code as root. If you don’t know what the code exactly does it may be better to not do that. 
Try to imagine how your program will evolve in the future! Maybe you add more functionality like an interactive command line to print information about the server ? Its not always an bad idea to keep a little bit more information in the beginning. Also since you don’t want to alter your code anytime a server is added I would suggest to not use a static array. Ever heard about linked lists ? You can implement them pretty easy by adding a pointer to the next server in your server struct. This results in a chain of servers which can be extended by just adding a new struct at the end! To downside is access time. A static array can be accessed directly where you have to iterate over the chain to reach a specific server. 
 $ ./configure $ make # make install I love it! I just wish I knew how to write the necessary scripts for it....
It looks confusing, but I bet it's quite doable after a little bit. Just like regular makefiles.
If you search ["configure.ac"](https://github.com/search?q=configure.ac&amp;type=Commits) on github and see how many commits are related to it, number that pops out is 1.7 million. Obviously it's a poor metric of how many projects do use it (some might not be counted if their commit message never contains that string, some projects might have several commits related to it); nevertheless I think it's fair assumption that number of projects that use autotools is 5 figure number.
What makes CMake bad for user? I've not had problems with it the few times I've used it.
Both autotools and cmake are nice from user perspective I think, in guneral you are 3 commands away from compiled and installed project. What makes autotools (and to much lesser extent CMake) bad is extremely steep developer learning curve for non trivial projects, slowness (CMake is pretty nice, autotools is horrendous) and bunch of weird quirks that come into play over time (broken builds if you update dependencies or compiler and things of that nature).
Ok maybe not that bad. But things like no compiler optimization by default (or if you make a typo in `-DCMAKE_BUILD_TYPE=Release`), no "make uninstall" and the whole confusing concept of cached variables (some by cmake, some overridden by the project) give the impression that cmake is primarily meant as a tool for developers who want to release binaries.
I really recommend the book by John Calcote called Autotools: a practitioners guide https://www.amazon.com/Autotools-Practioners-Autoconf-Automake-Libtool/dp/1593272065 I had the same problem. After reading some of it I had already understood most of the parts I was struggling with.
The worst thing in my opinion is that you get a project with autotools and you can compile it without even knowing what IS autotools (Readme, configure --help, etc.). If you don't know how to use cmake you depend on the creator to leave a Readme with some examples, or you are lost. Cmake online documentation, however, is quite good. But it is targeted at developers, not users.
A growth factor of 2x is a bad choice. 1.5 would be better and is easy to implement with just integer math. If you grow by 2x every resize, then you will never be able to reuse previously allocated chunks of memory. Growing at 1.5x allows that.
[relevant for people who haven't looked into growth factors](https://github.com/facebook/folly/blob/master/folly/docs/FBVector.md) If you want to use 1.5 or 1.3 use 3/2 or 13/10 in the define without parentheses (this will do v-&gt;capacity*3/2, which is left associative and will work fine), additional precautions may be required with large elements to avoid integer overflow.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [facebook/folly/.../**FBVector.md** (master → b3aee94)](https://github.com/facebook/folly/blob/b3aee940b418996cbb65777365bda30f9d754a13/folly/docs/FBVector.md) ---- 
really old ones do, the top example off the top of my head is FLAC. it's a PITA to use tho, seriously don't use autotools, it's not nessicary anymore. just use cmake, or even your own hand written makefile, anything but fucking autotools.
Don't forget brew install autotools brew install automake brew install libtool ./autogen.sh ./configure make make install is much more like what it actually takes to compile a project that uses autotools.
lel, not even close to most.
Why not just statically link it?
Why not link the library into another library? I do that literally all the time with my dependencies...
That's also not true... What the shit compiler are you using? Clang does not do that, and AFAIK never has.
The compiler is not the linker and you can't enable LTO on already compiled code.
What's the granularity? milliseconds, picoseconds, nanoseconds?
just like regular everything when it comes to more complex programs apparently. It doesn't really matter which language it is. It's too repetitive. Let's add a little bit more complexity to the build. Except the only guy who reallllly knows how to use the build framework is the one that built it. Or the one that has a few months to years full-time experience with it. Oh and also for every new program you're still writing a ton of boilerplate again, and again. Or copy-pasting your old boilerplate and adjusting a few things. i don't like make, i don't like cmake, it's as simple as i don't want to learn yet another language to make my shit compile. even dealing with maven is a pita just beacause now it's not a language you need to learn but a structure. fuck at least intellij has maven autocompletion integrated
if there is no bug, it should be nanosecs. I will re-test this later. **tm\_interval** which is **double** represents seconds. You can specify half second by 0.5 or 0.0005 or nanosecs by 1-e9... It uses **mach\_absolute\_time()** on macOS, **QueryPerformanceCounter** on Windows and **clock\_gettime(CLOCK\_MONOTONIC, &amp;ts)** on other platforms e.g. Linux. &gt;can you just write one once and use it anywhere This is correct. But linking process me be different, GCC/Autotools, Xcode vs VisualStudio :) Users do not need to specify any **#ifdef**s. If you mean me, yes there are **#ifdef**s for checking for platforms. But after included library like **#include &lt;tm/tm.h&gt;** you do not need to check platform. All are hidden in source files (not in public headers). It also provides **tm\_sleep(tm\_interal interval)** in nanosec accuracy (almost nano): [https://github.com/recp/tm/blob/master/include/tm/sleep.h](https://github.com/recp/tm/blob/master/include/tm/sleep.h) actually it is a wrapper for nanosleep on POSIX systems and simulate it for windows. This will help to use cross-platform nanosleep with simple interface. On Windows it may not be nanosecs (1e-9) instead it is 1e-7 if I remember correctly (according to MSDN, because it uses SetWaitableTimer). 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [recp/tm/.../**sleep.h** (master → ce34702)](https://github.com/recp/tm/blob/ce34702c21bb0b77250d693f91b6042b628d3189/include/tm/sleep.h) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e3dd5u8.)
As bumblebritches57 said, statically linking is a good way to take some of the pain out. If that's not possible, you'll want to build libusb for each platform and architecture that your cross platform project supports, and include it in your distribution. Is this likely to cause an issue with some licenses? I'm not very savvy when it comes to this bit. The least attractive alternative is to _assume_ that whatever library your project needs is already installed, or that the users are savvy and patient enough to hunt it down and install it somewhere the loader can find it. Static linking and providing a library that can be loaded (and replaced) each have their benefits, so you'll have to weigh up the pros and cons yourself. I don't think there really is a "best way", it depends on the project; I'd suggest either building and bundling libraries needed for dynamic linking, or statically linking with equal weight to the both.
If you've got experience with a language like python, Simon's [Descent to C](https://www.chiark.greenend.org.uk/~sgtatham/cdescent/) is an excellent resource. Prepare to devote a lot of time, C is a very rewarding language but has some points that can be difficult to grok. I personally refer to the [C section of cppreference.com](https://en.cppreference.com/w/c), I think it's a very helpful resource. As you've got a linux machine and mentioned you wanted to play with the OS, become comfortable with the manpages. `man 3 fopen` will provide you with the C library manpage for `fopen` (and associated functions). Tackle a small project using networking (e.g. following Beej's guide) and you'll quickly become more adept. If you can stomach it, I would _strongly_ suggest reading through the [comp.lang.c FAQ](http://c-faq.com/). Just work through bit by bit, googling for things you don't understand. Make sure you have gdb; Become familiar with it and other tools for analysing your programs, e.g. valgrind. I personally would suggest avoiding codecademy and other similar tools where you have rely on software validating your own. Have some fun and create something yourself. Why not a barebones HTTP proxy? Or a telnet client? Or netcat?
Since all timers are running in a background thread, if timer callbacks need to access a resource on main thread then thread sync is needed, e.g. mutex, rwlocks... because callbacks are always called in runloop's thread not in main thread. It seems there is nothing to do about this Any better suggestions about this?
&gt; I realize it's all necessary due to the complexity of programming but fuck I so, so wish it were simpler Then try to make your own build system. Pun intended, of course :P
Thank you very much for this thorough answer! Much appreciated!
I was definitely in the same boat as you with python. I resisted C language when i first started learning computer science and programming. I wised up and decided to buckle up and truly understand C language like I did with Calculus while leaning physics, algebra was just not making it all click for me. Calculus dramatically improved my way of interpreting data and C language dramatically taught me how to think through using that data correctly with computers. besides the random youtube videos, I used MIT and Harvard open courses to learn. I'm pretty old school and I like books so this was my bible for awhile and i always keep it on my desk [https://www.amazon.com/Programming-Language-Brian-W-Kernighan-ebook/dp/B009ZUZ9FW](https://www.amazon.com/Programming-Language-Brian-W-Kernighan-ebook/dp/B009ZUZ9FW)
Thanks! I got it a few days ago, seems like a great book so far!
Hello, I implement a very similar thing in basically all my projects and like you, I like to keep it as minimal and simple as possible. I have two small remarks: - `realloc()` could return NULL if its size argument was 0, but in that case, a return of NULL should not be considered an error, since the call is equivalent to `free(ptr)`. - in `vector_free()` I would also set `v-&gt;array` to NULL. Also I have a question: in the example, you don't explicitly set `v-&gt;array` to NULL (nor size or capacity to 0). Will it be implicitly set to NULL thanks to that c99 (I don't remember the name) `struct` initialization way?
I second descent to C. Very useful concise guide. Also the time thing as well. Taking your time learning it is as fundamental to the language itself. It's not meant to be python fly around and have everything up and running as soon as possible. C language is tedious and frustrating. I used to think there was no reason to learn C, and now I feel like i was smoking in a room full of oxygen programming without knowing it lol
autotools is overkill for 90% of projects IMO. just use good old Makefiles or sexy Mkfiles
No it does not. Tha is needed for developing a project that use autotools, not compiling it. 
Why is that bad practice, out of curiosity? How does it lead to errors? Is it something to do with some quirk of C?
If you do this the compiler can often not catch you passing arguments of incorrect types leading to errors that are challenging to diagnose.
&gt; No it does not. Tha is needed for developing a project that use autotools, not compiling it. Exactly. Unfortunately (or fortunately, depending on your point of view), a lot of software is shipped to the end-user as Git repositories nowadays, rather than tarballs, which means they're forced to put themselves in the shoes of the developer and have all the developer tools on hand. Autotools-generates tarballs do not require the end-user to have Autotools installed.
Maybe try to actually do the assignment yourself, since that's how you learn. Doesn't matter if you don't succeed as long as you make a good-faith effort. If you are truly unwilling to put in the effort, perhaps it would be better for you to drop the course and find something else to do with your abundance of money.
As a very experienced C programmer (not saying I'm *good*, just experienced!) who's never taken any math beyond college algebra, and that almost a quarter of a century ago, I feel like a lack of calculus knowledge is one of the bigger gaps in my education. Can you recommend any resources for learning the parts of calculus that you find useful in your programming work?
&gt; Is this likely to cause an issue with some licenses? I'm not very savvy when it comes to this bit. libusb is LGPL v2.1. [This means, roughly, that so long as you don't change the *libusb* sources, you are OK to redist without providing full source code](https://github.com/libusb/libusb/wiki/FAQ#Licensing). You *are*, however, required to provide linkable objects, so that the user can use their own version of libusb if they wish. So as long as there isn't some other library presenting licensing weirdness, there shouldn't be any licensing issues for the most part. As long as you follow LGPL, you're good to go.
For some reason my code is not indenting properly :(
What do you mean by "vector"? just an array? a resizable array? a weird linked list array hybrid? something else entirely? IDK, I'm just tired of people using the same damn word for like half a dozen plus seperate ideas.
The basic info has been covered, so a comparison as you get into this... It's best said that C is like a 5year old that you send to the store. If you aren't very specific, he's coming home with ice cream and waffles. C can do a lot, but shooting yourself in the foot is par for the course. The language not only lets you, but it's a feature. Course, none of that really applies until you learn pointers :D
Thank you for the answer! That seems to be the prevailing expression, shooting myself in the foot haha, is that from K&amp;R? I just got to pointers btw :) You guys are right, might stick with python 😂 joking aside, I quite like how close to the metal it is, might even supplement it with some assembly down the line if I get into hardware specific stuff!
Hey thank you! I’ll definitely read it, and will surely take my time! 
I've yet to see a system that handles cross compiling or the wide variety of architectures that autotools ends up supporting. ( Not to say it's not possible, they just don't do it as well.) Also, while mist systems dont need to check for select or log2 or whatever, some systems still do. And emacs and all kinds of other tools still need to (and are expected to) work on those systems. For instance, take the new processor out of India. It may not support all instructions yet, or have working floating point, or have viable async io support, but emacs should still work, as well as lots of other tools.
&gt; assume 
eh, I think I heard it on bash.org originally. Doesn't matter, it's still a good comparison. Pointers make everything better; they put you in control of everything with the assumption that you won't fuck it up. Which you will, at least a lot. 
That’s Believe me, I am prepared to do that. I’m of the “fail a lot fail quickly” kind of people and it’s helped me tremendously in life. I just love the fact that knowing C will allow me to tinker with OS stuff, it’s getting me really excited!
Your system_time (that you got from `time(NULL)`) is the number of seconds since the UNIX epoch, or 1970-01-01 00:00 (UTC). Your user_time is the number of seconds the entered time is after midnight. This explains your 425853 hours (over 48.5 years).
What would be the correct way to do it then? 
You can use `[localtime](https://linux.die.net/man/3/localtime)` to get the time relative to your timezone.
I tried implementing localtime and I still get the same thing. Why is this?
I still get the hours since 1970. I basically did it how you did the example there.
Yep! The hours still dont display correctly. I tried on my laptop as well
What is the output when you run my example, and what OS/compiler?
That looks like a correct output, assuming that is the local time of the machine that it ran on (i.e. not your machine, but the online service's machine).
Did you just add a call to `localtime` and change nothing else? `localtime` does not change the time_t variable. What can you do instead?
I'll have a research again on the internet. We have not learned time in class but it is apart of our assignment and we are expected to do research on it. So sorry for my lack of knowledge on this topic
ok, hint: `localtime` fills in a `struct tm` for you (see the man page I linked earlier for details). See how I printed the current date and time in my example. You can then use the information in the `struct tm` in further calculations.
Hahaha I still can't get it to work. I think I need a rest and maybe continue it tomorrow and finish my other questions in the meantime. Thank you for all the help! I truly appreciate it:)
Someone actually did, after writing a blog post complaining about autotools. He came up with Meson. I think that would be the thing I'll be reaching out to in the future.
Awesome, that's helpful. Thanks SoraFirestorm!
&gt;- `realloc()` could return NULL if its size argument was 0, but in that case, a return of NULL should not be considered an error, since the call is equivalent to `free(ptr)`. Good point, edited that into the original post. Never ran into an issue with this as I always use resize with strictly positive numbers but since it's just an added conditional in the NULL check I see no reason not to. &gt; - in `vector_free()` I would also set `v-&gt;array` to NULL. I usually have that in there, it seems I was somewhere else when I wrote this as I also forgot to reduce the size when using `vector_resize` with a number smaller than current size, some pretty major oversights, all fixed though! &gt; Also I have a question: in the example, you don't explicitly set v-&gt;array to NULL (nor size or capacity to 0). Will it be implicitly set to NULL thanks to that c99 (I don't remember the name) struct initialization way? Yes, this is designated initialization, all members that are not explicitly initialized are initialized like they have static storage duration, so zero'd out, this is [guaranteed by the standard](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf). See section 6.7.8 paragraph 19, see paragraph 10 for initialization of objects with static storage duration. The gist of it is pointers are null and numbers are zero, this applies recursively to sub-structs and union, though only the first member of a union is initialized.
I'm referring to a C++ like std::vector. Basically a dynamic array with automatic memory management and contiguous allocation for efficient cache utilization. Also, I've never heard people use the word to refer to anything else besides the mathematical construct. 
Find a c# forum maybe
Hello, thanks for a very thorough answer. One thing i forgot to mention is that I want to distribute the source so that the users can modify it if needed and then compile the project themselves. Is the best way here to just constrict the user to the set of specific compilers that libusb distributes binaries for and bundle them?
[removed]
If you have set up the build system (autoconf, cmake, meson...) properly, it should usually find the library automatically on user's system when they are compiling your project. You don't have to (and should not) include the library with your project, just write in your README.md file that it is required so users can get it via their package managers first (by typing `sudo apt get libusb-dev`or similar). Additionally, it is a good idea to provide binaries for Windows (both 32 and 64 bit), because most Windows users don't have a compiler and package manager (like msys2) set up. Either just bundle your executable with the library's dll, or link the library statically (I would link it statically if possible because this makes the whole download smaller and most of the benefits of dynamic linking don't apply on Windows, but it doesn't really matter) 
C# is off topic in this subreddit. Please post C# questions to /r/learncsharp.
What exactly do you find complex about it? I mean, other systems might be better or worse, but that is less factual and more opiniated. Autotools, CMake, and Meson all attempt to solve the same problem of detecting platform features before compilation and using macros to propagate the results of the feature checks to the compiler. An example of a concept you struggle with might help clarify the issue.
You've got some good answers already, but to offer a different approach... I was using libusb for a bootloader utility (makefile for Linux, Visual Studio project for Windows), but very quickly received reports of issues under Windows with certain USB controllers, which turned out to be a known issue libusb under Windows (this might have changed tbh, this was a couple of years ago). I ended up writing a little abstraction layer that allowed me to use either libusb or - under Windows - WinUSB. It didn't take that long to write, and as well as removing that issue with certain controllers, it made packaging things up a bit easier as WinUSB is just part of Windows (since 8). I'd love to share the code but it was written for a client.... But it just took a bit of time looking at the MSDN docs to get an idea of how to use WinUSB so it wasn't a huge undertaking. All I needed was device querying, bulk in and bulk out, so it was pretty basic. So, if you're so inclined, this could be an alternative approach for cross-platform USB usage.
Might I suggest using the standard C function [`difftime`](https://en.cppreference.com/w/c/chrono/difftime)?
Thanks. I really want to try to make time to learn some higher math just for my own satisfaction. It always feels like being secretly illiterate when I'm around so many smart engineers and scientists.
Thank you for your reply! Happy hacking!
This is C++ code, not C. You should ask your questions at /r/cpp_questions instead. In the meantime, I'll make a few comments on your code: * `while(!fin.eof())` is basically never correct. Burn whatever book told you to do it that way. * Be careful when mixing `getline` with `&gt;&gt;`. It looks like you're using `fin.ignore()` to get around the issue. IMO, the best thing to do is just use `getline` to get a line of text from the file at a time, and then use one of a thousand different ways to convert the line with the percent to a `double`. * You never actually get `tempP` from the file.
For the next time, if you want to post your program, make a link submission, not a self-text post. This way, people can easily see where else your project has been posted and refer to the other discussions.
`mem_size` is undefined inside `initMEM()`. In the header file the second parameter is `mem_size`, but in the function definition it is `size`. I don't think I've ever seen someone put spaces around the arrow operator, and I have to say I don't like it. It makes it harder to read and understand at a quick glance. My eyes want to parse things separated by spaces as different things, especially when just skimming the code and not reading every line from left to right. `chunk_ptr -&gt; size &gt;= chunk_size` this makes me focus on `size &gt;= chunk_size` and sort of ignore the `chunk_ptr` part unless I change from skimming mode to full comprehension mode.
It looks like your code is C++ - "delete" is not a C operator. If you want to implement memory management yourself using pure C, you'll have to either reserve your space on the heap, or use lower level calls like 'sbrk()' to manipulate the heap directly. 
That's what I get for reading too quickly. Comment removed.
It doesn't, but this code is wrong in the definition, not the declaration.
&gt;Why not link the library into another library? I do that literally all the time with my dependencies... Because that's not what OP as asking for.
`mem_size` is declared on the first line of the function body. Besides that, parameter names don't matter to the compiler; your function definition and declarations can use completely different parameter names as long as the type signature is the same. In fact, in my experience, it's sometimes common to omit the parameter name from the declaration entirely. You can argue it's weird, but that's a matter of stylistic preference.
Do you think leaving out variable names for "obvious" things only strikes a good balance? Example: A boilerplate function that operates on a typedef struct BAR pointer vs a function that acts on a typedef struct SERVER pointer and accepts a max number of connections to accept. `int num_foos_inside_bar (BAR *);` `void accept_connections (SERVER *, int max)`
You're right. I missed that.
I would recommending the book "Programming from the ground up" by Barlett. It teaches you assembly and C will be a breeze after that.. 
I'm sceptical. I've written a lot of Haskell before moving to C and have worked with [Frama C](http://frama-c.com), a formal verification/static analysis framework that works by annotating C code with invariants and contracts. I found that all the extra annotations do not really prevent all that many things that wouldn't normally get caught during testing, but make further development way more tedious because interface coupling is much tighter with extra contracts attached. I also think that many programmers will be overwhelmed by the complexity Rusts's borrow checker adds to people's code and decide to work around the borrow checker, creating weird and unnecessary code that is hard to understand. I'm also not sure how portability is going to pan out given that Rust allows a much stronger coupling between source code and details of the tool chain through a complicated ~~module~~ crate system and the ability to precise influence aspects of the build system in the source code. C is portable because the language makes it hard to make precise assumptions about the target platform, so people are encouraged to write code that makes less assumptions and thus is more likely to work on platforms that challenge these assumptions. As another problem, Rust doesn't seem to have a stable and complete specification. As far as I am concerned, only one implementation of Rust exists and others have yet to emerge. I am not to keen on writing my code in a language that depends on the whim of a single project that has neither made any useful stability commitments nor has a history of being strictly conservative with the stability of their interfaces. Lastly, I'm super annoyed at the recent Rust evangelism and the frequent projects to rewrite old programs in Rust. While well-intended, these projects are ultimately futile and carry an air of hybris with them, especially since people only seem to want to rewrite programs that are either trivial to write (like the libc sans multi-byte and hard stuff) or have very high publicity (like the Linux kernel). 
In my experience, the borrow checker mostly fades out of your mind once you’ve written enough rust. Sometimes you have to deal with it, but it’s pretty well thought through, so there’s usually a simple enough solution in my experience. 
Have not used them myself, but I’m guessing for certain cache fetching scenarios or for unique hardware. Interested in what someone else has to say..
Indeed, if you're fighting the borrow checker you were probably writing some not so great code in other languages anyway. The borrow checker just makes it obvious.
I feel the same way, Rust isn't a C replacement, it's a C++ replacement. C is still great and will still have a lot of use, but hopefully Rust takes a big bite out of C++. Worst case is we have an option. Some people will prefer C++ for valid reasons, and others will prefer Rust. Just like we have the option of C or C++ today.
You usually need aligned memory for using SIMD intrinsics.
I think the syntax is pretty nice, what bits don’t you like?
If you have to ask, you probably don’t need to use it. It’s generally necessary for optimizations to align with cache or page boundaries, hardware requirements for specific instructions, operating system requirements, etc. For example, I had a system that required allocation on 1MB boundaries and another that would perform better if you allocated in 16MB chunks on 16MB boundaries. In both of the above, vector operations were required to be performed on 128 byte boundaries while, on one, GPU DMA operations had to be aligned to something like 512 bytes. Usually, when working in those kinds of systems, your custom allocator just defaults the alignment to something sensible, like 32 bytes, and you only specify higher or lower as needed or as an optimization. In those kinds of systems, linked lists of objects around the size of the alignment are horribly inefficient, so vectors were almost always faster, even for insertion operations. So, stuff like that. 
Rust is a solution to a lot of the issues that arrise in pretty much every non-trivial program. It's also a modern language which makes boiler plate somewhat nicer to deal with. That being said it's almost complimentary to C. Rust's primary goal is safety but C makes it easy to do quite unsafe things. For instance a specialized memory allocator I don't think you'd want to write in Rust but is pretty straight forward in C. Well until everything is broken all the time because that's hard. My point is Rust is great and powerful but 1) it's not going to replace most other languages (or even a good idea if you could magically re-do everything in Rust) and 2) people will consider it *too* new even though it's been a relatively popular language for what feels like a good while.
Another example might be for [page locking](https://ftp.gnu.org/old-gnu/Manuals/glibc-2.2.3/html_chapter/libc_3.html#SEC60) See also a corresponding [StackOverflow answer](https://stackoverflow.com/questions/32139051/what-are-benefits-of-allocating-a-page-aligned-memory-chunk)
You can't do anything meaningful with unicode codepoints either as they are still depending on the context.
It's a mess. The amount of memory needed to run Rust is absolutely crazy. If it were an order of magnitude less, it'd still be a bloated mess.
I worked on a project where we were trying to modernise part of our infrastructure and move away from a Java service which was politely a steaming pile of unmaintainable shit (it was a contract job). The problem was the performance and part of our team is very experienced in working with functional languages and since it wasn't a large piece of code we had no qualms with trying to use Rust as our alternative. I want to lead with the fact that it ended up performing an order of magnitude better than the Java service (subsequently allowing us to reduce our server hosting instances to deliver the same service) and it is about a quarter of the code base (in part by shitty template design by the contractors). However in my usage I found the build environment to be pretty poor; sometimes incremental builds just didn't happen and would end up building the whole code base. Building is slow (this is due to the compile time checks) and we depended on a piece of software that tracked the nightly rustc release so periodically we would update our toolchain and our code would not compile. This is to be expected and I will not blame that on rust for it is a new language and is not as static in it's definition as C is. Also I found it hard conceptually from someone who develops mostly in C. The data structures are numerous and because of how invasive the compiler is, you can't represent them in your head in the same way as you can in C. Perhaps that's my limitation rather than the languages. In C I feel as though you can predictably translate in your head how each statement, expression, whatever will be represented; I found this was not the case in Rust where it feels as though you give hints to the compiler and it optimises as it pleases. This is good to an extent, I think on average, a programmer is more likely to be able to have their concepts be well defined in terms of quality of the generated code. Again that's probably more to do more with me and how bad I am at conceptualising certain abstractions. If you are looking to produce performance sensitive code, you may struggle with this. Syntactically its clean but a few bad design decisions along the way and suddenly your code is littered with artifacts of how it manages it's memory; traits very quickly become a nightmare. There is plenty of good literature out there to understand it but it can at times be frustrating. All in all, I do really like it. It has very good performance, inspires confidence that the code you ship is of high quality and has been somewhat audited by the compiler before doing so. There are a few drawbacks for *me* but that's probably because I look at it as the eventual successor to C (because of popular opinion) and for me it just can't beat it at the moment, but I think outside of very niche use cases, it is an exceptional alternative (read: not replacement). 
Since I'm interested in games and audio processing, I'm much more interested in the development of Jai (which should be getting a release date within 1-1.5 years, if I understand Blow's time frames properly). I think Rust creates a lot of daily friction, looks ugly, and doesn't solve the problems I regularly encounter (memory and safety aren't as big of issues to detect and fix as many people make them out to be)
The SLIST_ENTRY structure needs to be aligned on a 16 byte boundary in order for the interlocked singly-linked list functions (InterlockedPushSListEntry, etc) to work correctly. _aligned_malloc() is one means of facilitating this. If it's not aligned correctly (i.e. on an 8 byte boundary), you'll get an access violation trap when attempting to use those functions.
I saw it in use for file io code saying it was "faster". But I was skeptical thinking that sounds hacky. What do you think?
"int" is short for "integer", which indicates the "type" of a variable. When you say: int redLed = 11; That is called a variable declaration. It tells the compiler will set aside a chunk of memory for the variable. That chunk of memory holds a value (initially 11, though it could change) and a name (redLed). It also has a "type". The type tells the compiler (1) how much memory to set aside; and (2) how that memory is going to be used. In your case, you have chosen to make that variable an integer. On the Arduino, that means that your variable is (I think) 16 bits (2 bytes) in size and can hold values between -32768 and +32767. On different platforms, ints will have different sizes.
So in C you have a series of fundamental “types”. The might be “char”, “int”, “long”, etc. This describes two things. a) the type of information that can be stored in the variable. b) the size (in bytes) used to store the information in memory. In the case of an “int”, short for integer, it means it can store whole numbers, and (on 32 bit systems) is stored in 4 bytes. Something such as a “long” also stores integers, but is twice the size of int (8 bytes) so it can hold a larger range of numbers. Other data types may be smaller, such as char (short for character) which is one byte in size, and can hold pretty much any ASCII character. That’s the simple version at least. 
Aligned addresses can also be used to store information as the least significant bits will always be 0. This is commonly used to store type tags. Just clear the bits when you need to dereference.
using a keyword to define a function instead of the context like it's shell scripting. using `-&gt;` in the middle of a function declaration for no discernible purpose. using `let` to create or define a variable like a fuckin heathen. `fn get_buffer&lt;R: Read + ?Sized&gt;(reader: &amp;mut R, buf: &amp;mut [u8]) -&gt; Result&lt;()&gt;` Pretty much the whole god damn mess tbh.
I see the lack of proper support for shared libraries as a problem. Although it is theoretically supported by compiler, the whole Cargo ecosystem is based on static linking; there is no stable ABI and I wouldn't know how to design a library API that allows replacing the shared library without recompiling programs that use it. Also, interfacing C is inconvenient. The common way to use C libraries from Rust is to write wrapper libraries, but how are you supposed to keep these in sync with the original header files? C++ and Zig solve this better by being able to directly include C header files. The other way around, using Rust to write libraries that can be used from C and other languages, seems to be completely uncommon. So Rust may be a nice language that is useful for small command-line tools and web back-ends, more of an alternative to Python, PHP and Go than to C.
&gt; Rust evangelism and the frequent projects to rewrite old programs in Rust. The is because Rust community wants to create a self-contained world where every library, program and even the operating system is written in Rust, instead of seeing the language as a useful tool that integrates well with existing stuff. I have higher hopes for Zig, which focuses more on interoperability and has "creating a C library" as a primary use case.
The Quintessential Question that Didn't Deserve it's Own Thread. I can't believe other people have the patience to even draft a proper answer. Stop being a Help Vampire - this is Square One.
Arduino ints are two bytes. Personally I prefer using (u)int_X variables though when working with embedded. 
To add on to this, "On different platforms, ***ints*** *fundamental types* will have different sizes." This is why we generally include the `&lt;stdint.h&gt;` header, so we can use types like int8_t, int16_t, int32_t, int64_t (and the unsigned variants), because they're guaranteed to be the correct size, or not available at all.
It probably is faster.
I think it's massively overhyped. I don't have an inherent objection to the idea of a safer systems programming language, but one developed primarily by academics with no real job experience and apparently designed to appeal to webdevs who don't have much low-level experience anyway isn't exactly one that I want to succeed. The Rust Evangelism Strike Force annoys me as well.
No. The standard specifies that `int` “has the natural size suggested by the architecture of the execution environment” (§6.2.5) and that it must be *at least* large enough to hold numbers in [-32768, +32767] (§5.2.4.2.1). It is perfectly fine to assume a wider range if you only target implementations for which that assumption holds. You will be hard pressed to find code today that assumes `int` is anything less than 32 bits unless it *explicitly* targets 16-bit systems.
This is especially pedantic because we're talking about Arduino on which ints are typically 16 bits wide, and the OP explicitly said he was a beginner and didn't understand much about memory. No, it's not perfectly fine to assume ints are 32 bits wide even if you don't explicitly target 16 bits system. You can only assume that if you explicitly exclude 16 bits systems from ever being a compilation target, which, since we're being pedantic, is not the same thing. If there is the possibility that the code you're writing could be used on an arduino, or on embedded systems (some of which run linux so if linux is a compilation target, assuming ints are 32 bits wide already breaks on some systems which you implicitly target), then you cannot make that assumption. Again, not that there would ever be any reason to make that assumption when *the standard defines fixed-width integer representations.* There is also the possibility that ints are much wider than 32bits, although this is unlikely to be the case it's perfectly possible that a future platform would use 64 bit ints, and if you're using them to store 32 bit numbers you're wasting memory and cache efficiency and running twice as slow as you possibly could.
&gt; Now that I actually understand it, that's a dumb idea. On another note, people from Taiwan, China and Japan like to use their own character encodings because Unicode is pretty fucked for Chinese characters. In some cases, there is no 1:1 translation between native Chinese encodings (like Big 5) and Unicode, so it's important to handle the texts in Big 5 instead of translating them to Unicode, even intermediately.
Or you do it like people did it before `stdint.h` and just deal with the fact that you can't predict type sizes. Use a type that is specified to be large enough and use bit masks if you want defined wraparound.
It does in the sense that the parameter name should be syntactically valid. Which is why you see people use weird parameter names in their headers to make collisions with user-defined macros less likely.
Thanks, didn't see those
I’m not sure how much faster it would be for general file I/O. It’s certainly not faster to allocate. That code could also be wrong and whoever wrote it just misunderstood some documentation. However, if the file I/O used things like DMA and those DMA operations were faster if aligned a certain way, sure it’s possible. Usually, it’s important for systems that either don’t support or where an unaligned load / store incurs a (meaningful) penalty. Think of it this way, if a system at the hardware level always loads and writes at 16 byte alignment with 16 byte “pages” and you have something that’s not aligned, it has to read and write 32 bytes for each operation because your 4 byte integer crosses a boundary.
I tried it a couple of times and never warmed up to it. * some things that should be trivial but aren't (like bit twiddling). Very frustating. * essential functionality I expect to be in laugage core only provided by third party * cargo has the same security probles as npm * no stable ABI (last time I checked) In general it reminds me of my C++ days. I waste too much of my brain-time dealing with the language instead of the actual problem I'm trying to solve.
The best reference is the C standard, currently C17. The most recent freely downloadable draft is this: http://www.open-std.org/jtc1/sc22/wg14/www/abq//c17_updated_proposed_fdis.pdf
Now that’s just straight not true. Idiomatic, well-crafted C, C++, Java, C# and pretty much everything else will make the borrow checker bitch slap you in rust. If you’re not battling the borrow checker, you either have plenty of experience with rust or are just not writing anything beyond simple utilities. 
I know nothing about the language itself, but the last time I was building all the ports for my FreeBSD system, Rust got pulled in as a dependency of Firefox for some reason. The Rust build grew so large -- far larger than any other port I use -- that it went beyond a 10GB tmpfs and nearly thrashed the system to its knees. It won't be installed on any of my systems soon.
No. The real standard ("ISO/IEC 9899:2018") can be bought from ISO (https://webstore.iec.ch/publication/63478) or from national standards organizations. When a new standard revision comes out, the old version will be shown as "withdrawn" there. The draft link above is more or less intended for internal use by the working group that actually writes the standard, and there may be some minor differences to the published standard. But still good as a reference if you don't want to buy the real standard.
As someone else mentioned, the C standard is the best. There is also the [glibc manual](https://www.gnu.org/s/libc/manual/pdf/libc.pdf), and there are a list of resources in the sidebar.
&gt; Rust got pulled in as a dependency of Firefox for some reason. [Rust is now required to build Gecko](https://developer.mozilla.org/en-US/docs/Mozilla/Firefox/Building_Firefox_with_Rust_code).
Wow. Spaces around the arrow and spaces around parenthesis, EXCEPT if the parenthesis comes right after a statement like `if`. if( (chunk_ptr -&gt; state == FREE) &amp;&amp; (chunk_ptr -&gt; size &gt;= chunk_size) ) {
Lol, Who are you talking about on articulation.
C99 &amp; C89 standard is widely used. C1\* standards are pretty much useless!
[https://www.amazon.com/Reference-Manual-Samuel-P-Harbison/dp/013089592X](https://www.amazon.com/Reference-Manual-Samuel-P-Harbison/dp/013089592X)
That's probably a valid solution in most use cases, but arduino has a 2 kb of runtime memory. Large Strings are enough to cause memory issues and are usually stored in program memory if possible. 
You can use fopen to open the file and fread to read to write part of the file into a buffer of type char. You can then iterate through the buffer to get each individual byte.
A reminder that both C and C++ were like that in their early years. C started development in 1969, was released in 1973, but wasn't standardised until 1989. C++ started development in 1979, was officially released in 1985, but wasn't standardised until 1998. Both languages had updates before standardisation that majorly changed the language and the spaces were rife with incompatiblity between compilers. Rust started development in 2006, had its first pre alpha release in 2012. The time between release and standardisation for C and C++ was about 15 years. Rust has been out for 6 so far. I wouldn't write it off because it is still in active development. If in another few years it isn't starting to stabilise, then I will cede my point. 
It's a LOT more involved to do it right than you could possibly imagine.
Very helpful... 
use bitmap format. read about the bitmap format specification (there is an ieee rfc document). implement a compression algorithm that you think would be good. try it out. benchmark and share. :)
It's the same thing that is going on with JS and many other languages. Somebody decides to rewrite something in their language of choice for whatever reason (better integration/less hassle, curiosity/learning purposes, or just because they wanted to), releases it, and shares it online. Basically, it's a new language and it's learning its identity. Give it time, figure out its place, and most of the fanaticism will die down. Also a lot of the low hanging fruit (library wise) will have been hit by then. 
It depends a little bit on the format of the image. I am not very familiar with image file formats but normally there is some header stuff involved. I would suggest you start with something easy (png?) and check out how a png is constructed. Than just fopen the file and save it to a char array to get a byte-by-Byte representation. To print stuff on a binary level you need a wrapper function. You can could a function which gets a byte as input and iterate 8 times. While you iterate you check every bit if it is set and Printf the result. 
I agree: historically, it took a while for C and C++ to get a specification, but it exists now, while rust has none. Rust doesn't need an ISO standard either, it needs some kind of specification at all; otherwise, how would you accept and implement an RFC without introducing a contradiction to the language? Go is about as old, and it seems to be specified much better.
The rust documentation isn't nearly as unified as I would like it however it does have a reference and they seem to be making a concerted effort to get a unified reference released. Otherwise I largely agree with you. 
Pick the simplest image format that comes to mind, PPM is the one I think of. Then either use a library to parse it, or do it yourself and extract the data.
Both C89/C99 are well know by most non-C developers, portability is another issue, Windows did not even properly implemented C99. C1\* adds some interesting features to C bojo, still, If I ever needs more than C99, **Rust** would takes priority as it has features of the newest hardware that C cant really achieve ...easily. Embedded heavily uses C89 as C99 still bleeding edge. Most famous and widely used Free and Open Source projects are written and maintained in C89/99. In my vision, C will survive next decades but mostly by maintaining projects rather new ones! Rust and any new system programming languages has more to offer to new projects! 
[https://www.gnu.org/software/libc/manual/](https://www.gnu.org/software/libc/manual/)
PCX and BMP are also very simple. Both use run-length encoding, which is trivial to decode. Both also use palettes, but that's not difficult to handle either.
Whatever...crappy OS! 
&gt; you are reccomending C17 where?
The "Rewrite It In Rust" crowd. Also, the people who treat a safe systems programming language as a massive, era-defining breakthrough despite the existence of Ada and MISRA C which are actually used by groups that demand extreme safety in their systems, but don't receive the same praise as a language that is more notable for its marketing than anything it brings to the table technically.
Have you seen [this](https://www.youtube.com/watch?v=uZgbKrDEzAs) presentation about Jai? Completely killed any interest I had in the language.
Everything is bytes, and every thing is code is made up of them. An int usually refers to a 32-bit signed integer, 4 bytes. The first bit is used to specify positive or negative, in other words to "sign" it with a + or -. An unsigned int is also 32 bits, and can represent a wider range of positive numbers, but can't represent negative ones. So it is a construct of memory, but most memory constructs really aren't as difficult to understand as you may think. 
It took the same amount of time for me to type my response with an explanation as it did for you to make a totally unproductive comment. Food for thought.
Yes, the world would be better off if more sw was written in rust. Ada killed itself by having a compiler that cost like $2K of 1980's dollar. And lol @ MISRA C. Rust brings the borrow checker to the table. If you legit believe that MISRA C has more of a technical merit than Rust, you are deluded.
&gt;Rust brings the borrow checker to the table. If you legit believe that MISRA C has more of a technical merit than Rust, you are deluded. If you think that marketing a systems programming language to a bunch of webdevs who treat low-level development as either a novelty or something to be afraid of rather than people who are actually going to use the language for something useful, you're deluded. Any technical merits that Rust has are disguised by the fact that it's treated with messianic praise (How exciting! How exciting!) rather than a measured analysis of its merits and demerits over existing languages.
A `char` always occupies a single byte and are not an issue. If you need at least 16 bits, use a `short`. That's good enough. It's not really an issue in practice.
Then tell me how Go manages to circumvent all these problems. They've had a specification since the very first release and have remained compatible ever since.
All the compilers were expensive back in 1980.
I know you're asking for a book, but I highly recommend [this site](https://en.cppreference.com/w/c). Yes, it's mainly dedicated to C++, but don't let fool you. It's C reference is just as good.
I have not. I'll check that out and report back with my findings
&gt; Are they adopting it in avionics and control systems for nuclear power plants, though? That's a very narrow worldview. I dont care if they have adopted it, I care more about how much of a pain in the ass is it do work with simd. Show me a better simd framework than this one https://github.com/AdamNiederer/faster &gt; updates on Reddit doesn't make the language Stop talking about Reddit. Talk more about Rust. 
I aint one of them. Just think that C is not anymore the best tool because hardware changed a lot since 80's
I'd argue for someone just picking up C the glibc manual you linked is far more useful that the iso standard.
Do you usually keep changing the subject? Its rather unuseful approach, it at most will make you "shine" in conversations but at the same time makes all of it shallow and a total waste of time! Just a tip! 
I didn't change the subject. You, on the other hand, are dodging my question. Where did I recommend C17?
* Put four spaces in front of each line of code * Get rid of all the backslashes print_inventory(inven_arr[]); Leave out the `[]` from this call. return 0; Your `print_inventory()` function is declared with a `void` return, take this out.
Rust core team member (and /r/c_programming subscriber) here. There's a number of different things at work here; one of them is that Go is significantly more minimal than Rust, and so has much less to specify in the first place. For example, Go's `unsafe` package says &gt; Packages that import unsafe may be non-portable and are not protected by the Go 1 compatibility guidelines. By contrast, in Rust, we're *extremely* interested in specifying our usage of unsafe. This is because what we want is a *formally provable* specification, which is a pretty lofty goal. Significant work has been put into this; the EU has granted almost two million Euro to work on this problem, for example. Most of that has been on `unsafe`. It's already borne fruit; it's found both unsoundness issues that we've had, as well as areas where we were over-constraining and could loosen things up without introducing unsoundness. TL;DR: it's true Rust doesn't have a spec yet. We're working on it. It's non-trivial.
&gt; Also, interfacing C is inconvenient. The common way to use C libraries from Rust is to write wrapper libraries, but how are you supposed to keep these in sync with the original header files? C++ and Zig solve this better by being able to directly include C header files. These days, wrapper libraries are automatically generated by [bindgen](https://github.com/rust-lang-nursery/rust-bindgen).
&gt;That's a very narrow worldview. I dont care if they have adopted it I happen to find that keeping aeroplanes from falling from the sky and nuclear power plants from venting radiation is pretty important in the grand scheme of things. They're some of the applications which could most use safety in their programming languages, so the fact that they're not jumping wholesale onto Rust shows that it's not the paradigm changer that its proponents portray it as. &gt;Show me a better simd framework than this one // TODO: Is this unsafe? Way to admit that the biggest selling point of Rust is also something that costs it performance.
rustc is [x86-only](https://forge.rust-lang.org/platform-support.html) at the moment and unsuitable for portable software.
&gt; I happen to find that keeping aeroplanes from falling from the sky and nuclear power plants from venting radiation is pretty important in the grand scheme of things. Admirable. Right now I care more about the project I'm working on and Rust is just such a good match that it's not even comparable. &gt; Way to admit that the biggest selling point of Rust is also something that costs it performance. It doesn't. 
Giving him a fish would be giving him a program. Fishers produce fish, programmers produce programs. More like I gave him a lure. Plus, you've spent as much time on this post as I have, and haven't given anyone including yourself anything but inanity and a waste of time. Provide something or fuck off. It's simple.
&gt; C is portable because the language makes it hard to make precise assumptions about the target platform, so people are encouraged to write code that makes less assumptions and thus is more likely to work on platforms that challenge these assumptions. Unfortunately, my experience is that people make those assumptions and then get bitten, badly, when the platforms they port the code to challenges them. &gt; I am not too keen on writing my code in a language that depends on the whim of a single project that has neither made any useful stability commitments nor has a history of being strictly conservative with the stability of their interfaces. After 3 years, I would say that it *does* have a history of being strictly conservative with the stability of its interfaces. C++ has seen more deprecation churn between C++14 and C++17 than Rust between 1.0 and 1.28. C hasn't, but that's mostly because it hasn't evolved either, since C17 was just about fixing defects in the standard.
&gt; Building is slow (this is due to the compile time checks) Actually, it's generally not. You can use `cargo check` to only perform the compile time checks without building, and you'll notice that it's significantly faster than building; you should expect it to complete within seconds even on moderately large projects. For most projects, code generation is a bottleneck, and yes, it's slow... and worse, using `cargo test` will compile twice (in both normal and `#[test]` mode).
&gt; In some cases, there is no 1:1 translation between native Chinese encodings (like Big 5) and Unicode Unicode roundtrips original Big5 (1984) just fine. I believe it also roundtrips Big5+ (1997). It may not roundtrip the latest Big5 extensions just yet, but no, outside of special circumstances Unicode is just fine for Chinese characters.
&gt; LOTS of platforms (Apple's Cocoa, Windows, Java, JavaScript) use UTF-16 as their default if not only supported Unicode variant, and it's really dumb to limit Unicode to just one transformation format in the first place. All the common [encodings](https://encoding.spec.whatwg.org/), including UTF-16, are implemented in Rust and just a single line away: https://docs.rs/encoding_rs/
&gt; - essential functionality I expect to be in language core only provided by third party I am surprised at this comment, seeing as the C standard library itself is rather lean too; could you specify which functionalities you expected to find in `std`? &gt; - cargo has the same security problems as npm I was hoping it didn't, as many npm issues were known during the development of cargo; could you elaborate? &gt; - no stable ABI (last time I checked) This is still the case, and will be for the foreseeable future. Committing to an ABI, unfortunately, prevents progress. It is possible, however, to use `extern "C"` on functions and `#[repr(C)]` on `struct` to get a C-compatible layout which is guaranteed to be stable, and this is the recommendation for plugin interfaces and the like. 
I like the code written by Antirez [https://github.com/antirez](https://github.com/antirez), especially I like his sds library.
Then I have been informed wrongly. Does the same apply to Shift-JIS?
i don't think you'd want to use huffman encoding for images unless you want to compress screenshots from 1980s video games, though there's nothing stopping you from doing it for learning purposes. for reading an image, you'd normally want to just use a library for it. but if you want to implement an image reader yourself, i recommend you start with BMP for the simple reason that it's relatively easy to implement (if you only care about reading 24-bit uncompressed images, that is) and that the format's supported by practically every image editor in existence. [the wikipedia page on it is usable as a reference](https://en.wikipedia.org/wiki/BMP_file_format)
**BMP file format** The BMP file format, also known as bitmap image file or device independent bitmap (DIB) file format or simply a bitmap, is a raster graphics image file format used to store bitmap digital images, independently of the display device (such as a graphics adapter), especially on Microsoft Windows and OS/2 operating systems. The BMP file format is capable of storing two-dimensional digital images both monochrome and color, in various color depths, and optionally with data compression, alpha channels, and color profiles. The Windows Metafile (WMF) specification covers the BMP file format. Among others, wingdi.h defines BMP constants and structures. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
He wasn't begging us to debug his code, just asking for help understanding a concept. Now that he undertands the concept, it will be easier to understand other related concepts on his own. Begging for code fixes or "just works" solutions are help-vampiric. Asking for help with a concept on a dedicated forum *is* research.
OH MY FUCKING GOD YES. I've never been so excited in my entire life. Which tells a lot about how exciting my life is.
From what I've heard, the building is slow mainly because the LLVM IR that rustc passes to LLVM isn't great, and they need to do a fair amount of passes to optimise it down to C-like performance. And compilation is per crate, not per file. I think that's being changed with incremental compilation though.
No problem, just post in the right subreddit next time.
What is the value of the remaining array entries? Those that do not store meaningful values.
Not always. I've often heard this, but then I discovered `-Z time-passes` and lo and behold, most of the time is actually spent in the compiler, type checking and expanding macros, not LLVM. LLVM is ~ consistently 2 seconds per code-gen pass, but type checking inside of macro expansions took anywhere betwen 1 to 27 (!) seconds, so yeah. If you exclude that, then yes, codegen takes the longest, borrow checking only took 0.2 seconds or something like that. Sure, cargo check is faster (which is good for CI), but often times it's not enough, you actually have to run an example or run the code, at which point Rust just becomes a pain to develop. I mean I like Rust, but Rusts compilation speed is just dog slow compared to C or even C++ (if you don't go overboard with templates). I could compile the whole OBS Studio in a few minutes on my desktop, try compiling servo (a project of similar complexity) and we are talking 45 minutes - 1 hour. Yes, you can excuse it by saying "it's LLVMs fault", but as an end user I simply don't care, I just see a slow compiler.
Hey can you ELI5 why this is significant? 
The `qsort()` call is going to sort every value it encounters, so if you've got a `calloc`'ed array of 10,000 elements but only 1000 nonzero values, you'll get 9000 zeros at the start (assuming your nonzero values are &gt; 0). However, `qsort()` takes the size of each element in addition to the number of elements you wish to sort. That means you could keep a running count of how many items you've actually got in the array and just sort those. This assumes of course that the entries are all sequentially entered in the array and you don't have gaps.
&gt; seeing as the C standard library itself is rather lean too; Except when it isn't for kinda weird reasons. Like, the hashtable that it includes, which is actually pretty cool. Except it's not re-enterant and the re-enterant version is a GNU extension. So if you want to be standard, you can only have 1 hash table at a time.
&gt; Are they adopting it in avionics and control systems for nuclear power plants, though? No, but the reason is rather simple. Look at how long it takes to develop a nuclear power plant. Most of them (at least here in Germany) are build and developed in the late 50's - 70's the software is currently mostly certified with stuff from the late 80' - 90'. Once the software is certified there is not much development happening in favor to update the software. We had quite a debate here in Germany about this and i assume its the same in most countries. Siemens build a lot of them (all of the power plants in Germany) and i heard similar things from General Electric and Toshiba. So one reason is, Rust was not available at this point in time where the decision was made. Also the nuclear power plant industry is highly conservative. Very much the same as the rocket industry that mostly build its rocket systems with technology from the 70's. Not necessarily all of the software but mechanical parts pretty much. That's the reason why SpaceX is so successful – they're not so conservative. Writing software for Rockets is also a different thing altogether. It doesn't really matter how good your language is at preventing bugs/errors etc. it happens eventually if the process around the creation of code is just wrong. See our Ariane V88 disaster with a bug in the Ada code – from my point of view they should cancel the hole program in favor of the Falcon9. I hope this shed some light to the fact that it is almost impossible to see Rust in these kind of fields now.
Whatever it initializes to. I just create the array and then add to it.
There are lots of complexities here. For example, LLVM has a fast path (FastISel) that handles only subset of LLVM IR but much faster. The subset includes what is typically generated by C compiler. It does not include some of what is generated by rustc, but upstream is against extending it because as a fast path, extending it necessarily slows it down for currently working cases.
Those are definitely help vampirish/ic. This is a question that is elementary. There are no shortage of resources that explain the concept. He's a help vampire for not finding the answer for himself.
In C you'll need to initialize those (either by using `calloc` or setting them to some initial value yourself). Otherwise, they will just be filled with random values. 
k
Do you know why it is that Rust generates instructions that C doesn't? Is it due to some specific language feature, or more of an implementation decision?
&gt; one developed primarily by academics This isn't true. It's primarily developed by Mozilla for real world use. &gt; and apparently designed to appeal to webdevs This isn't true either. Even if it were; why is this a bad thing? Rust supports WebAssembly because it helps to solve performance issues on the front end. That's not so much for front end developers but for library writers and platforms. A lot of code in various browsers runs on top of the JavaScript engine for that browser, and so moving to WebAssembly helps to improve that. You need to bear in mind it's sponsored by the manufacturer of a browser to help solve their issues.
&gt; most of the time is actually spent in the compiler, type checking and expanding macros, not LLVM Do you have a link to some source code I can look at? 
This is an oversimplification. The biggest impact of targeting a Tier 2 architecture is that if you're using nightly builds you might be stuck on a particular build due to a new or in-development feature being broken, until it's reported and fixed. There are plenty of people writing production code for deeply embedded systems in rust targeting non-intel architectures.
&gt; LOTS of platforms (Apple's Cocoa, Windows, Java, JavaScript) use UTF-16 as their default if not only supported Unicode variant, and it's really dumb to limit Unicode to just one transformation format in the first place. Talking about how Rust handles different encodings requires diving into the details of `String`, `OsString`, `CString`, etc., which is kind of a lot of detail. How it works on Windows is that strings that come from the OS, which are "kind of UTF-16, except maybe with invalid surrogate pairs" get converted to WTF-8 internally, and then back to sort-of-UTF-16 at the boundary when calling into system APIs. That means that OS strings can be cast into native Rust strings with a validity check, and casts in the other direction are free.
&gt; then I discovered -Z time-passes My understanding is that `time-passes` is no longer accurate; FYI.
Nobody uses the `htable` interface. It's a read herring.
&gt;This isn't true either. Even if it were; why is this a bad thing? Because it makes people for whom "move fast and break things" is their core philosophy think that they can - and should - bring that attitude to system programming. This is a group of people who think that Node.js and Electron apps aren't profoundly wrong.
Except for whoever caused it to be in the standard, of course. They probably needed it, I don't imagine things just get thrown in the C standard without good reason, they're there because one group or another needed it.
I tend to think that the conservativism in those fields comes from somewhere. If Elon Musk had failed, he'd have just gone down as yet another dreamer, or snake oil salesman or what not. If people developing avionics software or power plant control software get it wrong, they get absolutely shat on. And that's what the "Rewrite It In Rust" crowd don't get, because they so frequently come from a background where "move fast and break things" is a core philosophy and they think that they can - and should - bring that attitude into system programming instead of sticking with a field where their mistakes aren't going to end up with people getting killed.
&gt; I don't imagine things just get thrown in the C standard without good reason Annex K is a good example for bullshit in the C standard. I don't think `stdint.h` was a bad idea. I just think that in most cases, it's not what you actually need. There are very rare cases where you require an exactly sized type. Mostly, any type is fine as long as its large enough. Picking a fixed size type might make your code less efficient on platforms where this type is poorly supported. For example, operating on 16 bit types comes at a slight performance penalty on x86 that is avoided by using 32 bit types instead.
Sometimes, when people say this, they mean the *ecosystem*, rather than the language itself. Rust is young, and so is moving very fast. Many libraries are pre-1.0, and so new releases include breaking changes. We have tools for dealing with that, for example, you have to specify that you want to update that dependency in order for the breakage to happen. But on some level, breakage feels like breakage, even if it's not the language itself that's doing that.
&gt; Many libraries are pre-1.0, and so new releases include breaking changes. If a library is pre-1.0, you don't use it. No excuses, no exceptions. Anything else means you deliberately accept unstable software. One more reason not to use Rust. Weird how Go suffers much less from this problem, eh?
&gt; Though I'll admit I'm not a fan of the curly brace placement in that position, `rustfmt` produces fn get_buffer&lt;R&gt;(reader: &amp;mut R, buf: &amp;mut [u8]) -&gt; Result&lt;()&gt; where R: Read + ?Sized, { } instead, which looks even better IMHO.
My understanding is that although `time-passes`is somewhat broken, macro expansion (marked "expansion") measurement is accurate, so there is no reason to doubt parabol443's report. I observe this tactic often from you, and I hope you stop. "time-passes is no longer accurate" is true, but replying so to "I measured rustc's slowness in macro expansion with time-passes" is dishonest, because inaccuracy in question is unrelated to macro expansion.
Note that I did not say that this means that their results are invalid. I do this because I used to do the exact same thing, and then was told that it's not accurate anymore. I don't think that many people know this.
I've grown to quite like it, and I'll forever be a C fanboy. That said, the Rust learning curve is more like a cliff. I've written production code in probably a dozen languages and have never encountered a language so difficult to work with during the initial stages. When I was first learning pretty much everything more complicated than "Hello, World" was absurdly frustrating. It's like Pascal on steroids. "I'm sorry Dave, I can't do that." -- endlessly and forever. Once you push past that point it really does become an awesome language to develop in. It totally changes the edit-compile-debug cycle. Once a piece of Rust code compiles it's nearly certain to work (and do what you expect). I think Rust's biggest hurdle is its extreme learning curve combined with the fact that for whatever reason many in the community try to deny that this is the case. 
I don't think it's weird; Go has a much larger standard library, and doesn't (though it will soon) have much in the way of dependency management, and so Go programmers tend to use libraries less. As with everything, it's tradeoffs.
One thing that's similar but different; we had to turn off some optimizations in LLVM because they were buggy; Rust's `&amp;mut T` is `restrict` in a C sense, and so it gets a *lot* of workout in Rust compared to C. We hit edge cases, turned it off, filed upstream, they fixed the bug, and this release turns them on.
I agree that conservatism can be a good thing especially in the case of nuclear power plants. If Elon had failed with his rockets nobody would really care. I a nuclear power plant fails – the world cares very much. So building it the same way that had worked previously has inherent value. I was just saying that the argument is not that strong from my point of view. See – no matter what language would be release in the last 5 years (just imagine for a few seconds) in which it is impossible to write any kind of bug (not even logical bugs) and its mathematical proven and besides that solved P=NP ... you would not see a single line of this language in any nuclear power plant today. &gt; And that's what the "Rewrite It In Rust" crowd don't get, because they so frequently come from a background where "move fast and break things" is a core philosophy I very much object this. I don't know if you confuse Rust with Swift in that case but Rust is pretty much in the opposite spectrum! One of the most important goals of Rust is not move fast and break things! [That was the single most Feature for Rust 1.0](https://blog.rust-lang.org/2014/10/30/Stability.html) Rust has a testing facility i have never seen in any other language to try to uphold this. Rust is constantly (at least for every release) pulling every package (crate) from its central package repository (crates.io) and build AND test every single one to look if stuff breaks. 
Now that I've watched the entire thing, I can finally respond: Personally I agree with most, if not all of what he's saying there, but that might just be because I've been following the project from the beginning and I'm automatically converting what he says into what I think he means. What in particular killed your interest?
&gt;I think Rust's biggest hurdle is its extreme learning curve combined with the fact that for whatever reason many in the community try to deny that this is the case. Pretty much all the regulars I see in /r/rust acknowledge the learning curve. If there is a cabal of curve deniers, I'd guess that there's fewer than it seems, and they're just noisy, serial trolls.
You don't need to sort the array to find the lowest element. A single pass through is all that is necessary.
Denial is two-way. Just as many deny Rust is hard to learn (I think that Rust is hard to learn is uncontroversial; whether it is *extremely* hard to learn probably is), many deny that you eventually get productive in Rust.
&gt; using -&gt; in the middle of a function declaration for no discernible purpose. The arrow points to the return type, common in functional languages. &gt;using let to create or define a variable like a fuckin heathen. makes it clear when a new variable binding is being declared so local type inference can be used to identify the type of the variable. &gt; fn get_buffer&lt;R: Read + ?Sized&gt;(reader: &amp;mut R, buf: &amp;mut [u8]) -&gt; Result&lt;()&gt; If you write rust its pretty clear what this means, this defines a function called get_buffer, which takes a mutable reader that implements Read and Sized traits and a buffer which is a slice of mutable u8s and outputs a result. I agree it looks weird, but the point of Rust is that it is explicit and doesn't rely on runtime 'magic'. 
&gt;If a library is pre-1.0, you don't use it. No one is forcing you to.
The "magically returning variables without a keyword" is only at the end of a function, and requires the *lack* of a semicolon at the end to count as a return.
&gt; Sized traits Careful there, `?Sized` means it *doesn't* have to implement the Sized "trait". It's the only trait where you can do `?` to mean "not required". Sized isn't really a trait, it's more "Do we know how big this variable is?". Sized is implicitly a bound by default, because you *have* to know how big something is to work with it. Otherwise, you need to work with it through a pointer, as this function does. An alternative would be to use `R: Box&lt;Read&gt;`, and then you box up the object that implements Read. A box is a smart pointer, and a pointer has a known size, so you can pass in the box directly without using a pointer to it.
From the OP: * Support for ISO C threads (ISO/IEC 9899:2011) has been added. The implementation includes all the standard functions provided by &lt;threads.h&gt; See this SO post for some background: https://stackoverflow.com/questions/24557728/does-any-c-library-implement-c11-threads-for-gnu-linux 
I'm not saying it's impossible, I'm just saying that you're swimming against the current because the language's design goals do not always align with ease of game development. So what I would say about those developers who are trying it is: if it works for them, great, but it doesn't work for me.
thanks fixed.
Why would you sort all 10000 elements of the array if you're only using 1000?
Why don't we rewrite everything in D instead? Zero cost abstractions, incredible metaprogramming features and great standard library. /s But seriously give D a try: https://dlang.org.
Thank you! 
And if you have any pre-1.0 dependencies, you're not allowed to be 1.0 yourself. 
Heaven forbid development should be about building solutions. &gt; This is a group of people who think that Node.js and Electron apps aren't profoundly wrong. Ultimately the industry is finding that Electron allows teams to build far more, and in particular complicated UIs, in less time. This is in comparison to prior alternatives, including native solutions.
The more libcs that actually support C11 threads, the easier it is to write cross platform multithreaded C programs. glibc and Windows are the two 500 pound gorillas of C runtimes and now one of them has finally taken the step. (Now for all the "but you can use pthreads on Windows!" comments... Some of us would prefer to keep third party dependencies to a minimum on that platform.)
Pre 1.0 doesn't mean the software is unstable in rust. In means that there will be breaking changes in the library. Once you are 1.0 you are only allowed to make breaking changes when you jumpt to 2.0. Many of the most used crates like crossbeam and winapi are pre 1.0. And even rand, the main provider for random numbers in rust ist pre 1.0.
&gt; LOTS of platforms (Apple's Cocoa, Windows, Java, JavaScript) use UTF-16 as their default if not only supported Unicode variant, They use it as internal format, which means nobody has to care about it. All of those platforms work with utf8. &gt; and it's really dumb to limit Unicode to just one transformation format in the first place. Far better than not being able to make any assumptions and deal with possibility of failure everywhere. 
In my beginner days, I thought K&amp;R's prototype parameters not matching the definition (in a handful of cases, at least) was some sort of editing oversight, or that I had purchased a bad copy. A couple years later I was relieved to discover that I'm not crazy, just an idiot. 
&gt;Ultimately the industry is finding that Electron allows teams to build far more, and in particular complicated UIs, in less time. Ultimately, the industry is more and more willing to throw massive amounts of system resources at these UIs, ignoring that other applications may be running at the same time and demanding their own share of the resources. And these are the people you want to encourage to do system programming? Get tae fuck.
That's not a sustainable state of library development.
This sub is for C and not C++
What's the difference and there's no subreddit for c++
Windows is an OS, not a C runtime. There are various C runtimes for Windows.
Half of it is just him boasting about their fast compiler. While I think that fast compile times are super important to rapid prototyping, slow compilers are not at all intrinsic to existing languages. I saw someone complain about syntax ITT; he too hadn't watched this video. Also a lot of the stuff he talks about as novel things can very easily be done in existing languages with but a little friction. Contexts are just passing a struct to all functions - glorified globals. A stack as a temporary storage that is manually cleared each tick surely makes rapid gamedev possibly, but kills any assumptions about the lifetimes of the data. What about slow running tasks that persist across multiple frames. (Not that you'd choose Rust for its memory guarantees but it would prevent that mistake.) While you gain productivity - again ideal for gamedev - I feel like you lose the control of C or the flexibility of something like Rust, which solves the problem with move semantics. You can do the split example just as easily in Rust. He says that everything has to be in a standard place to enable coordination. To do that you have to write a languag... or just write a library. `set_icon_by_filename`: Alright, yes it can be menacing to have to set the icon of an executable but he says it himself, "because Microsoft makes it harder than it should be". This hasn't anything to do with C/C++. It's just tooling. Why language level. "C++ is underspecified and it's a hassle to build stuff". C++ has excellent tooling. Cmake solves that problem and allows you to use whatever IDE you want natively. Rust has cargo which is amazing. Arbitrary compiler plugins. Alright cool. Like procedural macros in Rust. I guess the conventional way of doing this would be to have a config file and in the build script generate source files. Which would be messy. However, the cost of doing these sorts of things at runtime is really pretty small, and I don't see any system binding keys via custom compiler plugins being a simple one. I realize that my points are completely one-sided, but it's justified by his arrogant punches at existing languages. With a closed beta like it's some kinda game. Then when pitching a new game development language you can't just focus on C++ from the 90s and ignore Modern C++. I would love to see what cool things Jai would bring to the table of language design, because I refuse to believe he wrote the language just for the sake of it. However I won't jump on the hype train until it's out.
&gt; Also, I feel like this is cuz C17 came out and clarified the issues. It seems more likely that glibc devs found all those issues while trying to implement it, and proposed the fixes that now appear in C17
They want to keep most things out of std, because if its in stable they cant be breaking changes. In some languages its beneficial to not use stable and instead use a better/faster library. Rust doesnt want to be one of these languages.
Sorry, the "Microsoft C Runtime".
They're two conflating issues which makes compilation exhausting. 
If you read the sidebar there are plenty of links to C++ subreddits. C++ has many features like classes, function and opporator overloading, and more that C developers will be unfamiliar with.
&gt; And these are the people you want to encourage to do system programming? This comes off as pretty elitist gatekeeping tbh. Your whole comment is also pretty hypocritical. You want people to write more efficient code. So WebAssembly is brought out, and a new language that aims to target it. That aims to do what you're asking. In the same comment you complain that those should not be a part of it.
Rustc can not only target non x86, it runs on many non x86 architectures.
Even 1.0 doesn't save you from breakage. And most breaking upgrades are trivial to migrate to. Some of the big libraries even come with a migration guide.
I would think that the "500 pound gorilla" libc resides in BSD UNIX and SVR4 UNIX.
Hold it .. what? How to write the "structure" to a file? Surely you mean how to write the data out to a file. However for what purpose? A file to be read by a human? A file to be read back in by software and a human? A file to be read by software only? Seems like you are saying you need "the program" to read it back in. So pure binary output is fine I guess.
In practice i believe full rebuilds are rare, though. leaving the lack of incremental as the biggest offender in most cases. Full rebuilds i generally assume will take a relatively long time by definition, and usually happen on the CI when building a release anyway.
I'm always amazed at how man douch-bags rant about Rust evangelism, but, I never seen a Rust Evangelical. Get a grip man.
I think that Prudential, JPMorgan Chase Bank, Pratt &amp; Whitney and all of UTC as well as the rest of heavy industry would disagree with you. Sure there is a ton of android on cell phones but the heavy industry world still runs a lot of mainframes and UNIX monoliths. Otherwise Oracle and Iron Man wouldn't be selling their M8 servers into their datacenters.
To be clear, it's not a *lack* of incremental; they're saying that bugs make full re-builds happen more often. I haven't experienced that myself, but I guess they have. Rust has incremental builds turned on by default these days.
&gt; actually actively contributes to the build time problem as well as making the default compiler optimizations less effective This should only happen for the first build; dependencies are not recompiled after that, no matter how much you change your code.
And once the breaking changes settle down, we sometimes move things into `std` as well; this is happening with Futures right now, for example.
&gt; could you specify which functionalities you expected to find in std? Signals for example. And C gets many additional features just through Posix. &gt; I was hoping it didn't, as many npm issues were known during the development of cargo; could you elaborate? My biggest concern is lack of acountability. What I would really would like to see is an organization that maintains a package repo of stable, high-quality libraries. If there is a security problem they should be accountable. Think Debian model, where there is an upstream developer but Debian actually maintains the package. There are too many single-proammer projects, that is terrible from a security standpoint. 
It happens! I know there's a lot more to do there.
It's more general than just returning at the end of a function. A block ends with an expression and the block evaluates to the value of that expression. So you can write e.g. `let x = { let y = 4; y + 2 };` and the block evaluates to `6`. A function returns what its block evaluates to if you don't have an early return.
Interesting. I remember reading some criticisms about threads.h, that is was botched and pthreads are better anyways. Is this still the consensus?
[https://gustedt.wordpress.com/2011/12/28/emulating-c11-threads-through-posix-threads/](https://gustedt.wordpress.com/2011/12/28/emulating-c11-threads-through-posix-threads/)
* rust is a chemically castrated c language! * by the way go is also a chemically castrated python language
&gt;For instance a specialized memory allocator I don't think you'd want to write in Rust but is pretty straight forward in C. I'm not so sure. [Here](https://github.com/emk/toyos-rs/blob/master/crates/alloc_buddy_simple/src/heap.rs) is a simple buddy allocator in Rust. Looking through, I don't see anything that would be much nicer in C
I think the criticism was that C11's threads are a bit limited compared to posix threads and also slightly incompatible, and they should have just used posix threads for the C standard instead.
`size_t` is a data type. Just like you can't use `int` or `char` as a name, you can't use `size_t`.
Actually, if size_t is a typedef it compiles. The top answer in this [SO post](https://stackoverflow.com/questions/45383503/typedef-and-variable-names) quotes the relevant standard excerpt. Just like with variables, you can shadow typedef identifiers.
In a classic Rust forum rant manner, let me prefix all this by saying that I actually want to like Rust, and that I would love to some day witness a future where one has to explain oneself for *not* using a systems language with a fancy type system that prevents a lot of errors, but I don't see Rust moving into that direction at the moment, despite claims of the contrary. For a supposed systems programming language, Rust displays a remarkable lack of features in that regard. My favourite examples would be inline assembly, naked functions, disabling the standard library, custom allocators, and last, but not least, an actual memory model, the lack of which -from a theoretical point of view- means that everything inside an `unsafe` block is undefined behaviour. Given that some of these things exist in the unstable builds, one may get along for hobby projects on x86, since that's the one platform for which they make sufficient guarantees as to assume the unstable builds won't get *catastrophically* unstable. But because you can hardly do systems development on stable as of today, Rust is effectively an x86-only language, which really limits its usage. Rust is also badly designed with regards to ergonomics, which mirrors a bad taste the community appears to have in that area. *Making things explicit is not the same as making them ergonomic.* For a negative example, refer to [this article](https://github.com/MajorBreakfast/rust-blog/blob/master/posts/2018-06-19-outer-return-type-approach.md), which turned out to be a popular opinion amongst the redditors of /r/rust. This is really noticeable when using the language. There is an absurd amount of paper cuts and oh-come-on moments, like [not being able to cast a `u16` to a `u8` without external libraries](https://codecs.multimedia.cx/2018/06/nihav-progress-report-2/). Now all of the above are signs for the language just not being ready, and in a vacuum, that would be okay. It is not okay, however, when the community keeps boasting about their production ready language that works so well and blows everything out of the water. Rust is not in a state where unconditional recommendations to learn and use it feel right. It does not "just work". The nightly compiler *does* break your codebase. There rarely is a good answer to the question "which library should I use for this", because they are all in pre-alpha, abandoned, or summon creatures from the seventh plane of torment (or so I'm told). It turns out that "don't" is not a good default answer to "how do I write this data structure". Not everyone wants or is even able to install like 50 packages just to get the language into a functional state. There are several issues left to talk about, but I shall not, since the danger of becoming wildly inaccurate in one's remarks rises exponentially with the length of the reddit comment. Also, compiling Rust to webassembly feels like using a high pressure cleaner to do the dishes. Thank you for your kind attention.
&gt; but it doesn't work for me. **** &gt; language's design goals do not always align with ease of game development. Which part? How so? What, specifically, doesn't work for you with game development in Rust? One would think rusts trivial threading, data race safety, memory safety, and general ability to do anything Modern C++ can do*, to work just as fine as Modern C++ would for game development. *Coming from C++, it seems theres little C++ that can't also be done in Rust, and in many cases i find Rust makes it easier. Theres less hidden magic happening, stuff is explicit. Like error handling. games aren't using exceptions anyway. or all those tricky implicit casts. or the mere act of getting a compiler and compiling your code correctly. And many important performance enhancements are done by default in Rust, and safely too. Such as moving stuff instead of copying everything. compare with `std::move` everywhere. References instead of moving/copying everything, too. and not changing those const references out from under you(no mutable and immutable borrows). RAII. Destructive Move.(Which is the only sensible and right thing to have)
Because you're not including a header that defines the type? `size_t` is a typedef...
I mean, it says right in the article that `Application developers must link against libpthread to use ISO C threads.` So you aren't avoiding linking against pthreads.
I'm definitely not saying C++ is superior. It might be the case that Rust is preferable to C++. I'm simply saying that, in my opinion, C++ has too much cruft, and Rust has too much friction for me. It's not about capabilities, it's about the amount of frustration I feel as a programmer while doing things in the language.
Requires GC
I guess the learning curve (and how you are able to conceptualize it) depends where you are coming from. Tell me about your functional programing colleagues, did they had the same difficulties? My experience is coming to Rust from Scala with C++ background. I find it nice compromise between abstraction power (no HKT or template of templates), resource safety (no segfaults, NPEs, data races, etc) and performance predictability. I like it very much and I hope it will close one day on the missing parts that are not fundamental anyway.
I've come to love the 'fn' keyword. It makes it so easy to find a function's definition. I miss it when I'm coding in C++.
&gt; disabling the standard library Rust has [always supported `no_std`](https://doc.rust-lang.org/book/first-edition/using-rust-without-the-standard-library.html), and many libraries [document their interactions with it](https://docs.rs/arrayvec/0.4.7/arrayvec/). &gt; custom allocators Rust 1.28 actually [just shipped today](https://blog.rust-lang.org/2018/08/02/Rust-1.28.html) with support for replacing the global allocator. I think the per-container allocator work is ongoing. &gt; not being able to cast a u16 to a u8 without external libraries I think the source article is referring to casting to `u8` while being polymorphic over all possible numerical input types. (Which I think indeed requires traits from 3rd party libraries like `num`.) But a literal cast like `0u16 as u8` works just fine.
Rust isn't even limited to x86 for Tier 1 support, I think ARM64 also gets that distinction.
Well, he's learning, so he's not wasting his time. Besides, doing that kind of projects he'll learn some very useful things to keep in mind when programming later on.
Re: optimization. I think cross-crate optimization is less reliable than in-crate optimization. For example, you may need to remember to add `#[inline]` attributes.
Nope, I linked the official document, ARM64 is not Tier 1.
As many other people have pointed out, sorting shouldn't be necessary to find the lowest number. But, if for some reason you need to sort I would point out: * Why sort all 10000 elements, just sort the number of ints that was sent over.? You'd pass the same array to qsort, just a smaller element count. * If you insist on sorting all 10000 elements know that you may be creating the worst case scenario for quicksort (performance-wise). Quicksort does poorly on lists that are already sorted (O(n^2)). A 10000 element array filled with mostly zeros would be such a case. Selection sort would be a much better choice, but you'd have to roll your own (plenty of code out there you can copy). As for where quicksort will put the _unused_ elements - it's entirely under your control. It's determined by the comparison function you pass it in conjunction with whatever value you chose to initialize them with.
For audio specific stuff you might like "The Audio Programming Book" by Richard Boulanger and Victor Lazzarini. I personally really enjoy the style and organization used in "C Interfaces and Implementations" by Richard Hanson but the markup (forgot what it is called) can be kinda offputting at first. I don't know any specific repos but I'm sure you can find the sources for the books and the books themselves floating around on the internet.
Every time I pick that book up I find what I need in like a minute or two. It's organized in a really friendly way.
I guess you could \#undef it if you *really* wanted to, but why?
Ah, that’s true, thanks!
I asked you like 3 months ago about it being used for avr and you said it didn't work. So we can actually target avr by compiling to C while llvm doesn't fix their bugs?
Gamers riseup
Gameup. *** ^(Bleep-bloop, I'm a bot. This )^[portmanteau](https://en.wikipedia.org/wiki/Portmanteau) ^( was created from the phrase 'Gamers riseup'. To learn more about me, check out this )^[FAQ](https://www.reddit.com/78ilq0).
Go made it a priority. Certainly paying some associated costs for it. Go isn't exactly an innovative language. It's what Java probably should have been back in 1995. Specifications are nice to have. But there are plenty of languages that manage to do fairly well without them. Also, you're tone is just lovely. Keep the discussion level ;)
this doesn't absolve electron of being a bloated abomination that consumes system's resources like crazy. 
It's not elitist though, it's being realistic. Yes, it is gatekeeping, but you wouldn't exactly let high-schoolers design an automic submarine. Webdev is nowhere near in terms of the level of expertise and responsibility required to do systems programming. If you write a crashy and slow webapp - it's just your shitty webapp. If you write a crashy and slow system utility, then you are negatively affecting every person who uses this utility.
But pthreads is the standard on Linux. Not the case for Windows.
DJB's implementation of the sieve of Aitkin https://cr.yp.to/primegen.html
Great one, thanks!!!
Yeah if you want to target the esp8266 you have to take that route, but doesnt rust have a version that works with avr, where they have a llvm fork? https://github.com/avr-rust/rust
This isn't how semver works.
The parent comment I replied to said &gt; (Now for all the "but you can use pthreads on Windows!" comments... Some of us would prefer to keep third party dependencies to a minimum on that platform.) which invalidates their argument as `glibc` needs `pthreads` to compile.
Great link. I'm really surprised that Atkins sieve is only like 3x faster than this impl in the 1 billion upper limit case. I was expecting a lot more speedup for the increase in complexity.
Doesn't no_std need feature(lang_items), which is nighly only? And maybe he meant casting from u16 to [u8], wich requires unsage transmute without the crate byteorder.
glibc supports Windows in addition to Linux and Hurd?
Nope, it was a guy named Jens Gustedt.
Go.. Away.... 
There is some truth to this, but personally I think it's just because a lot of Rust programmers come from places other than C/C++ and for them figuring out native dependencies is weird and scary compared to how incredibly easy and frictionless it is to add pure Rust dependencies. The language itself is explicitly designed to integrate extremely well with C/C++, in fact that's its main selling point when compared to Go.
https://rust-lang-nursery.github.io/api-guidelines/necessities.html Okay it's not any dependency it's a public dependency where a breaking change on their side has to be a breaking change on your side. (So, using their types). An internal dependency that could be swapped out without a breaking change is allowed.
I’m new to reddit, the title of the post should have been: ‘Concurrent Object Oriented Generic Language” Don’t know how to fix it.
You are welcome. Now that I think about it have you considered the source for csound? The authors for the audio programming book have contributed to it and talk about it in that book. https://en.m.wikipedia.org/wiki/Csound it is written in c.
&gt; Personally, I don't think it'll replace C, at least not anytime soon. How do you define "Y replaces X" here?
&gt; Rust isn't a C replacement, it's a C++ replacement. What do you mean by that exactly? There is C code which got/is replaced by Rust code: * https://github.com/GNOME/librsvg * https://www.mercurial-scm.org/wiki/OxidationPlan
Regardless of whether size\_t is a type or not (it is, it's typedef-ed in one of the headers and as soon as you include any of the C standard library headers you'll probably get it), it's a reserved name. Anything ending in \_t is reserved for future use by the language, so even if size\_t were not a type then it could in the future and your program could fail to compile. It also doesn't make much sense as \_t is shorthand for "type" in C, so that would read "int size type." What? The value is a type?
IME most people complaining about the rewrite-in-Rust 'movement' seem to be missing the point. Rust has a combination of features that *no* other mainstream language has: Compile-time guarantees of memory safety *and* predictable performance (no GC). No more buffer overflows, double frees or segfaults (NPEs). Can you imagine the effect that this would have on the overall security of our systems which are currently written in C or C++?
1. An parameter list of `()` and `(void)` mean different things in a function declaration. See the notes [here](https://en.cppreference.com/w/c/language/function_declaration). 2. global variables are often a code smell. `extern` doesn't make something "more global", it just says that it's defined in another translation unit. 3. Compilers ignore `register` these days. 4. C has inline functions (As of C99) that are generally preferred over function-like macros.
a function that is declared no parameters and without void in the parentheses takes an unspecified amount of arguments. Global variables are touted as evil because historically people have used them willy nilly and they introduce a lot of often subtle bugs and namespace clutter, sometimes though they're the best solution to a particular problem, like gotos. no idea about register C has inlining, macros however can allow type agnostic functions without the use of pointers which is faster.
No, you can turn off the GC.
And even if you do, it might not put it there anyway, because of what you said.
I think it's safe to assume that everything in K&amp;R except `register` and `auto` (and trigraphs, if it mentions them?) is still current.
&gt; So you aren't avoiding linking against pthreads. But your C code is more portable if you use C11 threads instead of the posix threads api. You only have to deal with different platforms in the build script/Makefile. 
I never do. But, for example, complex applications like the CPython interpreter register (sparsely) certain variables because of the traffic they receive. But that might just be on the safe side and most compilers would get it right without them
No. Don't use it. Its effect is nil at best and negative at worst.
You just demonstrated that it is elitist. You assume that a shitty system utility has more bad impact as a shitty webapp because a web user can go away from the webapp but magically cannot from the system utility and every user is forced to use it forever. So you better write it good. When your system utility is bad no one uses it and they just use a better one in the same way a website user would. Assuming that's not the case with every kind of software and only applies to systems programming IS elitist. 
Faster than what? Unless you have very specific and obscure needs, “aligned” usually means either a word boundary or a page boundary. The standard `malloc()` is already required to return pointers that are (effectively, if not literally) aligned on a word boundary, and most implementations will align large allocations on a page boundary.
So Rust. But you want money.
The beautiful thing about the Rust compiler is that it won't let you "move fast and break things". It will stubbornly refuse to compile until you do things properly.
&gt; 4.2 - functions not taking arguments must be identified by void in the parens This is still 100% true. &gt; 4.3 - global variables are cool Global variables should be used judiciously. Make sure you know what you're doing before you declare one &gt; and you can use extern to make them even more global Yes &gt; 4.7 - use register for hot variables No. The compiler knows better than you what to put in a register, and will probably ignore that keyword anyways. &gt; 4.11.12 - macro substitution makes small functions quicker C has an `inline` keyword now, so you can just use that.
Register should not be used with the intend to get it into the register, most compilers will ignore it for this purpose. But you can say to the compiler that way, that the address of this variable won't be needed 
&gt; Doesn't no_std need feature(lang_items), which is nighly only? It is required for `no_std` binaries, but not for libraries.
&gt; An alternative would be to use R: `Box&lt;Read&gt;`, and then you box up the object that implements Read. A box is a smart pointer, and a pointer has a known size, so you can pass in the box directly without using a pointer to it. Why the forced heap allocation? If the function currently takes `&amp;mut R` and `R: Read + ?Sized`, then you can just change that to `&amp;mut Reader` (or `&amp;mut dyn Reader`, if you you think editions are a good idea).
How do you do it in libraries/
Hey mods, we're being brigaded. Especially from [PCJ](https://www.reddit.com/r/programmingcirclejerk/comments/93y753/rust_in_a_nutshell/)
How did this discussion transition from rust to node.js and electron to Elon Musk and spaceX. 
because I forgot you can do that Time to rewrite some code
 ¯\\\_(ツ)\_/¯ Guess I'm just not very good at arguing.
&gt; Nah, that guy was pretty thoroughly rekt by the follow-up comments. He's not wrong, TBH.
Where should we be paying attention because between Hackernews, /r/programming and /r/rust I never see anyone seriously say something like the Linux Kernel should be rewritten in Rust.
Thanks for all the great answers. This made me realize, that I need to get the basic concepts straight first, If I am to progress further. I wanted to focus on pure C, and use the Arduino as a platform for this experience, because I'm not interested in software programming, only embedded. But I might as well first try to see if I can learn the "Arduino C", and then pure C for the non-Arduino embedded work.
That’s not possible with an static array. It’s called static because the size needs to be known at compile time. If you define int array[99][99] there is 99 times 99 times sizeof(int) space reserved in the resulting binary, which gets loaded into memory and therefor is useable. When you define with [size][size] I am not exactly sure what’s happened. I assume it’s undefined behavior. When you need dynamic sized arrays you need to allocate the memory by yourself using malloc and friends. 
To reply to both you and your parent, there is some work, yes, but &gt; had no plans to work again. is pretty strong; it's down to a few codegen bugs. The team *itself* is not working on this project, but some other people are.
Turbo Pascal was not a professional compiler; Borland Pascal was.
The strictness of Rust's safety checks making me feel like I'm fighting with the language just to accomplish basic tasks. I realize I could put everything into unsafe blocks, but at that point, why use Rust at all if I'm not taking advantage of its primary reason for existing?
I haven’t looked at the code in detail, but the prompt in the program states that the input has to be an *odd* number between 1 and 99, and I suspect the program does a load of erroneous memory accesses if this requirement isn’t met (eg with input 10)?
The definition of `square` in `main()` is perfectly fine, and memory for the array is allocated at run-time.
Yeah you aren't because you just skip over rebuttals that you have no answer to. You basically just wasted everyones time. On a unrelated point it's also comical you think systems programming is some elite thing vs something like programming web servers.
Thanks for the correction. I mixed things up there. But my comment holds for static arrays right ? 
Thanks for the correction. You are absolutely right. 
I would recommend using individual variables for `x` and `y` (`x0`, `x1`, `y0`, `y1`) instead of arrays. Your program is incorrect regardless of whether `magic_square` is defined with a static or variable size. It just happens to work, by accident, in the first case. 1. Ask yourself what the value of `magic_square[y[0]][x[0]]` is at the end of the first iteration of the loop in `create_magic_square()` and where it comes from. 2. Ask yourself whether you have adequately accounted for all possible values of `x[0]` and `y[0]` before using them as subscripts. If necessary, use `printf()` to verify that they have the value you expect. 
No, Rust doesn’t have a compatible subset with C. You can not seriously imagine the Linux, BSD, Windows, macOS, Solaris or AIX kernels being adapted, easily, to Rust, it would be a complete rewrite to do so. With COOGL you can. Look at the language description. There is a book that describes it, free (forever) to download, at www.COOGL.org. Would love to know what you think about the language.
Coincidence. There are several bugs in the program. It just happens to work (or at least, not crash) if the array is sufficiently larger than the run-time value of `size`. But it invokes UB either way.
Turbo Pascal is the consumer version of Borland Pascal. Borland Pascal is the version for commercial software development and came with extra libraries and tools. Both were developed at the same time as different products compiled from the same code base.
Exactly. It’s basically the opposite of volatile and allows the compiler more freedom in optimization.
Thank you! Void is necessary, got it. That’s interesting about macros being type agnostic. I remember the text mentioning that also. 
Macros are just text substitution. Macros don't care about types, the substitution happens at a translation phase where there aren't types yet.
`auto` is just as current as it was back then. It's just never explicitly needed. but every once in a while it is useful to explicitly write `auto` when you want to underline that a variable is not `static` and the storage class specifier has not been accidentally omitted.
The main thing that makes Rust hard to learn is that it requires deep semantic learning, not just learning a new syntax and library surface. I'm a huge Rust fan, but I totally see how difficult this part of the learning curve is. It's not "how do I write this familiar thing in a new syntax", it's ,"how do I completely re-approach this problem, while adhering to a set of formal rules that I don't yet understand or value". Rust pushes a great deal of problem solving into the stage of writing code, rather than at test time. That frustrates a lot of people.
I honestly can't imagine a scenario where that would be necessary. Speaking of `register`, I have serious reservations about having *Modern C* listed in the sidebar...
You’ve obviously not followed my recommendation to educate yourself. Turbo Pascal was the product Borland sold for $50 in 1984 Borland charged an additional $100 for the right to distribute binaries created by the Turbo Pascal compiler. The phrase “Borland Pascal” was used generically and informally to identify the dialect of Pascal supported by the Turbo Pascal compiler. In the early 90s Borland created and object orientated variant called Delphi. There was never a product called “Borland Pascal”. This is all explained on the Wikipedia pages for Borland, Turbo Pascal, Pascal and Anders Hejlsberg, and on many other webpages. 
If it's possible to easily do something using only the standard library, I prefer to do just that. So I'd rather use C11 threads over pthreads or Win32 threads in most cases.
What about Windows support (without Cygwin and other such tools)?
C11 threads are modelled on pthreads, for simple stuff you can almost just search and replace names, not quite, but almost. Go with C11 unless it's missing something you need to do.
For me, it depends on what the library is for, and if there are other libraries that do the same thing without libc++. There's a famous quote along the lines of "the amount of complexity I will accept is proportional to the size of the problem being solved." I think he was talking about LD_PRELOAD_PATH or something, but I think it still stands. If it's a big framework like [kore](https://kore.io) or something, I wouldn't mind it. If it's the only library that does what I need, then I wouldn't mind. Of course, in both of those cases, that's assuming I can continue writing my own code in pure C and not casting my `void*`s. 
&gt; Yes, you can excuse it by saying "it's LLVMs fault", but as an end user I simply don't care, I just see a slow compiler. I have not seen anyone mentioning that it was LLVM fault, so let's not build a strawman please. First of all, as sanxiyn mentioned, the simplest way to check whether performance is in the front-end or in the code generation layer is to use `cargo check`: - If `cargo check` is slow, then you have hit a slow path in rustc. My experience has been that the compiler team is very receptive to bug reports of that kind; you don't even have to do profiling or anything of the sort yourself, although it's appreciated of course. - If `cargo check` is fast and `cargo build` is slow, then you have hit a code generation issue. The problem may *still* be in rustc itself! Or likely it is in the interaction between rustc and LLVM: LLVM does not like much the IR that rustc produces (see sanxiyn comment on FastISel), which is not really anyone's fault, but does mean that the workflow in Rust is slowed down.
I think the most frustrating thing about ownership/borrowing, is that it's not gradual (or as you mentioned, it's a cliff). You struggle for hours/days/weeks depending on how close your mindset was, then overnight it just clicks and you're on. I remember a similar cliff with learning pointers and recursions; some students would understand right away, and others would struggle, leaning on awkward metaphors to try and get going, until finally they abandoned or just groked it. --- I also think that coming from C and C++, there's an extra twist. As a C or C++ developer, you're used to managing ownership. You've developed a usually fairly accurate spidey sense which picks off unsafe patterns and manifests as a funny feeling in your tummy when you're reading a bit of code... though it may remain just that, and you may fail to see what's wrong (and maybe nothing's wrong). In any case, you are used to that spidey sense, and you've got idioms you lean on to avoid tripping. Confident, you launch yourself in Rust, and the compiler sends you packing. That's a harsh reality slap. Humbling, even. It induces doubt: "Have I been doing it wrong the whole time?", and anger: "Wait, I know that's safe! What's this thing complaining about!" Perfectly human reactions which get in the way of a smooth learning experience. And the anger is warranted. As any automatic tool, the Rust compiler only allows a *subset* of safe code to pass. If it cannot prove it, it will err on the side of safety, and reject the code. Which means that a number of idioms you know and instinctively reach out for are now rejected by the compiler, and thus you have to stretch new muscles and learn to do it differently. *What a waste of time!* :)
&gt; The pthreads api seems a bit bloated for most use cases I think you miss-spelt “feature complete.” I don't get why you want a library with half the features missing that is on topic incompatible with the system's standard threading library (pthreads). &gt; think that the int return value of the thread function (in C11 threads) is a little more convenient So... how would you return an object then? 
Wouldn't it be better to always use pthreads so you don't have to learn the function names of two threading APIs? Especially since the migration path is much easier if you don't need to switch the threading API in case you need the extra functionality.
Which development environment for Windows supports C11 threads?
&gt; Imagine that portability wasn't an issue at all. If you were going to develop for a system where both implementation were available, which would you use and why? 
Generally, if a program exits, all of its memory is freed by the Operating System. While it's certainly polite and a good idea to free memory, it's not completely necessary if your application has failed to the point that it's exiting abruptly anyway. 
The criticism here is that only x86 platforms are Tier 1 platforms for rustc, and it's definitely a valid criticism. Hopefully, as the community gets larger the situation will improve; specifically, it would only take one motivated company seriously using Rust on mobile phones to contribute ARM CI machines and immediately elevate many ARM targets to the Tier 1 status. In the mean time, though, non-x86 architectures get the sub-standard treatment. *Note: thanks to the Beta channel, though, I would hope most if not all Tier2 targets to work correctly on Stable; it should only be Nightly which can get horribly broken from one day to another.*
These questions pop up all the time. You might also ask why a hammer doesn't have pneumatic action so you don't have to worry about hitting your finger. But then you wouldn't have a hammer. Just like this, asking why doesn't have some X method to take care of things for you means you want something other than C.
tinycthread.c implements most of C11 threads on both POSIX and Windows platforms. Also, Pelles C does, and midipix.
Hi! You're trying to solve the problem that is probably as old as C: How do I write it securely? There are various answers to that but usually it poils down to the following points: * It is time consuming * It is slow * People are lazy and don't follow guidelines * You should only really use C when you have to A lot of the issues you mentioned go away when you use a language like Java, Python or even C++ and you should always use a language like this in a professional setting when you have the chance. It is more secure, quicker, cheaper and easier to maintain. Now, to the more directy questions/observations. You usually want to avoid macros. maybe not at all cost but pretty close to it. Macros are hard to debug, can have interesting side effects and are pretty hard to get right. The forech loop you mentioned is usually implemented as a function call with a function pointer as parameter and a lot of datastructures do so. Check Glib as an example: https://developer.gnome.org/glib/stable/glib-Doubly-Linked-Lists.html#g-list-foreach Regarding the memory management: In a typical environment it is entirely unnecessary to free storeage prior to program termination. When your program terminates, the virtual address space where it resides in is removed and all memory allocated to it is freed.
I think you read into my question something that I didn't ask. I basically wrote: I've seen these patterns a lot. It seems that often times when writing C generally, we're following the same procedures. I've noticed macros can be useful for turning simple variable assignments into operations that assign and perform checks. Are there patterns in the code you write that account for runtime errors and do you replace them with macros? Aka. How do you handle errors gracefully rather than just aborting?
Rust build sizes are unbelievably large. Nearly-free disk space has spoiled us all, I think.
Why should I want to use an API that is larger than I need? C doesn't know about scheduling, stack size, fork etc, why should I use an API that deals with these things? Larger APIs are less portable, not all platforms will always be posix. &gt; how would you return an object then? via the function's argument, like we do with pthreads if we want to return an integer instead.
\&gt;reminder that they're optional and pretty much no compiler supports it, let alone fullyr First of all, it's not the job of the compiler to support it. It's the job of the C library, which are two different thing. Second of all, there are to three major C libraries - glibc, musl and MSVCRT. Two of those support C11 threads (glibc and musl), while on Windows pthread doesn't work natively as well, and wrappers of WinThread exist for both C11 threads and pthreads, but wrappers for C11 threads are much smaller. \&gt;However, it's a heavily trimmed down version of pThread, and you should use it only for learning, if that actually qualifies as a actual use for it You should use the smallest amount of features you need.
Yeh, thanks for the clarification.
Thanks for wrapping code examples as codeblocks BTW. It's way easier to read than anything I see in this sub being posted. I can read it on my phone. 
&gt; Why should I want to use an API that is larger than I need? So you have a clear upgrade path in case your needs get larger. &gt; C doesn't know about scheduling, stack size, fork etc, why should I use an API that deals with these things? You don't have to use these things. Note that pthreads doesn't provide a fork-like interface, that's an implemenation detail. &gt; Larger APIs are less portable, not all platforms will always be posix. Right now the number of platforms that implement pthreads is much larger than the number of platforms implementing C11 threads. Generally, the extra feature set of pthreads is not that hard to implement. Let me ask a question to you: if the C committee wished to have a simple threading API, why didn't they simply standardise an appropriate subset of pthreads? After all, C11 threads are pretty much just that, except they renamed everything to create an artificial division.
&gt; Are there patterns in the code you write that account for runtime errors and do you replace them with macros? Aka. How do you handle errors gracefully rather than just aborting? The general pattern is this: result = function(); if (function failed) { deallocate resources; return (error code); } that's about it. At an appropriate level (in my case, usually as soon as I am not in a library routine), at an error message instead: result = function(); if (function failed) { print error message; deallocate_resources; return (error code); } I do not wrap this kind of thing in macros because it is very important for me that the control flow is clear at all times. Macros make the code hard to read and don't actually make it much easier to write the program. Error handling isn't the tedious part in writing code, coming up with a good algorithm and interface design is.
&gt; It's always one of the most heavy passes, according to &gt; this comment &gt; it's because the pass has an O(n²) complexity. Seeing it's from 2016, isn't this about HIR borrowck? Does it apply to MIR borrowck as well? (On the other hand, MIR borrowck is generally slower, not faster)
You're going to need to be more specific than "Super vague". So far all you've said is "It doesn't work for me" because "Friction" and "too strict"(Which is just saying "friction" again, so not helpful). What, specifically, exactly, explicitly, is giving you "friction"? What, specifically, exactly, explicitly, is "too strict"? Maybe give examples of the ~~terrible~~ code you're trying to write and which parts are "oh so strict and friction-y and Totally Not Bugs™"?
Exactly! That's a useful design pattern. As a rule of thumb, always deallocate resources in the same function you allocate them and only pass them down the call tree. Some times that's not possible of course, so be extra careful if you have to choose another design pattern.
yah sorry forgot about that the problem is when i run hte program i get some build errors but it allows me to work and the writing to file and the reading to file works as well but when i continue i get some error saying stack around variable choice was corrutpted 
Actually post the errors, please.
And then sit in front of a mountain of pain once you realise that you did need a feature-complete threading API like pthreads in the first place and now have to refactor your entire code.
Because rust loves debug symbols. If you use lto, strip and global alloc you can reduce the output size. Enabling lto can shrink a wasm lib by over 99%.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/gamedev] [Newer version of my pure C math library, MATHC, for 2D and 3D programming • r\/C\_Programming](https://www.reddit.com/r/gamedev/comments/94eylq/newer_version_of_my_pure_c_math_library_mathc_for/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
and it was the fucking mod /u/FuzXXL that posted the damn thing there!
Stop propagandizing steve, leader of the RIR team.
I don’t generally advocate for that, sorry, you’re confused.
Absolute fact, and this brigading by the fucking rustifarians isn't giving it a better fucking name.
It uses LVM, don't act like it wrote it all it's self, which is written in C++ you fucking shills.
Hey guess what? The admins are investigating your brigading. Enjoy your ban.
Not at all, because that's C++, which isn't C... I mean, is this a serious question?
&gt; compiler is smarter than you Depends on the architecture. IBM Power processors have a lot of registers and some functions in hash algorithms benefit from keeping "hot" data in a lot of those registers. Unless you get real specific there is no promise GCC will do the right thing. Smaller cpus like x86 are another story. 
The output size isn't the issue (for me): it's the build size itself. A modest-sized program can easily have a 1GB `target/` directory. I'm often working on a half-dozen programs at once: it starts to look like real storage on my 2013-vintage SSD.
While this is true, it means I can add support for no_std to a stable library. The no_std people still have to use nightly, but I can stay on stable and support stable users while also supporting those nightly users.
Rust was initially made to experiment on a potential html engine (Gecko) rewrite/ succesor for Mozilla. I believe currently there is no plan to do finish the engine for all web standards and build a browser around it anytime soon but large pieces of the rewrite are being added to Gecko/Firefox for safety and speed/concurrency reasons
I don't think their is a brigade. I though the users of /r/rust might want to have some insight into the opinions of other subreddit's users.
&gt; Shouldn't there be a pattern to writing safe C? Sure, I guess? I don't really know because C is in a place in that vertical classification of languages where it's unsafe-ness is actually a feature. One of the first things you learn about C is that it's a powerful tool that takes a lot of responsibility to wield it. If you want to offload that responsibility, I'd say, not for this reason alone, that you're better off with a higher level language, like C++ or C#. 
Your typedefs are incorrect. Are you sure you're using a C compiler? 
ISO/IEC 9899:2018.
C will always let you shoot yourself in the foot, trying to create safety using macros is error prone and clunky. As far as the foreach loop and other such features, if you're maintaining an array struct with the array and its size, it's trivial to use for(i = 0; i &lt; array.size; i++){ temp = array.data[i]; // Do stuff } which, if you're maintaining your array size properly is just as safe and more readable, and if you're not maintaining it properly the macro will not fare any better. &gt; add the pointer to some table that tracks ALL the allocated memory The way I do it when it becomes too much of a burden to keep track of all memory allocation is this: create a stack structure, every time you make an allocation, push the returned pointer on the stack with the function that needs to be called on it for cleanup, before exiting the scope, call a function that will call all these cleanup functions on the stack in the reverse order of allocation. If at any point the function fails, calling this early will only free resources that have already been allocated. example: stack_t stack; int *array = malloc(1000*sizeof(*array)); push(&amp;stack, array, free); char *buffer = malloc(1000*sizeof(*buffer)); push(&amp;stack, buffer, free); vector_t *vector = newVector() // custom allocation with custom cleanup function push(&amp;stack, vector, free_vector); //do stuff freeStack(&amp;stack) and the freeStack function would look somehting like this: void freeStack(stack_t *stack){ for(int i = stack-&gt;size-1; i &gt;= 0; --i) stack-&gt;array[i].cleanup(stack-&gt;array[i].pointer); } which will basically do this: vector_free(vector); free(buffer); free(array); You could even make the allocation one line by making the push function return the pointer it was passed such that you could call it like this: int *array = push(&amp;stack, calloc(1000, sizeof(*array)), free); char *buffer = push(&amp;stack, calloc(1000, sizeof(*buffer)), free); vector_t *vector = push(&amp;stack, newVector(), free_vector); //do stuff freeStack(&amp;stack); Keep in mind you can push custom cleanup functions on there, so it's perfectly feasible to have a function in there that would try to dump its data to disk before freeing so that you don't lose data in case of error. As far as checking for null, you can't really get around it, again, macros will be clunky and error prone, you can relieve some of the burden by making your functions null tolerant however. If something fails and returns null and your program cannot carry on, that's a good indication that you should null check explicitly anyways. Returning a null is like throwing an checked exception in java, sometimes it's fine to catch it and keep going, other times you have to log and and quit.
Yes, that's true, which is already a good point. Now, hopefully, the WG Embedded will manage to polish the last tidbits to push Rust over the finish line :)
libc, glibc, musl, pdclib, libc11, etc, etc, etc are just the standard library dude. What are you trying to do? that's where you start, fuck the rest of the nonsense.
I guess i want to kearn to make desktop and console programs and maybe move on to embedded. I guess i need to learn things like file saving and reading, sockets, and others things like that. And i know that the standard libraries have predefined functions that make working with strings and stuff like that easier.
So if I understand it right: When using gnu compiler on linux and include some of the standard libraries , like &lt;stdio.h&gt;, glibc is the name of the implementation of these libraries. And POSIX is just the standard that tries to make different standard library implementations on unix-like systems like each other when doing something most unix-like systems should be able to do.
Use the [POSIX reference](http://pubs.opengroup.org/onlinepubs/9699919799/)
Exactly. POSIX is the standard (and a superset of the ISO C standard library) and glibc is an implementation of POSIX (+ some extensions) for Linux.
Mingw is not a posix implementation. Cygwin is.
Thanks! Your answer helps. Indeed, at first, when I tried `int square[99][99];`, the original sentence is `int square[99][99] = {0};`, however, `int square[size][size] = {0}` didn't work. It returned `error: variable-sized object may not be initialized`, so I ended up with `int square[size][size]` instead. I just tried these after `int square[size][size]: for (i = 0; i &lt; size; i++) for (j = 0; j &lt; size; j++) square[i][j] = 0; And the problem solved! Also, I tried ur solution, and found it simpler and work like charm! I just need include `#include &lt;string.h&gt;` as well.
Thanks for ur suggestion. 1. At the first loop, `num == 1`, and it is assigned to the first spot at the start. Then the loop copies `x[0]`, `y[0]` to `x[1]`, `y[1]`, respectively. Then `x[0]` and `y[0]` moved to the right top and the loop checks if it is outside the square to change the position, then after the loop the increased num will be in the spot. 2. Just did the initialization, and the program seems to work well. Yes, without initialization, the result of `printf` is totally a mess. Bonus answer: Same result as before. Initialization helps! Thank u! It makes me realize that initialization is really important.
Yes, and? I see no "Ranting" or abrasiveness (for the most part) from supporters of Rust. I think that many programmers/developers who are now, like me, middle-aged, have fear of the new. They're so used to what they've been doing that anything new becomes threatening so they tend to lash out while accusing the so-called "Millenials" etc. of being clueless, over-zealous, idiots where the fact is, they are themselves guilty of miopic viewpoints and irrational ranting. It's kind of sad, but, at the same time expected and normal. Frankly, I'm not as nice as most "Rustaceans". I'd punch most of the people in the face if they were acting as they do in person (I'm talking about people against Rust) for the flagrant, idiotic, misbehavior. Please, some of these people need to take a "Chill Pill" and relax a little. Just because someone is explaining some new ideas, or even advocating for a possible new way of doing things, doesn't mean they are "fanbois" or "clueless" or "zealots" or the other nonsense (like in this thread) that is consistently tossed around. In due time, if Rust truly is a better paradigm, it will likely win the day, if it is nothing but hype, it will fall to the dustbin of history (just as we all will soon enough).
Tried 99 and some odds smaller than it, haven't found so-called situation...... That's a number larger than 99?
I would say ignoring the 20+ years of software engineering that has shown GC languages to be superior in terms of security and reliability (and now getting close on the performance front as well), is far more dangerous than ranting - and certainly more counter-productive for the field.
Just check that `size` is within reasonable bounds. If you use a static array, it needs to be smaller than or equal to the dimension of the array. If you use a variable-length array, the upper limit will depend on your environment. Empirical testing shows you can go up to 11,500 on FreeBSD 11 but only 1,450 on RHEL 7.
thankfully it looks like it might *not* be one of these header only libs! I'll have to see what its like as a drop in replacement for kazmath, looks a lot more streamlined...
&gt; would say ignoring the 20+ years of software engineering that has shown GC languages to be superior in terms of security and reliability How is it being ignored? It is explicitly providing an alternative paradigm that has a sound theoretical basis steeped in CS research.
 counter: int = 0; Why? Just why?
That's a valid point. Maybe it is just the complexity of the implementation I have a problem with. You can look at Swift/ObjectiveC with ARC and the borrow checker is unobtrusive and out of the way. It just works (except for cyclic references, but at least they're understandable - not even sure how to do that in Rust, seems very complex to me).
Out of curiosity, how much time have you spent really delving into Rust? It is definitely a different way of thinking about memory, but, I've found it to be enlightening. It seems like that is a common refrain from people who take the time to examine it carefully and deeply in an unbiased manner.
&gt;thankfully it looks like it might *not* be one of these header only libs! Nope 😂 &gt;I'll have to see what its like as a drop in replacement for kazmath, looks a lot more streamlined... It is, just drag and drop. If you want to reconfigure the library using the macros, just add an \`-include config.h\` in your compilation command, then in the \`config.h\` you can add the macros for configuration.
Any example anyone is ever going to bring up will be countered with. "Well in rust you do it like this" and then get represented with some code that is either slow, wrong, unusable outside the context or 5 times as long as it would be in c. All of these things are part of friction.
I’ve admitted I’m new to Rust. Evaluating stdlib and other sources of code. I’ve read the entire Rust documentation. Frankly it’s quite light on practical examples of common patterns except for very trivial ones. 
Check out https://github.com/ossu/computer-science
It would be let counter: usize = 0; (You need the `let` and `int` isn't a type) &gt; Why? Just why? Well, most of the time the type is inferred, so it's let counter = 0; This is a simpler transformation than if we used a C-style declaration. But beyond that, `let` takes a *pattern*, not just a name: let (a, b) = some_tuple; This will take a tuple and break it apart into its two elements, `a` and `b`. The form with the type written out might be let (a, b): (i32, i32) = some_tuple; these forms are easier than (int a, int b) for example. Basically, this syntax is how languages with type inference usually do it, so we followed suit. It carries over into what function arguments look like too: fn foo(counter: i32) { same form.
I've been learning for a couple of years now, so take all this with a pinch of salt, but: I think it depends on your taste. I usually like fairly traditional books, so I enjoyed K&amp;R's The C Programming Language. It's straightforward, practical, and treats you like an adult. Avoid any books that claim to teach you x in n number of hours/days, or market themselves as for absolute beginners. Programming takes time to get good at, and rushing doesn't help. Also, lots of people have very strong opinions about things that ultimately don't matter that much, or are more matters of taste than they appear. As for other books, it depends on the subject. I like 'Compilers: Principles, Techniques and Tools' (Alfred V. Aho, Ravi Sethi, Jeffrey D. Ullman ), Tanenbaum's Modern Operating systems, both of which are nice because you can buy cheap second-hand copies. That's very taste-dependent, though. I spent a lot of time before I was into programming being into philosophy, which turns you into the kind of masochist who only feels comfortable reading pretty dry work. I think generally speaking, the biggest guideline I can suggest is only read the work of experts. People who are really the giants of their field are pretty generous with information, and they write manuals, books, and blog posts. Reading somebody like Knuth is usually more worthwhile than reading people just trying to market themselves as knowledge workers. There's a lot of stuff out there that's opinionated, hype, or both. You can usually avoid that by picking authors who have really impressive technical accomplishments or serious renown - so for instance, people who were the lead maintainer on an interesting project, the creator of a language you use, responsible for an advance in graphics tech, etc.
&gt; slow compilers are not at all intrinsic to existing languages This isn't much help if they're all slow anyway. As much as rustc *could* be less slow, it's not. &gt; Contexts are just passing a struct to all functions - glorified globals. This completely misses the point, which was emphasised repeatedly. Contexts are a convention. It is important that they are there by default. Trying to retrofit them onto an existing language isn't going to work without rewriting the world. &gt; A stack as a temporary storage that is manually cleared each tick surely makes rapid gamedev possibly, but kills any assumptions about the lifetimes of the data. What about slow running tasks that persist across multiple frames. (Not that you'd choose Rust for its memory guarantees but it would prevent that mistake.) While you gain productivity - again ideal for gamedev - I feel like you lose the control of C or the flexibility of something like Rust, which solves the problem with move semantics. This is pretty much entirely false. Blow's whole point is that heap allocation of dynamically sized temporaries is a problem. Jai still has the main, slow heap; you are just only expected to use it sparsely in larger, mediated chunks. Your slow-running task is going to be storing its long-life data in, and allocating from, the structures explicitly allocated for that job. The frame allocator is designed for those ill-fitting temporaries that you need for working, and its existence vastly simplifies the equation! You *can't* just use move semantics, because move semantics means either allocating on the stack─only suitable for regularly sized data, requires slow data movement, has problematically uncomfortable lifetimes─or it means allocating on the heap. If you do go with the heap it means you take a huge runtime penalty and have to mitigate this with coalescing, arenas, and all manner of interference that is invasive and difficult to make APIs for; most Rust types simply don't support anything useful there. The result is the only way to handle this stuff properly in normal languages is extremely difficult and error-prone, and the only way to handle this stuff nicely is horrifically inefficient. &gt; `set_icon_by_filename`: Alright, yes it can be menacing to have to set the icon of an executable but he says it himself, "because Microsoft makes it harder than it should be". This hasn't anything to do with C/C++. It's just tooling. Why language level. This was just an example of the difference in philosophies. &gt; "C++ is underspecified and it's a hassle to build stuff". C++ has excellent tooling. lol &gt; Rust has cargo which is amazing. I don't know if Blow has much against Cargo as a whole. For sure he would point out that it's incredibly slow, and he argues against its form of dependency management (Rust is much more "newest dependency requires transitive version updates" and "uptime is a distributed responsibility" than he likes), but his arguments against using Rust in game dev are not focussed on Cargo. &gt; Arbitrary compiler plugins. Alright cool. Like procedural macros in Rust. No, not really at all like procedural macros. Watch a video on it if you care for details, but the basic idea is that the compiler is an event-driven loop that can be hooked into at every level by a dynamic (interpreted) runtime, which happens to also be his language. 
Also he mentioned Cygwin and Mingw32. Cygwin actually provides a full emulation layer for POSIX calls and emulates them in Windows (even with things like sockets, so you don’t need to write BSD -&gt; Winsock yourself as you would need to with Mingw32). So there is a small overhead for using it. Some devs just take the approach of making all their code POSIX compliant and then just using Cygwin if they want to build for Windows. With Cygwin you’ll need to include the Cygwin runtime library with your program for it to run. Mingw32 doesn’t provide a POSIX emulation layer, but some of the POSIX functionality is supported via runtime libraries. Mingw32 has no overhead, and no runtime library needs to be included with your executable. I personally just use Mingw32 because the only code that doesn’t work on Windows for me is BSD Sockets, and there is only a few differences between BSD Sockets and Winsock. I know this isn’t directly related to your question but I just wanted to expand on what he said to you :).
I only have a grade school level basis with mathematics, and a lot of people suggest Knuth (Concrete Mathematics) but it seemed like a very hefty leap. Is there a good primer on algebra and anything to help me grasp the finer portions of the math I’m likely to come across? I’m going to take a lot from this reply, so I’m just trying to grease you for more.
Isn't cygwin programs needing some sort of copylefted library to run outside cygwin? And would that even allow me to program gui applications? I don't have anything against opensource console applications, but think i will choose mingw or maybe even learn to use visualstudio and microsoft compiler instead😅. And I wonder are the windows libraries worse that the once built upon posix? Because i often hear people say learning c is easier to learn on unix-like os than windows.
[C Programming: A Modern Approach - K N King](https://www.amazon.com/C-Programming-Modern-Approach-2nd/dp/0393979504) This book covers high, low level of C99 and C89! Should be enough to be a proficient C developer! It is wise to keep a good reference book: [https://www.amazon.com/Reference-Manual-Samuel-P-Harbison/dp/013089592X](https://www.amazon.com/Reference-Manual-Samuel-P-Harbison/dp/013089592X) There is a good book with new concepts its not a beginner book so you must know well C to understand it: [https://www.amazon.com/21st-Century-Tips-New-School/dp/1491903899](https://www.amazon.com/21st-Century-Tips-New-School/dp/1491903899) **PLEASE IGNORE ANYONE THAT ADVISE A BOOK FROM 30 YEARS AGO!** 
Well, my feeling is that school maths is not that great a preparation for programming maths. School generally involves a lot of computation exercises, without really teaching the basic principles and proofs that you need to be more than a really shitty calculator. In programming, you have a computer, so it's much more important to know the proofs and principles - and that's the kind of thing you get in undergraduate textbooks. Generally speaking, I think the amount of maths you need is really dependent on what you want to do. Plenty of good programmers are fairly poor mathematicians. I can't recommend the Knuth book, since I haven't read it - but he's generally very good. All I can say is that learning maths as an adult (I do this too) is very different to most other kinds of reading. People generally read about five pages a day, and consider that productive. It's pretty slow, on the whole, and it's worth doing lots of exercises. As for books, I like Hammack's Book of Proof. A lot of the time, books like this assume a fair bit of knowledge (like what's a rational number, a real number, etc) - but wikipedia is your friend, and if you're really stuck, Freenode has an excellent #math chatroom. I also have a massive book about Calculus by James Stewart that's cheap, extremely comprehensive, and has an appendix that covers algebra. It's also colossal, so I've not worked that far through it. To be honest though, while a lot of the inspiration for cutting-edge work is maths-based, I think it's not that important for most of what people do. Algorithms and data-structures generally don't require a great level of maths to implement, and a good command of the available options in this regard means you can do pretty much everything. I think the maths portion of programming is over-egged, tbh. Most people would much rather work with somebody who produces nice, simple and clear code that's well documented than a mathematical genius.
It seems really weird to read it like that, that's all I complain about. The language has some interesting features. I really like how easy is to control the memory allocators, loggers, etc used by a library. Right now we develop some internal libraries that are used by all kinds of products made by my company and some have really strict memory constraints (some are on systems where malloc or new doesn't exist) so whoever uses the library needs to register callbacks for memory management, logging, synchronization primitives and so on. I'd like to have that simplified by the language. 
Because most of it teaches is bad practices nowadays! C89 is not that different of C99/C11 but programming is way different! 
Just curious here. Any particular reason you're going for C?
yep, I think Python, web development would easier and faster to change of careers.
Right. And even if the OP is not interested in web development, it's insane how easy it is to get started with all sorts of things using python and its huge set of ready to use libraries.
I don't really know how to fully answer your question, but for a more rigorous and theoretical introduction to programming and computer science, you could follow SICP (video lectures and book are available online). [http://web.mit.edu/alexmv/6.037/sicp.pdf](http://web.mit.edu/alexmv/6.037/sicp.pdf) [https://mitpress.mit.edu/sites/default/files/sicp/index.html](https://mitpress.mit.edu/sites/default/files/sicp/index.html) [https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-001-structure-and-interpretation-of-computer-programs-spring-2005/video-lectures/](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-001-structure-and-interpretation-of-computer-programs-spring-2005/video-lectures/) To me, still today, this is the best introduction to CS and programming that there is. However, don't take this as your primary material as this is too theoretical. I think it's beneficial for you to approach this as something you study little by little every week for long term returns. The course uses a programming language called Scheme, but that is close to irrelevant. You'll be able to apply what you learn in this course pretty much everywhere.
Python is a scripting language, for some definition of scripting language. The Linux, and UNIX philosophy is to use such languages whenever they're appropriate. People in the UNIX world realized that C wasn't exactly a good programming language for you to be using most of your time ages ago. Adoption of things like perl, python, awk, Java, php, and so forth happened in the UNIX world way before anywhere else (as far as I understand). This is so much true that the large body of programming languages that we have today sort of came from the UNIX world. The notion that you should stick to C (or to C++) as your main primary choice of language was never part of the UNIX philosophy. This actually is a more Windows "centric" point of view. In the past (90's and early 2000's; and even today to some extent, but much less today), if you wanted write windows software, you basically had to use C, or C++ (nowadays it's mostly C++ on windows afaik).
It's not likely anyone will help you when the posted code isn't formatted as code and contains a bunch of erroneous backslashes. If you're having trouble formatting your program as code on Reddit you could also use any number of external tools to paste your program (gist, pastebin, ideone, etc...).
Signals aren't actually part of C. That's a feature offered through your kernel, if it even supports them. I often work with signal handling in Rust, and it's easily done by just importing the `libc` crate and doing what you'd do with C. Also of note is that Redox OS is a microkernel written in Rust which is interfaced with through its syscall crate, rather than a C interface. So signal handling has to be set up through there instead of `libc`, since it's not a C kernel.
Shared libraries are often a bad thing, however. Through static linking, you may enable LTO to strip out every function that your program doesn't use. You then end up with a lean binary that can stand on its own. No need to worry about solibs, solib versioning, or a bad dylib compromising your entire system. When building multiple projects, Cargo will often share the build artifacts if you've already built that version from another project. And as for C headers, there's bindgen for generating a Rust wrapper from a C header, and cbindgen for generating a C header for a dynamic Rust lib that exports a C API.
Imperative programmer for 10+years (C/C++,Python, Java, Go). Today, i'm becoming like a child learning Functional Programming or FP. It is called Haskell. Not Scala. Not F#. Only Haskell. It is too important not to understand FP. 
You might be interested in [fern](https://docs.rs/fern), [rayon](https://docs.rs/rayon), [crossbeam](https://docs.rs/crossbeam/0.4.1/crossbeam/), and [parking_lot](https://docs.rs/parking_lot).
Actually, I think that Rust lends itself well to the type of architectures that AAA game development relies upon. Games are often written with data-oriented architectures and entity-component systems. Rust leans heavily towards the direction of data-oriented architectures, and entity-component systems are the ideal API that the borrowing and ownership system is happy with. Check out [specs](https://slide-rs.github.io/specs/).
Oww !! i have the same perspective that a rewarding learning process should be through the hardest way and using information resources that doenst make us comfy, we need to push our limits . tbh when i decided to learn C as freshman i picked u some basic (syntax, definitions, etc ) on a website called openclassrooms but the material was so verbose and felt like i m memorizing the stuff. so i jumped to dennis ritchie C book that was beyond my standards and whats i was expecting, it takes me about 3 months to relativly digest most of the content, then i did some project euler exercices and other C practices... and trust me despite it was the hardest learning period in my life but the first time i felt succes and achievment ( sort of ) I m still in high school ( my last year ) my maths skills arent the high-end, i m not genuis either, i struggled during my the process and found some gaps in my maths knowledge ( the system education in my country is trully shiit ), but ... fucc off thanks to internet i picked a lot of books (spivak calculus, ivan savov books , ...) and start cramming all the pages . TL;DR : THE BEST WAY TO LEARN SOMETHING, PICK UP THE BASICS ==&gt; GET OUTTA UR COMFORT ZONE
I think that LTO can fix that issue
You can also cast anything to a void pointer in Rust, and vice versa, and use it however you like. It doesn't stand in your way when you acknowledge that what you're doing is wrong, and it will make it trivial to revisit that code you write when performing an audit via a quick ripgrep of the codebase. let void_ptr = &amp;data as *const _ as usize; let struct_from_void = ptr as *const usize as *const T; Unsafe isn't required to do the above, but it is required if you want to get data out of the pointer. println!("{:?}", unsafe { &amp;*struct_from_void }); Playground example: http://play.rust-lang.org/?gist=571ca9b08afb45de355b602aec3842ad&amp;version=beta&amp;mode=debug&amp;edition=2015
Binary sizes are only large on Linux because by default they are compiled with jemalloc statically linked into the binary. It's now possible to disable that and use the system allocator instead, but jemalloc is usually much more efficient at allocations.
I'll bite and say that the absolute beginner series was actually quite good from what I remember. Yeah, they didn't teach you best practices, idioms, or paradigms, but they *did* stop to take you through the weeds like a lot of programming books refuse to do.
&gt; I would say ignoring the 20+ years of software engineering that has shown GC languages to be superior in terms of security and reliability Of course it does. The industry alternative to GC languages for the last 20+ year have been C and C++, languages that, in addition to not being GC-ed, aren't memory safe. The hypothesis behind Rust is that the reason GC-ed languages have been more secure and reliable is because they've been memory safe.
Most code that you write does not have to be unsafe, though. Even within low level libraries and tools. In fact, Redox OS is written with a minimal amount of unsafe in the kernel, of all places. A benefit to Rust for such domains is that you can take advantage of the safety guarantees and high level zero cost abstractions (ADTs are easier to work with than Unions, &amp; Iterator makes for some very efficient machine code compared to a for loop), as well as the ability to audit the few instances of unsafe easier.
I think that linked example is a very good example as to the many bullshits you have to do. ```.to_owned``` ```as *const _ as usize``` ```unsafe { &amp;*data }```
Hey, I like my generics. It produces some rather flexible data structures &amp; APIs. IE: just recently I wrote a crate that contains a data structure for building a parallel bounded single-reader, multi-writer. The kicker is that it doesn't matter what types the source or destinations are, as long as they implement the corresponding traits. `io::Read` for the source parameter, and `io::Write` for the destinations. That means that each source and destination can be completely different types. They could be files, in-memory data structures, or even network sockets. Doesn't matter. The C alternative is to use void pointers, which is entirely unsafe.
Coming from the Redox OS project, I see no doubt that Rust already is replacing C. We have an entire microkernel written in Rust, with a display server, UI toolkit, system shell, file system, etc. All the things that you'd normally use C for happen to work just as well, if not better, in Rust.
Rust makes you aware of the costs of your actions. Converting a string view into a string buffer is going to require a heap allocation. Declaring that the string will become an owned value at runtime is hardly BS. In fact, the same also applies to C, as there is a big difference between a static string view located in the binary space of your program, as compared to a string buffer that exists on the heap. It'd require much more typing to do the same in C, invoking malloc to ensure that the string is in the heap. And for messing around with pointers, it is precisely to discourage software developers from doing crazy nonsense like that.
The benefits of shared libraries (possibility to update libraries without relinking, memory usage, disk space usage) are as important as ever. Static linking makes sense only if you follow the questionable stali/suckless.org philosophy and avoid libraries at all, and use lots of individual cooperating programs instead. But rust doesn't really encourage that either. LTO helps only to a limited extend. Code in libraries is often so entangled that there is not much to be stripped. C has solved to problems associated with shared libraries; it has a stable ABI and makes library versioning easy. In fact C is pretty much the only language that has achieved that (C++ still suffers from ABI incompatibilities), which is the reason why it is so popular. Rust needs to solve them too to be taken seriously as an alternative to C.
Obligatory http://harmful.cat-v.org/software/dynamic-linking/
&gt; possibility to update libraries without relinking Doesn't benefit the end user, and linking is typically pretty quick &gt; memory usage, disk usage Research shows the opposite: more memory, and more disk usage
In the example you provided there is no need for the string to be on the heap, so yes it is BS. And if I want to "mess around" with pointers I should be able to do that without the language being in the way all the time for that. It is not crazy to cast void* data to know structs. A very simple example would be the loading of a file. You load some data into a buffer and just cast it to the header you expect it to be.
For some reason the users here believe that Object Oriented Programming with C is 'hacking' or a 'perversion' of the language.
I actually think the gophers evangelize more than the rustaceans. 
It has nothing to do with efficiency. The array is allocated on the stack and different systems have different default stack sizes. I don't remember how to modify it, try `ulimit -s`. 
&gt; Doesn't benefit the end user, and linking is typically pretty quick Updating a shared library (e.g. for a bug fix, including security patches) requires the end user to just install the updated library. Updating a static library requires them to update every single program that uses the library, by linking each program again against the updated library or downloading updated binaries for all the programs (and these might be huge with static linking). And this applies recursively if the library is also used by other libraries. 
well now people can.
These are great, and I appreciate the examples from your own code. Thank you for the review!
For modern architectures (i.e. CPUs with cache), linked lists are the worst data structure you can use with respect to performance. Start with a vector. They are even simpler to implement and will always be faster (except in the most contrived cases that have almost no real world use). Bjarne Stroustrup (C++ creator) gave a explaining that arrays are always faster than linked lists on modern architectures. https://www.youtube.com/watch?v=YQs6IC-vgmo Chandler Carruth also makes the same point. Efficiency with Algorithms, Performance with Data Structures https://www.youtube.com/watch?v=fHNmRkzxHWs At 34:40, he talks about "Performance and Data Structures". Reveal: "Discontiguous data structures are the root of all (performance) evil". and "Just say NO to linked lists". "There is almost nothing more harmful you can do to the performance of an actual modern microprocessor than to use a linked list data structure." Cache effects are real and to be taken seriously. Or stated differently, modern RAM busses are extremely slow. 
For modern architectures (i.e. CPUs with cache), linked lists are the worst data structure you can use with respect to performance. Start with a vector. They are even simpler to implement and will always be faster (except in the most contrived cases that have almost no real world use). Bjarne Stroustrup (C++ creator) gave a explaining that arrays are always faster than linked lists on modern architectures. https://www.youtube.com/watch?v=YQs6IC-vgmo Chandler Carruth also makes the same point. Efficiency with Algorithms, Performance with Data Structures https://www.youtube.com/watch?v=fHNmRkzxHWs At 34:40, he talks about "Performance and Data Structures". Reveal: "Discontiguous data structures are the root of all (performance) evil". and "Just say NO to linked lists". "There is almost nothing more harmful you can do to the performance of an actual modern microprocessor than to use a linked list data structure." Cache effects are real and to be taken seriously. Or stated differently, modern RAM busses are extremely slow. 
Aside from what others have said, if you've been out of school for 15+ years and only have grade school maths background, you will need a more complete reference to learn from. K&amp;R C is very good, but also terse; not everything is explained. K. N. King's book on the other hand is quite detailed and takes you from a blank slate starting point.
ok so when i change that it does not give me an error but the program auto closes
 char same_item; scanf("%s",same_item); Look at your compiler's warnings. They are important. Do not ignore them.
You need a while loop around your program options, user prompt for choice, and switch statement. while (choice != 'f') { statements; } 
ok i made the changes now i get Run-Time Check Failure #3 - The variable 'choice' is being used without being initialized. i am confused as hell i am horrid at c and freaking out here
Take a deep breath. Walk away from the computer for a bit. Go take a walk for 10 minutes. Drink a glass of water. Once you come back, post the code you have. I fixed all the compiler warnings and the program works for me except for this: system("pause"); Which you should really never ever do. Don't use system(), especially not for something as simple as pausing the program. Use getchar() instead. Also, as another posted mentioned, if you only want to exit when the user presses 'f' at your menu, you need to wrap your menu in a loop.
Hey thanks again for the help been stuck with this program for weeks by here is my updating code u mind sending me the fixed code https://pastebin.com/XaXk0LWR
It returns 8192. It seems the program is poor on performance and fails to reach that and stuck on a number far from that.
I would love to hear what you think about the COOGL language.
C/C++? You either develop in C or C++...choose one ignore the other! 
If you're execing a new program in the child process, that program is going to have to set its own signal masks and handlers. They're not carried over across an exec - how could they?
You haven't fixed any of the things I already mentioned in this code. Look at the compiler warnings, fix what is wrong, and then see how it works.
Do not post content in Urdu or Hindi. Do not post C++ content. Since you keep doing this, enjoy your ban.
&gt;how could they? Just like the other stuff is carried over one could assume.
A million years ago when I learned C, the text was the simple enough [C by Example](https://www.amazon.com/Example-Easiest-Learn-Program-Programming/dp/088022813X). I'm linking this even though it's crazy ancient, but you can score a used copy for just under $6 USD. And it certainly reads on the level of high school. The other book was of course "The C Programming Language, Second Edition](https://www.amazon.com/gp/offer-listing/0131103628/ref=dp_olp_used?ie=UTF8&amp;condition=used) although I see it's now $30++ which is kind of crazy as it's from the late 80's (88). C itself is a very small language, and it's almost easier to start small. Don't jump into C++ or C11 as initially it'll be crazy confusing. Unfortunately older tools end up being collectors items, which is a shame as something as simple as "QuickC for Windows" would be enough of an environment for a beginner, but you'll probably have to go the way of Visual Studio 2017 which .. may be a bit daunting but I'd highly recommend messing in the IDE before even going into the CLI.
I've written a lot of software in Rust, even something as complex as a next-gen system shell for Redox OS, without ever needing to allocate except when necessary (thanks to the Iterator trait). Satisfying the borrow checker is quite simple, even for applications with a lot of threads and mutable state across threads. There are a few tricks to know, but they're kind of obvious once you think about it. Feel free to reach out and ask the community, or take some time to read the source code that others have written.
Nah, there are plenty of jobs in C and C++ (although these are different languages and often jobs involve writing one or the other, not both). Many of the largest tech companies in the world, such as Google Amazon, Facebook, and Microsoft, hire veritable armies of C++ programmers. Likewise, there are legions of C programmers working at any company that makes an OS or other low level software like Microsoft, Apple, Google, Intel, Qualcomm, Cisco, etc. There are no shortage of positions, you just have to look.
C is for low level OS and embedded work right? What does C++ do? Is there significant overlap between Java and CPP?
The .dll.a files are import libraries for DLLs, the other .a files are static libraries .
https://www.educba.com/c-plus-plus-vs-java/ What a simple search cant do for you
&gt;I would love to hear what you think about the COOGL language. haha my thoughts are mostly questions. 1. what does it mean for a language to be 'safe'? what is it about C/C++ that makes it unsafe compared to other languages? 2. what problem does it solve? Since C is ubiquitous, what is it vulnerable to? malicious attacks? human error?
Cool project!
C is very viable as a career, but I feel like most places that are going to do lots of C will value an engineering background (over something like a boot camp)...
&gt; Contexts are just passing a struct to all functions - glorified globals Or alternately a reader/state monad. 
&gt; I assume you have limited your comparisons to C/C++ because we are in the C subreddit Indeed. Outside of C/C++ I am also aware of D, Nim and Zig for example. They all have some interesting properties that the others don't. Nim has the best C++ FFI for example (by transpiling to C++) and Zig has alignment as part of the pointer type (for compile-time checked type-casting). &gt; Custom allocators are still experimental, but because the standard library has an `experimental` namespace, they are effectively there for people to try out without risking explosions elsewhere. &gt; I can't say anything about the positioning, and of course there is progress, but as of now, systems programming is another item in the list of things rust claims to be capable of but the requested feature is currently unavailable, please retry later. I must admit having a hard time reconciling those two statements. I don't see much of a difference between using a Nightly version of Rust and the `experimental` namespace of D. In either case you get code that has not been thoroughly validated and whose API/semantics may change in the future. Using the Nightly version of Rust, you get `asm!`, naked functions, and all the features necessary to write OSes (and people do: TockOS, Redox OS, as well as multiple OS tutorials). You still miss the memory model, which is of course a concern, so you have to use the Nomicon instead as a guide for what is allowed and what is not, which is not as formal, but still gives you quite a lot of mileage in the mean time. *(Note: I am not sure whether D/BetterC has a memory model)* 
While there's no shortage, there's absolutely a lot less jobs in C than there are in higher level languages.
Yes. Moved from Java to C++ and finally to C job. Never regretted it.
This has **nothing to do with efficiency or performance**. Get that out of your head. Instead, try to figure out, *just from reading the code*, approximately how much stack your program uses for a 1,447 x 1,447 magic square.
I’ve just grabbed its pdf, so far it’s a great read, thank you!
I guess a better question would be, why use this over C++? Does C have add any real benefit to object oriented design or vice versa?
Not a begginer and not very well as we need to spent years to get really good at one programming language! 
Although C is well known for low-level and system software, one can write just about any kind of software with C! C++ is another programming language with different features. Comparing C to C++ is like comparing Java with Clojure! 
yeah just look into embedded
I've worked professionally with C for over 20 years. I've found that opportunities are more difficult to find these days as modern languages creep into spaces that were once reserved for C. In particular I find Go being used where C and even C++ might have been in the past.
Been doing it for the last 2 decades. It's doable, but your luck may improve based on the regions your are in. Currently I am searching for a job and around here there is some embedded work here and there, but more likely, I'm seeing across Java, Database, Front End, and Full Stack development. So it's there, but it takes some patience to find. 
C is an amazing language, as is C++. Not only are there lots of opportunities but the salaries are enormous too. C is fiddly and low level. Every modern is designed to do what C does but in an easier fashion and so that regular devs. An manage larger codebases more effectively. C and C++ are fast and lightweight, making it ideal for embedded devices. It’s also essential where single threaded performance is either a necessity (AAA games, OSes) or a competitive advantage (Finance) You won’t find much of it for web apps and simpler systems where the solution could involve a desktop computer and a simpler language.
The instructor
Alright, thanks for the advice
I can't guarantee anything but they should be safer than they used to be, as the site was [acquired not too long ago](https://www.reddit.com/r/sysadmin/comments/4n3e1s/the_state_of_sourceforge_since_its_acquisition_in/) and there has been an effort to purge the adware bundled in the past.
I want to be you someday (But I want to skip C++ phase)
Thank you
&gt;I guess a better question would be, why use this over C++? Does C add any real benefit to object oriented design or vice versa? i don't know. it's not the question/problem i wanted to solve because i don't really care what language you use. the problem i wanted to solve is that writing object-oriented C code is tedious, repetitive, and error prone. yet i still find it fascinating. So I automated it.
Hi I just posted a brief answer to your first question under: https://www.reddit.com/r/C_Programming/comments/94tq04/what_makes_coogl_a_safe_language_coogl_is_a_new/ All the code written in C (and C++) is at risk from being attached externally (over the network, by feeding it malicious data in files, or interactively) and exploited and taken over by malicious hackers or entities. Programming errors that lead to software being vulnerable from C's unsafe nature are prevented by the COOGL language.
Note that C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
Also, if you want people to help you with your memory issues, consider posting your source code. It's hard to diagnose issues in source code nobody has seen but you.
If I had linked only to the book (PDF) would that be considered self promoting? I can edit the post (I think) and do that. Thank you!
Yes, I agree. It is more of a general question if this could happen in my situation. A general answer therefore is absolutely fine.
You do it incrementally. C and COOGL code can coexist in a large project. Some amount of code reorganization is required. For example for the Linux kernel each kernel component can be adapted, one by one, for example the memory management code under “mm/“ and it’s matching architecture code “arch/arm64/mm/“ (and other architectures). Then you build and test, and repeat with the next component. Eventually you have a whole module (the kernel itself) and then you proceed to the next module, say a specific file system. Eventually over a large step by step effort the whole code base is all COOGL code. The impact on the code is small. If you reorganize it right you can still compile the code with the C compiler. That requires that the reengineered code is reengineered first into Clean, the common subset of C and COOGL. This would allow for parallel development down both paths, 100% C code while reengineering into COOGL. For example to cutoff module by module from C to COOGL.
It's all self-promotion, regardless of what you link. There is not a problem with self-promotion per se, just keep it to one post every two weeks per project. This is a subreddit about C, not about COOGL, so people are not going to appreciate getting spammed with content about COOGL.
Ok thank you. I thought C programmers would be interested in a better alternative than C++ as an evolution of C.
Surely they are! But one post every two weeks should be enough.
Also, /u/RamonPantin, using more than one account is a huge no-no and a bannable offence. If I see you using more than account again, I'm going to ban all your accounts without further warning. Just keep it to one account at a time.
Interesting to see. I especially like that opening a block comment twice is an error, although I think the /# style seems somewhat redundant. I skimmed over the book and have a few questions: What is the difference to Rust? It seems to fill the same niche of being a safer low level language with checked unsafe code and built-in concurrency How are inheritance and other features with potentially hidden costs implemented and what is the runtime overhead involved? I am somewhat confused about exceptions, because on the one hand, the book says there are none, however it also states that out-of-bounds access results in exceptions Is there a repo for the compiler? I'm sorry if my comment comes across somewhat prying, I always enjoy seeing new languages pop up and would love to see the compiler code
I only have one account, I am new to reddit. I am using my real name. Confused.
I see this 2nd post was removed, was that because a moderator removed it? New to reddit, my daughter said that I should read the rules for the subreddit and I didn’t see anything wrong there about trying to find an audience to get feedback from about the language.
I am a moderator of this subreddit (as you can see by the green [M] next to my posts). Every subreddit (i.e. this is the subreddit /r/C_Programming) has its own moderators and comes with its own rules. There are a few [sidewide rules](https://www.redditinc.com/policies/content-policy) which apply everwhere and should be absolute no-brainers to all users. Apart from these, subreddits are allowed to make their own rules. As for this subreddit, I haven't really written down the rules, but this is roughly how I moderate posts: * this subreddit is about the C programming language, posts that are not about C are removed. This also applies to posts about unrelated topics only posted to get the attention of C programmers (surveys are a common offender) * shitty beginner tutorials are removed * self promotion is okay as long as you keep it within reasonable bounds. Don't spam the subreddit with posts about your project, once every two weeks is okay. Posting in shorter intervals is okay as long as it's not about literally the same thing. As a courtesy I generally flair removed posts as such. Generally, there is no easy way to tell if your post has been removed; I tell people why I removed their posts so they can improve their posts for the next time. Note that you are still welcome to post if your previous posts have been removed. Just try again while obeying the rules.
Thank you for the feedback/questions. ‘I especially like that opening a block comment twice is an error, although I think the /# style seems somewhat redundant.” That is because the C Preprocessor is gone, so no #ifdef-in-out code, so you still need a way to comment out code in a hurry that already has comments within it. ‘What is the difference to Rust?” Rust is syntactically too different from C. Not good to reengineer, incrementally, a large code base. Rust is good if you are going to rewrite the code. Rust is not good if you want to keep &gt; 95% of the code untouched. How are inheritance and other features with potentially hidden costs implemented and what is the runtime overhead involved? “I am somewhat confused about exceptions, because on the one hand, the book says there are none, however it also states that out-of-bounds access results in exceptions.” Exceptions are delivered to the program and you can catch the with a C/UNIX like signal handler mechanism. There is no language level try-except syntax to write exception handlers. “Is there a repo for the compiler?” Not yet, but son, the compiler is still being worked on. It is not done.
Thank you!
Well, /u/T_R_I_L_L reposted this exact post of yours. See how it says /u/T_R_I_L_L as the submitter of this post but /u/RamonPantin as the submitter of the other post. I am not sure if it was you who reposted this, looks a bit weird.
When I click on "same post" above it takes me to my post. How do I find the post from /u/T_R_I_L_L ? I can't see that one. Can you send a link to that one?
By the way I am logged in - with one account - from my Mac, my iPad, and from my iPhone. You can probably figure out who /u/T_R_I_L_L is with your super-powers of moderator and see that it is not me. I have never, ever, used reddit before. Anyhow thanks for all the help and guidance.
Let me make your question simpler. "how safe are files"
Got it! Thank you for your patience in explaining this.
It's my pleasure. I hope you find your first few days at reddit to be not too confusing. Perhaps try to post your project to other subreddits like /r/programming, too.
Thanks, I thought of doing so, but the rules there (if I remember right were against doing so). I particularly thought r/C_Programming was best because COOGL evolved from C and would find a natural audience of people interested here. I’m getting interesting questions about it already so that is nice. In the past, prior to adding safety to the language, I had presented it in the San Francisco Bay Area C/C++ user’s group (too long ago, I have had no corporate support for this project, so it’s all down to my spare cycles to work on it, it was called C3 or C— at the time but those names had trouble with other languages) hence trying to raise money to hire somebody to finish it). Now that I am at Google (working on the Android Linux Kernel team) I might be able to make this my 20% project. I will also try to present again the language in the C/C++ user’s group and internally in technical talks at Google.
Pelles C, tinycthread (implements most, but not all, of it), midipix, MINGW + glibc 2.28 (although that also requires pthread support), LADSoft's OrangeC, [this github gist](https://gist.github.com/yohhoy/2223710), and many more.
The answer to your first question was removed by the moderator (too much self promotion), here it is for you: It was asked elsewhere in a reply to a post in (r/C\_Programming) what makes COOGL (Concurrent Object Oriented Generic Language) a safe language? COOGL prevents unsafe memory accesses that could be exploited to take over control of the program. Unsafe memory accesses are: over/under indexing of arrays, accessing memory through pointers on which arithmetic is being performed that causes the pointer to be outside of the underlying memory area that they are supposed to be referring to, returning addresses of data on the stack (directly or indirectly) to functions earlier in the call chain such that those functions can later pass those addresses to other functions and cause them to stomp on memory of the wrong type. COOGL does all this while preserving the ability of C to lay out data in memory to form complex data, usually network protocol packets, file system metadata, RDBMS data and metadata, etc. For example a network protocol with a header followed by optional headers, variable length data, and trailers, etc. COOGL accomplishes its safety without garbage collection. The language is very close to C so it is good for reengineering large code bases into it (for example incrementally reengineering the Linux, BSD, Windows, macOS, Solaris or AIX kernels into it. See the book at [www.COOGL.org](https://www.coogl.org/) if you are interested in learning more about it.
There isn't really a way unless you know for each array how long it is. There is no way to find out the length of an array in C having only a pointer to it without some sort of *a priori* information.
Oh, I see. But what if I added this to the code? int size = sizeof(jagged); int* p = (void*)jagged; Would I be able to iterate then?
Ah, it makes sense to me now. Thank you for taking the time to help me out. Really appreciate it! Could you also link me to something where I can read about compound literals and jagged arrays more?
I don't really have a reference for you. The basic trick in situations like this is to keep track of the array sizes somehow. For example, you could use a structure like this: struct slice { int *data; size_t len; }; struct slice *jagged = { { (int[]) { 0, 1 }, 2 }, { (int[]) { 2, 3, 4}, 3 }, };
this is indeed a great solution! thank you again!
Sadly, I wrote a whole book about it with all the details. I am learning that people won't just go read the relevant sections of the book. So I'll try my best. Also working on videos that explain the language now. Mechanisms: * the language has array descriptors that describe an area of memory that is being interpreted as an array (or a subarray of another array, i.e. slices) * when an argument is declared with square brackets, like: char *strstr(char haystack[], char needle[]) the language passes the array descriptor that describes the underlying memory so that over or under indexing needle or haystack raises an exception. * because strstr() returns either NULL or a pointer to memory within haystack[] then it could be used as means to cause invalid memory references to occur, for example bad() (below) causes stomp() to store into memory that is not valid to be referenced: void a() { char *p = bad(); // p points to hay[] array within bad() !!! stomp(p); // might stomp on its return address, etc } char *bad() { char hay[] = {"who am i"}; return strstr(hay, "am"); } void stomp(char *p) { *p = 'x'; } * this kind of bad code is caught by the compiler even if all those functions are in separately compiled modules * so a pointer argument is passed with '*' and you can not do pointer arithmetic with it, unless the compiler knows that the pointer is associated with an array descriptor or derived from it, so it can check at compile time that the array won't touch memory outside of it * non-pointer-containing data can be played with to form network packets, metadata, etc without concern because that kinds of carefully laid out memory should not contain pointers (its going to go over the network or to disk, or maybe share memory between processes). So C's richness is preserved where it matters. * memory is not garbage collected, but types don't mutate * only way to write unsafe code is if you use unsafe_cast()
&gt; I am learning that people won't just go read the relevant sections of the book. Your book is very long. It is really too much to ask everybody to invest many hours reading your book just to judge if the project is interesting or not. You should really provide some convincing examples so people know in what general direction your language goes before having to read your book. PS: read the formatting guide for how to format text. Right now, your comment is a bit garbled and very hard to read. 
I started my career programming in both Fortran and Ada (in the defense space) and then learned C in the late 80s. I've been programming in C ever since in the context of embedded systems (satellites, storage systems, medical devices, etc.). C is still the lingua franca of embedded programming.
Maybe the compiled libraries you are linking against do not correspond to the headers you've included in your code 
I am up for learning C++, what are your plans? 
This is a subreddit for C (and only C). You should try these subs: /r/CPP /r/CPlusPlus 
Just from your explanation this design seems a bit weird. Typically, you design your code such that there is a fixed number of threads as threads are not a cheap resource. Spawning one thread for each block seems excessive. I have not read your code and can't say what exactly went wrong though.
The latter is indeed a smart solution! 
I mean, the thread "dies" and restarts every time a block dies and a new one comes.
Okay, so I edited my code according to you but the compiler is throwing all kinds of errors here. Code: #include &lt;stdio.h&gt; struct slice { int *data; size_t len; }; int main(void) { struct slice *jagged = { { (int[]) { 0, 1 }, 2 }, { (int[]) { 2, 3, 4 }, 3 }, }; return (0); } Errors: https://imgur.com/a/WbN4hQV
Make the first element of each array its own size
Linux kernel and driver development.
A node-pointer implementation of a list and an array based implementation of a list have very different asymptotic performance for different use cases. Further, you can batch allocate nodes (and do other work to keep linked nodes close to one other) to mitigate the issue of TLB misses that linked-lists usually have.
`inline` keyword and macros are not the same thing. For example, inline negater(int n) { return -n; } and #define negater(n) do { (n) = -(n) } while (0) behave very differently.
I did find a solution after searching for a little bit more. I found that statically compiling using this command works flawlessly `x86_64-w64-mingw32-gcc test.c -o windowsBuild/test.exe -DIN_LIBXML -DZIP_STATIC -I/usr/x86_64-w64-mingw32/include/libxml2/ -L/usr/x86_64-w64-mingw32/lib -lxml2 -lz -llzma -liconv -lzip -lbz2 -static`
Aaah I understand now. So that's how it works, hehe. Thank you, man. And I'll look into the system call thing!
Hi again, a few more questions: * Did you ever figure out who that /u/T_R_I_L_L person was? * Was that account deleted or disabled? Is that why I get an error when I access it?. * How long did that account exist, etc. Was that post by that person what caused my post to be removed? * I know I have made two posts about COOGL at the top level of r/C_Programming so I guess that would have caused the removal of the second one. * Elsewhere you mentioned that I was welcome to re-post if I deleted my earlier post. * If I understand you correctly if I delete the original post that introduced the project to the group (you deleted the other one) can I repost sooner than two weeks? thanks again!
SourceForge has acquired a bad reputation because it used to bundle malware and spyware in some downloads. That was mostly in the 2013-2016 era, and since then they've been under new management and from what I've heard, their behavior has been much better since then. I'd say SourceForge is generally safe these days, especially when it comes to reasonably well known software (which I'd say Dev-C++ is an example of). I'd still suggest running a malware scan on all downloads (wherever you get them from), just to be sure - even if a site itself is generally safe, there's always the possibility of individual developer accounts being compromised and used to host malware (even GitHub is susceptible to this sort of thing), so practicing caution is never a bad idea. 
They scan their stuff now. The site was bought out a few years ago, and the people responsible for the adware binding were all sacked. I've been hosting there for 10+ years and never felt the need to move, at best I get maybe a few thousand downloads at the start of each semester, so I guess some poor schools are using it. Nobody ever leaves feedback so who knows. I did like that in addition to code and files they have mailing lists, wikis and hosted sites, far more than the other people. And it's profitable not the trendy money black hole.
I never get anything from sourceforge unless I am on one of those inferior windows machines.
Oh yeah I forgot, operating system choice is a contest.
Why are people still using this? It had been abandoned years before my professors told me to use it when I was in my AS program 8 years ago...
If you've looked at strings at all, this is how they work, they're arrays of characters and '\0' (the char with value 0, also called null character) denotes the end of a string. It's not all that easy to do with numbers however, as you have to know that you never want to treat it as an actual value, if you wanted to use -99 in your code you'd have to go through and change it everywhere.
This is a purely algorithmic question, nothing to do with C, don't think this is the right sub for it. This is not my domain of expertise to take this with a grain of salt, but I'm pretty sure I can see the expected answer from looking at this. &gt; I'm thinking iterate through the tree nodes it's a graph, not a tree, hopefully you know that already but I'll just point it out so it doesn't obscure your thinking. &gt; using Rabin Karp rolling hash How exactly do you plan to use rolling hash here? That's the problem that is posed: modify R-K to use in this problem. &gt; converted to a string why? 
&gt; Did you ever figure out who that /u/T_R_I_L_L person was? No. &gt; Was that account deleted or disabled? Is that why I get an error when I access it?. I have no idea. Typically this happens when the site-wide admins (which I am not) ban an account. &gt; How long did that account exist, etc. Was that post by that person what caused my post to be removed? No. What caused your post to be removed was you making two advertisement posts about your project in quick succession. &gt; I know I have made two posts about COOGL at the top level of r/C_Programming so I guess that would have caused the removal of the second one. Correct. &gt; Elsewhere you mentioned that I was welcome to re-post if I deleted my earlier post. You are welcome to re-post two weeks after your earlier post. Whether you delete it or not doesn't matter. &gt; If I understand you correctly if I delete the original post that introduced the project to the group (you deleted the other one) can I repost sooner than two weeks? No.
I guess what I'm confused about is how to modify R-K for this problem. It's an algorithm that detects matches by hashing substrings so how might I apply that here
&gt; how is he able to determine the size of the function to store the calle's stack frame. Well, the code has this: enum { FRAME_SZ=5 }; //fairly arbitrary So it sounds like he just guessed and hoped for the best. The assumption is that the caller isn't going to need that much stack space, so it won't clobber the "coroutine's stack" (which is really just a different part of the single program stack). This article really demonstrates _why_ `makecontext` and friends exist. Building reliable, flexible coroutines out of `setjmp`/`longjmp` is basically impossible.
"so you can compute the hash of B from the hash of A by removing the contribution from edges of A that B doesn't have, then adding the contribution of the edges of B that A doesn't have" What do you mean by the hash of B and hash of A exactly? 
Let's say A's adjacency is [0 1 0 1 0] and B's is [0 1 0 1 1] and our hash function is sum from i = 0 to n of adj(i)*2^i, A's hash would be 10, to compute the hash of B you would take the hash of A, substract the contribution of A[4] because it's not the same as B[4], then add the contribution of B[4], so h(B) = h(A) - ph(A[4]) + ph(B[4]) where h is hash and ph is partial hash. so you would do h(B) = 10 - 0 + 16 = 26. 
Cause in the outout of `man ulimit`: SYNOPSIS ulimit [−f] [blocks] .... OPERANDS The following operand shall be supported: blocks The number of 512-byte blocks to use as the new file size limit. 
* It outputs 12.50 because the function `fun` is taking `j` as an integer so 2.5 is cast into integer(2) so the division is done as integer division as you said but the result will be 7(15 / 2 = 7.5 -&gt; 7 when promoted to int). * Not exactly, here 5 represents the minimum field width and 2 is the precision.
2.5 is coerced to an int with value 2 because the j argument to the fun function is an int. Then 15 / j is done as integer division because both 15 and j are ints. The result of the integer division 15 / 2 is 7.
2.5 is coerced (cast automatically) to an int with value 2 because the j argument to the fun function is an int. Then 15 / j is done as integer division because both 15 and j are ints. The result of the integer division 15 / 2 is 7.
Is the stack a file?
Embedded is seemingly getting weird I feel because what \_is\_ embedded is expanding. [IEEE](https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages) has even listed Python (but not Java) as embedded. It seems like this is a combination of larger memory systems in embedded environments and JIT/AOT hardware support becoming more common. Both those would help Java as well. I'm on the embedded end myself and it seems weird. My most common language is C. C++ pops out of the woodwork for software simulations mainly. Python and Java in embedded still feel weird.
Take a look on this: http://c-faq.com/aryptr/aryptr2.html http://c-faq.com/aryptr/aryptrparam.html and let me know if this still would not be clear. 
In function declarations, there's no difference between arrays and pointers. See also chapter 9 of Expert C Programming. Excerpt: #When an Array *Is* a Pointer An earlier chapter emphasized the most common circumstance when an array may not be written as a pointer. This chapter starts by describing when it can. There are many more occasions in practice when arrays are interchangeable with pointers than when they aren't. Let us consider "declaration" and "use" (with their conventional intuitive meanings) as individual cases. Declarations themselves can be further split into three cases: * declaration of an external array * definition of an array (remember, a definition is just a special case of a declaration; it allocates space and may provide an initial value) * declaration of a function parameter **All array names that are function parameters are always converted to pointers by the compiler.** In all other cases (and the main interesting case is the "defined as an array in one file/declared as a pointer in another" described in the previous chapter) the declaration of an array gives you an array, the declaration of a pointer gives you a pointer, and never the twain shall meet. But the use (reference in a statement or expression) of an array can always be rewritten to use a pointer.
Arrays in C are capricious things. Almost anything you do with an array will actually involve it being converted to a pointer. So there's actually no such thing as passing an array to a function in C. The following two declarations are *identical*: void f(char *x); void f(char x[]): Within the function, the `x` variable has type "pointer to `char`", no matter which form you use. In both cases, of you pass an array as the argument the array undergoes "array to pointer conversion", yielding a pointer to the first element of the array. Given this it shouldn't be too surprising that your first two output lines have the same address. The reason why the third line has the same address is that taking a pointer to an array yields a pointer with the same value as the one you get via "array to pointer conversion". The *type* is different &amp;mdash; it's a pointer to an array, not a pointer to an array element &amp;mdash; but the *value* is the same.
you need to hard code the size of the array in the function prototype. Like: void myfunc(struct mystruct array[10]){....}
Incorrect. The length of the "outermost" dimension of a formal array parameter is ignored.
Yeah, it sure does. But do you have a study plan yet? Did you pick learning material to work on? Also, what do you want to program with C++, cause learning the basics (syntax and standard library) is fairly easy, but for advanced topics you need to work on projects. 
Oh, that makes more sense. So only for arrays the compilers pass them by reference (as pointers). Thanks!
Thanks! I was struggling to wrap my head around the part that even when arrays are passed to functions, they're really decayed to pointers 
Thanks! Much clearer now. About your last line.. it would mean that I can do pointer arithmetic with one but not the other, no?
oh yes you are right
... stack size (kbytes, -s) 8192 ... Wow, got it. Still wondering how to compare using it.
If you can register a single callback on the driver, I'd say that's the best approach (or the fn* array). If you can register multiple callbacks, another approach is to register all EventXHandlers and inside the handler test if it's the event you want to handle in that callback, and return if it's not. One upside of this approach is that each handler is independent of the others, and you don't have to keep track of all event types: if you only care about 2 or 3 events out of a 100, you don't need an enum with a 100 items (well you wouldn't anyway, but then the enum would be "incomplete"). Other than that, I'd suggest you *benchmark first*, before you try to come up with optimization schemes (like the array of fn*). Compilers can go a long way optimizing stuff these days. On the other hand if you have a 100 events each with it's own handler, the array of fn* might be better than the switch case. Just remember to check the array for NULL pointers, and **do a bounds check** before calling into the array.
I'm not sure if this might help but you can do a kind of ad hock inheritance using structs, if the "extended" struct has the base struct as its first field (not sure I explained that too well!) struct baseEvent { .... generic fields common to all event types } baseEvent; struct keyEvent { baseEvent generic; ... key event specific fields } struct mouseEvent { baseEvent generic, .... mouse specific fields } 
How to compare what?
Thank you.
Hey OP, how about a callback function for copying?
Not sure what you mean by that.
Another usage not yet mentioned: Virtual memory using paging. Pages are some fixed width (usually 4KB or 4MB), and begin at those alignments. So aligned mallocs are very useful for systems programmers who are dealing with memory allocation at the page level, or who are writing memory virtualization software.
Since you're basing this off of std::vector, `std::vector&lt;std::vector&lt;int&gt;&gt;` will, on insert, allocate memory for and copy the `std::vector&lt;int&gt;` being inserted. Right now, your vector can only support fixed-sized objects. So you can do a run-time version of `std::vector&lt;std::vector&lt;int&gt; *&gt;`, but not `std::vector&lt;std::vector&lt;int&gt;&gt;`. A callback to a copying function would fix this. 
Not sure if that's the best way to look at it. There really is no difference at all between using array notation vs pointer notation on your function declaration; the compiler treats them exactly the same.
This subreddit is about programming in C. C++ is off topic, please post C++ questions to /r/cpp_questions or as /u/flexibeast already mentioned, /r/learncpp.
You mean Dev C++? A lot of teachers never pick up newer knowledge, there was a teacher that still told her students to use Turbo C not too long ago in my engineering faculty, and another pretty much forces his students to. Although his argument is that students rely too much on their mouse and they have to learn shortcuts, I think the benefit is too small compared to the disadvantages.
Oh it's the guy that said python3 is not turing complete, has a hard on for python 2, doesnt understand c strings, hates k&amp;r, got crushed by criticism and swore to move to go(lang). Yeah totally not a nutcase :)
May I suggest considering embedded [doubly linked lists](https://github.com/basic-gongfu/cixl/blob/master/src/cixl/ls.h)? The main limitation they bring is that you need one link per list it's going to belong to inside each element. On the more positive side they are dead simple and allow closing the performance gap to vectors since the links are allocated with the structs.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [basic-gongfu/cixl/.../**ls.h** (master → 62160c7)](https://github.com/basic-gongfu/cixl/blob/62160c7d9f46a49cf3f9263f75b1cdedb4f876ec/src/cixl/ls.h) ---- 
I got a lot of value out of learn Python the hard way but I couldn't stand the condescending tone. Python was my second language after C++ so it was a good intro, but if you're already half decent or know a language or two, leave his books alone. I personally think he's just trying to cash out of his programming carreer since his assholishness is known industry wide by now.
His book is awful, and no one should use it. It has a number of errors, which have been pointed out. The author simply said "no, I'm right and everyone else is wrong". Go get a real book on C. That book should be called "Learn C the wrong way". 
That seems to be true...
I'm using C how to program by Dietel
True story...
C primer plus might be a good one
Once you get comfortable with the basics, try this [deep c](https://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298) It helped me a lot understanding complex/ambiguous behavior in c. How are variables declarations interpreted? why are static variables initialized to 0 inside a function while auto local variables are not? what is the ans to a++ + ++a ? what are sequence points? lots more but i can't think of from the top of my head. 
I really liked Modern C by Jens Gustedt
&gt; Oh it's the guy that said python3 is not turing complete You should not criticise what you do not understand. The guy said that there is no software that can completely automate the conversion from Python2 to Python3 and the only excuse for this absurd absence would be if Python3 was not Turing-complete. A tongue-in-cheek exaggeration that newbies usually fail to parse.
&gt; So you can do a run-time version of `std::vector&lt;std::vector&lt;int&gt; *&gt;`, but not `std::vector&lt;std::vector&lt;int&gt;&gt;`. Not really, my implementation will in fact make a vector&lt;vector &lt;int&gt;&gt;, but it will not copy the underlying data array, only the pointer to it, it will make shallow copies of the inserted vectors. You can however easily roll out your own copy function,and insert a deep copy into a vector: vector v = {.elem_size = sizeof(int)}; vector vv = {.elem_size = sizeof(vector)}; vector v_copy = vector_copy(&amp;v); //allocates an array of the same capacity as v and copy the contents vector_push(&amp;vv, &amp;v_copy); //vv is a true "vector&lt;vector &lt;vec3&gt;&gt;" vector_free(&amp;v); //v.array is now free'd but v_copy.array is not I don't think adding a copy_function callback is a good idea however, the main reason being that in a lot of cases when you push something onto a vector, it's because you plan to access it from the vector going forwards, meaning the object that you pushed is now defunct and is likely to be freed or reused. Something like this (consider that particles.txt contains 3D coordinates of particles, separated in blocks depending on their type, so you'd want to have one vector per type, and store those vectors in a vector of vectors which I call vv) FILE *fp = fopen("particles.txt", "r") vector vv = {.elem_size = sizeof(vector)}; for(block of file){ vector v = {.elem_size = sizeof(vec3)}; for(line of block){ vec3 point; fscanf(fp, "%f,%f,%f", &amp;point.x, &amp;point.y, &amp;point.z); vector_push(&amp;v, &amp;point); } vector_push(&amp;vv, &amp;v); } Notice that when exiting the outer for loop, v goes out of scope, but since we never freed it, its array is still allocated, which is fine because we pushed v into vv. Now consider that vector offers a copy callback. If you have experience with C++, you'd be tempted to do it like this: FILE *fp = fopen("particles.txt", "r") vector vv = {.elem_size = sizeof(vector), .copy_callback = vector_copy}; for(block of file){ vector v = {.elem_size = sizeof(vec3)}; //copy_callback is null-initialized, in this case we use a simple memcpy. for(line of block){ vec3 point; fscanf(fp, "%f,%f,%f", &amp;point.x, &amp;point.y, &amp;point.z); vector_push(&amp;v, &amp;point); } vector_push(&amp;vv, &amp;v); // this copies the content of v.array into a new array vector_free(&amp;v); } which would make a copy of the array before freeing it, while transferring ownership is much more lightweight (In c++ you would probably achieve this using move semantics or some such, I'm not too familiar with c++), by forcing an explicit copy you're sure that the programmer is conscious of the semantics, and only copies when it's actually necessary. Another reason I don't like a copy callback is that it implies that vectors of objects with pointers to other memory is a common use case and good practice, and would "encourage" people to push items with pointers to non-contiguous memory into vectors even when they are fixed size, iterating through those members' data would cause pointer chasing and would be horribly cache inefficient. Lastly, as I said, this is supposed to be minimalistic, there are plenty of functions you can implement on top of this, adding a copy callback if you need it seems relatively straightforward, I just don't think it's part of the core functionality of vectors.
Ah so you're hashing the adjacency matrices How did you arrive at this solution
http://hentenaar.com/dont-learn-c-the-wrong-way 
Well where to begin? No comments to explain what you are doing or why. The code may be cross platform and may not be. I see no reason to look further than your header and a few lines of the code. There is no compellins reason to read any of it. If you want feedback then explain what the hell you are doing and why. Nice use of calloc by the way. Glad to see that is finally catching on. 
You can provide the getters and setters as external functions. Inlining across (shared) library boundaries is generally not a good idea because it introduces a dependence on the structure layout. 
I currently only use static libraries, but in the future i may move to shared, does that change things?
&gt;Not really, my implementation will in fact make a vector&lt;vector &lt;int&gt;&gt;, but it will not copy the underlying data array, only the pointer to it, it will make shallow copies of the inserted vectors. You can however easily roll out your own copy function,and insert a deep copy into a vector: Yeah, that's the distinction. &gt;Another reason I don't like a copy callback is that it implies that vectors of objects with pointers to other memory is a common use case and good practice, and would "encourage" people to push items with pointers to non-contiguous memory into vectors even when they are fixed size, iterating through those members' data would cause pointer chasing and would be horribly cache inefficient. Its a common use case depending on what you're doing. Need to make a collection of dictionary tries? vector&lt;Trie&gt;. If you don't want to support that, that's fine, its your data structure after all.
I will agree that starting a student in an IDE like Eclipse is a very bad idea. Better to just give them an xterm and vi. Once they have a clue how to code simple stuff and perhaps write a few separate source files and then separate compile and link steps move onwards to Makefile stuff. Then last, dead last, the use of IDE tools. However "a lot of teachers" just pick up a pay cheque and could care less about what you learn. Face it .. most of them have never had a real programming job even once in their lives. Good luck trying to explain Atlassian Jira ( for team code work ) or even git. Most teachers are a sham.
Remember that with a shared library, the library version might change while the program doesn't (or vice versa). So if your struct layout changes and any function interacting with it directly is inlined into the program, things break in horrible ways.
You mean like the order of the feilds in the struct? Cuz that's a great point, tho I do tend to organize my structs from largest to smallest types so the padding is mininized Still tho, that's a very good point.
a node's adjacency vector is its identity, if two people have the same friends they have the same adjacency vector. Then there's the fact that you are asked to use a modified version of Rabin-Karp which is basically just using a rolling hash. The only way to use a rolling hash effectively is to have a lot of commonality between two successive hashes to save on computing power, otherwise there's no point in using a rolling hash, hence the sorting.
C programming a modern approach 2ed and for pointer stuff: Pointers on C
Zed shaws sentences are like decision of the oracle of delphi. Nebulous and if "incorrect" then it must be ones lack of understanding. Infact I still fail to make any connection between missing python 2 to 3 conversion and turing completness. I admit defeat, please enlighten me.
Thank you for sharing your experience. I'll use it for sure
Is it going to teach you C language or programming with C language?
Teaches the C language. It's not a book for learning how to program.
Thank you. I'll try the Book on pointers that you mentioned for sure.
Ok. Thanks. I'm still working with programming itself.
&gt; Is there a way to avoid inlining? Well, don't put the functions definitions in the headers. Just implement them like normal functions with declarations in the headers.
&gt; Oh it's the guy that said python3 is not turing complete Lol wut? Source on that?
&gt; Infact I still fail to make any connection between missing python 2 to 3 conversion and turing completeness. I admit defeat, please enlighten me on this elaborate joke. Python3 has been presented by its creators as a newer version of the same language. The backwards incompatible changes should be a set of rules that can be expressed as code in some source-to-source transformation software (like 2to3) right? Many years after Python3 appeared, neither 2to3 nor any of its competitors manages to accept any valid Python2 source and convert it into the equivalent Python3 source code. The most likely reason? Python core programmers are a bunch of perpetual newbies who can't code their way out of a paper bag. The humorous reason that you did not expect? Maybe Python3 is not Turing-complete and it can't express all the constructs present in Python2. Now do you also need me to explain the concept of humour, the role of surprise and human nature in general?
C Programming: A Modern Approach is the best book I've found that starts at an introductory level and gradually builds up to more advanced concepts. The only downside is that it's intended to be a textbook for courses and therefore you can't download answers to all the exercises.
Zed Shaw strikes me as what British readers might call a Marmite author, i.e. you either love or hate him and you're unlikely to convince someone on the other side of the argument. He goes about introducing concepts in an unusual way compared with every other C book I've read, but perhaps that works for some people (I don't know how many copies he's sold and what his return rate is).
C11 atomic types have been supported by gcc and clang for ages. 
I've never once put a definition for anything in a header, except enums...
Then I wonder what your question is. 
OP a lot of discussion is already about how Zed Shaw is a charlatan. I'd like to add on a bit, and then discuss why learning C is different than learning many other programming languages. Zed Shaw is a pseudoscientist who claims that copying code examples from his over priced book is the best way to learn a language. Nowhere does he provided any type of academic study to support this claim. Onto why I think learning C is different from other programming languages: The standard C 'programming environment' consists mostly of three things: 1) The virtualized model of computation provided by the *nix kernel: That is, the program stack and the memory heap. In C, you are intable to interact directly with the program stack, schanging values stored on it, corrupting it, ignoring it, or even hacking it to do crazy stuff. Additionally, you can access heap memory haphazardly (and you *will* access heap memory haphazardly as you learn how to program in C). You cannot effectively program in C without understanding the memory model presented to a process by the operating system kernel. 2) System Calls and inline assembly. The way a process (a virtualized program) requests resources from the kernel is trough a "System Call". There is no built in C instruction for `interrupt`, but the only way (on an x86/x86-64 machine) to enter the privileged space where the kernel resides is through an interrupt. Thus, system calls must be implemented directly in assembly language. A C program, then, can call functions written in assembly, or even include "inline assembly" --- assembly language written inside a C file. Thus, whereas programming in other languages, you access the kernel through some high level library, C gives you access to the system calls directly. Learning to program in C means learning about operating systems and often means learning assembly language, as well. 3) The C standard library. This is really the only part of C that is similar to other programming languages, and even then it is often both more barebones and more general/powerful. TLDR: Learning C as a second, third, etc programming language is about learning how *nix kernels create a virtual environment for programs to run in.
Might not be relevant in your context, but sometimes you have the problem that to determine the right handler you also needed to know what triggered the event. Example: Say you have the event DEVICE_OFFLINE, and that it can either happen because you requested it, or because it for external reasons went offline, and also say that what you want to do in those two situations is different. If you make a test inside the handler checking if you requested the event, it might be subject to a race condition. Say you requested an event, but before the device could process that request, an external factor caused the same event. So to keep the link between cause and event it is sometimes best to pass the individual callback/handler all the way down. 
I like the DFA suggestion from /u/Harlangn a lot. Keeping the historical context encoded in a single variable would help avoid a need for the resolver from looking through a lot of history. If not using a DFA, I personally would definitely go with the function pointer array, if handling more than, say, 10 events. Regarding the event handlers themselves, I would have them take the event code as a parameter, so that I could have a single function that handles multiple events in broadly similar but minutely different ways.
&gt; However, i think i'm still missing a lot of things, i mean, i know what a pointer is, but can't really figure out when they are really needed (apart from the arguments by reference things) , the arithmetic of pointers, struct, union and so on. In that case you might want to learn about data structures next. Knowledge about them will come in handy even when you switch programming languages later. The simplest point to start with are linked lists, once you have mastered them you will want to look into trees.
You won't be able to do pointer arithmetic with the second one, since the array in the "pointer to array" is of indeterminate size.
You can only declare a type at compile time. You might be able to do something with unions for runtime dispatch, though.
You might want something like a tagged union: ``` typedef enum { UINT32, UINT64 } DType; typedef struct { DType t; union { uint32_t u32; uint64_t u64; } v; } DValue; void printDValue(DValue dv) { switch(dv.t) { case UINT32: printf("Value: %d\\n", (uint32_t)dv.t); break; case UINT64: printf("Value: %ld\\n", (uint64_t)dv.t); break; default: fprintf(stderr, "Unknown type.\\n"); } } ```
Digging through your github profile it looks like you are one of those python2 forever guys, that are super salty about python3. Maybe only then one can understand this indepth joke and more importantly, enjoy it. Just face it, python2 is dying, soon EOL and nothing will change that.
Thanks for the writeup. The functionality I am looking for is the ability to assign a type to a variable; the type being selected at runtime. I don't think it is actually possible though. :( 
This was my suspicion but C always manages to surprise me so I figured I'd ask. Thanks. 
Actually, there's one way in which I'm wrong. It is actually possible to say this: void myfunc(struct mystruct array[static 10]) { ... } and the compiler can treat that as a hint that the array is not NULL and that at least its first 10 elements are to be accessible. But the compiler does not have to emit any diagnostic if you violate those assumptions, and indeed I wouldn't be surprised if most compilers simply ignore the hint altogether. This is rather obscure syntax. I've never used it, and I don't think I've ever seen it in other people's code before.
Thank you for your comment. I learned from it 👍
&gt; Digging through your github profile it looks like you are one of those python2 forever guys, that are super salty about python3. You gathered all that from my contributions to a project bringing backwards-compatible Python3 features to Python2? Oh, wait, you probably haven't figured out how to see my GitHub contributions, so here's a direct link: https://github.com/search?o=desc&amp;q=is%3Apr+author%3Astefantalpalaru&amp;s=created&amp;type=Issues &gt; Maybe only then one can understand this indepth joke and more importantly, enjoy it. No, you just need to not be dense on purpose, in order to get it. &gt; Just face it, python2 is dying, soon EOL and nothing will change that. Python2 is dead. Long live Tauthon! ;-) 
Try to find a different way to achieve the desired goal. A common way is to provide two versions of your binary, one with the type being one type, and one with the type being another one.
I understand what you are saying, but wrong is wrong! I looked at his python book and it was not bad as the c book. If you read the C book, you'll know what I'm saying. His book on C is just wrong in the idea behind it.
I mean you just confirmed what I said didnt you and so does your link. Python2 will EOL and tauthon is just that childish last ditch attempt at saving what is already lost. But now that I understand your mindset (bitter, conceited, feeling superior, dismissive) I can understand why you regard zed shaw as your soulmate.
So how would this be Monte Carlo? Why wouldn't this give a correct answer every time?
Programming in C requires a good mental model of computer memory: bits, endianness, stacks, etc. My guess is that EE’s take computer engineering courses that give them such knowledge.
Then you're using the wrong language, friend.
Thanks. I haven't used unions much, so I'm still a bit rusty on the syntax.
The new version won't work either since your union still has a name.
Thanks for your answer. Can you please provide some link? Yes i know that i can google it, but i would like to know about your specific resource :)
I first learned C (books) back there in 2011 (27 years). I definitively aint smart, so yeah, anyone can learn C as first programming language! C will take more time and effort to get in an ok knowledge but that its, it aint THAT DIFFICULT as most devs say! 
&gt; didnt you Is grammar also an invention of the Illuminati who are out to get you? &gt; you regard zed shaw as your soulmate If your end goal was to spit some ridiculous insults, why waste your time in programming subreddits? Please go role play as something else. We programmers are rather busy people.
C makes perfect sense if you've already taken assembly. If not then things like endianness, signed v unsigned, memory arithmetic, pointers, overflows, etc will trip up beginners.
Now you bring the illuminati into the play? I guess zed is not the only nutcase drawn to python2 :)
In what ways are his book wrong? Like is it the exercises themselves (which there is a big challenge for and people can submit PR requests), the content or both? I only ask because I've been going though his Python book and was planning on C after. 
Why are you using an uninitialized `temp` as an argument to `accum(void)`? Also, use a state machine instead of a ridiculous number of nested if statements. 
1) I have no idea. 2) I based my code off of [this](https://circuitdigest.com/microcontroller-projects/gps-interfacing-with-pic16f877a). It used a ridiculous amount of nested if statements. 3) How can I tell if it's buffered and/or blocking? 
I would suggest everyone learn a bit of assembly before taking up C. Because C is pretty much portable high level assembly. If you just want to get things done (like create guis, web servers, games without any hassle), then C will disappoint you. If you love to know how computers work (along with all the mess of different endianess, OSes, hardware, ABI, cpu architecture), C can do well as a first language. 
1) Don't. If its needed, there is a design flaw in `accum`. If it is not needed, then it shouldn't be there. 2) OK. Don't do it that way. It is illegible, prone to error, difficult to debug, and anyone else who ever works on the code will be pissed off at you for it. Instead, do something like this: const char target[] = "whatever"; const int target_len = strlen(target); int state = 0; char c; while (state &lt;= target_len) { if (target[state] == (c = inChar2())) ++state; else state = 0; outChar(c); } 3) Read the documentation and/or look at the source code?
If by confrontational you mean "wanting to know the issues you have", and by the way i'm talking you mean "trying to solve the issues you have", then sure. but it's pretty clear at this point you're just a troll and don't actually have any real issues with the language, just some vague FUD about "uhh it's hard" or "uhh types", since you havnt managed to give even the simplest example of a *single* problem despite being asked?
Don't forget when he called Py3 non-turing complete because it couldn't run python 2 exclusive code. And then backed off claiming he was trolling. His counter example was "well, you can run ruby in java" neverminding that it'd runs in the jvm using jruby which compiles the ruby code to jvm bytecode rather than executing it directly. Zed is just an asshole who wouldn't know his ass from a hole in the ground. 
Read KN King's "C: A Modern Approach". You canprobably skip the first few chapters but it gives a great intro to pointers, memory management, etc
It seems like you are the kind of person that are willing to explore different/exotic ways to do things, here are two methods that might be of interest: 1. Pass your custom value around as *u_int8 and a length so that only the length need to be determined during runtime and can use a ?: operator as a macro to simplify it. 2. If all your logic/code using this custom value is exactly same for both the type, you can write your all your functions as macros which take one argument which is the actual type. When such macros expand, it will generate different versions of functions with special suffix that you can call. I personally do not recommend the second method but it is a valid method that I have seen actual usage.
Presumably, because the cast is truncating the double to an int, but the desired result is they want, for example, 89.5 to round up to 90. By always adding 0.5, truncating will effectively round up or down as expected.
Coursera's Duke University course teaches C programming very well, and it's free. CS50 has first 3 lectures for C programming. They cover almost everything the beginners should know. 
When `nan` is part of any mathematical expression, the result is always `nan`. What would you expect the result to be here?
**IEEE 754** The IEEE Standard for Floating-Point Arithmetic (IEEE 754) is a technical standard for floating-point computation established in 1985 by the Institute of Electrical and Electronics Engineers (IEEE). The standard addressed many problems found in the diverse floating point implementations that made them difficult to use reliably and portably. Many hardware floating point units now use the IEEE 754 standard. The standard defines: arithmetic formats: sets of binary and decimal floating-point data, which consist of finite numbers (including signed zeros and subnormal numbers), infinities, and special "not a number" values (NaNs) interchange formats: encodings (bit strings) that may be used to exchange floating-point data in an efficient and compact form rounding rules: properties to be satisfied when rounding numbers during arithmetic and conversions operations: arithmetic and other operations (such as trigonometric functions) on arithmetic formats exception handling: indications of exceptional conditions (such as division by zero, overflow, etc.)The current version, IEEE 754-2008 published in August 2008, includes nearly all of the original IEEE 754-1985 standard and the IEEE Standard for Radix-Independent Floating-Point Arithmetic (IEEE 854-1987). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Isn't this an assignment? If so you should probably the TA or the teacher, from the limited question statement you gave the best I can do is guess. Hashing couldn't really be considered monte-carlo, monte-carlo is random sampling, hashing samples the entire input and creates a reduced output space, but I really don't see how monte-carlo could be applied here.
Avoid it as the plague. I remember cute things like "make is your new Python!" and then using the make command without Makefiles instead of gcc throughout the book. Also, his response to being called out by a senior C developer was "Oh, you must be a beginner, I'm right by the way". 
I got rid of it. It is just a wrong book
Good riddance
&gt; The virtualized model of computation provided by the nix kernel I mean, I'm not sure how to read this, but it sounds to me like you're saying that one can't program C on a non *nix kernel? I would be wary of calling others pseudo sicentists when making such obviously wrong statements.
check your scanf-calls. some are missing the &amp; 
This is not correct. Please do not say so.
Can you have 2 declarations for a function, in 2 different headers? HeaderA has Declaration1. SourceA has Definition1. HeaderB has Declaration1. will that cause trouble? 
You can do this and as long as both declarations are the same it is fine.
I don’t think that C is very beginner friendly, imo. A good place to start though would be on C# (where I started). It’s a good high level language, beginner friendly, and it’s closely related to C
I've read the C book and I didn't think it was well organised, the way topics were introduced were a bit haphazard (e.g. Makefiles before functions). I haven't read any of his other books so I have nothing to compare with.
No.
C was my first language, it's far simpler than hard OO languages. with them, you never know what exactly a function does, with C, you knw that generally it's gonna do the bare minimum, and to get complex behavior, you have to make multiple function calls, which simplifies things greatly.
I already knew C when looking onto Zed's LCTHW after a friend who was had learned Python from his other well-known book, which served him pretty well. So he comes complaining to me about how he doesn't understand a thing from the LCTHW and how bad/complex C must be. I then briefly looked into it and oh boy... It's been a while but I still remember telling my friend not to use that at all. The main reason he wanted to have C was natively compiled binaries, which is why he later jumped on Go - and for what he needed, that's was much better fit than C.
I can't figure out the "virtual environment" parts of that post. If I'm directly manipulating memory, how virtual can I be? Isn't the kernel written in C? 
Check out a Vaidehi Joshis blogpost called”BaseCS”. I don’t have the link on me, but a quick google search will do the trick. She does a wonderful job explaining linked lists, and trees in a very quick and digestible format. I hope you enjoy, and happy learning.
I definitely recommend learning C at some point, it's a better vessel for learning certain concepts about how systems work than any other language IMO. It probably shouldn't be your first language however, as it doesn't really hold your hand at all and can be quite daunting at first.
In this instance, there are no events with multiple causes. The event enum is fairly complete - one value for no-data, one per actual event and one for an error code that's propagated from the underlying interface. However, I see what you mean by passing the callback all the way through - I might have a use case for that approach in another module!
For all my affinity for DFAs (something people I work with, who come from other paradigms, do not look upon kindly) I completely forgot that's a valid way to frame the problem. I think I'll go the DFA variant and uncouple the state logic into separate functions, that should make it _slightly_ more readable.
Thanks for the suggestion - definitely looks like the way to go for this particular module.
I see : #include &lt;stdio.h&gt; Looks like a header to me. 
Here's a little experiment you can run: int main(void) { int a; printf("%p\n", &amp;a); } On my laptop, this outputs something around 0x7ffcc675f9c4, which is 140,723,638,106,564. Now, seeing as my laptop doesn't have 140 trillion bytes of memory, something must be going on here, right? An x86-64 machine can theoretically have up to 2^48 or 2^42 bytes of memory, but this limit is seldom if ever reached physically. What happens instead is that the CPU provides memory virtualization services known as "paging". The kernel is written in, C, but because the CPU's paging feature is turned on, its memory is still virtualized (although it likely has a "linear" view of memory. Also note that low values in virtual memory are often paged to point to those same address in physical memory in order to better support things like DMA.
There are plenty of other comments explaining just how bad the book is. Some of his "examples" include very bad, unsafe, dangerous, or otherwise incorrect coding practices. It's obvious that the author is not a C developer.
Tuples already exist in C. They're called arrays and structs.
How to check whether the value of size is reasonable? 1447 * 1447 * 4 = 8375236 1000 * 8192 = 8192000 8375236 &gt; 8192000, it seems reasonable to me?
First, it's 1024, not 1000. Second, there is no good way to tell, from within your program, how much stack space you have left. Just enforce the arbitrary limit that you already picked (99 in the initial version).
&gt;I would like something that gives me, in short, what is what and where i should use it. I think you will know where to use it when you needed to use it :) It is all about practice, try to work on some some (small or big) projects e.g. simple data structures... Learning libc may help to see big picture. Link (GNU version): [https://www.gnu.org/software/libc/manual/html\_node/index.html](https://www.gnu.org/software/libc/manual/html_node/index.html) I was tried to read all APIs (because I love C language), you don't have to that. You can pick some APIs e.g. strcmp, memset, memcpy... then if you like it (you probably will) then you can check other APIs. This will (or may) give you some ideas what is what (on API level, not syntax level, because you already tried to learn syntax on books). You can also read APIs by man pages but that I liked GNU HTML pages. You can also check C ISO standards time by time.
This comes down to a question of scale, or maybe scales. C was my first language because I was self teaching at 10. C had been mentioned in video game magazines so I knew about it. I could get my hands on the compiler easily before I was internet fluent. Books were easy to find. So for me it really came down to access, but that't not the case these days. I feel that the first forays into programming for anyone are going to be equally difficult/easy regardless of language these days (barring assembly, esolangs, maybe something really deep down the FP rabbit hole). Things like printing to the command line, doing basic math, conditional statements, loops, etc (the basics) are pretty equal in Python, C, or whatever; however, C will have some more "magic lines" sitting around than python (i.e.: what is this #include &lt;stdio.h&gt; even doing, and why do I need it. Granted you might have the old #!/bin/env python too...) When you get into more advanced topics like string manipulation, things that use more libraries, maybe network stuff for the brave novices, that's when a beginner would likely become more overwhelmed. As for C books, I do like K&amp;R, though I think its age definitely shows. When I was starting in C, the books that really got me going were not really the ones that handled like a course text, but rather the ones that targeted and interesting end results (games or math for me) and used C as a tool to achieve that goal. If you can discern interests like that for whomever you're buying for, then find a good book that leverages C to get there, I think it'll be more effective since it will be able to hold interest from the C angle and the hobby angle.
I read that Python is not a language for 'development', but rather for prototypes, models. Simply, creating a working program flow. There are lots library in Python (NumPy, SciKit-Learn, PyTorch and many other), but how people write a C/C++ program according to the Python code? I mean these libraries are restricted for Python. When we need more performance, of course wouldn't use an interpreter. 
[Beej's Guide to C Programming](https://beej.us/guide/bgc/pdf/bgc_USLetter.pdf) is a pretty fun a friendly intro to C that helped me when I was just beginning...
You can't dynamically change types at runtime The compiler needs to know how much space to reserve for the variable
That's an incredibly inacurate representation of python. A lot of large scale applications (including reddit and EVE-Online) are written in python C is mainly a systems level language and allows for insane speeds (one of the main reasons it's still heavily used in the games industry for example), while python is almost exclusively used as an application level language and is more concerned about dev speed than runtime speed (though thanks to C extensions it can get some extremely performant packages). Python programs being rewritten in C is extremely rare, though it is not uncommon for parts of a python app to be rewritten in C or C++. it's quite hard to compare these languages as each have their strength and weaknesses (they are about as dissimilar as two imperative languages can get)
I won't claim I remember the reasons, but the consensus suggest to avoid this book. On the other hand, his networking guide is quite good. Maybe I read that at suckless, take that as you will.
&gt; I read that Python is not a language for 'development' Hm, not true. I've worked on numerical simulation systems, emulators for old computers, systems to help engineers model building damage and control systems to populate and manage research compute clouds - many from scratch and all in python. I started out a long time ago in C. When python became a thing I had a look at it and decided to learn and use it. I told myself I could always write parts of any solution in C if I needed speed. Fifteen years later and I've never needed to speed up python with C. I'm sure someone will come up with some example of how *they* needed to rewrite in C, but I've never had to. I still write embedded C, though.
Jens' book is for people that's already intimate with C. IMHO.
I definitely learned those concepts on C, without explicit knowledge of assembly, and learned the concepts of assembly as an extension of C. C certainly isn't far from assembly, but there's definitely no rule that says you need assembly first. It still requires you to know a lot about the computer, which I rather like.
I'm a C developer. C is for people who want to learn C. There are plenty of people who are VERY smart, and VERY skilled, and know more than any of us ever will about "what they are doing". Many of them write code in python. Part of being good at something is knowing when the tool you're familiar with is the best one for the job, and when you might want to try something that's a better fit for the task hand. Don't be elitist. You're not better than python developers just because you "know C". 
Define "beginner friendly." If I really want to know and understand programming, I'd start with C. Otherwise, probably Python or Java
What the fuck is wrong with you, man? Forget how to behave like a normal decent human being?
If they're so good they probably also know C and a bunch of different languages. Because in order to chose the right tool you need to know what tools are available. Besides, I am not primarily a C developer and in my experience many of them are just as narrow minded as Python or JS devs because they never venture out of their comfort zone and have a very limited horizon. 
I'm saying that knowing C has nothing to do with whether you understand what you're doing. It's like saying you have to speak English to be smart. Different languages are used for different things, and not knowing a particular language does not imply much about your skill. I think everyone should learn C, but not as a first language. It's far easier to learn a different language first. It's far easier to make useful things in other languages, and that can be quite rewarding for someone who's learning. How long do you think it'd take the average completely new programmer to build a working game, with a graphical interface, in C? What about python? Or other languages? I'd consider that alone to be a good reason not to learn C first. 
That has nothing to do with C. Those are developer conventions with which you disagree. You are free to use other conventions
&gt;Hell, I even see GOTO statements wtf?! "goto coalesce_done;" Dude, consider that you're a shitty programmer if you can't think of a good use case for a goto statement.
The same applies to the standard library. Just look at this shit: printf, fprintf, sprintf, snprintf, printf\_s, fprintf\_s, sprintf\_s
terrible bait, buddy.
How do you get out of the most inner loop without goto? You can without it but goto is the cleanest way to do it 
Well, you are the one being unimaginably crude, rude, and invasive with someone who was just putting his point forward politely and professionally. Your bizarre responses evoked umbrage within me. Make sense?
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
I find it hard to imagine you don't know that at least the Windows operating systems don't have a *nix kernel and yet people are compiling C on them and run C applications on them.
my bad didnt realize there was a C++ one specifically
No problem! Just post in the right subreddit next time.
Are you his alt account? One can argue about the professionaly part but polite? Are we reading the same text?
Making a small game with GUI in C takes about 2-3 weeks for someone who is new to programming plus whatever time they need to learn the basics of control flow (should be the same for Python and C). I know because this is the final project we give to freshman students in introduction to programming and most manage to submit something. C may be less rewarding as a first language but it definitely teaches you more about programming and computers than Python. In Python it is much easier for students to just guess their way through without actually knowing what happens in the program. Additionally, C's limited (albeit very confusing) syntax keeps everything manageable whereas Python has lots of syntactic bells and whistles that are intimidating to someone who wants to learn the language (and read code snippets online)
Why do you post pictures of code instead of code as text? Why are your source files suffixed `.cc` (C++ source) instead of `.c` (C source)?
I would be amazed if someone who has never coded before could create a graphical game in 3 weeks time. That would be hard in any language. Learning something like python first teaches you good programming practices. Those practices will make working with a lower level language like C easier. I taught myself BASIC as my first language because it was what was available to me. Then I picked up TI Basic, then z80 assembler, then java and finally C when I was in college. I'm not VERY good at C, but would not suggest it to any beginner as their first language, because it gives you too many details to start with. But don't just listen to me - why do you think every university in the US teaches python or java in their "Introduction to Computer Science" classes? I'm not aware of any schools with a C class that doesn't have another class as a prerequisite. I'm not saying it doesn't exist - but it's extremely rare. Look at Stanford. MIT. Georgia Tech. What language do THEY teach to students first? It isn't C. It shouldn't be. 
I would be amazed if someone who has never coded before could create a graphical game in 3 weeks time. That would be hard in any language. Learning something like python first teaches you good programming practices. Those practices will make working with a lower level language like C easier. I taught myself BASIC as my first language because it was what was available to me. Then I picked up TI Basic, then z80 assembler, then java and finally C when I was in college. I'm not VERY good at C, but would not suggest it to any beginner as their first language, because it gives you too many details to start with. But don't just listen to me - why do you think every university in the US teaches python or java in their "Introduction to Computer Science" classes? I'm not aware of any schools with a C class that doesn't have another class as a prerequisite. I'm not saying it doesn't exist - but it's extremely rare. Look at Stanford. MIT. Georgia Tech. What language do THEY teach to students first? It isn't C. It shouldn't be. 
OK? x86 machines use paged virtual memory. Once again, OP is not interested in programming a toaster.
By their own account, most of these schools now teach something like Python or Java because they want to be closer to industry demands. Doesn't mean that you actually learn more that way. Many universities in Germany teach C as a first language and MIT used to teach Scheme, which IMO is even better than C as a first language. The point is that you can not understand why Java or Python are the way they are without knowing how it works under the hood. You won't understand how parameter passing works in Java, why Java doesn't allow multiple inheritance, what virtual calls and so on
sure - even the SIM card you have in your phone right now is running java.
java has actually been in embedded devices for quite a while, like in those old flip phones and all that. ARM even had a jvm instruction set accelerator at some point (called jazelle or so, I think). also it runs on SIM cards and such.
If C didn't work on 8-bit microcontrollers, your car wouldn't start. I'm not here to help the OP. I'm trying to help you divorce yourself from the notion that the "standard C programming environment" is married to any one implementation -- and particularly not a Unix implementation, nor any implementation that relies on virtualization. Your claims to the contrary are simply false.
Zed? Is that you?
At this point you are just being obstinate because you feel embarassed that you didn't know what memory virtualization is. Its pretty pathetic.
LOL, no.
Nope, not at runtime. At compile time, you can use _Generic, which is pretty cool, but not at runtime.
I want a retro feel , and my emacs has better config for c++
 The first loop seems like a convoluted way to find the length of `src`. Is there a reason you don't want to use `strlen`? The fact that the first loop initializes `i` to `start` is subtle and I could easily see it leading to bugs later if the code is modified. At the very least, use a better name than `i` since the variable is used after the loop. If you think about it a bit, it shouldn't be too hard to rewrite this using a single loop. Also, most string functions use `size_t`, not `int`. E.g. `strlen` returns `size_t`. Note, `sizet_t` is unsigned and would make your upfront error testing moot.
There are other ways, of course, but it's hard to tell whether they are better. For example you can get rid of the for using src[start + i] in the while loop. But, to do this, you need to be sure that start is lower than the string length by calling strlen()... that performs a loop. You can also use strncpy() to replace the while but I think this would reduce the value of the exercise. However there's one thing you are missing: the check for NULL of both src and dst.
Get some help. Seriously.
cslibrary.stanford.edu
&gt; I want a retro feel css can achieve that and make text selectable. As an aside, your font is huge, that combined with half the page being a menu, and the interline spacing being huge, as well as giant images throughout the entirety of the article makes for a very unpleasant reading experience, the largest amount of words I can have on screen at once in this particular article is 171. That is the same number of words as this comment. Lastly your code snippets should illustrate what you're talking about in text, but they're so big and colorful compared to the post's text that they completely draw attention away from it. Then there's the fact that there is absolutely no introduction to what's going to be talked about in the article and how in depth it's going to be. Then you jump from topic to topic with no transition whatsoever. Generally speaking the writing is quite poor and the ratio of text to code is so low that it's barely better than reading commented code directly.
I'm not sure why you're using a start index, it makes your code a lot more complex, if someone wants to take a substring in the middle of a string, they can just pass a pointer to that middle char instead of the actual start of the string, like this `substr(&amp;dest, &amp;src[5], len);` or just `src+5`. As someone pointed out, if you use unsigned types you can avoid sign checking. Implementing both those things in the code makes it trivially short, and IMO, much easier to read and understand: size_t substr(char *dst, char *src, size_t len){ size_t count = 0; for(; count &lt; len &amp;&amp; src[count] != '\0'; count++) dst[count] = src[count]; dst[count] = '\0' return count; }
THIS! Thank you so much sir!!
Very interesting. I've just read the "compilation vs interpretation" part, and learned a few things! Added to my feed. Thanks you very much :)
 if(start &lt; 0 || len &lt; 0) { should be: if(start &lt; 0 || len &lt;= 0) { 
True, but if you are going to "early out" on simple cases that should return an empty string then you might as well include len == 0, rather than handling it separately. This also makes the code potentially more robust if you decide later to change the logic.
He's not really looking for the length of \`src\`, he just wants to make sure it doesn't end before \`start\`. \`strlen\` may be less efficient.
You cannot do that here, because it does not allow you to check if the string ends before the start index.
It's just the responsibility of the caller to check that they're not starting past the end, really don't see the problem here. 
You can design your own functions however you want, but OP chose to implement that in his function.
And he's asking for feedback, I'm arguing that checking if you're past the end of a string is superfluous. There is rarely a case where you actually need to check if you're past the end, because most times you're going to call substring at a position that you found by searching the string. 
If you look at the gnu strlen code, there is some very tricky manoeuvres that make it highly efficient. It's one of those cases where if there is a bottleneck then maybe use something else, but I certainly know that I could not sit down in an afternoon and write something more efficient. However I agree with your above point. 
Agreed, this is a good improvement, thank you!
You should work on your self-awarness
cheers :)
I want to compile my program on Linux *for* windows using mingw. my issue is that I can't do it without statically linking that program otherwise iy can't be run on a windows machine that doesn't have mingw installed
Why have you submitted a link to a link to your library? Why not submit the github page directly?
Someone posted this library [a few days ago](https://www.reddit.com/r/C_Programming/comments/94ep06/newer_version_of_my_math_library_mathc_for_2d_and)
I guess I missed it. Was posted on hackernews today.
1. These aren't really "tuples." A proper [tuple](https://en.wikipedia.org/wiki/Tuple) can have any number of elements. These can only have 2. 2. These aren't really type-safe. If the programmer passes the wrong type as the `T` argument to `tuple_a` or `tuple_b`, they will get undefined behavior without any error or warning from the compiler.
Ah, I see.
Damn this community is harsh. How dare you share something neat with us when u/kn0wsitAll saw it a few days prior? Downvote this peasant to hell!
nah...emacs c support is even better!
hahahahaha
May you explain how this is funny? 
ASM as first programming language! hehehe
windows, yuk!
Cant recall last time Ive used windows!
 yeah me neither, but I still like C#, even if I don't program in it any more.
Well if you are willing to learn C as a first language, why not learn Assembly as well? Just the basics. Nothing complicated. 
That was my first thought when reading it, it didn't make much sense.
Serious question: what description of mingw is incorrect? I only saw that it is a compiling tool for making Windows apps. While I only really see mingw in windows, I thought it was originally (maybe currently) a cross compiler to produce Windows apps from Linux. 
There are infinitely many real numbers (take any real number, add some more digits, and you have a new number), but only a finite number of bits in your computer, and much more so for a standard 32/64-bit number. There's only so many different values (2^64 to be exact) that can be represented by 64 bits. For floating point numbers, this means there is a sort of "resolution" built into them; 10^-100 is far too precise to be represented by a single 64-bit number. If you are doing reasonably complex computations, there's a very good chance that somewhere a long the way, the computer will stumble across a number it simply cannot represent with the standard number of bits. So it will use a nearby number instead. Some software lets you use arbitrarily many bits for a number to get around this problem, but standard C isn't part of that. So after you are done with the computations, your answer will probably be off by a tiny bit. Rather than betting on the tiny/impossible chance that your answer is exact, it's best to find a suitable error range (which again has to be within the floating-point resolution) and check that your answer is within that range. Here's a better explanation: http://fabiensanglard.net/floating_point_visually_explained/
Thanks!
**Numerical analysis** Numerical analysis is the study of algorithms that use numerical approximation (as opposed to general symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics). One of the earliest mathematical writings is a Babylonian tablet from the Yale Babylonian Collection (YBC 7289), which gives a sexagesimal numerical approximation of the square root of 2, the length of the diagonal in a unit square. Being able to compute the sides of a triangle (and hence, being able to compute square roots) is extremely important, for instance, in astronomy, carpentry and construction.Numerical analysis continues this long tradition of practical mathematical calculations. Much like the Babylonian approximation of the square root of 2, modern numerical analysis does not seek exact answers, because exact answers are often impossible to obtain in practice. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
You can, in fact, rely on the exact value of small integers (up to 2\^number of bits of precision not including the exponent or sign). I say this because it's often a sensible thing to do in unit testing, not because you should ship an embedded scripting language that depends on this behavior as part of every major web browser. You can rely as well on numbers that are entirely the sum of numbers of the form 1/(2\^n), such as 1/2, 1/4, 3/4, 7/16 etc, provided all intermediate values are also of this form and you don't underflow the precision and you don't screw up in a dozen other ways that I probably don't know about. Binary arithmetic can't represent other numbers. The same principle applies to decimal arithmetic -- you can't represent 1/3 as a non-repeating decimal expression, only numbers that are the sums of 1/(2\^n) and 1/(5\^n) (2 and 5 being the factors of 10 -- the base of the everyday number system).
&gt;The decimal part is imprecise when stored as **buts**. But... but... but...
I wrote this to simulate the loot box dropping mechanic in the popular video game "Rainbow 6 Siege". I wanted to simulate 1 billion drops and C seemed like it would be better suited than Python speed wise. I'm still fairly new to C. I worked through most of "Learn C the hard way" this summer (I know I know, it was free). I've been reading the criticism of Zed Shaw online and I'm curious to see what I'm doing the wrong way. Thank you
Some things that stood out to me: * Your probability code would change depending on the value of RAND\_MAX. * Just return (comparator1 &lt;= comparator2) instead of using an if statement. * You don't check for NULL after malloc. * Instead of commenting lines randomly, think about code in groups of related lines and explain with comments before each group. Hope that helps, cheers.
I'd use `perror` since it will print the reason for the `NULL`, and print to `stderr` instead of `stdout`, and use `EXIT_FAILURE` for the return value, but otherwise yup thats the right idea :)
&gt; However, if you reuse those "incorrect" values in another operation, you will carry on those rounding errors all the time and then bounds get far more complicated. No doubt. My point is just that these issues _can_ be treated rigorously, but most software that works with floating-point arithmetic simply doesn't... and for good reason: it _is_ complicated! And simply _accounting_ for errors at each step in a calculation isn't necessarily sufficient. Calculations can often be reformulated to _minimize_ errors. [Take this example](https://diego.assencio.com/?index=c34d06f4f4de2375658ed41f70177d59), for instance. Many programmers, when asked to calculate the mean of a list of values, will not realise that the "obvious" solution of adding them up then dividing by their count isn't necessarily the best approach. This is the kind of stuff I wish I'd studied more. I know it exists, and I'm glad of that, but it's a big scary topic that I know I don't know enough about.
Sure, but minimizing errors takes people who, as you wrote, studied that topic and it takes time. Things most companies don't care about.
As a small sample, I still remember during my doctorate courses we were implementing a 24 order Taylor integrator, and our teacher (head of the research group, too) mentioned how, although it would make sense in terms of speed to precompute 1/N for N up to 24 and multiply what needed (lots of 1/N*x kind of stuff would be around, and when you are doing high precision + high number of operations everything counts) that would be less stable than computing x/N on the go since computing 1/N would always be error-biased in the same direction whereas x/N would spread the error better since it would vary depending on x.
While the article you linked is correct, notice how it had to put n in the millions to start seeing errors. That's because, and mentioned in another comment, the error for small integers is 0, they can be represented exactly, and thus there won't be an issue dividing them. And n is almost always small... This is the basics Numerical Analysis, really, and I don't feel it's very big and scary. Read up more on it here: https://en.m.wikipedia.org/wiki/Loss_of_significance Basically, be wary of subtraction and to a lesser degree of multiplication. The latter because it might truncate the result which introduces new errors. 
&gt; Basically, be wary of subtraction and to a lesser degree of multiplication. [And summation.](https://en.wikipedia.org/wiki/Kahan_summation_algorithm) And probably every other floating-point operation you can think of, in some way. I'm always suspicious when people start off with "basically...". It means that the rest of the sentence isn't telling the whole story.
&gt; Numerical analysis has the answer, but it's a little different than what you might think. It's not dealing with round-off error in particular, just errors in general. Most of Numerical Analysis would still be relevant with a perfect real-number representation. And there you go. This is why I knew I didn't understand the problem properly. It's good to know what you don't know. :-) (To be honest, I was just going by the first sentence in that Wikipedia article, which quite clearly uses the word "approximation". But I now realise it's talking about approximate algorithms rather than algorithms dealing with approximate values.)
Sure it's slower. What's keeping people from doing? ``` SomeOpaqueStruct s; initOpaqueStruct(&amp;s); ``` Still the user don't care about what's inside.
Try to use `const` when possible void printPlayer ( const struct Player *player ) int rollPlayerLootbox ( const float current_chance ) { //return 1 if player should get loot box based on random roll const int rand_result = rand(); const int comparator1 = rand_result % 1000; const int comparator2 = current_chance * 1000; return ( comparator1 &lt;= comparator2 ); if( comparator1 &lt;= comparator2){ return 1; } return 0; } there is no shame in breaking the `printf` statement in `printPlayer` in multiple lines, if you really want only one `printf` you could end the line with `\` void printPlayer ( const struct Player *player ) { printf("\n\ =====\n\ Wins: %d\n\ Losses: %d\n\ Current Chance: %.3f\n\ Boxes Collected: %d\n\ =====\n\n", player-&gt;wins, player-&gt;losses, player-&gt;current_chance, player-&gt;boxes_collected); } Does `player-&gt;current_chance` need to be capped ? Be consistent in the spacing around operators, `*` and `+` get surrounding spaces, but not the `%` operator 
This subreddit is about programming in C. Your post is off topic; posts trying to recruit people for projects are only allowed if said projects are written in C or are about C. If your project is, please add some details and a link to the project page. Then respond to this comment so the mods can approve your post.
IMHO, a much nicer way of presenting this is as follows: void printPlayer(struct Player *player){ printf("\n=====" "\nWins: %d" "\nLosses: %d" "\nCurrent Chance: %.3f" "\nBoxes Collected: %d" "\n=====\n\n", player-&gt;wins, player-&gt;losses, player-&gt;current_chance, player-&gt;boxes_collected); } This is what I tend do to, which also means you don't have to worry about wanting to stick a `//` comment somewhere and have it fail due to the line having it's carriage return escaped previously.
Linked lists are still used
If you think linked lists are not used anymore, you didn't understand linked lists. You have to understand the trade-offs that each data structure have. I think the only importantant data structures missing are dictionary and hash table. Note that dictionaries can be implemented using binary trees or hash tables. Also it's a good exercise to implement stacks and queues using arrays/vectors instead of linked lists. Another one is to implement a stack using queues and vice versa.
I can see the confusion. The [official Mingw page](http://mingw.org/Welcome_to_MinGW_org) says &gt; For those who would prefer to use a cross-compiler tool chain which is supported by MinGW.org, we do provide a set of interactive shell scripts, which will guide you through the process of building a suitable cross-compiler tool suite directly from our sources. However, please be advised that, due to limited manpower resources, we have been unable to update our offering of such scripts to deliver any version of the tool chain which postdates GCC-3.4.5. I haven't had time to look at the CVE, but it appears that it is this cross-compiler being discussed. The doc says that they don't provide the cross-compiler, just that they provide an outdated set of tools to build one. 
being relocatable was a requirement of Win32s... does that mean that modern tools using address randomization are Win32s compliant again?
Dynamic Array. Probably one of the most useful, general purpose data structures. Good for string implementations too. Hash table, which will also provide a good use for your linked lists :-P (to use for chaining of collisions, although there's other ways to deal with collisions too). Hash tables are very important to understand. Hash tables are often used to implement maps/dictionaries and sets (red-black trees, or some other balanced binary search trees can be used too, but typically only if there's another reason you'd want the data in that format). They have constant time lookup and amortized constant time additions, so they're usually the magic data structure you need if you need to store and retrieve information quickly by key in memory. Binary Heap (implementing Priority Queue). This provides constant time access to the max (or min), and fast additions and removals (log time). Circular Array (useful for deques). Balanced binary search trees, like a red-black trees. A 'normal' binary search tree is not very useful because they can become unbalanced very easy. These (along with linked lists) are probably the 'core' data structures. &gt; I know linked lists aren't used anymore Linked lists are used, but rarely as a general purpose way to just make a list (dynamic arrays are often used there, or a circular dynamic array when you need to grow from both ends).
I’d imagine almost any data structures book will cover these particular data structures since they’re so fundamental. CLRS is the ‘gold standard’ but is heavy on theory so might be difficult without some level of mathematical maturity. Even the Wikipedia article is likely enough to give you the info you’ll need to implement them. 
Think about the way many fractions cannot be represented exactly as decimal numbers with a finite number of digits. For instance, 1/3 (one third) is 0.33333... where the 3 repeats forever. If you use 0.33333333 (8 significant digits) in calculations, you've introduced some imprecision, so you have to keep that in mind. The same thing is true when numbers are represented in binary, but it affects different fractions. For instance, 0.1 (one tenth) in base 10 becomes 0.0001100110011 in binary, with that pattern repeating forever. If you're writing an accounting program and it adds ten cents as a float (0.10), the number being added isn't exactly one tenth; it's as close to one tenth as could be represented in however many bits of floating point precision you have. When you use the results of those calculations, as in comparisons or a display, you have to be careful not to expect more precision than there is. Knowing exactly how much precision you have can be tricky, because the imprecision can multiply as you use the values in more and more calculations. (Think about what happens if you put .33333333 into a calculator that has a maximum of 8 digits, then divide it by 10, then multiply it by 10. You just lost a digit of precision.) That's why, when possible, it's best not to use floating-point values in calculations at all, but turn everything into integers, like calculating in whole cents instead of dollars.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions. That said, you probably need to configure your locale correctly for this to work. Windows is a huge bitch to work with wrt. multibyte stuff, so special considerations might apply there.
&gt; But I now realise it's talking about approximate algorithms rather than algorithms dealing with approximate values. You said it better than I did.
Mingw-w64 is often used from Linux as a cross-compiler, especially in CI/CD situations. For example, on my Debian, there are 41 packages of `mingw-w64`.
1024 * 8192 = 8388608 Enforce, u mean enforce the limit using `ulimit` command?
&gt; Can someone explain to me if I can write (and execute) operations after a recursion call? Yes. Just do it. &gt; Can I store a recursion call of a function into a variable and than make operation with it? A function call is not a thing; you can't store it anywhere. You can however store the recursive call's return value just as you can store any other return value. &gt; If I can, how can I do it? Well, just like with any other return value. For example, to capture the return value of a (recursive) call to `foo` in a variable `x`, write x = foo();
directed/undirected graphs triesspatial trees bitsets range trees union-find computational geometry also has a lot of interesting but more niche data structures like spatial trees or doubly connected edge lists also I'd equally recommend looking at implementing algorithms that use each data structure as well
Oops! Sorry about that. The post is only a notice for a Discord server, so it's off-topic. Never mind!