&gt;I think that in this case is the same. Or I'm wrong? You would like for it to be the same. Logically, you'd think it would be the same. If you change `+` to `|`, do you get the same result, though? (Still using `char`, not `unsigned`.) &gt;I use this to not show trailing 0xFFFF on the output. More visible output. *Leading* FFFFFF. But word\[i\] is a char. Eight bits. FFFFFFC3, which is what's printed if you don't `&amp; 0xFF`, is more than eight bits. So why the leading FFFFFF? &gt; That was the problem It's one way of fixing the problem. But why?
You'd be surprised at how stupid people are becoming. [**This**](https://old.reddit.com/r/iamverysmart/comments/an0tmy/man_cant_understand_simple_math_problem_but_has/?st=jxxonwia&amp;sh=6894767a) discussion in /r/iamverysmart illustrates that many people are not being properly taught order of operations in elementary school math
&gt;*Leading* First of all sorry for this. My english it's relatively bad. &gt;You would like for it to be the same. Logically, you'd think it would be the same. When I put `|` instead of `+` I get `int= FFB10000`. I don't really know why. &gt;So why the leading FFFFFF? This part of code confuses me a lot, I know that a `char` = 1byte. I don't figure out why the Leading FFFFF are in this part.
I suggest reading up o two's complement representation of signed numbers. https://www.cs.cornell.edu/~tomf/notes/cps104/twoscomp.html A char is a signed type. The compiler assumes that if the most significant bit is set, it's a negative number. If it converts it to a 32bit int, it fills the upper bits with 1s to preserve the value and sign.
Whether `char` has a sign is implementation defined.
Thanks a lot! I'll read this now
Thanks, fixed!
If you code end up looking like a weird ((((alt right)))) message, you have a good candidate for refactoring.
A lot of classes still use it, partly because the teachers/professors are moderately out-of-date (and usually still teach that C is almost-assembly) and partly because pretty much any compiler (excepting the oldest or most embedded-targeted) can handle ANSI C in a reasonably correct fashion. Some compilers still default to a C89/-ish mode as well, and C89 diverges the least from C++ if that’s of any import. And when writing code that other people will need to use, you need to at least check for C99 and error out—the `-std=c89` flag is there, so it’s something one can encounter in the wild.
&gt; First of all sorry for this. My english it's relatively bad. It wouldn't matter except that it'll be important later. &gt; When I put | instead of + I get int= FFB10000. I don't really know why. Well, when you print it, char[0] is FFFFFFC3 and char[1] is FFFFFFB1. So a = char[0] &lt;&lt; 24 is C3000000 and b = char[1] &lt;&lt; 16 is FFB10000. Then, a | b = FFB10000. If this is the case, what is a + b? &gt; I know that a char = 1byte. I don't figure out why the Leading FFFFF are in this part. Char is 1 byte with the range -128 to +127. Unsigned char is 1 byte with the range 0 to 255. 0xC3 in a signed char is the number -63. The chars are getting automatically converted into ints. The number -63 in an int is 0xFFFFFFC3.
&gt; If the string is being read into a fixed-sized buffer, the length index is never going to get anywhere near large enough to overflow an int on any normal system I agree in principle, except the reasonable thing to do would be move the buffer size out into #ifndef BUFFER_SIZE #define BUFFER_SIZE 1024 #elif (BUFFER_SIZE+0) &lt; 1 || (BUFFER_SIZE+0) &gt; SIZE_MAX # error "invalid definition of `BUFFER_SIZE`" #endif in which case there’s no practical limit other than `SIZE_MAX`. &gt; they behave in arithmetically-correct in the range near zero. but entirely UB at the outer reaches, which is a fine way to leave security holes in real-world software.
OK, so yes, strictly conforming. But without OP describing their compiler, ABI, and settings, strictly conforming is the safest and most correct thing to aim for.
This is not how you format code for Reddit, and we need the declarations of things like `i`, `a`, `add`, `c`, and `run_tot`. (And is `run` different from `run_tot`? Because if it is, you’re [a.] triggering undefined behavior, and [b.] reading [if lucky] undefined data from `run`.)
sorry about the format. I added my declarations, and the initializing and ending functions. also sorry I changed name in my compiler, but when I copied and pasted code it was the old name. The name is not the issue. I believe it may be my use of %d or %i in the wrong instances? I sometimes get mixed up with what variable I am looking for and it gives me the wrong values in my scanf and print lines.
I would disagree that this set of rules is simple and easy to remember (especially if you program in several different languages), but I've given you an upvote for the nice summary! (BTW, your #10 is showing as #0 for some reason.)
Basic data structures, not really API design ...
I think you’re answer is correct and helpful but I haven’t had time to try it out yet. I’ll let you know how it goes once I get around to it. :)
It's up to you if you interpret my comment as serious or sarcastic. I have intentionally tried to admit both interpretations.
"When you hear hoofbeats. think horses, not zebras". Are you aware of any actual implementations that are unable to process pointers to different types of data interchangeably for purposes of passing as a \`%p\` argument? What fraction of posters can be expected to ever write any code that would ever be called upon to run on such an implementation? If there were a concise means of writing a pointer-to-pointer cast expression that would squawk if the thing that was expected to be a pointer, wasn't, using that would offer the benefit of forcing a diagnostic if code accidentally passes the value of an integer-type (or character-type) object rather than its address, even on implementations that don't otherwise validate \`printf\` arguments. If there were any realistic likelihood of most programmers' code being run on a machine where \`%p\` couldn't handle any pointer types other that \`void\*\`, that would be a practical argument in favor of using a \`(void\*)\` cast \*despite\* the fact that it could stifle what would otherwise be meaningful warnings if code passes an integer value instead of its address. If there were standard macros to indicate whether an implementation imposed requirements which the Standard allowed implementations to pose, but most implementations don't, it would be reasonable as a matter of course to have a project header file test to ensure that it will be rejected by any implementations that, for whatever reason, don't meet its requirements. If the fraction of implementations that can't treat pointers to different data types interchangeably for purposes of \`%p\` exceeded, or at least came close to, the fraction that can treat such pointers interchangeably but don't define any particular macro to indicate that fact, one could reasonably argue that portable code should test for such a macro. Since the former fraction is really close to zero, however, while the latter is nearly 100%, such tests don't seem practical.
Easy to forget for a retard like me then at times, although I could've sworn I've seen compilers warn of math precedence issues such as this before. It didn't this time around although with the innumerable flags I pass when compiling a kernel module I may have neglected one.
The precedence of division and exponentiation is generally determined by the layout of symbols on the page, except in cases where exercising control over such layout would be impractical, such as in computer program source text. An expression like a ----- + d b+c doesn't contain any parentheses, but I don't think anyone could reasonably argue that PEDMAS implies that the division of b into a should have higher precedence than the addition of b and c.
Bit fields are the best way to get things packed. Most variables will use a whole register a lot of the time even if they are smaller, bools being the classic example. Plus when storing on the stack since every variable needs a unique address(except for bit fields and some compiler specific extensions) it will use at least 1 byte more likely a whole word(same size as register). You do need to consider whether having the packing is actually worth it since there will need to be a bit extraction operation whenever you want to access the value if it isn't nicely aligned.
Bitwise operators having lower precedence was a mistake. The precedence rules can be somewhat confusing. I really like Go's precedence rules though.
Does it run better if you initialize a?
If code computes \`sizeSoFar + nextSize &lt; maximumSize\`, for the purpose of seeing whether another sub-object will fit in a space, having the addition performed as unsigned math would cause the object to be reported as fitting if the computation exceeds the maximum value for the type. Implementations are allowed to trap on signed integer overflow, and that would be a useful behavior \*in cases where integer overflow would cause a computation to yield arithmetically-incorrect results\*. Using unsigned values would block the possibility of a security-conscious implementation offering such protections.
Indeed it's a mistake! This dates back to B which lacked logical operators (bitwise operators were used instead). Later B compilers interpreted `&amp;` and `|` as logical operators when used in a control expression, which eventually turned into dedicated `&amp;&amp;` and `||` operators.
You would have found the problem sooner if using the recommended malloc style: p = malloc( N * sizeof *p ); (tweaked for kmalloc of course).
&gt; Bitwise operators having lower precedence was a mistake It was a happy accident for C++ though!
Since you plan to work on a Linux system, check the GNU GSL library https://www.gnu.org/software/gsl/doc/html/vectors.html#c.gsl_matrix_transpose
Looks like that should work. Thanks, I don't think I've heard to GSL before.
3rd grade here lol
Oh wow there’s a bunch of stuff wrong if that’s your entire program. So first off for(i = 0; i &lt; a; i++) `a` has not been initialized yet, so this is UB; in a formal sense, anything beyond this is undiagnosable. Your compiler should have protested loudly about this, and you should have heeded it. Next, your `scanf`-and-clear-line statements should probably be `fgets` and either `sscanf`, or `strtol`. You can also cheat and put a space after the `%d` specifier, which will cause `scanf` to eat any whitespace or line break afterwards, but that leaves your input in an ambiguous state. I suggest pushing input+clear line into its own function; covered below. You also need to check that `scanf` actually read something; if it returns anything &lt;1, `add[i]` will either be undefined (→UB) or retain its former value. It could mean there’s no more data in the input stream (`&lt;0` or `==EOF`), or it could mean there’s garbage in the input (`&lt;1`). Next, your `c = getchar() != '\n'` has the parentheses in the wrong place. This is actually being interpreted by the compiler as (c = (getchar() != '\n')) != 0 &amp;&amp; … which is completely different from what you want. Your `scanf`+`getchar` stuff should probably be `fgets`, and as long as you don’t have to handle very long lines, it’s easy-peasy. You then end the `while` statement with a `;`, which is a *terrible* idea. First off, don’t do that; either do `{}` or `(void)0;` on its own line. (I prefer `(void)0`; it’s an explicit do-nothing.) Throwing a `;` after a loop statement is a *really* easy thing to miss when you’re trying to figure out WTF went wrong, since `);` looks perfectly normal at a line end. Also, `while(…);` looks like the end of a `do`-`while` loop, so the reader will curse softly and hunt upwards, expecting that you’ve misindented and they’ve perhaps missed something. Your if(add[i] &gt; 0) continue; is continuing the `do`-`while` loop, not the `for`, and you shouldn’t be `continue`ing, you should be `break`ing there. For now, always use braces for body statements, even if there’s only one. You’ll catch your errors much more quickly, and you can go a little laxer if you want to once you’re intermediate or advanced. The next token, `else`, is entirely unnecessary. Control cannot possibly continue to the next statement after the `continue` or a `break`; those are glorified `goto`s. Your `printf` should probably be an `fprintf(stderr, …)` or `fputs(…, stderr)` instead since that’s what `stderr` is there for and error messages are (typically) not part of the normal output. (Think of some program like `sort`; its normal output to `stdout` should be its input, sorted line by line. Error messages should go to their own stream. The user can do `2&gt;&amp;1` on most shells if they want the streams combined.) `fputs` because you’re not actually formatting anything. Don’t put an extra format arg in there; that’s iffy at best, and the compiler is within its rights to discard it and its effects. If you’re just trying to mash another statement into the `printf` so you don’t have to `{}` it, don’t do that, `{}` it, and if you’re that desperate you can use the `,` operator: (void)--i, fprintf(stderr, "…"); End of the `do`-`while`: while(add &lt; 0); The compiler will first attempt to use `add` as type `int[10]` or `int[]` (e.g., via operator `sizeof`), but the only operator there is `&lt;` so the compiler will attempt to use the address of the first element in `add`, which has type `int *`. You’re comparing that against integer-literal `0`, which in the context of a comparison with `&lt;` will promote to type `int *`, which value is the `int *` version of `NULL`. So you’re comparing a pointer against `NULL`, not something in `add` to zero. Comparison with any pointer not in the same “object” (standard parlance; read “memory block” for now) is IIRC implementation-specified or undefined behavior, and `NULL` is in its own non-object so the comparison may or may not do anything ever. Even if the compiler emits an actual comparison, it’ll likely never be `&lt; NULL`, although again, who knows. And on top of all that, you don’t need this `while` statement anyway. You can reformulate the input loop in a few different ways. Simplest and most likely to rouse the ire of an instructor/teacher/professor: int v, k; retry_input: /* Note: `read_input_line` given below. */ if((k = read_input_line(&amp;v)) &lt; 1) { if(k &lt; 0) { fputs("error: unexpected EOF\n", stderr); return 1; } fputs("error: invalid input\n", stderr); goto retry_input; } if(v &lt;= 0) { fputs("error: input must be &gt; 0\n", stderr); goto retry_input; } add[i] = v; (Note that packaging `read_input_line` up into its own function makes your life a lot simpler. That means before `main`, put this: static int read_input_line(int *); and after `main`, put this: /* static = Local to this file * int = returns an integer * (int *out) = takes a pointer to (“name for”) the output */ static int read_input_line(int *out) { char buffer[1024], *after; size_t len; long value; char last; /* Read up to EOL, EOF, or end of buffer, whichever comes first */ if(!fgets(buffer, sizeof(buffer), stdin)) { /* No more input */ return -1; } /* Try to convert the start of `buffer` to an integer */ errno = 0; value = strtol(buffer, &amp;after, 10); if(errno /* overflow or bogus */ || after &lt;= buffer /* empty input */ || value &lt; INT_MIN || value &gt; INT_MAX /* out-of-range */) { /* Bogus input */ return 0; } /* Make sure the remainder of the buffer is whitespace. */ for(last = 0; *after; last = *(after++)) { if(!isspace(last)) { /* Garbage after input */ return 0; } } /* Make sure we’ve cleared to EOL. */ if(last != '\n') { int k; while((k = getchar()) &gt;= 0 &amp;&amp; k != '\n') { if(!isspace(k)) { /* Garbage after input */ return 0; } } } /* Store the value. */ *out = value; return 1; } And I’m giving that thorough a source for it because input handling is easy af to fuck up if you’re new at this. That’s what you want in a full-fledged program, but you can also use `scanf` in exactly the same way, just swap out the function call for `scanf("%d ", &amp;v)`.) Note that I’m using intermediate variable `v` before I stuff the value into `add`. This is good practice for something called input sanitization. Treat `add` as the “trusted” input; you’re getting *some* integer `v` from the user, but you’re not sure yet whether it should go into `add`. ITF this sort of practice will (short term) help you discover things you accidentally left undefined, and (longer term) help keep an attacker from walking your program around by the nose. Anyway, if anybody kvetches at you about `goto` being harmful, tell them in no uncertain terms to piss off in this particular instance. They’re referencing an old article by Edsgar Dijkstra, who was railing at the `GOTO 10` sort of statement, not this one. (C `goto` is no more confusing than a function call unless you’re considering jumping over declarations; don’t do that.) This is a jump to a label already seen by the reader, named descriptively. Version #2: for(;;) { if((k = read_input_line(…)) &lt; 1) { if(k &lt; 0 ) {…; return 1;} fputs(…); continue; } if(add[i] &lt;= 0) { fputs(…); continue; } break; } No `goto`, but does the exact same thing as the `goto` with more code, and imo has higher cognitive load, but Misinterpreted Dijkstra would be pleased. If you don’t like the infini-`for` and `break`ing, Version #3: char /* or _Bool, if you’re allowed C99 */ endInput = 0; do { if((k=read_input_line…) &lt; 1) {fputs(…);} else if(add[i] &lt;= 0) {fputs(…);} else {endInput = 1;} } while(!endInput); Or you can do if(scanf) {fputs; continue;} if(add[i] &lt;= 0) {fputs; continue;} endInput = 1; but frankly both forms of #3 are entirely overworked, and something you should avoid unless you’re a static analyzer. OK, done with the `do`-`while`. Next: run = run + add[i]; This is C, so you can do run += add[i]; Not strictly necessary, and really `+=` originally came from avoiding a symbol table lookup that’s like 40 cycles nowadays, but `add = add +` will get you looks from other C programmers. Not good looks, or even horny leers. You should really rename `run` to `total`, also, because `run` is usually what you name a function that runs something, or a variable pointing to a function that runs something. Anyway, that’s what I’m seeing and my suggestions for.
Update, it doesn't solve my issue, i'm still getting the overrun error.
if they're that stupid they shouldn't be writing C code
The correct way to approach it security-consciously is size_t sizeSoFar = …, nextSize = …, totalSize = …; if(nextSize &gt; SIZE_MAX - sizeSoFar) { /* OVERFLOW */ } β(sizeSoFar + nextSize &gt; totalSize) This neither invokes UB nor relies on unsigned modulus nor fails, and it can be adapted to positive integer values, but then you’re just half-assing your typing. (Which describes to the reader and compiler exactly which set of values you/it should consider valid. Which in this case does not include negative ones.)
You really should actually go through the K&amp;R book. It’s a good resource for C, even if a little old (uses C89 when C99 is generally pretty common, and I think we’re on C17?). There’s honestly not *that* much to learn with C, as crass as that might sound. What you should do is understand memory management and pointers, structs, macros, and writing well-structured code. Pretty much everything else comes down to knowing the stuff in K&amp;R. Do that and you’d be golden for a lot of C programming. But you definitely need to understand pointers, which I suspect is where your confusion stems from in your data structures course, because there’s not a whole lot to C. It was designed to be simple.
I recommend you to start C on sololearn to start from the very basics. Then you should read K&amp;R, it is an old book but still a reference if you want to learn C programming. I also recommend you to watch this freecodecamp video about C: https://youtu.be/KJgsSFOSQv0
&gt; Are you aware of any actual implementations that are unable to process pointers to different types of data interchangeably for purposes of passing as a `%p` argument? I haven’t waded through the source code of any compilers, but I have waded through quite a bit of documentation, and it’s not mentioned anywhere ever. Which means ¯\\\_ツ\_/¯ there’s no telling. However, I just tested GCC 4.8 (and presumably the rest of the GNU genus): $ gcc -Werror -pedantic -o /dev/null -c test.c test.c: In function ‘main’: test.c:5:5: error: format ‘%p’ expects argument of type ‘void *’, but argument 2 has type ‘int *’ [-Werror=format=] printf("%p\n", &amp;foo); ^ cc1: all warnings being treated as errors If it’s enough to cause a diagnostic message, it should be enough to change behavior, if only so people using your code can use full `-pedantic` settings.
I'd say it's more than possible to have a decent grasp of C if you write code for 3 hours a day for a month and a half. Some concepts will take a while to fully grok, but it's a relatively small language with a relatively small standard library. &amp;#x200B; I think K&amp;R 2nd edition is still a very good beginner resource for the language, but the most important thing is to \*write code\*. You could read documentation/tutorials/K&amp;R over and over and not absorb very much, but having to solve actual problems and spending some quality time beating your head against why something doesn't work is the best way to learn any programming language. Do you have some idea of what your course is going to cover? Why not get ahead of your class and try to write a file archiver yourself?
are you OP? user is different but very similar...
You could just go back and do a good job on your data structures assignments. Being a competent programmer is mostly just practice. Writing any non-trivial project will give you practical experience. Pick a project you're interested in so you'll spend time doing it. Look stuff up in K&amp;R when you're not sure, buckle down, and do it. If you haven't used a debugger before, learn how to use it. It really helps to step through code as it executes. Where I worked, if a new hire didn't know C coming in, they typically became reasonably proficient in about a week, maybe a little less. That would be one week as a full time job, for someone who was already a pretty good programmer in some other language.
Actually, it is very much API design, because, as the author mentions, you can get stuck with the decision and not be able to re-order the lower numbers. It's also an ABI design issue. Note: This also has nothing to do with data structures, because this is talking about return values and not something you store in a data structure.
I don’t disagree with any of the content just the title. But sure you could lump nearly any C code into API and ABI design if it’s small enough. Like how to use an enumeration.
It wouldn't waste CPU cycles
How in the world do you take classes requiring C but have no C background? Are you winging it at John's Clown College or do schools nowadays have no counselors to help with this?
I totally agree, but it looks like everyone else in here is enamored by their own infallibility.
Yes I was using a bitfield at first but then choose to use int16_t and int8_t types. I might go back to using the bitfield approach but I would need to add padding
This will be useful thank you
A typical answer! It's possible to design structs badly. In most cases, you really shouldn't worry about it. The compiler will modify things pretty aggressively -- very dependent on what you're actually doing. There are lots of layers and complexity involved in how efficient operations on a struct are. It's difficult to figure out and doesn't actually come up as often as people think, so it's generally not worth programmer time to think about. (See: premature optimization.)
How bad are you actually though? like 3 hours a day for a month and half is massive for college course imo (if you have a solid programming background). Just learn as much as possible about pointers, references and values (how to move them around ect). Then just drill strings and structs if you actually understand that stuff that's basically the language apart from the stuff that requires actual just computer knowledge like files, sockets, design patterns, preprocessor, errors, threads and of course data structures.... the stuff that requires doing projects and I assume you are being taught in the classes. I had the same experience at university although I wasn't CS where they would just through you into courses and not teach programming just abstract concepts like how interrupts work or something like how are you supposed to learn this stuff if you barely understand how to use pointers?
Eh, although my uni never taught C, there were a few classes that required C and the onus was on the student to get up to speed to do the class work. Just got to roll with the punches sometimes.
new code works a treat [bouncing\_ball.c](https://github.com/skippa/gamedev/blob/master/bouncing_ball.c) &amp;#x200B; working on using `struct` as suggested (and debated) above - need practice with structures anyway :)
&gt; Bug 2 - instead of what I expected, sizeof(unsigned long) * __NR_syscall_max+1 (8 * 313 + 1) being 8 * 313+1 (314) unsigned longs, for 8*314, it's 8*313 = 2504 + 1 = 2505, NOT my expected 8*314 = 2512. memcpy() is copying 2505 bytes, not 2512. That's not C. That's basic math. First multiplications and divisions (left to right), then additions and substractions (left to right). Use parentheses to change order.
Learn C The Hard Way, by Zed Shaw is what you need, given that you are in a hurry. If you want to go further into C, also grab Ben Clemens’ 21st Century C
Came here to give similar advice, but will also add &gt;another 3 hours to doing leetcode for interviews, but i'm doing that in python Why python? It's a fine language and all, but why not go do some of the easy leetcode problems in C? Indeed, they will be really difficult when you start, because you are not going to have the crutch of all the nice collection classes and operators. But once you get one knocked out you'll be able to crank out additional ones more easily, and eventually get pretty comfortable with the language and what's going on under the covers. Plus this will exercise fundamental data structures (for which it sounds like you could use a refresher).
Haha, a long time ago I started to do typedef enum { E_OK = 0, ... } Picked it up as I went. And so I accidentally saved me some headaches.
btw it's PEMDAS.
Point of interest, I was taught differently in primary and secondary education. Originally addition preceded subtraction, and multiplication preceded division. Still not sure what that was about.
A very clearly written article which conveys an important warning to us all, something we are prone to forget. Thanks for this article.
Integer type ranges are generally lousy at conveying to compilers or humans the range of values that should be considered valid in any particular situation. Some directives for the purpose of indicating to compilers that there are a wide range of ways they could process a construct \*while still meeting application requirements\* would enable optimizations fare more easily, effectively, and safely than than granting compilers unlimited freedom to jump the rails in case of integer overflow. I'm reminded of a cross-assembler I had for an 8-bit microprocessor which, when I accidentally tried to define initialized storage for an object with size -1, treated it as a request to insert 4294967295 bytes worth of zeroes into the object file, resulting in a disk full error after writing about a gigs worth of data to the output file. The fact that the number of bytes to be reserved is a signed integer doesn't necessarily mean that all values up to 4294967295 should be considered valid (especially if--as was the case at the time--the OS required that volumes be subdivided into partitions of 2GiB or less).
Or if your C code looks like LISP, refactor.
&gt; Integer type ranges are generally lousy at conveying to compilers or humans the range of values that should be considered valid in any particular situation. I agree; I’d much prefer to see C have either some sort of general range or enumerated value set for integers, or permit free-form invariants that must be maintained on read/write. But aside from `enum` (which is just …so fucking frustrating in C, moderately less so in C++≥11) there’s no good way to get at that sort of thing, and `enum` makes it even *harder* to check if there’s any question of the underlying representation being invalid. &gt; Some directives for the purpose of indicating to compilers that there are a wide range of ways they could process a construct *while still meeting application requirements* would enable optimizations fare more easily, effectively, and safely than than granting compilers unlimited freedom to jump the rails in case of integer overflow. GCC and AFAIK Clang are really good about pulling out unsigned overflow checks, both from the above sorta technique and things like `a + b &lt; a`, either of which would use (e.g.) `jc` on x86 to catch overflow. They suck badly at detecting signed overflow checks (which would become `jo` on x86), although newer GCCs (and maybe Clang?) have some set of `__builtin`s that will check for overflow explicitly, and there’s a bit better than they were back in the 4.0 days. But yeah, I’d really like to see some sort of `_Checked` modifier where overflows should be caught as (e.g.) `SIGFPE`, and a `_Modular` modifier so two’s-complement could be explicitly declared. Or hell, a more general `_Format` options doodad. Could be useful for all sorts of stuf like BCD, endianness, compaction, etc.
Some of the diagnostics in gcc and clang, if enabled, can be triggered by strictly conforming programs, and I believe gcc and clang allows very fine-grained control over which diagnostics are enabled or disabled. The fact that an implenetation can be configured to reject a program doesn't mean the implementation isn't capable of processing it usefully, and if the only problem that would ever result was that compilers that were configured to squawk would do so, configuring compilers to omit the useless diagnostics would seem a better solution than adding code that would risk stifling useful ones.
One of the most fundamental problems with every version of the C Standard to date is that there has never been any consensus over whether it was intended to describe a highly extensible core language which wouldn't be terribly useful by itself, but could be easily extended to serve a wide range of purposes, or whether it was trying to define a self-sufficient language. One thus ends up with the authors of the Standard deciding that there's no need to have the Standard mandate that `uint1=ushort1*ushort2;` be processed using unsigned arithmetic because (according to the Rationale) the majority of current implementation would treat signed and unsigned arithmetic identically in such a context *even in cases where the MSB of the result is set* (and presumably the Committee expected that future ones would do so as well), but the authors of gcc interpreted the lack of a mandate as implying a judgment that implementations, shouldn't be expected to process such an expression reliably in cases where `ushort1*ushort` yields a result between `INT_MAX+1u` and `UINT_MAX`, even on quiet-wraparound two's-complement hardware. Note further that even a trap-on-overflow implementation would be allowed to process the above multiplication in unsigned fashion. since there are no defined cases where the it would affect behavior, nor would anything forbid an implementation from treating values from `INT_MAX+1u` to `UINT_MAX` in useful fashion. A major problem with manual overflow checks or precise overflow semantics is that they generally force operations to be done in precise sequence, and make it necessary to detect overflows even in cases where the program would have behaved in arithmetically-correct fashion.
\_\_NR\_syscall\_max sounds confusing, number of or maximum? Less times you have to use +1 and &lt;=, the better.
[removed]
*PEMDAS
You’re the second person to say that, and I can’t tell if it’s supposed to be a joke or not lol
No, really, that's how I learned it. I just looked it up to be sure.
So whats the right the way to do it then?
He said it... Have the "fixed point" which are enums that won't change and should be default, at the beginning.
So first off, you asked for when it might ever be a problem, and I gave you two of the three big compilers with exactly one flag that’s *very* often used, which causes a diagnostic to be emitted for uncasted `%p` argument. Whether or not that diagnostic is even enabled, the compiler can obviously tell that the argument is bogus. And because it can tell there’s a difference, without the compiler docs specifying one way or another, or without auditing the source code, you can’t be sure there won’t be some compile-/link-/load-/run-time behavioral change as a result. (Have fun auditing compiler optimizations.) I’m … honestly kind of surprised you’d suggest that something counter-`-pedantic` is hunky-dory, given the fact that you’re knowledgeable enough to know what strict conformance is in the first place. The go-to recommendation for the usual OP-ignored-the-compiler kind of post is to enable `-Wall -Werror -pedantic` and less importantly `-Wextra`, especially for class assignments. That recommendation is absolutely correct IMO, and if I were grading such an assignment I’d dock a couple points for ignoring the format string warning/error, because noobuary is not when somebody should be learning to play fast-and-loose with a language. Wrt warnings outside basic conformance: `-pedantic` does not enable those, it’s strictly about standards conformance, and it’s the only option required to get a diagnostic for this kind of format string problem. More generally, AFAIK if a diagnostic isn’t included under the `-Wextra` umbrella, it reflects something that’s usually wrong, and that at least needs to be addressed so a reader doesn’t wtf or shit themself. E.g., `if(ch = next_char())` is strictly-conforming; but `if(!!(ch = next_char()))` is valid, explicit about how the `=` is operating, and ~guaranteed diagnostic-free. Regardless, if you’re writing code that anyone else will use, it’s thoroughly unreasonable for it not to work silently with *at least* `-Wall -pedantic -Werror` by the time it hits v1.0, especially for something this basic, obvious, and easily fixed. Without a fix, nobody can use the compiler flags they want worry-free. *They* can’t easily test *their* code for conformance, for all that’s worth given the format glitch’s non-strict conformance tainting every stage up to the final executable. Or they can just avoid the code in question entirely, so it can maintain toy status forever.
That looks like it should work. What error do you get?
Unnamed Clown College. What legitimate school requires C but doesn't teach it?
The point the author is making only applies to APIs. If you have an enum that is only used internally in a library and the library is fully rebuilt from source every time, then changing enum value positions, while still not good practice, won’t actually break anything. The problem comes when *someone else* uses your library with compiled code that expects enum values to be specific numbers.
Quite a lot. I've been looking around at universities recently and it's the more questionable ones that do offer to take a student from the ground up. Most of them concentrate on teaching how to get there rather than hand holding. Students have a lot of time and they can still go to the lecturer for help. Chances are, if a course requires c, the students have been given enough time and help (should they require and ask).
He’s allocating an array, how would this help?
I'm still looking for names of colleges and universities that require C for courses but do not teach it. I went to St. Louis University and Washington University. Both taught C. Reddit, as always, rarely backs up anything they say.
1. Read a string of size 6, ensure no leading zeroes, and convert to int 2. Read an int and divide repeatedly to ensure it's 6 digits
On phone. Can’t share any code. But the process is pretty straightforward. First use read upto ⑥ digits into a char buffer. For each character, check whether it’s a valid numerical value (just clamping the ascii values should be enough for this). Then use scanf on your buffer to convert your buffer into a long.
you asked this before: [https://www.reddit.com/r/C\_Programming/comments/c9dobu/help\_restrict\_userinput\_to\_6\_digits/](https://www.reddit.com/r/C_Programming/comments/c9dobu/help_restrict_userinput_to_6_digits/)
And as if by magic, the thread is deleted....
yup, must have been a homework question
Don't use enums for a library return value. I hate debugging code using a library, get a value back and have to manually count enums to figure out what it is. Look at the linux error code header: http://www-numi.fnal.gov/offline_software/srt_public_context/WebDocs/Errors/unix_system_errors.html Do something like that please! Much easier for users of your library to use than a giant list of enums that we have to count to match up with what we see in GDB.
It depends on a person, but 3 hours per day for one a half month should be enough. Read K&amp;R again. It's only ~2h of _careful_ reading. However, it will take longer if you want to do exercises. In that case, I suggest giving your code to someone knowledgeable for review, because IIRC solutions were a bit outdated. After that, write more code and practice, practice, practice. Focus on data structures. Remember: C is a simple language, but you need to use it wisely. Watch out for usual traps: variable initialisation, array bounds, input verification, error checking, memory leaks and NULL pointers. Switch on all warnings in your compiler (for GCC `-Wall -Wextra -pedantic -pedantic-errors` is a good choice) and fix the code until compiler output is clean, not even a single warning. When you get to dynamic memory allocation, make yourself familiar with tools like Valgrind and use it. Debugger is great for finding problems and figuring out how things work - learn to use it early, trust me.
I'm a total newbie: So it's a great thing I'm learning this important lesson now (about enums used as an ABI) right off the bat! So ya, essentially my take away: NEVER EVER reorder your enums like that! Even if it's just at the tail end, and you think "what could it hurt?"... I could see that introducing even far more subtle errors/crashes down the road, because a program could pass a lot of testing with the majority of the enums just fine... but that one time the more subtle enum comes into play near the end... And these days with robotics, cars, airplanes, spaceships, and medical equipment, an error like that could even get people killed! -------------------------------- Anyways, on another note: that's a very nice, clear, concisely written article. Seems to have been written by someone called Chris Siebenmann. I'm going to have to check out his other writings on that site. Looks like the main page for his blog on that site is [HERE](https://utcc.utoronto.ca/~cks/space/blog/).
Especially these days
I'm not clear on what exactly you're advocating: using Unix error codes in applications instead of custom ones? Does gdb have built in translation to strings?
That's the updated code based on feedback I got here, so yes it works now. It had to do with declaring the snd object globally instead of inside main()
Yes, but that is confusing notation vs precedence. Because you put the addition COMPLETELY under the divisor line, it is implied that everything under that line is the divisor. However if I wrote the following: a -- + d b + c
Yet it's a quite common piece of advice to always prefer enums over macro `#define`s.
Not relating to the issue at hand, but have you considered using kedr for debugging? I found it to be absolutely essential: https://github.com/euspectre/kedr/wiki
In C, everything is pass-by-value. The pointer-array of strings that is `argv` is also passed to `main` by value, so yes, somewhere out there the original pointer still exists.
This is the proper way to allocate an `N`-length array (ie. a contiguous memory space) of whatever type `p` points to. Of course, sizeof should have parentheses? p = malloc(N * sizeof(*p));
&gt; If you do need to multiply by a size, this is an unsafe pattern. I'm not sure why calling malloc with a multiplied size is an unsafe pattern. Potential for integer overflow?
Did you not read my comment where I agreed with the content?
Can someone explain why this would be an issue if you are using error_t to determine the result? Is it common place to use the numerical value for evaluation instead of the type? I work in embedded systems so the amount of libraries used is pretty minimal, but I'm guessing this could be a problem for instances where multiple libraries might have their own implementation of a typedef called error_t making it more attractive just to use the index. Using the type just seems safer overall than relying on the index.
If you have the resources, find a competent and qualified tutor. If you don't have the resources, you'll need to be your own tutor. You get better at *anything* by learning methodically -- ie. making a plan, executing that plan, then evaluating the results and modifying accordingly. 1. First off, identify your goals. This isn't a matter of "I need to learn C" but rather identify *what* parts of C you are having trouble with explicitly. This is going to be tough, because it's hard to know what you don't know.... but see if you can start to put down your thoughts. As a starting-point, try using your data structures assignments as a guide. Look at an assignment, and think to yourself "What was this assignment trying to get me to achieve?" and write down the bullet-points. Then, look at the solution code, and ask yourself *on every line* "Do I understand what this line does?". If not, make a note of it. If there's any syntax that you don't understand, make a bullet-point to learn that. 2. Next, make a plan to practice your goals. This should take the form of Read/study -&gt; Execute minimal example -&gt; Execute contextual example -&gt; Internalize and expand. Breaking this down... First you academically study a topic and read source material to understand what something is, how it works, and the proper syntax. K&amp;R is your friend here. `man` in linux is your friend here. Minimal examples are basically a quick toy program that executes a concept in isolation. Ie. think of it as a hello-world for whatever concept you're working on. A contextual example is a bigger program that uses the concept "in the wild". Your data structures assignments are good examples of this. Finally, once you've executed, you should review to make sure you truly understand what's going on. 3. Practice quick-and-dirty exercises or "drills" to hone and build understanding. There are 3 exercises I like doing with students. The first is basically a muscle-memory drill. Starting from scratch, fire up your code editor, and write a program that does X minimal example. Compile it, run it, confirm that it works, then delete your files. Now repeat that 10 times for speed. It's kinda silly, but the point here is to drill the *mechanics* of writing code so when it comes time to building larger programs, you don't have to think about it... Too many times, I see students spending mental energy on "how do I futz around in my editor" or "how do I use X syntax" rather than conceptualizing a problem. Another exercise: walk line by line through a program and diagram the memory usage. Draw a line down the center of your diagram, such that one side represents memory on the stack, and one side represents memory on the heap. (Also make a space for code/static regions, if applicable). For every variable, that's assigned, draw a box. Label that box with a variable name, a size, it's type, and a value. If the box is a pointer, draw an arrow to the space in memory where the pointer points to. Do this in pencil, and erase/re-draw your values or pointers or whatever as they change. Cross out your boxes when they go out of scope or get freed. If there are print statements of any type, anticipate what the output to terminal is going to be.
&gt; So first off, you asked for when it might ever be a problem, and I gave you two of the three big compilers with exactly one flag that’s very often used, which causes a diagnostic to be emitted for uncasted `%p` argument. Whether or not that diagnostic is even enabled, the compiler can obviously tell that the argument is bogus. And because it can tell there’s a difference, without the compiler docs specifying one way or another, or without auditing the source code, you can’t be sure there won’t be some compile-/link-/load-/run-time behavioral change as a result. (Have fun auditing compiler optimizations.) The fact that the flag controlling the warning is called `--pedantic` suggests to me that the people controlling gcc in the late 1980s recognized that for most practical purposes the *warning* was bogus. The authors of the Standard have a consistent way of handling situations where the vast majority of implementations process an action in the same useful fashion, but on some rare platforms it might be impractical to guarantee consistent behavior without breaking existing code for those platforms: simply characterize the action as having undefined behavior on the assumption that the marketplace will sort out what should be expected of commonplace code and implementations. From the Rationale, p.11: | The goal of adopting this categorization is to allow a certain variety among implementations which permits quality of implementation to be an active force in the marketplace as well as to allow certain popular extensions, without removing the cachet of conformance to the Standard. Further, on page 13: | A strictly conforming program is another term for a maximally portable program. The goal is to give the programmer a fighting chance to make powerful C programs that are also highly portable, without seeming to demean perfectly useful C programs that happen not to be portable, thus the adverb strictly. Is there any aspect of the program #include &lt;stdio.h&gt; void declare511AutomaticObjects(void) { #define decl17(N) char a##N,b##N,c##N,d##N,e##N,f##N,g##N,h##N,i##N,j##N,k##N,l##N,m##N,n##N,o##N,q##N; decl17(0) decl17(1) decl17(2) decl17(3) decl17(4) decl17(5) decl17(6) decl17(7) decl17(8) decl17(9) decl17(10) decl17(11) decl17(12) decl17(13) decl17(14) decl17(15) decl17(16) decl17(17) decl17(18) decl17(19) decl17(20) decl17(21) decl17(22) decl17(23) decl17(24) decl17(25) decl17(26) decl17(27) decl17(28) decl17(29) char lastDummy; } int main(void) { if (0) printf("%p", "Wow"); return 0; } that is not strictly conforming? If a hosted implementation was for whatever reason not able to meaningfully process any other source text that happened to declare 511 identifiers in a single source block without running afoul of translation limits(*), would the Standard not require that it process the above code in a fashion that returns success without side-effects? (*) If for every translation limit listed in N5.2.4.1, an implementation would be capable of processing at least one source text which nominally exercises the limit in the fashion described by to the Standard, the Standard would impose no requirements on how the implementation process any other source texts. Thus, the only situation in which the Standard would impose any requirements *at all* on how an implementation processes any particular program would be if failure to process it would mean that the implementation was unable to process any programs that would exercise some limit. The authors of the Standard recognize that this is a very weak requirement, but do not see that as a problem: | While a deficient implementation could probably contrive a program that meets this requirement, yet still succeed in being useless, the C89 Committee felt that such ingenuity would probably require more work than making something useful. As for your last point, I can't think of many situations in which production-worthy code would use `%p` at all other than for trouble-shooting purposes, nor in which it could be useful without knowing the platform's ABI. While `%p` can be useful for trouble-shooting purposes on a platform with a known ABI, issues of "production readiness" don't seem particularly relevant in those cases. Further, there actually exist C11 implementations which would be *incapable* of processing code that uses `%p` to output all forms of data pointers interchangeably, I'm still not sure what purpose the warning could serve other than "smug pollution".
Yes, that's exactly why.
Yup: [Integer Overflow into Information Disclosure](https://nullprogram.com/blog/2017/07/19/). It's really easy to mess this up. The mentioned [`reallocarray(3)`](https://www.freebsd.org/cgi/man.cgi?query=reallocarray&amp;sektion=3) helps avoid that issue.
The standard specifically allows this (in 5.1.2.2.1, "Program startup"): &gt; The parameters argc and argv and the strings pointed to by the argv array shall be modifiableby the program, and retain their last-stored values between program startup and program termination. So this is no problem, and is commonly done. For example GNU getopt() rearranges the argv array to remove options and leave only operands for the program to process.
That's brilliant to hear, thank you! Oddly happy to hear that something I did is common practice, as a new programmer. Thank you again for the short and sweet reply.
An implementation is not required to process \`main\` the same way as it processes other functions, and in some cases C99 would effectively compel most implementations to process it differently (an implementation could process all functions that return \`int\` in a way that falling off the end would be equivalent to \`return 0;\`, but on most platforms applying such treatment to non-\`main\` functions whose callers ignore their return values would needlessly impair efficiency). Many compilers do in fact process \`main\` just like any other function, save for the requirement to add an implied \`return 0;\`, but the Standard grants considerable freedom to treat it specially. A conforming implementation could, for example, rename the first two arguments to reserved symbols and process them with external linkage, and include library functions that access those same objects, making their values available within nested functions. Modifying the objects might disrupt the behavior of such functions, but since the Standard would allow implementations to do anything whatsoever with code that calls such functions even when the symbols aren't modified, implementations would be under no obligation to prevent such disruption \[and in fact, could even specify calls to those functions will reflect anything done to\`main\`'s parmeters\].
Note that the Standard does not require that all implementations be suitable for purposes involving "manual" memory management. Code which reserves space for a structure using \`malloc\`, writes some members, uses a struct assignment to copy it, and only uses character types or the structure type to access any parts of the copy that weren't in the original, would have defined behavior even though some parts of the structure weren't written. The way the Effective Type rules of N1570 are written, user-written memory-management functions would not be able to guarantee behavior in such cases if an allocation was satisfied using storage that was previously written using a different type and not modified since. While many implementations process a dialect which supports manual memory management, the optimizers of clang and gcc will not do so without the use of compiler-specific syntax.
\[GNU getopt\] *The default is to permute the contents of argv while scanning it so that eventually all the non-options are at the end. This allows options to be given in any order, even with programs that were not written to expect this.* \[and ways to change that default\] &amp;#x200B; Whoa. Thanks!
Yeah this is definitely not the standard i'm used to regarding the bsd's, it's good that it's pointed out like this. It reminds me of my first try to create a package for openbsd haha. Some don't like the way openbsd developers come across but they always\^Wusually have a very good point. So then i rather listen then argue.
I'd start by skimming the sidebar for resources, the go-to book is The C Programming Language by Kernighan and Richie. If that doesn't work for you, there's some other suggested books. You can also try using tutorialspoint.com as a quick reference if you forget the syntax for something or need a basic example. Other than that, the best way to learn C is the best way to learn any language - start using it. Write some basic programs like a Caesar Cipher encoder/decoder or a simple blackjack game, or anything else you think is in reach. There's lots of good beginner projects listed on GitHub if you're interested. Last, keep in mind that C and C++ are different languages and so there are different ways of doing things in each. Have fun!
Thank you for the reply! I will definitely try what you've said!
C and C++ are closely related but *very* different languages, and whenever I see someone put "C/C++" on a resume I immediately know that I'd be lucky if they even know C. Don't do that. Take a look at the books in the sidebar. K&amp;R is a classic, written by the creators of the language; it's outdated in some respects but the fundamentals are solid. Beyond that, I'm sure you'll find lots of opinions on whether you should use Windows or Unix-like OSes, using IDEs or text editor+command line; but I think the most important thing is to set up a workflow you're comfortable with and start writing code.
BTW, with regard to being able to precisely specify numeric representations, I'd like to see C add some new concepts to structures, somewhat along the lines of "C with classes", but with all semantics rooted in C concepts. Most significantly, I would add semantically-scoped macros (as opposed to preprocessor macros) to the language and allow them to be used, among other things, to be attached to struct-member-access syntax, so that something like \`structLValue.x(arg1, arg2) += 5\` could be processed in a fashion similar to a macro invocation \`\_\_op\_TypeOfStruct\_caplus\_x(structLValue, 5, arg1, arg2)\` if the structure defined such a macro. If structures could also assign macros for "assign integer value to" or "use as integer value", then code which expecting something to behave as a 32-bit unsigned integer stored with four bits per \`char\` value in little-endian format could define a structure type that would behave in that fashion even on platforms where \`char\` isn't 8 bits. If there were a means of specifying that pointers to certain structure types should be implicitly convertible to certain other types, member macros could be used to accommodate virtual methods without requiring that compilers "own" any storage associated with a structure. Rather than saying that \`x.virtMethod(a,b,c)\` invokes a method via unspecified means that involve an unspecified amount of storage, one could simply have the structure type specify a macro for \`virtualMethod\` such that the above function call would become a macro invocation \`\_\_op\_TypeOfStruct\_call\_virtMethod(x, (a,b,c))\`, which could then expand to something like \`((x).typeDescriptor.methods\[0\](&amp;(x),a,b,c))\` if that's how user code set things up.
C++ is off topic in this subreddit. Post this elsewhere.
I'm trying to wrap my head around this, too. I think one problem is when you are using a shared library that was built with one enumeration, but you are using the new enumeration when you're compiling and some of the numbers have changed. You're accessing ALL_OK in your code, but ALL_OK is now 5 when ALL_OK used to be 32 or whatever. But that would imply that you are using the header file associated with a different version of the API than the one that is on your system. If you're using the same version, you would presumably have the same header file with the same enumeration in your code. As long as your code checks against ALL_OK instead of just 5, then you should still be alright, I think. I'm probably still missing something.
Number of; there's another macro that is \_\_NR\_syscall\_max+1, so that '&lt;' less than can be used for iteration. However, IIRC it's surrounded by some ifdef's so I just put the +1 in there to remind me that it is indeed the number of system calls, starting at 1. So with \_\_NR\_syscall\_max its 311 but would be 0-310 start 0.
No I had not seen this before your post! Thank you so much. I am trying it out now.
No worries. It's fantastic for detecting and diagnosing memory leaks. As a word or warning, kedr needs to be recompiled and reinstalled on a kernel-by-kernel basis. So it's good if your workflow involves a kernel that remains constant, and the modules simply change.
Mind if I add you on discord or something? I've been learning those languages too, mostly C, we could share resources and help eachother with basic stuff :D
Sure send me your ID and I'll add, although j haven't started yet so not sure I will be much help to you XD
You will catch up rather quickly, learning the basics won't take you that much, you will be ahead of me in a couple weeks :) I'm at work right now and this app doesn't allow me to pm (it crashes), I will send it a bit later today :D
Note that in gcc, a function like \`unsigned mul(unsigned short x, unsigned short y) { return x\*y; }\` will sometimes disrupt the behavior of calling code if the arithmetical value of \`x\` times \`y\` is in the range \`INT\_MAX+1u\` to \`UINT\_MAX\`. According to the published Rationale document, the authors of the Standard not only noted that signed and unsigned arithmetic would have the same defined behaviors except when the results are used in certain specific ways, but also noted that commonplace implementations would apply this treatment even to cases where the Standard would impose no requirements, thus avoiding the need to write rules to make short unsigned types promote differently depending upon how the result is used. Because the Standard doesn't forbid implementations from processing functions like the above in silly fashion, however, the authors of gcc pay no need to the authors' stated intentions.
Yes but that wouldn’t actually fix the problem of calculating the overall malloc size wrong
mostly to share dependencies between different compilation units. &amp;#x200B; it's not the best way of doing things, but keep in mind that C is ancient and it was designed to work on machines that had memory you could count on your fingers.
I think the biggest problem with macros is that preprocessor macros are oblivious to the rules of the language, but when combined with inline functions they've have managed to work just well enough to discourage the adoption of a proper compiler-based mechanism for token substitution.
The header file shows the interface. The source file contains the implementation. The idea is that a person using the code only needs to consult the header file to see what the calls are and how to use them. You don't need to see the source code in order to just use a function. It's also entirely possible that there is no source file, and the implementation is a binary, in which case you're really gonna need that .h file. &amp;#x200B; That said, all C programmers fight this for a little while, until one day you have 8 .c files that all behave like a single miserable main.c and it's impossible to debug.
In theory, yes (barring naming collisions) you could mash all the `.c` files together and compile it in one big blob. Compilers that support whole-application optimization sort of do this. The more usual way of compiling C is that each `.c` file is compiled separately into its own `.o` (object) file, which contains the implementations of functions from that module. Then you *link* the object files together to make the final executable. In that case, when you have functions you want to use across multiple `.c` files, you only want to include the *declaration* of the function everywhere. So you put the declarations in `.h` files and only `#include` those from other modules.
There's nothing special about header files, it's just a convention for organizing C programs. You typically put the implementation of your program's different modules in \*.c files and compile each \*.c file separately, and in the header file, you put only the things that whatever uses those modules needs to know to compile, like the function signatures or definitions that comprise its API, or any code that you want to be inlined in other compilation units.
Well, you wouldn't write to the standard *input*, that's either not going to work or generate some sort of error. You can read from `stdin`, it will either be input from the user or whatever data they piped into `stdin` (could be a file, or the output of another program). If you don't do anything special then `stdout` and `stderr` (FDs 1 and 2) are going to be identical. When a program is being executed, those could be redirected to separate places, so this can be used as a way to filter the text output of your program. For instance, you might print high severity error messages to `stderr`, and other diagnostic information to `stdout`. So if someone only cares about the high severity messages they could redirect `stderr` to a logfile and then that file would only contain the things your program wrote to `stderr`.
It's a nod towards meta-programming that never took off.
0 - stdin 1 - stdout 2 - stderr Different file descriptors for the standard io. Sorry, i use mobile rn
When you call the "open" function, you get a filedescriptor - which is basically an integer - in return. This filedescriptor is then passed as first parameter into the write function. You can use the numbers 0,1,2 to directly address stdin, stdout and stderr, but if you want to write I to your custom file that you have previously opened, then go with my description above
I am not suggesting use linux errors codes in a library as its API. I am suggesting that using `define` rather than `enum` to create your own list of error codes is better for a library due to the aforementioned reasons.
A quality compiler that is suitable for low-level programming on a platform with a particular ABI won't require that one jump through needless hoops to make it behave in a fashion consistent with that ABI. Because the Standard deliberately avoids requiring that implementations be suitable for any particular purpose, however, the question of whether an implementation is conforming is orthogonal to the question of whether it is suitable for low-level programming (or any useful purpose whatsoever). The fact that code written to perform some particular task will only work on implementations that are designed to be suitable for that task hardly means it's "broken", regardless of what some compiler writers seem to think. I wonder how long it would take the authors of gcc and clang to write it them a way that relies upon nothing that isn't mandated by the Standard beyond a bona fide effort not to impose needless or contrived translation limits \[the authors of the Standard note that a contrived implementation could be simultaneously "conforming" and completely useless, but it would be unfair to expect anyone to write code that would work usefully on such an implementation\] . Note that there are many situations where the Standard describes a general construct as invoking UB without bothering to mention specific cases which should obviously be processed usefully, but if the authors of gcc and clang are going to claim there's no excuse for UB, there should be no excuse for their exploitation of such constructs. To be sure, something like \`someStruct.arrayMember\[i\] = 23;\` would be far more readable than \`int temp = 23; memcpy(&amp;someStruct.arrayMember+i, temp, sizeof temp);\` but should that really be an excuse for accessing the stored value of a structure type using an lvalue which isn't one of the types listed in N1570 6.5p7? People who accept that the Standard isn't intended to be "complete" could justify such usage by saying that the authors of the Standard obviously intended that if an lvalue could be used to access an object, quality compilers that can see that a pointer is freshly derived from it should allow that pointer to be used likewise without regard for whether its type is listed in 6.5p7. Since the authors of clang and gcc are actively hostile to that principle, however, they have no justifiable basis to use it within their compiler.
Tip: if you know both, write C and C++.
C is one of the most light weight language around that you can learn the fundamentals in less than an hour. C is used everywhere in everything. THAT is why C is still taught in universities!
Ignore suggestions for K&amp;R as a first book on C. It’s a good resource to give you context on older C after a proper introductory text, but it’s too crufty as a first read. 21st Century C is good and walks you through the usage of many necessary supporting tools. It had a second edition. Stay away from Modern C. The author is an opinionated academic. The book has value once you have written enough code to be able to disagree with him. Get your feet wet quickly with the preprocessor. It’s not going to go away. There aren’t any good books I know of, but [this github page](https://github.com/pfultz2/Cloak/wiki/C-Preprocessor-tricks,-tips,-and-idioms) has everything you need to get started. There are a lot of great resources on C++. Just avoid any bad ones. Check book reviews. Programming Principles and Practice by Stroustrup is a good ground up C++ book, although he dilly dallies a lot. My favorite C++ resource is [cppreference](www.cppreference.com). You can read the language description comfortably start to finish to learn C++ if you already understand C.
Writing just C++ means you wrote C but with classes. People actually used C++ features add the standard they adhere, too, like C++11 or C++14.
We need header files because C is an old language that predates when module systems became common, so instead what they did at the time was to put the declarations of functions into a separate file and then textually include that file into every source file that needs to use the function. In modern languages you don't generally need to do this because the compiler is smart enough to seek out the declaration it needs to know about from one of the modules you are using, but the price that you pay is that the work needed to do all of this--in addition to introducing headaches like figuring out the order in which to compile the source files and what to do about cycles--makes the compiler and the build process more complicated. Writing a separate header file with the declarations creates extra work for humans (and is potentially prone to errors if you don't update the declaration in the header when you change the definition in the source file!) but it has the advantage that it is easy to implement in the compiler because it can just dump the contents of the header in the source file and then proceed as it normally would.
The macros are entirely unnecessary. Just manually add the prefix. For example if is common in GLib-based libraries and applications to have a project prefix. GLib uses G. GTK uses GTK. json-glib uses Json. Come up with an abbreviation for your lib and prefix your structs and functions appropriately.
C is the foundation of nearly everything. Other Languages, OS's, embedded devices, microcontrollers, etc.. it's valuable knowing how things work at a lower level. And, it's relatively small and easy to learn.
Ah, I misunderstood your objection.
I haven't been programming in C for a while but I remember seeing macros being used for this. So I don't think its that uncommon.
IMO C is much better than almost any other programming language at teaching the background of all other languages as well as data structure and algorithm fundamentals.
I don't know the specific reasons why universities use it, but I think a solid base of low-level knowledge is a good foundation for any programmer. With C, you are basically speaking the language of the processor. It gives you a much better perspective on what's going on under the hood of high-level abstractions.
Use constants rather than literals, will help you in the long run.
by default in unix/linux OS the file descritor "1" references stdout, "2" stderr and 0 stdin. you can also use write() with any kind of linux/unix file descriptor, and keep in mind that almost everything in linux is a file descriptor. short example \#include &lt;unistd.h&gt; \#include &lt;stdio.h&gt; &amp;#x200B; int main (void) { char \*message = "some message\\n"; // might give a compile error fp \*file = fopen ("some.file", "r+"); write (file, message, sizeof(message)); fclose (file); }
You can use the macros, but they get you nothing. What's the difference between: ```XYZ_P(foo) ``` and ```xyz_foo ``` ? The only thing the macro would get you is that you can change the prefix at compile time but it's really not worth the trouble.
The question is not "why C is still taught in Universities" the question is why Fortran 77 is still taught in Universities, particularly outside computer science. C is still very important, its the most portable language we have that's close enough to assembly. And it's still widely used outside the web.
A CS degree should teach you important concepts like stack frames and memory allocation, layout and addresses that are not exposed through higher level languages like Java, Python and JS. That is why C is taught.
C has the smallest *magic* among the languages you have mentioned.
so you mean that I won't use fd 0 and 2 because there is no way to use them? if it's like that why should write got 3 parameters? shouldn't be default fd 1?
file parameter should be FILE or NULL value as I think, isn't that impossible? because write accept only 0,1 or 2?
why should write use stdin or stderr?
I was thinking this as well
Thanks for this, that actually makes a lot of sense.
The name C is used to refer to two diverging languages. The language Dennis Ritchie invented is designed to be suitable as a form of high-level assembler which can use semantics of the form "perform this action in the execution environment, with whatever consequences result" to do a wide range of things, without a compiler having to know or care about how the execution environment would process the indicated actions. The authors of the C Standard recognized this: "Although it strove to give programmers the opportunity to write truly portable programs, the C89 Committee did not want to force programmers into writing portably, to preclude the use of C as a “high-level assembler”: the ability to write machine specific code is one of the strengths of C." The language the authors of clang and gcc want to process is superficially similar, but with most of the abilities to exploit features of the underlying environment removed. It is also, ironically, much more complicated than it would be if such features had simply been left in. For whatever reason, a religion as sprung up around the idea that any program relying upon features not mandated by the Standard is "broken", despite the fact that the authors of the Standard have said "The goal is to give the programmer a fighting chance to make powerful C programs that are also highly portable, without seeming to demean perfectly useful C programs that happen not to be portable, thus the adverb strictly."
I guess we should just write ANSI C/C89/C99/C11/C14/C With Classes/C++98/C++03/C++11/C++14/C++17/C++20/C++2x.
To add to all of the great input here, teaching C first makes teaching assembler and computer organization much easier. It also lowers the barrier of entry for software engineering majors and CS majors to get into embedded development. It’s also a good way to teach algorithms and data structures and the memory management associated with the two.
I think the main use for C besides the things you have already identified is that it introduces you to un-managed pointers and unsafe pointer arithmetic. This makes the jump to C++ a lot smoother (although it has managed pointers). Professionally, I make a lot of UI's in C# (Basically a better Java), but there have been times that I've needed to drop down and do a managed-to-unmanaged context switch to C++ to crunch some numbers (Image processing) and quickly and pass them back to the C# Garbage Collector. I wouldn't be able to do this without knowledge of pointers. There are times when pointer arithmetic can be a lot more convenient. Consider UDP, where I want to send a single 32 bit float across the network, but must convert it's bits to a byte array to send it). In a language like Java I might have to copy the whole array out, while in C I can just pass the pointer address and change the pointer scale factor. To be fair, yes I do think C is used partly to weed out students from the CS Program, although I think [Theoretical Computer Science](https://stackoverflow.com/questions/4294270/how-to-prove-that-a-problem-is-np-complete) (see [Multi-dimensional Dynamic Programming](https://itnext.io/introduction-to-multi-dimensional-dynamic-programming-666b095b2e7b)), and hand tracing [IA-86 Assembly](https://stackoverflow.com/questions/8483641/tracing-a-stack-in-x86-assembly-code) with paper and pencil is much more effective as weeding mechanisms.
The only other thing missing from the comments here is the idea of function visibility - headers allow compilation units (.c files) to hide functions that shouldn't be visible to other compilation units without declaring them as file-level functions (the `static` keyword) - this is sometimes known as an 'internal' scope, especially when talking about libraries used by other applications. Crudely, it's related to the idea of namespacing, but more exactly it's just visibility. This is a requirement for programs with multiple copies a function with the same name - e.g. each .c file could have a function called "init()" and when you cat'd all the files together, the compiler would have no way to disambiguate between the versions of "init()".
Did you actually read K&amp;R? Its treatment of language fundamentals is not existing and it is a very bad book for beginners. It is more suited for people already experienced with other languages and just want a quick overview about how things look in C.
...and very hard to master :).
Just like Chess. The greatest board game.
And your point is ...?
You are confusing write and fwrite.
Other than the obvious point about C, don't forget that universities are institutions that exists not to give a person a job but give mostly theoretical knowledge on a certain field. So as unintuitive as it might sound, you should be more worried about why C/assembly and such aren't taught in a university. At the university I studied, we had to make/validate turing machine on paper.
My attempt at an analogy would be that the header file is like a restaurant's menu. It doesn't contain the recipe to create each dish, but it indicates what food can be made at that restaurant. The .c files would then be the recipes to create the food.
&gt; It's also entirely possible that there is no source file, and the implementation is a binary, How do you do that?
Linkable libraries
Well, close to two decades ago now, and I've only taken occasional glances at it since, but K&amp;R 2nd edition was how I first learned C. My memory is that it's a concise and effective introduction to the language. My memory may be wrong of course, and I'm sure there are better and certainly more up-to-date books; I just can't vouch for them.
You should never write to [stdin.you](https://stdin.you) should \`read\` from stdin. stderr is very useful where the application output may be piped to a different application/file/fifo/etc, but you still what to present information to the user.
This is how libraries work. If you want to compile code that uses functions in a static or dynamic library, you still need the header files. The header file tells your compiler the function signatures -- the calling convention, the number and types of the parameters, and the type that is returned. (It also puts the names of the functions in the symbol list, but that information is also in the library binary, while the signature is not in the binary.)
\&gt; Then, you include file1.c in file2.c, and use the function from file1.c. Why do we need header files? The short answer is that you don't do that, because in the long run it makes organizing even mildly complex programs incredibly difficult. If you get into the level of organization of having libraries, you absolutely need header files (or a trivial substitute for them).
&gt;Well, you wouldn't write to the standard input, that's either not going to work or generate some sort of error. If your program is connected to the console, it will fail. But your program in the Unix world doesn't know much about stdin -- it could actually be connected to a file descriptor where write would work. That said, don't do it, because it really doesn't fit the model of how you should be using stdin. &gt;If you don't do anything special then stdout and stderr (FDs 1 and 2) are going to be identical. If you're on a console, they will *mostly* go to the same place. That doesn't mean they're the same.
You don't have to use them, but it makes life a bit easier if you do. They are a way to say "I want this source code to be the same for everyone who needs the stuff within it."
&gt;so you mean that I won't use fd 0 and 2 because there is no way to use them? The only reason you wouldn't use FD 0 for write is that "writing" to an input-only file doesn't make sense. Stdin is intended to be an input-only file. You absolutely can use FD 0. If you're familiar with more introductory, "cooked" C, writing to FD 2 is like fprintf(stderr, ...). Error messages should go there, while "normal" output should typically go to FD 1. &gt;if it's like that why should write got 3 parameters? shouldn't be default fd 1? Like the documentation says, you can use open to open an arbitrary file and then use write to write to it. A program is supplied with a probably-functional FD 0, 1, 2 for stdin, stdout, stderr, but the program is free to open more files on more FDs. Many do! C doesn't have default parameters.
No; module systems predated C. Not by much, but I'd date JOVIAL to before C and it has modules. Neither approach is inherently better than the other. People will prefer whichever they are most comfortable with. I find module systems slightly worse - they don't grep as well as header files do.
Functions that take a FILE parameter are "cooked" functions -- they're a slightly higher-level abstraction that is provided by the C standard library. Functions that take a file descriptor, in general, are lower-level functions. For example, write is just a trivial wrapper around the Unix write system call.
get confused the time I start using write.
I'd say C isn't taught very much in school. Perhaps it shouldn't be; I don't really know. C is generally the primary ancestor of a lot of other languages. But learning it in a class setting is sort of a problem because it requires some time to learn properly. I don't think people who don't like C should have to use it. By the same token, don't ask me to use Python.
Thank you for the reply. &gt; No; module systems predated C. I know, that is why I specifically said it was before a time when modules were common. Do you disagree with that? &gt; Neither approach is inherently better than the other. I made no judgements either way. My only intent was to explain why C currently uses headers in contrast with most modern languages in order to provide context, which I thought might be helpful if the person asking the question has had experience with other languages that do not require header files.
&gt; compilers give no help for. This isn't true at all, some compilers sure. Type defined variables in IAR are resolved to the actual enumeration name, not just an integer value. This makes debugging a lot easier than seeing integers in the watch window. &gt; an important warning to us all, something we are prone to forget I disagree that this is an important for all C programmers (This is /r/C_Programming, not just specifically C programming for Linux). Using enumerated types strictly without integers is the safest thing you can do when using indexed lists. Here is a good example of why enumerations are safer than arbitrary index values: typedef enum { NO_ERROR = 0, ERROR_1, ERROR_2 } error_t; error_t getErrorValue(void); error_t errVal = getErrorValue(); if(errVal != NO_ERROR) { ASSERT(); }
Linker voodoo. I'm a mere coder, not a build engineer, so I'll confess that I don't totally understand it, but it's how vendors supply proprietary libs sometimes.
Besides defining functions and return types you also define data structures, custom types (u_int16 etc) , and macros among others. You can also put entire libraries in headers. You can also go the extreme and only have main in a c program, and all your other files as headers and include them all. It's an old school 'whole program optomization' thing and it'll only invoke the compiler once. Which is great for fast single cores. Or keep the files small and run make in parallel and use all your cores.
&gt; the bsd's, OpenBSD has a standard of excellence. The others? Not so much.
Backing up a tad, `sort` is an instructional example. Its input (stdin) comes from whatever’s to be sorted, usually line-by-line text. Its output (stdout) is that text, sorted. If it encounters an error (e.g., I/O error, insufficient memory, insufficient disk space, interruption), it would write that error message to stderr, not stdout. You’d also use stderr to write out status messages, and things like progress bars (possibly with color, even) as long as you’re sure stderr is a tty (usually via `isatty` or maybe `fstat`). Essentially, stderr lets you avoid polluting your normal output, so that programs expecting to see that output in a specific form don’t choke on your (intended-for-human-use) error/warning/status/info/debug/trace messages.
Im about too marge the two data structors with the new one. [https://github.com/squidfarts/retro-squid-colletions.git](https://github.com/squidfarts/retro-squid-colletions.git)
Btw, why do you call yourself “team squidfarts” when you are just a single person?
Why do you use meson build files? I’m just curious, I’ve never tried it out.
Header files exist mainly to support modular program structure and to allow separation of interface and implementation. If your `main()` calls `printf()`, the compiler needs to know the signature/interface of `printf()` so that it can properly check the types of the arguments, generate code to manage the call stack, and so on. But it can do so without knowing what `printf()` actually does, that information is only needed at the linking stage, which occurs after everything is compiled. It's entirely possible to `#include` one source file in another, but there's rarely a good reason for doing so. If `a.c` and `b.c` are part of the same project and both include `util.c`, then building the project (which entails compiling `a.c` and `b.c`) will compile the contents of `util.c` twice, and may even result in two instances of every function in `util.c` being in the final executable, which increases executable size without providing any real benefit. In addition, when working with system or third-party libraries, the use of header files means that libraries and applications may be recompiled separately, so long as the interface remains the same. If a library has to be modified, the *library* will need to be recompiled, but any programs depending on the library only need to be re-linked, which is generally quicker than re-compiling the whole application. Likewise, if all libraries were `#included` rather than linked, any change to the program would require recompiling the whole library, even though the library itself is unchanged.
In C you can declare a function before you define the function. You absolutely have to declare a function before you call the function. You can define the function wherever you wish. In order to compile a function, all the functions that it calls have to be declared. If the compiler sees a function that it doesn't already know about, it throws an error. In c89 and K&amp;R that declaration had to linearly occur in the source file before any code that called it. You could define it somewhere else, but you had to declare it. Later versions of C might be multi-pass and let you declare it anywhere but it's never come up for me because I put everything in a header. Your method works if the functions in file2.c never, ever call the functions in file1.c. If they refer to each other, now you've got a problem. There is no way to order the includes to satisfy that every function (and variable) has a declaration. You would have to manually merge the files, or the pre-processor would have to relocate all the declarations to the beginning of the code. Imagine if you had a large project. By splitting the declaration into a separate file you no longer have to worry about the order you define your functions in. It also ceases to matter what order you compile your files in. You solve the problem of cyclical includes with pre-processor macros.
Abstraction isn’t magic.
Eh I just don't want to mention my uni, but it was a pretty decent UC.
Meson build system requires the project to have 'meson.build' files. Build system [comparisons](https://mesonbuild.com/Comparisons.html).
I enjoy these parts. My approach to programming is to massage the problem I want to solve until it is resolved to implementing a precise specification.
Team of one. But i'm open to having other developers taking intrust in this side project.
Well, usually I'm the one who wrote the design specification so if it sucks i have no one to blame but myself. The coding is trivial, solving the problem is both the fun part and the part that takes the most time. What is tedious is going to meeting from meeting trying to explain why you don't get any real work done because you are in meetings explaining why you don't get any work done.
I showed you mine. Now show me yours. As I said, redditors rarely back up anything they say. That's why reddit is such a laughing stock and shit show.
Nup, I'll decline. I don't really care to prove a point you're obsessed over. Take it or leave it.
Thanks so much! That's a good idea to go back and redo my data structures assignments - I think I'll use those to practice C and do it well this time. Re: debugger, I use XCode as my IDE, and I think the debugger there is lldb. Is there a significant difference between lldb and gdb, do you think? Our class notes recommend that we learn gdb, but my intuition is that debuggers aren't really that different from one another.
Without header files, you have to write your own printf for every program you write, that’s one example
Thanks for responding! I thought to do the Leetcode problems in Python because I'm trying to simultaneously prepare for both my next CS class (for which I need C) and internship interviews for next summer, but I figured since I'm awful at C, it'd be faster to learn C separately and prepare for internships with a language I'm already relatively comfortable in, which in this case is Python. But I don't know all of Python 3, so even doing Leetcode in Python is helping me learn 1) python syntax I don't yet know and 2) when/where to implement what data structure. And then I could just use Python in interviews since using C means I'd have to construct all the data structures, etc. from the ground up. Maybe it'd be a good idea to do the problems first in Python and then reimplement in C? Honestly my main concern is that since I'm on a short time crunch and trying to optimize for two separate goals (preparing for next class and doing well in interviews), using C might significantly bottleneck me in the latter goal. I hope this makes sense - I'm a bit tired, so this might not all be perfectly articulated. Thanks again for your time!
Thanks for your response! It's a bit encouraging to hear that C is relatively compact - I think my issue with C in the course was that it was a wildly different paradigm than what I was used to previously. The intro course in my sequence at my university is in a Scheme-like functional language, and my other programming experience is mostly scripting in Python, since I came from a biomedical research background in high school. So having to think about arrays and how they relate to pointers, or having to define my own structs, writing code that was more complicated than simple scripts to process/handle scientific data, etc. combined with C's sometimes weird syntax made everything relatively difficult. It was a total paradigm shift, a headache which was compounded when my code kept throwing segmentation faults and I kept having to use the command line for stuff (I'm used to nice GUIs lol).
In a header file you put the definition of a function (type, parameter types, etc) and if a program wants to use this function, that definition is all you need in order to organize the memory accordingly. Then to implement what the function actually does, you can use another c file just for implementing the functions defined in the header file. Then you can compile them together (linking) and your program will work.
Thanks for responding! The next course in the sequence is systems programming - I'm trying to get to a point where I can go from my currently 0 C knowledge (not really 0, but close enough) to being able to write the file archiver in a month's time before the class starts. I'm unsure if the better idea is to 1) try to redo my data structures assignments and *then* try to write the file archiver in like a few days or 2) try to start writing the file archiver right now and figure stuff out along the way. If 2 is the better option, I'm unsure of how to find out how I'm supposed to even begin. As someone else mentioned in this post, it's a problem of not knowing what I don't know, if that makes sense.
&gt; What is tedious is going to meeting from meeting trying to explain why you don't get any real work done because you are in meetings explaining why you don't get any work done. Thank you for bringing this to our attention, necheffa. We will schedule a Monday meeting to address that.
After one learns how it works.
Stockholm syndrome.
Also, get good enough that you can avoid work like that or make someone else do it because you're more of a "big picture" type.
Break up your header files into internal (like in an inc directory) and API (api directory). Then only items define in the API directory need your library's prefixes. Everything else becomes private and internal to the library. Using static attributes helps enforce this as well, but if course that limits the usage of the declared item even more.
Wow, that's actually a really good analogy!
One of they're main uses is for organizing large scale programs. They seem pointless to you because most likely none of the programs you've worked with were big enough for you to see the benefit.
&gt;You absolutely have to declare a function before you call the function. The spirit of this is correct, but not the letter. The compiler may complain at you, but your program will still link and run fine if you call an an undeclared function's whose return type is `int` and you use it that way. For example, this perfectly legal in C: foo.c: int foo(int a, int b) { return a + b; } bar.c: int main(int argc, char *argv[]) { return foo(1, 2); } When you link and execute that, the return value of the program will be 3.
Noise cancellation headphones and some good music.
If it's very repetitive stuff, I would use some macros. (Emacs works well for that.) You could also go a little crazy and write some scripts for code generation.
Are you a masochist or what?
Lobby for more interns, get them to do it. If it's something where automating the code generation might be more interesting than writing it by hand or save time in the long haul, I might write a script to do it.
Wow, that's an exhaustive list! Thank you!
In one word : making code managable.
&gt;Maybe it'd be a good idea to do the problems first in Python and then reimplement in C? That's actually a really good idea, because Python is a pretty forgiving environment to figure out the algorithmic approach. Then the exercise becomes how to do things in C that you've already accomplished in Python. Now it's not perfect. In practice, there are high-level differences in the two platforms that usually translate to different approaches for the same problem. But your goal here is to learn C while practicing leetcode for interviews, not developing highly scalable systems software, so this is largely an academic concern.
I had one of those jobs (in Oracle Forms, not C). I amused myself by writing all of my comments in haiku. It is seriously the only reason I remember *any* of what I did on that project 20 year ago. *products to be shipped* *in containers they must go* *how many will fit?*
That's an explanation, but it's not the actual reason. The reason is because the compiler needs header files to be able to compile files one by one from top to bottom without holding the other source files in memory, because memory was much more expensive and limited back when C was originally designed.
The issue isn't that src can not be nul terminated it's that it's just a extra work that doesn't need to happen and just bad imo.
Imo meson is 100 times easier to use than cmake, especially if you’ve never used cmake before. Specifically the learning curve is much lower. The documentation is mostly better and the scripting language makes more sense if you’ve used other scripting languages like python or JavaScript. It’s still pretty powerful and allows for a large amount of end user customization, though it probably doesn’t have full feature parity to cmake/make. Instead of outputting a make file it uses ninja to build your project, which I’ve found to be faster in general.
I organise my code into extremely modular functions. Each function does one thing - and one thing only. Imagine if there was no strlen. If you made it once, you would be mad to rewrite it every time you came across the same situation.
Because you redefine *mem as function arg and print data from stack
It's a Very good analogy.
&gt; `unsigned char *mem = (unsigned char *)&amp;n;` i think you want `size_t mem = &amp;n;`.
I've used several debuggers, but none of them were lldb or gdb, so I can't comment on them specifically. Breakpoints, single stepping, and the ability to look at variables are 99% of what you need, and I'm sure lldb and gdb both support them, and probably more. If you can't spec a project, you can't really write code for it. "File archiver" is so vague that I wouldn't start on it without a whole lot more detail on what it's supposed to do. But if you have a good spec that you understand, go for it. Otherwise, pick a project of your own. For personal projects, which can be open-ended, it's helpful to sketch out intermediate milestones that you can code to, just to break down your project into manageable chunks.
I have to agree. I also prefer to have a solid design that spares from thinking whilst I'm typing the code in. It's also an awesome feeling when you hit Run the first time and your code doesn't bug out. It's probably because I learned programming on grid paper and with flowcharts.
You have got things upside-down. The problem is not compiling your code against a library, the problem is when you have a compiled application and the library it calls gets updated in the background. Then your application will suddenly no longer work. Compiled code calls a dynamic library through the Application Binary Interface (ABI), and when the enum constants change, that manifests in an ABI change and all applications which used the old ABI will no longer work with the new one. Hence a library update causes previously-good applications to fail. C programmers who build libraries (who this article is aimed at) have to be acutely aware of these issues.
`print_memory` dereferences `mem` (i.e. `mem[size]`) - that why it's printing the _contents_ of the address, not the address itself. The way the function is designed supports this behavior - you pass in a pointer (`mem`) and also how many bytes it points to (`size`). If all you wanted to do was print the memory address, there no need to pass in the size - it's the size of a pointer. E.g. `sizeof(mem)`. But, if you want to print out the address one byte at a time you'll need to know big-endian vs little endian in order to print the bytes in the right order. It's much simpler to simply use: `printf("%p\n", &amp;n);`
You don't get it. Please read my response to u/bundes_sheep below.
This is the most important answer. You don't include file1.c in file2.c, you link them together after they are compiled--so you need some way for file2.c to know about what is exported by file1.c, which is what the header file is for. Note that this isn't really required, especially with the sophistication of compilers these days. For example in C# you just say "I used some stuff from file1.c" and the compiler examines it to figure out what it exports. But it's how C has always worked.
Especially these days
There isn't really a right way to do. The point of the article is to make library writers mindful of the potential pitfall. The only rule you can make is, when developing a library for its next release, think VERY HARD about the implications of changing the numerical value of ANY compile-time constants. This applies equally to ```#define```s, ```const int```s, etc.
The proper answer is that it's a relic of the past. When C was developed, computers were slow and memory was expensive, so C was designed to parse the code in a single pass. Therefore forward declarations was needed and a culture og making header files emerged. Newer languages often don't require this, because they were not developed with this limitation in mind.
Use vim. Then you focus on writing text than mouse clicks. Trust me, when ur writing that kind of code, distractions can add up quick.
It helps for some people who want closed source and they don't give the source code so they just give you header file containing all function prototypes and object file (.o) of that header file.
I just do it, don't find this overly tedious to be honest. Sometimes it's nice just to do something mechanically for a change. Make a cup of coffee, put on some music and type away.
&gt; The more usual way of compiling C is that each .c file is compiled separately into its own .o (object) file, which contains the implementations of functions from that module. Then you link the object files together to make the final executable. Nice answer, but you're missing an important part that probably seems trivial to you (but OP might not know). By separating the C files into separate compilation unites, tests and updates to the code are easier and faster. Why? - because **you only need to compile the `.c` files that were updated instead of the whole code-base**.
Even if you ignore some benefits such as code management, separation of concerns or encapsulation (none of which exist once you include all the `.c` into a huge `.c` file... there's the issue of compilation, testing and development speed. By compiling each `.c` file separately and using only header files to share information between `.c` files, we can avoid re-compilation of `.c` files that aren't edited across builds. For example, when editing and fixing a specific function in `foo.c`, you don't need to compile `bar.c` every time you make a change. Yes, today's computers are fast, so for many small/medium projects we're talking about saving seconds rather than minutes, but it still saves time, it adds up and it feels better to develop this way. In addition, all those reason I ignored at the beginning are very important as your projects grow. These reasons become de-facto requirements when coding as part of a team.
`where you have to implement precisely what a specification says` This is heaven for me, and is where I'm most productive. I put on [this soundtrack](https://www.youtube.com/watch?v=FmSEBmtxcDg) and get the job done. Coding precisely to specification is where I can just methodically tackle a solution, and design an elegant solution, build my tests, and submit my work feeling 99% confident about my work. As long as I have tests that touch upon each part of the specification, I can be assured that my code is up-to-snuff.
&gt;It is more suited for people already experienced with other languages and just want a quick overview about how things look in C. So... people like OP?
I've been using brain.fm it sounds really hokey but it works well for me.
It is not really common. This "name mangling" may be necessary in complicated cases where there might be multiple implementations of the same API ([for example with OpenGL](http://mesa3d.sourceforge.net/mangling.html)). But usually a library defines its own API and can assume to be the only implementation, so it just pick some likely unique prefix.
You're just proving my point about redditors. On top of that, my additional point is that, what redditors call "college" or "university" is not anything most of us call such things and, more likely, it's a clown college like "Joe's Computers and Stuff" that you found advertised on a match book cover.
Why? OP is passing ```mem``` to a function that expects ```unsigned char *``` as a parameter, and they're not doing any integer arithmetic with it.
&gt;The only thing the macro would get you is that you can change the prefix at compile time but it can get you into some weird link issues. Ye, I saw it in a project where they allowed you to change the prefix by setting the macro. But like I said I havent been programming in C for a while.
Because an `char` is usually 8 bits, and thus probably won't be large enough to be able to hold all possible pointer values (unless the OP is using some non-x86_64 system, which i'm assuming is unlikely). Obviously the rest of the code would need to be changed accordingly.
It is true that "modern" languages don't use header files, and this is reasonable for scripting languages, but I think it is a fundamental design flaw for compiled languages. Header files allow you to define a stable API separate from the implementation, which is important especially for shared libraries. For example, Rust and Go don't use header files. The consequence is that although it is technically possible to build shared libraries with them, this is impractical due to the lack of header files -- which is why you usually have to resort to static linking with these languages. And even though C++ has header files like C, it lacks the clear separation of interface and implementation because there are usually templates, inline functions, private members declared in header files. Because of this, it is not uncommon to use *C* header files as a wrapper for libraries implemented in C++ ("hourglass pattern").
Right, which is why they're using a pointer type and not a char. ```char``` might be only 8 bits, but ```char *``` is normally 4 or 8 bytes - the same size as ```void *```, ```int16_t *```, ```long double *``` or whatever other kind of pointer you can think of (except perhaps pointers to functions, but that's not relevant here.)
One other thing, avoid header-only libraries in C. See the relevant thread on this sub about it. In C++ it's more common and has less issues because of templates.
adderall
*Tentatively accepts*
You're right - gah, my bad. :-/
Yep, sometimes I like being the code monkey
Ha! The joke is ok you because I'm already double booked for meetings all Monday.
you've got that totally wrong. Needing a header file for pretty much everything is annoying, you don't need a stable API for everything. &amp;#x200B; In modern languages you can easily create another file with the interface. There , you have the stable api.
it males you understand logical concepts better than pther languages as it is closer to Hardware. Furthermore you can wrote very efficient code by including inline asm. It is also supported by pretty much any platform, from microcontrollers with 2k ram to fully blown desktops or even gpu's.
this sounds interesting, could you rephrase it?
I'm no expert but writing code in a very modular fashion I think is probably one of the easiest and safest ways of getting things to work as intended, it's definitely what I do. Also what js strlen?
Yes that's kind of true unfortunately. I regularly donate to openbsd but i don't run it as much anymore as i used to unfortunately.
Gets the length of a string It is part of string.h. For more, do this from the command line: man strlen
You completely missed my point. Not all C programs are dynamically linked. This line of thinking completely glosses over embedded systems.
No, from the wording I don’t think op is actually knowledgeable in python or programming in general but just used some of its packages for some quickly hacked scripts.
Yeah all I want to really say is it is a UC, whether you consider that a clown school or whatever is up to you. I don’t really care about what you consider a “redditor.”
I'm a computer scientist by profession. I write C code to implement algorithms I designed. The algorithm design is the hard part and happens entirely on paper and in my head. Once I'm finished with the algorithm, implementing it is very straightforward and just consists of casting the algorithm description into the syntax of C. It's the payoff for months of work you could say. I really enjoy doing that, even if it's not particularly creative work.
You allocate space for three pointers to Pair objects. But you do not allocate storage for the Pair structures themselves, much less the strings you copy into them.
Thanks for reply. How would I know how much space to allocate for the Pair structures in cases the input for first and second are given by the user?
Unfortunately my software design course was taught by a professor who really didn't know what he was doing, so all I learned was MVC and C# delegate methods. Do you have any books or other resources you used when learning to design code?
If you want to use an array of Pair objects, you should declare it as `Pair list[3];`. `Pair *list[3]` means an array of pointers to Pair structs and you have to allocate those. You'd do that like so: `list[0] = malloc(sizeof(Pair))`. Like the other comment said, the strings inside Pair must be allocated as well. You do that like this `list[0].first = malloc(sizeof(char) * 100)`. This is assuming you declare it as Pair list[3]. Also, in the first part of your code you're using indices from 1 to 3 but array indices start at 0 so you should do list[0], list[1], list[2]. That's all I can think of for now.
Try to mix it up a bit. Use a new data structure or a new library if you can. Do something in a different way might build your skill out and open some door to more tools in your toolbox.
The first mistake I notice from your code is that arrays start at 0 up to 1 - the total size allocated. So if you have an array of size 3, you can store information on 0, 1 and 2. &amp;#x200B; Second mistake I notice is that you do not allocate space for your structure or for your strings. I view a pointer in C as an address to a space in memory. You have to specify the size of that space. &amp;#x200B; First you need to allocate memory for each of the Pair structures in the array through the use of malloca (memory-allocate) on every index: * list\[i\] = (Pair \*)malloc(sizeof(Pair)). &amp;#x200B; &amp;#x200B; Second you need to allocate memory for each string of the Pair structure: * list\[i\]-&gt;first = (char\*) malloc(12\*sizeof(char)); * list\[i\]-&gt;snd = (char\*) malloc(12\*sizeof(char)); &amp;#x200B; You have to decide how long each string can be. In the code above, I set it to 12 characters. &amp;#x200B; &amp;#x200B; Third, you can alter each string as follows: * list\[0\]-&gt;first = "fst"; * list\[0\]-&gt;snd = "snd"; &amp;#x200B; &amp;#x200B; &amp;#x200B; I hope this helps.
The Pair structures themselves are easy enough, as you know their storage requirements immediately: struct Pair *list[3]; for (i = 0; i &lt;= 3; i++) { list[i] = malloc(sizeof (struct Pair)); } Or, if you want to make it a bit easier for yourself&gt; struct Pair list[3]; /* Allocates three Pair objects, rather than pointers to them. */ As for the strings themselves, rather than strcpy(), use strdup() instead. Going with the simplified allocation of the Pair structures, you'd do it like this: list[0].first = strdup("first pair first"); list[0].snd = strdup("first pair second"); .... printf("First is: %s. Second is: %s.\n", list[i].first, list[i].snd); In addition to this, remember that C arrays a 0 indexed, so your assignments should be to list[0], [1] and [2].
Thank you very much!
My job put us through SEI's Software Architecture series. I didn't take the certification exam, but it's three courses each with a textbook: [https://www.sei.cmu.edu/education-outreach/credentials/credential.cfm?customel\_datapageid\_14047=15203#term](https://www.sei.cmu.edu/education-outreach/credentials/credential.cfm?customel_datapageid_14047=15203#term) There's links to the textbooks inside the individual course links.
Do not do number 2 if you are using number 3 or your program will allocate the memory and then lose the reference. Stick with strcpy.
Here here
I like that C stresses that the programmer is responsible for the resources s/he uses. Allocate memory? Then you are responsible for free()’ing it. Open a file? Then you are responsible for maintaining it. For trivial programs, sure, people let the OS recover those resources when the program terminates. For non-trivial programs, resource management is important, and students should be exposed to these ideas.
"I try to write the best possible algorithm for this specific problem that I spend hours trying to design and then it assembles exactly the same as a call to std::sort" is what I like to do best. Of course, that's not what I tell people, I implement my engineering skills and knowledge to design problem specific algorithms, trying and usually outperforming the standard methods.
These moments are a lot of fun. I particularly liked when I wrote a sophisticated C implementation of the popcount function. Clang recognised what the algorithm was doing and emitted a single `popcnt` instruction.
In general the need to remember to free a resource after using it is a burden the programmer should not have to shoulder, since it just leads to memory and resource leaks or use-after-free and double-free errors. That's why other languages have destructors, RAII and/or garbage collection.
If nothing else, in this way, C can help people appreciate what goes on behind the scenes.
Did you find the courses useful? I ask because the textbooks themselves did not get great reviews.
I read mostly first-principles books about OO, from authors such as Shlaer-Mellor, Booch, Leon Starr, and Lahman, and avoid the newer books addressing specific design architectures. My favourite is Object Lifecycles - Managing the World in States, by Shlaer-Mellor, followed by Model-Based Development, by Lahman. The first is quite dated, and the second is quite dense.
Yep, exactly.
Thank you for this comment
So question: Im a c# developer and the tedious stuff in dotnet is the absurd about of abstraction for abstractions sake where methods are 2 lines and have a call stack 150 layers deep. Really makes coding not fun. I love C and FORTRAN, but never thought about working with those languages. What are some of the mundane things that you encounter working in C?
I thought they were. Probably not useful enough to pay $5000 out of pocket. I think the key takeaways are the paradigms like MVC and others, the idea that you should lay out the system and its behaviors before you start coding, that you should design for scalability, etc. I don't have a full CS background, I'm an EE with two semesters of C++ programming that ended up doing embedded, so I thought it was useful to get an idea of some of the design characteristics. One impression that I got from the class was they think a system architecture was some beautiful, glorious crafted thing. They end all be all. That there should be many meetings to design and review the architecture and a dedicated architecture team and then external reviewers come in to review your architecture. I dunno. I think the key takeaways are the "-ilities:" quality attributes like scalability, modifiability, interoperabilty, reliability, etc. &amp;#x200B; Where are you in your career? If you're on the job, I'd try to get your employer to pay for a course. If you're in school and already took a software engineering course where you worked in a group to complete a large project, I'd say you're good for now.
Thanks, I'll at least take a look at those. I'm not looking for info on specific architectures anyway, so something that teaches me the principles is going to be more helpful anyway.
Thanks for your response. I have a degree in Business Information Management Systems, so I received formal training in software architecture. But, that was over 20 years ago now, and the industry has moved on. Thankfully, I have about as many years of experience to lean on, in addition to self-learning. Still, knowing that there are these courses available, I wondered whether they would be beneficial. The -ity are very important in an enterprise environment to meet customers' expectations. Recently, I had to fill in a questionnaire of over 150 points for a client to prove that we satisfy all of these -ity, including confidentiality, security, etc.
It has its challenges but it also has a relatively short spec compared too something like Python or C++. I'd say those languages are harder to master in the sense that they just offer more stuff.
Something wrong with the name?
I think it's a bit silly.
Most of the answers saying why C should be taught are only applicable to the language Dennis Ritchie invented, but are not applicable to the language that the authors of clang and gcc want to process.
It's not the language that's mundane, just the stuff you have to do. Implement a struct using precisely this defintion with these variables of these types. Create a function to do X, then do Y. and there's about 50 of these same format things you have to do.
Oh, I never thought C was mundane (might be why im getting downvoted). Like I said. I love the language. It's just as a dotnet developer, my type of mundane might be different than you guys. Ive never used C in a mature production environment. I see a lot of people talking about design documents and having to implement those strictly and thats something I've never had to do.
Alcohol. That or interns. If there's a LOT of REALLY mindless/repetitive typing it might be faster to write a code generator. Usually there's not too much of that once you're past the initial setup stages of a project... if there is then you should try to look for ways to reduce that going forwards.
Try it and see what happens :) ```#include &lt;stdio.h&gt; enum demo { FOO, BAR, BAZ, BOO, GOTCHA }; int main() { enum demo value; value = FOO; printf("Normal value: %d\n", value); value = 10; printf("Out of range: %d\n", value); }; ```
thanks! Looks like it works fine
The enumerated type is a char, signed or unsigned int. Depending on what your implementation chose it to be, you may or may not experience integer overflow, assigning an arbitrary value to it. The C standard does not list it as undefined behaviour by itself, so my interpretation is that the implementation have to emit a diagnostic in case it can detect an overflow, and in cases where it can't, it will summon the nasal demons over general overflow.
Up to a point, at least #include &lt;stdio.h&gt; typedef enum {THREE = 3, TWO, ONE, ZERO} invoff_t; int main(void) { invoff_t value = ZERO; printf("ZERO has the value %d\n", value); value = 1; printf("Last assignment has the value %d\n", value); value &lt;&lt;= 8; printf("Last assignment has the value %d\n", value); value &lt;&lt;= 8; printf("Last assignment has the value %d\n", value); value &lt;&lt;= 8; printf("Last assignment has the value %d\n", value); value &lt;&lt;= 8; printf("Last assignment has the value %d\n", value); } Output: ZERO has the value 6 Last assignment has the value 1 Last assignment has the value 256 Last assignment has the value 65536 Last assignment has the value 16777216 Last assignment has the value 👃👿 In the end, undefined behavior, summoning a nasal demon.
Thank you, I knew I was missing something pretty basic and couldn't come up with it.
&gt; Header files allow you to define a stable API separate from the implementation, which is important especially for shared libraries. You can get the same effect by indicating in each module which functions it exports. &gt; The consequence is that although it is technically possible to build shared libraries with them, this is impractical due to the lack of header files -- which is why you usually have to resort to static linking with these languages. I see no problem with either building or using shared libraries in either [Rust](https://doc.rust-lang.org/reference/linkage.html) or [Go](https://stackoverflow.com/questions/1757090/shared-library-in-go#35060357). Could you elaborate on what the difficulty is?
\&gt; I'm kinda confused of how to use the write() function &amp;#x200B; Other answers have explained the fd numbers well, but to be crass, you shouldn't use write until you understand it well. Printf and fprintf are much more appropriate to use initially, especially when writing text messages. These two functions actually call write under the hood, but adds buffering if appropriate (depending for example on if they're writing to a terminal or not). Buffering is important, because write is a system call, which are slow and shouldn't be called until necessary. &amp;#x200B; Write is appropriate to call once you are done collecting data and just want to send it off, or when copying a large amount of data. You'll typically not use it without some kind of buffer you store the data in temporarily first. One of the reasons for that is that a short write might happen, which means write returns after writing some but not all of the data. If that happens you have to call it again to send off the rest of data, after adjusting the arguments to point to only the unsent part. &amp;#x200B; Tl;dr use (f)printf, not write.
Enumerated types get converted to either \`int\` or \`signed int\` prior to computation. If a 32-bit \`int\` has value 16777216, the Standard imposes no requirements upon the effects of shifting it left 8 bits, and thus no prohibition against nasal demons. An attempt to store the value 4294967296LL into a 32-bit signed integer would be required to either set the integer to an implementation-defined value or raise an implementation-defined signal; neither course of action would allow nasal demons.
discipline
&gt; Enumerated types get converted to either `int` or `signed int` prior to computation. You forgot char. Annex J.2 Undefined behaviour. Conversion to or from an integer type produces a value outside the range that can be represented (6.3.1.4). Assigning a value that cannot be be converted to the chosen enumeration type *is* undefined behaviour. If you don't want to get hung up on the semantics of shifting, multiply by 256UL in each step instead. You'll end up in the same place.
Can you provide the link?
Basically, you can do it, but the compiler doesn’t have to behave as if it’s possible for a variable of enumerated type to have any value/representation other than the explicitly enumerated ones. This can actually screw up error-checking if optimization’s enabled; e.g., enum letter {A, B, C, letter__MIN=A, letter__MAX=C}; enum {letter__COUNT=4}; int func(enum letter k) { if(k &lt; letter__MIN || k &gt; letter__MAX) { return -1; } // Surely it’s valid now! … return 0; } Here, the compiler is free to eliminate that `if` statement, because `k` “must” have a value in that range if it’s of that type. Instead, you have to do something like int func(int k) { if(k &lt; letter__MIN || k &gt; letter__MAX) { return -1; } // It is actually valid now. … return 0; }
Read K &amp; R C programming language.
the forsaken bible!
Post your actual question here, and I'm sure someone will take a whack at it.
Yeah I didn’t understand what they were asking. If they had a question in particular related to some code or if they’re asking somebody to spend time and give them a one on one lesson about c.
 #import "psychic.h" Can we get a hint?
I was in some thread the other day here where somebody said something to the effect of "Much of K&amp;R's book is now considered bad coding practice." That's when I knew that one could never be correct in this sub.
Section 6.3.1.4 describes some situations where conversions between *floating-point* values and integers can yield Undefined Behavior. Conversions among integer types are described in 6.3.1.3, which describes conversions between larger integer types and smaller ones.
Pics posted. I'm learning without any prior experience, and I'm just completely lost with this one.
I have used CMake before and I would say that yes it's true that Meson is easier. I would agree that Ninja is faster especially when I compared it with Make.
Good. I'm not sure what you're expecting me to name a team. But I have no regrets.
So as I understand it... s/he gives you the code and then wants you to take the steps s/he listed in making the changes?
First, never post screenshots. It's absolute hell to read. Second, no one is going to hold your hand. This is a subreddit to solicit help with YOUR assignments. This is not a tutoring survive or a school. We can help, but YOU must be the driving force in your learning. Read this: https://idownvotedbecau.se/noattempt/ Then start filling in the blanks with what you've done to get started.
Thanks cause I actually want to know and understand what I'm doing and learning, I just find it a bit difficult hear and there without any hands-on training. I'm a rookie at this.
&gt; Thanks cause I actually want to know and understand what I'm doing and learning, I just find it a bit difficult hear and there without any hands-on training. I'm a rookie at this. Great -- I apologize that this is going to sound harsh. You still haven't given us any information about what you're struggling with -- you just keep repeating that you're lost and that you're learning on your own without any prior experience, and frankly -- we really don't care about the backstory! If you want help, give us: * I'm starting by working on X, and here's my understanding of X * As I'm working on X, I'm having trouble with Y * I've tried A, B, and C to get over my trouble with Y, and here's the results Until you've done that, there's really nothing else to talk about.
&gt;The enumerated type is a char, signed or unsigned int. It can be any integer type (not `int` specifically as someone might read from your comment). &gt;Depending on what your implementation chose it to be, you may or may not experience integer overflow, assigning an arbitrary value to it. Assignments cannot overflow. "Overflow" means arithmetic producing a result out of range. An out-of-range assignment is implementation-defined, so the result cannot be an arbitrary value. The compiler's documentation must specify the behaviour. &gt;The C standard does not list it as undefined behaviour by itself, so my interpretation is that the implementation have to emit a diagnostic The standard explicitly says when diagnostics are required, and this is not one of those cases.
&gt; but the compiler doesn’t have to behave as if it’s possible for a variable of enumerated type to have any value/representation other than the explicitly enumerated ones This is wrong. A variable of `enum` type can hold any value of the underlying type. In your example the compiler cannot eliminate the `if` statement. A common example that takes advantage of this freedom is: typedef enum { FLAG_A = 0x1; FLAG_B = 0x2; } FLAGS; FLAGS flags = FLAG_A | FLAG_B; the result of the bitwise-or is not any of the enumerators and is outside the range spanned by them, but this code is correct.
The problem I'm having mainly is understanding what the code is supposed to accomplish once changes are made. I think knowing what I'm supposed to be trying to accomplish will help me make the necessary changes to the code.
This is no evidence of anything, as you cannot say whether the behaviour is well-defined, implementation-defined, or undefined, just by inspecting the output.
&gt; Conversion to or from an integer type produces a value outside the range that can be represented (6.3.1.4). That only refers to the source being a floating-point type. Annex J is non-normative, which means the text does not form part of the language specification. It refers to 6.3.1.4 which is a normative section and covers this case in more detail.
Some questions: When is the deadline for this? Have you had any prior experience programming in other languages? Have you tried any of the steps your professor listed?
This is a good way to have your code break on a different compiler. While that particular example will work on every compiler since the type of an enum must be at least a char, using other values may or may not work. The only assumption you can make is that the type of an enum is large enough to represent all its members.
It seems like you need to step back and first understand your problem. This has nothing to do with programming, but it will help you communicate with us. We can't help you if you can't even describe your problem. A few screenshots that seem out of order and missing information is not enough to go on here.
How do you know/set what type an enum is stored as in your particular project with whichever compiler you're using?
Sunday Night 11.59. Zero experience programming, I'm transitioning military and my rate has nothing to do with programming. I have attempted barley. Its just confusing cause Im not getting what the completed code is supposed to do.
I’m going to be completely honest. If you’ve had zero experience programming. All this will be very confusing to grasp. Your instructor mentions you can ask them questions if you have any. I’d recommend doing that. Apart from that, you’re going to have a long weekend regardless and have to read a good amount to understand what your professor is doing. Us explaining the topics to you will not really help your learning, these are topics that have to be learned by reading and testing out the code with small little programs. Like I said, be prepared to spend the whole weekend figuring this out. There’s no shortcut, you’re going to have to read and test what you read by writing small programs.
To print the address of `mem`, use `print_memory(&amp;mem, sizeof mem);`. it's not clear why you write `sizeof(&amp;n)` either since that is not really relevant to anything
I do not understand the problem. I don't like to have my hand to be held to get through things but I'm that's just where I feel I'm at with this course
You can't specify directly what type is used in C (though I think you can now in C++) and I would classify this as something you shouldn't rely on knowing. What are you really trying to do here? Assigning ints to enums and enums to ints both have gotchas that compilers often don't catch, or do catch and will cause headaches if you ever try to compile on another platform or compiler. enum demo e = 500; // What if it's a char type? int i = SOME_ENUM_CONST; // What if signed int isn't big enough? unsigned u = SOME_ENUM_CONST; // What if the const is negative? Here's how I would approach this: separate the two things you're trying to represent into two variables. Say you have a game where the state of an enemy is represented an enum, and if the enum is ESTATE_ALIVE then an additional hit point value is considered valid. enum enemy_state { ESTATE_ALIVE, ESTATE_DYING, ESTATE_DEAD, ESTATE_REVIVING }; struct enemy { enum enemy_state state; int hp; }; Here you have a state enum that's guaranteed to be able to hold all the ESTATE_ constants and if the state is ESTATE_ALIVE, then there's an additional hp variable to hold how many hit points the enemy has left. Nothing is left to implementation defined behaviors. If you really, really want to save a few bytes, you could probably do this, though. enum enemy_state { ESTATE_DYING = -1, ESTATE_DEAD = -2, ESTATE_REVIVING = -3 }; struct enemy { int state; }; This way if state is &gt;= 0, it should be interpreted as a hit point value, but if it's negative then it should be interpreted as a state. You know this will work because you explicitly define all the state values, that they're all negative and that int is signed. I wouldn't do this, though. It's just less clear what's going on and those 4 or 8 bytes saved probably don't matter. Whatever you do, don't rely on assumptions like "well, it works on my compiler." If you're unsure, don't try to force it. It's a really good way to shoot yourself in the foot later on. We all run into these, and we all end up relying on compiler specific behavior because we simply don't know the language backwards and inside out, but it's best to get in front of these if you can.
The content to learn from is literally screen shots of adding/searching arrays, find length of strings and convert strings to lower or upper case. Anything you advise reading?
Sure you can build shared libraries in Go and Rust, but they are not useful because in order to use an already compiled library in these languages, you would either need their source code or redeclare everything when using them. With C you can 1. compile a shared library and install it along with it's header file 2. compile a program that uses the library, using only the already compiled library and it's header file, NOT the source of the library 3. update the installed library with a compatible version, without having to recompile the program that uses it. You can't do this in Rust or Go, because the compiler can't extract the API from the compiled library. Which is why the build tools and the whole ecosystems around these languages are based on static linking and dependencies being available as source code.
I’ve mentioned already the K&amp;R c programming book, this pdf can be found online through a quick google search. It is naive to think that the only content to learn from is these slides. All of this material can be learned through google. I’m sure you could google c tutorial and get results that would start running you through how to get a “hello world” program running. A buddy of mine jokes that he didn’t get a degree in cs, he got a degree in how to google, and that’s the reality of it, all this can be learned by looking on google.
&gt;Sure you can build shared libraries in Go and Rust, but they are not useful because in order to use an already compiled library in these languages, you would either need their source code or redeclare everything when using them. I see no indication that this is the case in the documentation. Perhaps you could point me towards where you are getting this information from?
It's simply not a feature, so there is nothing in the documentation about it. For Rust, see for example [this](https://www.reddit.com/r/rust/comments/abefuy/how_to_create_a_dynamic_rust_library_and_link_to/) or [this topic](https://www.reddit.com/r/rust/comments/bfbrev/what_is_the_issue_with_dynamic_libraries_in_rust/) related to the issue.
There's a lot of bad information in this thread. Thanks for making all the corrections!
According to 6.7.2.2, "The identifiers in an enumerator list are declared as constants that have type int and may appear wherever such are permitted." Although it may be useful for an implementation to allow enumeration values larger than `INT_MAX`, I don't see how such treatment would be consistent with the above text. Since the above isn't a constraint, I'm not quite sure how the Standard would handle situations where an `enum` would be given such a value. While the Standard would allow an `enum` to be stored using a larger type even if none of its tags were that big, it would seem a bit weird.
Thanks for the info. My situation is not complicated so I'm not too worried about it causing problems down the road. I'm working with a microcontroller - the sdk specifies an enum with 8 entries as possible values to write to a specific peripheral control register. The manual for the chip says that the register can take anything from 0-&gt;15 however. I just want to make sure I'm safe writing up to 15 to an enum type that only goes up to 7. None of the comments I've read here suggest that that simple case won't work. It's good to read all the other information about more complex situations though. I really don't want to change the sdk source code since that will make migrating to newer versions more difficult in the future.
The thought of demons flying out of someone's nose always makes me chuckle. It would honestly be so much better if [that guy](https://groups.google.com/d/msg/comp.std.c/ycpVKxTZkgw/Y4JUNt5em5sJ) used daemons instead though. What I don't understand is why they joke that the compiler should be as unforgiving as possible. I thought the C standard left things undefined so as not to impede performance. &gt;Who knows, the compiler writers might consider it to be an important language-extension to be able to summon nasal demons by taking the sizeof an incomplete type, or to be able to format a hard drive by simply running the C compiler on a program missing a colon I honestly wonder how you might debug something like that. One of the main reasons Java is so slow is that everything is so rigidly defined that it's hard to optimize the JVM to work well on varying hardware. As I understand it [they changed the specification to allow floating point calculations to deviate from the IEE 754 standard as long as the final result followed the standard.](https://softwareengineering.stackexchange.com/a/153847/313994)
I wasn't suggesting there be enumerators that are not `int`. The underlying type could be a larger type (although this is probably something that only the DS9000 would do, or a system with 64-bit word size that makes `int` 32-bit perhaps)
No one actually thinks the compiler should be deliberately unforgiving. The joke is just emphasizing that good programs must not depend on a particular compiler's fortuitous choice of how to deal with undefined behavior.
Hmm, well the second link says nothing about needing the source code, but after scrolling down most of the way through the first link it would seem you are right. This is not true for Go, though, as [it produces a header file automatically](http://snowsyn.net/2016/09/11/creating-shared-libraries-in-go/), the main disadvantage being that all functions have to effectively be in the C ABI (though the advantage is that it is easy for other languages to call them). If the headers produced by Go are the kind of thing you had in mind, then I agree with you, I just don't think that there is significant benefit to having headers be manually created or textually included anymore.
Well I said I knee it was a joke, but as noted further down forgetting a semicolon or colon may constitute undefined behavior which would be an accident rather than relying on the compiler's choice. &gt;I certainly hope that a compiler wouldn't format my hard drive if I accidentally left out a semicolon somewhere. and &gt;Who knows, the compiler writers might consider it to be an important language-extension to be able to summon nasal demons by taking the sizeof an incomplete type, or to be able to format a hard drive by simply running the C compiler on a program missing a colon (I can never remember the arguments to format programs, that actually sounds like a helpful thing to me... ;-). In the second to last comment someone said: &gt;Should violation of a constraint should completely prevent a program from being executed? Sounds good to me. Why even have a standard that allows programs to violate constraints and use undefined behavior if I'm encouraged to never use undefined behavior and violate constraints? I'd prefer not to do that, since it would make for better code, but why am I able to do it if everyone says I shouldn't?
So there is a different .c file for all the functions defined in the stdlib.h header file?
Do you have a question? If yes, what is it?
Basically, yeah.
**PROGRAM NOT WORKING**
You haven't allocated memory for \*ch `ch = malloc(sizeof(char)*20)`
POST NOT QUESTIONING.
Google pointer arithmetic, might want to rephrase questions better in the future ;)
Sorry I forgot to mention Why the 1st code not working
Can you explain in what way it doesn't work? “It doesn't work” is not an error description. I can't tell you what is wrong with it if I don't know what it's supposed to do.
In the first code you have declared a pointer to nothing and told gets to store a string into the nothing. I'm guessing this results in a segfault. In the second code you have declared a block of memory on the stack and told gets to store the string there. This is a correct way. If you want to use the first version you will need to malloc a block of memory on the heap for gets to store the string into.
It is not giving any output of printf
Thanks
Thanks
Now I understand memory should be dynamically allocated by malloc as explained by others.
Few things: 1. Define "not working" in posts like these so people can understand the actual problem 2. You should probably use fgets() whenever possible since it handles bounds checking on the buffer you give it 3. When you pass the char* to gets() that pointer isn't initialized, so gets() will try to write into whatever address that's pointing to... Your `char buf[20]` works because you're allocating 20 chars on the stack for your buffer and giving that to gets(). In the char* example you're not allocating any space. For that example to work you need a buffer allocated (on the stack or heap), then you would take a pointer to the buffer and pass it to gets(). And as a reminder: when an array like `char buf[20]` is passed to gets() it basically "decays" to a pointer type
How come C language was chosen for programming processors?
In the first one you don't want to allocate a buffer. What you should do is call getc in your loop to check one character at a time without using a memory buffer at all. https://en.cppreference.com/w/c/io/fgetc
I think there have been implementations which usefully allowed enumerators to be of larger types (especially when \`int\` was only 16 bits), and IMHO the authors of the Standard should have expressly stated that implementations must allow enumerators throughout the range \`INT\_MIN\`..\`INT\_MAX\`, but may allow larger values at their leisure, if they use a type that can hold them, along with allowing implementations to, again at their leisure, either be store with a consistent type or pick a type that can hold the appropriate range. This would have undermined one of the apparent (and IMHO unfortunate) goals of having the Standard unambiguously categorize programs as either being valid or invalid. As the Standard is written, however, it does not allow for enumeration values outside the range of \`int\`, which would suggest that while it might be useful to have an implementation use a e.g. \`char\` or \`short\` as a backing store, it would seem unlikely that using something bigger than \`int\` would be useful unless an implementation allows values that aren't representable as \`int\`, in which case the Standard would be irrelevant.
C was written to be usable on Programmable Data Processors (the marketing people at Digital Electronics Corporation weren't interested in "computers") which had severely limited amounts of memory. This meant that compilation needed to be subdivided into small steps that could be processed separately, and also imposed limits on the practical sizes of source files. Having a preprocessor that could take files that were individually small enough to fit in a text editor, and combine them into a file that need not be editable directly, was thus useful. In the C language that existed in 1974, according to the "1974 C Reference Manual" [easily retrievable via search engine], a compiler that was evaluating an expression and found an identifier followed by an open parentheses could assume it was a function call, and could process the function call itself without having to know anything about the function itself, but if function calls are used in contexts like `int x; x=foo()+bar();`, the types of `foo()` and `bar()` could affect the code the compiler would have to generate for the addition and the assignment. While it would have been possible to use include directives to simply concatenate multiple source files together into a single program (and indeed that's how multi-file projects were handled using the first three major versions of Borland's *very* popular Turbo Pascal compiler), such an approach requires that a compiler have enough memory to handle all of the global symbols used throughout an entire program. If a file defines a few functions that should be usable by code written in other files, having another file that contains only the information that would be necessary to process client code will make things more efficient than requiring that a compiler processing client code read and remember a lot of information that would be irrelevant for the client code. Header files in C strike an annoying balance between being inferior to many other approaches, but just good enough to discourage any effort to standardize anything better. On a system where compilers must be as small as possible, using the same code to process imported function declarations as would be used for forward declarations of functions within the same source file will generally require less RAM than code to process some other form of import specifications. Such trade-offs haven't really been relevant for many years, but header files because entrenched as a practice before RAM became cheap enough to make otherwise-better approaches practical.
Not mine. I deal with documentation and specs that contradict each other, or are incomplete ( some are simply referring to previous implementations of the same system ). So I have to write experiments into code to find out what it really does. This means there's a few prototypes that get reorganized into a proper code base at some point.
Any downvoters care to specify what they disagree with?
If it's sufficiently repetitive, write a code generator. Then you can concentrate on rules and not semicolons.
Thank you for the extended history! It is worth noting that C++20 features modules which removes the need for headers (though you do need to put the module interface in a separate file if there are mutual dependencies between two files) although of course it will take some time for everyone to migrate to using them.
I'm writing this while I'm deeply hoping you are using gcc to compile your code and not mingw, cygwin or msvc. 1. While compiling your code add debug flag gcc -g -ggdb source_file.c -o binary_file 2. Run your program with gdb gdb binary_file 3. Start the program with run command run If a segmentation fault occurs, the execution will stop and gdb will tell you where exactly the problem occured. Then you can look for the call stack with backtrace command bt full This will show you which functions were called along the way. You can put breakpoints to stop the execution and advance over the code line by line to see the behavior. breakpoint source_file.c:123 breakpoint some_function next print some_variable Hope this helps you in the future.
General Quicksort Algorithm: https://www.youtube.com/watch?v=Hoixgm4-P4M Annotated source code: https://code.woboq.org/userspace/glibc/stdlib/qsort.c.html
It casts the address behind a/b to an int *, and then uses the value behind that address. Then it subtracts b from a, and thus returns whether a is equal, lesser or greater than b.
&gt;Then it subtracts b from a, and thus returns whether a is equal, lesser or greater than b. So it returns either true or false based on whether the numbers are equal? How does that help though?
&gt;Then it subtracts b from a, and thus returns whether a is equal, lesser or greater than b. So it returns either true or false based on whether the numbers are equal? How does that help though?
The comparison function is what's known as a callback. It's called repeatedly by qsort to figure out the relative order between two elements of the array (then perform a swap or some other movement based on if they're out of order). I don't know the exact sorting algorithm that qsort uses, but that's not super important to you, as a caller, unless you're concerned with optimization. Anyway, what's happening in the comparison function that you have implemented is that, qsort assumes that that function will take two pointers, one to each element in the list that are currently being compared by qsort. Keeping that in mind, the function first casts them to int pointers, since your array is of ints. (This is important, you have to keep that consistent.) Note also that qsort can, in this way, sort any arbitrary data object, as long as you provide it with the correct method of comparison. The "return" line of the comparison function you have simply performs the subtraction. If a is greater than b, the result is positive. If a is equal, the result is 0. If a is lesser, the result is negative, and this return value indicates the relative order of the two elements to qsort so that it can do what it needs to do to perform the sort.
No, it returns -1 if a is lesser than b, 0 if they are equal and +1 if a is greater than b.
QSort can sort any values, but you need to tell it how to compare one value with another. In this case cmpfunc tells it how to compare integers. If in stead of integers you had strings, should they be sorted by length? or by lexicographical/alphabetical order? Both would be valid ways of sorting. That is why you have to give it a function that tells it how to compare two strings in this case.
Note that the C standard does not require QSort to implement Quicksort, but the Unix C library uses a variant of Quicksort.
Indeed, good point...
Uuuh ... qsort is quicksort. Unless the to be sorted partition is smaller than 4 entries. Then it uses iteration sort.
Such a philosophy is probably a result of someone being unable to recognize that "use of a nonportable or erroneous program construct or of erroneous data" describes not only situations in which code is erroneous, but also cases where correct code relies upon features which aren't common to all implementations but would be present on all targets of interest, or to situations where a program that would correctly process all correct data receives incorrect data. A fundamental problem with that philosophy is that the Standard makes no attempt to mandate everything an implementation must do to be suitable for any particular purpose. A language which mandated that all implementations support every action needed for some particular purpose would be unsupportable on any platform that couldn't handle all those actions, and a language that limited programmers to actions that all platforms could support would be unsuitable for any purposes requiring actions beyond those. C historically avoided those problems by serving as a "core" language which implementations intended for various purposes would extend in ways appropriate to those purposes. If one recognizes that the Standard makes no attempt to forbid implementations from behaving in obviously-stupid fashion, many contentious issues would largely evaporate. For example, many people try to read all sorts of wrinkles into the Standard to accommodate the fact that N1570 6.5p7 doesn't make any provision for accessing the stored value of a struct or union object using an lvalue of member type. No amount of twisting and tweaking, however, will allow those rules to accommodate all cases that should obviously be allowable, without blocking optimizations to accommodate cases that implementations shouldn't have to support, unless one recognizes a principle: compilers shouldn't have to magically know things they can't see, but shouldn't be blind to things they can. Given the structure definition and two assignment statements: struct s { int len; int *dat } x; ... x.len = 4; *x.dat = 4; The Standard wouldn't require that a compiler recognize the possibility of either of those affecting the stored value of `x`, since they both use lvalues of type `int` to access the stored value of a `struct s`. On the other hand, one construct contains some very strong hints that it might modify the stored value of `x`, while the latter really doesn't. Trying to specify when implementations should or should not be expected to recognize various kinds of hints would have complicated the Standard with corner cases that generally aren't relevant. They thought that the cases that would matter would be sufficiently obvious that they shouldn't need to spell them out, and never allowed for the possibility that some compiler writers might try to claim that there's no evidence that something like: void inc_float_exponent(float *x) { *(uint32_t*)x += 0x08000000; } might actually affect the stored value of a `float` [never mind the fact that the passed-in argument from which the `uint32_t*` is derived has type `float*`].
That makes sense with the name. Thanks.
Some popular Pascal dialects on the PC and Macintosh (and I think also the Apple II, though I've not used such features on that platform) avoided the need for separate headers by having "Units" start with an Interface section and later contain an Implementation section. The Interface section included function headers as well as definitions for variables and types that would be exported to other units and/or the main program.
Quicksort is: 1. Choose a pivot (usually the first item) 1. Partition the rest of the container into two containers: smaller than pivot, and greater than or equal to pivot 1. Call quicksort on the partitions (so, heirarchally recursive) 1. Return the result lists, pivot appended inbetween It's actually much easier to understand it in some other languages. I'll use `erlang` because that's fun quicksort( [] ) -&gt; []; % the quicksort of an empty list is an empty list quicksort( [Head | Remainder] ) -&gt; LessThanHead = fun(Item) -&gt; Head &lt; Item end, { LessThan, GreaterThanOrEq } = lists:partition(Remainder, LessThanHead), quicksort(LessThan) ++ [Head] ++ quicksort(GreaterThanOrEq).
But how is it comparing two values by subtracting them? &gt;If instead of integers you had strings, should they be sorted by length? or by lexicographical/alphabetical order? Both would be valid ways of sorting. not sure about it. How would you sort by length if it were a string?
&gt;han b, the result is positive. If a is equal, the result is 0. If a is lesser, the result is negative, and thanks for the detailed response. I didn't look into how qsort is actually being implemented but I was mainly concerned about why subtraction of the dereferenced pointers was returned but I guess after reading your response it's probably used by the qsort for sorting the elements accordingly.
Triple backtick syntax doesn't work correctly on this site. Your code comes out all garbled.
The others comments are right. What you're missing here is the memory allocation to copy those strings, because strcpy expect to receive a pointer to a buffer with enough space to store the string. But in my opinion, allocating is not the simplest nor the best answer. In this case the strings are already in memory, as strings literals, I'm not sure you need a new copy of them. So you can simply write this : ```C void test () { Pair list[3]; list[0].first = "first pair first"; list[0].snd = "first pair second"; list[1].first = "second pair first"; list[1].snd = "second pair second"; list[2].first = "third pair first"; list[2].snd = "third pair second"; for (int i = 0; i &lt; 3; i++){ printf("First is: %s. Second is: %s.\n", list[i].first, list[i].snd); } } ```
The standard doesn't mandate it use the quicksort algorithm underneath or any time/space complexity requirements. It can be bogosort for all we care.
Note that this is technically not the "true" quicksort algorithm. Quicksort is defined as being an _in-place_ sort, and this is not an in-place sort.
Oh, it seems fine on my side, I'm using Chrome. Which syntax should I use instead?
There's a folk dance video that I think gets across the concept really well. [https://www.youtube.com/watch?v=ywWBy6J5gz8](https://www.youtube.com/watch?v=ywWBy6J5gz8)
You would implement a comparator that calculated the lengths of the strings and compares them I.e int cmpfunc (const void * a, const void * b) { return ( strlen((char*)a) - strlen((char*)b)); }
Oh hey, that works! Thanks for the cooperation.
&gt; Here is how I would write it: Am I missing something? You assume that `x0` to `x3` are preserved across function calls. This cannot be assumed, so the compiler used some callee-saved registers instead. This of course requires the compiler to save the previous contents of these registers on the stack, which is what you see.
From what I can see, only x0 and x1 and modified by the function, and the compiler should also be able to see that, this is not an extern function declared somewhere else, the compiler should know everything about it. If I'm not mistaken, x2 to x15 can be used without a need to save/restore them. I've already tried the same code with 4 members vectors, it does not seem to change a lot, but I'll try again and check the output on different compilers. I'll try the alignas directive to see if it has any effects. &amp;#x200B; Is this C++ code? Which part? I think this code can be read as C code. And I posted here because I think C tend to be viewed as lower level and closer to the metal, so people here might be more inclined to reply.
The comparator is called a "three way comparison", it accepts 2 elements (by reference) and reports whether a&lt;b, a=b, or a&gt;b , implemented as the sign of the return value. The sort algorithm uses the results of comparisons between the elements to perform the sort. Some sort algorithms (not in the C standard library) use two-way comparison instead, the comparator returns boolean for a&lt;b or a&gt;=b. The two techniques are equivalent in capability because calling a two-way comparator twice with the arguments flipped will give you thw same information as the three-way comparator. If you study sorting algorithms in more detail you will look at how this choice between two methods affects the speed of the sort, and so on.
&gt; From what I can see, only x0 and x1 and modified by the function, and the compiler should also be able to see that, this is not an extern function declared somewhere else, the compiler should know everything about it. Your function is external (as you have not declared it to be static) and is subject to symbol interposition, i.e. the compiler cannot assume that the same function it emits is what is actually called at runtime. Thus it cannot make this assumption. It could make the assumption if you were to mark the function as static, but even then it likely does not. &gt; If I'm not mistaken, x2 to x15 can be used without a need to save/restore them. Yes. But that also applies to any function called, so the compiler cannot safely assume that the value is preserved after calling `Add16Vectors`. &gt; I've already tried the same code with 4 members vectors, it does not seem to change a lot, but I'll try again and check the output on different compilers. With a good compiler and a simple situation, there should indeed be little change. However, in complex situations, the compiler tends to generate better code if the structure size directly corresponds to vector size (or half or a quarter of a vector). &gt; Is this C++ code? Which part? I think this code can be read as C code. The disassembly is a dead giveaway as it exposes that all your functions are being demangled by the disassembler. Also, your use of `__restrict` indicates that you do not program in C or at least not standard C; the keyword is spelled `restrict` in C and is something that does not exist in C++. Some compilers support it as an extension with varying syntax. While C and C++ look very similar, they are neverthless distinct languages and idiomatic code looks very different in the too. If you take advice that is good for C when optimising C++ code, it is often not the best advice you can get for C++ code (and vice versa). I am not interested in taking this into account when writing answers. The `alignas` syntax I mentioned before does not exist in C++, so my suggestion is wrong for C++ code. &gt; And I posted here because I think C tend to be viewed as lower level and closer to the metal, so people here might be more inclined to reply. That is a wrong perspective and by pretending you program in C when you are actually writing C++ code, you are making this a very frustrating experience both for you and for everybody trying to help you. Don't do this. Ask C++ questions in a C++ forum.
Found the compiler writer.
What auxiliary information is it using that makes this not a quicksort? https://en.wikipedia.org/wiki/In-place_algorithm
&gt; fun For whom? def quicksort(array): less = [] equal = [] greater = [] if len(array) &gt; 1: pivot = array[0] for x in array: if x &lt; pivot: less.append(x) elif x == pivot: equal.append(x) elif x &gt; pivot: greater.append(x) return sort(less)+equal+sort(greater) else: return array
I use [godbolt.org](https://godbolt.org) to test different compilers. Of course I could add some flags so it compiles C11 or C99 instead of C++, but the result would be the same. I mostly use C inside a C++ environment for practical reasons, I'm not pedantic about the slight keywords differences here and there, they are mostly historical artifacts and IMO C++ can be viewed and used as superset of C, when removing the OOP constructs they are pretty much the same. &amp;#x200B; I tried various things, adding a dummy member to the structure and forcing the alignment to 16bytes, it made the resulting code worse for all compilers, for reasons I do not understand. &amp;#x200B; So far my conclusion is that Clang seems to be the only compiler capable of producing reasonable SIMD code for a simple example like this one. I can live with that. But I still do not understand why the x64 code needs about twice as many instructions that the aarch64 counterpart, I know there are less registers but this is not x86...
`LessThan` and `GreaterOrEqual` contain, between them, a copy of all elements of the original input. Moreover, this is repeated at each level of the revision. At the deepest level of this revision some elements have been copied many times over. I invite you to read [Hoare's original paper](https://academic.oup.com/comjnl/article/5/1/10/395338). The "quick" part of quicksort is a direct consequence of *not* exchanging elements that are already in their correct partition. Moreover, elements are not unnecessarily copied. To pull a quote from the conclusion: &gt; The data are sorted *in-situ*, and therefore the whole site may be filled with data to be sorted.
It’s whatever contents are in that memory location assigned to hold your int. At some point it will change I’ve that memory is used and freed. Good reason on why you should initialize your variables.
The first thing you need to do is go to the right sub. We only talk C here, not C++! /r/cpp_questions is best for asking questions about the language itself, /r/cpp is for more high-level language discussions (with active members from the ISO committee), and /r/cplusplus is somewhere inbetween. The second thing to know is that C++ is probably not what you learned in college ... it's even better. Most schools teach "C with classes" which is a major disservice to the language -- an outdated view of C++ from the beginning, made even worse by the "modern C++" style.
I didn't have a question. I just wanted to talk but okay.
&gt; I use godbolt.org to test different compilers. Of course I could add some flags so it compiles C11 or C99 instead of C++, but the result would be the same. Yeah, don't make that assumption. You'll be surprised. Keep C and C++ code strictly separate. &gt; I tried various things, adding a dummy member to the structure and forcing the alignment to 16bytes, it made the resulting code worse for all compilers, for reasons I do not understand. Did you also process that dummy member in the same way as all other members? &gt; But I still do not understand why the x64 code needs about twice as many instructions that the aarch64 counterpart, I know there are less registers but this is not x86... Basically, the x86-64 assembly generated (for some flags I tried, I can only guess what you tried) is not vectorised at all. I suspect the issue is that the total structure size is only 3 doubles, so the compiler doesn't consider putting one such structure into a vector. On ARM64 it can do due to how NEON works.
The value of an uninitialised variable is unspecified. You cannot make assumptions about what it is going to be.
So there's a number in that memory in that memory location, it's just changed when i assign a value?
This is also not a true quicksort, for the reasons I outlined in [this thread](https://www.reddit.com/r/C_Programming/comments/ccu895/-/etpk9sd).
Just a random number?
You're probably compiling in a debug environment where uninitialized variables are actually set to a common, easy to spot value like 0xCCCCCCCC so they can easily be identified in the debugger as bad values.
It looks like a number because your printing it that way. It could represent literally anything. When the compiler allocates the memory for your variables it does not zero out the allocated memory by default for performance reasons.
“random” as in “no assumptions can be made about what it is,” not as in “it's going to be a different number every time.” Also note that using the value of an uninitialised variable is undefined behaviour and must not be done in a correct program.
Although they share a letter, C is not C++, it's not even close!
It's actually indeterminate, not unspecified
Indeed! Thank you for correcting me.
There are more welcoming places for this, there are probably lots of discord chats and stuff. Try /r/learnprogramming.
You can do this because (in the general case), the language can't prevent you from doing it. And, for efficiency reasons, even when it can't it still won't. C takes a very simplistic view of arrays: when you pass one around, what you're really doing is just passing a pointer to the first element. All information about the array size is lost completely. Unfortunately, that also means the computer can't check to make sure you stay within the array bounds, unless you manually pass the array size information yourself and explicitly do the check. Even if the language did keep track of the array size (which other languages do), there's another problem: some additional code would need to be inserted whenever the array is accessed to make sure you're within bounds. There's a few problems with this. First is the question about what the computer should do when you're out of bounds. C doesn't have exceptions or other built-in error reporting mechanisms. Stopping the program sounds nice until we remember that C is used in embedded applications and hard real-time systems. There's also the problem that this involves adding extra checks, and some C programmers really don't like it when the compiler does that (especially with hard real-time systems). But possibly most importantly is efficiency. That extra check to make sure all array accesses are valid takes time, which can be a big problem in tight, performance-sensitive loops. Early compilers simply couldn't optimize out redundant checks, so it made sense to just not check at all, and just trust that the programmer knows what they're doing. That's what this really comes down to: C's core philosophy is to trust the programmer. So what happens when the programmer can't be trusted? What happens when you assign at index 17? Most likely the computer happily assigns to a value somewhere else in memory. Maybe it modifies some unused memory, maybe it modifies a useful variable that was meant to store something else. But this is undefined behavior, so even more strange things can happen once the optimizer steps in.
Can't you do everything exactly like you do in C in C++?
You can try seeing if adding const qualifiers helps the optimizer with hints (it might, it might not): vec3 AddVectors(const vec3 a, const vec3 b) { const vec3 x = { { a.x + b.x, a.y + b.y, a.z + b.z } }; return x; } void Add4Vectors(vec3 * const __restrict a, vec3 const * const __restrict b) { a[0] = AddVectors(a[0], b[0]); a[1] = AddVectors(a[1], b[1]); a[2] = AddVectors(a[2], b[2]); a[3] = AddVectors(a[3], b[3]); }
Almost, but not quite. C has some features that C++ doesn't, and there's some code that will compile in both but has different behavior. It's better to say that C and C++ share a common subset, and that subset encompasses most (but not all) of C.
Yup, I sometimes have had to use C++ compilers but I still "wrote C" so to speak. But C++ adds 10 trillion things to C that nobody around here likes :)
&gt;C has some features that C++ doesn't, and there's some code that will compile in both but has different behavior. I was completely unaware of this!
I don't think that's what a callback is. I think of a callback as a function that's registered with some runtime that is called after some event. this is just passing a (a) function to a (b) function to be called before the (b) function pops off the stack, which is superficially similar, but a callback to me is more specific. the search terms here are "functional programming", "map function", or "functions as parameters". not trying to confuse or argue but to clarify
I used to write separate asm code for critical functions, but I find this solution to not be very practical. The asm code has to be "ported" to various platforms and compilers, and all the hand optimized ARM code I wrote at the time is not mostly useless because 64-bits archs has superceded 32-bits, and I am not targeting the embedded world here, mostly gaming devices. &amp;#x200B; const does not help here as we clearly want to write the result!
I found a way to get better results on x64 with Clang. I cast the pointers to this structure, which is exactly the same in memory typedef struct { struct { float x1; float y1; float z1; float x2; }; struct { float y2; float z2; float x3; float y3; }; struct { float z3; float x4; float y4; float z4; }; } vec34b; // simple 3D vector void Add4Vectors(vec3* __restrict a, vec3* __restrict b) { vec34b* __restrict aa = (vec34b*)a; vec34b* __restrict bb = (vec34b*)b; aa-&gt;x1 += bb-&gt;x1; aa-&gt;x2 += bb-&gt;x2; aa-&gt;x3 += bb-&gt;x3; aa-&gt;x4 += bb-&gt;x4; aa-&gt;y1 += bb-&gt;y1; aa-&gt;y2 += bb-&gt;y2; aa-&gt;y3 += bb-&gt;y3; aa-&gt;y4 += bb-&gt;y4; aa-&gt;z1 += bb-&gt;z1; aa-&gt;z2 += bb-&gt;z2; aa-&gt;z3 += bb-&gt;z3; aa-&gt;z4 += bb-&gt;z4; } Here is the generated code before: Add4Vectors_old(vec3*, vec3*): # @Add4Vectors_old(vec3*, vec3*) movsd xmm0, qword ptr [rdi] # xmm0 = mem[0],zero movss xmm1, dword ptr [rdi + 8] # xmm1 = mem[0],zero,zero,zero movsd xmm2, qword ptr [rsi] # xmm2 = mem[0],zero addps xmm2, xmm0 addss xmm1, dword ptr [rsi + 8] movlps qword ptr [rdi], xmm2 movss dword ptr [rdi + 8], xmm1 movsd xmm0, qword ptr [rdi + 12] # xmm0 = mem[0],zero movss xmm1, dword ptr [rdi + 20] # xmm1 = mem[0],zero,zero,zero movsd xmm2, qword ptr [rsi + 12] # xmm2 = mem[0],zero addps xmm2, xmm0 addss xmm1, dword ptr [rsi + 20] movlps qword ptr [rdi + 12], xmm2 movss dword ptr [rdi + 20], xmm1 movsd xmm0, qword ptr [rdi + 24] # xmm0 = mem[0],zero movss xmm1, dword ptr [rdi + 32] # xmm1 = mem[0],zero,zero,zero movsd xmm2, qword ptr [rsi + 24] # xmm2 = mem[0],zero addps xmm2, xmm0 addss xmm1, dword ptr [rsi + 32] movlps qword ptr [rdi + 24], xmm2 movss dword ptr [rdi + 32], xmm1 movsd xmm0, qword ptr [rdi + 36] # xmm0 = mem[0],zero movss xmm1, dword ptr [rdi + 44] # xmm1 = mem[0],zero,zero,zero movsd xmm2, qword ptr [rsi + 36] # xmm2 = mem[0],zero addps xmm2, xmm0 addss xmm1, dword ptr [rsi + 44] movlps qword ptr [rdi + 36], xmm2 movss dword ptr [rdi + 44], xmm1 ret And after: Add4Vectors(vec3*, vec3*): # @Add4Vectors(vec3*, vec3*) movups xmm0, xmmword ptr [rsi] movups xmm1, xmmword ptr [rdi] addps xmm1, xmm0 movups xmm0, xmmword ptr [rdi + 16] movups xmm2, xmmword ptr [rdi + 32] movups xmmword ptr [rdi], xmm1 movups xmm1, xmmword ptr [rsi + 16] addps xmm1, xmm0 movups xmmword ptr [rdi + 16], xmm1 movups xmm0, xmmword ptr [rsi + 32] addps xmm0, xmm2 movups xmmword ptr [rdi + 32], xmm0 ret For aarch64 the results is still exactly the same as before: Add4Vectors(vec3*, vec3*): // @Add4Vectors(vec3*, vec3*) ldp q0, q1, [x1] ldp q2, q3, [x0] ldr q4, [x1, #32] ldr q5, [x0, #32] fadd v0.4s, v0.4s, v2.4s fadd v1.4s, v1.4s, v3.4s fadd v2.4s, v4.4s, v5.4s stp q0, q1, [x0] str q2, [x0, #32] ret
And you missed the point entirely... Good job! Find some C++ discord servers for chatting random C++ stuff.
Can you tell me where you got the idea that in order to be true Quicksort it must be in place?
That variable declaration is unlikely to cause a segfault for small values of `n`. For large enough values of `n`, you may overrun the stack which will cause all sorts of mayhem. But rather than review poorly indented code (sorry, but if you want someone to review your work, you'll get more interest if you make it readable), I'd suggest you investigate how to use a debugger, which will tell you the exact line of code and calling context where the fault occurs.
appending each node is going to cause extreme reallocation thrash if you're doing it that way, you might consider pre-allocating the new arrays to the maximum possible size. it's less time wasteful than all those reallocs
What is your question?
Yeah I still need to get into Python as well. C is what I learned to program with first, but the problem with C is that as powerful as it is, it also gives you lots of rope to hang yourself with. Then in terms of the job market, you've got to be a pretty good C programmer to get a job with it, but with Python there's a lot more "code monkey" type positions to fill. As much as I prefer C, I still focus on it as a hobby more than a career option. I'm just not that good a programmer to get a job as a software engineer designing the type of stuff they use C for.
when i run my code, a segmentation fault occurs, how can i fix that?
Using a debugger to find where the segfault happens would be a good first step.
Use "rb" then after reading into the buffer, `printf("%02x", buff[I])` in a loop iterating over the buffer. I also recommend reading the file with fread instead, fgets is meant for text-encoded files but if you want to print the bytes of the file fread sounds better suited to me.
Mostly... but then you're just writing C. Most "idiomatic" modern C++ code will have a very different flavor from C code - you should very rarely see a raw pointer or an explicit allocation/free in modern C++, for example.
I've never found it hard or time consuming to port asm code, it takes mere minutes to port a lengthy function since most platforms share the same style of instructions. And I have written a lot of ARM &amp; AVR bit-bangs for weird buses in my time. The most fun I've had bit-banging was taking [this guys work](https://wp.josh.com/2014/05/13/ws2812-neopixels-are-not-so-finicky-once-you-get-to-know-them/) and further improving it to the extremes to drive a 64-ring NeoPixel Ring (1,536 WS2812B LED) arcade gaming floor off a single 16MHz Arduino output pin. I ran multiple tests to find the best way to shape the wave far far far beyond what any datasheet said was possible. It also still runs at nearly 30FPS providing some pretty cool animations: https://i.imgur.com/JXxxO7R.jpg (all white test) https://i.imgur.com/BO5IGKR.gifv https://i.imgur.com/sSIEnnF.gifv
Don't you mean insertion sort?
Instead of using structs try just using an array and indexing it.
You're absolutely right and I didn't state or mean to imply otherwise.
If I'm interested in writing command-line applications, which would be better? C or C++? I've used both. I like C because the language is minimal and easy to read. I also like C++ because working with strings is much easier than C.
Try running this: #include &lt;stdio.h&gt; int main() { int numbers[5]; int more_numbers[12]; more_numbers[17] = 100; printf("%d", numbers[5]); } For me it prints 100.
To be fair, it's not a huge deal. Most of the differences aren't something you'd see in real-world code (for example, code that relies on `sizeof('a') == sizeof(int)` instead of `sizeof(char)`), or the C++ compiler will allow a C-only construct as an extension (e.g., variable length arrays), which is relatively easy to do since most C++ compilers have a C mode anyway.
C does whatever you tell it to, even if you tell it to do something stupid, so if you tell it to write 100 to a memory address you're not supposed to be writing to, but the process does not crash by chance/coincidence, then it'll "still run fine". &gt; The output is 100. Only by chance.
Absolutely pre-extend, and rename "sort(" to "quicksort(".
excellent. Thanks for your help.
Why would you use strncpy? It looks like you're just taking the whole string, not a subset. so why not just copy the pointer address to the struct?
Why is `x-x` indeterminate? Unless you are running multiple threads where race conditions can occur, algebraically `x-x = 0` no matter what `x` is.
Because the result of `indeterminate - indeterminate` is `indeterminate` . [Further discussion here](https://stackoverflow.com/questions/25074180/) and [here](https://stackoverflow.com/questions/11962457/why-is-using-an-uninitialized-variable-undefined-behavior) with citations
in.txt or input.txt ?
`__restrict` can be used for header files to be included from both languages ; if the compiler supports it for C++ then it will support it for C too
This causes undefined behaviour (strict aliasing violation) so use at your own risk
I have a related question about Qsort: How does Qsort access the function pointer's arguments? qsort is defined as `void qsort(void *base, size_t nel, size_t width, int (*compar)(const void *, const void *));` When it calls `compar` how does it access the unnamed parameters `const void *`?
Yes to your second question. When you assign a value to a variable, you are actually storing that value in the memory location represented by your variable and the size of the memory location (number of bytes) dictates how much you can store and is defined by the type of variables (int, char, short, struct, etc). the size of int in your case is defined by the system architecture, usually 32 or 64 bits -1 for the sign.
A real life example is musl using smoothsort, which is a variant of heapsort. [https://www.etalabs.net/compare_libcs.html](https://www.etalabs.net/compare_libcs.html)
It casts them.
It’s the number/value left over a previous operation/program in the memory location you’re accessing. It’s something I like to call a garbage value since it has no real meaning to your current program.
But how? there's no variable name to reference the parameter, are they using some macro magic to get the position of the argument from the stack or something?
You're confusing a few different things here. Take these two functions: int foo(const void *x, const void *y) { /* ... */ } int bar(const void *a, const void *b) { /* ... */ } Both of these functions have the same _type_. They have the same number of parameters, the parameters have the same types, and they have the same return type. Yet the names of these functions and the names of these parameters are different. So the type of a function is quite distinct from how that function is defined. This shouldn't be too surprising, it's no different from home: int x; int y; are two variables with different names but the same type. Getting back to `qsort`, your prototype has: void qsort(..., int (*compar)(const void *, const void *)); That `compar` parameter has the same type as would a pointer to these `foo` or `bar` functions would have. That is, you could use `&amp;foo` or `&amp;bar` in a call to `qsort` for that parameter. (As a convenience, C allows you to omit the `&amp;` in this scenario.) The `qsort` function doesn't need to know what the names of those two parameters are, because it never actually uses those parameters. Somewhere inside the `qsort` code there will be a call that looks like: result = (*compar)(a, b); for two expressions `a` and `b`, but what the parameters are actually named in the comparison function is completely irrelevant. In a function call, the _caller_ doesn't care what the function's parameters are named. Again, this should not be surprising: when you call `qsort` your code doesn't care whether `qsort` uses `base`, `nel`, `width` and `compar` for those arguments.
Check that you actually succeed in opening the files before reading/writing.
Accessing beyond the end of an array is undefined behaviour. Undefined behaviour means that the compiler has license to make the code do anything; it could do exactly what you expect it to do (as it does here) or it could blow up your computer. There are no guarantees.
Try godbolt.org to see what the compiler is doing. It is most likely reading off from the stack. So whatever is in the stack will be read.
Oh, so what you're saying is that basically the compar function is called, and the arguments are supplied to that function from wherever the original call is actually made, so the declaration it's self doesn't need to know it?
No, it returns a negative number, 0, or a positive number. This tells qsort where these numbers are in the array/list relative to each other. This is how qsort works. This function is called over and over until the list (of ints in this case as seen by the cast from void) is sorted.
try printing a newline character at the end. stdio is buffered and only flushes at new lines or when the buffer is full.
&gt; Oh, so what you're saying is that basically the compar function is called, and the arguments are supplied to that function from wherever the original call is actually made, so the declaration it's self doesn't need to know it? Actually, what I'm saying is more fundamental than that. Take the `cmpfunc` that the OP gave us: int cmpfunc (const void * a, const void * b) { return ( *(int*)a - *(int*)b ); } The _only_ thing that needs to know the names of these parameters, `a` and `b`, is the body of this function. Nothing else in the program needs to know them.
cuz 'd' has a lower ascii value than 'D'. You basically underflowed.
ASCII value of 'd' is 100 and 'D' is 68
dang, you are right. My bad, I though it was the other way around
The string `"d"` may be stored in read-only memory, and attempting to alter its contents can yield undefined behaviour.
Undefined behaviour. `p` is pointing to a string literal, which is illegal. There is no correct behaviour for this program.
Use an array or malloc
&gt; But how is it comparing two values by subtracting them? Why not? How does `&lt;` work anyway? If you have two variables, `x` and `y`, if `x - y ` is negative, that means that `x &lt; y`, right? If the difference is `0`, they are equal, and if the difference i s positive, `x &gt; y`. `qsort` uses the same logic to check how any two pairs of values are ordered by using the return value of `cmpfunc` invoked on two items at a time. You can see it better in the actual source code for `qsort.c`: 138 do 139 { 140 while ((*cmp) ((void *) left_ptr, (void *) mid, arg) &lt; 0) 141 left_ptr += size; 142 143 while ((*cmp) ((void *) mid, (void *) right_ptr, arg) &lt; 0) 144 right_ptr -= size; 145 146 if (left_ptr &lt; right_ptr) 147 { 148 SWAP (left_ptr, right_ptr, size); 149 if (mid == left_ptr) 150 mid = right_ptr; 151 else if (mid == right_ptr) 152 mid = left_ptr; 153 left_ptr += size; 154 right_ptr -= size; 155 } 156 else if (left_ptr == right_ptr) 157 { 158 left_ptr += size; 159 right_ptr -= size; 160 break; 161 } 162 } 163 while (left_ptr &lt;= right_ptr); (source: https://sourceware.org/git/?p=glibc.git;a=blob;f=stdlib/qsort.c;h=17c42b3112710cc928cc232667586baee2cd7577;hb=HEAD) Does it make sense now?
I get where your confusion stems from. The key to remember is this - the actual function where the function pointer is passed **must** have a way of passing the correct parameters to the function pointer, not the function pointer itself. For instance, in this case, look at the first few parameters of the `qsort` function - `void *base, size_t nel, size_t width ...`. So you have a pointer, the number of elements, and the width of each element, right? So the `qsort` function itself loops through the array, passing in the two required parameters to `cmpfunc` in each iteration, and uses the results to *sort* the array. Suppose the function was called `print_the_smaller_element` instead of `qsort`, you would still have the logic to print the smaller element defined in `print_the_smaller_element` itself, and it would be the responsibility of this function to pass the correct parameters to `cmpfunc` in each iteration. Make sense? Think of function pointers as pure behaviour getting its required data from the function to which this function pointer is passed.
If you want to do it that way, I think the best approach would be ``` #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main( ) { char * p = (char*)malloc(1*sizeof(char)); *p = 'd'; if(*p &gt;= 'a' &amp;&amp; *p &lt;= 'z') *p = *p - 32; printf("%c",*p); free(p); return 0; } ``` The missing output in your code is caused by a segmentation fault. It just isn't shown in the IDE you are using. It happens because when you go for *p="d", you are actually pointing to the string's base address, but that address wasn't allocated, so when you try to access its content a segmentation fault happens.
Sorry for this stupid formatting, I just am not able to format code blocks properly on reddit.
Honestly, this issue is a little annoying. C99 has defined the *restrict* (not *__restrict*) leywors, though some compilers cannot recognize restrict but __restrict.
No dynamic allocation necessary. Just assign the string as char p[] = "d"; and you'll get a mutable string.
Because it's more portable than assembly, but still low-level enough to provide very tight control of the system.
Throw the pointer in the trash, you don't need it. Just use an array.
Why do you need dynamic allocation. *Insert huge knife cutting bread meme
How does this guarantee a mutable string?
 char s[] = "d"; is a stack based allocation. AFAIK if you use /u/noobProgrammer5861 's version, you're still gracing UB because there is no null terminator on the malloc'd string. Using the stack based allocation accounts for it.
I would say to avoid the lesson in `malloc` just yet, and just allocate space on the stack: char p[] = "d";
The null terminator would not be needed as the string is not being interpreted as a null-terminated string literal. It is simply a pointer to char and being accessed as such. As soon as printf("%s") or a str* function appears, then sure, the null terminator would be needed.
Yes, so when you use malloc solution you need two characters, because printf might break.
You actually dont have to cast return value of malloc, void pointer gets safely promoted to other types.
Wow thank you for the thorough response. I'm learning more and more that with C you gotta do everything yourself.
Thanks for the response. So a lot of it is up to me to make it work.
Thanks. I'm assuming that since this is a simple example, the computer probably won't crash, but it's bad practice for more complex programs.
That's odd, why does it do that?
It doesn't if the layout of the structure is compatible. The type of the structure members is `double` and you access them through a pointer of type `double *`, so everything is fine.
Alright. Thanks for the help.
Thanks for the help guys
Makes sense, thanks
Will check it out, thanks.
I'm new to this so probably
That's makes sense thanks
Thanks
But note, though. It's still undefined behavior in C. But in practise, thats how it works.
I'll check out Godbolt
Yeah, I shouldn't do that kinda thing in practice
Because the compiler makes room for a total of 17 ints on stack (which is where these automatic variables are stored, typically), and uses the two variable names to know where they start. But they are contiguous, and so as you go outside the bounds of one, you start to access the inside of another (in principle, their order can be reversed, so I had to test which order gave this result). If you start to write past the boundaries of \*both\* these array variables, you will start to write the other information on the stack, such as the return address that is stored there to be used when the function completes (and must resume from after the place it was called). This is a typical "buffer overrun" error, and a common source of C security issues (historically).
Even if you don't know much assembly language, you can see the color highlights the two sections where there is a "rbp-12" memory access, meaning they access the same location. \*But\*, that is using two different array variables (in the C code). Because doesn't (as explained by 'boredcircuits') prevent array subscript overruns).
`~(y - 1)` effectively means converting TABCHAR_CELLS from 2's complement to regular representation. Maybe TABCHAR_CELLS can be negative? I have no idea what the rest accomplishes.
~ (8-1) == 0xfff8 x &amp; 0xfff8 would give you (x - (x%8)), so we += 8 so x is rounded up to be a multiple of 8.
If `y` is a power of 2, then `x &amp; ~(y - 1)` is `x` rounded down (towards &amp;minus;&amp;infty;) to the next multiple of `y`. To round up instead, you add `y - 1` before rounding down, giving you `x + y - 1 &amp; ~(y - 1)`. In your code, `ctl-&gt;maxlength + 1` is `x` and `TABCHAR_CELLS` is `y`.
&gt; Another way would be: X + (X &amp;7) I don't think that works. For example, suppose we have X set to 1. Then `X + (X &amp; 7)` yields 2 which is not a multiple of 8.
Thanks, now it makes sense. It's interesting that this is calculated in a way that will only work when \`TABCHAR\_CELLS\` happens to be a power of 2.
Thank you for correcting me. 👍
Hey, It works with tinfo now and it's a separate c file and h file too ! However I don't think I can remove any more of the macro without putting way too much time into this small project. Here's the link if you are interested : [https://github.com/0pb/macroColor/tree/function\_refactor](https://github.com/0pb/macroColor/tree/function_refactor)
Oh, oh, of course. s[] is on the stack, initialized from the constant. I hadn't had enough awake yet.
It's unfortunate that C and C++ have taken such divergent paths, since there was a need in 1986 for a language that was usable as C but added a few features (which is why C++ was invented in the first place) and that need really hasn't gone away. Although there were even then some aspects of C++ which represent fundamental departures from C philosophy (e.g. the notion that a struct's storage would be something other than a concatenation of its members with whatever padding would be needed to align them), there are many features in C++ which could be useful in C save only for chicken-and-egg issues.
The entire point of the exercise is to actually gain some understanding and do it without printf's help.
Then, convert the address to a uintptr_t and using shifting and masking to access the bytes. Accessing the bytes directly forces you to deal with [endianness](https://en.wikipedia.org/wiki/Endianness). This needlessly complicates the code. Unless, of course, the whole point of the exercise is to force you to deal with endianness.
Looks cool!
The Standard says nothing about the cases in which implementations must allow the stored value of a structure or union type to be accessed with an lvalue of a non-character member type. Instead, the authors expected that implementations would use the rules merely to identify cases in which lvalues with no apparent relationship must be presumed capable of aliasing. Given something like: struct s { int x; ...} sp1,sp2; int *ip; *sp1 = *sp2; ip = &amp;sp1-&gt;x; *ip = 2; *sp2 = *sp1; a compiler should recognize that the store to `*ip` must be sequenced before the following read of `*sp1`, but if it didn't keep track of how `*ip` was formed it might not realize the need to perform the store to `*ip` before reading `*sp1` *unless* it presumed that the access to `*sp1` or `*sp2` might interact with an access to an `int*` of unknown provenance. Note that such pessimistic behavior would not be needed in the reverse situation, since a compiler that isn't able to fully track everything done with `*ip` could handle the possibility that it will be used to access `*sp1` by performing the store to `*sp1` before it evaluates the address of `sp1-&gt;x`. A compiler that can track what is done to `*ip` in more detail should be allowed to defer the store to `*sp1` past the write to `*ip` and even past the store back to `*sp2`, if it ensures that `sp2-&gt;x` receives the proper value; requiring that the write to `sp1` occur before the write to `ip` would have prevented that. There are many ways by which compilers can handle constructs like the above, and what matters is not the specific means by which they do so, but rather that the overall behavior does so. The authors of the Standard thought that sufficiently obvious that it could go without saying, but obviously they were mistaken.
&gt; The Standard says nothing about the cases in which implementations must allow the stored value of a structure or union type to be accessed with an lvalue of a non-character member type. You don't access the structure object. You access the member object through a correctly typed pointer. I agree that the strict aliasing rule is violated if the structure is not in scope at the time it occurs.
Part of why I was doing this was to deal with Endianness. Not to deal with it as much as learn, and understand it. This is still something I wish to make work, just to further my own understanding, for another project I have laid out for myself.
Ok, then you have to determine the endianness and and loop over the bytes in the correct order. You want to print the bytes out starting with the most significant proceeding to the least significant. Your current code starts with the _last_ byte and loops backwards. This means it's assuming that last byte is _most_ significant. I.e. the first byte is the _least_ significant. I.e. you code assumes little endian. Are you, in fact, on a little endian machine? Nowadays, this isn't so likely. Assuming you've already sorted the issue of printing the contents of memory vs the address itself - what do you see when you compare your code vs the result of using printf with %p ? If the bytes are reversed, you're running on a big endian machine.
 INCLUDES_DIR = -I./includes
I never actually got around to finishing the simple code, as I'm balancing things like this alongside course work, but the Endianness seemed to be correct. The only real issue was that I was for some reason skipping the first byte, as well as the last. Odd little bugs, but I think I could get rid of them when I go back to the project.
I always heard the Redis is a good C project to check. I used it on a project of mine a year ago and it was great.
The Linux Kernel. Qemu. OpenSSL. Libssh Libssh2 They are quite different but I think they are all very good prijects to look at.
I guess people normally do use a power of two as their tab stop, e.g. 2, 4, 8. It seems to assume that the tab stop is always a power of two because it will be 99% of the time. Odd that they optimized their code based on that though.
Are you looking for huge projects, or personal projects?
https://github.com/wren-lang/wren
Do check out GTK(https://en.m.wikipedia.org/wiki/GTK), it's mainly implemented in C
Desktop link: https://en.wikipedia.org/wiki/GTK *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^268229. [^^Found ^^a ^^bug?](https://reddit.com/message/compose/?to=swim1929&amp;subject=Bug&amp;message=https://reddit.com/r/C_Programming/comments/cd8wib/what_are_some_of_the_best_open_source_c_projects/etsh2qz/)
You can use git bisect to find out which of your commits broke it.
&gt; It doesn't if the layout of the structure is compatible. The type of the structure members is double and you access them through a pointer of type double *, so everything is fine. The standard isn't clear, but many people , including the major compilers, take the view that `p-&gt;x`, i.e. `(*p).x`, accesses `*p` , not just the member.
* Reddis * OpenBSD * SQLite * Git
&gt; The standard isn't clear, but many people , including authors of multiple major compilers, take the view that p-&gt;x, i.e. (*p).x, accesses *p , not just the member. That is correct and if you were to cast a pointer to a double to a pointer to a structure whose first member is a double, that would be a violation. But we aren't doing that. Rather, we access `*p` where `p = &amp;q.x` for some structure `q`, i.e. we do it the other way round. Which is fine.
Any tool from GNU's coreutils.
If you want a debugger, use eclipse. If not then I just use sublime or atom
Notepad++ is perfectly fine. If you want the features of an IDE, perhaps try Visual Studio.
For C programming there are two options: 1) Vim: editor not an IDE. It's my choice. Vim has a lot of plugin for autocomplete and for customization. 2) CLion: one of the best IDE that I ever used. It's very easy to use, it is configurated perfectly since the first start. Seeking information about Vim you could discover Emacs, my advice is to avoid emacs because it's very complicated as editor.
I like VScode a lot
Per OPs title, vim. Once you learn it you can really fly.
&gt;Rather, we access *p where p = &amp;q.x for some structure q, i.e. we do it the other way round. Which is fine. The code was `aa-&gt;x1 += bb-&gt;x1` and other similar expressions, where the type of `(*aa)` and the type of the type of the actual object in memory are incompatible structs/unions, i.e. not allowed to alias.
Ah, that explains it! I thought you were answering to this comment: &gt; Instead of using structs try just using an array and indexing it. But I was mistaken. Thanks for clearing this up.
Isn't GNU's style generally regarded as ugly?
JetBrains IDEs are just so wonderfully good at what they do. They index the world, are generally context aware and just generally speed up coding.
Atom is a pretty good editor. I use it a lot and it has some predictive capabilities. Limited, but still there
Personally I don't think so. I learned a lot reading code from coreutils.
Visual Studio Code (*not* Visual Studio, which is a full IDE) works quite well, with C/C++ plugins. Try it out: https://code.visualstudio.com/ If you don't like telemetry, you can disable it by editing configuration file or just try VSCodium (https://github.com/VSCodium/vscodium), which is Visual Studio Code without Microsoft branding and with disabled all kinds of telemetry. Both are free to use.
I use emacs for everything. I assume there are probably code completion plugins available, but I hate the idea so I've never looked into it.
Linux's is regarded the same by some. You just get used to it.
Thanks for the responses! Ill definitely give them a try. Also, i am a relativity new programmer and i thought that IDE was just a fancy word for text editor. What is the difference? And what benefits do each provide?
Does it have a free version or just the paid one?
I have taken a liking to [4coder](http://4coder.net/). It's fairly new so a lot of features are missing out of the box but it works great for C-like languages and the creator is actively working on it with a lot of interesting stuff on the roadmap. It is highly customizable (with a customization layer in C/C++), lightweight and feels a lot more responsive than other editors in my opinion. The customizable version is not free, but there is a free demo available.
I use [Sublime Text](https://www.sublimetext.com) it should have everything you want.
IDE stands for Integrated Development Environment. This means it comes with a Editor, usually with code completion, syntax highlighting, formatting, syntax error checking etc... A compiler, usually with tools like Make etc.. And a debugger. All built into the tool.
Ditto. Emacs is potentially infinitely powerful, running its own domain specific extension language. Not for the faint hearted, but the nuclear option for those who care to wield such a thing.
&gt;For C programming there are two options ROFLMAO
Atom?
You can run the beta version for free. JetBrains also gives free or reduced cost licenses to a whole host of people, check their site for details
A note re: jumping into The Linux Kernel -- This is best tackled while simultaneously reading a book on the kernel like [Linux Kernel Development (3rd Edition) by Robert Love](https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468) and a book on general *nix fundamentals like [Advanced Programming in the Unix Environment by Stevens and Rago](https://www.amazon.com/Advanced-Programming-UNIX-Environment-3rd/dp/0321637739).
Seriously, who in their right mind would use something else then 0 for their "OK" (or whatever you call your STATUS_OK)? Only people I saw not wanting to have 0 as OK status were students who were just starting with programming. If a serious vendor shipped that enum in real API, then change your vendor. Whomever makes an API should always know there will be extensions. Heck, one changes error codes even while writing their own code (API), so it is just awkward not to have OK at zero and just increment error codes as new ones come up in design.
By looking at it - I find it weird that you specify $(INCLUDES_DIR) as pre-requisite for your rules. You’re telling make that ./includes must exist before creating that target, but make has no rule to create it. Most likely the directory does not exist? I generally don’t list include directories as pre-requisite. Individual files yes.
you should try out the IDE clion. It is free for students. I love it for C++, have little experience with it for C. [https://www.jetbrains.com/student/](https://www.jetbrains.com/student/)
you should try out the IDE clion. It is free for students. I love it for C++, have little experience with it for C. [https://www.jetbrains.com/student/](https://www.jetbrains.com/student/)
you should try out the IDE clion. It is free for students. I love it for C++, have little experience with it for C.
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for linux mac and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux mac and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux mac and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux mac and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux, mac, and other more difficult to use OS's
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux, Mac, and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
WTF, you need to read documentation in order to become a better dev and your makefile scream that you don’t. Push swap is a medium size project and your makefile is a mess. https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions My login if u want more info : nihuynh
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux, Mac, and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux, Mac, and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
I honestly find that most IDE's are bloated with simple options often difficult to dig out of their gui hierarchy If you're comfortable with Makefiles (and you can make them much simpler than some do!) then look for a text editor with just a little more.... I quite like geany, it gives intelliguess functionality ("predictive text") and also will list functions and variables in the side bar which can be very useful for rapid navigation of code. while it does have an integrated terminal I prefer to alt-tab to a separate terminal to maximize the size of the code window. available for Linux, Mac, and other more difficult to use OS's [https://www.geany.org/](https://www.geany.org/)
This. BTW y must be a power of 2 for it to work. But then again, in 2s complement (virtually always) the right part of the expression is overly complex. Just `-TABCHAR_CELLS` would suffice.
This. BTW y must be a power of 2 for it to work. But then again, in 2s complement (virtually always) the right part of the expression is overly complex. Just `-TABCHAR_CELLS` would suffice.
OpenSSL is known for being a shit codebase. Definitely not something a newbie should be reading to gain knowledge of any kind. Here's a single example of what I say https://github.com/libressl-portable/openbsd/commit/7b0fe3beb8f56250b618780bea72a94a15247b89
I use gedit
I'll just set my tabs to 3 and watch the world burn.
\`\`\` \#include&lt;stdio.h&gt; int main( ) { char p\[\] = "d"; if(\*p&gt;='a' &amp;&amp; \*p&lt;='z') \*p=\*p-32; printf("%c",\*p); return 0; }
Accordign to the docs I read SSL_CIPHER_description uses OPENSSL_malloc to allocate the buffer. That code is then using std free rather than OPENSSL_free. This seems unwise to me. I actually question why this person is replacing the fixed length buffer with the dynamic allocted buffer but thats just me.
It tends to be verbose, and its whitespace choices are a tad weird sometimes. But it tends to be very _clear_ code.
Something a little out of the ordinary: I was quite impressed with the Postfix source code.
I understand the aversion to paying for stuff “that you can do for free”. But nothing does for free what JetBrains IDEs do. I don’t have too much experience with other C IDEs beyond doing basic vim setup, but I can compare the Java side and IntelliJ makes eclipse look like a child’s plaything. Truly, with eclipse, I can fully understand why some people dump it and go back to the simple life. Eclipse likes to step on your toes and otherwise trip you up a lot. JetBrains IDEs are more like a **context aware** HUD that you can choose to participate in or not. Context is something that is sorely lacking or outright non existent with other competitors.
&gt;nothing does for free what JetBrains IDEs do. emacs will run around JetBrains and spit in its face.
If an access to a structure member didn't access the stored value of the parent structure, that would imply that given: &amp;#x200B; struct1 = struct2; struct1.someMemmber = someValue; struct2 = struct1; &amp;#x200B; the last assignment could be omitted because struct1 and struct2 would have the same value, but that's clearly ridiculous. The only reason I've seen for people to claim that an access to a structure member isn't \*also\* an access to the parent is because of a belief that the Standard was supposed to specify everything, rather than omitting things that would be difficult to specify, but where a bona fide effort to uphold the principle "Don't prevent the programmer from doing what needs to be done" would make it clear how things should work.
Yeah, but I’ll be done a years projects before you get emacs configured to do anything.
It is printf(“ %f \n”, x); . Also try using {} for the body of for.
thanks man, i'm always looking for stuff like this!!
This sub is for C, which is not the same as C++.
I'm on linux and i use vim with some plugins and when i feel the need for an IDE i use qtcreator.
I don't like IDE's because of the bloat that comes with them, but I can see the allure. The built in debug suite that comes with Visual Studio (last used it like 3 years ago I think) is really really nice. I work in vim combined with ctags, and I normally mix this with tmux. You can compile and do all that fun stuff in vim on it's own, but I like having tmux at the aid. I started tmux a while back so that I wouldn't lose ongoing work on machines I had to ssh into, but I've got used to building using in with multipane set ups.
Fat L
Doom source code. It is fantastically documented and well-written C code https://www.doomworld.com/idgames/idstuff/source/doomsrc
CPython implementation and git source code. Both on github btw
Did you say the same thing about your operating system?
Writing a web server is a good way to get into things like network programming, buffer management, and, if you write a classic server, process management. This project is less about advanced algorithms and more about interfacing with the OS, which is a lot of what C is used for outside of game programming.
I enjoyed going through [sds source code](https://github.com/antirez/sds) which is a library for "Simple Dynamic Strings" used in [Redis](https://github.com/antirez/redis). The code is short, self-contained, easy to follow, well commented and solves a problem easy to understand.
The lecture notes
Could you pls recommend one open source web server for me to learn?
https://github.com/LambdaSchool/C-Web-Server That's actually a sequence of assignments connected to a codebase which should give you a bit to chew on.
Thank you
You write c code. You'll never learn to read it if you dont write it
I've heard great things about [the sqlite source](https://www.sqlite.org/src/doc/trunk/README.md) -- especially their approach to testing.
I tried to compile this source code by using the MAKE command under WSL environment. But it told me this error. May I ask if you can successfully compile the code? ------------------------------------------------------------------- gcc -Wall -Wextra -c -o server.o server.c server.c: In function ‘send_response’: server.c:63:33: error: ‘response_length’ undeclared (first use in this function); did you mean ‘response’? int rv = send(fd, response, response_length, 0); ^~~~~~~~~~~~~~~ response
It's right under a comment block that says IMPLEMENT ME! Implement the part which goes there correctly and it'll compile. This is meant to be like schoolwork, not a finished system.
Try the quizzes out with actual code. If you want to see what happens, type it out and run it. That will give you the most accurate and correct answer. That will probably help you understand why it behaved the way it did, too.
Sorry, I did not pay attention to the details. I found another version which has been implemented: https://github.com/AmyShackles/Web-Server-in-C
According to the published Rationale for the C Standard: | Although it strove to give programmers the opportunity to write truly portable programs, the C89 Committee did not want to force programmers into writing portably, to preclude the use of C as a “high-level assembler”: the ability to write machine-specific code is one of the strengths of C. Further: | The goal is to give the programmer a fighting chance to make powerful C programs that are also highly portable, without seeming to demean perfectly useful C programs that happen not to be portable, thus the adverb strictly. In C89, the term "indeterminate value" was defined as being either an unspecified value or a trap representation, implying that it was equivalent to "unspecified value" for types where all bit patterns were equally valid. Recognizing a category of values with semantics are looser than "unspecified value" may be useful, but only if execution is guaranteed to either stay on the rails or trap in Implementation-Defined fashion. For example, given: struct string31 { char dat[32]; } x,y; void test(void) { struct string31 temp; temp.dat[0] = 'H'; temp.dat[1] = 'i'; temp.dat[2] = '!'; x=temp; y=temp; } if the last 253 bytes of `x` and `y` will never be observed, letting them retain whatever values they happened to hold before the function call would be more efficient than requiring that the programmer write code that would ensure that all 256 bytes of `x` and `y` are left with matching values. Saying that the only way for a programmer to keep the compiler on the rails is to write meaningless values to the last 253 bytes of `temp` prior to the assignment would result in less efficient code than simply treating `temp` as having an Unspecified value. If an implementation traps on accesses to uninitialized storage, the usefulness of such traps may be sufficient to justify the cost of manually writing all the storage, but requiring that storage be explicitly written with meaningless values merely to facilitate "optimization" would be counter-productive.
I suggest CLion. It's commercial software, but I think you can get it for free if you're a student. It's cross-platform, flexible, and its code analysis and refactoring features are second-to-none. Using it as an IDE will require some familiarity with the CMake build system, since its project awareness is built on top of it, but that's good to know anyway, and for simple projects it's trivial to set up. My only real knock on it is that the built-in debugging is just adequate. IMHO coding in "dumb" text editors is for old dudes and preening hipsters, not programmers looking to get work done quickly and well in 2019. Powerful tools make coding much more pleasant.
IMHO my code for `bfs` should be reasonable to study, if a bit large at this point. https://github.com/tavianator/bfs/blob/master/main.c
Try asking in a c++ community. Good luck!
Actually, the Standard says that given: struct s { double value; } *sp,*sp2; double *dp; double test1(void) { *dp = 1.0; return sp-&gt;x; } double test2(void) { sp-&gt;x = 1; return *dp; } a compiler that knows nothing about `*dp` nor `*sp` would need to allow for the possibility of aliasing in the first example, but need not do so for the second. This makes sense if one considers the fact that in cases where an operation done using a pointer to a structure member is followed by an operation involving the structure as a whole, the pointer or lvalue used for the latter will usually not be derived from the member pointer, but in cases where an operation involving the structure as a whole is followed by an access via member pointer, the member pointer would usually be derived from the structure. The authors of the Standard didn't expressly say that a compiler given something like: double test2(void) { sp-&gt;x = 1; dp = &amp;sp2-&gt;x; return *dp; } should recognize that an access to `*dp` is an access to `*sp2`, and thus potentially to `*sp`, but that's because they mistakenly thought such things were sufficiently obvious that they could safely go without saying.
I'm not very familiar with Rust, but I'm struggling to understand the relevance of this article to C. If you're using an uninitialized variable in a context where its contents matter... just don't.
What about in situations where the contents would affect the "short-term" behavior of a program, but where all bit patterns would yield equivalent long term behavior? For example, consider a data structure which needs to be able to determine if a particular 16-bit value has been stored into it, and which will need to be reset quickly. One approach would be to use an 8192-byte array of bits, with each bit mapping to a value 0-65535, but reinitializing that data structure would require clearing 8192 bytes of RAM. An alternative is to use two 65536-element arrays of `uint16_t` (called `value` and `location`) along with a `uint32_t count`, such that `count` holds the number of values that have been stored, `value[0..count-1]` hold the stored values, and for each `value[i]` in that range, `location[value[i]]==i`. For any value `x` which has been stored, `location[x]` will be less than `count`, and `value[location[x]]` will equal `x`. For any `x` which has not been stored, if reading `location[x]` yields a value `y` in the range 0..65535, then either `y &gt;= count` or `value[y] != x` will be true. If code reads `location[x]` into `y`, and the same value will be used in both of the above comparisons, it wouldn't matter if each attempt to read `location[x]` yielded a different unspecified value in the range 0..65535. Would you say that the value of `location[x]`, for an `x` which hasn't been stored, matters in the above algorithm, or that it doesn't matter?
ugh. I don't know why lecturers ask what happens when you use printf() with a missing parameter. It's much better to learn what the language does when using it how it is defined (which I do all the time) to be used rather than exploring undefined behavior (which I almost never come across). Sorry, if that doesn't really answer your question.
Not sure if this helps, but the two do generate different code. &amp;#x200B; \`\`\` float x = 0.4; //this converts a double 0.4 to a float implicitly float x= 0.4f; //this assigns a float to a float \`\`\`
Gnuplot doesn't do that.
Its better to split things into functions, yes. I store my game state in a struct, initiate it in the main function, and pass it as pointers to game function, first of which is `Game_run`, which runs the main loop. So the `main` function can look like: int main() { Game g; Game_init(&amp;g); Game_run(&amp;g); return 0; } I also split things into multiple files based on functionality. Idk what minesweeper is but for a minecraft clone, I had game.c, player.c, world.c, etc..
\&gt; Should all the game logic go inside main For anything not completely trivial, this is a bad approach. IME, it's a good idea to break your program down into loosely coupled modules made up of clearly delineated, reusable units of functionality. If your function is long and does a lot of unrelated stuff, it probably should refactored into multiple functions. A good rule of thumb is that the name of your function should be able to succinctly and clearly describe what it does. In C specifically, for a project of sufficient complexity, you should generally break up your program's submodules into their own c files, with headers associated with each module that expose as little as the users of that module need to know about it. Clearly separate procedures and program state ( for example, don't make functions do different things depending on the value of some static variable inside the function), and bundle related state together inside structs.
Python's source code. Almost as beautiful as Python itself :)
post to /r/cpp_questions this is for C, not C++.
&gt;idk what minesweeper is YOU TAKE THAT BACK.
What have you tried so far? Post your code. What are you struggling with specifically?
&gt; Can anyone help me with this? )': Yes.
BSD source is interesting: https://minnie.tuhs.org/cgi-bin/utree.pl
Have you tried Visual Studio Community? Sure, C support goes as far as the C++ demands, but within that set, IntelliSense works, and it's wonderful.
Doesn't really inspire me enough to switch from VSCommunity to it.
I get what you mean. However I also understand why he's doing that. Because you never know when and where yourself or a team mate might've missed out something somewhere and because the compiler rests the responsibility on you, it'll still compile fine and you'd have scour through the code to see what went wrong.
The quizzes are on paper and no access to laptop. And when I say quizzes they're more like tests. We don't know the questions beforehand.
Though I agree that that's the best way, but unfortunately I'm going through a crash course with math and c programming and there's no time for that :( currently there's lots of math concepts to learn and practice and there's just no time to experiment with c code.
Practice math problems by coding them in C
Intellisense is pretty good. I find that JetBrains stuff just flows more nicely as I type than visual studio does though. Command line editor completions used to all be laughable and more often than not just got in your way. I haven’t done much evaluation of them since language server picked up steam, I admit.
MSVC is very good... if you're developing on/for Windows. This is inherently very subjective, but I think CLion has an edge in user experience and useful code awareness, and it's more broadly useful for more kinds of work. On the other hand, MSVC's built-in debugging suite is more powerful.
I mean, you obviously won't be able to cheat, but doing all of the problems and seeing the output and understanding exactly why it happened is going to prepare you so much better than memorizing what exactly a printf is going to say. Actually interacting with code is how you develop an understanding, asking why is going to get you ready way better than flashcards or even worse, guessing
Can you please explain the differences between indeterminate and unspecified?
This discovery pleases me deeply. Thank you for posting this!
1. *indeterminate value* is a special state that does not correspond to any of the possible valid values. The representation of an indeterminate value may or may not be a trap representation. If we are talking about a variable holding an indeterminate value, then reading it (while also avoiding causing undefined behaviour) may give a different result each time. This last property is normally called "wobbly", although the standard doesn't use that term. 2. *unspecified value* is effectively defined by the standard as being an indeterminate value that doesn't have a trap representation, so both of these options are "wobbly", but each time you use an unspecified value it will behave like one of the valid values in the range for the type. 3. These cases are both different to the case of a valid value that results from unspecified behaviour, e.g. after `int x = rand() % 10;` then `x - x` is guaranteed to be `0`. The standard doesn't have particular terminology for this third case. ---- Now, the standard text on this whole topic is widely regarded as deficient. [DR 451](http://www.open-std.org/Jtc1/sc22/WG14/www/docs/dr_451.htm), which you should read, recommended changing the terminology like this: * *unspecified value* means a non-wobbly, non-trap value , e.g. my case 3. * *indeterminate value* should cover my cases 1 and 2, and the standard can say "this may not be a trap representation" when required. An example of all this is structure padding bytes; the standard says that they're *unspecified value* which means they may be wobbly but not traps according to the current wording. However DR 451 itself is not clear about whether the new suggestion "passing indeterminate values to library functions causes undefined behaviour" applies to structure padding. ---- If you're wondering about the rationale for having wobbly values of any sort, it means that memory usage can be optimized by doing something else in the space of a variable whose value is wobbly. E.g. if you have int A, B; /* code that uses A and doesn't write to B */ /* code that uses B and doesn't use A */ then the compiler can use the same memory location for both variables assuming you don't defeat this by checking the addresses of the variables. Also it means compilers can use structure padding to store short-lived variables.
Both C++ and German content are off topic. Perhaps try /r/de_edv for this sort of content. I know it's not optimal, but I don't think there is a better one for German Arduino content.
&gt; there's no time for that If you have no time to write C programs but enough time to post questions on reddit, you are allocating your time wrongly. Writing C code to experiment doesn't take long.
I've removed the duplicates of this comment you posted.
I prefer `~(y - 1)` to indicate that the intent is to generate a mask of the form `1..10..0`. This is less clear with a two's complement negation.
Learning to pass these quizzes is going to come down to knowledge of two things: 1. The behaviors of certain specific functions that are part of your curriculum (like `printf`) 2. Understanding of C syntax as-a-whole (ie. understanding the grammar of C) 3. Being able to mentally follow the execution of a program line-by-line, and work out what variables have what values, what statements evaluate to etc. Your (example) question sounds like an instance of #1 -- namely, what does the `printf` function do under XYZ circumstances. For this, you either need a bunch of practice, or you need to make flashcards, or whatever else you need to do to *internalize* the behavior of that function. The way to think about ALL functions that you learn about is in the following way: Every function -- and I do mean EVERY function... has 3 components to it: * Arguments - ie. what goes into it (and the restrictions surrounding what goes into it) * Return type (and what the return value means) * Side-effects (ie. what the internals of the function does, what it modifies, what logic it performs, what it reads/writes etc.) For example.... Arguments: the `printf` function takes at least 1 argument, the first of which must be a `char *` that we'll call the "format string", which has certain additional requirements. After that, it takes a variable number of arguments, which correspond to the number of %-tagged values in the format string. *If there are not enough variables to fill all identifiers, the behavior is undefined*. Return value: `printf` returns an `int` corresponding to the number of characters successfully written to `stdout`. On failure, it returns a negative number. Side-effects: The `printf` function writes the format string to `stdout`. If the format-string contains `%`-identifiers, it attempts to fill those identifiers with data from the subsequent arguments. So... don't think about functions as some magical words that are just *part* of the language -- they have rules that govern them, and they can be broken down and digested.... Re: #2 -- you will learn all of this through practice. Book-learning to study this stuff will likely take *way* more time than actually writing sample programs as practice. Re: #3 -- this comes naturally with time. Certain people are better than others. I've found that the best way to do this is to come up with a system that works for you -- for me, when I was first learning (and even today, for tougher blocks of code...) I diagram out what the memory (ie. stack, heap, static) sections look like with little boxes, and I write what values are assigned to each box, while I follow line-by-line with my pencil. For pointers, I draw arrows to the chunk of memory they refence. As variables get modified, I update the values in the boxes, or the arrows accordingly, and as they go out of scope or get freed, I cross them out. Honestly, though -- just write some damn code. A few hours here-and-there writing your own quick-and-dirty test programs goes MUCH MUCH farther than simply doing book-learning studying for a quiz.
&gt; I don't know why lecturers ask what happens when you use printf() with a missing parameter I'm guessing that the professor made a big deal of it one day, while talking about undefined behaviors.... These types of questions are often callbacks to what I call "red flag" parts of the lecture... Typically, while the professor is giving their lecture, they'll change their demeanor to point out something very specific -- as if it's a big deal. Usually, this isn't necessarily a *concept* per-se, but rather a specific example of a concept... Whenever a prof would do this, I'd tag the line in my class notes with `PROF_REDFLAG` then would grep for those lines while studying. Sure enough, most of those redflag concepts would pop up on the exams....
Get used to it -- that's 80% of programming.
Your lecturer is an asshole and a moron. The correct answer is that the behavior is \[undefined\]( [https://stackoverflow.com/questions/12660232/printf-insufficient-arguments](https://stackoverflow.com/questions/12660232/printf-insufficient-arguments)). The only way you'd have insight into this particular question is if you wrote a printf implementation or if you read the C standard. If it's in your lectures and you just missed it, then you know you messed up. But in that case, he is still incorrect for posing this question, if he is expecting a particular answer.
It's undefined behavior, so it'll most likely be different on most systems
It's funny you say that to shame OP but at the same time you don't realize that the output of his example is undefined behavior. You don't learn everything by just writing code, you need to read, too.
You write a lot but say little.
I mean... I'm not trying to say a fuck-tonne of super-insightful things about the language.... but rather I'm attempting to demystify functions (that we consider part of the language itself) by providing a framework for thinking about functions. It's not intended to be some massive insight -- it's a way of thinking about the language that *someone who hasn't worked with it* wouldn't immediately realize. Your response to the OP's question is very accurate *but entirely misses the point*. The question isn't "What does `printf` do when it doesn't get enough arguments?" -- the question is "How do I *learn* to do X". Anyways, if you don't have any other quippy one-liners about the content (or form) of my responses, I'd be quite content if we're done here, and you hurl your unsolicited negativity elsewhere.
Thank you friend 🥺 I found that going through the C online test from pskills.org is pretty good to see these outlier cases.
The source of simple tools like: chmod cat chroot cd ...
And it can be done without arrays , pointers or dynamic memory, too! But you need some kind of start. What's your input? What's your expected output?
The question is how to deal with quizzes written by idiots that test whether you wrote down everything they said instead of whether you understand the material. You are rude and patronizing to assume that he needs advice on learning C.
[/r/csharp](https://www.reddit.com/r/csharp/)
Cheers mate :)
I'm not shaming anyone. I'm just stating a fact. Taking the time to write code, play with it. Break it on purpose. Write all different kinds of code in a single language. Thatd the best way in learning how to read.
thanks I abandoned it in the end (assuming it wasn't posted) it kept saying there was a problem and hadn't seemed to post....
I love how you took the time to try to call me out when your answer is literally 'write c code to understand it'. Be a bit more respectful. We aren't all 'morons' and you aren't the minority because you struggle. News flash, we all have had our struggles. And we have all gotten the same answers from people in this post when we asked. And we took it and tried to be better. And it has made us better programmers. Sure you won't get the bedt advise sometimes but that doesn't make somebody a moron. Grow up and be more respectful
No, you just became more like them.
I see that went so great for you because you don't even notice that the question is completely inappropriate for a quiz.
How is it inappropriate to ask a C coding question on a quiz that is suppose to be on C code?
The question is ill formed because the C code in the question is ill formed. As in, it's not C. May as well be a question about how to bake blueberry muffins.
See now you're just being foolish. Nobody can write code perfectly on their first time and being able to debug your code is a skill you need to know. Saying this code is almost like asking how to bake muffins is so foolish. In that logic asking any debugging questions improper. Its a way of learning C and learning the improper outputs of C when you write code that won't act as you want it to. Learning the outputs and adapting your knowledge and training yourself on what to fix when you get these outputs is the goal of a question like this. Its perfectly reasonable
In practice, any compiler updated to a version since like 2000 will give you warnings for any and all undefined behavior when you compile with \`-Wall -Wextra -Werror -Wconversion\` (there are some more but this is a good start). And your code will have to pass automatic testing in whatever company you work at which will not pass code with warnings unless the guy reviewing your code decides that it shouldn't be written in a way that doesn't produce a warning.
The output of this example is irrelevant because it is not legal C and should not compile, but your compiler might allow it. If you use warnings like you should, the code should not compile.
So in your mind, teaching runtime errors isn't important? Teaching them how to spot bad code and predicting its outcome and debugging skills arent important? This is why you aren't a teacher.
It's not a run time error. It's not bad code. It's not code.
The a-star algorithm is way faster and easier to implement for a situation like this, and has guarantees. A deep q learning approach will not give you guarantees about the solvability, but a-star will.
What's a star algorithm?
[This](https://en.m.wikipedia.org/wiki/A*_search_algorithm)
http://bgrins.github.io/javascript-astar/demo/
C# is off topic in this subreddit. Please post C# questions to /r/learncsharp instead.
This is going to sound counter intuitive, but try understanding code without documentation. The Linux kernel is a good place to start: [https://github.com/torvalds/linux](https://github.com/torvalds/linux) ... somebody already suggested DOOM which is also a good project to learn from. In the real world many times you'll dive into undocumented code to learn how to use a certain library or piece of code.
I'm trying to find that example but wasn't succesful. What section is this in?
While that may be true for others it is not for me. I can not learn when I understand nothing of what I read.
The example wasn't in the Standard, but N1570 6.5p7 specifies what types of lvalue may be used to access an object of a given type, and it specifically provides for the access of a member-type lvalue by a containing object, but does not provide for an access of a containing object via member-type lvalue. From what I can tell, such a distinction makes perfect sense if and only if one regards as obvious the notion that if an lvalue would be usable to access an object, and a compiler can see that another lvalue is derived from it, it should treat an access through the second lvalue as an access through the first. The authors of C89, however, seem to have been averse to mentioning anything that wasn't a requirement, and trying to specify detailed rules for when compilers must "see" things would have been tricky. Among other things, the need to have compilers recognize various constructs would vary depending upon the kinds of optimizations they do as well as the range of tasks for which they are used. Personally, I think it would have been better to recognize that the purpose of all of these rules is fundamentally to decide whether any pair of accesses or addressing operations needs to be regarded as sequenced, and specify that compilers may at their leisure, for each pair of operations, select in Unspecified fashion from a number of reasonable ways of making such determination; a strictly conforming program would be required to avoid conflicting unsequenced operations for all allowable ways of making the sequencing determinations.
If you know the basics of C and understand pointers and the language in general it shouldn't be difficult. Initially it will be, but the more you practice the more you learn and the better you get. But I totally understand that people learn differently. Headfirst C is a great book if you're new to C.
No problem, I know they also released the tech engines sources for other doom versions as well (like doom 3) and quake, wolfenstein, and some other tools. I found them here: https://github.com/id-Software
I just reread your post, and with a grid that small.. and if you only care about solvability, a simple floodfill routine would be ~10 lines of code.
Anything important here? [https://docs.microsoft.com/en-us/windows/win32/api/winbase/ns-winbase-\_commtimeouts](https://docs.microsoft.com/en-us/windows/win32/api/winbase/ns-winbase-_commtimeouts)
Nice
That's not exactly C... Switch lights on and off in a loop (you will need either two I/O registers or an additional shifter). Attach interrupt handler to input (button), that for example sets a global variable telling how many lights should be blinking (i.e. what stage your prop is in). Debouncer may be required if you are not doing this in hardware.
Do you have cygwin installed
No, not that I know of at least. I went here [http://www.codeblocks.org/downloads/26](http://www.codeblocks.org/downloads/26) and on the row with "codeblocks-17.12mingw-setup.exe " clicked on [sourcefourge.net](https://sourcefourge.net). As far the book "c programming for absolute begginers greg perry" told me, you don't need to do anything else at all. There is no additional instructions on the download code blocks website also. Also, this comes with Mingw, I thought that means I don't need Cygwin. This is what I understand. But I'm a noob, so what's your opinion?
What compiler is configured? If you go to Settings &gt; Compiler , what do you see?
&gt; This may or may not be what you want. Given that the minimal checks in the fast implementation only detect certain specific errors, and that those errors (e.g., double free) tend not to cause additional problems, you may decide that a “no harm, no foul” approach is more appropriate (for example with production code where aborting with a core file is frowned upon ;-). Is this an April Fools post? The fact that a heap-free function is invoked on something other than a validly-allocated heap object implies either that the heap has become corrupt, the data structures which use the heap have become corrupt, or the code is just plain broken. Silently ignoring double frees might allow broken code to work on some single-threaded environments, but so would ignoring all calls to `free` entirely.While a core dump may not be the best way to forcibly shut down any and all code that might be trying to use a corrupt heap, I fail to see any situation where it wouldn't be less evil than blithely continuing to run under such cases. I would also tend to view the fact that the performance of malloc/free would materially affect a program's overall performance as a sign that it should probably use a heap manager whose design is better suited to its particular needs (e.g. one that uses a separate heap for each size of block) than the jack-of-all-trades-master-of-none malloc family of functions.
It says "GNU GCC compiler". I also, if it helps, remember choosing precisely that compiler, when I first started using this software 2 days ago (or in its installation , one of those 2)
Does that file exist in your toolchain installation?
I don't know, and I don't know how to know. The only thing i understand about what you mean is that toolchain means like a chain of compiler linker debugger, that i read on wikipedia today. I only clicked on install and hope it would work, there is no additional instructions. What you mean, can you explain?
This guys manages memory
as best as I can tell, it sounds like GDB is looking for a source for some startup code you don't have, or it doesn't have the right path to for whatever reason. Can you just set a breakpoint inside your program instead of stepping into it, so that GDB only breaks once it's in your code?
Actually, this will happily compile with any compiler of note (though it should be easy to catch if you have warnings enabled). I wouldn't say it's a good question but it's not an unreasonable question if the class has covered how arguments are passed and a little about how printf works.
I don't understand your solution. I have a suspicion that the only easy way to solve this problem is to find someone with the same problem that fixed it already. It's one of those bugs. &amp;#x200B; I will use Eclipse or something else that works for now, it's a huge shame, but I don't have enough skills to know what's going on, and I don't understand what your last paragraph means. Do you want me to do that every time I debug a program? I mean, I need to step into to debug. If not I need to set millions of breakpoints. I want to go step by step.
How are you starting your debug session? I've never used code::blocks so I have to speak in non-specific terms. Don't start your program by stepping into it, because I'm guessing it's stepping into some startup routine you don't have the source for. Put a break point in main() (in codeblocks, looks like you can right-click the line of code and add it) and "start" the debugging, instead of stepping in.
Well... let me tell you this in respect to that: I always include at least one breakpoint (red dot), right in main(). That part works really well. But then I step into a couple of lines, and then the bug happens. I think the best is if you don't even use this program, to not waste your time on this issue. I don't think you'll solve my problem, I thank you very much for trying thought!
Uh Linux is an awful place to start. I doubt someone 'just starting to dig deep' would yet have learned the concepts the linux kernel implements, let alone be able to really grok its implementation--which has a tonne of added complexity; partly because it needs to be robust; partly for speed; and partly because of technical debt.
i didn't manage to use MALLOC\_CHECK\_ in pure C on a Mojave OSX.
`printf` is (usually) done with buffered I/O (I *think* the buffering can be controlled). So, a couple of ideas off of the top of my head: * Often (IIRC), the buffer will be flushed when a newline is seen. So, try making sure there's a newline at the end of your string * You might have luck using unbuffered I/O. I forget what's available in Windows, but in the Linux-ish world, there are `open` and `write`
debugger ?
You should never compile without all warnings enabled.
You didn't say what O/S you're using, but "find" seems Unix-ey. You can put the "find" command in a pipe. See "man popen". Mind the pathing. Your shell will be smarter than the C compiler. If you're not queasy about using fgets(), it's reasonably safe to use for this purpose since you pretty much know the format of the output of find. Be sure to check the return from fgets(). If you are, then you have to use fread(), which is weird with a pipe because you can't use fseek/ftell to determine a buffer size to use. So just allocate a your-guess-as-what's-big-enough buffer, and use realloc() if you use it all. 1 megabyte isn't usually a problem these days. And if you use fread(), you still have to split the thing into lines of text.
Especially these days
Sorry, i'm on unix (mac os and ubuntu). I'll look more into popen (I looked quickly and test it. It seems to do what I want) and I don't have problem using fgets and it will be faster since find return each result by lines. Thanks for your answer! (would it be a problem if I still ask you question)?
&gt; Especially these days You mean a 1-meg buffer? Agreed.
Go ahead and ask.
I meant another day if it’s ok with you.
This is true. Sadly, it's also what you see a lot of when programming full time. You're probably right on the Linux thing if OP has no knowledge at all of Linux.
bearssl.org - some of the best C I’ve ever come across and amazingly documented in all regards.
bearssl.org - most impressive use of C (even despite the dot net to C compiler stuff), well intentioned library, amazing documentation.
On another note - the qmail source is pretty awful despite being incredibly secure.
glibc 2.3.4 ? So this malloc/mallop stuff is not portable at all.
\&gt;It’s not possible to be a C programmer and not be reasonably familiar with the memory management functions in glibc. &amp;#x200B; Incorrect. In twenty years of C programming I have never used the standard c library. I guess it is popular with people writing applications running under an OS.
You replied to a bot.
You posted on a C sub but your question is about shell scripting? In C you'd use something like `readdir()` and friends, or the higher level `scandir()` to do this.
it's not really a script question, I'm using a script command because it already filters the files I need (without having to check the extension). I will try using readdir(), thanks for the answer!
First, this is C++ code and off-topic for this sub. Seems pretty self explanatory - your test case is failing because it expects `"Mary Beth\nStudent's last name is Regan\n"` and gets `"Mary Beth Regan\nStudent's last name is Regan\n"`.
Yeah, I've found DJB's code to be close to unreadable. It doesn't help that he often makes up his own peculiar conventions, sticks to them rigorously, then break when things outside his control don't meet them. I spent of bit time tracking down a bug in `tai64` because the log file it was parsing had become slightly corrupted.
thanks, i posted in the proper sub I should prob delete this thread
I don't know Cygwin, but did you try to step into a system function? If yes, don't. Just step over everything that isn't yours.
I tried to step into a simple, old "for" loop. Yes, a for loop. I'm sorry for saying that in the post.
Sublime text is a text editor not an IDE therefore it does not have a debugger.
If there is a function call in the initialisation or check section of the loop, stepping in will try to dive into the function and you don't have a debug file for it. In that case step over. You will go inside the loop, but without going in the function (it will still be executed). Also, make sure you are compiling without optimisations, otherwise the code in the debugger will not be consistent with what you are actually executing and it may look like you are entering the loop, but do something completely different in reality.
What do you use?
I'm sorry: In the last message I meant: " I'm sorry for NOT saying that in the post. " i forgot to type this "not" and the sense of the sentence was the opposite. Re-read my last comment to understand it now. &amp;#x200B; This was the code: \#include &lt;stdio.h&gt; \#include &lt;math.h&gt; int main (void) { printf("How many coefficients do you want to enter?: "); int coefficients\_count; scanf("%d",&amp;coefficients\_count); float polynomial\[coefficients\_count\]; /\*the user inputs the coefficients of the polynomial\*/ for (int i=0;i&lt;coefficients\_count;i++){ printf("Coefficient corresponding to degree %d?: ", i); float k=0; scanf("%f",&amp;k); polynomial\[i\]=k;} &amp;#x200B; &amp;#x200B; printf("Where to evaluate?: "); int evaluation\_point=0; scanf("%f",&amp;evaluation\_point); /\*Evaluates the polynomial in the evaluation\_point\*/ float result=0; for (int i=0;i&lt;coefficients\_count;i++){ result=result+polynomial\[i\]\*pow(evaluation\_point,i); } printf("The result of the evaluation is: %f", result); }
A combination of a proprietary library and the open source EDK libs of Tiano - for firmware initialization. So for example, we have to discover and initialize memory before we can even have stack. When we finish, then we hand everything over to the operating system which will then manage the memory we tell it about. [https://www.tianocore.org/](https://www.tianocore.org/)
Neither of these for loops should require additional symbols. If it's not the case of optimisation, then I give up. Cygwin is weird apparently. I don't programm on Windows, so can't help you with that one. Sorry for making noise :( `cygwin.S` is a part of libgcc. Maybe there is an option to install dev files for the compiler?
The real problem is trying to use Code::Blocks, which is a terrible desicion of mine, when that software hasn't been updated in 18 months. I will try to go with Eclipse, visual studio, etc. (dev c++ blodshed hasn't been updated in 14 years, and orwell dev c++, it's succesor, hasn't been updated in 4 years). It's a real shame this excellent software projects get cut and don't continue. Thank you.
Check out CLion. It's great, but quite expensive, unless you are a student or you work on an Open Source project that fulfills some pretty steep requirements. There's a 30 day trial available if you want to fall in love and put your wallet at a serious risk. It is made by JetBrains - people who know how to make a good IDE.
I don't currently have the money or interested in it, because I'm a huge noob, I should be using notepad++. Thank you.
Freestanding implementations typically have a linker that is told what memory is available, and can then indicate what region of that address space is unused. Code can then make use of that address space as it sees fit. A typical implementation might have two sets of mark-allocate and release functions, one of which allocates storage from the bottom of the heap upward and the other of which allocates top-down. Code which frees any object from the upper or lower heap must also simultaneously free all objects allocated after it on the same heap. Note that this design won't fit all usage patterns, but it will work with many kinds of systems that need to build data structures on startup whose sizes will vary depending upon configuration settings, but don't need to allocate and free objects in arbitrary sequence. Another useful pattern with freestanding implementations is to have a master allocation list, and have code hold indices into the list instead of pointers. This approach has a couple of advantages, especially on small-memory systems: if there are fewer than 65,535 objects (not uncommon in the embedded world where most microcontrollers have fewer than 65,536 bytes of RAM total), the indices can be stored using two bytes each instead of four, and the storage associated with each object can be rearranged by the memory manager if defragmentation is required. Note that the Standard does not require that all implementations support the semantics necessary to implement custom heaps, but instead treats support for such constructs as a quality-of-implementation issue. Some compiler writers feel no obligation to do anything beyond the bare minimum required by the Standard, except in cases where that would be too undeniably ridiculous, but quality compilers that honor the Spirit of C described by the authors of the Standard, and are designed to be suitable for various tasks, will not needlessly obstruct programmers from doing what needs to be done to accomplish those tasks.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
How about int line\[12\] to downcount the active lights, a pot in A/D to control the "simulation heat" and random() to set lines to active state.
So what I ended up doing since the activation method doesn't really matter is I hooked it up to a 10k potentiometer and set "if potentiometer is in x-y range then repeat blink on pins 1234... until not equal to x-y range. And just set the ranges. Worked perfectly. Thank you for the advice.
You have to choose if you go depth first or breadth first. If depth first, scan file names in a loop, then directly inside the loop call a new function with the file name as parameter and open and read that file from there. If breadth first, you have to store the file names in an array, possibly dynamically grown with realloc, then go through the array to process each file. Probably a good idea to do it in a separate function in that case as well.
If you have a text file containing the paths/filenames of other files to read from then you simply loop over the first file and create as many filepointers as required to later use for your other fscanf/fgets/etc.
This isn't breadth first/depth first. You are processing files one by one in each version, probably in same order (unless you treat your array/list as a stack), it is just that you store filenames internally instead of in a text file. He could even mmap his first text file and treat his first file as an array already. Anyway, I think it is quite unnecessary to read the first file in advance (into an array or list), unless there is some checking required. He could just use one FILE\* for the first file (list) and then one additional FILE\* for file that is currently processed. Unless the parsing of files is super simple (very simple format), I agree with you that he should make a function in which he parses his file, and call that one per file from some loop in which he loops over filenames in his first file.
Dude you are thinking too much. I think blargh4 gave you quite good advice. What your example do is what he just told you not to: don't use uninitialized variable in a context where its bits matter. Initialization means you are setting those bits to something that matters to you (or your program). Whether it is a number, char, pixel, bit pattern, whatever. There are only numbers in computer. What those numbers mean is completely up to you and your program. Your entire blog post, while correct, but makes somewhat erroneous assumption that people are relying on undefined behavior for initialization. We need uninitialized memory not because we rely on some bitpattern in uninitialized memory, but because we don't need to initialize memory if we are going to overwrite it directly with something else. We can simply save some writes, and undefined behavior by standard is undefined because compiler is left with choice to do whatever it assumes most efficient, correct or whatever and you should not rely on that behavior for correctness of your program. What those bits will be, depend probably on your OS, since OS might choose to overwrite or randomize pages for security reasons before it allocates them to your process. C compiler however does not require your variables to be initialized because it will mean unnecessary writes in some cases. Yes, compiler can optimize away unnecessary assignments, but optimizations are not part of standard, and standard still tries to make for an efficient language so it does not require your variables to be initialized to some standard values. As blargh4 wrote: If you're using an uninitialized variable in a context where its contents matter... just don't. That should be 101 of programming. At least in C/C++. I would like to add, there probably is not many contexts where you can use uninitialized variable other than assigning a value to it, and/or maybe make compiler happy in some special cases where value of a variable does not matter at all.
`fopen` opens one file and returns a pointer to that `FILE` structure that you can use to interact with the contents of the file, including using `fscanf` to read from it. It can't do anything with more than one file at a time. What you **can** do though is create more than one `FILE*` by calling `fopen` more than once. Conceptually, you want to open the first file and start reading lines from it using `fscanf`. Each time you read a line, you need to take the string you read (which is presumably the name of another file), and use it as the argument to `fopen` to get a brand new `FILE*` that you can use with `fscanf` to read from *that* file.
Check out the `getline` function. Or implement it yourself: read pieces of input into an array until it is full. Once the array is full, call `realloc()` to make the array larger. Do this until all your input has been read.
Can you parse it in chunks instead? For example: let's say you're just trying to count how many "a" characters there are in the string. You don't need it all in memory at once, so you should just read a byte, do your test, then read another byte into the same location. If you do need to store the entire thing: you could cache it to disk. If you can't cache it to disk: you should malloc it so that it goes into the heap instead of the stack and you'll be fine. A million characters is only one megabyte.
Wow, that actually makes tons of sense. Thank you for that.
I use visual studio at work and vim at home. I don't think there's a reason to use an IDE for C if you don't work on a bigger project with more than one developer.
Don't forget that virtual memory is cheap. If you have char \[100000\], but only use the 100 first characters, you might actually use 4 kB (or so) real memory.
&gt; We have uninitialized memory not because we rely on some bitpattern in uninitialized memory, but because we don't need to initialize memory if we are going to overwrite it directly with something else. We can save some writes. In some cases, a guarantee that reading an uninitialized location will yield an arbitrary value which can then be cross-checked for correctness will allow more efficient algorithms than would be possible absent such ability. If there were a standard means of indicating "give me the last value I've written to this chunk of memory, if any, or else give me some arbitrary value", then it might be reasonable to require that code for algorithms requiring such semantics employ such means. As yet, however, no standard means exists. &gt; Undefined behavior by standard is undefined because compiler is left with choice to do whatever it assumes most efficient, correct or whatever and you should not rely on that behavior for correctness of your program. That would be true of behaviors which are described by *neither* the Standard nor an implementation's documentation. If an implementation's documentation says "This implementation processes action X in fashion Y", and doesn't describe any exceptions, that would historically have been taken to define the behavior of action X in *all* cases without regard for whether the Standard would impose any requirements. If one part of the Standard or an implementation's documentation describes the behavior of some action, while another categorizes it as Undefined Behavior, that would historically have been interpreted as indicating "the behavior is only defined on implementations that specify it, which they may or do, or not, at their leisure". The Committee made no effort to distinguish behaviors which should be specified by all or nearly all commonplace implementations but might be impractical on a few obscure ones, versus behaviors which few if any implementations should be expected to specify usefully.
 ASW != "YES" `!=` does not compare the contents of strings. Use `strcmp`
&gt;In some cases, a guarantee that reading an uninitialized location will yield an arbitrary value which can then be cross-checked for correctness will allow more efficient algorithms than would be possible absent such ability. I believe we are completely missing each other. What I am trying to say is that you should not "cross-check for corectness" uninitialized memory, exactly because you are not having any guarantee that you will have an arbitrary value. However, iff you read something, than you have it in your CPUs register, which is guaranteed to be some bitpattern I guess. But you should never rely on it being any particular bitpattern. That is what blargh4 told you with different words. Anyway, what would it even mean to "cross-check" something that is uninitialized. I understand uninitialized to be "undefined". If you are going to "cross-check" anything, than you will have to have some reference to check against, which will mean something that is initialized to something. Anyway, what are you affraid of? What do you want to "cross-check" for? &gt;The Committee made no effort to distinguish behaviors which should be specified by all or nearly all commonplace implementations but might be impractical on a few obscure ones, versus behaviors which few if any implementations should be expected to specify usefully. I am not sure if I agree with you on this one. If that wasn't the case, then you would have no language at all. Distinction is made exactly by declaring certain places as undefined == left to compiler implementer, and those places which are well-defined that all compilers have to adhere with. &amp;#x200B; Also, I don't see how is it relevant to speculate about how things would historically be interpreted in some hypothetical case. Or do I misunderstand you there?
&gt; read pieces of input into an ~~array~~linked list of buffers until it is full.
Am I gross for preferring or enjoying writing small c console apps to invoke various syscalls instead of just writing a script?
That should be &amp;ASW in the scanf parameter. And the while loop doesn't make sense? What are you trying to do?
Thank you. I was practicing making a program that will stop only when it gets the right answer. If you answer anything besides Yes and yes, it will ask you to enter any else again until it gets the right result, and then "Right answer" would show up
You're logic is wrong in the while loop. and you need to use a string compare function. If I type "yes", well "Yes" is not equal to "yes" so you will get the "wrong Answer" message.
Read the lines of the first file into a buffer For each line in the buffer, attempt to fopen a file by the name of whatever string you're currently operating on. fread the new file into a different buffer.
You need to do something like do { scanf("%s", ASW); } while (strcmp(ASW, "yes") != 0);
&gt; What I am trying to say is that you should not "cross-check for corectness" uninitialized memory, exactly because you are not having any guarantee that you will have some defined value. Suppose I have an array `uint16_t foo[16384]`, all of whose elements have defined values 0..65535, and I want to know if any holds the value 12345. I also have an array `uint16_t indices[65536]` and I know that if any element of `foo` holds the value x, then reading `indices[x]` will yield a value such that `foo[indices[x] &amp; 16383]` will equal `x`. Given the above, what else would you need to determine quickly whether any element of `foo` holds the value 12345? Would you be able to find the value 12345 as quickly if you didn't have `indices[]`?
No, linked lists are not a good solution.
How is that a check for some kind of correctness? In an uninitialized memory block, you have no guarantee whatsoever what values will be present. You might as well have 12345 somewhere, or everywhere, or just 0's or literally anything. Only thing you are guaranteed to have in that block are bit patterns. If you are reading those patterns in pairs of two bytes you can interpret them as unsigned short, or signed short or whatever you want. Mantissa of a fixed point 16.16 float? &amp;#x200B; You are continuously looking for a meaning in that bit pattern, while as I understand *undefined* it means: don't assume any meaning or behavior in those bit patterns. I think it is where you make a mistake, but I might be misunderstanding you. Anyway I am trying to understand you, maybe I learn something :-).
Just realloc to double the size every time you run out. That's amortized O(1).
use `mmap()`. it allows you to open and access a file using pointer semantics.
A 800x640 pixel picture requires much more space. If it’s your project isn’t embedded or compute heavy then I really wouldn’t worry about an array of that size.
It just says it can't open a source file that is provided by the toolchain file. It just means you can't view the source code of some code (such as system or compiler functions). Not sure what context it appears in, but usually you can ignore it (unless you debug gcc/standard library/compiler).
It's AppV**e**y**o**r. Additionally, if I remember correctly, in the settings you can set to a custom `appveyor.yml` in the UI or configure directly in the UI (which then ignores the file settings), see [the documenation about it](https://www.appveyor.com/docs/build-configuration/#appveyoryml-and-ui-coexistence). Then maybe search a button in AppVeyor if they can trigger an build manually, or create a new commit (if build on commit is enabled).
If I could ignore it I would just ignore it. The problem is that I want to debug and debug doesn't work. In the code below, I set a breakpoint in main line. Then, I just click step into repeatedly, nothing else. When I try to "step into" the line with the first "for" loop, it displays that message and refuses to step into. So I can't debug, and thus I can't use Code::Blocks. Not being able to debug is a big deal. I didn't find easy instructions on the web on how to install the nightly build, when I tried to do it, I encountered the exact same debug problem as here (it's very possible I did the nightly build incorrectly, but again, the instructions are way too un-friendly). BTw, I'm just ranting to you about Code::BLocks frustration, please don't get mad, I just want everyone to know why I stopped using this software. This was the code: \#include &lt;stdio.h&gt; \#include &lt;math.h&gt; int main (void) { printf("How many coefficients do you want to enter?: "); int coefficients\_count; scanf("%d",&amp;coefficients\_count); float polynomial\[coefficients\_count\]; /\*the user inputs the coefficients of the polynomial\*/ for (int i=0;i&lt;coefficients\_count;i++){ printf("Coefficient corresponding to degree %d?: ", i); float k=0; scanf("%f",&amp;k); polynomial\[i\]=k;} printf("Where to evaluate?: "); int evaluation\_point=0; scanf("%f",&amp;evaluation\_point); /\*Evaluates the polynomial in the evaluation\_point\*/ float result=0; for (int i=0;i&lt;coefficients\_count;i++){ result=result+polynomial\[i\]\*pow(evaluation\_point,i); } printf("The result of the evaluation is: %f", result); }
Please go ahead and post the code also.
Also, I am not sure if this is the proper suberddit to ask C questions. If not please tell me where I can do so. Thanks have a nice day!
int main(void) as explained here: http://www.c-faq.com/ansi/maindecl.html (void) makes it explicit that no argument should be passed to the function.
What di you mean by "argument"?
See here: https://stackoverflow.com/a/156787 It's a fairly generic programming concept, learning about functions and parameters/arguments is important.
Arguments are the values passed as parameters. For example, if I have the function `int f(int y) ...`, then it has the parameter `y`. If I then call that function like `f(3)`, it has the argument `3` (which binds to parameter `y`). [Source](https://www.quora.com/What-is-the-difference-between-argument-and-parameters-in-C)
Ok thank you! I am am not that good in English😅
This is actually the most perfect subreddit to ask to a C question like this!
Standard C main functions return `int`. Some compilers allow for `void` (notably Microsoft Visual C), but this is non-standard and compiler-specific. In other words, `int main` will work everywhere, whereas `void main` won't. I think that most people (including myself) would recommend to only ever use the standard version. Note that this applies to both C and C++. The other answers explain the whole `void` parameter thing. Note that this does not apply to C++.
No worries. These aren't the normal meanings of those words anyway. This only really applies to mathematical / computer sciency / programmy stuff.
`int main(int argc, char** argv)`
https://qr.ae/TWnkoE
Thank you!
Nice!
Oh thanks for the c++ note, it may help me in the future!
Fixed size array is not the same as fixed element count array in C. Having a 100000 elements big char array means you can store a string that is 100000 characters long. I doubt your names are only empty strings because those would be the only strings that you can store 100000 of in such array. ("" is {'\0'}) I hope we are in the clear of what is the problem. Now, you need to have an array for char * that is 100000 elements big. It means char * names[100000]; This is an array to char pointers, effectively and array of variable length string that is fixed in element count, which is 100000. We have achieved what you wanted, but now we have to make it work. To run through it, you need to read from file one name at a time to a temporary buffer, measure it, dynamically allocate for just the correct size, copy the string from your buffer to the newly allocated memory. I hope names in the file are \n seperated because you can just use fgets to read from the file.
Fixed size array is not the same as fixed element count array in C. Having a 100000 elements big char array means you can store a string that is 100000 characters long. I doubt your names are only empty strings because those would be the only strings that you can store 100000 of in such array. ("" is {'\0'}) I hope we are in the clear of what is the problem. Now, you need to have an array for char * that is 100000 elements big. It means char * names[100000]; This is an array to char pointers, effectively and array of variable length string that is fixed in element count, which is 100000. We have achieved what you wanted, but now we have to make it work. To run through it, you need to read from file one name at a time to a temporary buffer, measure it, dynamically allocate for just the correct size, copy the string from your buffer to the newly allocated memory. I hope names in the file are \n seperated because you can just use fgets to read from the file.
The correct use now is either: int main(void) {} if you don't want to use arguments (switches, options,...) your program may be run with from the command line, or int main(int argc, char * const argv[]) {} if you want to use them. `argc` holds the number of arguments and `argv[0]` is always the path to your program, as it was executed (may be relative to the current working directory). For example, if you ran your program like this: ./prog -a -b c `argc` will be 4, `argv[0]` will be `./prog`, `argv[1]` will be `-a`, `argv[2]` will be `-b` and `argv[3]` will be `c`. `argc` is always at least 1 and `argc[0]` always contains the run path, even when no arguments were provided in the command line. There is also (rarely used) third form: int main(int argc, char * const argv[], char * const env[]) {} where `argc` and `argv` have the same meaning as before and `env` is a NULL-terminated array of environment variables and values. The reason why it is rarely used is because there are more convenient functions for getting environment variable values. The names can be different. It is just a convention. Also, sometimes you may omit the const qualifier and compiler won't scream at you for this.
\&gt; How is that a check for some kind of correctness? In an uninitialized memory block, you have no guarantee whatsoever what values will be present. You might as well have 12345 somewhere, or everywhere, or just 0's or literally anything. The point is that for each element \`indices\[x\]\`, one of two things will be true: either \`indices\[x\]\` will have a defined value such that \`foo\[indices\[x\] &amp; 16383\]==x\` is true, or its value will be irrelevant because \*every\* element of \`foo\[\]\` will hold a value other than \`x\`. Requiring that \`indices\[x\]\` be initialized even when its value would be irrelevant would not be a recipe for optimal performance.
The answer is different if you use C++ rather than C, so this is of no relevance.
vi says otherwise.
IMO, C::B is a rubbish IDE and the debugging never worked properly for me, even when there were no errors it would work for a bit and stop working for all sorts of reasons. Also, gcc 4.8.1 is very old, any reason you are not using the latest version of compiler?
it has been a long time since i played around with reading largeish files, back in the 1990's, but i remember using the mmap(), which if i remember correctly basically allows you to read and write to ram instead of the disk file.. one issue that i remember testing is using the write() and read() functions, in dos i think, i found that read one character takes just as much time as reading 64k of data in one chunk.
Only on Linux.
Some compiler optimizations are stupid and unable to accelerate calls unless the ancient void syntax is used
`mmap()` is POSIX and is available on almost every unix-like operating system. there are implementations and analogous functions for windows.
You talk about Meson like it's the second coming of Jesus. What makes it work for you?
Using warning_level alone is usually not enough, because the compiler flags it sets don't make much sense: -Wextra is already added at warning_level=2, but -Wpedantic is added only for warning_level=3. It should be the other way around, because usually you always want to use -Wpedantic, but not -Wextra because it gives a lot of false positives. ([Here is an open issue for this](https://github.com/mesonbuild/meson/issues/3742)). As a workaround, I think the best solution is to use warning_level=3, and then add additional flags to disable some of the -Wextra warnings that cause problems, like this: project('myproject', 'c', default_options: [ 'c_std=c11', 'warning_level=3' ] ) cc = meson.get_compiler('c') add_project_arguments( cc.get_supported_arguments([ '-Wno-unused-parameter', ]), language : 'c' )
Thank you. Indeed GCC 8.4.1 it's ancient, it's from may 2013 [as said here](https://www.gnu.org/software/gcc/releases.html) I didn't realize that. However, as a MEGA NOOB, my super shitty understanding is that you can have many GCC's on your system at the same time. For some reason it's using that ancient GCC, i have no idea why, it also says "i386" in it's path , which is 32 bits, so tat is weird also. I'm only starting in GCC stuff in Windows, and for example, the other day, because i wanted to look at my mingw version, I found here online the commmand "gcc --version" that I can paste in the cmd, and it tells me the version of my gcc, which is gcc.exe "([MinGW.org](https://MinGW.org) GCC-8.2.0-3) 8.2.0 " I have no idea how do these diffreent GCC interact each other. I installed code blocks 2 days ago, so i have no idea why their non mantained piece of crap has that old gcc.
There are no {} braces in the for loop. ! Has a greater precedent than &lt; and and an associativity of right to left so instead of it being (!y) the compiler will automatically group it as (!&lt;). There is no !&lt; comparison operator, Not less than means something is either greater than or equal too so use =&lt; or &lt; Y also hasnt been declared nor have you stated you're using the ASCII constant 'y' as theres no quotation marks So you're trying to compare 1 to something undeclared. You're Declaring X then comparing it to 0, not initialising it. X assuming you wanted it to be a float is 32 bits yet you're giving the format specifier to print a char. I'm not sure if it'll implicitly typecast but you need to cast the float to be a char.
How are you detecting an upper case character?
Actually I have to store strings in arrays my teacher doesnt let me use the predefined strings so I did this if(s\[i\] &gt;= 'A' &amp;&amp; s\[i\] &lt;= Z) I did that inside a while.
That's a good start but you're missing some state information. You need a variable to allow your program to know what it's looking for. You'll probably have an overall while loop that loops over the string, `while (string not over)`, and then inside you're going to be looking for a period, and then when you find a period (indicated by a variable, say, `foundPeriod = 1`), you want to ensure that the next non-space character is a capital letter before continuing on your period search. Hopefully that's enough information to start you thinking about it.
&gt;you need to read from file one name at a time to a temporary buffer, measure it, dynamically allocate for just the correct size, copy the string from your buffer to the newly allocated memory `getline()` can do this automagically. You still have to `strdup()` the buffer to make a copy.
Thanks I think I'm beginning to understand, This is my code so far: i = 0; aux; if ((s\[0\]&gt;= 'A') &amp;&amp; (s\[0\] &lt;= 'Z')) { Mayus = TRUE;} else{ Mayus = FALSE; } while (s\[i\] != '\\0') { if(aux == 0) { if ((s\[i + 1\]&gt;= 'A') &amp;&amp; (s\[i + 1\] &lt;= 'Z')) { Mayus = TRUE;} else{ Mayus = FALSE; } } aux = 1; &amp;#x200B; if (s\[i\]== '.'){ Punto = TRUE; aux = 0; } i++; &amp;#x200B; } if((Mayus == TRUE)&amp;&amp;(Punto == TRUE)) printf("\\nTexto valido."); else printf("\\nTexto invalido"); Mayus means uppercase and Punto means period.
I never realized that argument and parameter were not synonyms.
I've told you once.
Yep. Often another name taught for arguments is 'actual parameters', as it's the *actual* value of the parameter (3 in my previous example). However, I personally think that sounds clumsier than just calling them arguments.
&gt;I need to make an algorithm that checks that every sentence in a text begins with an uppercase and ends with a dot. Define a "sentence". If sentence does not start with an upper case letter, you cannot detect if the previous one ends with a dot, because you don't know where that end is... if it is. If by "sentence" you mean a claster of words, where first one is titled and the rest is not, then you have no way of detecting the sentence if it doesn't start with a titled word or previous sentence does not end with a dot. How do you detect sentences in `I have no mouth and I must scream white cat jumped on the roof pickled onions`?
If I were you I'd check how other people have done it with a simple google search. https://www.geeksforgeeks.org/check-given-sentence-given-set-simple-grammer-rules/ https://repl.it/repls/OptimalAlarmedSemicolon
`void main()` is just plain wrong. In practice, there is no difference between `int main()` and `int main(void)` unless plan on recursing on main, or making a pointer to main. The first says "main has an unknown number of parameters" and the second says "main has exactly 0 parameters". Unless you plan on calling main more than once, there will be no difference in behaviour, though the second is good habit.
Meson is 100 times easier to use than cmake, especially if you’ve never used cmake before. Specifically the learning curve is much lower. The documentation is mostly better and the scripting language makes more sense if you’ve used other scripting languages like python or JavaScript. It’s still pretty powerful and allows for a large amount of end user customization, though it probably doesn’t have full feature parity to cmake/make. Instead of outputting a make file it uses ninja to build your project, which I’ve found to be faster in general. * [Meson website](https://mesonbuild.com/index.html) * [Manual](https://mesonbuild.com/Manual.html) * [Reference](https://mesonbuild.com/Reference-manual.html) Meson also has a dependency tool that downloads dependencies from GitHub like [Unity unit testing framework](https://github.com/ThrowTheSwitch/Unity.git) for example. Developers using Meson would probably like to use a "\[wrap-git\]" file. * [WrapDB](https://mesonbuild.com/Wrap-dependency-system-manual.html)
For a fun (?) sidebar on semantics: If a function "takes an argument", is that synonymous (in your opinion) to that function "having a parameter"? What about "taking a parameter"?
I usually take a coffee break when an "int main()" is launched instead of an "int main(void)".
I think I'll stick to plain Makefiles for my projects.
\#include &lt;stdio.h&gt; \#include &lt;stdlib.h&gt; \#include &lt;string.h&gt; \#include &lt;time.h&gt; \#define SIZE 100000 //#define SIZE 250000 //#define SIZE 500000 int main(void) { const char filename\[\] = "new\_name.txt"; FILE \*myfile = fopen (filename, "r"); //char names\[SIZE\]\[15\]; //char line\[SIZE\]; char c; if (myfile == NULL) { printf("Cannot open file \\n"); exit(0); } c = fgetc(myfile); while (c!= EOF) { printf("%c", c); c = fgetc(myfile); } fclose(myfile); return 0; } &amp;#x200B; That is what I have so far. Sorry for the late response I've been at work
For vi they work because vi has a dynamic buffer system where it swaps lines in and out of memory. This is not what OP wants to do; OP wants a single array with the data in it. if you used a linked list to keep a series of buffers only to copy the data into a single buffer later on, you just made your life needlessly complicated.
Never ever use `void main()`. It's not legal C. Explicitly passing `void` to a function is redundant in my opinion but is fine. Some people like to use `int main(int argc, char **argv)` even in programs that don't take command-line arguments. I don't know why.
you should not use main() or void main() it's older standard and gives error on latest gcc compilers. you can use int main() or int main(void) or _Bool main() etc.
May its a good habit?
Yeah because we spent 90% of our cpu time in a program calling for main. Jeezus how can be so assertive and so wrong at the same time?
&gt;Requiring that \`indices\[x\]\` be initialized even when its value would be irrelevant would not be a recipe for optimal performance. Congrats. That's what I have been telling you since first comment :-). &gt;The point is that for each element \`indices\[x\]\`, one of two things will be true: either \`indices\[x\]\` will have a defined value such that \`foo\[indices\[x\] &amp; 16383\]==x\` is true, or its value will be irrelevant because \*every\* element of \`foo\[\]\` will hold a value other than \`x\`. No. I believe it is a false premise.
I've been thinking about C and its practical implementation after learning the basics. And to organize the information I tried making a skill tree as you would find in the game Skyrim or Kerbal Space Program, where you complete tasks to get points to advance in the skill tree. I hope the low quality of the image provides enough context that this is not a complete work and something I'm poking around with, feel free to suggest nodes or resources for anyone the nodes as the rest of this post will be me trying to provide some context and resources for each node. **Basic C** It's right there in the sidebar for anyone to get started. [C Programming Language](https://www.amazon.com/gp/product/0131103628) Pretty much go through this first, generally suggest using a minimal text editor and the command line to compile programs. **Intermediate C** This has been marked as optional, as a general stepping stone for using a few more materials to learn or reference before jumping into any projects. Books like Modern C, practice books, or understanding pointers could go here. Let me know if you have any suggestions for books, youtube, websites. **Sockets** Sockets is marked as optional to separate the group. But in general this section resolves around the concepts of tcp and udb and sending signals between computers. Example projects for this group are things like making a [basic http server](https://rosettacode.org/wiki/Hello_world/Web_server#C) on the http side, or programming [with bluez](https://people.csail.mit.edu/albert/bluez-intro/c404.html) on the bluetooth side. I threw in game server on the end as there are several open source projects that create the back end for games that don't have online services any more. This seems like a good way to get familiar with a specific set of structs and packets, maybe someone can leave some examples if there are anyones that are a good place to get started. **GPIO** I haven't gotten into gpio myself very much, and most of the tutorials for it seem to use python. But this seems like a pretty good use-case for a practical implementation with C. **GUI (Gtk)** For making user applications with C, GTK seems to be the most common library for implementing applications with widgets. The best resource for this pdf seems to be [An Introduction to C &amp; GUI Programming](https://www.raspberrypi.org/magpi-issues/C_GUI_Programming.pdf), and there are a few more examples posted in the [gtk discorse](https://discourse.gnome.org/t/useful-documentation-for-gtk/29/5). **Graphics** This is the node with the most sub-nodes and not the easiest node to organize as there are a lot of libraries that can be used. For libraries there is GLUT/GLFW/SDL/GTK+/Raylib/EGL. In general GLUT and GLEW seem to have the least features with them being mostly focuses on getting and window and providing OpenGL context. Freeglut provides a [decent wiki](https://en.wikibooks.org/wiki/OpenGL_Programming) for getting started, and while the examples are in C++ it's not too bad to translate them back into C. GLFW seems to be the libary that the [OpenGL Red Book ](http://opengl-redbook.com/) currently uses. SDL is a really common and popular library that's been used for a lot of games, including Open Tyrian. While it's popular, the only strictly C resource I've found for it so far is [this blog ](https://www.parallelrealities.co.uk/), which provides a 2D Shoot 'em Up tutorial. Though the most well known tutorials are written by [Lazyfoo](http://lazyfoo.net/tutorials/SDL/index.php), and are provided in C++, while these tutorials have probably been ported to other languages I don't know of any C-only examples out there. The GTK+ library provides the GTKGLArea widget which allows for an OpenGL 3.0 and above context to be created. So it might be a decent choice to work with if you want to create applications that allow for toggles and widgets, along with a 3d view port. A few example applications for GTK can be found [here](https://gtk.dashgl.com/). For Raylib I haven't tried it, it often gets suggested here and on forums pretty fequently. So maybe someone can provides links, and maybe provide some context of some comparison between Raylib and some of these other libraries. EGL is an option that I've seen pop up here and there, but it looks like it allows you to write directly to the framebuffer for embedded computers without needing to start a desktop. There's a really good series of tutorials that can be found [here](http://raspberrycompote.blogspot.com/2012/12/low-level-graphics-on-raspberry-pi-part_9509.html). **Summary** So this is what I have for resources that I've found so far that fit into the skill tree. I think there are a few more honorable mentions like libpng, or file compression, or POSIX coding and terminal games and applications. And are there any other nodes that you would add to the skill tree?
You do realize that suggested linked list of buffers is de facto a dynamic buffer system? &gt;OP wants a single array with the data in it I don't interpret op that way. Read his post again. But I can agree that a single array will do the work since OS will do the hard part behind his back or with other words as already commented above virtual memory is cheap or a dynamic string/array (vector) could do just fine.
You **MUST** put `void` inside function's round brackets if the function accepts no parameters because otherwise, your compiler will think that you are writing a function declaration, not a function prototype. You can read my article (it's in Russian, but the examples are clear) - https://habr.com/en/post/456682/.
Ohhhhhhhhhhhhhhhhhhhhh thanks mate!
Now everything makes more sense now
So basically the compiler will think that I am declaring just a normal function?
A segmentation fault is a message from the kernel that occurs when accessing memory that is outside of the applications scope. Step through the code and check array access by for or while loops. If the array has a constant size check if thr loop exceeds this limit. If the array is dynamicly created take note of the creation size or if it is created in the first place.
There are more necessary topics than, for example, Bluetooth and a game server - \*\*EVERY\*\* C programmer should know at least one build system (CMake, Make, Ninja, ...), multithreading (OpenMP, pthreads, ...).
int main(void) is correct for C. int main() is correct for C++ (where it means "no arguments") and acceptable (but obsolete/non-standard) for C (where it means "an arbitrary number of ignored arguments") void main() is invalid (for C or C++).
Thank you!
What makes you think it's line 414? It's a fairly big file, if you can install valgrind and run with valgrind, can be probably easily solved.
 int main(void) Perfect solution, everything is clear for a reader and the compiler.
this is the right answer. "depends on the compiler".
A function declaration is a syntax that tells the compiler that a function with a given name has been defined earlier. A function declaration consists of a return type and a function's name, whereas a function prototype is a subset of function declarations that specifies parameter types. For example: ``` // A declaration: // void foo(); // A prototype: // void foo(int arg1, long arg2); // A definition: void foo(int arg1, long arg2) { long result = arg1 + arg2; } ``` `void foo();` means that you can pass absolutely everything as arguments, for example, you can do `foo(NULL, "lololo", 1838, 28438.344)`. Don't do this, this is deprecated syntax. You should always use a function prototype.
It's a bit counterintuitive: "d" returns an address 'd' an actual char &amp;#x200B; #include &lt;stdio.h&gt; int main() { printf("%p: %c\n", "d", "d"); // returns an address + nothing printf("%p: %c\n", 'd', 'd'); // returns d as 8 byte unsigned long + d return 0; } Output: 0xcd1ac15a4d8: 0x64: d This is undefined behavior, on my machine it just does what I expected :)
Thanks for that I will try with it. The code stops at line 414, I found it out using printf statements, so assumed so.
printf isn't reliable for this since the stdout buffer isn't flushed right away. fprintf with stderr for this kind of debugging or a debugger to determine the point where the program stops.
Every C programmer or every professional C programmer? While build systems are important for projects in a lot of cases beginners are probably going to be making short programs and linking a few libraries, so that seems like something that becomes important once you reach a certain level of complexity. It kinds of seems to be the same case with multi-threading, programs can start with loops simple loops and threading can be introduces as that level of complexity becomes required. In most cases for games, you'll be setting up a game loop, getting input updating the state and then sending draw commands to the graphics card and repeating. What kind of tasks are you anticipating programmers to be required to manage multiple threads right away? That seems like something you would start implementing after becoming familiar with an http servers, and then saying, "okay, now how do we handle multiple requests at once?"
In your world, what is GPIO?
[General Purpose Input/Output](https://en.wikipedia.org/wiki/General-purpose_input/output)
Ok, same as my definition... but I don’t understand how tutorials for it use Python. Nobody uses python for GPIO handling. Even the Raspberry Pi uses a C abstraction layer afaik
Yeah, thanks for that. Used valgrind problem was with a different line ahead of 414.
The example link from the PiHut I provided uses python: import RPi.GPIO as GPIO import time GPIO.setmode(GPIO.BCM) GPIO.setwarnings(False) GPIO.setup(18,GPIO.OUT) print "LED on" GPIO.output(18,GPIO.HIGH) time.sleep(1) print "LED off" GPIO.output(18,GPIO.LOW) As stated in the original post, most of the resources I've stumbled across use python for examples. Maybe you could be gracious enough to share what C resources you know of.
every day the same question. google it you will find a lot of curated lists on stackoverflow or github some of then even describing pros and cons of those books.
A function has N parameters and therefore can take N arguments. A [variadic function](https://en.wikipedia.org/wiki/Variadic_function#In_C) might take more arguments than it has *explicit* parameters: void foo(int x, int y, ...); foo(1, 2, 3, 4, "hello", "world"); Also, as mentioned, C functions can take an undefined number of arguments: void foo(void); void bar(); foo(1, 2, 3); /* Error */ bar(1, 2, 3); /* OK */ &gt;What about "taking a parameter"? Arguments are given by the caller and taken by the callee, whereas parameters are something a function just has. At least, that's in the case of C. Slightly whackier languages with closures and lambdas might require slightly different definitions - I'm not 100% sure.
This is the community in case you were wondering: [https://www.facebook.com/groups/TalentHubLyto/](https://www.facebook.com/groups/TalentHubLyto/)
I like the way you try to structure you learning efforts. Sounds like a great plan. A few observations: 1. Socket programming in C is IMHO very simple. What makes it hard is getting it right. Look into different primitives (RPC for example) and try to design a nice and flexible protocol around your code. Network programming is strongly about concepts. And also try to design your code to work with IPv6 too. This way you are less likely to copy paste things from stack exchange ;) 2. GPIO is a little specific. Why not label it embedded programming ? Sure it all stars with getting that Arduino LED to blink, but why not also write a small UART driver? Buy yourself an arduino or similar (I like the NodeMCUs with WiFi. Running a Webserver on an embedded computer is fun) and have a little fun with the Arduino IDE. If you prefer less abstraction then use a opensource C operating systems for embedded computers (RIOT OS is an example) Hope this helps :)
Speaking of game servers. Modern game servers are Designs such that multiprocessing can be easily integrated into the architecture. Separate your Game Loop into different Modules and May let the NPC/Environment Logic run in a distinct thread. Sure you can implemented it afterwards but that’s most likely more time consuming than designing and building it right away. Also you learn a lot about c Programming. I would also say that the pthread lib and fork as well as communication between processes are c programming basics.
Google any book you are interested in, add filetype:pdf. The results might surprise you.
[removed]
Side note: In the example, argv[4] is also set, and guaranteed to be NULL. (since just like env, argv is NULL-terminated).
Good point :)
I forgot about the filetype "trick" with google, sorry😅
So quite a few downvote fairies (around 14 atm). I'm open to criticism to make improvements, so I'd appreciate if people would let me know their reasons for disapproval so I have some context of why I suck or what can be improved.
Why isn't there anything about files IO (And browsing an directory tree in general), signals or memory management? Dealing with program arguments or with configuration files? This skill tree is a good idea to give kind of a road map to someone new to C, to explain where to start, but it seems very much oriented for someone coding windows compatible video games. And I would agree that it could be good to add the toolchain revolving around C : compiler, debugger, memchecker, make, autotools/CMake, svn/git/mercurial (for source management), and other I probably have forgotten.
Thanks this is the kind of feedback I'm looking for. So pthread lib and fork are programming basics. I guess that's the kind of thing that would go into the or replace the 'Intermediate C' category, along with make files. Forks I've kind of seen here or there in my random google searching, but this is the first time I think i've seen pthread mentioned.
Make simple games, I highly recommend starting with [Raylib](https://www.raylib.com/). or [Ncurses](https://www.google.com/search?q=ncurses) if you like terminal games.
I wouldn’t say basics, but very important features. So yes the intermediate category is probably well suited. There is a critical difference in fork (starting a new process) and pthread (which is all about threading). One of the main differences is that threads can share an address space by default while this takes additional effort when using fork. In my experience a thread is often the way to go and distinct processes are an overkill but it really depends on your use case. The shared address space makes communication between the threads more easily but you have to take care of synchronization.
I'm with Gymmassoria, there are definitely other things that C programmers ought to know, and build systems are really really among them. In addition to that, I'd add good debugging skills and code profiling (gdb, valgrind). At a certain point I do agree that higher performance skills are very braod in application as well, so can you vectorize code, make smart use of intrinsics or inlined assembly if needed, and definitely multi-threading. Other more niche topics can be specialized. The graph is clearly gaming related. We can also include operating systems and their arena (drivers, file systems, etc). What about hacking and reversing (can you kick off a ROP chain? Maybe hide malware in an x86 binary?). Compilers are also big. Simulations of anything like processors or wind tunnels are always going to have some interest too.
In school computer science classes were always centered around Java, and never actually provided any explanation about how coding interacted with the hardware. It generally centered around memorized syntax and knowing the right magic words to get a program to compile. So I started trying to teach myself C as a way to try and how computers work on a more fundamental level. This chart and post is everything I'm managed to map out so far from my skatter-brained attempts at self learning, so that it could provide a visual guide for new comers to C programmers to plan out what they want to learn and get an idea of the kind of projects and resources that would help them get there. So my understanding of C is no-where near complete, so it does also help me try and focus where my energy should be directed. 2. For GPIO, i put in the name as that's the method of which you're interacting with the hardware. For an LED, a button or some sensors, effectively it's communicating with a piece of hardware over the GPIO pins and checking, or setting high or low. Embedded is a good way to describe the implementation of what's done with the GPIO pins, though EGL on the graphics side could also be described as embedded programming, so it might be a good idea to add an embedded tag or color into future revisions of this map. For nodes that could extend from the GPIO node, i was thinking that HTTP + GPIO could be IoT, you could create small server that would turn a light off or on after getting a specific set of packets. Or potentially Bluetooth + GPIO you could make a simple controller that is able to send commands over bluetooth. 1. For sockets and networking i've only done a few examples from what I could find for http and bluetooth. I bought the book [TCP/IP Sockets in C](https://www.amazon.com/TCP-IP-Sockets-Practical-Programmers-ebook/dp/B005VO375A/ref=sr_1_1?keywords=tcp%2Fip+c&amp;qid=1563450345&amp;s=gateway&amp;sr=8-1) but it's been sitting around on my shelf until I can get to it.
Yea the wording in the software development world is often inconsistent. GPIO merely means the actual hardware PIN which itself is programmable (as input xor output). Hardware programming is often more than just writing a GPIO Pin (even if this is what’s happens in the background). A WiFi or BT module often communicates via a actual serial interface design (SPI for example). That said in wouldn’t necessarily connect stuff like web programming with hardware programming. There is a clear abstraction layer between both. A Webserver written in C could run on any hardware as long as there exist access to the relevant interfaces (posix sockets in most cases).
No offense, but it seems like that you are really into game development and you pretty much built this roadmap around it. I like the idea of making a roadmap for C programmers, but I can't really agree with the way you've done it. \- GPIO: This one is pretty much only useful for embedded C programmers. \- GUI GTK: Yeah, that sounds reasonable to learn that if you're doing (frontend) desktop applications. \- Sockets: Again, there are people who will need to use that, but not everyone. \- Graphics GLUT/GLFW: For graphical apps (e. g.: games) \- Intermediate: Optional? If someone wants to master C, it won't be optional. It turns out that you made a few 'nodes' in a 'C talent tree', but in such a tree (after mastering C), almost every skill is optional, no one needs all of them. As others said: I would add some more options like PThreads, OS-API, etc...
&gt; I'm with Gymmassoria, there are definitely other things that C programmers ought to know, and build systems are really really among them. In addition to that, I'd add good debugging skills and code profiling (gdb, valgrind). Considering that comment got a lot of up votes a lot of people seem to agree that it's important, so I wanted to see what kind of follow up I got for being cheeky to see what kind of context that provides. Specifically what I'm curious about is what is the advantage of using make over providing a simple script that provides the links to compile the program? Is it that it allows for builds on other platforms, provides manage dependencies, or that it provides a standard interface that other people can read? &gt;Other more niche topics can be specialized. The graph is clearly gaming related. We can also include operating systems and their arena (drivers, file systems, etc). What about hacking and reversing (can you kick off a ROP chain? Maybe hide malware in an x86 binary?). Compilers are also big. Simulations of anything like processors or wind tunnels are always going to have some interest too. This map represents the small area of C programming that I have attempted to map out from my experiences with trying to get familiar with implementations for making OpenGL applications in C. Though in general I think that games are a great mechanism for getting familiar with programming topics as it allows for feedback on the graphical side, a fixed client to work with for network programming, and fixed target to work with for embedded programming. So it's a good way to get familiar with a specific subject.
&gt;No offense, but it seems like that you are really into game development and you pretty much built this roadmap around it. I like the idea of making a roadmap for C programmers, but I can't really agree with the way you've done it. That's the idea, make a draft, throw it out there. Get critiqued and edit and revise as needed. The map generally breaks down into four main areas, once you've gone through the main syntax of getting familiar with C, basics like opening and closing files, where do you go from there? What are some practical programs you can make with C? And I generally broke it down into Graphical Oriented (games), GUI or user interfaces (likely with GTK for C), GPIO often used with embedded programming, and networking or sockets. There are probably more nodes that could be included in the tree like Kernel development, Cyptography, OpenCL computing, compilers, but that gets complicated and it's not something i'm familiar enough with to add those kinds of nodes into the tree and say, "these are the kinds of resources that will help you get into this kind of programming". The goal of the skill tree isn't to provide an all encompassing, "do everything to master C", but it's more of a way to visually plan out what steps and what resources are needed to reach a certain goal. Like for instance someone takes a basic C 101 course in college, but their professor isn't very helpful, and they want to get into embedded computing, then "okay, it makes sense to learn pthread, bluetooth, and gpio things, and here are some projects and resources I can use to get myself there".
&gt; Source code Source code *not as an image*, but as text, properly formatted for Reddit (i.e. with four leading spaces on each line).
&gt;Why isn't there anything about files IO (And browsing an directory tree in general), signals or memory management? Dealing with program arguments or with configuration files? For files I figured the basics of opening and reading files, will probably be covered in basic programming and from there will likely depend on the implementation is. And http program is likely simply going to read and send a file, while reading a png is likely going to involve reading RGB values, so it's hard to nail down file IO into one category. Signals and memory management seems like an important topics that need to be included somewhere. &gt;This skill tree is a good idea to give kind of a road map to someone new to C, to explain where to start, but it seems very much oriented for someone coding windows compatible video games. This is my bias being expressed. The graphics side it the most populated of the four categories included, but I also centered around games as it's generally a good learning device. New programmers can build a game, see how the concepts of programming structs and memory management can be used to move sprites around the screen as a method of learning the fundamentals of computer science. Which is why i put priority for gaming on a tree like this, but I'm open to suggestions for what kind of nodes or skills should be included, maybe databases? &gt;And I would agree that it could be good to add the toolchain revolving around C : compiler, debugger, memchecker, make, autotools/CMake, svn/git/mercurial (for source management), and other I probably have forgotten. This is definitely important and will be address for future revisions of the map.
I think pastebin, gist, etc. are ok too.
Modern C
That's not even a tree. GTKGLArea has two parents.
&gt;For files I figured the basics of opening and reading files, will probably be covered in basic programming It may depends how it is presented. If you only consider printf/scanf (with format) or write/read (as a stream of bytes). &gt; and from there will likely depend on the implementation is. I must admit that I am not sure of how it is managed on Windows, nor to what extent the usual functions that you usually find under `man 2` pages are available. &gt;And http program is likely simply going to read and send a file, while reading a png is likely going to involve reading RGB values, so it's hard to nail down file IO into one category. Signals and memory management seems like an important topics that need to be included somewhere. If you present the question from the "stream" point of view (so the way the system manages file descriptors), then writing to a socket is basically the same as writing to a file or to the standard output (And that's the beauty of abstraction). The question is, is it known how to serialise? Are there any endianess issue to foresee? &gt; Which is why i put priority for gaming on a tree like this, but I'm open to suggestions for what kind of nodes or skills should be included, maybe databases? I quite agree on the usefulness of the games to learn the how to's. But there is very quickly a need to know basic about computer architecture. And for database, a need for combinatorial maths in addition of the rest...
Build tools like Make are really helpful. If you invest a little into learning it, you get a lot out. One big thing for Make over just writing bash scripts or the ilk is dependencies and rebuilding things. Say you modify one or two included sources that your final project uses, a properly set up make file will recompile only what is needed to rebuild the target. So if your `main.c` or whatever depends on `a b c &amp; d`, and you fix something `d` depends on, you only recompile that, `d`, and `main.c`, `a b &amp; c` aren't looked at again cause they're already set and can be used. Doing this in make is almost always way more easy than a bash or perl script or what have you. Another topic I forgot to mention that is super important is some kind of code subversioning tool experience, like git or svn. These tools are life savers on larger projects, and make working as a team so much easier. It's a little hacky in some folks views, but if I have a git repo with submodules and all that fun, for building my top level stuff, I normally will include some git work in the make file to get things neat, then build since I can make that a dependency as well in make. Games, I agree, are a good way to motivate students or oneself for learning certain topics. I wanted to bring up other topics because those are really fun too, but the direct cross over with games isn't super present to me at least, maybe aside from HPC stuff. Would it be fun to hack pong or snake into a boot loader or something as a proof of concept? I think it would be a fun first target, but bashing on a boot process to get into a root shell when I shouldn't be able to is even more enticing to me. So I think maybe the topics is just different strokes, different folks sort of deal
Do not spam.
Do not post links to pirated books. You have been warned.
Not a huge fan of this idea.
I think I can just delete this point. I have my answer
&gt; For files I figured the basics of opening and reading files, will probably be covered in basic programming and from there will likely depend on the implementation is. So effective use of `select()`, dealing with encoding issues, dealing with interrupted transfers, using `readv` and `writev`, traversing directory tries (e.g. with `nftw`), dealing with file metadata and links, etc etc is all just unimportant? Personally I find this skill tree very weird. From a certain point it's all just slight varieties of the same libraries. This is a very skewed perspective.
No, don't! Do not ever delete your posts after receiving an answer! That's very bad style! All the people who have given answers spend time doing so. By deleting your point, you erase their answers such that they cannot be found by future readers. Do not erase the work of other people. Do not delete your posts.
It wasnt a spam. I was asking for opinion.
Cool. Could you provide some details on how you developed &amp; deployed this; maybe a link to the GH repo?
Your post tries to plug a product that is completely unrelated to C programming. That's spam.
I havent uploaded it to github yet, i pretty much just finished it a few hours ago, and im going away for a week on vacation later tonight so i will do that when i get home. Its really nothing special, and there is still a few bugs. I am really really new to real coding, and ive learned everything by doing, so its probably really poorly done. Altho, if i remade it now, it would be alot better since I learned how to print out an int value way to late. Im planning on making something more complex next, probably going to be Connect Four
why Low Level ( System Programming: drivers, osdev, etc ) don't be in Guide ?
Well, sorry for not understanding well. Firstly it's related to programming as it is a community for developers. Therefore, it is related to several topics as it's a broad field. Secondly it's not a product. It's completely free and we are not making ANY revenue from it. We are just starting with a project we would love to see happens. As it might have happened to you when you started this sub reddit you need to inform people about what are you doing so that they at least get the chance to decide if they are interested or not. Starting is difficult especially when you do something on your free time and out of pure passion. Once again, sorry for trying.
Sorry!! I didn't about that! It will not happen next time! Also I read my comment, and it was non-sense/selfish. Sorry about that
* Is your code written in C or some other language (i.e. C++, C#, Objective-C, Whitespace)? * Have you tried to type your question into Google? * Do you use `scanf()` for user input? * Is your code compiling without errors and warnings with "-Wall -Wextra -pedantic"? * Have you tried to use debugger to see what is going on?
Is it specifically about programming in C?
Nope but maybe those interested in C might be interested in our challenges about different programming languages every week. From C to JS or maybe they get interested from developing together collaborative projects written in C. Maybe the delivery could be improved?
&gt; Nope Then your post is off topic. Merely trying to get an audience of C programmers is insufficient for your post to be on topic. Do not post this again. If people wanted to see advertisements for random projects like yours, they would have subscribed an appropriate subreddit. &gt; As it might have happened to you when you started this sub reddit you need to inform people about what are you doing so that they at least get the chance to decide if they are interested or not. Nope. Never felt the need to do that.
Fair enough. Again, sorry about that.
The map was intended to come with a [post](https://www.reddit.com/r/C_Programming/comments/cep9zl/c_skill_tree_visual_guide_for_c_resources/eu426vf/) that describes what in the maps, and what resources are available for each step. Conceptually there are a lot more topics that could be included, but I didn't think it would responsible to throw in random links from google for tutorials and resources I haven't tested or verified.
The idea is that GtkGLArea can be approached from either the graphics side or the gui side.
&gt; Personally I find this skill tree very weird. From a certain point it's all just slight varieties of the same libraries. This is a very skewed perspective. It's a biased sample with some of the libraries I've tested and worked with. Conceptually there are more nodes that can be filled in, and I thought it would be better for people with experience to fill those in.
So, the point is that for an experienced C programmer, using these libraries is not really a skill. It's just another thing you do with your existing skills. The real skills are in algorithms design, data structures, software engineering, making effective use of the tooling, and general approaches to program design. Writing portable software requires skill as well. Using a new API after the first few times is just a matter of reading the documentation and then using it. It's not that each new library you used is a significant milestone in your journey towards C.
You're really new to programming and you made a game that deployed to the DS? Impressive mate. I assume it's a homebrew game on an R4 card?
These would cut down lots of meaningless questions.
In retrospect I think that's very true. It's not that you're working with provided tools as much as you become familiar with the fundamental structs and concepts and learn how and where to apply them effectively. Though after someone's first read through "The C Programming Language 2nd Edition", even though they've technically been introduced to 95% of the C code doesn't mean that they can probably go and write their own kernel now that they know the basic syntax. So idea behind the map is to provide a route and suggested resources for being able to start taking the basic syntax they've learned and applying it practically.
It's an adjective. The length of the array can vary at run time and is only determined when the array is declared. The length doesn't have to be a variable. For example, you could do: int foo[a * b * c + 42]; Note that while variable length arrays are very convenient, the amount of space on the stack is limited to something from a few kilobytes to a few megabytes. The compiler has no way to check if there is enough space left on the stack to allocate your variable length array and if you try to allocate more space than what is available, behaviour is undefined. Usually that means that the program crashes, but this can be exploited to take over your program. As a rule of thumb, do not use variable length arrays if the array length is derived from input data.
Do not post pictures of code. I have removed your post so you can try again with your code posted as text. Also post enough code for us to actually reproduce the problem.
If the Meson build system seams strange that's ok, I used to be a CMake build system user tell someone started talking about Meson. It also seamed strange to me at the time. But you never know it works tell you start comparing tools.
\*seemed I just have no need for all this extra complexity. And portability with Meson is worse. There is no way I can get a project with a Meson build system to compile on old Unices, like my trusty Ultrix 4.4 machine.
Thank you very much!
&gt;As stated in the original post, most of the resources I've stumbled across use python for examples. Maybe you could be gracious enough to share what C resources you know of. I prefer to do GPIO stuff in C and then create an extension to python. wiringPi is the library you want to use for GPIO stuff on the RPI.
My point wasn't about the reason for the connection, but that the connection makes your diagram not be a tree as opposed to just a directed graph.
Let me offer you a more complete example and a couple of challenges. Here's a function which will accept a `uint16_t *dat`, and `uint32_t length`. I claim that for any combination of values in `dat[0..length-1]`, it will return the index of the first item that matches a previous item, or 0 if none exist, provided only that using `memcpy` to copy an uninitialized item of `indices` will have no side-effects beyond leaving `index` holding an Unspecified value in the range 0..65535 [which--being Unspecified rather than Indeterminate--would be guaranteed to behave consistently in the two places it's used]. #include &lt;stdint.h&gt; #include &lt;string.h&gt; uint32_t find_dupe(uint16_t *dat, uint32_t length) { uint16_t indices[65536]; for (uint32_t i=0; i&lt;length; i++) { uint16_t item,index; item = dat[i]; memcpy(&amp;index, &amp;indices[item], sizeof index); if (index &lt; i &amp;&amp; dat[index]==item) return i; indices[item]=i; } return 0; } Your challenges are to: 1. Identify possible starting contents for `dat`, `length`, and `indices` where the function wouldn't work as described, and/or 2. Identify a reasonably-simple algorithm which would never read uninitialized storage, but would perform essentially as well in all scenarios (including those where the first duplicate occurs near the beginning, middle, or end of a long collection). Initializing `indices` at the start wouldn't materially affect performance in cases where there a long list had no duplicates, but would seriously degrade performance in cases where the first two items match. Using a linear-search algorithm would give good performance in cases where a match is found early, but horribly for a long list with no duplicates. Starting with a linear search, and switching to an initialized-table-based algorithm after some number of non-matches would yield poor performance in cases where the first duplicate was found immediately after the switch. If you can find an algorithm which is anywhere near as simple, and performs comparably to the above in all cases, without the ability to read uninitialized storage, I'd be genuinely curious to see it.
It does seem to be a bit overly restrictive.
No, i followed a guide that explained how to build it for the 3ds, and it builds a 3DSX file that i put onto my softmodded 3ds and launch with the homebrew launcher. The tutorial only covers how to build it tho, it doesnt teach you any coding
Plus, i know how programing works in theory, since im very good at Scratch 2/3
It is a noun. It is what you call an object which is an array sized by variables when the array is declared.
Just because they are not thread safe does not (necessarily) mean that they can't run in threads. You could try spawning a separate thread for each of the three libraries, and keep the main execution in its own. No guarantees though.... Another option might be to not let the event loops run on their own, but `tick' each one round-robin fashion, effectively doing the time-slicing by hand. You'll have to read the manuals very carefully to work out the best way to deal with this.
Couldn't have said it better
More constructively, I think you should scrap the idea of 'Basic'/'Intermediate' C and replace with nodes that describe C features/design patterns/functions that are relevant to the next topic/library. Like for GUI stuff you'd have function pointers and callbacks. File descriptors and I/O for sockets/network programming. May want to pick end point programs (3d game, unix-style shell, compiler) to sit on the outermost ring layer, then work backwards to a 'core c' node in the center.
I think your tree doesn't show the essential skills a "good" C programmer needs. On one hand, it is too specific, and on the other it is absolutely not. I guess you should first focus on the basic C aspect, and explode that node into many others. What about memory management ? That's a large and essential topic to care about when learning the C language. What about basic system programming ? No program could run without the system, so it is important for a C programmer to figure out what are the system specificities his program will run on, and how he can find information he needs. That's opening many other topics, like basic IO (what a file is, what are standard input and outputs, more globaly, how to get data from the user, and give him a result, because that's the point). C is also about tooling. You cannot be comfortable with C without knowing how to properly use the compiler, a debugger, a memory checker, a build system as other said. C is also about building things from scratch, at least compared to other language. Being a good C developer without knowing the basic of algorithm is a dream. I have colleague that doesn't even know what a linked list is, those kind of folk are handicaped programmers, and I'm sorry about that. I feel it's very fun to program basic data structures! I have passed many time of my C learning writing the same algorithms, and I'm ever doing that. Many other aspects are very important, like knowing how to deal with errors (that's a large topic, but a professional knows how to limit risks of seeing his porgram crash in production without having any idea of how he could fix it). I think that if you learn C without focusing on these aspects first, you will have trouble during your journey. However, knowing all I mention above (and many more) will make your learning of specific topics of the computer programming world very very more pleasant. One other thing is troubling me when I read your tree : you quote many libraries, but how could you be good using OpenGL if you don't know what a matrix is ? How the GPU works ? Theorical skills are very important, and are often a prerequisite to learn a library. Of course all of that is a very personal thought, but if I would have to give courses to someone that wants to become a good C programmer, I'll do it learning him the above topics. And then, going on more specific things like graphic programming or networking. Good luck !
In discussing features of programming languages generally, without reference to a particular language, the term \`variable\` refers to a region of storage which is identified by name and is not part of any other identifiable region. Many languages, such as Pascal, use the term in their language specification, with the same meaning. The authors of the C Standard, however, have opted to deliberately avoid using the term "variable", but don't define any other term with the same meaning. Instead, they opted to overload the term "object" to refer to variables, members of structures or unions, elements of arrays, or anonymous regions of allocated storage created with functions such as \`malloc()\`, or--in some platform-specific contexts--regions of address space that behave as anonymous objects of static duration. Whether it is better to use the term "variable" or "standalone named objects of automatic duration" would depend upon the anticipated level of pedantry of the target audience.
You made me recheck if I wasn't in /r/ProgrammerHumor with this one. But anyways, when you say "Its really nothing special" and "I am really really new to real coding" you are either hugely suffering of impostor syndrome or you just followed that guide and have no clue what you are talking about/you have done. Accomplishing a finishing GUI game (even tho it's tic tac toe) using tools like homebrew and make for a custom platform with its API is an astonishing step for a guy who says he's "really really new to real coding".
&gt; What are some practical programs you can make with C? All of them? Seriously, *every* kind of program can be, and has been, written in c.
Well so the guide didnt really tell me much i didnt know, only what programs i needed to build the actual game. It never learned me how to code one bit, then i worked off a preset that had the ”hello world” text, and i built of that. Ive now started my connect four game, and it works functionaly like a regular real game does (right now it doesnt tell you when somebody wins, and it doesnt keep score, and it has no colours on the placed pieces yet)
https://www.reddit.com/user/DrpeperoniYoutube/comments/cewusz/connectfour_wip_unfinished_build/?utm_source=share&amp;utm_medium=ios_app
What do you mean, "what's the difference?". Of course your code will be different to the solution given in the book - it was written by a different person. If you're convinced that you've solved the problem then just move on to the next exercise.
I agree with the impostor syndrome thing. What you did was great work and you should be proud of that. And you also sparked my interest in wanting to do something with my dusty 3DS. So thank you.
What do you not like? Is it the concept of having a template for questions, the idea of it being enforced automatically, or the particular template that OP suggested?
Im mostly saying its not that great is cause i was unsure if a smal little project fit in when i saw what others posted here
Answering questions is not the primary purpose of this subreddit and I don't want to install any infrastructure suggesting otherwise.
In practice it doesn't lead to errors because you use include guards. [https://en.wikipedia.org/wiki/Include\_guard](https://en.wikipedia.org/wiki/Include_guard) &amp;#x200B; Basically in every header file you put: `#ifndef MY_UNIQUE_HEADER_NAME` `#define MY_UNIQUE_HEADER_NAME` `// all your declarations go here` `#endif` &amp;#x200B; So the first time you include the header, the symbol MY\_UNIQUE\_HEADER is undefined and you include all the contents of the file. The second and subsequent times the body is skipped.
Normally you would put header guards around your header to prevent conflicts. #ifndef __MY_HEADER_H__ #define __MY_HEADER_H__ .... My header stuff.... #endif This way you can safely include the header in multiple files without worrying about if it has already been declared or not.
I'm using header guards. I assume 3rd party libraries are too? It's just, ok, I'm compiling with multiple source files...and so each source file has to include the same library. That has nothing to do with header guarding. Because its having to reinclude stuff. My thought is that this seems inefficient compared to trying to manage scoping so that you don't have to separate everything and include everything....
I figure the use cases for header guards are for IDEs and accidental excessive imports. They've nothing to do with actually needing to include something
epoll, non blocking io, is not basics my friend:)
\*Unix Did you trey it on an old Unix machine?
As others have said, you use include guards to ensure that each translation unit has a single copy of each header. I'll add that adding `#pragma once` to the top of your header is a less unsightly way to do this that is supported by any compiler you're likely to encounter.
Not sure what you mean by complex but all that's needed is this to start the simplest project in Meson. # Simple example. project('simple', 'c') src = [ 'source.c' ] executable('myexe', src)
Not sure what you mean by complex but all that's needed is this to start the simplest project in Meson. # Simple example. project('simple', 'c') src = [ 'source.c' ] executable('myexe', src)
Meson was designed to work on modern operating systems in use Windows, Mac OS X and Unix/Linux like systems, like my trusty Raspberry PI 3 or my Ubuntu docker image.
Here's what I would do: Spawn three separate threads, one each for gnome, libev, and some library. Each thread has its own event loop that reads events from the corresponding library. It doesn't do any processing, but instead sends those events through some threadsafe message-passing queue you create, to your main thread. The main thread then does all the actual processing on these events. The library being thread-unsafe may not actually be a problem. It may be possible that if you only ever read from one thread, and only ever write from another, that it works fine. However, as the sibling says, you should read the documentation very carefully.
I don't think most put double underscores around their header guard defines. It's not the sort of thing that people's own stuff is likely to conflict with.
Not with c#.
Well i just need help with the C part so i can use it from C# ! .. i havent got any help elsewhere really
So--you need help with writing c# code to interface with a c library.
Well what i need help with is creating a DLL with functions (figuring out how many images in a HEIC/HEIC file, getting thumbnails and images with an ID). The part to call those functions from C# is not a big problem. I am trying SWIG at the moment. I imported the Library into VS 2019, from CMAKE view i cant seem to be able to add files or edit properties! I want to create a file in the Project directory named "libheif\_Swig.i" containing this : `%module libheif` `%{` `#include "libheif/heif.h"` `%}` `%include &lt;windows.i&gt;` `%include "libheif/heif.h"` Changed the properties of this file (Custom Build tools/ Command Line: c:\\swigwin-4.0.0\\swig -csharp -c++ -outdir C:\\dump\\swig\\Generated libheif\_Swig.i Then just right-click libheif\_Swig.i and select ‘Compile’. This will generate those files in the Generated folder. cpp.cs cpp\_file.cs cppPINVOKE.cs and this file in the libheif folder cpp\_file\_wrap.cxx &amp;#x200B; But still trying to to get the library to load as a normal Visual Studio Project to try those steps
The point of header guards is to allow header files to include other header files that they depend on. For example, suppose you have the following header files in your project: * `common.h` * `foo.h`, which depends on `common.h` * `bar.h`, which also depends on `common.h` Because `foo.h` depends on `common.h`, any file that includes `foo.h` also needs to include `common.h` in order to compile without errors. You *could* do this by just writing two separate `#include` statements, but a much easier way is to just put the `#include "common.h"` *inside* `foo.h`, so that it's taken care of automatically. The problem is, if you use this technique, what happens when a file tries to include both `foo.h` and `bar.h`? Because both `foo.h` and `bar.h` depend on `common.h`, you'll end up including `common.h` twice, which will cause compilation to fail due to multiple-definition errors. The solution is to use header guards. With header guards, it's fine to include `common.h` twice, because only the first inclusion actually does anything.
You can dig up the sources for any open-source implementation like glibc/newlib/musl Here's musl's math library, for example: https://github.com/ifduyue/musl/tree/master/src/math
this seems like a great resource, but I don't think they have an ASM-implementation of the pow()-function?
I like what you did there with the design
Why should they? Its not a low level feature
Not every function needs to be written in assembly.
When you "include" a library, it's really just the preprocessor copying the library header file into your source/header file before the code is compiled. But it's just the library headers. Your code is compiled by the compiler and then the linker links all your object files and the library later. &amp;#x200B; So there's always just one copy of the library. If it's a shared library it's not a part of your executable at all. If you're linking statically, the library code gets included in your executable, but just once. &amp;#x200B; So if you #include&lt;math.h&gt; in 50 different source files, you don't get a bloated executable or anything (if that's what you're thinking about). libm is a shared library so the linker just makes sure your executable knows where to find all of the functions it calls. You use #includes so that each source file can see the declarations from math.h. Without the declarations (or macros) your code wouldn't compile.
yes, it's just that that is what I need for the project, so I hoped someone had maybe written documented code in Asm.
 int main(int argc, char **argv) or int main() are acceptable. The other forms are wrong, but *probably* won't break.
There are a handful of ways to compare implementations: * Algorithmically - via flow charts and block diagrams - you can already find the standard implementations, so this is pretty easy * Practically - via unit tests, also very easy * Actually - via compiling their function, outputting their assembly, and doing a comparison with your version. There's a GCC and Clang option to output the assembly
In my day we called those "handles".
You can try to paste the musl code into a tool such as [the compiler explorer](https://godbolt.org/), which will compile the function and show you which C lines correspond to which ASM instructions. It will not be really "documented", but it helps you understand how the asm generated works. It may also be useful to compare the output of multiple compilers available on the site to find the one you find easiest to understand.
Posting a photo without any code on a C subreddit...
Essentially as well? As far as I know, there is no faster way than O(n) to find a number in an unsorted array of n numbers, and that is exactly what you are doing, in O(n). You don't need your indices, you can just traverse the array from 0 to 2¹⁶ (or whatever) and simply look for your number. When I said I don't believe your premise is correct, I meant that you are not correct about that being any kind of "cross check" or proof of anything. You are just asserting self evident. Some number(s) between range \[0,2\^16\] will obviously give your x from your example which is just asserting a truth. That is why I already told you that I believe that you think too much. Just as a side note, in this example above, why are you mixing 32-bits with 16-bits numbers? You are only doing comparisons and assignements between 16-bit unsigneds. You are not performing any multiplications or additions so you can't get overflow and there is no reason to use 32-bit numbers. Since you are working with only 16-bits numbers your "length" can as well be 16-bit. &amp;#x200B; memcpy(&amp;index, &amp;indices[item], sizeof index); That is a costly and silly way to say: index = indices\[item\]; You could skip your index and item completely and just write: if( indices\[ dat\[i\] \] &lt; i &amp;&amp; dat\[ indices\[item\] \] == dat\[ i \] ) Finally, your check makes no sense to me, at least if you are trying to find a duplicate (if I interpret your function name correctly): What are you even looking for? You are trying to find if there is a number in range \[0,2¹⁶\] within your data on certain index iff that index is less than current loop iteration. Why? What does that give you conceptually? I don't understand what you are trying to assert or find there. You have two arrays of random numbers, one you call dat, and another one you call indices and you are trying to see if they contain same value on some index &lt; current loop iteration. ? Please educate me what is it good for. Are you sure that you are really comfortable with 2-complement, computer arithmetic, how machine work on low level, registers, bits, bytes and so on? It seems that you are too much in high-level thinking and that you are trying to solve a problem that does not really exist.
A Makefile for the same project can be omitted as make is smart enough to figure this out. Ultrix is a flavour of UNIX, look it up. If you only care about Linux variants, you have not understood portability.
Google is your friend: [https://github.com/EbookFoundation/free-programming-books/blob/master/free-programming-books.md#c](https://github.com/EbookFoundation/free-programming-books/blob/master/free-programming-books.md#c)
If hardware does not do what my program tells it to do, say save my file or input letter 'A' when my program tells it to, I would either change my program due to bug or by new hardware due to faulty machine.
If it is a school project you should take your time to learn the material and write your own and not copy-paste from the internet. If you are doing some project and pow function is your bottleneck than assembly version probably want help you much, you should look for algorithmic solution first. Otherwise, search for some optimized libraries like IPP or similar.
But people *do* come to this subreddit when they need help making their program work - moreso than /r/C_Homework, which was set up for that purpose. There's even a flair for questions. The way I see it, we can either leave things as they are; try to move the questions to another subreddit; or try to improve the quality of the questions. Which do you think is best?
It looks like a sorting algorithm for sorting an array of string after the length. The program itself init an array prints it then uses the algorithm to sort it and the prints it again
 #include &lt;stdio.h&gt; void func(int str_num, char *str[]) { int i, j; for (i = 0; i &lt; str_num; i++) { for(j = i + 1; j &lt; str_num; j++) { if (str[i][0] &lt; str[j][0]) { char *p = str[i]; str[i] = str[j]; str[j] = p; } } } } int main(void) { int i; char *str[] = {"cat","wolf","tiger","lion"}; for(i = 0; i &lt; 4; i++) { printf("%p\n", str[i]); } func(4,str); for(i = 0; i &lt; 4; i++){ printf("%p\n", str[i]); } return 0; } Formatted your code
It's sorting the str array in alphabetical order by the first letter of each string
Here's a version with self explaining output: #include &lt;stdio.h&gt; void func(int str_num, char *str[]) { printf("\n\nOutput:\n"); int i, j; for (i = 0; i &lt; str_num; i++) { for(j = i + 1; j &lt; str_num; j++) { if (str[i][0] &lt; str[j][0]) { printf("\n\nInfo: Arg %i\t-&gt;\t%s\n", i, str[j]); char *p = str[i]; printf("p\t(%p) = str[i]\t(%p)\n", p, str[i]); str[i] = str[j]; printf("str[i]i\t(%p) = str[j]\t(%p)\n", str[i], str[j]); str[j] = p; printf("str[j]\t(%p) = p\t\t(%p)\n", str[j], p); } } } } int main(void) { int i; char *str[] = {"cat","wolf","tiger","lion"}; for(i = 0; i &lt; 4; i++) { printf("%p\t-&gt;\t%s\n", str[i], str[i]); } func(4,str); printf("\n"); for(i = 0; i &lt; 4; i++){ printf("%p\t-&gt;\t%s\n", str[i], str[i]); } return 0; } Output: 0xd416b20d5e8 -&gt; cat 0xd416b20d60d -&gt; wolf 0xd416b20d5e2 -&gt; tiger 0xd416b20d628 -&gt; lion Output: Info: Arg 0 -&gt; wolf p (0xd416b20d5e8) = str[i] (0xd416b20d5e8) str[i]i (0xd416b20d60d) = str[j] (0xd416b20d60d) str[j] (0xd416b20d5e8) = p (0xd416b20d5e8) Info: Arg 1 -&gt; tiger p (0xd416b20d5e8) = str[i] (0xd416b20d5e8) str[i]i (0xd416b20d5e2) = str[j] (0xd416b20d5e2) str[j] (0xd416b20d5e8) = p (0xd416b20d5e8) Info: Arg 2 -&gt; lion p (0xd416b20d5e8) = str[i] (0xd416b20d5e8) str[i]i (0xd416b20d628) = str[j] (0xd416b20d628) str[j] (0xd416b20d5e8) = p (0xd416b20d5e8) 0xd416b20d60d -&gt; wolf 0xd416b20d5e2 -&gt; tiger 0xd416b20d628 -&gt; lion 0xd416b20d5e8 -&gt; cat &gt;!It puts the last string on first position, so the word cat gets positioned as last string, through ordering the pointers of char \*\*str!&lt;
That's awesome mate, well done. If possible kindly throw some light and share your ways on how to develop the same? . Anyways, I highly appreciate the same. Kudos !!! :)
no
it orders from z -&gt; a -&gt; Z -&gt; A. So it won't just order alphabetical
The MCU should have a set of registers for GPIO controlling. Since registers are 32 bit wide in this architecture you should be able to do something like this: volatile unsigned *reg = 0xAABBCC Now you can write into the register as you would write an int value. Maybe use uint32_t if available for guaranteed size. The addresses of the registers and the meanings should be documented somewhere.
The screen isn't enough.
This was surely a great job for a new programmer, but I agree with you. I think it's slightly off-topic.
Are you mixing up headers with libraries ? Even if you decided to avoid vendor libraries, peripheral address and bit definitions in headers are very useful. Wouldn't you rather write OSCCTL |= FOUR\_X than \*(int\*) 0xF0000123 |= 0x56 ?
Awesome man!
In the first piece of code you're summin A + B before initializing them with the values you want like you're doing on your second attempt
The issue you’re having is more of an issue of when you initialize the variables and when you define what C is equal to. In C/C++, all variables are really just a location in memory, and if you do not initialize those variables with your values, then they just keep whatever “garbage data” was in those memory locations before them. Because in program A, you define C before you define A and B with the values you want, you’re getting the wrong answer. In program B, you wait to initialize C until after you define A and B with the correct values.
The issue you’re having is more of an issue of when you initialize the variables and when you define what C is equal to. In C/C++, all variables are really just a location in memory, and if you do not initialize those variables with your values, then they just keep whatever “garbage data” was in those memory locations before them. Because in program A, you define C before you define A and B with the values you want, you’re getting the wrong answer. In program B, you wait to initialize C until after you define A and B with the correct values.
Thanks. I think I understand my mistake. I have to follow really step by step. in the first code: A takes a random value, because I don't initiate it. B takes a random value, because I don't initiate it. I do C = A + B I ask a value for A I ask a value for B And then print C. But because I don't declare now C= A + B, C will have the value of the 2 random values for A and B.
Thanks for the help. I think I understand my mistake.
This is the sub for C, not C# mate.
Damnit. Couldn't see anything for C#, thought it might be included. Thanks anyway. Cheers
There you go [https://www.reddit.com/r/csharp/](https://www.reddit.com/r/csharp/)
Very interesting.
So... for example if you type hello and ur string is: Hello he's happy. Then in that case your code won't be able to find that word. Is that supposed to happen?
Formatted code &gt;i = 0; &gt; &gt;printf("Ingrese una palabra clave \\n"); &gt; &gt;fflush(stdin); &gt; &gt;scanf("%c", &amp;cl\[i\]); &gt; &gt;while ((cl\[i\] != '\\n') &amp;&amp; (i &lt; MAX - 1)) &gt; &gt;{ &gt; &gt;i++; &gt; &gt;scanf("%c", &amp;cl\[i\]); &gt; &gt;} &gt; &gt;cl\[i\] = '\\0'; &gt; &gt;IniciePalabra = FALSE; &gt; &gt;Resultado = FALSE ; &gt; &gt;int pos = 0; &gt; &gt;i = 0; &gt; &gt;while ((s\[i\] != '\\0') &amp;&amp; (Resultado == FALSE)) &gt; &gt;{ &gt; &gt;if (IniciePalabra == TRUE) &gt; &gt;{ &gt; &gt;if (s\[i\] == cl\[pos\]) &gt; &gt;{ &gt; &gt;pos++; &gt; &gt;if(cl\[pos\] == '\\0') &gt; &gt;{ &gt; &gt;Resultado = TRUE; &gt; &gt;} &gt; &gt;} &gt; &gt;else &gt; &gt;{ &gt; &gt;IniciePalabra = FALSE; &gt; &gt;pos = 0; &gt; &gt;} &gt; &gt;} &gt; &gt;else &gt; &gt;{ &gt; &gt;if (s\[i\] == cl\[0\]) &gt; &gt;{ &gt; &gt;IniciePalabra = TRUE; &gt; &gt;pos = 1; &gt; &gt;} &gt; &gt;} &gt; &gt;i++; &gt; &gt;}
you are such a jerk
i really need help with this code. I´m new at this.
Not the hero we deserve, but the hero we need
Change the comparison to a common case e.g. all uppercase and use strstr to find the case insensitive match.
Finding a sub-string inside another string is a quite common algorithm and is called "regular expression matching". I'm not very familiar with doing it in C but here is a SO link that might help you : [https://stackoverflow.com/questions/1631450/c-regular-expression-howto](https://stackoverflow.com/questions/1631450/c-regular-expression-howto) If you have no idea what a regular expression is, you will find LOTS of explanation on the Internet.
Just make a function to transform a capital letter to lowercase. Like this ``` char toLowercase(char c) { if(c &gt;= 'A' &amp;&amp; c &lt;= 'Z') c -= 'A' - 'a'; return c; } ``` Then, when call this function when comparing if two characters are equal ``` if(toLowercase(s[i]) == toLowercase(cl[pos]) { } ```
I have to do it without using functions :(
What happens when you close() only the the socket you have listened on?
&gt; Essentially as well? As far as I know, there is no faster way than O(n) to find a number in an unsorted array of n numbers, and that is exactly what you are doing, in O(n). You don't need your indices, you can just traverse the array from 0 to 2¹⁶ (or whatever) and simply look for your number. You don't need your indices, you can just traverse the array from 0 to 2¹⁶ (or whatever) and simply look for your number. The function given algorithm is O(K) to search for *any duplicates* in an array of N elements, with K being the location of the first item that matches an earlier one, or N if no duplicates exist. Previously I was talking about finding a single number, but here I give the complete function to show how the 'find a single number' would be used in context. Using a linear search for each number would make the overall "find any duplicates" operation take time O(K²). Using an initialized table of size O(N) would yield overall execution time O(K+N). Without the `memcpy`, attempting to read an element of `indices[]` which had not previously been written would be Undefined Behavior. The use of `uint32_t` is to allow the function to check for duplicates in a list of precisely 65536 items [obviously any list of 65537 items that doesn't have a duplicate in the first 65536 slots would have a duplicate item in the 65537th]. Further, many processors are faster to work with arrays of 16-bit values than arrays with the same number of 32-bit values, but are faster to work with individual 32-bit values than 16-bit values. The ARM, for example, has no 16-bit registers. If `i` had been a `uint16_t`, the compiler would have had to use a 32-bit register, but process `i++` as `i=(i+1) &amp; 0xFFFF;`.
Not sure you need to. Can't you just stop calling accept?
There are a lot of things I would probably change here, but I think you can get away with just using the standard tolower/toupper functions. &amp;#x200B; Add \`#include &lt;ctype.h&gt;\`, and then in your code you will want to change your if-statements from \`if (s\[i\] == cl\[pos\])\` to \`if (tolower(s\[i\]) == tolower(cl\[pos\]))\`. &amp;#x200B; In general, I would consider looking at either copying the input strings and making them all lower/uppercase, or using \`strchr\` to simplify this. Also, consider switching from \`scanf\` to \`fgets\`, as it is intended to get line-by-line input.
Use godbolt to compile it down to asm.
I find post on reddit, not on google... simple, i think what your guide is not full
I well give it a look maybe it's available as a docker image. As for portability I test my projects on a Windows 10 desktop, Mac OS X, Raspberry PI3, Raspberry PI2 and finally both the Fedora and Ubuntu docker images.
In my day, the term "handle" was a pointer to a data structure that contained a pointer plus some ancillary information, and functions which expected handles would malfunction badly if given "fake" handles--pointers to pointers which did not have the associated information attached. To be sure, most programming was done in a language which could distinguish between: Procedure UpdatePointerSomehow(Var ThePointer: ^Ptr); {Pass a Ptr by reference } and Procedure DoSomethingWithHandle(TheHandle: Handle); { Pass a Handle by value } and most things of pointer-to-pointer type were in fact handles, while things of reference-to-pointer type, were, of course, not. C lacks proper pass-by-reference semantics, and thus uses pointer-to-pointer for both use cases, though in C99 and later, using a `restrict` qualifier when using pointers to fake pass-by-reference semantics would probably be a good idea. Incidentally, PalmOS did something that arguably the MacOS should have done: rather than allowing handles to be used directly as pointers to pointers, it requires the use of `LockHandle` to get a pointer from a handle. Although PalmOS wasn't multi-threaded, such a design would smoothly allow memory to be allocated by multiple threads, something the classic MacOS really couldn't do.
Read about polling, for example `select()`
What insane institution is forbidding you from decomposing a large program into functions?
&gt; Wouldn't you rather write OSCCTL |= FOUR_X than *(int*) 0xF0000123 |= 0x56 ? Generally, though Atmel's headers rather annoyingly use unions for everything, so one has to write `.reg` at the end of every single I/O related lvalue. While there are some occasions where the ability to *read* bitfields directly is nice, the semantics of writing bitfields aren't specified adequately to make such things safe. While the ability to say `TIMER-&gt;CREG3.MODE = 2;` would be great if C were extended to include the features of C++ whose semantics could be defined in terms of C, so that such a call could be processed as a call to an inline function like __MEMBERFUNC_TIMER_set_creg_mode(&amp;TIMER3.CREG, 2); which could then perform the operation in interrupt-safe fashion, the Standard has totally ignored the needs of embedded programmers, while stifling innovations to address those needs.
This seems like a really backwards way to learn. Why not start with a working example that the microcontroller vendor provides with their SDK, and figure out how it works? Either way, you'll definitely need your MCU's reference manual, which you can grab from ST in your case. The output value and direction of a GPIO pin driving an LED is controlled by hardware registers mapped into the MCU's memory space (you would typically also need to first configure various clocking subsystems to enable power to the MCU peripheral you're interested in - again, see the mcu documentation/examples). #include "stdint.h" // get fixed size types #define GPIO_DIR (*((volatile uint32_t*)0x40000200UL)) typedef struct gpio_periph { volatile uint32_t dir; volatile uint32_t outvalue; } gpio_periph; #define GPIO_PERIPHERAL ((gpio_periph *) 0x40000200UL) void test(void) { GPIO_DIR |= (1 &lt;&lt; 4); GPIO_PERIPHERAL-&gt;dir = 5; GPIO_PERIPHERAL-&gt;outvalue = 4; }
Hehe nice. You've actually refreshing my memory.. I'm thinking back to the Mac Plus days.. where the address space was 24 bits, leaving the upper byte of the handle available for lock bits and some other things. iirc MacOS did indeed allow "locking" of handles. to prevent the OS from moving the memory underneath. To access a bitmap via its handle, you would do something like bitmapptr = LockHandle(bitmapHandle) then fiddle with it.. bitmapptr-&gt;width and then UnlockHandle(bitmapHandle) when you were done. I'm actually kindof surprised the post didn't touch upon that. The main use for ptr to ptr imo is that it allows manual memory management and memory compaction without the use of an mmu.