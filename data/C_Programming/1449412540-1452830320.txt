C doesn't have methods either. Did you mean *function?*
When asking such questions always post the actual code. If you don't understand something you aren't in position to assume what is important in your code and what isn't.
Please show us more of your code. It's hard to tell what went wrong with so little.
because you have made an error somewhere else. post the full code.
Works fine on my system: #include &lt;stdio.h&gt; int main() { int lines = 20; int items = (lines - 2) / 6; printf("items = %d\n", items); return 0; } How do you determine the values of lines and items? With a debugger?
As much as I disagree with the way you say it, I have to say that reading the unix manual for all string functions is indeed what taught me the most.
Yeah, we need to see the context of the code. I'm going to take a wild stab in the dark though and suggest there may be a function call involved which is passing a parameter by value, changing that parameter and expecting the change to be reflected outside the function. If so you might want to take a look at [an article I'm working on](http://mikehigginbottom.com/wordpress/referential-semantics/) about exactly this problem.
What exactly is the question here? There are many tutorials on C IO on the internet (including fgets). I'd love to help more but there isn't a question other than "I don't understand"
woops! chars variable must have accidentally been deleted it should be: int chars = 0; as for the seemingly random values I was testing a .txt file and I was trying to get the outcome to match wordcount on word, not sure why but those values seemed to fit for the .txt file I was using.
No it doesn't: clang and icc also support it. Plus it's not for no reason; it's to gain the code quality benefits I already discussed.
It sounds like you're describing a GCC extension for variadic macros: #define Foo(x, y...) bar(y) is a GCC extension which has a similar effect as ISO C's: #define Foo(x, ...) bar(__VA_ARGS__) The ISO C version is slightly less flexible in that `...` must match at least one argument. So in the above examples, the GCC version could be called as `Foo(5)` which will translate to `bar()` . 
This is a learning experience for me. I could easily do this in Python, but I want to learn to do it in C. It's discouraging to try to accomplish something in C, find a hangup, and be told to just give up and not use C. I don't want to give up; I want to learn. No one ever learned anything from giving up something that was totally possible.
 &gt;case BOOL: if ( strcmp(val, "1") == 0 || strcmp(val, "true") == 0 || strcmp(val, "on") == 0 ) { c-&gt;val.val_bool = true; ret = true; } else if ( strcmp(val, "0") == 0 || strcmp(val, "false") == 0 || strcmp(val, "off") == 0 ) { c-&gt;val.val_bool = false; ret = true; } break; Condition statements are met if the expression evaluates to a non-zero value. c-&gt;val.val_bool = !(strcmp(val, "0") &amp;&amp; strcmp(val, "false") &amp;&amp; strcmp(val, "off")); If val == "0", strcmp returns 0. This triggers short circuit evaluation. Flip the value. 
Thanks! This looks a lot like the code I had issues with. I will change according to your suggestion.
For some context : I am trying to build the linux kernel library (lkl) with msvc instead of mingw (I have not used Windows in more than 8 years so it is a learning experience - trying to force square pegs through round holes is how I learn ;) ) I have made a vcxproj / sln file based on a list of object files from a mingw defconfig build so the compile can be done completely natively on Windows. Right now the compile chokes on some headers and this issue came back a few times, for example in the headers Include/linux/stringify.h Include/linux/compiler.h
I've been working on the median for a while now and its partly working. I mean it sorts it but it doesn't quite work properly.. for example If I enter 3 data's: 45, 89, 65 then it shows them as 89,65, 0.. for some reason the last integer comes out as zero. I would post the program I've written up but I'm scared that the plagiarism tool used by my college might think I took it from here..
There is almost no chance that the plagiarism tool would catch you on that. And even if it did, you could quite easily prove that you're the one who posted it. Without seeing your code, it's difficult to help.
ur right. i rtfm and it all worked. i was confused w/ getc returning int and stack overflow wasn't explaining it like the manual. also strcmp i had issues with and solved it by r-ing-tfm. I used some of the references ppl posted elsewhere in this thread
I'm really glad. The Dennis Ritchie book recommended above is very very good, if you take the time to read it. But if you don't have the time, that's what the man pages are for. If you want to go even deeper and understand computer systems, which you have to understand what is going on when you run code, I suggest Bryant and O'Hallaron "Computer Systems" There is a very good reason people have been responding to these questions with rtfm since the invention of internet forums. 
If you don't post the code then it will be difficult for us to help. An easy way to sort an int array is with two nested loops. You probably have an off-by-one error on one of the loops.
But he's also wrong there. A sentence ends with a dot and the next one starts with a space, so each end of sentence the program counts two words. There are some exceptions like if the sentence ends, and then there is a newline, or if it's the last sentence of the document.
I'll take a look. I need to get a better understanding of how code compiles and such. I kinda skimped over the whole understanding how assembly code works and how c code compiles and its gonna bite me in the ass if I don't go back over it over winter break.
C# has nothing to do with C. Ask /r/csharp
On line 107, you opened another set of brackets. It seems like you forgot at that point that you had done a do-while statement and were trying to have another iteration that loops. You took everything in the `do` block and pasted it below the `while`. And you added in another little set of braces to try to loop on that copy-pasted section. But the semi-colon after the `while` should have been a hint. The while ended. Anything after is just normal code totally unrelated to the do-while. I'm imagining you were trying to figure out why it wouldn't loop no matter what you input. And after copy-pasting your code, it seemed to work! Buuuut, it didn't. You won't keep looping. Even if you fix the `getchar` issue and actually stop looping when the user types anything but 'y' or 'Y', you'll still have another go at the whole thing. Everything from line 107 to line 200 needs to be deleted. The fact that you copy-pasted should have been a dead giveaway that you weren't really solving the issue. Once you get rid of everything from line 107 to 200, delete the extra closing bracket after the `return 0`. But once you do that and fix everything else, there's still a potential issue. But it's not a big one. Your do-while starts before you ask the user for input. This means that every time you go around, you're writing over the same variables and such. There's a couple of potential problems here. First, your professor may not want you to have to input everything all over again. Second, your professor isn't giving bonus marks for starting over once everything is done. He or she is giving bonus marks for something much more difficult: being able to restart from scratch whenever you want. He or she is saying that if you set up your program that at every step along the way you can type something like "restart" and it'll just go back to the beginning then you get bonus points. That's definitely more difficult and worth the bonus. Anyway, hope this helped.
Fantastic answer, just one thing. The mode is the most common value. So in the set `1, 2, 2, 3, 3, 3, 4` the mode would be 3.
Yes, thank you, this was what i was looking for! I'm still not sure, though, how to use the `temp` variable. I do understand that I should use it later to swap places in the series array (right?). Is the `temp` also an array? How would i go about swaping them? Edit: Well I do know *how* to swap them, but what Im trying to say is, why is that varible needed? Isnt the series array all i need?
Yes, thanks. That's such a stupidly simple thing to muck up.
Wow. this is really, really good. Thank you for this but I have a few questions: Firstly, I don't understand what you mean by re-initializing i (line 77 onward.) I thought that if I just used the value of i already set when running the program then it would store that number and use it once again.. So if I reinitialize it, doesn't it bring it back to zero? Also, I don't understand the last paragraph /: specifically when you're talking about newline character.. We haven't really covered that in class but it seems like information that I should know off so I'm going to read a little more about it on google right now.. lastly, i dont quite understand what you mean by the if else command on line 85.. I guess its bad practice but how do I make it good practice? :| Will switch case work there? YAY! I'll be waiting for Part 2.. I cannot thank you enough for this. (:
ive posted the code
ive posted the code
&gt;Firstly, I don't understand what you mean by re-initializing i (line 77 onward.) I thought that if I just used the value of i already set when running the program then it would store that number and use it once again.. So if I reinitialize it, doesn't it bring it back to zero? At the start of the program, you initialized `i` to 0. In the `for` loop starting on line 30, you used `i`, incrementing it with each iteration of the loop. Once the loop is finished, `i`'s value has been changed. After that `for` loop, the value of `i` is equal to `size`. Once you get down to the `for` loop on line 77, you use `i` again, but its value is `size`. So `j &lt;= size+i` is equivalent to saying `j &lt;= 2 * size` (because n + n = 2n). The fact that you didn't reinitialize it is a problem because you use it as a bound on a loop that accesses an array. `z` is only `size` elements wide. But you are trying to access 2*`size` elements. You will run into trouble as soon as you try to access the `z[size]` when `size` &gt;= 10 (because you declared `z` to only store 20 `float`s and 10 * 2 = 20). But that only highlights the *larger* problem which I pointed out: your sorting algorithm is borked. It doesn't do what you want it to do. If it did what you wanted it to do you probably wouldn't be using `i` at all, and so you could just leave it alone. &gt;Also, I don't understand the last paragraph /: specifically when you're talking about newline character.. We haven't really covered that in class but it seems like information that I should know off so I'm going to read a little more about it on google right now.. Okay, then I have a question for you. On line 101 you did `repeat = getchar()`. Then on line 103 you did `getchar()` by itself. Why did you do this? The fact that you're asking the question leads me to believe that you were just copying it as a pattern that your professor demanded without understanding why you were doing it. That's not a problem. We all do it eventually, but it's not a good way to learn. So I'll explain. When you call `scanf` your program waits for the user to type something into `stdin` (read: standard in; AKA the console) and press enter. So let's take a simple program. #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main() { char * name = malloc(5); scanf("%s", name); printf("%s", name); free(name); return 0; } If you run that, the program will wait for you to type something. If you type "test" (without the quotes) and press enter, it'll just print out "test" (without quotes) and exit. Now what actually happens when you type "test" is you add the following characters to `stdin`. 't', 'e', 's', 't', '\n' `stdin` is a buffer. In this context, that means it stores the characters temporarily until you use them up. `scanf` watches `stdin` until characters appear in it. But when does `scanf` finish? Well, it waits until it sees whitespace. Whitespace are things like tabs ('\t'), spaces (' '), and newlines ('\n'). When you press enter, you add a newline ('\n') to the buffer. So `scanf` sees 't', 'e', 's', 't', and adds them to `name` one at a time. When it sees the newline it stops, adds a null-terminator ('\0') after the last letter it put into `name` and then returns. So here's what `stdin` looks like when you press enter: t e s t \n And here's what `stdin` looks like after `scanf` returns: \n There's still a newline in the buffer! So what happens if I call `scanf` again? Well, luckily if `stdin` *starts* with any whitespace, it just ignores it. So say we add another call to `scanf` in our example. Then we type "test" again and press enter. Here's what `stdin` looks like: \n t e s t \n `scanf` sees that first newline and just throws it away. It picks up the letters, adds them to `name` and then returns when it sees the last newline. Afterwards, `stdin` looks like this: \n Again! A leftover newline! Well, what if after calling `scanf` that first time, I just wanted to get a single character? Well, that's what `getchar` is for. It pulls a single character out of `stdin` and returns it. So if after our printf we add a call to `getchar` what'll happen? Well, the program will pause just like it did for `scanf` and wait for you to type something. So let's say I type 'y' (without quotes) and press enter. What does `stdin` look like? \n y \n Unlike `scanf`, `getchar` does not ignore whitespace. It just picks up whatever character is first. And what's first? The old, leftover newline character! This is *exactly* what's happening in your program. You are using `scanf` to get a bunch of user inputs. Then you're using `getchar` to get a single character (asking for a 'y' or a 'Y'), but you're picking up the old, leftover newline character from the last time you called `scanf`. So `repeat` has a newline character, and '\n' is obviously not 'y' or 'Y' so the while loop never does another iteration. Hopefully that clears that up. &gt;lastly, i dont quite understand what you mean by the if else command on line 85.. I guess its bad practice but how do I make it good practice? :| Will switch case work there? On line 85 you have this: if(size % 2 == 0) median = (z[size/2] + z[size/2 + 1])/2.0 ; else median = z[size/2 + 1]; Normally, `if` statements are written with a pair of opening an closing brackets like this: if (condition) { // do stuff } However, if the "do stuff" only takes up one line, you don't need to add the brackets. The same applies to loops like `while` and `for`. Which is what you did. You omitted the brackets because you don't need to do them because the body of your `if` was a single line. But this is bad practice. It is very easy to mess up and cause all kinds of problems in your program, and it can be very hard to track down those types of problems too. Just avoid it altogether by always writing the brackets. The fact that you asked me if you should put a `switch` statement, though, worries me because it makes me feel that you did not fully understand why I suggested you use a `switch` in another portion of the code. That's okay! It's okay to not understand something, but if you don't, you should definitely ask questions. The `switch` statement is a neat way of handling a massive chain of if-elses when the conditional chain is testing various possible values of *one variable.* In other words, the `switch` statement turns this: if (condition == 1) { // do hinky stuff } else if (condition == 2) { // do slightly different hinky stuff } else if (condition == 3) { // so much hinky stuff } // continued ad nauseum Into this: switch(condition) { case 1: // do hinky stuff break; case 2: // do slightly different hinky stuff break; case 3: // so much hinky stuff break; // continued ad nauseum default: break; } Which is generally easier on the eyes and brain. You can read up on the `switch` statement [here](https://msdn.microsoft.com/en-us/library/66k51h7a.aspx) with many example usage and stuff. Hopefully that helps clear that up. &gt;YAY! I'll be waiting for Part 2.. I cannot thank you enough for this. (: Part 2 is the response I made to my own post. You can find it [here](https://www.reddit.com/r/C_Programming/comments/3vrcrk/help_need_help_understanding_how_to_find_the_mode/cxq5x0e).
We don't know what the `temp` variable is used for without seeing the rest of the code. One use case would be to swap teams in the array, possibly to sort by points. `temp` is not an array, it is a single struct. Following the previous example, after Arsenal wins you might want to move them to the top of the list. Determining which teams to swap is outside this scope, so I'll just show one example temp = series[0]; series[0] = series[1]; series[1] = temp;
Okay. Good luck with that! :)
I wish you good luck with that, too, although I would just use sed -e 's/word//g' for that purpose.
If you're allowed to replace the word with a blank spaces it's trivial, if you don't want blank spaces it's going to be a little more involved. Start with the first way. You said you're already going through the text and finding each place the word occurs. It's not much of a step from there to set those characters to be spaces. 
i think replacing it to blank spaces works. but how do i do it so it only removes a word "HELLO" and does not remove the same letters from other words
You added that later. Anyway, I would implement a string searching algorithm like [KMP](https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm) and amend it to output unmatched characters, dropping all matched characters.
&gt; any pointers? https://xkcd.com/138/
[Image](http://imgs.xkcd.com/comics/pointers.png) **Title:** Pointers **Title-text:** Every computer, at the unreachable memory address 0x-1, stores a secret. I found it, and it is that all humans ar-- SEGMENTATION FAULT. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/138#Explanation) **Stats:** This comic has been referenced 93 times, representing 0.1020% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cxqhjwg)
It will output the character 0. How do I know? I took your two lines, added "int main() {" before and "return0;}" after and hit compile. While I don't really want to be rude this question is... I mean, seriously? It would have been shorter to actually test it yourself than writting a reddit post.
The `&gt;&gt;` operator does not modify its operands. Seems like you have a misconception there. Only operators ending in `=` (except for comparison operators) and the `++` and `--`operators modify their operands.
Yeap. Thanks anyway :)
++, --
Thank you.
OP is using `scanf` already. Don't be so condescending.
The current problem is the way scanf works. If you try looking at the character that gets read into ctrl, you'll see that it actually reads the enter key that is left over from the last scanf call, instead of waiting for you to write a character. To solve this, try changing that scanf call to `scanf(" %c", &amp;ctrl);` (mind the space before %c). This tells scanf to throw away any whitespace it finds before reading a character. Secondly, using goto is generally considered harmful, because they make your code harder to read (The goto part actually works if you want to keep it, though). Have you learned about do-while loops? I'd suggest putting the entire code in a do while loop. They look like this: do { // Do some stuff... } while (this is true); The body of the loop will be executed once, and if the condition at the end is true, it will loop back to start, which is equivalent to what you were doing with goto.
Mem mgmt - If hard for complex structures, scrap and refactor in tighter units (substructs) from minimal test case? Er... Something that drives me up the wall at present is my inability to get expected warnings even though I have for some time used "-Wall -Wextra -Werror -Wpedantic -Wimplicit-function-declaration" (and many others which -Wall might miss). E.g. the other day I was getting a corrupted float passed into a function - though source value was 100% just before the call - because I'd forgotten to include the necessary header for the function I was passing the value into (which I assume should cause an error, but does not). Nothing online prepared me for this, and it was only the memory of the last time this happened that got me to a solution. Maybe it's the way I include headers - always in other headers, never in source except for the associated header (i.e. test.h for test.c, etc.).
I agree with everything you said. I'd like to add that as far as memory management goes, especially in trees, recently I implemented a k-ary tree in C of massive size (usually 2GB in ram) and releasing it in an efficient way seemed almost impossible at first. I tried recursive methods like post-order, pre-order or euler but for some reason valgrind always showed me leaks. Finally I did a singly linked list with two members; a next and a pointer to void. [Here you can see what I mean, ignore the other things in the code it's in a very early stage, but as far as memory management goes you can allocate GBs of memory and free them that way quite easily](https://github.com/Gikoskos/ChessLib/blob/master/lib/chlib-computer.c#L29). Basically I add all malloc'ed pointers to the list as void pointers and free them in the end. Valgrind shows no errors or leaks so far. [Also here is how I add the pointers to the list](https://github.com/Gikoskos/ChessLib/blob/master/lib/chlib-computer.c#L176)
Makes sense from the viewpoint that releasing in order of allocation would be the most efficient for cache purposes? - singly linked list stores exactly that.
I'm tentatively suggesting that just as keeping data tightly packed in memory benefits _reads_ by minimising cache misses, it's possible that deallocating in order of alloc benefits _frees_ the same way, due to the way cache reads ahead (e.g. an 8mb L3 cache is going to pull in a lot of the elements you are just about to free). Pure conjecture on my part.
Come on, man. Python is a great language but this isn't really the place
The `continue` keyword will immediately stop executing the loop and jump back to the start of the loop. The `break` keyword will immediately stop executing the loop and jump out of the loop. In both cases, execution flow never reaches your `printf()` line. If you want the `printf()` to happen you need to remove one of those commands or put the `printf()` before the `if`.
For this specific issue, perhaps a linter would help? &gt; the way I include headers - always in other headers, never in source except for the associated header (i.e. test.h for test.c, etc.) I take the approach that the header should only include what is needed in the header. Any includes needed only in the implementation are included in the implementation. This makes the relationship clear, reduces complexity of other files that include my header, and lessens the need to reocmpile other files if my implementation changes. 
Hah. I missed that. OP: You need to use scanf again, then make a string with your custom shutdown command. Try using printf to insert the number.
&gt; (which I assume should cause an error, but does not) You should compile with `-std=c99` or whatever you like so the compiler considers implicit function declarations an error. Generally, gcc chooses a pretty weird C dialect (gnu89) by default and you should really use `std=...` to make it conform to ISO 9899.
I do, yet oddly... no go. &gt;CFLAGS = -I$(LIBDIR) $(INCLUDES) -std=c11 -m$(BITS) &gt;-fms-extensions &gt;-fopenmp &gt;-fstack-protector-all &gt;-Wstack-protector &gt;-Wall &gt;-Wextra &gt;-Werror &gt;-Wimplicit-function-declaration &gt;-Wmissing-prototypes &gt;-Wpointer-arith &gt;-Wcast-qual &gt;-Wstrict-prototypes &gt;-Wlogical-op &gt;-Wcast-align &gt;-Wconversion &gt;-Wpedantic &gt;-Wfloat-equal &gt;-w -O0 -MMD` (though admittedly this was re-ordered for display here)
That's really weird.
Agreed. I'll supply the full build script and details on the MinGW distro used, but I don't want to clutter this thread which should be about the experiences of others. Note: Linux builds same code with expected errors, typically(?).
I'll repeat my suggestion for a good lint utility. It can augment compiler messages quite nicely. In Linux, I use splint and cppcheck (which is really for C++, but it helps a lot). I haven't done much work in Windows in a while, but I recall reading about a couple of really good lint tools for Windows. 
Thanks for sharing your experiences. I use klib (kvec and khash) also, but though it's pretty damn fast, I must say I still find the interfaces a tad annoying. `typedef`s help with that but `typedef`s also obscure what is going on under the hood (can be good, can be bad). I'd also written my own generic map &amp; list before I used klib... much slower!
[Done](https://www.reddit.com/r/C_Programming/comments/3vy0tp/werror_should_be_showing_warnings_and_triggering/). Was unsure how such Q's would be received here - better to be invited to do so!
I already tried doing that. I remember doing strcat("C:\\Windows\\System32\\shutdown.exe -t ", customTimer); but to no avail
To be fair this may hold true for entreprise level C or some variation of a desktop application. However I would argue that there is a limit to what you can do with python as it exists today, even with the use of cython or even GPU resources. Also consider that a very large volume of the 'C' code written today will be for an embedded standalone system (baremetal) or for an application running on some flavour of RTOS. In those scenarios you don't really have that many options but to use some choice of C, C++, or Ada. Regarding day to day stuff like task automation, managing test runs, etc. Then absolutely use python's path of least resistance! So in reality as designers/engineers we should aim to be tool agnostic and focus on the right tool for the right job rather then try and transform the problem into the 'nail' to slam with our prefered 'hammer'. Or as a good old Prof of mine would say "in Engineering the correct answer is always: ...it depends!!"
POSIX pthreads act as a 'de facto' standard for multithreading but it would be nice to have an actual explicit thread support in the C standard. As an example I feel like a lot of what the Ada language comittee has done with 'Tasks' is bang on. However as a pleb I would struggle to make a business case to switch half of the world's embedded code to Ada. So yeah!... I guess that would be my pet peeve with C... Multithreading. 
If you have a "char *", you can pass it in to a function that wants a "const char *". The 'const' in the function prototype simply tells you that the function won't/can't/isn't supposed to try to/ modify what's pointed to. system("constant string"); system( strPtr ); These are functionally equivalent, if strPtr contains "constant string". Maybe you could use a function like printf, but one that targets char strings instead of standard out. See the printf man page for a list of functions that are similar but work on different kinds of outputs.
Many are criticizing the relatively low performance of Python. Writing python in python? It would just die.
You mean like those threads added in C11?
Is splint not-dead? Last I checked years ago they had no support for really basic stuff like C99 for loops, it just died and called them a syntax error. I'm not a fan of my lint checking me against the best practices of 20 years ago rather than today.
Not only that, but fewer inter-header dependencies means you're less likely to get the always fun circular header loop, which is something I always adore.
True. Header guards help, but they are ugly. 
Fair point ...is there an industry grade compiler (that I could use today) that my boss could throw money at, which does supports C11 thread features? edit: 'industry grade' as in Keil or IAR
...Suggesting that C is not the best tool for games, simulations and other real time applications? Because that's what the OP - me - is using it for. Why even go off on this rant? It's simply a waste of space. I've considered more established, more efficient, more cost-effective options than Python for games / sims (e.g. C++, Unity / C#, Java), all of which came off second best for current requirements, all languages I had more prior experience in than C. How do you think Python fares on that scale, then? Your initial response remains as off-topic as it is possible to be. Assume the focus of this question to be C - as titled.
&gt; Suggesting that C is not the best tool for games, simulations and other real time applications? The answer to this question is (almost) always "It depends what you're doing", and how much of each language you know. If you're doing something that needs as much speed as possible, use C, obviously. If you know python and C about equally, and don't need as much speed, write the intensive parts in C and the outer code (to which speed doesn't really matter) in python. If you're writing a simple webserver, do that in python, there's one in the standard library. &gt; Your initial comment remains as off-topic as it is possible to be. This is a C forum. People don't have issues talking about C in /r/python. Every language has some things that it's shit at.
What part of this topic's title asks about people's experiences and epiphanies in Python, @5225225? There is this popular concept on the interwebz known as "on topic" for good reason. Or shall we talk about cars, sports, and what you did last Sunday, as well?
Guess you've never seen Stackoverflow then. Fair enough.
gcc and clang both support it I think, but it seems like there's no commercial compiler that supports C11, including MSVC, which would be useless for embedded anyway.
 $(SolutionDir)Lib Try $(SolutionDir)\Lib 
That or specifying full path seem to get rid of that error but am now getting the following errors: http://pastebin.com/cECb3YpC
I just don't understand why you couldn't just google how they worked, seeing as you were able to find out where in the code your mistake was?
It only happens when I try to import capstone library even though the errors seem to point to errors with other libraries
Some additional info about *continue* vs *break*. The *continue* keyword will jump over the code that follows it and land at the point **before** the closing curly brace of the loop that encloses it. In your example, that point is the line before the closing curly brace of the for loop. The *break* keyword will jump over the code that follows it and land at the point **after** the closing curly brace of the loop that encloses it. In your example, the point is the line after the closing curly brace of the for loop. For a visual of *continue* in action, modify your *if* statement as shown below and run the program: if( i &lt; 10 ) { printf( "%d - continue\n", i ); continue; } The output you should see is: -1 - continue 0 - continue 1 - continue 2 - continue 3 - continue 4 - continue 5 - continue 6 - continue 7 - continue 8 - continue 9 - continue
&gt; I keep SomeType_init separate from SomeType_construct This is called *two-phase initialization*. A major problem with it is what to do with entities where the first phase succeeds and the second phase fails. If you undo the first phase in this case (or if the second phase *cannot* fail), you may as well have used single-phase in the first place. If you don't undo the first phase then you have a "zombie object" and all the rest of your code that might use this object has to have extra handling to know what to do when it gets passed a zombie. It leads to the code that uses these objects being overly complicated. The main purpose of RAII is to avoid guff like: if ( bla fails ) goto cleanup; bla bla if ( bla bla fails ) goto cleanup2; bla bla cleanup2: if ( ptr ) free(ptr); cleanup: if ( bar ) fclose(bar); (someone on this sub actually recommended this to me the other day). This sort of code structure quickly descends into spaghetti, and/or takes an inordinate amount of time to manage and maintain, and runs the risk of making a bug where you clean up variable that actually didn't need cleaning and so on. 
The first part of your comment is just... tiresome. This discussion has been had, elsewhere. It is unproductive. This post addresses the [second part](https://www.reddit.com/r/C_Programming/comments/3vy0tp/werror_should_be_showing_warnings_and_triggering/) in full. 
At the risk of sounding vague, I'll explain why I'm not convinced. There is the concept of _phase symmetry_, which is not a thing I can concretely prove is needed, but rather something I've found over time to be a way to make my code make sense and that avoids associated niggles for lifecycle phases like those under discussion. By symmetry I mean that just as `dispose` counters `construct`, `clear` (or `deinit`) counters `init`. `clear`/`init` can indeed be separated into distinct categories / processes / pairs, since it may indeed refer to several distinct logical aspects per object type. Assuming we could still recover from failed object creation / initialisation, this way assures that we are not conflating more `init`/`clear` than is necessary into a single phase - conflation of concerns generally being a Bad Thing which is one major reason I disagree with RAII - i.e. we only step back through those phases we need to step back through, instead of gutting everything in order to retry. And this makes it easier to pinpoint in logs the point at which the failure occurred - i.e. _why_ it occurred. Another point is that generally when `dispose`ing, it is not necessary to `clear` since you are deallocating the object anyway. But when using object pools - an oft used pattern when avoiding excessive alloc at runtime as for performance reasons - this can become the incorrect way since you may indeed want to explicitly clear state from objects going back into the pool, to avoid later debug confusion given zombie state. This distinction means I like to have control over when we do and when we don't `clear`. ...These are my primary reasons going against RAII. If there are aspects of it that I've misunderstood, inform me. What I'd like to know is under what circumstances the latter phase can fail. I can realistically see the first phase failing if e.g. heap memory were no longer available. In my use case, the only circumstances I can see causing the latter phase to fail is where we are talking about a configurable object failing to read the correct config from a file, or a render-related object failing to acquire the necessary resources to exist. Both would to my mindset (note: possibly flawed!) have been picked up at a phase earlier than new object construction and thus either been prevented altogether or have kicked off an `exit(EXIT_FAILURE)`, and thus `atexit()` etc. - an orderly retreat. I'm all ears where possible architectural flaws are pointed out. But I fail at this stage to find concrete evidence that this is a likely outcome in _any_ circumstance for my use case. Perhaps were I working on a different sort of thing (more complex?), I might be far more inclined to trust my objects to the conflated RAII / RRID idiom. Having said all of that, if the `cleanup` attribute is available on all target platforms, I've no problem with using it _where appropriate_. I only really take issue with having such decisions made _for_ me by the language.
Wait, slowed me down.... uhm... hold on... oh yeah there's a library for that, otherwise slowed me down how exactly? Sorry, I am a bit of a C snob. I prefer it over C++, and many other languages these days. But I admit it has it's issues. No language is perfect. * Well if your OOping to much in C you are doing it wrong sir. There is a bit of OOpness sorta if structs and structs in structs and so on, but really C isn't really designed to be OO. You can be OO like, but you shouldn't depend on that. You need to look at the problem in a different way usually and I found that way works perfectly well. Usually just using a struct and functions to work on those structs is the standard C methodology (with handy prefixed names). You can use function pointers inside structs if you really really want it to act OO. * Never really had a problem with the File I/O in C. Though that stupid as hell streams crap in C++ is so damn stupid and annoying in every way I can think of. String management in C is easy for me really, a did write a few new string functions to help me out (actually a poor man's utf8 library that just replicates the c functions but for utf8), but otherwise not so bad. * I always run as pedantic, getting into those compiler specific extensions tends to make debugging a major hell. Most of them are fluff that no real C programmer needs if they know what they are doing. Otherwise just don't screw up, I kid, I kid, but seriously make sure to have an idea what your routine needs to do before you do it, and try not to copy pasta. * Well, not initializing your variables is sometimes the right thing to do, but usually not. C++ doesn't do this for you either, you have no excuse unless your coming from an vm/interpreted/modern language. Keep in mind C is pretty old. * Okay, you got me there, C doesn't really do well with those. Thought C11 seems to have solved some of it with the _Generic keyword. But I suggest typedef over macro or void * if you have to do it that way, at least so you have some indication of what you expect to get * Memory management isn't so bad, just takes some getting used to doing. The biggest problem is getting data back from libraries that may have been malloced by the library (which honestly is a big fat no no, libraries shouldn't be doing that, but it is sometimes unavoidable).
That post doesn't include any code samples. The description of code in the "Additional info" is extremely vague. Do you mean that you intended to have `#include &lt;tgmath.h&gt;` but didn't, so a mathematical operation was performed in double precision instead of single? Maybe it'd be worth your time to distill a standalone example of the problem, then we could advise on how to avoid that particular class of problem. 
&gt; `CFLAGS = -I$(LIBDIR) $(INCLUDES) -std=c11 -m$(BITS) -fms-extensions -fopenmp -fstack-protector-all -Wstack-protector -Wall` &gt; `-Wextra -Werror -Wimplicit-function-declaration -Wmissing-prototypes -Wpointer-arith -Wcast-qual` &gt; `-Wstrict-prototypes -Wlogical-op -Wcast-align -Wconversion -Wpedantic -Wfloat-equal -w -O0 -MMD` The `-w` near the end, means **Inhibit all warning messages**. This renders your previous `-W` flags redundant (later flags override earlier flags that conflict). /u/danielcamiel's example produces a diagnostic , so long as you don't put `-w` in to suppress it. Also, `-Wall` implies `-Wimplicit-function-declaration`. 
Superb. Nailed it :)
&gt; -o tmp.exe tmp.c -lnlopt-0 Alright so it compiles but it doesn't run :/ http://i.imgur.com/uKGmcFV.jpg
That's some error specific to Windows and I don't know what it means. My guess is that you're mixing 64-bit and 32-bit somehow.
I'll take heat for this, but I go for code that is clean and clear, and will trade some things that are complicated and buggy for more simple and legible articles. Like arrays over doubly-linked lists. I know the advantages of linked lists - you can add items to infinity is one (no others occur to me rt now). But if I can make a good assumption about the max count of an array, you bet I'll go with the array. It's also possible to re-alloc an array (for more indexes and space), and although slightly complicated, the result is still more readable, maintainable and less buggy than a linked list. Hate on me now, go ahead, do it. Anyway, that's just one example. For my experience, simple code is often solid code, and maintainable code too. 
Thank you, exactly what I was looking for. Thanks for loop suggestion too!
21st Century C is pretty neat. I don't know of any book about C11 specifically though.
Don't use `atof()`, it doesn't do error checking. Use `strtod()` or `scanf()`.
Yes, it's possible. How is the input file structured? Is it in plain text? Or does it contain binary numbers? Generally, you would need to compute the offset at which the datum of interest occurs, then `fseek()` there and finally overwrite it with `fwrite()`.
Thanks for the tip. Does strtod() or scanf() have problems with scientific notation?
Excellent, thanks.
There's really not much that changed in C11. I'd look at 21st Century C, which is commonly recommended for "modern" C. 
I have a question for you about using strtod() if you don't mind. [This website](http://www.tutorialspoint.com/c_standard_library/c_function_strtod.htm) gives a description of the parameter "endptr". In the description it says that if endptr is **not** NULL, a pointer to the character after the last character used in the conversion is stored in the location referenced by endptr. Should I not initialize my char * to NULL before I pass it to endptr? Is endptr just a pointer to the element after the last char number in my char array? Will it cause me problems if I pass a NULL pointer to endptr? Edit: Disregard this question, I think I found online that it's OK to pass a NULL pointer to strtod() in parameter endptr if you don't care about the pointer to the next char.
I don't know how your device is set up, but this code looks like it's going into an infinite loop and never reaching your output code: if (SysTick_Config(SystemCoreClock / 1000)) { while (1); }
I did try removing that at the past but then nothing worked. The system tick timer just stopped working. My device is basically meant to be operating as a smart meter where the voltage cannot go more than 25 kW, i managed to set it up to a point where the Voltage 1000 is printed every second along with a green led which is also coming on every second. When i began to add stuff to make it so the potentiometer controls the values of the kW and print them out. It stopped working all together
 #define X 3 #define Y 3 #include &lt;stdio.h&gt; int main(int argc,char*argv[]){ FILE *fp; int a[Y][X],i,j,x,y; fp = fopen("data.txt","r+"); if(fp==NULL){ printf("Errore in apertura"); return(1);} for(j=0;j&lt;Y;j++) for(i=0;i&lt;X;i++) fscanf(fp,"%d",&amp;a[j][i]); fscanf(fp,"%d %d",&amp;x,&amp;y); a[x][y]=0; fseek(fp,0,SEEK_SET); for(j=0;j&lt;Y;j++){ for(i=0;i&lt;X;i++){ fprintf(fp,"%d ",a[j][i]); printf("%d",a[j][i]);} printf("\n");} fclose(fp); return(0); } This is the whole code, the blank line is where I should add the output part, but I'm still looking for sources that explain thoroughly how to do it. The input file contains only the integers needed for the program to run detached by blank spaces. (I'm getting started in these days with different I/O sources so bear with my unexperience :p )
&gt; i dont know where to start Start with `PrintStructure` and `PrintAccountArray`. Then you'll have a basis for testing all the other things you have to do. Make a dummy array in `main` that you can print to test the `PrintAccountArray` function. Give it at least 3 entries (so you can test sorting). Completing the `SortByBalance` function looks like it is copy-n-paste from previous work. You can test that with a dummy array too. Doing that will reinforce your knowledge of structures and arrays. By the time you get to the file I/O bit, read the documentation for `fopen` and `fread`. Study the `fread` that's been given to you. 
I agree with the choice of 21st Century C. Quite a good book.
Yah, you really do need to pass &amp;endptr, otherwise something like "12Q" will appear to work without incident which I doubt you want.
What is an int on your system? 16 bit, or 32 bit?
Where do you set adcVal? You have it defined in your main function (as volatile even?), but no where in there do you use it. Is this supposed to be a global variable instead? Does ADC_StartCnv() also wait for the conversion to be done? It better since you just grab adcVal and use it right away. What does ITM_Port8(0) do?
Read the [documentation for `SysTick_Config()`](http://www.keil.com/pack/doc/cmsis/Core/html/group___sys_tick__gr.html). It returns 0 for success, so the while loop should never happen.
Hmm, searching around for `ADC_StartCnv`, I assume you're using something similar to [this](http://sirius.cs.put.poznan.pl/~inf91007/pcue/Lab3/Blinky/ADC.c)? In that case, you're not using it correctly. `ADC_StartCnv()` just turns on the ADC. To read its value, you need to call `ADC_GetCnv()`, which waits for the ADC to say that it's done with its conversion, and then reads the converted value. You're not reading anything; as someone else pointed out already, you never assign `adcVal` a value, so its value is random gibberish.
Thanks, it's probably the simplest solution and it works. If I wanted to modify only the defined number how would I calculate the offset? I was trying to do something like (ROW_MOD*10+COL_MOD) *sizeof(int) but it didn't really work out.
ok i'll try sprintf().
can u give me an example of sprintf? I find the documentation confusing
Most of the changes from C99 to C11 are bugfixes, and re-wording of unclear text. The thread support is all new, but it seems that no compiler actually implements C11 threads yet... people seem generally happy with POSIX threads.
If each node holds a payload of 10 chars and a pointer to the next node you are wasting a lot of memory. Not only is the pointer 3-6 times overhead, but also you have HUGE padding in each node. You really should rethink if a linked list is the right data structure for your problem.
Visual Studio is really nice. I've also used code::blocks with great success and it worked immediately. I didn't have to download a compiler.
*Beginning C* 5th edition by Ivor Horton seems to cover C11, just keep in mind that you need a C11 compatible compiler.
This is a bit off the topic of OP's question but why are calls to malloc() considered so expensive? I have a few programs that have hundreds of thousands and sometimes millions of calls to malloc(). How much faster would my program run if I could find a way to reduce the number of malloc() calls? Is it a linear scale?
That seems to be spot on. The reason I was curious about C11 is that C++11 and C++14 seemed like a mayor overhaul. But then again, we could use modern C++11 without using classes. 
QtCreator comes bundled with gcc. Pretty good IDE.
can you spoon feed it? XD
That's one way to do it. Or you could declare it as an array that's large enough to hold the biggest value that could be printed. You can also add a maximum length to the %d. There's lots of ways of handling the problem.
Yeah Qt Creator is nice but I don't really want the whole Qt framework and IDE with it and it appears it just includes the standard MinGW-W64 32-bit build not 64-bit (on Windows anyway).
I use good old fashioned Cygwin. I like the unix environment stuff. 
A `malloc()` call typically involves `malloc()` searching through its internal data structures for a chunk of memory it can give to you. This is fast, but for special purposes you can get even more performance if you know in advance what data you are going to allocate.
 void deposit(struct bank* b , int money) { account += money; } The fact that you're not referencing the argument `b` should probably be a hint something is wrong with this function. You have a similar issue in your `withdraw` function. Both should probably be using `b-&gt;balance` instead of `account`
I have a lot of bad memories of Cygwin so would rather avoid it tbh. It is nice to have a POSIX environment but it can make things more difficult for some things, at least in my experience. MSYS2 seems to be a better options if I want a POSIX environment. 
Hmm it appears he has some very specific build configurations such as forced static builds. I would rather a more "standard" (?) GCC build. Looks like MSYS2 or TDM is the way to go. Shame the TDM build is about 6 months old. 
If you are targeting posix-like systems, why not just run linux in a VM, or even on bare metal for that matter? It doesn't sound like anything Windows specific is being targeted. Am I missing something?
You mention "better portability outside of Windows". Well, let's back up a step... what is it you're trying to write? Is it something you want to run on multiple platforms (Windows, POSIX [including Linux/Unix, MacOS, Android, iOS, etc.])? If so, how are you intending to deal with the system calls not being the same? Yeah, if all you're using is printf and fread, it's no problem, but pretty much anything more complicated means you start having to worry about what set of APIs you're using. The answer to that question dictates your choices. If you want to write code that's more or less standard C and POSIX, then you want one of the MinGWs or something similar. (I don't really know the difference between some of the ones you listed, I'm afraid.) If you find the "min" in MinGW to be too restricting — it really is pretty minimalist — but still want to be fairly POSIX-like, you want Cygwin. If you are okay using different APIs to get stuff done and/or would prefer to use the native Windows APIs directly, then you might as well go with Visual Studio. If you don't care, then I recommend Visual Studio. It's a pretty good IDE and compiler, with lots of fine-grained warnings.
Because that's the sign bit.
Balls, the switch statements in that Go code are horrible. Why would you list out every possible byte, when the only difference between them is what registers they operate on?! The real CPU relies on the opcodes having a regular format so it can decode "this is an 'add' instruction, and the operands are register A and register C", so why wouldn't you write the switch statement the same way? Ahh, but thinking about it a little more, there's an answer: speed. The PDF you linked talks about this. You wouldn't want to use a long chain of `if` statements, because then you have to walk your way down that chain. A `switch` statement, if it meets certain optimization criteria, will be implemented as a [jump table](https://en.wikipedia.org/wiki/Branch_table). Basically the compiler will make a table of code locations to jump to. It will take the value you're switching on, find that index in the table, and use that value as the location to jump to. It's O(1) instead of O(n). So what's the problem with decoding the opcode by type and then by arguments, like I suggested? You'd either have to write `if` statements, which we decided is bad, or you'd have to list out multiple cases (say, all the bytes that mean "add") using fallthrough, and then in the common handling for those cases do additional work to decode the arguments (again, either with an `if` statement [bad] or a `switch` statement). It's just not as fast as the simple but dumb way of just listing out every opcode and argument.
&gt; There is the concept of phase symmetry &gt; By symmetry I mean that just as `dispose` counters `construct`, `clear` (or `deinit`) counters `init`. Yes, phase symmetry (I don't know if there's another common name for this pattern) is great. The code I work with is very consistent about this, and it's blissful when it's done right. For any given structure, depending on what it needs we might have a `ctor` and `dtor` (takes a pointer to the struct and sets up its initial values), `new` and `delete` (allocates a struct and calls the `ctor`; calls the `dtor` and frees the struct), `alloc` and `free` (allocates/frees but doesn't call `ctor`/`dtor`), `init` and `destroy` (usually for a service or system), `start` and `stop` (also for services), `add` and `remove` (obvious), etc. I suppose some of it counts as RAII. When we use the `new`/`delete` pattern, it both allocates and runs the constructor. If the constructor can fail, it will free the struct that it had allocated. We have no use for something that couldn't complete its constructor, so what's the point in keeping it around? If you made the caller separately allocate and construct it, then the caller needs to check whether the constructor succeeded and free the object. There's no point doing that every single time you create something, when it could be done once. If there were something where construction is expensive or otherwise shouldn't be done at the same time as allocation, that's when we'd use the `alloc`/`free` and `ctor`/`dtor` patterns. That's rare, though. (We also use the separate `ctor`/`dtor` for when the object might not be dynamically allocated, and just needs to be constructed on the stack. That's also uncommon for us.) I think I'm just plain confused by your names... what's the difference between `init` and `construct`? To me, those sound like two names for the same action. Unless by `init` you actually mean "allocate", in which case you really out to just call it that. &gt; generally when `dispose`ing, it is not necessary to `clear` since you are deallocating the object anyway. But when using object pools... Yes, very true! I'm not following your point. I mean, sure, the destructor shouldn't care where an object lives, and shouldn't wipe the object. But the deallocator does know, and should. If the allocator and deallocator are using a memory pool, then have the deallocator wipe the contents of the object. (Or consider having the memory pool do that for you.) But so what? Why can't `new` call `alloc` (to get the object from the pool) and `ctor`, and `delete` call `dtor` (which just releases any resources the object owns, maybe asserts that the object isn't on a list, etc.) and `dealloc` (to wipe the object and return it to the memory pool)?
&gt; I suppose some of it counts as RAII. Agreed. The lines get a bit blurry when you start picking these concepts apart and inspecting the pieces close up. &gt;I think I'm just plain confused by your names... I should have used different terms there. Recently I've come up with a naming convention for this. If it's pure allocation, I use `MyClassName_alloc(ate)()`. It it's pure initialisation, `*_init(ialise)()`. If it's both together, I use `_construct()`. Typically I keep them separated as the former two until I know there is no need to do so, rather than starting with just a single `_construct()` (as probably most others tend to), avoiding premature conflation out of caution. And of course the opposites apply for destruction (more on that below). I note that you use terms `new` and `delete` as well. I'll pretend not to understand what those mean in this context as in C, there are only `alloc` / `init` / `deinit` (`clear`) /`free`. This may require you to explain your last para again ;) &gt;Yes, very true! I'm not following your point. I mean that one can code for the general case by ensuring these two phases (and their startup counterparts) are always discrete. Explanatory interlude... let's jump to: &gt;If there were something where construction is expensive or otherwise shouldn't be done at the same time as allocation, that's when we'd use the alloc/free and ctor/dtor patterns. Exactly this - the worst case scenario which I prefer to plan for as a default case to avoid nasty surprises. Distinction between conflated `construct` vs. discrete (`allocate`+ `init`): sometimes you don't allocate where you initialise. In realtime apps for optimisation purposes in critical sections you might need a large pre-`calloc`ed array of type T, but you only need do proper initialisation of the various T instances therein, ad hoc as and where appropriate, i.e. later / elsewhere. So if we take worst case as general case, we _don't_ want to conflate `allocate`+ `init` into a single `construct` by default. And phase symmetry then suggests that if we mandate separation of `alloc`from `init`, we must do the same for `free` and `clear`. Moving from there, the coder in my gut says, "if we know we have two there in startup, we expect to have two mirrors thereof, here in the endgame". This is the principle of least astonishment. To avoid surprises and maintain uniformity, even though object pools and pre-init-allocated arrays are uncommon, I code for those cases generally as a form of defensive coding / time-saving. For me even the idea of conflating `alloc` and `init` into `construct` _later on_ rings little alarm bells (what if I refactor?). I'd rather these two things always remained distinct. In always doing it this way, we never forget to call one with the other when required (most cases) or subtract whichever one isn't needed (rarer cases). Whereas you easily _can_ forget when you conflate into a single `construct`/`destruct` by default, e.g. "oh crap, this constructs but doesn't yet initialise" or "oh crap, this clear operation can't actually go into the destructor because this is an object I don't want to deallocate since it goes into a pool from whence it should be cleared". Not conflating means not making faulty assumptions - this _has_ been done but that _hasn't yet_ been done. &gt;But so what? My worry - perhaps unnecessarily - is over RAII's conflative effect in the case of multi-phase, nested `alloc/init/dealloc/deinit`. Now you want those same 2-4 phases applied for N different aspects of the object in question, and be able to recover from a failed step / aspect (this _does not_ apply in my typical use cases - never needed backstepping during construction due to failure creating components - in my area it's normal to just exit gracefully if e.g. certain resources are missing. But if I did I'd want it all laid out as code before me - no magic), without conflating `alloc/init` etc.! Correct me if I am wrong - I'd hate to harp on something that isn't true - I never got deep into this aspect of C++. But I see conflicting logic there since now that conflation is mandatory. I'll say this: If such complex scenarios are doable within the scope of RAII without obscuring anything from me, cool. There is no use in looking a gift horse in the mouth - if it _is indeed_ gift. I know there are other cases where RAII is flawed, like closing files in dtors... this also speaks of lurking potential issues because you chose not to just DIY. Point being simply - I don't want the language making these decisions for me. "Magic" like RAII always comes at a cost to transparency. The opposing argument is of course, "But look how much time it saves on the overall". 
In C the type of the result is determined by the type of the operands (not their values). Applying a unary arithmetic operator to an `unsigned int` results in an `unsigned int`. There is no signed overflow, or out-of-range assignment in this code.
As ugly as you probably think this switch statement is, I would say it's likely your best bet for this problem, for two reasons. The first is that, once compiled, a switch is probably going to be roughly as fast as any other solution. You could perhaps come up with some inheritance or function pointer solution that looks smaller in your C code, but that will eat up about as much time as a long switch. Emulating the GameBoy's 4.2Mhz processor will be super easy for modern computers, so speed isn't a problem. So speed really isn't a concern. The other reason I think this is a fine solution is that it maps out the opcodes in the code very clearly. No digging to figure out what each hex value means in opcode land - it's laid out as neatly as any comment could lay out. This will make it easy to read and understand in the future, and you will likely be reading this code a lot. I know a big switch list looks terrible, but like BigPeteB says, jump tables will likely be used, and those can be optimized fairly efficiently. I say leave the switch statement and move on - you have lots of other issues to play with that will be much more worth your time.
I use CodeLite 9.0 + TDM-GCC, supports C11 and C++11, 14 standard, in IDE many settings + supports threads from Eclipse.
I plan on making more complex emulators down the road, so performance is an issue just because I want to build the proper techniques in order to make more of them. I never really used a jump table before, but I can already see the performance boost over a big case statement. I just need to know how to implement one. 
I agree. Sometimes the best answer is the ugliest, brute force approach, particularly when programming Verilog
Best of luck then!
Can you send me some documentation on how jump tables work and how they are setup?
&gt; #define MAX_LEN 255 //or what have you &gt; char fname[ MAX_LEN ]; &gt; strcpy( fname, file ); &gt; strcat( fname , ext ); Or better yet, use strncpy(), or _strncpy if your compiler doesn't support strncpy. 
In C, the concept of a jump table can be modelled by an array of function pointers, e.g. int add(int a, int b) { return a + b; } int sub(int a, int b) { return a - b; } ... int (*operator[]) (int a, int b) = { add, sub, mul, quot, rem, ... }; operand1 = operator[opcode] (operand1, operand2); 
That massive switch statement is exactly why I would recommend C++ for this type of project just for templates. Check out Bisqwit's NES emulator video here, it will blow your mind: https://www.youtube.com/watch?v=y71lli8MS8s
Try something more simple like DCPU-16, however 8088 and Z80 are know to be easy to write an emulator using a big switch or jump table. 
Switch statements are implemented with jump tables. That's why most responses are saying the switch statement is the way to go.
I don't see anything in the documentation that tells which one means what. I'm assuming `short` is supposed to be 16-bit and `int` to be 32 (even though `int` isn't even guaranteed to be 32-bits in the standard), but what about `float` and `double`? Do they have a page explaining in detail what they mean? Otherwise, this interface is actually really nice.
Well....gcc exists on almost everything. Despite using gcc goodness you can still compile for other platforms and other architectures. gcc was my first compiler, and that was on RISC OS. I use all the time on ARM and x86 Linux. I've used on Windows more than a few times. And gamecube, PS2, PS3. And LLVM aims at gcc compatiblity. So if you are going to use compiler specific stuff, gcc is the compiler to do so with. Plus you know, it's libre.
Just learn c# or .net or java imo. Dunno how much my opinion is worth, but those are the languages I run into most often
I personally don't think C is a great first language for an average person. It was mine, and things didn't really click until I did some assembly. Depending on how serious/techy you are, you might have more fun with a higher level language that make it easy to work with graphics/graphical interfaces. With Python for example, you can start writing simple games right away. Not something you can do with C (with the same level of ease).
C is a perfectly fine first language and will lay the foundation for you.
C is actually quite simple to get started. It has relatively few data types, built-in/default libraries, and the like. Since almost every language after it has built on its concepts, it will also give you a good solid background for most anything you do in the future. That said... While C is simple to get started with, it's full of traps and pitfalls that might have you screaming at your compiler trying to understand what's happening. With C, you have ***no*** training wheels. My best advice is that if you are just getting started programming, your first question should be "what do I want to program"? If you want to work on small embedded systems where MIPs and power are limited, then C is second-to-none. If you want to make websites, it's not a good choice; if you want to make scripts to sort the photos on your computer, it's not a good choice. Selecting the right language should be both about learning something relevant and about choosing a tool that's right for the job. If you don't select correctly, you might get frustrated and stop programming, which would be the worst possible outcome. Whichever language you choose, try to pick one that lends itself to helping you create something you're passionate about.
A bit old? It's essentially a 60s language (BCPL) updated slightly to work with early 70s minicomputers (PDP-11). I think it's a terrible language altogether, though because of its symbiotic relationship with Unix it's managed to make all its competitors practically extinct. So it's really the only tool remaining on the shelf for certain kinds of programming (at least if you have risk-averse management telling you what tools you are allowed to use) and so it can be rather useful to learn it, depending on what sort of programming you want to do. C++ inherits all the flaws of C, gives you a number of new opportunities to create hard-to-debug errors and a myriad of new choices to make, but also provides some abstraction and program structuring mechanisms that C sorely lacks. It's also the lingua franca of the games programming industry. So if you want to program games, I'd suggest finding a good mentor for C++ in a game setting and just skip C altogether. For the sort of games a beginner is likely to make, though, you might also be better served with a framework built around C# or Lua or something that isn't so covered in sharp edges. If you want to program operating systems or embedded systems, you're probably going to be stuck learning C, though I'd recommend checking out Rust and really internalizing the things that Rust prevents you from doing so you can prevent yourself from doing them in C (or C++, which can be a bit more helpful in that respect if you know how to ask it to be.).
&gt; how hard is it to pick up C++ after C? If your ultimate goal is to learn C++, you should *not* start with C, because almost all C code is terrible C++ code. [Here](http://www.stroustrup.com/bs_faq.html#prerequisite) is what the inventor of C++ has to say about the issue: &gt; Knowing C is a prerequisite for learning C++, right? &gt; Wrong. The common subset of C and C++ is easier to learn than C. There will be less type errors to catch manually (the C++ type system is stricter and more expressive), fewer tricks to learn (C++ allows you to express more things without circumlocution), and better libraries available. The best initial subset of C++ to learn is not "all of C".
I'm a beginner that started off using Python, but recently moved to C for a work opportunity. Whilst I've not necessarily found C harder, it's certainly been a slower process, but this could be down to the resources I've found. The material is seemingly more in depth than the Python stuff i.e. how it relates to the hardware, where things are stored etc. As a mechanical engineer I found this was more pleasing than the superficial Python resources. Python reads and writes much better though, but I didn't fancy learning two languages at the same time. 
C was my first language, so yeah sure. If you're anything like me it'll be frustrating as shit to learn tho.
Please fix your formatting. The code in your post is completely unreadable. Alternatively, post your code to a paste service of choice and link it here.
It depends what you want to learn. I don't want to tell you "go learn C" and have get so frustrated with it that programming becomes a big turn off. I also don't want to tell you not to learn C because you can really learn a lot with C. C is sometimes called portable assembly language because (once you take a class is computer architecture or assembler) you can see how a block of C can map to a series of machine instructions. In fact, you'll probably think "gee, I can kind of create C using a good set of macros in my assembler". There are some good things about learning C: 1) There is no magic. What you you code you get. There's no implicit changeroo that turns the string "1234" into the integer 1234. 2) You become aware of all the computer related issues like dynamic linking and loading which most languages completely hide from you. 3) Memory errors abound as you watch your programs core dump. This exposes you to how things are laid out in memory, something from which most other languages shield you. 4) The whole operating system is available to you, including writing loadable kernel modules and device drivers. You don't have to wait for someone who knows C to create a wrapper in your language to a specific library or kernel feature. 5) You will learn how to use a debugger to examine raw memory and register values - something you rarely or ever do in other languages. You will get frustrated. You will spend a lot of time chasing "stupid" errors for the first time. (Like everything works fine and then you *remove* a print statement and your program crashes because 15 lines earlier you over-ran an array.) I would recommend a book on computer architectures and operating systems to go along with C. I don't want to make it sound overly daunting. At 16 I was learning 8086 assembly and I knew guys who were coding in 6802 assembly and decompiling assembly programs. And yes, I would spend countless hours pouring over bug riddled programs, but I also learned a lot doing that. Most of the graphics libraries that you might be interested in have a C interface as their "real" API but then wrappers for just about every language out there. OpenGL and SDL, as an example, are programmable using many different "safer" languages but their APIs are actually written in C. That being said, I've seen some amazing stuff done in JavaScript in the browser for games. You could write JavaScript/WebGL/SVG in what should be a "safe" language environment with great tools, and still spend countless hours on frustrating and stupid bugs. C++ and C are different languages. A well written C++ program uses different concepts, such as generics and templates, that produce programs that can look little like a similarly featured C program. The abstractions provided by C++ allow you to code in a related but also very different style from C, although C++ is a superset of C and almost any valid C program is also a valid C++ program. (Of course a valid C++ program that uses C++ features is not a valid C program). I'm often happiest coding in C precisely because it is a simple language, down on the bare metal, and it's tedious but I'm actually programming the "real" computer. I don't don it professionally but I find it relaxing. A kind of therapy. [Edit : One thing that I often see is people who get stuck on very simple issues like a library not being in their library search path because they know ruby or JavaScript but have no idea what actually goes on under the covers. They treat that world as nothing they should ever worry about and get upset when the illusion provided by their high level language breaks. Or they're doing something that is extremely, insanely expensive but don't realize it because it's just a couple of lines of Python. Even if you don't start with C, at some point in your education learn C and assembly and how a computer actually works.]
&gt;Alright, I'll do C. So, it's probably not suited towards this, but with enough determination can C produce 2d games like Undertale? Quake was written mostly in C, as were many games in the 90s. 
getchar() always returns a byte of input (converted to an int). Recommend you use a library such as glib.
I can't it's part of an assignment :/ 
yeah a char is always i byte, i am wondering how to know when a character( a symbol) is 4 bytes or 2
Then you've got a tough task ahead of you. Checkout https://www.ietf.org/rfc/rfc2781.txt. I think if the first 2 bytes are less than 0x10000 then you can assume it is a full character. *bytes not bits
Yes, you can pick C as your first language. Just keep in mind that you will want to use a proper C compiler (GCC or Clang) if you want to learn proper C. While C is not the easiest language to learn, it is a good starting point because you will be forced to learn how a computer actually works. I recommend that you set yourself a clear target, something like: * learn basic C in 1 - 2 months * code a few small 2D games in C (you can use OpenGL or SDL2) like Pong, Breakout, Asteroids 
constantly pretty much hahha
&gt; C is a subset of C++ This is not technically true anymore after C99 and C11. C++ contains only a part of C. But you are right that you can code in C++ using only the C features (contained in C++) if you want to.
Ok, so I did some reading (https://en.m.wikipedia.org/wiki/UTF-16) and this is what I found out: UTF-16 has bytes divided via code points. Each code point is variable length from 2B(ytes) to 4B. This is where you're question comes in: Do you read 2B or 4B? To answer this quickly: You'll ALWAYS read in 2B steps so that you can determine what value you're going into. Firstly, there are three different ranges of value you can be looking at in the first 2B. Here's a quick reference, where 'U+' is used to symbolize Unicode much like '0x' is used for hex: * [1] U+0000 to U+D7FF: One 16-bit unit [2Bytes] * [2] U+E000 to U+FFFF: One 16-bit unit [2Bytes] * [3] U+10000 to U+10FFF: Two 16-bit units [4Bytes] So to determine if you're in the [1] or [2] space of UTF-16, you read in a 16-bit value and see if it's with range of U+0000 to U+D7FF, or range of U+E000 to U+FFFF. If so, you're done! That's your UTF-16 value. Now, what if it falls in the [3] space? A.k.a U+10000 to U+10FFF? Well, let's revise [3] into [3a] and [3b] spaces: * [3a] 0xD800 to 0xDFFF: 1 high/low level surrogate 2B value to UTF-16 * [3b] 0xD800 to 0xDFFF: 1 high/low level surrogate 2B value to UTF-16 As you see, if the 2B value resides in the above 2 ranges, they are part of a "surrogate pair". That is, two of these numbers will be combined together via a certain algorithm to give you your UTF-16 value. Now, an example of a UTF-16 value that falls into the [3] space may help you understand this if you don't yet. Let's take the Wiki example of U+10437 (𐐷): 1. Subtract 0x10000 from 0x10437: 0x00437 is result, or in binary: 0000 0000 0100 0011 0111 (Why the extra bits on the left? because we'll need them. So if you're doing this in code, use a 32-bit num or be aware of the data primitive you are using) 2. Split 0x00437 into high and low values: 0000000001 and 0000110111 3. Add 0xD800 to high value to make 'high surrogate': 0xD800 + 0x001 = 0xD801 4. Add 0xDC00 to low for 'low surrogate': 0xDC00 + 0x0037 = 0xDC37 So, ultimately, U+10437 has been encoded into these two 16b (2B) values: 0xD801 and 0xDC37. You're done! In order to retrieve your UTF-16 encoded value from bytes, you simply do the reverse process. ~~Of course, you need to determine endianness as well, since without that knowledge you won't know if the [3] ranged value you're looking at is the high or the low surrogate.~~ Keep endianness in mind. You may need to swap byte order if your decoder is the opposite endianness of the encoded or vice versa. Hope this helps. It's a bit complicated at first but, given time and patience, can be picked up.
That RFC tells you exactly what you need to do.
FYI, 2 byte values will always be less than 0x10000 ;)
The risk is that there are no training wheels. The corresponding advantage is that no abstractions hide from you what is really going on. I would suggest that it is a great language to *know*, but a risky language to *use*. (Though that advantage might outweigh the risk for certain environments where the lack of abstractions is critical, such as building an operating system.)
Bjarn has some great statements on C++. &gt; In C++ it's harder to shoot yourself in the foot, but when you do, you blow off your whole leg. &gt;Within C++, there is a much smaller and cleaner language struggling to get out. But you want to listen to a wider audience... &gt; I invented the term Object-Oriented, and I can tell you I did not have C++ in mind. Alan Kay &gt;Whenever the C++ language designers had two competing ideas as to how they should solve some problem, they said, “OK, we’ll do them both”. So the language is too baroque for my taste. Donald E Knuth (For the record, I used C++ for half of the 90's, I haven't used it since. I still use C.) 
Couldn't write it better myself. Literally... I've been writing it up but you beat me to it. Also endianness can be apparently determined by BOM character at the start of the text. If you read first 16 bytes as a number and it's 0xFEFF your endianness is same as that of encoded text and you don't have to flip any bytes around. EDIT: I don't think endianness has anything to do with whether high surrogate or low surrogate comes first. High surrogate always comes first. But each byte inside 16bit code unit is affected by endiannes. That's why you need to know it.
That makes sense! Didn't think too much about endianness, I figure it's important to just be aware of it as well. I'll edit my response too.
Sorry if I'm being stupid, but how do you "see if it's with range of U+0000 to U+D7FF, or range of U+E000 to U+FFFF"
If you start with C, I also recommend trying to pick up a debugger like gdb, even a small subset of its functionality is good to know. Valgrind is also your friend - if you get a segfault and don't know why Valgrind can help you get a clue.
So 16 bits of data will give you a hex value of 0x0 to 0xFFFF. If it's within 0x0 to 0xD7FF, then it's within "U+0000 to U+D7FF". If it's value is in 0xE000 to 0xFFFF, then it's within U+E000 to U+FFFF. UTF-16 values U+0000 to U+D7FF and U+E000 to U+FFFF can be held within 16 bits of data, so the above will work. The space between values 0xD800 to 0xDFFF is reserved for values U+10000 to U+10FFFF
It looks like you have a misunderstanding about the way memory works. What is happening in TxFam_func is that you create some space on the stack for namestore, but as soon as that function returns, the namestore buffer is no longer valid to use (because it is on the stack). The proper thing to do here is allocate namestore within your main function, then if the person lives in Texas, copy their name into the namestore. There are many opportunities for buffer overflows fixed-size buffers, so watch out for those. Hope this helps you get going on the right direction.
Why bother with the "U+" notation? You're just treating it like hex, right?
FWIW I am also writing a Gameboy emulator, and I chose to use a jump table. Besides being more legible, it makes it much easier to group similar cpu operations into a single function. Specifically, I have two jump tables. The first one is the "typical" one, and the second one is for the second byte in all of the 0xCB-prefixed operations.
Are you planning to write your own C compiler (or a substet of C) ? Or just stop at the expression parser ?
&gt; Would this work? Why don't you try it?
Same reason we use "0x" for hex, or "0b" for binary, it's to quickly show that we're talking about a specific symbol/numerical/character representation in an ASCII-friendly fashion. * 0x - Hexadecimal * 0b - Binary * U+ - Unicode If you want a more specific reason and history, check out this email: http://unicode.org/mail-arch/unicode-ml/y2005-m11/0060.html
Because, while code points in the ranges U+0 to U+D7FF and U+E000 to U+FFFF encode under UTF-16 to hexadecimal 0x0 to 0xD7FF and 0xE000 to 0xFFFF, the same is *not* true for code points from U+10000 to U+10FFF, which encode to surrogate pairs of 0xD800 to 0xDFFF. Also, UTF-16 is not the only Unicode encoding out there -- UTF-8, which is arguably more common, does wacky bitwise things to code points to squeeze them into fewer bytes, so the raw data you read in almost never literally equals the code point it represents. That's why it is useful to draw a distinction between the two.
I know, but that's getting fairly technical, which is why I said "generally speaking".
I didn't mean confusion with my [3a] and [3b] points. What I meant is when you're comparing the literal 2 bytes of data to the hex value. * Right, C doesn't have unicode literals. * You need to know ahead of time whether you're dealing with Unicode or not in your data input, then you handle appropriately. * Yes, when comparing 2 bytes worth of data, I compare with a hex value. Whether a Roman 5 is greater than a Urdu 4 depends on the context. If we convert those to actual decimal number representation, then obviously the 5 is greater. But if it's within Unicode and the 5 is of a lesser representation than Urdu 4, then the 4 will appear to be bigger.
You can try out [babun](http://babun.github.io/) if you've had bad experiences with cygwin. I like it a lot - but goddamn is it slow, especially with git. Thus, I'm not seeing a clear winner between cyg and msys2 yet. You CAN use mingw installed outside of cygwin with cygwin. You don't have to use cygwin one. Blessed be the prefix. I compile my own gcc (I tend to use snapshots) on OSX, Linux (Ubuntu and Fedora), but on windows I use nuwen's http://nuwen.net/mingw.html even though you can compile it on your own as well. Using cyg or msys2 on windows is not a requirement if you use windows only, but having the same tools across platforms is great. In my own case I've been hardwired to unix-like from forever (I started out on SGI). Can't think of using anything else so far. 
Thanks I will take a look. 
Well, it does that because you assign check the first thing inside the loop but you don't check it until the next iteration
Yes! Agreed! I meant to use "U+" as a way to talk with humans, not as a way to interpret in a string in C.
Had no idea, I'll look into this. Thanks!
`if ( check != 3 )` occurs immediately after `check` is assigned (which will be true if `check == EOF`).
Thank you for the response.
Well... There is a platform for Objective C. (yeah, I know) I'm sure there's a lot more quips out there about C, C++ and all the other languages than anyone has time to read.
Do you have to use getchar() or is getwchar() okay? The latter, when coupled with the right locale, should make this fairly simple.
Neither of these concepts are particularly complex. I suggest reading the appropriate manual pages for fopen, fread/write and fclose. For structs, the Wikipedia article is likely more than sufficient when it comes to introducing the topic. https://wikipedia.org/wiki/Struct_(C_programming_language) Additionally, there are likely few better resources than those already freely available online. If you're really struggling, providing a code snippet underlining more specifically what you're attempting to achieve would help people to point you in the right direction if they feel so inclined.
Preferably a git repo
[similar post here](https://www.reddit.com/r/C_Programming/comments/3wlo1k/file_io_and_structs/)
[similar post here](https://www.reddit.com/r/C_Programming/comments/3wlkrt/help_with_a_program/)
I'm not sure I understand your question. whether you memset 3 bytes to NULL or manually assign those 3 bytes to null the result in both cases is those 3 bytes each have the value NULL... Then again you could also make an array of null char by just doing this char stack[256] = { '\0' }; manually initialize the first element, then the reamining elements are implicitly assigned NULL value. edit: accidentally had array of pointers
No, it isn't, but I'm not quite sure if that's what you are asking about.
or is it illegal? 
can you send me your facebook or something, cause this problem have 3 file that main.c mp1.h and mp1.c Could you please see that you can help me doing this please :( sr for my bad english
If you have a char array of 3 bytes called *Stack* and you initialize the first element to '\0' like so: Stack[0] = '\0'. Then this is not the same as setting all the elements to '\0' with memset(). 
use pastebin or github to put the files up
ok ty I will repost this thread :)
I've uploaded file into this folder, the problem is given in the pdf file, you guy run 3 file mp1.c mp1.h and main.c i am on my progress on mp1.c https://www.dropbox.com/sh/dlzc3n4cdnys7uv/AAAyqac2WgU9XU2gkBe6KR0oa?dl=0
Yes: The key is actually understanding a bit of syntactic sugar allowed by the C language. When initializing an array, you're allowed to leave out entries and they will be automatically assigned zero. Thus: int a[10] = { 0 }; Sets *every* entry to zero, not just the first, because the unspecified entries (The entries we left out of the list) are automatically set to zero. It's worth noting that this doesn't work like you might expect though: int a[10] = { 1 }; This sets the first element of `a` to `1`, but since the rest of the entries are unspecified they are instead set to `0` - Not `1` like you might think. Thus, this trick really *only* works for initializing something to zero. If you want to initialize all the elements in `a` to `1`, you have to physically write out the right number of `1`s: int a[10] = { 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 }; Note that *all* of the above are different then this: char s[10] = '\0'; This is simply illegal, because you attempting to assign a character to an array - You have to use the array notation I used above, with the `{}`.
`NULL` is a pointer value, not a character value. Don't misuse it like that. 
true, edited
Yes it does! I definitely love me some GCC extensions. Noting that though, only this is a GCC extension: char array[256] = { [0 ... 4] = 'k' }; This is valid C99: char array[256] = { [6] = 'g' }; Also valid C99 is struct initializers. And you can combine struct and array initializers: struct foo { char bar[10]; int baz; }; struct foo[10] = { [10].bar[2] = 'c', [5].baz = 20, [7] = { .bar[1] = 'k', .baz = 5 } }; Which gets pretty complex, but is generally a very good way of initializing a structure. When handling arrays of structures like that I usually combine the above with an enum for each different one: enum { FOO_BAR, FOO_BAZ, TOTAL_FOO, }; struct foo[TOTAL_FOO] = { [FOO_BAR] = { .bar = "bar", .baz = 20, }, [FOO_BAZ] = { .bar = "baz", .baz = 5, }, };
Dude figure out how to do your homework on your own, if you get people to code for you you will just become a shitty programmer 
I tested this logic with the examples in the pdf and it works. Not the best way and I'm no expert but I don't agree with the method laid out by your teacher. For example who the heck #includes source files like that, lol. for (i = 0; i &lt; 4; i++) if (guessNum[i] == pegNum[i]) { perfect_matches++; pegNum[i] = -1; guessNum[i] = -1; } for (i = 0; i &lt; 4; i++) { for (j = 0; j&lt; 4; j++) { if (guessNum[i] &lt; 0) goto skip; if (guessNum[i] == pegNum[j]) { pegNum[j] = -1; misplaced_matches++; } } skip:; } where perfect_matches and misplaced_matches start as 0. if perfect_matches == 4 return 1 from the funciton edit: for those who want to test it all * http://pastebin.com/ZBU704Dd main.c * http://pastebin.com/KtZhyQFd mp1.c * http://pastebin.com/QNaUhW5V mp1.h Manually assign the code values inside start_game() (in mp1.c).. I am too lazy to make an interface. 
It might be easier to just implement the general quadratic formula yourself. When ax^2 + bx + c = 0, x = (-b + or - sqrt(b^2 - 4ac)) / 2a. http://www.sosmath.com/algebra/quadraticeq/quadraformula/quadraformula.html 
Pretty sure he/she's asking about the optimization technique: https://en.wikipedia.org/wiki/Quadratic_programming
Ah, my mistake. Sorry about that. I should probably learn read good.
This isn't exactly what you are looking for, but when I've needed to do quadratic optimization I've used LAPACK along with [OOQP](http://pages.cs.wisc.edu/~swright/ooqp/) for C++. I don't know of any c libraries sadly... Hopefully someone else here knows one. 
Have you used OOQP? If so could you comment on the simplicity of use. I can easily translate code to get the input vectors and matrices typically needed for a quadratic program. Edit: never mind, actually already looked at OOQP. 
I'ved used QuadProg++ before, and it's not bad. http://quadprog.sourceforge.net/
Essentially I am going to apply QP to a quadratic approximation of a particular objective function. Said objective function is a linear combination of the variance and third moment of a data set. The variable to be solved for is a weighting vector that puts allocation into a particular data set out of n datasets. If you're familiar with portfolio optimization this will make some sense. Otherwise, what I said is a bit confusing. 
thank you :)
i am in Vietnam and they make us to learn a whole semester in just 2 freaking weeks dude =)) and the result is still false. I really dont wanna fail any subjects more because the cost of 1 credit is too fcking high :(
Day job is navy nuke, free time is spent hacking on OSS C software. Mostly libuv and other networking projects right now
Do you end up using a lot of OOP'like strategies in C? or do you use C purely as a lower level development when interfacing with hardware or larga numerical problems for graphics? If/when using OOP'ish'ness which strategies you feel work best in terms C maintenance/reusability?
Communication middleware in a airline company. 100% C.
I work on a specialized networking stack on Linux. Somewhat alike to rewriting drivers in some special setting. I'm junior, started a few months back. Wanted to specifically work with C and OSS. I wasn't really big on the networking stuff but it's not that hard to understand (I'm coming from image analysis and 3D programming otherwise).
I'm the primary developer of an integrated development environment, Simply Fortran. Our code base is something close to 80% C and 20% Lua. The IDE focuses on Fortran (obviously) and uses the Win32 API. We should have a native GTK+ port for Linux coming out in the next month or two as well. Some people assume that Simply Fortran is a legacy code base given that it's a Fortran IDE written in C and Win32. However, it's a relatively new product; the first version was released around 2010.
In the if statements, you're using '=' instead of '=='. The former is assignment, the latter is comparison. On another note, randompos will never equal 3. If you want it to equal three, you should do rand() % 4.
Ok, you're right thanks! But i tried and the segmentation fault is still there...
Out of interest: Console/PC or tablet/phone?
I mainly work on either userspace programs (thin wrappers around ioctls to be honest) or normally linux filesystem related stuff. Though lately I got elected to do some silly rest api for some daemons we have. That is in python, and I don't like it at all.
try inserting some printf statements to determine program flow, it'll help to narrow down the location of your segfault.
Here's one I made early: https://www.reddit.com/r/linux/comments/3u5fn1/c_or_c_for_embedded_linux/cxcm5tr 
I will risk repeating myself but I'll ask the same question I asked /u/GenocidicBunny ... I assume you will probably have an obsessive amount of documentation and standards to follow in Avionics. Do you end up finding yourself using OOP'like design patterns? And if yes, what strategies you feel work best regarding code reusability and maintenance?
Thanks! I put the loop before the menu, but now the menu is popping up twice after I return from a subfunction. Anyone have any ideas? I'm guessing this is related to the carriage return. int main(void) { { char c = 'x'; long int first; long int second; long int answer; while (c != 'q') { printf("Please choose your operation: \n"); printf("a. Addition s. Subtraction\n"); printf("m. Multiplication d. Division\n"); printf("q. Quit\n\n"); c = getchar(); { switch (c) { case 'a': printf("Please enter two integers: \n"); scanf("%ld %ld", &amp;first, &amp;second); answer = addition(first, second); printf("The sum of %ld and %ld is %ld\n", first, second, answer); break; case 's': printf("Please enter two integers: \n"); scanf("%ld %ld", &amp;first, &amp;second); answer = subtraction(first, second); printf("The difference between %ld and %ld is %ld\n", first, second, answer); break; case 'm': printf("Please enter two integers: \n"); scanf("%ld %ld", &amp;first, &amp;second); answer = multiplication(first, second); printf("The product of %ld and %ld is %ld\n", first, second, answer); break; case 'd': printf("Please enter two integers: \n"); scanf("%ld %ld", &amp;first, &amp;second); answer = division(first, second); printf("The quotient of %ld and %ld is %ld\n", first, second, answer); break; case 'q': break;
audio stuff, 100% C
I haven't written C professionally for a while now, but when I did, it was firmware for a security system component. For a personal project, I've been reverse-engineering someone else's firmware originally written in C, but being reconstituted in my own toy language.
I'm a Software Engineer, working at the Oracle RDBMS. 
Oh great yes!! You magnificent!! Thanks i'll run to try..
C isn't a big language, it has only few reserved words, so it's easy to learn. However, just like playing chess, it only takes few minutes to understand the rules, but it takes years to become an expert.
I work at a research lab as a professional developer and spend about 95% of my work coding in C these days. (The other 5% is Matlab, Clojure, JavaScript, Java, and C++.) I write software for data processing, data presentation, modeling and simulation, and, on a couple of occasions, embedded network devices. C is my own choice the vast majority of the time. Virtually none of the work specifically requires C and I could have chosen C++ or Python or whatever else, with the only consequence being that the more esoteric my choice, the less likely I can find co-workers to work on my stuff. In my environment, C *is* considered somewhat esoteric, but it's not too hard to get a software-minded person up to speed, especially if they're familiar with derived bracket-languages like C++ or Java. 
Embedded development on uClinux/linux and bare metal. I've been doing this for almost 10 years, so I suppose I consider myself to be a type of expert. There's always something new to learn though, and you never know everything, so in some ways I still consider myself to be a "student" of programming.
Java developer by day. OpenBSD developer by night.
Don't code in C anymore, but I used to tinker on embedded POS systems, with modems, serial ports, chip and magcard readers, running some weird OS if you were lucky. If you were really unlucky, you didn't even have a filesystem library. Nowadays there's no challenge anymore to embedded - pretty much everything runs a full blown Linux these days. I could even `apt-get` stuff on the last thing I wrote software for, and the recommended language to code in on that device was python... So I then moved on to more server-side/backend coding, made the move to C++ - but never felt home there. Now I have a sysadmin/analyst role and when I code, it's usually in Go or Python. Guess I'm a bit too pragmatic - there's little reason for me to code things in C these days. I'll always love the language - but unless I'm writing a driver or something else os-level - I see little point in writing stuff in C these days.
Automation of measurement instruments using their APIs. 
For some reason only the y value is making it to the called function. When I print the value of *b I get the Y value but when I print the values of *a and *c I get 0. Does anyone know why the values of two of the numbers are being lost?
Embedded.
Do you understand what char * hello = "hello, world!" + 3; does? And why it prints "lo, world!"? If you do, the follow up question is : what is the value of `'h'`? 
The pointer that points to the first element of the string is increased by 3, which leads to pointing to "lo, world". 'h' should be the number of the ASCII-code, 103, if i'm not mistaken. so the pointer should be increased by 103.
Yes, and the "hello world" string is less than 103 characters long. So your pointer could be pointing at anything .. the behaviour is undefined.
ok. i guess the message is just something the compiler gives out in this case. Anyway, thank you very much for your help.
Nice work, i am writing a Lock free queue and was about to start implementing a memory pool but now i found this and will use it. Are you interested in integrating your work into lock free queue ? It needs some modification to make it thread safe.
Which part?
company's main piece of software is based on an L4 µkernel. We have to port this OS to different SoCs regularly and I do some of that. We provide an SDK and DDK and it includes the linker script/scatter file. Actually it is cpp or C; C99. We don't support shared libs so it's static linking all the way. Now that I think about it, as long as there is a compiler available, you should be able to get it to run (bare-metal with syscalls), but guess we only provide "support" in the SDK for C/CPP. I wouldn't consider myself an expert at C.. I've never read any of the standards or std lib code. All I know is C is good at doing what you tell it to do (and you can always check the assembly to confirm). And I'm good at understanding that and underlying cpu arch or system arch. I much prefer having access to "&amp;" and string.h with cpp. I am a big fan of the linux kernel for C style. edit: pretty sure google's style guidelines describe the type of C++/C I like as well. I'm in my twenties but a majority of the people I work with are 40+. edit: if I were to program to prototype/build things that are in my head (and not just embedded SW), I would probably consider doing most of the work in python/Go/elixer/C (or rather C++ dumbed down)/typescript/ruby. Based on what I've read and don't already dislike. 
I'm in games as well, where I mix between C++ and sometimes deal with older C code. I would consider the C++ code I work with closer to a "C with Classes" model than the C++11/14 stuff that people like Scott Meyers talk about these days. I'm also just starting a project called Handmade Quake, where I go through the source code of the original Quake on YouTube and look at how id Software built a game engine in C. Their code looks quite hackish compared to what we create today, but it's a complete game engine that changed gaming in the mid-90s, so I think it's valid to understand how they did what they did.
I have a question about barcode scanners. My scanner reads 2D codes faster than 1D. Would this just be a quirk with how the firmware works? 
It's not avionics, it's messaging between airline company and other companies, airports, customs, Global Distribution Systems, etc. I use OOP, a own classes/objects system implemented in C, asynchronous, with Finite State Machines. 
I see, I misinterpreted when you mentioned 'airline'. Thanks for sharing!
I don't want to be personal but which school in Vietnam you're talking about? Just being curious, because I lived there for a couple years :-)
Audio stuff? like audio plugins? or what?
Do you actually run OpenBSD on hardware, or do you use a VM?
Graph algorithm/analysis code (sits under a ruby/rails layer for UI).
It's not something given out by the compiler, it's whatever happens to be found 103 bytes after the "hello, world!" string in the completed executable. Probably an error message of some library that got statically compiled into your program.
oh no problem, it's bachkhoa but I won't tell you the city just for my sake haha :)
Quite a few. We have an in-house reflection thats been developed over many years. I wouldn't use our codebase as any kind of model though -- its fairly organically involved and as such has a lot of warts, especially around the reflection system, which is heavily integrated with most of the OOP-ness we do have.
&gt; C with Classes This is my experience as well. What C++ usage we have is to make use of the nice parts that we feel are missing from C -- namespaces, classes, private vs public members. We end up using very little of anything related to templates, and as such, also do not end up using the STL much outside of a few instances. I think C is still a quite viable language to develop games, if only for the fact that C is still a universal language and almost anything can be made to interface with C code; That means you have a lot of flexibility when it comes to the parts you expose to designers and artists, and a lot of power in the lower-level systems. With that in mind though, C can be difficult to work with, especially if you're mostly concerned about getting something done rather than doing it well, which tends to be the case a lot in the games industry.
In C ( C11 ) you also have atomics, as @assassinator42 mentioned. GCC provides atomic built-ins as well: http://gcc.gnu.org/onlinedocs/gcc-4.4.5/gcc/Atomic-Builtins.html
Nice clean code.. Why not, in the init put all the blocks into the free list? It would simplify the allocation. (might also lead to some other simplifications) And a small thing.. perhaps order your members by alignment.. on a 64 bit system, you'll have 4 bytes of padding between blocksUsed and blocks. Keep up the nice work, and thanks for sharing. 
Your professor is giving you misleading advice. Not only is cast not necessary, but using one can have harmful effects — it will paper over the mistake where you forgot to include `&lt;stdlib.h&gt;`, and you instead got the implicit prototype of `malloc()` that returns int. You want that to generate a warning because you made a mistake that needs correcting, but with a cast the warning is suppressed. (Hopefully you have warnings turned up all the way and would get a warning about implicit prototypes even with a cast. Learn you compiler's diagnostic flags.) A cast is necessary in C++, due to the differences in type systems. If you're writing code that needs to be able to be compiled both as C and as C++, then you need the cast. You might also see casts in truly ancient (pre-standard) code from a time before `void` existed and when `malloc()` returned `char *`, but that should have zero bearing on code you write in 2015.
The modulus operator discards information, making it non-reversible. For example, if I'm told that x mod 10 equals 1, there are still an infinite number of values of x that will make that a true statement. x could equal 1, or 11, or 21, or 31, etc. Any value of the form 10n+1 will work. There's no way to tell which of those was the original value of x. If you don't care about *which* value of x, and you just want *any* value of x that makes the statement true, then the problem is solvable. You can simply rearrange the equation under modulus as if it was a regular equation: N = x + y + z (mod 26) x = N - y - z (mod 26) For example, if N = 19, y = 74, and z = 209, then x = -4. Or it could equal 22, or 48, or any other value matching the pattern 26n-4 for any integer n. The point is that this will tell you *a* value of x, not the original value. 
Thank you very much! Next time I see my professor I'll ask him why he wants us to that typecast although it's wrong. Yes, I turned my warning all the way up. 
Thank you, too. The linked website is nice. To answer you implicit question: I'm in a C-Class. Next year we are learning C++.
That you shouldn't cast malloc is pretty well known among C programmers. It's a bit frustrating that your professor doesn't know about it. If he's not a very reasonable person, I'd approach him with care, because he may not like being corrected (about something like that) and, in the end, he's the one deciding your grades.
&gt; but using one can have harmful effects *could have had harmful effects, up until 1999 
Classes do not exist as part of the C language.
Classes are things you take to learn what a structure is and how to use it. :)
You've already got the answer you're looking for, but [here is another good explanation.](http://stackoverflow.com/questions/605845/do-i-cast-the-result-of-malloc)
Isn't this a normal thing in any undergrad CS program? I know I had to...
Please explain. What /u/Rhomboid said makes sense. Although, I tend to cast the return value of `malloc` in order to explicitly document what I intend, and to catch (via warnings) if I'm assigning the pointer to the wrong variable. (e.g. catch `char *idx = (int *)malloc (10, sizeof(int));` when it should've been `int *buff = ...`). 
Many people who are programmers haven't followed a CS program. This sort of informal look at such a project can definitely be interesting.
Sure, you're right. I just got a little confused about that. It's all pretty new to me. Just have to make my mind clear what the difference is between these two some times. You can write really confusing code with all these pointers, arrays, structs and dynamic memory allocation. :D
Where/when did you do your undergrad where this was required? 40 days sounds like a very quick pace. I imagine most undergrads would easily take 3 times as long. Plus, they'd have to have a sense of what they were doing before they started the project. How would you fit 4 months of work plus instruction time *plus* other course work on top of that, all within a 12-week semester?? I can't imagine the logistics of it. I certainly had to write a compiler, but it was for a toy language (not C), for a toy architecture (not x86), and we wrote the compiler in a real language (it was not self-hosting). That brought it down to a couple weeks of work, which is manageable within the confines of an undergraduate course.
I have a question not related to your work but a piece of code in it. I just randomly clicked on your map.c file and noticed that make_map calls a static do_make_map. I understand that do_make_map cannot be directly called since its static but why exactly make this call one more level deep? I've seen similar kinds of things being done, I don't remember where now but I would like to understand why it's implemented in this way. I'm really interested in learning how big c projects are structured and often struggle a lot getting it right. 
In my case it took a bit over a week of intensive afternoon work (4-5h/day), tokenizer/parser, syntax, semantics, optimization and code generation. It's true, I knew what I was doing, it was after having learned the theory in class, but it was plain old C, it was for x86 and it included (limited) code optimization techniques. I chose to do it in C (others chose perl), so it was self hosting in the end. How would I fit all that in 12-week semester? It was nothing out of the ordinary, we had tons of projects like those.
Here's mine as well from my operating systems course: https://github.com/landaire/opsys-ush. I don't think it was as advanced as yours by any means though.
lol that would be the guy I worked on the project with. I think he does that so that when he's working at the end of a file he's not constantly looking at the bottom of the screen.
No, those are different things. The first one, arr1, is an array of 30 char elements. The second one, arr2, is a pointer to a char. Pointers and arrays aren't the same. Pointers are about storing addresses. Arrays let you store a contiguous bunch of elements in memory of the same type. Someone told you that if you sizeof those two, you'll see a difference. The thing which is confusing about pointers and arrays for newcomers to C, I think, is the fact that when you use an array of N elements each one of type T whenever a pointer to a T is required (or any compatible pointer type, like void\*), then an implicit conversion will happen and what you get from using the array there is a pointer to its first element. For example, whenever you use arr1 when a char\* is required (or when a const char \*, or void \* is required for example), what you're going to get there is a pointer to the first element of arr1. fgets(arr1, 10, stdin); /* implicit conversion, you actually are passing &amp;arr1[0] */ fgets(arr2, 10, stdin); /* no implicit conversion in the same way as above */ This implicit conversion rule lets you refer to arrays in places pointers are required all the time in C. It also seems to make beginners think arrays and pointers are the same thing. As another clear to see different between arrays and pointers, consider the two types: char \*\* and char (\*)[30]. The first is a pointer to a pointer to char, the second is a pointer to an array of 30 chars. Pointing to a char[30] is very different from pointing to a char\*, which can be easily evidenced by some simple tests in address arithmetic. __Obs.:__ *I avoided using scanf in the example because of some extra rules on implicit conversions that kick in whenever you're dealing with variadic argument functions (I don't remember those very well right now).* __EDIT (FIX):__ As /u/leolas95 pointed out.
You know how many days March and April have (31 and 30). So to add 49 days : if Easter in in March, add 1 month and 18 days if Easter in in April, add 1 month and 19 days 
Using ANSI C is not ancient, it's common practice in C programming. 
It is but that's no excuse. Use gcc instead of some ass crusty custom compiler with literally thousands of bugs.
No this is using gcc. Lo and behold if you take out the line `std=c99` out of your makefile gcc will try and use c89, and it won't evaluate your fancy `//` comments and your variables declared in for-loops. Trying to put that line into makefiles that make legacy code will break your project. So you go along with the tools you got. It's good though, it is well known that simple compilers build more than just programs, they build character. The Fortran IV compiler has built generations of pacman-players into real programmers.
void whit(int year) { int month, easterDay, weekday, whiteday; easterDay = easterCalculationDay(year); year = GetYearFromUser(); month = easterMonth(); if (easterDay &lt; 11){ month = 5; whiteday = easterDay + 21 + DaysUntilWhit - 31 - 30; //31 the number of days in march, 30 the nDays in april 49+21= 70, 70-61= 9 } else{ whiteday = easterDay - 10 + DaysUntilWhit - 30; if (whiteday &gt; 31){ month = 6; whiteday = whiteday - 31; } else{ month = 5; } } weekday = getWeekDay(month, year, whiteday); printf("Whit day in %d year is on %s %d which is a %s\n", year, MonthName(month), whiteday, dayName(weekday)); }
Not sure if this is right... Appreciate if you could help me look into it
I'm writing to a file though
Yep, that fixed it. Thanks.
Never had to do it for mine
were all of the libraries given to you? or did you have to make some of your own libraries? im just wondering if for some programming classes they dont let you use a bunch of other code and want you to go through the process of making some libraries yourself
There's are multiple problems with the last two lines of the ordering() function.
&gt;I've seen similar kinds of things being done, I don't remember where now but I would like to understand why it's implemented in this way. Notice how `do_make_map` is used for both `make_map` and `make_map_parent`? `do_make_map` is a generic solution for making the map. You can apply it in many different contexts, but the implementation is independent upon the context it's applied to. Oftentimes you'll want to do multiple difficult but related things. You can implement them separately, but if you take a step back you can implement the easier, generic solution which makes the other problems go from difficult to trivial.
This is more evidence that college is utterly useless for learning C programming. Pre-C99, I think there are more important things to worry about than a missing stdlib.h inclusion, so I consider the cast to be more an issue of style than an issue of incorrectness. People who omit the cast because they're worried about a missing stdlib.h are probably the same "defensive programming" klutzes who code hideous shit like if (5 == i), which virtually screams "toss my resume in the trash and hire a more confident programmer." Personally, I omit the cast because it's less typing. Your professor's real sin is not discussing the two options and not telling you how to consult authoritative C sources. 
After some sleep and reading your text the second time I finally understand what you are saying. Thank you very, very much for your clarifying text. :) You seem to be in the topic very well, so here is another question I asked myself: With "realloc" you can change the size of the memory you are reserving. And let's say you have reserved memory for "..malloc(2*sizeof(int));" two times, and these two reserved memory "blocks" are sitting right after each other. What happens if you want to enlarge the first "block" to the size of 3*int ? Is the first "block" moved right after the second "block" where actually is enough space or is the second "block" moved so that the first "block" has enough space for enlarging?
[Related Pre-xkcd](http://www.marcomoser.it/data/fun/realprog.gif)
Embedded systems for automation controllers. Not exactly pure C but I like to keep it on the C level because each "empty" device usually comes with its own variation of toolchain to use and rather then debug and change variations of C++ I try to keep it on C which pretty much all support.
Like most of the more esteemed C references, that C-FAQ breaks down with bad advice and inaccuracies when getting into the language's nuances and corner cases. And I recall it containing quite a lot of buggy code. I clicked on "13. Library functions" for a skim to see what it had to say about malloc() casting and found this garbage recommended: (int)((double)rand() / ((double)RAND_MAX + 1) * N) which can erroneously escape the range of 0...N-1 and return N on an ISO/IEC/IEEE 60559 double-precision machine with a sufficiently (and plausibly) high RAND_MAX. That's what happens when strictly-conforming nuts try to sit down and actually write code for the abstract machine. Many of the biggest strictly-conforming blowhards on Stack Overflow are actually horrible coders who make newbie coding errors in their github toy programs or, as in this case, get hoist by their own portability petards when hypercorrecting. I then looked at "7. Memory Allocation" and discovered incorrect information for malloc(0) (7.13) and realloc(..., 0) (7.30). There's no substitute for the standard itself. The code in 7.30 is also buggy, testing for a size_t overflow of nchmax BEFORE adding 1 to it, which can overflow itself on the abstract machine, resulting in realloc(retbuf, 0): nchmax += 20; if(nchread &gt;= nchmax) { /* in case nchmax overflowed */ free(retbuf); return NULL; } #ifdef SAFEREALLOC newbuf = realloc(retbuf, nchmax + 1); #else if(retbuf == NULL) /* in case pre-ANSI realloc */ newbuf = malloc(nchmax + 1); else newbuf = realloc(retbuf, nchmax + 1); #endif The unsigned overflow is defined, but there is then undefined behavior in the following code, no matter which of the two implementation-defined options a conforming implementation chooses for realloc(retbuf, 0). That was in only five minutes of browsing. Never hire these guys to write production-quality code. Let them stew in their C bubble with their bug-ridden 100-line toy programs on github.
Wow, no questions left here! I'm really enjoying your long writings. Thanks for your effort!
Just iterating through its items, that's what you want? Two nested for's, one for the row and one for the column
You can try a very simple way of testing by using [minunit.h](http://www.jera.com/techinfo/jtns/jtn002.html) I have been working with this for a while now and have created my small variation. You can view on [github](https://github.com/AntonioCS/acsclib/blob/master/minunit.h). If you search that project you will see how I use it. Good luck!
Cool, this is really useful!
I genuinely winced when I read the last 3 comments. The first... Kinda makes sense but... It's hard enough understanding someone else's code... But no comments? Fucking he'll. Job security. What the hell is this code doing anyway?
&gt;I thought about just dividing (255) by 100 and so on to get 2 in the 100s place You're going in the right direction. You need to use the % operator as well. What's 255 % 10?
Integer division by 10^n "knocks off" the n rightmost digits -- it is effectively a rightward "digit shift". However, as you've discovered, you also need something to trim it down from the left, and that operation is modular division. Reducing a number modulo 10^n "knocks off" *all but* the n rightmost digits. In other words, to isolate the nth digit, you reduce the number modulo 10^n and divide the result by 10^n-1 -- like so: 255 % 1000 = 255 255 / 100 = 2 255 % 100 = 55 55 / 10 = 5 255 % 10 = 5 5 / 1 = 5 Clearly, if you're looking for the leftmost or rightmost digit, that can be done using only one operation.
out of all the people, it seems like you would be a god tier C programmer. I would say you have a pretty good resume xD
Yes, I even have it here on my system because kernel compilation. But that level of proficiency and that scope is far beyond what I can grasp at the moment...
Thanks! I don't want to just seem like I"m bragging, but on the other hand experienced developers are very prone to Impostor Syndrome; it is a trap to avoid; to get hired, you have to be able to sell your accomplishments a little bit. After programming since I was ten years old there is no point in pretending I'm not good at it, but on the other hand there is always more to learn and I am always trying to improve.
There's two things here: the thing you didn't know (the modulo operator) is only one of them. I'm going to talk about the other. Take 255 and after dividing by 10, in C (with integer truncation) note you get 25. If you multiply this by 10 you get 250. The difference between the two is the value that was truncated, in this case: 5. Repeat the operation: Take 25 and divide by 10 and this time you get 2: Multiply by 10 and take the difference: 5 again. Repeat the operation: Take 2 and divide by 10. This time you get zero. Zero times anything is still zero, so the difference between zero and 2 is just 2. Try plotting this operation. Imagine [y for 2](http://i.imgur.com/DQisbCS.png) and then [y for 10](http://i.imgur.com/XHtbqXS.png). Those stripes are very regular: They go to our parameter in a straight line over and over again. In this way, you can plot all the values and solve using linear algebra: int f2(int x, int y) {return x-(2*(x/2));} int f10(int x, int y){return x-(10*(x/10));} Doing this a few times might make it easier to imagine it [three dimensionally](http://i.imgur.com/lajRoyn.png), which then gives you the more general: int f(int x, int y){return x-(y*(x/y));} This operator is built-in to the C language (as you've discovered from the other comments), but not every operator is, and if you find you need an operator you should equip yourself with the tools needed to discover it and implement it. You will find this to be a much more useful skill than learning the C language.
[SQLite Github](https://github.com/mackyle/sqlite)
Busybox? Edit: Also, might not be intermediate, but the classic "Lion's Commentry on Unix 6th Edition" is very education. Good and important old code with a good walk through guide.
I like to just google for different implementations of the common linux programs. like "linux cp source" "linux mv source" etc.. * https://opensource.apple.com/source/file_cmds/ * http://src.gnu-darwin.org/src/bin/
Can C++ be considered a superset of C?
Try libuv.
That's from the historical period when the standard input device was a stone tablet, hammer, and chisel.
No. Definitely not.
I'm annotating the Quake source code on Youtube in a series I'm calling Handmade Quake. It's inspired by Casey Muratori's Handmade Hero, where he builds an entire game from scratch live on Twitch. The videos are also uploaded to Youtube. It's spawning a whole group of people who love low level code, and we're all putting together a website called Handmade Dev.
I'm alright in C, but would like to expand my knowledge as well... but that code is extremely cryptic, I feel like. 
https://github.com/5225225/cgasm I'm learning, so feel free to comment on anything that's shitty.
I tried a switch statement, and it didn't work. I'll see if I can convert it to be using a switch statement, that might improve the speed a bit.
Quake, Quake 2, or Doom 3, all from id Software's Github
So I took an Algorithms and Data Structures course at my university this semester. Ee learned how to implement and work with stacks, queues, lists, graphs, trees and heaps. Our assignments were always to implement one of the above data structures. Since I realized that I had to implement all of those basic data structures, I thought that it would be a fun thing to do as a first project. So I started my [dslib](https://github.com/ivandardi/dslib) project. I am heavily inspired by glib and the STL library. I think I got a good grasp on how to do most stuff, but hey, I'm still learning. Luckily next course I take will allow me to use C++, so making new data structures will be way easier. Anyways, that is my first big C project. Anyone is free to do pull requests and help me work on it. :) (Here's the link again just in case: https://github.com/ivandardi/dslib)
That sounds pretty interesting. Sometime, when I can find the time, I'd like to check that out. 
I just tried. The problem is that there are var declarations in the blocks. So, making a function do all the work would be possible, but I don't know whether that fits in this kind of 'machine programming'. Would also improve readability though...
thats a good one...
This is what I have after some refactoring. Just personal style. Break up complex things until they become simple things. Readability is the goal. Don't sweat micro-optimizations, in a program like this you're never gonna notice. This is just part of your program, obviously. Result of 10 minutes' refactoring. static inline void opcode_plus(const uint8_t *prog, uint32_t *reg, uint32_t *pc) { reg[prog[*pc + 2] - 'a'] += reg[prog[*pc + 1] - 'a']; *pc += 3; } static inline void opcode_minus(const uint8_t *prog, uint32_t *reg, uint32_t *pc) { reg[prog[*pc + 2] - 'a'] -= reg[prog[*pc + 1] - 'a']; *pc += 3; } static inline void opcode_hex(const uint8_t *prog, uint32_t *reg, uint32_t *pc) { uint32_t tv = 0; uint32_t read = 2; for (int i = 0; i &lt; 8; i++) { uint8_t ch = prog[*pc + 2 + i]; read++; if (isdigit(ch)) { tv = (tv * 16) + (ch - '0'); continue; } if ((ch &gt;= 'A') &amp; (ch &lt;= 'F')) { tv = (tv * 16) + (ch - 'A'); continue; } break; } if (islower(prog[*pc + 1])) reg[prog[*pc + 1] - 'a'] = tv; *pc += read - 1; } static void exec(const uint8_t *prog, uint8_t *reg, uint32_t *pc) { switch (prog[*pc]) { case '+': opcode_plus(prog, reg, pc); break; case '-': opcode_minus(prog, reg, pc); break; case '*': opcode_multiply(prog, reg, pc); break; case 'x': opcode_hex(prog, reg, pc); break; } }
Yeah you have to find the happy medium between modesty and arrogance. It helps when you are in an interview and you know your strengths and accomplishments. 
Is there a reason why you only allow programs of 1500 instructions or shorter?
idt's DOOM is available 
Anything on http://suckless.org
Does that now make you a C++-- guy?
&gt; So we have the native integer representation "int" and its various &gt; modified versions "long int" and "short int" and its signedness &gt; buddies "signed" and "unsigned" Unlike 'char', which is either the same type as 'signed char' or 'unsigned char' (depending on the machine), 'int' is required to be the same type as 'signed int'. Couple of technicalities, though: (1) In Standardese, 'char', 'signed char', and 'unsigned char' are actually three distinct types, so when I say "same type," I'm speaking loosely. (2) Bit fields break the equivalence between 'int' and 'signed int'. &gt; So why not be able to include endianness in the data type &gt; declaration such as "uint64be_t" or "int15le_t". A fair question. The ISO C committee has received a lot of criticism for spending time on what many believe to be arcane nonsense while failing to provide a convenient means for doing useful stuff like handling byte order and structure packing. The thing about the standard is that its idea of a strictly conforming program amounts to a program that's either trivial and useless or entirely nonexistent. Here's Poul-Henning Kamp, the noted FreeBSD developer, wondering the same thing as you (I bookmarked these a while ago because I found them amusing): http://lists.freebsd.org/pipermail/freebsd-threads/2011-December/005177.html http://lists.freebsd.org/pipermail/freebsd-threads/2011-December/005146.html Here he is with some harsher words: http://lists.freebsd.org/pipermail/freebsd-threads/2011-December/005179.html
sqlite is ugly as sin. Mature, robust product, but ugly as sin.
When the CAlottery first started a talk show host said your chances of winning were about the same as flipping a coin 25 times heads in a row, or tails 25 times in a row. So I wrote a little C program that flipped a coin until it got 25 in a row.
&gt; Something even more interesting would be to try and implement a basic userspace filesystem maybe This is a good idea. Try to implement a simple fat16, starting with a vbr, 1 copy of a file allocation table, and a root directory. Use a small blank file like 10mb in size or so. fat16 is pretty simple. make a library that initializes the volume with metadata, implements write(), read(), close(), open(), delete(). could add multithreading and multiple users as well. other good projects: * write a bourne shell (you could use this to test your filesystem) * producer/consumer using POSIX(to practice threading and concurrency) * write a library, like a string library * write a chess program, use ascii or unicode characters for chess pieces. 
error: expression is not assignable
well a string with size_t and char * that inlines small strings into the size_t w/ zero padding would be optimal.
If your program depends on byte-order, you are doing it wrong. If you use `htonl` and friends outside of socket braindeadness, you are doing it wrong. If you read from a file into a structure without marshalling (or use `#pragma pack`), you are doing it wrong. Consider using encoding-agnostic functions like this: void write32le(unsigned char *buf, uint32_t x) { buf[0] = (x &gt;&gt; 0) &amp; 0xff; buf[1] = (x &gt;&gt; 8) &amp; 0xff; buf[2] = (x &gt;&gt; 16) &amp; 0xff; buf[3] = (x &gt;&gt; 24) &amp; 0xff; } This macro works on any endianess. I'm not sure if gcc picks this up already (it didn't when I [checked](http://stackoverflow.com/q/25219621/417501) a year ago) but that doesn't matter anyway as IO is slower than that by magnitudes.
The Linux kernel is poorly designed and unsuitable program to learn anything from.
http://trippler.no/wpcms/?page_id=20 It makes random data pretty &lt;3 
I'm asking because these my friends told me visual basic is extremely easy... You only have to "take" the window and put it where you want... I said "no, it's not possible... Too easy" but they persist, so i'm here...
I'm work on a web crawler framework which allow you to write web crawler by C easily. This program still has many aspects to improved, and I working on it now. BTW, here is the link(https://github.com/luohaha/CSpider). 
FreeBSD/OpenBSD source code - the most beautiful code in C I've ever seen. 
I'd say read a bit before you write. Sqlite, busybox, Wine, Glib are some good code bases to hand. Linux has quite a few good bits, but some hairy bits and it's massive. Personally I like classic books, like "The C Programming Language (2nd Edition)", "Lions' Commentary on UNIX 6th Edition, with Source Code", "Advanced Programming in the UNIX Environment". They don't always reflect how modern C is written, but they are good ground work. Anyway, welcome.
And is it hard?
Great work, thanks for sharing. 
That error probably has something to do with you not allocating enough memory, and therefore your probably overwriting some metadata the allocator requires. result = (char**) realloc(result, i); result[i - 1] = (char*) malloc(strlen(line)); How much memory do you think those two lines allocate, and is it enough for the data your writing into it?
And all UpperCamelCase names are reserved by Windows :-P. In practice it doesn't make any difference in both cases (except you wont have people saying to not use UCC because Windows might use the same name) and you can avoid them. Besides, the `_t` suffix for types is consistent with other existing types (like `size_t`).
I think realloc takes a pointer to the first element of allocated memory and an int specifying the new size. Could it be that it should be result = (char**) realloc(result, i * sizeof(char*)); !?! Trying that out...
That ~~macro~~ function is also dong it wrong as the byte swap operation is native or emulated on most platforms. EDIT: since you winged about it, I changed that word for you. But if you want to get into a pissing match, why _isn't_ it a macro or inline funciton? Why would Anybody (sane) add a function call stack frame and overhead to the cost of encoding one integer? That's not really the point. Anything with a fixed binary structure record, like a platform agnostic file system, or a "raw" image format, could easily be defined for raw structure IO _but_ _for_ "solutions" like word-specific write macros such as the one you offer. consider "le" and "be" as indicator attributes for endianness. (They are two short for practical use, but I'm typing here so I picked a short representation). struct RAWPixel { le uint32_t Red; le uint32_t Green; le uint32_t Blue; le uint32_t Gamma; }; struct RAWImageHeader { le uint16_t Version; le uint32_t Size; struct RAWPixel Data[]; }; ... struct RAWImageHeader * image = malloc(/*size calculation here*/); ... write(fd,&amp;image,/* size calculation here too */); There are no ugly macros or whatever, I can allocate, fill, and write the structure as a first class data item with no questions of portability. For actually working wiht the pixel data I'd probably create a better vector of known native integers for the various usages. So real manipulations would work on something like bit planes. uint32_t Red[imagesize]; uint32_t Green[imagesize]; uint32_t Blue[imagesize]; uint32_t Gamma[imagesize]; and image slices would probably be in vectors of structs in native representation... struct NativePixel { uint32_t Red; uint32_t Green; uint32_t Blue; uint32_t Gamma; }; And if I had to export that same image into a database with the other ordering... struct DBPixel { be uint32_t Red; be uint32_t Green; be uint32_t Blue; be uint32_t Gamma; }; Now instead of all that byte slicing for every element of every macro I can write a for loop for (int counter=0; counter&lt;size; ++counter) { image.Data[counter].Red = Red[counter]; ... } The compiler itself could then generate code like the pseude-assembler below: load r1,r2[r4] bswap32 r1 store r3[r4],r1 ... or ... move r3[r4],r2[r4] Depending on weather or not the native and the specific representation of the 32 bit values are the different or the same. If you don't see why this compiler level support is superior over of all that manual bit shifting and bit masking... well... I wouldn't know what to say next.
thats it. BAM! Thank you! Here you go: `\uD83C\uDF6A`!
&gt; Besides, the _t suffix for types is consistent with other existing types (like size_t). All standard library types are going to end in `_t` because that name space has been reserved precisely for that purpose. Do yourself a favour and don't name your type `something_t`.
No problem :) I guess you fixed the other bug as well then? HINT: "zero terminated strings"
also, it's better to use another variable for the return value otherwise you can't free when it fails and returns null. If you need to read a lot variable length data it might also be neat to wrap it into a structure with a counter and initial allocated block size. You then only resize when counter == the allocated block size by double that ammount. e.g. start with a block for 16 entries (best guess of input) and count the items which you add upto 16 entries, then resize to 32 counting upto that, then resize to 64 etc. etc. This is how the c++ vector works for instance.
thats neat. Too much in this situation, but i will keep it in mind. Variable: thanks, done it!
strcpy copies the nul, so the last line isn't necessary. But, yes, `strlen(line)+1` is correct.
Talk down to someone else. I know about structure packing and portable interfaces. Adding a bunch of #pragma pack noise to _this_ _example_ would have been "effing off-topic". That you don't understand the value of this sort of thing and think a function call worth of overhead to write a single 32 bit value is reasonable speaks _volumes_ about your understanding of cost complexity in computations. That you imagine any program that needs to be aware of storage order is somehow incorrect just indicates to me that you've never actually written any code that needs to be properly portable _and_ binary conformant to things outside your control (like hardware you didn't invent, and the data written thereby). If your take away from an extemporaneous example of intrinsic endian operations took you to structure packing then you lack the focus necessary to be taken seriously. (hint: Every example isn't about every _other_ _possible_ topic and example.) I've made no claim that I don't know _how_ to code around this problem, I'm an old hand at that bullshit, I just want to know why I still have to. A small number of functions called a huge number of times adds up to repetition and error prone duplication of effort. That's the sort of thing a rational compiler _ouhgt_ to do for you. "So damn Easy and Clear" -- sure, and maybe respectively -- but computationally cheap and efficient? Not on this "damn" planet.
Yep, there's a beautiful simplicity/elegance to *BSD code that I find lacking in Linux/GNU code. Even from a purely visual perspective it's more beautiful. 
So close... 8-)
 void newGame(game *session) { int r, c; for (r = 0; r &lt; session-&gt;rows; r++) for (c = 0; c &lt; session-&gt;columns; c++) session-&gt;board[r][c] = rand() % 2; } 
&gt; only a miniscule part of the whole process. You've obviously never dealt with bullk image processing/archiving where getting data formatted in and out of the processor is no trivial thing. Same thing for any number of tasks where you don't control the full stack of hardware and software. So what you imagine about practice is clearly unpracticed. And in what way is all that preprocessing and code, written long-hand, "better" than being able to declare a variable with its required attributes and letting the compiler handle it as needed? You are defending what you are used to _because_ you are used to it. But objectively, the entire value of "type safety" is to automate this sort of thing. A normal program with no external dependencies is one thing, and nobody is going to trip over endian support in such a condition. But simple integer type safety isn't something that should be left demanding that programmers remember to selectively violate type safety in a common task. You are seriously suggesting typing all that instead of being able to type "little-endian" or "big-endian" in the same context one would type "unsigned" is the superior choice? After all, why add two words to the compiler when you can make thousands of programmers type dozens of lines _each_ and then remember to invoke the functions for every relevant access? I know... what could I _possibly_ imagine might get overlooked... I must be crazy to want something so heinous. But _thank_ _god_ I can type "noreturn" instead of declaring the function void, repeat sentiment for any of the other recent "features" have come along to bloat the language. (And your fixation on the alignment of "int" versus "big-endian int" versus "little-endian int" or whatever is pathological and off-topic as "endianness" doesn't change "size" so it wouldn't change "alignment". On any compiler that will already handle "#pragma pack", the packed-ness of the data is already handled separately. The write requirements for alignment are _already_ handled. That code is already in the compiler. So give "toe mai gawd, teh alignments" a rest already. 8-)
thats right... there is this xkcd about segfaults that I'm sure you know. It applies here.
Could be worse than a segfault, depending on how the allocator manages its internal bookkeeping information on the heap. ;) Even on the stack, a one-byte NUL overflow may be exploitable, though with today's OS and compiler defense mechanisms, it's not as likely. On the x86, for instance, if the array was positioned alongside the saved frame pointer (which compilers would typically do if the array was the first thing declared in a block), a one-byte NUL overwrite of the saved frame pointer's least significant byte would affect a critical reference point in the parent function's stack frame. That parent function could then start reading pointers from attacker-controlled words or grab its saved return address from an attacker-controlled word upon ret. Even the most innocuous-seeming problems can be dangerous. 
Exactly like me, I would really like to understand how low level things works (C compilers, kernels, drivers, etc). Maybe starting simple to get the basic ideas. But for now I think that I need to **really** understand trees and queues for my class on uni.
Thank you so much! It's my mistake, I know nothing about these before.
Matrix?
Thanks!
&gt; result = (char**) realloc(result, i); This line is broken. If `realloc` fails (and returns `NULL`) it won't free the pointers passed to it, but you replace the old pointer with `NULL`, so it's a leak. You also don't check the return value of `realloc` and just assume it succeeds, which is also horribly broken. May not be the specific problem you're running into, but it's still broken and should be fixed. 
&gt; ...consider the two types: char * and char (*)[30]. I think that you meant char ** instead of char *. Excellent answer nonetheless.
Yes. And the `/*cba*/` "if" line above it doesn't do anything -- just ends with `;`. Where's the block? I'd also move the "printf" statement from ordering() to main() for consistency. You should also change your "if" statements as caramba2654 suggested previously. For example, this code is bad: if(x == 1) y = 10; if(x == 2) y = 20; ... Once you know what `x` is, no need to keep testing it. It should be: if(x == 1) y = 10; else if(x == 2) y = 20; ... You have the same issue in your code.
I've been working on an emacs editor called MightEMacs for a couple years that I use at home and work (http://github.com/italia389/MightEMacs.git). It includes binaries for OS X and RedHat Linux, but should compile easily on other platforms. If you're interested in a less complex (and easier to learn) emacs than GNU, you might want to try it.
You will probably find this helpful: https://processing.org/tutorials/pixels/
good luck with that! Did that very recently, its fun(and we'll need it)!
its a boss battle :) yep, now I know why everyone told me to rtfm.
I see! fixed it, thank you.
&gt; I am not sure I understand that. Is there a convention that pointer arrays are always followed by a NULL pointer, sort of the '\0' of char arrays? Makes sense... In C all the statically sized arrays -- e.g. `int array[20];` -- you can find the size dynamically with sizeof nonsense as in `sizeof(array)/sizeof(array[0]) == 20`. But once you pass an array in or out of a context like a function, you lose the `[20]`ish-ness. int number_of_indexes(int array_arg[]) { /* it's _impossible_ to know the size of array_arg here */ } int other_search_for_indexes(int * array_arg) { /* same problem here */ } This is the core of the "string problem". You will notice the similarity of `other_search_for_indexes(int *x)` to `some_string_function(char *str)`. The core concept for resolving this is the "sentinel", a data value that doesn't belong in the valid data set but fits into the data type. For strings this is the special character with value zero -- a.k.a. `'\\0'`. When you pass around other data types you need a similar sentinel, for an integer array you might use zero, but zero might be needed. So you usually have to do something annoying. You either need to pass the relevant array length along or you need to play games with signs or explicitly reserved values. This sucks, but it's also why, for example, linux system calls all return non-negative numbers for success and negative-one for errors. For a pointer however, there's a natural candidate. NULL which is really just `(void *)0` -- that is the value zero cast to the pointer type. So with the returning an array of pointers to strings, how will you tell how many lines were read from the file? Without _manually_ adding the NULL you'd need to do something else. One of the "best" techniques is to return a structure with an fractional array at the bottom. struct ProperVector { size_t entries; /* other stuff you need */ char *data[]; }; /* then do the allocations as (pseudocode) ... */ struct ProperVector * new_vect = realloc(X, sizeof(struct ProperVector) + X.entries*sizeof(char*)); And if you want to do super clever stuff you can use a sized array struct ProperVector { size_t entries; /* other stuff you need */ char *data[1]; }; That `[1]` leaves room for the sentinel and the rest of the overhead can go along with it too. (By that I mean it's easy and ready to pass the X.data vector into routines that want the NULL sentinel, even as you get to keep your overhead in line.) Sometimes I use this same thing to keep strings in good order. In high-performance applications I use pairs of pointers... struct string { char * start; char * end; }; struct buffer { struct string control; char buffer[1]; }; Or you can just go _crazy_... struct buffer { struct string * fragments; char buffer[1]; }; The above is a way to keep a buffer and its subsections... so like if you are dividing up a string into a set of sub-strings, like when using regular expressions to carve a large buffer into potentially overlapping chunks. The "string" structure is good for passing slices around. The buffer is also an extensible means of combining the slicing and the storage and it automatically remembers to allocate the extra character for the `'\\0'`. I know I'm just tossing tidbits out there and asking you to imagine the uses. But as you think it through, using pointer pairs lets you do some very high-performance zero-copy stuff. Once you really think about the very simple idea that "sentinels are useful" but also "sentinels suck" a number of patterns start leaping out. P.S. It's late and I'm a little punchy, so I'll check this ramble tomorrow to make sure its not pure insanity. 8-)
having that struct `properVector` makes a ton of sense to me, having started out with java. struct ProperVector { size_t entries; /* other stuff you need */ char *data[1]; }; The `[1]` is like having a placeholder that is always NULL and gets 'pushed' behind newly `realloc`'d elements? Thats great, given all functions working on it obey the rules. 'In situ' algorithms get a whole new meaning with your `struct string`. I am going to try implementing merge sort for strings using the crazy struct, that seems like a good match since if I do the algorithm correctly, there should be no overlaps. Thanks for taking the time to teach a greenhorn!
Well, I've worked in plenty of codebases that don't use typedef at all. The idea being that typedefs hide information and you have to go spelunking to find them. So, there's that option. 
`CamelCase` is a common convention for types.
Yeah, in my other comment I actually kind of realize it just makes sense to have different style conventions for variables and types. Maybe `CamelCase` for types, and `snake_case` for names? Do you use any (free/open source) static checkers for style conventions? The only one that I've used specifically was SonarQube, however my previous work used the paid plugin, which let you define Regex's for different items (types, local/global variables, etc).
LOL!
GLib/GTK does this. CamelCase for types and snake_case for functions. But I prefer universal snack_case and _t postfix. I don't see why only POSIX stuff gets to use this nice convention. It's used in other places alway.
A good type name and convention should mean it is easy to grep for.
Older interfaces in the libc use `MACRO` convention since `typedef` is a rather recent invention, for example, `FILE` was originally defined as: #define FILE struct _iobuf For my projects, I usually don't typedef.
Yeah, thats one of those things that are really helpful when you have to go look for what the impact will be when you touch something. I've definitely used a regex like this for a first look when about to touch the code: `adc_.*_t`. Camel case is definitely possible to regex, but I'd have to go look that up (instead of remembering off the top of my head)
Agreed. I like to keep my coding standards short, machine-enforceable, and reasonable. If you argue about it once during code review, make a rule, add it to the doc, try and check it automatically from now on. Now you never have to argue again. I made a thread over [here](https://www.reddit.com/r/C_Programming/comments/3xhrht/would_anyone_mind_sharing_what_tools_you_use_when/) if you have any suggestions for automatic coding standard checkers. I've been meaning to put together a set of open/free tools, and scripts to automatically run all of them on every save/commit/whenever you feel like it.
`_t` suffix isn't reserved for POSIX officially, as far as I know. AFAIK, `_t` stands for "This is the type of a typedef'ed struct". A lot of people will tell you not to use typedef's (the linux kernel guidelines certainly do so), but I see no harm in defining a typedef to be used inside the file where the struct is defined. I've seen many codebases that use the `_t` suffix. 
Which is why I said "as far as I know". Regardless, it's true that people continue to suffix their typedefs with `_t`
And people continue to spell their words incorrectly. That doesn't mean you should do so, too.
I do not know if this counts, but we use QA-C and Klocwork. These are mostly static analysers but can check some formatting errors too. For a budget project I would use PCLint. Cheap and incredibly powerful.
`strcpy` **cannot** write past the end of the buffer, when you just allocated the buffer by using `strlen` of the thing you are copying from, + 1. Both functions have their issues, but it is easier to use `strcpy` correctly: do a length check first. If you want to use a function that does not require any pre-checks or post-actions then do not use either of those options. &gt;So having done the work to ensure the nul ('\0') by fixing the length, strncpy() is better Why is it better? `strcpy` would be more slightly more efficient in this case (if the compiler does not optimize), although that is immaterial next to the security aspect we were discussing. &gt;Better to run off the end of an improperly terminated string during a read then during a write. Not really. Bad reads lead to awful bugs too, especially ones that seem to work OK in testing and then fail in the field. 
No, POSIX does reserve it, but that really doesn't mean much since so many people (including me) use it anyway. Just check to be sure you don't collide with any POSIX stuff and be prepared to fix it if it does in the future.
Opinions... /sigh. strcpy() _CAN_ be coerced to miswrite the destination buffer. Not in this program if we _presume_ that it is single threaded, and not in this program because there is no sign aliases to the pointers. In "best practices", however, you always protect the _write_ with a bounds-check. Period. Most of this program wold be better dealt with via `strdup()` anyway, but if yous still don't get why I prefer strncpy() to strcpy(): - long read is a safer bad outcome than long write. - there is no negative efficiency to `strncpy()` since - we had to do the `strlen()` to size the buffer anyway - we exact-sized the buffer to a copy length so the same number of bytes that an unperturbed strcpy() would copy absent input corruption. - with asynchronous input corruption on the table (via string arguments or threading, which probably isn't the case here, admittedly) the distinction is real - _Best_ _Practice_ is that thing you "always do" so that when it does matter you didn't make the "bad" choice by habit. Explicitly bounded writes are _always_ the "Best Practice" function call choice since stack and heap integrity are always on the line and a runaway read will not damage a stack or a heap.
Is there a reason _not_ to just use `itoa()` or good old `snprintf()` to format your received byte input into a string buffer? itoa() may be optimized for your platform, though it's not technicaly standard, and snprintf() is safe as houses and absolutely portable.
I _hate_ code formatting tools. (/ignite religious wars here) Part of the job of a source code is to communicate with later programmers -- who may or may not be you. Strictly enforced layout rules often hide tricky bits of thought by burying them in monotonous shapes. The best source code format for any piece of code is the one the programmer thinks in, and _hopefully_ all the programmers are thinking in the same one -- at least on the big points. So it is far, far better to have formattng guidelines that are "Strongly Recommended™", but having a "and we always run the code through indent before check-in" code formatting dictatorship is just asking for anguish.
same, -Wall -Wextra -pedantic, and run with valgrind.
Well, as the warnings tell you, you are using those variables when they are uninitialized. The variables `firstname` and `lastname` are pointers. This means that their values are memory addresses. You are passing the values of each one to `scanf` in order to give `scanf` the address of a memory location in which to store the string it reads. But what are the values of those variables? What memory addresses do they hold? You haven't initialized them to anything. They are uninitialized. You need to allocate memory to hold those strings, and then you need to be passing `scanf` the address of that allocated memory.
Your not allocating any memory to hold the strings. That it runs without crashing is just pure luck.
I understand what you are saying. I shouldn't be using pointers.
I didn't say that. You can't use `scanf` without using a pointer, because you have to give `scanf` the address of a memory location in which to store its result. But the pointer that you give to `scanf` has to point to something.
&gt; Well I fixed it using arrays instead of pointers. You didn't use arrays *instead* of pointers. You used arrays *and* pointers. The value that you are passing to `scanf` is a pointer—the address of the first element of the array. &gt; So could I do something like: &gt; &gt; char * firstName; &gt; firstName = (char *) malloc(20); &gt; &gt; To achieve identical results? Yes.
&gt;The idea being that typedefs hide information That's the point. Information hiding is about obscuring unimportant details so that you only have to think about important things. 
https://en.wikipedia.org/wiki/CamelCase
Length of string read nets undefined behavior rarely, if at all, unless it is in concert with the design and implementation that sloppily uses string buffers without protections. Describe for us, if you would, an undefined behavior caused by a string read that _doesn't_ hinge upon a later failure to use a constrained write (such as using `sprintf()` instead of `snrintf()`) and/or check the return value of such a function to discover that it ran out of destination buffer. That is, crash, if you will, a program using an unconstrained _read_ without, say, shaving off return value precision into a presumed data type -- e.g. you can crash/hang a program using things like. /* pretending to "know" that a string has a limited possible size sch as */ uint8_t length = strlen(unsanitized_string); /* or */ char buffer[1000]; sprintf(buffer,"%s", unsanitized_string); /* or */ snprintf(buffer,sizeof(buffer),"%s :: %s",unsanitized_string,other_string); /* ^^^ Didn't make sure return value was less-than sizeof(buffer) */ FunctionBadForAssumingStringSanityOf(buffer); /* ^^^ function that crashes program if it can't find two strings and the " :: " glyph */ So yes, if you make a mess of _all_ your string handling then feel free to use `strcpy()` as you might as well hope for the segfault or bus error on the immediate write. Shall we argue `vi` versus `emacs` next? 8-)
Basically, structs actually include the word "struct" in the type name. Typedef names are the exact type name and so they do not need to be preceded by anything. Using your examples, this is how you define a variable named `s` of each type: With typedef: typedef struct {} adc_sample_t; adc_sample_t s; Without typedef: struct adc_sample_t {}; struct adc_sample_t s; If you included both: typedef struct adc_sample_t {} adc_sample_t; struct adc_sample_t s; //uses the "struct" type name adc_sample_t s2; //uses the typedef type name Note that the types are essentially equal. You can assign the address of a variable of one type into a pointer variable of the other type: struct adc_sample_t * p = &amp;s2; //p has type "struct adc_sample_t *" but &amp;s2 has type "adc_sample_t *" or assign a variable of one type into a variable of the other type. adc_sample_t s3 = s; //s3 has type "adc_sample_t" but s has type "struct adc_sample_t" TL;DR: it's purely a namespace-ish issue
I'm doing the following: typedef enum { /* ... */ } adc_sample_status__u; typedef struct { /* ... */ } adc_sample__s; typedef &lt;truely opaque type&gt; adc_sample_opaque__t; Unions get a "__u" suffix, structures a "__s" (that is, structures where the fields can be referenced by the user); the rest get "__t" (note: all of these are two underscores followed by a letter). 
&gt; Why would I use strings? Char arrays are better! THAT is what I call low level control. I don't want your bloated string class. Combined with inline assembly, C is where it's at. Because of this paragraph, I seriously cannot tell if this post is a troll post or not. Honestly.
The most usefull tool is compiler instrumentation like address sanitizer. For formatting I sometimes use clang-format.
I've recently become a fan of gcc's sanitizers (memory sanitizer and undefined behaviour sanitizer). It does a lot of stuff for the stack that valgrind misses.
While you cannot declare variables of type `void` normally, you can declare them just fine if you make them `const void`: extern const void end; Some poorly written compilers don't like this and crash though.
&gt; I am implementing a memory pool and the idea is that consumer thread &gt; can mark the memory atomically as read, so the memory pool can reuse &gt; it . Do you think that it would be a right choice ? This sounds reasonable, though the devil is in the details. However, in a producer-consumer situation (since that's what this sounds like), fully lock-free is generally the wrong approach. You *want* your producers to block when the buffer/queue is full, and you want your consumers to block when the buffer/queue is empty. Unbounded queues are dangerous. The primitive you would use to implement it, semaphores, when [implemented well](http://preshing.com/20120226/roll-your-own-lightweight-mutex/) (i.e. benaphores, futex, etc.), use atomic operations most of the time and only lock when necessary (on contention: buffer/queue is full/empty). &gt; At the end of q_initialize ? Yup, just before returning put `__sync_synchronize()`. This ensures that all the writes will complete before the function returns. It's a stronger memory barrier than strictly needed, but for one-time initialization it's fine. The atomic operations in push and pop are implicit fences, which is why you usually don't need an explicit fence in those functions. &gt; Do we have double wide cas in gcc ? I thought that `__sync_bool_compare_and_swap` could operate on structs, but researching it now I see that's not the case. It's only valid on integers. The equivalent C11 function, `atomic_compare_exchange_weak()`, [*does* work on structs](http://nullprogram.com/blog/2014/09/02/). The struct would look something like the following (increment `aba` on every update). struct example_dcas { void *p; uintptr_t aba; }; On x86_64 you would need to compile with `-mcx16`. Some platforms don't have double-wide compare-and-swap, so to support those you would need to find another work-around. 
That's very helpful, thank you a lot. I definitely look at lightweight mutex implementation. In your article you mentioned Load-Link/ Store Conditional. I think cas ( GCC ) will translate into ldrex/strex instructions on armv6 which is ll/sc . In that case, do you think that __sync_fetch_and_add will behave properly ? I found that your project ( lstack ) is on my studying list, i will study that first.
Maybe take this opportunity to link to your videos instead of making people google for it :D 
If you can confirm that fact about ARM, then the ABA problem is presumably already solved for that platform. My knowledge is mostly limited to x86, though, so you'll have to check the documentation. (Though unfortunately GCC's built-ins are underdocumented.) I also have a [single-writer, multiple-reader lock-free queue](https://github.com/skeeto/). I haven't given it as thorough a review as the stack, though. 
And that's what std::string does on most implementations. SSO has been a thing for years.
Huh, TIL. Although the important part seems to be the `extern`, not the `const`. You can declare an `extern void` or an `extern const void`, but not a `const void` or a `void`. This quick and dirty demo compiles fine with clang and gcc: #include &lt;stdio.h&gt; int main () { extern void a; printf("%lu\n", sizeof(a)); } Judging from the output, the size of `void` is apparently 1.
 cc -std=c11 -o main main.c ./main 1 Compiles and runs without warning. Same result with `-ansi`, and with clang plus either flag. It looks like `sizeof(void)` being 1 is indeed [a GCC extension](https://gcc.gnu.org/onlinedocs/gcc-4.4.2/gcc/Pointer-Arith.html#Pointer-Arith).
It sounds like you want to design your own hash function? Unless you know your shit i would suggest using ANY other hash function you can find on the internet. The new shiny is probably MurmurHash3, but it requires reasonably new hardware to be effective. Personally though, i would choose something simpler... This list has a few http://www.partow.net/programming/hashfunctions 
It looks like these functions aim to create a string. In my application my end goal was to split 1 char into 3. Each byte will go to a different function on the screen (a gauge or dial from a sensor/my arduino) so combining the information won't help unless I want to use multiple bytes for larger numbers.
This! Actually, only the actual function was giving me problems: I can use an already existing function, as you pointed out, and then solve collisions through double hashing. Thank you!
Typing the word `type` has never killed anybody. The C mentality has its roots in the days when identifiers were constrained by space (seven chraracters to be precise). That gave us "why type 'create' when you can type 'creat'" and his little buddies. Also, back in the day, the `ype` added significant compile time for a long project as `bob_t` and `bob_type` could really add up when you were effectively paging from floppy. I was there, I remember it in detail. People still cling to this impulse to use abrv instead of abbreviate, seemingly because "that's the way we do things around here". It's pure culture. All of the reasons for terseness are long gone, now it's just a bad habit. So just add `_type` or `_Type` or `Type` if it works for you. I don't decorate types at all, I tend to use the generic name of the implementation as a type and the use classification as the variable. /* nobody is going to misread this */ EmployeeList_Type New_Hires; EmployeeList_Type All_Employees; ... add_to_list(All_Employees,New_Hires); And the `_Type` is pretty unnecessary really. Code has to read fluently and be easy on the eye. 
https://www.youtube.com/watch?v=cDICuT9lKYo I wanted to add digit readout to the dial in the upper left. As stated above (albeit not very clear) it's just using unsigned char so it comes in from 0-255. In all actuality it is coming in as code for escape, #, &amp;, *, HOME whatever, but the program sees 0-255. I did what /u/acwaters recommended above with mod and division and stored the result in digit1, digit2, digit3 variables. The program then has if-then statments for each digit that say if it is 0-9, pick the corresponding texture for that number and draw it in the correct location on the screen depending on which digit it is drawing. Hope that helps.
&gt;I've tried learning Python but I found it incredibly boring and slow. Then maybe you need to get better at it, snowflake.
So you are using a graphic texture to display the digit, and picking that texture from some sort of lookup table/array. Makes sense. I'd just stop using the word "digit" as that implies a character set and character to most programmers -- at least in my experience. Not sure what I'd recommend in its place though, something with 'radix' 'value' and whatnot... so okay. Most of my arduino work has been practical (multi-zone heating controls for a geothermal heat pump) so its all been about the relays and sensors and no so much about the terse ASCII display. 8-)
If you mean find boring as in you're not getting the opportunity to type floats/ints/booleans/strings I recommend picking up Java. you will get the opportunity to type all those primitives and Java specific types and casts. 
Watch all the videos you can about how pointers and addresses work. Also get linked lists down. These two things will help you an incredible amount. 
There are many reasons to choose C over Python, but "boredom" is a new one to me. Are you sure it's the language that you found boring, and not programming itself? I know plenty of people who find programming boring, but I don't think a different language would make them feel any different. Anyway, if you found Python boring I suspect you'll find C even more so, with all the additional details regarding variable types and memory management that you have to keep track of. I doubt that going from Python to C will give you a better experience.
&gt; He only wants all functions to be a screen of text. If it's more than a screen of text That is reasonable. &gt; The entire source (over 700 files) is entirely flat; no subdirectories. Depends, does it matter or not? If you can still find your way around easily then it's better than creating pointless hierarchies. &gt; Most of his functions are used once and not by anything else. Says this is "layering". This is not layering, but there's nothing wrong with that if it means separation of concern and simpler functions. &gt; No comments; says he doesn't believe in them That's the most idiotic thing you could possibly hear. I generally expect that from "superstar programmers".
Good tools must be boring.
Why don't you use the battle tested https://github.com/troydhanson/uthash?
An interesting macro based implementation, I will definitely check it out after I'm finished implementing mine. Thanks.
First, C programs are not called "scripts". Generally, scripts are interpreted, not compiled. Second, why did you keep installing more and more stuff? Post an example program you're trying to compile and the exact steps you're taking to compile it, along with _all_ of the output you get along the way, including when you try to execute the EXE. You probably cluttered up your path with so many different compilers that none of the environments you installed know which one to use.
Hmm... How is python boring? Maybe you should learn some libraries. I know both C(C++) and python, and C is really boring because you spend more time debugging the program then actually making things. And there's really no reason to learn K&amp;R C, as it's incredibly outdated. Honestly, there's no reason to learn C, unless you are doing low level systems programming. Keep learning python. If you hate python, pick up Java, or if you really want to learn a systems programming language, learn C++.
You got a newline on the end of your string? Sometimes (can't remember when, might be consoles on Windows) it won't be flushed until a newline or a manual flush. So it could be exiting without printing anything because of that. If you do have one just try fflush(stdout) before you exit. Without seeing the code I'm just guessing. You code should be: #include &lt;stdio.h&gt; int main(int argc, char* argv[]) { printf("hello world.\n"); return 0; } 
Both C and Python are fun. It takes much longer, I think, for C to become fun than Python. You can get started writing significant programs in Python quicker than in C. Typing programs in the interpreter is another factor of fun, for me, though I primarily loved that in Lisps.
I suppose that makes sense. Here's a preview where I download the source code from id's Github and built it in Visual Studio 2015. https://www.youtube.com/playlist?list=PLBKDuv-qJpTbCsXHsxcoSSsMarnfyNhHF I won't be using this for the main series, but thought it would be a good place to start. Enjoy!
The `exit()` function (which is implicitly called when `main()` returns) flushes all output streams before returning.
Well this is kind of not that bad. Here's a better suggestion. I'm assuming this is a parser for a compiler. Don't all your tokens end of with a whitespace except the last one? Why don't you replace the whitespace with a null-terminator? And now you just need need keep the pointer and type. 
Not that then. Mmm
Unfortunately, they don't all end with whitespace.
Well said. Premature optimization refers to spending time and effort "optimizing" -- generally for speed or memory usage -- code at the expense of readability, maintainability, or "just getting it written". In other words, it's an intention more than an action. If your purpose is to save time and/or memory and you haven't done any analysis, then it likely is premature optimization. 
I see. Is this a parser for the compiler front end? Then there might comments or lots of whitespace, which equates to unused dead memory inside the big block. A huge hunk of memory is generally inefficient and cache-unfriendly. Plus generally, allocating more memory than you need at any time is a recipe for cache misses which adds to suboptimal performance. Personally, I would allocate and copy each token into its own block. Also have you looked into bison?
I don't think this is wrong. If you think this is a reasonably efficient way of doing the operation you want to perform, that's fine.
Apart from suffering from the typedef-with-`_t`-suffix disease (just use `struct token`), I think this is a completely sane way to tackle the problem. You have a const pointer to char, so the source is read-only. By working with string lengths instead of null delimiters, your parser is immune to crashing on input that contains nulls. Null-terminated strings are overrated anyway, because you can do pretty much any string operation with the `strn*()` or `mem*()` family of functions. You can define your own helper functions for more specific operations. Of course you do it this way, what other way is there?
getting bored of one language and trying to fill that void with another language is like jumping around to a newer, hotter girlfriend every time one pops up. the best thing is to learn how to like it by getting better
I believe Doom 3 is C++. For Quake you can follow this [guys work](https://www.youtube.com/playlist?list=PLBKDuv-qJpTbCsXHsxcoSSsMarnfyNhHF) He is trying to do something like Hand Made hero but for Quake. Might be interesting.
I remember reading some blog where the guy did a simple review on a part of the redis code. It was really nicely done and showed how well it is organized, but I can't find it on google :( Any google fu master??
This seems like a really interesting project.
"Premature optimization is the root of all evil." - Donald Knuth
Why do you need to use that huge number as a seed?
You need to use the modulus operator `%`. X % Y gives the remainder when you divide X by Y and is an integer between 0 and (Y-1)
Is there an RNG that had a big enough internal state to be able to use that number as a seed? A mersenne twister has about 20000 bits of state (2^ 19937 = 10 ^ 6000). And that's considered big. You have 10 million bits. However, to answer your question, you would pass it in in as an array of bytes of a suitable size (10Mb if my calculation is correct). That's if you find a RNG with that big of a state
Library Of Babel. I want to use the seed as a kind of a location of the book in the Library. 
You don't need to seed with that value. That's just the amount of possible books. What your assignment wants you to do is to generate a lot of random numbers between 0 and 55. That's all there is to it. You can simply use the clock as a seed. 
Okay, I know this is /r/c_programming, but I suspect that the reason you're not finding much is because people generally fall back to some scripting language or another for "small tools". That said, we need a better definition for what you need to build. Generally, folks build tools for a purpose- because they need a small, but useful program. Programming "tools" usually end up getting built in the highest-level language which 1. is reasonably fast, and 2. has the easiest access to components on the "next lower level" of abstraction. So, if I'm building a tool to manipulate files, I'd probably write a Bash script or a Ruby script (considering I'm usually a Ruby dev). I wouldn't benefit from dropping down to C, because the speed increase doesn't matter that much in relation to what I'm trying to do (writing to the filesystem is slow, even when the kernel's doing some buffering for us) If, on the other hand, I'm trying to write... say, a test program for a device driver, I'd write my tooling in C, because dealing with syscalls and binary data in most scripting languages is fiddly at best. At least, in my experience. Does that help at all? Feel totally free to describe your problem in more detail.
It's not futile; it's pointless. If you think you need a seed that large, you don't understand how PRNGs work.
There are tons of open source desktop applications. Anything specific that comes to your mind?
Almost all the basic UNIX tools are written in C. Look up GNU Coreutils, or browse the source tree of a BSD.
My preference is to not decorate for type at all. But that wasn't the question. I got over things like LPSTR once I saw it, doubley so once the types behind the type signatures changed but the interfaces couldn't be reworded. Types are for compilers, code is for people. 8-) 
I definitely agree with all your points and often it is just easier to use a more high level language with a more extensive standard library. You just have to compare the python standard library with the C standard library to see the difference, which is OK for C since it is supposed to be so simple for better portability. But if you really want to write "tools", what I interpret as small scripts/programs in C the standard library will not get you very far and you have to drop into ugly platform depended code. If you still want to use C for tools the best option would be to either write a more extensive library for yourself or use and extent an already existing library. Sean Barrett has an interesting [youtube video](https://www.youtube.com/watch?v=eAhWIO1Ra6M) (it is a bit lengthy but worth it) describing his process for writing small C programs with his [single header library](https://github.com/nothings/stb/blob/master/stb.h). So if you really want to use C than this is probably a good start. Small thing that I noticed while writing some small tools in C is that you have to program in a completely different programming style than otherwise. For example string handling can get quite ugly in C at least if you have to manage all that memory. But you can simplify it by for example just allocating one big memory block in the beginning of the tool and just allocate from it and only free the memory at the end of the program. This should by no means be the definite answer of how to write small tools, but I hope I could provide some interesting points.
That was Lock free Queue !! This is Priority Queue ( Max Heap ), two different things .
If you had such a large, truly random number, you could just use it as your entropy source instead of using a PRNG. I think you need to copy and paste the text of your assignment so that others can help you understand where your problem is.
Hi. This is the second, or third, post on concurrency/parallelism related subjects that I see you posting. I think maybe you'll find this material interesting: https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html
Why don't you like the `_t` suffix?
For the lack of one, have a shitload: https://wiki.gnome.org/Apps They all are open source, so you can take a look at their code.
I've heard Go is really good for writing tools, I just haven't had enough time to look into lately. Anyways, thanks for the references!
I guess I could be a bit more detailed, so I am wanting to write just...any type of low level tool, I know that's vague but the reason it's vague is because I want to do it just to learn how that sort of stuff works, not really because I have any particular problem I am trying to solve, however let me give some examples of things I feel like would be cool: -A Codec -Any kind of driver software -Plug-ins for an IDE or something like that (I would like one that does better syntax highlighting for my comments but I suspect you wouldn't do this sort of thing in C) -Anything related to a web tool that you would write in C, like I don't even really know where to start with that or what it would really entail, but it sounds really interesting and I suspect it would teach you a lot about how the web works in general :P (to be clear I do web dev so I'm not a total newbie, I just don't know how it really does things at a deep level). Hope that gives you some ideas of what I mean, and hopefully it clears up that I don't actually need the tools, I just want to learn to write them, which sounds pointless but it's part of how I learn I guess, haha.
Messaging you on [**2015-12-22 23:30:00 UTC**](http://www.wolframalpha.com/input/?i=2015-12-22 23:30:00 UTC To Local Time) to remind you of [**this.**](https://www.reddit.com/r/C_Programming/comments/3xtw0c/thread_safe_priority_queue_in_c/cy7y0uy) [**CLICK THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/C_Programming/comments/3xtw0c/thread_safe_priority_queue_in_c/cy7y0uy]%0A%0ARemindMe! 6 hours ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! cy7y25t) _____ |[^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^([Custom])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^([Your Reminders])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^([Code])](https://github.com/SIlver--/remindmebot-reddit) |-|-|-|-|-|
Fixed it by putting a &amp; before the vector in scanf My code works and I don't understand why. A friend of mine will be explaining me pointers later though. Thanks :)
Yeah I know that, I meant directly using them (writing * and &amp;). Still stupid of me to say that I guess? It is clear however I don't understand jack shit about pointers though. Got a 90% on my first sets and started studying for other stuff since I had no more programing tests until January. Even missed most lectures. In hindsight it wasn't a good idea..
Mutexes are *a lot* easier than strictly atomic operations, eh? This queue is straightforward and clean by comparison. Be careful with your chosen identifiers, though. Double underscore is reserved for use by the C implementation. C99 §7.1.3: &gt; — All identifiers that begin with an underscore and either an &gt; uppercase letter or another underscore are always reserved for any &gt; use. Using `static` is sufficient to keep the function private to the translation unit, so there's no reason to get fancy with the name. If you really need more, your compiler and linker will have platform-specific features (visibility, exports, etc.). 
Thanks for your advice, i tried to apply the rules you told me in another post. I wasn't aware of double underscore in C99 specification and will fix it. Is there anything else which needs improvement ?
http://codeandlife.com/2012/04/02/simple-fat-and-sd-tutorial-part-1/ If you need any help or pointers just ask 
&gt; I don't know where the error is occuring Did you read the error message? The error message tells you exactly where the error is occurring. /home/coderpad/execute: line 10: 12 Segmentation fault (core dumped) ./solution Program terminated with signal SIGSEGV, Segmentation fault. #0 0x0000000000400c2b in main () at solution.c:46 46 scanf("%lf", &amp;matrix[counter_line][counter_column]); #0 main () at solution.c:46
sorry, I didnt't expres myself ok. I don't understand what is wrong with that line, and what should be changed... I tried to use %d which implies using int instead of double for the matrix, however the same error occurs...
Well, you can make a copy of your code at coderpad.io, can't you? Just don't make changes to that copy once you've posted it, because it's already hard enough to debug someone else's code without them changing things while you're trying to understand it.
allright, if there is anything you don't understand just ask me 
Are you using that coderpad.io site to compile and run your code? Because if so, you must have noticed that your scanf's don't prompt for input. It is ignoring them and `n` is getting a nonsense value. 
no, I compile and run the code on another software on my pc 
Well 1 definite bug is double computeDeterminant(double matrix[255][255], double matrix[n][n]; computeDeterminant(matrix, start, end)); computeDeterminant wants a 255x255 matrix. Unless you enter 255 for `n` and then 64 thousand numbers, this isn't going to work.
ok lets modify that to 3 and see if it works 
Hey, a couple comments from a first overview. Sorry if I miss the mark on any of these (please feel free to tell me if I am wrong). * MPANIC seems to be similar to assert.h's functionality (`stderr` and `abort`, instead of `perror` and `exit`). Any reason for writing your own here? * `ITER_AND_NULL` seems to be similar to `memset(heap-&gt;array, 0x00, initial_length * sizeof(*heap-&gt;array));`. You only use it once, not sure why it needs to be a macro. you can save some space by calculating `initial_length * sizeof(*heap-&gt;array)` once and using it for your malloc and the memset. * heap-&gt;array is not checked for a NULL value after you malloc it. * no calls to `pthread_mutex_*` are checked for an error return value. Its been a while since I've used pthreads, so I dont know if this is a big deal, but it seems important especially on init and lock. * It would be nice to maximize `const` usage, especially because this is a library. * There are no comments other than license text anywhere in this code. It would be nice to at least have function-level block comments explaining your design choices (like the fact the heap grows by double every time, etc). * There are no NULL-checks of the heap pointer passed in to any API call. If you omitted them for performance, at least make API level documentation that they must be non-null. * the if statement on line 157 could really be broken into multiple parts/lines to improve readability. 158 would be nice to break up too, but I think branches are more important to be readable than calculation * You use *2 and /2 all over the place, it would be nice to pull those out to a constant, so you dont have to grep if you decide quadrupling/quartering the size is more effective than doubling/halving * Ninja edit: You could even make position_to_depth and depth_to_position helpers instead of handling *2+1 or /2 etc. Thats personal preference though * In __pop, consider a switch case instead of three if statements for heap-&gt;current. Thats a minor readability thing though. * In __pop theres some duplicated code between current == 1 and current == 2. Not a big deal. * You could probably shrink the code a bit if you wrote a `_node_swap(node* a, node* b)` helper function. You swap in three different places. * in priqueue_free =&gt; Null check not necessary, free(NULL) is a NOP. * You should probably document it is necessary for the consumer to free the node, and the data in the node, as they are two separate mallocs. It might be nice to have a helper API function that does this, like `priqueue_free_node(node*)`, so if you change implementation later, it does not break user code * If there are items on the heap when priqueue_free() is called, is all of that memory leaked? It appears so. I didnt check any of your logic, just the top level code. I would suggest simplifying the more complex bits and writing unit tests against it. Regarding line 157: if ( ( heap-&gt;array[i]-&gt;priority &lt; heap-&gt;array[i*2]-&gt;priority ) // Left child larger than parent || ( heap-&gt;array[i]-&gt;priority &lt; heap-&gt;array[(i*2)+1]-&gt;priority ) ){ // Right child larger than parent // Determine largest child unsigned int biggest = heap-&gt;array[i*2]-&gt;priority &gt; heap-&gt;array[(i*2)+1]-&gt;priority ? heap-&gt;array[(i*2)]-&gt;index : heap-&gt;array[(i*2)+1]-&gt;index; Hope that helped. Again, if I read or understood the code wrong, feel free to let me know :) **Edit 1:** * You dont re-NULL the additional space when you expand `array` in realloc_heap. * You may want to make sure that `MHEAP_OK == realloc_heap(...)`. You probably should be compiling with `-Wall -Werror -Wextra -pedantic`. I think theres at least one warning/error in GCC for "you didnt check the return value". * You never shrink the `array` member. If it hits 10000 items, but then 9995 are consumed, its still 16k records large.
&gt; computeDeterminant wants a 255x255 matrix. Technically, the first dimension doesn't matter; so it would be fine to pass in an *m*-by-255 matrix for any value of&amp;nbsp;*m*.
Looking at the coderpad page, it seems `n` is retaining its previous value if the input is closed (which I think is correct behaviour)
Super-short primer. - Get a small glass, like a shot glass, - Get a pencil. - Name the pencil "pointer to shot glass" How many things do you have? Two. Are they similar? Not at all. Can the pencil hold water? No (it has no cavity with which to hold water). Can the shot glass "point" at something? No (it's round). Now, drop the pencil on the floor. Is it _actually_ pointing at the shot glass? Probably not. Now put the glass on a table and then put the pencil on the table so that the pencil is pointing at the glass. The pencil has been a "pointer to shot glass" this whole time, but it wasn't a _valid_ pointer to a shot glass until you, the programmer and controlling entity _deliberately_ pointed it at the glass. Now pick up the glass or move it. Is the pointer still "valid"? Nope. You didn't do _anything_ to the pencil, but you changed the shape of what's on the table. Now put you smart phone down where the shot glass was... If something comes along and does a "fill whatever the pencil points to with water" operation, will you be happy? Nope. So all computers work on memory. And the "general memory" of a computer can be put to any real purpose. It's a giant array of bytes. Everything in that memory can be found by knowing "where it is". Imagine the table we were just using was covered with a nice checker-board table cloth and every square had a number. When you put the shot glass down it was _somewhere_. It got a number. When you replaced it with your smart phone, the smart phone got the _same_ number, or at least part of the smart phone got the same number. The phone is bigger than the glass. That number is "the address of" the shot glass, then it was "the address of" part of the smart phone. Now the pencil was somewhere, it has an address as well (but we don't care about that at this point). The value of the pencil was that it "pointed at" the shot glass. So... int * A; // "A" is a variable that "_can_ point to" an "integer" But we've got no integer to point to yet. We have the pencil but no glass. int B; // B is a variable that can contain an integer. Now we've got the glass _and_ the pencil. But the pencil isn't pointing at the glass. We need to have a "tell me the address of something so I can point at it" operator. That's the `&amp;`, the ampersand, the "address-of" operator. A = &amp; B; // hey, I've got this B, find its address and put that in A so that A now points at B Or in your case. x[i]; // This is the value of the i'th element of the array x &amp;x[i]; // This is the _address_ of the i'th element of the array x The last little bit is scanf(). Everything goes into a C function "by value". That is "by copy". So if you send "a copy of the value of the i'th element of x[]" into the function it _can_ _not_ know where the original is. You want `scanf()` to replace the old value of `x[i]` with what it read from input. The function doesn't even _care_ about the old value, it just needs to know where to put the new value. So it doesn't need "the value of" `x[i]`, it needs "the address of" `x[i]` which we get by using that `&amp;` operator. Think of it this way. You are Google and you are sending me a phone. If I just send you a picture of my old phone then you _can't_ know where to send the new phone. I have to send you the _address_ of where I want the new phone to be sent. So `scanf("%f",&amp;x[i]);` reads as: Hey scanf, here's some instructions (the format string) that says "read and save a floating point number", and here is (a copy of) (the address of x[i]) where you need to save it. So just listen to the words. "Thing" versus "Pointer to Thing". Later you'll start getting more complex ideas because "pointer to thing" is a thing in and of itself. As you master your language you'll have "A Pointer to A Pointer to A Thing." and arrays of pointers to things, and all sorts of fun. It's such a simple concept that it gets confusing. Just remember the basics. A pointer _can_ point to something, but something has to make it do that, and the pointer to a thing isn't the same as having the thing itself, any more than my ability to point at a Tesla S means I have one. 8-)
awesome reading material for the holidays :=) That isn't nano or pico, but maybe its femto. Certainly the size of the executable is right :) Happy Holidays and thanks once more.
I've never met anyone besides Casey who uses Emacs as their main IDE. I do think Emacs has some pretty great things going for it - the macros alone are just great. But in the game industry, everyone just works in Visual Studio. It has its own set of tools that I'm more familiar with.
You are right, Doom 3 is C++. I should have typed Quake 3. On a side note, Doom 3 is a very C-ish using of C++, whereas Doom 3 BFG edition is one of the most elegant C++ game engines I've ever seen. There isn't a line wasted or piece of logic out of place.
http://pastebin.com/Y2FmXCXY
i fixed that thanks,but the problem still is that the buffer isn't send to the client..
What value are you passing in as `appnum` when you run the program? Could be a port issue, try a value higher than 1024. Also in the future it is helpful to post the output of the program when it stops working.
i use 20000,i'm rebuilding it after some advices and thanks for the tip!
You should debug this to figure out a few things: 1. Does send return a value? Is it returning a success code? What is the fourth parameter? 2. Is recvln a blocking call? Does it receive data from the clients? Can recvln fail and if so, what does it return? 3. What does 'stops working' mean? Do you get an error at fflush()? What is it? Also, you could try removing as much code as possible to see what still reproduces the problem. Right now, you have two connections. Get rid of one of them and see if it still happens. Simplify it to just a single await_contact, send, and recvln. Does it work?
If you're doing it as an exercise then the data is the least important part of the problem. Get list creation, node addition and deletion working first. If you're going to do an allocation and store a pointer in the list then this will make creating and deleting a node slightly more complex that just storing an int. Will it make a measurable difference in performance? No.
Storing data directly vs. storing data indirectly (i.e. as a pointer) has a measurable performance difference because of cache locality. But if you care about that, you probably wouldn't use a linked list in the first place.
Yeah I know that. My question was purely about the performance impact between void and other data types. They are both a bunch of bytes in the end.
A pointer to void or to a specific data type should be the same, a specific type should give you a lot more secure code in exchange to loss of abstacts
Do a book library. Functionalities: * Add book * Remove book * Look up book by name * Look up book by author * Look up book by ID * Look up book by date * Look up book by publisher * Ability to store books and open them later * Ability to edit book infos * Word look up: how many times a certain word appears in all of the library's books, in which books and in which pages. And whatever else you can come up with :P 
Many errors... Not sure where to start. I also am no good at mathematical matrices, so I can't speak to the logic. But here's some easy stuff: - Don't use "unsigned char" for numbers without overwhelming need. - Don't combine subtraction and unsigned anything especially if you are getting close to the maximum unsigned value. For instance you were using `M[255][255]` and `unsigned char start`. This is a no-no for hiding possible mistakes. double computeDeterminant(double matrix[3][3], unsigned char start, unsigned char end) {...} /* wrong */ double computeDeterminant(double matrix[3][3], int start, int end) {...} When you get better at coding and understanding loops you can start breaking the rules because you'll understand why the rules are there. If you are counting through arrays with an `unsigned char` you are just making the compiler do more work to turn it into a register-sized value anyway. Next, you are doing arrays like a mathematics-guy not like a programmer. int M[20] = {/* data */}; int counter; for (counter = 1; counter &lt;= 20; ++counter) {...} /* WRONG */ for (counter = 0; counter &lt; 20; ++counter) {...} /* CORRECT! */ `M[x]` creates a vector `M` with x subscripts from `0` (zero) to `x-1`. So `int M[20];` is `M[0]...M[19]`. So the wrong line is wrong for starting at 1 (unless the math thing is going to use `M[counter-1]` when working with `M[counter]`, again I don't know the math part). But WORSE, the wrong part is going to try to access the invalid and core-dumping, segmentation-faulting, or random-mathematical-error-causing `M[20]` that doesn't actually exist. When you see "less than or equal to" in any for loop in C there is a ~~high probability~~ near certainty that the code is wrong (unless the end variable has been subjected to some coercion, but it's still bad form). In math speak you should always think of the bounds of an operation in C as the interval `[start_subscript,end_subscript)` In programming terms, the actual subscript `M[i]` is not the 1-to-n you are used to. So `double M[4][3] = {{1,2,3},{4,5,6},{7,8,9},{10,11,12}};` nets the following matrix... M|`[0]`|`[1]`|`[2]` :---:|:---:|:---:|:---: `[0]`|1|2|3 `[1]`|4|5|6 `[2]`|7|8|9 `[3]`|10|11|12 So `M[1][2]==6`and so forth. I cant remember if mathematicians expect the first number to "vary faster" in a matrix, but in programming it's like in aribic numbers, the right-most varries by one then the next one varies by the radix of the right most column, and so on. With clearer reading 'double S[4][3];` reads in English as "S is an array of four arrays of three double precision floating point values". You start with the name, then read right, then go back and read left from the name. The reason this is this way is that the name is the name of the whole thing, and the first part of the whole thing. And each each element is a "distance from" that first thing. This is just how the computer has to access memory. So `type-of-thing ARRAY[X'][Y']`, used as x and y vary, is a request to get the `(x*Y')+y` element after the thing. So when you create the double array M[5][9], and you ask for M[2][3] the computer finds the number (2*9)+3, a.k.a. 21, and multiples that by the size of "double" and that's how many bytes it skips over to find the double you are looking for. So this vector (if we switch to long integers for readability) lives in memory as M: .long 1 .long 2 .long 3 .long 4 .long 5 .long 6 .long 7 .long 8 .long 9 .long 10 .long 11 .long 12 Just one number after the other that the computer thinks of as a block called "M". (Other similar math happens if you allocate arrays of pointers to other arrays, which you have to do if you cannot predict the size of your data set, but that's extra complex so pretend the above is the whole answer until you get the hang of it). So now you know why C counts from zero for arrays and why you never use `&lt;=` in a loop over an array and you simply use less-than (`&lt;`) instead. So sanitize what you wrote for this new understanding of how arrays work in "C" -- by basically counting from zero instead of one in all your loops but still using the "number of things you need" when allocating the space. Once you fix these things _most_ of your errors will be gone.
Similar to what u/grishlefleeple said, but you could doing a ping tester that basically pings a machine passed in as command-line argument. Though honestly depends on how comfortable you are with C? How much have you learned overall?
The first types of programs I wrote when learning C were simple utilities that were missing in standard Unix distributions. For example, you could write a program that converts a text file with CR-LF or CR line endings to NL, with automatic detection. Or write a library routine that will process switches on the command line and return what was found, given a table of switch names and attributes that are valid. Similar to the shell's `getopts` command.
Thanks for all the help guys. Thanks for the tip to test the list. I'll try to use it for testing.
Not good idea up to me, it's preferable to do some useful tool. It will motivate much more then writing useless code. Also you should anticipate question from a recruiter, why did you choose to do this? 
thank you for your answer. I really appreciate it.
What exactly are you trying to achieve? I'm not sure what you try to do, just based on your question.
Learn c beforehand. Don't do more than you can chew now. Worry about that when you are comfortable with programming. I recommend reading Ivor Horton beginning c. I loved that book, it introduced me to programming very well .
I want to "remove" the first five elements of the array... by moving its pointer. Can i do it?
Depends on how `array` is declared. If it's a pointer, you can. But keep in mind that this doesn't remove the items, they are still there, just at a different offset.
And, if not done correctly, may result in a memory leak. I'd advise against this approach. Create a new array, copy over the desired items and free the first array.
or women.
It's a lot simpler than it sounds. Nothing wrong at all with being new, but if you can't do something like that in like half an hour or less then it's probably not time to be asking us how best to represent yourself as a C programmer to employers.
Maybe pointer pointer would be even better.
What do you mean, draw what it looks like? Like, print a fake image of a word doc using ascii symbols to stdout? 
Some projects I did in school when learning c: Write a userspace file system. Copy fat16, for example. Write a shell to test it. Implement a program that encrypts text and decrypts it, using whatever scheme you want, Cesear cypher is an easy one. Create a tool that hides information in images using Steganography techniques. Rewrite malloc(). 
Your post got caught in our spam filter. I approved it just now. I'm sorry for your inconvenience.
Understand that everyplace Java used the word "reference" other languages would have used the word "pointer". Understand that in "C" when you declare `SomeThing name;` you actually get a "SomeThing" because C allows you do have SomeThing(s) directly. Since Java _only_ uses pointers, you've never lived with the joys of copying. (And I do mean joys, that's not sarcasm.) So /* Java */ SomeThing name1 = new SomeThing(); // constructed object cramed into name1 pointer. SomeThing name2 = name1; // two names for the same object /* C */ SomeThing name1 = {/* initial values for thing */}; SomeThing name2 = name1; // name 2 is a _copy_ of name1's contents SomeThing * name3 = malloc(sizeof(SomeThing)); // enough memory for a SomeThing, contents are random. name3-&gt;Data = values_from_somewhere; // initialize the data SomeThing * name4 = name3; // name3 and name4 are the same object like in Java; SomeThing name5 = *name3; // name5 is a _copy_ of the contents of the thing pointed to by name3. So `*` should be read as either "a pointer to" or "the contents of " in C. You've already learned to read declarations backwards (right-to-left) in Java, though you may not know it. Now you have the unenviable task of learning a superset of a dialect. C is "broader of concept" than java. You also now need "the address of" operator ampersand (`&amp;`). So `int A;` =&gt; A is an integer `int B; ` =&gt; B is an integer `int *C;` =&gt; C is a pointer to an integer `C = &amp;A;` =&gt; let C be equal to the address of A `B = *C;` =&gt; let B be equal to the contents of (the thing pointed to by) C Basically the design of Java "spackles over" a lot of the C concepts by doing the work for you, but in so doing it deliberately made certain, useful/annoying/dangerous things impossible. Some of those impossible things are now _mandatory_. So if you can wrap your head around the fact (and it is a fact) that every "reference" in Java was a pointer you'll be several steps ahead. For that recognitian you will now also see that you can use ~~references~~ pointers to the simple scalars, like int, without the annoying intermediate class wrappers. Basically the coaster breaks and training wheels, and indeed, legitimate protective devices, will now be stripped off your programming experience. This is a good, and a bad, thing. Where you used to just replace obects: SomeThing name1 = new SomeThing(); SomeThing name2 = new SomeThing(); name1 = name2; // runtime frees up old name1 for you. you now have to manage lifetimes yourself. /* going to skip initializing stuff */ SomeThing * name1 = malloc(sizeof(SomeThing)); SomeThing * name2 = malloc(sizeof(SomeThing)); free(name1); // you have to throw it away manually. name1 = name2; Why do you have to throw it away manually? Because you have to keep track of whether or not you put it somewhere else. struct SomeThing { struct SomeThing * next; }; SomeThing * name1 = malloc(sizeof(SomeThing)); name1-&gt;next = NULL; SomeThing * name2 = malloc(sizeof(SomeThing)); name2-&gt;next = name1; // free(name1); THIS WOULD NOW BE AN ERROR name1 = name2; So "lifetime management", usually called "memory management" but which is so much more than that such that I hate the term, is a skill and a chore. As such it is both a boon and a hazard. It is the thing you will hate most in changing over between these two languages. Taken as a chore, lifetime management is a minefield that has blown up many a program. Taken as an opportunity, lifetime management can be a fantastic set of tools. In Java you've met constructors, factories, and the "finalize" method. But you've learned that the finalizer is nearly useless because it may not _ever_ be called and if it is, you won't know what's happening around it. In C, if you make the allocation, factory, and constructor concept into a unified thing for a particular structure, then you can make the deallocation and destruction of a thing an equally valuable concept. C++ makes the destructor method a real concept that shames the finalize method int submission. But I've used explicit fixed lifetime management in C since before C++. By writing the Factory and the Recycler at the same time and making sure they are used symmetrically, I find that the I often gain insight into the way my objects pass through their lives, which in turn lets me fine tune them significantly. But anyway, the real difference is that you now get full control, so joy and danger abound.
Its not a modifiable-value. 
I answered this over on Stack Overflow. Here's the TL;DR from that much longer post. TL;DR :: because of the way linux uses and manages data and code, there is never a benefit for marking any part of a normal application as uncacheable that doesn't cause more heartbreak than it saves. As such, there is no unprivileged API for doing this.
I don't have an exact answer but from personal experience, being able to read and understand some good projects in C like Redis is a good point. Because they are real projects intended to solve real problems, you will find a lot of interesting stuff usually not found in books. One example is how redis uses struct hack for dynamic strings and pointer arithmetic to crawl into original struct. http://redis.io/topics/internals-sds
Mastering any programming language takes years and many thousand line of code written. Knowing C on a level that is useful will take many months. A resume is pretty much a list of lies for most people, so you can put it on your resume any time you want to really... The problem with knowledge and intelligence is that it's not easily measurable, and even harder to say when is something useful.
Oh thanks! I just wrote the letters followed by a `.` and pressed enter and this time it didn't record the "enter" as a `\n`, which is good..but why is that? How would I do it if I wanted the user to confirm each letter with a enter click? I mean..if it doesn't take too long to explain **EDIT:** Yeah nvm. It didn't catch the last '\n' because of the break command. Other question still stands though ahah
Another redditor already [helped me here](https://www.reddit.com/r/C_Programming/comments/3y7obn/my_array_is_working_funny_jk_im_just_coding_funny/cyb8wba). But I still have 2 questions...if you're willing to answer them Thanks a lot :D
This is a pretty difficult question; people will expect different things when you say you 'know' something on your resume. As to your personal satisfaction of how well you need to know something before you can move on, that's up to you. If you're not going to be using C (or any other language, really) for anything professionally, then I'd say *any* point is an appropriate one to move on from if you feel you'd like to spend your learning time elsewhere. Having C on your resume is only really useful in a few contexts, and in those cases you're probably not going to get to a point where you can ever stop studying it. That said, here are some "benchmarks" you might judge your knowledge by. Can you write a correct linked-list implementation from scratch, along with appropriate test code that verifies you got the edge cases right, in a reasonable amount of time? Could you sketch out a simplified version of the code on a whiteboard in an interview? Do you know which types in C are considered numeric, and how/when they are implicitly converted in expressions? Can you explain the difference in how C treats signed vs. unsigned numbers? Can you explain how pointers and arrays are related in C? Do you know the rules for casting between pointer types and other types? When it's appropriate to use a void pointer? Can you explain how the representation of C objects can be portably examined and manipulated? How about the effect that the alignment rules have on data representation and manipulation of representations? Can you give a good story as to how to handle management of resources in a medium-sized program so that you won't leak them or release them too early? I.e. dynamically-allocated memory, socket descriptors, etc. This is not so much knowing the language itself as it is knowing how to use it effectively. Are you aware of which language constructions and library usages are syntactically legal but are either prone to security flaws or are common sources of undefined behavior in programs? Do you know how to use tools like linters and dynamic instrumentation (e.g. profilers or dynamic resource analysis tools like valgrind) to find problems or potential improvement in your code? I think you can probably get away with a guarded statement of experience in C (e.g., "some experience with C") without knowing all of those off the top of your head, but it's by no means an exhaustive list and I think you ought to at least know where to quickly find the answers (and recognize when you need to!) if you want to say you've mastered C. And so you're prepared, the bit about writing a linked list is a very common interview question for C programming positions, as it quickly weeds out people who haven't internalized how pointers work. You might also be given a similar task regarding binary trees or some other fundamental data structure.
" %c" discards any whitespace (tabs, line breaks…) and reads one character. It differs from "%c" in that it discards the line breaks, so you won't read the '\n' you get when you press Enter (when you press Enter, that character goes into the buffer, as any other character, so it'll be read the with the next scanf). As for " %1s", it reads a one-character string; it's, as far as I know, *almost* equivalent to " %c", the difference being that a one-character string is actually two-character long (all the strings end with '\0'), which would give you a problem in the hundredth character, since you would be writing that '\0' outside the array.
It's usually done with AND and bits in the appropriate position. Say you want to get the 16th bit of `i`. It'd be `i &amp; (1 &lt;&lt; 15)`. (I don't know if the parentheses are necessary, but they do no harm.) You then would get either 128 or 0; if you want 1 or 0, you can do `i &amp; (1 &lt;&lt; 15) != 0`. I don't know if there's a faster way, but that works. Edit: I've just noticed it was about *setting* and *clearing*, not *getting*. To clear, AND the int with the negated of `1 &lt;&lt; 15`; to set, OR it with that number.
&gt; Mastering C may take many months or even a couple of years You must have a definition of *mastery* that is very different from mine. Since you have a programming background, if there's a problem that you can solve in language *x* but you have no idea how to address it in C (regardless of whether it would be a really stupid move to use C to solve the problem), there's still room for growth. Now if you can create typical data structures and algorithms in C (where "typical" means that you'd probably learn about them in college or be asked about them in a technical interview), I think that's a good sign that you can claim competency in C on your resume. Obviously, you wouldn't get to that point unless you had a good handle on the syntax and were familiar with many of the common library functions.
When you're operating on individual bits, you typically use `|` to set bits and `&amp;` to check or clear them. You can write a function or macro to get the bits you need, and a function to set or clear the cells: #define BIT(n) (1 &lt;&lt; (n)) uint32_t GameBoard[32]; void set_cell (uint32_t *board, int x, int y) { board[y] |= BIT(x); } void clear_cell (uint32_t *board, int x, int y) { board[y] &amp;= ~BIT(x); } void toggle_cell (uint32_t *board, int x, int y) { board[y] ^= BIT(x); } int get_cell (uint32_t *board, int x, int y) { return board[y] &amp; BIT(x); }
You've not really defined the problem very well. What do you mean you have to "do" a string matrix? You have to implement one in C obviously, but what does that mean? What are the dimensions? Is it up to you? Do you do it automatically or dynamically? That is, do you specify it's size up front, whatever size you're told to make it, or do you need to prompt the user or have it made some other way during run time? Is this terminal based? Do you have to print the matrix out to the screen every so often? If the "cleaning robot" hits a 0 it turns it to a 1 and if it hits an x then it "rearranges its path and cleans another block"; what does that mean? Where does it go and what does it do then? Also, you need a string matrix, meaning you need an array of strings, a char matrix, a 2D char array? Do you need null terminators so they're proper C-style strings? Or do you need a 3D char array, a real string matrix? Assuming that this was a terminal based program where the memory for the matrix was allocated automatically, and it was a char matrix without null terminators, and the size was, say 5 rows by 6 columns, I would basically make a 2D char array (double char pointer if you have to do it dynamically) of those sizes and then use a for loop to populate it with 0's, either in a function of in main. Then probably in a function, use srand() and rand() from stdlib.h and time.h to randomly generate two numbers corresponding to the row and column (look up srand() and rand() to see how to set the bounds, in this example you'd have your row between 0 and 4 and your column between 0 and 5 and so you'd generate number between those bounds) and when you get a set of random numbers they correspond to where you'd put an x in the matrix. This should be in a while loop inside that does this some random number of times, for our example here let's say it will generate a place in the matrix to put an x between 5 and 15 times. Another function (because you don't really say what the overall structure of the program should be it might be a function that called again and again, or it could be in main called just once) would be your cleaning robot that uses nested for loops with if statements inside that goes through the entire matrix and looks at each char and if it's 0 change it to 1, if it's an x then do whatever you have to do from there (you don't say). Finally, you'll want to print this out every so often, how do you decide that? You'll need a function to do that, again with nested for loops. Probably call it in main first after it's populated with 0's and x's, then again each time the robot cleans it?
Solid response.
Very good questions. I've been programming in C for eons and had never really thought about it. I think the decision is primary a personal preference, but for what it's worth, I've never seen your Option 1 used anywhere -- always Option 2. If I was looking at someone else's code, I'd be looking for a `typedef`, not a `#define`. The latter would be very strange. What I like about using a `typedef` for a `struct` or `union` declaration is: * I can use a `CamelCase` name for the "object" and also the `struct` keyword by itself (as in your Option 2). * The type name is one word instead of two, easier to type, and more readable. * The name also connotes that the type is complex and can be considered an "object", which is how I like to think of it. So I instinctively know to pass it around by reference instead of by value and am always cognizant of where the object itself *is* (on the stack, on the heap, ??) so I don't forget to free() it if necessary when I'm done using it. Like you, I don't like to have to code superfluous `struct` and `union` keywords everywhere. `StrList` is definitely preferable to `struct StrList`. I also agree that you should not add `_t`. That way, you can easily distinguish standard type names from your own.
And if you can get to D, you can include C++ as well.
I think that with SDL I could do it, unfortunately I'm programming an MCU. The screen will be an LED matrix or just a Nokia 5510 LCD
Sorry if I made it seem like I took your word as gospel, as the mod I reference in the original post is indeed yourself. I never thought of your advice as anything other than helpful opinion, but it would taste a lie to say it didn't leave me wondering (hence my search for clarification). I suspected that the response I would receive was going to be very similar to your answer and other answers provided, but on the other hand I'm new, have it written on my forehead, and am genuinely curious about appropriate conventions when it comes to C. While the (ab)use of the preprocessor I've posted here is certainly not conventional, I didn't see anything wrong with it so long as the code was clear, but now I see that there are cleaner alternatives to this problem, and will most likely be using your rule of thumb from now on, not because I see your word as dogmatic law, but because you've continued to be a reasonable person and developer. Thank you for your continued patience, and excellent advice, as always.
In my totally personal opinion, I'd use typedefs only for working with function pointers. (Examples below.) I'd never typedef structs and enums, because I prefer the structure of my code to be as vanilla and generic as possible. Typedefs in my opinion are "premature complexity", if that makes sense. In my experience, keeping my code crystal clear cuts down on the urge to be "clever" at the micro level, and makes it easier to be clever at the macro level by combining simple parts to do complex things. (Complexity should be an emergent property of coupling simple parts.) However, function pointers are a valid case for typedefs. Let's say you want to make a struct containing a single member called `signal_handler`, which is a function pointer: struct test { void (*signal_handler)(int signum, void *widget, void *user_data); }; Or you want to make a function which takes one argument, which is a function pointer: int test(void (*signal_handler)(int signum, void *widget, void *user_data)) { That's just horrible and confusing. If you create a typedef: typedef void (*SignalHandler)(int signum, void *widget, void *user_data); you can write the much more readable: struct test { SignalHandler signal_handler; }; int test(SignalHandler signal_handler) {
I find that having struct and enum keywords in the code help out with that "self-documenting" thing people always shoot for. Typedefs hide information, which is sometimes what you want, but generally not when using C. I feel the same way about naming member variables in c++ with an underscore or an "m". Just use "this" and it's immediately clear what the variable is.
&gt; When should I use a typedef? All the time! Hear me out. There are a bunch of different reasons for this, and I'll get to them. &gt; (in my opinion more importantly) there is nothing wrong with just typing struct each time I reference my structure. That's a stupid argument. There's nothing wrong with typing `int (*funcP)(char*, size_t, const char*, int)` everywhere, but it's pretty damn annoying, wouldn't you agree? I've got a counter-argument in favor of using typedef... the compiler/debugger I use at work for a particular embedded processor *doesn't recognize `struct` in the debugger*. Or if it does, there's some bizarre syntax to it that isn't documented and that I haven't figured out. So that means if I'm debugging something in an Expressions window, and I need to cast something (like a bare memory address I pulled from somewhere) to a struct, *I can't!* The only way I can do it is if there's a typedef. As others have pointed out, a codebase's existing style guide takes priority. If you work in my company's code and you don't typedef, we'll reject your code as being incorrectly formatted and make you go back and fix it. But even as a general argument, this argument of "well you could always just type `struct`" carries no weight with me. There are much bigger concerns in a decision like this than how much typing you're doing. &gt; I've been using the preprocessor to #define a shortened struct call. Is this appropriate? Rarely. Why use the preprocessor when the language itself gives you a built-in facility for this that's better and less error-prone? The compiler may also offer you better error-checking that way (not really in C) or at least better error messages. &gt; Is there any advantage to using a typedef? Yes. It hides information. That is the *entire f&amp;%king point* of using typedef. Somehow, Linux looked at typedef and decided that hiding information is bad, and banned the use of typedef. They argue that if you're declaring a variable that's a structure, you should know it's a structure, and so they want you to type `struct`. What a poor argument. Firstly, if you're declaring something and aren't sure whether it's a structure or a pointer or an integer, how the hell do you know what you're supposed to do with that thing after you declared it? Generally I'm following an API and documentation, so I know whether I need to look inside the structure (using `-&gt;`) or make one locally and pass a reference to it, or just keep a pointer to one someone else made for me. Based on those usages, I already know whether it's a structure or not. Or, maybe I don't. Maybe it's *designed* to be opaque to the user. At one point in my code, one particular object used to be a `KeyValuePair*`, but we needed to change it to a `KeyValueObject*` (made up types for explanation). Since users held a pointer to this thing (but never looked inside it), that meant all user code had to also change theirs. We decided instead to `typedef KeyValueObject* AccountSettings`, so that it's more apparent what the thing is (since `KeyValueObject` is used in lots of places), but also because *it hides information*. Users only keep a pointer to this thing, but it's opaque to them; they don't need to know whether it's a struct or not. We could have just as well changed it to an int handle, and it wouldn't make any difference to the user. And now that it's a typedef, we *can* change it to an int handle. Only this time, the user *won't* have to modify their code at all. That was the lesson we learned: by not using a typedef from the beginning, we didn't hide information from the user, and thereby involved them in a change that they should have been protected from.
Thank you. It was a hobby project that evolved into a more serious hobby project.
Use a typedef when it makes that part of the program easier to think about.
I totally agree with you, but I can sort of see the point of the Linux kernel people. It *might* be useful to know that something is a structure if you allow people to access the elements inside that structure. So in that case I can see the point of making people aware that the thing they're using *is* a structure (although I myself tend to typedef even in those cases). But where I draw the line is when that struct's elements are hidden from the user. Because what's the point of forcing people to remember that something is a struct if that knowledge is of no use to them? A case in point is the stdio library. I neither know nor care what a FILE is, since I'm not supposed to look inside it. I only pass pointers to them in and out, and that's all I need to do. There's no point in forcing me to type `struct` (or `union`, or `int *` or whatever it is).
What is your reasoning behind this seemingly shortsighted opinion?
I had never considered using a `typedef`on a function pointer before. I suspect partially because I almost exclusively only see them used on `struct`s, but what you've shown me here has completely changed the game. Thank you.
I have commonly used a `typedef` for use 3, and occasionally for use 1, but I haven't yet tried to tackle use 2. Still, these are all great things to keep in mind, thank you!
The 'P' in front means it's a typedef for a pointer. You are calculating the size of two pointers, not the size of two structs. And what's more, you're declaring a pointer to a pointer to a struct, because you're adding a `*` to a type that's already a pointer. There's also no need for this bizarre dance of initializing a pointer to NULL only to assign to it on the next line. PIMAGE_SECTION_HEADER foo = malloc(sizeof(IMAGE_SECTION_HEADER) * 2); 
I can only add that it may sometimes be better to follow such approach: type_t *pointer = calloc(count, sizeof(*pointer)); Note that I try to get rid of repeating the type name and use calloc to avoid overflow (good C libraries usually handle integer overflow inside calloc).
Yeah, I definitely see the usefulness of 2, but I do almost all my development in/for Linux, and in particular for personal use. It's absolutely something I ought to look into if I ever want to expand my horizons though.
This subreddit is not about C#. C# is not C.
These animations are language agnostic and very well made http://visualgo.net/
For Linux and Mac, distribute the binary with the SOs for the libraries. Then they should just be able to run it with everything in the same directory just fine. Alternatively compile the libraries as static and just link them in as one large binary. More work but a little cleaner. For windows, somewhat the same. Bundle the DLLs in with the distribution. 
Thanks. But I already know the concepts. I'll give it a try cause it does seem to be complete.
It seems to be complete, but it's not easy to follow, especially for me. I'll give it a try anyway.
These look amazing. Thanks, I had the same problem as OP and these will be helpful. 
You could take an algorithms and data-structures class.
No time for it.
You've hit the nail on the head. There is *perhaps* some value in making it apparent that something is a `struct` and that you need to poke at the members inside it. But even inside the kernel, when you're just calling `kthread_run()` to create a task and check whether it started successfully, you're *not* going to look inside the structure. So why force everyone to declare `struct task_struct*` when all they really need is an opaque pointer?
One tactic is to compile your code as "static" instead of "dynamic". Static binaries will include all the symbols they need and not use any dynamic library. The downside is that your binary will be huge (because it will include all the symbols from your code and other people code) and the really bad downside is that if they find any security bug/memory leak in the libraries, your code won't be affected. The really nice solution is to use a build system like Autotools (if you're brave enough) or CMake. This way, it will make it easier to find the libraries and allow people to build your code (and it would also help in making a packaged version in the future, like deb or rpm).
I heard of it, but I only know the site. Is it the same with the book?
Carefully proofread where you are using `1`, `2` and `3` at the end of `array`. You've made a mistake in 1 spot. Also `num` is undefined. 
What does 'a=5' do in C? What does 'a==5' do? Are they the same or different? hint: if ( a=b ) is almost always wrong in C. 
ran the code with == instead of =, got a bunch of warnings and the output gave me memory locations instead of whats in array[i]. 
Maybe you should pay attention to those warnings. What warnings did you get? 
When you do this `for(int i=0; i&lt;num; i++){` there isn't a previously defined variable called `num`. This will give you weird results ... I'm surprised it even complied! 
The magic of C where the most common answer is "compiler dependent ".
Don't do OPs homework for him.
I actually figured it out without looking at this post...
This is beyond unhelpful for someone that is just learning how to program....
I will definately provide the source code for people to compile themself. I will look into the static linking, I dont think the size will be a big problem! Thanks a ton!
Thanks for the suggestion, on static linking. I will try to use CMake, it looks pretty powerful! 
Be careful with licenses when linking statically though.
There was once this SO post which challenged people to write complex solutions to CS-Freshman problems which were right but would be probably overkill in any situation. Don't hate the player, hate the game ;) PS: On mobile right now so I can't source you on that one sry!
All the suggestions above are good. However, if the end user is a novice then asking them to compile etc can be a bummer. My approach would be to look for multi platform installers which can make a single binary installer and will provide user a simple experience. The installer takes care of installing dependent libraries etc on each platform. In additional you can bundle your source code if needed with installer. From user experience, next best option is to statically link everything and provide a single executable. 
Thanks for the reply. The processor that the program was running on is an i3. I thought that i3 only had two cores? Do some i3's have more than 2 cores?
Those same languages are less popular with programmers, at least hardware-facing programmers, for exactly the same reasons but simply facing the other way. Now I'm an Odd Duck™ in that I genuinely enjoyed Ada because it had in-built array slicing and it carried the indexes around with it. The language had first class support for asking an array what its current bound were and you could just add and remove chunks. But I also love the sparse elegance of C's interactions between indexes and pointers. The relationships inherent in the idea that the subscript is also the "distance from the first element", and the address of the array is also the address of the first element, means that when using vectors (arrays allocated in contiguous lumps of memory) one can write code that flys through the mind and the processor. The total mental baggage is purely psychological. I've switched back and forth between 0-based and 1-based arrays in languages freely for most of my programming life. void Transform(double * vector, size_t size, double factor) { double * extent = vector + size; while (vector &lt; extent) { *vector *= factor; // multiply in the factor ++vector; //move on to the next element } return; } ... double OneDimension[30]; double TwoDimensions[5][4]; double AdvancedExample[7][4][18]; ... Transform(&amp;OneDimension[0],30,0.5); Transform(&amp;TwoDimensions[0][0],(5*4),0.5); Transform((double *)AdvancedExample, sizeof(AdvancedExample)/sizeof(double), 0.5); This then leads to the truly generic code for allocating and pushing around variable sized vectors (which I won't elaborate here). It also takes us to the land of the vector processing instructions and hardware that make modern graphics and modern data set processing possible -- also not elaborated here. There is very little reason for most non-programmer scientists to learn the intricacies of programming, they have their science to do. But there's also a reason that the compilers and interpreters for the languages you mention are all implemented in a mix of C and occasional bits of "portable Assembler" or platform specific assembly. And this isn't a dig at those scientists, I've never wanted to write a web browser since others have that covered, and a there is no reason anybody would expect anybody would _want_ to code out what Matlab does by hand every time they need a graph. P.S. If you are using Matlab, I'd suggest trying [Octave](https://www.gnu.org/software/octave/ "open-source and free alternative"). There are some patented syntax in Matlab that Octave could not then implement exactly the same way... because patenting math is evil. But if you switch you don't have to "borrow" copies of Matlab for new computers or to take home.
That falls into the "its far more complex then that" segment. Basically intel chips have something called hyperhreading, which runs two threads on a single core to simulate additional cores. Generally they are not considered as good as actual additional cores. But there are of course other opinions on the subject.
Thanks for the information.
The performance gain is dependant on the percentage of your code that can be parallelized. Look at Amdahl's law (https://en.m.wikipedia.org/wiki/Amdahl%27s_law). 
Very nice, thank you.
Another question I have for you is if there's a standard text for multi-threading in C similar to how K&amp;R is a standard text for C?
&gt;Is multi-threading part of the C standard library? Not quite. You'll either use an OS-specific library, or a more general framework. You'll also need to make a distinction between multiple processes (different address space) and multiple threads (same address space, can be many threads/process). On UNIX you'll generally use fork from unistd.h to do multiple processes, or pthreads is a common solution for multiple threads. On Windows you'll use functions from the win32 API. Alternatively, you can use higher level, more generic threading libraries. One such example, which you mention, is OpenMP. &gt;Would I have to use something like this or is OpenMP only for multiple processors? Would writing for multiple cores be the same as writing for multiple processors? Does a thread know whether it's going to a core or a processor and does it matter? To make things simple when you're just starting out, I think it's safe to assume you're only using a single CPU with multiple cores. Each core is it's own execution unit and can execute one thread at any given time (not strictly true for the pedants out there, but ignore this for now). OpenMP will be just fine in this situation. &gt;Should I expect a linear performance increase (e.g. a program written with 2 threads would generally be twice as fast as the same program with one thread)? The guy who linked Amdahl's law already provided a great answer here. To add to that, Amdahl's law is the theoretical maximum speed boost you can get from parallelization. In practice you will see smaller gains due to various threading overheads like synchronization, context switching, cache contention, and more.
Tacking onto this while I wait for a train at a bar. Hyper threading allows for running multiple contexts on a single core concurrently, but not truly in parallel. Concurrent is asynchronous and can generally be run in parallel, but in the case of hyper threading true parallelism can't be achieved because a single core can only execute one instruction at a time. It is possible, however, to obtain better performance in some applications that rely on context switching or parallel computing with hyper threading, but mostly, hyper threading allows for better execution of multiple programs because hyper threading silently maximizes utilization of shared resources. This includes stall or io wait, but does not include things like a cache miss since a cache miss will just require an additional synchronous fetch from memory. Since hyper threading is at the processor level and not at the operating system level, in general, you can usually get better performance from threading a program, but only if the problem is inherently parallel. If it is not, you will actually see a reduction in performance. Also, if it comes down to a work situation, if the problem is easily solved with an unthreaded solution and doesn't require massive amounts of processing power, I generally advise to use the simpler approach. It is easier to write and maintain. For educational purposes, though, I say go for it. It'll make it a lot easier when you need to implement something for real and the synchronous case will take days, weeks, or months longer to process!
Thanks for expounding on that for me.
&gt; Each thread can run on one core, so if you have two cores, two threads can run at the same time. Not really, you can have multiple threads on a single core. see: http://stackoverflow.com/questions/16116952/can-multithreading-be-implemented-on-a-single-processor-system
Since everyone is mentioning threading I thought I'd share my knowledge of threading - incase it's useful. There is a standard c library for threading called `pthread.h`. Here is an online example: http://timmurphy.org/2010/05/04/pthreads-in-c-a-minimal-working-example/ And I made something ages ago to demonstrate it to myself here: https://gist.github.com/geekskick/827917ac8b0744403764 Hope it helps
Quick question since you seem to know about hyperthreading... if a cache miss generates a page fault does that then become an IO event that would allow a hyper-thread context switch? I don't work on x86, but your detailed explanation has made me curious.
Why are MARK1 and MARK2 lines the same? if(array1[i] &lt; array2[i]){ array3[i] = array1[i]; // LESS !!__MARK1__!! }else if(array1[i] &gt; array2[i]){ array3[i] = array1[i]; // GREATER !!__MARK2__!! }else if((array1[i] = array2[i]) || (array2[i] = array1[i])){ array3[i] = array1[i]; } So I couldn't tell what you were doing (going for min or max of arrays, but you've gone _way_ overboard. First off the entire else-if thing is wrong. And equality is transitive so `X==Y` and `Y==X` are the same question. (btw `X = Y` assigned the value of Y to X, even in an if statement.) Also, in the case of equality it doesn't matter which one of the source arrays you pick because they are equal. So you test for less than (or greater than) and if the first test passes you use that, otherwise you _always_ want the other one. // find minimum values between two arrays if (array1[i] &lt; array2[i]) { // use "&gt;" to select maximum values array3[i] = array1[i]; } else { array3[i] = array2[i]; } Meanwhile, if you really want to understand why the program is horribly wrong start with making array1 and array2 constant. const int array1[7] = {-5, 1, 3, 6, -2, -5, 9}; const int array2[7] = {6, -3, 7, -2, -1, -5, -7}; Now to see why the extra weird numbers come from, lets initialize the result array with zeros. int array3[7] = 0; So you have several problems. * you've over-thought the whole "if" * The first `else if` is redundant * The second `else if` _mangles_ array1 and array2 with assignments and then what? * It's possible for the logic to go all the way through and never touch array3 (try `0` for both) And you've managed to create a series of operations that confuse the instruction scheduler in the compiler to split a couple writes or do some really novel "branch prediction" -- you are compiling "incorrect" code with optimizing on -- as near as I can tell, to get those interesting large numbers. P.S. after the four spaces you can keep spacing to add indents. So the above lines have 4 and 8 spaces respectively. It doesn't have to be multiples of four. Four spaces is a "quote" the rest of the block will appear as is.
Look up The Dunning-Kruger effect. The more you know of something the _less_ likely you are to feel you've mastered it. Stated as "the less you know, the more sure of your knowledge", it works in both directions. So you've got a scale. So I've been using C and C++ and a number of other programming languages for thirty years or more now. And I can plonk out the rough draft of lots of different problems with no-look precision... But I still look up operator precedence and use a lot of parenthesis that others might find redundant and I re-read function and library definitions for lots of stuff now -- `strncpy()` anyone? Mastery is a middle step, it comes right after "sophomore" and "journyman", and the sense of it leaves you once you _really_ know enough to know you should double check some stuff. This insight usually happens after some sort of runious data loss (or in the old days, burning hardware... you could seriously blow up a monitor on the old PCs). 8-) So nobody is going to hand you your Official Mastery Certificate™, and if you ever decide you _have_ mastered it, you should either add another language to your repertoire or go back into your code base looking for pathological errors. True Story: Long about 2002 I found myself forced to dive into some C code on an embedded processor (an 8051 microcontroller). It had a serial line driver that was crapping out under load. The code _looked_ good, but it just couldn't keep up. So I went to the manuals. Found out all sorts of stuff was declared using some bad specifiers. I fixed it, and got a call from the programmer when I checked it back in. He was incensed. Outraged I tell you. Then I pointed out that he thought "IDATA" was "internal data" but it was "indirect data". (that's super obscure here, but follow along...). I had to give him the actual manual page. Then we laughed and he admitted he'd been using it backwards for eight years. (*) That's a master of his craft. Both sure of his knowledge but ready to see that his knowledge has developed tribal habits and be ready to be corrected by fresh eyes. Expertise is a perishable skill, and it's prone to contamination. That's the reason that Appeals To Authority are considered logical fallacies by default. You become a Master of something when you are good enough at it to be looked to for knowledge, but you've lost the sensation of being threatened by disagreement or error. There are supple masters, and hide-bound masters. Time honors the former and discards the latter. The first sign of true mastery is to quit-claim the title because your ego doesn't need it any more. I've had people tell me that so-and-so is a master of something or other, and then met so-and-so and been quite impressed, or occasionally disappointed. I've never met someone who told me that they _themselves_ were a master of something who didn't disappoint me greatly. Before enlightenment? Chop wood, carry water. After enlightenment? Chop wood, carry water. -- butchered Zen koan. 8-) (*) Explanation: /* correct. IDATA needs a pointer register to get to it, but it's fast SRAM. * DATA is part of the built in SRAM that can be fetched easily. */ IDATA char buffer[100]; DATA char *pointer = buffer; ... char value = *pointer++; // very fast. // Load value of pointer into register si=DATA[3] // Get character from buffer "value=IDATA[si] // increment si "inc si" // save "DATA[3]=si" /* correct. IDATA needs a pointer register to get to it, but it's fast SRAM. * DATA is part of the built in SRAM that can be fetched easily. */ DATA char buffer[100]; // using up all the direct SRAM IDATA char *pointer = buffer; // "pointer" is stuck behind a register ... char value = *pointer++; // very slow. // Load address of "pointer" into register, so like "si=3" // get value of pointer itself "si=IDATA[si]" // Get character from buffer, "value=DATA[si]" // Copy index register into arithmetic register "al=si" // increment pointer value "inc al" // load address of "pointer" again "si=3" // save incremented pointer "IDATA[si]=al" So you make a ring buffer with its insert and remove pointers and you do slightly more than twice the work to fetch each character and four times the work to compare the pointers to see if the buffer is full or about to overflow. Use a microcontroller correctly it's a dream, fight it and it will screw you. And the compiler "knows" you are a master so it doesn't complain at all. Nine years of that code because "IDATA" sounds like the internal SRAM and "DATA" sounds like the bulk area, but the chip designer thought otherwise. Particularly since the optional "external" ram chip was "XDATA" and the documentation talked about the internal and external memory and then the indirect memory. Calling the direct memory "DDATA" would have saved lives but "toe mai gawd!", that extra D on the default would have killed us all for being so much extra work! (maximum extra work was 128 repetitions per project since the DATA region was tiny.) ASIDE: bad wording, particularly of flags and variable names, is the bane of all standards and processing. 8-)
&gt;Hyper threading allows for running multiple contexts on a single core concurrently, but not truly in parallel Sort of an implementation detail, the way hyperthreading works (which you probably know but some may not) is by usually duplicating commonly used 'parts' of a cpu.
Not as far as I know, but I've seen this book being recommended some times: http://www.amazon.com/Programming-POSIX-Threads-David-Butenhof/dp/0201633922/ I've never read it. APUE is generally recommended (not specifically for multithreading though), and it has chapters on multithreading and multiprocess programming: http://www.amazon.com/Advanced-Programming-UNIX-Environment-Edition/dp/0321637739/ __Obs.:__ People are talking about multithreading a lot, but there are other approaches. Multiprocess is another way to possibly take advantage of multiple cores on a CPU or multiple processors on a computer. Differences between the two approaches involve: - what your OS defines as a thread and as a process (processes and threads are commonly OS supported concepts, but I've read about multithreading that doesn't require specific OS support for threads [green threads - check http://c2.com/cgi/wiki?GreenVsNativeThreads], but I've never heard multiprocess programming without the assumption of the existence of an OS that supports the idea of a process and of multi processes running "at the same time" [it seems possible to me to extend the notion of green threads and come up with something like green processes, but I've never seen that done out there]); - what means through which threads can pass data around and what means through which processes can pass data around; - the amount of resources it gets utilized to create and destroy a thread and a process; - etc. Processes are generally heavier weight (they spend more resources) and are more isolated from each other, in comparison to threads.
He actually said "can run" and not "will run", "must run", or "will necessarily run". He seemed to have chosen the word "can" in there on purpose. The fact that "each thread can run on one core" doesn't mean it will (his sentence sounded somewhat weird to me, but I guess he meant that each different thread can run on a different core). The fact that "if you have two cores, two threads can run at the same time." doesn't mean they'll run at the same time. It's possible for it to happen, but it's not necessarily true. It can happen, it's not that it'll necessarily happen.
Exactly what you say.
OpenMP is a fantastic solution in many circumstances. But the question of whether or not OP should use it, I think, depends on what they want. If they're looking for the fastest, easiest way to get their program running faster, there's a good chance that OpenMP is it. However if they really want to learn about parallel programming, OpenMP hides some of the nitty gritty, so I would recommend messing around with naked processes or threads using whatever library is available for their OS to start with, then moving to higher level libraries like OpenMP later. My $0.02
&gt; Tacking onto this while I wait for a train at a bar. Attempting to attain the [Ballmer Peak](https://xkcd.com/323/)?
What about flex/lex libraries?
&gt; without flex Why?
&gt; that analyze a text file Can you be more specific? What exactly are the contents of the text file?
see the [link](http://imgur.com/I8mUTMu), like you give it a txt file, it analyze it, and tells you what are the keywords, numbers, operators ...
we got asked to do it without using flex, its for school tho :/
Lua contains a fairly simple lexer.
If you're going to write your own lexer I'd recommend watching [this video](https://www.youtube.com/watch?v=HxaD_trXwRE) of Rob Pike talking about writing a lexer in Go. Yeah, he's using Go, but you can still apply almost all of what he's suggesting in C.
My advice would be to take a look at some assembler program source code for a "simple" chip like the 6502 or z80. These often contain simple handwritten parsers and lexers that don't use flex or bison. 
I'm liking it already! I'm only about 50 or so slides in so far but it's really good and makes you think. I love "language lawyering" so all of the discussion of an undefined return value (ANSI) vs assumed return 0 (C99) is great along with the implicit/explicit will it work on link? debate I now have to re-read `static` again (and in the OP I said i thought I "knew" `static`). I know that `static int a;` is predefined to 0 (all globals and statics predefine to zero, learned that a few weeks ago as I was digging through the source screaming "Where's the initialization statement? How can we use the variable if we haven't initialized it yet?" Now I'm confused again: so void foo(void) { static int a = 3; ++a; printf("%d\n", a); } called three times produces "4", "5" and "6" I'm guessing that a static initializer is ignored after the first time? OK kind of makes sense, you don't always want them to start at zero. But the syntax seems counter-intuitive. I realize function-scope static variables are "special" in that they aren't allocated on the stack like automatic function variables, but are instead allocated in a global data segment.
I'll check those out as well.
The attempt was successful!
While this is true, typically (as far as I have seen) the instructions are passed to the individual core synchronously and then data dependencies are checked at run time. In the case where a program is very parallel in nature or when memory is aligned perfectly for multiple instructions on a single cache read this can definitely help. I still don't see this as true parallelism, but I definitely consider it a brilliant runtime optimization that makes my life significantly easier.
&gt; What other approaches are commonly used? One trick that operates slightly outside of the realm of standard C is to provide an allocator function, say, `libfoo_malloc()` as a weak symbol. A user that wants to use its own allocator can provide a custom implementation of `libfoo_malloc()`. In your library, write: #pragma weak libfoo_malloc extern void *libfoo_malloc(size_t n) { return malloc(n); } A user who wants to overwrite `libfoo_malloc()` can then just do: extern void *libfoo_malloc(size_t n) { ... } in his own code to override the stock `libfoo_malloc()`.
In that case it was a very incomplete answer, and worded poorly. I think conflating the concepts of cores and threads will just lead to confusion.
It is, but there is a Windows port that works quite nicely called [Pthreads-win32](http://sourceware.org/pthreads-win32/) (although I've never used it directly, only as a requirement for other higher level parallelism libraries).
Thanks for the reply.
Provide an init() function that receives and stores function pointers to the custom allocator
If I do that, then I'm in the "pass state to all function parameters" options, which looks like it may be the best solution. Of course, I say this assuming that I want the library to be thread-safe (no hidden global variables in the library). Thanks for helping me think on this. 
The best method's to avoid it, but consider some of the following ideas for your endeavour. /* caller */ extern void *(*lib_realloc) (void *ptr, size_t size); void *erealloc(void *p, size_t size) { if ((p = realloc(p, size)) == NULL &amp;&amp; size &gt; 0) { fprintf(stderr, "can't allocate memory\n"); exit(EXIT_FAILURE); } return p; } lib_realloc = erealloc; /* implementation */ void *(*lib_realloc) (void *ptr, size_t size) = realloc; /* any of the following could be defined for convenience */ static void *lib_malloc(size_t size) { return lib_realloc(NULL, size); } static void lib_free(void *ptr) { lib_realloc(ptr, 0); } static void *lib_calloc(size_t nmemb, size_t size) { void *p; if ((size &gt; 0 &amp;&amp; nmemb &gt; SIZE_MAX/size) || (p = lib_realloc(NULL, nmemb*size)) == NULL) return NULL; return memset(p, 0, nmemb*size); }
I'm less worried about your C ability than about the decision to use an ARM but no OS! I would find that awfully limiting; it's not like there aren't simple lightweight RTOSes out there, rather than running in a non-multitasking setup. But, you mention coding standards like JPL and MISRA as well as what sounds like a task loop, so I'm guessing you're doing something safety-critical with sufficiently limited requirements that even a minimal OS would be overkill and/or multitasking is discouraged. Very different from what I work on. Anyway, I don't really know any resources to point you at... but you seem to be in pretty good shape to me. I came into my job pretty good at C, but not knowing anything about embedded stuff like talking to peripherals or how to use a proper debugger. You'll figure it out.
Understanding hefty-nifty grammar is necessary but is not important. You can avoid using grammars you can't clearly remember. When you see code snips you don't know, you can google, or write a small program to test the result. Then next time you will know. How much you understand pointers determines how good a C programmer you are. One practice is to implement a linked list and then google what is the best way to implement it. Another good practice is to understand the allocator in the K&amp;R book. It was enlightening back to my early days. The more important is data structure and good design patterns, which are not specific to C, though.
The include statement is quite literal. When the compiler sees #include "myHeader.h" it reads that file and inserts the contents as if they were typed into the .c file directly. I'm a little confused about your last paragraph. In c, the executable program knows nothing about the source code. The source code is just a recipe used to produce machine code. If I weren't using my phone, I'd link a few articles to explain this process. 
In general, includes of the form: #include &lt;stdio.h&gt; are "system" headers and are located in a location specific to the compiler (or platform---on Unix, these files are typically stored in "/usr/include") and you don't really need to concern yourself with them. Includes of the form: #include "myheader.h" Are typically located along with (in the same directory as) the source files. You can store header files elsewhere for a project, but then you'll need to consult the documentation for your compiler (or IDE) for details.
One method is to just simply write the library so no allocations are required---all memory used by the library (or function) is passed in. That's what I did for my DNS encoding/decoding library (https://github.com/spc476/SPCDNS). I also have an AVL tree library (not published) that avoids memory allocation, leaving that up to the user code to handle. I realize that not all library code can be so constrained, but it is worthwhile to see if you can avoid allocations if possible.
Read all the C questions on stackoverflow until you understand all of them.
&gt; But the syntax seems counter-intuitive. What would you suggest instead?
It isn't exactly functionally correct either, but you should treat it as such. 
Thanks to it I've learned linked lists, doubly, stack and queues so far
I've considered this approach, and consider it a "future feature". Of course, a benefit of that is that I will end up constraining the number of times I require memory management. This is all just an exercise for me -- I've never *had* to work with these constraints, so I want to see how well I could. I also expect to learn some other things as a side effect (e.g. maintainability might be improved if I limit the areas that require memory management). 
You might be confusing header files with the actual code that performs operations. (and if not you can ignore this comment. I don't mean to be condescending, just educational) Header files typically only contain declarations (and other stuff that doesn't do anything on its own), while the .c files (and the resulting library or program) contain the actual code. But the declarations are necessary for other code, such as your own program, to know which functions exist, what argument datatypes they take, and what datatype it returns. A header file could look like this: int add_numbers(int a, int b); It doesn't do anything, it just says there's a function named add_numbers that accepts two integers and returns one integer, enough to compile the function call. The equivalent .c file (which may or may not already have been compiled into a shared library, system or non-system) would look like this: int add_numbers(int a, int b) { return a+b; } Sorry if I'm getting some terminology wrong.
This is what i didn't get, thanks for the answer.
This is what i didn't get, thanks for the answer.
`=` is the explicit assignment operator. `==` is the test-for-equality operator. This comes from the original program syntax idea "let A equal 5 times 3" versus "if A is equal to 9", e.g. the "conversational mode" of the idea. Besides, you assign more often than you test for equality, so why would the assignment operator be _longer_ (e.g. have more characters to type) than the test operator? The idea is that in normal thought, the conditional is both more rare and more complex an idea than assignment, so it gets the slightly more exotic syntax. Pascal uses `:=` and `=` respectively, which is, in many ways, less clear. After all, in math, `y = mx + b` is essentially an assignment and is expressed by mathematicians as `y = f(x)` almost constantly. In math you write `f(x) → mx + b` as the definition and then use that as `y = f(x)`. Mathematicians (and math teachers) are simply crap at actually recognizing their own syntax once you make it practical. 8-) This also comes from the fact that at the time "not equal" was popularly `=/=` to represent the `≠` on the ASCII keyboard, so it was natural to just remove the slash and be left with `==` for "is equal". TL;DR :: There _are_ reasons for all of this.
which is all well and good until somebody does an `if( a = 1 )` when they meant `if (a == 1)`
Use four spaces in front of every line for code formatting. Reddit doesn't parse &lt;code&gt;
You should check your for loops. At least one of them is completely wrong.
Why don't you try adding some debug printouts, like: printf("Entering first if\n"); ...... You can use that to figure out what path the program is taking and where it's going wrong. You need to look up how to declare and use for loops in C. 
im using this with flex &amp; bison to edit an image...
Yep my bad. I was mistaking the difference between the header and the associated .c file. 
The best way to learn them is first to understand the code logic behind these concepts and then, implementing it in pseudo-code, with hand-written diagrams and animations which represent what actually tasks do. Then, apply them and with some accuracy and after you've tried several times, you make a perfectly functioning list.
One tip for your future career: start writing code in English, which is the de facto language used in programming. I doubt many ppl cba to try and help you otherwise.
Sorry about the code formatting. I'm on mobile and i can't seem to get it right. Edit: never mind, I got it I don't know about flex/bison or the Bresenham method, but your last two FOR loops don't look right. I think they should be: for (x = x1; x &lt; x2; x++) { // initialize x for (y = y1; y &lt; y2; y++) { imagem[x][y] = corUtilizada; // use x } } Your X loop is incrementing x but you're using the value in x1 instead. x1 is never incremented so you lines will always be vertical (x = constant) In Portuguese: Eu não entendo de flex/bison ou do método Bresenham, mas seus dois últimos loops FOR não parecem certos. Eu acho que deveriam ser assim: for (x = x1; x &lt; x2; x++) { // inicializar x for (y = y1; y &lt; y2; y++) { imagem[x][y] = corUtilizada; // usar x } } Seu loop do X está incrementando a variável x, mas usando o valor de x1. x1 nunca é incrementada entao suas linhas sempre serão verticais (x = constante) P.S.: em inglês, use "question" em vez de "doubt". Doubt não costuma ser usada nesse sentido. Seu título parece estar dizendo: "Duvide da linguagem C".
very thanks bro ;) 
why do you need a .exe? can you not just wrap the perl script call in a batch file or something?
https://stackoverflow.com/questions/1237286/how-can-i-compile-my-perl-script-so-it-can-be-executed-on-systems-without-perl-i This question the same thing as you are and gives an answer: https://stackoverflow.com/questions/1237286/how-can-i-compile-my-perl-script-so-it-can-be-executed-on-systems-without-perl-i
You mean MSYS. MinGW is a proper port, like Clang for Window.
Last I checked clang/llvm couldn't produce debug info on windows, so it's not really a great choice. Never used MinGW, but it's old enough that I'd assume it can though.
I've compiled c code w/ mingw, although it had some issues w/ EMET (but I doubt that matters to most people). The setup is a little tricky though, I seem to remember "msys" being a key component to getting it to work. Getting the environment setup was tricky. Sorry I can't be more help, but it's new years :D
Last I used Visual Studio, the C compiler there only supported C89 which was a deal breaker for me. 
If you really, actually want a 16-bit DOS compiler, you can look into the antique Turbo C [here](http://edn.embarcadero.com/article/20841) and Watcom [here](http://www.openwatcom.org/). Follow the Watcom 'Download' link and you'll find version for DOS, Linux, OS2, Win32... I don't think either support/have regex in the library, but then, you could craft your own regex(). After all, getting good with string matching/manipulation is something of a dark art, finding few that are capable, and could enhance your value significantly as a programmer... http://www.regular-expressions.info/ As others have pointed out, it doesn't have to be 16 bit DOS app to run from the cmd.exe prompt. In fact, I'm not completely certain Win 7 and higher are capable of running 16 bit anything in any *native* manner, anymore. (WinXP can/does, of course). Win32 console apps (as provided in a few mainstream, current day compilers) do a handsome job of emulating the look and feel of the old DOS apps, but are full 32 bit. The UI isn't as snappy as the old 16 bit counterpart was, because textmode is actually translated into graphical mode at runtime, but the look and feel is certainly there. Operations behind the UI, however, are almost certain to run more quickly, thanks to 32 bit code and architecture. Also -- it's pretty cool to malloc() yourself a 50 MB array for your console app -- you couldn't do that in old 16 bit DOS. But you can easily do in a Win32 console app. I'm possibly the last guy on Earth who still likes console apps, once in a while. The bold colors and all that, using the keybrd a bit more than the mouse, the tiny footprint and ability to run from a USB pendrive free of any installation procedure, etc. I'm weird. But if you use and like [puTTy](http://www.putty.org/) for example, we may have something in common. 
&gt; I'm possibly the last guy on Earth who still likes console apps you're not alone, quite far from it
The return value of `fork()` tells you which process you currently are. This should be enough.
I know that, I'm having problem with implementing program that would work for different inputs.
Something like this should be reasonably simple to implement: 1. Create a tree structure in memory from the input you receive. 2. Point a pointer to the root of the tree. 3. If any children need to be created, fork, else proceed with step 6 4. Find out which process you are, if you are the child, move the pointer to the corresponding child node 5. Proceed with step 3 6. Call pstree to print a process structure
This subreddit is about C, not C++. See the sidebar for a place where you can ask C++ questions. I removed this post as it is off topic.
Sorry, I was using a loose definition of compiling. Most Windows computers will have a JRE. You're right about GCJ.
As a note, part of the problem you're probably having is that your leaf processes (The ones which don't have any children) exit immediately - And when those exit, `wait(NULL)` will return in the above processes and then that process will exit, causing your entire tree to close. Since the timing here is complex, you're probably best off if you simply have your leaf children sleep for a few seconds. That way, you can call pstree during that timeout and your entire tree will still exist. Also as a note, `wait(NULL)` will return when a *single* child exits. If you want to wait till every child exits then you have to call `wait(NULL)` once for every child. I managed to implement it pretty easily using FUZxxl idea of parsing the input before doing any of the forking - I was originally going to do it much differently, but his idea really is the easiest way in this case. Dealing with the logic behind `fork`ed processes is very confusing the first time you do it, but it's much easier when you keep in mind that `forks` inherit the entire state of the their parent. This is useful because it means that if you already have the input parsed into a tree, every fork gets a copy of that tree to look at. More over, if you use `fork()` in a loop, then the `fork()` inherits the current value of the loop variable. I don't want to give things away, but I used a simple tree structure to hold the desired process tree that I read from standard-input. The structure is just this: struct process { int child_count; struct process *children; /* Array of 'child_count' number of struct process objects */ }; After I parse input, I get a structure in memory like this: root: child_count: 1 children -&gt; 0: child_count: 0 0: children: NULL 1: child_count: 3 1: children -&gt; ... The cool part is that when you `fork()` you don't actually have to worry about any of the actual PID's, because the `fork`'s get the state of the parent, which will tell you everything you need to know. Without giving the actual code you'll use, if you take this example: for (i = 0; i &lt; 5; i++) { switch (fork()) { case 0: /* child starts here */ printf("%d\n", i); exit(0); default: /* parent */ break; } } It prints out the numbers 0 through 4 (The order is not technically guaranteed, since it's dependent on when the OS decides to run our forks, but it doesn't matter). Even though we `fork`, the `fork`s inherit the value of `i`, so it works anyway. If you use a loop like this to create your children, then the forked children can take the parent's `struct process` (Which should be around as a variable somewhere, left over from the parent), get it's `children` array, and then index it with `i` (Which will be different for every `fork()`, since it gets called in a loop). Using that, the child process can get it's unique `struct process`. Then it can replace the current `struct process` pointer being handled with it's own, and then jump to start over the loop (And runt he loop over it's own children instead). If you hit a `struct process` with `child_count` equal to `0`, then instead you sleep. And after the `for()` loop that creates your children is done, you can call `wait(NULL)` for every child.
Quadratic complexity means that the runtime of your algorithm is proportional to n^2 where n in this case is the length of the input string. So, for example, a 50-character string would take 25 times longer to count than a 10-character string. This is because you're calling `strlen`, which is a linear-time operation that traverses the whole string, inside your loop condition, which operates once for each character. You can fix this in two ways: - Call `strlen` *once* and save the result in a variable; since it never changes, you don't have to keep recalculating it. - Don't call `strlen` or keep track of the length at all; just test each character for NUL as you come to it. The buffer overflow problem is more serious. You've allocated 100 bytes for my input; if I type in 500 bytes, your program will (best case) crash or (worst case) continue running but behave unexpectedly.
Oh, thanks a lot :) As for the buffer overflow, this is just for training, but good to know! Thanks again :)
Hm, interesting. Yeah, in old K&amp;R style C that is the case. I didn't know that, I just assumed it was a syntax error. Learn something new everyday. However, you are using very outdated C. What are you learning from? Consider getting newer learning materials. You want to be learning at least C99. Check out C11 as well, though I'm not entirely sure what's new in that.
Nothing wrong with puts(). fgets() is what he should be using for input, though.
Edited
Main post. Titles says what I want. EDIT clarifies what is happening instead. But nvm, someone helped already :) Thanks 
The function for reading a line from an input stream.
I dont get what your are trying to do. Unions are not the same as structs. Unions are used for genericity. First you set u1.a, which inside the union uses the first 4 bytes. After that you set u1.b which overrides u1.a since it also occupies the first 4 bytes. Then you set the second part of d which is the bytes 5-8. Then you print c[0] which is the first 4 bytes that you set to 100 with u1.b. Then you print c[1] but tell printf: "read those bytes as an int" and those 4 bytes you wrote when setting d correspond to 256 if interpreting the bytes as an int.
That's one thing I love about Anjuta. You worry about writing your code and it handles the packaging for you.
That header file is terrible, it completely craps over any feature test macros you define.
Why don't you use pthreads directly? It's the better, more portable API.
I do/was. In old codebase at least. In newer I'm going forward with C11 API. No special reason, except one. All code I write is the one that I alone touch again (more or less). Whenever I write anything new, I kind of think it will be around a year or so and then new stuff will be written. However, I severely underestimated longevity of code. At least in my case. I still have code lingering around that's 15-20 years old. I don't know if that makes sense.
The readline/editline library is pretty good. fgets is probably what ~~you~~ OP *would* want though. 
In general, what [Pronouns](https://www.reddit.com/user/Pronouns) said but, there are certainly cases you could safely make use of unions in that manner. Take a completely contrived example where you convert from an ip address in integer format to dotted-quad, e.g., #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;stdint.h&gt; #include &lt;string.h&gt; typedef union { uint32_t address; uint8_t bytes[4]; } ipaddr_t; int main(int argc, char *argv[]) { ipaddr_t ipaddr = { 0 }; if (argc != 2) { fprintf(stderr, "Usage: %s &lt;dotted quad or number&gt;\n", argv[0]); exit(EXIT_FAILURE); } if (strchr(argv[1], '.') != NULL) { /* note: due to prior initialization, partial dotted-quad's should contain zeros. */ sscanf(argv[1], "%hhu.%hhu.%hhu.%hhu", &amp;ipaddr.bytes[0], &amp;ipaddr.bytes[1], &amp;ipaddr.bytes[2], &amp;ipaddr.bytes[3]); } else { ipaddr.address = atoi(argv[1]); } printf("IP Address (dotted-quad) : %d.%d.%d.%d\n", ipaddr.bytes[0], ipaddr.bytes[1], ipaddr.bytes[2], ipaddr.bytes[3]); printf("IP Address (unsigned int): %u\n", ipaddr.address); printf("IP Address (hex format) : 0x%0X\n", ipaddr.address); return 0; } The thing to really be careful about is creating a situation where you end up with so-called "trap representations." Though in general, *IIRC*, if all you're dealing with are unsigned members in your union, then you should be okay. (very big **IIRC** - please point out my idiocy if I'm wrong!).
This is legal for some compilers, notably GCC, which gives guarantees about this sort of `union` usage. As far as the standard is concerned though, this is *not* allowed. The standard says that it's undefined-behavior to write to one member in a `union` and then read from the other. This makes sense when you consider the context that the standard does not specify big-endian or little-endian format for integers, which controls the output of your program. Noting that, I would recommend you don't ever actually do this in code, and instead do the conversion to IP address manually via bitshifts and masking. It's not as fun, no, but it does guarantee that you'll always get the same result on big-endian and little-endian machines - And if you're curious, all x86 desktop machines are little-endian, and basically all phone's/ARM arch's are big-endian, so it is very relevant. Speaking technically though, ip-addresses are a special case where you *can* actually do this correctly for every machine. You just have to make sure you always store the union in 'network-byte-order' (Which is just big-endian), and then use `ntohl` and `ntohs` to convert back into a regular integer value for the host machine. You have to be *really* careful to get the endianness right though - Currently, your last two `printf` statements will display different values depending on the endianness of the host-machine, a call to `ntohl` is necessary to get the correct value back from the network representation.
The language was changed in a TC to C99. It's now explicitly allowed and not left undefined anymore. The reinterpretation that happens might yield a trap representation though.
Take a look at this: http://pastebin.com/AXV5B3J1 
I'm not sure how this is supposed to help OP.
Vim or emacs are perfect for that purpose ; although each needs some time to learn (and way more to master) they are entirely dedicated to their simple task: editing text (well, emacs does a lot more, but only if you ask it to. Otherwise it's a simple text editor).
Nano, vim, emacs, etc. I prefer vim, but that is my personal preference. A good list can be found here https://en.m.wikipedia.org/wiki/List_of_text_editors I apologize for the mobile link
If you want a graphical tool, I personally use jedit a lot, and it has a built in terminal interface so you can compile and run programs right in it, too. More intuitive to learn than vim or emacs, and cross-platform.
All troll appart emacs is a good editor. While I don't like its default keybindings all is there to help you adapt your environment to something you like. I'm a vim guy but emacs was my first text editor (on windows, a long time ago) and it is fit to that purpose. Also it has by default a graphical interface while to use vim you have to reach for gvim. Not much of a problem and not my cup of tea honestly, but I understand that for windows users it can be important. To stay OT there are other editors like sublimetext or atom that I've heard good things about but I never used them.
Can you elaborate on what a _trap representation_ is? Thanks.
Err... you could at least have put a valid sample, "c ..." will generate the beautiful "?" error because the "c" command doesn't accept any suffix. 
I cannot recommend this enough; you get up and running with ST very quickly, as opposed to emacs or vim where you have 400128 shortcuts or 59182 modes.
You are exactly right. When users don't have to install and configure Perl, it's one less layer to cause them trouble. I don't have to hide the code, just make it easier for novice users to use my CLI. 
I don't want a 16-bit compiler. &gt; In fact, I'm not completely certain Win 7 and higher are capable of running 16 bit anything in any native manner, anymore. Because I think you are right on this. 
they provide gcc with mingw as target, probably clang too but I didn't look for it.
Being a vi person originally, I switched to emacs a few months ago. It is pretty much perfect with evil mode.
I wonder how RMS feels about evil mode. 
I strongly recommend spacemacs. It's beautiful and delivers the full elegance of vim and the raw power of emacs.
Visual Studio 2015 supports C99.
Eighty Megs And Constantly Swapping. (Back when 80 mb was considered a lot..) (jokes.. emacs is an impressive and versatile piece of software.)
You're pulling my leg right? Next you're going to tell me all your code begins with `#include "/dev/stdin"`. 
I really like atom. It's similar to VS Code but has been around a little bit longer so has more packages. When it comes down to it though, you just need something to write code. Just about any editor that was designed for writing code will suffice. Which one is best depends on your preferences.
cloud solution: c9.io. I've used it to write a ton of C with no problems at all and it meets all of your requirements. 
If you are using a glibc based system (e.g. linux) you can just use the existing malloc hooks to replace/instrument your system. This isn't an answer to your question per-se, but it's a useful tidbit to know. 8-) http://www.gnu.org/software/libc/manual/html_node/Hooks-for-Malloc.html
Don't use `scanf("%s", ...)`. What happens when somebody enters a word that is longer than the array you're trying to store it in? Or wants to use a filename with a space in it? Use fgets().
Will do. Thanks!
&gt; Ask yourself, why was your code crashing when you had = instead of ==? What line was it crasahing on? I'm clueless tbh
I think I get your point (hopefully OP does as well) but, *technically*, the function that breaks in the original example is `fprintf`, because `fp = NULL` also returns `NULL`, causing the `else` clause to run with a `NULL` pointer.
Thanks a lot 
I would recommend the Harvard CS50X on edx.org (it's free) &amp; Learn C the Hard Way (also free) personally.
Not *quite* what you're looking for, but a really good book for people who already know C but want to be more up-to-date about it is [21st Century C](http://www.amazon.com/21st-Century-Tips-New-School/dp/1449327141).
This is a good example of why some people ensure their code is built in different environments, with different compilers. Linux on x86 and ARM, BSD on whatever, gcc, clang. Helps bring assumptions to light. It's nice to see a post saying "I had a problem, found the solution, here's what I learned". 
K&amp;R C, 2nd Ed, Section 2.2, p36: &gt; "Whether plain chars are signed or unsigned is machine-dependent, but printable characters are always positive."
I might still have that book. 
Have a look at https://en.m.wikipedia.org/wiki/C_variable_types_and_declarations It gives the minimum amount of bits in a specific data type.
Just FYFR it’s not a bad idea to learn “modern C” but if you get familiar with C89 you’ll be good to use 99% of C compilers and it’ll take you like 30 minutes to learn the new C99/C11 stuff. Maaybe with the exception of threading but C11’s version of threading is mostly misbegotten Pthreads and I haven’t seen much stuff use it in practice.
Thank you very much for your answer. Is embedded a career option you would recommend? I love C, and I'm afraid that C only has use cases in OS development and embedded nowadays. Do you think the Arduino is well suited for getting a foot into embedded or should I start with something different? But I guess I will get an Arduino Uno and the second version of the book you recommended.
You're not initialising the buffer you get back from malloc. 
And by initializing, do you mean making a for loop to fill the buffer with null characters?
I am happy to see the scope of C's relevance diminish, as the C standards committee has not seen fit to let C change with the times beyond the barest concessions to the realities of modern computer architectures. They maintain C as a legacy language, and as long as that is the case, the industry should follow suit. That said, I do nearly all my programming at work in C, and despite the fact that I don't particularly like the language itself, I have come to terms with it and I really enjoy my job. I think embedded systems is a great career, and certainly a more stable and mature one than something like web front-end development, though with the 'internet of things' hype building there's likely to be a lot of growth soon. There are vastly more computers, and much more variety of architecture, in embedded systems than in PCs and servers. Although language choice is somewhat restricted, other aspects are more open, and projects tend to be smaller, have better-described requirements, and a more clear-cut lifecycle. And I happen to also enjoy what I've been able to learn about electronics and the interface between hardware and software.
Or use `memset`.
what would happen to this code if the optimizers were enabled? and how would it calculate the long value for ubuntu?
`void main()` should be `int main()`. You can continue to omit a return statement (as a special case, `main` returns 0 if there is no return statement). Also, signed integer overflow is not defined by the C standard. In fact, some compilers explicitly exploit this for optimisations. [Here's a good article about it.](http://thiemonagel.de/2010/01/signed-integer-overflow/)
You can't really get away from the basic C types. `char` is, by definition, the 'measuring stick' type that corresponds to the smallest addressable unit of data. All sizes in C are given in multiples of `char`. And `char` is not guaranteed to be 8 bits; thus the CHAR_BIT macro in `limits.h`. And then there are the standard integer promotions for arithmetic expressions; an operand of any type of lower rank than `int` is first converted (in a value-preserving manner) to either `int` or `unsigned int` before the expression is evaluated. By all means, use the `&lt;stdint.h&gt;` types where appropriate, but keep in mind that even if you use them exclusively, you're going to have values of the basic integer types in your program anyway and you'll need to be aware of their limits and any implementation-specific behavior that may be invoked by your program.
I should note that in a POSIX environment `CHAR_BIT` *is* always 8, but if you were to get into DSP programming you would run a reasonable chance of running across unhosted environments where `CHAR_BIT` is 32.
You can just use calloc instead of malloc to allocate zeroed memory. Yeah, the args are slightly different.
I've got 1st and 2nd edition both, love it that much. The 2nd edition everybody says is better, I get that. But the 1st edition, 1st chaper was 'Chapter 0' (Chapter zero). Now, is that cool, or what? It just doesn't get more C than that.
Good idea. may test.
Indeed, but the bit of code was just to test what wrap around was occurring, so CBA with int main and return 0, and comments, and proper indentation, etc etc etc. 
There is a commercial plugin for working over ssh from Sublime Text, search for *Sublime SFTP*. There is also a free alternative that uses a TextMate plugin in Sublime named *rsub*.
Chandler Carruth gave a nice presentation at CPPCon : https://www.youtube.com/watch?v=nXaxk27zwlk (C++ but should apply to C)
Your tool set should include performance measuring tools, often called a "profiler". Depending on what set of tools you're using this could be anything from gprof to a fully featured analysis app that measures dozens of metric (performance, battery impact, memory impact, leaks, network usage etc) as your app is running.
Yep
Thanks.
If I make two algos that does the same thing, and try to decide which is faster, i make a program with a timer that runs it 10^4,5,6,7,8 times. easy to see the difference then. If you want something more complete, then /u/thoughtzero is right. 
Are you doing C development on Windows regularly or is this an exception? I've done my share of C work and I've never attempted that. Linux is definitely the easier route. I'd strongly recommend installing a Linux distribution on a VM if you're unfamiliar.
Can you post your code and the exact error messages you're getting?
&gt; What can this be used for? The example on that page is packing seven fields into a struct that's smaller than it would be if each field had its own dedicated integer. The example is kind of bad, because it seems to assume a particular size of `int`, but that's not how C works. In any case, assuming that it was meant to be run on a platform where `int` is 16 bits, then the whole struct occupies 3 bytes (but there would probably be an extra byte of padding at the end for alignment purposes, making it 4 in size, although it's usually possible to disable that if space is at a premium.) Squeezing seven fields into three or four bytes is a considerable win given that the smallest possible struct you could create using disparate fields would be seven bytes (i.e. each field a char.) This takes advantage of the fact that some fields only need a few bits to represent whatever value they're storing. &gt; Why is it only valid in a struct You can't *actually* allocate individual bites. Computers address memory at the byte level. You can't ask for a variable that's 3 bits. It has to be a whole number of bytes, e.g. 8 bits, 16 bits, 32 bits, etc. But if you have multiple fields, you can *pretend* that it's possible to allocate bits by having them share a larger integer. You could take a 16 bit integer for example and pretend that it's really an aggregate of a 3 bit value, a 4 bit value, a 6 bit value, and three 1 bit values, all packed together. That's why you can only do this in a struct, because it requires an aggregate type for the fiction to hold up. &gt; why is it that in their example code some of them arn't named? The unnamed fields are used as padding to affect the alignment of the other fields within the integers. Alignment is a more complicated topic, but all you really need to know is that there are certain times when it's necessary to insert padding between fields. They aren't storing values, so they don't need names.
If you're running some variant of Unix system, you can just feed your algorithm with large input and measure the execution time with **time** command. This approach is widely used and is quite sufficient, IMHO.
Don't print a message on unknown command. Just silently ignore it. That's what the BF spec says, as it allows you to write comments in the code and use whitespace.
Thanks.
Thanks for the reply. I will check to library out.
gcc is already a collection of compilers.
I'm sorry but I don't understand your reply, can you elaborate?
gcc is the GNU Compiler Collection. It has compilers for many languages. Mingw uses gcc.
This is what I did? I added the ch++ to calculate the total number of words or characters in the file? Now when I run this it seems to work some what but the lines of data just keep going, it doesn't stop. Is this because it is in a while loop? Is their another way of making it work? int main() { FILE * AL; AL = fopen("test.txt", "r"); int ch; ch = fgetc(AL); while(!feof(AL)){ ch++; printf("%c",ch); } } fclose(AL); }
Made me want to type up my own version, took me about 15 minutes, mostly as I got side tracked trying to golf my [ and ] and realized there wasn't much point (since i'm never gonna use it heh). http://pastebin.com/y57wWfcx As for your issue, just ignore non-bf characters and everything will be a-ok.
What you appear to have is a program that opens your file and uses fgetc to read a single character and stores that in the ch variable. Then it starts a loop that will loop forever adding one to whatever number is stored in ch, and then prints it as a character. As I understand your code, ch is the variable that holds the character, so incrementing it does not do the count you want. I think, for example, if fgetc reads the character c, the corresponding ascii decimal value is stored in ch, say 99. If you increment it, the value rises to 100, and d is printed instead. * You need new different variables to store the things you want to count. * You also need to do a/the fgetc in the loop so it gets all the characters in the file, not just the first. This should also allow the loop exit condition to work. * You could use a while loop with a "ch = fgetc(AL);" call twice (once before the loop and once in the loop). Or consider a do-while loop instead with one "ch = fgetc(AL);" call in the loop. * You will want some if statements in the loop to control how the counting variables get incremented depending on what character is stored in ch. HTH
Sigh, I'm still confused. Are you saying the code should be changed to something like this? int main() { pthread_t threads[NUM_THREADS]; int rc; long t; long *temp; for(t = 0; t &lt; NUM_THREADS; t++) { printf("In main: creating thread %ld\n", t); temp = &amp;t; rc = pthread_create(&amp;threads[t], NULL, PrintHello, (void *)temp); if(rc) { printf("ERROR; return code from pthread_create() is %d\n", rc); exit(-1); } } pthread_exit(NULL); } 
Sure. But you don't need the variable `temp`. Just `(void *)&amp;t` is good enough. If you have a previous declaration for the `pthread_create` function (and you should), then you don't even need the explicit cast to `void *`, because the compiler knows that the third argument should have type `void *`. Now, in the `PrintHello` function, you are getting an argument of type `void *`. You know that this is really a pointer-to-`long`, so cast it to `long *` and dereference it to get the value in&amp;nbsp;`t` in your `main` function: `*(long *)threadid`
Thanks for your help, it works now! I have one last question for you. What do you mean by: &gt; If you have a previous declaration for the pthread_create function (and you should) Isn't pthread_create() just part of the &lt;pthread.h&gt; lib? What do you mean by declare pthread_create()?
Excellent, thanks for all your help.
It is legal to convert an integer to any pointer type, and any pointer may be converted to an integer *if* the integer type is big enough. What happens when you do this, however, is implementation-defined; this means it might not do what you want, and if it does do what you want with your current compiler/OS combination, it might not do what you want with another compiler/OS combination. Section 6.3.2 of the C standard specification talks about these issues, if you need to see the full technical details, but it's not straightforward reading. Anyway, that sort of thing *is* normal, in the sense that lots of people do it, and it generally will work. But if you're going to do it, you shouldn't use an arbitrary integer type, you should use the uintptr_t type from stdint.h, which will be large enough to hold the integer value of a pointer and thus avoid undefined behavior. I would recommend against doing it, though, unless you really can't do things in a way that's not dependent on implementation-specific behavior.
GCC includes compilers for C, C++, Fortran, Ada, etc. But a distribution of the GCC may not have all of them built, and the C compiler may be configured to support a different C library than you want to use. What you want to be asking is whether mingw w64 and your current mingw can coexist (mingw is more than just a compiler; it includes libraries and other tools as well). And the answer is yes, but the tools from the one listed first in your path environment variable will take precedence. You can leave them both out of your path variable, then create batch files to add the bin directories from each one into your path; then you run the batch file for the one you want to build with in each command prompt before you do your compiling. But it might just be easier to delete the old one and install the new one. They should be largely the same.
See the answer I linked.
Technically, you probably shouldn't do `(void *)&amp;t`. That will create a pointer to a local variable on the main thread's stack. However, if the main thread returns before the other threads run and dereference that pointer, the behavior is undefined. In general, once a thread returns, local variables on its stack are no longer in scope, and you shouldn't dereference pointers to variables that used to live on its stack (there are no guarantees what that memory is being used for now; it may turn out that dereferencing those pointers happens to work, but it may also sometimes give you garbage instead, if the memory location previously occupied by that thread's stack is now being used for something else). Instead, you should allocate space on the heap for `long`s for each of your threads. Perhaps a larger issue though is that you're not calling either `pthread_join` or `pthread_detach` from your main thread. Unless you do something, when the main thread of a process exits, all other threads exit as well, and the resources associated with the process get cleaned up. Thus, your other threads may get terminated before they've finished running. It's even worse because *sometimes* (perhaps even usually depending on how things get scheduled) your other threads will run just fine (so you may not notice anything is wrong), but it's not guaranteed. `pthread_detach` signals to the process that you don't care about the return value for that thread, and that the resources associated with the thread can be cleaned up as soon as the thread exits. A process also won't exit until all detached threads have finished running. `pthread_join` causes the calling thread (in this case, it would be the main thread) to wait until the specified thread returns, and then gets its return value. In general, you should almost always call at least one of these two functions on threads that you create. In this specific case, since you don't care about the return value for your threads, you probably want to just use `pthread_detach`. Here's an example, putting everything I've mentioned together: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;pthread.h&gt; #include &lt;assert.h&gt; #define NUM_THREADS 5 void *PrintHello(void *threadid) { long tid; tid = *((long*)threadid); printf("Hello World! It's me, thread #%ld!\n", tid); pthread_exit(NULL); } int main() { pthread_t threads[NUM_THREADS]; int rc; long t; long *thread_num; for(t = 0; t &lt; NUM_THREADS; t++) { // Allocate some space on the heap for the long* that this // thread will dereference thread_num = (long *)malloc(sizeof(long)); // Set the long that thread_num points to to be the value of // this thread number *thread_num = t; printf("In main: creating thread %ld\n", t); rc = pthread_create(&amp;threads[t], NULL, PrintHello, thread_num); if(rc) { printf("ERROR; return code from pthread_create() is %d\n", rc); exit(-1); } else { // Detach the thread, so that the process doesn't exit // until the thread has finished running (even if the main // thread exits first). 0 indicates a successful return; // we wouldn't expect this call to fail. assert(pthread_detach(threads[t]) == 0); } } // It's safe to exit now, because even if the other threads // haven't finished running yet, since we've detached them, the // process won't exit until they're finished. pthread_exit(NULL); } Hope you find this helpful! Edit: grammar
echo 'int main(void){ int nbr_of_seconds = 2.5*3600; printf("%d\n", nbr_of_seconds); return 0;}' | gcc -xc - &amp;&amp; ./a.out
It goes like this: int = float * int int = float * float int So, 3600 is cast to float, the 2 floats are multiplied together, and the result is then cast to an int. You can search further on type conversions and promotions. You might find "C: A Reference Manual" by Guy Steele and Samuel Harbison to be quite useful. 
Thanks for this in-depth post. You seem to know quite a bit about multi-threading. Do you have any resources you can recommend to help me learn pthreads? How did you learn it?
&gt; Using a floating point number as one of the operands of an arithmetic operator causes the other operand to be converted to the same floating point type if it's not already, That's if one operand is floating and one is integer. If they're both floating then the one of narrower type is converted to the type of the other.
I think the best (but incomplete) "book" is this: http://icube-icps.unistra.fr/img_auth.php/d/db/ModernC.pdf This isn't a very good from scratch book though, it's more aimed at people who already know a little C. It also uses a lot of C11 features which most people wont be able to use. People who use Visual Studio for example.
Thanks! This is very useful. :)
It all looks fantastic until you're doing maintenance programming on a piece of equipment whose code still uses a GCC 2.95 based toolchain. Then all the C99 stuff you've gotten so accustomed to is worse than worthless.
I'm sorry, your question is not clear. Do you need to simulate the random event (as hinted in the body) or do you need to compute probabilities (as hinted in the title)?
I majored in CS in college, and took courses on multiprocess synchronization and on operating systems :) I don't know of any particularly good resources online, I learned mostly via classes and by doing projects. Just Googling, this appears to be a pretty decent resource: http://randu.org/tutorials/threads/. You can skip to the section specifically on pthreads if that's what you're interested in. Note they have a pretty similar example to the one I outlined above, except they use `pthread_join` instead of `pthread_detach`. This allows them to just pass pointers to local variables on the main thread's stack, since `pthread_join` causes the main thread to wait on each of the other threads to return before exiting, thus guaranteeing that it's stack won't be destroyed before the other threads are done. Let me know if you have any other specific questions!
I didn't know this. Thanks.
Ok, was simple after all. void str_swap(char **s1, char **s2) { char* tmp = *s1; *s1 = *s2; *s2 = tmp; } 
&gt;If you need to re-initialize already allocated structs, declare a global zero-struct for later assignment You can use compound literals instead and do like this, too: *t = (struct thing){ 0 }; Doesn't depend on some confusing global variable, and might be faster in some cases - if you copy a preallocated zero struct, the entire memory (including padding between members) will get copied: ( clang -O2 -std=c99 -S -masm=intel ) xorps xmm0, xmm0 movups xmmword ptr [rdi], xmm0 With a compound literal, the padding can be left undefined: ( clang -O2 -std=c99 -S -masm=intel ) mov qword ptr [rdi], 0 mov dword ptr [rdi + 8], 0 This is IMHO even preferable, as valgrind (which you should use...!) will alert you later on if you try to access it. If the padding was zeroed, accessing it is still undefined behaviour but valgrind won't know about it any more.
The random event, sorry
Up front, please read the answer I linked, it goes into great detail about the problems with `while(!feof(file))`. I'm not rejecting anything “as a matter of principle,” there are solid arguments why your approach is invariantly incorrect. &gt; I think you take an issue with my statement that feof "works" only after reading. What I meant by this was that feof won't give what one might expect before an I/O operation, not that calling it before an I/O operation invokes undefined behavior or something like that. If this is still incorrect, please accept my apologies. A `FILE` has a flag called the *end-of-file indicator.* It is clear when the file is opened and set when a read operation encounters an end-of-file condition. It can once again be cleared with the `clearerr()` function. Calling `feof()` on a `FILE` is always well-defined, even if no IO has ever been done on the file. The problem with the `if (!feof(file))` approach is that it doesn't work when an IO error occurs when reading `file`. In this case, `fgetc()` returns `EOF` but the end-of-file indicator is not set, causing an endless loop and garbage, as you try to process `-1` as a character. It also doesn't work in multi-threaded programs (cf. [Time of check to time of use](https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use)) as a different thread could have cleared (or set) the end-of-file indicator between the `fgetc()` and the `feof()` call. If you don't like the standard `while ((ch = fgetc(file)) != EOF)` approach, consider something like this: int ch; for (;;) { ch = fgetc(AL); if (ch == EOF) break; /* process ch here */ } /* sort out the difference between end-of-file and IO error */ if (ferror(AL)) { /* error handling */ } This still has a time of check to time of use problem but the worst consequence is that you consider an IO error as an EOF condition (remember, the error flag can only be set due to an error condition so if `ferror()` yields non-zero, an IO error has occured at some time).
Im really getting confused now, let me try and ask something a little simpler. If I wanted to count the total number of characters in the file using the fgetc how would that be done?
&gt;C99 allows variable declarations anywhere Readability is always a matter of opinion, but is there truth in the claim that you may have to test the placement of your initializers for speed-focused code? I thought local variables were always pushed onto the stack at runtime (or optimized out at compile time) before the rest of the function gets executed anyways? I've tried fiddling with the two examples given by the author and no matter what I do gcc 4.9.2 always generates the exact same assembly instructions for both. (unless I declare the variable "static" of course) 
 ZBarcode_Encode_and_Buffer(...); HPDF_LoadRawImageFromMem(pdf, my_symbol-&gt;bitmap, my_symbol-&gt;bitmap_width, my_symbol-&gt;bitmap_height, HPDF_CS_DEVICE_RGB, 8)
It's rickety, I know but gcc-4.9.2 compiles w/ [this many](http://codepad.org/sgnGmthe) warnings :D
&gt; All of these functions read input from stdin and write it back to stdout in reverse order. Well, the basic process is as follows. void reverse(void) { int c; if ((c = getchar()) != EOF) { reverse(); putchar(c); } } You can write it millions of different ways, but I guess it will boil down to the same thing. edit: Looking at the code, it looks like it handles UTF-8 sequences, which explains the additional complexity.
You are most certainly correct, function 1 only works on x86 and is still kind of buggy, functions 2 &amp; 3 are (like you said) probably broken on big-endian architectures, and the 3rd function even suffers from a format-string bug.
I simplified them a little more: reverse1(byte) { if(read(0, &amp;byte, 1)){ byte += reverse1() &lt;&lt; 8; if(byte &amp; 0xC0 == 0x80){ return byte; } else{ return 0 * printf("%s" , &amp;byte); } } else{ return 0; } } reverse2(byte) { if(read(0, &amp;byte, 1)){ byte += reverse2() &lt;&lt; 8; if(byte / -2){ return !printf(&amp;byte); } else{ return byte; } } else{ return 0; } } Sizes changed again but they still work. I feel like it should be obvious what the second nested if statement is checking for but I don't see it.
It's broken even then, because it looks like it'll only work with utf-8 codepoints that are 3 bytes or less.
What exactly is wrong with memset? Is it just to avoid a function call (which would probably be inlined anyway)?
When you define a variable without initializing it, what value it has is undefined. Let's say, if you write just `int x;`, that x might be 0, or it might be 12345. There is no guarantee what is inside it. Same thing with pointers, if you write `char* myString;`, you have no idea where that pointer points to. This is called a dangling pointer. This is dangerous because if you forget setting that pointer to something before using it, you don't know what will happen. It can make your program print out garbage text, or cause data corruption, or even worse cause security issues. To make sure you don't have dangling pointers, it is a good idea to always initialize pointers, like `char* myString = NULL;` or `char* myString = malloc(10);`.
Something like this: off_t count = 0; while (fgetc(file) != EOF) count++; if (ferror(file)) { /* error handling here */ } You can also use `fseek` and `ftell` to find the number of characters in a file by first seeking to the end and then asking where you are but that's left as an exercise to the reader.
&gt; To make sure you don't have dangling pointers, it is a good idea to always initialize pointers I prefer to listen to my compiler's warnings for that instead. Initializing all variables instead has the bad side effect that the compiler cannot tell you when you forgot to gave a meaningful value to the variable, instead silently producing a wrong result. For example, consider code like this: char *buf = NULL; /* initialize every pointer to NULL */ ... some_function(buf); If you forget to actually allocate `buf`, `some_function(buf)` is going to be called with a `NULL` pointer and the compiler is not going to warn you. If you instead don't initialize `buf` at all, the compiler picks that up and tells you that you forgot to give a meaningful value to `buf`.
I'll try adding that in and see if it works, how could I put it in a for statement if itd work?
yep. If you need further clarification the accepted answer here sums it up really well. https://stackoverflow.com/questions/8403447/swapping-pointers-in-c-char-int
Variables that you don't intialize don't get any values, unless you either: - assign them a value. - declare them as 'static' - or both. Any static variables will be initialized to zero unless you initialize them to something else. Otherwise, you have no assurances of what will be there unless you write something to it first.
&gt; The first rule of C is don't write C if you can avoid it. How come?
At some level, yes, it's very likely. Quite a few actually run Java though, iirc.
My TV's manual actually has a licensing section mentioning the Linux kernel.
go spam somewhere else
At some level though, even those ones running Java for applications will be running C at the embedded level either for some proprietary OS or Linux. 
The `%f` specifier for `scanf` expects an argument of type `float *`. In your first program you are using it correctly. In your second you are not. You should use `%lf` if you want `scanf` to read a `double` value. Turn on all warnings in your compiler, and pay attention to what they say. A good compiler may warn you about mistakes like this.
I tried what you said and it indeed worked beautifully and correctly, so thanks so much! I thought `%f` is good for both floats and doubles, though? Or is there an exception with the `scanf` function?
That made so much sense; I never knew that `printf` and `scanf` actually treated them differently! Thanks so much!
MODS! Here's how to deal with this spam: https://www.reddit.com/r/modclub/comments/406zem/spam_subname_base_profiles_unmarried_age_21/
What are you stuck with? Have you tried compiling it? If it compiles have you tried running it? If it runs, what output do you get? 
I'm stuck with not knowing what to do :P It compiles with no errors. When I run nothing happens, just a black console.
So you need to know what it is doing. You can either run it in a debugger and step through it line by line, or you can put some printfs in to show what the program is doing and why. At line 23, add printf("str1 = &gt;%s&lt;\n",str1); printf("str2 = &gt;%s&lt;\n",str2); printf("*str2 = %d\n",*str2); That'll show you what was read from the file, and what data the `if` statement is working with. Some bugs before that point though are char str1[15]; char str2[2]; while (*str2 != EOF &amp;&amp; *str2 != EOF) str2[2] isn't long enough to hold a 2 digit score. C strings are terminated with nul character, so you need at least str2[3]. Since you've decided to read a string from the file, it should be bigger so that a misformed input file is less likely to make you crash. The 2nd bug here is that str1 and str2 are uninitialised the 1st time you access them. The 1st time you get to the while loop, you're reading the 1st characters from each of the buffers, yet nothing has been written to them yet. This is undefined behaviour and anything can happen. The compiler may decide the entire while loop can be optimised away. 
Here are some remarks and pointers: - Never copy-paste code. It leads you to errors such as that of line 19 where you have str2 two times. - Always close your file at the end of the function with fclose. - As the doc says: "The value EOF is returned if the end of input is reached". It is not written to the string buffer so your loop condition will never be fulfilled. You need to check the return value of fscanf instead. - Your condition line 24 make no sense. The array of characters « "10" » is very different from the number « 10 ». In memory it is seen as a succession of the numbers [49, 48, 0] and what you are really comparing is the numerical value of the first character of the string with 10. I'm pretty sure that's not what you want to do. To convert a string containing numbers to a numerical value use atoi() from stdlib.h - Also your indentation is broken in your "if" condition. Indentation matters. It makes reading your code, understanding it and finding bugs easier. EDIT: - Also your buffer's sizes are too small. Memory is cheap, you'd be better off with a 1024 bytes buffer than a 15 one as it lets you deal with potentially uncommon inputs. Don't forget that any C string ends with a 0 character too, it's easy to forget when evaluating size. As a programmer, as a human, you'll make mistakes. It's better to prepare for it than being overly confident in your ability to foresee what the file will contain or what size you need.
Concurrently reading the same data is safe.
No locking is needed when all parties are reading. The system is free to serve the data to both threads at the same time if it can.
If you know that the shared data is immutable then why copy it? Allocating memory is expensive and, as discussed, the shared memory can already be read by each thread at the same time.
Thanks for the reply. Does the C language provide a way to manage the cache or is that something that the OS does? Are all comparisons considered read operations (e.g. The operators &lt;, &gt;, ==)? What about when I want to check the difference between two values? For example, if a shared variable 'shared' = 10 and the first thread checks 10 - 5 while the second thread checks 10 - 20. Does performing this arithmetic constitute modifying the shared variable 'shared'?
There is no way to manage the cache. Even the OS can only flush it or disable it but not decide what is in there (on x86 and ARM, other architectures may differ). The CPU manages the cache on its own. All comparisons are read operations.
Sometimes, yes. Many systems have non-uniform memory access ([NUMA](https://en.wikipedia.org/wiki/Non-uniform_memory_access)) these days. Giving them a private copy can often be beneficial.
The string literal `"A string."` is in memory somewhere; it's part of the data of your program, and is loaded into memory when your program is loaded. The type of the literal `"A string."` is array-of-`char`. When you use an array *as a value*, the value that you get is a pointer to the first element of the array. So the value of the expression `"A string."` in this code is a pointer-to-`char` that contains the memory address of the character&amp;nbsp;`'A'` in that string in memory. That memory address is what you are assigning to the variable&amp;nbsp;`x`.
If you're on something unixy, playing with objdump is a very fun and informative way to spend a couple of hours. That literal is probably in the .rodata section, but you should create a handful of variables of different types, initialized and uninitialized, and see what sections the compiler puts them in. Fun! 
The string has static lifetime, which means it exists for the life of the program. It can therefore be statically allocated. The heap is for dynamic allocations, not static data. The details vary by operating system, but the general theme is that there are different sections of the executable that contain these various statically allocated variables: - `.bss` - uninitialized read/write data (note: variables with static lifetime that are uninitialized are filled with zeros, in contrast to variables with automatic or dynamic lifetimes) - `.data` - initialized read/write data - `.rdata` or `.rodata` - initialized read-only data The layout of all of these is determined at link time, not at runtime. `.data` and `.rodata` are memory mapped directly from the binary executable. `.bss` doesn't actually need to be stored in the executable since it's all zeros, so it's allocated and zeroed during startup. Additionally, the memory mapping corresponding to the `.rodata` section can be marked read only so that you get a fault if you try to write it. This is where string literals are generally allocated. 
That's a little different. Arbitrary strings that are read at runtime would be allocated either in static arrays (the space of which were allocated at compile time) or on the heap using malloc.
It's the same now as it was then. Any memory for a string that's read in (or manipulated) at runtime must be allocated explicitly. Often they're fixed-length, but variable-length is possible. C99 added VLAs, which are nicer than using the heap. Even before C99, a lot of people used `alloca` to do VLAs, even if it wasn't standard.
The code is not in any way doing Unicode handling. That would be much more complex to get right.
A NULL dereference isn't a guaranteed crash (common misconception). Also, do you really prefer your code to crash much later down the road at an unrelated point when you could have the compiler tell you about the problem right where it occured? And I'm not a huge fan of `-Werror`. If you are not sufficiently disciplined to actually listen to the compiler's output, maybe you need that, but it's really a pain-in-the-ass to edit out all the `-Werror` from other people's software when trying to compile it with a different compiler that warns in different places.
Well, if you compare my function with reverse1, I get these outputs for UTF-8 encoded input. # sed 's/\t/ /g' r.c #include &lt;stdio.h&gt; void reverse(void) { int c; if ((c = getchar()) != EOF) { reverse(); putchar(c); } } int main(void) { reverse(); } # make r cc r.c -o r # printf '\næ ,olleh' | ./r hello, � ... # sed 's/\t/ /g' r.c #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; reverse1(byte) { return (read(0, &amp;byte, 1)) ? byte += (reverse1() &lt;&lt; 8), ((byte &gt;&gt; 6) &amp; 3) == 2 ? byte : 0 * printf("%s", &amp;byte) : 0; } int main(void) { reverse1(); } # make r cc r.c -o r # printf '\næ ,olleh' | ./r hello, æ With this we can conclude that the UTF-8 sequence æ is retained by reverse1, but not by my own function. (Indeed, there's issues with how UTF-8 is handled in reverse1 and it won't handle larger sequences, but in my estimation the author of reverse1 intended to handle UTF-8 with the additional complexity.)
Common misconception and "virtually always true guideline" are different. Yes there is an occasional system where a null dereference won't crash your system, but it's rare enough that I'm comfortable ignoring it when speaking in general. Not crashing means you are writing on bare metal that also has no hardware access safety in place, in which case you should know what you're doing and understand the need for extra caution. Trusting the compiler is not sufficient at that point, except for trivial cases. Not liking -Werror means one of the following: you need to set up your makefile differently so that *only* your code compiles with your flags; you are a maintenance programmer in which case this is a moot conversation because you should follow the convention already established in the code; or you want the privilege to ignore warnings in code you are writing. None of these is a problem with -Werror. I happen to work on a project so large that without -Werror for my own code it's nearly impossible to find my own warnings in compilation. Using -Werror means I don't make the problem worse. Thus being a small part of a big system full of warnings actually argues in favor of -Werror, at least while I'm actively developing. 
Thanks
Thanks
Thanks.
You are responsible for allocating space, in C99 and all other versions of C. You need to make the decision of how you do it and write the code to do so, either by using VLA, malloc(), a normal (non VLA) array etc. 
Please do not delete your posts after getting an answer. Doing that repeatedly causes you to get banned.
What are you trying to achieve with a `for` loop?
Compilers themselves are not friendly. You want an IDE - an editor that also launches the compiler for you. What operating system are you using?
Use gcc with flags that will help you. f.ex: -Wall -Wextra -Wpedantic My recommendation for a newbie is to write the code in an IDE, but compile in command line. 
I am running win10, what IDE do you recommend? 
What IDE would u recommend then? I was looking at Eclipse a few moments ago, that should do the trick, right? 
Visual Studio Community 2015 is a solid IDE and is free from Microsoft.
Decided to go with Visual Studio, Thanks for all the advice guys! 
[quake2](http://fabiensanglard.net/quake2/) [quake3](http://fabiensanglard.net/quake3/) [quake](http://fabiensanglard.net/quakeSource/) Also there are great code reviews by Fabien Sanglard
Clang gives fairly detailed and user-friendly messages, and it has compatibility modes for Visual Studio (do not recommend!\*) and supports GNU (e.g., GCC) compiler extensions and quite a few architectures. It also tends to be out on the forefront in terms of C++ support, which is handy if you need it. \*I cannot recommend VS; it is primarily intended to be a C++ compiler and its C support is half-assed at best. It encourages you by default to use non-ANSI extensions that won’t link with any other compiler’s C libraries, and it still doesn’t support C99 properly. (Preprocessor’s always been funky, for starters.) If you want somewhat good error messaging and navigation when editing code, I’ve found Eclipse CDT to be quite useful for a project larger than ~5 files, as it’ll let you hyperlink between elements of the program. E.g., ctrl+click or shift-hover over a thing to see its definition. Eclipse will also let you walk through preprocessor expansion with Ctrl+=, which I haven’t seen anywhere else and is *super*-useful should you need to use the preprocessor very extensively. For single files or small projects, KDE’s KWrite and Kate (respectively) are quite nice and run on both Windows and Linux.
Just to add a teensybit to what other people have said: - Let’s say you use some string literal `"Foo"`; that is precisely equivalent (possibly modulo C89 declaration packing) to first declaring static const char __STR_Foo[] = "Foo"; // sometimes not const, but should be and then naming `__STR_Foo` anywhere you’d otherwise use the literal, with the slight exception of array initializers. More modern Cs will even let you do something like `((const char[]){'F','o','o',0})` which would IIRC/FWIW would be precisely synonymous to the string literal. Note that any time you name an array or string literal and aren’t using `sizeof` or some similar feature on it, its name will decay to a pointer to `that_array[0]`. So `sizeof("Foo" /*or __STR_Foo*/)` would be 4, but `"Foo"+0` would be a `const char *` to the `'F'`, and so `sizeof("Foo"+0)` would be equivalent to `sizeof(char *)`. Taking the address of an array gets you the same pointer value as `array+0` but with a completely different kind of type that almost nobody ever uses, `char (*)[]` in this case. - If you don’t know how big the array will be beforehand, the easiest thing to do is just declare by fiat that the string mustn’t exceed some maximum size and use a local or static array, which would look like `__STR_Foo`’s declaration above. (Don’t use more than ~8–16 KiB in a local array, as you can crash your stack that way. How much you can allocate depends on your target architecture and page size.) This is the usual way to write toy code, but this approach shouldn’t generally be used in production code without taking care to prevent buffer overflows. - If the simpler array approach doesn’t work (usually you can’t just assume sizes like that), you can use `malloc` and `realloc` to create and expand a buffer as needed. You can also start with a local array (much faster, but limited) and move things out into a `malloc`ed buffer (slower, but ~unlimited) if they won’t fit in the array. For example, let’s say you’re reading in chunks of data from a stream: char buffer[STARTING_BUFFER_SIZE]; char *bufp = buffer, *bufwp = buffer; size_t bufCap = sizeof(buffer); ... // do stuff that gets more data // Compare the remaining space in the buffer with what we need if(bufCap - (bufwp - bufp) &lt; AMT_NEEDED) { char *newBufp; size_t newBufCap; // If we're aimed into the stack, allocate a new chunk and copy over. if(bufp == buffer) { newBufp = (char *)malloc( newBufCap = expandBy(bufCap, AMT_NEEDED)); //* if(!newBufp) {complain(); abort();} memcpy(newBufp, bufp, bufwp - bufp) } // Otherwise, reallocate the existing chunk. else { if(!(newBufp = (char *)realloc( bufp, newBufCap = bufCap + AMT_NEEDED))) {complain; abort();} } bufwp = newBufp + (bufwp - bufp); bufp = newBufp; bufCap = newBufCap; } // Copy the new data into the buffer and adjust the write pointer. memcpy(bufwp, SOURCE_DATA, AMT_NEEDED); bufwp += AMT_NEEDED; // possibly *bufwp = '\0'; if you need to keep it terminated ... // loop, use the data, whatever, and finally... // Free it if it’s not on the stack. if(bufp != buffer) free(bufp); //* expandBy left as an exercise for the reader. :P - For C99 and better, you can dynamically allocate local arrays; e.g., char buffer[strlen(string) + 1]; memcpy(buffer, string, sizeof(buffer)); Again, don’t allocate more than ~8–16 KiB this way unless you know better. If you don’t have C99, you can do basically the same thing with `alloca`, which is super-nonstandard but supported on most platforms and compilers; that’ll allocate a chunk of memory just like `malloc`, but on the stack like a local variable, and as such it’ll disappear as soon as your function returns.
Thanks.
I am late, but it seems Visual Studio is a premium type of thing; not something you wanna start off using if you truly are a "noob". Ideone is what you are looking for. It's literally just a website - ideone.com - that you go to and start typing and running codes right away.
GCC was also my first reaction but he is on windows, has anyone here used [this](https://sites.google.com/site/virtualcide/)?
Portability is hard, especially when you have a non-standard operating system like Windows (where *standard* refers to IEEE 1003.1, i.e. POSIX). Basically, you have to write an abstraction layer (or use an existing abstraction layer) for all unportable functions you are going to use, which is a real pain-in-the-ass, especially when you need to support Windows, too. For cross-compilation, the best bet is to set up a virtual machine for every target environment and compile in that. Setting up a cross-compilation environment is tricky, especially when the target is not similar to the host or requires a compiler that only runs on the target.
Excellent feedback. I'm going to carry this on under the /u/sixteenlettername post. :)
Ok so I like this. I have no problem rolling my sleeve up and doing some SSH connections and working through a VM. I use Vagrant a lot (and Docker) so this stuff is ok with me. So, let's say I've setup a sweet build process where I can build on all platforms via SSH, NDK, Xcode etc... and all is good. Heck, let's say I get Visual Studio to do this (since I think you can actually do this with add-ons to Visual Studio). My last concern is the differences in each compiler. I've been reading a lot of stuff the past few days and I'm getting the impression that some compilers support C better than others. I should be clear by saying that some compilers support *true* C better? This is where I get a bit confused. C99 vs C11 (have I got that right?) and the idea that VS likes to use a C subset that tailors more to C++ so it withholds certain things? That scares me a bit, as an example, because what if Microsoft says "Meh, this part of C we don't care about, we no longer support it" and then I'm compiling against something that is controlled by an entity that doesn't care about me. I hope I'm stating my concerns clearly. I want to be able to write a "pure" C program (I realize it's not entirely possible, but as close to as possible) and not have to worry about my compilation of it in a given system.
This is in-line with a lot of things I've read and the comments here so far. Thank you. I believe Xcode is the way to go for Mac and iOS and I've seen it done (not in detail, just in passing) so I know there's magical unicorn way of doing this. Well, it looks like a magical unicorn to me, haha.
Xcode uses clang as the compiler. If you use a stock build system for UNIX (e.g. a bunch of Makefiles or autotools or cmake), your code builds just fine. I advise you to treat OS X as any other UNIX, invoke the compiler as `cc`.
Ahhhhh ok this is starting to make sense to me now.
For beginners- would you say that this article contains good practices? Or should one continue with the 'old' methods as in variables like int,char etc
Here are a few thoughts I had while reading this post: - 6 months into your first language is not that long. I think you should go a little easier on yourself. - In fact, 6 months in and you're building little tools for yourself sounds about appropriate to me. - That challenge you linked to has many steps, that include at least the following topics - reading input - properly handling of whitespace and comments in the input - understanding of rgb colors - opening a window and drawing to it - knowledge of basic graphics algorithms - You're going to find graphics programming difficult in general in C, because C doesn't have built in graphics libraries like Python does (hence the Python examples already posted). In fact, I would say C is one of the hardest languages to do graphics dev with for this reason. Just opening a window is quite a bit of work. Accessing the bytes to change the colors the way this challenge is asking you to do is even harder - in Windows you need to use a Device-Independent Bitmap and do some calls using Win32 that are fairly obscure to modern developers. - Challenges like /r/DailyProgrammer will not be aimed at C developers - they'll be aimed at other languages that have tools you do not have. Don't be upset with yourself for finding them so challenging. - I'm running a video series on YouTube called Handmade Quake that rebuilds the Quake engine in C. The first few videos are up, and discuss pointers and parsing command lines, and will gradually build up to the software renderer. I mention it here because I'm creating the program to fill in this beginner-&gt;intermediate gap in educational material that I found when I was in school looking for resources. Maybe that will be something that helps you continue to progress: http://youtube.com/philipbuuck - However you continue, you really shouldn't lose hope. It sounds like your ambition is outweighing your knowledge. You may want to consider the /r/ReverseEngineering subreddit, since you mentioned that, or my Youtube series, or a book on operating systems, which will get you familiar with how the guts of a computer operates. That's the level of development that C opens up to you, which is different from many of the /r/DailyProgrammer challenges.
Try to compile with `-ansi` or `-std=c99` (depending on what standard you want to be compatible with) and turn on `-pedantic` to make the compiler warn you about non-standard constructs. `gcc` extensions only pertain language extensions, if these are not available you generally have to rewrite the affected parts of your code. Examples are `__attribute__` and GNU's non-standard `inline` semantics. You cannot implement these by adding extra functions. Extra functions do help to replace missing library functions, of which there are a ton on Windows. Often there is something sufficiently similar in the Windows API or the function exists but with a different name (e.g. prefixed with an `_`).
Great, thanks for clearing that up. 
It sounds like you're come pretty far in 6 months! I don't know if more tutorials are the right answer to where you are. I've found that reading other people's code is a fantastic way to sharpen C programming skills. I look for code that solves the problem I'm working on and evaluate how it works, sometimes comparing multiple solutions. I then write my own based on what I learned an adapt it to my use case. Two books I highly recommend are "[Writing Great Code, Vol 1](http://www.amazon.com/Write-Great-Code-Understanding-Machine/dp/1593270038) which pretty much covers soup to nuts low level details of types, internal representation of numbers, endianness issues, and other topic of machine organization. You will get *so* much more out of C programming after reading this book. &gt;it's all mostly assembler stuff which i've touched on (learnt about the registers, control flow, jump instructions, etc.), it is very confusing I feel and am maybe not ready to undergo such a venture. The second book is Vol 2 of the same series, and is particularly applicable to your goal of reverse engineering and writing exploits. [Write Great Code, Volume 2: Thinking Low-Level, Writing High-Level](http://www.amazon.com/gp/product/1593270658). This book builds on the first and delves into compiler internals and how choice of conditionals and algorithms effect performance. The code examples are dissected in assembly to illustrate how minor differences in the source greatly effect the machine code generated. A deeper discussion of internal representation of data is also covered. Fair warning, I haven't finished this one due to life, but look forward to picking it up again. This author also wrote a highly regarded book on x86 assembly, but I haven't read it yet. Hope this helps!
&gt; I guess I'm just worried that I'll create a whole bunch of C code that cannot be compiled in other platforms, at all. This is an art unto itself. Much of it comes down to isolating the application specific code from the platform specific code through proper use of abstraction. Far harder in GUI environments than it is on the command line!
&gt; So, I've read that clang can lead us all down a dark and gloomy future where compilers are no longer free because of the licensing differences between clang and gcc? That's utter crap. BSD has been licensed under the BSD license (the same license clang uses) for decades now and they are doing fine. You should see the availability of clang as a good thing because fruitful competition is good for business. &gt; Should I be worried? I'd like to develop some commercial stuff in C. I have another post in this subreddit about cross platform compiling and, by far, the answer I received the most was to compile on each platform individually so I'd be happy to install gcc on every single platform I'm hitting (or clang) if there's some cultural preference by those who actually live and breathe C. Clang tries really hard to be a drop-in replacement for gcc. Many gcc extensions and almost all of the command line options are supported by clang. Clang has better warnings but the optimizer is deficient, especially for older platforms. For example, clang generates mediocre x87 floating point code while gcc excels in this regard.
I like this. I use GIT a lot and I run my own GIT repo / server and I write shell scripts to automate the GIT tasks I run most often. This is a good idea, thank you!
It's an edge case in the C language that occurs some time. Some people might be interested in it, thus I posted it here, too.
Awesome, the books blurb sounds a bit meaty but I'll give it a go! I try to make it a habit to look at other peoples code often as I learn alternate techniques to my own problems; one particularly cool piece of code I wish to understand one day is the greenpois0n jailbreak code, right now I don't really understand it and it appears to be a somewhat interaction with the hardware (?), here it is for those curious, https://github.com/Chronic-Dev/syringe I've been following the rasberry pi- build your own OS series made by cambridge university which delves into ARM assembly, the general consensus is that it is the easiest assembly to learn as a beginner. However, I've been watching an x86 assembly series on youtube and it doesn't seem all that bad. It is quite theoretical and a lot of reading but I guess I just need to digest it and keep working at it if I really wanna enter the infosec field! 
I'm guessing you mean Visual Studio? I'm using C inside of Visual Studio, as it has a C compiler - the descendant of the C compiler that Quake used back in 1996. The link I sent you is the lightest introduction to graphics that I know of in C. If you have another direction you're looking to go, let me know and perhaps I can suggest something.
Thank you very much; following your Quake series aswell as getting my feet wet with some introduction to graphics and reading some of the books mentioned by other redditers should be more than enough for now plus school is on its way and I need to study hard if I want to get into CS next year!
I found this interesting and even somewhat humorous, and it's just the kind of thing I'd like and expect to see as a subscriber to C_Programming. Thanks OP, I appreciate you!
Read the sidebar. If you haven't had programming knowledge before, then [The C Programming Language](http://www.amazon.com/gp/product/0131103628) by Dennis M. Ritchie and Brian W. Kernighan is right up your alley.
A minute ago you [wanted to learn C#](https://www.reddit.com/r/C_Programming/comments/40iwns/-/) and now you want to learn C? Well, okay.
I have some code that compiles on Windows 7 and Linux. I use MinGW and gcc, respectively. I just avoid cross compiling when I can. I stick to the standard library or use libraries that have been tested on both systems. I think that adding Cygwin or virtual machines can introduce layers of complexity in such a way that i'll shoot myself in the foot or I could spend a lot of time chasing configuration problems not related to the software's problem domain.
Quite a funny title if you misread Forskolin as foreskin, as I did.
`goto` is always local to a function. You cannot jump out of a function with `goto`, if you want to do that, you need the functions from `&lt;setjmp.h&gt;`.
What are you interested in?
Excellent, thanks for the reply.
If you write a video game, I recommend you to use the libSDL for portability. Real-time stuff (as needed for games) can be tricky to get right in a portable manner, too.
Yeah it blows. So I've decided I need to cut my losses and use my strengths to my advantage. Node webkit and/or Electron are Node and Chromium packaged binaries that can run on Windows, Mac and Linux. I've used them a lot and I can use regular ol' JS / HTML / CSS and Node to write GUI based apps. Slack uses Electron, for example. So I can definitely build a game with WebGL (or even OpenGL if I really really want to) in those platforms. So all I need is to compile Android and iOS and I've got the major platforms covered. If I can compile C for node modules and I can figure out how to compile C for Android (NDK I presume) and iOS (simply Xcode I presume) then I'm good to go.
What you're describing, with the identifier "cleanup", is commonly referred to as a label. Labels are the only identifiers that have function scope -- they're known all throughout the function in which they're declared, but only to that function.
Early C compilers (pre ansi) could `goto p` where `p` was a pointer and jump to an arbitrary address. This meant `goto f` where `f` was a function name was tail-calling. 
ok bro, thanks 
i do a pretty good 'hello world' if that catches your fancy?
My favorite is FFmpeg, but I'm afraid it requires a little bit of technical knowledge about each specific codec. Still worth taking a look, I guess.
yeah righto, so i get down voted because i made a stupid joke due to the fact the guy cant be stuffed adding in any other details about levels of experience or what he hopes to achieve, (let alone searching stackoverflow for ideas...). my proper advice would be to try and fix bugs in other programming languages, implement data mining algorithms, write a web framework or predict the value of stocks. if you have a hobby outside programming like music, find something around that because your motivation will burn out after a while, and you'll need to really dig deep in order to stay motivated (rather than "it'll look good on my CV"). 
If you're into circuits I believe ngspice (circuit simulator) is written in C.
For a fun way to start learning C i recommend "Head first C" simply and clear!
Thank you for that. Of course I know that but I can't believe I forgot to put one in. I should do a better job of looking through my code.
Your compiler can warn you about this if you enable all warnings.
That's a good idea! 
Thanks, I'll check it out 
I shall, thanks 
Stop posting this garbage. 
I would've agreed a year ago or so, I myself wrote a codec for them, but the project's code is pure spaghetti, and their leadership isn't much better.
Yum!
Haha I remember one of the developers making a presentation about it and saying how the code is a mess and should be refactored. I suppose making the code more organized is always welcome, isn't it?
Add a feature to GNU coreutils? It's a massive open source project (Most Linux desktop machines are running it. And if they're not running coreutils, they're running busybox). It would certainly be impressive, as your code would then be running on a shitload of machines. 
For extra points, OP, write a C program that uses labels and gotos within different functions, and then disassemble it. What did the compiler do to your labels? Or, instead of disassembling it, set your compiler to give you the assembler output instead of fully assembling/linking. It's a fun way to learn what's happening behind the scenes.
Source? I'd love to read about that.
Great suggestion, thank you 
It's possible to abuse `goto` in some creative ways. An interesting example is taken from busybox's udhcpc [code](https://git.busybox.net/busybox/tree/networking/udhcp/dhcpc.c#n1471) (look at how the control flow goes through `REQUESTING` and back to `leasefail` label): ... switch (state) { case INIT_SELECTING: if (!discover_retries || packet_num &lt; discover_retries) { if (packet_num == 0) xid = random_xid(); /* broadcast */ send_discover(xid, requested_ip); timeout = discover_timeout; packet_num++; continue; } leasefail: udhcp_run_script(NULL, "leasefail"); #if BB_MMU /* -b is not supported on NOMMU */ if (opt &amp; OPT_b) { /* background if no lease */ bb_info_msg("No lease, forking to background"); client_background(); /* do not background again! */ opt = ((opt &amp; ~OPT_b) | OPT_f); } else #endif if (opt &amp; OPT_n) { /* abort if no lease */ bb_info_msg("No lease, failing"); retval = 1; goto ret; } /* wait before trying again */ timeout = tryagain_timeout; packet_num = 0; continue; case REQUESTING: if (!discover_retries || packet_num &lt; discover_retries) { /* send broadcast select packet */ send_select(xid, server_addr, requested_ip); timeout = discover_timeout; packet_num++; continue; } /* Timed out, go back to init state. * "discover...select...discover..." loops * were seen in the wild. Treat them similarly * to "no response to discover" case */ change_listen_mode(LISTEN_RAW); state = INIT_SELECTING; goto leasefail; case BOUND: ... Not that I would advising writing such code to anyone, but again this excerpt is from busybox where people generally know how to be creative about abusing the compiler to do what they want and the way they want it.
And if you're looking for something to do, **add octal support**. (So when you type ls -l --octal (or some other flag), it will output the permissions in octal instead of the rw-r--r-- format). It seems like a really damn popular request but it hasn't been done yet (either because no one has bothered, or they reject it for some reason, no idea)
&lt;3
I'll mention radare2. Although it's maybe not the most beautiful code it's a very active project that will teach you a lot (really) about how binaries work and about a tons of things from databases to emulators.
I maintain a fairly small &amp; new piece of software called [imv](https://github.com/eXeC64/imv). It's a pretty small codebase, but a useful tool for those of us who live in tiling window managers. There's a few bugs and tweaks available to be worked on (see the repo's issues) if you're interested.
I haven't ever worked with those but I'll give it a look, thanks for the suggestion 
Oh yeah, and I have no illusion that I fully grok'ed the program from spending 15 minutes reading through the header while eating a sandwich :). I really like this though, so far you're at the top of my list. I'll look at it further as time allows. I'm definitely picking something in the next month or two and beginning to work. 
Thanks for the reply. How do I disassemble a program? Will the program then be in assembly code?
Thanks for the interesting example.
&gt;I'm still seeing most of the people we hire at my company having learnt Java and/or Pyhton, and then just learning C on the go, and doing just fine. This is it right here, really. Languages are surprisingly related across coding, all of them giving a deeper understanding into computers. C *would* be more popular as a first language, but *"pointers are just so scary and gross!1!"*. But yeah, I definitely don't recommend it as a first language.
Of the currently common languages, I think C as a first language is one reasonable approach. It teaches what the higher level languages take for granted - things like memory management and indirection. Moving on to a higher level language from C can help appreciate why some decisions were made, and why some things take more time. Personally,I think ada would make a good first language. It's very high level, yet easily allows exploring lower level concepts. Multi tasking is available as part of the language, not just as a library. It is easily read, too. I learned a lot about oo from the explicit (slightly cumbersome) syntax in ada95. That really helps me understand the underpinnings of c++. Note that later ada standards make the oo syntax less cumbersome, and more user friendly. edit: stupid phone thought more was Mike
I learned Python first with the scipy stack -&gt; c++ -&gt; c. I don't think Python first was a mistake, but learning C first would have definitely been more conducive to me understanding what was going on behind the scenes and set me up better in the future. Getting back to the whole circle jerk against C on what I assume is /programming... It really is mystifying. People say oh blah blah spaghetti code, so unsafe, etc. I feel like most of those people have never actually used C. These are all problems that other languages have. Definitely take what they say with a grain of salt.
I've actually never worked with an SQL database, maybe I'll look for one that involves that to plug a gap in my experience. 
No regrets from me that i started with C. Here's one thing i wish people had told me at first though: don't expect to do anything beyond basic console-based apps for quite a while. 
No. First, C is simple. In fact, when I first learned C, I was surprised by how simple it is given all the hate that you alluded to around it. I had a programming teacher who espoused FORTRAN as a first language for similar reasons. (She is an computational physicist.) Second, C gives you just enough of an abstraction of the hardware to get an idea of what is going on behind the scenes. I learned Python first (and still use it most), but after I learned C I had a much better understanding of what the system is doing that makes me a better Python programmer. Last, as others have mentioned, C is the basis for most other languages currently in vogue. You can appreciate the work that went into these (hell, many of them are or were originally implemented in C), and everything they handle for you. (And where the shortcomings are as well. For a while I was mystified mutable/immutable objects in Python. Ultimately I think pretending like pointers don't exist just creates more confusion, not less, even if in most cases you want the language to handle them for you.)
&gt; don't expect to do anything beyond basic console-based apps for quite a while. That makes me kind of sad to hear. Is that how it is for people starting out today? The earliest programming I ever did was all visual and I think the immediate feedback of actually *seeing* what the code was doing (and instant gratification of seeing it do anything at all) was a huge reason that I got hooked on programming. The first "coding" of any kind I was ever exposed to was turtle graphics as a small child and I was pretty amazed that I could tell the computer to do all these things and it would actually go and draw them on the screen for me. Later I had a book of programs you'd type into an apple II that drew lots of cool geometric stuff, and when I finally got to take a programming class in high school it was full of visual projects right from the start. Tic tac toe, breakout etc. At the beginning we were using a library the teacher had written that removed a lot of the boiler plate required to get a window from the OS and draw basic shapes. If nobody has a learn C course going that teaches it that way today that's a shame.
Everyone learns differently. The first programming class I took was an embedded assembly class. I didn't get much out of the class. After that I took an Intro to Programming with C and the professor was bad enough that it scared me away from programming for a few years. Did some embedded stuff on a co-op and it started to click. What really made the difference was learning Tcl and using the interactive interpreter. After learning Tcl, it was much easier for me to wrap my head around C.
Thanks for the reply. &gt; Very likely, but have you used a profiler yet? No, I haven't learned how to use a profiler yet. Thanks for reminding me to learn it. &gt; What total runtime are we talking about (milliseconds, minutes, hours)? The single threaded program takes about 13 days to run on an i5. I just tested a small segment of it on an i3. With 2 threads it performs about the same as the single threaded version but with more than two threads it takes longer. &gt; With millions of calls, malloc could even be a bottleneck in your single-threaded version. In any case, I really recommend profiling before optimizing anything. Thanks for the advice. Do you know if malloc() places a lock on the heap when multi-threading?
Never underestimate the power of a BASH shell.
Here is a bunch of small issues: - use `strtol(3)` instead of `atoi(3)` - print warnings to `stderr` for example with `warnx(3)` - the library doesn't warn on unknown args - instead of memcpy do the following: arg_queue[arg_queue_size++] = (struct argh) { … }; - args.c:57 this could lead to a buffer overflow.
I wouldn't say that it's a mistake, but choosing an easier, higher-level programming language (python comes to mind) means that you'll be able to get something going very fast with visible results. That plays a lot when learning a programming language if you don't have a very specific goal in mind because the first thing you'll find yourself asking after learning about loops and functions will be "Ok, and what do I do with those now?". There's a lot more that you can do in 10 lines of python than in 10 lines of C (without cheating) and that also means that actually doing stuff is easier. Also that way you don't have to learn everything at once and can focus on the basics before moving on to memory management, pointers and stuff. As I said I don't think C as a first language is a mistake and others have highlighted its advantages, but I really don't think it's the best choice either and I've never found myself reccommending it to anyone. I just thought you deserved some counter-opinion (beyond the obvious bias of comming to /r/C_Programming asking about wether to choose C or not).
Thanks. Does it matter which profiler I use if my program is multi-threaded versus single threaded?
Most profilers only show you time spent inside functions, but don't split the data up by thread. So, yes, it can matter a little bit which profiler to use, but if your threads all do the same thing, it probably doesn't matter for you. If your troubles stem from some blocking call somewhere, it will show up as one of the top time hogs in the profile.
Thanks for the help.
Depends. Do you think you'll need to see quick and regular progress in order to maintain your motivation to learn? Do you find it difficult to persist in the face of hard problems? Do you want to get something working but aren't particularly interested in computer science in the long term? If your answers are yes, then starting with C is a mistake. If no, then C would be a great first language.
`warnx()` is non-standard. Don't use it in a portable program. In fact, there is no reason to use any non-portable functionality in this simple program at all. Instead, use `fprintf(stderr, ...)` or write your own `warnx()`. The `warnx()` function also has the problem that it needs to know the program name which has to be set with `setprogname()` beforehand and is a lot of hassle.
&gt;13 days Uhmm or you have a big dataset, or complex calculation. In any case if you link the source we can help you to follow good practice and at least some basic optimization.. Maybe there is something wrong and it can run in seconds.
". . . it still helps me with **higher** level languages such as C++, python, C#, etc." He said it was higher level than C, which is accurate.
I don't see why after a few exercises in C one can't just go on to SDL, although it has a bit of boilerplate. C was my first language and I agree with a lot of the sentiment here, but I will say this: it's easier to get a visual feel for what you're doing early on in JavaScript, especially if you start with jQuery and manipulating the DOM. On the other hand, I find JavaScript's [wats](https://www.destroyallsoftware.com/talks/wat), lack of variable scope, bizarre inheritance system, and it's over-reliance on callback hell to be just as frustrating as pointers.
I would argue that pointers seem scary and gross because you started with another language that didn't directly expose them. I would also like to mention that I think structs are a great introduction to working with objects. I started with Java and transitioned to C, it wasn't a huge problem. But looking back I do feel going the other way would've been easier. 
C is a high level language. My textbook's definition of a high level language is basically "anything but machine/assembly code". If you're directly manipulating CPU registers and have to know opcodes, you're in a low level language. C is portable across architectures, you don't need to know assembly to write in it (though with the pointers, you do kinda need to know memory management). 
My first "real" language was Python (but I started with QBasic, then scratch, then visual basic, then python, and now I'm learning C). Personally, python is a great language to start with, if you have no prior knowledge. It's really easy to make something that just works™. C (at least for me) is a PITA to do complicated things, and it's pretty easy to fuck up. If you're asking if it's possible to go from python to C, or any other "harder" languages, yeah, it is.
Apparently rust looks pretty damn good.
&gt;I've noticed a circlejerk on Reddit recently that focuses around how "useless "and "glitchy" C is, and how learning it is "unnecessary, unavailable or simply unwanted" (not my words). I've noticed this circlejerk as well, and that's *exactly* what it is. It's generally propagated by young CS students and Web developer types who haven't the slightest clue how the underpinnings of their development environment works. It's sheer ignorance that any one language is 'superior' than another language for all use cases. High level languages sacrifice speed/efficiency for greater abstraction and faster development. C (and its direct descendants) is very unlikely to become 'obsolete', any more than assembly is. Embedded systems are a bigger deal now than at any time that has come before, and C is king in this domain of computing, and there is little chance that higher level languages will make significant inroads there.
Definitely. But I think if suffers a few things that C provides: * Lack of maturity (not a big deal, but sometimes it shows) * [Here is a small program to make it leak memory](https://github.com/fredmorcos/archive/blob/master/Examples/Rust/dining-philosophers.rs), try running the binary in `valgrind` * Semantics and syntax are definitely not trivial * C++isms: Understandably, it is around to be more of a C++ replacement than a C replacement * Documentation is unusable without a web browser
I've heard that a hundred times. I've also heard alternatives a hundred times, but they all sacrifice one or more of C's upsides. It's unfortunate, but that's the situation we're in. A C with checked return values, generics, no preprocessor and a proper module system could possibly go a long way without sacrificing C's upsides.
I will be downvoted to oblivion for this, but I hope at least someone responds with a reasonable retort than just a downvote. I don't think it's mistake, but I think it might be better to learn C++ first. C++ will introduce you to many C concepts and more importantly, tool chains, while simultaneously introducing you software architecture and design patterns that all the corporate jobs crave. You could learn all of that with pure C of course, but C++ has far more in common with things like Java and C#, which are arguably more in demand job-wise than C. 
You can accomplish a lot more, faster with a scripted language. I certainly took classes in C back in the day; I have a fondness for it, and the concepts helped, though I'm not sure how much. Another not so trivial point is if you have a bunch of utilities in C, you are faced with managing the source code. These days everyone works in multiple languages, so the two questions I think that are more appropriate questions are *what languages do I enjoy writing in*, and what languages do my employers or clients *want* (if any).
If you learn c first everything will feel easy. However it will be a little harder in the beginning. I think it really comes down to the person.
But I'm not creating any threads. It's literally a simple hello world program that causes this.
And it doesn't terminate even if you close the message box?
It could also be that you're using a slow algorithm (or at least one that is not suited for your input size / problem), or that your implementation of the algorithm is slow.
The first time I ran it the gui showed up and it exited. Second time nothing popped up but it shows up in the task manager. Also if I try and execute it from cmd prompt it doesn't let me insert new commands and ctrl z won't let me out or quit the program. I'm pretty much going to give up on learning c at this point.
"Your ability to dereference a pointer is insignificant compared to the power of the shell" :)
I'm not familiar with Windows GUI programming. I suspect that a Windows GUI program does not terminate on return from `main` which makes sense in a GUI program as you usually only want it to terminate once the main window is closed.
&gt; Each thread makes heavy use of malloc() (millions of calls) Why do you malloc millions of times? Mallocing that much seems wrong by itself as there are many other ways to do what you want: pooling, atomic operations, TLS, etc.
I don't disagree with you. But at least the additions/changes I mentioned don't sacrifice anything to have them. There's been ~30 years of programming language research to be able to have your cake from the 1980s and eat it too. I've decided that C is the best tool for the job I'm working on right now. But it would be great if it could help a bit more in a couple of areas. That's all.
Can you post some examples so we know where you're at? It might be better for you to get some good honest criticism than just be told "look at this project", because depending on your knowledge level it may go completely over your head
It depends on your compiler. You should learn about what happens when the compiler takes your C code and makes an executable out of it. First it compiles, then it assembles, then it links. You'll have to figure out how to tell your compiler to give you assembler code, or play with a disassembler yourself. Tinker with it! Read the manual to your compiler or do some research yourself. I'm giving you tools to learn - but you have to put in some work yourself :)
How are you compiling and linking the program? The source you posted in a comment should indeed terminate whether you use return or exit. You say that if you launch it from the command line, the command line waits for the program to exit? That is also incorrect behaviour for a Windows app.
A really brief checklist of my habits **comments** // within functions, /\*\*/ outside. That way if you need to comment out a large block of code you don't run into nested block comments. At the start of a function tell what the function does, what it's inputs are and what they're expected to be, what it returns, what it returns on error, what error codes mean Within functions, any confusing bits, if it can't explain itself it needs a comment explaining it. **Functions** Functions only do one thing, break big functions down into their individual pieces. Don't assume that data supplied to a function is correct, verify everything, don't assume pointers are initialized, don't assume called functions return correct data, it will add a lot of lines if code, but it will save you many hours of debugging. **misc** Use a version control system. In your source files, keep things organized. Before you start a project write out what the main tasks are going to be, they should reach their their own source file, be organized. Keep notes written. Don't start a project without a plan of what you're going to do.
C was developed to be a portable assembly - there's a reason you can write a kernel in C. You can get to a register level if you need to. Yes, it's a higher level than assembly, but it can get damn near as low if you need it to.
Thanks for the reply, I usually post my code when I'm asking for help but I'm not allowed to share this code.
Thanks for the reply. &gt; Is each call to malloc for an individual object of non-deterministic lifespan relative to other objects? Yes, I allocate about 1-2 KB of data at a time and then perform analysis on that data. &gt; Seeing this suggests to me that you'd see a substantial speed up by switching to an arena/region or pool. Can you explain what these things are?
Thanks for the reply. You're probably right that there's a faster way to do it but the nature of the problem I'm solving requires me to search and analyze the entire dataset billions of times.
Thanks for your insightful reply. &gt; Another thing to consider is that when you do many small malloc calls in separate threads, the memory will be fragmented between the threads. When two threads access memory that is in close adjacency (happens to be on the same cache-line) that's somewhat like having a lock on that piece of memory; when each cores pulls that piece of memory into a cache-line, and then they both want to manipulate some byte on that cache line, even though there is no collision, the cores need to synchronize about who goes first. So in general it is greatly preferrably if each thread gets its own big chunk of memory to work on, so that most of the time the threads work on memory regions far apart. How can I make sure that my threads aren't accessing memory on the same cache-line?
Thanks. I'll definitely spend some time trying to learn how this process works. The entire build process is still a mystery to me. Is there a standard text on how this works similar to how K&amp;R is the standard text for C? 
Here's the thing. I've read that people use GTK and QT as their graphic libraries. The Stanford Portable Library seem unknown. I wanna make some C Gui apps on the raspberry pi, but i'm stuck at using G++ and something that requires xinit.
Wow! Thanks for this in-depth post! Very helpful!
&gt; Yes, I allocate about 1-2 KB of data at a time and then perform analysis on that data. That technically does not answer my question. To take it a step further, how long do those 2KB chunks live? Do you throw the chunk away and then `malloc` the next one? Or do they both exist at that point? When does the first one get thrown away? When does the last one get thrown away? Those are the kinds of questions you need to answer to know what kind of memory structure you can use to speed things up. For example, if the pattern is `malloc` 2KB, process it, and then `free` it, you're looking at a possible pool pattern. You can just `malloc` one large zone and reuse a section of it for each chunk without calling `free` in between. https://en.wikipedia.org/wiki/Memory_pool For another example, if the pattern is `malloc` many chunks, do lots of processing, and then `free` those chunks all at once, you're looking at an opportunity to use a region or arena. Or it may just even be a stack. https://en.wikipedia.org/wiki/Region-based_memory_management If you `malloc` a mysterious number of chunks before calling `free` on those chunks in some random order (not freeing the first ones or the last ones), then things get tough. Sometimes a pool can address that (if the chunks are fixed size); sometimes it cannot.
I'm reading "Learn C the Hard Way" by Zed Shaw and he comes right out and says that unless you're doing something niche where C's strong points are still valuable (e.g. embedded systems), you probably shouldn't be starting a new project in C. He says the design choices for C made sense in the 70s, but that it is difficult to write robust, secure code in C for the modern age.
&gt; as you usually only want it to terminate once the main window is closed. But this is something the program takes responsibility for, not the Windows API. You can absolutely close a Windows program by returning from the main function whether or not a window is open - the window will simply be destroyed when the program's memory is deallocated.
&gt; I can't post it here for obvious reasons. Why can't you post your code here?
&gt; Declare variables at the beginning of a function definition. &gt; Always declare variables in the closest scope possible. Does not compute. I also think it's time we moved on from -ansi. It's a couple years older than I am, and there's been quite a few useful improvements since then (e.g. _Static_assert and stdint.h). Otherwise I mostly agree with a lot of what you said.
Not necessarily, in OP's code it could have opened with: int n = something; int (*p)[n]; in which case `sizeof *p` is technically undefined behaviour, although in practice people generally ignore that and pretend it's well-defined.
&gt; If pointers are supposed to help speed things up That is not their purpose.
neat
Yes. Should I delete very descriptive comments when I'm done? Seems like they'd help me a lot but would it look weird? I feel weird with comments because everyone's saying to not overuse them but I feel like the minute I start writing a comment I have to write paragraphs in it so I avoid using them altogether. Also one thing that I'm very guilty of... I declare a lot of global variables to use them in functions, and change them more easily... Is it better to use pointers on local variables to do the job ? I feel like it's easier to just use globals but sometimes it looks half-assed. 
You're thinking of passing large structures. It is quicker and easier to pass a pointer instead of copying lots of data. But that's just one of the many uses of pointers.
I think the definition that you've heard is not actually correct. In the same way that it is faster for you to say "thinkvitamin" rather than "the reddit user who created their account on this date with this information with this password" and so on, but it's not faster for you to say "the integer that is 5 steps forward on the number line from 0" than to simply say "5". Both of them ("thinkvitamin" and "five steps forward") are pointers (of sorts...) and you can see how in one case it reduces the amount of data and in the other it simply increases the indirection, or the steps that have to be taken in order to get to the information that you want. In short, a pointer *can* make things faster, provided you are passing around a pointer to an element that is larger than the word or register size of the architecture you are working on (This is the 32/64-bit you may have seen on your machine). This is also an overgeneralization; in some cases it's faster to pass around a structure that is larger than a register size for other, more technical reason, but in general this statement holds true for machines and so not all data can be 'pointed to'
As others said, the expression inside `sizeof` is not evaluated (except for VLAs). So, if you do `int i = 0; printf("%zu\n", sizeof ++i);`, the value of `i` after this would be 0, not 1.
In the old days highly abbreviated names for functions and variables was the norm. It was faster to type a short name and easier to spot typos when you're only looking at a few letters, but it was terrible for readability. It made it a lot harder to understand the programmer's intent. Today we use modern code editors that autocomplete long names and get the spelling perfect every time, so long names are easy now. As a result code fashion has shifted to longer, more self documenting names. So which should you do? As a programmer you'll usually match the fashion set by your boss, agreed upon by the group, or in this case, ask your teacher. He's the one marking it. 
Do you think it is faster to mail someone an url, or a 4megabyte image, when all the recipient wants to do if forward it to someone else ? And what when you want to send a full 4.7gb movie ? Or When you need to send the name of your Twitter handle ? If an url contains the address of some content, then how is that faster than sending the content itself ?
[memory pool](https://en.wikipedia.org/wiki/Memory_pool), [thread local storage](https://en.wikipedia.org/wiki/Thread-local_storage), Atomic operations are in c11.
Thanks.
Sure, but I wasn't sure about how this is handled in Windows GUI programs, especially if they start with `WinMain` instead of `main`.
it doesn't speed things up when you have one variable and one pointer, it speeds things up when you are messing with big structures and you are just tossing their addresses around instead of all the data they contain. Also note that pointers can make a program more complicated, so unless the speed is **greatly** improved, you shouldn't use more pointers than needed. 
Actually for C++ a lot of the names are first-second (especially in newer versions) and for Java they have alwas been firstSecond (not FirstSecond). The major point in this is: **use the code conventions that are used by your team!** Also a good reference are code conventions like those of google and other large companies. You can also look inside standard libraries to see the code conventions and how that code is written. 
&gt; it is best to just declare the variables where you gonna use them, instead of the beginning of the scope (prefferably in the closest scope possible). Could you talk about some reasons why you feel that's the way to go? I've always kept all the variable declarations in a single group at the top of each function thinking the self documenting nature of that style was way to go. At a glance I know the full extent of all local variables I'll encounter in the function, and later if I see a variable I'm not sure about I don't have to scroll around looking for it's declaration, I know right where to look.
&gt; Java basically also uses pointers everywhere and we all know how slow Java is. *crosses fingers for value types to make it into Java 9*
Good question. I struggled with this kind of thing for ages when I first started learning C. You're right to imply that pointers don't speed things up when dealing with 'regular' variables. If you are dealing with regular variables then you might want to use pointers to take advantage of their reference (as opposed to copy, or value) semantics as a functional rather than performance gain. For example they let you change a parameter passed into a function, within that function. In terms of performance though, passing or copying pointers to data rather than passing or copying the data itself, makes a useful contribution only when the data occupies a large amount of memory (slightly dodgy rule of thumb would be 'more that several machine words worth'). Have a look at http://mikehigginbottom.com/wordpress/why-should-i-not-use-pointers/ for a bit more info.
Thanks for the advice.
How about this: http://ideone.com/zJk9Ih Atleast I'm getting an output now! 
&gt; Also I thought that the expression *top referred to the value at the address contained in the variable top. You haven't actually created an int called top, you've created a pointer-to-an-int called top. You're declaring top on the stack, so just declare it as an int. Then, when you're passing it to a function that takes a pointer to an int, pass &amp;top, which is the memory address where top's value lives.
`*top` is OK inside `pop` and `push`, but not when calling them, because what you want to give to those functions is the address where you want them to change values, not the values themselves.
This is better, but don't initialize `top` to -1, since `push` first stores into that index, and then increases the index, so the first value is stored in the index -1, not 0.
Write your calls to those functions such that as soon as they return, there's no more instructions in your main menu to run. Take always into account that functions are meant to return to where they were called from, and only in very specific situations they won't return (when you call `exit` inside them, for example).
Have you checked the processor utilization while running this?
Uh? #include &lt;unistd.h&gt; unsigned int sleep(unsigned int seconds); Or, if you *really* want to busy wait (for whatever reason you may need): for(wait = time(); time() &lt; wait + wait_seconds; ;) ; 
&gt; Write your calls to those functions such that as soon as they return, there's no more instructions in your main menu to run. I'm sorry, didn't understood, can you elaborate a little more?
The thing is, `Login` will always return to the main menu, to the next line it was called from, but maybe you want that, after a login, nothing else is done in the main menu. For that, you can, for example, write a `return` after `Login()` inside the main menu, so that the main menu ends after the login is done (I'm assuming inside the login you have all the operations that involve the user, so that when you exit the `Login()` function you want to exit the program altogether, but without a specific program it's difficult to give more detailed answers).
Thank you very much. It worked!
I think one of the main domains where concurrency is useful in C, is where you have multiple blocking read loops operating simultaneously. Take a TCP server, for instance. With HTTP servers, where it isn't usually necessary for a client to influence the state of a server with what they send, there's no need for IPC so it can usually be implemented with a simple call to fork. But with something like an IRC server, where the server needs to continuously relay messages between clients, this approach doesn't work too well and a solid form of IPC is needed, unless polling/non-blocking calls are utilised. I suppose my main interest in coroutines and channels is in how well they handle this last case, but the issue is there aren't many coroutine libraries for C (or at least none that have really caught on), so I tend to use polling/non-blocking I/O, similar to Node.js. (Which has some obvious issues -- one blocked call or busy loop stalls the whole thing.) My question is whether the library supports this particular case and, if not, is there any interest in supporting it?
You can use the lengths of the headers as the minimum field widths, for their corresponding values, int main(void) { char *hdr[] = { "Integers", "Squares", " Cubed", "Square Roots" }; int i; printf("%s %s %s %s\n", hdr[0], hdr[1], hdr[2], hdr[3]); for (i = 0; i &lt;= 50; i++) printf("%*d %*d %*.0f %*.2f\n", (int) strlen(hdr[0]), i, (int) strlen(hdr[1]), squared(i), (int) strlen(hdr[2]), pow(i, 3), (int) strlen(hdr[3]), sqrt(i)); } edit: Using a global field width, is one other option, printf("%12s %12s ...", "Integers", "Squares", ...); ... printf("%12d %12d %12.0f ...", i, squared(i), pow(i, 3), ...); I guess just experiment with field widths. Once you understand how to use them, your creativity's the limit. :-p
&gt;Any coding standard which insists on syntactic clarity at the expense of algorithmic clarity should be rewritten. This is a brilliant hack that I would *never* use in production code, but I'm going to make this quote into a poster.
This is the correct answer, along with changing the number before the control string specifiers to give some space (but it looks like that has already been done in the OP).
I don't really understand what you're asking. You don't need to do any string formatting to output a newline to stdout: `putchar('\n');` If the issue is that you don't want two statements each time you print something, then put them in a wrapper function.
It's the lack of caffeine. I'm such an idiot I should delete this post, but I'll leave it up to demonstrate, well, what an idiot I am in case I ever decide to pursue politics. 
If I increased the index first, would top = -1 work? Which is better? Or is it just a choice left up to me? Then I will set top=0 and continue. http://ideone.com/xhau2t
Post your code, we have no idea what the issue is without seeing what is going on...
It's pretty standard.. My problem is the output in terminal is blank. ␣␣␣␣#include &lt;stdio.h&gt; ␣␣␣␣int main() ␣␣␣␣{ ␣␣␣␣␣␣␣␣printf("Hello, world!\n"); ␣␣␣␣}