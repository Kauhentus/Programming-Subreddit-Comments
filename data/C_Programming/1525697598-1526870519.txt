An elegant weapon from a more civilized age.
You can ignore the C++ STL and you won't have to deal with exceptions :o
Yeah, I can ignore exceptions if I am willing to not use 95% of all libraries. Once exceptions are in the language and acceptable to use, they are everywhere. That's why it's important to either not provide exceptions or make absolutely clear that they are not supposed to be used for error handling (see e.g. Go).
Java sometimes uses exceptions as a "secondary return". But C++ uses them as real errors. e.g. trying to access an invalid index in a vector with vector::at. Of course, you also have the operator[] to access an index without check. What I want to say is that exceptions exist to help. And if you don't want to use them, you may just ignore the classes/methods that throw. Anyway, sometimes I prefer a helpful exception instead of a crash.
Disclaimer: I'm a hobbyist, not a professional. C is familiar and comfortable. Most languages have hooks for it, so something I'm writing in C can be used elsewhere with (usually) minor changes. It's close to the hardware. The core language is small and easy to learn (not easy to master, tho :-)
* Minimal size of library. * Fantastic tooling. Debuggers and static analysis tools IMO are much harder to use on a C++ program than a C program. * Explicit error handling. * Portability. Try compiling C++11 on obscure architectures... * Speed of compilation. * Speed of execution. That being said, I find C too "old school" and lacking certain basic features. I hope Zig gets more stable soon so I can try that out (see /r/zig).
Link work?
Not for me
First problem: putchar(counter); You probably meant to use `printf` here. &gt; And the program prints out the input first before the line numbering. You need to print the line number after printing the character, and you'll need to do the first line number explicitly.
no I am not allowed to use printf for this exercise what do you mean by "explicitly?" sorry English is not my first language
Well, if, for example, a file is not present and you try to &lt;open it&gt;, the program logic is wrong and an exception is thrown. If you try to convert an invalid string to a number with stoi, you'll get an exception. If you do the same with atoi, you'll have an UB, and a 0 value with strtol. What do you prefer? C++ exceptions, unlike Java ones, are really exceptional cases. Of course, you must check everything if you want your program to run correctly (same in C). After years and years programming C++, I have only seen exceptions when the program crashes because of them (always serious problems, like indexes out of range). Well, use whatever language you want, but remember that if you find an exception in C++, it's because your code is wrong, not a C++ problem.
&gt; no I am not allowed to use printf for this exercise Ah, I missed that. In that case, you'll need to be a bit fancier and convert the number to the characters manually like `printf` does. &gt; what do you mean by "explicitly?" sorry English is not my first language No problem. Here's what I mean (using `printf` because I can): printf("1"); while((c=getchar())!=EOF){ putchar(c); if ( c == '\n' ) { printf("%d", counter); ++counter; } }
thanks for your answer is there a way to solve it without printf? and the output is not exactly right it should be something like this for example if i type in "program" this is how the output should look like 01 program and so on...
&gt; is there a way to solve it without printf? Yes. /u/boredcircuits already told you what you need to do: you need to manually convert the line number to text, digit by digit.
&gt; is there a way to solve it without printf? Sure. But I don't think I should spoil the solution, that's half the point of this exercise, I think. You'll need to decompose a number into the individual digits (`/` and `%` are helpful here) and convert each digit to the correct character (knowledge of ASCII math is helpful), which you can then print using `putchar`. Once you do that, getting the output exactly how you want it isn't difficult.
Close. There's a big difference between the number `0` and the character `'0'`. So for the first line you could do: putchar('0'); putchar('1'); And that would print 01 before the first line. Of course, it's going to look different for all the other lines, since the value you need to print is in a variable, not a constant "01".
Thanks for the reply First time I am hearing something like ASCII math our university never teaches us the necessary things so i printf we use %d,number so for putchar should I use putchar('%') putchar('d') 
I've always been a real nuts-and-bolts type character, obsessed with the nitty-gritty, so I'm drawn to projects that are more technically complex and algorithmic in nature, and not so much focused on UX or end-user aesthetics and convenience, or working with so-called 'frameworks' via some kind of simple scripted control. Incidentally I recently finally decided to start fiddling around with existing game engines just to see if there's anything there I'd be interested in leveraging for gamedev purposes. That's something I thought I'd never do considering that I have an aversion to 3rd party code. It's been fun. I write programs specifically to implement algorithms which require high performance execution to be useful. Typically they require the processing of lots of data, sometimes in the form of CAD/CAM utilities, sometimes in the form of custom game engines, sometimes for freelance projects or some other experimental stuff. I usually develop experiments that require low-level OS interaction or involve some kind of reverse engineering aspect. In all cases, using some kind of managed language or higher level language (than C) is counterproductive or a hindrance to the goals of these projects. I've never really been big on webstack dev, or scripting stuff for other peoples' low-level code to run. At that point it's not really a matter of preference that I use C, it's a fact of life for the work I choose to do. 
They've brought the obfuscation to a whole new level.
My Education 
"switched from OpenGL2 to SDL2 + simplified resource loading using SDL… " facepalm, SDL is ancient, barely maintained and generally a pita, there's tonnes of stuff like this https://github.com/nothings/stb kicking about to do simple resource loading....
Thanks for your comment. The person you're replying to obviously has made some erroneous assertions and it takes some courage to counter the top comment on the thread, especially when you get brigaded with downvotes thereafter.
If a file is not present and I try to open it, the program logic is not wrong---either the wrong file name was passed in (perhaps on the command line which makes it operator error) or it was deleted (again, perhaps an operator error) or it could be a "don't care" option (state from a previous run and this is the first run). It doesn't imply a bug in the program. The `stoi()/atoi()/strtol()` example is one were I can see why someone would use exceptions, but in my not so humble opinion, that's an abuse of the definition of an exception. To me, an exception indicates an actual *bug* in the program (seg fault, division by 0), not an error in external data being read in. 
No problem. I think I need to take a moment to explain numbers vs. characters and ASCII. To a computer, everything is a number. 42 is an obvious example, of course, but characters are numbers as well. You might have seen [this table](http://www.asciitable.com/) which shows the number behind each character. That's the ASCII table -- there are other encodings, but that's the one your computer is using in your program. The character `'A'` has the value 65, `'!'` is 33, and so on. We might expect that `'1'` is 1, but that's not the case. Instead, it's 49. If you were to run this code: putchar(48); putchar(49); That will print out "01" like we discussed previously. The question then is, if I have the number 5, how do I convert that to its equivalent character? By simple addition! If you notice, adding 48 to any digit will convert it to the correct character. We can express that concept in code like this: int c = 5; putchar(c + '0'); `'0'` is 48, as I mentioned previously. (Actually, in C a character literal is actually an `int` literal, so this isn't a trick. It really is just the number 48 written in a different form.) That addition produces the number 53, or the character `'5'`. But notice this only works for individual digits. Trying to convert the number 42 like this fails. `42 + '0'` is 90, or the character '`Z'`. So this is only part of the solution. The rest is what I mentioned before, using `/` and `%` to extract the individual digits from a number (which you can then convert and print like I've shown here).
good idea :)
would looping it a million times suffice?
You should check first if the file exists. And yeah, an exception in stoi may not be the best solution, but returning 0 is worse. It's just an example (the best solution is the TryParse way C# uses, in my opinion)
Back up now, slow like loading. But found the URL! http://www.ioccc.org/2018/2018.tar.bz2
If a race condition occurs, we can consider it an "exceptional case", one process deleting a file and another trying to read it. Anyway, it's just an example. In C++, an exception is thrown while opening a file &lt;only if you want an exception to be thrown&gt;. You can define it's behaviour, and you can check if it failed and why it failed later.
ok.
Thanks for your reply I am not allowed to use functions 
only allowed to use std library 
Well, `execve()` might not be in *the* standard library, but it's definitely in *a* standard library (POSIX) :-)
Not related to.this but im also a beginner c programmer(student). Do you mind if I also worked on these exercises whenever you finish em and post my own code here to compare?
To sum it up as much as I can, I would say just because it gets sh*t done the way you think about it. You don't have to "worry" about Classes, or some other functionality that would be imposed by another language. Since it is "low level", and thanks to it's syntax and overall feeling, it is very close to the human "natural" way of thought. You can read C almost as normal text if the code is clean enough &amp; presented the right way. Maybe it's not a technical enough of an answer, but the main feeling I have with this language is that it is very intuitive and natural. 
First off, `open()` will check if the file exists and return an error if it doesn't. But okay, I'll play along---I'll call `access()` first to see if it exists and I have the required permissions. There *still* exists the chance that the file permissions can change between `access()` and `open()` (or it could be deleted). It's a race condition, and race conditions are *bad*. `stoi()` seems to be a C++ function, so I can't say anything about how good or bad that is. The C function `strtol()` *does* report back an error. So I think we'll have to agree to disagree on the applicability of exceptions. 
Its sheer minimalistic beauty.
That's good, humor is the best way to react.
Clarity. Simplification. Mostly, I mix my C with C++ by using classes as containers (strictly) for data, but still writing the bulk of my program in C. The blend works well, I don't get overtly bogged down by the OOP mess.
&gt;SDL2 Which is not ancient. Please educate yourself before making statments like that, thanks.
&gt; I am not allowed to use functions This doesn't invalidate the answer of /u/sp1jk3z . A function would be just a nice way to pack the "complicated" stuff in one place so it doesn't get in your way. You can still adapt the pseudo-code to run in main.
Duh, not far from the monsters that you can see at banks/corporations
Language proficiency, I'd argue, includes knowing how to properly utilize their standard library.
I'm not really even a programmer i just do some scripting for networking stuff which i usually use ruby for. Learning C however was the first time i really felt like i understood programming. I can't really explain why, I always thought I'd prefer the easier/lazier languages but something about C just made sense to me. I like to think if I ever entered a programming heavy job or hobby I'd use C and do some systems level stuff but for now I'll keep messing around with it when I have the time.
Because it's awesome. Don't need more reason than that.
Hey, megayippie, just a quick heads-up: **alot** is actually spelled **a lot**. You can remember it by **it is one lot, 'a lot'**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
update: ran it on windows a couple of times with about 10,000 loops. probably no significant time difference. it might still be there but i'm not gonna bother with chi\^2 test since plugging the memory leak seems more important. turns out looping it a lot makes memory leaks really obvious :\)
This might be helpful: https://wiki.musl-libc.org/libc-test.html
Maybe a silly question, I was looking for the libc implementation of malloc the other day for ubuntu and couldn't find it. Any idea where to look?
Fair enough, but I don't need to be proficient, just capable - I can read through an API and make use of it, but if I don't know what sorting algorithm to use I'm still screwed.
I'd have no problem with that and you can even PM me as well. I have the rest of my code here: https://github.com/borntuft/K-and-R-The-C-Programming-Language
PDClib, and libc11 are both libc's that I've contributed to, pdclib is not updated hardly at all unfortunately, and libc11 has been dead for almost a year at this point; there's a bunch of pending patches that the author hasn't merged, who knows when they'll be merged.
Just wanted to say that I like this answer.
This is absurdly wrong. We’ve been doing segments since the 1960s and by the 1980s fragmentation drove every major implementation to segments over pages over a flat memory array. Only thousands of concurrent segments and segments of only 4GiB were both major limitations by that time as well. They don’t scale in any dimension. As for sequential languages, FORTRAN, PL/I, COBOL, Pascal, C, APL and many others have run fine on flat/paged and segmented machines as well as byte addressable and word oriented machines, making the original article’s noise about sequential code being only a C thing nonsense and the BCPL commentary of being only word oriented self contradictory. There have been plenty of custom parallel processing systems without shared memory on the order of tens of thousands of processors coded in C as well and that perform far better than off the shelf large general purpose systems. Those custom systems would be completely useless on a wide range of general purpose problems which is why the general purpose computing world has worked to make sequential processing as fast as possible. Even in the 1960s memory bandwidth was an issue which is why some systems could read 32 words each memory cycle. Caching is great for small data sets or computation with great locality of reference but for big random data it’s always going to be memory bandwidth that rules the day. **tl;dr:** the low fuit was picked decades ago so stop pretending there is a magic bullet at no cost to make everything infinitely parallel.
See Itanium. See i860 which required explicit pipelining. See the iAPX432 which operated only on typed objects. And those are just some of the bold attempts by Intel.
&gt; You should check first if the file exists. Way to go with race-conditions. Or do you want me to check this before *and* catch the exception? I think this is redundant.
Your not calculating your random index correctly. Try: randv = C + rand() % (size - C);
Wow, it works beautifully! It's crazy how such a simple change was all it needed. Thanks a million!
Before you wrote that I should check it, now that the class does it. So what should *I* do? Check it or not and how does this make the class understand whether I want an exception to be thrown or not? I honestly don't understand what you want to tell me.
I am not sure how you will let people not see your source code since they would need it to use your library. But using static before a function makes it only accesible in that file. So make every function that only can be used in that file static and put the others in a header file.
For Windows, shipping a compiled .dll with a .h header file or .tlb type library is likely what you want. On linux a shared library with a header file will do the same trick.
Yeah should be possible, i am not that familiair with it as i never have done that. But it seems /u/vedicvoyager is familiair with it. Good luck!
Thanks!
Okay, sounds good. On Windows, dynamic linking is somehow essential to hiding my code's innards?
The Open Group has a compliance test suite which, if I recall directly, tests compliance with POSIX, not the C standard.
I’ve read it a few times. It hints at a magical unicorn language which requires no branching, memory references or interprocessor synchronization and is childlishly dillusional in thinking that the pre or post increment syntax is unique to the PDP-11 and can only be executed efficiently on that architecture or that the ability to perform more than one operation per clock is somehow evil (see the CDC 6600 from the early 1960s, well before C, which has no read or write instructions, no flags, no interrupts, no addressing of any object less than 60-bits on the CPU and still performed instruction level parallelism with its assembler COMPASS as well as assortment of higher level languages.) It talks of the wonders of the T series UltraSPARCs while ignoring the fact that Solaris and many of its applications are written in C. It blindly assumes locality in all applications and therefore assumes whole objects are always sitting in cache to be manipulated as a single entity. Ask Intel how the iAPX432 worked out... Show me the magic language which completely rewrites its data structures repeatedly in different orders with different alignment and packing at runtime for improved processing with zero compiler or runtime overhead, the lack of which is listed as a flaw unique to C. He doesn't grasp the features of the language which actually further *decouple* it from the instruction set architecture which is not the case for many other existing languages which have been successfully adapted to processing advancements for many decades. Indeed, if he had ever written Pascal or Modula2 or Ada or FORTRAN or BASIC or any of many other languages on a 16-bit processor and wanted to store the number 65536 as an integer he’d realize C is a higher level language than all the rest. This isn’t a 2018 or even 1980s issue. He also doesn’t seem to understand the economics of rewriting the volume of code which is driving software spending in the many hundreds of billions of dollars a year range. Having Intel drop a few billion to sell hardware that underpins trillions of dollars of existing software that simply won’t be rewritten seems blatantly obvious. Overall it’s a lot of whining that making general purpose systems exponentially faster for many decades is getting more and more difficult. Yes, it is. I don’t need (and in most cases don’t want) many HD videos tiled on many 3D objects on my cell phone just to read a web page with an article with less than 1K of text. The big issues of waste are far broader and more expensive than Intel and a few others making fast yet complex chips. 
No, the .dll format is just a library file format that applications can hook into using defined include statements. The library export definitions limit exposure to the functions you want accessible. More info here on how to define exports in a library for Windows: https://msdn.microsoft.com/en-us/library/z4zxe9k8.aspx
Controlling visibility ( aka without exposing the internals ) can be achieved either with proper use of the static keyword qualifying global functions or with compilers specific extensions which instruct the linker on what to do. I think that [this is a good place to start](https://stackoverflow.com/questions/756174/how-to-export-symbols-from-a-shared-library)
On the topic of complexity, the article cited by the OP talks of LLVM being 2 million lines of code, yet [this article](https://www.wired.com/2015/09/google-2-billion-lines-codeand-one-place/) indicates Google’s 25,000 engineers are making 15 million lines of changes a week or more than 2 million every day including weekends. That’s just one company.
Okay, thanks everyone, I think that's enough to get me started.
In general should use libtool (usually in conjunction with autoconf and automake) on Unix, since building and installing shared libraries manually (via handwritten Makefiles) is hard to get right portably. It should also work on Windows, least when using msys/mingw. Here is a good explanation for doing this with libtool; you can simply specify a prefix for your exposed functions: https://autotools.io/libtool/symbols.html
I do think it's worthwhile, yes. The reasoning is as follows: 1. It's important to know how an operating system works, in broad strokes. The reason is that the code you write will typically be interacting with an operating system (some embedded systems are exempt from this). At some point in your career, your code will not be performing the way you expect to, and understanding how an operating system works (how the filesystem works, how the filesystem cache works, what a system call is, what a context switch is, what the cost of a context switch is, what a process state is, what virtual memory is, what a page is, what a page fault is, etc.) will help you tremendously in troubleshooting that. 1. "Those who do not understand Unix are condemned to reinvent it, poorly" has a lot of truth to it. Unix is the best-designed operating system that is in wide, mainstream, general-purpose use. You don't need to understand how a specific operating system is implemented at the nuts-and-bolts level (is fork() implemented as a system call, or is it a function call?), but if you understand how the major POSIX system/function calls fit together (process management, file descriptors, etc.), you will have a good understanding of how your process is being treated even by non-Unix operating systems. 1. When using a library, you should have a mental model of what it's doing to the machine. What does `new Thread()` actually do? Knowing how that snippet of code fits into a real machine will help you develop what some call "mechanical sympathy". Programmers who have "mechanical sympathy" (an appreciation for how the code they write will affect the actual physical machine) will make you write better code adn will make you more valuable in your career.
Besides what has already been pointed out, it also seems you are not setting the rand seed. If Im correct the deck will always be shuffled the same way.
very nice!
Kids these days.
Yeah, that does sound good. I dimly recall using makefiles in the 90s, but I'm sorry to say that for this project it' been more like "gcc \*.c". I'm going to need to get a bit more sophisticated...
It was just an example. The whole point is that you won't have to handle C++ exceptions if you don't want to.
You can, but the steps to compile and package the library depend on the platform and whether you want to link it dynamically or statically. To create a statically linked library on Linux, you usually just pack the object files in an ar archive
GCC and Clang both support C99 fully, no need to redefine restrict for them. The alternative versions like __restrict__ is for use when mode is lower than C99.
Next time i'll post it somewhere else.
A windows .dll and Linux .so are the same thing conceptually, just different formats to fit with their parent OS. We do this quite a bit at work - /u/NamespaceInvader's post about using autotools/libtool is a good one, it significantly simplifies the process.
wow is it really that easy? or am I just not suited for programing? I have been trying since sunday I just cant solve this problem. 
Yup. No one here will give you your free homework but if you start lots will help.
Check out the source for it on GNU coreutils.
wait forget my quote I am almost there!!!
Several independent implementations: * [OpenBSD](https://github.com/openbsd/src/tree/master/bin/ls) * [Busybox](https://git.busybox.net/busybox/tree/coreutils/ls.c?h=1_28_3&amp;id=2c5ceb6065b94f3b6ad886a212fcae0c8fdfa5f8) * [GNU Coreutils](http://git.savannah.gnu.org/gitweb/?p=coreutils.git;a=blob;f=src/ls.c;h=4becd06e7f7ed805eb9dd0f2047c41c3926b4150;hb=27b2b19aa8d8b30b8cb4198b2f4b54568e10a35e) Key functions are [stat(2)](http://pubs.opengroup.org/onlinepubs/009695399/functions/fstat.html), [opendir(3)](http://pubs.opengroup.org/onlinepubs/009604599/functions/opendir.html), and [readdir(3)](http://pubs.opengroup.org/onlinepubs/009604599/functions/readdir.html).
I am using [Gtest](https://stackoverflow.com/questions/5335268/is-google-test-ok-for-testing-c-code) for years now in my C and C++ code base. We've been also experimenting with [CppuTest](http://cpputest.github.io/). For mocking, we started evaluating [Isolator++](https://www.typemock.com/isolatorpp-product-page/) to ease our legacy code testing hell. You can also try [Gmock](https://stackoverflow.com/questions/31989040/can-gmock-be-used-for-stubbing-c-functions).
Thank you! That’s super helpful! This is close to what I’m looking for. I’ll use this as a basis and edit the code down to the level I need
You should try compiling your examples before posting them – that compound statement syntax is wrong (remove the second parentheses!). Anyway, no, the C standard does not specify where in memory that array will end up in, or even if it should be stored at all if e.g. the compiler detects that you never access it. In practice, it'll end up in static memory just like *myVar*. This means it will actually "leak" if you set *array* to something else, but since it's only 20 bytes it's not like it matters a whole lot.
Sorry, I wrote this quickly as a simplified version of my current situation. Thank you for your answer!
You’ll never get everything right for every compiler out there. If you have masochist tendencies you can try to figure out how a major build system like `GNU autoconf` tries to figure it out. But be warned, autoconf is ugly and *very* hard to understand. I’d just test for MSVC and otherwise assume a C99 compatible compiler. You can still improve this when some user files a bug report. Or write a small test program that uses the `restrict` keyword. If it fails to compile define `restrict` to the empty string.
Yeah, I knew that they could be OR'd together, but my main concern was, for example, a system which defines ERROR as 10000000, WARN as 01000000 making me think that loglevel &gt; WARN is safe (for example), but then another system does error on 00000001 and WARN on 00000010. Both can be OR'd together, however there's not a guaranteed ordering between the two. I'm *pretty* sure I'm safe in assuming that a system will follow the RFC, but I've added a tiny bit of indirection anyway to be safe, my own values, which *are* guaranteed to behave how I want, which map directly to the syslog ones :)
The standard approach is to provide a *map file* that describes what symbols are to be exported and give it to the linker to configure symbol versions. You can also use compiler dependent attributes to specify visibility, but this approach is less portable.
Yup. Everytime I start the program, it'll shuffle the same way. However, if I shuffle twice while the program is running, the result will be different to what I'd get if I had only shuffled once. I've got it fixed.
Neither C++ nor C# are on topic in this subreddit. Please post elsewhere, e.g. in /r/cpp_questions.
[cmake](https://cmake.org/cmake/help/latest/module/WriteCompilerDetectionHeader.html) and [autoconf](https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.69/html_node/C-Compiler.html#index-AC_005fC_005fRESTRICT-900) both have a way to find out what the compiler accepts as a restrict like keyword. Plus gcc understands `__restrict` too iirc.
As i already said, next time i'll post somewhere else. But you dont have to read the commands, do you?
Damn, already confessed to my teacher. :\(. He looked pained when I did it, as if he wished I didn't mention it. He said he would need to talk to Conrad about whether it is cheating or not.
To understand why this matters it's helpful to do the proof that elements actually are uniformly randomly distributed, that the element from any given starting location can end up in every location with equal probability.
Sorry to necro but do you have some links i could further research web apps in c?
&gt; But you dont have to read the commands, do you? Not sure what you mean with that.
Valgrind only works on linux, no? I’m currently a Windows user with Visual Studio. I rarely use linux, just for school :/
Get Ubuntu on windows. You can compile it through that and run valgrind on it. 
Because I wasn't sure if you could define a macro as a keyword (not that i think it's *actually* a keyword on the 3 compilers listed in the op) and had just woken up. It didn't occur to me that I could just try to redefine static or const or something... since I know you can for example `#define whilst while`, maybe the reverse is true.
Those look exactly like what I need but I've got no clue how to use them. It's been years since I tried to install another compiler, perhaps it's time to try again.
Holy shit, that takes 615 lines!
You should probably look at this page how to check for build environments and compilers: https://sourceforge.net/p/predef/wiki/Home/ For you problem the easiest solution would be to assume the compiler supports restrict, and add extra defines for visual studio. #ifdef _MSC_VER 
&gt; This is absurdly wrong. It isn't... I don't think you understood what I was saying. &gt; We’ve been doing segments since the 1960s and by the 1980s fragmentation drove every major implementation to segments over pages over a flat memory array. Only thousands of concurrent segments and segments of only 4GiB were both major limitations by that time as well. They don’t scale in any dimension. Yes, I'm aware of that. This is a flaw that was brought about by popular OS and language paradigms. Segmentation could have easily scaled. In fact, Intel tried to make it happen with the [iAPX 432](https://en.wikipedia.org/wiki/Intel_iAPX_432) processor. You would have known this had you read the links I posted, but you evidently did not. &gt; As for sequential languages, FORTRAN, PL/I, COBOL, Pascal, C, APL and many others have run fine on flat/paged and segmented machines as well as byte addressable and word oriented machines, making the original article’s noise about sequential code being only a C thing nonsense and the BCPL commentary of being only word oriented self contradictory. He's not saying that C doesn't *run fine*; he's saying that it's not *low-level*. Just like APL, Pascal, etc. are not considered low-level. BASIC is a sequential language, but not considered low-level. Same thing with Ruby, which can hardly be called low-level or non-sequential. &gt; There have been plenty of custom parallel processing systems without shared memory on the order of tens of thousands of processors coded in C as well and that perform far better than off the shelf large general purpose systems. Those custom systems would be completely useless on a wide range of general purpose problems which is why the general purpose computing world has worked to make sequential processing as fast as possible. Even in the 1960s memory bandwidth was an issue which is why some systems could read 32 words each memory cycle. Caching is great for small data sets or computation with great locality of reference but for big random data it’s always going to be memory bandwidth that rules the day. I don't really get how this is relevant to what I said. &gt; *tl;dr:* the low fuit was picked decades ago so stop pretending there is a magic bullet at no cost to make everything infinitely parallel. I'm not talking about parallelism as much as I am about segmented memory vs. flat memory. Either way, I never said that any of this is a magic bullet, just that things would be greatly improved had this low-hanging fruit been embraced, rather than rejected by essentially what was popular vote in the OS / language scene.
**Intel iAPX 432** The iAPX 432 (Intel Advanced Performance Architecture) was a computer architecture introduced in 1981. It was Intel's first 32-bit processor design. The main processor of the architecture, the general data processor, was implemented as a set of two separate integrated circuits, due to technical limitations at the time. The project started in 1975 as the 8800 (after the 8008 and the 8080) and was intended to be Intel's major design for the 1980s. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
They work by using the opendir Unix system call. Unix system calls are shared by Linux, BSD and MacOSX, however not by Windows and DOS. \- System call \- open dir [http://pubs.opengroup.org/onlinepubs/009695399/functions/opendir.html](http://pubs.opengroup.org/onlinepubs/009695399/functions/opendir.html) \- UNIX &amp; GNU/Linux \- System calls \- opendir\(\) \- [https://www.badprog.com/unix\-gnu\-linux\-system\-calls\-opendir](https://www.badprog.com/unix-gnu-linux-system-calls-opendir) You can see what those system calls does in Nix based system by just typing $ man opendir in the terminal.
How do you think `Gtest` measures up with `Cmocka`? cmocka.org
Any leak matters a whole lot.
Grab VMware player or Virtual Box. It's worth having a VM to run it on. 
My implementation (for FatFs, not POSIX) is about 140 and it's much more limited than the usual ls. A bunch of that is handling wildcards, which really ought to be handled by a library function.
Agree, instrumentation has performance impact. The user can instrument object files selectively instead of profiling whole library at once. I have never used system-tap, will give it a try.
Your code-base is definitely not simple. We're lazy. Add a Makefile. **But** this motivates me to write my own HTTP/S server in C. So thanks for the post! 
Thanks for the feedback and point taken! I'll push one (a makefile) in the next build.
Nice work. This was on my list of things to do this summer. 
LOLZ :)
&gt; Also, as a side question, where is the memory [that the pointer points] to allocated here? I think myVaris allocated on the stack here, but is the array of int allocated here too? Implementation dependent but generally NOT the heap nor stack if they are static locals or globals. Because they are mutable in most cases, they sit in the data segment. The literals however they may point to, may not, ie your example or a simpler example of a null terminated string constant. These are usually in the text segment. So if you initialise a pointer to such a string and try to write to it, you may get a seg fault. Also, if you only have one pointer to such a resource and lose it, yes, you’ve kinda lost that memory, but since it’s not a lot nor recurrent... I wouldn’t call it a leak per se. It may be the most sensible way to do something, for example a default structure. If you’re losing pointers to heap mem in a frequently called function THEN it’s a serious deal. Depends on your machine. https://manybutfinite.com/post/anatomy-of-a-program-in-memory/ 
I would do without it for now. It's easier to optimise on a case-by-case basis for a particular target at the time of compilation, than to optimise ahead of time while maintaining generalised source. `restrict` offers very little aside from the potential for code optimisation, what it does do is add complexity and restriction in use.
Hey Brandon, nice project, thanks for sharing. Could you maybe show us (me) what documentation or books you read in order to gather all the knowledge and information to be able to make such a project? I mean, before you make any project, you have to have some idea of how it works, whether it is an HTTP/S server or a chat app or whatever. So, what docs/books did you read? Thanks :) btw
I don't have any experience with `Cmocka` but from the looks of it, it's not being maintained, unlike it's "parent" project [Cmockery](https://github.com/google/cmockery). So I would suggest trying that before trying `Cmocka`. The main advantage of these Google open-source frameworks is that they're maintained by both Google and the community, so you can find answers to most questions if you have any.
Hm... You might also want to check out the various POSIX test suites. They do surely test the libc in a spectacular number of ways.
Please put four blanks in front of every line of code so your code appears readable.
I think you meant to say one tab. Tabs are specifically for indenting code/text.
I sorta did fix it. Internet is incredibly slow tight now, so bare with me 
Yes. This tells reddit that your code is code so reddit won't apply formatting to it.
Check out Beejs Guide to Network Programming. It's a good starting point. 
No, reddit needs four spaces, not tabs.
Thank you for your cooperation. Looks good now!
Well, I'm not sure what kind of help you are looking for. Despite asking for help multiple times in your post, there is no point where you actually ask even a single question. It's a bit hard to answer a question that hasn't been answered.
Well, I get errors saying undeclared variables. I'm not quite sure how to declare them. That's my main issue. 
It is surely a good idea to add the exact error messages you got as well as your actual questions to your post. Nobody wants to try and guess what you want.
I'll see if I can upload the error. Father is downloading so its a pain 
I have uploaded a link and some text explaining my problems
Why no "return 0"?
Nice work man! Are you interested in taking pull requests?
`off_t fsize(const char *filename) {` `int fileSize = fsize(fileName);` Good ol' C, it's crappy type system never disappoints. 
Absolutely!
Thank you!
I just wanted to do it really. I had other C server code laying around I had written, but nothing proper/simple. I'm not saying this project is proper yet though -- it still needs a lot of work.
Or you can follow this tutorial by thenewboston -C Programming Tutorials: http://www.youtube.com/playlist?list=PL6gx4Cwl9DGAKIXv8Yr6nhGJ9Vlcjyymq Alternatively you can practice some basic questions on this site https://www.w3resource.com/c-programming-exercises/
 ← This is a tab. Desktop Web Reddit renders this as code, but I've seen reddit clients that doesn't do that.
Simple example: you have a very large struct you want to pass to a function. If you pass by value the struct, you will end up making a full copy of it, which will be a small performance hit since you'll likely spill your register file. If you pass by reference, you only have to pass a pointer (size depends on system), and you are less likely to spill. Two more differences from this. When you pass by value, modifications to the struct made in the callee won't be visible to the caller unless you have something like my_str = my_fn(my_str); However, in pass by value, any modifications in the callee are observed in the caller as well
I don't see how it is not possible. After freeing your dynamically allocated memory you should be setting your pointer to NULL to prevent subsequent reuse. Any subsequent functions will check for NULL then respond appropriately. There's lots of applications wherre aborting is unacceptable. Therefore functions need a level of fault tolerance to continue from an undesired state. Also `const`ifying most of the code can be partially a style / standard. Even though it does not help in a lot of places it can be applied, it is extremely useful for developers to understand exactly what the code is doing. For you and your team it may be noise, but for me and my team it tells us exactly which variables are changing throughout the function. Which function arguments are inputs / outputs. It basically makes it easier to zone in on which variables are `non-const`.
Pointers are more efficient. You pass 32 or 64 bits rather than a copy of the struct. 
I replied to your other comment on this!
being able to free the struct
If you pass a struct as an argument to a function you'll be making a copy of the struct. Any changes to the copy won't be reflected to the original struct. If you pass a pointer you'll be using the original struct, not a copy of it. A pointer will be almost certainly smaller than the struct itself, so it takes less resources to handle it. It is paramount to understand this, as almost always you should be using one over the other.
RIF does so, too. Very interesting.
Anytime you use a "link" based data structure? 
the other answers focus on function argument/parameters. there's one area where you must use a pointer to a struct and that's when you dynamically allocate one (via malloc or something simiar). in this case you only have a pointer to a struct, so you must use it as a pointer to a struct.
I used pointers exclusively for a long while - such as when passing a struct into a function - but more recently decided to switch things up and start letting everything just get copied to local struct variables when I pass smaller structs as function arguments, except in situations where I want the function to operate specifically on the contents of a given struct. But for stuff like little XYZ vectors and whatnot I now just let the machine copy the whole thing and go the non-pointer route. It also just feels much cleaner and easier to deal with code-wise.
Maybe this will help, it's a simple program I wrote a while ago for one of the very early Project Euler problems to practice linked lists. Using pointers to structures makes it really easy to work dynamically. I only need one variable to store the address of current structure I'm looking at, and as I traverse the list I can change which element in the list I'm looking at by just storing its address. /* Each new term in the Fibonacci sequence is generated by adding the previous * two terms. By starting with 1 and 2, the first 10 terms will be: * * 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, ... * * By considering the terms in the Fibonacci sequence whose values do not exceed * four million, find the sum of the even-valued terms. */ #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; typedef struct fib_s { int val; struct fib_s *np; // next number in sequence struct fib_s *lp; // previous number in sequence } fib_t; int main(void) { fib_t *num; int sum = 0; // initialize the first two numbers of the sequence num = (fib_t *)malloc(sizeof(fib_t)); num-&gt;lp = (fib_t *)malloc(sizeof(fib_t)); num-&gt;val = 2; num-&gt;lp-&gt;val = 1; num-&gt;lp-&gt;lp = NULL; while (num-&gt;val &lt; 4000000) { num-&gt;np = (fib_t *)malloc(sizeof(fib_t)); num-&gt;np-&gt;val = num-&gt;val + num-&gt;lp-&gt;val; num-&gt;np-&gt;lp = num; num = num-&gt;np; } // sum the even entries while (num-&gt;lp != NULL) { if (num-&gt;val % 2 == 0) sum += num-&gt;val; num = num-&gt;lp; } printf("%d\n", sum); return(EXIT_SUCCESS); } 
I think in that last sentence you mean 'by reference'.
&gt; if (key[q] != ciphertxt[q]) You're comparing the wrong arrays. As a hint, consider the types: `key` is a `char` array and `ciphertext` is an `unsigned char` array. &gt; or L97, I am not sure whether or not I need code here, shouldn't L93 &gt; be doing what this line is saying to do? You need to track whether you exited the loop because it reached the end or because it found a mismatch and used `break` to escape early. &gt; if (strcmp(key, ciphertxt) == 0) The ciphertext is raw octets, not a string, so you can't use `strcmp()`. It's expecting a null-terminated string. Have a look at `memcmp()`. Also, this check seems to be redundant with the previous loop. &gt; printf ("%x", outbuf[0]); This will only print the first byte, so you need to make a loop to print every byte. Your format specifier isn't quite right, though. For example, 0 will print as "0" when you really want "00". Read the `printf()` documentation on how to correct this. Finally, there's a little bug at line 43. This appears like it might be a mistake by your instructor, unless you wrote that code. The `fgets()` function does not touch any bytes beyond the length, so you can't rely on anything past the null terminator. There's an attempt to pad this out, but the loop is written incorrectly. 
Well thats a good enough reason :) I like it. 
At [line 142](https://github.com/roecrew/cerver/blob/434fee49a5bd34752dbfd7b0b17d5b1873edeb9c/main.c#L142) you're not allocating enough space for an `int` -- it should be something like `malloc(sizeof *newsock)`. 
If you could post an issue it would be much appreciated!
Will the compiler not sometimes be able to figure out it can just send a pointer (as long as the function is not modifying any fields in it) when it sees it will be faster? I have some vague memory of that being the case.
Well I personally never heard anything about this
One reason I haven't seen: opaque pointers and separation of concern/separable compilation. Typically, if I have a complex data structure, I won't want to give direct access to the structure, and instead have an interface to it. By defining the interface and the structure in one file, and having the header file only use pointers to the structure, other code doesn't need to know about the internals of the structure. If I need to modify the internals of the structure or how it's accessed, then it's just a matter of changing the one C file. In the header, something like typedef struct MyStruct MyStruct; is enough of a prototype for pointers to exist to the struct, and in my implementation I can define the members. Then you can have function prototypes like MyStruct *MyStruct_new(); int MyStruct_add_postal_code(MyStruct *, char *); and so on. One example of this is FILE *. We don't have to care about what FILE really is, just the functions that act on them. It's not quite C++ or Java, but it allows some separation and basic object-oriented style programming. Sure, it's generally going to be less performant and less cache friendly than passing a struct by value. Still, we're using C. It's hard enough to be organized, and it's already incredibly fast. Why not take the easy route once in a while?
Ok, you need to get the basics first. First lets get your functions in order. `// DIAMETER TO RADIUS` double diameter\_to\_radius\(double radius\) { *return* *radius \* 2*; } Diameter is 2 \* radius. All this function needs to do is receive radius \(see: sending parameters to functions by value, by pointer, etc...\) and it needs to return calculated diameter. `// AREA calculation` double area\(double radius\) { return PI \* radius \* radius; } What is your take out from this ? Function in C can return only one value with a return statement. Your code where you have two returns one after the other can be compiled, but everything after first return is unreachable code. random\_value\_generator is this: double random\_value\_generator\(int Rand\_MIN, int Rand\_MAX\) { double Rand\_Value; double range = \(Rand\_MAX \- Rand\_MIN\); double div = range / Rand\_MAX; Rand\_Value = Rand\_MIN \+ \(rand\(\) \* div\); *return* Rand\_Value; } This way you can have one function that is generating numbers from MIN to MAX and you will just call this function like:double radius = random\_value\_generator \(0, 15\); // for the radius or double diameter = random\_value\_generator \(0, 30\); // for the diameter Since I don't want to solve your homework I'll just give ou a few hints. In main when you want do generate a new radius you need to declare a variable, e.g. called radius \(see and C programming book what is meant by "declaring"\) and then initialize the variable like this: double radius; radius = random\_value\_generator\(0,15\); If you want to calculate area with that radius, you need to call the function that calculates area with: circle\_area = area\(radius\); radius needs to be **declared and initialized**. circle\_area needs to be **declared.** Think how will you make calculate radius from diameter ? 
Maybe "crash" is too harsh, but "gracefully exit" isn't right either since that implies cleanup operations. If a program detects it's encountered a bug, it should hard abort as soon as possible. A cleanup might cause more damage. Some sophisticated interactive programs will catch some kinds of crashes and, in clear and unambiguous terms, warn the user to immediately save and restart the application. For some interactive programs that may not be too unreasonable.
The error message tell that the line is broken after the %d. Combine line 29 and 30 to one line, and recompile. 
You made a typo copying the content of `main.c` into `multidarrtest.c`. Have you even tried to read the error message? It tells you what went wrong.
If you just have a prototype in the header file as you have above, you can't actually malloc\(sizeof\(MyStruct\)\) unless you're in the file with the full MyStruct definition, right?
It used to be worse: fpos\_t rpos; int max\_bytes = 0; int bytes; /\*...\*/ rpos \+= bytes \- max\_bytes \+ 1; 
Remove the `"\n"` from your format string. Also, your use of `feof` isn't correct. Instead you should be checking if the return value of `scanf` is `EOF`.
Thanks for the help I'm slowly getting there
Yep! And I'm slowly figuring out how to do that 
Thank you so much. My professor was confused as to what was happening but taking out the eof part as well as the \n fixed my issue!
I C that Rust is replacing C\+\+ very well...hahahaha My beloved Lisp, hang in there! 
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions.
First, this is C++ code but you've posted it to a C programming subreddit. However. return percent; You have a function called `percent`, but you're not actually calling it here. You need to pass a value, like return percent(numright); You will encounter a few other issues with your code once it's running, but I would suggest you post those to to /r/cpp_questions
You seem really smart. I would love for you to submit some pull requests if you have the spare time! :)
Im so sorry. i couldnt find that one when i was searching.
As for your points. - a thread per connection doesn’t scale very well. "No duh. As I said in the readme -- This project is in development... It's not ready for a production environment." - loads of unchecked OpenSSL calls. "Can you be more specific?" - unsafe string operations when constructing responses. "I'll be fixing this in the next build." -SSL_read() won’t guarantee that that rbuff is NUL terminated and you are treating it as a C string. "I memset rbuff with '\0'..." - Cute, but don’t expose this to the internet. "Then please show me (us) how to make a full-proof incredible https server" 
&gt; Have you even tried to read the error message? It tells you what went wrong. The error message is just the compiler giving up after finding a linebreak inside a string. It could be better. If the programmer does not know that strings must be terminated on the same line, then the error message doesn't explain it.
This is a great paper. Thanks for posting.
I've been having fun dropping this on people's plates who claim c++ is a zero cost abstraction. 🔥🔥🔥
The other replies have correctly identified the bug (note the difference in the line numbers reported for the last two error messages), but to answer the title question: No, you don't need to have a file named **main.c** but you do need to have a function **main()** in one of the object files being linked.
What program is that and how do you write an extension? 
Im curious because there is (propietary) software I use at work and I'm always thinking it would be nice to add some features to it.. wondering if that's possible 
If the calls stays within the same compilation unit, the compiler can do whatever it wants. If the call crosses object file boundaries, the ABI dictates how the struct is passed (barring LTO). Usually `struct` arguments are passed as if they’re decomposed into their fields, so `struct {int a, b;}` would just be passed as two `int`. Return values that are ≤2 words are usually passed back as if decomposed into fields (e.g., in RDX:RAX for x86-64, or EDX:EAX for IA32) and anything that doesn’t fit takes a secret pointer, so that struct large function(int x); becomes void function(struct large *out, int x); and then the compiler allocates the `struct large` before making the call.
Use a switch! Also you don't have to use strcmp, just check the character as == 'A'
How would I use a switch in it? 
https://www.tutorialspoint.com/cprogramming/switch_statement_in_c.htm Basically follow that syntax and use Calculate as your 'constant-expression' and have statements for case 'A' and 'C' and the default will the code that is executed as any other value.
&gt; "Actually, for most use cases it is fine No it really isn't. It's an archaic design that has no place in new server code. &gt; "Can you be more specific?" SSL_write() can fail, I see you already somewhat are dealing with that now, thats great. SSL_new() can fail, SSL_set_fd() can technically fail. One good point in defensive C programming is that if it can return an error, you check the return value. &gt; "I memset rbuff with '\0'..." You are literally doing: SSL_read(ssl, rbuff, sizeof(rbuff)); which tells that function "hey read up to sizeof(buf) bytes". Since SSL_read() works on TLS records, I could very easily send you a 10k record that is not NUL terminated. What do you think happens then? &gt; Then please show me (us) how to make a full-proof https server" https://github.com/jorisvink/kore/ - I wrote this. 
I have had a try with the switch, I'm almost there. I just not sure how to get it to run. Getting errors that ask "While" statement to be before my case
Well, you'd want to design your predicates so that they *don't* fail, IMHO.
The base or radix is the number of unique digits, for example 10 in the decimal system which uses digits 0 to 9. https://wikipedia.org/wiki/Radix
I don't fully understand why all the elements wouldn't be uniformly randomly distributed. Isn't uniform random distribution what the FisherYates is all about? Or are you refering to a way that the FisherYates may be implemented incorrectly?
Hey, Lofenyy, just a quick heads-up: **refering** is actually spelled **referring**. You can remember it by **two rs**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
great paper, its interesting to see the difference on https://godbolt.org when you compile the same C code with a C++ compiler, very occasionally its slightly smaller (c++) but the all of a sudden you'll hit something and the c++ assembly becomes significantly larger... c++ just ain't K.I.S.S.
Normally, I'd stick with the first option, and if a predicate really needs to fail, either use 0 as true (1 for false, negative for error code), or live with a global var for the error (if not using threads, of course). I like the idea of an error code return pointer, though!
Not a C\+\+ expert by any means but I suspect this kind of huge difference in assembly output often happens when you add a "const" or "constexpr" whenever possible.
Can you show an example?
It refers to the [base or number system](https://code.tutsplus.com/articles/number-systems-an-introduction-to-binary-hexadecimal-and-more--active-10848) that your input string uses. For example, say you want to convert a numeric string in binary (base 2) that looks like "10110010101001" into a value that your program can use. Instead of writing several different functions that each convert strings of different bases into values, the creator of strtol just added a third parameter so that the user could specify the base they want to use. That way, to read in this string you just have to write something like: long value; char * string = "10110010101001"; value = strtol(string, NULL, 2); Hope this helps
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
It's probably a case of a missing or extra brace or semicolon. I'm in a rush and didn't have time to parse it. Also, putting your code into functions can make it look neater and easier to read and find issues like this.
The first one make more sense to me personally. An another possibility with 1) is that the error code indicates that the result might not be fully constructed if an error occurred. Method 2) suggests that Result does not have a "partially constructed" state. Method 2) suggests to me that I can still do something valid with Result even in the case of an error while I would expect that 1) might leave result unchaned from some possibly unitialized (and thus invalid) state. 
A predicate should only return true or false, depending on if some condition is met. Not true, false, or error.
Leitura muito interessante, um bom trabalho e um bem haja de um estudante da UMinho
The one i use is open source
Pure data. It’s for audio, mostly
1 is more common in C You can also reverse special values in return to indicate errors. Very error prone, but all error management in C is error prone. The very best is to design functions that cannot fail. For instance, why does empty can return an error? What is the underlying concept? If it is a data structure, why testing for emptiness can yield an error? If it is some more elaborate data structure (say a work queue), can’t you avoid providing such trivial function on it? I remember reading stuff about functions that cannot fail ong ago in [Writing Solid Code](https://www.amazon.com/Writing-Solid-Code-20th-Anniversary/dp/1570740550), in the Chapter “Candy Machine Interface” (IIRC) that had a lasting impression on me.
I cannot disagree with Point number one more than anything. I don't think code can have too many comments, the more the better. Having to read two lines of comments versus 25 lines of code is much faster.
Is your iPhone jailbroken?
Have you thought of just ssh’ing into an existing box somewhere? That’s what I do. If you don’t have one, you can get a small vps somewhere for under usd $10/month, I’m pretty sure. Last I checked there was nothing really decent on the AppStore. Happy to be corrected.
Yeah there isn’t anything in the app store you’re right but you know there are some apps that you download externally from safari, the ones that require a profile installation. I thought may be someone here knows an app like that or some app that’s hard to find ind app store.
Ah. If you were jailbroken, you would probably able to install gcc/clang and go "fully native". In the absence of that option, have you tried https://itunes.apple.com/us/app/cppcode-offline-c-c-ide-compiler/id936694712?mt=8? It's far from polished, but having just tried it, it seems functional (ish).
You won’t find anything on the appstore, as Apple have more or less banned any app that creates code on the iPhone.
interesting. Just downloaded it, looking at the ui and trying to figure it out. Why are there lines across my screen like a school kid’s copy book?
Yeah, the app has it's... "quirks". Tap more on the top right, then Project, then "New Project". I think that the lines you are seeing is from the "diagnostics" (linting) output window, but it should be pushed to the bottom when you start a new project.
So you can make a function and give it a descriptive name. 
C++ is off topic on this subreddit. Please post C++ questions elsewhere, e.g. in /r/cpp_questions.
Theoretically you could also use something similar to exceptions using setjmp/longjmp
Wow, all that to just list all current folders haha... GNU team rocks! 
cool! 
I prefer 1) because copying the Error status on the return is small (a signed int generally) and you only copy of the point to the struct into the function. In 2) you are copying the result structure (which can get large depending on what your function is doing) on the return. While it could be changed to return a pointer to the result, that introduces some ambiguity about who is charged of dealloc'ing that memory. The owner of the memory problem with 2) is why you see the struct filling idiom so often (where the caller passes in a pointer to an allocated struct, and the function fills the struct with the data, returning a status/error code). 
I am a simple guy. I know and Like C and CLisp. If ever a new programming language offers me anything beyond what both of those can do, I would gladly learn it! C++? not that much! Rust? , it seems it does! 
That hardly is a Developer feature nowadays as most developers are able to do that much! 
&gt;unsurprising. R u kidding! haha
It's great to see C doing so well, but I was kind of disappointed by how poorly Lua does.
The traditional way is to use return value for the actual result if possible, and to return a negative number or null pointer to indicate an error. The problem with that is that you can't return additional information about an error, you either have to use errno, or log error information somewhere else. [glib's style](https://developer.gnome.org/glib/stable/glib-Error-Reporting.html) is to pass a pointer to get error information, but this is optional and can be set to NULL; the return value is still used for both the result and indicating whether an error occurred.
You could also imagine separating validation and getter: if(is_valid(data) &amp;&amp; is_empty(data)) That's just to add to the possibilities, I do not say I recommend it.
Personally I would use: 2) Result function(Error* error); Due to the amount of details, But that is Preference. 1) Error function(Result* result); could be good for posting to stack exchange or another Reddit forum.
Nevermind; finally solved it!
This looks really cool! Why did you choose C over C++? (not judging I’m just curious)
Ya I think if you wanted support then there should probably be a section in your readme that describes some goals or potential features that you were looking to build.
I can definitely appreciate the convenience of various C++ features and the wealth of quality C++ libraries that are available. Personally, I haven't yet invested the time to become proficient with the language, especially C++11 and beyond. I am comfortable writing C code and I personally enjoy the style of C programming so I choose the language for my own projects. Still, I think there is some merit to using C for a project like this - when there are fewer syntactic abstractions, it makes it easier to think about memory access patterns and execution time of functions. Lastly, I just find it a very interesting challenge to make the complete software using a very primitive language like C.
For the time being, I am still working on it independently. For me, the purpose of writing this code is to learn about graphics and engine programming as much (or more) as it is to produce a working engine. So I want to solve all the problems by myself. I post the source code now just to share many hours of work and get feedback. However, I do believe that this software has potential to be actually useful. There are not many open source RTS engines out there, and each one has some unique characteristics. For now, I am aiming to create a minumum RTS prototype, including pathfinding, fog of war, and a basic demo. At that point, I may collaborate with others to take the project to the next level and will take the steps to make the collaboration possible, including sharing my detailed plans, setting up a chat channel, etc.
I wonder how it work. and how to use is
Try /r/cpp_questions. This is a core component in C++, but does not exist in C.
Sorry, I can't find that
Some classes and fucntions are generic. Meaning that they can work with any type of object, strings, int, char, etc. When you create an object of a generic class, you must specify between the ' &lt;&gt; ' the typename that you want to work with. For example : you can use vectors with any objects, string int, char, etc. When you create a vector, you put between '&lt;&gt;' what is going to be store in your vector. I hope you understand, if you have more questions just look there : https://www.tutorialspoint.com/cplusplus/cpp_templates.htm 
Google generics and templating. It will take some studying.
"Some" is certainly not enough
This is super cool. I wanted to write my own engine for a long time now, but I have no idea where to start. I bought Jason Gregory's Game Engine Architecture book in hope to finally get the tools I needed to get started. Even though the book was interesting and worth every penny, I still feel that writing my own engine is to overwhelming. Good job and thanks for the inspiration! :)
There are lots of books and websites to learn C language. C language is building block or base of C\+\+, Visual C, Java and so on. In C language at first you understand the basic methods like Arithmetic Operators, logical operators, if condition, if\-else and nested if, loops\(for, while, do\-while\), function, arrays and writing program from starting brace to ending brace with concept of all headers files and build in keywords for particular headers.
Love the comment style. Super easy to read main.c for instance. I'm a big fan of tiny code comments to briefly explain what's going on in a block..i.e /* iterate tests in suite */ ... /*Exclude tests for new versions of C */ ... /* Get functions to test */. Really pretty. I can just scroll through the function in like 15 seconds and know everthing going on. That said, you could probably get away with extracting some of that code to other functions..regardless though its easy to read. +1 for introducing me to 'getopt' command line parsing util +2 for a giving me a refresher on 'extern' +3 code structure design I was looking around to see a sample text file which could be redirected as input to demonstrate the command line syntax for testing. Is there one I missed? 1. Why is it you include local files with &lt;&gt; over ""?
I thought C++ performed pretty well? Wasn't it the best all around OO?
C++ questions are off topic in this subreddit. Please post C++ questions to /r/cpp_questions.
Use `fprintf(stderr, …)` to print warnings to the error stream. Or simply `warnx()`.
&gt; I am using Gtest for years now in my C and C++ code base. For the C code base, do you happen to have any github repo URLs which provide useful examples? If you're comfortable sharing your own, that might be helpful 
I have had my share of scripting 'interactive programs'. Mostly, I ended up grepping out the "warnings" which were irrelevant for my use case.
how do you find nuklear as a gui solution ?
Thanks for the feedback! I like to stick with &lt;&gt; for just so that if I change my project structure one day, I can just switch up my CFLAGS and not have to worry about updating any include paths in the code. I don't have any syntax examples except for what -? spits out, but my goal is for the user to just give the path to a compiled libc and the results to come out like magic.
I think it's good. I spent a couple of hours on one bug where I would get crashes sometimes but, ultimately, it was my mistake in using the API. Other than that, it's very nice - the GUI elements behave like I expect them to and the library is easy to use. I have not done too much in terms of custom styling but one thing I like is that this library lets you do custom styling of the widgets down to how every last pixel is drawn - you're not constrained to just a few color/size options.
Mmm ok. Ya I saw the print statements in main, but otherwise I had no way of knowing exactly what you were looking for. Nice work.
Yup, so you go ahead and create a `MyStruct *MyStruct_Init` function in your source, and declare it in the header. For super simple types it's pointless, but then again, there's no reason to hide those definitions. For complex types, a simple calloc probably wouldn't work anyway.
Learn to use gdb
What is it that you want to accomplish here? You have some serious issues with missing input validation. For instance, what happens if you enter '12345!"#¤%&amp;/6' rather than letters? I can't see any place where you'd get an infinite loop, so try to answer the following questions: * What do you expect to happen? * What actually happens? * Get a rubber duck (The yellow ones are the best), and tell it why your code is supposed to give you the expected output. If those three stteps fail to get you further, please get back to us with the answers to the two first bullets. 
It was the best OO. The non OO languages beat it though. Once again, showing downsides of OO, and that "zero cost OO" doesn't exist.
Haha about the input validation no need to check that .. (That's what we told to yes its a hw) other than that I can't find a case with inf-loop too .. Using a debugger will help?
As I wrote, start by explaining to your rubber duck what you expect to happen. Then explain to it what actually happened. As there are clearly some distance between those two, proceed to explain to it why your code was supposed to produce the expected output. I am deadly serious about the rubber duck. I the vast majority of cases, you will spot the error in your code while trying to explain to others that it has to work. You have lots of questionable constructs in your code, but I suggest that you start by eliminating the logical flaws. As I'm not entirely sure what your code is supposed to achieve, I'd be happy to see a written copy of your dialogue with rubber ducky.
Dude you're really serious about that ha? But you don't understand the situation .. So basically I submitted this hw two days ago (I wrote this code in the same day plus 2 other codes) there was 4 tests that this code passed that I know the input and the expected output ... But then when the feedback came back .. There is an option to resubmit but they told me that there is test 5 that stuck in inf-loop .. I don't know the input nor the the output of this test .. So I'm trying to ask some of you experienced people to help .. But it didn't go well haha ... Thanx anyway.
Actually, yes, [Rubber Duck Debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging) is a real thing. The idea is that by having to explain your code, you are thinking about it differently and will see the problems more clearly. One of the things I learned in school, that wasn't explicitly taught, was being comfortable thinking about the code. WI learned to think abotu what it does, and how. I learned how I think, so that I can look at my code (and problems in general) from different angles. Debuggers aren't that hard to learn, and there are free ones. If your'e in an IDE, there is likely a debugger available inside of it. Debuggers like gdb can be a bit daunting (not too much, really), but there are GUI wrappers around it. There are a few "non-debugger" debugging techniques that I still use to this day: 1. Rubber Duck Debugging has already been mentioned 2. printf(), AKA "poor man's debugger". at interesting points of the program, print out the value of your variables. And check those values to make sure they are what they *should* be. Understand what you expect them to be. 3. Paper. Yes, pencil and paper (you can use a spreadsheet if you'd prefer). Make one column per variable. Use rows for each line of code that wold be executed. Manually "trace" through the program. 
**Rubber duck debugging** In software engineering, rubber duck debugging or rubber ducking is a method of debugging code. The name is a reference to a story in the book The Pragmatic Programmer in which a programmer would carry around a rubber duck and debug their code by forcing themselves to explain it, line-by-line, to the duck. Many other terms exist for this technique, often involving different inanimate objects. Many programmers have had the experience of explaining a problem to someone else, possibly even to someone who knows nothing about programming, and then hitting upon the solution in the process of explaining the problem. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
https://github.com/
Homework haha
Get OSes to add it to their package managers.
&gt; I don't know the input What strings have *you* tested your code with? List them out, look at your code, and see if you can think of any inputs you haven't tried.
That sounds great, thank you, I'll look into it!
C does not have a community. C is just a tool. People use it to make programs and libraries, once the program or library is finished, it doesn't really matter what tool you used to write it.
Agreed. C is superior, but the gains were marginal. In my opinion, C++ is definitely a language to consider if cost for production is a factor. 
its not messy. you can put in a usb drive with a live linux version on it, make it persistent, install your tools and boot the stick if you need to 8GB is more than enough space and creating it is super easy. Download a Linux Mint 18 iso, and use the [Linux Live USB](https://www.linuxliveusb.com/) to create the USB stick and then you can boot linux from the stick without any real installation and changes on the stick will stay.
Use. The. Debugger.
this. Once you find out what GDB is, it will be your best friend (as far as C code goes, and assuming you are not using some IDE like CLion)
What's the error?
Also, if you're having problems you can always use printf to check the output to find where something is wrong, and sometimes if you think you've found a culprit you can use // at the start of a line to comment it out and keep it from running. Those are two things you can use to debug.
If you're willing to be your own maintainer (packaging and pushing the library yourself) it's easier to do, although it's a nontrivial exercise to get it initially accepted, they do a LOT of vetting before accepting a new package. Look into publishing for Fedora and Debian and you'll capture the vast majority of the Linux market (they are the base used to make CentOS/RHEL and Ubuntu). There really isn't a central place for Windows in the same way as the Linux package managers.
Without seeing your code, it's hard to help you. Since this seems to be the first time you are looking for help, let me recommend you to read [this article](https://stackoverflow.com/help/how-to-ask) on how to ask for help such that people can actually help you.
btw, I just looked to the sidebar, I noticed there's another reddit called "C Programming Jobs". Still, does anyone have any insight into trying to find a C job, or insight on if it'd be the right fit for me or not?
Where are you located? Perhaps someone can help you find a job. &gt; Will an interpreter for a language I created be enough demonstration of skill? Depends on what it does. If it is impressive, then certainly.
[indeed.com](https://indeed.com), [monster.com](https://monster.com), ... 
I'm located in Halifax, Nova Scotia, Canada. It has functions and if statements, I use Flex but not Bison. If I gave it another month or even two weeks, I can give it variables (even though the language doesn't need them to be turing complete), and while statements. 
Makefiles or autotools, look for this book: https://www.amazon.com/Autotools-Practioners-Autoconf-Automake-Libtool/dp/1593272065 GNU autotools online documentation is good once you know about it, but it is a bit difficult to get started with.
In the past it was common to use sourceforge, but nowadays it's way better to host your code in github and provide a good "getting started guide" in a readme.
There's actually a lot of programmers, but Halifax is still a medium city. I don't think there's many specifically looking for C here. That being said, a couple embedded system positions do want C - would they specifically be looking for someone who has already done a bit of it? I wouldn't get hired off just knowing C, right?
Do `blockA` and `blackB` point to locations within the same object? E.g. a single block allocated by a call to `malloc` ? If not, then comparing them results in undefined behavior. You might be able to get away with it, but...
There is [clib](https://github.com/clibs/clib).
I know undefined behaviour is undefined, but is there any example C platform where this doesn't work?
Can you expose a C ABI on the Haskell version of your library as well? 
An example is something like hx: https://github.com/krpors/hx. Make a pretty readme, and make it easy to install with ```make``` and ```make install``.
You might have heard of near pointers and far pointers from people developing for Microsoft platforms back in the day...
Comparing pointers in different memory segments in DOS or other x86 real mode environments?
Yes, [FFI](https://wiki.haskell.org/Foreign_Function_Interface), many low level Haskell libraries run on C. [Network.Socket](http://hackage.haskell.org/package/network-2.6.3.1/docs/Network-Socket.html) is a big one. Or do you mean the other way around with a C library running Haskell?
Looks promising, thank you!
So, it sounds like you have the same issue that `memcpy` has. Is there a reason you cannot make it the caller's responsibility that the data does not overlap the vector? To help out, you could provide `AddManyFromVector(const T* otherVector, int index, int count)` which people would use if they wanted to copy data from one vector to another. In this case you can compare the vectors and determine if there's overlap. 
I think it would be simpler to just make Add always use a vector as a source of the data to add - period. This would prevent anyone from screwing up and adding from a vector to itself. Then, if you have a requirement where you have some raw data (not in vector) that you need to Add - what I'd do is have a way to make a, cheap, vector wrapper using that raw date (i.e. not requiring a copy) and then use that wrapper with the Add api that requires a vector. This would be how I'd keep the API surface minimized - everything in terms of vectors. Vectors are your abstraction - I think you want to avoid [leaking](https://en.wikipedia.org/wiki/Leaky_abstraction) the details (underlying pointers) as much as possible.
We can't see your code. 
You need to post your code first. This is just the execution of your program.
#include &lt;stdio.h&gt; #include &lt;conio.h&gt; #include &lt;string.h&gt; float gtotal; void main() { int orderno; printf("WELCOME TO Kuya WoW's karinderya"); printf("\n [1] Main Menu"); printf("\n [2] Exit"); printf("\n Please select order: "); scanf("%d",&amp;orderno); if (orderno==4) { endtrans(); } else { switch (orderno) { case 1: maindish(); break; // case 2: // drinks(); } } } void endtrans() { printf("GRAND TOTAL: %.2f",gtotal); } void maindish() { char answer='y'; int ctr=1; float maindishtotal,change,payment; float menuNo[]={0,1,2,3,4,5,6,7,8,9,10}; menuNo[0]=0.00; menuNo[1]=90.00; menuNo[2]=90.00; menuNo[3]=70.00; menuNo[4]=60.00; menuNo[5]=100.00; menuNo[6]=30.00; menuNo[7]=20.00; menuNo[8]=30.00; menuNo[9]=30.00; menuNo[10]=50.00; char* dname[]={"Exit","Adobo","Papaitan","Pinakbet","Sinigang","Bulalo","Iced Tea","Orange","Pineapple","Coke","Buko"}; float price[1000]; char* ordname[1000]; int qty[1000]; while (answer=='y') { //WHILE system("cls"); int orderno; int inputqty; printf("\t\tMAIN DISH"); printf("\n [1] Adobo \t\t\t Php 90.00"); printf("\n [2] Papaitan \t\t\t Php 90.00"); printf("\n [3] Pinakbet \t\t\t Php 70.00"); printf("\n [4] Sinigang \t\t\t Php 60.00"); printf("\n [5] Bulalo \t\t\t Php 100.00"); printf("\n ========================="); printf("\n\t\tDRINKS"); printf("\n [6] Iced Tea \t\t\t Php 30.00"); printf("\n [7] Orange \t\t\t Php 20.00"); printf("\n [8] Pineapple \t\t\t Php 30.00"); printf("\n [8] Coke \t\t\t Php 30.00"); printf("\n [8] Buko \t\t\t Php 50.00"); printf("\n\nPlease select order: "); scanf("%d",&amp;orderno); printf("Enter quantity: "); scanf("%d",&amp;inputqty); printf("\n"); price[ctr]=menuNo[orderno]; ordname[ctr]=dname[orderno]; qty[ctr]=inputqty; int ctr2=1; float subtotal=0; for(ctr2;ctr2&lt;=ctr;ctr2=ctr2+1){ printf("%10s",ordname[ctr2]); printf("%10.2f x %d",price[ctr2],qty[ctr2]); subtotal= (price[ctr2]*qty[ctr2]); printf("\t\t %.2f",subtotal); printf("\n"); } maindishtotal=subtotal+maindishtotal; printf("\t\t %30 \t\t\t%10 _______"); printf("\n\n\t\t %30 \t\tTOTAL:%8.2f",maindishtotal); ctr=ctr+1; char confirmation; printf("\n\n Do you want to continue? [y]Yes [n]No: "); scanf("%s",&amp;answer); }//WHILE gtotal=gtotal+maindishtotal; printf("Enter payment: "); scanf("%f",&amp;payment); while(payment&lt;gtotal) { printf("Payment is less than the total please enter again: "); scanf("%f",&amp;payment); } system("cls"); int ctr2=1; int ctr3=ctr-1; float subtotal=0; printf("\n\t\t Kuya WoW's karinderya"); printf("\n\t\t OFFICIAL RECEIPT"); printf("\n\t\t===========================\n\n"); for(ctr2;ctr2&lt;=ctr3;ctr2=ctr2+1){ printf("%10s",ordname[ctr2]); printf("%10.2f x %d",price[ctr2],qty[ctr2]); subtotal= (price[ctr2]*qty[ctr2]); printf("\t\t %.2f",subtotal); printf("\n"); } printf("\t\t %30 \t\t\t%10 _______"); printf("\n\n\t\t %30 \t\tTOTAL:%8.2f",maindishtotal); change=payment-gtotal; printf("\n \n\n\t\t %30 \t\tCHANGE:%8.2f",change); } 
 #include &lt;stdio.h&gt; #include &lt;conio.h&gt; #include &lt;string.h&gt; float gtotal; void main() { int orderno; printf("WELCOME TO Kuya WoW's karinderya"); printf("\n [1] Main Menu"); printf("\n [2] Exit"); printf("\n Please select order: "); scanf("%d",&amp;orderno); if (orderno==4) { endtrans(); } else { switch (orderno) { case 1: maindish(); break; // case 2: // drinks(); } } } void endtrans() { printf("GRAND TOTAL: %.2f",gtotal); } void maindish() { char answer='y'; int ctr=1; float maindishtotal,change,payment; float menuNo[]={0,1,2,3,4,5,6,7,8,9,10}; menuNo[0]=0.00; menuNo[1]=90.00; menuNo[2]=90.00; menuNo[3]=70.00; menuNo[4]=60.00; menuNo[5]=100.00; menuNo[6]=30.00; menuNo[7]=20.00; menuNo[8]=30.00; menuNo[9]=30.00; menuNo[10]=50.00; char* dname[]= {"Exit","Adobo","Papaitan","Pinakbet","Sinigang","Bulalo","Iced Tea","Orange","Pineapple","Coke","Buko"}; float price[1000]; char* ordname[1000]; int qty[1000]; while (answer=='y') { //WHILE system("cls"); int orderno; int inputqty; printf("\t\tMAIN DISH"); printf("\n [1] Adobo \t\t\t Php 90.00"); printf("\n [2] Papaitan \t\t\t Php 90.00"); printf("\n [3] Pinakbet \t\t\t Php 70.00"); printf("\n [4] Sinigang \t\t\t Php 60.00"); printf("\n [5] Bulalo \t\t\t Php 100.00"); printf("\n ========================="); printf("\n\t\tDRINKS"); printf("\n [6] Iced Tea \t\t\t Php 30.00"); printf("\n [7] Orange \t\t\t Php 20.00"); printf("\n [8] Pineapple \t\t\t Php 30.00"); printf("\n [8] Coke \t\t\t Php 30.00"); printf("\n [8] Buko \t\t\t Php 50.00"); printf("\n\nPlease select order: "); scanf("%d",&amp;orderno); printf("Enter quantity: "); scanf("%d",&amp;inputqty); printf("\n"); price[ctr]=menuNo[orderno]; ordname[ctr]=dname[orderno]; qty[ctr]=inputqty; int ctr2=1; float subtotal=0; for(ctr2;ctr2&lt;=ctr;ctr2=ctr2+1){ printf("%10s",ordname[ctr2]); printf("%10.2f x %d",price[ctr2],qty[ctr2]); subtotal= (price[ctr2]*qty[ctr2]); printf("\t\t %.2f",subtotal); printf("\n"); } maindishtotal=subtotal+maindishtotal; printf("\t\t %30 \t\t\t%10 _______"); printf("\n\n\t\t %30 \t\tTOTAL:%8.2f",maindishtotal); ctr=ctr+1; char confirmation; printf("\n\n Do you want to continue? [y]Yes [n]No: "); scanf("%s",&amp;answer); }//WHILE gtotal=gtotal+maindishtotal; printf("Enter payment: "); scanf("%f",&amp;payment); while(payment&lt;gtotal) { printf("Payment is less than the total please enter again: "); scanf("%f",&amp;payment); } system("cls"); int ctr2=1; int ctr3=ctr-1; float subtotal=0; printf("\n\t\t Kuya WoW's karinderya"); printf("\n\t\t OFFICIAL RECEIPT"); printf("\n\t\t===========================\n\n"); for(ctr2;ctr2&lt;=ctr3;ctr2=ctr2+1){ printf("%10s",ordname[ctr2]); printf("%10.2f x %d",price[ctr2],qty[ctr2]); subtotal= (price[ctr2]*qty[ctr2]); printf("\t\t %.2f",subtotal); printf("\n"); } printf("\t\t %30 \t\t\t%10 _______"); printf("\n\n\t\t %30 \t\tTOTAL:%8.2f",maindishtotal); change=payment-gtotal; printf("\n \n\n\t\t %30 \t\tCHANGE:%8.2f",change); } 
Github URL? 
help
What seems to be the problem with the code?
total doesnt add up properly
I could be wrong, but I'm pretty sure CLion has GDB integration anyway
You won't know until you try. If you've not sat in front of a debugger for 6 days to find that your obscure crash was because of a ++var rather than a var++ in a for loop then you won't know if this is for you. Go get a job then decide if it's right for you. Only you know. If you want to just try you're hand at C then pull the latest kernel, find a bug and attempt to fix it although this does require much more knowledge than just C, it's the type of job you'll find using C. Most application shops are using higher level languages. 
&gt; If not, then comparing them results in undefined behavior That is true, but they are not compared(*) in the given code. In the code the pointers are first converted to `intptr_t` which was pretty much created for this usecase. So the code should be fine. Personally, I would use `size_t` instead of `int` and `uintptr_t` for safety. (*) Note that comparing with (in)equality is always allowed.
Thank you for this useful guide mate
Attempting to print an int with %f is undefined behaviour. The instant you invoke undefined behaviour, you cannot expect anything. Any question that begins with: &gt; Shouldn't it Is wrong. According to the standard, as soon as you write printf("%f", 4/3), the compiler is free to print 3141.59277, or print 5000, or not print anything at all, or print the complete works of Shakespeare, or reformat your hard drive (hopefully not that one). The point is, generally speaking, you shouldn't read too much into what the compiler is doing when you have undefined behaviour, because the compiler is allowed to do anything it wants. In this case, I can offer some insight into what gcc is *probably* doing, though. Assuming you're compiling for an x64 architecture, integer arguments and floating-point arguments are passed in on different registers. When printf sees a %f, it is mostly likely reading a value from a floating-point register instead of an integer register.
Well, in the 70s the defactor place was probably /opt/usr/share or something. Naturally that didn't scale well in the internet age.
Makes sense, thanks for the quick reply!
Isn't the answer the 1980s?
please add 4 spaces in front of your code in order to get formatting right.
Well, for one, it's indented like you wrote it in the middle of an epileptic seizure. Can you run it through a pretty-printer? For instance, `indent -kr` on Linux or BSD (you may have to install the `indent` package first). And while you're updating your post, you could also add something about what input you gave your program, what result you expected, and what result you actually got. I would suggest reading [https://www.chiark.greenend.org.uk/~sgtatham/bugs.html](this) first.
I think that most programming jobs for C programmers don't bill themselves as "C programmer wanted". They'll be jobs for kernel people, embedded software developers, realtime systems engineers, networking specialists, kernel people and so on. In other words they'll be looking for the skillset you have *next to* C. Figure out what your actual sellable skills are beyond just knowing the language and look for jobs that fit.
Can you give us some sample input and tell us what exactly is wrong? Nobody of us has the time to try and understand what you meant to do, so you need to explain this to us.
That's almost correct, but I advise you to use `uintptr_t` instead.
By converting to `uintptr_t` you circumvent this issue.
Bullshit. Converting to `uintptr_t` fixes all these problems.
Then it's right.
I'm going to assume you're talking about Continuous Integration testing (often called CI) because you're mentioning specifically GitHub and testing. GitHub itself doesn't test your code, but it can integrate with sites like [Travis](https://travis-ci.org/) that do. I can't give a concrete example at the moment, especially using GTest since I've never used it, but I can explain the basics of how Travis works. You make an account on Travis and link it to your repo on Github. Your repo should have a certain file that contains instructions for Travis on how to build the tests (ex make test) and how to run them. Travis or other sites will have specifics on what this file is called and what to put inside it. Travis will build and test it when you push changes to your repo automatically (Which is the nice part). Tests will return a status code like basically all programs do and that let's Travis know that the test failed and it will let you know by email or other means. Generally if the test program prints out what went wrong and returns a non zero status there isn't much you need to worry about using a specific test suite with a specific CI service.
I am not allowed to
What did you input into the system? What was your expected result? What did the system return to you?
your iterating through all the input chars ... if you only expect a single char, remove the while loop, check for length &gt; 1 and value &gt; 3 ... if either of those checks are true, print the input else print the string
You can use `getchar()` to peek at the next character in the input. If it is a digit, you copy the current character to the output without changing it. Then you use `ungetc()` to put the character you peeked at back.
It sounds like you're saying that C standard's admonition about comparing pointers resulting in undefined behavior is moot. All you have to do is cast to `uintptr_t` and it _works_. I'm dubious.
UB aside, here's what likely happened. Floating point (FP) arguments are passed in FP registers, integer arguments are passed in general-purpose (GP) registers. `printf("%f", 4/3)` instructs the compiler to place 4/3 (an integer) into a GP register, and `printf` to read and format the contents of a FP register. The preceding printf() call placed 3141.592773 into the 1st FP argument register, it wasn't erased, the second printf saw %f and pulled the value from the 1st FP register which is where the argument for %f would have been if the code were correct.
Undefined behavior in several places, reliance on unspecified and implementation-specific stuff in others. Check the `scanf` results to make sure you actually got something; if you hit EOF, it could return without initializing any of `p0`/`p1`/`p2`. Don’t apply bitwise operators to things that could be negative; the standards declare this undefined behavior. Generally it’s best to stick with `unsigned` types for bitwise stuff. Looking at the bitwise-ops expression specifically, though: The `&amp;p0[1]) == 0xF` part (there’s no reason to cast to `char`, and `char` may or may not be signed, in which case it could be negative→UB) means that both `p0[1]` (=the second character of the first password) and whatever comes out of `a^b` must have the bottom four bits as 1. For `p0[1]`, this would apply to SI (0F), US (1F), `/` (2F), `?` (3F), `O` (4F), `_` (5F), `o` (6F), or DEL (7F). Most terminals will treat keypresses Ctrl+O as SI, Ctrl+_ as US, and Ctrl+? as DEL (note the correspondence between un-Ctrl’d code and Ctrl’d code), but no guarantees there—you might want to hand it a file as input so you don’t have to worry about that. `a ^ b` would return the bit-difference between the two string differences. Given that `strcmp` doesn’t necessarily have to return 1, 0, or −1, only &gt;/=/&lt;0, you have no real way to know what specific comparison results would give this the right value. Assuming −1 is what comes out of `strcmp` for `p0 “&lt;” p1` or `p1 “&lt;” p2`, you could have `p0 “==” p1` and `p1 “&lt;” p2`, which would be `0 ^ -1`, which would be `-1`, which (assuming two’s-complement representation, which you’re not guaranteed) would be all Fs. ANDing this with `p0[1]` would return whatever `p0[1]` is, which if `==0xF` would have to be SI. So working back, inputs p0 “==” "A\x0F" p1 “==” "A\x0F" p2 “==” "B" would give you a == 0 b == -1 // again, maybe, who knows a ^ b == -1 (a ^ b) &amp; p0[1] == 0x0F or else, inputs p0 “==” "A\x0F" p1 “==” "B" p2 “==” "B" would give you a == −1 // etc. b == 0 a ^ b == -1 etc. etc. either of which should satisfy that `if` condition, iff the compiler and runtime goblins you’re taunting happen to decide in your favor.
I exactly did just that here : https://github.com/dullin/GoogleTestExample .
1. Array name is "category" 2. The array is storing "boolean" values 3. The SUBSCRIPT name is "endwhile" 4. The first loop loops 12 times and calculates the current sale date. The second loop loops -4 times and adds the sub-totals together.
If you write a shitty webasm-renderer and base it at zero it's possibly valid string. Also every 8-bit processor. We should fight IRL. I'm fat.
while (valor &gt; 0).... Do you eventually enter a negative number to halt the program?
When is the program supposed to terminate?
You only have one loop so it's obviously there. Unless you enter a negative value the loop will never end
char \* D2; and if\(valor&amp;#37;2 == 1\) D2 = "IMPAR"; 
The program doesn't even run
How can you have an endless loop if it doesn't run?
Okay.. What library? GTK, ncurses, something else?
What is a text box? Is that a Win32 EDIT control? A gtk+ text control? 
C# ?
That's a different language which probably has it's own sub
Your right, sorry :)
It runs for me
Correction: [ispc](https://ispc.github.io/) closes the gap a bit, and is C-like.
Not sure what compiler you're using, but if you can get your assignment to build with clang the sanatizers are a lifesaver for catching simple errors. -fsanitize=address and -fsanitize=memory are a C programmers best friends.
Forgive me, but I'm not sure on how I would fix that. How would you recommend fixing it?
Don't open the handle if you're not going to use it. Or, better, write your data to the handle instead of spawning a shell to do it
LOL go has garbage collection dude, it's anything but low level.
Why not use `ptrdiff_t` to store the difference between them
That is the kinda the stuff I wanna learn, what does garbage collection mean, what are pointers etc so I guess I have to learn some C at least 
I'm definitely surprised the least in C
This is a huge one for me
I think the confusion stems from both of the languages being called systems programming languages and people go "low level" in their heads.
Thanks for the insightful comment. I think I will start with learning some C but looks like I will end up like you using Go or even my existing JavaScript knowledge to write the apps I wanna write 
&gt; Calling C "low-level" is arguably a bit of a stretch, Technically it's a high level language. But I would consider it one of the "lowest" high level languages.
blah blah blah stop focusing on the technology and start solving problems.
Until you throw exceptions into the mix. It's much harder to reason about code that can throw 
I'm always bouncing between rust and C for my side projects. Rust has a lot of promise, but C feels like home.
A good point, rewriting existing programs which you already fully understand in a new language is an excellent way to learn it. Call it a training exercise if you will.
I need to be able to read assembly, even though I never write it. When debugging segfaults, you need every clue you can get, and working out exactly what the computer was doing means looking at compiler output. Compiler writers need to understand assembly even more.
If you want to learn how things work, then you should go for C, most other languages hide things for you especially when it comes to memory.
Sure, but that can all be done with OS-specific API in C, so it's more just an adoption of the OS' functionality and not really a reflection of the language per se. By default C just gives coders the convenience of completely denying that exceptions are even a thing, while still offering lower-level exposure to how memory is laid out and interacted with. Don't write code that throws exceptions and you'll be fine.
if you want low level, and C, buy an Arduino Nano clone (a few quid) and make some flashing leds work... then gradually replace all the SDK calls with low level equivalents, from there you can throw away the SDK, and just write low level code for AVR's with C, which you can still get to work with Arduinos serial boot loader, the benefit is you can also create stuff like clocks etc and have a physical end product for your C code... 
Given N it's easy to pick an initial range of numbers that must contain √N...
per se*
You can use a while loop to read one character at a time from user and each time you read one you can put them in an array. 
How would I make it so when the user enters -1 it ends? I think that's the hardest part for me
IMHO you make my point. Given that you have an 83% over the semester and you can't start the last program...
So lets say you have an int x, you give a value to this x everytime you read an input. Add an if statement to your loop to check if this X value is greater than zero if it is add it to your array if not just stop. Hope this helps :)
Sorry I didn't realized the inputs are separated by space then you may read it as a char(check scanf char if you don't know how) then look at the ASCII table to know if you've read an '-'.
Yeah I know it doesn't make sense but im fine with it once I get started. Just not sure how. Guess I'll focus on entering the integers then move on slowly. Pretty stressful mate moving from year 12 to first year uni. I'm asking for help here and not negativity. If you don't want to assist me, then please move on
Wait no the prior one should work
Ah I see, I'll try that in the morning. A goodnight sleep should help. Thanks!
It is stressful, I agree. That doesn't justify asking the world to do your homework for you. IMHO. 
I never asked for anyone to do it for me I specifically said just to help me move the stone then I can get it rolling. If you have a problem with someone trying to learn here, well then this thread is not for you
No problem, good luck!
[isdigit()](http://en.cppreference.com/w/c/string/byte/isdigit). Having every one separated by spaces sure sounds like they want you to read them as numbers with `scanf()` and "%d" though. Crappy interface design, but that's normal for programming classes... Should be either digits broken up into groups by spaces the way they are on a credit card, or just one big unbroken string of digits like you do making a payment on a web site.
I fully understand what you are asking for. This thread is great for me because I am a C Programmer and a C teacher at the uni level. 
&gt;To be honest, it doesn't really matter which language you learn persay, because it sounds like you need to study data structures, algorithms, and hardware level interaction \(assembler\), to learn what you want. &gt; &gt;Just pick any language you want and start reading code. This. Languages are just tools in the end. If it's "good enough", use it.
That means you have to clean up your use of the heap. If you request a block of memory for an object or something, you're responsible for tidying it up for reuse. You clean up your rubbish yourself. Auto GC is when there is some code that occasionally gets run to look for blocks of previously allocated memory that it thinks is no longer in use, freeing you from this task.
Ignore everyone telling about `getchar()` and `isdigit()` and whatnot. Use `scanf()`. Here's the loop for you, hopefully you will be able to fill in the rest: while (scanf("%d ", &amp;x) == 1 &amp;&amp; x &gt;= 0 &amp;&amp; x &lt; 10) { /* the user entered a number between 0 and 9 inclusive } 
C++, when used with care, can be usable, but all the new standards seem to be pushing it towards an Akira doom. C does appeal more. And then there's your everyday C+.
Thankyou! Ive almost finished the question. Few minor bugs but almost there
&gt; Some Go fanatics say go will replace C Wasn't that Rust?
I was in a similar situation, and I learned Go, then moved to C. Pros of Go: * Go is easier, and has almost no 'gotchas'. Error messages are more simple to understand, the tooling is easier to setup, and the documentation is both great, and centralized. * Go will absolutely help you learn C, if you want to, afterwards. Go has a similar feel, and working with pointers in a more gentle enviroment is a nice introduction to working with them in C. * Go makes a lot of decisions for you. Cons of Go: * Go's tooling is much easier to find and use, but it is much less comprehensive than what C has. * Go makes a lot of decisions for you. After a while, you'll find this annoying. * In C, you can basically do whatever you want. In Go, a lot of stuff is black-boxed, and the syntax is much more restrictive. * C is everywhere, and you can do anything you want with C. With Go, much less so. My feeling is that C is pretty horrible for the first few months, good for the first several years, and excellent for a lifetime. Golang is great for the first few months, then mediocre ever after. 
Good for you! DM me if you want a code review, but I might not be able to answer for a couple of hours.
C\+\+ is the Perl of compiled languages \(probably get downvoted for that!\). I know C\+\+98 reasonably well and I do like OOP, but IMHO references completely f'd C\+\+ up. Example: why do we have move vs. copy constructors? References. I learned OOP on the Mac in the late 80s with a Symantec pre\-C\+\+ OOP language \(sometimes referred to as C\+\-\) and it was much cleaner. Didn't have templates \(generics\) but that's another story. On my own time I usually write in Swift. Granted that if your target isn't an Apple product its usefulness is currently limited, but if you want to learn a language where OOP was done right, Swift is a good example.
When I first started learning C++, I went the route of learning the language rather than how to use the language to actually program. This was my biggest mistake. I knew a lot about the language but not so much about why I would use a const here, a template there, a pointer parameter over a reference parameter. C++ is a massively intimidating language and I agree with you on how it can be very hard to read other peoples C++ code because it allows for such a wide variety of stuff to work. Bjarne Stroustroup said himself to keep things as simple as possible and to only to add complexity when complexity is required. After I realised I was going about it wrong, I changed my direction and started reading books on actually using the language compared to learning everything the language has to offer. Once I did that, I found it easier to read peoples code and distinguish between well written and poorly written code. 
I have to remember the phrase *Akira doom*.
With “Teach Yourself Cc+ in one hour a day” you will start to use in the right way the right modern C++
Formatting
Please put 4 spaces in front of each line of code. Your post is currently unreadable.
Hi!!! Happy cake day!! I just fixed it :) 
It's definitely not fixed.
OOP is one of the best features of C++. But, of course, you won't be able to use it until you understand how it works. OOP code make programs faster to do and safer (of course, if the classes are well implemented). In C, well, you can do anything wrong. You can have memory leaks. You have to manually modify each field of your structures (or call a function). The code is not readable like C++/Java/C# (OOP) code, even if you're a C veteran (same applies for ASM). C is easier to learn, yes. But because there is so little to learn. C is very plain. C++ is harder, but with it, you'll learn OOP, a really fantastic feature if you master it.
If....
I’ll go back and look at obj c. Is there a good book for the cranky c guy you’d recommend to read? 
Paragraphs man.
What would this mean and does it have any relation to the anime?
Going against the grain here... C is very nice, don't get me wrong, but after writing in "very" high-level languages, you realize C is just so tedious (manipulating strings f.ex.). OOP btw to me is a very nice feature of C++, and once you understand the mechanisms behind it C++ is just so much better to write in.
I think this comparison is a bit unfair. C\+\+ has its strong points and its uses in the industry. It's a very capable language that allows programs to use OOP abstractions and metaprogramming while having native performance. Its standard library is full of usefuls things that you don't have in C standard library. It is not for everyone but you do not need to know every little detail in order to write programs in C\+\+. Buy the book from Stroustoup if you want to go the C\+\+ way; it really explains the language in the easiest possible way.C is my favourite language, don't get me wrong, but it is not the best language for everything out there. Also: " When I decided that I wanted to learn I consulted in forums, coming to the conclusion that if I wanted to learn to program anything I should learn c\+\+ \(they said it was the most used language in the video game industry and other leading applications like Photoshop\) " This is the worst approach to programming ever. If you do not need the speed and feature that C\+\+ offers, why don't you learn Java or Python for example?C is very nice, it's easy to learn but very difficult to master, especially when your programs begin to be bigger and more complex than beginner stuff.
*Objective-C Programming* 2nd edition by Hillegass is pretty good. Unfortunately, after 2014 and Swift no one seems to be interested to write about Objective-C. If your intention is to use Objective-C outside of the Apple ecosystem I'm afraid you will be disappointed. 
I lean toward C because I think about data structures in a C way. It “feels” right to have a chunk of data with a library of functions that act of that data type, rather than calling a function from a class. E.g., I prefer `translate_sphere(&amp;mysphere,x,y,z);` instead of `MySphere.translate(x,y,z);` Hard to explain why I prefer it.
With the caveat that everyone you're working with knows C++ very well, and also doesn't have the propensity to write OOP doom hierarchies, or do stupid things with overloading (or exceptions).
I mean to use it as when it bloats itself into oblivion. Yes I was basing myself in the anime.
Would you move to Ontario or Toronto?
After having learned C, I started getting my feet wet in C++ and I had a similar experience as you. As a result I didn't learn much CPP(that was before c++11 btw) and quickly gave up. As I was reading about design patterns/techniques as well as reading both c and CPP codes I then started appreciateing CPP and the convenience it often provides. It is very likely that you find reading CPP code difficult because you are not familiar with the idioms. You have to put some effort to learn these but they pay back quickly: 1) by being able to understand others people code (and they also understand yours) 2) because these are well established and studied 3) they are used in other languages as well, you will soon be able to work in other languages! 4) it is much easier than implementing them again and again on your own in C. I am not saying that CPP is preferable to c, code design is not easy and you need to decide what is more convenient for what you are doing.
I hope to one day be able to do this sort of thing. Wish I could be more helpful other than an atta boy.
&gt; OOP code make programs faster to do The usual reason for this is because OOP encourages you to cut corners and to make many early assumptions about the "shape" of your program. It *feels* productive to build this model. The tradeoff is that you inevitably end up with an object hierarchy which you want to unpick or change later but can't, and what would usually be a small modification becomes a huge refactoring exercise. &gt; or safer Not sure where you got this impression from. It isn't true.
I totally get it, I was bad at C++ kind of recently. I could not expect to be same level as a language I've being actively using for more than a decade, professionally, and compare it with something I toyed with 20 years ago. C is kind of "easy" to pick up language, less than 40 keywords, simple standard library. C is also simple to adapt to domain specific environments (e.g. embedded), not necessarily because the language facilitate it, but as there is already some industry agreement on how to use it. Then we have modern C++, with so many features and new programming paradigms compared to C. Can you use it for any domain specific C replacement? IMO, likely yes, but if you are not an expert on it and your industry has not reached consensus on good practices, you're going to struggle. Example, in the embedded domain, just as a C super-set, I love using C++ function templates to replace bare preprocessor macros for better type safety. But even in for that example, a naive template can be abused, if you are not familiar with either your domain or C++, you'd need expertise to "harden" the implementation to restrict it to some types or create specializations (I know I can use generics in C11, but I'd take simple templates over them any time). Having said so, use the language you can deliver the best value. 
The first rule of encryption club is don't write your own encryption algorithm, use an existing implementation of an industry standard one. But you can't do that. Are you expected to write your own AES (or whatever) code, or is just doing something super basic like xor-ing input bytes with the bytes of a key acceptable? The latter is a 5 minute project so maybe not...
I too prefer C over C\+\+, but I think pretty much all of your reasons are flawed and result of the echo chamber that exists around the rather known "language X vs Y" issue that permeates this world. The complexity difference is pretty much the only valid one, and by itself is one of the most important differences between the 2 languages. However, all of your other points are just personal bias. Tegarding when you started making mistakes, reminder that compilers \(ahem, GCC\) only started emitting friendly error messages \(as well as improving many other things\) after Clang started to get relevant. It's true that template errors still are a nightmare, and that's one of the things Concepts are supposed to pretty much solve, but as it's not the case yet, I'll give you that one. That thing you said about worst errors is actually more of a C thing than C\+\+, which inherited it for the sake of compatibility with C, so it's actually a counter\-example. C\+\+ has stricter types and casting rules than C, so that's just wrong. The debugging part is just difficult to buy because besides being wrong, pointing out that you don't have a clue of what you're talking about, it's also hard to buy the premises over which you make the complaints. For a start, you don't need many debuggers, you just need a good one, and I can assure you that it exists. GDB and LLDB are amazing, and if you need one that besides amazing is also good, you should definitely try VC\+\+'s one. Literature on debuggers being lacky is also not true. Just google for "tutorial GDB" or "tutorial LLDB" or VC\+\+, whichever you prefer. There are more, contrary to what you said, but these are the most famous and likely the most known. Another crucial flaw of this point is the failure to consider that C and C\+\+ debuggers are not separate entities. All major compilers have debuggers that debug both languages alike. The assumption that literature teaching how to program should also teach you how to debug, as well as the part you say that it's a big mistake that the same literature doesn't include such content, is also debatable. The only book I know that does this is Deitel's, but the others try to do it while keeping it to a minimum for the sake of brevity and focus. However these books do walk students over some of the most common mistakes, so again, it's hard for me to see your point here. The previous 2 points I addressed, along with you deciding to do C within C\+\+, if anything, makes it clear how biased your opinion is, how you had no idea of what you were getting into and how misguided the decision to go with C\+\+ first was, and shouldn't be taken as more than a anecdote that hopefully will be useful to those who are just starting out.
I mean, it's really up to you, what your goals are, and what resources you have available to you. I've known people to write C libraries that they then use to extend Python or Node. They did academic research in a field where engineers were not always readily available for them and with people graduating turnover was high, so having new researchers learn Python allowed them to stay productive while teaching non-programmers a valuable skill. It also benefited them because for data sets that needed more performant code they could use pure C. It's similarly useful for services you need quickly because you can boost your workforce with Python (or similar) programmers, who are more common, in order to get a base/skeleton/prototype up and running, and then you can scale up with C later. The downside of course is that this adds a lot of refactoring to your development cycle. For a lot of people that's not reasonable, because it's somewhat more complicated or they don't have as flexible of a workforce, so opting for Go from the beginning is often preferable. This is usually for people with smaller, dedicated teams for whom Go is performant enough or where a flexible workforce isn't an option. This usually takes longer to implement than Python, and isn't always as performant as a Python/C hybrid, but more often than not it knocks it out of the park and requires less refactoring. Go is also great for contract work because it self documents better than Python, with similar development time, and faster execution. The problem is that if you need more performance Go doesn't mesh super well with lower level languages and while cgo is super useful, it usually doesn't end up with increased performance. At the end of the day you have to consider what you're building and what your goals are for the project before choosing the right tool. I usually don't work with large teams, so for higher level stuff Go is great, but there are pros and cons to both styles. Moreover, there are other ways to use these languages than the structures I've listed here.
That's very interesting. Under the hood that's exactly how member functions are implemented anyway.
Read about [RC4](https://en.wikipedia.org/wiki/RC4). It's an incredible simple stream cipher that, until very recently, was the most widely used cipher in the world. You can implement the whole thing in about a dozen lines of code.
**RC4** In cryptography, RC4 (Rivest Cipher 4 also known as ARC4 or ARCFOUR meaning Alleged RC4, see below) is a stream cipher. While remarkable for its simplicity and speed in software, multiple vulnerabilities have been discovered in RC4, rendering it insecure. It is especially vulnerable when the beginning of the output keystream is not discarded, or when nonrandom or related keys are used. Particularly problematic uses of RC4 have led to very insecure protocols such as WEP. As of 2015, there is speculation that some state cryptologic agencies may possess the capability to break RC4 when used in the TLS protocol. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
My teacher said he didn't care what algorithm is used \(even if we write it\), as long as it works, the concept can be explained when we present. Though, I think it should be a level above XORing. The main point of the task is just to simulate writing a larger program than what we normally write in a group setting. I think my main issue, is just lack of experience, cause I have never done a read/write to a file in binary \(only text\), same as my group members. I assume it would just be similar to that and applying an algorithm? Also my teacher said something about accounting for the header of the file and only encrypting the data for certain formats. I'm really not sure what is expected, as long as there is proof of decent effort in the project and all members contribute.
&gt; don't write code that throws exceptions Much easier said than done. You need to throw out large parts of the standard library in c++ to not throw. You can turn exceptions off at a compiler level, but that has it's own problems (mostly: what happens if code you call throws). &gt; C gives coders the convenience of completely denying exceptions exist What? They are a C++ construct. They don't exist in C. Sure you have things with similar names provided by the OS, or interrupts if you're dealing with the hardware directly, but C++ exceptions do not exist in C.
Yeah, I have heard about it. I actually major in cyber security but I am a first time programmer, so this is all new to me.
Files are files. They're all just streams of bits. The actual content format don't matter for something like this. Just open the file in binary so that if you're on Windows, its line ending conversion doesn't screw things up, and you can use the same code for encrypting and decrypting any file type.
Writing a python frame enforced with c libraries later is a good point I didn’t consider or even know was possible. I knew that python is written on top of C but didn’t know it was possible to extend the language. Selecting the right tool requires knowing what each tool has to offer. so it looks like there is no way around learning C principles before deciding if I need that or not. and right now it seems that the consensus is that C/C++ is the ultimate programming tool, even though many other easier tools exist. In addition to that. I like tackling the most difficult part of each task first, and it seems even though learning and coding in C is difficult, it will make learning everything downstream easier 
https://en.wikipedia.org/wiki/KISS_principle for me this isn't C++ ....
**KISS principle** KISS is an acronym for "Keep it simple, stupid" as a design principle noted by the U.S. Navy in 1960. The KISS principle states that most systems work best if they are kept simple rather than made complicated; therefore simplicity should be a key goal in design and unnecessary complexity should be avoided. The phrase has been associated with aircraft engineer Kelly Johnson (1910–1990). The term "KISS principle" was in popular use by 1970. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Thank you for the help, I will give it a go throughout the week. 
&gt;Much obliged! That is a bad, really bad book to learn how to C\+\+ correctly! Get one of the Bjarne C\+\+ books and will be fine! 
Good luck learning C\+\+\(21,23,26,29,30,31,36\) lmaooooooooooooooooo!
C\+\+ = Frankstein! Rust will dump that freak PL in that trash for good! 
You mean how assembly treats data?
Functional programing is a **lot** easier in C++ thanks to it having first class functions. :)
I'm gonna start being accused of being a shill at this stage because I recommend it so often but Programming Practices and Principles by Bjarne Stroustrup, the man who made C++. It's the book that really made C++ make sense. It teaches you programming and a lot of computer science related topics and just happens to be using C++. It makes use of most of the features C++ 14 has to offer, good programming practices and above all, teaches by reinforced examples. 
Yep, writing the code doesn't need to be excited, it needs to be correct. Designing your code well and using good external libraries are much more important than a choice in language. You can easily write bad code in any language.
Thanks, I never spell it right.
I'm curious about Ada, think I'll give it a try.
...which is why C gives coders the convenience of pretending that they don't exist, because they're not a thing in C. I'm trying to figure out how you construed what I said as meaning that they do exist in C.
C and surprisingly Scheme let me think in smarter way using simple tools to achieve great effectiveness! While that, all those complex PL will restrain you from thinking as you have to learn, learn learn learn.....
nah nah nah nah!
I feel the same way. For me I think it's because member functions really belong to a class, not an instance of a class, but `instance.function()` feels more like the function is a property of the instance. The function is going to be the same for all instances, the only difference is which instance gets passed as the this pointer.
Simplicity is best. :)
It sounds like you want to open the file in *append* mode with `"a"`. *Appendix B1.1* in *"The C Programming Language (Second Edition)" by Kernighan and Ritchie* discusses the various mode strings accepted by `fopen()`.
I think that far too many people view C++ as a foolproof language. In any language you're writing, it is essential to know what's happening behind the scenes. Black boxes are alright later on in group projects, but terrible when starting out. I had my fair share of terrible computer science professors and let me tell you, 9/10 times the biggest issue was that they didn't want to go into the "why". My favorite computer science professor taught C as well as C++, and in his introductory C++ class we were given specifications for a class in the STL and rewrote it in our own way before we were allowed to use the STL version. We also had to fully understand C before ever moving on to C++. It's far too dangerous to go into C++ without understanding the basics. Just look at the number of people who use the cmath pow function to do a^2, not knowing just how inefficient it is compared to a*a. or people who use vectors (without initially resizing) instead of arrays when taking a set number of elements. not considering that for a vector of 100 elements starting at the default size and only resizing using the push_back function you are going to be allocating a new array, copying all the information, and freeing the old array 7 times. when it could have been done 0 or 1 times. Honestly, think about it like art. Photoshop has some built-in tools and luxuries that make things easier to manipulate and organize, but you're going to have a damn hard time if you don't understand drawing with a pencil and paper first. What you're doing may also have very flawed composition problems with over the top shading to try and compensate. And some people are always going to prefer traditional art. I don't think C is inherently better than C++, nor do I think the opposite. They both have their benefits and disadvantages. My best advice would be to not pass by any black box while you're learning. If there are any functions that you're only understanding as input and output, look deeper. Make sure it's the most efficient thing to use. An example that is absolutely everywhere is pre-increment vs. post-increment. Did you know that i++ takes the slightest bit more processing power than ++i? insignificant with integers, but what about incrementing user-defined objects? what about a few thousand objects? What if that slight difference is multiplied by the number of pixels being updated in a single frame? Programming for video games, especially engines, is without a doubt the most unforgiving as far as efficiency. That's why working in C to start with may be the best bet. 
A function pointer holds the address of a previously defined function, which can be stored in a variable, passed to a function, and called. Pretty useful - you can't have generic functions like `qsort()` or `bsearch()` in C without them, but limited because the actual function has to be defined at compile time at top level. Lambdas, on the other hand, can be defined at point of use, increasing readability and convenience for small functions, and are created at runtime, with access to values only known at runtime, making them way more flexible. For a contrived trivial example, consider a map-like operation - updating the values in an array to the result of calling an arbitrary function on the old values. In C, it'd look something like this: void map(double *arr, int len, double (*f)(double)) { for (int n = 0; n &lt; len; n += 1) { arr[n] = f(arr[n]); } } double square(double x) { return x * x; } double cube(double x) { return x * x * x; } // ... later map(arr, len, square); map(arr, len, cube); whereas in C++ it'd look something like: std::transform(std::begin(arr), std::end(arr), std::begin(arr), [](double x){ return x * x; }); std::transform(std::begin(arr), std::end(arr), std::begin(arr), [](double x){ return x * x * x; }); or making it more generic to demonstrate binding values: double n = some_other_function(); std::transform(std::begin(arr), std::end(arr), std::begin(arr), [n](double x){ return std::pow(x, n); }); 
Had a good sleep and see if I can finish today, ill send you a DM if i need anymore questions! THanks 
Start here - http://www.charlespetzold.com/code/
&gt; I finally figured out why Mr. Torvalds doesn't like C++. I think when Torvalds argues against C++ he's limiting his scope to the OS. Even he (and team) ported subsurface from GTK to QT.
&gt; you will inject bugs into your program due to weak typing and raw pointers being passed around. No I won't. Don't place your weaknesses onto others. 
Great talk. This summarizes zero cost abstraction pretty nicely. Less code means less time coding and debugging while getting a highly optimized binary that can run on anything.
It's often easier to reason about numbers when written out in base 16 than it is with base 10. If you have, say, `uint16_t x = 0xFF00;` you know that the upper 8 bits of x are set, and that same pattern applies no matter if it's 0x00FF, 0xFF0000FF or whatever. Compare that to memorizing a bunch of decimal numbers.
It’s almost like calling a member function is a request rather than a demand, if that makes sense. Sort of like, “hey car, go get washed” instead of “hey car wash, here’s a car, deal with it”. Like I said, hard to explain why that paradigm feels right to me. I’m one of the few where I work that prefer C. C++ is getting a lot more attention these days for optimization. Although, aside from the C/C++ debate, I was recently criticized for making heavy use of #define to drastically increase performance of an algorithm. I believe they said “you may be guilty of pre optimization, the compiler knows better than you do.” My code was unreadable, if you didn’t read the comments directing you to the headers which documented the algorithm quite well, but it was over 150x faster after averaging 1 million iterations compared to function calls. And since my target platform was much less powerful than a desktop PC, it matters quite a bit. 
Yeah it's that the first language I learned was javascript, which the only time I was declaring stuff was either to numbers or manipulating the DOM. So after taking my first embedded class I noticed we were shifting with hexadecimal. I just don't completely understand why we are using this method instead of maybe trying to use just the number 1 to 5. idk if you completely understand my question but any insight helps lmao, I might just be confusing two things completely as well
The answer is because you're frequently examining things on the bit level. You might be using a bit vector, or looking at a flag register. Using hex, as others said, makes it easier to reason with bits. 
Hex encodes more data in less space than binary or decimal.
Usually computers work at lower level with something called *word* or *byte*, which in most systems mean 4 bits. Now with 4 bits you can represent 16 numbers (0-15) so it's easier to work with base 16 instead of using 4 bits all the time. Some examples: Bin Hex. Decimal 0000 0010 = 02 = 02 1001 0110 = 96 = 150 1110 1101 = DC = 220 1111 0001 = F1 = 241 See how each byte maps neatly to a single hex digit? Once you get the hang of it, you can easily convert from hex digit to byte in your head. Now try to go from the decimals to each byte, it's much harder.
In which Systems (most?) is a byte 4-bits?
&gt; want to learn low level language c vs go https://sqlite.org/whyc.html &gt; Safe languages insert additional machine branches to do things like verify that array accesses are in-bounds. &gt; Safe languages usually want to abort if they encounter an out-of-memory (OOM) situation 
Or you're setting some memory register value which has various bits that mean different things. You might not be operating on the value in your code, but the underlying system might be.
The main difference is that C++ lambdas can have state. In fact, if a lambda doesn't capture anything, it can actually decay into a function pointer. Here's an arbitrary example I just made up: let's say we want to sort a list of strings based on the nth character. We can create a function that will be passed to `qsort` like so: int n; int compareNth(const void *p, const void *q) { char* l = (char*)p; char* r = (char*)q; return l[n] - r[n]; } //... n = 3; qsort(list, list_size, sizeof(char*), compareNth); (Caveat to all examples: I didn't compile or test anything, so forgive any mistakes.) Notice that we had to use a global variable in order to represent the state `n`. Given our interface to `qsort` (raw function pointers), that's literally the only choice we had. It works, but everyone here knows the problems with global variables. Let's say we could change `qsort` so it could take a state variable. We could then write: typedef struct { int n; } state; int compareNth(const void *p, const void *q, const void* s) { char* l = (char*)p; char* r = (char*)q; state* st = (state*)s; return l[st-&gt;n] - r[st-&gt;n]; } state s { 3 }; qsort_stateful(list, list_size, sizeof(char*), compareNth, &amp;s); (A `struct` isn't strictly necessary, but imagine you need more than just a single `int` as state in a more complex example). As you can see, it's totally possible to get the same result from C without resorting to global variables ... but look at the equivalent C++: int n = 3; std::sort(std::begin(list), std::end(list), [n](const char* p, const char* q){ return p[n] &lt; q[n]; }); In the end, this is more or less doing the same thing as the manual C version, creating a struct to hold the state. Because we're dealing with templates, though, we don't have to cast back and forth from `void*`, and everything is much easier for the compiler to inline. The comparison function is defined directly where it is used, which is very helpful with short functions like this. It's just a couple lines of short, powerful code.
You might not even be doing bitwise manipulation, but it helps show intent. I'll use decimal for counting things, like 'for (x = 0; x &lt; 10; x++)', but I'll use hex if that same loop is using memory addresses. Use decimal for things that make sense in decimal to humans, and hex for things that hex makes clearer. And fun (or maybe just pedantic) bonus fact - 0 in C is an octal number, since it begins with 0. Not that it makes any difference to anything. Whenever you have more than one way to do something that comes out exactly the same to the compiler, try to choose the one that most clearly shows what you're trying to accomplish.
&gt;That thing you said about worst errors is actually more of a C thing than C\+\+, which inherited it for the sake of compatibility with C, so it's actually a counter\-example. C\+\+ has stricter types and casting rules than C, so that's just wrong. I think it's funny how often that's true. The worst criticisms of C\+\+ are often directly a result of its C compatibility. It would be a much more simple, cleaner, robust language if C weren't its starting point. On the other hand, it wouldn't have been nearly so popular, either. We should keep in mind that C definitely has its own faults; any language that maintains near complete backwards compatibility with C will inherit every single one of those problems, and layer on top its own. And it feels sometimes like there's an O\(n^(2)\) relationship there.
I've been working with Ada a lot recently. I haven't been impressed, to be honest.
I would recommend looking into the LLVM bytecode instead. It's significantly more accessible and will show you exactly what the compiler \(well, clang at least\) is doing internally.
fucking lol'd
&gt;&gt;We’ve been doing segments since the 1960s and by the 1980s fragmentation drove every major implementation to segments over pages over a flat memory array. Only thousands of concurrent segments and segments of only 4GiB were both major limitations by that time as well. They don’t scale in any dimension. &gt;Yes, I'm aware of that. This is a flaw that was brought about by popular OS and language paradigms. Segmentation could have easily scaled. In fact, Intel tried to make it happen with the iAPX 432 processor. You would have known this had you read the links I posted, but you evidently did not. I didn't need to read an article about an architecture with which I am already familiar. I also know that you have to look at the letters as well as the numbers when comparing 64KiB to 4GiB. You've clearly read these limits and assumed because the first has the digits 64 it's bigger than the 4, but it's not. This is why 4GiB segments being too small isn't solved with data segments which top out at 64KiB. &gt;&gt;As for sequential languages, FORTRAN, PL/I, COBOL, Pascal, C, APL and many others have run fine on flat/paged and segmented machines as well as byte addressable and word oriented machines, making the original article’s noise about sequential code being only a C thing nonsense and the BCPL commentary of being only word oriented self contradictory. &gt;He's not saying that C doesn't run fine; he's saying that it's not low-level. Just like APL, Pascal, etc. are not considered low-level. BASIC is a sequential language, but not considered low-level. Same thing with Ruby, which can hardly be called low-level or non-sequential. The subtitle is "Your computer is not a fast PDP-11" and states "It's easy to argue that C was a low-level language for the PDP-11" which say you're wrong. "You would have known this had you read the" article. The fact is with octet level addressing, easy direct or chained operations for 8, 16, 32 and 64 bit operations and 2's complement math your computer is far closer to a PDP-11 than the GE600 series on which C and Multics ran because C wasn't tied to these hardware limitations even before the seminal 1978 K&amp;R was published. Any language that could run on a 16-bit octet addressable machine and 36-bit word oriented machine and which would allow for some reordering of operations (the order in which function parameters are evaluated for example) demand both implementation defined and unspecified behavior which other high level languages did. As for Pascal, it may not be considered low level but everywhere I've seen it used it was used to create self modifying code. Too many stereotypes, too little understanding. &gt;&gt;There have been plenty of custom parallel processing systems without shared memory on the order of tens of thousands of processors coded in C as well and that perform far better than off the shelf large general purpose systems. Those custom systems would be completely useless on a wide range of general purpose problems which is why the general purpose computing world has worked to make sequential processing as fast as possible. Even in the 1960s memory bandwidth was an issue which is why some systems could read 32 words each memory cycle. Caching is great for small data sets or computation with great locality of reference but for big random data it’s always going to be memory bandwidth that rules the day. &gt;I don't really get how this is relevant to what I said. You asserted "Segmented memory is ultimately what we're trying to achieve will all of this juggling and mess with caches." The visible functionality of caching which is to improve apparent memory bandwidth and latency under limited circumstances **has nothing to do with virtualizing memory.** Segments, pages, or paged segments are all layered over a shared physical memory with all the performance and concurrency issues that a system without VM would have plus a bunch more that are unique to having these address translation layers. The ultimate problem for general purpose computing with multiple processors with shared memory is memory bandwidth and latency which aren't caused by C nor solved with segments.
Kind of ironical, pointing out others' code being illegible then not structuring the complaint.
The main reason I've seen is that you're using a variable not as an integer value, but as a series of binary or hex digits that represent something else. For example, if you have a 32 bit unsigned int you are examining as 8 different elements with possible values from 0 to 15, it's going to be a whole lot easier to think of the data in terms of hex rather than decimal. In this example, if we were to look at a variable like 0x00002001 or 8193, and you're going to add one to the 5th element... well, it's going to be a hell of a lot more intuitive to add 0x0001000 rather than 4096. same with examining a certain element. Various bits of the same register can mean vastly different things in a system, so human readability is important. Another reason that is coming to mind is with stepping through memory. You'll notice that a lot of variable types are either 2 or 4 bytes. The human brain finds it a whole lot easier to follow stepping through memory by 1 or 2 than by 16 or 32. For example, in hex stepping through ints in a system where they are 2 bytes long, you're looking at 0x00000010, 0x00000020, 0x00000030, etc. In decimal 16, 32, 48, 64, etc. Both are just as easy for the computer, but the decimal is not very nice for the human. Especially as the address gets larger.
&gt; I didn't need to read an article about an architecture with which I am already familiar. I also know that you have to look at the letters as well as the numbers when comparing 64KiB to 4GiB. You've clearly read these limits and assumed because the first has the digits 64 it's bigger than the 4, but it's not. This is why 4GiB segments being too small isn't solved with data segments which top out at 64KiB. Who crapped in your cheerios, buddy? No, I did not misread the sizes. The iAPX 432 was Intel's first ***32-bit*** processor. Those figures of 64KiB per segment with 2^24 segments was actually significantly more impressive back in the 80s. We did not have 4GiB per segment back then. That would have been ludicrous. But I guess you *still* wouldn't know that since you *still* aren't reading anything I'm posting and you're just full of yourself. &gt; The subtitle is "Your computer is not a fast PDP-11" and states "It's easy to argue that C was a low-level language for the PDP-11" which say you're wrong. Umm... no, that doesn't say I'm wrong. &gt; "You would have known this had you read the" article. The fact is with octet level addressing, easy direct or chained operations for 8, 16, 32 and 64 bit operations and 2's complement math your computer is far closer to a PDP-11 than the GE600 series on which C and Multics ran because C wasn't tied to these hardware limitations even before the seminal 1978 K&amp;R was published. Any language that could run on a 16-bit octet addressable machine and 36-bit word oriented machine and which would allow for some reordering of operations (the order in which function parameters are evaluated for example) demand both implementation defined and unspecified behavior which other high level languages did. C didn't run on Multics until c. 1986 ([source](http://multicians.org/mgc.html), [source](http://swenson.org/multics_wiki/index.php?title=Multics_C_Compiler#A_Very_Old_C)). It most certainly had some certain hardware limitations before K&amp;R was published, and even somewhat afterwards. All of the fancy details you're expounding on there basically boil down to nothing. It doesn't matter that the PDP-11 is closer to modern hardware than the GE-600. That's a no-brainer and the point of the original article which this thread is all about. Modern computers have been made to conform (more or less) to that old model to compensate for laziness and deficiencies in the choices of OS developers and language choices. &gt; As for Pascal, it may not be considered low level but everywhere I've seen it used it was used to create self modifying code. Too many stereotypes, too little understanding. I'm not making any statements about Pascal other than that it's not considered low-level. No stereotypes or misunderstanding is coming from me, unlike what you're implying. &gt; You asserted "Segmented memory is ultimately what we're trying to achieve will all of this juggling and mess with caches." The visible functionality of caching which is to improve apparent memory bandwidth and latency under limited circumstances has nothing to do with virtualizing memory. Hmm, ok, now I get what you're saying. Yes, caching does help with memory bandwidth issues. I should have explicitly said *paging,* instead of caching which has essentially supplanted segmentation. Paging was a large motivator for caching, not just memory bandwidth issues. It had a become a crutch for the modern paradigm. This is talked about in the articles I link to as well as OP's article. &gt; Segments, pages, or paged segments are all layered over a shared physical memory with all the performance and concurrency issues that a system without VM would have plus a bunch more that are unique to having these address translation layers. The ultimate problem for general purpose computing with multiple processors with shared memory is memory bandwidth and latency which aren't caused by C nor solved with segments. It's not *caused* by C, but it is largely perpetuated by it. It is not *solved* with segments, but a segmented model would make it stop being such a crutch for paging. This crutch is what caused Meltdown and Spectre, since Intel was really just trying to enhance the crutch, but they enhanced it too much which caused security vulnerabilities.
Rock! ✊ I lose
```B0 = 1``` means B0 gets the value 1 ```B0 = 0x01``` means B0 Lowe’s it gets sets to 1 So, both are compiling to the same instruction, but are conveying a different reason to the human reading the code. In embedded system, you often work with hardware, so,you often have to understand the it pattern of values, and end up using hex. Note that the connection may not be as direct as bit-to-bit. For instance, you could see something like ```unsigned i = 0xff;``` to convey that i contains the maximal number that can be stored in an unsigned char (8 bits set to 1), instead of ```unsigned i = 255;```
For your first program: you say you want to sort shapes (colored rectangles?) in ascending order. First you need to figure out what the ascending order on shapes is and then you can implement your choice of [sorting algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) using your ordering when comparing elements of the array you're sorting. If you're allowed to use the standard library without restrictions, have a look at [`qsort`](https://linux.die.net/man/3/qsort). -------- For your second problem, after going through the warnings the compiler gave me (you're compiling this with at least `-Wall`, right?), I noticed some obvious problems in `read_CreditNumber`: 1. When you use %f as format specifier in scanf you tell scanf "try to read a floating point number". This is unnecessary, as you will never have a floating point number that's part of a credit card number. 1. You seem to expect to read the credit card number digit-by-digit, this will only work if your input has the digits separated by whitespace. 1. In `read_CreditNumber` you read the input into the `value` array, but later you check the `CreditNumString` array, which is never initialized, so your string-&gt;int conversion won't work correctly either. From your description of the runtime behavior it sounds like your program waits for you to enter a second (and third, etc) floating point number in the first loop in `read_CreditNumber`. The next big issue with the code is that you're calling `Sum1` with `&amp;LuhnSum` as the argument, while the implementation of `Sum1` expects the credit card number array as argument and returns the sum. The same goes for the call to `Sum2`. The last big issue is that throughout the implementation, it is not clear where you expect the check digit to be in the input. Do you expect `CreditCardNum[0]` to be the check digit? The way `read_CreditNumber` is written, the check digit will be in `CreditCardNum[19]`. Finally, taking a step back, you should really read [this article](https://stackoverflow.com/help/how-to-ask) to make your questions easier to understand. In that vein, none of my cards (VISA/MasterCard) has a 20 digit number, so please include a 20 digit number that should pass the check and one that should fail the check, so others have a chance to test your code, i.e. post what amounts to a [minimal, complete, and verifiable example](https://stackoverflow.com/help/mcve).
**Sorting algorithm** In computer science, a sorting algorithm is an algorithm that puts elements of a list in a certain order. The most-used orders are numerical order and lexicographical order. Efficient sorting is important for optimizing the use of other algorithms (such as search and merge algorithms) which require input data to be in sorted lists; it is also often useful for canonicalizing data and for producing human-readable output. More formally, the output must satisfy two conditions: The output is in nondecreasing order (each element is no smaller than the previous element according to the desired total order); The output is a permutation (reordering but with all of the original elements) of the input. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Thank you! I don’t know why I didn’t think of that, it’s just when I see math problems with coding it goes over my head easily 
When dealing with microcontrollers you're frequently dealing with bit-level operations. Now, a number is just a number, regardless of the base you're working in, the computer doesn't care. You though, care. It's about making things easier for you, the programmer. Imagine you're working on a microcontroller with 16 I/O lines, and you want to know if bit 14 or bit 5 are set, in pseudo code: if io_pins AND 0b10000000010000: print hit binary! if io_pins AND 040020: print hit octal! if io_pins AND 0x4010: print hit hex! if io_pins AND 16400: print hit decimal! The binary is hard to read because there's no grouping, did I put exactly the right amount of 0's in there? The decimal I'd have to break out a calculator to be honest, I just can't quickly convert that in my head. Octal is grouping the bits into threes... `100 000 000 010 000` Hex is grouping the bits into fours... `0100 0000 0001 0000` Decimal isn't grouping the bits at all. Programmers learn the 16 bit patterns for the 16 digits of hex, and from then on can very quickly read the hex into bits in their head. The grouping is easy to see, it maps well to the size of a byte (2 hex digits == 1 byte) and words. So it turns out that hex is a very nice representation that maps well to the physical side of the device (button on pin X, button on pin Y goes to bits X and Y of io port Z). It maps well to the size of the bytes and words in the CPU itself, to memory locations. As you learn and get used to it you start to read things quickly and prefer it for things like memory locations. It's why things like on a Commodore 64 often games started with SYS 8192 or SYS 49152 (start at the 8KB boundary or 48KB boundary). From a hardware point of view those are very easy numbers. From a hex point of view they're easy (0x2000, 0xC000) numbers. They just look harder to read in decimal.
For me there are two aspects: 1) it’s easier for me to see bit patterns in hex than in decimal (where it’s close to impossible — consider 3855 vs 0x0F0F). 2) it is a form of comment that shows that the coder knew how many bits he’s changing/setting. For example the C line of code that says _uint32 reg1 = 0xFF;_ would bother me and make me figure out why the coder used only one byte notation. In contrast, _uint32 reg1 = 0x000000FF;_ makes sense and shows consideration to the actual hardware. I don’t think I’ve seen anyone use hex to save ASCII characters except perhaps in transferring a binary file using ASCII, but even here BASE64 is better. I’d be a little concerned about someone that gave that as a reason in source code (do they skip commenting their code for this reason too?).
I promise you, that wasn't the intention. Copy-Paste error. Sorry.
&gt; For the C code base, do you happen to have any GitHub repo URLs which provide useful examples? I don't know of any GitHub C only repo's using gtest but you can search [here](https://github.com/topics/c?l=c), I'm sure that there's some framework. [CppUTest](https://github.com/cpputest/cpputest) is also nice and you can check its repo to see how they run tests for their framework. I don't have a personal repo on GitHub.
I would assume the second as the size is allocated at compile time as opposed to run time.
You've got some dangerous stuff going on in your code (scanf("%s") not checking the bounds), but that's another question.... All other things being equal, the second will be more efficient. For indices i and j, in the first struct layout, `arr[i].ch[j]` will require two memory load operations (and with effectively no spatial locality of reference: they will almost certainly be on different cache lines). In the second struct layout, it will require only one memory load operation.
Really depends on your target architecture. In some cases the third option, doing it with a single malloc(), would be the better choice... but it depends entirely on the target environment. Statically allocated RAM might in some cases just be slower, so using malloc’ed RAM might cost startup time but be better at runtime. I’m thinking DSP’s with compilers that put static RAM in one bank and have a smaller DRAM for heap.
The first version makes less efficient use of memory, storing both a pointer and the string itself, and with more fragmentation. But it potentially supports arbitrarily long (and short) strings. The only limitation is how you're reading them. | ptr | ptr | ptr | |ssssss0| |sssssss0| |ssss0| The second is more efficient — there's no pointer involved in their storage — and all the strings have compact, automatic allocation. But they're strictly limited to a maximum length of 9. |sssssssss0|sssssssss0|sssssssss0| 
Engering data directly in binary is far more painful than with hexadecimal. Try it.
Load the core dump into gdb and have a look.
The problem with these types of errors is that there is no defined behavior. Null pointer dereferencing doesn't have to cause a crash, after all it's a real location in memory on most systems. Most operating systems are just nice enough to trap access to the zero page. Some systems may just map invalid addresses back into valid address space. Same with stack smashing, buffer overruns, etc. It might cause a segfault, it might run just fine by pure coincidence, or it could play Bethoven's 9th. Undefined behavior. To understand those types of runtime errors you have to look at the operating system and the architecture. 
Most of those things are platform-dependent. I never get segmentation faults, because all of my C programming is on systems without MMUs - and thus no segmentation. Stack overflows are not intrinsically detected by the language and take some extra work to detect.
Long ago I worked on a system that not only didn't have an MMU, it didn't generate a data ready signal if you accessed memory that didn't exist. That left the processor in a hung state that you couldn't recover from without resetting the whole system (and no way to know where that was). Ah, the good old days!
There's an important distinction to be made between C code in abstract and code executed on a real life processor. In abstract C, if you dereference a NULL pointer, it's undefined behaviour. This means that literally anything could happen - even demons can fly out of your nose. If you dereference a NULL pointer on a processor... well, it depends on a processor and an exact setup. For example, on x86 linux, you program will receive a segfault signal. Processes can receive a lot of different signals, some of them indicate an exceptional condition (SIGFPE, SIGSEGV, SIGBUS, ...). For more info on signals see [man 7 signals](http://man7.org/linux/man-pages/man7/signal.7.html). Some errors (like "stack smashing detected") are caught not by the processor, but by the program itself. For example, if the stack gets corrupted, the program will detect it, print an error message and kill itself. These types of checks are added to your code by the compiler, so you need to read the compiler docs. For example, gcc adds stack protection with option `-fstack-protector` (which is enabled by default). [Here's gcc's docs](https://gcc.gnu.org/onlinedocs/gcc/Instrumentation-Options.html).
&gt; CDC 180 series machines were 64-bit processors with 4GiB segments. They were too small for some applications. Earlier you replied to my original reply which included *Only thousands of concurrent segments and segments of only 4GiB were both major limitations by that time as well.* You might want to read up on how Multics used the term "single-level store" for more perspective here. Yes, I understand that these systems often used caching along with segmentation. I didn't think I had to spell this out for you, but apparently I do: I know that paging and segmentation were used together in Multics, the CDC, and other older systems. Nowadays we use paging exclusively. It is a terrible mistake and we're paying for it with things such as Meltdown and Spectre. Not to mention many other messes. Have you read the CDC manual, by the way? They used segmentation explicitly for security. Multics and the CDC *only* used pages for the storage allocation problem. This is detailed in the Multics paper on virtual memory and the CDC manual. &gt; "It's easy to argue that C was a low-level language for the PDP-11" and "he's saying that it's not low-level" are opposing statements. No, they aren't. What's low-level for one machine is not necessarily low-level for another. This is demonstrated thoroughly in OP's article. &gt; "...Windows, on which Word and Excel ran..." Does that mean Word ran on Excel? No. The original 1978 K&amp;R not only addresses the fact that C already ran on the GE600 series machines and also covered some less understood features of the language like why character pointers may not be the same size as other pointers (in the case of the GE machine an 18-bit pointer would get you a word but you still needed more bits to identify an individual character hence a character pointer on that machine was 36-bits long.) But was C running on Multics on the GE-600 or on GECOS? Again, it seems that a C compiler didn't exist for Multics until about a decade after K&amp;R. &gt; 15 years ago on a modern single core microprocessor one could retire many instructions in one cycle but a memory cycle required 200 processor cycles and even the first level cache took multiple processor cycles to return a value. These are limitations of physics, not C, and if you abandon caching, parallel execution units, speculative execution and a host of other techniques to improve the performance of a general purpose system a new language and OS isn't going to get that performance back. The options of adding more processors still adds more cost and complexity and doesn't solve the serialization problem and going with separate isolated memory arrays per processor is a no-go for tasks requiring a lot of shared memory (there is a reason we have tightly coupled MIMD systems in the world.) 50+ years of research on parallel processing hardware and software has provided many awesome but narrowly usable solutions but it's no where near solving the general usage case, and it's not for lack of trying. You ignore what I said yet again. The issue with memory bandwidth / latency wouldn't be so bad if we weren't using paging as such a crutch. You still seem to be ignoring everything I'm saying in favor of rehashing what you already believe. &gt; I keep seeing platitudes like "laziness and deficiencies" but no one from the original article author to any commentator in the larger set of threads has provided a general purpose solution for all the tasks which can be performed by a high end x86_64 box which is always significantly cheaper and faster. With over a trillion in IT spending each year there is clearly incentive to come up with a universally more cost effective solution. Nice job, you made me chuckle. A trillion in spending in *anything* does not indicate incentive to come up with a universally more cost-effective solution. It means that some people are bathing in money and solutions don't bring more money to your pocket; continuation of the problem does. This can also be seen in the medical industry as a prime example, or the energy industry, both those are rather tangential to this discussion. &gt; Segments without paging with the single-level store model of Multics, NOS/VE (CDC 180) and others simply won't work with modern data sets. It's also a disaster with frequent (OS level, not just process level) segment creation or resizing as fragmentation can mean lots of large memory moves or swapping. These are why every sane segmented memory system ultimately supported paging underneath. Paging without segments still provides both process isolation and a means to provide limited sharing of memory between processes. Paging does an inferior job to segmentation, especially for security purposes. &gt; Paging can also provide access controls but it doesn't give you that nice top bound of a segment, but that bound comes at the cost of having a fixed hardware tradeoff between number of segments, data per segment, and all the additional overhead it introduces. This is orthogonal to memory caching which had to do with the fact that memory couldn't feed even a single CPU with enough data to keep it busy. Caching wasn't possible until extremely fast (which also means very small relative to main memory) memory became cost effective. Really old mainframes and supercomputers without cache made up for this for a time with massive memory buses but it just couldn't scale. No, it isn't orthogonal to memory caching. Memory caching was implemented in modern CPUs largely to make the flat memory address space seem fast, on which paging is dependent. From Wikipedia: &gt; The early history of cache technology is closely tied to the invention and use of virtual memory. Because of scarcity and cost of semi-conductor memories, early mainframe computers in the 1960s used a complex hierarchy of physical memory, mapped onto a flat virtual memory space used by programs. The memory technologies would span semi-conductor, magnetic core, drum and disc. Virtual memory seen and used by programs would be flat and caching would be used to fetch data and instructions into the fastest memory ahead of processor access. Extensive studies were done to optimize the cache sizes. Optimal values were found to depend greatly on the programming language used with Algol needing the smallest and Fortran and Cobol needing the largest cache sizes. &gt; The checks are correctly performed on non-speculative execution which means all the data is available (though not necessarily as timely as one would like) to perform the same checks on the speculative references. This was people (very likely spread across many independent design teams) not thinking the problem through, not a fundamental limitation of either paging or C. The fact that we could once allocate/extend files on many OSs and absorb other users' abandoned data because the OS neither zeroed the data on disk nor simulated zeroing on read isn't the fault of disks. Many people at many companies who wrote this breakage didn't think the problem through, security folks found the problem and the companies were ultimately forced to fix it. The problem is not a *fundamental limitation* of paging or C; it is a natural result. Hey look buddy, this debate has been fun and all (not really), but I don't really have time to keep debating you about this. You can keep replying, but I'm not going to reply back since I've got work to do and this is going nowhere fast. You won't read anything I'm saying and you're just interested in pulling out random factoids, many of which aren't important or even that relevant to my original point.
I will have been working in embedded development for the last 40 years as of September. The system I was talking about was a custom 68000 board in the late '80s. It had an ["aircraft carrier" 68000](https://i.imgur.com/BHp8mkg.png) on it. The chip select decoding was a little lacking which is what caused the problem I mentioned.
IMHO, the following (third) option has a number of advantages: - the type name is distinctly different than possible variable names (by using a postfix type identifier). I use `_s` for structs but some people use `_t` (for types). Note that `_t` is reserved and strictly speaking should be avoided. - It minimizes fragmentation by using a single `malloc` call and a [flexible array member](https://en.wikipedia.org/wiki/Flexible_array_member). A similar solution, pre-C99, would use a pointer that points to the end of the struct. FYI, it's possible to create a similar Stack oriented solution. typedef struct { size_t len; /* length */ char data[]; /* flexible arrays point to the end of the struct */ } string_s; /* note the _s postfix that identifies this as a struct type */ /* a use case sample */ string_s * string_new(char * data, size_t len); { if(!len) { return NULL; } /* single malloc call for container and data */ string_s *str = malloc(sizeof(*str) + (len sizeof(char))); if(!str) { return NULL; } str-&gt;len = len; if(char) { memcpy(str-&gt;data, data, len); } return str; }
**Flexible array member** Flexible array member is a feature introduced in the C99 standard of the C programming language (in particular, in section §6.7.2.1, item 16, page 103). It is a member of a struct, which is an array without a given dimension, and it must be the last member of such a struct, as in the following example: The sizeof operator on such a struct gives the size of the structure as if the flexible array member had been omitted except that it may have more trailing padding than the omission would imply. As such it is preferable to use offsetof when determining size for dynamic allocation, as in the following example: When allocating such structures on the heap, it is generally required to reserve some space for the flexible array member, as in the following example: When using structures with a flexible array member, some convention regarding the actual size of that member should be defined. In the example above, the convention is that the member arr has len double-precision numbers. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
That and also it's easier to reason about a lot of stuff (memory addresses, bit-flags, etc) when you see them in hex, than in decimal. For example, if I see `FFFFF800882FCD7D` I know that it is a kernel VA (on an x64 Intel/AMD), if I see `-8793808188035` I know nothing. 
Are you sure about `0` being octal? Pretty sure most (if not all) C parsers define octal numbers as `0[0-7]+` not `0[0-7]*`. Although obviously I could be wrong about that.
You can use [GTK+](https://www.gtk.org/), which uses C.
Paper is like old books, we call it samua and is lightweight 60 gsm, and feels good to read it 
This was the book my uni used. Still have it
QT
Does GCC have that kind of tool too? 
What's the story with that back cover?
I think so, but I've never used it. Look into RTL to get a start.
This, and in embedded systems, you can use 2 seven segment displays to display an 8 bit integer, or 4 for an 16 bit integer.
yeah it's technically an octal number. A decimal constant begins with a nonzero digit and consists of a sequence of decimal digits. An octal constant consists of the prefix 0 optionally followed by a sequence of the digits 0 through 7 only. A hexadecimal constant consists of the prefix 0x or 0X followed by a sequence of the decimal digits and the letters a (or A) through f (or F) with values 10 through 15 respectively
That's a very good point. That's the ultimate in limited display capability, a hardware 7 segment display. A lot of conventions in computing got their start because computers used to be very limited in capacity in every way, and workarounds made working with them easier or cheaper. 
We used to call the first edition "The Old Testament" and the second edition "The New Testament". They also existed in hardback.
I have the one my father used at university and I use it at the university too! https://imgur.com/a/ezr45kI
How can you be so sure of that? Even the best C programmers screw up once in a while. And even if you really never do, a team member would someday. I'm not a fan of C\+\+ but I do think it's probably better in this regard.
I made it 😀 
I guess the question was: why did you put Ken Thompson there, but not Brian Kernighan?
don't forget there are 10 types of people in the world, those who understand binary, and those that don't..... everything on a computer, no matter how complex is basically a whole bunch of binary operations, heaped on top of each other, to make something more complex and seemingly none binary. as previously mentioned hex is just a more human friendly way to represent numbers each digit being 4 bits, "after a while you stop seeing the matirix...." in fact we should just do away with this silly decimal, tech kids their 0x0e times tables....
Thankyou ill have a look again and try again The tutor wants us to be able to enter 20 digits in, but can be 16
Thankyou, ill have a look again. And no we have to use MSYS to compile
No problem, I'm in the same boat. It always takes me a while to decipher what these types of questions are asking for. 
This looks great, but is it.. illegal?
As long ad he doesn't make money out of it I think it's not illegal
I'd start by writing a function that reads an integer, or the next non-whitespace character from `stdin`. int rdtoken(int *p); It could return a digit character (such as '0') and store the computed integer in `*p` if a decimal value is presented, otherwise simply return the next character that was read. The rest of the program should fall into place easily once that first part is worked out. :)
Thnx, I'll get back to you in the morning after I try it out 
So how will your code figure out when all the digits have been entered? Maybe see [this thread](https://www.reddit.com/r/C_Programming/comments/8j2wiu/help_with_an_assignment_question/) for an alternative on how to read in card numbers (I'm assuming that's the same assignment).
MSYS is gcc for Windows (this is an oversimplification), and has all the usual flags, but without knowing how you're using MSYS it's hard to say where and how you have to specify the flags. Generally, on the command line you would do the following to run gcc with `-Wall`: gcc -Wall -o program program.c
Thank you! Ill try it with -Wall in class we are told to run the program as "gcc -o run program.c"
Fair warning: don't expect -Wall to magically fix all your problems, but it may tell you more about potential issues in your code: Compare u@:~/src $ gcc cc_luhn_orig.c cc_luhn_orig.c: In function ‘main’: cc_luhn_orig.c:112:12: warning: format ‘%d’ expects argument of type ‘int’, but argument 2 has type ‘int *’ [-Wformat=] printf("Credit Card number is: %d",CreditCardNum); ^ with u@h:~/src $ gcc -Wall cc_luhn_orig.c cc_luhn_orig.c: In function ‘main’: cc_luhn_orig.c:112:12: warning: format ‘%d’ expects argument of type ‘int’, but argument 2 has type ‘int *’ [-Wformat=] printf("Credit Card number is: %d",CreditCardNum); ^ cc_luhn_orig.c: In function ‘read_CreditNumber’: cc_luhn_orig.c:40:1: warning: control reaches end of non-void function [-Wreturn-type] } ^ cc_luhn_orig.c: In function ‘main’: cc_luhn_orig.c:128:7: warning: ‘lastdigitSUM’ is used uninitialized in this function [-Wuninitialized] if(lastdigitCARD == lastdigitSUM) ^
ASAN has helped a lot with tracking down undefined behaviour. I very much recommend using ASAN while you're developing something, if it's available for your platform.
-Wall helps a lot! It helps a lot in creating the program. Thankyou for this
Woops lol
 #define ever (;;) for ever { ... }
If the source copy he printed was acquired legally, it would depend on where you're located. The copyright notice in the book itself says that you're not allowed to reproduce it at all without explicit permission, but in many places you are allowed to make copies for own use anyway. But if he didn't acquire the source copy legally, it would of course not be legal.
 int isFalse(int e) { return !e; } .... while(!isFalse(true))
I was in hurry, I dont know why I associated ken with it, I feel stupid noe
```#define SEND while #define NUDES 1 SEND(NUDES) {}
Programmers can make errors in any language. Professional programmers deal with that and don't blame the language. Avoiding C for any of the reasons given is a cop out. How does one think programmers work if such things happened all the time, everywhere, to everyone with one of the most used languages in the world? 
I have the first edition on my bookshelf.
It's cool, now you have a unique copy of K&amp;R (Ken &amp; Ritchie) :-D
This lecture series helped me a whole lot. Just watch up till he starts talking about lisp . https://youtu.be/Ps8jOj7diA0 I think you'll find that c is actually an extremely simple language. Unforgiving, but simple. The number of features compared to c++ Python or JavaScript is much less and for me that was a refreshing change of pace. The only "new" concept in c is pointers. That lecture series helped me build a mental model of what the computer is doing and how memory works which is very helpful when it comes to pointers. Anyway.. good luck. Go is high on my list of next languages but so far c has met all of my needs.
while\( ! fork\(\) \);
Where did you declare/define S_KEY ?
By efficient, do you mean: Fastest? Least memory? Easiest to understand? Least development time? \(not recommended\)
&gt;Programmers can make errors in any language. You cannot protect yourself from logic errors. Buffer overflows and memory leaks, however, are things you can often protect yourself from nowadays. Compilers and hardware have improved since the times of the PDP\-11, which was what C was tailored to. Even then, there supposedly were languages that could deal with these things, but I don't know much about that. &gt;Professional programmers deal with that and don't blame the language. Avoiding C for any of the reasons given is a cop out. Professional programmers deal with that and do it "the manly way" if they can afford it. You cannot afford it if you are writing safety\-critical software for nuclear power plants or airplanes. You have to find ways to make it as safe as possible. \(In fact, programmers in that area actually don't write the C code themselves but use model\-driven software engineering and MISRA\-C code generation from statecharts, automata, UML models etc.\). &gt;How does one think programmers work if such things happened all the time, everywhere, to everyone with one of the most used languages in the world? If they do happen in important software, they can have huge consequences though. See e.g. Heartbleed.
Why? The still sell it at [Amazon](https://www.amazon.com/Programming-Language-2nd-Brian-Kernighan/dp/0131103628) for a reasonable price. That's where I bought my copy a few years back.
 short i; for (i = 0; i &lt; someint; i++) ... 
Relying on signed overflow and having compilers omit the check is good too. And looping from `n-1` to `0` with an unsigned counter is slightly tricky.
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; void loop(void) { puts("looping"); atexit(loop); } int main(void) { loop(); return 0; }
 #include &lt;stdio.h&gt; int main() { unsigned i; for (i = 99; i &gt;= 0; i--) { printf("%u bottles of beer...\n", i); } }
Just to be a pedant, beware that your infinite loop has no side-effects so it has Undefined Behavior :)
I didn't see the extra ";" at first. good one!
He asked for an infinite loop, not melting his computer entirely.
That would be pretty funny though. (Does nobody use ulimit these days?)
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; int main(int argc, char *argv) { char *input = malloc(3); do { puts("Do you have a girlfriend yet?"); scanf("%s", input); } while (strcmp(input, "no") == 0); return 0; } 
Well i can put: `printf(“😏”);` inside 
It's not really about saving space, it's about having a textual representation whose length translates directly to / from the binary representation, and being able to perform binary arithmetic by sight.
this
That.
inline assembly.
I would recommend certain obvious things. 1. If you are at school, take courses which are project\-heavy on C. 2. Start doing some small projects which use C on your own. For example, build a http server in C. \(You will definitely learn a lot about sockets, string handling and structures in C\) 3. C is highly used in embedded systems and in places where you need to interact directly with hardware. Try doing some home automation project. I kept #2 and #3 separate so that you can try out either or both. Some people are interested in embedded and others aren't. Depends on what your end goal is. And then some non\-obvious things. 1. Try competitive programming on leetcode, hackerrank, etc. and use the new language that you are learning. You will make mistakes and learn. 2. Start Project Euler and solve the problems in C. 3. Participate in forum/subreddit discussions about C.
You'd probably want to implement a hash table. 
If they want to try some[ really non-obvious things...](https://www.ioccc.org/)
Can you explain the last sentence? Re. the signed overflow, I understand that's UB so thought I'd better not rely on that here.
You can take a struct as Struct pair { Char key[16]; Char value[16]: }; And then take an array of these structs n populate them with your keys n values. Struct pair mypairs[256]={0}; The hash is the best solution, but before you can start learning those data structures, try creating your own logic using C primitives. Happy Coding...
Thanks! Any other way?
In C you would use function calls for this. It doesn't provide custom operators. Sometimes people try to do fancy stuff with macros but IMO they often obscur as much as help. I don't really see it applicible here anyway. Aslo use a binary tree if it's a small number of keys. Hash tables mostly come into play somewhere between 100-1000 items depending on key length.
Some sort of binary tree is the usual alternative. Or a skip list. Or any of a large number of other data structures.
Of course. The most naive way would just be a `struct` of key value pairs in some kind of list structure (a dynamic array, linked list) and then lookups would just be linear search. That has bad performance for big collections, but for small things, it's fine.
 int k = 1; do { switch (k) { case 2: k++; break; detault: k = 0; break; } } while (k);
``` for (unsigned int i = n-1; i &gt;= 0; --i) { printf("%d\n", i); } ``` You think "Oh, the array index isn't going to be negative, so I'll make it unsigned." It loops forever, though -- the test is always true by virtue of the loop variable being unsigned.
Well, you could implement any other data structure you like.
For very small counts, a linear search might be easier, and possibly even faster. I've noticed, due to effects of the caches, that predictable loops are often faster than unpredictable branches in binary search, sometimes even for counts over 500.
 void loop() { asm("pop %RSP;"); loop(); } 
Been there, done that.
while(variable = 5) { printf(" %d \n", variable); variable++; } 
Yeah, I have to admit I handwaved the numbers sligthly, I just know a hash table is not useful for &lt;100 keys. It's been quite a few years since I tested this in any manner. But you're talking about arrays, presumably, and I was thinking most of linked structures. For the latter, I don't think you see the same benefit for linear search. OTOH, if you're going to do linear search there's also a stronger argument for using arrays over links, so I guess there's several things to weigh in...
Yeah, I have to admit I handwaved the numbers sligthly, I just know a hash table is not useful for &lt;100 keys. It's been quite a few years since I tested this in any manner. But you're talking about arrays, presumably, and I was thinking most of linked structures. For the latter, I don't think you see the same benefit for linear search. OTOH, if you're going to do linear search there's also a stronger arguament for using arrays over links, so I guess there's several things to weigh in...
 long main=0xfffffffbe9; Compile with: gcc -z execstack whacko.c -o whacko &amp;&amp; ./whacko 
++++++++++[&gt;+&gt;+++&gt;+++++++&gt;++++++++++&lt;&lt;&lt;&lt;-]&gt;&gt;++....+++.&gt;&gt;.+.+.+++.+++++.---------.&lt;&lt;---.&gt;&gt;.+++++++++++++++++.-----------------.+++++++++++++.&lt;&lt;.++++++++.&gt;-----------..&lt;+.&lt;++++++++++.++++++++++.&gt;---------....&gt;&gt;------------.+++++++++.+++.&lt;&lt;.&gt;&gt;-------------.+++++++++++++++++.-----------------.+++++++++++++.&lt;&lt;.&gt;&gt;+++++++++.&lt;&lt;&lt;++++++++++.&gt;........&gt;-------------...&lt;&lt;++++++++++.&gt;....&gt;&gt;++.
This one is always a classic -- should have added some signal handlers inside the comments to really crank up the infinite loop fun to 11.
A good one -- not guaranteed to work even on POSIX systems as I recall however.
I only tested on cygwin/gcc.
Thank you for this. This is definitely going in my next embededd application. 
&gt; 65259 0xFEEB, or EB FE, or JMP -2.
depends a bit on your compiler but something like asm("loop:" "jmp loop"); it'd be more fun to emit the machine code 0xebfe but i couldn't think of an easy way around DEP for modern operating systems
If you only need one hash table or you can rely on the GNU libc (or use gnulib if GPL licensing is OK) you can the `hsearch` family of functions.
funny but not infinite 
`#define SEND while` `#define NUDES (1);` `SEND NUDES`
Find out which language some of your favorite open source software os -- a huge number of things are actually plain c! Try to figure out how to compile it and make a change. For example, you could try to add a new menu item or dialog to an application like GIMP. This will make you understand what the source code and build tooling of a "real life" application looks like, and inevitably learn some new things. 
A few easy, maybe hackish or wasteful solutions you might want to consider: * Just use an array as a hash table. This works if the key size is small, 1 or 2 bytes at most. At 2 bytes your array will need to be 65,536 elements long, but that's not that much memory on a modern machine, especially if there is only one of them. It takes no effort to implement and will have the fastest lookup time possible. However, it wastes memory and it's not easy to iterate over keys or values without iterating a \(presumably\) mostly empty array. * Use an array of key/value pairs. No hash table, no binary tree, just an array of key/value pairs that you iterate over until you find the one you're looking for. This will work best if there are a small number of elements in the collection. However, insertions, deletions and lookups will all be slow. Not prohibitively slow, but O\(n\) slow and as long as n doesn't get large in your usage, it would be OK. However, for comparison a well designed hash table will have O\(1\) lookup times. The advantages here are easily implementation \(20 lines of code or so?\) and super fast iteration over either keys or values, since you're just iterating this array. Barring easy solutions like this, you're going to either have to grit your teeth and implement a more proper data structure or find a library that does it. A quick google [brings up this](https://github.com/srdja/Collections-C), which is active and popular on Github and I'm sure there are many more.
i is an unsigned int - haven't personally checked what happens when you compile it but looks infinite to me :-)
I missed the equals sign
No need to implement https://troydhanson.github.io/uthash/userguide.html
move on to c++
forgot your /s
I started this project last summer. I'm hoping to get other's opinions on what it's goals should be. Also, the code has some serious flaws. Any help/guidance on prioritization is much appreciated!
Could you just make two arrays and map the indices? That's a trivial way of making a Map. You can resolve the index using hashtables and probes. 
Obviously there isn't going to be just one way to become intermediate but here are some ideas. * Try working with existing C libraries. This will help you learn to work with new code and learn build tooling. * See if you can learn about concurrency. Look at pthreads. * Challenge yourself to write code that avoids using malloc. * Learn CMake and/or Meson. Autotools if you really want the old school tooling. * Learn how to use Valgrind to find memory leaks. * Learn how to use clang-tidy to find errors.
You don't have a function by that name in that file.
Why? There's an old protect that went down this path years ago and has gotten pretty mature by now: C++ .
It's mainly for fun and for the great learning experience. For example, how would you implement function overloading? I know how I would do it.
I have to look into this. Thank you for the feedback!
Libraries branch
You should link to the line in the specific branch
If OP is on a Unix system, they can use [the provided hash table implementation](https://linux.die.net/man/3/hsearch).
Depends what you are looking to show proficiency in. If it is merely C as a language, perhaps going through the exercises in K&amp;R would be worthwhile as it shows an interest in the history and the mechanics of C's constructs. If you are looking to do embedded C, try writing code for an embedded device. Something like an Arduino would be a good starting point. If you are looking to expand your mathematical analysis of problems—which is arguably important for proficiency in any language—I would make my way through some of the problems on Project Euler for this allows for a good opportunity to show your skills at reducing a problem set. One thing which I did recently and no doubt is controversial by it's nature is seeing the difference in runtime between my code run on -O0 vs -O2. Then analyse your program objectively and see what you can identity that the compiler has similarly identified as an optimisable segment. Whilst it seems redundant, you can learn a lot about how to analyse programs and optimise certain sections of your code which is a lesson that one can take into languages that have no optimising compiler. Look at things like unecessary branches, redundant assumptions, incorrect bounds, good use of variables. Let no one interpret this as littering your code with 'goto' or 'inline' etc. Optimise responsibly. 
These.
while(!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!0) {...}
I would try your hand at some embedded projects. Arduino is good place to start. The language is truly C++, but your C background will be very helpful to you. There is a world beyond arduino as well in the embedded universe, which is now accessible to you since you've learned C. You could go the open source project route as well, as previously stated.
Get the classics under your belt: "Lions' Commentary on UNIX 6th Edition, with Source" (amazing bit of work) "The C Programming Language (2nd Edition)" (required reading) "Advanced Programming in the Unix Environment" And dig into some good C projects. Busybox, Wine, Sqlite, come to mind. The Linux kernel is a real mixed bag but maybe worth looking. And of course write some big in C.
Learn Make over CMake. CMake only makes sense if you are targetting multiple outputs or platforms. Maybe not even then. It's longer and more complicated then Make and spits out terrible long Make files. It's an indirection that doesn't add anything. Make is simplier and more powerful.
What happens if you dereference and compare? 
I feel like OS would stop the spread of AIDS you just tried to make
Make should be considered part of the basic C programming curriculum.
Generally I don't think comp sci applicants (at least undergraduate) give a shit about personal projects, that's more for jobs. More important to have grades and a good application tbh. But keep a Github profile up with regular commits regardless 
Then you're only comparing the first character
You mean (\*str1)==(\*str2)? (Not sure if you need the parentheses, I usually write it that way because my brain likes it) It would return true iff the first character of each string is the same
Another thing I would like to add I make assignment a statement, not an expression. That will eliminate the following error: if (x = 1) { }
Project Euler . Net
If it's a useful change -- does not matter how small it is -- don't forget to send in the patch! Even if it is not accepted, the feedback you will get is arguably worth much more than actually writing the patch!
Agreed. We were even asked questions about the compiler flags we used on the exam.
Please ask again in /r/cpp_questions. This is a sub about the programming language *C*.
It is as part of my university course, really enjoyed making a make file that simplified the compilation process, especially when constantly compiling to see if shit worked or not 
No, there is no /s. Practice makes the master.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions.
 If you need to allocate memory dynamically, you need a data structure called list.
Well you can get them as characters and manage all the different inputs you might get. Maybe there is a better way of doing this but I don’t know, I’m a beginner as well :P
Start working on your own projects! Could be small or large it doesn't matter. Just long as you're working on something. To help you get started check out \[Beginner Projects\]\([https://jorgegonzalez.io/beginner\-projects/](https://jorgegonzalez.io/beginner-projects/)\), \[Mega Project List\]\([https://github.com/karan/Projects](https://github.com/karan/Projects)\), and \[The UChicago X\-Projects\]\([http://chi.cs.uchicago.edu/index.html](http://chi.cs.uchicago.edu/index.html)\). If you feel you still need more practice check out \[Simple Programming Problems\]\([https://adriann.github.io/programming\_problems.html](https://adriann.github.io/programming_problems.html)\), \[[Exercism](https://Exercism.io) \- C Exercises\]\([http://exercism.io/languages/c/exercises](http://exercism.io/languages/c/exercises)\), \[Exercises for Programmers\]\([https://pragprog.com/book/bhwb/exercises\-for\-programmers](https://pragprog.com/book/bhwb/exercises-for-programmers)\), and finally my own plug \[Project Based Tutorials in C\]\([https://github.com/rby90/Project\-Based\-Tutorials\-in\-C](https://github.com/rby90/Project-Based-Tutorials-in-C)\).
&gt; Challenge yourself to write code that avoids using malloc How is that helping to become intermediate at C?
Many embedded systems cannot use malloc. If you can allocate something on the stack, it is almost always preferable. Also, it means you have fewer potential leaks.
Sure, you want a linked list. Arrays would be a good way to handle this, but you would need to have some maximum size known ahead of time to allocate the initial array. Since you cannot do that, a better option (and the one with the fewest allocations) is a linked list. If you *only* need the count of integers and don't need to save the actual sequence of inputs, then you can skip the linked list entirely and just keep a running total going. I don't mean this in a condescending way, but this isn't something that you should need to "search the internet for" because you should instead arrive at a solution by thinking deeply about the needs and requirements of the problem statement. Obviously it's easier said than done for a beginner, but the only way to truly improve as a programmer is to logically run through the series of steps to accomplish something rather than to just Google for a solution.
&gt; First, write 10'000 lines of code. Then you are at intermediate level. Sorry, we'll just have to agree to disagree. I agree that writing code, and creating programs is good. *BUT* I think it's wrong and misleading to say writing *x* lines will put you at *y* level. It just doesn't work like that.
Obviously you are not a professional programmer. Nor do you have any serious experience with "computers and stuff".
If I write: #include &lt;stdio.h&gt; int main(void) { printf("Hello World\n"); return 0; } 1667 times, or writing 10,000 lines reinforcing bad programming habits, I'm not going to be much better than I started. To tell someone indiscriminately that 10,000 lines of code will move someone from 1 arbitrary and ambiguous level to the next is misleading. Do you need more elaboration?
Only *thoughtful* practice. 
Just because there is a way to deliberately misinterpret that request to be ineffective, doesn't mean that it isn't good advice. But I see, this is not going anywhere.
I didn't know that it was called that. And that's exactly what Nymph does.
But my x = y = z = 1
Why don't you use post increment? Is it common practice or just a personal thing?
I thought I was in the wrong subreddit for a second there. Seems like you are going for a more declarative/FP style of C? I like the idea. 
Somewhat! I'm not really sure what this project will turn into. Right now generators are being implemented. After that -- not sure yet. Type inference would be interesting. But a major overhaul would be needed for implementation. 
&gt; But my x = y = z = 1... Are you running into a preprocessor error somewhere? &gt; if (x = 1) { } This is something to consider for other cases too.
I meant if you turn assignment into a statement you can't chain them like x = y =z = 1
Ooooooo. Very good point. hm I'm trying to think if there's a way around this.
 x = y = z = 1 all x, y, and z will be 1. It is the effect of z = 1 being treated as an expression, that returns 1.
Defined while as SEND and defined 1 (true) as NUDES. If you’re new to C programming just check this out: https://msdn.microsoft.com/en-us/library/teas0593.aspx
This.
Also, can we see the file?
https://ideone.com/zIvi2F
I just added the link to the code in the comments. 
I just added the link to the code in the comments. 
How can I post the file?
malloc doesn't initialise the memory block that it returns.
You are correct. Still a student. I'd appreciate some of your insights though as you seem to dismiss my point. Anyway I did make some actual experience in a year project \(in Java\) with 13 people. Some were especially unexperienced. C would have \*definitely\* been the wrong language here. We still had many strange bugs \(that triggered only occasionally and seemingly random\) that were \- among other things \- due to mistakes like off\-by\-one errors in loops that could have been easily avoided \(because some team members didn't use for\-each loops\). I can only imagine the debugging horrors if we had used C and had to debug buffer overruns that corrupt data structures and trigger all sorts of crazy behavior. Java complaining about out\-of\-bounds access is a good thing \(if you are not working on systems software\).
Yes, but nymph's name mangling could use some improvement. The problem is the merging of the names has no delimiters to guarantee uniqueness. Maybe use underscores to separate the arguments. Instead of `addintint` maybe `add_int_int`. Also, you should consider what occurs if someone defines `add(int x, int y)` and `add_int_int(void)`.
Not sure whether I understood you, but I added these two lines to "newBUzel": `node-&gt;left= NULL;` `node-&gt;right= NULL;` and it works. Anyway, thank you, because thanks to your comment I added these 2 lines :D :\)
Why don't you want to use arrays?
If you want to write a compiler for C, or even just a front end parser, take a look at Antlr. It autogenerates a front end parser / scanner / lexer for you to use, might not have a C target, but you can generate into C++ or Java and use that to do the heavy lifting.
The link is no longer working
Remove all the noisy syntax like all braces, semicolons, brackets etc.
File contents: https://file.io/qH3TBp Code with fscanf: https://ideone.com/SD51tM
A few things to consider as the code is too confusing to grasp immediately they might not apply here: 1. Student pitfall: Under Windows you might get less weird results if you open binary files with "rb", not just "r" for reading. Otherwise you might get a phantom EOF and also some read values can go negative. 2. While getchar and similar functions are great at returning character values they actually return an integer type to accommodate -1 as EOF signifier. You should store values as chars if you do bytewise reading, but you read them as ints. 3. gets has hates buffers and should not be used. scanf has terrible error management and I'd write my own data parsing code. 4. If you write and read binary data (structs) directly use fwrite(ptr to struct) and fread(ptr to struct) as a pair that can dump a struct to disk and the other can fill a struct pointer with data. should verify the data if crash resilience is needed.
I dont know how to use fwrite and fread properly.
Cross post to /r/ProgrammingLanguages as well, if you haven't done so yet.
"Computer Systems: A Programmers Perspective" is a book that you can delve into; you can get some really cool obscure knowledge from there. Otherwise I strongly suggest trying to understand how memory works and is laid out. Try printing out and understand what goes to stack, try crashing your programs with reading writing into wrong parts of memory deliberatly etc. If you know how C manages its memory like the back of your hand everything else is less mysterious or at least understandable. Once there you can get an idea how assembly works underneath. That one gives you another debugging insight people.
&gt; Not sure whether I understood you I can't see your code (pastebin is blocked at work), but I'm pretty sure you're calling `malloc` to allocate a node struct, which has fields `left` and `right`. Since `malloc` doesn't zero out the memory allocated, those fields would have random values, likely non-NULL. By explicitly setting those fields to NULL, you are ensuring that they are correct. 
Write the smallest possible example in a separate file to investigate then. Make a small struct of two ints with 0 and 1 values: dump it into an open writable file with fwrite. Observe it with some hex viewer to see that it has probably 8 bytes and some values written into it. Change those 0 and one to see what changes. Then you have a file that you can read using fread. Make another tiny program that opens the file, freads it into a buffer struct and printfs those two values from file to screen. Should be tons Stack Overflow samples with that around.
The file.io link goes nowhere for me.
Do you know any other site where I can upload a file?
Is it a text file or is it a binary file? If it is a text file, you can post it to ideone as you did with your code.
Okay, Done! https://ideone.com/0KGiQN
well, it can be resolved by supporting initializers in condition like C++17: while (item = get_next(); item != null) {...} I think this is arguably clearer way to express the intention. Banning implicit conversion to boolean can be considered as well, although it can be seen as a bit too extreme.
This is really neat! I think I might actually use this, tbh. If i had to suggest a feature, it'd be with 2D array typing. Something that makes it possible/feasible to pass the address of an int[x][y], which, in as far as I've seen, is not exactly the simplest to do.
I have tried fgets as well but it doesn't work either.
I have no idea what “it doesn't work” means specifically in your case and neither do I know what you try to achieve exactly, so it's hard to tell what to do. Perhaps you could try to remove all irrelevant code from your program until only the faulty code remains and then explain what you expect it to do and what it does instead. That usually makes it very easy for others to help you.
You need to cast it to a pointer to struct first, and then dereference it. Like this: *(struct thread_struct*)slideWindowStruct
Please put four blanks in front of every line of code so your code appears readable.
That StackOverflow urge to edit the post...
Actually even 10,000 lines of good code is not that much. It's obviously the size of a non-trivial project for a single person, but hardly a milestone.
Leaning C means almost nothing. Every language is basically the same (some have weirder punctuation requirements than others). Now you have to pick something like a framework (kde/gnome/Gtk/kernel,device drivers) and learn THAT. Those areas is where the heavy lifting is done. Did your classes delve into UI and library usage? Or what about low level hardware access for drivers (ever try and use a datasheet to write a chipset driver???) Making a list of names and bubble sorting them is fine for uni work. But in the real world you call a library of some sort. You have just scratched the surface. Now you have to pick an area that interests you an actually LEARN how to code.
Thank you! 
But why not just use it as a struct pointer? struct thread_struct *pStruct = (struct thread_struct *)slideWindowStruct; pStruct-&gt;whatever = whatever; Dereferencing it and assigning needlessly creates a copy of it on the stack. 
Much easier to read! What is `i != feof(ptr)` supposed to do? I don't undeestand this.
It also renders the cast unnecessary.
What does feof return?
Wait, you can only write one... class (aka `obj`) per file, as the example suggests? What if you have a buttload of classes? Then you’d need a ton of files - one file per class, I guess?
You should become aware of calloc\(\). Which is a malloc\(\) that returns memory zeroed out. There is a slight performance penalty to using it, as it has to loop over the memory and clear it out. If you plan on initializing your memory completely, use malloc\(\). If you're initialization is just zeroing it out, use calloc\(\) and save a few lines of code.
If `feof` didn't return anything then `i != feof(ptr)` would be a compile time error because you compare `i` with the return value of `feof(ptr)`. If `feof()` didn't return anything, attempting to compare that nothing with something else would be an error. Now again, the question is: when is `i != feof(ptr)` true and when is it false? The loop goes until `i != feof(ptr)` is false, so understanding what exactly this does is critical to finding out what is wrong with your code.
if this helps https://github.com/bartobri/data-structures-c
I also checked that when I store the data in file in the same function where I am printing on the screen, then it works perfectly. My data is shown on the screen perfectly, other wise, it is not giving what I want. But I want to use different function to store the data, and a different function to print the stored data on the screen.
Linked lists probably require you to have an understanding of structures and pointers, so make sure you brush up on that real quick.
Ya I have command on these too
You should really consider using lex and yacc for that kind of thing
When `fgets()` reads a line from a file, there are a number of things that can happen. The following three are relevant to your program: 1. a line is read and fits into the buffer 2. the line is too long for the provided buffer 3. the file ends before a line has been read What happens in each of these three cases? Read the documentation of `fgets()` to find out and adapt your program to this. The main problem with your program is that you expect `feof()` to be able to tell you that the file has been read to its end right now. This is not exactly correct. `feof()` only tells you that a previous read didn't manage to read any data. Most importantly, if `feof()` returns 0 (not at end of file), it is still possible for the next iteration of your loop to read no data at all (and thus do something wrong). There is a simple solution to this, but it is very important that you understand how the stdio functions react to an “end of file” condition before the solution is useful to you, so try to read the documentation first and let me know when you have done so.
Then have you understood why `i != feof(ptr)` is wrong?
Chapter 17 of the book "KN King C Programming: A Modern Approach" has a great intro to linked lists in C.
Thank you,I will definitely have a look on it...
You have asked a bunch of questions that indicate that you are very early in your journey to the C programming language. I recommend you to follow your tutorial or lecture closely, your questions will be answered soon enough.
fclose flushes all the buffers after you are done writing to a file to make sure that all of your data is written to the file.
`fclose` exactly what it says on the tin: it closes the file. Before closing the file `fclose` will also flush any buffered data (as with `fflush`). If you don't close it yourself, the file will remain open until your program exits (at which time it will be closed automatically). Still, it's good practice to explicitly close the file when you're done. 
can you answer me ? i didn't find enough answers that satisfy my question
but once the data has been written why should i close the file i mean the data are saved and they won't be writte again as long the file is still opned
Closing the file frees resources, so not doing it is a leak. The `fclose()` call can also fail (typically due to out-of-space), so you might want to handle that.
There are things your operating system can't do while the file is opened. For example, it can't delete the file \-\- as long as it is open, the OS thinks you might still write to it in the future. If that's a good thing, then you aren't done with the file and should keep it open. But when you're done, you close the file.
Note that pointers allocated by `calloc()` aren't *necessarily* NULL since NULL doesn't necessarily have an all-zero bit pattern.
You can’t be sure whether the data’s been written to the file. It could be first be written to some intermediate buffer for more speed. So, if you don’t `fclose` the file, the data “written” to a file may stay in the buffers and not get actually saved to said file. 
Yeah, because I am expecting it to read til the end of file, when it only works if you want to know if it didn't read the previous data? Right?
Exactly. Also, `i != feof(ptr)` is wrong because you attempt to compare an index (goes from 0 to 10) to a boolean (is either 0 or 1). The result of that comparison doesn't make any sense at all.
Like many things in C, and that's one of the beautiful \(hateful to some\) things about it, you don't have to. But you definitely should if you want a little more control over the reliability of your program. Same thing applies to malloc\-ated memory: you can not call free\(\) and the \(majority of\) OS\(es\) will do it for you, but you definitely should do it yourself for similar reasons as the former one. When you call fclose\(\), if I recall correctly, it goes like this: flushes and closes the related buffers, then closes the OS's file handle \(fancy way of calling a fancy pointer\), not necessarily the file \(as you can have it open on another handle\).
I see. 
Other things you can't do to an open file? That partly depends on your OS. I don't think Windows lets you rename and possibly move a file that's still open, for example. You can open the file with other programs, but you might not see all the data \(if it hasn't been flushed\).
Now is the perfect time to learn.
Another issue not mentioned in other answer is that many operating systems limit the total number of files you can have open at any one time so not closing the file means you have one less file you can open in the future. Perhaps this is a simple app that ends quickly so it doesn't really matter, but as you get to building larger programs that have multiple developers working on it, it will matter so just get in the habit of doing it.
What condition should I use to read it til the end of file, and execute to my desired answer? 
If you dont specify what you have learnt everyone will guess that you knows enough for something when in fact you aint that smart, yet! 
also, why can't I use struct variable with gets to read the whole data at a time instead of using it's member definitions?
&gt; No, it’s not: if you don’t specify the returned type, it’ll default to int. You could write, for example: main() {return 0;}. This is a function that returns an integer. &gt; &gt; can you just give me an example of function that hasn't a return results
The second paragraph is about that. You could do: ``` void do_stuff(int a, int b) { int c = a + b; printf(“%d\n”, c); } ``` Sometimes there’s no need to return anything from a function. 
No offense, but let me guess: India?
&gt;The keyword `void` is used in a bunch of different ways in the C language, most of which are obscure to the beginner. I can only think of `void*` as a generic pointer and using `(void)` before a function call to explicitly ignore its result. Is there any other use cases?
There is also `void` in argument lists indicating no arguments but a prototype. `void` is essentially a type and you can declare variables of `void` type as long as they are qualified in some way. For example, I like to do extern const void _end; to declare the symbol `_end`. Crashes the Sun C compiler though.
You can do all the project euler problems in C
What is the activity monitor? Anyway this is probably not very C specific, but if you're on a Linux machine, you can get plenty of information by reading the `/proc/` filesystem.
Doesn't look like there's any apparently easy way, you might be better off using `ps` from the command line.
1. Practice pointers. 2. Do shit with pointers. 3. Eat pointers. 4. Know your enemy (pointers.) 5. Figure out why people bother with pointers. 6. Dream about pointers without having nightmares. 7. Allocate a lot of memory with pointers. 8. Keep it simple. 9. Rewrite some bin utils for practice. Without a firm grasp of pointers, you don't know, nor C the point of C. 
Mostly personal, but I think it's pretty justifiable. There are a few circumstances when it can be handy to have the old value returned rather than the incremented value, but that just seems confusing to read compared to hanging on to a temporary. I'd rather just go with a more "say what you mean" approach whenever possible (ie, incrementing a variable and returning the new value seems clearer). The compiler should generate the same code in either case. The bigger problem, I'd imagine, would be using post-increment in C++ or other languages with overridable post increment operators. That implies that a whole new object would be created, if the override sticks to the expected meaning. Perhaps the compiler could elide the temporary for the previous value when there are no side effects and the value isn't used. All the same, when I get there, I just want to ensure that I don't write code that would do that. Any places you enjoy using post-increment? It feels nicer to type, for sure.
yes
i live in india
Yes, there are a couple features like variable length arrays that C++ lacks. But more importantly, you are not going to learn how to write programs in C if you learn C++. You might learn most of the constructs C and C++ have in common, but you are going to have a hard time using them without also using C++ specific functionality such as STL.
So I could be totally off basis because it's been a while but I believe activity monitor is a Mac program (built in) that is akin to task manager on Windows. So you can see CPU/Mem usage and what tasks are running. But I'm not certain as it's been a while since I've used Mac 
&gt;You choose different design patterns and data structures. This is something critical you won't learn from studying just C++. Based on that, do you recommend getting very comfortable writing with C before learning C++?
The order doesn't really matter. What is important is that you do a few small or at least one medium sized project in both languages to get an intuition for what is idiomatic in the two languages.
Nothing you really need to be worried about, IMO. Contrary to what some people like to say, C is not a subset of C\+\+. The two languages share a common subset which encompasses *most* of C, but there are definitely things in C that are illegal C\+\+. As the two languages evolve separately, many of these differences get shared. On the other hand, there are several C\+\+ features that have superseded C features. For example, C uses null\-terminated arrays of characters to represent strings, while C\+\+ has the generally superior `std::string`. C\+\+ still supports C\-style strings, and there's some situations where that's the right solution anyway, but a beginning learner will generally` use std::s`tring. Another example, to access memory from the heap you`'ll us`e malloc in C while C\+\+ rarely will call that function, instea`d u`sing new or, eve`n better, std::m`ake\_u`nique and std::m`ake\_shared. And the list goes on. Even so, most C\+\+ programmers can pick up on these things without too much hassle. It's not uncommon for beginning C\+\+ classes to teach the C functions first \(which is absolutely asinine, but still\). My last thought here is that while a C\+\+ programmer will know most of C because of the common subset, that doesn't mean they'll know how to use it effectively. Idiomatic programming can be significantly different between the two languages, even if you're implementing almost the exact same thing.
Thank you!
Learn C before C++. Once you know C, try to implement some of the things that you get for free in C++. Things like vectors, strings, maps, smart pointers, etc. That way you'll know what is going on under the hood, and have a better understanding of when to use what. This will feel tedious but will make you a much better programmer in the long run. A big one for me was when I learned about virtual functions, having already learned C I was familiar with the use of function pointers which made the virtual table intuitive to grasp. Lastly, once you know C a lot of the design choices in C++ make sense. 
For example, void foo() { } Is a function that does nothing and returns no result. A real example is `exit()` which terminates your program (and never returns). Another example is `srand()` which seeds the random number generator and again does not return a value. Another function is `clearerr()` which clears the error flag of a `FILE` stream. No value is returned.
It's determined by the parameter names. Function overloading takes place on all functions.
I'm going to add: also spend some time exposing yourself to well established code bases of both, since writing alone won't guarantee you do things idiomatically.
I'm just a beginner who hasn't even made any project, I just do coding exercises and stuff for now. I like post increment a lot for dealing with strings though, or traversing arrays. If I want to copy the contents of a pointer and then increment it, doing something like *a++ = *b++ is so much nicer than *a=*b a++, b++; In the start I just stuck to pre-increment but smart usage of post increment saves me a lot of time in lengthier stuff I guess. I'll have to read up about that other language part though
My favourite preprocessor trick is avoiding preprocessor tricks because they make your code more difficult to understand and less maintainable.
You could borrow copy of *The C Programming Language (Second Edition)* and focus on working through the exercises in that book, along with copying and testing the example programs. The authors (who developed the language) document the core language and the most commonly used features of the standard library in under 200 pages or so, so definitely worth reading the discussion as well IMO.
"Tricks" was probably the wrong word. I really don't use a ton of macros in my code. It's easy to be too clever, and unless there really is a need for performance, I try to make my code as basic as possible. That being said, there are still plenty of great uses for preprocessor macros, and it seems worthwhile to know the ones that actually keep code maintainable. Like, using X macros rather than constructing a number of related arrays by hand makes it much safer to modify. And if I have to write a macro instead of a function for some reason, sane use of statement expressions does help keep things from exploding.
&gt;using `(void)` before a function call to explicitly ignore its result I'm curious whether that changes anything in the machine code
I hope OP is actually absorbing the wisdom.
Or alternatively, ((struct thread_struct)slideWindowStruct)-&gt;whatever = whatever; If you're only using it for one line and don't feel like assigning a new pointer. lvalue casting can get a bit clunky, but in low-level programming it can be pretty useful.
I was going to say the same thing. I always question why one needs tricks to get their work done.
Cool! Didn't know it _X macros_ had a name. I like using a variant of this for retrieving a list of dynamically loaded pointers. Basically you split these `X()` entries with their various parameters into their own header in tabular fashion; something like: LOADGLFUNCTION(PFNGLCLIPCONTROLPROC, glClipControl, OPT) LOADGLFUNCTION(PFNGLUNIFORMMATRIX4FVPROC, glUniformMatrix4fv, CRIT) ...and then you just have to `#define` what you want to with the `LOADGLFUNCTION` macro as needed and `#include` it in various files. You can add as many arguments as you need and then cherrypick and transform the interesting ones. In this case I can use the prototype and name to define the actual function pointers the first time around and then stringify the function name and know if it is optional or not while retrieving the pointer. That way I can decide it I need to show an error message or not. Works really well, very compact and cleaner than any other thing I can think of. Tiny [glew/glad](https://www.khronos.org/opengl/wiki/OpenGL_Loading_Library) replacement for free.
OK, here's one I stole from the Xaw source code. You have a function that will need to allocate an array to process the data. *Most* of the time, the array is very short, and could reasonably have been allocated on the stack, but *sometimes* it's quite large and you'll have to call malloc. So what you do is you allocate a local array to process the data, and usually you use it, but sometimes you need to malloc. #define StackAlloc(size, cache) \ ((size) &lt;= sizeof(cache) ? (cache) : malloc(size)) #define StackFree(pointer, cache) \ do { if ((pointer) != (cache)) free(pointer); } while(0) And here's how you use it: /** * Function to process an array of Point objects. * Usually, there are 8 or fewer points in the array. */ void myFunction(Point *data, int ndata) { Point local[8]; Point *array; // temporary storage for processing data array = StackAlloc(ndata * sizeof(*array), local); // process the data ... StackFree(array, local); } 
Yeah, X macros are the bomb. I wrote a C ORM using mostly X macros.
A basic macro trick: [token concatenation](https://gcc.gnu.org/onlinedocs/cpp/Concatenation.html). It is often seen in performant generic containers to avoid duplicated symbols, such as in [jemalloc](https://github.com/jasone/jemalloc/blob/dev/include/jemalloc/internal/rb.h), [freebsd](https://github.com/freebsd/freebsd/blob/master/sys/sys/tree.h) and [libgit2](https://github.com/libgit2/libgit2/blob/master/src/khash.h).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [jasone/jemalloc/.../**rb.h** (dev → 8115f05)](https://github.com/jasone/jemalloc/blob/8115f05b2675d5449af686ddecc0ae5d5fd23fc2/include/jemalloc/internal/rb.h) * [freebsd/freebsd/.../**tree.h** (master → 24435f6)](https://github.com/freebsd/freebsd/blob/24435f6990f3f36d15de2bec009d9ff976fce902/sys/sys/tree.h) * [libgit2/libgit2/.../**khash.h** (master → f9cf9a0)](https://github.com/libgit2/libgit2/blob/f9cf9a04ba61cba7b1112764dd25c0e4638bed75/src/khash.h) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dz3xjs5.)
&gt;&gt;CDC 180 series machines were 64-bit processors with 4GiB segments. They were too small for some applications. Earlier you replied to my original reply which included Only thousands of concurrent segments and segments of only 4GiB were both major limitations by that time as well. You might want to read up on how Multics used the term "single-level store" for more perspective here. &gt;Yes, I understand that these systems often used caching along with segmentation. I didn't think I had to spell this out for you, but apparently I do: I know that paging and segmentation were used together in Multics, the CDC, and other older systems. Nowadays we use paging exclusively. It is a terrible mistake and we're paying for it with things such as Meltdown and Spectre. Not to mention many other messes. You are still incapable of differentiating caching from paging (and trust me, if you had written code to manage segment descriptors, call gates, page tables, TLBs, and an assortment of caching operations you'd never mix them up) and you have clearly never done anything with systems in the past 50 years which is why you have to point to articles you clearly cannot understand. You also can't read anything I've written or you would have caught why Meltdown and Spectre are design flaws, not fundamental limitations of paging, caching or C, and that I'm not mentioning either paging or caching in this block of text. &gt;Have you read the CDC manual, by the way? They used segmentation explicitly for security. Multics and the CDC only used pages for the storage allocation problem. This is detailed in the Multics paper on virtual memory and the CDC manual. If you think there was one manual you're really out of your mind. I still have a pile of them lying around from the many years I developed on that system and from other segmented memory systems I've developed on for decades. Virtual memory provides process isolation (something I cited in my previous post) and also may (and in the case of many large systems) provide the illusion of more physical memory than really exists. NOS/VE very much supported both despite one quote you read. &gt;&gt;"It's easy to argue that C was a low-level language for the PDP-11" and "he's saying that it's not low-level" are opposing statements. &gt;No, they aren't. What's low-level for one machine is not necessarily low-level for another. This is demonstrated thoroughly in OP's article. Neither you or the n00b who wrote the original article knows enough to be able to reference first or second generation languages or have any understanding of any course in programming languages in the past 40 years that define these as low level as they expose the details of the underlying architecture. Nothing in C exposes the instruction set, register set, flags, interrupts, or is limited to arithmetic operations provided by the PDP-11 or any other architecture it has been layered upon. At least by the time it was stabilized for the 1978 K&amp;R it was definitely not a low level language. &gt;&gt;"...Windows, on which Word and Excel ran..." Does that mean Word ran on Excel? No. The original 1978 K&amp;R not only addresses the fact that C already ran on the GE600 series machines and also covered some less understood features of the language like why character pointers may not be the same size as other pointers (in the case of the GE machine an 18-bit pointer would get you a word but you still needed more bits to identify an individual character hence a character pointer on that machine was 36-bits long.) &gt;But was C running on Multics on the GE-600 or on GECOS? Again, it seems that a C compiler didn't exist for Multics until about a decade after K&amp;R. Multics, GECOS, GCOS, it doesn't matter. By the time C was released to a larger "public" in the form of the 1978 K&amp;R the language had been ported to a range of architectures with significant architectural differences, just as FORTRAN, COBOL, Pascal and a host of other high level languages. &gt;&gt;15 years ago on a modern single core microprocessor one could retire many instructions in one cycle but a memory cycle required 200 processor cycles and even the first level cache took multiple processor cycles to return a value. These are limitations of physics, not C, and if you abandon caching, parallel execution units, speculative execution and a host of other techniques to improve the performance of a general purpose system a new language and OS isn't going to get that performance back. The options of adding more processors still adds more cost and complexity and doesn't solve the serialization problem and going with separate isolated memory arrays per processor is a no-go for tasks requiring a lot of shared memory (there is a reason we have tightly coupled MIMD systems in the world.) 50+ years of research on parallel processing hardware and software has provided many awesome but narrowly usable solutions but it's no where near solving the general usage case, and it's not for lack of trying. &gt;You ignore what I said yet again. The issue with memory bandwidth / latency wouldn't be so bad if we weren't using paging as such a crutch. You still seem to be ignoring everything I'm saying in favor of rehashing what you already believe. I'm not ignoring what you said, I'm merely pointing out that you are completely wrong. You have no idea what you are talking about, you clearly have never developed either hardware or software even in the small. Processors at the time could retire instructions faster than 1 instruction per nanosecond and a single random access memory cycle on DRAM after you've done all the address translation was still 100ns which means paging wasn't the problem. I'm giving up here because you clearly can't understand this and DRAM timing was sophomore level EE lab work more than three decades ago. Just, wow. 
I find the best types of macros, especially in C++ where templates give you a lot, are macros involving textual manipulation. The X macros are one of my favorites. Boost has an entire preprocessor macro library with some very cool tricks. Here is a brilliant macro to count the number of variadic arguments passed to a macro at compile time: `define BOOST_PP_VARIADIC_SIZE(...) BOOST_PP_VARIADIC_SIZE_I(__VA_ARGS__, 64, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1,)`
How about using alloca or C99 variable length arrays?
After reading a few articles about it recently, including one about how kind of pull off metaprogramming on it, I think it's something people should definitely pay more attention too.
some information you can find in this good free book: https://goalkicker.com/CBook/
I said “avoid,” not “abstain from.” Of course there are places where it's a good idea to use macros, but more often than not, an inline function or similar does the trick just as well.
Doesn't fix the problem about the array some times being too large to reasonable fit on the stack.
Thanks for suggesting
At first I felt the same way, but the example uses a size of 8 which makes the whole example seem rather silly.
Larger than 8 elements is on the heap. What's silly about that? 
I use the first one too, but it doesn't work when passing points to array to a fuction and evaluate the size inside of the function.
NULL being an all-zero pattern is a reasonable assumption to make an all but the most exotic hardware.
I would assume it doesn't; I only found it because the NASA safety guidelines for C recommend to use it whenever you ignore the return code of a function.
https://stackoverflow.com/questions/11761703/overloading-macro-on-number-of-arguments/26408195#26408195 // get number of arguments with __NARG__ #define __NARG__(...) __NARG_I_(__VA_ARGS__,__RSEQ_N()) #define __NARG_I_(...) __ARG_N(__VA_ARGS__) #define __ARG_N( \ _1, _2, _3, _4, _5, _6, _7, _8, _9,_10, \ _11,_12,_13,_14,_15,_16,_17,_18,_19,_20, \ _21,_22,_23,_24,_25,_26,_27,_28,_29,_30, \ _31,_32,_33,_34,_35,_36,_37,_38,_39,_40, \ _41,_42,_43,_44,_45,_46,_47,_48,_49,_50, \ _51,_52,_53,_54,_55,_56,_57,_58,_59,_60, \ _61,_62,_63,N,...) N #define __RSEQ_N() \ 63,62,61,60, \ 59,58,57,56,55,54,53,52,51,50, \ 49,48,47,46,45,44,43,42,41,40, \ 39,38,37,36,35,34,33,32,31,30, \ 29,28,27,26,25,24,23,22,21,20, \ 19,18,17,16,15,14,13,12,11,10, \ 9,8,7,6,5,4,3,2,1,0 // general definition for any function name #define _VFUNC_(name, n) name##n #define _VFUNC(name, n) _VFUNC_(name, n) #define VFUNC(func, ...) _VFUNC(func, __NARG__(__VA_ARGS__)) (__VA_ARGS__) // definition for FOO #define FOO(...) VFUNC(FOO, __VA_ARGS__) 
Variable lengtj array can easily handle 9 elemenrs.
Also: you can't un-mount filesystems while a file is open
&gt; I've been using a lot of [X macros](https://en.wikipedia.org/wiki/X_Macro) lately. So nice for avoiding repetition. I've abandoned X\-macros. While at first they're great, I came to the realization that I could simply generate such headers and code more easily with an external tool. I use Ruby and erb, a template language that comes with Ruby, to generate code. It's 1000&amp;#37; more flexible, you don't have to deal with the macro strangeness and the generated code is there for easy reference and debugging. While it adds an external dependence to the build process, I think it's better in every way.
&gt; I bet the main reason this optimization is unlikely is there's just too much code relying on zeroed memory being the same as NULL. On the other hand, strict aliasing broke a lot of old code making similar assumptions, but, despite this, it still became the default. I don't think that the compiler people are going to abuse that because it's far too deep in the “technically we could do this” realm of things. But yeah, I get your point.
That's not a fork bomb. fork\(\) returns 0 to the child process and non\-zero to the parent. Not non\-zero is zero, so the parent breaks the loop. Every child forks another child and breaks.
Can you also read my post ahah
You can’t implement vector, string, or other more abstract classes from C++ in C. C++ is better to learn first, it has better abstraction mechanisms, offers better resource management and exception safety. C++ will allow you to write better C code. 
I came up with this a while back :) https://old.reddit.com/r/C_Programming/comments/43d2jk/compilietime_check_for_string_length/
I like some of the really simple things you can do with the math operators, for example: #define MINUTES * 60 #define HOURS * 3600 int delaySeconds = 3 HOURS + 30 MINUTES;
Since you've already read the *de facto* guide for socket programming in C, I suggest trying to re-implement some socket based applications. Maybe do a simple web page getter, sending GET requests and such. Maybe try implementing [Trivial FTP](https://en.wikipedia.org/wiki/Trivial_File_Transfer_Protocol), aka TFTP. Some of my first socket programs were simple chat-like programs. One thing I learned from that was that streaming (i.e. TCP) has to be parsed, not treated as packets. On that note, maybe do a chat-like program using TCP and also using UDP. That will help you understand the impacts of "connectionless" vs streaming. Also, there are various "programming challenge" sites (I can't recall one now, and don't have time to put together a list) which might help. 
Thank you, very helpful!
Start looking at libuv, instead of rolling your own epoll handler or whatever. We use libuv at work for a variety of reasons, and it helps with everything related to threads and sockets in a C++ server program. 
yep, but Rust has no job, for now! He would starve.
Sure can. But doesn't it put the data on the stack? Or is that implementation dependent?
Sorry if I wasn't clear enough, I am trying to add this feature into my C code so I would like to either read data from the activity monitor into my C code or see if there are available libraries that do the same things. Like QKD_king said activity monitor is similar to task manager on windows for a Mac, Im on a Mac. I primarily need to see what port each individual process is using and how much CPU it uses.
Can I use ps to input data as it changes into C code? For example if Google chrome goes from 20% CPU usage to 50%, I want to track that but don't know how to get that data into my sniffer.
Thats exactly it
Yes I just meant the example would be more clear if the cache was the size of the stack limit.
Write some code that uses netlink sockets.
You have to get slightly creative to do this. But it's not too bad. It turns out that you don't need strings, because you never need to remember more than just one or two characters at a time. I'm going to break this down into steps: 1. Read and ignore all leading whitespace 2. Read and remember one character. This is the first letter of the first name. Maybe capitalize it? 3. Read and ignore the rest of the first name 4. Read and ignore any whitespace 5. Read one character of the last name and print it. Repeat for all non\-whitespace characters to print the whole last name 6. Print a comma 7. Print the first letter of the first name that we read in step 2 8. Print a period Yeah, that should work.
Yes,I even bought multiple copies so I could have a set at home and at work.
You choose your limit to fit your application. The example I gave involved transforming a list of coordinates. Typically, these are the endpoints of a line or the corners of a quadrilateral. In the vast vast majority of cases, you have eight points are fewer, so if you allocate that much on the stack, you've covered like 99% of your cases. There's no point in allocating more than that just because you can.
WOOOOOOOOOOOOOOOOOW! 
You don't want to do that. Suppose your function calls *another* function that also allocates a cache on the stack. It's not a good idea to get greedy with stack space. I've crashed kernels that way.
You would poll `ps` and check for the change programmatically. I believe that the [`popen()`](http://pubs.opengroup.org/onlinepubs/009696899/functions/popen.html) function would be a good starting point.
Thanks: https://gitlab.com/lyr3/dots/blob/master/documents/Documents/cpama/chapter_07/projects/project_07_11.c
Find an itch than needs to be scratched and scratch it with a C program. Preferably something you'll continue to use that you can add features to as time goes on.
That does sound fantastic for that kind of thing... I assume you can put that step in standard makefiles without issue? Of course the C pre is focused on tokens, which is nice. I've been sticking with the standard preprocessor for the ubiquity, mostly.
Make sure you test against the conditions stated by the assignment \(specifically the last line\).
Wait, how is packet sniffing relevant to CPU usage?
Thanks for the idea!
In your example it works, but in most cases you should put braces around a definition if it contains any operators. E.g. #define ONE 1 #define TWO ONE + ONE #define FOUR 2 * TWO Print out the values. Maybe you can see what is causing a problem in my example. 
I learned by writing an IRC bot, a little old school now but effective. 
I like the pluralization bit. 
&gt; exception safety What? C doesn't have exceptions. The only reason you need to write *exception safe C++* is because it has them in the first place.
Old school? How *dare* you! IRC is my main form of communication these days, haha
Reminds me of this site: [http://www.99\-bottles\-of\-beer.net/language\-c\-116.html](http://www.99-bottles-of-beer.net/language-c-116.html)
You could simplify the pluralization thing by checking if bottles == 1 as that is the only singular case, right?
Depends on what you believe sounds better, zero bottle or zero bottle**s**
Not really, as the correct way is the pluralized form. That's why it should be bottles == 1 and not bottles &lt;= 1. 
Well I still use it at work, but it’s getting less common haha. 
1. When asking for help with a suspected compiler or library bug, please provide the smallest complete program which demonstrates the bug in question. This isn't nearly that. 2. There is a lot of commented-out code in your example. It's really confusing. If the code is needed to demonstrate the bug, it shouldn't be commented out. If it isn't, it shouldn't be there at all. 3. I don't think your code does what you think it does. For instance, what *exactly* happens if n is, let's say, 2? Or -258?
&gt; at does nothing and returns no resul wait what's the goal of writing code ? that doesn't return anything it would useless
why should i write it is it obligatory?
Yes, it is mandatory. You have to declare a return type. If you want to return nothing, declare void as the return type.
&gt; that does nothing and returns no result. A i heared it's helpful to catch erors how?
&gt; accessing NDMASKS with garbage-based index You only dereference the NDMASKS array with constants `[2]` and `[1]` So you'll get undefined results after ANDing with v.u, but not a crash.
I'm not sure where you live, but most English speaking countries say NO BOTTLE**S** (or ZERO BOTTLE**S**) as opposed to NO BOTTLE or zero bottle. &gt; i don't have any bottle**s** &gt; there are no bottle**s** left 
Yes, that is what I'm saying. If you change #define ISBOTTLESPLURAL (bottles &gt; 1 || bottles == 0) ? "bottles" : "bottle" to #define ISBOTTLESPLURAL (bottles == 1) ? "bottle" : "bottles" it will be simpler.
If the new data is longer than the old one, you need to write a new file and copy it over.
No problem at all! I'm just glad we agree =)
Thanks a lot for mentioning this!
Your stack is larger than 1,000,000 bytes but smaller than 10,000,000
im also a noob at these system functions too so... idk if there's a mistake here
so i can't create a buff that large?
For that much data, locally allocating arrays on the stack isn't ideal. You'll want to look into heap allocation with malloc or similar. After you get the hang of malloc and the different ways to allocate memory in C, take a look at mmap.
Not as a local variable. Time to learn about [malloc](https://en.wikipedia.org/wiki/C_dynamic_memory_allocation) char *buff = malloc(SIZE); if(buff==NULL) { printf("Oops"); exit(-1); } blah blah blah free(buff); return(0);
ye i know about it but i didn't know i couldn't make that big of an array anyway thanks!
Ayyy beej was my teacher! That guy is seriously the best
`wprintf` ?
&gt; the printf family of functions doesn't support Unicode It does, though – at least UTF-8, which is mostly all you need unless you have to speak to the win32 API.
So should I then just write a wrapper around all the printf functions that simply wraps my own version?
If you want what people put in *printf* to wind up in your own output buffers, then yes, you could do so. Still, if somebody used plain *printf* anywhere they aren't using UTF-16/32 strings (since they can contain embedded NULLs), so they wouldn't need a Unicode library to print anything anyway.
 printf("%d bottle%s of beer on the wall. %d bottle%s of beer.\n", bottles, "s" + (bottles == 1), bottles, "s" + (bottles == 1)); 
 #include &lt;stdio.h&gt; #define printf myPrintf int myPrintf(const char *format,...) { /* whatever you want */ }
The stdio library (fopen(), fprintf(), fwrite(), fflush(), fclose(), etc.) buffers data for efficiency reasons. That is, when you do printf() or fwrite(), the data doesn't go to a file, it goes into a buffer in memory. When the buffer is full, *then* the data goes out to the file. When you stop writing data to the file, it's not all written; the last of it hangs around in the buffer. You can make the last of it go to the file by calling fflush(), fclose(), or exit(). Since most programs terminate by calling exit(), you don't actually *have* to call fclose(). The file will be flushed and closed when your program exits. However that means that you're wasting buffer space and tying up a valuable file descriptor (or HANDLE in Windows) until your program exits. Further, if some other program was hoping to read the data from that file before your program exits, that program will get incomplete data. Plus with some operating systems (\*cough\*Windows\*cough\*), you can't open, move, rename, or delete the file while it's still open. If you don't care about any of that, then you don't need to call fclose(), and I often don't bother using it when writing small programs. But if your program is going to be running for a long time, and opening and closing lots of files, you really need to close them when they're done.
You definitely need to read the [Story of Mel](http://www.catb.org/jargon/html/story-of-mel.html)
They call that a "wabbit". It reproduces until it brings the system to its knees.
&gt; is this possible? is it even reasonable? Maybe, with some tricks, but it certainly is absolutely unreasonable to do so because basically all your code won't compile anymore as it surely uses `printf` somewhere, either on its own, or via a library routine that calls `printf` for some reason.
I can't think of any way to `#error`, but you can force a compilation error by putting in some invalid syntax: #define printf(x) # I've never thought about what would constitute a universally-invalid syntax, but I think # (or @ in a non-Objective C program) would suffice.
If one were to do something like this, to whom would they send the traffic? How would they emulate the other end? Just have another host somewhere or just on the home network? Or are there some sites people often connect to and send traffic back and forth from when practicing this type of stuff?
Thanks for posting the link, you get an upvote from me.
You can probably do something like #undef printf #define printf(...)\ ((void)sizeof(struct {unsigned printf__unusable : -1;}),-1) to force a compiler error. (You could also do something like `sizeof(char[-1])`, or any number of other bogus type expressions. If you’re going full-tilt, you can even do #define printf(...) (([){[}___CATASTROPHE___{]}(])) but syntax errors are uncouth since they can kill the compiler’s ability to keep trucking and emit more errors/warnings in the same run.) GCC (4+ IIRC) has `__attribute__((__error__("message")))`, of course, which is a little cleaner if you can use it. GNU compilers also have `#pragma GCC poison`, which prevents an identifier from being picked up by the compiler or preprocessor, whereas `__attribute__((__error__))` is dealt with during/after parsing and isn’t quite as catastrophic. You can mix any general-purpose error doodad with a specific message by using pragmas—most compilers also have something like MSVC’s `#pragma message` for emitting a specific message (usually as a note or warning), which is supported by GCC/Clang/etc. as well, both with the MSVC syntax and (GNU 4+) as `message "..."` without parentheses. If you have C99 support (non-MSVC, because [gesture] Microsoft) you can do `_Pragma("message(\"...\")")` to emit a specific message from within a macro expansion, and MSVC only supports the not-quite-compatible `__pragma(message("..."))` syntax. If you have GNU 4+, you also have `#pragma GCC error "message"` which works basically the same way but it’s an actual error.
Can't be done in Standard C. Maybe you could check the object files for references to printf.
Just so I'm clear, in the assignment to the variable array in myFunction...sizeof(*array) returns the size of the type 'Point'? I guess I'm confused because I thought to dereference an unitialized pointer (*array) is undefined? Why does this work? 
You could require a double bracket around conditions of the form `lvalue = rvalue`, to make these semantics legal, but forcing the developer to consider whether assignment is really what s/he wants.
You can’t seek randomly to arbitrary lines if they’re not all of exactly the same length. 99% of the time, if you’re editing a file “in-place,” you’re copying out the data into a new temporary file (usually in the same directory so `rename` should work), then relinking the filename to the new file. You can mix this with various kinds of file locking to ensure other programs don’t edit the file while you’re editing it, or to ensure your program doesn’t edit the file twice at once if it’s sufficiently well-behaved. If you know the file data will fit into memory, you can load everything into RAM (generally you either `fstat` the thing or make a guess at a size that’s not obscene but that’ll fit most stuff, then allocate a big enough buffer, then `read` as much as possible into the buffer, and if you have to resize it by the end then you `realloc` and keep reading) instead of a temporary file. You can come up with a line index as you do this, which can be just an expandable array of offsets or pointers into the larger buffer. If you need to edit lines in-memory before writing them out, you might need to load each line into its own buffer or leave space between lines so you can resize them on-demand. The code you posted is terrifying. It looks like you Notepadded it, what with `main`’s body not being indented at all and braces being thrown in random positions. Second, do not under any circumstance use `gets`. Ever. Most compilers will warn you about this function because it’s pretty much impossible to tie down safely. (You then propagate that unsafety by `strcpy`ing out of it. This is not Java; either of these functions can trivially be exploited to piss all over your program’s memory with all kinds of exciting results. A cat could hijack your program accidentally.) `s` is not necessarily initialized before you start `strcmp`ing against it. Why do you keep running `main` if there’s no input data? You can’t possibly update anything, and the contents of the file won’t change since it’s nonexistent. Can you just Don’t use globals unless you need to, and mark them `static` unless you have some good reason to share them with other compilation units. Especially don’t use single-letter variable names for globals, not that you should be using single-letter names all that often anyway. (If you’re absolutely desperate not to type more than one letter because you’re not using a proper editor with proper autocomplete, use a proper editor with proper autocomplete.) Check all input. Anything coming in from outside your program is evil, and out to get you. You could hit EOF without reading a string with `gets`, you could hit EOF before reading in all of `e` (if you do, how do you know how many records you’ve read?), you could run out of space or hit a bad sector while writing, and input lines or fields could be any length—potentially teraabytes long, or in the case of something like `/dev/urandom` or `/dev/zero`, infinitely long. Don’t `getchar` to clear out the buffer after `scanf`, and certainly don’t just assume that the number ended cleanly with a newline (maybe it ended with `z` or `|` or SOH); generally don’t `scanf` at all, `fgets` to get an entire line and then `sscanf` out of that if you have to. (`scanf` is kind of an awful set of functions for most purposes. `strtoul` and `strtol` are muchmuch more useful if you just need numbers, since you can see exactly where the number starts and ends, you can handle multiple bases, and you can handle errors cleanly.) If you have to stick with `scanf`, throw a space at the end of the format string and it’ll suck up the newline after whatever input field(s), plus whatever other spaces or tabs. Not a great solution, but better than a blind `getchar`. If you’re doing almost anything with text, `fread` and `fwrite` are not what you want to use. You’ll have to do `fgets` and break down/reconstruct records yourself. It’s a bit tedious, but once you’re used to string handling it’s pretty easy. For things like your `i` and what you’ll presumably need for some stored count of input records, use unsigned types unless you have a good reason to deal with negative numbers. Since you’re storing in memory, `size_t` should suffice, but you might need to resort to something like UNIX/POSIX `off_t` or, failing that, `unsigned long long` for record counts. For things like what you’re doing on lines 38,39 or 47,48—which is almost certainly not what you want to do, but let’s pretend—there’s no reason to maintain separate buffers for your record and input strings. You’re loading an arbitrary number of characters into a buffer, then copying that arbitrary number of characters into the record. It’s actually twice as unsafe as just `gets`ing (again, don’t) into the record. Your `if` inside the `for` loop is only valid for a single iteration. You have no idea right there whether the ID actually exists or not, just whether the ID you’re currently considering matches what you’re looking for. Only once you’ve finished the `for` loop will you be able to determine whether you’ve matched. (And you `break` early, so everything after the match will be dropped from the file.) Finally, unless you have some external requirements dictating otherwise, it’s generally best to write error and prompt messages to `stderr`, which is (a.) more likely to be tied to a terminal, and (b.) more appropriate for things that aren’t primary output like what a filter (e.g., `more` or `grep`) would write to its stdout. It’s a good idea to get used to doing more rigorous messaging, with consistent capitalization, punctuation, and formatting—most stuff uses a small collection of messaging functions so they can just do msg_error("unable to open input file: %s\n", strerror(errno)); instead of bandying `printf`s and whatnot about.
So "s" + False will equal nothing printed? Am I understanding this correctly? 
There’s no outright prohibition, and if there were it’d be per-ABI. You can probably make an array that big if it’s a global or you declare it `static`, although there are no guarantees since systems with smaller (e.g., ≤32-bit) pointer sizes will need higher regions of memory for DLLs and the kernel area. Most OSes will let you twiddle the maximum stack size with things like `ulimit -s`, although you can’t necessarily access that entire amount of memory all in one go, you typically have to walk it down in smaller increments. Or you can allocate a big honking stack and use threads, ucontext (boo), or `sigaltstack` to ensure you have a big enough stack. For locals though, generally stick ≤64KiB per stack frame for 32-bit non-embedded, 128–256KiB for 64-bit non-embedded, and 4–16KiB for embedded and you’ll be fine.
That prints "s"
I have not downvoted anyone at any point in time on this thread, I know he still contributed to the thread even if not what I was looking for :)
I don't know what your end goal is but what jumped out at me was the fact you don't need `buff` at all, you could just write directly to the file, e.g. for(int i=0;i&lt;SIZE;i++) write(fd, "x", 1);
You have `"s"`. Note that you get a *pointer* (`char*`). Then you try to add the result of `bottles == 1`, which is either `0` or `1`. So if it is `1`, it is `1` and thus `"s" + 1` will move the pointer by the `"s"` to the next character, which is implicitly `'\0'`. In other way: char *plural_s = "s"; int is_one = (bottles == 1); printf("%d bottle%s of beer on the wall. %d bottle%s of beer.\n", bottles, plural_s + is_one, plural_s + is_one);
The simple chat I did started out on the same computer, one served and one listened. It then grew to support 2 different computers. I think that is as far as it got before I started doing sockets for a specific work project. You could go any direction that interests you - support for multiple users could be interesting. 
Probably, but then that introduces complexity to the language, as well as the code written in that language. I believe simple is better, it forces the programmer to spell out what he wants clearly.
It's called stack overflow. Extremely hard to debug in big applications, though quite obvious in your case.
I use UTF-8 strings with printf without issues, you can also use UTF-7 if you must. Are you sure printf doesn’t support Unicode? Unless you are using UTF-16 or worse UTF-32 and then I must ask why? Windows has wprintf but I don’t think it is standard C and it supports UTF-16.
Is there really such thing as "socket" programming? I think the term you're looking for is network programming - designing/implementing various protocols, which is a lot harder.
I'm very interested in that too if you have any resources you want to share.
You're doing `'s' + 1`, but the code is `"s" + 1`. If you aren't sure about the difference between single and double quotes in C then now would be a good time to review :) . (The comment you replied to explained it already)
On linux the stack size is typically 8MB
Adding 1 to a pointer gives a pointer pointing to the next memory location 
ok, thanks
`wprintf` is definitely standard, but `wchar_t` is compiler-dependent, so you don't get to pick which UTF to use.
That's exactly correct. `sizeof(*pointer)` is the size of whatever type *pointer* points to, but doesn't actually dereference the pointer. The value of `sizeof()` is actually computed at compile time, not run time. Here's an idiom I use a lot: Foo *pointer; ... len = sizeof(Foo); // bad len = sizeof(*pointer); // good; this is how I do it Why is the second way better? Because if someone later changes *pointer* to be some other type, or copies-and-pastes the code, and doesn't notice that `sizeof()` operator further down, then `sizeof(Foo)` becomes incorrect (and a *very* hard bug to find, possibly) while `sizeof(*pointer)` is still correct.
What do you mean by signature? 
my head hurts
True; and it's probably impossible to know the size of the stack at compile time.
no i swear
wt????
Then please rephrase what you are trying to ask and for the love of god use commas.
i need to know what is virus signatures i heared they are type of data what data exactly can you give me example?
flags?
what is flags
you gave me a headache 
Oh ok, i know what you're trying to ask, but this isn't really the subreddit for these kinds of questions "Your antivirus software relies on virus definitions to detect malware. That’s why it automatically downloads new, updated definition files – once a day or even more often. The definition files contain signatures for viruses and other malware that have been encountered in the wild. When an antivirus program scans a file and notices that the file matches a known piece of malware, the antivirus program stops the file from running, putting it into “quarantine.” Depending on your antivirus program’s settings, the antivirus program may automatically delete the file or you may be able to allow the file to run anyway, if you’re confident that it’s a false-positive." -HowToGeek https://www.howtogeek.com/125650/htg-explains-how-antivirus-software-works/
done
This is absolutely nothing to do with C.
Mark it as potentially harmful. But why do you want to know anyway? If you want to bypass antivirus, you might have some luck using a VM'd language. It compiles to bytecode, not assembly. Popular byte codes like MSIL and java byte code might get detected. So if you really want to hide, creating your own vm and bytecode will be the most effective as anti-viruses will have no idea about it.
Well, look at the last line of your question. Suppose you have a virus executable, and you create its hash using some algorithm. You then store it in a database. Suppose you then get another executable, generate its hash using the same algorithm as before, you find a match in your database, then you can be pretty sure that your executable is the same virus. Of course, no doubt AV software are far more complicated than that today, but that is how logically you could use hashes in this scenario.
Sure it does. There's a c in a few of those words!
The good thing about preloading the symbol is that you won't need to recompile everything to be able to use your function. This is very common in memory allocation libraries such as jemalloc, which offer this possibility for replacing the malloc calls to libc.
Do you mean Open Sound? I think [this](http://manuals.opensound.com/developer/programming.html) should be relevant although there might be some changes if you use an other version (which, on most systems you probably will). Maybe take a look at [SDL](https://www.libsdl.org/), it's a library which is cross platform and does support game development. For editing c code any editor will do but you might like an ide which is more helpful. Personally i use vi or emacs so i can't really recommend one. Otoh, there's nothing wrong with using a simple editor, it might even be better in the long run.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://www.libsdl.org/) - Previous text "SDL" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
It can only be known at runtime, since you don't know who called you.
Or `#define printf(...) _Static_assert(0, "error")` if you are using C11, for a clearer error message.
There is also _Static_assert, available in C11.
ah, well that depends on the package. It's quite a mess these days even with all these different build systems people use. If you are on windows i'd recommend looking for an installer. Otherwise maybe the source code has a visual c project included. For that to work you'll need to download Visual C which is, i believe, a free download (for a bit older version). Another newer alternative is to use the linux layer you can install on windows in which you can compile software or even better, just install a package. I believe it has a version of ubuntu so you could probably use apt-get for almost all the things. I haven't run windows in years however so i'm clueless about installing both.
I have Visual C but idk how to actually get it to launch.
I would like to know how I'm supposed to manually build things also
https://imgur.com/a/9laq8PI That is all thats in the readme. It doesnt explain much and its for people who does know how to do it.
You should open the file in program which understands unix/linux/mac line endings.
Good way into tricking people to think youre not using gotos :p
LoL
@gardeimasei: Everyone is in the end using goto's all the time, since all the iteration and conditional constructs in C are built on top of local jumps. 'Goto considered harmful' is not about never using goto, but only using goto when there is no higher-level flow construct available yet that does what you want to happen. ^_^ That said, the macro hoop-jumping that is required to write something that accepts a block (or in this case, possibly multiple blocks) definitely stretches even this definition somewhat, since this code really is hard to read. But then again, the consumer of this library does not need to care for its internals, of course. :-)
`char` isn't relevant to anything I said, but it also isn't inherently any particular encoding at all, it's just that \*some\* string manipulation functions will treat it according to the current locale, but that's unrelated to `printf` to which it's just bytes.
yup agree with your view on goto’s Powerful when used what they’re there for Generally try/catch can be regarded as a form of goto
Why can't you implement variable-length arrays in C++ the same way you would in C?
I might remember wrong but i think my teachers said that the program is slower if we write only 1 "x" each loop than if we write the whole thing with no loop, is that wrong?
No, that is correct. But you could also have a smaller buffer that you write out repeatedly.
&gt; Is there really such thing as "socket" programming? [Yes.](https://en.wikipedia.org/wiki/Berkeley_sockets)
**Berkeley sockets** Berkeley sockets is an application programming interface (API) for Internet sockets and Unix domain sockets, used for inter-process communication (IPC). It is commonly implemented as a library of linkable modules. It originated with the 4.2BSD Unix released in 1983. A socket is an abstract representation (handle) for the local endpoint of a network communication path. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Never used it, but [Port Audio](http://www.portaudio.com/) might be worth checking out. Depending on what you are trying to do, it might make sense to use a software synth that your program controls.
Try catch in linux kernel (c) is actually implememted with goto
They don't use BSD sockets. They use `pipe(2)` which predates them by ten years (UNIX v3, 1973, vs 4.2BSD, 1983).
The abstract machine has always supported some degree of non-sequential execution. Operations between sequence points don't have any particular ordering. But even sequence points themselves need not actually happen in order — or at all. Only to an observer do their effects have to *appear* to have happened in order and there are few ways to observe the insides of the abstract machine. C11 extended the abstract machine to support threads, most importantly defining some memory semantics. The actual C11 threading API isn't useful. Modern compilers will automatically do some SIMD vectorization if your data is structured for it. There is a [common set of compiler extensions](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#) that add SIMD intrinsics, with semantics that map onto the abstract machine. This is the most effective way to use SIMD in C today. 
Mmk ya that makes sense. So, if int a = 5; int *int_ptr = &amp;a; int y = *int_ptr; In the assignment expression to y, what does the compiler do when it evaluates '*int_ptr'? Does it just check the type of the rhs = the type of the lhs? It obviously doesn't return type 'int' or 4 bytes.. Whereas in this statement: sizeof(*int_ptr) The compiler evaluates '*int_ptr' and returns 'int' type..which sizeof(int) = 4 depending on the machine. Sorry if I am going off topic here but this threw me for a loop. Much obliged. 
you would think you could use your source code and compile it on a windows 7 machine and it run, but not have the newer features that .NET runtime has in 10. ˆI am sure you're close to figuring out what to do. Good luck
what .NET runtimes do they have 
Use md5sum to check the file isn't corrupted. Then check you are using the same binutils (and same bits) in both cases. 
Yeah, basically. **a** is int. **int_ptr** is a pointer to int. \***int_ptr** is an int. So sizeof(a) is the size of an int, sizeof(int_ptr) is the size of a pointer, and sizeof(\*int_ptr) is the size of an int. ---- For the most part, we tend to assume that all pointers are the same size, and one pointer can be reasonably cast to another. I.e. a char\* and an int\* pointer will be the same size and a valid int\* pointer can be converted to a valid char\* pointer. I don't know if the C standard requires this to be true, but I'm betting not. For example, 286 architecture has the concept of [near and far pointers](https://stackoverflow.com/questions/1749904/what-is-the-difference-between-far-pointers-and-near-pointers) where near pointers are 16 bits and far pointers are 32 bits. Generally, sizeof(pointer) is not of much use in C. You almost always want to know the size of whatever the pointer points to.
This can be done using a couple of loops. Any reason why it has to be an array?
.NET is for C#, not C (or, more accurately, object files produced by the compiler). So the .NET version doesn't matter at all.
make a function to draw the axes (what you have here) and a separate function to draw specific points inside
[Here](https://ideone.com/ipW0YX) is a very crude, loop only function plotter. No arrays needed. Determining when to plot a point, to make it look correct, is possibly the most tedious part.
A 2D array is an inefficient use of memory, as most of the space will be unused. You can simply have one array with the x values and another with the corresponding y values. For a more elegant solution, you can have an array of structs to store x and y together. You will have to print with a loop, line by line. It may be useful to sort the array by y value in descending order.
https://ispc.github.io/
Do you use the same toolchain on both computers? Can you show us one of these object files? Different toolchains have different object file formats, it could be that that's the issue.
You are mixing x86 and x64 object files. It sounds like your daughter's computer has x86 mingw installed. It's not going to know what to do with your x64 object file.
This sounds like it could be my issue. I was deliberately using slightly different toolchains to try to reproduce the error, and because I don't know what toolchain the client will be using. So is my goal, to supply a static library that will work on any 64-bit Windows 10 set-up, unattainable?
Yeah, I doubt it's that. I transferred the file via Google Drive, and the full-size was identical to the byte. Thanks though.
&gt; Hash, hex, and a bunch of other names all mean the same thing. so av does some kind of reverse enginnering? thank you very much
Okay, I'm trying to get my head around this; please stop me where I go wrong. The two computers are both amd64 (which is the same as x64?). But I've installed an x64 version of gcc (and nm, objdump, et cetera, which are all part of "the toolchain") on my computer, but an x86 version on my daughter's. My daughter's compiler works locally (compiles hello world, at least) because backward compatibility is built into the amd64 spec. Thus if I just compile my static library using an x86 version of gcc, people using any C compiler on Windows 10 should be able to use it.
Usually mingw-w64 is considered the "current version of mingw". The mingw that isn't mingw-w64 is old and rubbish.
So would it be reasonable to assume that, if the client knows what they're doing, they'll be using an x64 toolchain?
Yes, pretty much.
I wouldn't say so. They could use 32 bit mingw-w64 , or maybe a different compiler, who knows?
&gt; batshit insane I was starting to wonder.
This is called [default type promotion](https://www.eskimo.com/~scs/cclass/int/sx4cb.html), it is particularly important to understand when dealing with variable arguments such as printf. Essentially, if you call a function without first providing a prototype, it will assume certain types. In your sqrt example, the compiler already knows the prototype for sqrt, so all is well.
In C you can call a function without specifying its prototype, i.e. without the compiler knowing the number of arguments, their types and the return type of the function. This behaviour is somewhat different between standards and sometimes you might have to specify prototype or at least the return type of your function. Though it is always strongly recommended to do so. For example by including the corresponding header file, containing the declaration of the function you are going to use. If you want to use for example `sqrt` you have to `#include &lt;math.h&gt;` and in this case `sqrt(2)` will work as expected because the compiler will have all the necessary information to perform the right conversion. If the compiler sees a function call and does not have the prototype it has to make some assumptions. One assumption is that the return type is `int`. Another assumption is that the arguments to the function are `int`s or `double`s and the compiler would perform those conversions. Therefore it is sensible to declare the arguments of our own functions as `int`s and `double`s because they could also be potentially called without prototypes and in this case default assumptions of the compiler would be right.
Check out dlopen(), dlsym() and dlclose() in Linux. There is a similar mechanism in other OS’es
As fallback C has a default function template, should the dev dont specify what type are the argument, function return value. `int xxx (int) {return int;}` K&amp;R aint a good book for beginners or some coming from a high level programming language. You should complement it with \(C a Reference Manual\) if you dare keep reading K&amp;R
As you I am novice, but unlike you I gave on K&amp;R as I found it too fast and not exactly instructive for a total novice as I am! Maybe I am just dumb for that book! But King's book \(C a modern approach\) is better fit for me as he teaches as in a class! Well, He is a university teacher, anyway! &gt;Sorry for the runt
`sqrt(2)` would not work as expected if you did not `#include &lt;math.h&gt;` (and no other header happened to implicitly include it). I assume you are actually reading K&amp;R 2, since K&amp;R 1 was published before function prototypes existed.
If there is a declaration but no prototype then the return type is taken from the declaration. Also there are more arguments possible than `int` and `double`, e.g. pointers, structs, `long`
No, the antivirus software just looks at the hex instructions of the file. You can do that right now with websites like [www.hexed.it](https://hexed.it/) which basically just opens the file. It’s very simple and you can do that with any file. The hex code in the file directly correlates to the C code. So there isn’t really “reverse engineering”.
Yes, you are right. If there is no prototype but there is a declaration the compiler would be happy to use that. And the possible argument promotions are not limited to those to `int` or to `double`. I just wanted to restrict my answer to the specific details mentioned in the excerpt from the book. Probably that could be a little bit misleading.
By setting specific defines in a header file during the configuration process. You later use those defines in your code to conditionally introduce blocks of code depending on those libraries/options/etc. Example: - "configure" argument determines the value of "HAVE_PROC" in a generated "config.h" (it's actually the part where it's undefined or defined that's relevant here, not the value): https://github.com/hishamhm/htop/blob/04cc193e3c0c39ea47eb01d61a6866b32d70baea/configure.ac#L117 - "htop.c", having included "config.h", uses this define to guard a conditional block of code: https://github.com/hishamhm/htop/blob/04cc193e3c0c39ea47eb01d61a6866b32d70baea/htop.c#L184
If you compile on your computer with "-m32" it will work on your daughters. x64 has been around for a long time. Most likely both installs support x86 and x64 builds, but the x86 install defaults to x86 builds. You could also try compiling on your daughter's computer with -m64. Either way, they need to be the same architecture to link together. 
Probably, but maybe not -- depending on what kind of graph it is.
&gt; In the for loop, it just keep looping until the last space or tab and record that if it's the last, so what's the use of loop? As you said, it looks for the first position of a group of spaces and tabs. Not sure what you're asking. &gt; Why does it use line[mark++] = '\n'? Why not do line[mark] = '\0' directly? The program reads a block of text till it is filled, `EOF` or `'\n'` is being encountered. If there was a `'\n'` in the block, you want to preserve it. If you didn't do that, the `'\n'` would also get deleted and the entire text is on one line. Not very useful. &gt; what I am confused at is that in the for loop, why do `isblank(buf[index-1]` instead of `isblank(buf[index]`? Looking at the previous statement, `buf[index++] = c;`, `index` points to the *next* avilable space in the array to be written. As a side-effect in the `for(;isblank(buf[index-1]);--index )` loop, if `buf[index-1]` isn't blank, then `buf[index]` is the space after the non-blank character (which is blank). Then a `'\n'` is placed there to terminate the line. &gt; why do the `break` in the case? Seems like some leftover from previous code. It can indeed be removed, but the entire `case` statement can also be turned into a `if` statement. Ask the author personally, but I don't think you'd get a useful answer. &gt; why do if (c != EOF) again in the end? The author uses a buffer to read up to 2048 characters into the buffer (which is 1000 chars big, it seems this is a mistake). It stops after filling the buffer (`&amp;&amp; index &lt; 2048`), thus any line longer than 2048 would exit out of the loop and trigger a warning to inform the user, since it hasn't read the entire thing (no `EOF` encountered) but its buffer is full. 
Look in [the Remarks section](https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/crtdumpmemoryleaks): &gt; **_CrtDumpMemoryLeaks** calls _CrtMemCheckpoint to obtain the current state of the heap and then scans the state for blocks that have not been freed. When an unfreed block is encountered, _CrtDumpMemoryLeaks calls **_CrtMemDumpAllObjectsSince** to dump information for all the objects allocated in the heap from the start of program execution. [Another part in the documentation](https://docs.microsoft.com/en-us/visualstudio/debugger/crt-debug-heap-details#BKMK_Check_for_heap_integrity_and_memory_leaks), which describes additional actions it does: &gt; You can use a call to _CrtCheckMemory, for example, to check the heap's integrity at any point. This function inspects every memory block in the heap, verifies that the memory block header information is valid, and confirms that the buffers have not been modified. So you can use [`_CrtMemCheckpoint`](https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/crtmemcheckpoint) to get an `_CrtMemState` that you can [inspect](https://docs.microsoft.com/en-us/visualstudio/debugger/crt-debug-heap-details#BKMK_Heap_State_Reporting_Functions) it, which also contains a pointer to the latest allocated block in the (double) linked list, which you can [transerve and check](https://docs.microsoft.com/en-us/visualstudio/debugger/crt-debug-heap-details#BKMK_Find_buffer_overruns_with_debug_heap). To [detect an freed block](https://docs.microsoft.com/en-us/visualstudio/debugger/crt-debug-heap-details#BKMK_Types_of_blocks_on_the_debug_heap), you'd check the `nBlockUse` member whenever it is `_FREE_BLOCK` or not. All untested and taken from the documentation.
&gt; what is the best way to secure this table, so that I first have to enter my username and password before I can use all functions in the Key-Value-Store? Depends how the communication is. The client can just ask that and send it to the server. If the connection is persistent (e. g. TCP), you could create a custom command that logs you in and sets a state for that connection that it is authenticated. If it isn't persistent (e. g. UDP, HTTP), you could send the username and password in every request. You could also create a "session" and give it some ID that you can give it to the client so the client can identify itself with the session (like HTTP cookies). &gt; Is there something, so that I can lock all functions, and unlock if my username and passwort are correct? That is your job. You'd probably want to give the function some state parameter (or a new function that is then being called by the client) and using the state it can check whenever it is authenticated (and allowed) to do it. 
What does a declaration of a function without prototype look like?
Typical Linux programs do this detection at compile time using *autotools:* before compilation, a *configure* script determines what libraries are installed and creates a `config.h` file with appropriate configuration for your program. The program is then compiled to assume the existence of all libraries detected before.
Without arguments only: float function(); Without anything: function(); This applies in type expressions too; `(void (*)(void))` is a pointer to a function taking nothing and returning nothing, whereas `(void (*)())` is a pointer to a function taking who-the-fuck-knows and returning nothing. (This is a common fuckup when trying to use C++-compatible code in C.)
Indent code by four spaces on its own line, or Markdown formatting will take over and wreck things around asterisks. When you throw down a string literal, the compiler basically creates an array like static char ANONYMOUS[] = "Name"; When you assign that to a pointer, you’re aiming `name` at that array. (Always use `const char *` to refer to string literals. Writing to them is undefined behavior, and it’ll usually cause a crash since they’re shoved in the .rodata section or its equivalent, which is usually protected as read-only like code.) In your second example, you’re passing the value of `name`, which is an uninitialized pointer, to `getname`. If you had warnings enabled properly, you’d see that (a.) attempting to read the value of `name` when you pass it into `getname` is undefned behavior since `name` isn’t initialized, and (b.) attempting to `printf` `name` has the same problem. The compiler or code could come up with literally any value for the contents of an uninitialized variable, or do whatever it/they want (crash, crash spectacularly, erase your relatives); you’re quite lucky that `NULL` is all that showed up. What the body of `getname` does is assign the address of an array like `ANONYMOUS` to its argument variable, then promptly forget about that when it returns. (And since there’s nothing actually reading `name` after that assignment, the compiler’s free to eliminate any call to `getname` entirely; ditto for the body, and ditto for the anonymous array. This is probably another place where warnings would help.) Your first example works because you’re passing the address of `name` to `getname`. The address of `name` is readily available to the compiler regardless of `name`’s initialization state, so no bugginess there. `getname` receives the address, writes an address through it (to `main`’s `name`), and then when you `printf` `name` has an actual value.
[Ted Jensen's Tutorial on Pointers and Arrays in C](http://home.netcom.com/~tjensen/ptr/cpoint.htm)
So, if I understand what you're saying correctly, anytime I assign a string literal to a char pointer, the compiler stores the literal in an array at some memory location and assigns that location as the value of the char pointer. In my second example, I'm passing the value stored in my char pointer (which is supposed to be the address to a string literal stored in some array) but since I haven't initialised anything (the compiler did say unintialised variable) I'm basically passing nothing? And so, "Name" is getting stored at nowhere and I'm printing nulls? But in example one, I'm passing the address of the address holder, so the literal is stored in the address of the address holder, and when I'm printing it, printf looks at the address holder, sees that it's got some address stored in it, goes and looks there and finds "Name". Right?
Wrt string literals: Yes, basically. You’re not assigning the string literal itself to the pointer, you’re assigning its starting address. (You *can* assign a string literal in an array initializer, however: static char data[] = "A string"; The reason it looks like you’re able to assign a string literal to a pointer is because array-typed values [e.g., `data` or `"This"`] very easily/quickly “decay” to a pointer to the start of the array. So `sizeof(data) == 9` because `sizeof` captures the array type without it decaying, but `sizeof(data+0) == sizeof(char *)` because the `+0` coerces it to `char *`.) In your second example you’re not passing nothing, you’re passing end-of-decidability. Once you read an uninitialized value you trigger the dreaded ~~Lord Cthul~~undefined behavior, the function call may or may not happen, your program may or may not keep running sanely, etc. etc, or the program could for any number of reasons just skip the function call. What typically happens in a no-optimization scenario is that you read some arbitrary value out of memory or a register, and execution proceeds otherwise-normally. The function `getname` in version 2 is effectively identical to void do_nothing(void) {} Lemme walk through what the compiler sees if it’s optimizing at all. First, I’ll reassign variable names: int main(void) { char *name₀; getname(name₀); printf("%s\n", name₀); return 0; } void getname(char *name₁) { static char __ANON₀[5] = {'N', 'a', 'm', 'e', 0}; name₂ = &amp;__ANON₀[0]; // → __ANON₀+0 → __ANON₀ } (Note I used `name₂` for the `getname` assignment—an assignment is the same as substituting a new variable in for all future references to the variable.) Now we can see that by the end of `getname`, neither `name₁` nor `name₂` is ever read. This means that neither actually needs to have been written, so the compiler can rewrite it as void getname(void) { static char __ANON₀[6] …; } with the caveat that `getname` would only be `void(void)` from the compiler’s viewpoint, not from a language viewpoint. (It keeps type `void(char *)` whether or not the compiler eliminates the `char *` parameter.) And since nothing references `__ANON₀`, that can be dropped as well, leaving you with just `{}` as the body. Because `getname` isn’t declared `static`, the compiler will have to emit something along the lines of .globl getname getname: ret into its output so that other compilation units can reference it safely. From within the same compilation unit, we can back up to the call site getname(name₀); and see that—modulo undefined behavior—(a.) `name₀` doesn’t need to have been defined before the function call, because its value isn’t used anyway; and (b.) the entire call to `getname` can be eliminated because it doesn’t have any visible side-effects. So the body of `main` is basically reduced to printf("%s\n", __UNDEF__); return 0; (If `getname` were declared `static`, it would be eliminated entirely at this point.) The compiler would be free to cinch `__UNDEF__` to `NULL` if it wants, or literally do whatever. And your description of the second one is correct, yes. If you drop one level of reference, it’s exactly what’s happening in int x; getint(&amp;x); printf("%d\n", x); ... void getint(int *p) {*p = 1234;} except instead of `int` the value type is `char *`, and instead of `1234`, the value is the address of a `char` array.
It's a declaration, but you are correct it would not parse correctly. Then again, seeing as we do not want it to compile anyway I think I'd rather go with a clear error message over proper abstract source trees in this case, even if that means another compile later to catch other errors. A judgement call to be sure.
So if it’s wrapped as ((void)sizeof(struct { const volatile char __0; _Static_assert(0, "etc."); }), -1) then it should be the best of all possible worlds.
Wow, this is extremely comprehensive. Thanks a lot. Username definitely checks out. You've been a great help today. I had no idea so much happens in the back end. Definitely got a lot more to read up on. Thank you!
 for(i=0;i&lt;40;i++){ fptr=fopen("temp.txt", "w"); if(strcmp(e[i].id, x)!=0) fwrite(&amp;e[i], sizeof(e[i]), 1, fptr); } fclose(fptr); fptr=fopen("temp.txt", "a"); It looks like you're opening the same file 40 times in a row here, which doesn't make much sense. Also, you *really* need to fix your indentation - it'll make things much easier to understand. I've corrected it to some degree here, but in your code, lines 29-31 at first glance look like a compound statement, but they're not. Line 30 is the body of the if statement, and the following brace is for the for statement on line 27. My own coding standards disallow single-line if statements entirely. If you're going to use them, I'd suggest keeping them all on one line. Without consistent indentation to show the flow of the code, it's going to be very hard for anyone to read and easy for you to introduce mistakes. Maybe there was a problem with tabs vs spaces when you posted it, but many of those lines have no indentation at all.
+1 Clever; I like the way you think.
i want to learn how to reverse enginnering btw can you send me website where i can learn asm?
and thank you!!
and i wanna know does the reverse enginnering give the equilivent code to what c for example printf ("test"); it output it as echo "test" just giving you an example
I dont know much about the bound checking. I just realised about the opening of same file 40 times, and I think I did that out of frustration because my program wasn't working the way I wanted it to. I''ll work on consistent indentation for sure. Thanks.
I removed while(!feof(ptr)) because I realised it was not doing anything useful.
Yeah, in arch maybe, but what about say Ubuntu, where packages are precompiled?
Yes, I knew about these, but do these methods work the same as the linker? What if the linker has different search paths? Is there a chance of that happening?
But what about binary distributed packages?
&gt; But what about binary distributed packages? What about them? If they have been already compiled, they have been already configured and you're only left with runtime decisions.
Yes but there are packages that say "depends on sdl and, optionally, if you have youtube\-dl, you can also do this", that's what i'm interested in.
&gt; How do they know at runtime if and where is that installed? By trying to execute it from the standard paths.
Both editions of K&amp;R were released before the first formal C standard was released in 1989. Function prototypes weren't part of the original language and even after the first formal standard defined function prototypes in C many C compilers still did not support them (and old code didn't use them even if the compilers did support them) so you needed to understand the old rules. I don't have my C99 standard handy but [this Wikipedia article](https://en.wikipedia.org/wiki/Function_prototype) includes the following: &gt;This feature was removed from the C99 standard, thus omission of a function prototype will result in a compile error. Don't expect every compiler to report all errors (most don't report mixing function and object pointers by default for example) so take the time to see what flags your compiler takes to emit more warnings and errors.
Often you don't dlopen the library, but instead you write a plugin for you application. The plugin links to the optional library normally, and the application dlopens the plugin. One reason to do that is working with dlsym is a pain. You plug in will typically export a single symbol, and that symbol is a struct of function pointers. So you end up needing only one dlsym call, one cast, and everything else is normal C.
Thanks! I'm not sure of the use of the for loop, it just keeps record between `-1` and the index of the tab. Maybe for the last character before `/n`? And the `if` is about dealing with the last character if it's tab or space? Then if `line[i] == '\n'`, why `line[mark++] = '\n'`? The mark++ is exactly the same as the i.
What I'm puzzled at is that if line[i] == '\n', why line[mark++] = '\n'? The mark++ is exactly the same as the i. 
This is all dealt with using package managers and dynamic linking. The actual distribution dependencies are defined with the package, not the program.
Thanks, maybe i'll try it sometime
This is what I ended up doing: I used \-m32 to create a 32\-bit version of the static library, and also \-m64 to create a 64\-bit version. The plan is to ship both to the client \(after some further testing\). Thanks heaps.
`youtube-dl` is a program, not a library. To check if `youtube-dl` is installed, you just try to execute it. If that works, `youtube-dl` is installed. If not, it probably is not.
Hey, I fixed my indentations here https://ideone.com/RB6TMn Can you see where I am making a mistake in the program now?
So it is not possible to do that with libraries?
It is possible but it's a bit tedious. You can use `dlopen` to open a shared library and then use `dlsym` to find symbols in a library. Difficulties arise from the difficult places in which libraries could be installed, so this is usually not done. Unix (and by extension Linux) is an operating system designed around source code, not binaries. It is completely natural to demand a recompilation to make use of newly installed libraries.
r/shittyprogramming ?
( this is for 32 bit systems ) I don't know much about the C standard and compilers, but from an assembly perspective all arguments to a function will be passed as 4-byte aligned values on the stack. The cdecl calling convention also allows for some amount of blindness between the caller and callee regarding the arguments passed. #include &lt;stdio.h&gt; char __cdecl myCharFunc(char c) { printf("my char is: %x\n", (int)c); return c; } int __cdecl myIntFunc(int i) { printf("my int is: %x\n", i); return i; } typedef int (__cdecl *int_fn_ptr)(int); int main(void) { int argument = 0x123456; printf("my arg is: %x\n", argument); int_fn_ptr fn = myCharFunc; printf("calling myCharFunc...\n"); printf("returned %x\n", fn(argument)); fn = myIntFunc; printf("calling myIntFunc...\n"); printf("returned %x\n", fn(argument)); return 0; } $ gcc main.c -m32 -g -O0 $ ./a.out my arg is: 123456 calling myCharFunc... my char is: 56 returned 56 calling myIntFunc... my int is: 123456 returned 123456 In this code myCharFunc expects a 1 byte argument but knows it will actually receive an int because of 4 byte stack alignment. It will probably do a zero or sign-extended move to pull its argument off the stack into a register. If main() had called myCharFunc() directly rather than using a function pointer, then main() would have pushed only the lower byte of argument onto the stack rather than the entire int. With a prototype supplied the type conversion of the argument would have occurred in the caller ( main() ) and without a prototype the conversion must occur in the callee ( myCharFunc() ). Not sure if this helps answer your question, but I always found this type of stuff interesting!
The indentation of your for loops is still a bit out of whack in the version I'm seeing. I'm not clear what format you're trying to handle records in. You're reading them as data structures with fread() at line 28. For that to work, with all of the fields declared as char[], those entries will need to be fixed length - name[], for example, will always have to have 10 characters, including the terminating null. On lines 51 and 58 you're using fscanf() to... what? If it works, it'll *read* a record from fptr, not write one. If you made it fprintf() it'd write a record to the file, but not in the format you're looking for at line 28. You won't get a terminating null for each field and you won't get any blank spaces. It looks like you either want to use fprintf() to write the record in a delimited format and fscanf() to read it, or fwrite() to write a structure and fread() to read it. You don't want to mix the two. If you use fread() and fwrite(), the records will all be the same size so you can overwrite them in place in the original file if you need to.
I am not sure if this would help you but there is a function called malloc, this function gives you an amount of bytes on the heap of the memory. This function is executed on runtime some you could use it to perform some memory management, is very simple to free this memory. if you want some more details, let me know Greetings from Argentina 
I think Casey is saying that about memory because he's not doing any meaningful "management" of it in HMH. From what I've seen in his streams, he just allocates a chunk of ~2GB at the start of the game and uses that for pushing structs to it. Deallocating the memory is done at application termination by the OS. Ie, not doing it manually. :D He was also the one to say that he only accepts the context for the term "memory leak" in the case where you allocate memory in a loop. Otherwise I guess it's just "unfreed memory" that, as above, is handled by the OS at application termination. I'm not sure I completely agree with his philosophy, but objectively he's making sense. :)
In general, when I'm working on a subsystem, I don't want to think about the other subsystems, and I don't want to assume anything about how the other subsystems work or what they are doing. As I said, I might even want to add new subsystems later. If I'm assuming things about how they are going to work, I'm coupling (or complecting (i.e. making complex, intertwining), a word I like better) them together. If I can't work on one subsystem without thinking about everything else, that's a problem. This example of a game might now have been the best, but let's continue with it. Say the model subsystem is done with the character, because the character died or something, but the graphics subsystem wants to display some animations or whatever after the character died, so it still needs the character. Or some other subsystem wants to analyze and log events in the game and still needs the character. In order for me the programmer to decide that we are done with the memory, I have to consider every subsystem. It seems like a burden. I would like to be able to build my system out of simple components that I can consider individually without using a lot of spaghetti to tie them together.
In your expanded example here, the graphics subsystem would never free the memory for the character because some other subsystem might need it. Only free memory when you are absolutely done with it. Otherwise don't. Once you are certain that all the subsystems that might use that particular bit of memory no longer need it, then you can free it. Not before.
/r/cpp
There's no uniquely right answer to this, but I use a mixture of convention and documentation. By default, the function which created an object is responsible for destroying it. Responsibility can be passed to another function by documenting that this will happen in the comment header, or by incorporating the object into a larger data structure (eg. a linked list or a tree) that is already owned by another function. Oh, and regularly test your program using valgrind or similar to find out whether you missed anything. 
There are no exceptions in C. Are you getting an exception or a SIG?
And how do I know that a subsystem does not access the memory without thinking about it? Your answer to my overall question was "You the programmer are responsible." Ok, but I don't get how I can do it with, as Casey said, "almost no time" spent. You have not talked about how I'm supposed to manage it.
`&amp;array` == `array` (i.e. `&amp;workers[i].age` etc. is pointless) `void function( char * val[] )` == `void function( char ** val )` (i.e. the char pointer you're feeding your function gets treated as an array of char pointers instead) Also: compile with warnings, the compiler would have told you this!
Visual Studio is saying "Exception thrown: write access violation. *sub* was 0x1110142. 
You have no idea how to do something, then characterize it as "quick" and "it should not take longer than five minutes". Why not learn how to do it yourself?
Doesn't the "sizeof\(struct driver\)" gives us the entire length of the structure, and give access to the members of it to read it? I used the fwrite instead of fscanf and it is still not working properly. I am not really sure that we can over\-write in the original file with fwrite without the usage of fseek. I try to use fseek but the compiler gives me an error always. 
I need something done quickly and I am willing to pay. So, if you want to do it, then PM me. If not, then why bother commenting something like this? What's the point? I do have a general idea on how to do it, but paying someone to do it faster would be better for both. With that said, if you are interested, Pm me on here or on my discord mentioned above.
It sounds like the strategy you want to use in this case is [reference counting](https://www.google.com/amp/s/mortoray.com/2012/01/08/what-is-reference-counting/amp/)
&gt;Doesn't the "sizeof(struct driver)" gives us the entire length of the structure, and give access to the members of it to read it? Sure, but that assumes that what you're reading is actually the structure. You haven't posted the driver4.txt file so I don't know what's in it when you start, but what you're trying to write (if you used fprintf() instead of fscanf()) is not a structure, it's a text string. Your driver structure (disregarding packing) is going to be exactly 39 bytes long. 10 bytes are always the name, 4 bytes for ex, 10 for ID, and so on. fread() will read chunks of 39 bytes into your structures. If the file is really a text file, like the .txt extension implies, that's probably not what you want. If you used fprintf(fptr, "%s%s%s%s%s", ...) to write your records, you'll get each of those strings (name, ex, id, ...) back to back, with no spaces or delimiters of any kind. So the first question is are you working with fixed-length binary records, or variable-length text records? You can do fixed-length text records, of course, but you need to specify the lengths when you write them, and pad them with spaces or something. fread() and fwrite() read and write raw bytes without regard for what they are. fscanf() and fprintf() read and write text.
Thank you! I will definitely make sure to compile with warnings from now on. Also I have removed the pointers from the program and going line by line, I have found out the issue comes from trying to get the workers\[i\].zip from the file. I copy it as a string then convert it to a int, but it is still causing the issue.
You should go get yourself a [hex editor](https://www.hhdsoftware.com/free-hex-editor) and do a few test writes to understand what it's actually writing. Writing a struct with fwrite() writes an *exact*, byte-for-byte copy of what's in memory. fread() does the same thing in reverse. Let's say your line looks like this: "madsci abc 12345 100000 51 1" If you use fread() into your employee structure, you're going to get name="madsci abc", ex=" 123", id="45 100000 ", salary="51 1\r\n" followed by stuff from the next line, if there is one. Also, if you try to print employee.name, you're going to get "madsci abc 12345 100000 51 1" and probably a bunch of garbage, because there are no terminating nulls. employee.name just gives you an address, and a string command line printf() will start reading at that address and keeps going until it hits a 0. You didn't put any 0s there, so there aren't any and it'll read off into memory beyond that structure until it hits a 0 or gets a segfault. On the other hand, fscanf(fptr, "%s %s %s %s %s %s", employee.name, etc...) says that you're expecting a set of six strings and they should be copied into the specified locations. Keep in mind that if employee.name can have spaces in it, it's not going to work unless you have some other delimiter between records. I honestly rarely use fscanf() and I don't remember all of its quirks, but that's the gist. Normally you'd represent numeric values with numeric types in your structure. Age would be a number, so you might use 'unsigned int' instead of char[3]. In fscanf you'd specify %d instead of %s to tell it it's reading and converting from a string to an integer. With age stored as a string you couldn't do any math or numeric comparisons on it. And don't forget that the strings in your struct need to be large enough to hold the field *and* the 0. If you have a 100 year old employee, your code is going to break because age will be "100" and the 0 will get written into attend[]. If you don't have a debugger, throw some printf() statements in there to take a peek at what's going on. When you read something, print it out again so you can see what you got. Trying to figure out the whole thing at one go without seeing what's going on in the middle is going to be very difficult. Focus first on reading and make sure you can reliably read a driver record. You'll almost certainly be using fscanf(), or maybe fgets() to read it into a 1-line buffer and sscanf() to parse it from there. I'd probably prefer the latter, partly because I don't remember what fscanf() does with newlines. Most of the devices I work on don't even have a file system. You can't seek to a string with fseek(). It has no awareness of strings or lines - it'll just seek to a particular offset, which only helps if you have fixed-length records. You'll have to scan a line at a time to search for your record. Go try a fscanf() followed by a printf() to show what you got. And if you need more help, make sure you include the text file so we can see what you're working with.
You'll need two variables for that; one for the string and one for the integer.
This is a perfect example of keeping in mind the context for Casey's advice when he gives it. He's first and foremost a game developer, and he's generally looking at programming problems from that angle. If you're doing game development, I'm sure it's very spot on, but often he gives advice that makes less sense outside of that context. In HMH, and probably many of the other games he's worked on, there are two big ways he gets to avoid thinking much about memory management: 1. His program doesn't need to operate on arbitrarily large input or arbitrarily large structures. He allocates enough memory for the known worst case for the game, and that's it. This is the big allocation at the beginning of HMH. 2. The lifetime for most allocations is per-frame. This is where the stack-based allocation comes into play. He pushes structs onto a big buffer as needed to compute physics and rendering. Then when the frame is all done, he resets the stack pointer. Some structures live longer than strictly necessary, but it solves the problem really neatly and simply. 
C++ is off topic in this subreddit. Please post C++ posts elsewhere.
C++ is not on topic. Please don't post C++ content again in this subreddit.
Please don't post these.
This is a C subreddit, not a C# one. I've not done iOS development, but I'd Iook into events. And a timer that adds and removes an event callback, probably.
https://pbs.twimg.com/media/BA-7wDYCUAEmjiJ.jpg
How can it be a bug that a commented-out piece of code is skipped?
One way I've seen it done is basically doing explicit reference counting. Each subsystem "claims" interest in the memory by incrementing the counter and then "relinquishing its claim" by decrementing. When the counter becomes zero (or appropriate sentinel value depending on the counting scheme, if there's a manager that always has a claim, etc) then the memory gets freed. 
How much of programming are in embedded market? Ive hear that not that much, is it true?
Seems like a Unix issue and not a C issue. setbuf() works just fine for disabling stdout buffering. It's a valid concern, I'm just not sure this is the place for it.
C# is off topic in this subreddit. Please post C# questions to /r/csharp.
&gt; its not working right, What does that mean?
“its not working right” is not an error description. Read [this article](http://idownvotedbecau.se/itsnotworking/) and edit your post according to its suggestions.
And please take pride in your code which includes simple things like basic formatting and consistency. It will make people want to help you more when you show you care about your code. 
Casting the value that is being assigned (ie. the left-hand side of the operator). I think it may only work with pointers, in cases where the pointer is to be dereferenced. In the parent comment, I showed an example where I casted the lvalue (the original pointer) to a pointer of another type, and then assigned the data that was pointed-to as if it were a different type than that of the original pointer.
when I compile and run it in gcc it prints 1,0,0,0,0..... but when I do it in windows it works propely
Throwing a big guess, you need to link with libm to use the math library : gcc program.c -lm
At line 114, what is the value of `c`?
thanks.
hm its supposed to ne the last spot of the array used
Lines 112&amp;133 fill the entire array with the same number. At line 114, `c` is 100 so `vec[c]` is an out of bounds access. You don't need an array to display the Fibonacci series.