Just for your info, you can use EntityTypeConfiguration classes in your DbContext in EF Core 2.0: protected override void OnModelCreating (ModelBuilder builder) { base.OnModelCreating(builder); builder.ApplyConfiguration(new YourTypeConfiguration()); }
For developers who do not want to get deep into Redis I would emphasize simplicity. Make wrapper simple to use. Performance should be secondary concern. For performance-oriented developers the minimal wrapper that more closely reflects data structures of Redis would work better. 
Love Udemy but this post looks like spam. Not clicking.
I assure you they are not spam, you can kill me if you want.
Sure thing!
Thanks alot! Will add these to the list of features to be implemented
&gt;. . . ¿ alot ? . . . I THINK YOU MEANT **a lot** ^^I ^^AM ^^A ^^BOT^^^beep^boop!
What technology? Webforms, MVC, web api? 
Sorry, Webforms.
You could always store the events about the item rather than update the row. E.g. your even would be something like StockPriceChanged which contains the information you need, such as the stock item id and then the new price etc. You could then replay these events, applying them to a stock object to give you its state. This way you have a history of every event that's happened to the stock item and can get the state for any point in time ever. This may or not be overkill for your situation but hopefully it gives you an alternative to just updating the stock items row in the database which means you loose any context about how it got to the current state. Think of it like an accounting ledger.
I'm not sure if I'm deeply under-evaluating the complexity of what you're asking but surely a simple Dictionary relating timestamps (epoch or similar) to prices would be enough? As for the relational database, the same approach could be used. A table called "prices" with 2 columns, a time and a price.
LINQ query on a dictionary is just a serial search through every item. 
Really something as simple as StockId Price DateTime should be enough. Primary key on stock id and date time. I'd be tempted to put the clustered index on those two columns too.
So here's the rub with good ol' session - you are probably already pulling an entire object when you need it. Session is just a big dictionary that gets serialized and deserialized. So lets say you are dumping like 10k of data into session. Lets say 9.9k of it is a shopping cart and .1k is something like last time they touched a page (LastActiveTime). Retrieving and updating LastActiveTime means dealing with the whole 10k of data. No big deal, until you move to SQL Server storage. Now you are introducing some issues. So, anyways. Two common patterns for dealing with session. 1. A class named like SessionKeys. Dump a bunch of public constant string in here for each session key your app uses. 2. A class that wraps Session calls with getters and setters. So you'd have something like public SessionData { public DateTimeOffset LastActiveTime { get { return Session["LastActiveTime"] } set { Session["LastActiveTime"] = value } } } Anyways, long story short - session already works like you want to make it to work. And yes, it starts to shit itself quickly in larger apps. That's why the best practice here is going to not use session for anything more than the id and have custom code written to do the session management. Because once you do anything serious bad things quickly happen.
Seems fine to me except that you are at risk of information loss if the web server crashes or is restarted. Could the information be stored in a database instead?
Works for an accounting ledger, but use case #1 for viewing historical stock portfolio would be showing high, low, average for each stock in the portfolio for 1 day, 1 week, 1 month, 3 month, 1 years and 5 years. Use case #2 would be "show a chart for it" With a ledger data structure this would be an absolute nightmare to query against. And unlike an account ledger, you really don't care "when" a stock price changed. Stock prices could change a 1000 times in a minute - we wouldn't want to track each one of those. Or for an absurdly low volume stock it might take an hour between trades. In that case "filling in the blanks" would be problematic. 
Good work! Looks great!
Not so much, you even eluded to the 'solution' in your main comment, you snapshot the state at the time intervals you're interested in and keep that separately for easy querying, it's really not that much of a problem to do, you'd already be projecting the current state as events are happening anyway.
What I tried at the time was creating a wrapper that receives an IEnumerable&lt;T&gt; and a collection of property expressions. For each one of those properties, I called IEnumerable.ToLookup (note the differences between IDictionary and ILookup). Then it exposed a search method that received a predicate and used one of the lookups to perform the search. Never finished it, though.
I think it is this one: https://blogs.msdn.microsoft.com/mattwar/2008/11/18/linq-building-an-iqueryable-provider-series/ Otherwise, you can search for "c# custom linq provider" for more info
Same exact post in 19 different subreddits in less than a day. Sure smells like spam
Removed: Spam.
Basically, I would do it the same way as you described. Use three hast tables. Maybe place the list of object within a class, which also contains the Dictionaries with references to the lists objects. A good source for finding solutions is codeproject. Maybe you should check if this article provides a good solution: [Codeproject: Multi-Key-Generic-Dictionary](https://www.codeproject.com/Articles/32894/C-Multi-key-Generic-Dictionary) 
Why? That's been dead for 10 years
Alluded
Constructive...
Accurate...
Because not all systems magically gets updated out of the blue everytime #bigcorp invents a new platform/framework/technology.
Lmao if you really think that for webforms then you truly are lost
True - but in this case, sessions expire within a short space of time anyway. Pertinent, persistent data is already stored in SQL, the session is used to hold data whilst, for example, a profile is being built. 
That's pretty much my approach. SQL is being used to host persistent data anyway, short term session data is being used to hold information like the current elevation level, the last page visited in this session, data that needs to persist over state changes etc.
What? He didn't express any opinions. He just stated the fact that code generated 10 years doesn't magically sync with current tech.
While I agree with you about this. Lots of people still have to maintain legacy webforms products with managers who won’t entertain the idea of updating it as it currently ‘works’.
We have some massive webforms projects where I work. We had to wait for a big CMS to support MVC before moving to MVC from Webforms. It have taken us years. I am currently working om the last project to undergo the transformation. If you think it easy, you havent tried working such huge projects.
I am not sure this is the best way for small portfolio but for the large dataset with historical prices the data structure may look like this: (SecurityId, DataProviderId, StartDate, EndDate, Price). The trick here is “compaction” logic on Insert operation. Also not doing Update and Delete helps tremendously. From the database you need an index. Correct index or indices will let you retrieve data in the most efficient way. Relational database is a good choice.
I disagree with the idea that a db backed session can't scale in larger apps. Large apps tend to make lots of db calls on every request. Just don't expect it to perform faster than a db call. 
Point of DTOs is to have strongly typed objects, dynamic does not give you that.
[MSDN](https://msdn.microsoft.com/en-us/library/aa479041.aspx#aspnetsessionstate_topic5) seems to state that session is stored in-memory and is not serialised/deserialised so the above would be wrong; am I missing something?
Using the session object to store all session state in a webform is crusing for a bruising. Absolutely everyone on a team needs to be highly aware of every single thing being stored in session. Each page that needs session needs to bring in the entire session for the entire application. You are shipping around a crap ton of data you aren't using for no reason other than the fact it is easy to write Session["ShoppingCart"] over being explicit about how/when you want to persist and retrieve that data. Yeah, it *can* scale. But I'd rather use developer resources being explicit on how we are tracking transient user data rather than forcing them all to be super careful and hyper-aware about the entire application's session storage. Saying "we are already making a bunch of db calls anyways, what's another couple of useless database calls" is pretty much the opposite of a scaling strategy.
that's only for InProc mode. For all but the simpliest of apps you'll almost certainly move onto a state server, redis or a sql server backend for production eventually assuming you want fault-tolerance or are looking to scale out.
How did you fix it? I'm trying to implement the exact same thing.
&gt; In conclusion, using the C# dynamic keyword can make a code base smaller, easier to maintain, and require less typing IMO these "advantages" are highly debatable at best. Dynamic types are rarely easier to maintain, and less typing/smaller code bases is a pretty bad metric. DTOs take 30s to create, and actual typing tends to be a small percentage of total time "programming", in my experience.
I agree. Also performance isn't (wasn't? May have improved since I last checked) great especially on the memory side. 
The example is about reporting but the actual code is so abstract it has no relevance to reporting whatsoever. Amazing.
Assuming that the following holds true: * 1 Portfolio contains 0-to-many stocks * 1 stock entry has 0-to-many stock price entries Then you could have this (please note, I just whipped this up in a text editor quickly, so there could be mistakes): create table Portfolio ( PortfolioId int, constraint PK_Portfolio primary key (PortfolioId) ) create table Stock ( StockCode char(3), CurrentPrice decimal(10, 4) constraint PK_Stock primary key (StockCode) ) create table StockPriceHistory ( StockCode char(3), PriceDtm datetime2, Price decimal(10,4) not null, constraint PK_StockPrice primary key (StockCode, PriceDtm), constraint FK_StockPrice_Stock foreign key (StockCode) references Stock (StockCode) ) create table PortfolioStock ( PortfolioId int, StockCode char(3), constraint PK_PortfolioStock primary key (PortfolioId, StockCode), constraint FK_PortfolioStock_PortfolioId foreign key (PortfolioId) references Portfolio (PortfolioId), constraint FK_PortfolioStock_StockCode foreign key (StockCode) references Stock (StockCode) ) go create procedure UpdateStockPrice @StockCode char(3), @StockPrice decimal(10, 4) as -- Use a transaction to ensure the update/history insertion happen atomically. begin transaction -- Update the current price in the Stock table. update Stock set CurrentPrice = @StockPrice where StockCode = @StockCode -- Insert the new price in the StockPriceHistory table insert into StockPriceHistory (StockCode, PriceDtm, Price) values (@StockCode, GETUTCDATE(), @StockPrice) commit transaction go Note that this is simple and doesn't guard against things like concurrent modifications of the data.
Yep, I have it in the roadmap, however I’m a bit busy with my main project and looks like that it will be implemented not earlier than in February
Yes, you must register your service class with the container builder in the application. Referencing a nuget package only makes the packages types available to the application and nothing more.
The only thing I know of that kind of works like what you are asking for is [MEF](https://docs.microsoft.com/en-us/dotnet/framework/mef/)
Sadly that's all too common. I wish people would focus more on real world examples for this. Possibly taking them directly from the .NET Base Class Library or language-specific equivalent.
You are absolutely right, the client will be to register the components itself. You might know how you'd like them to use it, but really it should be left up to them. I have seen a few packages that included helpers for the more popular containers but they gave that up pretty quickly with the maintenance and support headaches.
(ÒДÓױ)
Will a List of tuples not do what you want? Then you can search item1 item2 etc.
The implementation in the article shows a dictionary of strategies to functions. To me that indicates that the language has evolved to a point where you no longer need the GOF book to guide you to the implementation. Here's a nice old slidedeck about design patterns and how most of them are 'are either invisible or simpler' in Lisp: https://norvig.com/design-patterns/design-patterns.pdf With modern day C# and Java it may be a good idea to revisit the state of affairs with regard to design patterns. 
Let me take a swing at this. Let's say you have this setup: Host Assembly DI Assembly/Container Builder =&gt; References to all NuGet packages which could be called in the container. Service 1 =&gt; References to Service 1's packages. Service 2 =&gt; Reference to Service 2's packages.
I fixed it with the following code, which is almost the same as the one above only I failed to properly configure Form2_Load. Configuring the Form2_Load fixed the issue. private void timer1_Tick(object sender, EventArgs e) { try { Ping ping = new Ping(); PingReply pingStatus = ping.Send("srvasdm01eonl.kuiken.nl"); if (pingStatus.Status != IPStatus.Success) { label6.Text = "offline"; label6.ForeColor = Color.Red; } else if (pingStatus.Status == IPStatus.Success) { label6.Text = "online"; label6.ForeColor = Color.Lime; } } catch (PingException) { // Discard PingExceptions } } private void label5_Click(object sender, EventArgs e) { } private void Form2_Load_1(object sender, EventArgs e) { timer1.Interval = 5000; timer1.Enabled = true; timer1.Tick += new EventHandler(timer1_Tick); timer1.Start();
Great article, hope it will spread wide as it's damn too common to see switch statements in OO languages ;) Cheers
It isn't, since you still need to get to the DLR whose performance gets better over time when it has the time to cache, but than you have problems with memory. So in the end you have higher CPU time needed and bigger memory consumption for something that doesn't even give you design time help.
Have you downloaded the demo projects from Codeproject and used or created the InlineILCompiler.exe provided with these? Have you then added the described lines to the Post-Build events? And have you used exactly the described tags "#if IL" and "#endif"? What exactly is going wrong. It's a bit difficult to help without getting a description about the problem. Basically, all necessary steps are in the Codeproject article. 
To anyone reading this and thinking this would be a good idea: please, for the sake of the sanity of your coworkers, do not do this..
On the other hand, a reflection-based approach would never fly in production. If you find yourself in a situation where you believe reflection is the elegant solution, then you need to revisit your problem. In this case, the switch statement or dictionary (consider using `Lazy&lt;T&gt;` to defer object initialization until it's actually needed) really is the elegant solution. If you really have hundreds of concrete implementations from multiple contributors that you're dealing with, it's time to consider a plugin architecture (and now you have other problems, not the least of which is security). If you're implementing those all in one assembly, then you may as well write the one or two extra lines of code to add them to your dictionary or switch statement.
'If you find yourself in a situation where you believe reflection is the elegant solution, then you need to revisit your problem.' I love that sentence ;) And sure, I am not claiming that switch statement is completely useless but strategy pattern is something I'd love to have interns/junior devs understand and use (when applicable ofc)
To be fair, I cribbed it at least spiritually from my favorite quote of all time (at least with respect to programming): &gt; Some people, when confronted with a problem, think, "I know, I'll use regular expressions." Now they have two problems. - jwz Also, a dictionary or switch implementation is still technically the strategy pattern if implemented correctly. All the reflection solution does is remove two lines of code that the strategy-implementing developer must otherwise write to participate in the pattern, in favor of a less robust, bug and security-prone solution. Great for examples on the web, not so great for something you want to ship (semi-acceptable for unit tests, though if you're implementing the strategy pattern in a unit test you're probably not unit testing correctly).
It reduces the API surface of the interface, though, and the extension methods can then be tested separately.
&gt; Plus he is being a moron. That might be a bit drastic to assume, don't you think?
&gt; If you find yourself in a situation where you believe reflection is the elegant solution, then you need to revisit your problem What if I need to be able to load modules for my program, at runtime? Right now, my solution is to have an interface in a separate assembly, and check DLLs in a specific folder; if a DLL contains a class implementing that interface, it's a module and I can use it (by using said interface).
The reason for the dictionaries is O(1) search time. The list will do the job, just slowly.
No
I don't know if there are any convenient solutions to just embedding IL in a single method. One option is to move all your IL stuff to a separate assembly and call ILASM as part of your build steps. I think corefx does that for some of the unsafe helpers. If you want to replace/insert a single method in a larger assembly, you could have a look at Fody. You'll probably have to write a custom Fody weaver plugin for this.
Yes, that's absolutely the right way to handle construction failures. Although you might consider creating an `Init()` method instead, if you actually need to be able to use the object even if it is not successfully initialized.
That agrees with the conclusion of the article: **Conclusion** *Always keep in mind what the impact of complex logic within constructor might be.* *You may shoot yourself and observe really weird non-deterministic issues or repeating support cases because of unreadable log files.* *For me personally - avoiding the complex logic during the object construction is the preferred way of coding.*
I basically just want to be able to arbitrarily execute IL code. Like the __asm keyword in C++.
&gt; On the other hand, a reflection-based approach would never fly in production. If you find yourself in a situation where you believe reflection is the elegant solution, then you need to revisit your problem. I'd like to hear more about this. I absolutely love reflection and use it frequently. Some major advantages: 1. It reduces the distance between data and metadata. Instead of using a dictionary to classify/group methods, I use attributes &amp; reflection. Sometimes it makes sense to decouple methods from their metadata--in particular, if it might change during runtime--but often the reflection is taking place in a base class and the attributes merely inform the base class how to treat the new methods. A really powerful example of this is the entire ASP.NET MVC paradigm and System.ComponentModel.DataAnnotations. Adding decorations to methods is such an elegant way of changing behavior! 2. It's a great way to build low-latency static cross-reference tables. Build an enum, decorate it with attributes, and you have a cross-reference table that doesn't break if there are data connectivity errors (as it would if it were in a SQL table) and that can actually house functionality (for example, attributes can sanitize data, whereas a SQL cross reference table value can only have a corresponding method that needs to be called, often with a string literal instead of a code-change-compatible nameof(Method) convention). A really common use of this is Enums with DisplayName attributes. 3. It plays really nicely with LINQ. Reflection would be useless without LINQ. LINQ makes Reflection paradigms beautiful. Without it, Reflection would involve lots and LOTS of loops. 4. It separates high-traffic code from low-traffic code. Bury your complex logic in a base class that uses reflection, then have nice simple child classes. The less times people need to change the core code of your app, the better. And if somebody *does* touch it and something goes wrong, you don't need to sort through the 1,000 times that somebody had to go in to a class to add a property or something. The disadvantages are also considerable and limit the times when Reflection should be applied. Two in particular come to mind: 1. Performance can be poor. However, this isn't as big a deal as some people make it. After first run, it can be as performant as a dictionary because reflection can be used to generate the same dictionary you're otherwise creating by hand. I've only had to do so once or twice, though. 2. It can make for pretty cryptic code. Crappy Reflection code is worse than other crappy code. Documention is important. Sensible design patters are important. Anyways I'd love to hear your thoughts on why it's never a good approach. It may be that I'm overusing it, and if so, I want to know!
Why not go one step further? A specification is a `Func&lt;T, bool&gt;` (also known as a `Predicate&lt;bool&gt;`). If this contains too little type information for your taste, just create a named generic delegate type `Spec::Specification&lt;T&gt;`: public static Spec { public delegate bool Specification&lt;T&gt;(T value); } Your specification declarations become more idiomatic static member functions: public static bool IsDomesticOrder(Order order) =&gt; order.ShippingAddress.Country == "USA"; public static bool IsHighValue(Order order) =&gt; order.Value &gt; 100; public static bool IsHazardous(Order order) =&gt; candidate.OrderItems.Count(x =&gt; x.ContainsHazardousMaterial) &gt; 0; public static bool IsInStock(Order order) =&gt; candidate.OrderItems.Count(item =&gt; !item.IsInStock) == 0; Combining several specifications together can now be done with natural C# syntax instead of methods called `And` or `Not`: public static bool IsRushOrder(Order order) =&gt; IsDomesticOrder(order) &amp;&amp; IsHighValue(order) &amp;&amp; IsInStock(order) &amp;&amp; !IsHazardous(order); 
It is. Microsoft says that themselves actually. As taken from this [link](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/constructor). But only if you keep the object initialization simple, IMO. `✓ DO throw exceptions from instance constructors, if appropriate.`
I agree with this - as mentioned in Conclusion cited below - do it but only if that is simple and straightforward.
Maybe this helps? =&gt; https://stackoverflow.com/questions/36179304/dynamic-url-rewriting-with-mvc-and-asp-net-core
&gt; Exception occurred while: Calling constructor MyDataReader(). Exception is: AggregateException - One or more errors occurred. This is pretty clear, is it not? AggregateException is what one gets when async calls fail, too. Yes, throwing from a constructor is a good idea. If there is a setup problem (case here), it's best to crash as quickly and as loudly as possible . The TFA solution to use Lazy could be interesting if the goal is to start up faster - but the the price is a bigger possibility of failures "at runtime". IOW, Lazy is bad in this situation.
From that same link: &gt; ✓ DO minimal work in the constructor. &gt; Constructors should not do much work other than capture the constructor parameters. The cost of any other processing should be delayed until required. I would say it is OK to `throw` in a constructor if not doing so would leave your object in a partially initialized state. An object should be either constructed "uninitialized" with some sort of initialization routine or "initialized" with a valid object and no initialization pattern. This is particularly meaningful with an immutable type. Since immutability would mean you cannot mutate it with an initializer, a constructor that would trigger an invalid state should raise an exception.
Do you really need to do this, though? A plugin system is one of those things that every developer will implement at least once (and some developers will keep reimplementing over and over their entire career), but in most cases it's the wrong thing to do for the project. It's fun and interesting, and at the same time destroys code understandability and maintainability. Most projects don't need anywhere near such flexibility, and it's a pretty good bet yours is the same (think about what you are doing that nuget and design-time project references are insufficient and you need to dynamically load any arbitrary assembly?). Reflection (though not necessarily arbitrary module loading) is certainly useful if you're building a framework. Most people aren't, and shouldn't be, building frameworks.
Ok, I see what you meant. Indeed, I probably don't need such flexibility. But if I did need it, there wouldn't be a non-reflection solution. Then again, it is indeed pretty fun and interesting, even though it's harder to "read" than just static references. But on the other hand, you gain a program that is dead easy to add functionalities to, given you know the guidelines. In the end, it's probably wiser to go the static way... But I'm in no way old enough to be this wise :D
That isn't an assumption. That is my conclusion after reading the entire article.
For my purposes, I'm simplisitically categorizing code into two buckets - product code, and framework code. Product code is the code written specifically to solve whatever problem you're working. In this case, let's say you're writing a web service to do something. Framework code is the reusable pieces of code needed to build that thing. In our example, if the product is a web service, the framework would be things like Newtonsoft's Json.NET and ASP.NET Web API. Those frameworks certainly rely a lot on attributes, and obviously parsing attributes involves reflection, but the point is that's being done in a framework that hopefully has high traffic/usage and lots of eyes on it, not in your product code. Your first example illustrates this -- the reflection heavy lifting is in the ASP.NET MVC framework that's hopefully been vetted by thousands of firms, millions of developers, and not in your product code that's touched by dozens. I'd argue your second example is also an example of framework code, for example PropertyName on JsonPropertyAttribute to let you follow camelCasing json format standards while keeping PascalCasing C# Property format standards. The reflection is in the json framework, not your code. (IMHO, I wouldn't argue that nameof() is reflection; it's part of the C# language and is handled at compile time, not runtime). Similarly, your fourth example defines framework code vs. product code. Your third example is another pet peeve, as I tend to avoid heavy LINQ usage in production code for the same reason I avoid reflection -- its performance and behavior is opaque, and the code is often confusing to newer developers. But I get I'm in the minority on that, so I won't belabor that point. To me, the most important piece is your second disadvantage. Reflection leads to unmaintainable code, and significantly hinders the ramp up time of new developers. We all want to look smart and write fancy code, and it certainly feels good to bust out a really elegant piece of code now and then. But if you step back and look at that code from the eyes of sustained engineering, is it readable by a new college grad? Will you remember what it does 5 years from now? If it breaks, will someone be able to figure out how and why it broke at 2am on a holiday? Will you be able to diagnose performance issues when (not if) they arise? I once had a manager whose mantra was "Don't do fancy shit". LINQ is fancy shit. Reflection is fancy shit. That doesn't mean you can't or shouldn't use those. It just means you better have a very good justification as to why you need that, and that justification better hold up when you've accidentally taken the site down and everybody's running around like the world's on fire (because it is).
I also did something similar with middleware changing request URL based on form parameters. Since it happens before MVC gets invoked, it works just as if the URL was different from the beginning. It also works great with wildcard URL that handle unknown tokens. 
There's a reason I specifically used the phrase "in production". Reflection is something fun to play around with in personal projects. It's not something you want to troubleshoot at 2am on a holiday with the world burning up around you and management screaming at you. I'm not saying "don't do it". I'm saying "think about your product, and whether or not this is the smart thing to do for reliability and maintenance, even if it does feel more elegant from a development perspective."
Thank you Dathen for replying. I didn't know if this was helpful because I'm a beginner myself.
Weird example, though. Feels kind of like a strawman. You're not forced to nest 47 ifs and use the worst LINQ invocations ever just because you don't wrap all the logic in this s.... stuff. What if I told you there's a less retarded way to AND logical values together? It's called, spoiler alert, **and**! public bool IsRush() =&gt; ShippingAddress.Country == "USA" &amp;&amp; OrderTotal &gt; 100 &amp;&amp; OrderItems.Count(item =&gt; !item.IsInStock) == 0 &amp;&amp; OrderItems.Count(item =&gt; item.ContainsHazardousMaterial) == 0 Now, if only there were an easier way to check if **all** elements, or, for that matter, **any** element in an enumerable satisfies a condition? Like "item is out of stock"? [Oh, right!](https://m.popkey.co/8d0cf0/6MYdb.gif) public bool IsRush() =&gt; ShippingAddress.Country == "USA" &amp;&amp; OrderTotal &gt; 100 &amp;&amp; OrderItems.All(item =&gt; item.IsInStock) &amp;&amp; !OrderItems.Any(item =&gt; item.ContainsHazardousMaterial) But for real though, tell me how doubling the lines of code while still essentially adding *nothing* of value makes this simpler. I'm not saying the pattern needs to be crap, but it **needs** a better example/"pain story" than "I want to write twice the amount of code".
My suggestion is to create a cost comparison algorithm to determine the best price for an item, like a TV. You can actually explore GitHub projects by language, so definitely peruse through that -- find something that doesn't look too prohibitive and play around with it! Holberton School (https://www.holbertonschool.com/)
The problem with this example is the original code wasn't that horrible looking. The reality is that we often are refactoring code that looks much worse which is why we have to refactor. Watch this video if you want to see how to really do refactoring of a complex, large codebase like an expert. This is required viewing for any of my developers. It also emphasizes the value of unit tests all the way thru. https://www.youtube.com/watch?v=aWiwDdx_rdo
My first thought upon seeing this would be a potentially serious overposting/overbinding vulnerability. What happens when your client modifies the POST to send a few thousand extra JSON properties? At this point you'd be at risk in a couple ways: 1) Incurring the CPU/memory allocation expense of deserializing an unnecessarily large payload. Since you specify dynamic the serializer can no longer ignore all of the extra information and has to assume you may need it. 2) If that dynamic object gets passed to another library or function which does any dynamic reflection, your may start executing branches you did not expect.
I mean, the starting point example was way overdone and too simple, but we've all seen the method with 3 different sets of triple-deep nested ifs that have no business existing. 
If I am understanding what you mean, it's done in two parts. Part 1 - set the variable (do something) Session["MyVariableName"] = "Hello. I am a Session Variable"; (do something else) Part 2 - check the variable (do another thing on another page) if (Session["MyVariableName"] != null) { String s = Session["MyVariableName"].toString(); (do something that uses the String s you just extracted) } else { (do something if the variable is not set) } This ensures that you check the session variable has a value first, then extracts it. You can also add extra code to check it is a string once you've extracted it if you want. This works for most variable types - int, String, float etc. For more complex types - classes and the like - you need to cast it when you extract it. Session["MyComplexType"] = MyClassOneVariable; MyClassOne mcov = (MyClassOne)Session["MyComplexType"]; and so on. Hope that helps :) 
Why not: static void Main(string[] args) { string poem = "Mary had a little lamb its fleece was as white as snow"; for (int i = poem.Length - 1; i &gt;= 0; i--) { Console.Write(poem[i]); } Console.ReadKey(); } No split, no array reversal, etc.
You could probably add a middleware for this if you don't find anything more suitable built in. It's a fairly common pattern in ASP Core for middlewares to check URLs and take control if they find a URL they want to manage. OAuth is an example of this, which has a special endpoint for auth, which isn't set up on a controller.
Nice progression in explaining the pattern, but you left out dependency injection and unit testing which are two of the big uses of this pattern.
I scratch my head when I hear naysayers on an issue like this. Obviously the demand exists for a way to implement an interface member. Obviously we don't have multiple-inheritance. You call the guy a moron for giving a workaround. I get the awful feeling your response would be "framework doesn't let you, so you are dumb." I.e. not productive, /r/gatekeeping. 
Has absolutely nothing to do with r/gatekeeping Keep scratching your head because my stance on this is not changing. It seems like your biggest gripe is with the word "moron". If that is the case, then [sorry, not sorry](https://www.youtube.com/watch?v=-MsvER1dpjM) &gt; I get the awful feeling your response to "ok, how do you propose we do this" would be "framework doesn't let you, so you are dumb." No that isn't the case. His article title and overview are misleading and click bait. That is my issue. &gt; When you write an extension method for an interface, you’re actually providing it with implementation. My original point, which seems to be missed, is that his statement is not true.
I think I understand where you're coming from. There's a risk/reward equation that comes into play whenever you get "fancy" with your code. That's doubly true in large teams, where things like good documentation can be much harder to enforce. There's one mitigating factor, which is that a properly constructed and documented framework can make maintaining and adding code faster and less error prone by making high-touch objects simpler. In other words, you get to choose where your complexity goes, and spreading it out evenly isn't always the best solution. Plus, DRY, right? :) &gt;LINQ is fancy shit I don't agree with the idea of LINQ being fancy. For the most part, LINQ is a prettier way to write loops. It also produced code that come much closer to expressing a human thought by abstracting things like control logic and tracking variables. The performance is quite excellent in all but the most demanding situations. &gt;Reflection is fancy shit. That doesn't mean you can't or shouldn't use those. It just means you better have a very good justification as to why you need that, and that justification better hold up when you've accidentally taken the site down and everybody's running around like the world's on fire (because it is). I totally agree. 100%.
Depending on what you are looking for out of the box .net AES encryption can do everything you possibly need. However I see it allow you to interface with different targets such as SSH. IMO this is the only reason why you would want this library. Don't buy it because you need to encrypt something.
Thank you. Have you used this library?
To add to this, if you have a JSON response or request you can "Paste JSON as Class" in Visual studio. Making DTOs barely takes any time at all.
&gt; I don't agree with the idea of LINQ being fancy. LINQ is great. I love LINQ. The code you can write with LINQ (as long as you stay away from the SQL-ish syntax) is pretty, concise, and meaningful. It also obfuscates everything and can lead to unintentional or unexpected performance problems and other side effects. [This](https://www.reddit.com/r/csharp/comments/7ih2fv/is_there_a_better_way_to_answer_this_question/dqyrj9s/) is a perfect example. Trivial code, right? The LINQ looks pretty, easy to read, does exactly what you want. And is 3x slower than writing the loop yourself. The non-LINQ loop isn't as pretty, but it should be just as easy to read. That's not to say the LINQ couldn't be just as fast, but if you don't understand what it's doing then you have no hope of understanding that's where your bottleneck is and why you're getting those 2am pages. That's where it's "Fancy shit". I'm not advocating throwing it out of your toolkit, only using it sparingly where you understand what it's doing. Education and experience will make that moot, but you have to think about more than just your own education and experience. You have to think about all of your team members, from the most senior to the most junior, because any one of them could be the one who gets the 2am page or gets the "investigate why our performance is tanking" bug. If the code you write isn't immediately obvious for them to understand, then your code needs to be better. Some people only work with total rockstars with 50 years of experience in C#, or by themselves where they don't have to worry about other people understanding or maintaining their code. I don't have that luxury, and I'd expect most people don't either. So you write your clever code, you feel good about it, and then you rewrite it as understandable code (and then someone ends up refactoring it into helper functions, and then someone else realizes "These helper functions look like LINQ" and converts to LINQ, and then someone else notices a performance issue was introduced with that commit, and then you start the whole cycle over).
I don't totally understand what you're trying to do, but on page 2 you never initialize the "name" variable. You declare it, and you use it, but you never set it to anything.
basically page 1 is a page to sign up page 2 is to login page 3 is where the content works but currently when running the project it just results in going between page 1 and 2 but im unsure as to why. do you think it could be the non initialised name variable ?
Well like I say, I don't understand what you're trying to do and reiterating what you said in the original post isn't helping. But the code as-is is wrong. You're using a variable that you haven't set to anything. So regardless of what you're trying to do, you need to figure that out. Any time there's a piece of code that goes "declare variable, use variable" without an "assign variable" between those two lines, there's something wrong. The compiler should be at least warning you about this as well.
sorry the "username" on page 2 should be just "name"
&gt;The problem with this example is the original code wasn't that horrible looking. The reality is that we often are refactoring code that looks much worse which is why we have to refactor. &gt; Exactly. I would call out the author for over-engineering if they did this for the given example. 
&gt;This is a perfect example. I mean, the LINQ isn't really the problem there, it's conversion to a generic collection and performing work within an anonymous function, neither of which is related to LINQ. That's an issue with generic collections which are DEFINITELY overused. You'll notice a company comments down that someone kept the LINQ but changed that part, and the performance was comparable. &gt;If the code you write isn't immediately obvious for them to understand, then your code needs to be better. I don't think that's a fair statement. Some concepts *really are complex*, and code doesn't make them *less* complex. So the question is, how much complexity does your code *add* to the inherent complexity of the concept. For example. At your company, you realize that you need to contact all your US customers that have had a credit card transaction on an order this year. I need an output of all the customers sorted by last name. In LINQ (db is my data source, likely EF), I do this: var list = db.Customers.Where(c =&gt; c.Country == "US") .Where(c =&gt; c.Orders.Where(o =&gt; o.Date &gt;= startDate) .SelectMany(o =&gt; o.Transactions) .Any(t =&gt; t.TenderType == TenderTypes.CreditCard)) .OrderByDescending(c =&gt; c.LastName); The best thing about this code is that every line (except arguably for one) directly correlates to a specific way I want to filter the data. It's functional programming within an OO scope. And it's so easy to figure out what it does! Even someone entirely unfamiliar with LINQ could figure out most of it. Compare that to traditional loops, which would include at least three nested foreach statements, non-linear continue statements for efficiency, and at least one tracking variable to break out of nested loops. I'd be impressed if you could do in in less than 25 lines of code, and *that's not even counting the sorting algorithm*. For my money, LINQ is adding a lot less complexity in situations like this. ---------- Ultimately I think we agree on all of this in theory. In practice I think I've had more experiences where I've felt like LINQ was justified, whereas you've been bitten on the ass by LINQ a few more times. It's not surprising that different careers have yielded different perspectives.
https://code.msdn.microsoft.com/windowsdesktop/Simple-Calculator-MEF-1152654e 
Well, now we get to talk about using the right tool for the job, which is a completely different discussion. I wouldn't have done that query in C#. I'd have written it in T-SQL and executed that directly (LINQ to SQL hides the "to SQL" part, which is good for easily replacing your backing store but bad for understanding the shape and performance characteristics of your data), probably as a one-off from Powershell. But then I also come from an old SQL background where I've done enough query performance tuning to last me a lifetime, so my immediate concerns are things like "What's the query plan for that end up looking like?" and "Do you have the right indexes in place, and are you sure that query's going to use them?". With plain T-SQL, I can figure that out on my own. But that's nitpicky, and you're right. LINQ absolutely has its uses, and you've provided a perfect counterpoint. But I still think it falls under "Don't do fancy shit", because the unwritten part is "unless you have good reason". This is good reason.
I have used this library at work (Healthcare) with some clients that php encrypt their files.
They have a free trial, why don't you try it? Also if you need only encryption features you may take a look at https://www.bouncycastle.org/csharp/index.html
&gt; We're rebuilding our e-commerce site, and the marketing and customer service teams want the ability to manage their own webpages for various topics. So, are you on some sort of CMS? Allowing non-IT folks to manage content is kinda a core feature of a content management system... Anyway, your DB-based approach could work, but this really, really seems like something that should be handled by a CMS. 
So now I'm annoyed because I was having fun but now we agree on everything. *Sigh*
I'm glad you mentioned the Linq improvements. I'm fairly novice at C# and that was my initial reaction, too. Thanks for confirming it! 
You could clear or null that session object at certain periods if you needed it or look at local data sources, nosql dbs for quick dump and retrieval 
Hands up if you'd far prefer to work with the original code than what was written by the end of this acticle.
Or especially, the more straightforward, less obfuscated version of the original that would be written in practice: public bool IsRush() { return ShippingAddress.Country == "USA" &amp;&amp; OrderTotal &gt; 100 &amp;&amp; OrderItems.Count(item =&gt; !item.IsInStock) == 0 &amp;&amp; OrderItems.Count(item =&gt; item.ContainsHazardousMaterial) == 0; } 
Reflection is often a critical feature relied on by some of the most popular libraries in .NET. Such as IoC libraries, serialization libraries and even ASP. Reflection is one of the most important features in .NET and many large libraries, tools and frameworks either rely on it or rely on it indirectly. Hopefully you didn't mean in general, and meant just for this case, but if you did I really have to disagree.
There are some post-buil VS plugins for that. I don't recall their name. I have always just used ILASM for that. I understand the need, since generic pointers can be done in IL but not C#, but VS and C# can't handle inlined IL out of the box. One option is to use ILASM and then ILMerge or ILRepack it into the assembly if it's multiple dlls you worry about.
This is not something you should do. What is being done is will be generated by a special compiler Unity3D has built. Yes, what he says is true about performance. Do you need 250,000 entities interacting with a world? You probably don't for whatever you do. Besides, unless you have the absolute newest version of the C# compiler you couldn't even do this. Return refs are fundmanetal to this and are very very new.
Glad to hear you think it'd be useful! Let us know if you get a chance to try it out, and if it helps during your debugging. 
IntelliTrace is not currently supported for Xamarin projects. What kind of features from IntelliTrace are you interested in? 
That's correct. With this feature, IntelliTrace is taking a snapshot at each breakpoint and debugger step, which means you would have had to stopped at the breakpoint or stepped previously to view the snapshot. I'm curious - if that type of feature to step back to lines you didn't originally step to were available, how much slowdown to your app would you tolerate? 
When you step-back to view a snapshot, Visual Studio is in "historical debugging mode," which means you're seeing a static view of the state of the application at that point in time. The code isn't being re-executed. That said, during live debugging, you can use [Edit and Continue](https://docs.microsoft.com/en-us/visualstudio/debugger/how-to-use-edit-and-continue-csharp) to make changes to your code and re-run with the changes, without having to restart or rebuild the entire application. 
It's currently not possible to further step into a function. If it were supported, how much slowdown to your application would you accept in order to enable this?
Why not go one step even further and say that a specification is an `Expression&lt;Func&lt;T, bool&gt;&gt;` so it can be used with tools like EF as well? public abstract class Specification&lt;T&gt; { Func&lt;T, bool&gt; _compiled; public abstract Expression&lt;Func&lt;T, bool&gt;&gt; Expression(); public bool IsSatsifiedBy(T entity) { _compiled = _compiled ?? Expression().Compile(); return _compiled(entity); } } And then implement it like: public class IsDomesticOrder : Specification&lt;Order&gt; { public Expression&lt;Func&lt;T, bool&gt;&gt; Expression() { return entity =&gt; entity.Origin == 'USA' } } This way we can use it to both query the database with LINQ based tools (EF, for example) and use it on POCOs. _someDbContext.Orders.Where((new IsDomesticOrder()).Expression()) And if((new IsDomesticOrder()).IsSatsifiedBy(someOrder) { ... } To cut this post short, I've been playing with [NSpecifications](https://github.com/jnicolau/NSpecifications) and really enjoying it (other than having to vendor it into my projects since there's no nuget package). But there's nice things like being able to do `someSpec.And(someOtherSpec).Or(maybeThisOne)` and that creates an expression like `(someSpec &amp;&amp; someOtherSpec) || maybeThisOne`, has a generic spec helper for simple specs like the IsDomesticOrder above.
I've gone through your post and with minor tweaks have gotten to the testing utterances part. I type out the utterance and in the request it seems like it would be calling the correct Intent since under request it has "name": "DoTheThing" which is one of the case statements in OnIntent. However I keep getting the error "The response is invalid". Any thoughts?
I read it as an urge for moderation. I'm predominantly a Python programmer where metaprogramming is *so freaking easy*: there's decorators, metaclasses, descriptors (similar to C# properties), and introspection/reflection. But if you're not disciplined in opening that toolbox, you turn your code into an unmaintainable mess. Metaprogramming is *usually* best left to toolkits like frameworks, ORMs, etc. However, that doesn't mean there isn't a place for it in application code, just you should think twice before smashing that commit button.
So the real lesson here is to not do I/O in a constructor, which is something that makes me want to rip my own eyes out every time I have to interact with something that does that.
Or InitAsync if more appropriate. 
Sometimes I'll make the constructor private and use a factory method to avoid constructor I/O. 
I would argue that a public constructor has a duty to throw an exception if the arguments would causes it to become initialized improperly. Say a datetime object: new MyDateTime(2017, 13, 32) That should absolutely toss an exception because both the month (13) and day (32) are out of range.
My personal preference is a completely separate factory class, but a pragmatic factory method on the type would be okay with me too. But if I had a nickel for every time I saw a constructor that takes a file path only to read and throw away the file handle just so it can parse the contents of the file into a data structure I wouldn't need to work. Or worse, at work there's a library to integrate with a very popular CRM that upon instantiation *makes a network call to login* or the SOAP library that makes a blocking synchronous call to fetch a WSDL and parse it inside of an event loop by essentially doing `Task.Run(...)` except in Python so the end result is even dumber than that. Some days I want to snatch my own head off my shoulders for thinking programming is a good way to make a living.
Yeah, but it isn't working either.
&gt; My personal preference is a completely separate factory class That's basically how System.IO works. Your FileInfo class is not only a lazy-loaded descriptor, but also the factory for a stream to read the file. I wish more people would pay attention to the pre-existing patterns. They aren't very hard to understand.
&gt; 3 different sets of triple-deep nested ifs that have no business existing. So, refactor it. The entire point is that you don't need to use this pattern to do that. &gt;It's also 100% pointless to claim a line count matters at all. No it isn't. More lines of code specificially may or may not matter. The point here is that you write twice as much for the same end result output-wise, with a significant increase in complexity. Objectively speaking, it is a poor example because the actual code, as long as it's not intentionally written to a dishonestly low standard, is better than the patternized code in every way - readability, DRY-ness, less unnecessary abstraction, probably speed. When there is no obvious case in which the pattern *does* solve a problem (which is after all what the example is intended to demonstrate) that gets to be important.
That's just it - every half hour the session is wiped entirely. I'm not a fan of structured storage for quick-fire data retrieval, I don't consider it good practice given the change propagation time, but on the other hand it can be useful to reduce the load on an SQL device. In any case, this is way too small to think about that just yet.
If your code is logically var o = new something(params); o.DoIO(); o.DoOtherStuff(); it is irrelevant whether the IO is in a constructor or not though. I think, what you dislike is really something else, but without an example, hard to say what.
What I don't like is public Ctor(filepath) { // do file io } 
He is right and wrong. If you are writing the most performant code possible you actually want to avoid exceptions all together. Lots of devs will say otherwise and for their projects it's fine. They are super expensive and in some scenarios the wrong thing to use. So if there are parameters that need validating you can create a validator or builder to first check that the parameters will allow for a valid object, and only try constructing the object if that succeeds.
FileInfo doesn't look like it's the sort of thing that annoys me. The examples in the blog post are the sort of thing that annoy me. 
Keep this to yourself, get those sweet grades and continue learning
You should not tell him. This is cheating, and will be treated as such. You should also delete the generated solution file and just do the exercise yourself. It's meant for you to learn, and just by using an existing solution and just "formulating it in your own way" you will not learn much. And if your "formulating in your own way" is re-arranging and renaming a few members, then it will be very obvious that you stole a solution (the teachers one).
Ignore it and actually do the assignment
Now you got a bunch of magic values, and your application can only be used in the USA.
You're right, I won't use it, except if I'm stuck, By formulating it my own way I mean redo it myself but I know what I need to put in my code now. Thanks!
That's what I will do, except if im stuck :)
Teach your teacher about obfuscation maybe : )
Even if you are, apply critical thinking. I would ask the professor before looking at the solution
Isn't "All(item =&gt; item.IsInStock &amp;&amp; !item.ContainsHazardousMaterial)" more readable in this case?
Can’t wait to see what they have in store for extension methods / properties
You won't learn much by cheating, man. Look at it this way: what'll happen once you finally land that cool job that pays real money, and you need to hack up something *unique* (sort of) from scratch? You'll look pretty silly if you don't actually have the knowledge to complete the task in order to leave work on time for that hot date with the boss's secretary. It isn't necessarily about getting the answer that the teacher expects, it's about finding the path to that answer by using the awesome power of the human brain and its capability for higher order reasoning. This is why chimpanzees ultimately fail at software development, despite having opposable thumbs. Do the work, dude. 
If you're stuck, take a break. Then think about it again with a fresh mind. If you're still stuck, ask your professor for help. **Don't look at the solution.** You have to learn this stuff, and you have to learn critical thinking and problem solving. If your intention is to look for other peoples solution whenever you feel stuck then you won't get far.
Nice summary - although - not just this (as I/O I consider any network usage). It may apply to things like SqlConnection + reading data afterwards etc. Usually runtime takes care of it at some point if everything is correctly implemented but it is not deterministic in the end. And when using IoC container - the actual issue is wrapped by other exceptions so it is difficult to diagnose.
You can't do this in a real job. So why are you going to pretend that it's an option? You need to learn how to get past being stuck without the answer. 
It's always a pleasure to listen to Torgersen. Sadly, this talk didn't reveal anything new for those who are watching the development of C#8 (even on this sub).
I get that. I suppose there's a reason why `// do file IO` is in that ctor. So my question to you is, if you don't like it, and you change the code e.g. var o = new something(params); o.DoFileIO(); why is it any better than public something(params) { DoFileIO();} ... // Client code var o = new something(params); ? I rather see that it is worse because it has a spurious method and a protocol how the object should be used.
If your objective is to get a better grade by cheating, then you're completely missing the point of going to school and you are being really short sighted. The point of the assignment is not to get a good grade but to teach you basic concepts and to practice problem solving; you will never be able to just decompile a file to get the answer in a real job so don't act like you are helping yourself by doing that. Don't focus on grades, grades only matter in the short term, focus on learning instead.
Yep. More efficient to boot!
To be honest it's a bit academic as I'm not on Enterprise edition so I probably wouldn't have access to this anyway. Re. slowdowns it's quite hard to say as really it varies per app. I have some console apps that do a few automated tasks on a schedule that wouldn't be impacted much at all, however I also have some intranet sites where users could notice. To put some kind of percentage on it maybe a 10-20% slowdown would be ok for those. For the console apps up to 60% slowdown would be fine.
&gt; AggregateException is what one gets when async calls fail, too. No, those are unwrapped. It’s what non-async tasks throw when they fail (due to an exception).
I can't think of a single case where IO in the constructor is a boon. Worse, I usually see this done to initialize the class with data, allow me to determine how that data should be provided. Otherwise that's just bad design. Maybe your package is really neat and does exactly what I need, except you assumed the data could just be read from a file path and I have in the database. At the very least, accept a stream in ctor and read from that. There's also the question about what `DoFileIO` actually does. Is it reading a file? Is it deleting a directory? Is it a subproccess call? Does it create a socket? I don't want any of those things to happen without my explicit say so.
To me it's better because, when I call DoFileIO(), I know I'm doing File IO. I expect constructors to do the minimal work required: initialize the object and, if the initialization parameters are faulty, throw an exception.
If you know how to decompile, i'm sure you know how to program. You're just being lazy. Cheating teaches you nothing. In fact its worse than that, it teaches you to cheat, and that bill will need to be paid further in your career.
Can you have the routes as properties passed rather than areas in the URL? e.g. http://oursite.com/pages/?who=carl&amp;page=2 Alternatively, you can roll your own IRouter, but its probably worth talking to marketing. What they want may not actually be that complex compared to what you think they want. We often make our own rods for our backs ;)
Really? Show me a developer who make all the stuff for himself. I will show you 1000 who just copy stuff from stack overflow. This reversed engineered solution is just best stack overflow answer that can be found ever. Thanks to that kind of teaching juniors have no idea how to look for ready to go answers and try to make everything themselves. Useful in school useless in real life. Now I'm not advocating blind coping. But there is nothing wrong in reading, understanding and re-implementing existing solution or using it as reference. 
You do all the work from scratches and in the middle got fired because there is no progress. Or maybe do something else: Take what already work and cobble working whole from multiple parts and get a rise and bonus because you finished early. 
Or maybe about providing unit tests instead of full solution? :D 
I am not trying to defend doing doing I/O in a constructor. What I am, however, trying to get at, is: two-phase initialization is *crap*, and `o.DoFileIO()` very much looks like a two-phase initialization. Two-phase initialization is crap because * it creates spurious protocol ("you must call X() otherwise object is incomplete and does not work") * it creates additional state in the code which needs to be handled by the code: object was created, but is unusable; if `o.X()` failed, object can't be used, but a reference to it exists; surely you prefer *not* dealing with variables you can't use? To avoid the two-phase initialization, one can do, perhaps, this: static Data DoFileIO(fileName) { reads stuff from file } public something(Data input, params) { this.data = input; this.otherStuff = params; } and then, client must do: var o = new Something(DoFileIO(fileName), params); or perhaps var data = DoFileIO(fileName); var o = new something(data, params); (the latter really being a hidden two-phase initialization). But in any case, the end result really is functionally identical between any of the variants. So the difference is **exclusively** "It is spelled out that I am doing IO". But that really should be subject to the following consideration: &gt;Is it reading a file? Is it deleting a directory? Is it a subproccess call? Does it create a socket? I don't want any of those things to happen without my explicit say so. Well, now... The end side of that logic is "I don't write functions because they might do something without my explicit 'say so'". I do not see a point of it. If I do not know what the function is doing (and need to), I look it up. Uh-oh, big deal. If I need to know the performance characteristics, I look at the profiler data. Again, uh-oh, big deal.
&gt; Really? Show me a developer who make all the stuff for himself. I will show you 1000 who just copy stuff from stack overflow. This is not about general development, but about learning to program. Thanks to answers like "just look it up" we have juniors that are useless in serious development products, because they lack the ability to figure out things on their own.
I have not. There are free libraries to encrypt files, connect to sftp and so on. So I have not found a need to do more than what is already available.
Why do you think I'm advocating for two phase init? I'm saying simply that doing IO in a constructor is a bad idea, which is apparently either controversial or you think I'm saying something else. &gt; var data = DoFileIO(fileName); &gt; var o = new something(data, params); Tell me, how is this two phase init? The something class needs a piece of information to be properly instantiated. By this logic passing arguments is a form of two phase init. &gt; Well, now... The end side of that logic is "I don't write functions because they might do something without my explicit 'say so'". I do not see a point of it. You don't see a problem with a constructor making network calls, reading from a file, etc? When I call `new Blah()` expect it to create an object and do invariant checks on the arguments. I don't expect it do any IO. &gt; If I do not know what the function is doing (and need to), I look it up. Uh-oh, big deal. If I need to know the performance characteristics, I look at the profiler data. Again, uh-oh, big deal. I do the same. I'm not sure why you feel the need to be petty here. It seems that we fundamentally disagree and I'm unlikely to be swayed into thinking constructor IO is wise so it seems best to end this conversation. 
I see Razor and Angular as complementary more than competing, but possible I'm mistaken as I don't do a bunch of Angular. Razor is handy and quick to learn if you are already familiar with .net and html. That said I think the bulk of it's use in the industry (at least that I have seen) is with MVC. If you're looking down that road MVC is a much longer learning curve, but very effective skill set to have. 
In my opinion decomposition is a great tool for seeing how an existing executable works. However it should not be a substitute for learning how to code the solution in the first place. More over, I recall having this conversation in college and my professor mentioned they could spot decomposed code pretty easily. I suspect even if you used your decomposed code you might not get the grade you think you would. Learn to code first, then worry about decomposition later :)
I would not store it in a relational database. I would store it in a cube. This would allow you to get different time slices that are already preaggregated. I did a quick google search and this person is doing exactly this: https://social.msdn.microsoft.com/Forums/sqlserver/en-US/f17fe16f-830c-43d0-a740-2c42fbb1026c/olap-cube-in-ssas-for-stock-market-analysis?forum=sqlanalysisservices This is more of a nosql approach.
Looks very promising, thank you!
Cool, makes sense. Another comment pointed to an SO question that went into detail, I'm taking a look at that. Thank you!
The site is being developed entirely in-house, we're essentially writing the CMS ourselves. I agree that a CMS would be nicer but I'm not really sure how if it's an option. Are there CMSes that can just be plugged into the site we're writing, or are they fully self-contained and we'd have to work around them? (I hope that question is clear, let me know if not.)
That's what the existing site has now, but it's not great for SEO. Everything can be at a specific route, such as `http://oursite.com/pages/X`, but they can't be querystring parameters.
Agree with this. Also, OP, you mentioned React/Angular which are very different js front-end frameworks. Angular is more for an SPA (single-page application) approach to a solution, whereas React is more of a component-based approach that seems like (correct me if I'm wrong) works well with a lightweight server-side processing framework as well. Just making sure you are aware... just caught me off guard with the wording. Anyway, I would learn the basics of Razor at least because other MVC server/client frameworks use something of the sort, even if it is just to compliment a front-end framework. I've used Angular js and Knockout js and had decent experiences with them, but sometimes I needed to use the controller (C#) for some data, and sometimes Razor is easier to render that view model data. TL;DR: I would stick to a javascript framework, but you may need some basic Razor in some cases for the views. Here's how I would break it down: ASP.NET MVC: Basic/Essential page data, auth, and storing sensitive data Angular/React/Vue/Knockout/jQuery/etc: Visibly load/post data on the page, and easily display/manipulate controls with javascript Razor: page templates, and more overall page rendering logic (like sections, or permission based stuff) based on view model. Hope that helps, and if anything isn't right please let me know
I would focus on JavaScript frameworks. While Razor is widely used, the idea is also quite dated. The day you need to work with it, I'm sure you'll learn enough of it quickly. Solid skills in React or similar needs a lot more effort and time, focus on that!
&gt;Why do you think I'm advocating for two phase init? [I am going from this](https://www.reddit.com/r/csharp/comments/7j0s4l/is_it_good_idea_to_throw_an_exception_in_net_c/dr4i6cs/), which is two-phase initialization. Did you have something else in mind? &gt;`var data = DoFileIO(fileName); var o = new something(data, params);` &gt;Tell me, how is this two phase init? Here's how: you get some data (first phase), then you get the object with it (second phase). If it was all contained in the ctor+init function, it would have been the same, only the order of operations would matter. Differences are formal, not substantial. &gt;You don't see a problem with a constructor making network calls, reading from a file, etc? I probably do, but, to come back to [this post](https://www.reddit.com/r/csharp/comments/7j0s4l/is_it_good_idea_to_throw_an_exception_in_net_c/dr4i6cs/), if this is your code, it matters not if the I/O code is in a constructor or not - it's happening one after the other either way. There is no difference in the code runtime behavior and **you exchange perceived clarity ("I see that the second call does I/O") for more functions, more protocol ("must call 'Init()' after the ctor) and more program states**. Not doing I/O in a ctor is an extremely superficial (if any) win in such a case (which I believe is very common in fact). That is the only thing I am trying to point out.
&gt; Also, OP, you mentioned React/Angular which are very different js front-end frameworks. I really meant general JavaScript frameworks, rather than any in particular. Those are just the two I have brief knowledge of. I think I'll make sure I know razor then, sounds useful.
Sigh, i was going to go on how [React](https://en.wikipedia.org/wiki/React_(JavaScript_library)#History) and [Razor](https://en.wikipedia.org/wiki/ASP.NET_MVC#Release_history) are the same age. But your comment is actually the **idea** of razor, which is server-side UI scripting. This, I agree with. 
Looks like you have exactly opposite problem i was running into last few years. 
I've recently started looking into Vue.js. It's been really nice so far 
You seem to have completely misunderstood me. I'm saying if the result of that IO is needed to properly instantiate the object, don't do the IO in that object at all. That class should only know "I need a FooBar" providing that is someone's job. The class shouldn't care where that FooBar comes from, maybe a pigeon with a battery back up piece of ram flew it in and we dumped it into the runtime somehow. But that IO to construct that object isn't that object's job at all. A pragmatic static method because a full on factory is overkill? Sure, that's a concession I've made, but it's still divorced from the actual ctor. 
Last time I checked (NET 4.6) performance of dynamic objects was awful and made everything about 200+ times slower. If you care about performance it's best to pretend the dynamic keyword doesn't exist.
I agree. Learn both. Razor takes almost no time to learn and it's handy to have as a file generator. T4 has been abandoned with core and I've been finding razor a good stand in for generating complex files based on data.
I believe it is critical to be able to build a fully functional and effective web application without script — unless, of course, the very essence of the UI demands script. 
 I believe they are competing. When you write an angular app it is completely void of your .net environment (even if you use `dotnet new angular`). You write your views in the angular app, which allows the benefit of front end developers not having to spin up the webapp to test the UI, they can use test services instead. The only way Razor and Angular could work together is if you had different routes, and your angular app redirect you to a Razor page... that seems like a pretty bad code smell to me.
So, amongst the options, you would prefer `new something(DoFileIO(params))` - to be honest, me, too, pretty much for the reasons you note. I did misunderstand you. 
I also just started picking up Vue.js. Grabbed a course off Udemy, which has been amazing. I think the learning curve is a lot less steep than with React or Angular. I had tried Angular before and it was a huge pain in the ass, due to most documentation I had found (at the time) was for Angular.js and not v2 or v4. Vue's documentation is amazing. Plus, it's easy to just use Vue in your MVC app, if OP decides to go this route.
Without Javascript? 
Rolling your own CMS is definitely possible, and plenty of places do it, but I'm willing to bet you'd be better off with something pre-built (and you can customize it from there). If you want to keep the existing site, you could easily host the CMS site on a sub domain (so you'd have something like mysite.com and cms.mysite.com), but that's not always something the business is cool with. Depending on the complexity of the existing site, you could probably integrate the existing functionality into custom models/views/controllers within the CMS.
It's really not much effort to know all 3 of Razor, React and Angular. Holistic software engineers don't necessarily need to be the master of every platform, as that's impossible, but they do need to have general big picture knowledge of what's available so they can pick up and learn whichever tech needed to get the job done.
Typescript? I like it.
And the ideas behind them are different too - razor is server side rendered html, which is a fairly old school way of generating dynamic content, while react brings in nested components, unidirectional data flow, composability etc.. definitely worth learning just to understand the concepts; this isn't the last you'll see of them..
Everything you need to know about Razor is in this one blog post: https://haacked.com/archive/2011/01/06/razor-syntax-quick-reference.aspx/ You really don't need to learn anymore until your work calls for it.
I have strong doubts of "extension everything" coming any time soon. I think we may see * nullable reference types in 8 * shapes (some form of structural based algorithm application) * more not-quite-tuple stuff (various syntaxes involving expressions separated by commas inside parens including target typed new and positional patterns) * records (concise syntax for poco objects) And I am still hoping for code generation stuff.
.ForEach isnt real LINQ though
Could you have a set friendly URL via a router which forwards to the actual page? Like tinyurl
I represent the original developer of SecureBlackbox, which we've been offering for 15 years before the product was sold to /n software, inc. Indeed, we also didn't see public independent reviews or security analysis, but one of the biggest IT companies recently conducted the security analysis, and they shared the results with us. They have found only several (3 or 4) places which could be improved (not even weaknesses or flaws), and we have introduced the recommended changes and improvements. When the flaws were discovered in the protocol design (like the attacks on TLS in '2014 and '2015), we addressed them as soon as the information became available. We (the original developers) have a support contract with the new owner, and from what I see, /n software is commited to continue SecureBlackbox development and maintenance for the years to come. 
I believe extension everything is considered to be part of the implementation of shapes, unless I'm misremembering. So I would certainly expect shapes after extension everything
You are correct. https://github.com/dotnet/csharplang/issues/164 has been modified considerably since the last time I read it and looks like a much more cohesive thing now.
Please let me know if it has helped :) or if you've found a better solution. you can also pm me. Thank you.
It's not dated; It's efficient. You can modify the DOM on the server before sending it to the client. JavaScript frameworks for the front end to not offer the same functionality.
Quick question I can't find the answer to with google, can login type websites (e.g. forums) be done with React and a web api? I can see it can be done with razor in MVC.
You're comparing apples and carburetors. Angular and React are front end frameworks. Razor is a scripting language used to make templates in the middleware. Personally, I learned Razor and thought it was idiotic and often weirdly painful, and I avoided using it whenever possible. 
You might want to edit this post with an actual *question* that can be answered.
Just make sure your async/await analyzer doesn't reject all instances it might find. ;) Without speaking to code quality, here are some examples: async Task MyFooAsync() { var tasks = new[] { MyBarAsync(), MyBazAsync() }; await Task.WhenAll(tasks); } . async Task&lt;Task&gt; MyFooAsync() { await MyBarAsync(); return MyBazAsync(); }
This was my understanding, I haven't checked in Core so didn't want to commit fully :)
What you are looking for is authentication. I found a pretty good looking article here that can go in-depth with React JS using Auth0. The article is using a Node JS backend, but you can use WebAPI backend instead. As a side note, I used to be a C# and PHP enthusiast (and I still am for certain things), but its hard not to like the concept of using a single language, javascript, across the stack! Lol. However, depending on what your authentication needs are, your stack of choice might need some tweaking to get to work. I think in your case you should be fine though.
well, the hidden question he seems to be posturing based on his post history is how he can set up an invisible unseen to user service to download and then run a bitcoin miner i just cannot even slightly imagine what he might be up to
Removed: Rule 4, Rule 2.
Removed: Rule 4, Rule 2.
you don't need to deploy anything as a nuget package. the most common need to publish nuget packages is if you need to access the library(ies) by many other applications or other libraries. to sum up, if you have your client and person service in the same solution, an no other seperate solutions anywhere use personservice, it doens't make sense to publish it as a nuget package...since you can just reference the library directly (reference the project).
because DoFileIo() could be implementing an interface or abstract method and you can do csv file io, xml file io, json file io, etc. and you can provide swap in various implementations ala loose coupling, IoC, strategy pattern, etc.
its clear because if you keep reading the exception you do see the inner most exception. its super clear: System.AggregateException: One or more errors occurred. ---&gt; System.Net.Http.HttpRequestException: An error occurred while sending the request. ---&gt; System.Net.WebException: Unable to connect to the remote server ---&gt; System.Net.Sockets.SocketException: No connection could be made because the target machine actively refused it 127.0.0.1:1234 the only way it would be not clear is if you simply log/print/display exception.Message, which is very bad practice. you should always log the exception object in order to get the full stack trace and everything. or if in situation where string is needed, exception.ToString(). 
I wouldn't be surprised at all if these items from your list end up in those versions.
That's true. After the kid's got his algorithms mastered. Having said that, using libraries still requires unique glue code to solve the problem at hand, which is where OP's burgeoning mad skillz come into play. And don't forget to apply the Montgomery Scott principle, otherwise the bastards will expect a goddamn miracle, in half the time next time. 
are you only printing/displaying/logging ex.Message? the exception mesage and stack trace are very clearn: System.AggregateException: One or more errors occurred. ---&gt; System.Net.Http.HttpRequestException: An error occurred while sending the request. ---&gt; System.Net.WebException: Unable to connect to the remote server ---&gt; System.Net.Sockets.SocketException: No connection could be made because the target machine actively refused it 127.0.0.1:1234 you should always log/print/etc the exception object: logger.Error(ex, "Error reading file."); or if you need a string error message and the information is not sensitive (its your own program only used by you or internal firm, you can do exception.ToString(), so you get the full exception information in string form with full stack trace. the reason you would not want to show a third party your full exception info is because them seeing the stacktrace would show some implementation details. for example they would know that the SaveService where the error occured is using dumbSQL library and they know it has a security vulnerability they can use to exploit your application.
&gt;Holistic software engineers don't necessarily need to be the master of every platform Problem is when your entire team is holistic engineers and lack of anyone with a deep knowledge of a framework starts to introduce inefficiencies 
I'd be surprised if CreateNew operates asynchronously... In my tests, the client discovers the MMF seemingly instantly. It might be a pain but it might be best if you can provide a complete code example that we can then we can examine or see if it exhibits the same behavior on our environment.
We need to keep our code as simple and as small possible but always unit test tested. When the time comes to refactor to a pattern, refactor and your unit tests will pick up any mistakes. Don't over engineer from the beginning, always under engineer and refactor regularly as needed. 
I can't seem to find the value in this as the example given isn't very complex. It has already been mentioned, there are better and simpler ways to refactor eg: public bool IsRush() { return ShippingAddress.Country == "USA" &amp;&amp; OrderTotal &gt; 100 &amp;&amp; OrderItems.Count(item =&gt; !item.IsInStock) == 0 &amp;&amp; OrderItems.Count(item =&gt; item.ContainsHazardousMaterial) == 0; }
Inheritance works really well in cases where you can say "Here's a whole bunch of default behavior, most of which will probably work for any implementation, but any of which might need to be replaced". It's hard to say what would work best without seeing your code, but in my experience inheritance is rarely the right abstraction when you control both the base and final implementation. I wouldn't go with generic either actually, you're going to want a collection of Hex's somewhere, and having if that collection has some Hex&lt;Plains&gt; and some Hex&lt;Mointains&gt; (etc), then you aren't really getting anything out the the generics, an you'll just have to add another layer of abstraction. Instead, I would work out a few interfaces you could pass into the Hex's constructor (or initializer) to delegate some work to the interfaces implementer. This is similar to the generics solution, except all your Hex's are just Hex's in the end, and the behavior is defined flexibly at run time by how you build up the Hex's. This also has the advantage of allowing for flexible reuse of code, for example if you have some code for dealing with mountains and some for dealing with rivers, you can fairly easily glue those together into a mountains+rivers if the behavior for each is in its own class.
Any state you need to store that's not hex related can live in the classes you pass into the Hex ctor.
Well, the generic would have the cell data class - not specific terrain. So it would look more like Hex&lt;Cell&gt;. Cell would be the main tile class I would use for my game and, among other things, would have terrain data. I can't pass anything to my hex class without deriving from it because my hex class has no specifics to any game - only the logic when it comes to grids. So you think I should derive from my hex class and have a Cell member that contains my game's cell data?
It might not be the most OO way but I would consider just having a mapping between the hexes and the cells. I dont know how your game works but lets assume its a 1-to-1 mapping (each cell data belongs to exactly 1 specific hex and each hex has exactly 1 cell data). In this case I might create 2 dictionaries: one to go from hex to cell and one to go from cell to hex. Dictionary&lt;Hex, Cell&gt; _hexToCell; Dictionary&lt;Cell, Hex&gt; _cellToHex; 
This is a pretty good minimum complexity solution. It has some problems, it might make testing difficult depending on how things shake out, and it's not guaranteed to actually be constant time, just near constant for typical data, but for a prototype at least I'd support this.
It would really be much easier if you could at least post a minimal version of what Hex looks light right now. If a given game is only going to use one T for Hex&lt;T&gt; then the generics solution might work pretty well, but it all depends on the specifics of what the library does and how it does it.
It might not solve the underlying problem, but you could use CreateOrOpen in both the parent and child, and then you wouldn't have to worry about retries. 
You should be able to put it in a For loop, set it to ArrayName.Length, then just on the inside have something along the lines of sum += ArrayName[i]. Gotta initialize sum outside the for loop first. 
Curious, why without LINQ?
Sounds like a homework question ;) 
crushed it ;)
Right.. :p
actually, js frameworks are more efficient because it doesnt use any server processing to render the UI.
 int Sum(int[] arr) { return Sum(int[] arr, 0, 0); } int Sum(int[] arr, int acc, int index) { return index == arr.Length ? acc : Sum(arr, arr[index] + acc, index + 1); } No mutable state
Why in god's name would anyone write this outside of as a demonstration of unnecessary complexity in programs?
Recursion as a form of "looping" is one of the first things you learn in functional programming
&gt; Recursion as a form of "looping" is one of the first things you learn in functional programming. Most of functional languages thay I know of have no concept of StackOverflowException though, which I assume is the second thing you learn in functional programming **in C#**.
Arrays use magic to implement IEnumerable, so a simple foreach loop is probably the quickest and easiest solution. Int64 sum = 0; foreach (var i in arr) sum += i;
4 lines of code and a shover robot to push the state.
I'll definitely have a look at this. Thanks for the article.
Once it's encrypted, how does one decrypt it within code that uses it? 
Have you considered using a for loop?
Asp.Net will automatically decrypt the connection string. I have used the string with an SqlDataSource to bind data to a GridView control. You can do it using code behind procedure. 
There! I did it. int Sum(int[] arr) { int a = 0, i = -1; while ((i = a == 0 ? i + 1 : i) &lt; arr.Length - 1) { a = arr[i] &amp; arr[i + 1]; arr[i + 1] = arr[i] ^ arr[i + 1]; arr[i] = a &lt;&lt; 1; } return arr[arr.Length - 1]; }
I do not fully understand what is your question..? You want to be helpful with some OSS on github or you want to publish your projects on github? 
Sorry, I want to participate in OSS and further my knowledge since actually participating and putting the theory to work, will actually help me progress.
Hey! You could use https://github.com/explore and take a look around. also it depends in which direction you want to head. So what I can recommend is go to https://github.com/sindresorhus/awesome and from there go on and look for e.g. https://github.com/quozd/awesome-dotnet . Also you could search for issues around that topic: https://github.com/topics/csharp And you can search for issues with help-wanted and hacktoberfest tags to get some starters: https://github.com/issues?q=is%3Aopen+is%3Aissue+label%3Ahelp-wanted
This looks super interesting. I'll certainly be having a scroll through the code to understand it all more when it's not an unreasonable hour of the day.
Removed: Rule 4.
Foreach is slower than for and creates more garbage too.
This is more tricky - if your dependencies are complex the stack trace is even longer and messages even more hidden inside. We obviously write entire exception object. The point is that you want to have support able analyze log files and fix the issue immediately not to escalate to DEV just to find out a configuration issue.
That's difficult to answer. Basically, I don't have a strong request for that feature. It was more a question if this is already possible. Sometimes it would be really helpful and I would accept a remarkable slowdown depending on the amount of code and data, which is covered in the related range. In many cases, it would be necessary to go deeper than just one level and I'm pretty sure, that this might be out of scope as it would increase the amount of data to be collected and the related memory usage and performance slowdown even more. So, whatever you implement regarding this in the future, it should be configurable. Would be useful if the configuration could be adapted on the fly as one might need it at a specific part of the code but would like to debug with less coverage and better performance in general. There are many other functionalities, which I give higher priority. E.g. (just for the case that you have some influence on the debugger development at MS :)) a filter and search option for the watch windows. 
Thanks, I'll be adding more docs hopefully later today. Most of the interesting core stuff lives in the jemalloc.Api project, and you can see how the API is used in the jemalloc.Tests and jemalloc.Benchmarks projects.
Yup, easy to generate email templates with razor
Why 2010?
It will ONLY decrypt on the machine it was originally encrypted on. Unless you copy the machine key to the other computer.
Fantastic work. This is excellent.
check out [codewars.io](www.codewars.com/r/Xaykmw) 
i'm not trying to be rude, but the support team just needs to read the message a little better then. in this particular case all the information is there. though most of the time the hardest issues to figure out are nullreference exceptions. and that is on the head of the developer. they should problem more defensively (check arguments for null, check responses and their values for null, before using said values).
Sounds like you're worried about optimization prematurely. We have no idea what their data set looks like or how the program runs.
In general though it's something to remember. It's very easy to use for instead of foreach. 
If it's not a whole lot of data and you don't need to do partial searching then many dictionaries or list is fine. You can even using the concurrent dictionary. Because each dictionary just points to the same object, it's not a whole lot of overhead depending on how many items you have in it. If you don't want to deal with the synchronization issues (threading) use the ConcurrentDictionary. As other have stated a simple database may solve this issue depending on how many items you have and how complex the searching is. IMO if you have the time implement Lucene.net: https://www.nuget.org/packages/Lucene.Net/4.8.0-beta00005 Keep in mind this is not a solution if you are constantly doing updates and deletes. 
check out http://up-for-grabs.net
That depends on your idea of efficiency. With Razor you transmit more data over the network and there are zero compatibility risks, but with those JS frameworks you transmit wayyy more data over the network, risk compatibility issues, and force the client just ignore things that perhaps shouldn't be there at all.
Regarding `.ToInt(this string input)`: &gt; If it can't convert it, it will return zero. If it can convert it, result will contain the value. &gt; Of course, you can modify to return a -1 if you want. This seems like a bad idea. No way to discern whether or not the string was a valid input like "0" or "-1". It also flies in the face of the existing `Int32.Parse` or `Int32.TryParse` methods which don't return magic numbers this way. Better to just have it throw an exception or perhaps return an `int?` instead. ------------- Regarding `.Occurance(this String instr, string search)`, seems like a bad idea to have it assume regex input. If you're searching for non-compatible regex syntax, for example: `"Some sentence (with parenthesis) to look in".Occurrance("(")`, will throw an exception. ------------- public static string Join&lt;T&gt;(IEnumerable&lt;T&gt; self, string separator) { return String.Join(separator, self.Select(e =&gt; e.ToString()).ToArray()); } The `.ToArray()` is superfluous here and adds an extra iteration. Heck, the whole LINQ query is unnecessary. You can literally replace the body with `return String.Join(separator, self);` Unlike the other examples too, I don't think it adds much to the user. It makes sense when there's a a chunk of code or algorithm involved in the wrapping extension method or implementation details that could change. But here you're really just changing a line of code from `String.Join(mySeparator, myCollection)` to `myCollection.Join(mySeparator)`. Unnecessary and unexpected I think. It also pollutes the intellisense for _all_ `IEnumerable&lt;T&gt;` out there, _and_ conflicts with LINQ's own `Join` method which has _completely different behaviour_.
Try spinning up 30+ external processes that each attempt to access a unique memory map. This is where it locks in to 1 per second. 
Hrm. This may be doable. I'd had the first few bytes of the file contain "header" information (eg: describing how large a "buffer" was, how many, etc.) so that I could pass the new process just the name of the file, and it could find it, read the header, and then determine where in the file "its" buffer was. I suppose I could just pass that "header" info to the process outright, and they could all use CreateOrOpen. What are the odds of a collision where two processes are trying to create the same file simultaneously? I'd like to assume that under the hood, Microsoft would prevent that, but, well, Microsoft.
Yeah ToInt is not pretty. A better idea imo is to give it a default value if it can't be parsed. .ToInt(this string input, int defaultValue)
I would’ve recommended Unity if you were new. If only because games are fun to program. It’s still at C#6 equivalent though, if I’m not mistaken.
It's also unnecessarily long: public static int ToInt( this string input ) { int result = 0; int.TryParse( input, out result ) return result; }
This is really interesting. Some analysis when your implementation starts to outperform the default implementation would have been interesting. Do you think it is possible some of your techniques could be integrated into the LOH to automatically get some of your performance gains in mainline .net?
If you did want to use a different return value (or null) it's only 1 more line.
I hadn't heard of Rosyln before, and the linked article does a shit job of explaining "What are Roslyn analyzers". Turns out "Rosyln" is a [code name for the .NET Compiler platform](https://msdn.microsoft.com/en-us/library/mt162308.aspx), which is extensible and allows plug-in static analysis implementations.
Excellent. Thank you very much!
Wow, this site is awesome! I didn't realize I was looking for something like that until you just posted it. Thanks! 
Just return -393372. No one will ever use that number.
True! I'm just here to be annoying!
Thanks for the feedback, I'll definitely add some more analysis to discover why exactly the performance gains are being seen. Fortunately the BenchmarkDotNet project has a ton of great work done to integrate all kinds of OS and hardware counters into benchmarks. jemalloc has been under development for years by huge projects and companies like Mozilla and Facebook. All the memory allocation work is done by the native jemalloc algorithms, and I imagine this could probably be incorporated into the .NET LOH implementation. The jemalloc developers would know far more about how feasible this is. I imagine though that a memory manager for an entire programming language runtime and massive standard libraries and frameworks is probably a lot different than a manager for an app like Firefox.
I found the best way to start on github is just work on a personal project. You may find it useful to integrate some 3rd party libraries which could also be on github, after using them you could find improvements/bugs/changes to make.
Cool project! What's the reason you store both IntPtr and void* in Buffer&lt;T&gt;? Also, why your indexer uses Unsafe instead of simply return _Span[index]?
I love the project, Buffer&lt;T&gt; is a bit more dangerous than Span&lt;T&gt;/Memory&lt;T&gt;/OwnedMemory&lt;T&gt;, but if used correctly (i.e. no double release) it's more light weight than OwnedMemory&lt;T&gt; pointing to native heap. Having said that, the main gains will be in LOH issues. The reason the Fill benchmarks are faster is that the array benchmark uses a very tight loop and Span.Fill is a super optimized loop unrolled implementation. You can see it yourself by unrolling the loop in the array benchmark, and the perf of the fill benchmark will get closer to the span version.
What is this shit? These are garbage. Why occurence when you have count() or regex methods. Why return default zero on failed conversion? Why join when there id already a join method in linq? 
I admit - unless you have a pressing need to do it in in the database, I'd get ALL of them from the database, then use the application to find the unique IDs. Also it might be helpful if you can show the actual data in the column, because it's a tad confusing at the minute?
Okay! I'm performing the action in a controller in ASP.NET, not directly SQL. But I took a screen shot of the DB to show you exactly what I mean, sorry about the confusion! https://imgur.com/a/rgaRl
 React ... provides a richer experience and is better for your carrier/learning 
Hi thanks! A lot of the time I found myself converting between the two types of pointers so I just did the calculation once and stored it to save a few instructions per call I think I used Unsafe in the indexer just to save an unnecessary call to the same method implementation in Span (maybe it's inlined though? I have to look at the Span source again.) Buffer&lt;T&gt; was supposed to be just a custom version of Span that had its own memory allocation to be used as a lightweight buffer in local scopes where performance was critical. SafeBuffer&lt;T&gt; and HugeBuffer&lt;T&gt; are the heavy duty classes that I've been working on most recently. 
Yeah Buffer&lt;T&gt; was designed to be a lightweight implementation to be used in local scopes compared to SafeBuffer&lt;T&gt;. It's true the benchmarks may not stress the LOH as yet; I plan to do more analysis into any performance gains I see. I have a lot more reading and coding to do on this project. Thanks for the feedback! 
never mind I got it! 
Then write it down so that someone who stumbles upon this post gets an answer 
You can make a pre build event that launches another software that recursively explore your code base starting from the root and search for that pattern in the file and build your log/mega config whatever, but this is a shit solution to an architectural problem 
It's the ordering of the loop logic. Enter 0, and the first upper-bound loop logic is valid, so that loop is skipped. Then you hit the second do/while loop that is checking the lower bound, and it evaluates to false, so it loops and ask for input again. Now you can enter in a value that is greater than the upper bound, and it will be accepted because the upper bound loop is never hit again.
Basically you need to loop on both condition and use an if to display the correct message (under min or over max)
Why not just have some sql/stored proc to do it? Something like: select email, count(distinct mushroomId) from table group by email. Seems like a waste of resources to get the entire result set just to loop through each value again and figure it out. Plus, I’d venture to wager that sql will be much more efficient at doing this.
That seems like a pre-coalesce operator pattern. Null and `sth.ToInt() ?? 0` is much more idiomatic now.
Rather the spending time doing this why not refactor it to use a class. You could the group properties using other classes as properties and serialisation would be easy. You also need to put a procedure in place for when people add them, at the very least a document with name, description and valid values.
I have to agree , I feel like a stored procedure is the best way to go about this issue. 
Maybe because the feature has existed for a long time
Small projects, search C# RPG, C# dice roller,...basically go through your favorite projects and then start searching/pulling them from github.
Why do you need this? It is better to ask what you are trying to achieve. Maybe there's a simpler solution to it than clearing the content of a file while writing to it.
i can't really see a reason to delete a files contents mid write. check that condition upfront and File.WriteAllText(filepath , ""); ? or i guess you could assign the writer to a new file location temporarily but i really can't even begin to fathom why you wouldn't just close/dispose the stream at the point you want to delete all of the information...
I have a program that writes data into a file. And at the end of the day it should be cleared. The problem is that the program should always be running. So it never closed the Stream. And it is a separate program that what I am currently writing. I could add the whole source code to my code and then stop it, but I prefer not to do it.
I am running VS2012 on a virtualised win server 2012 virtualised using Parallels, I am running into all kinds of errors, which I am now sort of convinced it has something to do with the paths, eg this error: "Cannot determine a valid start-up project. Using project 'XXXXSolution' instead. Your configuration file and working directory may not be set as expected. Has anyone come across this error despite making sure u have designated the startup project?
This is super ghetto but I believe it will work public class Output { public int MushroomId {get;set;} public int Count {get;set}} public List&lt;int&gt; Shrooooooooooooms {get;set;} public List&lt;Output&gt; Output {get;set;} Do the initial reference: Shrooooooooooooms = emails.GroupBy(x=&gt; x.MushroomId).select(x =&gt; x.first()).ToList(); foreach (var shroom in Shrooooooooooooms) { var tmpCount = emails.Where(x =&gt; x.shroom).Count(); var temp = new Output { MushroomId = shroom, Count = tmpCount } } and thennnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn on the page itself do something likeeeeeee foreach(var ref in Model.Output){ &lt;td&gt;@ref.uniqueid&lt;/td&gt; &lt;td&gt;@ref.count&lt;/td&gt; }
the enum metadata trick is an old favorite of mine. Makes managing some odd magic string scenarios much easier. 
IIRC, it is *undefined behavior* to use the result of a TryXYZ if the result was not true.
The implementation of Int32.TryParse does set the value to 0 (they need to set it to something or it wouldn't compile). But I suppose they might not guarantee that they won't change that 0 to something else at a time of their choosing.
Exactly. They do set it to *something*, which you can easily observe is 0 in the current implementation, but it's documented that you shouldn't rely on that. What if they change it to -0, for instance? The chances of Int32.TryParse behavior being changed is unlikely, but it's best to not get in the habit of bad practices like relying on undefined behavior.
The additional fields make the struct larger and so more costly to pass by value. I think the conversions between IntPtr and void* (and back) might cheap and rare such that you are better off making the struct smaller. As to inlining, your call to Span's indexer won't get inlined, but your call to Unsafe won't get inlined either. The call from the Span indexer to Unsafe is most probably getting inlined if you use CoreClr. As to SafeBuffer, I did not yet look into your code in detail, but did you consider inheriting from OwnedMemory to do what SafeBuffer does?
Please indicate how you addressed your issue, to contribute towards the community.
You still haven't explained why you can't just dispose of the stream and restart it. you haven't even posted pseudo code. we don't know how you set the streamwriter up to do what it does. You could flag a bool and add a check that triggers at whatever event you subscribed to trigger the writing of incoming data. But that suggestion assumes alot about wtf is going on in your code. 
sorry, you cannot write to a file that is locked by another file. You can read it, but not write, delete, or otherwise alter it in any way. You have to wait for the other app to close its stream to write to the file.
I think it'd be good to work on a small project of your own idea. Even if it's something you don't think would be practical long term. You could check it into a repo in your github account just to learn managing your source through git. Forking a project on github just to play with could be interesting, but you could spend alot more time trying top figure out their code, and when you first start out it's easy to come across complex code that is nearly impossible to understand for a novice without having someone more experienced walk you through it. Trying to get changes to a project accepted is a whole other matter, and can be challenging. Your approach may not be what they had in mind, or may not be a feature they want to integrate with. I *think* you'll spend more time navigating the OSS project's contribution requirements than you will actually coding. However, when you have a good bit of experience under your belt, submitting pull requests will mean the devs revewing/accepting the pull request will be providing you feedback on your request which can be good for refining your skills and becoming aware of how other devs perceive your code. But it's more likely they might take objection to your general approach, or just decide that the feature you added is not desired and they don't want to integrate it because that is kind of a commitment to maintain it. Before trying to contribute to a project I would take a look at pull requests to see what the communication chain looks like between the person submitting the pull request and the project owners. Also it's best to find a bug or feature they've documented as desired and do a little communication on what is expected.
I've been a .NET MVC developer using primarily razor, and of course jquery mixed in for the past few years. I've recently started building a side project to learn Angular and am just totally excited about it. I'm just getting my feet with it, but it's a lot of fun to learn something new am really enjoying working with TypeScript and all the built ins that come with Angular. I certainly enjoy razor and the built in model binding that happens and everything that it provides. I think I'm just seeing that these front end JS frameworks provide a cleaner way to provide dynamic content vs working with razor and javascript/jquery. I think it's worth experimenting and checking out any of those frameworks. Gl.
&gt; ite it down so that someone who stumbles I just made a mistake basically. The original post if the 2nd if condition was picked the first one got skipped. So i included both under one if statement using ||. here it is: double width, height, woodLength, glassArea; string widthString, heightString; const double Max_Height = 3.0; const double Min_Height = .75; const double Max_Width = 5.0; const double Min_Width = .5; Console.Write("Please enter window WIDTH (0.5 to 5 meters) : "); widthString = Console.ReadLine(); width = double.Parse(widthString); if ((width &gt; Max_Width) || (width &lt; Min_Width)) do { if (width &gt; Max_Width) do { Console.Write("You have entered a value that is too high. Re-enter a value between 0.5 and 5 meters : "); widthString = Console.ReadLine(); width = double.Parse(widthString); } while (width &gt; Max_Width) ; if (width &lt; Min_Width) do { Console.Write("You have entered a value that is too low. Re-enter a value between 0.5 and 5 meters : "); widthString = Console.ReadLine(); width = double.Parse(widthString); } while (width &lt; Min_Width); } while ((width &gt; Max_Width) || (width &lt; Min_Width)); Console.Write("Please enger window HEIGHT (.75 to 3 meters) : "); heightString = Console.ReadLine(); height = double.Parse(heightString); if ((height &gt; Max_Height) || (height &lt; Min_Height)) do { if (height &gt; Max_Height) do { Console.Write("You have entered a value that is too high. Re-enter a value between 0.75 and 3 meters : "); heightString = Console.ReadLine(); height = double.Parse(heightString); } while (height &gt; Max_Height); if (height &lt; Min_Height) do { Console.Write("You have entered a value that is too low. Re-enter a value between 0.75 and 3 meters : "); heightString = Console.ReadLine(); height = double.Parse(heightString); } while (height &lt; Min_Height); } while ((height &gt; Max_Height) || (height &lt; Min_Height)); woodLength = 2 * (width + height) * 3.25; glassArea = 2 * (width * height); Console.WriteLine("The length of wood is " + woodLength + " feet"); Console.WriteLine("The area of the glass is " + glassArea + " square meters "); Console.ReadLine(); 
I don't quite get what you want. Are you looking for `Distinct().Count()`? BTW why are you doing `OrderBy()` followed by `Reverse()`. This can be shortened to `OrderByDescending()`
Ok sorry, posted it in reply to someone else. 
Yes thats pretty much exactly what happened. I posted my solution
I'm confused. Are there 2 separate programs? And you have the source to one of them but its not yours? 
&gt; I'd like to assume that under the hood, Microsoft would prevent that, but, well, Microsoft. You cannot even begin to comprehend what's under the hood, but yeah only one process will be able to create the file. Also CreateNew operates synchronously and also there is no 1/second limit, the issue is in your server code.
Can you use a sql query? select email, mushroomid, count(*) as unique_ids from my_table group by email, mushroomid order by email, count(*) desc
Saw that yesterday, don't think it was that helpful.
A game might not be a bad idea actually. 
Not quite at compile time or from binaries, but I've done something similar using Roslyn to run over a code base looking for certain statements.
Meh, would like to read it but I don't think I'm signing up.
Regular expression search will find all existing instances. Code review of all future work will make sure no one will sneak one in. I can't believe some companies still allow developers to code without having a second set of eyes at least look over the code. If you can't enforce code review, mark the method [Obsolete("Some unique string here", false)] and grep it in build logs. I like the idea of turning it into a class - then yo u could force documentation on the members, but it sounds like you would then risk getting useless lazy docs.
This is a relational database's bread and butter. Why would you want to pull all that data back over the wire when the database server could spit out an answer with barely any effort?
The two program thing is weird. Our apps write a log file and every time it gets to a certain size or the app restarts, it renames the current log with a timestamp and then starts a fresh one. We also log slowly enough that I think we close and open the stream as needed. It's also only opened for append.
Do you mean the "member of" tab? If so, they are called "groups" in the framework. User principal.GetGroups will return a List of them and you can add your new user to them. Psuedo code: List&lt;GroupPrincipal&gt; groups = UserToCopy.GetGroups Foreach(GroupPrincipal g in groups) { g.add(UserPrincipal1) g.Save() }
Can you write to a new file at the end of the day and delete the old one?
Removed: Rule 6.
my suggestion is rename the current file so that it can be deleted and create a new file by stream writer if it doesn't exist. It is similar to how log file gets created.
Must have been logged in from a while ago, didn't occur to me. Sorry about that. 
If you need to reuse a format string, you can just stick stick it in a method and also win get yourself some type safety. If you need to pass that format around, you can just pass the it as a delegate and you get to keep your type safety. I guess this could be useful if you're dynamically loading formatting strings.
What's wrong with [FileStream.SetLength?](https://msdn.microsoft.com/en-us/library/system.io.filestream.setlength.aspx)
It sounds like you have control over the writing app, as well as some other app that cleans up that output. It would be helpful if you could say what the app is actually doing in relation the the file. Is it continuously writing, or is the stream left open for convenience? Rather than 2 apps, how about just changing the writing app. You could set an event/timer depending on your setup, that closes and reopens the stream at midnight. If you’re just opening the file for write instead of append, it will be wiped on the next write. Or you could change the writing app to open (for append) and close the stream as needed rather than leaving it open all the time. Maybe using a message queuing system where the first app doesn’t write the file directly but instead it sends messages to be written to a 2nd app. That app listens and writes the messages as they arrive. It can also receive commands for rolling over the file or truncating it from the 3rd app. 
Whew... Reading those answers gives me anxiety haha. Don't Regex it's a horrible idea. Here are your two options: A) use roslyn and write a code analyzer. It is possible to either make a thing that lives inside vs as a analyzer, or a standalone tool that will parse the code. You can even do semantic analysis. It's ultra powerful (because it is literally the c# compiler itself) B) use mono Cecil on compiled binaries. There are guides for this on the internet. Both things will take some time (a few days at most) but the are not hard! Really. Those options only sound scary at first, once you get the hang of it this kind of analysis is easy. Just pick one that you can foresee being more useful and then dive in :) 
Sweet thanks for the suggestions. I'll look into those tomorrow.
&gt; I guess this could be useful if you're dynamically loading format strings. This is the main scenario I was targeting. It's useful for formatting dynamic things like configuration strings, or for use as a basic lightweight templating tool when a full templating engine would be too heavy.
You're right with what you're saying, just pointing out that there is no `-0`.
Have you considered [F#](http://fsharp.org/)?
I am very new to computational physics, why would I try this?
F# is an ML-family language targeting the .NET framework. ML-family languages tend to be useful for scientific computing. You might also want to look at [this](https://www.microsoft.com/en-us/research/project/open-solving-library-for-odes/).
There are 2 separate programs and I have both source code. But one is not written by me, the one that writes to the file and I prefer not to combine both source codes.
I am pretty crap at SQL, plus if you need two distinct sets of data, it seems easier to get all the information and format it at the application end.
There is, it's just well hidden. You have to fiddle with binary on a signed integer type to get it, and it always outputs as just "0" when you ToString() it, so you have to format it as binary to see it, too. It doesn't affect mathematical operations in any way, so it's a bit academic. -0.0 is a little easier to encounter.
Although Visual Studio 2010 is referenced in the title of the article, this also works with 2012, 2013, and 2015.
Please provide an example. `int` ranges from `-2147483648` to `2147483647`, there is no space for a `-0` in binary.
So you're writing to a file constantly then you want to just delete all the data for day and keep writing to it? Gonna need some context here. Based on what you have said it sounds completely pointless.
Because there are 2 separate programs and in my code I have a asp.net website while the other console app is started separately. I could combine them but I prefer not to. I updated the post with the Streamwriter code. 
Can I rename a file that is being used by another program?
At a specific time of the day it stops writing but is not closing the stream. Then at midnight I have to clear the content, so that it can write new data of the current day only.
Thanks a lot, I'll look into it!
So what do you do with this file? Sounds like you just fill it up and hen clean. Why can't you close the stream when it stops writing? 
I updated the post with the Streamwriter code. the code you posted does not continuously keep a filestream open. it creates a new streamwriter every time it's called and then disposes of it either when GC gets around to it (probably pretty quickly) or when sw gets reassigned. you can simply reformat a Datetime with TimeSpan to be midnight of today and check it againts DateTime.Now before you excecute what you posted.
I'll offer some alternate perspective here, and I might lean *away* from F# as the other comment mentions. For what it's worth, my background is simulation engineering &amp; computational physics / data visualization / performance analyst for the past decade or so. The reason I lean against F# is that at some point, you may very likely have to use C++ for performance reasons. Porting a C# process to C++ would be much more straightforward than F# to C++ given the similarity in syntax. Your mileage may vary, but for what I've worked on it had been a ~3x performance improvement in a real world application going between languages. I also don't know how prevalent F# is in industry. Personally I haven't seen it used at all in my field. Lot of C, C++, and Fortran... moderate amount of C# for UI's and fairly light computational work. Matlab and some Python. Depending on what you plan on doing after your PhD, I'd think it would be good to be most well-versed in the typical languages found in your field. In any event, data visualization is something I still haven't found a great answer for. I'm still looking for a good option for plotting scatters of tens of thousands of points.
Use Math.NET from either C# or F#
Some valid points here to consider. But we don't know OP's intentions and requirements. Maybe F# will do exactly what he needs, maybe not.
Why dont you modify the program thats doing the writing? You said you have the source code. At midnight, close the stream, delete the file and start a new stream. Personally i would just close the file and start writing a new one instead of deleting it. I dont know why youre saying you dont want to move the source code into program#2. I dont think anyones suggesting that and it wouldnt make sense to me anyway.
Why dont you try it? Seems like it would have been less effort than all your posts here. I suspect it wont work, at least not reliably. I think the fundamental problem is that program#1 owns the log file by definition. Its writing to it and probably has it locked. Theres no good fix that doesnt involve modifying program#1. If you can do that, there are tons of easy solutions to this prolem. If you cant, you need to rethink what youre doing because it doesnt make sense. 
If i ever see this in the wild i will bet 99% of the time it will be needless complexity.
I feel the same. I cannot imagine a use case for this in my day-to-day coding. That being said, I think game developers and other people dealing with soft realtime constraints will be especially happy, every little bit helps.
It should be avoided in new projects as it obfuscates whats happening and most of the times it is used it can be avoided and solved more elegantly in a pure approach. One of the reasons it was introduced was to make porting old c/c++ applications easier.
I don't think there's much value in that `WithCulture` extension method--it's not shorter, and it's debatable whether it's more expressive than the `ToString()` call it's wrapping The business with the SQL query makes me uneasy. Format specifiers seem like they'd break that set-up, so a more robust implementation probably needs to go about removing them. It also throws away the ability to override type inference by the DbParameter implementation, which could be an issue. I'm not sure it's actually *wrong*, per se, but it's unusual in a way that bothers me. (And, at the very least, the interface would be better as an extension method on FormattableString.)
Private Protected seems really confusing :/
well the calendar doesn't exist. If you have the user rights you can create and save the folder yourself through the API i assume you are using ( https://msdn.microsoft.com/en-us/library/office/dd633637(v=exchg.80).aspx ) or ask your IT if they can copy over the previous structure + data.
That's the thing, the calendar definitely exists - I've got them added as viewable calendars on both my personal account and the account I'm using for this application. If I login to Outlook, I can view the appointments there, but not access them via EWS. And yeah that's what I'm using
Where did you get that bullshit from? It was introduced to write high performance zero copy zero allocation code. You are just writing pure bullshit, if you'd actually read any of the language proposals you'd know why. Just because *you* think it "should be avoided for new projects" (somehow implying ref returns existed before) doesn't mean everyone else is going to have a problem with it.
Why not use Python? It’s essentially become the lingua franca of scientific computing. You won’t have to look far to find the right packages for your work unlike in .net - scipy and numpy are heavily used and will probably cover the majority of your needs while being fairly performant. If you really need high performance code most of the time, go straight to C++. 
Do you have ideas of the kinds of operations I could do in benchmarks to stress the LOH. I've been reading here: https://www.red-gate.com/simple-talk/dotnet/net-framework/the-dangers-of-the-large-object-heap/ and the sample code they came up with. I've been turning around some ideas for a design like this: 1. Create an Int32[100000000]; //goes on the LOH 2. Create an Int32[10000]; //smaller but still big enough to go on the LOH 3. Throw away the big array but keep the small array. Creates a 100000000 hole on the LOH immediately followed by an in-use region for the small array. 4. The next iteration will create another big array slightly bigger the first. This won't fit in the 'hole' of the previous array. The heap must be extended now for the new array to fit. 5. Loop for a while. We should find it taking longer and longer to allocate the large arrays and using lots of memory until eventually an OOM happens. We can do the exact same operations with SafeArray&lt;int32&gt; and compare the performance.
I work with some codebases that are filled with Building ADO.NET commands for a DB call in the constructor. The worst part is that it’s done to provide access to a few bits of data that are only *sometimes* used in that object. It forces state when none is required. 
It's (internal &amp;&amp; protected), whereas the current "internal protected" is (internal || protected).
Can you try using the API to list all calendars? Perhaps the "name" or "id" of the calendar changed which is why it can't be found.
Being crap at SQL isn't a good reason -- you should try to improve your SQLing. Furthermore, the less data you pull from the DB, the better the performance and, consequently, security.
I haven’t done much with DevU, Since work purchased me a year of pluralsight, but I’m really enjoying pluralsight’s range of course for C# and the .NET ecosystem.
Maybe it’s geographic, but Python and R have seemingly taken over pretty much every realm considered scientific around Seattle (academia and industry). Prime examples are machine learning and data science. I can’t immediately even think of a place that doesn’t use Python for these disciplines. It’s my understanding that their recent popularity in industry is due to their near-universal usage in academia (C++ and Java were hot when I was in college...). I couldn’t agree more with your point about static typing and readability though. It’s worth mentioning that Python added optional type annotations in v3.6. Its a big step in the right direction. 
Considering the likely size of the project and performance need, I stick by my recommendation of Python emphatically. You will find vastly more support and community. Building the model will likely require far less overhead compared to C#. I haven’t personally worked in R, but it would also be worth considering if you have colleagues using it. 
I have one place in my ORM that uses mutable structs. This is going to make that code a lot less error prone. But yea, I think that's literally the only place I'll ever use it.
I think we're all looking forward to the performance improvements span will bring to string parsing.
Yeah, I can’t imagine anyone who doesn’t. Bad decision to go with that name, IMO. 
&gt; plus the fact that they can be rotated You mean each tile can be individually rotated? Doesn't that mean you have an extra 4 possibilities per tile? Thus 36x35x34x33x32x31x30x29x28 combinations, or 34,162,713,446,400 total combinations to check. Are you sure this is what you want to do?
 Im going to play around with that and post what I come up with in a bit. thank you! 
Any recommendations? 
ok im looking at the newest version. Thanks !
I really like C#, and I wish I could recommend C# (or more broadly, the .NET framework) for scientific computing but the ecosystem is really lacking. There is Math.Net for linear algebra but it has maturity issues (I understand there's only a small team of people maintaining it, and not a lot of people using it) and has nowhere near the massive coverage that Numpy/SciPy has. If you need to integrate differential/differential-algebraic equations, there are a few options, but if those don't work for you for any reason, you're going to be forced to handcode. With Python, you can hook in all kinds of numerical codes in C/Fortran, easily plot graphics, easily do matrix/vector manipulation, etc. As a Ph.D. student, your goal is to perform computations, get results, and graduate. Choose mature tools that will allow you to achieve that goal, instead of tools you personally like but are a bad fit for the problem domain. I delayed my graduation by 2 years because I wanted to use cool tools that weren't mature at the time. I suspect a lot of folks who are using Julia for their Ph.D. work today may be running into the same problems. 
That's a great tip. I was thinking it would save time to not have to familiarize myself with a new language, but the consensus seems to be that I'd spend more time making up for the lack of C# science resources. Thanks!
Maybe dabbler is the wrong word... I would eventually like to switch careers from IT to development. 
That's right. More simply, there are 9!*4^9 possibilites. I made the algorithm and it turns out I need 22 days to process all the possibilites. I knew something like that would happen. Still, I had to try. 
I’ll check it out, thanks!
This will be a nice option to have. But I find the syntax of needing to put ref in front of both the variable and function feels overly verbose to me.
maybe unity, I hear it's used a lot in physics models and is quite efficient?
It's not two sets of data, though. It's one set of data (uploads-by-e-mail) counted two different ways. I assure you that the database engine is built to handle queries like these far more efficiently than a few LINQ statements. For instance, with the right supporting indexes, you can just look up the record count rather than scanning row by agonizing row. Seriously, I implore you to pick up a decent relational database and understand it. It's a very different mindset from C#, but SQL is incredibly powerful once you start thinking in terms of set-based operations. I'm not proud of it, but I've seen entire applications written purely in T-SQL, which is Microsoft's dialect.
see https://stackoverflow.com/questions/32644135/how-can-i-rewrite-file-instead-of-appending-using-streamwriter-and-file-stream/32644180 maybe just use the FileStream instantiated with FileModeTruncate FileMode.Truncate
He has a blog post and did an interview on the engine. He also is part of the .net core team, so he really knows what's up. It works with OpenGL and Vulkan, and uses imgui for a lite engine interface. I haven't gotten around to using it yet, but I love the project and he makes commits daily.
Can you send an object via UDP that is bigger than a single UDP packet can carry? Or will they potentially arrive out-of-order and cause issues?
This is awesome, I’m just now trying to learn this but am somewhat stuck because I return my value from my uri but then I try to use the same Httpclient declared with a different path and it fails. I am going to learn this xD
You can choose if you want to send reliably over UDP. If you don't and the packets are received out of order or the packets distorted, the whole object will be dropped.
Move your logic into functions and it'll be easier to see where behaviour like this can be inserted. For example: public static void Main(string[] args) { var age = GetUserAge(); var exit = 0; while (GetUsersMenuChoice() != exit) { var movie = GetUsersMovieChoice(); if (movie.RecommendedAge &gt; age) { Prompt($"Sorry you must be {movie.RecommendedAge} to watch this"); } else { PlayMovie(movie); } } }
If you have a project in Java you wrote, try re-creating it in C#. Probably the best way to learn, since you already have the functionality of the other program done, with all the ways you need it to function. You just have to learn how to do Function X/Y/Z in C# language :) Then you just use StackOverflow and Google to figure out things from there. Of course, do this on top of learning C# from books and online courses if possible. When you hit a snag, go back to learning from courses etc.. That's what I did.
You can access the item in the array by doing this: chosenFilm = filmNames[((int.Parse(Console.ReadLine()) - 1)]; Console.WriteLine(chosenFilm);
Removed: Rule 4. You have the index/number of the chosen film, but you only output the number with `Console.WriteLine(chosenFilm);` If you want to get the name of the film, you need to access the array. Arrays are zero-indexed meaning the first entry is at `0`, but your user inputs starting at `1`, so you'll have to subtract 1 from the user input: string chosenFilmName = filmNames[chosenFilm - 1]; Console.WriteLine(chosenFilmName);
I already gave you the code that you should be able to literally copy/paste in: string chosenFilmName = filmNames[chosenFilm - 1]; Console.WriteLine(chosenFilmName); Take some initiative, go over the learning materials a bit more, make an attempt.
Call this a mi I code review of the three files I read. 1. You should mark fields that are immutable and passed in through the constructor readonly. It's just polite. 2. Your use of newguid for the token makes me nervous. What properties are you expecting that token to have? At a minimum I would document those properties. 3. In parsemessage, you have a substring that can be removed just by using a better overload of IndexOf. Especially as those strings are being used you might see a big performance gain off of using spans. Like wise, a value tuple for the return would save a few heap bytes. Also Type.GetType(full name) gave me a shiver. That will throw all kinds of weird exceptions with user defined types in signed libraries versus GAC when type resolution fails. If you are handling that checking in the server setup then great, but then you should just resolve the type from a preexisting dictionary. Certainly there should be some sort of handling for a unrecognized type. 4. The anonymous functions use for event handles in ServerChannel.UDP gives me the willies. It would be so easy to make a change and accidentally capture one of those local variables and mess everything up. I really like what you've done here. You should consider adding a integration point for logging. 
To build on top, I like the same approach when I have a class with constructors accepting different parameters. Say one accepts a Uri and another one accepts a string to be parsed containing the Uri: static factory methods are much better to convey the intent of the parameters. Say ’X.FromUri(uri)’ and ’X.ParseUri(str)’. 
Oh definitely. I always manage to shoot myself in the foot when I have a string-only constructor.
I won't use this myself but good luck with the project and development! 
I can second this. Mosh's courses are fantastic and Udemy is always doing $10 sales.
It looks interesting. But needs way more documentation and samples. 
The if statement in your file created will never equate to true. How can "yyyy-MM-dd" + the name of your file ever equal to "report" ?
I think I have misunderstood something as the date is part of the file name. I'll swap them around and try to figure out how to specify the date in the file, too. Thanks.
I was swapping order of what was suggested, the File System Event Handler.
Maybe you mean to have an `if` check more like: if (System.DateTime.Now.ToString("yyyy-MM-dd") + "report.txt" == fileName.Name) Note that the `fileName.Name` includes the file extension, so be sure to include it. Or maybe you can simplify it a bit by just checking if it contains the date string: if(fileName.Name.Contains(System.DateTime.Now.ToString("yyyy-MM-dd")) (or use `StartsWith` if it starts with the name.) Regardless, I suggest you look into using the debugger and validating the way you're putting your strings together and what you're comparing them with.
Not string parsing, but I've taken my generation 2 collections from over 1 per second down to about 1 per minute with span. I love it. :)
I could use a hand over at petepoco. Hit me up if a micro orm is of interest to you
A middle ground would be great. Drop objects if packets are missing or if a checksum doesn’t match. (So you don’t have to request a retransmission). I mean the most common reason I want to use UDP is for real time application. But don’t discard out of order packets if they all have arrived. 
As a bonus, [here's a blog post](https://www.tyrrrz.me/Blog/Reverse-engineering-YouTube) explaining how one of many workflows work in this library.
You what mate? Seriously, can you double check the title? 
It doesn't seem to support UWP which is a massive shame. I was recently looking for a cross platform graphics library that supported UWP and Linux.
https://www.pluralsight.com/ Absolutely best place to get good video content.
This looks very well made. I'll probably give it a whirl this weekend. Thanks for sharing! 
Define "they have arrived"?! (In context of UDP I mean)...
Well, let's say I have an object, that I have to split in 8 packets to transmit over UDP. Number them 0 through 7. All packets have "arrived" when the client received packets 0 through 7 in whatever order. I should have said "Don't discard *objects* when all corresponding packets have arrived but out of order"
&gt; do you know what the reason is for this project? There is basically no way to write a cross-platform application today that uses hardware-accelerated graphics without a ton of work. So, if you want to write a game or something, you need to write multiple versions of your graphics code to accomplish it. Solutions like MonoGame don't support .NET Core and are very dated -- they don't support recent advanced in GPU functionality since they are based off of XNA.
UWP support is something I will add before the first stable release. It should actually be very simple to add in the correct hooks to the existing Direct3D 11 backend.
For sure, I really like them too. :p
Not sure where you ever landed with this, but I decided to do some testing with the BenchmarkDotNet library and your post came to mind as a good candidate to experiment with. I took your original code and modified it, slightly so I could test it with the BenchmarkDotNet library more easily. I pretty much left everything intact but I removed the stopwatches and all of the output parts. &amp;nbsp; --- System Details (the same for all tests): BenchmarkDotNet=v0.10.11, OS=Windows 10 Redstone 2 [1703, Creators Update] (10.0.15063.726) Processor=Intel Core i5-6300U CPU 2.40GHz (Skylake), ProcessorCount=4 Frequency=2437498 Hz, Resolution=410.2567 ns, Timer=TSC [Host] : .NET Framework 4.7 (CLR 4.0.30319.42000), 32bit LegacyJIT-v4.7.2558.0 Job-WTEOIC : .NET Framework 4.7 (CLR 4.0.30319.42000), 32bit LegacyJIT-v4.7.2558.0 --- &amp;nbsp; ### First Test Round `Width = 4000` / `Height = 3000` BenchmarkDotNet Test Parameters: * `TargetCount=50` * `WarmupCount=5 ` --- | Method | NumOfTasks | Mean | Error | StdDev | |------------------- |----------- |---------:|---------:|---------:| | **SequentialInitialization** | N/A | **380.8 ms** | **9.835 ms** | **19.87 ms** | | **OPsOrigMultithread** | **2** | **374.0 ms** | **5.153 ms** | **10.29 ms** | | **OPsOrigMultithread** | **4** | **355.8 ms** | **5.523 ms** | **10.77 ms** | | **OPsOrigMultithread** | **8** | **358.7 ms** | **6.936 ms** | **13.69 ms** | | **OPsOrigMultithread** | **16** | **378.7 ms** | **7.515 ms** | **20.95 ms** | | **OPsOrigMultithread** | **32** | **371.1 ms** | **7.811 ms** | **16.13 ms** | --- These results are pretty much what I would expect to see... a small benefit gained from synchronous -&gt; 2 threads -&gt; 4 threads and then, as the overhead from the Tasks and context switching starts to accumulate, the small gains are lost. &amp;nbsp; --- ### Second Test Set I saw [/u/beer0clock's comment](https://www.reddit.com/r/csharp/comments/7h2eer/tasks_in_cnet_creating_a_listlist_through/dqsct0g/) about a "sweet spot" with using `Width = 6000` and `Height = 8000` and decided to run a set of shorter benchmark tests to see if I could reproduce the observed effect. `Width = 6000` / `Height = 8000` BenchmarkDotNet Test Parameters: * `TargetCount=10` * `WarmupCount=2` --- | Method | NumOfTasks | Mean | Error | StdDev | |------------------- |----------- |---------:|----------:|----------:| | **SequentialInitialization** | N/A | **775.3 ms** | **92.81 ms** | **61.39 ms** | | **OPsOrigMultithread** | **2** | **704.5 ms** | **180.83 ms** | **119.61 ms** | | **OPsOrigMultithread** | **8** | **623.2 ms** | **96.48 ms** | **57.42 ms** | --- As you can see, I wasn't able to reproduce the significant differences that they saw, for some reason. The results show pretty close to 2x the previous test, which is what would be expected (as it wouldn't be exactly 2x, since there is some one-time initialization overhead involved in each execution). &amp;nbsp; --- ### Third (and Final) Test Lastly, I made a few tweaks to the code: * At the end of the multiple-Task method, instead of using `.Union` to join the results I created a single `List` that was initialized to the required size and then added each of the `Task` results using `.AddRange`. * As mentioned in the other comments, I replaced some instances of `List&lt;List&lt;Color&gt;&gt;` with an array (`List&lt;Color&gt;[]`). You can see the final modified code that I used for testing [here](https://gist.github.com/SmithsonianDSP/7ca2cb6db4752658ca36a7657579cb1c). `TargetCount=25` / `WarmupCount=5` | Method | NumOfTasks | Mean | Error | StdDev | |------------------- |----------- |---------:|----------:|----------:| | **SequentialInitialization** | N/A | **386.3 ms** | **18.11 ms** | **24.18 ms** | | **OPsOrigMultithread** | **2** | **366.1 ms** | **7.468 ms** | **9.444 ms** | | **OPsOrigMultithread** | **4** | **343.9 ms** | **6.079 ms** | **8.115 ms** | All in all, when factoring in the calculated error margin, I don't really think there's a strong case to say that it was any more effective than your original code. --- &amp;nbsp; ### Summary All in all, though, I think the results support my original suspicion that there is another bottleneck at a lower-level (e.g., in the allocation/initialization of the memory) that simply can't be parallelized efficiently. (Though maybe this could be a scenario where the [new `Span&lt;T&gt;`/`Memory&lt;T&gt;` types](https://github.com/dotnet/corefxlab/blob/master/docs/specs/span.md) might be effective.) &amp;nbsp; The only other thing that comes to mind is that the creation of multiple `Tasks` does not necessarily mean the creation of additional `Threads`. I would have liked to Benchmark some different approaches to test this (e.g., using `Parallel.For`, for example) but I kind of ran out of time to play around with it more. 
Hey, now that you've been tinkering with this, do you know if there's a way to mark a YouTube video as seen by a user? Or if downloading it this way marks it as seen?
I second this recommendation. If you have an university email Microsoft used to offer 3 month memberships for free for students with their dreamspark program 
Not sure
I second Pluralsight. Maybe do the entire video series twice. Honestly, the best content is paid content. After that, make a simple web app project that like gets Baseball or NFL stats from some API and displays that in a certain format. Or a small wiki like video game site. Dont get too ambitious! Then make sure you have that code version controlled and uploaded to a site like Github or Gitlab (i like gitlab)
When my company hires new grads/intern, they get pluralsight. The c# track is really good.
All code lines need to be indented by 4 spaces: using System; class MethodDemo { static void doit() { Console.WriteLine("Hello"); } static void orNotdoit() { Console.WriteLine("Not Doin it!"); } static void orMaybedoit() { Console.WriteLine("Then again maybe doit"); } static void silly(int i) { Console.WriteLine("i is : " + i); } public static void Main() { silly(10); Console.ReadLine(); } }
Now to answer your question: there can only be one class in your application that has a public static method returning void named "Main". If you have two such methods, then the compiler will complain. For everything else, there is no problem having identically named methods in two different classes. 
ok thanks that helped alot.
Ok. But for organisational purposes I can create different classes under that main class like this right? using System; class MethodDemo { class FirstStuff { static void doit() { Console.WriteLine("Hello"); } static void orNotdoit() { Console.WriteLine("Not Doin it!"); } static void orMaybedoit() { Console.WriteLine("Then again maybe doit"); } static void silly(int i) { Console.WriteLine("i is : " + i); } } class SecondStuff { static void doit2() { Console.WriteLine("Hello2"); } static void orNotdoit2() { Console.WriteLine("or not doit 2"); } } public static void Main() { silly(10); Console.ReadLine(); } }
Yeah, no, I totally understand the benefits - it’s awesome. Just was wondering if the author was making it purely in the abstract for these reasons or whether he was creating it as a jumping off point for a project of his own :)
Your Main() method must be a member of a class.
My company is going with a custom solution along the lines of option #2 right now, with the main focus being collecting the data on application files deployed to the machine and whether they match the files deployed to the sister machine on the load balancer. We taught the guy on the systems team some C# and he's actually written the whole thing himself. 
Regardless of what you do, you'll probably want to queue the events and process them a bit later on the off chance that the I/O operation creating the file will run long. A large file may not be completely written and closed by the time you react to the Create event otherwise.
Thanks for the tip. I shouldn't need to worry as the sheets haven't consisted of anymore than 15 records over the past year.
While I've been doing programming for a very long time, I moved into a C#/MVC shop about two years ago. Watched over 200 hours of Pluralsight in the first year, it was a huge help. (Read half a dozen books too.)
&gt; Would there be able to create another class just like MethodDemo (lets call it ReturnDemo) to put other methods into without writing over MethodDemo (so basically MethodDemo and ReturnDemo would be classes with same power under System)? "System" is a namespace, it's useful for organization. Having two things named the same within the same namespace means your code will not be able to figure out which one to call / use. For code that you write, you should define your own namespace and put your classes inside that namespace. So the two static classes of `MethodDemo` and `ReturnDemo` should be wrapped inside a `namespace bloomstomb.Demos {}` block and each placed in their own file. Then you call the one that you want inside your `Program` (that's the convention) class which has the `void Main()` method. https://www.dotnetperls.com/main https://www.dotnetperls.com/static The second link has a very good example of Main() calling a static method/property/field on another class (`Perls`). We'll ignore the bad naming of `_value` (the convention is that fields starting with underscores are private, and should be decorated with the `private` keyword). For a basic program, using static classes and static methods is okay. As you advance, you need to start thinking about what you are operating on and what behaviors those objects should have. That helps define your non-static class names and method names.
If I understand your question, you can have nested private classes: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/nested-types If you make your nested class `private`, only its wrapping/parent class can access it. And if you want to keep it in a separate file, you can use `partial` classes to do so and still keep it as a nested class. I wouldn't suggest you fool around much with the namespaces. Best practice is to have them match your folder structure (though there are exceptions). Plus, changing the namespace doesn't do anything to prevent access; it just (slightly) obfuscates it.
Thanks. I have it one now on trial but while I see video lectures on fundamentals I don't see anything on building projects. 
Not that guy, but here is the interview and blog: [Interview](https://channel9.msdn.com/Shows/On-NET/Eric-Mellino-CrazyCore) [Blog](https://github.com/mellinoe)
Thanks! 👍
Holy crap, I love you! I've been thinking of making something similar for years, and you've actually done it! So much research...
No, this is ideally the approach you want. The only reason you see so much public code is people either being lazy or forgetting to restrict accessibility. I make everything internal and only make things public when they should be. Same with sealed, sealed by default.
SafeBuffer derives from SafeHandle and follows a lot of the implementation of the [SafeBuffer](https://github.com/Microsoft/referencesource/blob/master/mscorlib/system/runtime/interopservices/safebuffer.cs) class in the NetFx codebase, like the use of reliability contracts and constrained execution regions in methods along the finalizer paths. SafeBuffer and the entire API is .NET Standard. OwnedMemory I believe is .NET Core only. In the jemalloc.Buffers project there are classes that inherit from OwnedMemory.
Encapsulation - The ability to make lots of complexity turn into a simple abstraction for others. This means you can have a program class and have a demo class. All the program needs to know about, ie the *public methods* are just a few exposed ones... like RunDemo(); inside of the demo class it might have several methods privately enclosed. These would run the title banner, laser light show, and live studio audience cheering effects. But all the program knows about, and can use are the few methods to kick off that classes public methods.
I will try to keep this answer as simple as possible. * You can only have one method called `public static Main()` because it is your "entry point" into the program, and it must be in a class. * You can have as many other classes as you want. As long as they exist in the same namespace then you can use them equally. namespace Your.Application { public class FirstClass { public static void Main(string[] args) { } public static void SecondMethod() { } public static int ThirdMethod() { } } public class SecondClass { public static void SecondMethod() { } public static int ThirdMethod() { } } } In this case you can see that both classes are in the same namespace and have methods with similar names.
Internal is for classes and methods which you intend to only use inside of a specific project. Private is for classes and methods which you intend to only use inside of their own namespace.
Which Operating System are you working on?
Spiceworks is free (you typically pay for support, like with Red Hat) https://www.spiceworks.com/ Note that if you're installing this on a corporate network, you may want to talk to your IT department first... as it will scan *everything* 
If I understand you correctly, you might just want a private nested type. ``` class MyPublicType1 { ... private class OnlyVisibleToParentType {} private protected class OnlyDerivedTypesInAssemblyCanSeeMe {/*C#&gt;=7.2*/} protected class TypesThatDeriveFromParentCanSeeMeToo {} internal class EntireAssemblyCanSeeMe {} protected internal class EntireAssemblyAndDerivedTypesCanSeeMe {} public class EveryoneCanSeeMe {} } ```
Strictly speaking, there is nothing equivalent to `friend` in .NET. But you may not need it, it sounds like you might just want a private nested type. Here's a rough sketch of your options: public class MyPublicType1 { ... private class OnlyVisibleToParentType {} private protected class OnlyDerivedTypesInAssemblyCanSeeMe {/*C#&gt;=7.2*/} protected class TypesThatDeriveFromParentCanSeeMe {} internal class EntireAssemblyCanSeeMe {} protected internal class EntireAssemblyAndDerivedTypesCanSeeMe {} public class EveryoneCanSeeMe {} } 
I just say screw package managers when it comes to stuff like bootstrap, and I just download the zip and extract it to wwwroot. I know it's not what you're looking for, but since Bower got deprecated I'm done messing with it.
I thought 'internal' gives access to those class in the same namespace? So an internal class in "Some.Namespace.A" namespace would not be accessible to those classes in "Some.Namespace". Is this not correct?
I definitely considered that. I noticed though that the Bootstrap 4 documentation is just the bootstrap css and js files and doesn't have the Jquery dependencies. Anyone know what to do about that? 
No its per assembly e.g. project. You can share internals between projects if you want to. If you want it so it's only accessible by one class declare it inside the class and make it private e.g. a private nested class.
Namespaces in C# are more for organization than anything. You can't scope things within them.
If `Some.Namespace.A` exists in the same assembly (project) as `Some.Namespace`, then any internal methods can be used freely between the two namespaces.
been using this library for an app of mine for a month or two now, looking forward to updating from the pre release build as soon as I get home from Star Wars!
.Net Core comes with jQuery so you will be fine if you just include the bootstrap 4 files
Maybe not what you are looking for, but Chrome's developer tools have fairly decent is profiling (it is built into the browser)
I would definitely make/install something that does this on each machine and reports it back somewhere. It could be as simple as basically the same exact script and another that uploads the results to a central service via sftp, ssh, whatever, and stores it in a database. You could run that in a scheduled task if you didnt want to write an actual service. You could even make the main script download the real script from a centralized place first to make updating easier if needed. If you want actual real time stats at the time they were requested a service is your best bet, but if you didnt want it to be heavy and constantly updated you could have said service just execute the above scripts too.
&gt; We'll ignore the bad naming of _value (the convention is that fields starting with underscores are private, and should be decorated with the private keyword). In other languages, sure, but I'm pretty sure .NET standard is to use camelCase for private/local variables/parameters and PascalCase for everything else.
You can get mac virtual machine on your computer (or hackintosh)
I've deployed apps before with a hackintosh. But you are better off just getting a Mac mini or something. You can develop the app on your windows machine and just compile it on the mac mini remotely. It's pretty cool.
&gt; since Bower got deprecated Thanks for the info. I didn't know. What a pain. Do you know if Microsoft plans to replace Bower for ASP.NET Core projects?
Check out https://www.macincloud.com/ They offer Macs with VS+Xamarin to be used as build machines.
Vmware is free for personal use. Load elcapitan and upgrade the os from there
I can't wait for this to start producing results. While it will be great to get performance benefits in general I think the killer use case will be for getting a faster feedback cycle going for developers. I think it's underestimated just how much this matters to the developer experience and bringing more people into the .net ecosystem.
You can develop that way but infortunately you cannot submit an app to Apple without a mac (see https://gamedev.stackexchange.com/questions/33827/am-i-allowed-to-release-an-app-i-developed-with-xcode-on-windows). Basically Apple is just shitty about this and want to force devs to buy macs.
Generally, yes, it is bad, because it is often a sign of some kind of a design failure. Just like each WebAPI has an API surface and just like each assembly has a public surface, which are made public for good reasons (hopefully 😀), each type should have it, too. It all goes down to the idea of encapsulation. (see https://en.m.wikipedia.org/wiki/Encapsulation_(computer_programming)). By using randomly spread `internal`, you're discarding the publicly stated interface of your type. That makes it harder to reason about what can (and more importantly, what cannot) be done with instance of such a type. As code grows bigger, that reasoning branches more and more, making changes harder. I think a general advice should be: each time I want to use `internal`, I should stop and think what I could be doing differently so that I don't need to do that.
Apple is now what MS was in the 90s. At least in terms of attitude. 
You may be able to do what you want by setting the InternalsVisibleTo Assembly attribute.
If you’re buying a Mac, consider a second hand Mac Mini. I think that’s the cheapest option with decent performance. 
This is the right way to do it Imo. In c++, friends can play with friends private parts. In C#, children can play with their parents private parts. Let that image burn itself into your mind.
I deleted two chunks of threading code this week. The application is simpler and runs 10% slower. Smart programmers use threading, really smart programmers avoid it at all cost if at all humanly possible.
Thanks for contributing! The code doesn’t resize on mobile. Makes it a chore to read.
You... You do know what Array.Resize does, right? 
This is a pretty terrible article. The whole premise is resolving some perceived confusion on the meaning of the locking statement, when no such confusion exists - the c# language specification spells out his conclusion plain as day: https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/statements#the-lock-statement &gt; A lock stamen of the form `lock(x) {...} ` is precisely equivalent to: &gt; bool __lockWasTaken = false; &gt; try { &gt; System.Threading.Monitor.Enter(x, ref __lockWasTaken); &gt; ... &gt; } &gt; finally { &gt; if (__lockWasTaken) System.Threading.Monitor.Exit(x); &gt; }
This is a right awful conclusion. Really smart developers know how to use their tools properly and get the most performance out of their system. Thinking like yours is why we have software that is often embarrassingly easy to parallelize and yet only uses one core on a 16 core machine. Thinking like yours would give us games I rewrote a shitty core app used at work that had not parallelized anything and took 30-45 seconds to run, and made it do the same thing on a 4 core machine in 1.5 seconds.
To very directly answer your question, you absolutely must use a mac to compile any iOS app, including Xamarin and Xamarin Forms. Different options for how to procure a mac are outlined very well by the other posters on your thread
List&lt;T&gt; is an array. It manages capacity for you, like you're doing with Vector3. You can browse the source here: http://referencesource.microsoft.com/#mscorlib/system/collections/generic/list.cs,cf7f4095e4de7646 
Your virtList code is nearly a reimplementation of the List class. Matter of fact, it's possible your reimplementation is slower than the List class because the List class lives in a library that's gone through native image generation and is thus likely to be better optimized machine code. Also, consider using the Stopwatch class to measure the passage of time, it'll do so with the most precise mechanism available on the machine.
Yeah, It is funny how that works. Now as the underdog Microsoft is embracing open source, using git, and producing some pretty cool stuff (e.g. hololens).
&gt; How can list be 10 times faster than an array Your benchmark is showing `List&lt;T&gt;` to be 10x faster *than your custom class*, not an array. Effectively what you've done is made your own version of a `List` - a class wrapping an underlying array. &gt; they all say list is slightly slower to much slower than array? A `List&lt;T&gt;` will be no faster than an array, we can say that. Given that it wraps an array and does extra stuff, it's reasonable to assume that if anything it might be a small amount slower. Depending on what you're doing it may very well be imperceptibly different, but who knows - maybe non-trivial just the same. **More importantly** - for such broadly used base library types like this, it is unlikely that you will come up with a more performant version than language experts. Same reason I wouldn't think of trying to roll my own `std::vector` in C++. **Furthermore** I would say it's important that you benchmark and profile your application to find what specifically is being a performance bottleneck, or perhaps solicit feedback on some of your code. 
You do know what list does internally when it needs to increase capacity, right? Also I increased initial capacity so that a resize wasn't being done anyway.
I know..i said that in the post. It's a "wrapper" around the array class. So why is it so much faster?
I already compared stopwatch to unity's time.realtimesincestartup and they're pretty much identical. Your first point is interesting and i wonder if that's the answer.
I do say my class is a wrapper around an array in the first line. I'm just wondering why List is so much faster than my implementation - ten times faster. I am benchmarking and profiling my implementation. Nothing at the moment is specifically a performance bottleneck, I'm just trying to find ways to speed it up in general.
&gt; I'm just wondering why List is so much faster than my implementation - ten times faster. You should be able to profile this as well - and as another comment mentioned, the source for `List&lt;T&gt;` is available in the public domain.
Yes, I'm looking at it now.
"List is slower" is a pretty broad statement. Going to need more explanations about how and why you think it's slower. Anyways, the reason List is winning here is because of your naive RemoveAt. List's uses Array.Copy which moves memory around rather than having to copy 10,000 items each time. Much much faster.
Your array remove .net code to shuffle items up after removal, the MS List implementation uses native code http://referencesource.microsoft.com/#mscorlib/system/collections/generic/list.cs,884 Calls Copy which is an external
I see that in the source code and will give it a try.
2010 Mac Mini ftw.
You're right. I will switch to copy. thanks! 
&gt; i said that in the post Sorry I missed that part. I hope the source code helps, but the bottom line is that it's tough to make it as a Wrap Star in this business. *(I'll see myself out)*
&gt; This is syntax sugar provided by the compiler. Yep. It's part of the C# language. https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/lock-statement
Ha. I really did laugh out loud at that one. Thanks mate ... :-)
You could also use unity3d. You only need a mac for the final build and packaging before uploading it to the app store
Arrays don't have a concept of adding/removing items, so you can't really make any speed comparisons between arrays and `List&lt;T&gt;` there. When people say that arrays are faster than lists it's usually about accessing items by index (which you don't test here), for a couple of reasons: - the `List&lt;T&gt;` indexer is an additional method call, although it might be inlined - `List&lt;T&gt;` needs to perform an additional bounds check for its own `Count` - Arrays perform their own bounds checking which also applies to `List&lt;T&gt;` as its based on an array, but when accessing arrays directly those checks can be optimized away under certain circumstances (e.g. your typical `for (int i = 0; i &lt; array.Length; i++)` loop)
did that make a difference?
Did you run the test repeatedly in one session? It could be that the JIT was busy working on the array, but not the list (I say this, because array is done before list - and they are basically doing the same things). Things tend to be slower the first time than subsequent times.
Sure did. I posted in an edit to the original but anyway by using array.copy() I now get: My array (wrapped) : .063 millis avg List: .033 millis avg
Based purely on paste experience I have with rubbish like Orleans, I think it will essentially pick whatever actor is first available: The idea being that you might have hundreds of actors and you just get given one when you need it.
I was just about to post that. Frustrating to the point where I stopped reading as soon as I encountered it.
I think you might be missing something... List itself is just a wrapper around an array. So in fact we're both using arrays. Not sure what you mean when you say you can't really make speed comparisons... That's a good point about jit compilation and gc pauses. I will have a look at benchmarkdotnet. 
Here is the link to the source code for the List&lt;T&gt; https://referencesource.microsoft.com/#mscorlib/system/collections/generic/list.cs Obviously you have a bottleneck in your implementation. I can't imagine your adding is what is wrong since you are just checking the size and resizing if larger and the rest is just normal array assignment (though I think you have a bug, you are incrementing the count as you assign a value to the index, I think this will cause the first spot to always be empty and to start a resize 1 count earlier). So the bottle neck must be in the remove at method. My first thought was that you are using value type of Vector3 which I believe is a struct. If so then when you are doing your for loop and shifting the values down it is copying the value instead of the reference of say a class type value. I am curious if you made a class type and tried it if it would be faster. However, looking at both yours and the source code the difference is that the source code uses Array.Copy to shift the array down (does this by copying into itself). So let's take a look at the source code for that. https://referencesource.microsoft.com/#mscorlib/system/array.cs At line 292 is the one called from List.RemoteAt(). That then calls another overload of Array.Copy on line 305. I'm not educated on what exactly that call is, but it looks like it is not a C# function, maybe something system level or a C++ extension. My assumption would be that it shifts the values in memory for the array to have good performance. So if you replaced your for loop with an array copy for shifting values I think you will see a nice performance gain. But at that point you have a List&lt;T&gt; class! Using arrays over a list is a performance gain if you aren't adding and replacing. Having a fixed size and never changing it is where an array beats out a list. So if you need performance gain you might need to relook at how you are structuring your data and see how fixed arrays fit there. If the point is that you need to add and remove a lot of values maybe see if a linked list will give you what you want in performance gain. Someone with more CS knowledge and C# can correct me where I am wrong. 
Thanks, I hadn't even considered that ... As it turns out using array.copy made things better...
Someone else mentioned jit too and it's a good point. No, I only ran it once - but dozens of times. Which isn't really the same thing. 
Mate, did you even read my comment?
I'm aware how `List&lt;T&gt;` works, but you titled your post *"I thought list was supposed to be slower than array?"*.
If I may ask why do you have a bad experience Orleans and are you using Akka.NET instead now?
Haha, partially. I essentially agreed with you, but completely overlooked that you already posted the same link as I did.
Npm + webpack. Create a new ASP.net core + React project from the wizard to see an example configuration. 
For solving Ode in. NET you might have a look at OSLO https://www.microsoft.com/en-us/research/project/open-solving-library-for-odes/
Simple injector is wonderful. It's my go-to whenever I need IoC
It is very nice. In fact, the second edition of *Dependency Injection in .NET* is co-authored by the developer of SimpleInjector!
Checkout Shepherd. https://github.com/existall/Shepherd
I have been using AuroFac myself and been pretty happy with it.
I've been seeing a lot of blog entries lately that are restatements of the docs. Usually the author implies that they "discovered" it somehow. 
When you write &gt;ASPX .Net C# (default.aspx/default.aspx.cs) , do you mean ASP.NET Web Forms? If so, there seems to be plenty of discussion and solutions for it on Google, like this one http://www.cloudidentity.com/blog/2014/07/24/protecting-an-asp-net-webforms-app-with-openid-connect-and-azure-ad/ 
If you want an even easier description of DI and IoC: https://codeaddiction.net/articles/10/dependency-injection-in-c---a-simple-introduction
Nah, base class libraries are just precompiled assemblies to avoid cold start penalties. It's no different than compiled JIT performance wise. 
Yeah, wrong terminology in my searches I think. This is great. Thanks!!!
I started using this because of the ease of adding decorators in cqs.
Hi just wanted to thanks for all the answers. I think encapsulation and use of methods has been really been helpful and I think I am beginning to get a good grasp. I wrote this program. The //green parts are the working old code (without method encapsulation) and the new code is about 25% of the size and does samething: using System; class MyDoubleGlazeBug { static double highLowMethod(string startSentence, double low, double high) { double highLowDouble; do { Console.WriteLine(startSentence + " between " + low + " and " + high); highLowDouble = double.Parse(Console.ReadLine()); if (highLowDouble &lt; low) Console.WriteLine("You have entered a value that is too low. Stay within parameters"); if (highLowDouble &gt; high) Console.WriteLine("You have entered a value that is too high. Stay within parameters"); } while (highLowDouble &lt; low || highLowDouble &gt; high); return highLowDouble; } static void Main() { double width, height, woodLength, glassArea; string widthString, heightString; const double Max_Height = 3.0; const double Min_Height = .75; const double Max_Width = 5.0; const double Min_Width = .5; ////Method use and encap: width = highLowMethod("Please enter window width ", Min_Width, Max_Width); height = highLowMethod("Please enter window height ", Min_Height, Max_Height); // //Original Program // Console.Write("Please enger window WIDTH (.5 to 5 meters) : "); // widthString = Console.ReadLine(); // width = double.Parse(widthString); // if ((width &gt; Max_Width) || (width&lt;Min_Width)) // do // { // if (width &gt; Max_Width) // do // { // Console.Write("You have entered a value that is too high. Re-enter a value between 0.75 and 3 meters : "); // heightString = Console.ReadLine(); // width = double.Parse(widthString); //} while (width &gt; Max_Width); // if (width&lt;Min_Width) // do // { // Console.Write("You have entered a value that is too low. Re-enter a value between 0.5 and 5 meters : "); // widthString = Console.ReadLine(); // width = double.Parse(widthString); // } while (width&lt;Min_Width); // } // while ((width &gt; Max_Width) || (width&lt;Min_Width)); // Console.Write("Please enger window HEIGHT (.75 to 3 meters) : "); // heightString = Console.ReadLine(); // height = double.Parse(heightString); // if ((height &gt; Max_Height) || (height&lt;Min_Height)) // do // { // if (height &gt; Max_Height) // do // { // Console.Write("You have entered a value that is too high. Re-enter a value between 0.75 and 3 meters : "); // heightString = Console.ReadLine(); // height = double.Parse(heightString); // } while (height &gt; Max_Height); // if (height&lt;Min_Height) // do // { // Console.Write("You have entered a value that is too low. Re-enter a value between 0.75 and 3 meters : "); // heightString = Console.ReadLine(); // height = double.Parse(heightString); // } while (height&lt;Min_Height); // } // while ((height &gt; Max_Height) || (height&lt;Min_Height)); woodLength = 2 * (width + height) * 3.25; glassArea = 2 * (width * height); Console.WriteLine("The length of wood is " + woodLength + " feet"); Console.WriteLine("The area of the glass is " + glassArea + " square meters "); Console.ReadLine(); } } 
Here's an essay I wrote on the topic. https://www.infoq.com/articles/For-Each-Performance &gt; Array.Resize(ref verts, verts.Length * 2); Uh, you're just mimicking what List does internally, just less efficently. List is based on arrays, so by definition it cannot be faster. 
&gt; &gt; &gt; &gt; the List&lt;T&gt; indexer is an additional method call, although it might be inlined Fun fact: List&lt;T&gt; has its own stuct-based enumerator. If you use it directly in a for-each loop it will bypass IEnumerable/IEnumerator so that it can inline all of the operators and avoid memory allocations. Unfortunately Collection&lt;T&gt; doesn't do the same time. 
True, that could be Resharper specific (we're not terribly strict about code style such as bracing / whitespace and such, but will usually take Resharper's recommendations). I think that boils down to: - Public methods and properties are PascalCase. - Private variables within a method are camelCase. - Method arguments are also camelCase. - Private fields start with underscores. We do a pretty good job at the office of not getting bogged down in brace indentation, whitespace, whether arguments are all on the same line or separate lines, or absolute line length limits. There are sometimes good reasons for breaking code format, or indenting something in a particular way. Or removing/inserting white-space. As long as it makes the code easier to read and figure out what is going on at a glance. (Where we do get picky is for PRs that reformat a file when done as part of a bug fix PR. Makes it much harder to review the PR. Simple fix PRs should change as few lines as possible. If formatting is really screwed up, then we force it to be changed in a separate PR that only touches formatting.)
&gt; highLowMethod() To me that method should be named `GetValueFromUserWithinLimits()`. Took me a few passes to understand what the method's goal was. (Note: I do tend to have verbose method names. When a name gets too crazy long, it's a sign that I should probably refactor. Or encapsulate better.) The method should probably use TryParse() instead of `double.Parse(Console.ReadLine())`. What happens if the user gives you bad input?
Yeh I'm seeing the same pattern and haven't been on this sub but a few weeks. They often include a few really incorrect statements and I feel it seeds bad information in other devs that don't know any better.
It's interesting to point out that Microsoft has a [style guide](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/) for code that goes into the .NET Framework.
You were strongly downvoted but I agree in principle. Sometimes threading is unavoidable but if 10% slower performance is acceptable for your application you're absolutely justified in simplifying the code.
This looks very very similar to the unity container implementation. Is there any advantage to this over unity? 
Well, it's faster than my implementation and I was curious why. Turns out most of the reason was because I wasn't using array.copy() when doing a removeat() The rest of the reason might be because it is part of a library that is compiled to native. Still interesting to learn.
You are evil.
&gt; Strictly speaking, there is nothing equivalent to friend in .NET. Ahem, https://docs.microsoft.com/en-us/dotnet/visual-basic/language-reference/modifiers/friend chough cough
You're thinking of Java's `package private`. 
`internal` is still better than `public`.
Async main was added as a 7.1 feature. By default your project will use latest major release aka 7.0. You need to switch the project destiny to use 7.1 features.
It wouldn't build if they weren't using the correct version of C#
If you can repeat it with a simple code set up rather than a real world project and definitely confirm it's a problem that your specific code isn't causing then filename bug report with Microsoft 
&gt; Edit: I’ve “solved” it by just doing the old/usual approach of having a new static class called _Startup_ with all my async code in it, and then in _main_ doing _Startup.Run().GetAwaiter().GetResult()_ which gives me my exceptions but only at the highest level rather than VS taking you to the line where it’s being thrown, so not a great fix... That because VS defaults to breaking on unhandled exceptions, not thrown. It’s only unhandled at the top level, since the task framework captures it further down (to be rethrown later). You can turn on “break on throw” in exception settings in the debug windows menu. 
Try these, not sure which will work for you but start with the first one: [first one](https://msdn.microsoft.com/en-us/library/mt186161.aspx). [not the first one](https://msdn.microsoft.com/en-us/library/hh266747.aspx)
The only thing required as to be able to run your application on either windows 7, 8 or 10 would be the availability of the .NET Framework used in the original version. 
Erm... is the debugger set to stop on thrown, not uncaught, exceptions, by any chance?
Are you sure that host (`77.121.11.33`) is a web proxy? When I try it, it's just sending TCP resets.
That doesn't seem to help. I've already got that version of the .NET framework on Windows 10l
I've had no luck with those. I'm downloading Visual Studio 2017 Community to see if that helps. Can I import the project files into that and retarget them to Windows 10?
What's the actual symptom you're seeing? Does it refuse to start at all? Any error messages? 
I will check, where is that setting? I’ve never heard of it
All I see is the icon for the app in the bar on the bottom of the screen. I've tried running the compatibility trouble shooter but changing it to run in Windows 8 mode doesn't help. I'm installing Visual Studio 2017 Community right now. Can I import the project into that and use that to retarget it to Windows 10?
It's not a targeting issue. You're chasing a red herring. Does your process show up in the task manager? 
Yes, it does show up in the task manager.
Sounds to me then like it's window is just appearing off screen then. Hover over the icon in the task bar and see if the thumbnail shows up. If it does right click it and select move, then tap any arrow key and then move your mouse. 
I should've said when I looked at downloading "Tools for Windows 10" it wasn't available for Visual Studio 2015 Community, just for version 2017.
The thumbnail shows up but when I right click it there is no menu. I do see a new popup after a while with two options. One to close the app as it's stopped working and the other to debug the app. I've tried the second option and that didn't help, all it said was it had a problem with one of my plugins, from ErikEJ.
It was a Socks proxy, I tried it with a html proxy and its not throwing me an exception now but I am however getting this HTTP/1.1 400 Bad Request
Like others said, there shouldn't need to be anything to change other than maybe the framework version if you targeted something old like 2.0 or maybe something deep in the Windows API...which I think you'd know. Is it a console app or a WinForms app or a WPF app? You mentioned running the exe - can you run the source?
WinForms app. I can run the source code in Visual Studio itself.
Have you checked the event log? Just click start and then type "event viewer" (without the quotes), then navigate to Windows Logs | Application.
Where is this setting? I’ve never heard of it
But break on throw seems to have always been the default? Is this a new “feature” in 2017?
https://gist.github.com/anonymous/8b9c5f20a6977049ac1e24c347c98965 This is what I've got.
When open, change the resolution of your desktop, then change back?
It’s simple. 
Update?
So it sounds like from comments it is working just not displaying. One way to try to fix this is to go to task manger find the process, right click on it and select maximize. You might have to open the drop down to get it to work but this is how I fix Scene Builder when I work with JavaFX. 
You can run the source on the windows 10 computer? How were you trying to run it before. Did you copy the bin folder over? 
It is simple, faster, stricter. 
I like your passion about c# 
While debugging, Debug -&gt; Exception settings (I think, don't have VS in front of me).
I'm just getting started in Akka.NET too, but that sounds like a bad idea. It would not work for remote actors. So it's not scalable. It seem preferable to tell each actor to send their result parts to an aggregate actor which would combine these parts into the final result.
BTW: there is also an /r/Akka/ subreddit.
you dont need 2017 to write programs for windows 10. you dont even need to "target" a program for windows 10. something else is wrong with it.
I have bad news. [System.net.WebProxy](https://msdn.microsoft.com/en-us/library/system.net.webproxy\(v=vs.110\).aspx) only supports HTTP proxies. You're going to need to use a library that provides a socks client, or you'll need to write one yourself. 
Ahh makes sense! 
Yep, I've heard that it's used for visualising and modeling non game related fields. It's capable of displaying thousands of elements efficiently so I guess it makes sense... just thought I'd mention it.
Sounds like your problem is that your routine finishes early but there is a chance that it enters a failure state after that and would have to do more work? In this case I suggest implementing some kind of confirmation that the work has been finished. Then in your while-condition, you would check if all work has been confirmed instead of checking if all work has been accepted/started/whatever-it-checks-now. 
Don't forget that D in SOLID is dependency inversion, so you're following SOLID by doing it too.
Ok, I need to to back up, slow down, take a deep breath, and add some paragraphs and punctuation. Then, start reference counting. Make sure your things are dereferenced at the right time.
It got me thinking i might could have use some "working" list, stack or sth like that and whenever it sends some range to client/server i would add it in "working" list with some id and when the work is done it would delete it from that list and i would have check in while condition if "working" list is empty or not. It could possibly work i think. Probably not the best way how to handle it tho 
I like your passion about their passion
Just want to add that the event viewer is also accessible via the Windows 10 start button context menu.
And what’s your favourite fruit?
I was able to trim things down and keep it under 700 megs. So there was quite a bit of fat I could trim. However as far as I can see it is only really using 300 at most and once processing is done it goes down to 100megs. Task manager still shows it sitting there using 700megs till closed. On the previous build it could sit there for days and the task manager would still report over a gig used. I’m aware that the allocated memory may never be freed till the system has constraint issues.
Removed: Rule 4. No code to reproduce the issue, pretty vague description, the report is four years old. Probably best to produce a minimal, verifiable, complete example and contact the JabbR devs with it.
What are you talking about? you can clone the JabbR project....
Do you expect people to download/clone the _entire_ JabbR project, go through the **22 page tutorial** linked, in order to try to solve some (presumably) obscure 4 year old bug? No. It's not happening. That is _not_ a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve) and not a submission "made with effort".
Gotta love the Deftones hat!
You shouldn’t so much treat a message as a reference type that has a ‘state’ that is manipulated by multiple Actors, but more like an Actor has the state that you need to keep (maybe it’s persisted) and messages are mere value types that communicate changes in state. Messages can communicate state but not keep a state that is held by reference by other Actors. So you could almost think of the Actor as your ‘reference type’ and different messages sent by different Actors can change properties of that reference type and the Actor can produce new messages that communicate its new state to interested parties, or persist it for later retrieval. The reason to communicate state change instead of share references is powerful for Akka because you’re taking away the chances for race conditions and deadlocks that you might see with shared references to data across a system.
Try the following steps: * 1. Add a global exception handler as described here: https://stackoverflow.com/questions/3133199/net-global-exception-handler-in-console-application * 2. Write the exception to the event log as described here: https://stackoverflow.com/questions/25725151/write-to-windows-application-event-log-without-registering-an-event-source
Sweet post David!!!
&gt; I copied the debug folder to the desktop Have you tried to build "Release" and testing that?
Grapes
I liked "Javascript: The Good Parts" coming from a similar background.
You should iterate over the array, use foreach or for until arr.Length
hm what do you mean could you show me im a beginner to this
Alt-tab to select it (so it has focus), then hit alt-space to cause the context menu to appear (even if you don't see it). Then hit M which is the shortcut for "Move" and use your arrow keys to scoot it around until you can see it. 
You should iterate over the list to get all the elements for your array, Here is a [link to the documentation](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/foreach-in), that will help you out. Also, something important. you can get the length of your array by using arr.Length. with that you will not have to put a hardcoded 5 there. :)
There are three really good ones, I'd start with JavaScript: The Definitive Guide. This will give you a good overview of what you can do with the language, the syntax etc.. then I'd move onto JavaScript Patterns: Build Better Applications with Coding and Design Patterns, or, Learning JavaScript Design Patterns. These books will tell you how to write your Javascript so it follow good coding practices, the differences between OO, overloading, creating private variables etc... The next tip, is to just start using it everyday. I've read all three an I learnt more coding then I did reading, good luck!
Honestly, starting from the beginning if you've never properly learned javascript may be helpful. Many of the complaints about the javascript often boil down to never actually taking the time to learn the language or modern tooling. Elequent Javascript. Javascript: The Good Parts is another one. But you can also just watch Crockford's javascript lectures online. I'm not an expert, but if you wanted short list of topics to study. To my mind, theses are the concepts/features that I use the most from day to day. 1. Avoiding type coercion for all but the most trivial cases 2. prototypical inheritance (what the class keyword actually means in js) 3. closures 4. bind/call/apply 5. promises 6. Object.keys/values 7. Object.assign / spread operator 8. pure functions 9. avoiding mutation 10. const/let (scoping/hoisting in general) Javascripts tends to work best as more of a functional style language. I tend to only utilizing outright classes where is really makes sense like for public interfaces or to classify a data structure. It is also important because more and more javascript librarys/frameworks will only work properly if you avoid mutation, which can be often be tricky to avoid. This is particularly true if you are using react and/or redux or similar and dealing with complex nested state. Additionally, you'll want to learn modern web tooling like node, npm, npm scripts, babel, webpack, babel-preset-env, scss, and some scaffolding app for your stack like create-react-app or dotnet new react/angular/&lt;whatever&gt;. Project setup is a pain without these prebuilt solutions and a lot of ways for things to go wrong without one. Unit testing/TDD is also much more important in js, because a) static analysis is much weaker in js and b) firing up the browser or server to test code is very time consuming. Jest is probably the easiest testing framwork to use that has wide adoption.
Look into MVC. 
The C# way is to implement IEquatable&lt;MyClass&gt; on the class itself. Yes this means adding a method, but that doesn't necessarily mean manually checking all the fields. Most times for database models you can just check the ID field. For more complex data types you might want to use System.Reflection and loop through all the properties/fields on the class.
Okay, I will. I have started reading through the Microsoft page about it: https://msdn.microsoft.com/en-us/library/dd381412(v=vs.108).aspx I appreciate you taking time out of your day to respond, thanks!
Come on... a gain of 3000% and isolated batches is *SLIGHTLY* different that a 10% loss of speed. Whats with the insults and straw man arguments? This is programming, we should be logical.
This isn't exactly accurate, theres a whole bunch of things you need to override and implement, and you don't need IEquatable unless you only want one property to be compared.
If he wants to support == then that's what IEquatable is there for. You don't have to override anything else. If there are other ways could you give more details? The above is just my experience.
Not directly answering your question but I'd recommend taking a look at TypeScript. It transpiles to JavaScript and its syntax is pretty much just JS but with all the good stuff you are used to. It was created by Microsoft to bring some of JavaScript's awesome upcoming features to current day JavaScript by generating a lot of the work arounds you'd normally have to do. It also brings a (in my opinion) much needed type system. The reason I'm suggesting this is many of the features it allows you to use bring JavaScript much closer to C# and I think C# was a big influencer on the language. Classes, Interfaces, Inheritance, etc behave in a very similar way to what you are used too. With these added features you can focus more on understanding the quirks and dynamic prototyping nature of the language with out getting like you are hacking it to do something you would expect the language to do. Not to ramble on too much but a lot of being able to get on with JS in a productive and familiar way is to work out a good work flow and get used to the tools. If you are writing your code strictly for the front-end you can still get the benefits of NPM (the JS equivalent to Nuget) if you use something called Webpack which bundles up all of your code for you and makes it web friendly. I started the process of taking JS development more seriously a couple of years ago after nearly 10 years in C# and was overwhelmed by the buzzwords and tools. [This post on Hackernoon](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f) describes perfectly how I felt. The JS landscape is full of dozens of solutions for every perceived problem but the only tools you really need to master are NPM and Webpack. A lot of people are adopting TypeScript as their flavor of choice for JavaScript projects. Even Google are using it for a huge number of their Node.js and client-side libraries including their Angular web app framework.
https://msdn.microsoft.com/en-us/library/ms173147.aspx Sounds like you aren't doing it quite right.
+1 this list. For books I would add _Understanding ECMAScript 6: The Definitive Guide for JavaScript Developers_ as I personally found it helpful in improving my understanding of ES6. In my experience I have found jest to be slow, so I have been using mocha with chai. I still use jest to test reactjs components, though. 
Re the *JavaScript: The Good Parts* recommendations, here is an excerpt from the pseudoclassical inheritance section: &gt; The new function object is given a prototype property whose value is an object containing a constructor property whose value is the new function object. I love that sentence! My point is, the book is not light reading, and it's not aimed at JS beginners. You should probably start with another JS book before diving into this one.
Im super new to c# and im getting super excited to start learning, so i can eventually move over to unity! but for now, its all simple and for fun!
AWESOME!
You need to override the == operator as well. It will do a reference comparison by default. Usually you would add your IEquatable implementation and then override == to call it.
Snap a crash dump when you see the process is over a gig. (Visual Studio -&gt; Debug -&gt; Save Dump As -&gt; Minidump **with heap**. Don't use Task Manager to take a crash dump.) Load this up in WinDbg. Load sos: .loadby sos clr !dumpheap -stat This will show you if it's actually managed heap space. If that doesn't show you a smoking gun, you can use !eeheap to see what parts of the runtime are taking up memory. Additionally, you can use [ClrMD](http://github.com/Microsoft/clrmd) to enumerate all .Net Runtime memory regions to see what is eating space. Print this query out (and clean it up...): var regions = from r in DataTarget.LoadCrashDump(@"C:\path\crash.dmp").ClrVersions.Single().CreateRuntime().EnumerateMemoryRegions() group r by r.Type into g let count = g.Count() let size = g.Sum(i =&gt; (long)i.Size) orderby size descending select new { Count = count, Size = size, Kind = g.Key.ToString() }; If you still don't find a smoking gun, then it's likely native code is to blame. Maybe a library you call into? At that point, back to windbg: "!address -summary" should give some clues. Or [UMDH](https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/using-umdh-to-find-a-user-mode-memory-leak) for native leaks.
Try calling GC.Collect. Does the memory free up? If yes, you are right. If no, you have a reference somewhere.
Does this ever happen to anyone else? Or is it just because I am a beginner? If it does, I'd appreciate votes + exposure to try to boost the priority, as it's bit us a couple of times now. If it doesn't, how do you avoid it?
Hey Thanks for that. I will definitely implement this for the next release.
Hey, I'm applying the changes you mentioned. I just don't understand point 4. Was wondering if you could elaborate?
If you want to make really high quality web apps look at webapi + angular.
You can use your programming knowledge. Start here: https://www.youtube.com/playlist?list=PLoYCgNOIyGABI011EYc-avPOsk1YsMUe_
&gt;Have you tried to build "Release" and testing that? This fixed the problem. Thanks very much for that. I should've remembered this setting but it slipped my mind.
Removed: Rule 2. Please don't link to an executable. Instead post the source code to GitHub (or equivalent) and let people download/build themselves.
Use the [`TextBox.SelectionStart`](https://msdn.microsoft.com/en-us/library/system.windows.controls.textbox.selectionstart%28v=vs.110%29.aspx) and the [`TextBox.SelectionLength`](https://msdn.microsoft.com/en-us/library/system.windows.controls.textbox.selectionlength%28v=vs.110%29.aspx) properties to know where the user currently has the caret and/or what text they have selected. If they've just placed the caret somewhere and not selected anything, `SelectionStart` will be the index/letter where the caret is, and `SelectionLength` will be zero. By using these, you can change the `TextBox.Text` using string manipulation (perhaps using [`String.Remove`](https://msdn.microsoft.com/en-us/library/d8d7z2kk%28v=vs.110%29.aspx)) to delete the desired characters. You may need to do a couple tweaks depending on whether or not text is selected, or if it's the start of the string, or if you wanted to delete backwards ("backspace") or forwards ("del").
You don't need to recast your variables. Ex) you have vertlist class. You define verts as vector3 when you call vertlist and pass the int parameter you are recasting verts. 
Learn .Net framework. LINQ-to-Objects extensions.
Just override ``Equals`` and ``GetHashCode``. Then the ``==`` operator won't change its semantic (it still checks for referencial equality) but you can call ``Equals`` on your own object in order to check for *semantic equality*. Make sure you read about the pitfalls and how to implement a good hash code first. There are lots of good resources around. 
OK this is seriously cool.
Personally, when I need to learn a language I do one of two things: 1. I find resources online and read them. 2. I buy the Oreilly Associates book. Sometimes I do both. Remember in Javascript that all the major browsers have their own extensions and implementations, so if you write something that works perfectly in (for example) Internet Exploder, it probably won't work *at all* in any other browser. There are many libraries (like for example jQuery) that abstract you away from the browser details so you can focus on writing program logic and let it handle the idiosyncrasies of the browser for you. Trust me, *you want to use some sort of abstraction library*, or you will have to be updating your code every time one browser or another changes its version. I wrote my own abstraction code for years until I finally got sick of it and started using jQuery instead. As a result of this, you will want to learn some library concurrently with learning the language. I suggest you start with jQuery *just because it's easy*. There are other powerful libraries out there, you will probably want to learn one or more of them sometime, but jQuery should be enough for you to get started with. In terms of jobs, it's absolutely vital that you have some experience working with jQuery or one or more other libraries. Employers don't look for people with Javascript experience any more, they look for people with jQuery experience or React or Angular or Knockout or such. The more of them you know, the more jobs you may be considered for. The fewer of them you know, the more jobs you will be taken out of the running for. For years, I wrote my own abstraction library, which was lighter than any of the libraries I found and went more with my line of thought, and maintained it myself on my own time and let employers use it. I not only gave this up because it became too much of a time sink, but because I found employers were universally failing to consider that *if I was capable of making my own library instead of jQuery, then I must be a good enough programmer that maintaining their code with jQuery would be easy for me, right?* I got tired of losing out on jobs all the time and just took an hour and learned jQuery. (It's stupidly easy.) 
I used to design programming languages. This sentence makes perfect sense to me, and I understand why someone would struggle with it, just as when I was trying to explain about one of my languages why *object* is a function, but *function* is an object. (There is a very solid and logical reason for this which most people fail entirely to understand.) Object inheritance is weird, and most people need a simplified version for a long time before they get down to details, and may never get as far as details.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/dotnet] [Custom ruleset in TFS](https://www.reddit.com/r/dotnet/comments/7kjkn0/custom_ruleset_in_tfs/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I don't want to act like a fanboi, but i'm not sure if there any other guy on youtube who is more knowledgeable and explain concepts better then him. 
This oke makes the best WPF tutorial on the whole internet. And his voice doesn't put you to sleep. Good stuff.
Oh my God yes, please no more c++ for CUDA. I coded for NVIDIA GPU in C++ years ago and it still hurts my mind. 
Could someone ELI5 why this is great? Thanks!
I was in your same situation and I've bought the book "JavaScript Patterns". that was really useful to understand how JavaScript "works". you'll not become a JavaScript expert but I believe that's a good place to start - is not for *completely beginners* to the language (no too much syntax) but it illustrates the foundations of it (how objects and properties are treated, inheritance, scope of the variables, etc)
Not sure what you mean...the only int parameters used are for indexes... Can you tell me which line the recast occurs?
You're right, it's weird, I thought I'd tackled this in the past but it seems my use cases weren't this specific.
he did address the overposting scenario in the article.
Great writing as usual by Toub. I'm definitely looking forward to a follow up on Span in a few months as part of the "Performance Improvements in .NET Core" series.
So this proxy "192.99.46.182:1935" returns the weird thing While this proxy works flawlessly.. Whats the difference between them? "45.55.27.246:8080"
Where is you proxy authentication?
Thank you all, I hope you enjoyed it. There is much more to come! Just finished my article for the .NET Curry magazine - look for it in January. Also, checkout my pinned tweet https://twitter.com/davidpine7/status/941759704363085825 please share and retweet. Go deftones!
That is interesting, thank you. I will have to try that.
I guess thats the question, according to a profiler the memory is being freed up. The Task manager is not showing the same. I am running GC.Collect ever two minutes just for testing.
This made me feel like you were inspired from my question i had a few days ago: https://www.reddit.com/r/csharp/comments/7i6d9i/c7_nullpropagation_problem/ It's a pity that c# does not currently support this kind of functionality 
You need to turn all CLR exceptions to be able to break on them. https://i.imgur.com/yGrJRjY.png
I’m in a similar boat in terms of experience. (I’m at month 2.5) I do a few things, but recently I’ve jumped into making my first (what I would call) “full-size” application. I’m building the app to be functional currently, and when I’m close to finished, I’ll have something I’m familiar with to learn how to do GUI stuff on. Other things I do: - Codewars - Learning SQL &amp; about to jump into python. - watch tutorial videos and try to understand wtf OOP is. - Working through a udemy course on unity.
If i understand correctly, this allow to code for NVIDIA's GPUs in c#. Before that you had to use C++. CUDA is a framework used especially to compute operations on multiple cores on NVIDIA's GPUs.
Upvote my issue I posted. The good news is the team seems like they're willing to discuss it and consider improving upon it.
As a budding game dev who hates C++, sweet fucking Jesus.
Try override AroundPostStop() method: https://github.com/akkadotnet/akka.net/blob/a478c5e8c8d5de97dcf7bcea7e2a80fbaa5e6cc8/src/core/Akka/Actor/ActorBase.Lifecycle.cs#L85
Is this the same as a gated check in?
There are no insults in my comment to you. But the reason why you're so heavily down voted is that you're making an argument for ignorance - instead of learning how to use threading properly, you're trying to make a case for not using it at all. You went so far as to slow your program down in order to simplify it. Instead, you should be rising to the challenge. Learn how to do it safely and effectively. I'll help, if you want.
Thank you!
His videos are really great and he steps through everything so throughly. He has a great series on building installers which I used successfully the other day. 
My what? It's just a random proxy from the internet. 
I do ... very much. And I have several, kind of made it like a personal branding thing. All the regional talks I do I'm getting recognized by that hat. :)
&gt; "The shroud of C has fallen. Begun MSIL on GPU has.."
its not going to work perfectly yet. I havent even learned about TrypParse() yet. But I am methodically going through yellowbook and c# course by rob miles.
But will it even make sense for games? I know nothing about it but as I understand it only works with Nvidia cards which is very limiting.
I think it would be most useful for games that are graphically simple, (so the GPU isn't already stressed by rendering) but have a lot of easy to parallelize work to do. Procedural terrain generation for example. You could run all the noise functions on the GPU.
Removed: Rule 4. Choose whichever you're most comfortable with.
That's not the same as `friend` in C++. In the VB.NET world, `friend` is equivalent to `internal`. Example VB type: Class MyPublicVBType1 Friend ReadOnly Property Foo() As String Get Return "hellO" End Get End Property End Class And the corresponding IL code for the property getter method delcaration: .method assembly specialname instance string get_Foo () cil managed { /*implementation not shown*/ } Note the `assembly` qualifier which is the same as C#'s `internal`. 
Removed: Rule 4. There are a multitude of learning resources available. Check the sidebar, check /r/learnprogramming, there are many books to learn from, video tutorials, and PluralSight-esque training services. Jump in. No single way is "best" for everyone.
Though I question the goal here, you can accomplish something like that, but your *m_property* is not accessible from *Derived* unless you make it protected/internal/public. Here is an example of how this could be done (but it probably shouldn't): public class BaseClass { protected int m_property; public virtual int MyProperty { get { return m_property; } set { } } public class Derived : BaseClass { public override int MyProperty { get { return base.MyProperty; } set { m_property = value; } } } }
Not like that for 2 reasons. 1. In Derived, you're trying to set the instance field m_property directly, which is private, so of course it won't work. 2. Even if you were trying to set the *property* from Derived, it won't work since there is no setter. However, you *could* set MyProperty in the base class to have a protected setter, meaning Derived would have access to it. public class BaseClass { private int m_property; public int MyProperty { get { return m_property; } protected set { m_property = value; } } } public class Derived : BaseClass { public int MyProperty { get { return base.MyProperty; } set { base.MyProperty = value; } } }
Many thanks. Yes, I meant m_property to be protected. In case you're curious: the base class represents an overhead crane. I will be reading its position from a PLC. The derived class represents a simulated crane, in which I will be setting its position.
Look up Accord.NET, seems working to me
I would still recommend making BaseClass.MyProperty virtual and using the override keywork in Derived. Otherwise this is considered "hiding" and will result in a compiler warning, along with unexpected behavior when the instance is cast/passed as a BaseClass. public class BaseClass { protected int m_property; public virtual int MyProperty { get { return m_property; } set { Console.WriteLine("set from BaseClass"); m_property = value; } } } public class Derived : BaseClass { public override int MyProperty { get { return base.MyProperty; } set { Console.WriteLine("set from Derived"); m_property = value; } } } public class Foo { public void Bar() { var derived = new Derived(); } public void DoWork(BaseClass baseClass) { baseClass.MyProperty = 888; } } Calling Foo's *Bar* method results in *"set from BaseClass"*. While using the virtual and override keywords on *MyProperty* would result in *"set from Derived"*.
You can override the property by using the **new** keyword, but this creates actually a *new* property, instead of overriding the *existing* property. Most of the time, it is simply better to use a setter method.
So I don't know if you still care, but I decided to give `Parallel.For` a try. Pretty much right away, I started getting `OutOfMemoryException`s. So, in order to remedy this, I switched the build from `Any CPU`/`Prefer 32-bit` to an x64 build. And *this* is where I found some interesting results. Machine test info (same for all tests): BenchmarkDotNet=v0.10.11, OS=Windows 10 Redstone 2 [1703, Creators Update] (10.0.15063.726) Processor=Intel Core i5-6300U CPU 2.40GHz (Skylake), ProcessorCount=4 Frequency=2437498 Hz, Resolution=410.2567 ns, Timer=TSC [Host] : .NET Framework 4.7 (CLR 4.0.30319.42000), 64bit RyuJIT-v4.7.2558.0 DefaultJob : .NET Framework 4.7 (CLR 4.0.30319.42000), 64bit RyuJIT-v4.7.2558.0 So, for consistency in testing, I also benchmarked the original, normal, synchronous initialization as well as your original multi-task approach (the method `OPsOrigMultithread`), and all of them use the same `Width`/`Height` values as your test code (`3000` and `4000`, respectively). I did two variations of `Parallel.For`: the first one doesn't specify anything for `MaxDegreesOfParallelism` and combines the results using a `foreach`, and the second specifies a `MaxDegreeOfParallelism` and combines the results using LINQ `SelectMany()`/`ToList()`. | Method | NumOfTasks | Mean | Error | StdDev | |------------------------- |----------- |---------:|----------:|---------:| | **SequentialInitialization** | **1** | **40.21 ms** | **0.7863 ms** | **1.102 ms** | | **OPsOrigMultithread** | **2** | **39.10 ms** | **0.7744 ms** | **0.7244 ms** | | ParallelFor1 | 2 | 145.06 ms | 2.9433 ms | 8.3975 ms | | ParallelFor2 | 2 | 135.95 ms | 2.7057 ms | 6.2710 ms | | **OPsOrigMultithread** | **8** | **39.64 ms** | **0.5081 ms** | **0.3674 ms** | | ParallelFor1 | 8 | 142.34 ms | 2.7295 ms | 2.5531 ms | | ParallelFor2 | 8 | 144.52 ms | 2.7791 ms | 2.5995 ms | Now, if you recall [from my previous tests](https://www.reddit.com/r/csharp/comments/7h2eer/tasks_in_cnet_creating_a_listlist_through/dravgbx/) built targeting x86, **all of the results were in the ~380-400ms range**. # **The speed of your original code improves by a factor of 10 just by switching to an x64 build.** So this seems pretty significant. Either the different JIT used (32-bit used the "LegacyJIT" while the 64-bit uses "RyuJIT") accounts for the significant differences in execution time... or it is the increased memory addresses available when built for x64 that drastically increases the efficiency of the code. ¯\\\_(ツ)_/¯
This is a good queation. Last time I also interest to take that exam and i also wonder what material part its take. In my opinion Microsoft should update topic /material for preparation to that exam. 
The "You don't know:JS" series is good. https://www.amazon.co.uk/You-Dont-Know-Js-Book/dp/B01AY9P0P6 Also, there are a few podcast series that you could listen to that explain the fundamentals. Javascript Jabber is a good one, but there are others.
what would the python equivalent be?
&gt;You can override the property by using the new keyword, Override is the wrong term to use here, using "new" hides the base class's property 
Removed: Rule 4. It's a pretty broad question. You'll have to dive in and make an attempt. Make use of the various learning resources in the sidebar and /r/learnprogramming, and I assume whatever learning materials are being provided to you. If you still run into issues, feel free to post but include any relevant code of your attempt.
Import text-analytics Making this up, my friend is a python dev and all they seem to do is import lol
In what ways is friend different than using internal with InternalsVisibleToAttribute?
[removed]
Have you seen the one in 2017?
I'll try my best to answer your question. But first, let's quickly note that [`friend`](http://en.cppreference.com/w/cpp/language/friend) means something different in C++ and let's ignore that for the remainder of this specific post. :) In the .NET world (VB.NET), 'friend' refers to assembly-wide access: if you mark a type/property/field/etc. as `friend`, all other types within the same assembly can access it. There is also the concept of 'friend assembly' which is where `InternalsVisibleTo` comes in: this attribute is used to extend assembly-wide access to one or more specified external assemblies. Again, all of this is different from `friend` over in C++ land.
I'm not into c++, so unlikely to read all that. I was just wondering what the basic differences between c++ friend and c# internal were.
Try to crack it yourself, maybe you'll learn something 😃
If you kinda need it, you should kinda pay for it. 
Fair enough. Rather than talk about what `friend` means in C++, it might be easier to just point out that there is no formal notion of a module or assembly boundary (part of reflection, et al) in C++ where types and accessibility are strictly compile-time constraints. There is more to it if you want to get into C++ but save that for when insomnia strikes. 
1. You're not going to get help here with that crap. 2. https://msdn.microsoft.com/en-us/library/system.windows.forms.datavisualization.charting.chart(v=vs.110).aspx
What is this? Some sort of web browsing monitioring app for parents of child movie stars? 
Removed: Rule 2.
I don’t have much problems, 90% of the times the exception message is right. And when is in the inner exception is just a few clicks away. When I have to look a lot of the times the same innerexception I just add it to the watch list. It could be better, I have doing it like this for 10+ years and simply don’t care, probably because of habit...
This is extremely cool but I find it very strange that no actual performance comparisons are included against the CPU version of the code. I would argue that the main reason for this to exist is the performance you will get over a CPU implementation and a Mandelbrot demo should show great gains assuming that this works well. But without a CPU result to compare against I cant know if its a 10x gain or a 1000x gain. 
Actor pattern. Can't say much cause I'm not into this :p
No not yet.
You could use an off the shelf reporting solution like telerik reporting or active reports. What about SSRS?
I believe the == operator will only return true if you are comparing the same instance of a class with itself. If you want the == operator to do something different, you will need to overload it in your class.
I just read through a good chunk of that exam reference you posted and I am offended that Microsoft has an exam that is as comprehensive as that, yet all of the examples of their new technology are constantly bad practices. Like an official MSDN article on how to "Buzzword Buzzword MVC", is 70% garbage and bad practice, yet they have tests on how to do things right. Or "right"; I haven't finished reading the PDF.
Then you have a memory leak in unmanaged code. What unmanaged dependencies do you have?
HTTP 403 for me.
To print a pdf you need something which can render a pdf. If you can shell out the money, I highly recommend pdfprinting.net it has worked great for me. I used a combination of that and the built in System.Printing namespace to enumerate printer names and create an array of printers which I can print any pdf document to. There's another package from pdfprinting.net which does pdf creation and I highly recommend if you need to do any serious lifting with a pdf engine. I have no experience printing anything except pdf files, however it shouldn't be too difficult to turn a txt file into off (you still have to do line/page wrapping but it's fairly simple). I did a fair amount of research before settling for pdfprinting.net- it seemed to be the most modern and have ongoing support. 
C#'s machine learning ecosystem, while functional, is not well document or newbie friendly. If you want to walk the beaten path, write an IronPython library then use CLR interop to call into it.
Thanks for the clarification 😊
-"Welcome to Microsoft! Where everyone enters as a highly trained professional and leaves as a near-complete rookie!" 
I get a nice 403 error on that link
Using compute shaders would probably be a better option, and would fit in much more naturally with the rest of the game engine's graphics-related code.
First, I wouldn't search the whole registry, for example playing with HKEY_CLASSES_ROOT hive could damage some programs. There are Rgistry and RegistryKey classes in Microsoft.Win32 namespace, which can manipulate registry. RegistryKey class contains methods which will give you all subkey names or value names for given registry key. I still don't know what exactly you are looking for - strings in key names, value names, or registry string values?
I'm trying to remove all traces of a printer driver. the problem is, i have no clue where it writes in the registry, so i have no clue what to remove to "start over" with the printer installation. :/
Removed: Rule 4. Given your task, I would suggest not writing a computer program for it. Sounds like it's too prone to error. You can search in the built-in regedit.exe itself for keywords. If you're still thinking of writing the program, as suggested by the other poster, there are APIs you can use. Give them a shot, but be extra, extra careful. I would recommend you structure your program such that the searching mechanism can be run without deleting them then doing the deletion in a second pass after confirmation.
Then start with listing all the registry keys and values with that name, you can delete them later if you are sure you won't damage anything. To accomplish this, you would probably have to call the methods listing all the key and value names on every key. I don't think there is any method that would search the whole registry for you. Although you can try googling for some library that can do that. I am still not sure that this is the best way to solve your printer driver issue, there might be some knowledgeable people who could give you better advice.
Strange. Not sure what would cause that. 
So what is your question? How to store it in the DB, or what is the best way?
seems to be working fine now
Removed: Rule 4. Break down your application into components and research those individually. Don't google a description of your application, instead search for simple C# database tutorials, how to play a sound file, and so on.
The author points out that there's about 6 seconds of overhead, and it appears to be the time it takes to run the ui callbacks in order for the task to finish. There are some opportunities to fix that - a large part of that cost is probably the many separate posts to the UI to create individual the individual elements - invoking the ui thread several hundred/thousand times is probably not cheap. Not only does that make the UI work take longer, but it also takes away cpu from the threadpool threads running the classifier. What would be an interesting comparison would be to wait for all classifier jobs to finish, and then in a single UI invoke, create all UI elements. Instead, since he's adding the ui elements one at a time, that panel is going to do a full relayout and repaint cycle, eating a ton of cpu and time. If instead he added everything all at once, he could turn off updates/layout, add everything to the panel once, and then let it perform a single layout and repaint. I bet that would be significantly faster because his current design has exponential growth.
Better to make a separate interface (methods) to set the position, and keep the getter-only.
Is this purely an educational/experimental question? If I am understanding this correctly and if you are needing to do something like this, then your design might be flawed. With that said, you can do somewhat of a `Subclass Sandbox` pattern where subclasses are given a "sandbox" to play around in from its base class: public abstract class BaseClass { private int m_property; public int MyProperty { get { return m_property; } set { m_property = GetPropertyValue(value); } } protected abstract int GetPropertyValue(int value); } The sandbox is the GetPropertyValue method. The base has to be abstract but sandbox methods can be either abstract or virtual depending on your need, allowing subclasses to have their own implementation for something. Normally, I use abstract for subclass sandboxed.
great article! i'm pretty new to TAP and i'm really enjoying seeing this kind of article, where i can see real-life approach to parallel programming
I can see the benefit compared to using something like Mediatr if you have simple domains and your controllers do just like your example: bind the request into a model based on a Mediatr request, call Send(), then spit out the result to the client. However, I don't like to let details about my API leak into my domain. I don't like APIs that are just simple CRUD when it doesn't make sense, so I bind input to DTOs that include MVC/WebAPI style validation attributes and use ModelState validation. Then I simply map to a request model that's defined in my domain (but does depend on Mediatr) in order to have Mediatr wire up to a handler. My controller actions end up with just a few lines to create/send the request, then map the result back to something more appropriate for an API response (if any is needed). I don't mind writing a request model and handler for every request, because I don't need an all-encompassing "service" and interface that need to be injected that will end up bloated at worst, and force unnecessary dependencies at best. So, for the TL;DR: This seems like a nice idea that may simplify your API depending on your domain. However, I feel like if this benefits you, then you've truly created a pure CRUD application that isn't worth much, or you've oversimplified an application that should have been much richer and you're letting the front-end have too much control over business rules.
yup thanks
I'm not sure why you think you can only use this with simple CRUD? The code is example only. You are able to write whatever you want. The library just wires up the request to inject any dependencies needed for the handling of the request. As far as the UI controlling business rules, this is a matter of domain validation vs contextual validation. Contextual validation goes in the request and is handled depending on your set up. IValidatable object would put the validation handling within the class itself, or you could use FluentValidation and place it in another class. I wrote another blog post on it here http://dotnetcultist.com/dealing-with-validation-domain-vs-contextual/ Finally, validating a request can still be done with a validation filter and that uses ModelState.IsValid. Again though, how you validate your requests is up to you. Your request objects are just ways to interact with your domain, and there are no restrictions on that. Let me know if I'm misunderstanding what you are saying. Thanks for your feedback.
I still seem to be missing .net standard features. These are all .Net Core features.
.Net Standard is basically the spec for .Net Core. .Net framework is the Windows only stack.
Removed: Rule 4. Please include the connection configuration and/or code you're attempting to use. (Remember to censor sensitive information like IPs or passwords.)
Stuff like "npm Task Runner" is not even remotely related to .NET or .NET Standard. It's a Visual Studio feature. What a bullshit article.
The debugging thing doesn't work well for me, I keep getting [this error](https://i.imgur.com/ZYfesZF.png).
Yes, but only when dealing with Entity Framework. It is due to the fact the real exception is buried down several layers and it has custom properties that explain what the underlying issue is. I also rarely work with COM objects. I am referring to the post in the link you provided.
I have used the Fiddler library as a proxy to download streaming files from a well known music service. When set up correctly it can decrypt the traffic over HTTPS.
&gt; What a bullshit article. &gt; developer.telerik.com
I think you are confusing concepts. NetStandard -&gt; api declarations NetCore -&gt; crossplataform implementation of standard NetFramework -&gt; not cross implementation of standard (but more stable)
As the author called out, this is for CPU-bound work. Don't make the mistake of assuming the same performance or characteristics for IO-bound work, or when using the async/await keywords. These keywords introduce a state machine, increases [compiled] code complexity, and multiple continuations. Pay close attention to memory in these cases.
I get this error constantly, even before this update. Thought it was VS. Super annoying.
CUDA is very low-level, and you need an understanding of the GPU architecture to use it correctly. It's difficult. Higher level languages are abstracted to save us all some effort, and this abstracts those low-level GPU concepts to C#.
Removed: Rule 4. There are various bitmap loading methods and APIs for getting a pixel's colour. Do some googling, dive in and make an attempt.
I'm not sure if I understand your question; it seems that you're asking about performance differences between GPUs and CPUs. This library let's you write C# that will compile into GPU instructions (CUDA is nvidia's framework). It has already been demonstrated that GPUs are faster for the sort of work you'd use this for.
&gt; One IL to rule them all, one IL to find them, One IL to bring them all and in the darkness compile them. &gt; &gt; -- Jean-Luc Picard
Could you please refer me to one as, although I had used google prior to posting; I have yet to be acquainted with a service which grants utility to what I require. Thanks
Check out the [`Bitmap`](https://msdn.microsoft.com/en-us/library/system.drawing.bitmap%28v=vs.110%29.aspx) class. It has a constructor where you can pass in the file path, and a `GetPixel` method.
Thanks!
You could try System.Windows.Forms.Cursor.Clip, maybe it still works with wpf. You should however have a good reason to do this in the first place. I would be furious if some software would lock my cursor
Maybe I should ask if there is a better way to do what I want to accomplish. I am making a breakout clone to learn c#. I have a canvas and on mouse move I want to move the paddle but I get undesired results when the mouse moves off the canvas. I thought that cursor clipping might be able to keep the cursor on the canvas regardless how far past the canvas I physically move the mouse. Thoughts? 
Nice work, I wrote a sqlite query generator in powershell for some of my clients who were too cheap for real SQL.. this is above and beyond, good job
Do mouse capture instead. 
But what kind of loss is there due to the conversion? 2x? 5x? 10x? Or is there no loss at all? I have written a Mandelbrot before in hlsl and c# and saw roughly 38 times the performance between a GeForce 980 and a 6th gen quad core i7. Some simple metrics showing the performance of some converted code (Mandelbrot in this case) would be useful for me. It seems odd that performance is barely touched on, especially when you consider that moving code to a GPU is almost entirely for performance reasons. A graph with Mandelbrot framerates for CPU (c#), GPU (native cuda) and GPU (hybridizer) would be perfect.
Interesting, but I'm skeptical of doing SQL queries using formattable strings; how would this stop SQL injection?
Sorry about that. I delved a little deeper with your suggestions, but evidently I'm still missing something. I'll make a new post which includes some code.
If might help if you post what you've tried and what the exception was. Otherwise, you could try the cheater's way, but I'm not sure if it retains the existing SelectionStart when BtnBS is clicked.: txtAcct.Focus(); txtAcct.SendKeys.Send("{BACKSPACE}");
I also started getting that error today, never received it once before upgrading ReSharper today.
Someone give me the jist on what a tool like Resharper would be used for? Does it complement visual studio? 
I don't think this is the cheaters way, I think this is the answer. The sendkey methods exist to do exactly what OP is trying to do. 
Use command parameters for values (eg. Select * Where Col1 = {0}). Otherwise you will be vulnerable to a nasty security issue known as SQL Injection. Parameterization can also improve performance on some DB engines because the query planner can reuse plans instead of having to start from scratch for each query. This will also avoid nasty bugs when using certain characters in user input as evidenced by your section here: // replaced ' with | to avoid sql query executing error return "\'" + value.ToString().Replace("'", "|") + "\'"; And: else if (T.Equals(typeof(string))) return ValueString.Replace("|", "'"); Don't masquerade sync as async. Spawning a thread per query can have nasty perfomance implications. public Task AddToTableAsync(object item) { return Task.Run(() =&gt; AddToTable(item)); } There is already an ExecuteReaderAsync in SqliteCommand so you could utilize that. With proper usage of ConfigureAwait(...) you can utilize the same library calls either as async (await) or sync (.Result / .Wait()).
I said "cheater's way" because sending keys feels like a hack.
Nltk as the library instead of relying on cognitive services
Yes. Jetbrains the creators of IntelliJ IDEA among other IDE's found that their IDE and code had features that visual studio is missing. Resharper is a .net product/extension to visual studios, that takes their refactoring and analysis capabilities to visual studios and improves upon them. However, since it doesn't use Roslyn, but it's own data structures (it was created originally pre Roslyn, and on a different platform) it can slow your system down pretty heavily. However it removes a ton of the pain points that VS has, as well as adding extra refactoring + inference while coding to prevent mistakes.
ReSharper does a whole lot for a plugin and was my first introduction to JetBrains as a company, Rider is becoming quite a nice IDE though.
First, I apologize for the terrible formatting of that first post, if it wasn't clear that's me avoiding going to bed when I should by 'being productive' on the internet. In file, UDPClientChannel.cs, in the constructor you set up several events using anonymous functions. So there's not really a thing called an anonymous function. Instead, the compile dumps your code into a class, and any outer variables get 'captured' as fields of that compile generated class. Accidental capture is a cause of memory leaks (an object reference lives longer than expected as it's been captured) and strangeness (multiple deletes capturing the same object and mutating it's state). So hence my willies. The first thing I did when I say that in the code was analyze the parameters and calls to see if there was any variable captures. There isn't and the types are being used are directly compatible with anything in scope. But none-the-less, checking for that was my first thought. Since anonymous functions are a convenience thing and still just regular methods as far as the implementation is concerned, making those event delegates 'real' methods costs you nothing, and fixes my willies. Likely any fellow developer can tell I work in the enterprise world. We live in constant fear of our inputs, and the maliciousness of the environment, threads, and sunspots and my code review recommendations will always reflect that. Hope that helps. 
If it’s stupid and it works, it ain’t stupid. Sadly, this also seems the mentality of my coworkers but in this case it won’t hurt. 
I really messed up in the usage of the tasks..I was going to read this book "Concurrency in C# Cookbook" but i didn't have much time so i will read Stephen Cleary's blog instead. about the command parameters , i had already done that https://github.com/VirtualD3v/SQLiteHelper/blob/master/SQLiteHelper.cs#L125 but i forgot to give user the ability to set the column name Thanks!
Thanks :D
Thanks for the offer. Can you help me implement template validation in and angular 5 component so it reacts like a native html control? :) Ironically im going to have to re add some async stuff to the program i mentioned before, but i can handle that and keep it simple.
What I did in my GB Emulator was defining a RBG Struct with sequential layout, then having an array of these structs as framebuffer and drawing the framebuffer using OpenGL. See [here!](https://gist.github.com/anonymous/1b39d10c71a5bfe754be1c8188f10814)
`System.Drawing`/GDI+ isn't fast, but if all you're doing is copying pixels to a bitmap (via `Bitmap.LockBits`) and displaying that without any resizing etc. is should be good enough. 
Thanks for the answer!! I completely forgot about OpenGL, and maybe I can even dive into Vulkan if I find good and easy bindings. Thanks for the input, you steered me in the right direction!
https://github.com/AvaloniaUI/Avalonia/blob/master/src/Windows/Avalonia.Win32/WindowFramebuffer.cs MIT-licensed
Thanks, I am pretty much discarding it for now.
thanks!! I will give it a try too !
It adds a whole bunch refactorings not available in standard VS. I find that coding productivity for my team goes up substantially. Every time I install a new version of VS I hope I don’t need Resharper because it’s quite memory heavy (particularly older versions pre-Roslyn) but I’m always left disappointed with the standard options in VS.
Does it still have that performance problem, because thats the reason i deleted it after awhile. I got so frustrated with my visual studio becoming slow. I did like the features, but the performance hit wasn't worth it for me.
Me too. It was impossible to use when working with larger projects and solutions. 
Thanks for the effort! At some point I will revisit my code and see if by switching to x64 from x86 brings similar gains on my system too. Thanks again!
Thanks for the effort! *All in all, though, I think the results support my original suspicion that there is another bottleneck at a lower-level (e.g., in the allocation/initialization of the memory) that simply can't be parallelized efficiently.* I also assume this, but it could also be the case, that there is some concurrency in the .NET allocation implementation. But I also think there is a bottleneck which can not be efficiently remedied with (user provided) parallel array allocation. I will give a try to u/anon_smithsonian -s suggestion to switch to a build x64 from x86 as he reported some significant speed gains. One could also think, that the underlying allocation implementation of the x64 .NET runtime is probably more optimized. 
To me it feels as right as using sendkeys() to add the numbers as well.. A feeling not unlike the one you get when you really need to fart in a crowded elevator.
Somewhat off topic, but I found the mention of using lots of header interfaces in C# due to DI containers interesting. Why is this becoming so common? From my perspective I'd much rather just register the concrete class itself unless using an interface adds value. Which for me is only when either there will be multiple types that might be used to fulfill the interface or there is a real need to mock the dependency because it sits at the application boundary.
I like the interface approach because with interfaces you can just have some test class implementing that interface and it's definition/functionality is very clean. When using concrete class, you either need to subclass and have the methods virtual (if you can even influence that) or use mocks. With mocks the setup phase is pretty much a nightmare since it usually does "fluent" shit all over the place that isn't at all idiomatic to the language itself.
GDI+ is largely covered in the [System.Drawing namespace](https://docs.microsoft.com/en-us/dotnet/api/system.drawing?view=netframework-4.7). It's not really an alternative to Blend, though, just a set of basic graphics APIs.
For someone who don't know what it is: You position the cursor in the middle of the window and every frame you get the delta position of the mouse cursor and setting the cursor position back to the mid. That's how most game do it.
I have copied and run your code in VS17, I also did set *x64* as target platform and set solution/project configuration to *Release* I can confirm that there is a **sizable** speed gain just **by going to x64**, and also that *Number of parallel tasks* seems no to matter much... 
Maybe use something like an abstraction layer like SFML. Does sound/graphics/input etc/ https://www.sfml-dev.org/download/sfml.net/
&gt;I have copied and run your code in VS17, I also did set *x64* as target platform and set solution/project configuration to *Release* &gt; &gt;I can confirm that there is a **sizable** speed gain just **by going to x64** Somewhat fascinating, isn't it? It really doesn't seem to be anything that would benefit from there increased memory address over x86... Unless... Hang on. I'm on my phone have to switch to a desktop. Refresh this comment in about a minute. 
Thanks /u/TheManFromOregon What I've tried is about 30+ different "solutions" I've found elsewhere, however they don't take into account that I have inputs being recorded as well. The code you've provided has gotten me very close, but it relies on the user to focus the textbox first. After implementing your suggestion, and disregarding the fact that the textbox must be in focus first (I'll figure out a solution around that in time,) when you have a string for instance "123456" and you place the caret behind the "4", then press the backspace button, it's now "12356." The caret is now between 3 and 5, as it should be. Press a number (7), the textbox now shows "1234567" instead of "123756". The number being deleted is never removed from "_input." The fix for that is likely obvious, and I'm willing to bet there's some code that needs to be placed in every button's method that would deal with that.
You could pass a `ManualResetEvent` to that function, which is signaled at the functions termination - this event can then be checked to see if it is signaled.
Hey, That happens when VS debugger cannot calculate some value (e.g if ToString() for a local var requires some actions on a currently suspended thread). Since we (ReSharper, I mean) are calling VS debugger for all the stuff in the editor, a chance of getting this errror is slightly increasing. Currently the only way to avoid that is to turn off the debugging features in R# options. Sorry about that.
There is no easy way of finding out if a specific method is running in general. A debugger could kind of do it, but that's rather slow and impractical. What are you trying to do, exactly? The easiest option in your example would be to check the `IsCompleted` property of the `Task` object returned by `Task.Run()`. You could also update a counter in the method (via `Interlocked.Increment`/`Decrement` to be safe) or use some kind of locking mechanism (perhaps a `ReaderWriterLockSlim`, depending on what you're trying to accomplish).
You can find out whether the task is running by checking IsCompleted property: var task = Task.Run(() =&gt; ...); // task.IsCompleted
If I am not mistaken, the text box must be focused in order for it to have the caret. Is this not the case? Or do you assume that, if the text box isn't focused and the delete button is clicked, it should behave as if the caret is at the end of the text box's text?
Wouldn't work for my stuff since my database is not named `database.db` I'd suggest you make that configurable 
I'm on a phone, so bear with me. Your problem with the current solution is that the sendkeys method only updates the textbox value and not the _input variable you're storing your string in. When you send the backspace the _input still has the original value. When you press the button for "9" the method takes the unchanged _input and adds 9 to the end of it "+=". This is the reason why your cursor winds up at the end of the text. I would recommend that you get rid of the _input and just manipulate the textbox.text property directly using the sendkeys method. private void Btn5_Click(object sender, EventArgs e) { txtAcct.Focus(); txtAcct.SendKeys.Send("{5}"); }
If you do dig around for those bindings I would actually recommend taking a look at Veldrid, an open source cross platform graphics library with support for OpenGL, Direct3D, and Vulkan bindings already. I recently started playing around with it in its beta stage and the author has been very helpful while I learn it, filling in holes in the documentation or directing me where I missed something, even debugging my project with me until everything worked. The library so far is actually rather straight forward and mostly documented, I got about 95% there just reading docs and using old example code on his github. If you're sticking with C# I definitely recommend keeping an eye on this project c: www.github.com/mellinoe/veldrid
You COULD have a property called "IsRunning" and use it like this void MethodThatNeedsACheck() { IsRunning= true; //Method here IsRunning=false; }
String.Format isn't using command parameters. There is a better [example on MSDN](https://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlcommand.parameters(v=vs.110).aspx) that should have similar functionality in SqliteCommand. Using a command parameter guarantees that the user input is escaped and will come back out the way it went in so you don't need hacks to handle `'` or other escape characters in the value.
Ok, I found a solution for you that I think is actually kinda cool. I tested it -- all of your stated requirements are met. In the code that follows, I created a simple winform app. I added 0-9 buttons, a clear (CL) button, and a backspace (BS) button as well as the input text box. public partial class Form1 : Form { private TextBoxSelectionData SelectionData { get; set; } public Form1() { InitializeComponent(); } private void OnButtonClick(object sender, EventArgs e) { var txt = (Button)sender; var inputCommands = txt.Tag.ToString().Split(new char[] { ' ' }, StringSplitOptions.RemoveEmptyEntries); txtInput.Focus(); if (SelectionData != null) { txtInput.SelectionStart = SelectionData.SelectionStart; txtInput.SelectionLength = SelectionData.SelectionLength; foreach (var command in inputCommands) { SendKeys.Send(command.Trim()); } } SelectionData = null; } private void txtInput_Leave(object sender, EventArgs e) { SelectionData = new TextBoxSelectionData(txtInput.SelectionStart, txtInput.SelectionLength); } private class TextBoxSelectionData { public int SelectionStart { get; } public int SelectionLength { get; } public TextBoxSelectionData(int selectionStart, int selectionLength) { this.SelectionStart = selectionStart; this.SelectionLength = selectionLength; } } } I made use of the `Control.Tag` property that the buttons have. I stored the command text there that we send using SendKeys. In the designer, go to each number button (0-9) and set the `Tag` property equal to the number (i.e Btn3 should have a tag of 3). With the backspace button, the command is `{BS}`. With the clear button, the command is `^(A) {BS}`. Every button on the form has their click event mapped to the `OnButtonClicked` method. Furthermore, the txtInput text box has a leave event that stores the selection data. When the textbox loses focus, we lose that data, so we need to keep it in order to act upon that data. The above solution reduces the amount of code you have and makes it really easy to work with. If you need the current text at any time, you can still grab it from `txtInput.Text`.
&gt; Or do you assume that, if the text box isn't focused and the delete button is clicked, it should behave as if the caret is at the end of the text box's text? This is indeed the case. All number buttons should just send itself to the textbox. In the case of the "Clear" button, it simply clears the textbox and the _input variable. The "Backspace" button will delete the last character in the textbox, but if the user places the caret in the middle of the string (focusing the textbox), then it should delete the character before. And if there are multiple selected characters, the button deletes those as well. 
I updated the solution btw -- I don't know if you saw the version that used the 'TextBoxSelectionData' class, but I discovered it wasn't needed -- apparently, the text box does retain the selection start and selection length values even when it loses focus.
If you're trying to determine where your program is spending all its time, a profiler should be able to turn that up. If you need to prevent another piece of code from running while your function is still going, you can use a lock (or a semaphore, mutex, etc--check out articles on locking, concurrency, multithreading, etc) to manage that. If you just want to have some indication when the method starts and ends, wrapping the body of the method (or the body of the task) with something like this Console.WriteLine($"Started {nameof(MyClass)}.{nameof(MyStaticFunction)}"); try { // existing code goes here } finally { Console.WriteLine("$Finished {nameof(MyClass)}.{nameof(MyStaticFunction)}"); } If you *really* must, you could use reflection to inspect the call stack, but that's liely to tedious, slow, and fragile. Without knowing *why* you need to do this, it's hard to give you specific advice.
I will. but for now i'm using it like that. change the code 
Impressive approach! Thanks. It's working perfectly, except the "Clear" button seems to be ignoring the ^(A) part and just backspacing instead.
I didn't know about it. Thanks again. it was such an annoying bug at first 
I think you might be missing a key point; you use interfaces for this for testability *and you can also use that with mocking*. It's very very rare that I ever "manually" create an implementation for a whole interface for the sake of testing, I usually use something like NSubstitute (not a fan of the red tape that you need for Moq) and the setup phase becomes minimal as I usually only depend on a few members/methods from the interface, I can ignore the rest (or use the rest in a different test, etc). It's even nicer when combined with AutoFixture.
Just FYI, C# is not like java and you can do {localSeasonsGreetings == SeasonsGreetings)} instead of java like {localSeasonsGreetings.Equals(SeasonsGreetings)} the == operator is overloaded in C# to basically do a .Equals so it compares the characters, not references like how it is in Java
It's this kind of in-depth, well thought-through and inspiring posts that make reddit so great.
 You're
NomNomNom069 made great tutorials about the basics https://www.youtube.com/watch?v=8kr-V4EQ7gw&amp;list=PLrNC1KDUyzSqM2D7Q96wn14xAaJLJqbmF and Brian also https://www.youtube.com/user/LeftTechticle/ then take a look at Aeonhack's Themes he is such an awesome guy https://www.aeonhack.com/files/dl.php?id=31 
I was surprised at how well-structured and fact-driven the arguments were.
Thank god we're not a bunch of sadists
Thank god we're not a bunch of sadists 
Whatchu mean? "Things you should do with strings while you are coworkers are on holiday" seems right to me /s
Lots of possible reasons: * Mistakenly believing that's what is meant by "program to the interface, not the implementation" * Just doing what we did in Java (which was silly because Java is virtual by default) * Just doing what we did in WCF * Not trusting (or understanding) abstract base classes * Using mocking libraries that require interfaces * Not knowing that your mocking libraries that doesn't require interfaces * Just doing what everyone else is doing without thinking about it * Following the instructions of the DI Framework, which only gave examples using abstract interfaces 
Yep I love NSubstitute, very simple to replace all your interfaces and return whatever result you need from them, or verify they were called (with or w/o specific params) a certain number of times.
You might be interested in this project: https://mellinoe.github.io/veldrid-docs/updates/beta1.html
Hmm. Can you send me your designer code and the partial code behind?
Give him a break, he was educated the US.
I feel like VS follows "the Zelda cycle". A new version is announced, and everyone drools over the features. There's lots of groundbreaking new ideas within. People are ready to throw away the current version. It releases, and within a week all of the flaws have been found, and for many people it's declared unusable. The previous version is the best thing MS ever did, and no one can believe MS screwed VS up so badly. Then a new version is announced, everyone drools, then everyone hates it and declares the previous worst version ever the new best version. This is different from XCode in that no one has ever liked a version of XCode ever.
Don't you mean the *U's*?
Thanks for the info!!
Thanks, so many things to try, but I will check all of them to find the most suitable
The late 90s.
Yeah its amazing
If I recall correctly, string literals cross app domains. So you can not only screw up the strings in your website, but all other websites running in the same process (e.g. IIS App Pool).
Is `Account` a struct? Structs are implicitly created when they are declared. 
Yea Account is a struct, but then why do I need to use the "new" keyword in order to use info from the RobsAccount Struct in the Bank struct?
OP here. It's been a long time since I have created a Windows GUI App. I am not sure which files I need to place into my Git repo. This was created with Visual Studio Community Edition. Also, what should I have in my *.gitignore* file? Thanks.
I'm unsure, to be honest. Generally, using unassigned locals should be avoided even with structs. It makes for confusing code
Atomically increment a static counter every time the method starts and decrement it when it exits. If the counter is greater than zero, the function is running. 
Im surprised the first code block compiles. are you using a different IDE other than Visual Studio or an online editor? https://dotnetfiddle.net/2ppz6Z
Here's an ignore by github: https://github.com/github/gitignore/blob/master/VisualStudio.gitignore Should include everything what you need.
yes, unlike C++, you need the new keyword Account RobsAccount = new Account();
Thanks for the reply. I am assuming VS integrates with Git &amp; GitHub. Do you use the built-in functionality or use the cmd line git.exe outside of the VS environment?
For GitHub I use VS for the commits, the GitHub client to clone/push and the gitbash for reverting after a pull request (so that my fork is up-to-date). I would also use VS push/pull but I'm too lazy to log into GitHub.
One thing I'd mention with that is that there's a lot of stuff in there you don't actually need. Doesn't do any harm but just make sure you don't name your files/folders with clashing names. e.g. if you're writing a backup manager and create a folder called BackupUtils there's a rule in there that would cause it to be ignored. I tend to use something like the one posted but in theory you could just ignore your bin, obj and .vs folders for the project you listed, and packages if you want to keep your nuget packages out of the repository. I find it a good habit to check (at least with your first commit) what is being ignored using: git status --ignored 
&gt; But what kind of loss is there due to the conversion? Hopefully none! If you're able to write kernels and data transfer with parity between the C and C# code, there isn't a real technical reason the same ML can't be compiled to execute on the GPU. But, I see your point - you want proof. There is probably some performance loss switching to and from unmanaged memory too.
Counterpoint: VS2017 is much better than the VS2013 I was previously using.
Xello World
Yeah it's really hard to say without knowing the why. At face value this has a smell to it. Sounds like you have a design problem with something that really shouldn't be asynchronous.
I've used *git status* before, but never with the *--ignored* option. Thanks for the tip.
It's almost like that part was copied from a Java example, because interning of string literals is something the Java compiler does.
I thought unique strings in .NET were singletons anyway (ie. every instance of "foo" in the a single application is the *same* instance).
Your question here as to why it favours `A(int a, int b)` over `A(long a, long b)` is a nitty gritty detail in the C# specification regarding overload resolution and "betterness" rules. In section "7.4.3.4 Better conversion from type" (of the C# 3 specification): &gt; Given a conversion C1 that converts from a type S to a type T1, and a conversion C2 that converts from a type S to a type T2, the better conversion of the two conversions is determined as follows: &gt; ... &gt; * If an implicit conversion from T1 to T2 exists, and no implicit conversion from T2 to T1 exists, C1 is the better conversion. There are a quite a few other rules, but I think this is the one that affects your question. In this case: * type S: `byte` * type T1: `int` * type T2: `long` * conversion C1: `byte` -&gt; `int` * conversion C2: `byte` -&gt; `long` So while `byte` can implicitly convert to both `int` and `long`, so in theory either overload of `A` is viable, this rule makes one overload slightly better than the other. In particular, it's saying, we can implicitly convert `int` to `long`, but we _can't_ implicitly convert back from `long` to `int`. Therefore, the conversion `C1` (read: `A(int, int)`) is slightly "better" than conversion `C2` (read: `A(long, long)`) Beyond that, I'm not sure how to help you for your interpreter here. Is there a specific question? In particular, if you're just dealing with "Real" and "Integer", it should help simplify things as an "Integer" can implicitly converted or treated as "Real", but not vice-versa.
This is why you need a checkin rule to reject code that uses the unsafe keyword.
I was originally using 2013 and had no issues, attempted to use 2015 and had a marked decline in speed and compile times. Had some weird issues with 2013 after a windows update and decided to try 2017. There are some issues with 2017 I do not like but all in all I can live with them. So far I haven't seen the speed issues I had with 2015.
Not sure if you mean like constant/readonly strings? thats probably just stored as raw data somewhere like how it is in C I think. Could be wrong, I dont know much about low level .NET framework CLR. Really wanna buy the book tho
You can find the rules C# uses for numeric conversions in operators in the [C# language spec](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/expressions), it's a combination of the rules for implicit conversions, the set of defined operators, and the rather complicated rules for overload resolution and conversion priority. The relevant part for your example (`byte` to `int` or `long`) is this: &gt;##### Better conversion target &gt;Given two different types `T1` and `T2`, `T1` is a better conversion target than `T2` if no implicit conversion from `T2` to `T1` exists, and at least one of the following holds: &gt;* An implicit conversion from `T1` to `T2` exists [...] `byte` can be implicitly converted to both `int` and `long` so both overloads of `A()` are candidates. `int` can be implicitly converted to `long` but not the other way around so `int` is the better target. The spec also lists the effective rules for binary operators: &gt;Numeric promotion consists of automatically performing certain implicit conversions of the operands of the predefined unary and binary numeric operators. [...] &gt;Binary numeric promotion consists of applying the following rules, in the order they appear here: &gt;- If either operand is of type decimal, the other operand is converted to type decimal, or a binding-time error occurs if the other operand is of type float or double. &gt;- Otherwise, if either operand is of type double, the other operand is converted to type double. &gt;- Otherwise, if either operand is of type float, the other operand is converted to type float. &gt;- Otherwise, if either operand is of type ulong, the other operand is converted to type ulong, or a binding-time error occurs if the other operand is of type sbyte, short, int, or long. &gt;- Otherwise, if either operand is of type long, the other operand is converted to type long. &gt;- Otherwise, if either operand is of type uint and the other operand is of type sbyte, short, or int, both operands are converted to type long. &gt;- Otherwise, if either operand is of type uint, the other operand is converted to type uint. &gt;- Otherwise, both operands are converted to type int.
No, that's not the case. String literals are interned and refer to the same instance, but strings constructed at runtime are not automatically interned and replaced with existing instances. string a = "foo"; string b = new string(new char[] {'f', 'o', 'o'}); Debug.Print($"{a == b} != {ReferenceEquals(a, b)}");
Thanks, that helps with figuring out which of multiple conversions to use... The other part of the question was more open ended because I wasn't sure how to go about... designing it... I considered creating a look up table... like Null Boolean Real Integer Character String Null Null - - - - - Boolean - Boolean Real Integer - - Real - Real Real Real - - Integer - Integer Real Integer - - Character - - - - Character String String - - - - - String Then it would basically put one arg type on the top and one of the left and where they cross is the type to "Convert to"... however, this seems to cause issues when user types are defined. While many user types don't use "widening" or "type coercion" and using a Foo (subclass of bar) as a Bar is done through "Downcasting"(?) which I think is a different mechanic, c# does still allow users to explicitly define implicit conversions... which would not be possible in a static table type conversion mapping method... Sorry if it is hard to understand the question, not 100% certain I have all the terminology right... 
In a language without implicit conversions, each expression has exactly one type. There might be more than one type _candidate_, but you can apply rules to pick the best candidate. In your example, if you were to write `A(i, i) the compiler would have several type candidates for expression `A` (which is a method group) and the type `void(int, int)` would be selected. This process is known as **overload resolution**, and it relies on constraint resolution. For your `+` You can end up with a web of interconnected constraints and you'll have to shake them up to find if there's a unique solution. If you were to write, for instance, a lambda: &gt; int i = 3; &gt; return (a, b) =&gt; { Add(a, b); Add(b, i) } Then the constraints are: - [i : int] - [a : int, b : int] or [a : long, b : long] - [b : int, i : int] or [b : long, i : long] The constraints yield that b is `int` (because of the second call), and from there it would deduce that a is also `int` (because of the first call). - [i : int] - [a : int, b : int] ~~or [a : long, b : long]~~ - [b : int, i : int] ~~or [b : long, i : long]~~ The good news is that in such a language, if overload resolution does not result in exactly one type being picked, it is acceptable for to just emit an error, because it is a very rare occurrence. In a language with implicit conversions, an expression has two types: the real type (determined by what the expression _does_) and the final type, which will be equal to the real type unless an implicit conversion takes place. The relationship between the real and final type is also dealt with as a constraint. Back to your example `A(b, b)` (which I will rename to `A(b1, b2)` for clarity) the constraints are: - [r(b1) : byte] - [r(b2) : byte] - [f(b1) : int, f(b2) : int] or [f(b1) : long, f(b2) : long] - r(b1) implicit conversion to f(b1) - r(b2) implicit conversion to f(b2) So now you have two possible solutions: [f(b1) : int, f(b2) : int] is one, [f(b1) : long, f(b2) : long] is another. You could again decide that this is an ambiguity, and therefore an error. You could use a "simple" rule, saying that solution has a "cost" equal to the number of implicit conversions involed, and pick the solution with the fewest conversions. This would make `A(b, i)` work (even though the `A(long, long)` overload would technically apply, it would require two conversions, whereas `A(int, int)` only requires one). Or you could go even further, like C# goes, and compare two solutions based on the relationships between the involved conversions (so you would treat byte -&gt; int as better than byte -&gt; long). To implement constraints of the form "r(b1) implicit conversion to f(b1)" you need a matrix of conversions. But this is rather easy, in your case, because it is basically `canConvert(t1, t2) =&gt; t1 == t2 || t1 == Int &amp;&amp; t2 = Real`. The clever part is that `canConvert` is not just a function. Look it as if it were a Prolog statement: you can call `canConvert(a, b)` which answers a boolean, or you can call `canConvert(a, ?)` which returns the list of types that `a` can convert to, or you can call `canConvert(?,b)` which returns the list of types that can convert to `b`. Read a quick tutorial on Prolog to see what I mean. An overload resolution solver feels a lot like Prolog semantics. Another important thing, of course, is that at any point where you need to resolve overloads, you need to know the type of your inputs. You mentioned an interpreter, so you don't need to go all out on static analysis and knowing all types for all expressions before execution starts, but you still need to know, for every expression that you have evaluated, what was the type of its result.
Yo'ure
Can you provide a concrete example with inputs to the method and what method you expect to be invoked? For example, are you trying to do: Base.RunMethod("Save", "Some Parameter Data"); And expecting that to invoke `Config.Save("Some Parameter Data")`?
Yes, precisely just that.
From my point of view the real value of using DI is decoupling not unit testing. If you use a class you can't replace the implementation without changing the clients.
It's inherent to how it works. But it's never got in the way to me working with it, your mileage may vary. The other option is to disable solution wide analysis, but that loses a ton of the benefits.
Everyone I talked to said 'resharpers performance' was better before VS had Roslyn, because Resharper was the only thing performing complex analysis? and not having to compete with VS.
AFAIK, there's no "invoke this string here like C# code as if it were written" equivalent. There are some that are close, but I don't think what would meet your direct requirements. The use of static methods on inherited classes is a bit weird, and I'm not sure if this is the best way to go about what you're doing. That said, to get something working with what you have, you can use the [`Type.GetType(string)`](https://msdn.microsoft.com/en-us/library/w3f99sx1%28v=vs.110%29.aspx) method. You'll need to prefix the type name with its namespace, but hopefully that's a constant for you. Alternatively, assuming you also have control to what assemblies store subclasses of `Base`, you can get all subclasses implemented via the method described here: https://stackoverflow.com/a/8928493/1269654 If you do that, you can then just build a lookup table or iterate through them until you find a subclass that matches the specified name. Once you have a reference to the `Type`, you can use its [`GetMethod(string)`](https://msdn.microsoft.com/en-us/library/8zz808e6%28v=vs.110%29.aspx) method to pull out the `Save` method. This is assuming you don't need to worry about overload resolution. Otherwise you may want to use a more restrictive call to [`GetMethod(string, Type[])`](https://msdn.microsoft.com/en-us/library/6hy0h0z1%28v=vs.110%29.aspx) where you specify that it has a `string` input parameter. Then on that resulting `MethodInfo` you can call [`.Invoke(null, new object[]{parameterData})`](https://msdn.microsoft.com/en-us/library/a89hcwhh%28v=vs.110%29.aspx). All that said, it can be dangerous to pull out methods like this by user code; they could access components you don't intend for them to.
A non-refection based solution would be to have a Dictionary&lt;string, Action&lt;string&gt;&gt; and just implement RunMethod as myDict[methofName](parameter); Then the implementing class can just register whatever methods it needs to, either by just passing the dict into the bases constructor or having an abstract get-only property.
Why do the methods need to be static? 
Kind of weird that Java hasn't fixed or improved that by now. 
*apostrophe*: here come's an 's!
Or masochists. 
It's actually super irritating in C#, as you can never be sure of the semantics of `==` . At least java is consistent, which means you learn to just look out for it, and use the correct type of equality check depending on what you want to check for. See Scala's discussions for what happens when equality goes insane.
Good article. We need more material on IdentityServer4. It’s a powerful security framework, but for someone with no security background getting started is difficult and discouraging. 
&gt;this doesn’t encompass the “allow unsafe code” compiler option Uses unsafe code. Fucking duh you can mutate strings with pointers. Ffs.
I know that is possible, it's how a console works in a game I play. I decomposed the source but it's too complicated. However, all I want to do is simply invoke a method from a sub class. Don't worry about "dangerous" because I won't be putting anything in there the user wouldn't want to use. This is for a video game console system. And I want it done through reflection.
I would consider designing around /u/Cats_and_Shit's suggestion. Maintain a list of `Action&lt;string&gt;` with lookups to the registered methods. Otherwise, if you want to keep on trucking with the reflection, give what I tossed in there a shot. _Generally_ though, reflection is fairly slow. So you may want to look into potentially caching the reflection/lookups so you only take the hit the first time that "Config.Save" is called.
Can you write up a quick example? I just started with this language and it's not as easy as I thought it would be.
 var subclasses = typeof(Base).Assembly.GetTypes().Where(type =&gt; type.IsSubclassOf(typeof(Base))).ToList(); var classMatchingName = subclasses.FirstOrDefault(subclass =&gt; subclass.Name == className); if (classMatchingName != null) { var method = classMatchingName.GetMethod(methodName, new Type[]{typeof(string)}); if (method != null) { method.Invoke(null, new object[]{parameterData}); } }
This was near the same way the game developers did it. This is why it's confusing me. But they have a For Each loop that seems to look for every subclass then method and seeing if the method is there. Perhaps this is why I'm confused.
This doesn't work if you run the function more than once at a time. You would need to do something like. private static object myLock = new object(); void MethodThatNeedsACheck() { lock(myLock) RunningCount++; //Method here lock(myLock) RunningCount--; }
Why would you make a method on an inheritance chain static? Why not just use inheritance the way its intended and call the method on the receiver regardless of its type. 
Well the `FirstOrDefault` call is basically a `foreach` loop looking for a matching class name. My expectation here is that you don't intend to have _multiple_ classes named `Config` in this scenario.
Because it's an [XY Problem](http://xyproblem.info/) mixed with some [Voodoo programming](https://en.wikipedia.org/wiki/Voodoo_programming).
I was actually wondering about the cost of moving the data to the GPU too. Is this performant enough (in terms of throughput and latency) to perform on a frame to frame basis in a game for instance? I have lots of highly parallel code that is running every frame on my CPU in one of my latest games. I wonder if I could use this for easy offloading to the GPU? The latency for the system would have to be well under 1ms for it to be worthwhile however.
* Wanting to used sealed without completely killing mocking.
Because Unity doesn't seem to expose the class nor methods if it isn't static. I don't want to have to keep declaring a reference to said class. It defeats the purpose of a modular console system.
Thank you. I'm going to test your method out and report back. Is there any documentation I can read? MSDN seems to be dead.
Off of my experience, all you need is the sln, cproj, and all of the cs files that you have in your project. You can ignore the obj directory as that is for the generated files that compiler makes and you can probably ignore the bin file as well since it just stores the compiled application. I say probably because you might want to leave it if you want people to test the application right of the bat. If your using Github though, you can just put the compiled application in the release tab (I don’t know how to do that but I know that’s a way).
All the MSDN links are working for me. Could be a problem on your end. Maybe try googling them ala "C# msdn Type.GetType(string)" and checking the cached results. Otherwise, you can look into downloading the MSDN documentation for offline access: https://blogs.msdn.microsoft.com/pakistan/2013/02/04/download-all-msdn-documentations-for-offline-access/ (If you can't access that either, try this alternative link: https://web.archive.org/web/20170207114044/https://blogs.msdn.microsoft.com/pakistan/2013/02/04/download-all-msdn-documentations-for-offline-access/)
Something I would like to emphasise is I have not done large projects in C#, I have done a few basic form applications and many console based applications. If you have more things that need to be ignored that I myself am not aware of then you more than likely need someone with more experience than me. I ignore only the directories that need to be ignored like the obj and bin directory.
Thank you. With unsafe code you can do whatever you want. You can totally hack the Gibson. 
It's neither a Unity thing nor a Mono thing. This is purely an issue with your game architecture design/usage. I know Unity tends to drive code structure to be a certain way, but there's nothing stopping anyone from writing anything using traditional OOP techniques in Unity.
Thanks man, it seems to be working. I really do appreciate your help and your speedy replies. Now that I know this is possible and have a working system how would I go about optimizing it? Or is it optimal enough?
&gt; Or is it optimal enough? ¯\\\_(ツ)_/¯ Depends on your game and console hardware and how frequently you call/run this code. Best way to find out is just toss it on your target hardware and see how slow/fast it performs. Beyond that, I would suggest you try to abstract the internal implementation details if possible. That way if you need to change/optimize that backend, it hopefully doesn't break too much of your calling code.
That second part, you want to dumb that for this DumbBrick? I'm rather new to this type of programming. Working with files is more of my type of thing.
Example? I never knew methods could be called dynamically without using reflection.
Put it in, see what happens. Optimize only what needs to be optimized in practice. With regards to abstraction, try to keep the API calls (that is, `RunMethod`) simple and easy to change, so if you do need to introduce optimizations, it doesn't break your back.
Can confirm, would consume documentation.
Yup. I did the quick starts several times. I eventually understood what I was doing but could t create a silk project based in real client needs. The documentation is greet, it’s just a lack of experience I need real world examples and use cases. 
Yuore'
How did you learn C#? And how long did it take you to get great at it?
I honestly thought strings were value types. 
*Applaud's*
Have you looked at compute shaders? All modern graphics APIs support them. GPGPU solutions like this aren't really used in games as far as I know.
 class Program { static void MethodOne(string arg) { Console.WriteLine($"MethodOne received: {arg}"); } static void MethodTwo(string arg) { Console.WriteLine($"MethodTwo received: {arg}"); } static void Main(string[] args) { Dictionary&lt;string, Action&lt;string&gt;&gt; actions = new Dictionary&lt;string, Action&lt;string&gt;&gt;(); actions.Add("MethodOne", MethodOne); actions.Add("MethodTwo", MethodTwo); //Prints "MethodOne received: ParamOne" actions["MethodOne"]("ParamOne"); Action&lt;string&gt; methodTwoReference = actions["MethodTwo"]; //Prints "MethodTwo received: ParamTwo" methodTwoReference("ParamTwo"); } } The key concept here is called 'delegates', which are references to methods. They can also reference a method on a specific instance of an object, or if you want to get fancy an anonymous method.
I'm talking about running the method though and the code it contains.
Oh yeah I have used them before but they are fairly annoying to work with. Especially when it comes to synchronizing the data between the GPU and CPU. Also they are not as pleasant as C# to work with, no where near as expressive or intuitive. This looked like a decent compromise between raw performance and ease of use/implementation. It would be trivial to port my existing C# bottlenecks using this for instance.
‘Can never be sure’ except you could read documentation, and the overload being present or not is right there in the type metadata. And how come you can be sure what Equals does when that is a virtual method?
Might i suggest, then, simply creating a virtual class method `Foo` on the inheritance base that calls the static method in its implementation, and then doing the same for all inheritors, then you can just call `someObject.Foo()` which forwards the call onto the correct static method? Regardless, this whole thing smells fishy, like a concept was missed that is leading to a very wrong design. But, thats more of an opinion than an answer :)
&gt; Registry... It's a trivial API, it's not funny to even mention it. Consider these 5 .NET standard features you should miss: * MOBILE * DirectoryServices * EnterpriseServices * C++/CLI * Desktop dev. 
This just isn't possible in the way you describe. If the method is static, it cannot know about any derived classes. There are a couple of alternative designs: Instance methods with a static cached instance: abstract class Base { public void RunMethod(...) { this.GetType.GetMethod(...).Invoke(...); } } class Config : Base { public static Config Default { get; } = new Config(); } Config.Default.RunMethod(...); Provide a small method in each deriving class that passes type information to the static base class method: abstract class Base { protected static void RunMethod(Type type, ...) { type.GetMethod(...).Invoke(...); } } class Config : Base { public static void RunMethod(...) =&gt; RunMethod(typeof(Config), ...); } Use the curiously recurring template pattern to specialize the static methods and provide type information: abstract class Base&lt;T&gt; where T : Base&lt;T&gt; { protected static void RunMethod(Type type, ...) { typeof(T).GetMethod(...).Invoke(...); } } class Config : Base&lt;Config&gt; { }
IEquatable is needed indeed, but not sufficient 😀
My guess is that your implementation or RemoveAt is leaps and bounds slower than that of List&lt;T&gt;. So, nothing to do with an array or List&lt;T&gt;. Try without the RemoveAt part? No relevant difference, yes?
Yes, it was. 
They couldn't possibly be, value types must have a fixed size.
like the kids say in that game - "snap" anyway, you're right of course, a crap post as it stands. I had a lot more in the post which I ended up deleting. I probably should have deleted the whole post, but what the hell, lets add a little detail here instead. Let me vent a little more. imo '17 is the worst release "qualitatively" I've worked with. I emphasize that this is my own experience, ymmv. That said, VS is still streets ahead of anything else available, but by their own standards, and only by that, the QA MS is doing on '17 sucks. Big time. It's difficult to get right, I doubt that I properly appreciate the magnitude of getting QA on something so complex right. But, I'm pissed, because using the tool is making my work harder that it needs to be, and guys, it used to work so well... For several months I kept a list of all the little niggles in '17, and it grew quite large, but none of it was a showstopper, until yesterday. I could list them here, but that's going to take time which I don't care to spend as all of them and more have been reported officially. Take a gander there if you must. What is annoying is to see one issue I get multiple times a day, flagged as solved. Phantom errors that stick after the source has been fixed and recompiled correctly. Used to be I could trust VS because it's always right - if there's an error, I've done something wrong, so let me fix it. Can't do that anymore.) For me its boils down to the fact that '17 reduces my productivity where previously every update was an concrete improvement. '15 was good, so let's hope that the updates don't mess with that. /vent
I don't mind critical discussions and would have appreciated the list of nitty-gritty details. That would have been an excellent opportunity to discuss how other people mitigate those issues. Tbh though, I also enjoy opportunities for snark - it satisfies the troll in me, that I mostly keep tucked well away. ;) 
Why rewrite the title when you can copy/paste?
But strings try _really_ hard to act like they are &gt;,&lt;
In what way?
I need it to be dynamic though. With the way you described I feel like I would have to do: If Input.Text = "Foo" Then someObject.Foo(Parameter) Else If ' The IF train keeps on rolling... End If I don't want to parse commands like that. And games that have a command console like in Call of Duty or Battlefield might use the same technique too as part of their scripting engine. Their engines usually have prediction so the more you type the more possible methods appear.
You need to 'Manage NuGet packages', not 'Add reference'.
You may want to use Interlocker.Increment/Decrement instead. Actually, don't do any of this and just use the properties on task.
In the nuget console there should be a drop down that let's you select which project it is working against. Alternatively in the tools menu you can select manage nuget packages which gives you a nice ui for managing them.
https://youtu.be/kCpjgl2baLs?t=20
"Dynamically" in the same sense as virtual methods or interface methods.
**You are** coworkers?? No I'm not.
That's some water I never stepped in before. Any documentation related to what I'm trying to do? All I want is for the user to be able to run a method based off of a string, with no brute forcing.
://www.gitignore.io 
You could use custom classes with the same inherited base class, create lists of that base type and you can add everthing to it. Not sure this is what you are looking for
Where exactly do you get null reference exception?
I know this is old, but I was doing some googling related to ReSharper and stumbled onto this. Frankly I tried swapping over to Linux as my main OS, and VSCode as my main IDE (I've written all of our work projects in .net core.) While I really, really want to love VSCode... coming from VS2017, code just keeps getting in my way. I've had problems with debug lagging out with anything that does any meaningful amount of work, frequently having to reload the window to fix intellisense issues, the intellisense at times just being plain bad or wrong, to name a few of the more aggravating problems. I have no doubt they will improve it over time, and I hope they do - I'd love to use VSCode for stuff, but it's just not there fully yet. At least not for me.
Check if your CourseIds list is initialized before adding elements to it.
I can. I know this is old, but as I said in another reply to someone else, I was googling around. I've owned a ReSharper license through work for the last two years. It started out awesome, and was great when I was on VS2015. But now? It just lags horribly. C++ projects, C# projects, it doesn't matter. Take an example of this C++ project I'm on. I hit enter in a class that has nothing in it except declaring the constructor (not implementing, just declaring.) The project is less than 1500 lines of code easily, but I don't have an exact count (frankly it's probably less than 1000 - it's just a mockup for a concept.) I hit enter in this class, it lags out for a second or two blinking the mouse between "thinking" and normal before finally entering. And it's not just once, it does it *every time*. #pragma once class TheClass { public: TheClass(); // Hitting enter twice to move down two spaces to type private // lagged out the edit window for ~2 seconds private: // Typing the : to finish the "private:" section lagged out // the editor again for slightly longer (~3 seconds) }; It's literally every single thing I do with it. I've tried using it for about an hour now again, on 2017.3, and it doesn't get any better. I hit a button, any button, it lags out the editor for a few seconds. I'm on a Dell XPS 9560 with one of the latest generated I7s with hyperthreading, an M2 NVMe SSD, and 32GB of ram. **It should not be lagging**. It's done this to me for about a year every time I install it to try it, and I just end up getting rid of it. This is one of those extensions I want to love, but frankly seems to be getting so bad with lag that I would spend more time getting frustrated waiting on it than actually doing my job.
It isn't clear to me what you want to achieve. The code var type = typeof(string); dynamic list = new List&lt;type&gt;(); generates a syntax error 'type' is a variable but is used like a type Outside of this, I don't see what you accomplish by making the variable list dynamic. Why do you need to use dynamic? Possibly it would make more sense if you posed a more complete example.
My Form.cs is exactly like the code you provided above, and the tags/click events have been set as well. Here's the designer code for "Clear": // // btnClear // this.btnClear.Font = new System.Drawing.Font("Microsoft Sans Serif", 11F, System.Drawing.FontStyle.Bold); this.btnClear.Location = new System.Drawing.Point(12, 287); this.btnClear.Name = "btnClear"; this.btnClear.Size = new System.Drawing.Size(70, 70); this.btnClear.TabIndex = 12; this.btnClear.Tag = "^(A) {BS}"; this.btnClear.Text = "CLEAR"; this.btnClear.UseVisualStyleBackColor = true; this.btnClear.Click += new System.EventHandler(this.OnButtonClick); Is there a using reference I'm missing?
No offense, honestly, but what you are saying is missing the meaning of my point. I feel enough has been said on the specifics at hand, I would recommend looking at the source for some popular open source C# libraries, and trying to get a feel for OOP design, especially in dynamic/pluggable systems. Happy hunting 😊
I fixed the issue with a little refactoring, solution in OP
I fixed the issue with a little refactoring, solution in OP
That code doesn't make any sense. What are you trying to do?
Check out the “clean code” video series by uncle Bob. Did wonders for me on design, testing, conventions etc
I've found VS Code to be great for things that don't have a proper IDE when used in conjunction with the right extensions and a command line interface. That said I've used it primarily on Windows and I've absolutely seen the way that Linux distros bundle Chrome cause really strange issues with electron apps.
&gt;dynamic list = new List&lt;type&gt;(); That doesn't make much sense. You want to generate a dynamic list ( "dynamic list" ) statically ( " new List&lt;**type**&gt;() " )? If you want a dynamic list, you could try var list = new List&lt;dynamic&gt;(); 
Thanks, that looks like a great start, but I would also like to supplement it with a conference of some sort. Sometimes nothing works better than just going to a location and giving it 100% of your attention.
Is this before he essentially went a bit crazy with his outlandish opinions or before?
I don't think the quality level of VS 2017 is as good as VS 2015 &gt; Used to be I could trust VS because it's always right - if there's an error, I've done something wrong, so let me fix it. Can't do that anymore. This kind of trust in VS started to fade for me a a couple versions ago, having to close and re-open things to get rid of error messages is very sad. 
They are immutable 
Ya know, some of us were educated in the US and know how to spell and write correctly. Although I was reading at a highschool/college level in middle school (mainly D&amp;D books and shit) I had to take a regular english class in the fucking 11th grade (junior) and people still didn't know their "there/they're/their" and it's vs its, to vs too, etc Sad.
kidding right? i hope... https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/string
You could build an extension method on Type to instantiate a List&lt;T&gt; of the type involved. You'd need to do some reflecting through List&lt;T&gt; and learn about some ins and outs of generic types and reflection, if what you really want is a strongly typed list of an arbitrary type, resolved at run time. Would probably look something like public static dynamic ListOf(this Type x) { if (x.IsGenericTypeDefinition) { throw new ArgumentException($"can't construct list of generic type definition {x.FullName}", nameof(x)); } return typeof(List&lt;&gt;).MakeGenericType(x).GetConstructor(Type.EmptyTypes).Invoke(null); } The better question, as everyone else has asked, is *why*? If you are already dealing with dynamic types, do you actually have any guarantees that your list will really only contain objects of a specific type?
I’m not debating the truth. I just wasn’t aware of it until this article. 
you are using dynamic, unless you are using his to bridge an integration barrier then you should not be using dynamic and I am willing to bet your code is wrong in a lot of ways. Dynamic is not for your internal use, avoid it at all costs actually. If you find yourself needing it think hard. If you feel that in C# you should use dynamic freely I suggest getting into another language that is truly loosely typed from the ground up. This one is going to fight you in ways you dont understand. 
You are overstating this a fair bit, but the central point is reasonably sound. `dynamic` is primarily for handling interop with other environments. It's not something that should be necessary in C# code, generally.
Portability for me.
Immutability is largely a design choice, it's not unique or defining of value types. `System.Tuple` is an immutable reference type, while `System.ValueTuple` is a mutable value type, for example.
And that could be part of the issue. I do use VSCode on windows, but not as my primary IDE since I have VS2017. I mostly use it for non-IDE things like modifying and re-generating protobuffers (though I could probably set that up in VS), and writing powershell, python, bash, or PHP scripts - none of those trigger the issues I had with it.
Any good places to start? If I have to touch or modify my console system class at all just to add a command then in afraid it's not a good solution to me.
If you can't stay present watching a video, how do you expect to do it at a convention?
Feature-Completeness: - `File.ReadAllText` (Single method to read all the text) - Linq (including abstracting from data source) - Extensibility (Extension methods and overloading)
Lol, some context might help.
I think OP meant: var type = typeof("string"); dynamic list = new List&lt;type&gt;(); Either way, I think creating a List&lt;dynamic&gt;() is the way to go.
No there isn't a using ref you are missing. The tag on the button looks correct -- it worked on mine. Try setting the tag to "^A {BS}" instead (if you use the designer to do this, don't include the quotes). If that doesn't work, try using `SendWait` instead of `SendKeys`. I don't know why you are experiencing different behavior, though. What .NET framework are you targeting?
Reinstall visual studio probably. Go to the visual studio installer and see if you have the correct components.
That code is still broken in the exact same way. You can't put a variable in the triangle brackets.
This is no different from: var list = new List&lt;string&gt;(); Why does it have to be dynamic? It is a list of strings.
Are you using both WPF and winforms in a single app? If so, why?
A as string; A = textarea.text 
Good question, never came to my attention honestly.
Could you describe some of the topics that 1 class deals with? Perhaps share an abstract of that code? 
Do you have a categories list along the left side of the New Project screen? It should have sections for: * Recent * Installed * Online
Doh!, not enough coffee today, I said so many bad things in 4 lines haha
syntactical sugar and the VS Integration and feature support.
It is not so much about attention span as it is work\phone calls\etc getting in the way.
For me, starting with VS2013 each new release got a bit sloppier than the one before it. I just stay away from new versions for at least a couple of months after release now. I don't want to suggest the new versions are bad - there's a lot I really like about VS2017 and I do feel it's a definite improvement over VS2015, but they just seem to get released a bit prematurely these days. Silly things like built in snippets such as tryf causing the IDE to throw exceptions, live unit testing randomly crashing, random object files getting locked and unable to clean properly without a restart, obscure build errors that make no sense then disappear when you restart.
WebForms?
I've honestly switched almost full time to VSCode. There are still a few times I open up VS2017, but it's once a week tops. I do get the nagging reload window to clear errors problem sometime, but all I do is open the command palette and reload the window.
The problem with your current code is that you are calling an async method without awaiting or calling result. Right now that object is the unfinished Task. If you await or call result that will ensure the task is complete and you will get your data. As far as other options I like refit, https://github.com/paulcbetts/refit. Allows you to create a simple interface and forget about the boilerplate code. 
There are improvements in VS 2017, but overall, I don't find any compelling reason to switch away from 2015. 
Yeah, if you click "modify" you can install various different packages including all the .NET stuff.
I don’t understand. do you realize you need classes for some reason or just because it doesn’t look Like good OOP code? It seems that whatever it takes for you to realize you need additional classes would also provide you the info on what classes you need unless somebody literally provided some vague comment to you and you ran with it 
Maybe just List / IList with no generics
Look for your nearest DDD conference all day and totally free. On the other end of the scale try NDC London. 
Removed: Rule 4.
 You have to select options when installing visual studio. Redownload the installer, hit modify, and make sure you choose the actual loads you want to install. Visual Studio is just a shell, it uses those components to actually have functionality.
`IList` would definitely be a better return type, at least. If the type guarantees on the collection don't matter, I think I'd probably just use a `List&lt;object&gt;` before I dug up an `ArrayList` or something, though.
Thanks for sharing! The fact that it's lagging on Enter makes me suspect this might have to do with auto-formatting. Can you try the following two customizations (preferably one by one), and see if there's any improvement? * Tools | Options | Text Editor | [Your language] | Formatting: disable all auto-formatting preferences * ReSharper | Options | Environment | Editor | Editor Behavior: disable Auto-format on semicolon and Auto-format on closing brace (Both suggestions are taken from [this document](https://www.jetbrains.com/help/resharper/Speeding_Up_ReSharper.html).) Please let me know the results.
I absolutely LOVE RestSharp, a nuget package that is both incredibly simple, yet totally feature rich and extensible. Highly recommended.
&gt; What's the ***latest and greatest way*** to call a rest service in .NET? https://i.imgur.com/8Wps7pl.jpg
Removed: Rule 4. There are resources in the sidebar and check out /r/learnprogramming and /r/learncsharp. Could also look into picking up a book or pluralsight course on C# as well.
Have a look at flurl: https://tmenier.github.io/Flurl/
OP here. Agreed. C# does not let you do this, but I WANT to do this. Reason being that I want to avoid a whole load of switch / case statements over 300 possible classes. Instead, I want to use reflection to create the strongly-typed list. It seems that List&lt;dynamic&gt; is a good answer.
Alternative is RestEase. Very similar to Refit, but uses a different design philosophy, which some may prefer. It also works in Linqpad, while Refit requires MSBuild support. Example: https://github.com/Silvenga/DnsMadeEasy
I have a third party nuget package where you can do List&lt;T&gt; result = Client.Query&lt;T&gt;(params p) where T can be one of about 300 classes. At runtime, I will find out what T is. So now, I want to invoke that query without writing the same code 300 times in a switch/case statement. A perfect use case for reflection. How do I do this without dozens of lines of code to create a simple List&lt;myType&gt;? Answer (it seems) you can't. Perhaps I'm attempting an anti-pattern, all I know is that what I have is working fine... I just want some syntactic sugar to make it smell less. 
You and other posters are right. Object is better (and actually, what I am already using).
1. data.Where(d =&gt; d.Code == "x").Min(d =&gt; d.Date).First().Price
I find the type T out at runtime only. I guess what I am trying to do is just make a generic list of a class I only find out at runtime without tens of lines of reflection code. I wondered if there was a bit of syntactic sugar to reduce the line count. It seems that there is not.
I only find out what type I am using at runtime. The first line is just there to demonstrate that the second line is not possible in C# 7.
Yes. This is what I am currently doing. The "why" is that I only find out the type at runtime, then do what you suggested, then pass that List to a third party nuget package call. Reflection is awesome, but could be made easier with some syntactic sugar.
I'm not sure what your use case is, but I really can't imagine that being a good idea. Why would you want a `dynamic List&lt;dynamic&gt;` rather than an `ArrayList` or `List&lt;object&gt;`? You don't gain anything but overhead by using dynamic here.
Removed: Rule 4.
Def, esp if you dont know what you are consuming, dynamic is untyped but assumes you know where things are. Object and type give you more to discover. The API is very old, but some of the new enhancements in .NET 4.7+ I think give you some more sugar in this area. TIP if you are dealing with some known interfaces a DI tool may help make some of your code more clean. 
HttpClient?
&gt; without awaiting ~~or calling result~~ You're technically correct, but using thread-blocking methods in async code is dangerous and should be avoided. Also it appears OP may have updated his code.