I looked at HAP and decided not to use it, but I don't recall exactly why. I rejeted a lot of solutions that built a DOM because I didn't want to incur the overhead/memory pressure of building a lot of objects. I will look again. I probably would only use HAP if it did everything I need *and* if the performance was reasonable. If any post-processing was required, especially post-processing that required parsing text, I'd probably avoid HAP. You wrote, "[the] library could probably benefit from many things HAP has to offer." Did you have anything specific in mind? Thanks.
&gt;The other project is compiled for .NETFX 4.6.1, which also makes it incompatible with Core. Maybe: &gt;libsoundio-sharp is verified to work on Mono on Linux, and supposed to work on .NET Framework and .NET Core.
Have you tried setting the default to a decimal instead of a string? Wonder if the mapping is messing it up.
That's a habit that some might have picked up from C++ as a way of avoiding bugs from a typo if(NULL=obj) would give a compile error, where the reverse would mean some fun debugging.
i'm still using httpresponsemessage, what are the benefits of using this interface? is it just for readability?
i'm still using httpresponsemessage, what are the benefits of using this interface? is it just for readability?
Technically they don’t use ReferenceEquals, because they just translate directly to IL opcodes. They do behave exactly the same, though. 
ReferenceEquals is a bit more accessible than saying ceq 
&gt; wasm doesn't allow for JIT Is that really true? You can always generate a WASM module in WASM, pass it to the JS outside that does the loading already anyway and the JS cas also load the additionally generated WASM with the same memory.
Yes and operator overloading https://stackoverflow.com/a/4957846/516419
VS Code somewhat has this with its Workspaces feature.
Did you set the right `CultureInfo` in `TypeConverterOptions`?
Next time you switch around some properties in Visual Studio 2017, just remember that the properties windows is VB6 and Winforms
personally I'd say `if (object != null)` instead of some bang condition with the `is` operator
WebAssembly has [plans](https://webassembly.org/docs/jit-library/ ) to allow that sort of stuff without JS interop in the future. And a JIT based .NET runtime in wasm is definitely possible. But CoreCLR and Mono's JIT compilers will need a significant amount of work (everything is in C/C++ unlike CoreFX) to support a new ISA and platform. So I believe that the current plan is to ride on the LLVM train to produce full AOT binaries. 
What do you mean by gargantuan foreach? This sort of task is well suited for foreach. Can you show us the code you already wrote so we can understand what you find objectionable about it? Do you want to match the value exactly or do a text search within the value as well? The former is much easier. Do you want to test whether any of the values are present, or return the first cell that has one of the values, or return all the cells that have all the values?
if you want to search all rows and columns you'll have to walk the datatable fully at least once. You can use a gargantuan for loop instead of a gargantuan foreach instead if you want. 
Its a benchmark from [TechEmpower](https://www.techempower.com/benchmarks/#section=data-r16&amp;hw=ph&amp;test=fortune) that they run against hundreds of web frameworks and platforms: ## Requirements summary In this test, the framework's ORM is used to fetch all rows from a database table containing an unknown number of Unix fortune cookie messages (the table has 12 rows, but the code cannot have foreknowledge of the table's size). An additional fortune cookie message is inserted into the list at runtime and then the list is sorted by the message text. Finally, the list is delivered to the client using a server-side HTML template. The message text must be considered untrusted and properly escaped and the UTF-8 fortune messages must be rendered properly. Whitespace is optional and may comply with the framework's best practices. Example response: HTTP/1.1 200 OK Content-Length: 1196 Content-Type: text/html; charset=UTF-8 Server: Example Date: Wed, 17 Apr 2013 12:00:00 GMT &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Fortunes&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;table&gt;&lt;tr&gt;&lt;th&gt;id&lt;/th&gt;&lt;th&gt;message&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;&amp;lt;script&amp;gt;alert(&amp;quot;This should not be displayed in a browser alert box.&amp;quot;);&amp;lt;/script&amp;gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;A bad random number generator: 1, 1, 1, 1, 1, 4.33e+67, 1, 1, 1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;A computer program does what you tell it to do, not what you want it to do.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;A computer scientist is someone who fixes things that aren&amp;apos;t broken.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;A list is only as strong as its weakest link. — Donald Knuth&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;Additional fortune added at request time.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;After enough decimal places, nobody gives a damn.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;Any program that runs right is obsolete.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10&lt;/td&gt;&lt;td&gt;Computers make very fast, very accurate mistakes.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;Emacs is a nice operating system, but I prefer UNIX. — Tom Christaensen&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;Feature: A bug with seniority.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;fortune: No such file or directory&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;フレームワークのベンチマーク&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; For a more detailed description of the requirements, see the [Source Code and Requirements](https://www.techempower.com/benchmarks/#section=code) section. &amp;#x200B;
Thought so lol. It seemed so familiar
The ignite talk isn't available for me. Can you confirm its been unlocked for on demand yet?
Has anyone done much of a gap analysis anytime recently? Most benchmarks show that .NET Core C# is faster than JVM Java for contrived algorithmic benchmarks. I understand that language != runtime, but I haven't seen a good updated article comparing the CLR and JVM.
I love all the responses that are like "well you could hook up an iPod to a mac mini and then use .net core to invoke an ssh call on the mac..." Like yes you fools this is obviously the level of integration OP is asking for. OP the answer is no. Cannot be done the way you want.
Thank you for the reply. I edited the post with the current code part.
Core 2.1 can load dlls that are built against framework without any conversion. It is possible that this particular dll just works. I can't find the doc that states it specifically, but I know I have loaded the Sybase driver and can use some types from it (attempting to open a connection gives a type load exception, but a couple of the message event classes load fine).
this should work: [https://github.com/flibitijibibo/SDL2-CS](https://github.com/flibitijibibo/SDL2-CS) &amp;#x200B; I'm not 100% sure that binding will work in .net core but it should &amp;#x200B;
&gt;\&gt; The sources indicate that it's a VS2010 solution so it's definitely incompatible &amp;#x200B; That is not a thing that is generally true. An old solution may very well be valid as a .net core solution too. &amp;#x200B;
It is a bit hard to find (couldn't directly link it) but it's in the "On Demand" section with the title ".NET overview and roadmap". 
If you want to find out if any columns have a value and get those rows that have it, you can use linq ``` dt.AsEnumerable().Where(dr =&gt; dr.Table.Colums.Cast&lt;DataColumn&gt;().Any(dc =&gt; dr[dc].ToString() == value)).ToList() ```
Maybe. I watched Scott Hanselman's video today and they only mentioned it in passing, unfortunately.
The project format is completely different and Core isn't even compatible with VS &lt;15
Removed: Rule 4. Downcasting is when you take a base class and _try_ to cast it to a subclass. This can fail if the subclass you're casting too isn't actually what the object is. Upcasting is when you cast a subclass to its baseclass or implemented interface. This won't fail as it's ensured at compile time. For example: class Animal { } class Giraffe : Animal { } class Cow : Animal { } Animal animal = new Giraffe(); //downcasting that works Giraffe giraffe = (Giraffe)animal; //downcasting that fails Cow cow = (Cow)animal; //exception thrown //upcasting Animal someAnimal = giraffe;
How do you compare Spring with MVC/ASP.NET in terms of ease of use and performance?
Up casting is casting to a parent class. This is always safe. Down casting is casting to a child class: this is only safe if the reference is actually to the child class or one of its descendants. For the purposes of examples, let's have a couple classes: public class MyObject {} public class MyChildObject : MyObject {} The most trivial example of up casting is casting to object. Everything in C# is implicitly derived from System.Object, so this always works: MyObject foo = new MyObject(); object upcastRef = foo; But, so does this stuff: MyObject bar = new MyChildObject(); object otherUpcastRef = bar; Because upcasting is always safe, it's allowed to occur implicitly, but we can also do it explicitly: object upcastRef = (object) new MyObject(); It's just redundant, so you won't see that often. Downcasting can be unsafe, so it's always required to be explicit: MyObject foo = new MyChildObject(); MyChildObject downcastRef = (MyChildObject) foo; object bar = new MyChildObject(); MyObject baz = (MyObject) bar; // but foo = new MyObject(); downcastRef = (MyChildObject) foo; // InvalidCastException at runtime: foo doesn't contain a MyChildObject You can also do some things to test the type of value stored in a variable MyChildObject foo = bar as MyChildObject; // foo gets the value of bar if bar contains a MyChildObject or something derived from it, but is otherwise null if (bar is MyChildObject) { // the is operator returns true if bar is a MyChildObject or something derived from it if (bar is MyChildObject foo) { // foo gets assign the value of bar if bar contains a MyChildObject or something derived from it, but is otherwise not assigned a value switch (bar) { case MyChildObject foo: // this case gets run only if bar contains a MyChildObject or something derived from it Note that null doesn't count as an object of the specified type for those last three.
I think my point here was you would have different commands that would handle the user request that would then forward it to a method on your domain model where it is centralized. however, smaller code based may not need the domain overhead and could do work right in the handler of they want. another benefit would be that you can log the commands as json to replay them later or whatever.
Kinda like how google wrote go in go.
I heard you like compilers
It's old news, but the article telling the story is recent. And it's an interesting read, at least from a history point of view.
Most languages end up doing this after the initial build out. It's a good proof of concept and compilers are complex enough that it lets you see the ugly side of your language to fix it in the future.
&gt;we know that x must be &lt;= 54 Shouldn't this be "x must be &lt;= 55" since the condition was "x &gt; 55" ? x could still equal 55, it just can't be greater :)
ASP.NET MVC and Entity Framework were open sourced before that.
so I bootstrapped your compiler
Oh yeah found it.
Nobody mentioned any of that bullshit. /u/DH10 the answer is yes. The answer to this and 99% of other similar questions is yes. It may not be easy, but don't let this guy discourage you.
&gt; the answer is yes LOL love to see you prove it, using only .net core.
I don't know why you're being down-voted lol. This is common for languages to do, that doesn't mean something negative against C#.
sorry, i wasn't implying that you could just use it off the shelf, more that, as /u/McNerdius proved, it may be pretty easy to port it over to build targeting .net standard/core since it was already targeting the more limited mono framework.
https://www.nuget.org/packages/Vlc.DotNet.Core/
Under the lead of Anders, the first version of Delphi was written in Object Pascal and all versions after that were written in Delphi. Almost everything was written in Delphi, i think only the linker was C++. Delphi was what C# is now
And Mads Torgersen being the one that wrote the article, it's something worth reading. As stated on the page, he's the lead designer of C#.
 Why would i reinvent the wheel ? How about you prove none of these work ? https://github.com/flibitijibibo/SDL2-CS (targets netstandard2.0) Simple DirectMedia Layer is a cross-platform development library designed to provide low level access to audio, keyboard, mouse, joystick, and graphics hardware https://www.nuget.org/packages/Vlc.DotNet.Core/ (targets .NETStandard 1.3+) .Net API to use the audio/video capabilities of the VLC libraries. https://www.sfml-dev.org/download/sfml.net/ (builds for netstandard2.0) SFML provides a simple interface to the various components of your PC, to ease the development of games and multimedia applications. It is composed of five modules: system, window, graphics, audio and network. https://github.com/atsushieno/libsoundio-sharp (targets netstandard2.0) libsoundio-sharp is a C# wrapper for libsoundio cross-platform audio I/O library. See what's cool at the website. Namely it is... cross-platform among various desktop platforms https://github.com/atsushieno/portaudio-sharp PortAudio is a free, cross-platform, open-source, audio I/O library
Nope. If you look at the code in the link, each conditional involves `&lt;= 54` or `&gt;= 55`. Even though he wrote the conditional oddly, it is still "binary" because of how he wrote it. In my code, I fixed this by using `&gt; 54` etc.
Well, shit. That makes sense. 
finally a fuckign Medium article I can read that wasnt written by a webshit spinning yarn for some shitty javascript shit
how is that possible when [the average gopher looks like this?](https://i.redd.it/vwvo27dskmo11.png)
Hello from an old PowerBuilder developer. I don't know much about Delphi, except a lot of recruiters thought if you knew PowerBuilder, then surely you can do Delphi. AFAIK, PB was the first drag-out-visual-controls IDE, like Visual Basic, a few years before Visual Basic. Unlike VB, PB was object-oriented from the outset. It had *visual* inheritance: you could inherit from an object that had a number of UI controls, and they would manifest on the inheriting object. How does Delphi compare?
Gitignore.io provides standaard stuff you can leave out: https://www.gitignore.io/api/aspnetcore
There are premade gitignore textfiles for csharp (and for dotnet core) apps on gitignore.io, or google for recommended gitignores for csharp. If you do it yourself anyway: You should check in web configs and app configs. But remember to not store connection string or other credentials in them. Solution files should be included, and also project files. But leave out *.user files. You can also leave out the nuget package folder (/packages) and bin and obj folders. 
I have been building a cross platform mp3 player with .net core. I have confirmed the library I was using works on both Mac and Windows. I have been using [https://github.com/ManagedBass/ManagedBass/](https://github.com/ManagedBass/ManagedBass/), I'm unsure about flac support.
Great info, thanks!
This is interesting. I would love to work on building a compiler! 
Except for C++, where the first c++ compiler was written in c++.
Is java similar to csharp? 
I feel is a pivotal point for .Net solutions, and the future is still to be determined. Not only the first "enabler" this whole effort with Roslyn to optimize the dev lifelycle and compiler efficiencies, but then moving onto the audacity to rewrite the framework in itself, oh, and in the open for the first time. Also, facing the frustration with at least tens of major breaking changes along the way and still, frustrating early adopters, but oh, still pulling it off. As a technologist, quite impressive, the product management, execution, and evangelists of it all! I know there are ton of folks under the covers, but Huge props to the major thought and communication leaders innovators of the ship, Anders++, All the Scotts' G,H,H, + Mads, Damien, John G, Seth J, Miguel d'I, James M, JHill, of course, \***OP**\* for pushing the team and the framework, and 1000's of ppl from our .net community. I can only imagine how much heartache oracle would feel if JDK/JRE would "attempt to be re-written". Just look how long it took for This being that there is an 70/30 (according to me) split on critical open source major frameworks/libraries that originate in Java oss then ported to .Net oss. This re-write is the opportunity to flip the script for the next 5-8 years, because I believe there is no way Java consensus be re-written within that organization. \*Mostly, I feel, the urgency\* that MS needs to urge .net developers to look up out of their cubes and realize that there is a brand new way of doing things (I know most of the ppl on here get it, but not in the industry), that the days of the [Asp.net](https://Asp.net) websites, WCF, GAC, WPF, MVC v1, all the legacy crap, are over. Please push starting to declutter your organization with this stuff, you got 10 years out of those solutions, please re-train yourselves and please use new tech. After so many job interviews with candidates in a pretty decent market, its safe to say that our "Senior Engineer" candidates consider only time served, instead of growth. Good on you for knowing the ins and outs of Windows Workflow Foundation, can you explain why was it a bad idea again? &amp;#x200B; Pretty please. &lt;/rant&gt;
Nope, no native GUI support. Your only options right now are third party frameworks which are mostly works in progress (e.g. Avalonia) or packaging a web app with Electron or something similar.
not currently, but .net core 3 is supposed to be getting a compatibility pack for WPF and WinForms
I usually call it JavaShit in such contexts, heh.
Note: This won't be cross-platform, but it will apparently be part of .NET Standard in the form of a platform-specific "desktop pack". Which means .NET Standard is about to get a little less standard. _sigh_
I know it would be literal Development H\*ll but could I custom code the GUI?
&gt; Two legs baa-aa--aaa-a-ad 
Have they said if there will be a cross platform GUI? I assume console will work... But a GUI would be nice
Look, I really _really_ want .NET Core to take off on Linux. I do. I run Arch at home (btw I run Arch). C# is my strongest language, by far. I would like nothing more than to have a cross-platform UI toolkit that **finally** unifies the .NET world so that our best option for a cross-platform desktop UI isn't *fucking Electron*. MS gets this damn close, then runs back to their old "ha ha only serious" Windows-exclusivity bag of tricks. I'm disappointed, but hardly surprised. It's the nature of the scorpion, after all.
There is this :) https://github.com/migueldeicaza/gui.cs More info here https://channel9.msdn.com/Events/dotnetConf/2018/S313 
I may have overreacted. If the abstractions for WPF exist in .NET Standard, then it will be possible to write implementations of it that draw to ...X, I guess? Wayland? I'm not all that familiar with how the *nix GUI layers fit together. But before anyone can get started with that, there'll need to be a publicly available spec of how a WPF implementation should behave. A spec of what is currently part of the proprietary Windows source...
Plz don't mix .net standard with a .net core lib
A usable .NET core framework for QT would be my ideal. It's a shame Avalonia is GTK but I'm guessing that's because it was the path of least resistance due to Mono.
To be completely clear, the WPF toolkit will not be part of .NET Core. It will be a "desktop pack" that implements part of .NET Standard. Stop arguing and Google it already.
How is that possible?
There are Qt bindings somewhere. I will edit in the repo if I find it.
So when you use ASP.NET Core with MVC, there's some kind of GUI... you just need the browser to run it :D
Microsoft is still actively supporting VB6 on Vista through Win10, I don't think they'll ever abandon their old customers haha.
Thank you!
That is crazy. The same crazyness that .NET Core core library added APIs from .NET that will just throw a `PlatformNotImplementedException` on non-Windows systems.
How do you call Java shit then?
Exactly as you just did (seperate words) :)
Go on then, rhere's Roslyn, do not be shy! ;) 
.NET Core is not .NET Standard. .NET Core implements .NET Standard. Windows only WPF etc. doesn't have anything to do with .NET Standard. People seem to be confused by this very often. This might help https://msdn.microsoft.com/en-us/magazine/mt842506.aspx
Supporting VB6 is good thing tho. I bet there are thousands of people that are just confortable with it and don't want/need to switch to another language.
 the v3 only support GUI on windows or cover all platform?
Is there any compensation involved for mentors? 
Well, there is no financial compensation, but you do get lots of benefits from being a mentor, most of which are eloquently explained in the mentioned blog post. Speaking for myself, I get the following things from being a mentor: \- Helping students learn about the beauty of C# gives me great pleasure. \- Mentoring other people's code also gives me new insights on how to approach problems, so it makes me a better programmer. \- Students almost always really appreciate you helping them, and often let you know that through encouraging/appreciative words. \- It makes you be a better code reviewer, and important skill to have.
Windows only.
WPF or Winforms for .NET Core isn't a rewrite, they just made them work in .NET Core. But I've read that Xamarin Forms 3.0 is heading to Linux.
The overlap between C and C++, I would assume. 
I misread it as Exorcism.io which would be something else entirely. I'll have a look, I quite like helping people out.
Eww that's an icky article. .NET Standard does define a common BCL, but each BCL can implement additional functionality. [This one has a nice chart showing who implements what version](https://docs.microsoft.com/en-us/dotnet/standard/net-standard) The classic example is changes to the Reflection api between 4.x and Core and Appdomains which don't even exist in Core (thank god). I know *you* understand the differences, it's the article I'm having a rant about :)
 My understanding is that the WPF and Winforms binaries will be recompiled to ensure compliance with .Net Standard 2. Any changes required to be conformant will be made. As I mentioned above, Standard is a common set of APIs in the BCL, but each BCL can have additional APIs, i.e. Appdomains in .net 4.x. So the benefit is that a) the code will compile against .net core because it will only use APIs in Standard 2. That said, Winforms is based on GDI+ and WPF on DirectX, neither of which even have C# implementations that don't rely on the C++ versions. But, just because GDI+ and DirectX are Windows only, because the C# portion will just have a bunch of interface methods to those technologies, there's nothing to stop someone building a facade a Linux version could use. This all assumes the WPF and Winforms code is released. They have always been a bit reticent about it.
Careful. I can legally run a non-profit and still pay myself 500k per year. It's really more about paperwork than the concept of the person running it getting rich or not.
From the "terms of service page": Exercism is run and managed by Exercism, Inc ("We", "Us"), a corporation of Delaware. To me it looks like it is a company. As someone already mentioned I'm OK to potentially contribute, unless it's a for-profit because I don't work for free.
It’s very similar
I make C# video tutorials, but I don't understand why I should do this through a random website, that is owned by a company that at any time could simply start charging for stuff and make this project for-profit. Also, I'm simply helping this website instead of helping myself, which I am currently doing with my tutorials. Is there even one solid argument to be made that I should help people through this website rather than owning the channel yourself?
If that is the case, then the first compiler was really written in C?
.NET Standard only implements cross platform APIs and will not implement WPF. WPF will be a .NET Core library that will use GDI/DirectX on Windows and fail on platforms that don't have these libraries. Don't spread wrong information if you do not understand what the distinction between .NET Standard and .NET Core are. 
.NET Standard is an API contract implemented by all .NET implementations. GUI does not fit in here, .NET Standard is implemented by Mono, Xamarin, Unity and other implementations and adding WPF/WinForms to the standard would make it bloated and it will be a useless addition because it will throw on everything except .NET Core. 
WPF and WinForms will target netcoreapp3.0 and not netstandard. Don't know where the guy above got his information from. 
It also allows businesses to keep updating/paying for new versions of Windows/hardware. If your business has a LOB application that brings in the core of your revenue, you can't just ditch it and rewriting it for a new language/framework/runtime can be costly and risky and hard to justify if there's no tangible benefit for users or your bottom line. If Microsoft stopped supporting these legacy applications, it might cause businesses to keep using outdated/insecure old Windows versions, and make them consider developing against a different technology than Microsoft (Java, Linux, etc). For the most part, it's in Microsoft's interest to keep supporting the legacy stuff, at least for the medium term. We can see though how they're trying to encourage the switch to UWP and .NET Core. Presumably these are expected to be the long term platforms going forward.
Can you explain to a newbie? I'm just about getting into WCF but I thought Web API is the new way to do it now - what makes WCF necessary?
For a TUI, I like [BearLibTerminal](http://foo.wyrd.name/en:bearlibterminal). It requires the Windows compatibility pack for System.Drawing, and works great cross platform.
C++ wasn't really written at once, it slowly started as small tweaks and changes to C. The original compiler was written in something can can be argued to be either C++ or C, really.
There's this: http://avaloniaui.net Haven't tried it myself.
It would be great to have you!
Here's [Microsoft's own diagram on the topic](https://msdnshared.blob.core.windows.net/media/2018/05/netcore3-1024x983.png)
Here's [Microsoft's own diagram on the topic](https://msdnshared.blob.core.windows.net/media/2018/05/netcore3-1024x983.png)
Where is the source code?
That means that all these technologies will be able to consume . NET Standard libraries. It does not mean that UWP, ML.NET and WPF/WinForms will be a part of .NET Standard anytime soon. It's not even mentioned in text anywhere. 
Side note - I'm a backend dev but this site has a garbage mobile layout.
It isn't crazy. Trying to access the proposed unix only APIs .NET Core would also lead to PNSE. Besides the information is false. WPF And WinForms will target netcoreapp30 and not a version of .NET Standard. It makes no sense to add a GUI framework to. NET Standard, which runs on WebAssembly and what not. (WASM doesn't implement threading so every is on a single thread. As expected, threading APIs dont behave like they do on other platforms. Doesn't mean. NET Standard should abandon threading APIs because WASM doesn't support it.) 
could've mentioned Micr0$0ft only and we would've gotten your message (same old EEE shit) 
"Think of the exposure!"
https://github.com/GtkSharp/GtkSharp I've been using that Gtk3 binding for the past couple of months. They have been working very well for me, and is cross platform. I develop on Linux. Getting my app to work on Windows was a little tricky, but it works.
https://en.m.wikipedia.org/wiki/The_Scorpion_and_the_Frog
The articles aren't as in-depth as I was hoping. There is some useful content, but on a whole they are at a high abstraction level and many of them read like advertisements for Azure.
&gt; This is common for languages to do Exactly. This is in no way Go specific.
As someone who went to school for Computer Science (~$30K) and continues to read books on software development including C#, I am finding it difficult to want to help someone who is not willing to make the investment as well as work for free. Am I just being grumpy, or does anyone feel the same way?
This is the type of situation i would recommend using a SSIS package. It will verify the backup (if you chose) and can be run on schedule using sql agent. Is this a option?
I'm using SQL Server Express so I don't believe I can use SQL Server Agent. There must be a way to get this result though, surely?
This article might be exactly what you are looking for given you are working in Express. https://www.red-gate.com/simple-talk/sql/backup-and-recovery/backup-verification-tips-for-database-backup-testing/ 
Its kind of like 'apart' and 'a part'.
I'd probably just create the backup and backup verification as stored procedures in SQL itself, that take parameters so you can pass in the database name for the backup and the file path for the verification. In the verification stored procedure, you can initialize a variable to return and based on the value of: @@ERROR ...immediately after the RESTORE VERIFYONLY is executed, you can write in the procedure an IF/ELSE condition (or conditions) that evaluate the error code. If the value is 0, no errors occurred. Otherwise there was an error (you could create logic based on the error code as well). Assign some meaningful output based on the error code or lack thereof and return that variable from the stored procedure execution and write the logic in code based on that returned value. You could do the evaluation of the error code itself in C# but it's probably easier to maintain in the procedure.
Indeed I have, thank you very much! Fixed.
* [if](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/if-else) * [modulo](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/remainder-operator) `%` is actually the *remainder* operator (but everyone refers to it as "modulo", so don't sweat that). `x % y` returns the remainder of dividing x by y. An even number is one that has a remainder of 0 when divided by 2. `if (condition) { action; }` allows you to perform an *action* only when a particular *condition* is true.
One of the quirks of homework is that you sometimes need to use a less elegant solution in order to use all of the pieces that the teacher is trying to demonstrate. You can use an if statement and modulo operator together to test whether or not a number is even. I would use that as a jumping off point.
No disagreement there. Migrating from legacy is sometimes too risky or expensive. 
For(int i = 2; i &lt; 51; i++) { if (i % 2 == 0 ){ Console.Write(i + " "); } }
That's one way to accomplish it. Modulo returns you rest of division by 2 (in that case). So it will be 1 or 0. Use that knowledge to filter even numbers.
Lot's of existing applications use WCF. It's probably less about "WCF is the best" and more "We can't move to core until WCF is ported"
Fantastic advise. Although I would use both. VS as primary and Rider as second IDE. They can be installed together and why not try both? The more you know the better. 
Thanks! You are correct. I made Repository.GetCount() both async and throw exception normally and it behaved as you mentioned.
/u/AngularBeginner brings up a great point on why it does matter: OP can easily follow the directions of the teacher when using the same IDE as the teacher. 
Yes, that is exactly how it works. Change the config to “Warn” and it will surpass all debug and info messages. 
anyone have this problem??
Yes like you see .NET Standard libraries are shared between Desktop that runs in Windows only and ASP.NET, EF Core and ML.NET that run cross platform just like I said.
Do note that it is in alpha and is not recommended for production use.
Exactly this! I had to read it twice to get the demons out and be able to read it correctly.
You are understanding that diagram wrong, that means .NET Standard is shared between them all. Quote from Microsoft docs `.NET Standard is platform-agnostic` from here https://docs.microsoft.com/en-us/dotnet/standard/net-standard
That is exactly what I want. I only want to info/debug messages to be logged if an error occurs. Like the previous 10 messages before an error. If no error occurs then they are never logged.
They had me at app bundler. I want that.
thanks alot, i did something similar to that but without writing the modulo and if in the same way, which didn't really incorporate them into the application like it was supposed to. Thanks alot, apprecciate it!=)
&gt;the days of the Asp.net websites, WCF, GAC, WPF, MVC v1, all the legacy crap, are over. So, if WPF is over, what's the replacement for desktop app UI?
So what you're really asking for is time travel
When Microsoft launches any product or make any announcement they seem to add "AZURE" into everything. "Azure" is the new business for them now.
the .net core team is less constrained with having to deal with backwards compat, so they can do breaking changes for DPI for example 
No... I'm looking for messages to be queued/buffered and only written to the file when an error message occurs. 
I really like Linux and also can't stand that crap. I'm also amazed of how much whining is directed to Microsoft when it's not porting something to Linux desktop. Linux desktop is not viable commercially and making these ports takes lot of money. But I don't see same whining directed to Apple. Maybe this is the year when Linux desktop takes off :)
Nuget Install Time-Machine
Whenever you deploy a Web App to Azure, an entirely new VM may be spun up to host it. The local file system of the newly deployed version is probably on a completely different machine than the local file system of the old version (which is destroyed as soon as that web app is no longer in use). Depending on what options you chose and what product you're using, your local file system may even go away if your web app doesn't get any requests for some time (this is the case for the low-cost options on Azure Websites). Web APIs are not meant to have persistence within a node; it's intended that Azure Storage or another persistence service (such as Azure SQL Database or CosmosDB) is used for persistent data. The Web App/App Service is designed for auto-scaling, so it's expected that instances of an API may be spun up to handle more load when there's an increase in traffic (or shut down to save on compute costs when there's not much traffic); the service is not designed for tightly coupling the API to its backing store. Since you're using Entity Framework Core, you'll likely find it fairly easy to use [Azure SQL Database](https://docs.microsoft.com/en-us/azure/sql-database/) rather than a local database for persistence. My suggestion would be to introduce a configuration switch that allows using the SQLite database when running the code on a local dev box, but uses your persistent Azure SQL Database when deployed to a Web App on Azure. Disclaimer: I work for Microsoft in an Azure team, but this is not the service I work on (I have used it as a 'customer', though).
Hope this helps: https://www.google.co.in/search?q=sqlite+azure+site:stackoverflow.com&amp;safe=active&amp;sa=X&amp;ved=2ahUKEwi0_JuG1tvdAhUJtI8KHZK1AxEQrQIoBDAAegQIChAM&amp;biw=1440&amp;bih=758
I'll have a dabble tonight or tomorrow:)
The original announcements were a bit ambiguous, so it's remarkable we've got any clarity at all :/
There is nothing out of the box in Log4Net that will allow you to do that. I don't think I've seen any logging framework that supports that out of the box. You're going to actually have to write some code if you want that functionality.
&gt; netcoreapp3.0 Which will implement Standard, albeit an updated version. This is how .net works now.
Ive always used C# in Unity so that makes sense
Hey Microsoft, if you are listening...here are some other terrible ideas you can use to follow your own theme! * Office 365 =&gt; Azure Office (name change only affects the desktop version) * Direct X =&gt; Direct X 360 v5 * Microsoft Teams =&gt; Team Services * Skype =&gt; Azure Communicator * Visual Studio Code =&gt; Code (yes, they already have an editor with this name as well) * WinForms =&gt; WinForms Core (works on .NET Core, or .NET Framework) * Windows 10 =&gt; Windows
Yeah, I'm personally not a huge fan of Unity's naming conventions. I think they probably did that to cater to the JavaScript-like naming conventions UnityScript used to use.
I hold the some what unpopular opinion that "entities" are perfectly suitable "models". Display or view-models are acceptable where composite or interface specific models are needed to abstract or ease interactions where needed. I'm not a fan of redundant entities-DTOs-models-view models. Folks argue that bringing entities into higher level assemblies pollutes the integrity of those assemblies. I argue, I already wrote/generated that object, why do I want to duplicate that?
Here are also the full guidelines for C#: https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/capitalization-conventions
That is what I figured but I was hoping it was something I could just config and not have to deploy new code.
[Microsoft's .NET capitalization standard](https://docs.microsoft.com/en-us/previous-versions/dotnet/netframework-4.0/ms229043(v=vs.100)), while not the be-all-end-all, is pretty definitive for C#, since it's their language. I and most all C# developers I've come across will follow &gt;95% of those rules.
The onus is on you and the site owner to address this, not /u/KryptosFR 
could you link me to your videos? trying to learn here
Only because entities are not just POCOs, they imply the underlying data model, which implies implementation (quite directly). In any layered architecture, layers should depend on the abstractions of the layers below. I'm no fan of code duplication either, that's why I tell the frontend and backend teams to architect their own models (JSON payload and entities), thus the mapping between the two will make sense. Also, this means your data transfer objects would be decoupled from the app's concrete persistence layer, which should be the case in major applications anyways.
I appreciate the peace of mind the compiler grants that allows me to make a naming or data type change to an entity and know with 99% certainty that I’ve not broken any external services. Letting EF entities propagate all the way up the stack to controllers breaks this line of security. You can no longer make modifications to any piece of your data schema without also accounting for the effects this would have on _x_ consuming client applications. DTOs are redundant, they add a lot of extra time and complexity, and can be integrated poorly so as to actually make managing your code harder, but designed correctly, that firm line in your code between what model a client expects and what models you have complete compiler-protected control over is invaluable.
Not sure what you are using to render your game because you are not telling, but maybe you should use Monogame.
It's in the edit, and I don't want to use a liability other than what's default in C# / .Net
I've been following .NET Core before .NET Standard existed, I do know how it works. .NET Core can implement a .NET Standard version but that does not mean WPF or WinForms will a part of .NET Standard, or even .NET Core. Currently WPF and WinForms are independent packages (like ASP.NET Core) that `target` netcoreapp3.0. 
u/quadlix brings up a good point, but IMO, DTOs, and other architecture-layer specific models become necessary when one or both of the following occur: * The needs of other layers leak into the model definitions. * A good example here that I see a lot is a single class with attributes for EF, Json serialization, and MVC. This violates single-responsibility-principle and is an example of high coupling. Eventually, one of the attributes may even conflict in the worst case. Yes, I know that you can use the fluent API on EF, but there are other examples. * The number of entities grows past 5ish * The reason for this is that when your team is forced to make different models for each layer, if you are already relying on 10 classes throughout your layers, breaking those up will be painful. My last reason, that isn't really concrete, even though you might not feel like your code is DRY with the seeming duplicates, the different classes serve different purposes. One is supposed to represent a db row, one the body of a POST request, one your domain model. They might all nearly be the same thing, but one day they might not. For this reason, make them separate.
&gt; Maybe this is the year when Linux desktop takes off :) Ah yes, this is certainly the year of the Linux desktop.. for the 15th year in a row! 
Sure, that theory wins the "correct" answer. However, pragmattically, I've never needed the abstraction from the implementation that the layered DTOs+Models is meant to enable. There's never been a "let's change the data layer and nothing else" or "let's change the data provider" and nothing else. This mythical "they own that piece of the app, I own this piece" has never manifested in my app dev career. The best teams I've been on have been full-stack devs and owned full vertical slices of feature development. Abstracting the models from entities and view-models creates more duplicative work than enables the abstraction purity. 
What does that mean? Aren't both WPF and Winforms libraries as well? You mean you want to libraries made by only by Microsoft?
Blazor has already proven that you don't need JS to use HTML5 for your apps. HTML in itself could also be done away with, if someone takes the effort of writing a UI platform and a renderer for WebGL. But that'll take man-years of work, but at least it won't require any plugins or addons like Silverlight did. 
I didn't say I don't want to use libraries, I just don't want to use things like Monogame. The OnPaint and Invalidate loop is this. &amp;#x200B; `protected override void OnPaint(PaintEventArgs e){` `long now = DateTimeOffset.Now.ToUnixTimeMilliseconds();` `Graphics g =` [`e.Graphics`](https://e.Graphics)`;` &amp;#x200B; `if(Visible){` `g.Clear(Color.White);` `OnRepaint(e, Offset);` `}` &amp;#x200B; `FPSCurrent++;` `if (now-FPSTime &gt;= 1000){` `FPSTime = now;` `FPS = FPSCurrent;` `FPSCurrent = 0;` `}` &amp;#x200B; `Invalidate();` `}`
Yes, but I guess you've come across entity-specific attributes and model-specific attributes like ForiegnKey, Display and JsonIgnore. These are two extremely separate concepts, and they should be in separate classes, wouldn't you agree? Also, letting the entities "bleed" into other parts of the app, you involuntarily let inversion mutate state. For example someone getting an entity in a higher layer modifies some properties (because the client needs some transformation) and then log to the database. Your SaveChanges call then involuntarily saves the changes made to an irrelevant entity to the database along the log entry. 
What kind of display system are you using that requires those kinds of refresh rates. Or are you doing some multipass stuff?
Then would SharpDX be ok for you?
I'd like to point you to [one of my older comments](https://www.reddit.com/r/csharp/comments/9765wx/whats_the_best_framework_to_build_desktop_apps_in/e45wj5x/?context=3) in here. It should cover all the major .NET UI frameworks (that I know of) cross-platform or not. 
If your entity looks exactly the same as your DTO, you are probably doing something wrong. Entities in EF are a one-for-one mapping to a table or view schema. The odds of that being exactly what your application actually needs is pretty low. The vast majority of the time, your application wants a subset of that data. Sending extraneous information makes the database work harder, increases bandwidth, increases CPU utilization, etc. etc. Furthermore, it usually ends up with far too many objects. Applications often want a flattened view of the data. They don't need each and every lookup table value stored in its own child object. This increases the complexity of their code, reduces performance (memory usage, pointer chasing), and is just a pain in the ass. So even if your ORM can safely share entities as models/DTOs, that doesn't mean your design can.
Removed: Rule 1. Feel free to post it on the monthly job fair sticky though.
&gt; I tell the frontend and backend teams to architect their own models (JSON payload and entities), thus the mapping between the two will make sense. I actually went one step further than that. My UI developers architected their own models in RAML. I generated the C# models directly from the RAML. Then the ORM populated the models from views. You can't do this directly with EF, you need an ORM that does SQL generation by comparing the DTO's properties with the available columns in the database. But with some database reflection and runtime SQL generation, you can pull it off. 
Im not sure what exactly is going in your code, but It sounds like you’re rendering with the CPU.
For a beginner I'd say use the native intended IDE instead of a third party. Although maybe not for learning Python with IDLE though lol 
Yea, or that Invalidate just request a new frame, and the computer makes a new one when it feels like it. Instead of pushing them out as fast as it can.
Eh, this is not a job posting. This is a request for people to join a non-profit organisation to help people learn C#.
NodeJS is relatively `new` compared to Java and .NET Core and it's infiltrating everything already. At least MS isn't as overconfident about Blazor as it was about Silverlight. They have foresight this time, due to past experiences. 
Have you determined what portion of your execution time is the actual drawing part and what portion of your execution time is used for tracking your FPS? How many FPS do you get when Visible is false? 
With Visible false, I get 267 FPS with the same resolution. I think it's the Invalidate that causes the issue, since I think it just request a new frame, instead of immediately pushing out a new one.
I'd say that keeping your code clean is a must. Though you shouldn't really take it too far, you should check and update your code on daily basis to keep it easy and understandable. Also pair programming *can* work sometimes. If you're a junior, you should maybe spend a day or two with more senior guy to learn new practices and approaches. That's just my 2 cents, I'm not a professional programmer, I'm a freelancer who tries to get a real job.
 protected int FPSCurrent; protected int FPS; protected Timer FPSRotator = new Timer(RotateFPS, null, 1000, 1000); //System.Threading.Timer, not the other Timer private void RotateFPS(object unusedState) { FPS = Interlocked.Exchange(ref FPSCurrent, 0); } protected override void OnPaint(PaintEventArgs e){ Graphics g = e.Graphics; if(Visible){ g.Clear(Color.White); e.DrawString("FPS: "+FPS, FpsFont, FpsBrush, new Point(10, 10)); } Interlocked.Increment(ref FPSCurrent); Invalidate(); }
How about when you comment out Invalidate?
Ok, great discussion going on. I think I'm seeing that the answer depends on the application and it's complexity. No surprise there, I didn't really expect an easy answer. &amp;#x200B; I'm leaning towards preparing DTOs and having them be used in the Controller / Business Logic layer. I hope it won't be too redundant and that the gains will become apparent eventually. &amp;#x200B; Mostly because I'm not a native speaker, I wanted to compile a list of the various acronyms used in this thread, haha * DTOs - [Data Transfer Object](https://en.wikipedia.org/wiki/Data_transfer_object) * ORMs - [Object-Relational Mapping](https://en.wikipedia.org/wiki/Object-relational_mapping) * POCOs - [Plain Old CLR Object](https://en.wikipedia.org/wiki/Plain_old_CLR_object) * RAML - [RESTful API Modeling Language](https://en.wikipedia.org/wiki/RAML_(software)) \- this one I had never heard of. * I leave as an exercise to the reader: API, EF, JSON, LINQ, SQL, MVC, IMO and CPU lol 
Then OnPaint only run once, so 0
A code first approach of simpler systems generally end up with dto and entities that are basically identical. But either way, i agree to keep them separate. If for nothing else than "Future you will think you were a genius" later in the applications life.
That won't work either. It's not the result of a query. It's just a status message that SQL Server outputs.
That did bump the FPS up to 220, didn't know my method was that slow.
I've used this approach when starting out projects but eventually you have to decide what data you want exposed on an API and what you don't for security reasons etc. Using the entity on the API means by default everything is exposed so you're more likely to make a mistake, I'd rather take the approach where you explicitly have to add the property to a dto to expose it. Plus with automapper it's pretty Trivial and easy to maintain the API dto/view model
Thanks for your advice. Pair programming isn't feasible, as I'm just a hobbyist... no "more senior" people available, other than the interwebz (so, here I am!)
Yeah, I didn't really think that one through, did I? 
Is this all the rendering code? The only thing you are doing here is drawing the FPS... In java, how are you doing the rendering? Are you putting the code deep into the GUI code like this? or are you interacting with the graphics commands directly? Winforms is not designed for constantly updating the entire screen area. It's more suited for complex gui's that only need to redraw portions of the Gui at any given time. If you want good FPS in c# I'd recommend SDL or OpenTK... you won't get good FPS from winforms... not only because it is inherently slower because of all the winforms functionality it's buried in and also because it doesn't provide the tools required to optimize your FPS like differered rendering or spritebatches. Winforms uses GDI which is CPU side rendering... you need to move the rendering to the GPU to really get decent FPS (even for 2D stuff). Plus, winforms rendering is initiated through the message pump... a message goes into the message pump for every keypress, mouse move, etc...so the form has to chew through many messages per rendering message... so you likely aren't even requesting a rendering every frame. 
Force StyleCop on them.
Exactly. I think the message loop is definitely a problem here as all redrawing is done on main ui thread which is being timed by message queue. WinForms were never intended for this use. 
Which is why I came here, but so far no one have given me an alternative which don't require me to download another library. I just want something that's already in .Net Framework.
PB was the bane of my existence for a few years back, using it for the ERP platform we develop. internally we used to call it power fucker :P We later took the step over to C#. 
Format on save was another suggestion from a fellow sub reddit user
What UI frameworks are in your "approved tech list"? 
If you do a WinForms application you will always be limited by windows message loop (see [wiki](https://en.m.wikipedia.org/wiki/Message_loop_in_Microsoft_Windows)). This was one of the reasons Microsoft created WPF - successor of WinForms, to have independent rendering of components. 
Am I correct in the assumption that the for loop there will be creating lots of drop downs?
If thats a problem its not hard to make it always fetch from the database.
Well, since I can just Select WPF when I create a new project in Visual Studio, I guess I'm just going to scrap everything I have have done and use it instead.
Imho the controller layer should only translate the dtos to the models and back again. Keep your business logic as seperate as possible from the api layer.
I agree. I'm hoping to find some way to automate this, since this conversion would be pretty boilerplate. 
That's not enough. You also need to ensure you have a clean DB context. If you are using a local DB context I a `using` statement (like you are supposed to be doing with limited resources) then that's not too hard. But the common practice these days is to create you DB context at the start of the web request so there's no telling what crap its accumulated before it gets to that last read.
I'm guessing the actually DTOs in our case will be json serialized versions of our model objects. Is this not what you mean? The json will be sent from the api to the client and vice versa. 
Yeah I here you, adoption to the store just hasn't happened. It was good from a security model though.
yes. the for loop is just creating rows in a table. Each row represents and object in a list (agendaItems) that has two values: field and width. The value for 'field' is a dropdown but for some reason it is not populating with the value. 
Right. Non profit organizations still pay their employees. And their top employees are often rich. There are CEOs running non-profits that earn millions per year.
Too bad. It's a great idea that I would use all the time.
If your program was blocked as malicious, then it's likely a false positive. [Here are a few ways](https://www.ctrl.blog/entry/how-to-false-smartscreen-positive) to report the false positive. If your app was blocked by Smart Screen because it was "unrecognized".. you can: * [Tell your users a way to bypass the block only for your application](https://www.itsupportguides.com/knowledge-base/windows-10/windows-defender-smartscreen-prevented-an-unrecognized-app-error/ ) * [Tell your users to change the setting to "warn" or "off"](https://windowsreport.com/windows-defender-smartscreen-unrecognized-app/) https://blogs.msdn.microsoft.com/ieinternals/2011/03/22/everything-you-need-to-know-about-authenticode-code-signing/ 
This is why I advocate creating your own logging framework. Adding time travel would be pretty easy if you already have the concept of a pre-request scope. Simply defer writing to the log until the request is complete. You can't just bolt this onto an canned logging framework because it won't understand that events aren't going to be logged in timestamp order. 
It's fairly straightforward. Basically, you verify some information with a third-party company (a Certificate Authority) and get a signing key (Certificate). You use `signtool` with that key to sign your .exe and then distribute it. &amp;#x200B; This StackOverflow answer describes it pretty well: [https://stackoverflow.com/a/49696454/1122135](https://stackoverflow.com/a/49696454/1122135) &amp;#x200B; Note that generating your own key won't get around SmartScreen (since you have to generate a Certificate Authority key to generate your Certificate, and that CA isn't in Microsoft's trusted list) &amp;#x200B; I shipped some Windows binaries \~2 years ago, I went with K Software as they were the cheapest
Just start making stuff, and keep making stuff. Though a small project may sound simple, even the smallest apps can be quite a challenge to code once you really get into it. Start with a calculator or a weather app. Don't go to big starting out. You will overwhelm yourself and give up. The key is to slowly grow and expand your skills over time as you push yourself more and more to explore new things. No one will ever know everything there is to know about programming, so don't think that there is a stopping point where you can ever just stop learning. You will always be challenged at some level in just about every project you work on. &amp;#x200B; Once you get to the point where you feel like you have the basics down, start learning new frameworks and libraries within C#. Check out [ASP.NET](https://ASP.NET) MVC to build really cool websites. Check out Unity to code video games in C#, if you want. Learn how to interact with web APIs and databases. Learn learn learn. &amp;#x200B; Once you feel that you've got a solid grasp on C#, move on to other modern languages. Python, JavaScript, Swift, etc. I hope this helps! :)
You can create an additional appender that logs everything (ideally to somewhere that can handle all those logs), then match up your error logs to the more comprehensive set of logs after the fact.
https://www.introprogramming.info/wp-content/uploads/2013/07/Books/CSharpEn/Fundamentals-of-Computer-Programming-with-CSharp-Nakov-eBook-v2013.pdf#page=361
I like it
You could do this as part of a log rotation strategy. Heck, in C# you could go through the file line-by-line and write only non-debug lines directly into a [gzip stream](https://stackoverflow.com/questions/14297077/compressing-with-gzipstream) (no need for tar - it's only one file)
&gt; systems generally end up with dto and entities that are basically identical In my experience about 30% are really identical. The others have at least a small change like a property being hidden, another one flattened and so on. Some have pretty severe differences.
Best advice I can give: Change your major to computer science or computer engineering.
What I learned is that their are books specifically designed for you I highly recommend pm me for some examples
Seems what you are looking for is the BufferingForwardingAppender. You can use the evaluator to trigger the dumping that was buffered. I'll let you go through the documentation but you can have a read here : [https://logging.apache.org/log4net/release/config-examples.html](https://logging.apache.org/log4net/release/config-examples.html) &lt;appender name="BufferingAppender" type="log4net.Appender.BufferingForwardingAppender" &gt; &lt;evaluator type="log4net.Core.LevelEvaluator"&gt; &lt;threshold value="WARN"/&gt; &lt;/evaluator&gt; &lt;appender-ref ref="Target-Appender-Name-Once-WARN-Log-Triggered" /&gt; &lt;bufferSize value="2000" /&gt; &lt;/appender&gt; 
You learn by doing. Start making some simple programs that you need or for fun vs just exercises in a book. Don't forget data - make sure you acquire some good database skills. Start contributing to some open source codebases that interest you, at least browse through them to understand why things were written that way. Here's hoping by the time you enter the job market it's not all outsourced. Good luck. 
Have you thought about just turning your security policy off with a command before executing your insert? You may want to move all of this to another SQL login &amp; role with more elevated privileges, so that the user security context can't turn it's own security off. ALTER SECURITY POLICY [sec].[FilterApplicationByUser] WITH (State = OFF) [Docs](https://docs.microsoft.com/en-us/sql/t-sql/statements/alter-security-policy-transact-sql?view=sql-server-2017)
That is exactly what I was looking for. Thank you!
See https://www.reddit.com/r/csharp/comments/9jdsv9/log4net_question/e6rq4z6/
This example they provided is like one of those "I made a bot watch x hours of programming tutorials, and here's what it came up with" memes. That's a terrible example at whatever they were trying to demonstrate.
Silly question... If it's always fetching from the database why do you need a clean db context?
Personally I don't test that level of crud, it's costly and fragile. I also can't say I've every had any problems with model translations as generally isn't very error prone, its not rocket science e.g. [`dto.Id`](https://dto.Id) `= item.Id` [`dto.name`](https://dto.name) `=` [`item.name`](https://item.name) &amp;#x200B; &amp;#x200B; &amp;#x200B;
So you have a Person model class and a PersonDto class with a subset of what you want to expose from the API, then one way or another you return the JSON in the controllers which is the serialized PersonDto class.
A couple of ForeignKeys are acceptable loss, not sure why you would have display or JsonIgnore in an entity... Which then leaves you with 'programmers are stupid and don't know how to use entity framework' which I struggle to find as a convincing argument for an extra application layer in small projects. But I guess as the project gets bigger and bigger you would need to add that extra layer to protection because they will be so far removed from the core of the datastore that they won't know what the hell is going on. &amp;#x200B;
\^ This is a great comment. The thing is, you never know how long a small business app will live, or how large it may one day grow. And in either of those scenarios (long living, or large apps) you're going to really wish you had separated your layers cleanly. I shouldn't give specific examples from my career, but you wouldn't believe what your little prototype app might turn into later, and every dev that touches it will rue the decisions you made, if you skirt best practice corners in your architecture and layer design. Take the time to do it right. Make a habit of it.
Pretty much. There are a lot of places that still use WCF heavily. I still see jobs posted online for WCF service devs. 
Why should it be either costly or fragile? Essentially you're writing a mapper, right? Genuinely how hard is it to write unit tests that values are mapping properly? It's core functionality to your app. It needs to be guaranteed to work. Any breaking change should be caught in the dev's time, long before QA gets their hands on it. If you want that guarantee, you want unit tests on your mappers. We could wire them up in a couple of minutes. And you certainly want that code isolated from your controllers themselves. They already have a job. (convert api requests to local objects and hand them off in the right direction). They shouldn't be responsible for creating models.
I like Avalonia a LOT and I have high hopes for it. But to be fair, it has a ways to go. So there's that. Also theres the factor of using libraries/third party controls. That can be a hindrance if you need something that works with WPF but doesn't work with Avalonia. I guess the last thing is just getting buy in for it. Since it's not an official MS product, I can imagine decision makers being hesitant to use Avalonia. All that being said though, I still have high hopes for Avalonia. It's just that like with all this other stuff we have on the horizon with .NET (Blazor, etc), it will take some time.
AutoMapper can help that to some degree. 
I stand corrected.
We are heading into holy war territory and I will have no chance of convincing you otherwise but... Personally I find little benefit to testing controllers or crud. As soon as you refactor anything it breaks tests, it's a pain for little gain as at the end of the day the user interface still needs testing. &amp;#x200B; The real low hanging fruit in unit tests is something like a PriceCalculator or some other thing with heavy business logic and a good interface. They are so good at this you suddenly start to think you have a golden hammer! &amp;#x200B; n.b. Not sure what your going on about with controllers. They need to "convert api requests to local objects". Isn't that what II suggested that the controllers should do? e.g. DTO -&gt; LocalObject
Learn TDD and DDD as soon as practical. 
I spoke unclearly. Sorry. I meant essentially deserializing the json from the Request into whatever your dto is at that layer. Then handing that dto off to a service and returning whatever it gets back. Basically, wrap all the HttpRequest and HttpResponse details, but do literally nothing else. I agree 100% that business logic and calcs is where you get the most bang for your buck with unit tests. But I always put a layer of tests on core behavior. Sure, it's expensive to maintain. But that's the price you pay to have fewer bugs. I'm not saying put tests on getters and setters, or something. But "how do I convert a RequestDto into an instance of my model" should be covered.
You misunderstood me. I said exactly that you never should have display logic (or related AOP) in an entity. My whole point is you should have at least one more abstraction of data models besides the entities in any app that is more complex than having 5 entities. 
There is a good subreddit to learn the basics. Follow me to /r/ProgrammerHumor
Can you post the code for your select list creation.
I dabbled with ++ and # for a long time, but I didn't really understand much more than the basics until I decided to build an entire MVC from scratch in PHP...for fun. The language doesn't matter as much as the core concepts behind OOP. It's easy to Google the syntax if you understand how you should be getting to your destination. But whatever you do...start a project. My MVC ran on a small web server and saw maybe 5 users hit it in its entire lifetime. At the time it felt like a huge waste of time (hundreds of hours debugging stupid issues)...until I switched careers to program and realized every single struggle I had making that MVC has made my life far easier.
Wow! Great advice. Thank you. Any projects you would suggest? It’s probably the hardest thing for me to figure out is what to work on beyond my homework 
OData is a good approach for designing APIs, but it's absolutely not RESTful (which is fine). Most people who cal their API "REST" are actually just doing "json-over-http".
Don't use something in your code without researching a bit to get a sense of what it is. If all you learn is "You can get result B from A using tool X," and you never learn what X is or what it does, you'll never understand why something might be broken or how X might not be the best for your situation. Learn coding principles so that you understand the difference between code that accomplishes a task and GOOD code that accomplishes a task. The biggest concerns are things like maintainability and decoupling.
No problem. Don't be afraid to Google everything. I can't tell you how much I rely on random little tidbits through the day. As far as a project... It really doesn't matter what you build. It could be useful eventually, but it's also going to be complete garbage. I think I went through 4-5 complete rewrites until I got it to something I was happy with... But it's still interior (but extremely similar to) Slim PHP. I could have saved a ton of time by just using slim, but that wasn't the point. Just choose something you like the idea of building. Solve a problem you have on a daily basis, figure out how to contribute to an existing project, don't be afraid to have a monster goal... because the entire point is to throw yourself into scenarios you have to figure out solutions to.
Can you stay in school one more year or so and dual major in CS?
The SqlConnection.InfoMessage event allows you to listen for these messages.
Oh man, I hate automapper so much. I hope I can get rid of it in the project I inherited at work.
Don't give up. It will feel overwhelming at times. You will question why you decided to choose this path. The rewards are when you finally fix that bug you got stuck on for hours, or the epiphany you had when you stepped out to think about a problem, or when a concept you are learning clicks ... and many more moments like this. Often we touch on many subjects, skipping from one tip of an iceberg to another without sometimes going deeper, until it's necessary. It will be hard and rewarding. Never stop learning and never give up.
Some people have said make sure to learn X or do Y. Ignore that. What you should learn depends on what you want to do. The best thing you can do is put your goals first. Do you want to create games, graphics, websites, music, mobile apps, web sites, etc? Pick a (small) project that is personal and excites you. Then, once you know *what* you want to do, figure out what you need to learn to make that happen. Rinse and repeat. Seriously, as long as you're working on something that you find interesting, you'll be amazed at how resourceful you'll become and how much fun learning can be.
Turn back. There be monsters here. 
Well, I have just begun so haven't published many yet. But you have pm.
The qualification is a formality. Every decent programmer I've ever met is largely self-taught having already developed a passion that allowed them to learn it as a hobby. Keep doing that, and when the time comes you can just breeze through whatever qualification applies to the part of computer science you feel you're gravitating towards.
Not really true imo. People can comment on my videos and I'll respond. Sure I won't comment help people get better in terms that I will go through their code but I will help them to get better by showing how it's done in the first place and make them copy it. I would have no issue with teaching in the sort of way this website does it, but the problem I has with it is that I don't trust the company behind the website enough in order to spend my spare time contributing to it. At any time, they could start charging for content. Sure, maybe most mentors would leave but if they are big enough that doesn't really matter at that point as they could simply hire some people. Rather, I could just as well create my own website that does the same as Exercism.io does but just for C#. I don't see what need the website fill for me as a potential mentor.
Got to this solution: int summa = 0; for (int i = 2; i &lt; 51; i = i + 2) { if (i % 2 == 0) Console.WriteLine(i); summa = summa + i; } &amp;#x200B; Console.WriteLine(summa); My programming teacher is straight ass, if anyone has the time to explain how this code works in detail, i'd really appreciate it. Thanks!
hint: you need to use a second variable to collect the sum.
Linq could also do this. var evenSumTotal = arrayOfInts .Where(w =&gt; w % 2 == 0) .Sum(); 
Not much to this. * you initialize your for loop * you check if the number is an even number (kind of a double check since you're going up by 2 always in your for loop) * if even you write to console and add the amount to the step total int * at the end, you print out the total to the console
You are creating a loop, setting *i* to 2, and then incrementing it with 2 until it reaches 52, and the *i&lt;51* criterion is no longer true. For every such *i* you are checking if the modulus by 2 equals 0, *i%2==0*, and if that is the case, you write *i* to the console window. **This check is redundant: since *i* is incremented by 2 each loop, *i%2==0* will always be true**. You then add the current value of *i* to the variable *summa*. When the loop ends, you write *summa* to the console.
Do you mean curly brackets? They are used to keep a block of code together. Simple as that. There are certain places where they are mandatory - the signature line of classes and methods, for example, must be followed by `{ }` containing the body of the class or of the the method. And there are other places where they are optional - after keywords such as "if", "else", "for" or "while", for example you have to show which part of the code is associated with the keyword. You can either use `{ }` to contain a block of code, with as many lines of code in it as you want; or, if you only have one command, you can omit the `{ }` and C# will treat only the next command as belonging to the relevant keyword.
Which C#? :P .Net Core 2.1 has Math.Clamp methods for types defined, but unfortunately .Net Framework does not, so you'd need to implement the methods yourself. The implementation in Core can be viewed [here.](https://github.com/dotnet/corefx/blob/fd32c6dfc6cf6ff015d3c5df718e826cc0b5ee35/src/Common/src/CoreLib/System/Math.cs) 
I'm no expert, but they can serve 2 or 3 different functions. Firstly they are a required part of some of the C# lexical (i.e. the way the language is written), such as a class declaration defines the body of the class to appear with the { and } delimiters. Secondly it can be used to allow multiple statements where a single statement is implied from the lexicon. e.g. an if statement is defined as if (condition) statement, so you can write that on a single line with no braces, or one two lines even. But if you want to do 2 or more things where it says "statement" then you wrap those statements in braces. if (a &gt; 1) Console.WriteLine(a); or if (a &gt; 1) Console.WriteLine(a); or if (a &gt; 1) { Console.Write("a = "); Console.WriteLine(a); } Thirdly they affect scope, which is the process of defining where you can use a variable or other declaration. e.g. if (a&gt;1) { var b = 2; Console.WriteLine(a+b); } Console.WriteLine(b); // Won't compile, as 'b' is not in scope, and so not available outside of the braces. Braces can be used to introduce scope in places you would normally need it if required, e.g. inside a switch case statement: switch(a) { case 1: { var b = 2; Console.WriteLine(a+b); break; } case 2: { var b = 4; Console.WriteLine(a+b); break; } } Without the {}'s after each case statement you would get a compile error saying you had attempted to declare 'b' twice.
well my main gripe with this is, that `somethingFromUnity?.DoSomething();` doesn't work you instead have to do `if(somethingFromUnity!=null)` `somethingFromUnity.DoSomething();` although the ?. -operator is new and not many seem to use it, i find it reads so much better :( (iirc this includes the ?? operator)
The other day I was looking for a youtube I've seen before called something like "You're not doing REST you dumb fcks" (paraphrasing) which went through all the common approaches to doing something RESTy and why they were not REST. Never found it :) Pointless anecdote I know :)
Go back to plain C language and study what curly braces are for. C++ and C# evolved from it.
there are parantheses () and curly brackets {}. in short, parabtheses are where you put an expression (e.g. for an if statement) which iwll be evaluated, and also parameters for methods/functions. curly brackets are where you put your code in, they sort of set the border in which the code corresponding to e.g. an if statement, or a method, or a class is located. 
This is lousy advice for this guy. He's graduating in May. You can't just change your major. He's basically done. He will be perfectly able to find a lucrative career in programming irrespective of his degree. I work with brilliant programmers who have no degree, or degrees in English or political science. I also work with people who have master's degree in computer science and they are completely and utterly worthless programmers.
Pick something that interests you outside of computers. Comic books? Coffee? Board Games? Some sports team? Then write an app that keeps track items in a database... I wouldn't sweat too many details at this point, just get it up and running first. Then, maybe it lets users write reviews... or maybe it lets people curate their own collections of these items. You can get more and more complex as your imagination goes wild. This exercise will teach you basic application development and database techniques. Then, when you want to incorporate, say, push notifications (or whatever) into the site you already have it up and running and you figure out how to graft that piece on. You may never draw users to the site, but that's not the point. The point is you're using this project as a platform to learn new technologies, and you'll be motivated to work on the project because it's a topic **you** are interested in. 
I'm not the person you replied to, but what I've found works for me is finding something that bothers me today and try to solve that. For instance, when starting with C# I made an app that would change my desktop background automatically. You could select a folder and it would cycle through images in it every now and then. You could also choose the interval. Later, I added a preview mode, so you could click on an image in the folder, see what it looked like and then hit Apply to set it as the current background. That was a minor annoyance, but I found the solution appealing enough to consider solving it. It was also limited in scope, which is a very big plus when starting out. You are bound to likewise suffer some minor inconveniences in your life that you want to solve. Here are some more projects I'm considering taking on myself: * Monitoring the charge status of a laptop and showing a notification when done (since Windows won't) * making a shopping list where you can add favourite items or choose a template based on what kind of shopping you're doing * create a small web app for tracking my progress in the Bachelor's degree I'm doing Don't be afraid to use an existing code base (like a framework or a library) that will get you 80% of the way. Make sure you understand what it does, though. Completing projects is a good motivator to do more. Other times, you'll want to reinvent the wheel on purpose, in order to gain better understanding of stuff going on under the hood.
There are plenty of resources on c# that you will inevitably come across online, so language features and frameworks you will find during your experimentation and Googling. But, please, take some time to really understand object oriented programming and *design patterns*, and when, why, and how to apply them. Look up "Gang of Four". Learn about the concepts of memory management and how a managed languages deals with memory cleanup and allocation (stack vs heap, garbage collection, etc). Read about different architectures, like clean, onion, and hexagonal. You learn these things, you can be successful in any language. 
I'm not a fan of using View Bag to pass data. Why not add your data to the model? Then you get a strongly typed list. 
rule 4. also, if you want to get a job as a programmer in the future, you should learn how to use google, it's a super important skill that you need to learn.
We like to use DTOs, there are a couple of reasons why. We don't control the legacy data mode that EF scaffolds from. This isolates the ugly parts from the data model and will allow to concentrate or refactoring those parts later on without impacting our public interfaces. As a rule of thumb, only our providers and "things below" are allowed to know about entities from EF. We validate our DTOs coming in using FluentValidation and we inject or use a specific validator depending on the context since it makes it easy to encapsulate business rules into them, make business rules atomically testable and provides meaningful feedback to API clients as to why their input might be rejected. Most of our mappings from DTOs to entities are done using AutoMapper.
I know it probably seems like [PM\_ME\_YOUR\_HIGHFIVE](https://www.reddit.com/user/PM_ME_YOUR_HIGHFIVE) is being a smartass, but it's actually a very useful skill to learn how to enter the correct search terms to find the anwers you're looking for. Usually in the form of search results from StackOverflow and Microsoft...and occasionally even Reddit!
i figured that, but every explanation i found was very general and without examples aswell as most used advanced language, i did google. I am very new to programming and just started my course.
braces on a new line are called "Allman style" braces. https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference?view=vs-2017#formatting-conventions 
My advice would be target relevant and employable learning as quickly as possible. A good approach would be to invest in a relatively cheap online programming tutorial site, my suggestion would be PluralSight. Skill up on EF / WebAPI type tutorials then learn a front end framework such as React to compliment them.
TDD is overrated. With 16 years of .net experience I can honestly say I've found very few situations where it gives an appropriate balance of quality and productivity. The churn it produces on any meaningful application is immense. Also, unless your project is greenfield its very difficult to refactor legacy applications into a position to adopt TDD meaningfully. Given the guy is asking for advice and hasn't graduated yet I'd suggest skilling up on language features trumps TDD / DDD. &amp;#x200B; Not looking to start an argument or anything, just that I frequently have these TDD conversations in one of the largest software engineering employers in the world and rarely come across objectivity on the matter.
Is this a fucking joke? A beginner asks for questions with if-statements and loops and you want to write a loop with a LINQ statement?
Thanks, I'd love to see that too. I was originally doing automation + scraping with Selenium but it's slow as hell at scraping. Now I automate with Selenium, save pages, and scrape the saved file with HAP -- waaaay faster. Hearing about AngleSharp, and now H2X, makes me wonder if I can make my scraping time even better.
Things I recommend you learn besides your current C# classes. - JSON syntax (universal data syntax all languages can work with) - API's (learn how to build and work with them) You might as well get into web development asap, it's the future of... well everything.
The SMTP appender does this, not sure about others. It keeps a buffer of X messages, so when the threshold level is met, it will include the last logs. &lt;appender name="SmtpAppender" type="log4net.Appender.SmtpAppender"&gt; &lt;to value="" /&gt; &lt;from value="" /&gt; &lt;subject value="JobManagement Test Portal Notification" /&gt; &lt;smtpHost value="server name" /&gt; &lt;bufferSize value="10" /&gt; &lt;lossy value="true" /&gt; &lt;evaluator type="log4net.Core.LevelEvaluator"&gt; &lt;threshold value="ERROR"/&gt; &lt;/evaluator&gt; &lt;layout type="log4net.Layout.PatternLayout"&gt; &lt;conversionPattern value="%newline%date [%thread] %-5level %logger [%property{NDC}] - %message" /&gt; &lt;/layout&gt; &lt;/appender&gt;
It's fine to disagree with my suggestion. In the real world, most employers are too impatient to accept the initial overhead of developing unit tests, or product managers change the application behavior out of fucking nowhere, invalidating test cases. Not writing tests is, of course, a short term gain, long term loss. Tests are important. And I've almost never written any in 17 years. Doesn't mean I don't regret it. Learning TDD early on, to me, is more about learning certain habits and gaining a new perspective on software design than a dogmatic and rigorous approach to software development. Another tool in the toolbox to be used when it is deemed most appropriate. And maybe I'm taking language features for granted. Still, I consider language features and software design to be largely mutually exclusive - and we all have bad habits we picked up when we were first learning to write software, before we understood the difference between designing and coding. I was hoping that nudging a new person toward design concepts - at least planting the seed - would help them get a better high level view of what they will ultimately be doing.
Interesting. I will take a look at those tools, thank you. 
Gonna take you up on that one because TBH it's taking me way too long to figure out how this code is structured. Got any example files?
How is OData not RESTful? 
var list = new List&lt;SelectListItem&gt; { new SelectListItem { Text = "--- SELECT ---", Value = ""}, new SelectListItem { Text = "StartDate", Value = "StartDate"}, new SelectListItem { Text = "EndDate", Value = "EndDate"}, new SelectListItem { Text = "EndTime", Value = "EndTime"}, new SelectListItem { Text = "StartTime", Value = "StartTime"}, new SelectListItem { Text = "EndTime", Value = "EndTime"}, new SelectListItem { Text = "Name", Value = "Name"}, new SelectListItem { Text = "Venue", Value ="Venue"}, new SelectListItem { Text = "Room", Value ="Room"} };
Is the cert using sha1? It may not be. 
Value types assigned to references are [boxed](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/types/boxing-and-unboxing) into temporary heap allocations, so from the perspective of `TST()` all three arguments are the same: a pointer to a heap allocation with a header that describe the object's size, method table, etc.
Had that thought. According to the technical specs for OpenSSL, the hash algorithm uses SHA1, but on the safe side I also tried MD5 and SHA256 - no dice.
Whenever you call TST, [boxing](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/types/boxing-and-unboxing) happens and value types like `int` and `Rect` are converted to an `object` which is stored in the heap. 
Compiled assemblies contain metadata about their types.
I'm using similar approaches, although I'm using dapper mostly. What I always find clunky is that I let my data classes inherit from the domain classes, so that they just add some properties or an Id which is then hidden within the business code, because it is using the domain classes. I use this approach because that way when I want to save an object, the data layer can figure out if it has to do an update or insert. I'm only doing this because I'm not sure from a database perspective if a domain object has to be updated or inserted, because my service layer should just know about SavePerson(). I think the same problem occurs with the DTO approach, because an id doesn't fit into the domain
You might want to try googling a basic guide on C# syntax next.
All reference types, including boxed structs, have an object header that includes the type information. https://blogs.msdn.microsoft.com/seteplia/2017/05/26/managed-object-internals-part-1-layout/
&gt;Here's hoping by the time you enter the job market it's not all outsourced. I've been a developer for 20+ years and the trend of offshore outsourcing has really come down. Companies are waking up that you get what you pay for. The truly talented developers in Mexico, India, and China all make their way to the US. You can find cheaper programmers offshore, but they aren't discounted programmers. You are still getting what you pay for.
I've taken a concept that he or she is unfamiliar with, and showed them how it can be used to solve a real problem they are currently facing. That's a damn good way to teach someone, because it gives them a vested interest in understanding the code. The OP already figured out how to do it in a for loop. I just showed him or her another way.
Removed: Rule 4.
Have you gotten into LINQ yet? It's one of the best parts. Write all primes less than 1000 using linq functions: Console.WriteLine(string.Join(" ", Enumerable.Range(0, 1000).Where(x =&gt; Enumerable.Range(0, (int)Math.Sqrt(x) + 1).All(a =&gt; x % a != 0)));
What I remember being true about a "simple" question like this when I was a newbie is that often, I could read a ton of high-level explanations and still feel like "I'm missing something". So I would go to a forum and post what I knew. A lot of the time, someone would say "there's not a lot to it" and that'd be enough for me. I just wanted the feedback of a question/answer cycle where someone confirmed there wasn't some arcane use for the thing I was missing. In the end, it's better for newbies to get "no answer" than "learn to Google". In descending order of usefulness, these are the answers newbies get: * "Actually, what you have explained is all there is to know." / "This concept is too advanced right now. Come back later." * "Here, I'll try to cover what you need to know." * "I've always found this tutorial useful &lt;link&gt;." * &lt;no answers&gt; * "I could answer if I wanted, but it's a waste of my time. See, if I say the same thing over and over again, I can't help the people who I deem smart enough to be worthy of my attention. So I'm going to tell you like I've said a thousand times: there is a search engine you can ask questions."
You may have already found the answer elsewhere, but jQuery will treat an empty response as an error, regardless of the 200, because it's not valid JSON. "" is not valid JSON. You might try changing dataType: "JSON" to either blank (in which case jQuery will infer dataType), or "text". I've not messed with it from this angle in a long time... What I do for "void" calls like this is always return an object anyway. I have a standard payload class that returns (T)Data, (bool)Success, &amp; (string)Message. Regardless of what I need to send back I use this, that way there's never an empty string. Default value of that class just sets a blank message and success of "True". Also helps on the client side always knowing that my actual payload is always data.Data, success is always data.Success and error/notification message is always data.Message. var response = new WebApiResponse&lt;string&gt;(""); // WebApiResponse is my custom class return Request.CreateResponse(HttpStatusCode.OK, response); I haven't migrated to IHttpActionResult yet...crapton of legacy code dealing with HttpResponseMessage &amp;#x200B;
Solving for the general case... public static void DisplayMultiplesOf(int number, int min, int max) { for (int i = min; i &lt;= max; i++) { if (i % number == 0) { Console.WriteLine(i); } } } Usage: DisplayMultiplesOf(2, 2, 50); Result: I am not writing the results of this on my phone -- it works. 
No i did not. From a well experienced programmer it might seem that way but there are different assignments in every post.
One thing I would add is to formalize (or find and adopt someone else's) coding style. Really, I'm thinking about naming and casing. I was a hobbyist that transitioned to career. I was my own "boss" when it came to coding for a long time as well. Sorting this out seemed to help my productivity as I rarely have to think about what case a method/variable/property should be in. My naming convention might be more verbose than most; I almost never abbreviate anything, standard post/pre-fixes, etc. The advantage is I have to think less there as well. Point isn't to do it my way, just find your own rules so they become automatic to you, and you can use your brain power on solving the actual problem instead.
I did say it was 4:40am, but you still need the list of ints for your console output. If you turn the odds into zeros, you'd still need to filter them out. For just the sum though, this would be fine AND ...I learned something new. I didn't know sum could do that, so kudos to you for exposing me to something new.
Don't you need to create a SelectList object not a normal list?
I'll probably end up randomly generating a large file using those cases. Performance over such a small set would be difficult to measure. Will report back when completed
Assemblies store IL and metadata about the classes.
I get your point, but I checked OPs post history, and I think he/she missed some classes. And I rather teach someone to fish, than give him a fish.
Hell no
I do have my own conventions. They probably are nowhere close to "proper". I can usually look at a piece of code, and say to myself "I wrote that."
The main reason I prefer AngleSharp over HAP is DOM consistency. HAP generates a different DOM from malformed HTML, while AngleSharp gives the same DOM as browsers.
Why is that?
Hahaha thanks for the humor. Appreciated!
Generally properties start with upper case. Fields might be lowercase, but certainly not properties. I mean look at every other property in the .NET framework, all capitalized.
Think that you have 40 years to retirement or more. Investing two years now might prove a valid investment. Would you drop out of school if you wanted to become a nurse and were two years away from graduation?
Factorial recursion vs imperative is what every book I have ever seen do... ugh. this just looks like some hot fucking garbage that someone that picked up coding on the side and learned shit tons of bad habits from shtity web dev forums from pre 2010 internet
What installer technology are you using?
Whatever the standard is for publishing an application 
In what way *isn't* EF already the decoupling from the concrete persistence layer? It's basically a repository pattern unto its own.
Thanks for the explanation now makes sense
Today yeah. But what about tomorrow? He has 40+ years to retirement. China, India, Russia are producing more millions of developers every year, that work at the fraction of the cost of a developer in the US. Today the market is hot, but there are also hundreds of bootcamps cranking out developers all over the US. So today you're right, but we don't know what the future is made of. 2 more years of studies is nothing in the big picture of this guy's life. You're right, a degree means nothing by itself. You have shitty doctors with degrees. But look at trends on interviewing, and the scores of people bitter that algorithm and data structures take more and more space at interviews, even for front-end. It's a hundred times easier to nail these interviews with a formal education. Lastly, the network can be important.
I can't be bothered.
so would you mind recommending me a better source to learn recursion in programming on C#?? Thanks
You use a separate installer for c# applications?
It's probably one they built for the example app, might not actually be available in the toolkit.
I'll admit that there is a lot of value to leaving implementation to someone else, though. You don't have to know the whole details, but a general sense of what is going on can be very helpful.
It's a direct indirection above the database, it's a representation of the database itself. Not your business logic. If you want the client to query into the database, you might as well pass input strings as SQL into the database, no need to use EF, or any other layers in your application whatsoever for that matter. If your application is a CRUD only app without business logic and no complex business validation and your entities are sent over the wire, you should use OData instead to remove the redundancy. Do you always send the salted password hash to the client when they list the users? Hope not.
Sadly, learning recursion also requires some heavy math parts. Are you learning for fun or for university requirements and such? "academic" view of recursion - https://www.khanacademy.org/computing/computer-science/algorithms/recursive-algorithms/a/recursive-factorial next try to materialize this paper with actual code
Sorry; not trying to bust your chops, but it seemed worth noting for the rest of the audience. If you want to abuse LINQ and lambdas, though, you can toss in an `if` or a `switch` into the lambda to return 0 or write out the number and return as appropriate, but I wasn't clear on whether it really needed to still print the list of numbers, or just sum them up. Enumerable.Range(1, 50).Sum(i =&gt; { switch (~i &amp; 1) { // slightly less gross bit twiddling case 1: Console.WriteLine(i); return i; default: return 0; } }); Your coworkers will probably curse your name if you make a habit of *that* sort of thing, though.
Well it isnt for University requirements i just I am trying to leanr by myself, though I had seen discrete math before i had forgotten a bit about the recursion also seems harder to apply since for math is just linear you think about it in code is different you have to figure out the order of the algorithm and then then math
Eh I wouldnt say everything is going to be outsourced, but rather that there is a massive influx of new comp sci degrees and interest because its easier than being a professional (and licensed) engineer, and you roughly get the same pay or more for relatively "safe" work ie not designing a bridge that can break and shit, but more like "oops we got pwned and leaked 500000 emails and hashed pw, we totally sorry"
that exercise is just a shitty thinly veiled code reading comprehension test. also in the industry, people vastly prefer imperative solutions unless recursion IS neccessary (like looking for nested inner exceptions for some stack trace for example)
Well I see, I was wondering why it was so had to understand when they really dont explain it totally, it isnt recursion but does the same work, Well I just think I needed to learn recursion but this way is using iterations oseems harder
To simplify it further, you could say var w = whenebr w%2 = 0? 
First, I'm blind and not sure how I didn't see the 'SampleApp' project; two, this is exactly what I was looking for in terms if a UWP control. Thank you.
Turns compile time errors into runtime errors.
Just a fair warning: I'm not familiar with c# but I hope you are not discouraged of programming. int summa = 0; We create a "thing" which is an "int"eger named summa. for(int i = 2; i &lt; 51; i = i + 2) We are traversing a range of number, starting from 2 (as a number called i) to almost 51. But, we are jumping from 2 to 4 to 6. Sorry, not a native english speaker, don't know how to call it. if (i % 2 == 0) { Console.WriteLine(i); When our i is fully divisible by 2, we will print it to the console using that console.writeline. summa = summa + i; And we add the number (which we call it by i) into summa. } } Console.WriteLine(summa); And then we print our sum of the numbers by calling console.writeline on our number, summa. Hope it helps.
In that case, here's how to solve your problem: 1. Download GHC 2. Write the following: main = mapM_ print (filter even [2..50]) Problem solved!
Fizz?
Pace yourself. You will never learn everything there is to know about programming, and that can be frustrating when you want to learn it all. Learning programming is a life long process, so enjoy the process. 
`// TODO: Install` [`TimeMachine.NET`](https://TimeMachine.NET) `and remove all TODO's`
I really don't feel like my solution was an abuse of LINQ or Lambdas. It was a different solution to the problem. Sure, you could just go simple and there'd nothing wrong with that, but I wanted to demonstrate a different way. Apparently a bunch of butthurt programmers think that's a bad thing. I'm definitely weak on bitwise logical operators, and I appreciated your prior solution. It went back and reread about that stuff and refreshed a bit.
&gt; Not using `$` What is this 0.1x'er bullshit.
pcj brigading considered harmful
You'd have to write something like Func&lt;int, bool&gt; checkValue = w =&gt; w % 2 == 0; A lambda is, by default, understood by the compiler as an expression tree (which is a whole other topic), but will be implicitly converted to delegate (i. e. an object that contains a method) when assigned to a variable of a matching delegate type (that is, a delegate that contains a method with the same signature). `System.Func&lt;TArg, TResult&gt;` is a generic type for delegates that take a single argument that is a `TArg`, and return a value that is a `TResult`. In the line above, it takes an `int` and gives back a `bool`. There's predefined `Func` types for anything from 0 to 8 arguments, IIRC, and also `Action` (like `Func`, but always returns `void`, which `Func`'s type parameters cannot represent). There's also an older style of delegate syntax, but I don't think it really does anything much that can't be captured with a 'lambda', so you probably won't see it much. (You *may* see somebody define a delegate type, but that's usually to provide a meaningful name, so they can take a `ThingDoer` (or whatever) instead of a `Func`.)
What is the line between 'json-over-http' vs. 'restful api'... or what are the specifics that make something Restful rather then just 'json-over-http'? 
Oof. You really ought to learn the difference between a wrapper library, and actual .net core code, it'll make your future posts much less embarrassing. None of the links you provided are to 100% .net core implementations of an mp3/flac player. What comes closest is CSCore, which somehow you missed, but don't worry, it also falls short of OP's criteria because it doesn't work in OSX yet. 
Does that need to be registered in .NET Core API as a dependency injection? Or just straight use.
AutoMapper works well (IMO) in situations where: - The request/response models on the API map very closely to the database model (i.e. both are flat, or both have the same structure if there are sub-objects). - You will be mapping from class A to class B in multiple places. - You do not need to make additional calls to other APIs/databases during the mapping. If you start ending up with a lot of `.Ignore()` or dozens of resolvers or resolvers that have to hit the database / external APIs, you should probably be switching either to `.ConvertUsing&lt;SomeConverter&gt;()` or doing the mapping in a service class.
 What are you even talking about? Visual Studio literally has a standard publisher, ClickOnce.
How did you implement your IComparable&lt;T&gt; and IEquatable&lt;T&gt; interfaces? I think the problem may be there.
I didn't implement, IEquatable, just IComparable. Initially like this: public int CompareTo(Node other) { return this.FullCost.CompareTo(other.FullCost); } But then I realised the problem, so tried this: public int CompareTo(Node other) { if (other == this) { return 0; } if (other.FullCost == this.FullCost) { return 1; } return this.FullCost.CompareTo(other.FullCost); } That still didn't work, because I would never be able to remove the first open node for some reason. I have been buried in this for a while so it is quite likely I am missing something obvious at this point.
another fucking junior who just read c# unleashed or installed resharper and went with suggestions...
Oooor install node.js and then just npm isntall is-even-0-50
You should try adding a second comparison when the full cost is equal so that you don't have duplicates. Using the node's own GetHashCode() (essentially a random value if you don't override it) could work.
Yeah, such a junior 😒 Fuck off.
I think you should step up and help the guy out since you know so much about installer standards.
shush junior
I gave it another look... and I think you do need to use a different collection. Try with PriorityQueue&lt;T&gt;. It has methods for add and remove, and shouldn't remove duplicates, without modifying your comparer.
JSON is a transfer format - simple as that. Documentation belongs in your models, which could be C# or TypeScript classes. Take a look at [one of the most controversial Stack Overflow threads about this](https://stackoverflow.com/q/244777/382456) for some more good reasons why this is a bad idea.
Keep in mind that SortedSet *does not work* if you change the sort value of items after they've been added to the set. If you're updating FullCost, then you need to remove them, update, then re-insert them.
Et tu, dev-ops? This is one of the most insane things I've heard in a while. How do they envision this working, exactly? JSON doesn't support comments as far as I know. That seems like an obvious place to start. You know what does support comments and schema data? XML. I bet the front-end devs would _looooove_ wrangling a big ol' steaming pile of XML flecked with a healthy helping of verbose metadata and comments. Hopefully the threat of being sent to XML hell would make them reverse course but the absurdity of this request makes me not so sure. Or, if playing chicken isn't your thing... Maybe suggest that the front-end use console.table to print out the results of the requests. Work is done by them, management get to feel like cool hackers and use the chrome dev tools, and you don't have to do weird things to your stuff. Win win win. Otherwise, is there a more technical person in management you can appeal to? I can't imagine a competent CTO would abide these shenanigans. 
Your other choice for .NET Core is Visual Studio Code (which runs on Windows/Mac/Linux). But I agree with AngularBeginner's answer for the same reasons.
Well I actually did get it to work, took a little bit of tinkering, but the key thing was that the CompareTo must be consistent in both directions. Because I had the hack of responding "1" if the FullCost was the same I could get a bad situation where a.CompareTo(b) would give the same result as b.CompareTo(a). Here is the code now that works: public int CompareTo(Node other) { if (other.NavGridPosition == this.NavGridPosition) { return 0; } if (other.FullCost == this.FullCost) { if (other.NavGridPosition.x != this.NavGridPosition.x) { return this.NavGridPosition.x.CompareTo(other.NavGridPosition.x); } return this.NavGridPosition.y.CompareTo(other.NavGridPosition.y); } return this.FullCost.CompareTo(other.FullCost); } 
Thanks - rather than updating them, I am removing the old instance, and replacing with the new one. However now I have fixed the comparer I guess it should work, since it is comparing first on the grid position.
You are going to want a tree structure. Unfortunately, these are not implemented in C# standard libraries. Some quick googling around "in memory .net b-tree" should get you what you need.
Now that I have SortedSet working, do you still think a binary heap would be superior?
Just a litle sidenote. the actual json spec does not allow for comments (infact, its creator explicitly removed then [source](https://plus.google.com/+DouglasCrockfordEsq/posts/RK8qyGVaGSr) but most libraries can handle them. Apart from that, I totaly agree. What an insane request! Ps: I had never heard about console.table :O Nice tip!
&gt;This way everyone can look in chrome inspector and "say what this stuff is for". In addition to what everyone else has said, what exactly do they think that is going to accomplish? Who is it going to help, and is there a better way to provide that help? The answer, of course, is to provide that help through proper documentation, not streaming it over-the-wire with every request. It strikes me as strange that (from what I can tell--I could be super wrong here) management assumes external developers consuming your APIs would prefer documentation served with the data rather than available as a separate reference where examples and much more rich additional detail can be added. Another point to bring up is the additional bandwidth consumed by attaching all of this documentation to *every* request. Depending on how much traffic you're serving, that could potentially be considerable and worth bringing up not only from a technical standpoint but also a financial one.
Documentation will easily become at least 50% of the average payload, increasing memory usage and slowing down every single request significantly for no benefit in 99.9% of the cases. Much better is to have a standardized documentation serving URL such that any XHR URL can have "$metadata" tacked on the end and a GET request to that URL will give it the documentation. Or some other convention-based approach.
usually a priority queue (aka heap) is the preferred data structure for this there isn't one built in. it isn't too hard to implement though. 
If you want to save it to a text file, look into StreamWriter for saving, and StreamReader for reading/loading. (System.IO namespace) If you want to go the XML route, I recommend looking into System.Linq.Xml. Ideally though you can get a hold of a database, that is the best route. I believe there is a free version of SQL Server available. This is probably the hardest option because you are a bit new, but you stand to learn the most. 
omg savage
Use Swagger. It gives you a pretty place to go look at the endpoints, the docs, try things out, etc. As a bonus, when DevOps needs to troubleshoot something you say is broken, it lets them easily reproduce it without having to deal with test harnesses, idiosyncratic Postman collections, etc.
It sounds like what the company wants is something akin to [JsonApi](http://jsonapi.org/), which is a standard for defining and explaining a json response. This isn't a replacement for documentation at all, so I'd double check in case there was a communication break down. So why jsonapi? It's a way to return the json, but also other meta-data associated with the object include schema and types as well as links. This is to enable hypermedia , ie clients that don't hardcode to specific endpoints or models but can adjust based on api changes. 
Hint: when changing search direction, don't change the variables "row" and/or "col", just change the parameters you pass in. Hint 2: replace .ToString().Contains(".")) with '.' ditto, replace Char.Parse("x") with 'x'
That's weird. I thought the priority queue was part of the standard library. I'm glad you could solve it either way!
If your methods do exactly what the name says they do you shouldn't have to worry about anything. If you can click inspect element and see exactly what's going on under the hood it's a bad design.
This isn't necessarily an either-or situation. You can use both in tandem. You can use reflection to discover types and methods at runtime, and create and cache delegates to those methods.
The reflection APIs have methods to get delegates to methods. The simplest thing you can do is get those delegates and save them in the dictionary you talked about, with some string (like the method name) as the key.
Holy shit this tell managment. It’s and idea and your comments should be in your code base.
Really just buy a copy of CLRS because if you're at the point where you're worrying about efficient data structures you should probably own it.
&gt; If it does then I leave it alone Do you want to leave it alone during uninstall if it existed and had other files inside before install? You risk wiping out user files (depending on where this folder is located obviously)
Sweet, I’m waiting!
I may have accidentally changed it during pasting. Thanks. It’s publicly editable though, right? First time I use that website.
If you swagger it and put a swagger-ui in front of it they can look at it even without the inspector!
Rip the priority queue out of mine: https://github.com/valantonini/AStar Or try this (i havent tested it in AStar though): https://github.com/valantonini/PriorityQueue
When I say 'implemented' I sometimes mean found the source code on someone's Github.... 
You can choose either. And you don't haven to register every single map, it's so much easier to use.
No problem, hope it helps
I disagree that JSON is a transfer format anymore than XML is. That said, I also think direct API doc should go with the code. More thorough docs don’t fit there well, though. 
I think the point about the documentation being the half the JSON payload, and totally redundant was one way to convince management that someone with stupid ideas needs to go. OP's in a difficult position, but please, don't let them force you into something like this. It'll be a thorn in your side. You are in the right. The way you can convince management is you compile a list of pros (there is only one) and cons (numerous). For the pro, you provide any kind of alternative. I like to tell them when they try to cut corners like this, that when there are more solutions, the *tough* one is the correct route. 
The GitHub repo is only a readme, where’s the rest of the code?
Just to play Devil's advocate, you could always add duplicate fields as "comments" into your payload, else I can't imagine how OP's colleagues intend on this working. Something like this: { "price": "23.50", "price_doc": "price that includes tax" } I realise it's ridiculous, just can't think of the alternative.
...all of his repos are like that :|
I feel like it is missing a lot of functionality. 
Hi guys,the github link shows instructions on how to use the Nuget Package
Is there any chance you're using something like HAL format, which defines the use of CURIEs to link to documentation? This provides a lightweight means to generate doc links for all API resource links. http://www.mikestowe.com/2015/01/what-the-heck-are-curies.php 
Its a lightweight package for basic CRUD Operations.But future modifications may contain more functionality
So you'll be adding some code to it at some point, because right now it looks empty. That readme file is sweet though.
in short - no. is your project - web pages project? whole idea of spa is to offload routing to frontend and load pieces of UI and data only when required without reloading entire UI.
That's the reason using unity is hard for me. Those guys screwed that up hard.
Thank you.Yeah will add the source code.
Use a third party library for something this simple? Come on.
&gt; is your project - web pages project? yes web pages using ASP.NET web form(not MVC/Razor) and C# as back-end. ex: www.example.com/pages/about.aspx , www.example.com/pages/create.aspx , etc the idea is to make that url becomes only 1 single address which is only www.example.com what ever is the page menu clicked by user.
As a mostly front-end / JS dev who consumes backend APIs all day, USE SWAGGER. &amp;#x200B; Swagger is great, provides the names/paths of endpoints, the shape of the models it expects (from path/query/body of the request) as well as the shape of the payloads returned.
 bool isSuccess = false; try { db.Set&lt;T&gt;().Add(data); db.SaveChanges(); isSuccess = true; } catch (Exception) { } return isSuccess; This is a very bad practice. Any error messages are lost forever making it impossible to see what went wrong. Ther's also a high risk that anyone using this forgets to check the boolean returned and thus will never even know that something *did* go wrong (until some time later when data is missing or inconsistent. No code should swallow exceptions like this, and *especially* not a library.
Documentation in JSON responses sounds really dumb. Documentation is paramount in any good system, but shouldn't come at these costs *in production*. A thing you can use for this purpose is JSON schemas, they provide validation and documentation in one place! Schemas are pretty quick to write (even manually) and can often be implemented with ease! Now, since the primary purpose of the JSON schema is to provide validation, it makes sense that it also provide descriptive information for the thing it validates. For instance: "firstName", "required", "min 2 letters", "max 30 letters", "The first name given to the person". That's immensely helpful to anybody who implements your API:s. And for validation errors, you can simply send back (parts of) the schema in the response body. The schema can also be used to validate the front end. You can for instance serve the schema from the resource's url by appending '/schema' to the end, and then use it to validate forms (for instance).
The problem is when there is a grima wormtongue whispering into the ears of management. Someone who's not responsible for the work but has their ear and thus can make ridiculous demands of the devs. Typically this is an out-of-touch architect or someone who wormed in based on an "impressive" academic resume and speaks well but has no real world experience whatsoever.
You probably *can* do it, but it's a really stupid thing to try and do. The routing will be hideously complicated and it will still be a Web forms app. 
EF already provides an implementation of the repository pattern with the DbSet class. What you add to this is immediately calling SaveChanges after the Repository operation and suppression of raised exceptions. Calling SaveChanges immediatly breaks the Unit-of-Work pattern. A Unit-of-work (DbContext) collects all changes in one or more repositories associated with this DbContext and allows to committing them later as a single database transaction. This is USEFUL and far superior to an approach which commits every single change immediately. You don't need to 'fix' this. Suppressing exceptions is a design smell in almost any case I've seen it. You made two design decisions here which might make sense in the specific usage scenario you currently have but they don't qualify as an general implementation pattern. Also, my experience is: reuse only works with code which takes longer to write than 5 mins. I would never start looking for your NuGet package if I would have to write that code in a project.
u/ssentrep and /u/benevolent_coder : Gosh. *THANKS.* It's obvious once you pointed it out. I must have gone over this a hundred times and never saw that mistake.
Holy crow, thanks. That did it.
Note that this is a narrowing cast, so there's the risk of overflow. C# normally ignores these, but you can use the checked() function to explicitly look for this case. https://www.oreilly.com/library/view/c-cookbook/0596003390/ch01s13.html Or of course, you just may not care. ;) 
Yes! So... *everyone* should own it! 
I'm answering hypothetically for /u/grauenwolf here, but let's say you need to pull the Order's Customer info to determine what User's permissions are on the Order. You may not want User to actually see Customer, but based on the way /u/grauenwolf described cache pollution, EF might attach it anyway? This is news to me, but I could see plenty of cases where it could cause problems. 
You are wrapping methods that are already one or two lines of code to implement the repository pattern in a library that already implements the repository pattern. I'm sorry to say that this is not really of any use to developers that want to make their life easier.
Is this WPF? It plays well together with the INotifyPropertyChanged interface - implement that on your classes to get automatic UI updates for data-bound properties.
Yes it's WPF. Problem is that it won't fire if the property of a property is changed (hope it is clear what I mean by that, bit hard to explain). For observablecollection for example this only fires if an item is added, or deleted, but not if a property of the item is changed, and certainly not if the property of a property object of an item is changed. 
INotifyPropertyChanged must be implemented by you - it's the piece that allows the UI to automatically update data-bound properties. It's pretty boilerplate, normally you'd put this in a BindableBase class you derive from (google that), but if you only want the interface, making you free to derive from other classes then it'd look like this: public Child : INotifyPropertyChanged { private string property1; public string Property1 { get { return property1; } set { if(Equals(property1, value) return; property1 = value; RaisePropertyChanged(); } } private int property2; public int Property2 { get { return property2; } set { if(Equals(property2, value) return; property2 = value; RaisePropertyChanged(); } } public event PropertyChangedHandler PropertyChanged; protected virtual void RaisePropertyChanged([CallerMemberName]string propertyName = null) { PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName)); } } I personally find the BindableBase solution more elegant and easier to use, but this example makes it more obvious what is happening.
&gt;For Entity Framework I have seen Dapper, OrmLite, NPoco, PetaPoco and Massive but they all look like ADO.NET with a different name. I'm sure they have their uses and cases where they would be better than ADO.NET but for my intents and purposes I don't think any of them are suited. Well if you're looking for "lightweight" then the micro-ORMs you listed are one of the things that come to mind. All ORMs are a layer on top of ADO.Net, because that's how they're going to actually get the data from the database, although the micro ORMs are much closer to ADO.Net than EF or nHibernate. As far as ORMs go, it's tough to get something that's lightweight, but still implements IQueryable, mainly because implementing that and translating the resulting expression into SQL is a very complex problem, where as types and name matching is a much easier problem. &gt;So, I'd like to ask for suggestions as to what database to use instead of SQLite that has to be just as light as it is, I don't need a 100MB overhead on a 3MB application just to connect to a database file Again, SQLite is about as "lightweight" as it gets here. Technically you could try SQL CE, but that won't be any better. I think the ultimate question here is why do you need a database? Can you persist data to a file via JSON or XML? Do you need some sort of transaction support? Are you going to need a lot of objects in memory? I think answers to those questions would be helpful in trying to find an alternative solution, because it doesn't sound like the DB road is all that interesting to you. 
Yes, all of this is clear to me, however: private ObservableCollection&lt;MainClass&gt; myItems; public ObservableCollection&lt;MainClass&gt; MyItems { get { return myItems; } set { if(Equals(myItems, value) return; myItems= value; RaisePropertyChanged(); } ... ... } This - as explained - fires only if an item (instance of MainClass) is added or deleted from the collection. I need to know if the property of MainClass is changed, or even better the property of a subclass which in return is the property of MainClass. I would have to implement the notification on the properties of the subclass, but this (at least as I see it) is not a good thing, because, this subclass is used many times in different areas of the software, causing to fire the method I need quite often and out of context. Thus my two points in the OP: I would need to know if the subclass object is the property of the MainClass. 
Show them the link between performance and conversion. Bottom line is that increased loading time will lead to lower revenue, in this case without any gain to the consumer. https://www.google.se/amp/s/www.thinkwithgoogle.com/marketing-resources/experience-design/mobile-page-speed-load-time/amp/
Why would this be a bad thing? If your object's property changes you wouldn't want other code to use outdated data. Here it looks like you've implemented INotifyPropertyChanged on your ViewModel, but have you done so on your MainClass?
**Direct link**: https://www.thinkwithgoogle.com/marketing-resources/experience-design/mobile-page-speed-load-time/ --- ^^I'm&amp;#32;a&amp;#32;bot&amp;#32;-&amp;#32;[Why?](https://np.reddit.com/user/amp-is-watching-you/comments/970p7j/why_did_i_build_this_bot/)&amp;#32;-&amp;#32;[Ignore&amp;#32;me](https://np.reddit.com/message/compose/?to=amp-is-watching-you&amp;subject=ignore&amp;message=If%20you%20click%20%27send%27%20below%2C%20the%20following%20action%20will%20be%20taken%3A%0A%0A%2A%20The%20bot%20will%20ignore%20you%0A%0AYou%20will%20receive%20a%20confirmation%20in%20reply.)&amp;#32;-&amp;#32;[Source&amp;#32;code](https://github.com/bvanrijn/aiwy)
To be honest I thought of using SQLite because I wanted to train/excercise work with a database. As for alternatives, if SQLite is the lightest database out there and there is nothing that can compare, then I'll stick to it. As for EF - I thought there'd be something that's like it (I mean, I know it also uses ADO.NET but the implementation is completely different in my eyes) that's lightweight, some alternative where I could map the tables in my database and query them like in EF, rather than write SQL.
The data is very little, I thought of using SQLite because I wanted to train/excercise work with a database.
Ok I'm curious, what makes ADO.NET so bad in this situation?
For now it doesn't do much .My main idea was revolving around a generic repo for consolidation of basic CRUD operations.However,with time, simpler more useful modifications will be implemented.
Hmm, all of this is a bit tricky to explain so bear with me a bit. * My MainClass is a line in the datagrid handling how the userinputs are fed to my subclass. * My subclass is a filter containing sql queries and settings according to the userinput. My goal for all of this is to update the GUI somewhere else with all the current settings according to the settings the user puts. Objects of the subclass with the filter, however are used many times internally with no relation to the GUI whatsoever. If any of those object properties change, I don't want to fire my method which updates the GUI everytime. Or at least, I want to check within that method, if my object coming from that datagrid, before continuing. 
I just find "myTable.First(s =&gt; s.ID == 3)" more feasable than "Select top 1 * from myTable where id = 3" for data that won't change. Plus I also need to work on my EF. Sorry, but can you confirm SQLite is the lightest there is?
I'm a bit confused by the way you say "class" here. You have objects. One line is *one object instance* of MainClass, of which you can have many. And you seem to try to fix a non-issue. Are you actually experiencing the UI freezing or are you trying to do some premature optimization? &gt; I don't want to fire my method which updates the GUI everytime. *Your* method? Is RaisePropertyChanged doing anything other than `PropertyChanged.Invoke` ? If that's the case, change it.
Create a view model for the class and implement property notify on the view model. Then have an observable collection of the view models. You shouldn't bind directly to a model. It's the whole point of the vm in mvvm.
&gt;Actually, forget the INotifyPropertyChanged-Interface, this was just to show that it's only fired if an item is **added/removed** from an observablecollection. No, that's a different interface, INotifyCollectionChanged &gt; I want to use getter/setter of the properties to control when a method I wrote, which takes the information from the datagrid, handles this information and puts an corresponding output to a different view. The question is only when I fire that method. This is what events are for. You create a method and then you subscribe to the PropertyChanged event like so: var s = new SubClass(); s.PropertyChanged += YourMethod; Then your method does what you just said you wanted to happen if things change. If you do not want this to fire constantly whenever a user inserts new data in a cell you can add delay on the databinding. First of all, unless you haven't specified `UpdateSourceTrigger=PropertyChanged`, it will only fire when the cell loses focus anyway, which means not very often. But if you are using PropertyChanged, then a millisecond delay is possible: `DataGridTextColumn Header="Property1" Binding="{Binding Property1, UpdateSourceTrigger=PropertyChanged, Delay=500}" /&gt;` Or you could also set `UpdateSourceTrigger=Explicit` which means it will only update bindings when you explicitly call the UpdateSource() method on the BindingExpression object, which would require some code behind and maybe a separate "Update" button.
This is very helpful. I will get back to the code on Monday and will have a look at all all your points! Thanks a lot for sticking with me and my long (and maybe confusing) explanations. Cheers!
You probably need a completely different architecture because this sounds a bit funky. However you could accomplish this with ReactiveUI's ReactiveList and enable ChangeTracking which would notify you of properties on the class in the list changing with the ItemChanged observable.
I am glad that outside of my experience, things care different. I am with a large corporation that is cutting, cutting, cutting and replacing with off and onshore. Years back we would get some folks who were reasomsbly trained. Now it's just a tsunami of unexceptional bodies. The idea being if you throw enough bodies at the project, you can keep it at a level of acceptance. Why bother the little extra for excellence when mediocre will do the job. In theory, the in house guy at the top of the check-in will stop any disasters. In reality, the few who are left are watching as things slowly degrade, from egregious grammar and spelling mistakes to painfully bad code and processes. We watch as these employees are given kudos for the most mundane achievements as if they are in kindergarten. And yet, there are no impacts, or won't be for a long, long time - this dinosaur is so large, that it would take decades before anyone noticed the carcass had bled out. 
If NoSQL is an option check out [RaptorDB](https://www.codeproject.com/Articles/375413/RaptorDB-The-Document-Store?msg=5401131). I've used it on quite a few projects, and have come to like it.
if your application is just a web forms site. Separate your controllers into a web API and build on something like VUE.js(easiest solution for converting old websites IMO). Don't do what you're trying to do it's not going to serve you well in the future you need to start migrating.
Not all, but many of these degrees are bought. The competence level has dropped sharply in the past decade. See my reply above - businesses are dumping excellence for bodies - why buy an expensive dishwashing machine when you can cheaply hire manual dish washers. They may break some dishes, cause a few hepatitis outbreaks, but eh, overall it's working for us. 
I'd very much recommend against the explicit option, the entire featureset of WPF is to be able to make data-driven applications that seamlessly update all the areas that rely on and use a common piece of data. Also consider user experience, adding an extra click every time any little thing has to be changed will raise not only the propertychanged event but also frustrations.
Not me, only server side. I have a pretty fixed idea of how I expect my UI service layer to work and Akka has never been part of it. It is great tech though, so if you do use it, spend an hour writing up how it's serving you well :) Trip
I recommend https://github.com/okhosting/OKHOSTING.ORM
What if you use a hosted PostgreSQL database? You can spin one up with AWS’s free tier.
Also, for what it’s worth, dapper makes ADO.NET unbelievably more usable.
I don't disagree!
You should look into TPL DataFlow It let's you construct actor networks, even dynamically during run time. Albeit using networks properly is difficult enough statically let alone getting a dynamic network. 
Sometimes it's not what you say, but how you say it. The old adage to know your audience is important here. In your case, you may be dealing with a group that are closer to the technology and may think they know what they're doing. And worse yet it's your voice against at least a few others. Keep in mind that the fact they want better documentation is a good thing. In your case, I wouldn't try to tell them - I'd show them. Put together a prototype that demonstrates to them the performance implications of what they're requesting. Then present it to them with the reasoning that you were concerned and apparently rightfully so. The benefits to this approach are that you look diligent and you're not getting into a pissing contest. Even if they still want to go forward you know you did your part and you now have covered yourself if it blows up later.
Thanks I'll investigate that one.
Ooooohhhhhh I think I might understand it now... My links look like this: @Html.ActionLink("Policies", "Index", "Policy", new { area = "Agent" }, null) This is still linking to \~/Views/Policy/Index.cshtml unless I'm mistaken.
Sqlite +EF = VS2015? Where did you get that idea?
Hopping on the NoSQL train, have you tried http://www.litedb.org/? It advertises &gt; LiteDB is serverless database delivered in a single DLL (less than 350kb) I've used it in a few of my projects and I find it has a sweet spot. I will say, it does take a little finagling to get the repository pattern working just right, as when I started I seemed to miss a step in the documentation.
There's also the Orleans framework, I'm pretty sure the idea of the two is similar. Orleans is also free
Or your could build your xaml differently, specifically style it.
When I have specific needs in a collection implementation, the first place I check is the [C5 collections library](https://github.com/sestoft/C5) to see if there's a suitable implementation there. They do a great job of [clearly documenting the library](https://www.itu.dk/research/c5/latest/ITU-TR-2006-76.pdf).
&gt; if SQLite is the lightest database out there and there is nothing that can compare That is the case. Nothing really compares to SQLite. &gt; As for EF - I thought there'd be something that's like it (I mean, I know it also uses ADO.NET but the implementation is completely different in my eyes) that's lightweight, some alternative where I could map the tables in my database and query them like in EF, rather than write SQL. * Lightweight * LINQ to SQL translation Pick one. If you want LINQ translation, just use EF. It's arguably the best full ORM around - certainly for .Net - and has been for several years. It's also the most valuable to know in the job market. If you prefer lightweight, it's a micro-orm and involves some SQL. PetaPoco &amp; NPoco I know have a SQL builder helper and allow shorthand text - a query might look like `db.Fetch&lt;MyTable&gt;("WHERE ID=@0", 3)` or `db.Fetch&lt;MyTable&gt;(new Sql().Where("ID=@0", 3))`.
[removed]
I've found LiteDB to be pretty useful for simple storage on c# https://github.com/mbdavid/LiteDB/
Wow, litedb looks nice! One of the great things about raptor is the query speed, even with millions of documents. But, this comes at the cost of needing to create schema classes that complicate things. What's your experiences with litedb with regard to performance? 
This is why I’m deploying a Collibra in my company - documenting all data exchanges (and data stores) in a central place without cluttering the transactions. As for management (c level) it took us about 6 months to make them « see the light » on the broader topic of data governance. It’s hard to push small decisions (like yours) but when you setup a whole program you can stack benefits and in the end it makes sense to them.
That's my point: Entity Framework is a generalization of CRUD operations and much more. Why do we need this?
Im not sure akka.net is the right solution if you're just trying to deal with streaming data. If you want an actor network and all of the benefits that brings, that's another story, but I find that significantly overcomplicated for most frontend cases. Based on your description so far, I'd say look into Reactive Extensions (Rx) https://github.com/dotnet/reactive
I'm still very new to this as well, but why not go for EF core instead? It supports SQLite. You can also use a local db (MSSQLLocalDb I think) though I'm unsure of the size/overhead for that. Also, you can use EF6 with VS 2017? What was the issue you were getting?
Akka.Streams is a Rx implementation, one of the reasons I'm looking at it. Akka also has the ability to use Actors as sink and have the actor handle messages on the UI thread so it makes updating UI controls cleaner.
The only modification is the EntityState and saving changes part. One does not need to keep calling them every time, it's done for you by simply calling the respective methods. Otherwise one can still use EF as it is. 
Ok, but just saying that having a repo and a single readme isn't opensource (which is ok), but it also gives a very weird impression. People rarely have repos with no code, unless it's a tutorial or something. Have a readme with no code, for a package is worse than not having a github repo. I would have just put the instructions on the nuget package description (here - https://www.nuget.org/packages/OreoJam/) I see you published some source code, I'd recommend actually pushing it as a .cs file instead of a file called "Source%20Code" as you'll get syntax highlighting and would be easier for others to look at. I've pushed many Nuget packages to both github and nuget and here's the workflow I follow. * Setup the github repo first. * Work on package locally. Always pushing to github. * Create a free [Appveyor](https://www.appveyor.com/) account (or any CI server) and set it up to build the code when anything gets checked into master. After a successful build it creates a nuget package and pushes it to nuget.org. The nice thing about this workflow is you don't have to go back and share code later (which is what I think you did in the github UI) instead your code ALWAYS goes to github first , then goes to the CI server. It's also less work. As you make changes you just git push and you're done, new nuget package is on the way. If you want more control you can also configure it to only create a package on a specific tag, so before you push tag it with a release number or something in git. Sorry I'm not trying to be picky but offer guidance on how to set up a good workflow for nuget packages based on my experience with several. Also guidance on github, looks like you just copy pasted the code onto github after finishing, ideally you would be pushing to github as you are writing the code. If this is a project that you would like to include a portfolio, that's what I would look for as an interviewer (I've interviewed over 100 people at a large company in California for software engineer roles).
URLs are important. Don't break the back button and the refresh button. It hurts your users.
Hi, suggestions/feedback are always much appreciated. I think your work flow for publishing nuget packages is much better. Will check out Appveyor. Looking forward on using it publishing future packages :-). 
Wow, this isn't even remotely how you make an SPA. What led you to this bizarre idea?
Maybe something like litedb or linq2db might be good.
If your ID column is a primary key then you don’t need to add the top 1 bit
Right click -&gt; Add -&gt; Existing Items. The files aren't a part of your solution for some reason. 
Okay, so I've gotten to a point I thought is easy to handle and it's just not as easy as I thought. My maze solution gets to the exit all right, but then it throws an exception because the index is out of bounds (because of course it would; trying to go east at the exit would be out of the bounds of the array). That's fine; I expected that to happen. *However*, handling that exception presents another problem I don't know how to approach: if I deal with the exception in any way (even with a try/catch) the maze continues writing 'O's over its previous path, all the way back to the start. I know that this is because the prior calls on the stack are already there- they'll all resolve, happily writing an O where it doesn't belong. So my question is how I keep that from happening. Is there a way to, I don't know, completely abort the entire call stack once I've reached my base case? Or is my problem with the base case itself?
Great comment here. Suppressing exceptions is almost never a good idea, and literally never a good idea for a library that others could use. Saving immediately may work, but if the project grows big enough you will likely regret that. 
"I want to use a database but I don't want to learn SQL" Not sure what to tell you... 
Have you got any hints as to how it can be cleaned up?
&gt;That "reset game" will set a boolean to true. &gt;when a game is won, it will set XorO to true Is the method `StartNewGame`? The one that sets `XorO` to `false`? There's no place in the code that resets `XorO` to `true`.
Exactly. In fact, it was permission checks where I learned about this 'feature'.
It's because you are calling CheckForWinner(); then reversing the book with XorO = !XorO;
You explicitly flip the variable afterwards, I think that's the reason for the weird behaviour.
Yep, once you use Fody you can't go back. It's just so convenient.
Exactly! There is no place in the code that should set XorO to true after method StartNewGame, just like you said. However, it does. After StartNewGame has been run, it will be true. And if StartNewGame said "XorO = true;" it will be false after the code has been run. It makes no sense. &amp;#x200B; (I did say in the post that it was set to true, but i had it as false for testing\*and testing didnt give me any clues\*) But whatever StartNewGame is setting it to is irrelevant, because XorO will become the opposite of what StartNewGames says for no reason. But yea, sorry for the confusion there. Ill edit the post so it makes sense
When a button is clicked, Btn\_Click runs. &amp;#x200B; Scenario: XorO = true The code sees XorO = true and places X in textox AFTER this has been done, it will change XorO to false. Run it again: XorO is now false, it will put O in the textbox THEN put XorO to true. &amp;#x200B; Since it changes the boolean after it types X in the texbox, it is irrelevant. But yea, i dont see what else could be causing this, however that argument cant be true(because of my scenario above), its gotta be something else.
Indeed that was my thought as well. So i checked: CheckForWinner(); should not do anything related to it, but CheckForWinner(); leads us to ThereIsAWinner(); ThereIsAWinner(); The first thing this does, is set an irrelevant string, so that shouldnt be it... Next it can pop up a messagebox IF (IsAWinner = true), lets assume it is true(that somenoe has won the game), so messagebox comes up, and it goes on to StartNewGame(); and there is the problem. It leads to StartNewGame, which should in turn set XorO to true, but the opposite happends. And if it sets XorO to false, the opposite happends again. &amp;#x200B; It also leads us to Turcounter(), that mightve been the issue, but i removed this code to test this, and it didnt change anything.
Look at line 40 in the pastebin. That is going to be called after StartNewGame so whatever you set the book to in StartNewGame will be reversed.
StartNewGame, which sets XorO, is called by ThereIsAWinner which is called by CheckForWinner. This is where XorO gets set to a value which is "mysteriously" inverted. CheckForWinner() itself is used in one place. it is in Btn_click. Let's take a look. CheckForWinner(); XorO = !XorO; StartNewGame will set XorO but then once control returns to Btn_Click it will immediately invert it. Swap these two lines and the problem goes away. 
Update your resume/CV. I can't imagine a company like this lasting much longer.
In the btn click event, move `CheckForWinner()` after `XorO = !XorO`. You're welcome. `CheckForWinner` may eventually lead to `StartNewGame` which will set `XorO == false` but *execution returns* back to where `CheckForWinner` was called and, immediately after that, you have it flipping the `XorO` bool. So, move CheckForWinner *after* the bool flip. The code itself needs to be cleaned up. It isn't managing state very well, obviously.
/u/PurplebeanZ is right. I think you are misunderstandong some fundamentals of runtime execution. Consider the following: class Program { private static bool MyBool { get; set; } static void Main(string[] args) { MyBool = true; CheckForWinner(); Console.WriteLine($"MyBool: {MyBool}"); Console.ReadKey(true); } static void CheckForWinner() { if (MyBool) { StartNewGame(); } MyBool = !MyBool; } static void StartNewGame() { MyBool = false; } } I've reused some method names from your example. What do you think is output to the console? In this example, this is the exact sequence of execution, line by line, if we combined all of the methods: MyBool = true; //true if (MyBool) { MyBool = false; //now false } MyBool = !MyBool; //now true again Console.WriteLine($"MyBool: {MyBool}"); Console.ReadKey(true); Hope this helps.
Pretty much everyone in this post has told you the answer. Do this -- Set a breakpoint on the first line in StartNewGame() and run the program. Once you hit the breakpoint, keep hitting F10 to follow the program's execution sequence and you'll see what the problem is. You'll have to play through the first match before you hit the breakpoint I believe. Let me know if you need help on how to do this.
Getting the SQLite data provider to work with Visual Studio 2017. I.e. when adding the EF model there is no option to specify a "SQLite" database connection. Well, some saint of a guy did make a toolbox that does that but I encountered a problem with it, so the only working thing I got is with Visual Studio 2015.
Execution always returns **back to the caller**, even if the return type is void. The only exception to this is, well, when an exception is thrown and it isn't caught lol.
How so?
Thanks for the hints. I'll try and take in everything you've suggested. :) In my defence, the naming standard issue is simply down to me cobbling code together from different sources and not changing things until it works. And by that time, I've ... er... forgotten about the namechange things, and VS doesn't highlight the issue as the code overall works ok. As for using names like "btn" instead of "button", well... trimming down variable names to shave off the bytes and create faster code is a hard habit to break.
Depends on what is the container object. If the button is in a grid you can change the column and row it's in. If it's not stored in columns and rows you can change the buttons margin value.
Yeah, thanks alot. I already got the answer from previous comments by now, but this is a really comprehensible explenation as well. Had i seen this first i would've also understood it too, thanks for the contribution!
You would want to use the [Web Authentication API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Authentication_API) which is an open standard (draft) supported by all major desktop browsers (Edge, Firefox and Chrome). https://www.infoq.com/news/2018/05/firefox-web-authentication-api https://blogs.windows.com/msedgedev/2018/07/30/introducing-web-authentication-microsoft-edge/#VLp8toyKoLPqTBT2.97 https://www.chromestatus.com/feature/5669923372138496 
Yeah indeed, i figured by now, when the ppl realised how newbie i really was i got thourough explenations. And yes, it really needs to be cleaned up. I literally started coding 2 days ago, and i have tried to keep it clean/comment out stuff on the go to make it organised and managable, but i am not very good at it. I just end up coding spaghetti even though i try to keep it clean. I guess i just need more excperience and practice to code clean and managable code.
Hey man, thanks for replying. That's what I tried but I just can't. Sorry if this sound stupid, I'm new at WPF. I'm trying to make a simple game, and I want to move my player(a button) according to my speed int value = 5, How can I do that?
Thanks for that. We already used auth0 on the standard login but these are additional areas that are encrypted and we want to add another layer - They are already logged in (\[authorize\] is used) but these additional areas are password protected. Guess we might have to roll our own logic to validate the key. thanks for the links. I'll take a look at the api and see where we can hook in.
The is for the link!
All of this is solid advice. 10/10 very yes.
Since no one has mentioned it, you can set a watch on the variable to see when it changes: https://docs.microsoft.com/en-us/visualstudio/debugger/watch-and-quickwatch-windows?view=vs-2017 
C# is compiled and the compiler does not save variable names. It’s all just IL. Shorter variable names have no impact on performance. Much prefer readable variable names over abbreviations
Visual Studio 2017 Community Edition is what you're looking for concerning the IDE or 'what program you need to work on the projects'... [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/) &amp;#x200B; C# 7.3 is amazing. Enjoy!
https://docs.microsoft.com/en-us/dotnet/csharp/index and https://visualstudio.microsoft.com/vs/community/ are the 2 links you need. 
Thank you!
Thanks so much!
In WPF that might be a chore. You'd have to make a timer object with a constant interval and change the button's margin value. Issue here is you'd have to contend with threading and dispatch due to the way timers work in WPF. I'm just on the phone so I won't be able to show you any code sorry.
 playerGuess is initialized to 0, and randomNumber is between 0 and 25. This means it is possible for randomNumber to equal 0. Since you compare the playerGuess against randomNumber, then sometimes the user will "win" the game without ever entering a guess.
Awesome Ill check them out!
If the user enters a string for a guess, the program will crash.
There is... Get the right nuget package. Microsoft supports it.
Yeah, I'm going to add a message for when the player doesn't input an int. Thanks!
If the user guesses incorrectly 2,147,483,647 times, the program will crash. &amp;#x200B; HAHAHAHAHAHAHAHA!
I'm sure that won't happen anytime soon :P.
[pluralsight](pluralsight.com) is a great resource as well. It’s $30 a month, but it’s well worth it in my opinion. They have classes on a wide range of topics and skill levels. They have a 10 day trial so you can cancel if it’s not for you. Regardless of what path you take, just know there will be challenges and it will be tough, but keep grinding and keep learning. Good luck!
To be honest, unless you have an agreement with the site to scrape their data and/or they say it's cool to scrape their data, it's generally considered not cool to scrape a site's data. Also, please don't use single characters for variable names. :D
If the user guesses in the second try it will say that he did it in 1 try, you should put tries to 1 since he cant guess in 0 tries
Ok, thanks.
Line 22 and 44: You can use string interpolation. e.g.: `Console.WriteLine($"You got it with {tries} tries!");` 
Thank you!
Yeah, it is spaghetti code, but you are new so it is OK (for now). You'll eventually get in the habit of writing cleaner code -- that comes with experience. I wrote Tetris in VB.NET when I started and, while it *was* Tetris, the code was **absolutely horrendous**. I think I still have the source code for it too. Code should be written such that it is *self-documenting*. Self-documenting code can still be spaghetti code, though. Spaghetti code is unstructured, "all over the place", etc. You did a good job on some things but you lacked in other areas. For example, you have a `turCounter` field and a `turcounter()` method -- make it so you don't need to differentiate by case. Also, a `bool` doesn't best represent which player's turn it is (like you did with XorO), even if there are only ever two players. You can use an enum like this: public enum Player { X, O } Then, you can do something like this (... means omitted logic): var currentPlayer = Player.X; ... btn.Text = currentPlayer.ToString(); //sets text to "X" or "O" currentPlayer = (currentPlayer == Player.X) ? Player.O : Player.X; CheckForWinner(); You should also create a class that represents and **encapsulates** the state of the board. Assume we've written such a class, we can do something like this: var gameBoard = new GameBoard(); gameBoard.GameComplete += (object sender, GameCompleteEventArgs e) =&gt; //this is called a lambda expression) { MessageBox.Show($"The winner is {e.Winner}!); ... StartNewGame(); } ... gameBoard.SetValueOfCell(5, currentPlayer.ToString()); There is more that can be done to clean it up. You may also want to look into the **Model-View-Presenter (MVP)** architectural pattern for WinForms. Its purpose is to separate display logic (i.e the GUI) from business/domain logic (like the gameboard class, flipping the current player, etc). Also, google *where* to place class members in a class file by convention. For example, here is how I structure my class filed (not every possible class member is described): //all using statements namespace TicTacToe.Client { public class GameBoard { //private STATIC fields //private FIELDS //public EVENTS //public PROPERTIES //private PROPERTIES //static constructor, if applicable (rare) //constructors, sorted by least number of parameters to most public GameBoard() { ... } //public STATIC methods //private STATIC methods //public METHODS //internal METHODS //protected METHODS //private METHODS //nested types private class MyNestedClass { ... } } } Hope this helps.
Thank you! I'll fix that :).
You can just write, " else Console.WriteLine("Lower!");" because if it ain't higher the only thing it can be is lower
I know this one is meant as a sort of joke, but by limiting your user to only being able to enter a number between a specific range, or at least being incapable of entering a number larger than the max for the Int32 variable you assign their input to, it shows you understand the limitations and sizes of the integral types you're using and account for them in a clean manner. One of my favorite adages in programming is, "Programming is a race between software engineers to build bigger and better idiot-proof programs, and the Universe to build bigger and better idiots. So far, the universe is winning." That, and never underestimate the power of inquisitive idiots. :P Not to mention a good tester will file a bug for this sort of thing.
No. It could be equal.
If the number is the same it wont enter the while loop, think about it
Try catlikecoding for good c# and unity tutorials. It's all in text and images (no wading through video speel) and concentrates on good Unity coding. C# in Unity is more like a scripting language if you are just starting out concentrate on the Unity API and just getting stuff to work as behaviors. "Real" engagement with C# as a library and the extended toolsets are minimal.
Along these lines, if a user enters a guess larger than Int.MaxValue, it will cause an error.
In my mind i already changed the while loop to infinite and put an If the number is same, break; i forgot to mention that :p
In my mind i already changed the while loop to infinite and put an If the number is the same , break; after the input. i forgot to mention that :p 
I was in the same boat. Unity has really good tutorials even for just learning C# basic syntax Just start watching their learn C# videos. https://unity3d.com/learn/tutorials/topics/scripting/coding-unity-absolute-beginner?playlist=17117 https://unity3d.com/learn/tutorials/s/scripting You aren't going to retain it all at first but the goal is to give you a basic foundation. When you think you sort of half understand what's going on jump over to the project tutorials. Actually using all the bits and pieces and seeing other peoples code will help you actually understand it. Do the rollerball tutorial, then space shooter then survival shooter. https://unity3d.com/learn/tutorials Even if you don't fully understand and feel you are just typing what you are told push forward and finish. If you get stuck on a compile error look for what you did different from the tutorial, then start googling, then post your own question. Some where in the middle of the survival shooter tutorial a lot of stuff started to click and make sence for me. Don't get discouraged. If you get stuck for more then 4 hours take a break.
It's all good. :D
Thank you! With all these resources I almost feel like the books I got might have been redundant
&gt; start writing clean and understandable code that will assist you in understanding what's wrong with your code and also allow other people to understand your code easily. When you are first starting having a comment after every line explaining what the previous line does in plain English is a great learning exercise. It's a little excessive but starting out it forces you to stop and understand what you just copied from a tutorial. 
The unity books are out of date within 6 months. They still have a lot of useful info but the free online material can teach you almost everything. A good class with someone who can answer questions and critique is worth doing after you see how far you get with self study.
Check out Brackeys on Youtube
Please put braces around your if/else blocks. &amp;#x200B; [https://softwareengineering.stackexchange.com/questions/16528/single-statement-if-block-braces-or-no](https://softwareengineering.stackexchange.com/questions/16528/single-statement-if-block-braces-or-no)
Removed: Rule 2. What you're doing may not be permitted by DuckDuckGo (especially given the blocking). You can read more here: https://duck.co/help/company/partnerships And otherwise, maybe you'll have to contact them if there's a good way of doing this.
Ok Ill check it out thanks!
He's right on the explicit cast, it will make your error go away, and it's a good idea. But please note that this is doing integer division, and not floating point division. The result's remainder will always be truncated, so: 18/6 == 3 (which there's no rounding, so that's fine) 19/6 == 3 vs 19.0/6.0 == 3.1666667 (and this would have rounded down anyway) 23/6 == 3 vs 23m/6m == 3.833333 (this should have rounded up to 4) &amp;#x200B; So there's a point where the average should get rounded up, but with int/int (or long/int, long/long, etc) division, the truncation happens automatically. And if your results don't really care, that'll work fine as you have it. If you want the precision, you could be super explicit on what you want it to do: `double avgB = Math.Round((double)totals[0] / (width * height), 0, MidpointRounding.AwayFromZero);` `decimal avgB = Math.Round((decimal)totals[0] / (width * height), 0, MidpointRounding.AwayFromZero);` * you only need one side to be a floating point number for it to change to normal division * This also allows you to choose the midpoint rounding. The default rounding of a midpoint in c# is 'to even', so 3.5 rounds to 4, where 4.5 also rounds to 4. It's also referred to as banker's rounding, since it's used to statistically even out all roundings over lots of number operations. * decimal vs float vs double you can google * You could make your 'totals' array a float/double/decimal, and add integers to it all day And then you can still output it as an integer with a second line, or by adding on another step within the same line: `int avgB = (int)Math.Round((double)totals[0] / (width * height), 0, MidpointRounding.AwayFromZero);` &amp;#x200B; `decimal avgB_decimal = Math.Round((decimal)totals[0] / (width * height), 0, MidpointRounding.AwayFromZero);` `int avgB = (int)avgB_decimal;` &amp;#x200B; And if you really are worried about overflows, you can compare the value against int.MaxValue before explicitly casting it, or like xampl9 suggested, add a try/catch around the cast to catch overflows. 
I created a [gist](https://gist.github.com/prajaybasu/b84370c1a39622e3016dbbfd9103cdad) with my suggested improvements: * Use `const` for constants * `var` instead of full type names * Don't initialize a new variable if not needed * Use `while(true)` to make it clear that the loop is infinite (since you don't have `maxTries`) * Use `int.TryParse` instead of `Convert.ToInt32`(google for differences) * Add input validation by checking the result of `TryParse` using the `continue`keyword 
You probably want to use a [canvas](https://docs.microsoft.com/en-us/dotnet/api/system.windows.controls.canvas?view=netframework-4.7.2).
😂
There are loops with entry-conditions and loops with exit-conditions. In this case you want your loop to execute at least one time, so you'd use one with an exit-condition (do-while).
your response could be read as a pun lol
I think implementing our own FIDO2 server is not the way to go. Long term that would be a pain in the ass to support. We'll do some reading and figure out a simpler way to integrate this even if it means changing our login process. &amp;#x200B; Thanks for the feedback. cheers,
IsGuessedValueCorrect() should not write to the console as you don't expect it to do so from the method name
As others have said, focus on learning the language before any specific game engines like Unity. If you don't have a good foundation in the basics of the language you will just get frustrated when trying to learn how to apply different concepts that are required to create a game.
The great thing about WPF is binding UI controls to properties in the code. You can bind your text box to a string, where your string is essentially your log, and it will update the UI control automatically. If you’re logging multiple lines you can use an ObservableCollection&lt;string&gt; and bind a listbox to it, so each new line of your log is its own line in the listbox (fully scrollable too). Writing this on mobile so I can’t really throw in a clean example, but I’m sure if you look up how to bind a textbox or listbox to a string or stringcollection you’ll find what you’re looking for. 
Your answer was spot on! Putting it in the Loaded event was the key. Thanks for helping me out!
No worries
Why not use .Net core with the react template? Everything you need is already set up for you. 
I can't use Core at work. Do you think it's possible to convert that solution to work on .NET 4.7?
Why not just [call the DLL](https://github.com/golang/go/wiki/WindowsDLLs)?
Isn't this exactly what WCF if for?
I’ve done the same as this before and works nicely. My service class that does the work fires an event each time a file is moved and that gets added to the ObservableCollection&lt;string&gt; and data binding takes care of the rest. 
Why do you need to use UDP if standard in/out is working already? You can use standard in/out same way. You need have dedicated reader and writer threads to send and receive messages asyncronously. When c# console app receives request message from standard input and it creates a task and starts listening for next request. When task is ready it sends response message that includes request message id so response can be matched to request, to standard output. System.Threading.Tasks.Dataflow.BufferBlock will help you, here is some info https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-write-messages-to-and-read-messages-from-a-dataflow-block Then do similar system to Golang side using goroutines using channels.
creating a full WCF to wrap say, 5 dotnet library is kind of a bit overkill. I needed something that can be used without me having to create more C# code.
Really depends. Projects are removed, files are deleted.
If you're dealing with .NETFX, you can directly call .NETFX via its API and just use the assembly as usual. There's also [DllExport](https://github.com/3F/DllExport) which, if I am not mistaken, allows you to directly call .NET methods in a DLL from native code.
Can you write a little bit of C# code? I'd work with CodeDom and reflection to generate whatever wrappers you need :) that way if something changes you could regenerate your wrapper within seconds
This is an option. But one aspect of UDP benefit would be that the Go app can be deployed on a non-Windows OS. But I admit that the standard in/out is kind of nice at the moment. I'll see how this evolve.
it's not for dotnet-core no. DllExport seems to be good if you have a little number of function. In my case we're talking about 10-15 years C# data access and business rules libraries with multiple methods. That would be WAY too long to turn all those methods into native using their attribute. I prefer my &lt; 100 line of C# code which is far from complete but works with ALL .NET libraries without modifying 1 line of those legacy libraries.
I am not a game dev but I would recommend looking at the storyboards and animation space in WPF. 
The first solution also doesn't require changes to any of the libraries.
There's nothing strange here. You have three objects: oldInstance, ins1 and ins2. PrintString method of these objects returns value stored in \_stringToPrint of that same object. For oldInstance that value is "oldInstance", for other two it's "capturedString". MethodFromOldInstance sets Action to PrintString of oldInstance, which naturally returns "oldInstance", since that's stored in it's \_stringToPrint. Setting Action to PrintString of another object, will return value stored in that object. MethodFromNewInstance sets Action to PrintString of ins2, which stores "capturedString", so that's what it returns. &amp;#x200B;
The most newb friendly (commercial) book that I know is C# - Player's guide. It covers most language features (including the newer features (7+)), and the common classes from the standard library (I/O, Threading, Collections, Linq)
Sorry, I should explain more. I use Visual Studio, and i'm currently working on asp.net applications. it will have an MVC "template" that creates the folders and views and controllers for you. i may be putting those with paying programming jobs on a pedestal, but I figured when you have an actual job, you have to create the folders and routes by scratch. 
Rider is not still consistent as Visual Studio. There's still missing features in Rider and VS is mainly for Windows and Mac (partially). I'm mainly using Linux rather than Windows.
I'd say it depends on the task really. It's the same thing with APIs. Theres no need to invent the wheel twice.
Nope, you just tend to have your own templates that you follow as a company. The default templates are perfectly fine though
Stack allocated memory isn't collected by the GC, so the size of the span itself shouldn't directly make a difference. The main allocations here seem to be the strings allocated by `Convert.ToBase64String` and `stringBuilder.ToString`. The string builder seems to be completely superfluous, and the base64 string could be avoided by using one of the `ToBase64` methods that take a destination char array or span. Don't know why `1024 * 30` happens to be the threshold though. This should turn into a ~82kB base64 string, which is close to but not quite at the LOH threshold of 85 kB.
I've done this to integrate C# with R. It's a pretty seamless experience unless you end up using a cloud host that doesn't let you do such things.
Thanks for your detailed reply. I've always thought methods to not be bound to instances but to classes, which is true because that's how they're stored in memory. You stated that referring to an unqualified instance member implicitly refers to the instance that's \_currently executing the code\_. In both cases, the same instance \`CaptureFieldsTest\` is executing the code. When using \`inst.PrintString\` doesn't make the executing instance to be set to \`inst\` or am I wrong? &amp;#x200B;
As I said in the other reply, methods are bound to classes and not to instances, so I didn't expect a method (actually in this case a delegate) to need to store a reference to an instance. What i expected naturally is that the method will not capture anything but will use the instance it was called on, that is when I call \`[ins1.Run](https://ins1.Run)()\` it should run on \`ins1\` and for \`[ins2.Run](https://ins2.Run)()\` it should use \`ins2\`.
Thanks Sure enough, after removing the string stuff, we get stack overflows when increasing the size before the GC collects constantly (which is what I was going for): public unsafe void LogWrite(StreamWriter stream, RandomNumberGenerator rng, CancellationToken token) { Span&lt;byte&gt; data = stackalloc byte[1024 * 256]; Span&lt;char&gt; chars = stackalloc char[2048 * 256]; rng.GetBytes(data); var success = Convert.TryToBase64Chars(data, chars, out int bytesWritten); if (success &amp;&amp; bytesWritten &gt; 0) { stream.Write($"test @ {DateTime.UtcNow.ToString("o")} -- "); stream.Write(chars); stream.WriteLine(); } else { throw new Exception("TryToBase64Chars Failed to write"); } }
&gt; Some very subtle implicit compiler magic No, it's really not. This is basic c#. &gt; When using `inst.PrintString` doesn't make the executing instance to be set to `inst` or am I wrong? You're not executing PrintString there, you're referring to inst's PrintString method (or in the other location, this's PrintString method). `.PrintString` is just a reference.
StringBuilder would probably cross the 85KB threshold since it is a linked list of StringBuilder instances so it has a slightly higher memory overhead. 
I’d say the Windows Service template leaves a lot to be desired since it doesn’t come setup with any scheduling mechanism. 
It might be simpler to use a prewritten component such as NlogViewer? [https://github.com/erizet/NlogViewer](https://github.com/erizet/NlogViewer) ? Then you just log using NLog. 
I’ve found that for modifying templates provides more consistent projects across the different developers on my team. There are common libraries like log4net and slowcheetah that we use on all projects and this just removes the chance of a developer missing it. 
Can you expand what do you mean by this? &gt; If you're dealing with .NETFX, you can directly call .NETFX via its API and just use the assembly as usual.
I've done that. It works with every language. Java, node, python, whatever.
This is absolutely perfect! I'd used NLog 1+ year back and completely forgot about it til now. Good shout!
I’ve actually been creating templates for the other devs at work. I’ve made a template for 2 different styles of WebAPI projects and I’m working on one for MVC projects. These templates allow for a very fast start on new projects, as well as a consistent setup for our logging, security and data access standards. 
This is how I have my project setup. I’ll have to build my UI code using Cocoa, of course, but it looks like I can at least write services using a limited subset of the .NET Framework. Amusingly, it seems System.Drawing is not yet stable, which is precisely the dependency I needed for reusing personal libraries for this specific project. I guess I’m just going to have to give in and become more familiar with Cocoa than I’d hoped. An annoyance in the short-term, but probably healthy for professional development in the long-run, so I’ll try to focus on the silver lining. Thanks!
Go is a beautiful language!
Nice that you are learning c# and playing around with it, doing something for fun is a great way to learn! Over the years I have learned that maintainability is the most important thing to have in mind when programming. What I mean with that is that you should code in such a way that someone else should be able to read your code and understand it quickly, even yourself after a year or so. Do not bother with optimizations and trying to make the code short, longer better structured code is easier to maintain. For example create methods and classes that handle a specific task/data. You have a good start here, read about object oriented programming techniques, check out some basic patterns like SOLID. 
You will probably want to use something like a producer consumer pattern where your producer handles incoming UDP packets and your consumer writes them to disk. There are many examples of this on the web. [Blocking Collection](https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.blockingcollection-1?view=netframework-4.7.2) is perhaps easiest. [Microsoft docs](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-implement-a-producer-consumer-dataflow-pattern). [From the author of C# in a nutshell](http://www.albahari.com/threading/part4.aspx). 
why do you think there's a memory leak in your code? this is C#, not C. It's possible to intentionally leak memory, but it's not going to happen on accident in a tiny app.
Instance methods are declared on a type, but are executed on an instance of that type. You happen to have a specific example here where the type that invokes the delegate happens to be the same as type on which the delegates target is defined. In general this will not be so - what about cases where the caller is a static method, or a method declared on an unrelated type? As is the case in c# whenever you reference a local instance member, there is an implicit 'this' that the compiler lets you omit; So you can think of: inst.Run = PrintString as inst.Run = this.PrintString
I haven't read the entire thing yet, but... &gt; However, in C#, you need to specify the type of every variable in front of it like below. ...is only true if there is no right side to the expression or if you want an integer type *other* than `int`. These are perfectly valid in C#: var age = 12; // compiler will determine age is of type int var name = "Lara Croft"; // compiler will determine name is of type string
Yes. That's right. I covered that later. And I think many developers prefer specific types rather than `var`. int age = 12; string name = "Lara Croft";
Not really, for forms use double buffering 
Using the var keyword is preferred because it save you an extra place to edit if the type of the variable changes. var age = 12; —— Later... var age = “Twelve”; You still have all the other benefits of static typing. It’s just lesser keystrokes to type.
In most examples and projects, I thought specific types are more frequently used. Thank you for telling me. 
Yes, what you are doing is called RPC. A more formal way of doing this js to use a named pipe.
\&gt; decimal is usually used when accuracy is extremely important Money is the typical use case scenario for decimal. You don't want rounding errors there.
Just to pitch in I think examples tend to not use 'var' because its easier to see at a glance what type it is when you don't have all the code or using statements readily available to you as a reader.
You use `decimal` when you want an **exact** amount. You use `double` when you want a **large** range, but the exactness isn't crucial.
Is there a JS for C# dev?
Right. It's a trade-off between correctness and largeness. 
Thank you /u/VGPowerlord /u/compgeek78 /u/Havenoodswillshare! I edited about `var` in the post!
I've never thought about the sub-cent situations. I thought money can always be integers. 
I'd start with trying to profile your write patterns to the DB. Write a dumb console or xUnit test that will create 10 tasks to save 10,000 test messages to your DB (task.whenall(mySaveTasks)), then try to tune that. Benchmark or Stopwatch that and see what you are getting. Are you utilizing partitions across different physical disk? If not, consider partitions for your tables. I find a lot of people are just completely oblivious to the concept of partitions. RDBMS is not always the best solution, either. I'm not a MySQL expert, but support seems to be there and should be investigated for your problem. Producer/consumer or pub/sub as the_other_same mentioned is probably the route to go with software structure. I'm not familiar with OpenPDC enough to understand how well it is actually doing aggregation for you. Sounds poor-ish, or only really at a low level. But aggregation could be a solution you need to investigate to improve DB write performance if you've done all you can with the write tuning. Any data saving function you have may need to consider aggregation. Also not sure I know enough about the data you're taking in or the target structure to suggest more here. Some of these problems are easier to deal with using publisher/broker/subscriber so you can get the different pieces balanced and scalable across multiple host machines. Unsure if your problem is sufficient to require that. 
You will probably want to batch your database writes - save N seconds worth of data and send a SQL batch with a single multi-row INSERT statement. INSERT INTO x (col_a, col_b, col_c) VALUES (1, 2, 3), -- Packet #1 (4, 5, 6), -- Packet #2 ... (997, 998, 999); -- Packet #N 
You should only really use var in the one use case where it is required, or where the type's name is long. You should never use var when the right side is a method, only when you are calling a constructor directly.
Yes, users in this subreddit is fantastic!
&gt; var entity = ... // some database query What is the query? Are you sure it's not returning an enumerable? &amp;#x200B; &amp;#x200B; &amp;#x200B;
I'm already kinda doing that except the source of data is not the memory but the file written to the disk. I should try that though, maybe the time saved by not doing disk ops overweights the bonus of doing the load data local infile query..
&gt; maybe the time saved by not doing disk ops overweights the bonus of doing the load data local infile query I guarantee this is the case.
Your private backing field is a bad pattern. You can have a private set: public string GoodString { get; private set; }
You use `decimal` when you want an exact amount in **base 10**. You generally use `double` when you don't care about the exact representation in base 10 because it's performance is better.
I'd suspect wpf is being a bitch about when and where it has a sane default binding mode behaviour. , Mode=TwoWay otherwise i'm at a loss too 
Former Microsoft MVP Bob Powell's website is a treasure trove of tips for winforms graphics. He took it down and currently it's a spam site, but thankfully you can still access all the old stuff through archive.org: https://web.archive.org/web/20111230011843/http://www.bobpowell.net:80/Default.htm 
This isn't really true as the case for using implicit typing vs explicit typing is code readability. Explicitly defining a variable becomes a limiting factor especially when writing code that uses some library beyond your control. For example if you are calling some method that returns a list that your are then iterating over, if that library changes its return type in some future release your code will break, if you use var however your code will be fine. &amp;#x200B; Doing everything explicitly will still work, you just may face a lot of issues down the road especially if your code base is fluid and there is more than one developer.
Ugh. I definitely need to study this in depth, but I'm pretty sure that I've got a project that is doing this wrong. Unfortunately I left that company years ago so there's no way to fix it.
ExpandoObject and Dynamic have their uses, but this can lead to quite complicated code especially if you are new to C#. It can quickly lead you down the reflection rabbit hole, which is an incredibly powerful feature, but can also lead to complicated code. What you look at one day and say is perfect, in 6 months you won't remember why you wrote it or what it does, just that it broke somehow and will now tear your hair out trying to troubleshoot it. I would lean towards removing dynamic and ExpandoObject from the tutorial entirely or put it at the end.
In chapter 4, you say that object is object and dictionary is dictionary. This is not really true as dictionary extends from object as any non-primitive types.
There is no special kind of JavaScript for C# developers, isn't it? 
In the functions section, you should make mention of private, protected, and public and the differences between the three.
Learn to read and correct your own sentences in 5 minutes :D &amp;#x200B; For real tho, good think for beginners :)
Apologies for the late reply, had to enjoy the weekend :D As for your question, you are right to check the boundaries before doing anything. In addition to that, you don't really need all those if conditions to check if a path can potentially lead to a solution. In order to solve the problem of the maze "undoing" the correct path with Os, you can return a boolean from the method that says whether this path leads to a solution or not. With these observations, your function can be written like this: `private static bool mazeTraversal(char[,] maze, int row, int col)` `{` `if (row == maze.GetLength(0)` `|| col == maze.GetLength(1)` `|| row &lt; 0` `|| col &lt; 0)` `return true;` `else if (maze[row, col] != '.')` `return false;` &amp;#x200B; `// place an X` `maze[row, col] = char.Parse("X");` `PrintMatrix(maze);` `Console.WriteLine("\n\n-----------------------\n\n");` `bool canSolveFromHere = mazeTraversal(maze, row - 1, col)` `|| mazeTraversal(maze, row, col + 1)` `|| mazeTraversal(maze, row + 1, col)` `|| mazeTraversal(maze, row, col - 1);` &amp;#x200B; `if (!canSolveFromHere)` `maze[row, col] = 'O';` &amp;#x200B; `return canSolveFromHere;` `}` If you need more explanation on why this one works and not the other (after you try to understand, of course), let me know. Cheers. 
To be precise, they still have a strong type. You just don't have to explicitly type it down. Also var works with non-constant stuff too, like `var tst = new YourClass();`
Thanks. With your help I was able to find MSDN documentation about this behavior, which to me is not basic c#, but rather a special behavior of delegates when they're instance methods: ``` When a delegate is constructed to wrap an instance method, the delegate references both the instance and the method. A delegate has no knowledge of the instance type aside from the method it wraps, so a delegate can refer to any type of object as long as there is a method on that object that matches the delegate signature. When a delegate is constructed to wrap a static method, it only references the method. ``` I'm happy to have learned something new!
Thanks. Things are now clear to me. See my other reply for documentation about this behavior.
Typescript 
I believe it's even aliased as ``money`` in VB.net
I know it's just an example, but that "later" part made me throw up in my mouth a little bit 
I would not bring up `dynamic`/`ExpandoObject` at all, and definitely not in a beginner course. Seeing them is a code smell and only fits very specific use cases. I know that it is the closest thing to loosely-typed objects that C# has, but it's not worth the risk of teaching anti-patterns.
It looks a little strange when you only mention `short`, `int` and `long` as if those are the only integral types that exist. There are a few more. There are the signed ones: `sbyte`, `short`, `int` and `long`. Then there are the unsigned ones: `byte`, `ushort`, `uint` and `ulong`.
I think I worded that incorrectly. By later, I meant at a later date. Not later down in the same function. It should be an offense to provide code examples from mobile.
Maybe it's for printing on the screen as a word. Don't think so much into it. It was a very poor example, thought up at the spur of the moment.
Maybe it is ok to use something like apache thrift or gRPC, and then write small, console application for c#. You just need to predefine your api in separate IDL file. Advantages are that does solutions can use tcp/udp/inproc and some other type of communication between two processes or inside the same process. Application can be pretty small but you need library and generated code.
If you want type-safe JavaScript, use [TypeScript](https://www.typescriptlang.org/). It's also created by Microsoft and Anders Hejlsberg.
I heard that unsighed types aren't used a lot in real life. (Or is it just C++ convention?) That's why I removed that. I decided to cover it in my advanced C# article. But it seems that it isn't unnatural to add "These 6 types aren't everything. There are infrequently-used types like sbyte, ushort, unint, ulong." And linking them to MS doc. 
I think learning what it is, what is different, what can go wrong and getting warning is better than learning about that somewhere else and abusing it. And to emphasize this point, I decided to change "I don't recommend using it" to "Try not to use it at all cost."
I think this is terrible advise. In the local scope, the concrete type usually does not matter anyways. Usually i could not care less if ``peopleToGreet`` in var peopleToGreet = ListEmployees(); SendGreetings(peopleToGreet); is a ``List&lt;IPerson&gt;``, a ``Employee[]``or an ``IEnumerable&lt;IContact&gt;``. In the local scope, everything I care about is that the type returned by ``ListEmployees() ``fits into ``SendGreetings()``. Have you ever cared about the types of the stuff that gets returned by the more exotic Linq methods like ``GroupBy`` or ``ToLookup``? You don't just use ``var`` because the type names are too long to comfortably type (seriously, that's a very shitty reason), you use ``var`` because you don't actually give a damn about the fact that it's ``IEnumerable&lt;IGrouping&lt;TKey, TElement&gt;&gt;`` or ``Lookup&lt;TKey,TElement&gt;``. 
Decimal is 128 bit fixed point. It's almost exclusively used in monetary applications and completely overkill for almost anything else.
Damn. I still feel so out of my depth when it comes to async/await. I _get_ that there isn't going to be a silver bullet for asynchronous tasks, but the amount of caveats and the required level of understanding is a bit much.
Most of the problems aren't in async/await itself. Rather, they come when you start dealing with the raw Task, TaskCompletionSource, or TaskScheduler objects.
Good call on the return from set. But sometimes you have to do other things in a set. For instance, if there are other properties that are dynamically calculated based on that property, you might want to raise a PropertyChanged event. Or, maybe you need to do some input validation.... 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [C# for JavaScript developers: Comparing almost everything](https://www.reddit.com/r/LatexAndLoaf/comments/9kf0y8/c_for_javascript_developers_comparing_almost/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
It's not just about magnitude, also precision. Floats are complex, and lets not imagine we know shit about shit.
7 minute abs
&gt; Decimal is 128 bit fixed point. Decimal is quite obviously a floating point type.
Without any other details I'm assuming the user adds/uploads the 2 files through the UI somehow. You then want to manipulate the files and save the result back to their computer. Breakdown of things you need to figure out 1. [loading data from an excel file](https://coderwall.com/p/app3ya/read-excel-file-in-c) 2. [loading data from a csv](https://joshclose.github.io/CsvHelper/) 3. Create your own csv/excel file 4. Write it to disk You're basically going to create a couple classes that represent the data you're reading in from the excel sheet and csv. Load the data in. Create another set of classes representing the final result, manipulate the data, store it in the classes that represent your final result. Then iterate the data in the final result set, write everything to excel/csv file, then save to disk [Try](https://www.c-sharpcorner.com/UploadFile/6b8651/read-excel-file-in-windows-application-using-C-Sharp/) with this tutorial.
Yeah we ran into this too. Googling the issue led me to [this Stephen Cleary blog post](https://blog.stephencleary.com/2012/12/dont-block-in-asynchronous-code.html), and I'd given up hope that there was a solution, so we just worked around it by `Task.Run`ning the `SetResult` call. Providing `TaskCreationOptions.RunContinuationsAsynchronously` looks much better; thanks for sharing!
A procedural level generator for use with Unity https://github.com/valantonini/Promethean/blob/master/README.md
I haven’t used parallel.foreach. What are the most common scenario that you think is practical to use it to?
To be honest when I schedule any continuation manually (i.e. via `ContinueWith()`) I always (if I remember) try to assume it could execute synchronously *or* asynchronously and consider the consequences. If I recall correctly, even requesting that a continuation run synchronously is only a request; the scheduler can sometimes force a continuation to go async if it detects that the current synchronous-chain-of-callbacks has become rather large (i.e. there's a risk of a stack overflow).
I could have sworn it was fixed point, but it looks like you're right. 128 bit FP with 28 digits of usable precision. 
An atomics lib for C#; will be MIT-licensed.
Well i'm not the one opening threads :D &amp;#x200B; \^\^\^fml
For those unfamiliar with this unit of measure, one *mintue* is equal to 2,000 hours.
True, unsigned types aren't used very often. Just `byte, short, int and long` is probably enough. It just looks incomplete if you mention `short` but not `byte`.
Try not to use it at all cost, and if you fo you have to chop off a finger... Now you can use it 9 more times before you retire. 
Maybe. I almost never deal with projects that have been designed with async/await from the get-go; instead, they're a weird mishmash with bridging all over the place.
I believe you can set it for the entire controller.
This sounds like a better question for an Exchange admin group or something.
How many *smoots* can you run in a *mintue*?
Work smarter, not harder: int max = 50; Console.WriteLine( max \* (max + 2) / 4); &amp;#x200B;
No fun in Unity :( 
WPF couldn't find the DataContext in a nested DataGrid, and then I had to tell it what type to look for. &amp;#x200B; Stupid WPF
Yes. I've fixed the code I wrote above, now that I'm at my computer. Let's look at that. private string m_SomeOtherString; private string m_GoodString; public string GoodString { get =&gt; m_GoodString; set { m_SomeOtherString = m_GoodString; m_GoodString = value; } } So, in this code, for some reason (probably a stupid reason, but a reason nonetheless), I have to store the value of GoodString into two different private string variables. If I go with THIS method, that doesn't quite work out too well, as m_SomeOtherString never gets the value. public string GoodString { get; set; } private string m_SomeOtherString; ----- Okay, so that's a dumb scenario. Let's suppose that we're working with an application that is using data binding on a text box. That text box is using regular expression validation to validate that the user is inputting a valid IP address. But, let's suppose that this verification is client side (maybe we're doing some ASP.NET, and the verification is in JavaScript), so we absolutely need to validate that input. So, we accept a string variable. AND, since this is using data binding, the class implements IPropertyNotifyChanged. So, we have to raise that event. public class Test : INotifyPropertyChanged { public event PropertyChangedEventHandler PropertyChanged; private IPAddress m_IPAddress; public string IPAddressString { get =&gt; m_IPAddress.ToString(); set { if (IPAddress.TryParse(value, out m_IPAddress) == false) m_IPAddress = IPAddress.Loopback; PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(nameof(IPAddressString))); } } } SO. How do I do all of **THAT** with this methodology? public string IPAddressString { get; set; } Unless there's something crazy I don't know about - you can't. So, a private backing variable is necessary **sometimes**. Even if I wasn't also trying to parse the string, from what I can tell, as long as I have ANYTHING else to do in my get or set accessor, I can't use that format.
Warning just an assumption: ODATA is serving dynamic content, which can differ A LOT from the default response, from a usually static URL. Eg. /person/?select=address Whereas in REST-World you would have a /person/ which would give you a person and /address/:personId which would give you the address of :personId
You should give a damn, giving a damn can be the difference between code that works and is easy to maintain, and code that doesn't work and is hard to maintain.
It doesnt have to be monithic. I'm currently building a Vue app based on the template but the Client App is 100% disconnected from the back end. The back end serves as an API and nothing else. 
&gt; It's also because of the books that don't use var much. Microsoft used to recommend, to use `var` almost exactly the way you described it, basically just for LINQ results, and anonymous objects. I believes it's because it can have some pitfalls like replacing `double a = 1` is diffent semantics than `var a = 1`. But `var` is much more used in practice than that, and current tools provided by MS recomend to use `var` in a lot of cases, and apparently their stance changed on that. See: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions#implicitly-typed-local-variables 
&gt; dictionary extends from object as any non-primitive types Primitive types also inherit from object. https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/types/
You should calculate what you'll need to keep up with the inbound data, and then run performance tests on your loading methodology to see if it will keep up. Loading a file from disk with a MySQL native loader may be pretty fast, hard to say, though. Consider the data set you're loading though, and the impact of not just the raw data write, but index writes. The way you aggregate your files may impact speed. Appending a few different files (or in memory dictionary) as an aggregation may be a good way to speed up loading, but how you split up the data can matter, and also how you optimize the target table's design. 
It's a shame asynchronous continuations aren't the default. 
I'd recommend creating a new user control that inherits from a panel control, override the onpaint method there and draw using the GDI graphics context you can obtain via Graphics.FromHwnd(this). I prefer drawing onto a control over drawing directly onto the form because you can put a control onto a form... but it's harder to embed a form within a form... 
I started working on a workout tracker using WPF. I am quite new to programming and C#. Now I am feeling overwhelmed due to all the MVVM concepts. To make life even more complicated, I used Metro framework for the UI and NHibernate for the database. And now I’m feeling thoroughly lost amidst everything. I’m tempted to reset the project and write it using simple WPF controls. But can NHibernate be replaced with Entity Framework? I’ve used the latter for web development at my internship and I’m already familiar with it. Is this even possible? Can EF work with WPF and MySQL? Is it a good idea to write a Windows application today with the OS native appearance?
&gt; if you use var however your code will be fine. Don't quote me on this but I think it depends. If the method you are calling is defined in an external library, I am 90% sure the consuming library will have to recompile if you change the return type from, say, List to IEnumerable. When using `var`, you are telling the compiler to figure out the type for you (not the runtime). What I am suggesting is that you won't be able to swap out that 3rd party library that changed the return type of a method *without* also recompiling the consuming library *because* the consuming library was compiled such that the `var` was replaced with the appropriate return type of that method *when* the library was compiled. If the method's return type went from general to more specific (i.e IEnumerable TO List) you might be fine since your library is expecting IEnumerable still. Once you recompile against the new version, however, it'll be using List instead.
Visual Studio for big projects, Sublime with CLI tools for smaller projects. I personally think that learning new things with a simple editor without extensive autocomplete is more beneficial long-term.
The conference looks really interesting: does someone know if the talks will be live-streamed or available on a streaming plateform ?
It was a perfectly fine example. 
Every Senior Developer spec I've seen has varied hugely, and I'm in a similar place to you (4.5 years). For some it's a manager position, others just a dev position with more clout - ignore the job title and read the requirements. Also bear in mind that it's an employee's market, employers will bend over backwards for a proven competent dev, regardless of how exactly you fit what they 'want'.
Sure, it’s a matter of taste. I use it everywhere possible. Of course this does increase the requirement for using an IDE. 
I don’t see how that’s obvious. Depends entirely on the need. 
It depends a lot on the person writing the code. 
Whatever works for you, but other people’s mileage may vary. 
&gt; if that library changes its return type in some future release your code will break, if you use var however your code will be fine. No, var is strictly a compiler feature that doesn’t exist in the CLR. It *is* true that you might just need to recompile to get it to work again, so a bit less work. 
Yeah, make that 100% :)
I helped two of my junior devs (fresh out of college) move into "Senior" roles in 2 years. The key is not years of experience. From my perspective the key is a track record of being able to: * Design applications from the ground up (I don't mean UI, I mean code) with a design that not only works but is expandable for future versions. * Communicate this design vision both to a team of programmers and to business people to get business team buy-in on the work and ensure that you have business team signoff on the design so that they can't claim later that it's not as described. * Lead one or more less senior programmers through the programming work, delegating parts of it appropriately and ensuring that delegated work can fit into the framework to become part of the program as a whole. My guys were exceptions: in general I expect to see a senior programmer applicant have had at least one mid-level job at which they demonstrated the above skills to show they're ready to move up.
You can even use the new dictionary initialization syntax too: `var x = new Dictionary&lt;string, int&gt;` `{` `["key1"] = 1,` `["key2"] = 23,` `};`
Them keyboard shortcuts. Hnng
I use visual studio and vs code with the vim plugin 
Is there any aspect of `async/await` where doing the naïve thing doesn't result in risk of deadlocking or poor performance? It feels like outside the very narrow use case of "only use `async/await` in top-level UI code and never anywhere else" it's a lot of trouble. And even if you're appropriately using `Task&lt;T&gt;` at the lower, non-UI layers, you still have to remember to `ConfigureAwait(false)` everywhere for performance/to avoid deadlocks. In both C# and JS, I find dozens of articles that suggest, "This feature's great! But if you want to use it, be sure to write these 25 or 30 boilerplate helper functions to avoid deadlock." I never had this much trouble debugging asynchronous code when I used the Event-Based Asynchronous Pattern. 
I like your scenario. Yes, that's where it makes sense to create your own backing field.
And this, my friends, is civil discussion!
Are you specifically looking at C#? 
Checkout Omnisharp for Vim/Emacs omnisharp.net
0xff360465, 0x3a28213a 0x12479484
Thanks everyone for comments! &amp;#x200B; It turns out, that frontend folks do not need docs, because "they know what they're doing", so it's not my problem anymore :DDD
Removed: Rule 4. Check out the sidebar, and learning resources at /r/learncsharp and /r/learnprogramming.
We are considering it, but i can't give you any promise :(
Even as a beginner Visual Studio is supreme to any other editors for C# Unless you arent on Windows OS
In dotnet core .ConfigureAwait(false) is no longer an issue since ASP.NET doesn't use contexts anymore for requests, so that's nice. The biggest caveats of async/await are avoid .Wait()/.Result and use TaskCreationOptions.RunContinuationsAsynchronously unless you have a reason not to. Beyond that your typical dev doesn't need to worry.
Try explicitly changing it to 1080p. Not completely sharp, but reasonably so for me. (Not that I really want to see `ArrayList` pop up ever, ever, again, not even in a video.)
Visual studio is free and if you intend to be a professional c# developer (I know - not everyone does) you will need to know visual studio. So I don't know why you wouldn't use the best tool for the job.
(don't read in sarcasm, this is a serious question) why is it more beneficial? It's not like there will ever be a time where you don't have an ide with autocomplete to work with and it's not like the syntax of a foreach or for loop are so difficult that you need to type them out. 
Knowing your language and libraries is a given, at senior level. What's really needed is how to mentor team members, interact with people outside the team ("I have people skills, dammit"), and the delivery/deployment process. 
So I'm made a simple game on Unity a few months ago and it works fine on PC but there's a minor issue when I convert it into an android game. If anyone is interested to help, please drop a DM.
As someone with 16 years of C# experience, Visual Studio is supreme.
I’ve used LiteDB for an interview programming task. I found it easy to get started with and quite nice to use. I’d definitely recommend it for trivial tasks.
To me, a "senior" developer is someone who has: * earned some level of authority within whatever domain they are a developer in, generally through a significant amount of real-world experience in developing things in that area * built up a significant amount of general knowledge academically through book reading or classes - so in addition to knowing the ins and outs of their domain well enough * aware of a variety of approaches and possible solutions to problems that they can also consider * communication skills to convince a room full of developers of the soundness of their plan of action * proven ability to follow through with said plans reliably the upshot of all of these things is that this developer can take point on some difficult and important problems for the team, and leave the team (and management) feeling confident that the solutions to those problems are in good hands
Yea i did a poor job of wording that. You are right, it will need to be recompiled. I meant it more as, the dev wont have to go through the code base and manually update the explicit typing at each location it is used.
*Being a lead/architect on a complex solution *Effect change on your team by helping implement new processes/coding standards *Consistently, and reliably deliver **quality** work on time *Has been a mentor to junior developers *Knows when to call BS/ask more questions and isn't afraid to do so 
I recently started working on a C# client for Apache Kudu. I'm still experimenting with it mostly. I'd like to get it fully functional and production ready, but that's a ways off. https://github.com/xqrzd/kudu
Thank you for elaboration. Actually, I first learned C# almost right after 3.5 released. And I had almost no chance of using it for a decade and decided to review and learn it again to make a Unity development blog. It seems that my knowledge about C# was somewhat fixed at 10 years ago. 
Thank you. I also added that.
Good for people who are already very familiar and efficient with sublime+cli. You'd be amazed at the development speed you can achieve with it. &amp;#x200B; HOWEVER refactoring classes, renaming members etc are just better done in an IDE. I would personally never recommend sublime, I think you should stick with an IDE at all times if possible
It’s not that it’s wrong but for a complex ecosystem in larger firms, micro services are much more ideal. Monolithic is kind of the exact opposite of a service oriented architecture/micro service architecture- So you lose all the benefits of micro services which are independent components than can be built, deployed, updated, tested, documented, maintained, scaled, and used **separately**. If large enough these are ideally put in their own repositories and have maintainers that are experts in the realm of the service and are responsible for its documentation and contribution integration (quality check, expert assistance, etc). Same how we have repositories for various major third party .NET libraries that are open source. They also go hand in hand with continuous integration/delivery. You only update/deploy what you need. Monolithic apps usually have to be deployed all at once (ala a “major releases”). Performance wise scaling is trivial, and you only deploy what you need so resource usage is lower, and there’s less to go wrong environment wise. They are also perfect for containers which share resources and are designed to scale.
I'm on mint 18 and haven't had any trouble. Does the `dotnet` cli work for you? It must if you started a project, right? What does your csproj file have in it?
Same reason you learn to do math without a calculator. It's not that you'll ever be in a situation without a calculator. Its that if you're going to dive deeper than multiplication and division, not being familiar with doing it by hand will inevitably slow you down when you move on to algebra, calculus, and diff eqs. If you are always using autocomplete for everything, what happens when you come to situations where you don't know what you need to autocomplete? If you've never looked through documentation before, you might not even know where to find it or what it looks like. The value for me is practicing things I already know, but I don't know what anybody else gets out of it.
I thought I've seen byte used a lot somewhere when I was writing that part. But I couldn't remember it. And finally realized that it was used a lot in C# I/O. Thank you.
"Senior Developer" means a lot of things to different people. In my experience every company has different standards and they are very arbitrary. At my first real job, it was a large insurance company and they had rigidly defined roles. We had junior/intermediate/senior (I think) is what they called it, and in our annual reviews they'd rate your skills on a scale that aligned with being junior/intermediate/senior. So it sort of 'gave you a path' to becoming a senior developer. Having said that, we had a lot of senior developers who weren't great, and a few junior/intermediates who were a lot better. Mostly, it was about years of experience. If they hired you out of college, they wanted to slowly advance you and slowly bump up your pay. If they were interviewing someone with five years of experience though, he or she would just be offered the senior title. At my second job, it was a pretty crappy, small, software company that did government related software. I have no idea how they managed to stay in business as long as they did....they eventually were sued for not delivering/breaking their contracts and declared bankruptcy. Before that all happened, they had a 'salary freeze' and instead of giving people raises, they basically just gave everyone a promotion. I was a 'Senior Software Engineer', in title only. At my third real job, everyone was just a developer. This was at a pretty competitive trading firm; I was, without a doubt, the weakest developer on the team. Some of these guys were amazing...but not a single one of them were 'senior' developers. My TL;DR advice to you would be to apply for those 'senior developer' jobs. If they look at your resume and see that you 'only' have three years of experience and don't want to continue the interview process, let them decide. The truth is, a good developer with three years of experience is going to be a hell of a lot better than an average developer with ten. I personally believe that almost all people peak in 3-5 years....between technology changing and just the breadth of tools/technologies people use over the years and normal people's ability to retain information. 
There's almost no difference. I see it as a code smell though, and a sign the person might not be super trustworthy. First, the "almost no difference". In API, everything starts its life as a blank rectangle. When a Button is told to paint, it crates a thing called an `hDC` or "handle to a Device Context". This is more or less what you have when you get a `Graphics` object. Anyway, so let's say you have a Button. When it paints, it creates its `Graphics` object and does all the work to draw itself. Then, if you've handled the `Paint` event or overridden `OnPaint`, it passes the `Graphics` along to you and lets you take over. Now let's say instead you have a Control-derived class. It doesn't come with any behavior, so while it does create the `Graphics` and fill its background, that's all it does. It doesn't draw borders or text or 3D gradients or anything. It hands the `Graphics` instance along to you faster. That's the "almost the same". A `PictureBox` comes with a ton of code specialized for displaying bitmapped images. It can stretch and scale them, load them asynchronously, and do a lot of other things. If you don't display a picture and just draw on it, well, a lot of that code gets skipped since `Image` and other relevant properties are null. But that still has a teeny cost, and it's weird to have a `PictureBox` if you aren't displaying a picture, so it's better to just use a Control-derived class or draw straight on the form. Now. If that's the case, why do people do it? Back in VB6, you didn't have a lot of options for extending the built-in controls unless you wanted to do a LOT of API work. There was no concept of "just a blank control". But there *was* a way to draw to in-memory bitmap images, and the PictureBox control could display those. So when VB6 developers needed to do a lot of custom graphics work, the easiest way to do it was to use a PictureBox. When .NET came out, a lot of people moved to it from VB6. Using a PictureBox like they had done before worked just fine, so they kept doing it. They didn't see or read materials that told them not to because when what you're doing works, you don't ask questions. Then they wrote tutorials themselves. New programmers picked it up, and assumed that's "just how it's done". Cargo culting. That's why I consider it a bit of a smell. It tends to mean the person writing the tutorial doesn't have a very deep understanding of how WinForms is put together. It doesn't mean they're dumb, but I feel like if you sit and read how it works you'll figure out pretty fast you're intended to derive new controls from `Control` rather than base your programs on existing controls. Using PictureBox is for the people who don't sit and read how it works. Another thing to look out for, this one **is** a serious bad practice. If the tutorial uses `CreateGraphics()` instead of handling `Paint` or overriding `OnPaint()` close the window, and don't go back to that site. Period. I can't tell from your description if that's what's going on. But if it is, just... tweak the tutorials to use `Paint` or `OnPaint()`. The "Why" is a little bit too complex for me to want to write out unless it's happening. The short story is: `Paint` and `OnPaint()` are already automatically called when Windows thinks it has time to do the work. They already create a `Graphics` for you. If you do your work inside them, things always work. But if you use `CreateGraphics`, you're working outside of that cycle. What you draw will get drawn over by the next Paint cycle, so you have to handle EVERY event that could possibly cause that so you know when to redraw. Or you could, you know, handle the `Paint` event, since it's already called when that happens. `CreateGraphics()` gets propagated because of people who copy/paste and never ask "Why?". Don't fall victim! I wrote custom controls as a hobby starting in 2003 and worked for a company that sells them from 2007-2013. I have *never* found a reason to call `CreateGraphics()`. 
Thank you everyone. I applied everything you told me. 
Make the array public in the Usuarios class. 
This worked!! but how can I set the size of the array if I want to make it for example: 3 or 5, without having to predefine the size?
VisualStudio with VSVim, best combo for migrating from Linux development to Windows development
Do NOT expose the array because it could be changed. Instead expose an IEnumerable&lt;T&gt; property. Then you can do things like Users.Any(c=&gt;...). &amp;#x200B; If you want to add a member, then have an Add() method in your class. &amp;#x200B; To change size, if I understand your problem, you might consider a List&lt;T&gt; instead of an array. &amp;#x200B; Finally, I would consider this very bad code because of the use of hungarian notation. It hurts my eyes to read it.
Look at method names. Sorry, should have been more explicit in syntax.
I dunno - if you look at objective measures of programming ability there doesn't seem to be any correlation with age. Less objectively - I regularly see job postings looking for 3-5 years of experience. Rarely I see some 5-10 years of experience. I've never seen a job add that requires 20 years of experience. This would seem to imply that employers see diminishing returns on experience. More anecdotally, if you look at some of the famous/great programmers they all excelled from a very young age. Maybe they did get slightly better with age, but they seemed to effortless leapfrog people with 10-40 years of experience. While most of us were struggling to finish our programming assignments, Bill Gates pushed the limits of the Pancake sort. Anders Hejlsberg did more before age 25 than most developers will do in a lifetime. Finally, and also anecdotally, I was a computer science major. Many of my friends were computer science majors. If you were to ask my group of five friends to rate ourselves in terms of 'best to worst programmer', I promise you, all five of us would have agreed. And if you were to ask us now, 15 years later, the order would still be the same. Our career paths matched exactly what you'd expect. The guy who struggled to get his homework done, he got an okay job and does okay. The guy who was doing awesome stuff and showing off for the professor, he went on to have a crazy awesome career and is semi-retired/touring with his band. I might be wrong, but at the very least, the amount of improvement I've witnessed in others has been minimal. And I've hired a lot of fresh-grads. If they aren't rockstars after one year, they aren't going to be rockstars after five. I'm not old enough yet to know if they'll become rockstars by year 20, but I doubt it.
How does knowing how to do things like long division by hand help with more advanced mathematical topics?
You can call me whatever you like, just pay me a lot and let me do my job. Ultimately you will get hired if they think you're qualified for the job. Titles are silly. I'm a contractor now mainly so I can avoid all that kind of stuff.
I've been programming for a very long time and I undoubtedly get better at it every year. I also am constantly thinking about how to improve my craft. I recent years a lot of what I'm realizing has to do with how less is more, which I would have never really entertained in my 20s. If you are dedicated to looking for ways to improve I think there are many parts of programming that can constantly be improved.
Does the :map command work with vsvim?
Thanks for the detailed answer. I'll take some time to think about what you've said. 
Yup, both `map` (`nmap` and friends) in `_vsvimrc` and `:map` in the command bar.
Export all data from the word doc into a model class using the openXML library. Search for the data within that model. That's the easiest way, IMO, that comes to mind.
You might want to check out Aspose.Words. It is not free though. 
Use List&lt;AlmacenaUsuarios&gt; instead of AlmacenaUsuarios[] 
I'd like to work with you.
I see a lot of VSCode posts, you could also look into monodevelop. 
I believe your `doc` variable will have a `Tables` property. I’m not at a computer right now to try it, but I don’t see why you can’t iterate through the `Tables` to find the table you need and read its data. You can see an example of how to do that [here](https://stackoverflow.com/questions/17795717/parse-table-using-microsoft-office-interop-word-get-only-text-from-first-column).
I'm sorry if that came of as condescending (obviously not a native speaker, so it can be kinda hard to navigate situations like this), it's just that I have talked to several people in the past who did not understood that implicitly typed variables are still statically checked; and the argument that type inference could be a problem for program correctness does sound a lot like it was born out of this kind of confusion, at least to me. I honestly do not understand how one could make this argument otherwise. 
&gt; "Hey, control - based on 'something' get the data that you are supposed to display!" Feels like you're describing WPF
Forcing anything on anyone is seldom a good idea. I understand your aim to keep your code clean and pretty, but to enforce it is almost impossible. You can enforce formatting with auto formatting on everything sent your way. But you will never be able to enforce coding style. Notice how VS fails often in delivering good hints for naming conventions or other coding style recommendations. It is the same with C Sharper and that is pretty the industry standard in recommendations of coding style. They often tend to give contradictory hints, because there are cases where multiple chains of possibilities are valid. So you can enforce something but by far not everything and I am not sure with the outcomes. Do code reviews with experienced devs (or your inquisitors if you like), which is very good idea regardless of draconic coding style conventions. This way you will get clear code.
StyleCop will do, I think. It's highly customizable, but comes with a few bugs (well, that's not a big deal). My team (around ~50 developers) uses it locally and in CI pipeline, so it fails build when there are any unsatisfied rules 
Thanks, I will take this point in our next meeting, StyleCop might be the best after all. 
Maybe if you spent more time in studying and less on Reddit browsing
I used to think the same way when I had 5 years experience. You know a couple of very average middle aged average developers and make asumptions based on that. Then you keep getting better and you get hired into groups full of middle age developers, who can still be pretty average, but they are as a whole better than their younger counterparts. That said you still stumble across below average middle age developers, they just get worse because they lose grip with modern tech. Well thats my experience, results may vary.
I am talking about forcing with tools. The proper way is internal education. That's why i proposed code reviews.
We use [Git hooks](https://git-scm.com/docs/githooks) to force consistent style at commit time.
thanks!
If that works for you, fine. By my experience it's not a matter of education though. There are lots of rules that just don't have an obvious best practice but are more of a matter of taste and often lead to heated discussions (e.g. casing rules or indentation). Without a decision that's also enforced you quickly get confusion and messed up code. 
My experience says otherwise. People who are forced to obey coding rules tend to leave the team pretty quickly. Of course I had far too many heated discussions about coding styles. They were all for nothing. If a dev cannot adapt to agreed (or given) coding style. He/she cannot adapt in many other things, too. And I hope we can agree that you cannot enforce everything. A good dev will agree to a reason why some rules are imposed on him. The same as a good team leader does on a reasonable proposal from dev. So its always about communication and education and not enforcement.
Depends how you sell the rules. If you just define and enforce them yourself, sure, but you can also agree on a rule set as a team, by vote if necessary. Those rules should then be enforced and as automated as possible in my opinion. Otherwise people will go slack over time and go back to their old style. Code reviews are great but too time consuming to waste on code style. 
Style cop integration will do it as part of msbuild
Our company uses .editorconfig that Visual Studio 2017 supports directly and awesome free Visual Studio extension Roslynator 2017, it uses roslynator.config. We commit both .editorconfig and roslynator.config to source control so everyone shares these style settings.
Don't use standalone StyleCop, it's legacy and discontinued. You should use the StyleCop.Analyzers project on github, it's a live analyzer using Roslyn.
I'm not sure I could disagree with you much more strongly. Consistency is important and a lot of style is just choices that are fair to make several ways, but you shouldn't have people mix and match them and it's a huge waste of time to have people argue about them in code review. You should never waste effort having humans debate anything you can enforce automatically. I do agree naming conventions are harder, so there might be a limit on how much you can accomplish, but you should definitely cover line continuation and max line length and really almost anything to do with spacing (with the exception of when you choose to put blank lines to separate parts of a function, which is more editorial). Casing for names is also generally doable.
If these people can't work with laid out style rules then it's better that they leave. I'm not sure what your experience is but in professional setting if person can't even abide by small thing like coding style then who would want to employ person like that?
I'm only a beginner to C# but I notice that VScode is so inferior to VS in every possible way when it comes to .NET/C# development, in Javascript/HTML/CSS development, VScode seems to be very good and superior at it but when it comes to C# development, it's just so basic. Just download VScode, dude.
I am sure, being happy not working in a team under the rules you proposed. The sentence: "You should never waste effort having humans debate anything you can enforce automatically." offends me as a human being and as a dev.
I absolutely agree. It's fine to have a company style but the best way to work is to work together and when people disagree to discuss the disagreements and come to a compromise or agreement. That way everyone is in agreement and on the same page with the style. If people can't agree then there are no compelling reasons to use one over the other, so it's obviously not a big deal and you can just compromise and pick one thing from one person and one thing from someone else etc. 
Can you check for editorconfig rules as part of the build?
is it only for VS? We don't use VS.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/dotnet] [C# Features: Innovations or Imitations? – Part 2 • r\/csharp](https://www.reddit.com/r/dotnet/comments/9kq0p9/c_features_innovations_or_imitations_part_2/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
They're talented programmers? Good devs have good options for employment. They don't have to tolerate a nanny style manager. 
I agree that copy and past code is a way to NOT learn, but that's not at all the same thing as not using an ide. But you make good points and I don't entirely disagree, though I would still not take it so far as writing the code on a whiteboard (haha, ok, I'm only pretending that's what I think you said - :-P )
Yeah; failing a build for style issues is kinda poor... 
We use a tool called "overcommit" to manage the various hooks for our projects. It can be set up to only look at the lines that have changed instead of the entire file that was changed. Makes it easier stop things from getting worse without having to get everything perfect before adding the quality checks. We run both style checks but also run static code analysis to look for potential bugs.
[https://github.com/OmniSharp/omnisharp-vscode/issues/1851](https://github.com/OmniSharp/omnisharp-vscode/issues/1851)
.editorconfig is gaining traction on many other editors, though VS seems to be the biggest adopter so far. This won't *enforce* proper style, note, just encourage it.
TFS has the option to enable 'gated check in'. When you try to commit in the master branch for example [you'll get this message](https://i.stack.imgur.com/WppId.png). If the build or tests fail, it won't check in.
What languages?
Thanks, I had forgotten how it worked.
casting with dynamic might work as it delays the resolution, but its probably better to create 2 methods return PrepareResponse((dynamic)entities, envelope);
As we progress and more of my coworkers are confident with `?.`, it's what I prefer. So `x?.y ?? "empty"`.
&gt; those two lines are not exactly equivalent That's why I specified it :) &gt; nullable X, non-nullable Y &amp;#x200B;
Ah, whoops, missed that. :D
Well, I guess it's your prerogative to be offended, but I've found particularly in larger orgs that arguing about style choices is a time sink. Maybe we are imagining different things, so I will give some examples for clarification: * How many characters per line is the max, e.g. 80 vs 100 vs 120 etc. * Whether wrapped lines with added elements should have the "+" at the end of one line or the beginning of another * Whether referencing a field should use "this.whatever" or it should be named _whatever And so on. A particularly bad outcome of this, in addition to the time spent arguing about what are ultimately subjective choices, is what happens when subsequent pull requests alter formatting and thus as a reviewer you see a bunch of changed lines that aren't really changed and it's harder to focus on what matters. As an engineer I really have to ask - why NOT automate all of this (Or as much as possible)? I never want to do work I can avoid.
But the others are not. Sure in java I can you ternary, but it's longer and you have to repeat yourself. Those two are shorter but on the other hand I can see how distracting could the question marks be. That's why I asked which one you prefer since you have the option to choose which. 
.editorconfig is supported by JetBrains Rider as well, in case you use it.
No worries, maybe it'll help someone who didn't think about it.
I found out the problem, I didn't have the complete mono installed on my system, `sudo apt-get install mono-complete` and mint (probably ubuntu users aswell) can use synaptic packet manager and search for mono-complete and install it that way.
Do you not build and test your changes before committing? 
Also you can add Warning as error flag so the build will fail if there are any warnings. Then you add whatever tool ex. stylecop as a task in your pipeline.
He said they used it in their CI pipeline, so it fails the build... Do you find a CI build failing because someone forgot to indent a line of code acceptable?
&gt; non-nullable Y Looking at the code, I don't know that. I could find out easily enough, but I probably won't think to check. So these are the meanings I attribute to the lines of code... null != x ? x.y : "empty" //x might be null. If it isn't, return y. x?.y ?? "empty" //do not return a null here no matter what Yes they are equivalent in you specific example, but in my mind they have a different intent. 
How will our opinions change once we have C# 8 and nullable reference types? 
Yes, that's right and why I prefer C#. Coming from Java, I'm still not used to the others. If I was, I'd probably use them as they look nice and short (though understanding what you say about the distracting question-marks). I guess I'll take this thread of yours as an invitation to consider them more frequently ;)
Yes. If the team isn't running StyleCop locally, then they deserve the frustration of dealing builds that fail. If the team is running StyleCop locally, then whoever isn't building and testing their changes before committing deserves the frustration of a failing build.
The second one - how to "map".
Really? I have heard of the MVVM pattern but afaik it describes a way to structure your application. I am not aware of anything describing how to grab data "autonomously" MVVM, WPF or otherwise. So I welcome you to share your knowledge! :)
It is a misleading example, as a string can never be non-nullable in C#.
Oh, so adding the controls programatically, instead of by use of the designer?
There is the nullable reference types proposal, though we won't see that till at least C# 8.0.
Is an "employee card" a `UserControl`? Like, can you do this: var myForm = GetForm(); //just getting the main form in a generic way var card = new EmployeeCard("John Doe", "Sales Representative", "Sales", "johndoe@xxx.com", "867-5309"); myForm.Controls.Add(card); I guess I am confused because you can create a model object and have each card databind to it. Each control on the card would databind to a property on the model (i.e Employee.Name, Employee.PhoneNumber, etc.). Wouldn't you be querying the database already to get a collection of employees to begin with or are you hard-coding each employee card during design time?
I'm aware of it, but I didn't want to muddy my comment by bringing that up, since it's not directly relevant, assuming the example is written in a version of C# that exists.
Exception filters were already found in Visual Basic .NET for quite some time. The keyword is even named `When`, so this is clearly *immitation*.
You can always do both. CI is the right place because it will be executed under all circumstances. If your missing the git hook locally you'd be able to commit anything you want to. Especially for open source stuff trusting the people to use git hook is not feasible. 
Attributes are an idea from COM, which are an idea from IDL for DCE RPC, shared with other IDLs. Microsoft developed, somewhere in the 90's, "attributed programming" for Visual C++, which would turn the table on IDL/TLB-&gt;C++ to C++-&gt;IDL/TLB code generation. The attributes would be very similar to the IDL ones, in between square brackets. So, this is clearly *immitation*.
Look into databinding pleeeeeeease. You'll have to implement the `INotifyPropertyChanged` interface on the model that the controls will bind to. You can use my `ObservableObject` class [I posted awhile back](https://www.reddit.com/r/csharp/comments/9efpu7/my_observableobject_class/) as a base class for datasource models to help with some of the boilerplate that comes with implementing that interface. Basically, it will automatically call the PropertyChanged event for the property if a property's value changed. This is required for databinding. Assuming you create an `Employee` model class that inherits from `ObservableObject` and wire up its properties, you can do something like this: var source = new BindingSource(); //this is a component you can actually use the designer to add to an EmployeeCard. Look in the toolbox. Don't actually create one in code like this. var employee = new Employee("John Doe", etc..); source.DataSource = employee; lblName.DataBindings.Add("Text", source, nameof(Employee.Name)); //nameof protects against refactoring and lessens the effect of "magic strings" //lblName.Text will automatically be mapped to the model's Name property now and is initialized with "John Doe" employee.Name = "Frank Sinatra": //lblName.Text will be automatically updated to Frank Sinatra var employee2 = new Employee("Sarah Connors", etc.); source.DataSource = employee2; //all controls bound to the binding source will be updated with the data from the new data source (employee2) With the above, all you need to do is expose a DataSource property on the EmployeeCard control like this: public Employee DataSource { get =&gt; (Employee) BindingSource.DataSource; //assumes you've added a BindingSource component named BindingSource set =&gt; BindingSource.DataSource = value; } Now you can do this: var card = new EmployeeCard(); card.DataSource = new Employee("John Doe", etc.); Voila. The control knows how to update its controls because you've used the built-in databinding technique. It maked things *a lot* cleaner. 
I have all the people checking in code to install CodeMaid and the settings are checked in with the project. I have CodeMaid setup to force a cleanup on save and because everyone has it on you can tell right away if someone doesn't. The only trick is editing third party source, which should be in the style that it was written in. I work with designers that code, and telling them to follow a strict style guide is not really a fair option. It doesn't fix variable naming rules etc, but I feel like this has greatly improved many other things like code noise any style debate. It's kind of nice even if isn't your preferred style you can put your braces where you finger muscle memory wants to put them and it fixes it when you click save.
DataTemplates and DataTemplateSelectors But it goes the other way, instead of "get the data" it instead displays data differently depending on the data. DataTemplateSelectors make you able to do really anything and write your own conditions.
depends where you are living too, are you europoor? or just rural usa
Rural USA. Granted, I have little experience, no degree or certs and my GitHub is pretty empty. Was just my first real job outside minimum wage so I absolutely took it.
thats not too bad for rural USA
I guess not lol. Though, was looking around to compare a bit, and I'm getting paid half the average of devs with the same experience than me. Granted, I am making decent money for my age, so I can't really complain.
Not sure what you are using as IDE but Roslynator 2017 should work in Visual Studio Code as well.
Decimals occupy 16 bytes, and doubles are only 8. But it's a small price to pay if you want the extra precision and arithmetic characteristics of decimals. There are also no NaN or Infinity representations. Division by 0 is considered an error in decimals.
I have just implemented ReSharper's Code Inspection tool as a part of our pipeline. Working well so far. I tried editorconfig but I had difficulties getting it to work as you can't make the build fail or see errors in existing code (at least I couldn't do that in VS 17 when I tried)
`decimal` is a 128 bit type, compared to 32 bit `float` and 64 bit `double`. `float` and `double` follow the IEEE standard for floating point numbers and are supported directly by special CPU registers and instructions, while `decimal` arithmetic needs to be performed 'manually'. How much of an impact this has depends on your use case. `decimal` arithmetic is significantly slower in comparison to `float`/`double`, but it'll only be noticeable if you're doing a lot of calculations. For example, some kind of image processing where you're using floating point for each of the millions of pixels in an image would be much slower using `decimal`.
+1 on StyleCop Analyzers. I'm trying to get my team to move to it from classic StyleCop. Getting live errors and auto-fixes in VS is amazing. Plus classic StyleCop uses a different compiler than Roslyn and doesn't fully support C# 7 features (and will give generic errors if it fails to compile them).
We also use StyleCop analyzers and have Jenkins configured to fail the build if it detects any warnings, StyleCop or other.
The default rounding method of decimal is banker's rounding, ie. nearest even.
That's also the case for floats an doubles.
*picture of Spider-Man meme*
They will definitely use more memory and processing power. But you get better precision.
It works out of the box, if you configure a rule to show as error, the build will fail regardless of settings in VS. It's a great tool. If you need custom rules, you should write a Roslyn analyzer and refer it as a NuGet package. It's not that hard to implement and you can break the build by showing an error the same way. I had an experimebtal. package that shows a warning in any C# file over 300 lines of code long, and breaks (error) over 500 lines. Couldn't figure out a way to elegantly configure these numbers yet, but you get the gist. 
It would make much more sense if you mention Unity at least once on your post and use proper formatting for code. 
Sorry, this thread was indeed a bit rushed as I just copy-pasted from a Unity-forum
Use null-coalescing operators. They are recommended for programming in C#6 and above. Also, the 2 statements are not the same. `!=` will use the overloaded operator if one is available, while `?` or `??` will use `ReferenceEquals` (i.e., a simple equality check for null). 
https://docs.microsoft.com/en-us/dotnet/api/system.decimal?view=netframework-4.7.2 https://docs.microsoft.com/en-us/dotnet/api/system.double?view=netframework-4.7.2
No, they use simple rounding or truncating based on context. If you're averaging a lot of statistical values, decimal is not a good fit because of the rounding algorithm used, which is preferred in finances, but not in statistics. 
When you can use just ? then always use it. So in your case always use second one. Using ? just propogates null forward and ?? replaces null with right hand value so you can do `a?.b?.d?.e?.f ?? "empty"`. More info here https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/null-conditional-operators and https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/null-coalescing-operator 
Removed: Rule 4. Please indent/format the code to improve readability here. Since you've posted the question elsewhere, please include a link to that so readers can know if you've already received an answer. You can also see about asking at /r/Unity3D which would probably have people more knowledgeable about scripting for Unity. And yes, if the behaviour of looking at and moving to the waypoints is the same as with the player, then I assume swapping `waypoints[num].transform.position` to `myPlayer.transform.position` would work.
`float`, `double` and `decimal` all behave this way, there's no difference between the types in this regard. `Math.Round` defaults to banker's rounding, `ToString` rounds away from zero, and casting to an integer truncates.
Thanks for this, it seems I have to investigate a previous bug then and research a bit about this... Gonna leave my mistake up for reference.
Add a public method to the class that instantiates the array. Instantiate the array in that method. 
Why do you compare null to x and not the other way around? Just out of curiosity. Also, it was said somewhere among the language's GitHub issues that comparing to null can be overloaded, but type matching to null cannot. So if you overloaded your equality operator on type X, it becomes implementation dependent. In these cases currently `!(x is null)` is advised. And there is a proposed `is not` operator which would be equivalent with the above, but more verbose.
Just what I was thinking. I've heard several times that future C# features are current F# features, and as they are both MS inventions I don't see why it can't be considered an innovation, at least by MS.
Interesting article! A few comments on part 1 and part 2 from the perspective of a language mentioned in the article: **Static classes – Innovation** `object` in Scala. A bit cleaner than static classes though, because they nest correctly. The concept of "static" is hopefully something no new language will reinvent. **Anonymous types – Innovation** val x = new { val foo = "bar" } x.foo Not sure if this counts though, as Scala requires introducing a member name. (Java also supports this, but it's barely useful there.) **Auto implemented properties – Innovation** public string Name { get; set; } Scala had this with `var` since approximately forever. (And `val` for setter-only "properties".) The whole concept of properties is an ugly backward-compatibility hack in C#, and probably one example of what new languages should _not_ copy. **Generic covariant and contravariant – Innovation** I'm fairly sure Scala implemented this before C#. Also, C#'s variance still doesn't support classes. **Exception filters – C# Innovation** `catch` clauses in Scala accept a `PartialFunction[Throwable, T]` since [~2010](https://www.scala-lang.org/old/node/8070.html). Before that one could just use standard pattern matching (and therefore filtering). This means you could use arbitrary logic, pattern matching and of course "filtering" for half a decade before C# added it: try something() catch someFunctionThatHandlesExceptionsAnyWayYouWant One of the popular handlers is [`NonFatal`](https://www.scala-lang.org/api/current/scala/util/control/NonFatal$.html) which catches recoverable exceptions and lets fatal exceptions through.
What type of object is `client` anyway? Rather than using threading directly, if you're rewriting this, you might want to see if you can write it using `Task`s instead. Tasks have built-in support for [Task Cancellation](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/task-cancellation) so you wouldn't have to manually check every second for a timeout, too.
Keep in mind you have to deploy commit hooks to every dev machine. Git is fundamentally distributed and doesn't guarantee enforcement. 
client is an class that sends messages to pagers.
&gt; Why do you compare null to x and not the other way around? Just out of curiosity. https://en.wikipedia.org/wiki/Yoda_conditions 
So define you own rules! I love var, but it's a religious point, not a Ln objective truth.
I'm in the middle - var when the type is obvious, explicit types for types with keywords (int, double, string, etc) and explicit type when the value is returned from a method.
Yes, you must don't.
1) Most processors have explicit support for floating point operations that decimal operations cannot make use of. 2) Decimals take up 2x the memory as doubles 3) Doubles handle/propagate NaN cleanly I will use decimals any time I am handling money or any other case where I don't want to deal with 1 possibly being represented as .99999999999999~. And I've never had a real world use case where the performance/memory impact of a decimal was my bottleneck.
In general its probably better to use Tasks instead of Threads because its more high level and less easy to mess up. But if thats just an HttpClient then you can use this (though I don't know what type notifyObject is, so I'm just assuming its an HttpRequestMessage): private static HttpClient Client = new HttpClient(); public static async Task SendSomeMessage(HttpRequestMessage message) { var result = await Client.SendAsync(message); } Then you can call something like: var response = await SendSomeMessage(someMessage); &amp;#x200B; You can set the timeout on the HttpClient itself, it will throw an exception which you can catch and log however you want. Just note that you'll need to go all in on the async or you'll still be blocking the UI anyways. But without knowing more about this application, desktop, web, etc; I can't really give too many opinions.
Like to add another one now that you have edited your question. Microsoft uses this tool https://github.com/dotnet/codeformatter to enforce their CoreFX code style https://github.com/dotnet/corefx/blob/master/Documentation/coding-guidelines/coding-style.md If your coding style differs greatly from CoreFX then maybe you can modify it to fit your needs. 
Can you find and use an alternative client that is async capable? You're much better off using Task async/await. as the above and other comment from Osirus1156 below suggests. 
&gt; I also know that double in c# can store a number 300 digits long. This is definitely not true. There *may* be some numbers presentable in a `double` that have a 300-digit closed form as a base-10 number, but [double only guarantees 15 or 16 decimal digits of precision]. You should definitely do some reading on IEEE floating point: they're surprisingly messy. The biggest advantage to `decimal` is that it's not a binary floating point number the way `double` or `float` are, so it doesn't have the weird issues with approximation. The biggest disadvantage is that it is much slower.
Successful build is one of conditions to complete the pull request, that's it. It's not about **CD,** it's about forcing same code style for all team.
I agree. Using a async task and await your message will be the best option. Threads are tricky to keep track of in a larger application and messy if you are not familiar with them.
You mean non-nullable, really. 
So this was kinda interesting so I made a bench (using BenchmarkDotNet). This basically calculates approximation of [e](https://en.wikipedia.org/wiki/E_(mathematical_constant)) with the Sum(0 .. steps, 1/step!): ``` csharp float ApproximateEulerFloat(int n) { float kFactorial = 1; if (n &lt;= 1) return 2; int i = 1; float eSum = 1.0F + 1.0F / kFactorial; while(n-- &gt; 0) { kFactorial *= ++i; eSum += 1.0F / kFactorial; } return eSum; } ``` Results were: | Method | Mean | Error | StdDev | Scaled | ScaledSD | |------------- |------------:|----------:|----------:|-------:|---------:| | NeperFloat | 23.96 ns | 0.1587 ns | 0.1239 ns | 1.00 | 0.00 | | NeperDouble | 23.65 ns | 0.0605 ns | 0.0566 ns | 0.99 | 0.01 | | NeperDecimal | 3,324.17 ns | 3.5696 ns | 3.3390 ns | 138.76 | 0.70 | So speedwise decimal is really, really slow. float/double don't have much difference speedwise (bench machine is i7-6700 ) You can find [full source on github](https://github.com/pasisavolainen/Teshtink#speed-of-float--double-decimal). 
The docs ... that's how I found it. The story was like this: VS told me that a null-check can be further shortened and I was like "how?" and clicked to shorten it. ?? appeared and I went to google how that works and whether there are more operators like this. Found the ?. and immediately thought about great usage for both operators at the same time. Basically what's in the OP so I wondered if it is used often that way or the question marks are too messy so people prefer ternary operator over x.?y??z
I see ... we don't have overloaded operators in java so that kind of missed me. Thanks
Wow, C# has so much useful functionality I haven't even known about. Thanks!
Custom C# apps written by Wall Street companies usually employ decimals for money. Just saying :)
Right. You don't want to hardcode the values, so you'll need something that converts data into controls. A method that turns an employee row into controls will make it easier to modify how everything looks.
the price to pay is rather large in terms of runtime. &amp;#x200B;
Nope. The feature is actually called "nullable reference types" because you have to use a `?` when declaring them. Though yes, I would agree that the name is misleading. 
Yes I am. It looks awesome. I tried some c++ but hated it. Hoping c# will be better
I suspect the OP's remote team barely manages that.
https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1
You're right, a List&lt;T&gt; grows as things are added. You can use List&lt;T&gt;.Add() to add a new element. There's also the List.ToArray() method that you might find helpful.
Generic Lists are the best thing ever. Once you get used to them you will probably never use an array again. I honestly can't remember the last time I used an array. Think of it as an array that you don't have to worry about. You can add stuff, remove stuff, find stuff, and it takes care of the details like how big it is.
Any reason for that suspicion? 
either way you would be blocking until the client completes its operation, unless this is a GUI app? If it's a GUI app you should look at using a [BackgroundWorker](https://docs.microsoft.com/en-us/dotnet/api/system.componentmodel.backgroundworker?view=netframework-4.7.2).
If what you are misunderstanding is generics, then let me give you a little primer: List&lt;T&gt; means a generic list of any type T, the type doesn't matter because the operations that we do on the underlying structure of the list isn't affected by the type of whatever data we store, thus we can specify any generic type. Under the hood the generic looks a little like this: class List&lt;T&gt; { Array items; int currentIndex, size; public List&lt;T&gt;() { size = 5; currentIndex = 0; items = new Array(size); } void Add&lt;T&gt;(T item) { Array[currentIndex++] = item; if (currentIndex + 5 &gt;= size) { DoResize(); } } } And so if you want to use a list like this you would simply do: // Now that we actually want to use the list // we must specify what that generic type really is here List&lt;int&gt; numbers = new List&lt;int&gt;(); numbers.Add(5); 
Or maybe, just maybe, it's a way to make sure no one forgets a tab? Going to straight to "remote people won't listen" seems like a big jump. 
While it does grow as you add items (it doubles whenever it fills up), you can improve efficiency in cases where you know a minimum, or very common size it is going to reach, by supplying an initial capacity in the constructor. &amp;#x200B; So if you KNOW you are going to have 1000 elements or more, you can do \`new List&lt;int&gt;(1000)\` and avoid having to reallocate and copy from an array of size 2, to 4, to 8, to 16, to 32, and so on. &amp;#x200B; Also if you do not \*need\* the growing behavior of a List, then a regular array is more efficient still, though the difference is not large. &amp;#x200B; Lastly, random performance tip: &amp;#x200B; using a foreach loop on an array performs the same as a regular for loop. the compiler special cases it. using a foreach loop on a List&lt;T&gt; performs a little worse than a for loop. &amp;#x200B; &amp;#x200B;
&gt;and it takes care of the details like how big it is. And it does so using finely-tuned sorting and growth algorithms that are way better than you would ever care to write in most cases.
Forget you learned about Arrays. They're not very useful in C#. List&lt;T&gt; is your new friend. You should also get to know SortedList&lt;T&gt; and Dict&lt;T&gt;, those are both good data structures. Now let's improve your code using List&lt;T&gt; (where T is some type) public class UserInfo { public string Username; public string Password; // ToDo: Add standard ctor for username and password } class ArrayStorage { public List&lt;UserInfo&gt; UsersList; public static void SaveArray() { UsersList = new List&lt;UserInfo&gt;(); for (int i = 0; i &lt; 2; i++) { Console.WriteLine("Enter the Username for User #" + (i + 1)); username = Console.ReadLine(); Console.WriteLine("Enter the Password for User #" + (i + 1)); password = Console.ReadLine(); UsersList.Add(new UserInfo(username, password)); } } } This code creates an empty List of type UserInfo. Then as you grab the username and password from the console, you stuff the values into a new UserInfo object and immediately insert it into the UsersList. And you can keep adding to UsersList as its Dynamic!
Am programmer, can confirm. Just cache it in memory.
Just going to ask a general question here. Are these "Generic Lists" similar to or a version of a "Linked List" in Java for instance? 
If your not using List&lt;&gt; then your most likely not using Linq. If your not using Linq, it's time to learn. It will change the way you do absolutely everything in code.
`List&lt;T&gt;` is the C# equivalent to `ArrayList&lt;E&gt;` in Java or `vector&lt;t&gt;` in C++. 
Only in the abstract sense that you can add elements, remove elements, find them, etc. They both act as lists. But List&lt;T&gt; keeps its elements contiguous in memory, so iterating over it is much faster than iterating over a linked list (which has to chase pointers).
Aside from the fact that the BCL exposes arrays in most of its collection-based methods (like most everything in `System.Reflection`) or any method that takes a `params` argument, arrays are also specially optimized by the JIT. Don't think for a second that arrays aren't very useful--in fact, `List&lt;T&gt;` is just a smart wrapper over `T[]`. Understanding the fundamental types helps you think about the higher-level types and know the trade-offs.
Once you get used to Lists, start looking up Linq queries on your to find data in the lists. 
1. You can use LINQ on arrays 2. LINQ isn't a panacea for bad code. Although it helps with expressiveness in some cases, I've also seen developers convert simple loops into nasty LINQ statements. LINQ isn't the best optimized, either. I've seen some large wins removing LINQ from hot paths and replacing it with loops instead. Obviously, context is important and you should always measure your own scenarios.
Why would anyone downvote this? Linq is great. Of course you can abuse it, but it's really the best way to go instead of creating loops and whatnots to find something. 
Iterating a list vs linked list is the same. It’s random access that’s different. If you know you need to get the 100th element, list is faster than linked list. But, if you needed to add or remove to the middle of the collection, linked list is faster than list. It all depends on how it’s being used. 
Lists are a very useful data structure but remember that they aren't the solution to every situation. Look up C# generic collections and learn which type to use in which situation. I use hashsets, dictionaries, and arrays all the time while many of my coworkers give up the unique benefits of each of the collection types so that they can do what is familiar. To reiterate what others have said, Linq is your friend! After learning the basic collections and how to iterate through them, learn how to use the power of Linq
`float` and `double` are both standard IEE754 floating point numbers of single and double precision respectively. As such, they are represented internally by mathematical equations and you will have rounding issues. `decimal` is fixed-point arithmetic type instead. It sacrifices both speed and range for accuracy. Speaking of which, `float` and `double` should never be used for monetary calculations because of their lack of accuracy. It's also why the type suffix for decimal literals is `m` or `M` for money.
&gt; Does it make sense to start with Javascript first? That seems to be a more prevalent language in job postings. Or you could learn ASP.NET and JS simultaneously by building the backend REST API with ASP.NET Core and the frontend with HTML5/JS/CSS
You set the type of a list kid of like an array in it's declaration and construction like so. List&lt;int&gt; myList = new List&lt;int&gt;(); Then you can add stuff to it like so... myList.Add(5); Get length by using count. myList.Count(); //I think it's a method... Might be a variable, it's been a while.. You can index it to get and set variables like so... myList[0] = 5; And you can do removes and all sorts of other cool stuff using System.Linq. You'll never go back to arrays! Unless you have to learn C like I am now 
Iterating list vs linked list is not the same. Because linked lists are often not contiguous in memory, you'll get cache misses and have to spend time moving around memory. Additionally, barring some possible but difficult compiler optimization, you'll have to read a field every time you move to the next element which has a small but nonzero cost. 
Updated
Yep. Pagers. Also, this is used in th medical field :-D
LINQs great, but it's not the solution to every problem involving a collection.
My statement stands. Someone who is unfamiliar with a simple collection structure like List&lt;&gt; is most likely going to be unfamiliar with Linq regardless of it's capabilities in coordination with arrays. Nothing I stated hinted at being dogmatic in nature. Any code can be unreadable and poorly optimized if used improperly. Linq was a big evolution in the framework and is absolutley worth learning for a thousand reasons.
It's a big leap from `List&lt;T&gt;` to LINQ. LINQ's cool, but the OP needs to figure out basic data structures, first.
Not for financial applications.
The fun part is that a List&lt;T&gt; is just a set of arrays that contain buffers. Because arrays are imutable, when you need more space, a new array is allocated that contains all of the space for the original arrays with extra buffer space and the old set of arrays are copied to the new array. The same works in reverse as well to decrease the size. If you look into creating a circular Queue you will also see that behavior as well.
I hope this concept takes off. It seems to take the best ideas from React. I absolutely love working with React, but hate javascript. This seems to take the best of both worlds
A `List&lt;&gt;` is not a linked list, it's an array list.
It does. 
Arrays are not immutable. The _size_ of an array is immutable, which is probably what you mean. 
We use ? and ?? in our company's codebase extensively and at least to as us they make code more readable and maintainable. I'm not sure are going to get definite answer because this might be matter of preference or even some company's code style rules. Maybe you can browse Microsoft's code here https://github.com/dotnet/corefx so see how much they are using them. The thing is that these thing are not always interchangeable lets take these code examples. `var foo = bar == null ? null : do(bar);` or `var foo = dict.TryGetValue("foo", out var value) ? value : null;" you can't use ? or ?? here so ? and ?? are not always replacement for ternary operator
They have generic algorithms on iterators. 
&gt; weird ass-names *** ^(Bleep-bloop, I'm a bot. This comment was inspired by )^[xkcd#37](https://xkcd.com/37)
I only use arrays if I have to. Several other languages, like Swift, Python, don’t even have them.
Thanks Simon! I'll check those things out and update the article as needed. About Generic covariant and contravariant in Scala, I couldn't find anything written about it early enough link to prove Scala had it before.
&gt; The fun part is that a List&lt;T&gt; is just a set of arrays that contain buffers. While that is an implementation detail, in the current implementation a list is **not** a set of arrays. It is **one** array that contains all items.
&gt; essentially just map, filter, reduce You mean map, filter, reduce, etc. is just LINQ. ;)
I dunno... There are some purists who still cling to C++ style stuff and like to bash the niceties of C#.
The await in your one line method is unnecessary.
It gives powerful tools to manipulate, group, sort strongly typed collections. Strongly typed is the key. Productivity and compile time debugging is a HUGE bonus.
c#
Thanks for this. I see the video was published back in 2017. Is it still relevant for today?
Closest comparison between Java and C# list structures I could come up with (keep in mind it's some time since I had to work with Java) C# List - Java ArrayList C# LinkedList - Java LinkedList C# IList - Java List
Thanks!
very fast and dirty version string path = path+filename+counter+extension; just count the counter up every time you press the button
If you're a beginner then yes, this covers a ll the basics you need to know about programming in C#. The things that tend to go out of date are the patterns and technologies that you add onto those basics, not the fundamentals themselves. &amp;#x200B; I honestly think the old version of this that I followed in 2015 is still absolutely relevant, apart from some minor tricks that do nothing more than make your syntax neater. 
Dirtier if you use post increment operator inline
Lists are generic and dynamic. Arrays aren't. It's that easy. 
&gt; Do I have to set the List size or does it just grow as I enter information It grows as you add items &gt; how can I add information in the List&lt;&gt; List&lt;T&gt;.Add() Note that Lists are great for most use cases, but if you really want speed and need to optimize chache misses, Arrays are the way to go.
Through*
Hahahahaha. Oh man. Yeah. I used to correct people on that, too. And now I do it... *shrugs* 
_Technically_, `List&lt;T&gt;` is a generic type that cannot be used directly - it is a specification for a family of related constructed types. The `T` is like the `x` an algebra - it could take on a number of values. It doesn't become a "concrete type" until you decide what the value of `T` is. So then you get `List&lt;int&gt;`, `List&lt;string&gt;`, `List&lt;User&gt;` etc etc. http://www.informit.com/articles/article.aspx?p=1648574&amp;seqNum=4 See here for more: https://msdn.microsoft.com/en-gb/library/aa479859.aspx
Null null-coalescing is meant for readability so that you wouldn't have to write the kind of ternary in your example.
My colleagues will probably just never ever use C# 8 and stick with the old ways until they retire. I made them upgrade past .NET 4.0 and just doing that made so many warnings and refactor suggestions pop up you could see them sweating. They'd have a heart attack if the compiler suddenly started listing errors from all their unused and uninitialized variables, there'd be nothing but errors.
Or you can use the List's .AddRange() method.
For someone who doesn't really know much about web development, what is 'server-side Blazor' and why is it a big deal? I get that Blazor allows you to use C# on the client side where previously it had to be javascript, but I thought that on the server there was already ASP.Net that allowed the backend stuff to be written in C#. Sorry if this is a stupid question - the whole web development domain I find quite confusing.
I've watched all his fundamentals series at MVA, such a great teacher! (I started a year and a half ago and am yet to find a job as a developer but am slowly getting there)
Is there anything similar for F# too?
https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/enumeration-types#enumeration-types-as-bit-flags
I wouldn't really say 'go from 0 to 4, then double in size every time you run out of space' is an amazing finely tuned growth algorithm that you're not likely to be able to improve on. It's almost the first thing you'd come up with.
Yes, that's why Lists are generally preferred - because Lists grow as you insert information. Just use &gt; List&lt;object&gt; myList = new List&lt;object&gt;(); &gt; myList.Add("item1"); &gt; myList.Insert("Item2", 1); //insert at index 1 As always, head to [microsoft docs](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1?view=netframework-4.7.2) for better info.
I did the opposite, ten years in web services, api and sometimes asp.net web interfaces, now I'm moving to add desktop apps :D Learning good javascript can be a great idea, I'm doing the same. Also learning asp but not MCV, instead Aspnet Core, which will be the only existing asp quite soon
Senior developer into a Fortune 500 here. Yes, with three year is ridiculous, I got 10 and I'm Senior II in a scale that goes up to Senior III
For React/Angular/Vue SSR is very important. It allows you to ship a page with HTML just like pages normally work instead of rendering it with JavaScript. This allows users with JS disabled to see your page. More importantly it allows crawlers to see your page. While Google runs JS on pages (at least scripts that run on load) not every agent does that. Facebook, skype and others open your page to generate preview and if you are not shipping any HTML you won't get one. Also shipping HTML improve performance because the browser can start rendering without running scripts. Now interestingly this is not how Blazor SSR works or at least from reading the description it is not. (I haven't tested myself, please correct me if I am wrong). SSR Blazor opens a web socket and starts shipping HTML from the server and continues to do so even if the client has full wasm capabilities. In my view this makes SSR much less useful than its JS counterparts and for the life of me I can't understand why they are building it this way. One cool use case is using it in Electron apps where both the server and the client run locally but that's it.
Server-side Blazor includes a JavaScript shim that hooks into DOM events and pipes them to the server (I think it uses SignalR Core). The server then processes those events and sends updated HTML to update the page. I think it’ll work great when your page is just interacting with the server (click button, make http call, update page). I think it won’t work as well for real-time javascript interaction since it requires a request to the server. Today with Razor, you could generate the page and send it to the client... but you’d have to write any interactions with the server in Javascript and handle any DOM updates in JavaScript (react/angular/vue/vanilla/etc..)
I bet you're right. Like I said, it sounds tricky, and since there's clear alternatives, shouldn't be attempted.
In general, I agree. However, if memory usage is important, arrays are more optimal. Lists over allocate memory, this can add up, especially if storing structs that are not tiny. If I have any collection of data that are large and do not change in size, I use arrays. Passing a list capacity, if you know it ahead of time, is useful for performance and memory, but if that is the case, it seems like an array would be suitable anyway. `List&lt;T&gt;.TrimExcess()` can also be useful in some situations.
Thank you for the explanation!
Server side Blazor aka ASP.NET Core 3.0 Razor Components is very useful for enterprise (company internal software) and software running in fast networks. *Pros* - More secure because everything is running in server side - You don't need to create an API. - Programmer doesn't need to use JavaScript at all or any other client side language *Cons* - High latency or if server is running slowly will cause UI to slowdown. Visibility of this can be mitigated using CSS or JavaScript to create immediate responses. Like adding a class to button or showing a spinner. - More demand for server because it's keeping state, running logic and rendering HTML. Link from this comment https://github.com/aspnet/Blazor/issues/1004#issuecomment-398588045 in github it seems that Airbnb is using server side rending in their mobile apps.
&gt; Or maybe, just maybe, it's a way to make sure no one forgets a tab? Now, that would be overkill.
Did you happen to see any talk about SSR + Blazor similar to how React/Angular/Vue do it? This is very important for public websites and the current approach pretty much rules out Blazor for these scenarios.
I haven't seend any talks but just checked Blazor's github site and SSR is tracked here https://github.com/aspnet/Blazor/issues/24
Well if you wanted to help me out , you would! Just because you know and i don't is not fair hating me i did nothing to you just asked for help....but i bet there are things you don't understand in coding so we are just in the same boat. &amp;#x200B; And just so you know everybody learns with a different way ;) if you have a problem and you can't solve it you just ask for help is only normal. Otherwise the problem remains when you can't figure out the solution. And plus i don't have time to waste trying to figure on how to save the path as it shown... I need to focus on watching and learning through tutorials so ya.
using a while loop ,for loop ? or?
I'd say learn both [ASP.NET](https://ASP.NET) Core (MVC) and JavaScript (ES6). Why? First, you already know C#. [ASP.NET](https://ASP.NET) MVC is going to let you get **something** up and running relatively fast. That's a nice psychological win, even if your first site ends up being kind of ugly. :) Even with rich web apps, you need a platform for web services. C# is a fabulous platform for that. &amp;#x200B; Second, if you're working on the web, you just can't get away from JavaScript. It doesn't matter if you're doing JSP, [ASP.NET](https://ASP.NET), Ruby, or something else, JavaScript is the only way to get something to run on the client/browser. You can do a lot with round-trips (postbacks) to the server, but you're eventually going to run into a case where that leads to an obviously bad UX. But, if you start with C#, you can ease into JS. &amp;#x200B; Finally, if you're going to jump back and forth between web and desktop, there's a case to be made for either C# or JavaScript -- specifically, in the form of NodeJS and Electron. It's that desire to fluidly move back and forth that actually has me looking at NodeJS, lately. I'm still not ready to drop C# (I just love the syntax too much), but I do like having it in my toolbelt. &amp;#x200B; Your other option for "both worlds" would be to look at Blazor. While that looks promising, it's still a beta product and more what I'd view as bleeding-edge for the alpha geek than a production-ready tool.
A List uses a backing array. So for most of the operations, the speed and cache misses will be the same as with an array.
It's maybe a little bit outdated, as it targets .[NET](https://ASP.NET) Core 1.0, and .NET Core is now at 2.2. After a quick scan a lot of the concepts are still the same, but perhaps it would be better if you learned straight from the .NET Core documentation: [https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-2.1](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-2.1)
Resharper has a command line tool which can be used reformat code or run code inspections. It is not necessarily the automatic tool which is forced to run. However, a library can use this to period check code and clean it up to match a consistent standard. https://blog.jetbrains.com/dotnet/2018/03/01/code-cleanup-resharper-command-line-tools/ A common time to run the tool is whenever a merge is performed.
High load API on Core2.1 + Dapper + SQL Server. Any suggestions for how I can make it more responsive in case of POST/ saving document? I considered validating user request and sending it through a MQ like RabbitMQ and then saving it to DB on another app to avoid waiting for the DB. Also maybe creating shadow tables to make selects from. 
Yes :D
I believe you just make the actions async now - not the controller (i.e no AsyncController base). The advantage does not lie in JS or Postman - those apps do what ever they want to do - and the caller has no idea whether the web site is async or not. The advantage of async actions is that your app scales better because it can handle more simultaneous requests more efficiently. 
So it returns the thread, while awaiting the DB call? Of course I try to create my repositories to use async too. 
&gt; So it returns the thread, while awaiting the DB call? Yes.
Good. So I'm not making things worse by making all Actions async. And sometime it may even make them better.
Oh! Excellent, thank you!
I almost always use List&lt;T&gt; over arrays and have since they were introduced. There are a couple, narrow spaces where arrays have an advantage, but List&lt;T&gt; is generally easier. Actually, I need to confess... I almost always use IEnumerable&lt;T&gt; for method signatures and field definitions. Internally, that generally means List&lt;T&gt;, but a combination of LINQ and DI ended up getting me to favor IEnumerable&lt;T&gt; as an abstraction. FWIW, that works for either arrays or List&lt;T&gt; -- but, it doesn't include the .Add(T) method.
Basically your threads will be released to do other thing while you’re waiting for a database to respond or for email server to send and email or whatever... so yeah async is pretty much always better.
This video is just a video of the actual course, i highly recommend you do that instead ( as its free m, structured, and has little tests to help you learn ) [https://mva.microsoft.com/en-us/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC\_2706218949](https://mva.microsoft.com/en-us/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC_2706218949)
The point with this is that you can handle more simultaneous requests. You can think of it like requests per second benchmark or something.
"Pull operation failed" - should have used a condom. 
Is Blazor considered beta now? I thought it was still *very* alpha.
As others have said, start learning ASP.NET Core MVC. You'll be required to learn JS along the way. You can't get away from learning JS in the web world at the moment, unfortunately. Blazor may change that in the future, though.
He looked like a wonderful human being when I watched his videos. 
Do you know why they decided to default to Banker's? I feel there has to be a good reason since they actively chose not to use Half Round Up that everyone grew up learning. If there is no good reason, they are a bunch of trolls.
In which case the price to pay is rather large in terms of actual money :-D.
You'll see that bottleneck in game development. For example, you don't want to store an object's X, Y and Z coordinates as `decimal` since floats/doubles are more than capable handling all the calculations involving an object's position like collision detection and other physics -- the errors from using floats or doubles for this stuff just doesn't matter because the precision of a decimal just isn't necessary.
Bob Tabor has his own site, DevU.com, and it has several full courses on c#.
Appreciate this - doing in command line allowed me to see the real issue and diagnose. Thanks!
Use the **Managed Extensibility Framework (MEF)** to load methods you've exported. I can provide an example if you like. MEF resides in the `System.ComponentModel.Composition` namespace and assembly.
Way too early for that. 
It was chosen decades ago as the default rounding mode of the IEEE 754 standard for floating point arithmetic, and many programming languages have carried over that default. It does reduce overall bias when aggregating many rounded numbers and is considered superior or more correct by some for this reason. Of course, the question of how often you sum up rounded FPs consisting of even distributions of .5 fractions is another matter. IMO the principle of least surprise should have been applied here.
Thanks! I'll give it a look.
What courses on Pluralsight should I take if I'm an aspiring C# backend developer? (Just started writing endpoints for an API built with C# and Entity Framework, if that helps). Thanks!
Yes please.
Fortunately nullable reference types are something you have to turn on. But yea, I feel your pain. I've worked with people like that before.
Sorry I do not understand what you mean, how does this translate to an URL I can use in a browser? Or am I misunderstanding you completely.
&gt;For example, adding and removing to and from the middle of a collection, linked list is faster than list, since is O(1) vs O(n). This is only true if you have the node that you are inserting next to. If all you have is the index, you still need to iterate from the beginning to get to that index, which will be O(n).
[RabbitMQ](http://www.rabbitmq.com/)
Does it need to be high performance? If not I'd just use whatever message bus solution fits your needs or familiarity. AMQP, RabbitMQ, etc.
The "LINQ" concept is more about query syntax and IQueryable than IEnumerable. People just use the latter way more often, so that's what gets emphasized.
Thank you for the encouragement! I will surely keep at it!
Grpc?
Correct. For example, iterating through an unsorted collection, looking for the element to remove. Finding is O(n) for both list and linked list, but the linked list will remove it faster. 
Any custom remoting like protobuf, ws-\*, json-over-http, DCOM if Windows - only.... Choice is aplenty. Correct answer depends on "what for?" And a host of other contextual info. Queueing is not considered IPC (as it's async, there's no "got it, it worked").
I prefer `ICollection&lt;T&gt;`, unless I'm `yield`ing back the results, personally, but YMMV.
I meant it more in the sense of "not ready for production". I honestly didn't think beyond that.
Can anyone get the example to even work in VS 2017, latest update (15.8)? I cant compile T_T
GRPC lets you define your messages and get related code (other user said directly grpc, that's better than me going "protobuf"). At facebook, there's Thrift, similar to gRPC. Also (blast from the past ...) ICE? Edit: I am like you, would **never** do sockets for this. Others did it many times over. (Me, too, when I was a student). 😁😁😁
&gt; So it returns the thread, while awaiting the DB call? If you make that DB call asynchronously, then yes. You could make your action async and still call your DB synchronously and then the thread will remain blocked waiting for the DB call to complete.
I mean, List&lt;T&gt; also implements IReadOnlyCollection&lt;T&gt;.