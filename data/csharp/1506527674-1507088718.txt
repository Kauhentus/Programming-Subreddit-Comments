I think me leaning towards liking it stems from UI elements mostly. Even with intelli sense and error catching in the compiler I still like seeing iNumberOfSides vs NumberOfSides, when I read both the i only registers in my though process if I want to know at a glance if it is an int or double or ui etc All that said, decent names for variables and methods along with simple clear and concise remarks for what the functions do are way way more important to the future of the code.
That's the one thing that I think they are perfectly acceptable for.
I can see the rationale behind using hungarian notation for numerical types because the name of the variable itself usually won't convey enough information for the programmer to ascertain what numerical value type it is (i.e NumberOfSides could technically be any of the integer value types). Ultimately, you hit the nail on the head here: &gt; All that said, decent names for variables and methods along with simple clear and concise remarks for what the functions do are way way more important to the future of the code.
The objects in my list are actually of type CustomBusinessAssociateRelation, so I am only calling new BusinessAssociateRelation() when I call the base constructor. So I basically have: public class BusinessAssociateRelation { public string Relations { get; set; } } public class CustomBusinessAssociateRelation : BusinessAssociateRelation { public Guid LegacyId { get; set; } } Then, BusinessAssociateRelation a = new CustomBusinessAssociateRelation() { Relations = "Hello" }; DevExpress then looks at variable a and only reflects on the properties in BusinessAssociateRelation even though it is actually of type CustomBusinessAssociateRelation and should have knowledge of the LegacyId property. I read through several more support tickets about this last night, and I don't think it is possible to do except by using an unbound column, so I ended up approaching it that way.
Explicitly define them
&gt; I tend to feel that if your method needs to return 2 or more disparate data items that your function may be responsible for too much. I like this view. I'll own it. 
Thank you for the insight, and thanks for referencing that linter! I don't think I have that installed.. I'll look into it
That makes a lot of since! With that being said, I don't think SerializeErrorMessage can fail, so going with the "TrySomething" convention probably wouldn't be useful. I'll definitely keep that use case in mind.
About 20 years ago I wrote some software for natural language processing, of which this was a big part. It's a surprisingly complex problem because it's surprisingly hard to tell what's a quote. For example: * Apostrophes don't count ("there goes Bob's car") * Abbreviated years ("back in '01") don't count. * Measurement units for feet, inches, minutes, seconds ("I'm 5'8" tall") don't count. * You want to look for balance, which is complicated by * typographic quotes having a left- and right-side (and sometimes back-tick is used as left-single-quote, in which case the right side is the plain ambidextrous single quote) * In long quotes spanning paragraphs, the quote isn't closed at the completion of the paragraph, but is re-opened at the start of the next paragraph anyway. It's not closed at all until the end of the last paragraph. * Other obscure things like mathematical notation. So how simply and quickly you can attack it depends on how much of that junk is a requirement for you.
I always wondered, why Microsoft didn't make the switch at some point for T.TryParse() to return a Nullable&lt;T&gt;. Eric Lippert [made it pretty clear](https://ericlippert.com/2012/08/14/out-parameters-and-linq-do-not-mix/) at some point that the main reason was because the Try* pattern was established before nullable types were introduced, but at this point (especially with some of the major changes that have happened with the evolution from 2.0 -&gt; 4.7.1) you would think that would have been at least added as an option via polymorphism. It would be easier from a code perspective to check if(someVar.HasValue){...} as it is to say if(int.TryParse(value)){...} Theoretically, the performance difference should not be noticeably different in the average case...I think...
That's not the same situation as what I was describing. The situation described in the SO post was using `Task.Run` just to run some code on another thread and then doing nothing else on the original thread (returning it to the thread pool). That is pointless, as the SO answers correctly point out. The situation I described was if you have to do two (or more) different CPU-bound tasks that can be run in parallel. You have two choices: either run them all on the same thread one after another or run one on some other thread and the other on the original thread, in parallel. That is actually a useful thing to do, and it will be faster if there are enough CPU cores available. If you think about it this makes sense. Even if you're already on a thread pool thread that doesn't mean you have to do everything in series from then on. You may still have tasks that can be further parallelized, and it is appropriate (and likely the right thing to do) to use `Task.Run` in order to run those other chunks in parallel. What you don't want to do is call `Task.Run` and then immediately return if you're already on a thread pool thread. That's what the SO answers are saying, and I agree. But there are still other situations where it can make sense.
Good video over all. Only issue was it was hard to hear the difference between "emit" and "omit" by the speaker.
Huh, maybe I'm getting my Framework 4.6 confused with Standard 2.0. Could've sworn the .config files were the new way to go. Ah well, best of luck!
This may be a rare cases where it's easier to just loop the characters one by one keeping track of quotes etc as you go.
For the most part you should avoid functions with "Side effects". Changing the value of an input variable and allowing that change to persist after the block of code has executed is definitely a Side Effect. So, when possible you should avoid using the out keyword. However, this is a case where breaking the rule can be very advantageous especially for optimization... so instead of outright disabling this practice the Out keyword servers as an indication that programmers should be careful when manipulating those parameters. Now, I may be wrong due to compiler optimizations, but in essence public static byte[] DoIt(int len) { byte[] ret=new byte[len]; for(int i=0;i&lt;len;i++) ret[i]=rng.next(); return ret; } vs public static void DoIt(int len, out byte[] buff) { buff=new byte[len]; for(int i=0;i&lt;len;i++) buff[i]=rng.next(); } In the first case, a new byte array will be created in local scope, populated then returned to the calling code which will then copy the data from the returned array into the assigned value... so the data is copied twice. Using an out variable the data is copied only once, the second copy once it has been returned to the calling code is not required. Other times it is simply used to enable multiple outputs from a single function... such as public static bool DoIt(int len, out byte[] buff) if (len&lt;=0) return false; if (buff.length&lt;len) return false; for(int i=0;i&lt;len;i++) buff[i]=rng.next(); return true; Here, you would not be able to return both a sucess/fail and the required data without using the out keyword (Prior to the new tuples syntax anyway). 
Yep he only sorts the grade when he adds, but when he runs through the dictionary in Rooster() he does it on item lvl. The first item created is 2nd grade by adding peter, then 1st by adding Anna, then 3rd with Jim. That's why it is sorted with Alex Peter Zoe (2nd graders) - Then Anna Barb (1st graders)
You want a dictionary. It stores key value pairs (key being the enumVal and the class being the value) I would also recommend changing the name of the property and using an enum. You could then have MosterId Id {get;set} or similar. 
I have not found a simple/short method of accurately parsing tokens out of a line of text containing comments, quoted strings and escaped characters. The best way I know of is a simple state machine. It would be nice for it to be built in. And certainly possible... but the difficulty is that there are many different ways to determine what constitutes a token... there may be cases where you want to consider [abc def], or 'Some String' a "quoted string" or you may want variable name tokens to not allow numeric characters. I.E, You may want to parse X2 as "X2" where another application may want to parse it as "X" "2". You may want | or # be an operator token... 
Yeah, I added a simple state machine to the original text. Looking for optimization suggestions.
~~As for performance, out is like ref. Value types will get boxed, that's the first thing that comes to my mind.~~ Edit: I was wrong. Thanks /u/cryo for the correction. &gt; Do not confuse the concept of passing by reference with the concept of reference types. The two concepts are not the same. A method parameter can be modified by ref regardless of whether it is a value type or a reference type. There is no boxing of a value type when it is passed by reference. Source - https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/ref
This is a bit of an issue of dealing with legacy. Sure you can change the signatures but that would break a very old promise with .NET and would cause a lot of application and library developers issues. Is it possible to deal with that? For sure! In software dev, there is always a bigger fish to fry than something like that though and so it stays the same. 
I have updated the original post, the solution builds fine on Debian 8. I agree that the way of referencing the libraries is nasty, but it's fine for debugging when I make changes to a private library that only I use. I currently don't have a server to run my private NuGet feed. I also told you that I get error when I'm not referencing the `System.Threadng.Thread` package - its obviously a problem with the SDK itself on Ubuntu, since I've reinstalled the OS **and** the SDK - the problem persists. On Debian, I don't need to reference the package, because its correctly resolved from SDK. And of course, I have the VS fully updated, but I'm not trying to debug this on Windows - it runs fine there. Right now I'm running headless Debian so I only have the terminal to work with. It honestly doesn't matter to me on what Linux distro the app runs in production, Debian is just fine. I'm just a little disappointed that Ubuntu is such a pain in the ass to get working, even when I just clone the solution from repository, run `dotnet build` and get wastly different results on Ubuntu vs Debian.
Also, the factory could keep internal counters of how many of each type it's created, so every time you create a new one, it increments that counter. And it uses that counter to ID them, so every new one is a unique ID number.
Thanks! This is very helpful!
1. You can directly iterate string instead of character array 2. You don't need to create word array. Just have start and end index and substring out from the input. That was just a quick glance, sorry if I misunderstood your logic. 
Is the solution with using an unbound column not acceptable?
Just FWIW: I got a regex pattern that might do the trick, now: (?&lt;=(\s|^)\")(?:\\"|[^"])+(?=\"(\s|$))|((?&lt;=\s|^)[^"\s]+?(?=\s|$)) That also corrects some boundary problems the first one I posted had. Regexes get nasty really fast, and I'm not 100% certain about that one.
I did this before with StackOverflow's help. [Here it is](https://github.com/Tyrrrz/YoutubeExplode/blob/f24c5b0040ffdded6922fc1b853c3d7155812f0b/YoutubeExplode/YoutubeClient.cs#L512)
Youll eventually learn that functions tend to need to be responsible for more than one thing. Im a game developer and, especially in physics, expect to be working with procedures that dont do much but still return plenty of information or act upon several variables. out and ref variables when used incorrectly do indeed make for unmaintainable code. But so does every other facet of C#. Instead of owning this particular viewpoint, id suggest experimenting with using out and ref until you find a scenario in your code base that it just feels right in. The parameters for "feels right" tend to be that its simple for you to transition to, its easy to use, ends up reducing your overall LOC, and the logical order of expression is consistent with the rest of .NET C# 7 also introduced syntax which made working with out and ref variables super simple and seamless. EDIT: /u/eightvo made a SUPREME example of when and why its used. There are plenty of other scenarios such as in physics casting or in parsing where its beneficial, but his example is prime. EDIT 2: I misread part of /u/eightvo's example, hes on the right track but is his explanation of why it works isnt accurate with how arrays function in .NET.
I'd wondered the same thing, but without knowing what's happening behind the scenes, I didn't know if it'd be slower (eg: iterating the string more often). I'll run some tests! Thanks for the suggestion! *Edit: Found that trying to use a .SubString() return instead of keeping my own "word" that gets built on the fly was actually slower. The logic got complex when trying to manage escaped strings, and trying to do a "replace" was a significant slowdown.* *More surprisingly, there was a consistent 20% slowdown when accessing the value[i] directly instead of first passing it to the character array. I have to assume there's a tiny amount of overhead to value[i] over chars[i]. I mean, we're still talking in the fractions of a millisecond here, so there's that, but just thought that was interesting.*
`"Test"test test"test"` You may have a problem with the interaction between quoted regions and spaces.
I mean roster but I cannot use it because there is a function called roster. I see a error when doing that 
Value types are *not* boxed. The address of the value on the stack (in case of a variable) is passed to the method. And yes, out is like ref since out doesn’t exist in the CLR, only ref. Out is ref + some C# relaxations.
So I use the Dutch word for roster
A Try pattern like that would only work for value types. There is also TryGet in dictionaries, etc. 
&gt; the local flat earth approximation which is simpler and faster. Flat earth confirmed!^.^/s
How useful is service stack since it went pay to play?
I love it. If I were just using it personally I'd probably just stick to &lt; 4.0, but where I work we've bought it in and love it. EDIT: Hey, aren't you that guy from the Warwizard forums? ;)
This doesn't seem to want to work still. :D Here's what I fed it: Command.Say text="super fancy \"quoted\" string" description="This is part of the \"description\"." Here's what I expected: Command.Say text=super fancy "quoted" string description=This is part of the "description". Here's what I got: Command.Say fancy is part of the 
This one seems to have the same problem as [this Regex](https://www.reddit.com/r/csharp/comments/72sbt1/a_fast_way_to_split_a_string_while_keeping_quoted/dnl6tnr/).
ಠ益ಠ But that is interesting; I kinda wish they'd made a version that small developer / personal use friendly. Harder to convince company to spend money on something you can't build (easily) demos with. The limited version seems pretty... limited.
Yeah, I don't know how I want to deal with this scenario. We, looking at it, can see that logically it should be split where the quote ends or begins. However, I feel like that's not a "word" break, so shouldn't "fix" fat-fingering by people. Don't really know if I want to fix it for that reason. If you look at my tests, breaking on a leading quote would make this: Command.Say Text="This is the text" Not work correctly. So if I want to be able to do that, I can't break on leading quotes. If I don't break on leading quotes, then for consistency, I shouldn't break on trailing quotes.
More precisely: out &amp; ref are the same thing except ref requires initialization/assignment in the calling method, before the call, and out requires initialization/assignment in the called method before the return.
The free version (3.7.1? - just specify an exact package number in NuGet), should be enough to prototype with - and until very recently, our project was running on the free version just fine. Not having to arse around with WCF/WebApi/Whatever, and just write RESTful pocos and have it all auto wired-up is fantastic in its own right!
Full stack includes everything from backend to frontend which includes command line applications and non-web based tools... so while a console application obviously won't show case your knowledge of ASP MVC it will at least show that A) You have the initiative to further your knowledge on your own. B) You have at least some understanding of source control (assuming you provide them access to a repository rather then send the files on disc or something) C) It will display your coding style and, depending on the complexity of the console appilcation your software architectural/design abilities and process.
I honestly didn't think that WebAPI was all that difficult TBH. It has been a LONG time since I looked at service stack though so my brain is fuzzy.
Cool. Thanks for the follow up :)
...in C#. In VB the out attribute is ignored and its considered a normal by-ref parameter.
You could use the MouseUp and MouseDown events to more finely control when to set your context menu. https://documentation.devexpress.com/WindowsForms/DevExpress.XtraGrid.Views.Base.BaseView.MouseDown.event https://documentation.devexpress.com/WindowsForms/DevExpress.XtraGrid.Views.Base.BaseView.MouseUp.event
I'll sometimes use an "error" out parameter on a bool method that should only be evaluated if the method returns false.
Thanks, edited!
It's part of Visual Studio now. https://msdn.microsoft.com/en-us/library/dd547175.aspx
We added tuples to c# so you never have to use out again.
Dictionaries, and collections in general, are a specific and different use case of the Try* pattern though. They're not trying to manipulate a given input into an output; they're trying to find and return a value based on the key. The reason they have TryGetValue is because the lookup is the slowest part of the computation; calling ContainsKey() and then referring to the Item basically doubles that lookup work. I'm not saying that the whole Try* pattern should be replaced, just this particular use case could have been handled differently.
 public static bool DoIt(int len, out byte[] buff) if (len&lt;=0) return false; if (buff.length&lt;len) return false; That won't compile. You can't read a property on buff until after you assign a value to it. This is probably what you want: public static bool DoIt(int len, byte[] buff) if (len&lt;=0) return false; if (buff.length&lt;len) return false; for(int i=0;i&lt;len;i++) buff[i]=rng.next(); return true; Note that you don't need the `out` keyword because `byte[]` is already a reference type.
Get the free version... have a play. You'll be a happy WarWizard. Hit me up if you run in to anything.
Well, never mind, then.
&gt; In the first case, a new byte array will be created in local scope No, the byte array will be created on the heap. To allocate it locally you need to use the `stackalloc` keyword. https://msdn.microsoft.com/en-us/library/aa664785(v=vs.71).aspx &gt; Using an out variable the data is copied only once, the second copy once it has been returned to the calling code is not required. You save the expense of copying the reference (i.e. pointer, 32/64 bits), not the array itself. Where this really matters is when working with large value types. For example: struct { long X, long Y, long Z, Color Argb} That's 64+64+64+?? bits that won't need to be copied when using a ref or out parameter.
The simplest fix should be to add the line `students.Sort();` before `return students.ToArray();`. You can also drop the ToArray() since List is an IEnumerable.
&gt; &gt; &gt; /u/eightvo made a SUPREME example of when and why its used. Not really, he is misunderstanding how arrays work in C#.
:D
ServiceStack.Text has been free for a long time now regardless of the version.
I didnt say his explanation was accurate but his code is still consistent with functionality.
&gt; that you won't find in the documentation Why does this sound like it's supposed to be cute or some sort of positive? Or am I reading it wrong? :/
Yep agreed. Just to come full circle, I just think it was initially confusing when you had said Task.Run does not always start a new thread. Which, I guess is technically true, start might be a little ambiguous. What it does do is always offload the work to a different thread than the one that you're already on. It might start a new one, it might just move it to one that's already started, but it doesn't continue on the thread you called it from.
This is one of those places where VB is broken by design. Due to not having a specific Out parameter type, VB instead gives a warning ("warning BC42030: Variable 'c' is passed by reference before it has been assigned a value. A null reference exception could result at runtime.") in this code: Imports System Public Class C Dim s As String Public Sub M() Dim c As C Foo(c) Console.WriteLine(c.s) End Sub Public Sub Foo(ByRef c As C) c = New C() c.s = "asdf" End Sub End Class Changing the line `Foo(c)` to * `Foo((c))` causes `c` to be "passed by value" and changes the warning just like commenting the line out: * `'Foo(c)` (comment the line) triggers a warning "warning BC42104: Variable 'c' is used before it has been assigned a value. A null reference exception could result at runtime." (VB doesn't by default have a definite assignment rule) The "fix" is to allocate a value that will never be used: `Dim c As new C` Yeah... Good job VB, we are proud of you...
Imagine a scenario where you want to return multiple objects. Before C# 7 which brought us proper Tuples, the best method was probably to use 'out' parameters.
Yep, and the EnemyFactory could load enemy types from a configuration file along with their parameters so you can make adjustments to the enemy stats or create new enemies without changing code. You would no longer be able to have an enum type listing all possible enemies, but you could create an enemy "class" like "Level 1, 2, 3, ..." and then you could use an enum in your GetEnemy method to specify which class or level of enemy to instantiate. Then you could randomly instantiate any of the enemies within that class.* Sorry for reusing the word class in this way, when I say "enemy within that class" I mean an enemy with some identifier which says it's a "level x enemy" or something similar. Could just as easily be split between land, air, and water based enemies etc.
&gt; Due to not having a specific Out parameter type, VB instead gives a warning ("warning BC42030: Variable 'c' is passed by reference before it has been assigned a value. A null reference exception could result at runtime.") VB doesn't need an out keyword, they could just suppress the compiler warning when it sees an out parameter. That said, I think it would be better if VB did get an out keyword.
A reasonable change would be something like identifying the sub as setting the parameter in all code paths before using it and noting it as an out parameter. An out keyword isn't strictly necessary. An out keyword could be useful though: Public Sub Foo(OutRef c As C) which would then not warn (in either an explicit variable version or a detected version) on Dim c As C Foo(c) Console.WriteLine(c.s) But would have a different warning if you passed by value: Dim c As C Foo((c)) 'warning ???: variable passed by reference explicitly as out parameter is not captured in local variable Console.WriteLine(c.s) 'warning BC42104: Variable 'c' is used before ... 
Tuples are fine for private methods, but public methods returning Tuples are sketchy as they're too poorly defined. Usually I prefer going with the extra step of creating a "BlahResult" class/struct to contain multiple values UNLESS I'm dealing specifically with a "bool TryDoOrRetrieveSomething(..., out value)" pattern. 
I was hoping not to have to, but it is fine now. I was hoping to be able to add columns later and have it reflect on them. I guess I could do that in the unbound column. So I guess to answer your question, I think it will have to be good enough for now. Thanks for responding, I am new to dev express. 
None taken Cristo, best of luck to you as well! Thanks again :)
My rules... MIT or Apache license Recently updated. Isn't just some currently hyped stuff. Actually is something that saves a lot of time. Their is no need to reinvent the wheel every freakin' day 😉 
In addition to what's been said already, you could change this: &gt; public IEnumerable&lt;string&gt; Roster() &gt; { &gt; var students = new List&lt;string&gt;(); &gt; foreach (var item in Rooster) &gt; { &gt; foreach (var student in item.Value) &gt; { &gt; students.Add(student); &gt; } &gt; } &gt; &gt; return students.ToArray(); &gt; } &gt; To this: &gt; public IEnumerable&lt;string&gt; Roster() &gt; { &gt; return Rooster.SelectMany(x =&gt; x.Value); &gt; } 
Being curious coming from a Python background, why just not try to parse it and throw an exception of you can't? 
Exceptions are only to be used when something is, well, exceptional. When parsing strings, you might expect that something is going to be wrong a greater-than-0 amount of time and that you can do something about it. In that case, it's preferable to avoid exceptions (since they have to unwind the call stack and interrupt program flow) and just have a method that returns two values: if the value can be parsed, and if so, it's value. Since C# only allows a single return value, one of those has to be the output parameter. The biggest catch is that you have to remember to check the return value. I've seen devs mess this up before, but I think ReSharper will catch this now and warn you. In a functional language, like F#, instead of returning two values, you could return a Maybe value that either has a value or doesn't. In this way, you can force code to handle both paths.
Ok so this is a kind of big topic with lots of concerns that can be very situational. First in .NET most of what we do professionally is about leveraging code others have written. In simple terms a 3rd party library is just like a library project you would create and reference in your own solution. Its just pre-compiled and you have little to no control over the code that runs. You yourself can write libraries others would use as well. In general it is a good idea to think of your code as if someone else is going to leverage it, this keeps you from burning yourself in the future. **How do you decide whether a (third party) library is safe to use?** There are multiple considerations I look at when trying to pick a 3rd party library to solve a problem I have: * Does it actually solve my problem? * Does it require me to change my application design? * Does it prevent or limit me in some other way (IE try to avoid being married to a component you use)? * Does it have a license that allows me to use it in the way I need to use and distribute it? * Is it able to be supported (either by the company or community)? * Would I be able to do what I need myself more quickly or in a better way than the available 3rd party libraries? (if you are new the answer to this one is no most of the time) There are a number of other questions that may come up and their answers may or may not affect your choices to use a library but you should ask yourself these and make sure you formulate and understand your answers. When in review these would be the kinds of questions a senior or lead may want answers to. **Will libraries keep working when downloading them and including them in your application? Can the owner still change it some way or another? Or as long as you keep the same C# version there shouldn't be a problem? Since they're downloaded** Most people these days bring in 3rd party libraries using a tool called NuGet (this is built into VS now). This tool has you pull a specific version of a library and you will only pull that version going forward. You have to manually update to a newer version. In general this means that original authors will not change things on you unless you take a later version manually. It is important to note that this is a convention. While frowned upon it is possible to update an existing version with a new binary in-place without the people using the library knowing it. This is extremely rare and I have only ever seen it done with an internal NuGet server to fix a build issue caused by a custom powershell script. The older more traditional method of just keeping a copy of your dependencies is still done quite a bit as well though NuGet is so much easier most go there first. **Do you try to use as many libraries as possible? That does minimize effort, but isn't there a security risk?** This really varies depending upon both my goals and the goals of the system. In some cases you may want to 100% own everything, in which case you might use nearly zero 3rd party libraries. In other cases you will use a ton. Personally I tend to pull in 3rd party anytime I can as long as adding that component is quicker and easier than writing it myself (along with the other questions). I prefer this because mainly the task I need to complete has little to do with what the 3rd party library does for me as its just step 8 in a 22 step process. I don't really want to spend weeks writing things others already have, I want to focus on what my stakeholder asked for. 
So are you trying to just get rid of the quotes?
The only justification I can think of off the top of my head is if you've got a variable who needs to be able to be spontaneously modified within any given scope but you don't know exactly when where and how-- then those points at which you are possibly going to change it would be really good candidates for out keyword functions. Obviously as others have said, tryparse instances are the most common use, but other than that the big picture reason to use the out keyword is when you need to be able to pass a single variable around through a lot of interlocking scopes ; out keyword just allows you more fluid chain of command in the modification of the named memory space allotted. Obviously, practically there's not a huge difference between using out or just spooling up a new variable. If you want to be able to keep dealing with the exact same variable then out is a pretty effective tool, though.
Mobile apps? It's true, and you're looking for Xamarin. If you're making a game, MonoGame is good for that too. As for the last part, I have no idea. I hate mobile development. https://www.xamarin.com/
Inheritance doesn't solve the "enemy type" problem very well. You'll run into issues later on down the line when you want a Cat Dragon, where it has characteristics of both Cat's and Dragon's.
C# is used to make mobile apps but it is not the only system out there nor is it the #1 platform for mobile apps. If you are familiar with the Microsoft ecosystem of tools it will likely be the least steep ramp for you. There is nothing you can or cant do on the Microsoft platform so its a good place to start. If you plan on making mobile apps a major part of your career it may be a good idea to learn some other platforms as well. 
You can build a pattern that will work you just need to spend time on it likely starting with something close. A regex builder tool can help a ton here unless you are one of those that can regex in their head.
Seems odd to me, but then again people say the same thing about exceptions in Python. Ditto on multiple return values (though, it seems like y'all are excited about that). You also don't have to unwind the entire stack, you could do something like: try: x = int(some_input) except ValueError: # not a valid integer representation x = 0 # or some other default `int` doesn't worry about having to return some boolean value or fiddle with re-setting references, it just throws its hands up and makes it someone else's problem. 
Alright, I spent probably a bit too much time on this, but here goes. I Would split this up into 2 classes. The first class would hold information about the Type of enemy it is. public class EnemyType { //this construct turns ID into a property //Properties can have different access levels //for different usages of them. //for example outside of the EnemyType class //if you had a EnemyType named crowType //This would be valid //int CrowID = crowType.ID; //but this wouldn't be //crowType.ID = 4; //However, inside the class //that second statement would be valid. public int ID { get; private set; } public readonly string BaseName; public readonly int BaseHP; public readonly int BaseXP; private EnemyType(string BaseName, int BaseHP, int BaseXP) //private constructor, so that you can ensure that an ID get's set in the "RegisterEnemyType" Function. { this.BaseName = BaseName; this.BaseHP = BaseHP; this.BaseXP = BaseXP; } public static IDictionary&lt;int, EnemyType&gt; EnemyTypes = new Dictionary&lt;int, EnemyType&gt;(); //Dictionaries are access exactly the way you want //IE if you want the EnemyType that was assigned the ID 1 //the call would be EnemyType.EnemyTypes[1] private static int nextID = 0; private static void RegisterEnemyType(EnemyType et) { et.ID = nextID; EnemyTypes.Add(nextID, et); } public static void LoadEnemyTypes() { //later, you can replace this with code that loads enemyTypes from a configuration file //so that you don't have to code each enemy in to the game //and can add more enemyTypes without RegisterEnemyType(new EnemyType("Crow", 5, 5)); } } The second class would have a reference to the first class, and information about values for a particular enemy. public class Enemy { private EnemyType type; public int currenthp { get; private set; } private int maxhp { get; private set; } private int xpvalue { get; private set; } public String name { get; private set; } private Enemy(EnemyType et) { this.type = et; this.currenthp = et.BaseHP; this.maxhp = et.BaseHP; this.xpvalue = et.BaseXP; this.name = et.BaseName; } public static Enemy getEnemy(EnemyType et) { //Complicated logic could be implemented in this //method that adds modifiers to an individual //enemy's attributes //like say if you wanted 1/10 enemies //to be 50% stronger //you could take a reference to an enemy //Enemy crow //and in this method do things like //crow.currenthp = crow.currenthp * 3 / 2 //crow.maxhp = crow.currenthp * 3 / 2 //and other things return new Enemy(et); } } Then in order to do what you want to do, you could have this type of code. EnemyType.LoadEnemyTypes(); //do other setup work Random r = new Random(); while (true) //main loop for game state { int nextID = r.Next(EnemyType.EnemyTypes.Count); Enemy e = Enemy.getEnemy(EnemyType.EnemyTypes[nextID]); }
I'm sure he's talking about unity which uses c# as it's script language.
C# is used in unity which is very powerful for mobile app dev. Blizzard is actually releasing it's next game as a mobile app using unity.
https://unity3d.com/learn/tutorials/projects/2d-roguelike-tutorial Give that a shot.
In C#, exceptions (almost) always unwind the stack. That's just how they work. But making that someone else's problem can cause more issues since program flow is no longer straightforward. You can crash an application, for instance, if you don't catch the exception.
Same thing happens in Python. I typically have a catch all at the top most layer I can go prevent exceptions from crashing the program. I like exceptions for dealing with unusual cases. In the case of int, it thinks getting an invalid representation is unusual and doesn't want to deal with it since it doesn't know how to. Similarly, for loops in Python essentially desugar to: it = iter(iterable) while True: try: run_code(next(it)) except StopIteration: break You and I don't think that's unusual. Strings can contain things that aren't valid integer representations and hitting the end of an iterator is completely normal. To us. But exceptional conditions are local to the callee. 
I'm attempting to create my own control to achieve this. I know it's a fairly rudimentary drawing tool at this point but it's the first time I've ever messed with drawing features. It's all I can do to keep it from flickering. https://pastebin.com/N1YmGyK9 Now that it's somewhat stable I'll start adding rules like rectangles cannot overlap or extend off canvas.
That's a possibility, but if you use Unity for anything but a game I'll have to call you crazy. :eyes:
The documentation here means the public documentation on msdn. So it’s not meant to be cute, the book of the runtime talks about all the internals of the runtime, which wouldn’t make sense to talk about in the public documentation. There’s a lot of deep technical information in BOTR. It’s a good read if you really want to understand how and why the clr works the way it does. 
Exactly.
Since this is /r/csharp VB being different is moot.
Remember that this is a C# sub. Using out on a reference type has semantic meaning. The byte array variable passed into a method will be set by the called function. It's not a recommended usage, but it is allowed. Of course, from a design perspective, ANY use of out or ref is really bad anyway, since the method is perforce violation the principle of high cohesion.
I'm not familiar but I'll have to check it out. Thank you
Okay will do. Thank you
Don't give me that bullshit. 1. He posted code that literally can't compile. 2. The semantic meaning of the `out` keyword is the same as it's syntax rules, namely the called function will change the value if the provided argument. 3. Your "principle of high cohesion" doesn't exist. The reason we're supposed to avoid ref/out parameters is simple because they are harder to understand. (see .NET Framework Design Guidelines) 
It is important for understanding what actually happens at during JITing and at runtime.
Exceptions are expensive, both in performance and in the amount of code you have to write to deal with it. So it's common to have two methods, a normal exception throwing version and a Try version that uses an out parameter. The latter is used in if statements.
What about using diskpart at an elevated command prompt? I'm not sure if you can use the DELETE or FORMAT operations, or change the partition type (SETID) on a disk that's currently online though. I don't have a VM handy to test.
Awesome! That was immensely helpful.
I use third party libraries if they got the following criteria: 1. It's open source, 2. It's small enough that it would make sense to include the project (s) in my solution if I have to, 3. I can read through the code and understand what's going on, and 4. There are enough people working on the project at the moment so I have someone who can field questions I might have. Hope this helps!
i was saving diskpart clean as my last resort because i doubt it will work.
Unwinding the stack in .NET (or any compiled/JITted language) is very expensive relative to normal operations. You can easily measure the overhead. Perhaps it is not so in Python. If you are expecting that the input can be invalid, then it is not an _exceptional_ condition when it is, and so _exceptions_ should not be used.
But since you don't understand that in C# you can declare a parameter which is a reference to an object to be an out/ref parameter, I am fairly certain you have no clue what is going on.
I was trying to look into xamarin to understand, can I use it in my next project. I failed to find anything useful slightly upper typical "hello world" example. Everything is under paywall. I wonder why it is like that...
What bullshit? Teaching you that you are wrong about out/ref? That we have known for 60 years that having a function do multiple things is bad design? 1) I posted no code. 2) You said that you don't need out in the parameter declaration. That is just plain wrong. In C# ref/out ALWAYS means that the called function changes the variable passed in. For a value type, that means that a new value is placed in the variable that was passed in. For a reference type, that changes the object the reference points at. 3) You are no one that I would want working on anything I have anything to do with. I wouldn't hire you.
You a russian bot?
Hm. Makes sense I guess. Is it at least linked for those that might be interested but otherwise wouldn't know it exists? Like "external resources" or some such?
I'm pretty sure this violates rule 2.
Depends on the platform. For iOS, Swift would be the obvious choice.
Yes, C# can do the same via P/Invoke, which lets you call any win32 function directly from C#.
Sounds like someone does not know what realtime means. https://en.wikipedia.org/wiki/Real-time_computing
What?
As others have said, that's not usually how exceptions are used in c#. Besides, if that is the behaviour you want, there are Parse methods that do just that.
1) You can write mobile apps in C/C++ using the appropriate SDK. For iOS you probably need to write a thin ObjC abstraction layer. 2) Adobe PhoneGap is a framework that allows you to write cross-platform apps using web technologies. 3) As mentioned Xamarin
I like using out along with vars not defined at declaration. Int x; ... ... Switch(...) { Case .... Case .... Case .. If (tryget(..., Out x) ... .... Use x Since the compiler is so good at detecting when a var is defined through separate code flows, the pattern above will actually force all of the case paths to set x to something. This is great for making sure all flows through a complex if or switch explicitly sets x. Prevents someone from comming along later adding a case or conditional and forgetting to set x.
I don't know much about real time computing. In fact that's exactly why I went to the wiki page you linked where it says The term "real-time" is also used in simulation to mean that the simulation's clock runs at the same speed as a real clock, and in process control and enterprise systems to mean "without significant delay" By that definition, does that mean the majority of those apps qualify as real time? Not trying to be an asshole, just trying to understand. 
Check out Rapid Addition's FIX engine.
At work currently, but here you can read more information: https://superuser.com/questions/406819/what-does-windows-is-not-a-real-time-operating-system-mean
With real time systems the "operating system" (it may not even be a full operating system) will allow a program to control every aspect of when it runs. It's scheduling. In OS's like Windows for example the OS decides how much time a program gets to run, and will switch to a different application so that everyone gets a fair shot at the prize. So if the OS is interfering like that, it means there's no guarantee that your real time program will be able to respond in real time. And "Real time" might mean in a microsecond or a millisecond. Windows will allow you to run progams that do a billion things in a microsecond, just not let you choose which microsecond. Now, .NET adds a layer of complexity on to this because it's managed. It has a process to clean up memory for you. In newer versions you can actually control this more, specifically for real time applications, so you're not wrong about being able to do real time stuff with .net, there are just caveats. Short version as I'm off to work now!
Ah yea, I think I was a bit quick to reply, a while back I had a similar but different problem :) If you don't want to change the datasource type for reasons thats fine. But you could still achieve what (I think) you want without Unbound columns and mainly not having to keep any changes in sync. // For example as a wrapper that exposes properties to a datasource public class BusinessAssociateRelationWrapper { private BusinessAssociateRelation businessAssociateRelation { get; set; } public Relations // And other exposed properties required in the datasource { get { return businessAssociateRelation.Relations; } set { businessAssociateRelation.Relations = value; } } public Guid LegacyId { get; set; } public BusinessAssociateRelationWrapper(BusinessAssociateRelation businessAssociateRelation, Guid legacyId) { this.businessAssociateRelation = businessAssociateRelation; LegacyId = legacyId; } } And could be created from: List&lt;BusinessAssociateRelation&gt; businessAssociateRelations = SomeBusinessLogic.SomeManager.GetBusinessAssociateRelations(); var dataSource = businessAssociateRelations.Select( x =&gt; new BusinessAssociateRelationWrapper(x, /* Some way of getting LegacyId from x */)).ToList(); Useful if you have alot of logic, that you don't want in the presentation, for modifying a wrapped object. Or when you need a datasource that works as a controller for multiple objects. Edit: constructor name in class
Late to the party, but what's wrong with taking screenshots and parsing them? This seems to be the fastest and most safe (to avoid ban) solution of all. You could take screenshot every 2 seconds or so, parsing it should not take more than split second. Not sure how resource hungry would it be, but injecting dlls or running game through different processes will get your users banned... Just first create a program that takes screenshot every second and check in task manager how CPU and memory intensive it is. I think it won't be significant.
Thank you very much! This answered everything I wondered :)
Practice makes perfect! ..but if you think you can get away with not writing tests, and unstructured learning in a company with more than one developer, you're gonna have a bad time.
Be careful of licensing legalities.
Rule 2?
It wasn't always free but Microsoft bought it and now it is.
I think by tests OP meant examinations rather than unit/integration/etc.
They also used Unity to make Hearthstone.
You'll probably want to nail down what sort of apps you're looking to create (which in part should be influenced by the job market if you're looking to do this professionally) If you want to make games, Unity which uses C# is a good place to start. If you want to make cross platform apps that run on iOS and Adroid then Xamerin is one of the options available which is C#. Though there are pleanty of others including phonegap, cordova and React Native which is starting to become the market leader where I am. If you want to build iOS apps specifically then look at Swift for Android look at Java
Removed: Rule 2, maybe Rule 1ish. It's a bit out there, and lots of people learning here. Don't want anyone accidentally corrupting their own system. Plus, it's someone on the internet, surely we can trust that this is for altruistic purposes.
/r/csharp has rules in the sidebar: https://www.reddit.com/r/csharp/about/rules
I meant that I was not able to find any free good books/lectures/articles about it. 
Sounds like someone doesn't know that the same term can mean different things in different contexts, and that in the context of web applications, real-time just means that a bidirectional communications channel is maintained between the server and the client. Edit: [link](https://en.m.wikipedia.org/wiki/Real-time_web)
Code reviews are a thing too ;)
If the place where you're trying to use it is in the same method as the foreach loop, you could just declare it outside the foreach loop without setting it "Subreddit subreddit;" and then just set it in the loop "subreddit = TryGetSubreddit(subredditname);". If it's in a different method, you would either have to store it in a class variable (outside the methods, in the class itself) or pass it in as a parameter to the method that needs it, if it's known where that method is called from.
Look up what a "property" actually is.
I've used out when I need to pass more than one object back from a function. Like in an API. Passing a status or error class in the return and requested data in the out
I'm out of the loop, which game?
I already solved it. All i had to do is pass along subredditname, since the part where i wanted to use it was still in the loop
https://docs.microsoft.com/en-us/dotnet/core/deploying/
i have tried following the guide https://docs.microsoft.com/en-us/dotnet/core/deploying/ but keep getting error, HTTP Error 502.5 - Process Failure i guess it's not really c# related. Will have to look more into it.
HTTP500 errors are related to the server. Have you looked up the error code?
You need to isolate the appdomains completely by inheriting [MarshalByRefObject](https://msdn.microsoft.com/en-us/library/system.marshalbyrefobject(v=vs.110\).aspx) on **every type** that needs to be accessed in another appdomain. Instances of these types must be created using `AppDomain.CreateInstanceFromAndUnwrap`. Overhead could end up being an issue but I have not measured it before. Accessing things between appdomains requires serialization from the source appdomain and deserialization to the target. If you don't use `MarshalByRefObject` properly your assemblies will leak through into other appdomains because the serialization can trigger an assembly load. I have a test project [on my Github](https://github.com/Rohansi/PluginTest) where I got this working properly on Mono for use on Linux. I never got around to using it so I hope you find it useful!
You're a hero! Thanks!
It hasn't been announced. An MMO RTS is all I know.
I literally just went through this yesterday. I use winhost and was getting the same error. I ended up having to edit the .csproj file (VS2017) and add the relevant runtime ID for windows server 2012 (i.e making it self-contained). I also had to change my dependencies to target 1.1 (they were targeting 1.1.2) since the winhost server didn't have 1.1.2. After doing both, my website is up and running.
You cannot directly reference objects across app domains, so you need some kind of remoting setup to talk to your DLLs from the main app. It's not much different from using microservices in this regard. How much of a disadvantage this is depends on how tightly your architecture is coupled. Per-method overhead depends on the kind of remoting/service communication you're using, but will be significant relative to direct same-domain calls. Support for multiple app domains is also permanently gone in .NET Core, in case you're considering a cross-platform port in the future.
At this point, it'd be easier to use a stringbuilder and read each character one at a time. Also, google "OptionSet C#" and make your own variation of it. OptionSet is nice for parsing and organizing command line arguments. I might have my own implementation somewhere on my github. I'll have to che k and see at some point.
&gt; Support for multiple app domains is also permanently gone in .NET Core, in case you're considering a cross-platform port in the future. Well that's a full-on show stopper. These servers will be on Windows Nano Servers, which is .NET Core only. Thanks for the heads up!
This is spam.
Xamarin is good. You don't want to use some lightweight framework that doesn't offer the full functionality of the platform. Xamarin isn't the only way to build "professional" mobile apps however; most Android apps will still be coded in Java, and iOS developers will largely be using Swift or Objective C. The main advantage of Xamarin is that it allows a C# developer to apply some existing knowledge to additional platforms. You will still need to learn about the inner workings of those platforms to understand issues with your apps. Most of my learning on Xamarin and Android has come straight from the Xamarin docs. I recommend starting there.
This is a property, note the lack of brackets: protected int GraduationYear {get{return Year;}} But your error is because on line 43 you call student.GetYearsSinceGraduation()), with no parameter but your definition is, line 17 public int GetYearsSinceGraduation(int year), which requires an input parameter 'year'
There is an [open issue](https://github.com/dotnet/coreclr/issues/552) on .NET Core's Github for collectible assemblies. That would replace appdomains for this use case while also having less overhead. It doesn't seem to be a high priority though.
Also, @OP: you can have essentially a shared codebase if you use Xamarin. In theory, it'll make cross platform a breeze.
Probably. I'll allow this submission for now (there are far worse spammers out there). But /u/talisoroker, consider this a warning. Please review [Reddit's guidelines for self-promotion](https://www.reddit.com/wiki/selfpromotion) and participate (commenting/discussing, submitting other materials) outside of your own submissions.
Thanks! That's a good way to decide! Didn't think about the licensing.
Another reason to use the `out` keyword is to see if your code reviewer is paying attention :-D. I prefer using `goto` for that though haha.
I'd like to meet the C# developers who miss checked exceptions. I don't believe one exists but if he does I'd like to take picture with him.
Non-sequitur. Whether or not "he has a clue" is irrelevant to what he said, even though I doubt you yourself could claim to have a perfect understanding of everything. But this isn't /r/howtoavoidlogicalfallacies, so I'm just gonna say you are being an unhelpful asshat.
oke, so I have to give line 43 also a parameter and what about line 34. 
I don't miss checked exceptions at all, and haven't met anyone who does!
I'm not sure why I got down voted for a verification question, but whatever. My thinking was you could just use the .Replace on the string... Simple, straightforward. But if you're not just trying to remove quotes from your string, that's not going to work as well.
Here are some websites that I still use for C# http://freecomputerbooks.com/ http://www.onlineprogrammingbooks.com/ This website is mostly web app development http://www.dreamincode.net/ 
GraduationYear will no longer be a method, it will be a property. You can make a property 'settable' by giving it a setter. protected int GraduationYear {get{return Year;} {set { Year = value;}} Get is the value it returns when you use it. ie. X = GraduationYear; Set is what is called when you assign it. GraduationYear = X;
... get a new host
Downgrade your project to 1.1. I doubt you are using a 2.0 exclusive feature, some host providers take years to update to a new version.
Guy(s) who invented them must have liked them long enough.
Possibly namespace related. Your XML snippet is incomplete, but if the document defines a default namespace then the unqualified name in the XPath won't match.
Thanks, you saved my life. 
Why bother testing? If there is no clear advantage then it is a waste of time. Just look at the number of packages on nuget.
Sadly, I have no idea what you are talking about. Other than that it's not a complete XML file.
https://en.wikipedia.org/wiki/XML_namespace https://docs.microsoft.com/en-us/dotnet/api/system.xml.xmlnode.selectnodes#Remarks
maybe an unpaid or low paid internship?
It would probably depend on what mood you caught me in, but I did very little actual Java development, so take that with a grain of salt. On the whole, I don't think they're beneficial, but I do find myself wishing for documentation of what a given method could be expected to puke back in the way of errors, which usually means wishing my coworkers bothered to document anything of the sort. This lack of information leads to a lot of 'Pokemon exception handling'. Unfortunately, checked exceptions in Java seemed to create even more of that.
Removed: rule 4. Feel free to repost it but please include the error you're getting and the line. Also, please make sure your code is formatted for display on reddit.
I thought they were neat at first. Then I tried to write a lambda that called a method with a checked exception. And ended up having to write my own functional interface. Ugh. Actually, c# first class functions are superior in basically every way, with​ with the exception of being able to reference instance methods without an instance (using a signature like an extension method), 
1. `sort` only exists inside of the `for` loop. If you are trying to display `sort` after the loop is complete, it isn't in scope and will not be available. 2. `new List&lt;int&gt;(max)` creates a new list of integers that has a starting capacity of `max`, not one that contains the integer value in `max`. This may not do what you intend. 3. Knowing precisely what error you're getting would be helpful for diagnosing your problem. 4. Mutating a collection as you iterate through it is a great way to have fun with boundary errors of various types. It would be safer to build your sorted list and then remove the elements in `sort` from list when you're done. But! `List&lt;T&gt;` has a `Sort()` function that might solve this problem for you without having to manage a second list or do the sorting yourself. Or you could use LINQ. Some examples: // sorting a List&lt;T&gt; in place list.Sort(); // list is now sorted from smallest to largest list.Sort((x, y) =&gt; -Comparer&lt;T&gt;.Default.Compare(x, y)); // list is now sorted from largest to smallest // sorting with LINQ list = list.OrderBy(x =&gt; x).ToList(); // list now contains a new list, sorted from smallest to largest list = list.OrderByDescending(x =&gt; x).ToList(); // list now contains a new list, sorted from largest to smallest. YMMV.
Its linked off the runtime source repo read.me with more instructions like how to build, test, how to contribute etc &gt; [Documents Index](https://github.com/dotnet/coreclr/tree/master/Documentation) &gt; This repo includes several documents that explain both high-level and low-level concepts about the .NET runtime. These are very useful for contributors, to get context that can be very difficult to acquire from just reading code.
Where did you hear it from? I googled a bit and all I saw was that they were looking for people to develop an FPS game.
https://www.reddit.com/r/AndroidGaming/comments/72uu6k/blizzard_is_working_on_a_new_mmo_rts_for_mobile/ Looks like the job posting was taken down.
Covariant return types would truly be nice to have.
Since I use effort and seeds I know the state of my database in every test. 
Maybe some people like to absorb the information that way and don't come to the comments to complain about it. I bet there is a written guide about the same out there somewhere.
Actually not a bad idea. As long as you are actually being mentored properly. Other than that I'd say a pluralsight membership is good .. if you can't afford it Microsoft has a free club u can join for a month or two free pluralsight subscription Lastly just google and a real desire to learn is all you actually need. 
can confirm I did microsoft virtual academy and learned some stuff. My boss bought me a pluralsight sub so I was using it until life to a bit busy. I'm technically employed as software engineer...but often times I feel confused as all hell
49 comments and no REAL solutions
the thing /u/nimbomob mentioned is called "Dev Essentials." It's worth signing up for and I think you can do it via here: visualstudio.com You'll get a large collection of things, including a 3-month pluralsight token. It might be worth holding off on that, doing some other stuff from online (Like MS's virtual academy), and then using the pluralsight sub so you can pick a choose a little more what you study. You'll also get some credits for Azure and such.
I have to think that the reason no other language has them is because they're pretty universally hated. Languages steal features from each other all the time. But noone has stolen checked exceptions...
you did not just post a document covering the intro of a course that you did not make, for a C++ dev project, on a C# sub, right? Right?!?!?!
Hey, I'm not complaining. Makes my job easier. EDIT: Scratch that. I'm complaining. More work for me. Would have preferred they bother the /r/cpp mods instead. :P
Removed: Rule 3, spam.
Goto CodeWars.com, select C# and test yourself. Keep solving challenges daily and you'll get better and better at the language. The challenges are trivial but guess what? These trivial questions are the very things you'll be asked to code in interviews for entry level roles! You want to be a better coder? Sit down and code. Don't relent.
Yes, there are many downsides of AppDomains. So many that they aren’t included in .NET core. 
The OverOps entry is so forced it's humerus. Ad guys aren't even trying anymore. This post is OverOps's version of Nintendo's "The Wizard".
There are also [auto-implemented properties](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/auto-implemented-properties) where C# creates the variable for you. They look like this: protected int GraduationYear { get; set; } You can also assign the get and set methods different visibility, such as `private set`.
It may not be a popular opinion (because it's certainly not as cool), but is there a reason you can't just spin up a new server instance, and slowly drain connections from the old server instance before shutting it down? I've got a server app at work that I'm responsible for that's had 100% uptime for almost a year now. When we update it, we install the new version on a different server, watch its behavior, and then spin down the old one. It's incredibly easy to automate, and it removes the need for your code to care about its own deployment.
I mean, I'm 1 part of a team with like 1.5 developers on it, so it's just a natural part of development when we make a piece of the system that uses those things. My title is Senior Software Developer. I expect a senior in C# to be able to set up a build server, a deployment server, and allocate and consume resources on Azure.
You're in luck, as C# has acquired some very nice cross-platform mobile development frameworks in recent years, and it's not terribly difficult to learn from a C++ background, since much of the syntax is the same or very similar, so your learning curve won't be very steep. I'd recommend (if you develop from a Windows machine) making sure to get the latest version of Visual Studio (2017), so that you get the baked-in support for Xamarin. (As others have mentioned, Xamarin is the name of the framework used to target mobile platforms.) Microsoft still has a free version of Visual Studio for home use, so look up Community Edition if you don't already have VS2017 through some other source. Since good support for mobile dev is a bit of a late feature, and C# has evolved quite a bit since it was closer to C++, I'd recommend learning C# in the abstract first, and then mobile development using it. I'll try to give you the cliff-notes version of basic differences: * C# calls compiled code artifacts, whether DLLs or executables, 'Assemblies'. Assemblies are self-describing, as they contain loads of metadata (including some comments from source code) baked into the final product and programmatically accessible. * There's no header/code file distinction because you don't need separate headers to describe the assembly. You can define a single class across more than one file using the 'partial' keyword, though. * C# uses a paradigm where source code files are more tightly representative of the compiled code. It doesn't have very distinct linking steps like you'll see in C/C++ (they do happen behind the scenes, but you'll almost never see them). * In C#, you use libraries by adding them to the project as a reference, and then everything the library offers publicly is immediately available. Usually, though, you'll want to use a 'using' statement at the top of the source code file so that you don't constantly have to 'drill down' through the namespaces, which tend to be quite verbose. It's very similar to a 'using namespace' statement in C++. * C# doesn't compile to native code (x86/x64) unless you take some special steps, it compiles to an intermediate language (IL) that is then compiled at run-time (Just-in-Time or JIT) for specific processors using very thin virtual processors that translate the code into something the real processor understands. This lets it run much more easily on a wide variety of platforms and architectures, and also has some performance benefits of allowing late optimization for specific machines. * C#'s main set of libraries is called the ".NET Framework". You'll use this instead of the standard libraries you're used to, and it has (in my experience) far more features than the standard libraries even with boost. * Similarly, there's little to no preprocessor support, so you sidestep a lot of the #define soups that C++ tends to become. (Most of the things that really needed that are already taken care of anyway, so you probably won't miss them.) * C# doesn't have quite the fine-grained memory management (except in a few well-defined places) that C++ does, but it has a very good garbage collector, so you'll probably find it much easier to write code that doesn't leak memory. * C# does not allow data storage (variables) outside a class, nor classes in the global namespace. (You can still create de-facto globals with singleton patterns, but I'd avoid it like the plague.) * C# does not allow multiple inheritance. Instead, classes can implement multiple 'interfaces'. Interfaces are a key concept of C#, that describe something a class can do or be without defining anything about how it happens (no code). This is similar to inheriting from multiple completely-abstract classes, but with more restrictions. The upshot is that the .NET Framework (and even the language itself) uses interfaces extensively, which can make it easier to perform many tasks. For instance, any class (usually representing a container of some kind) that implements the IEnumerable interface can be operated on with a foreach loop. * C#'s reference types act a lot like C++ pointers, except that you don't have to worry too closely about them being disposed of properly. Good news is that a null reference doesn't segfault the program, it just throws an exception like anything else. * The C# value types are closer to plain-old-data types. But do be advised that there's more cross-over between value types and reference types in C#, and that can have performance penalties in places you might not expect. (Look up 'boxing/unboxing' for more info.) * C# has a type-system that is fully aware of itself, and you can access that information using 'reflection'. This makes some things that were very difficult (but useful!) in C++ quite easy in C#, such as finding all descendant class types of a particular class type. * C#'s generics look like templates, and they function similarly in most cases, but they don't depend on foreknowledge of the specific type that will be used to compile like C++ templates do. * You won't need to do a lot of project configuration. It's good to look over the settings boxes and become familiar with them, but it's dramatically simplified from C++ and the defaults are usually fine. For more specifics, where to start probably depends on how comfortable you are with newer language features of C++ (C++11 &amp; C++14), and your appetite for newer features. If you're much more comfortable with C++98 and not in a hurry, I'd suggest starting with tutorials for an older version of the language, like 2.0 or 3.0, as the flurry of newer features can be distracting from the basics. On the other hand, if you're already familiar with things like lambdas (or are just ready to dive into unfamiliar territory head-first), you might want to jump straight to the newest version, C# 7.0 so you can get right to the more modern practices and take advantages of the shortcuts and features. (As an aside, If you do decide to start with an older version, I'd suggest skipping the old asynchronous programming models, as those were heavily re-vamped with much better tool-sets in later versions.)
Yep. Not usually a "google it" kinda guy, but this is like "chapter 1" information. OP needs to put in more effort to succeed.
I find it interesting in that it forces you to either handle or document exceptions, but it's way too bulky to be something that you have to do everywhere all the time. Be nice to have something like that for when writing, say, APIs where you want every last detail to be documented. I'd imagine ReSharper does that but it's out of my price range, anyone know of any good alternatives? Something that would just throw a warning on a method if it calls something that could throw an exception but doesn't handle or document it.
Also for less popular libraries check the "Issues" section of the repository if it's on Github. That will give you an idea of potential problems and whether it's dead/dying. Posts like "is this library dead" or no apparent recent activity anywhere from the developer in response to issues are a warning sign.
News article about this too: https://arstechnica.co.uk/gadgets/2017/09/microsoft-quantum-computing-toolkit/ 
Don't have your logic in the database and don't have your unit tests depend on the database. Problem solved!
It's cray cray, as the youth say.
Do you mock your databases then? I feel that creates a swarm of new problems.
What if you’re trying to test your database repositories or database constraints? Some of our systems still use stored procedures and it’s nice to run tests against the calls to make sure they’re all updated after a deployment. 
Yes, you mock the results of the stored procedures. Like: GetProductByID(1) {return new Product("Reddit Gold", 1);}
You can use respawn even for non-unit tests. Unit tests are not the only tests.
Thanks you so much for the insight! I really appreciate the help.
I've been having the opposite problem. No compile or runtime problems in Unity, but VisualStudio won't clue-in and still thinks the project doesn't support the C#6 features. 
What are the uses of this that don't violate the Liskov substitution principle?
A qubit doesn’t represent 0, 1 or 3. It represents a probability distribution on {0, 1}. Qubits, and quantum computers, are inherently probabilistic. It’ll not be a part of C#.
Or a Rule 4 post. 
Most people don't understand qbits, I don't really. But the best explanation I've seen is to image a sphere the north pole being 1 the south pole being 0. When interacting with them you rotate around the sphere. If you ended up on the east pole when collapsed into a bit it would have a 50 / 50 chance of being a 1 or 0. So if you retrieved the value 1000 times it would be 0 500 times and 1 500 times. If you ended up on north east it would be a 75 / 25 chance. It doesn't simply add a third state.
[Qutrit](https://en.wikipedia.org/wiki/Qutrit) A qutrit is a variation of the qubit, only with 3 possible states and can represent a base-3 number. I didn't mean a qubit could represent 0, 1, or 3. I mistakenly understood a qutrit to be a measurement of 0, 1, and the superposition of both to represent a 3rd state, which isn't exactly true. &gt; It represents a probability distribution on {0, 1}. Qubits, and quantum computers, are inherently probabilistic. "There are two possible outcomes for the measurement of a qubit—usually 0 and 1, like a bit. The difference is that whereas the state of a bit is either 0 or 1, the state of a qubit can also be a superposition of both." A qubit can be 0, 1, or both. It's when it is in superposition that it represents a probability distribution (I think). I don't see how this would be a problem, though. If Microsoft created a language that resembles F#, that was meant to work on quantum computers, and was integrated into Visual Studio, what inherently would prevent a future version of C# from doing the same?
I mistakenly mixed up my understanding of a qubit with that of its variation, the [qutrit](https://en.wikipedia.org/wiki/Qutrit). That can represent a base-3 numeral.
I don’t want to do your homework for you, but think about what happens when your algorithm runs. Step through your decimal to binary converter, try it with a small easy number, like 3. Remember that the double data type can hold decimal numbers. 
Problem not solved. Unit tests don't prove your system integrates with a data store. Unit test them in isolation, but test them together in integration tests. 
 while (true) { string num1 = Convert.ToString(num); int oc = num1.Length; double dec = 0; for (int i = 0; i &lt; oc; ++i) { dec += ((byte)num1[i] - 48) * Math.Pow(8, ((oc - i) - 1)); } double deci = Convert.ToDouble(dec); while (true) { if ((deci % 2) != 0) binary = 1 + binary; else if ((deci % 2) == 0) binary = 0 + binary; deci = deci / 2; if (deci == 0) break; } Console.WriteLine(binario); Console.ReadLine(); }
Unless this is a challenge to yourself / assignment, you are going about this quite wrong for a professional C# programmer. int number = Convert.ToInt32(octal, 8); Console.WriteLine(Convert.ToString(number, 2));
Different implementation, but [Midori](http://joeduffyblog.com/2016/02/07/the-error-model/) has checked exceptions. Regardless, this particular bit stood out in the original article: &gt; The trouble with creating a new version of a method, he says, is that you may be adding new features that also introduce a new exception. If you do introduce a new exception, adding it to the throws clause may break the code entirely because the caller of the method most likely doesn’t handle that exception. This isn't even a problem with checked exceptions in my book. The code using this method handles exceptions A and B. Now you add an exception C. Poor you when C is triggered, because none of the code above even considered that it could happen - you essentially just broke everything above that wasn't catching `Exception` or something, but with a lower probability of manifesting than other breaking changes. Checked exceptions simply turned that into a compile-time error. I don't see that as a bad thing, even if there are other problems.
Emphasis “in theory” In practice it’s at least a strong gust 
I'm not sure whether that shows a problem with OOP, Inheritance, or exceptions in general; but it definitely shows a problem with checked exceptions. The whole idea of OOP is to abstract the implementation details away, but a new checked exception leaks those implementation details to a higher scope. I think we still have a long way to go before we figure out the optimal solution to this stuff. 
It's not leaking anything that wasn't already leaked. Your function can throw a new exception. Now the app crashes because nothing handled it, and rightly so because there used to be no chance of it happening. Even if you aren't explicit in stating that there's a new exception to watch out for, code not watching out for it is still screwed.
What's wrong with: ``` using (new TransactionScope()) { } ``` ? 
I've regularly done both in the same code base. 
Forget the language. You’re new to CS, so your assumption that C# itself is a career path is understandable... but actually, changing platform and language is a fairly easy change. I’ve been a PHP developer, Java developer, and C# developer. In hobbies I’ve programmed embedded devices and used C/C++, Objective C, Java and PHP again, etc Your career is “developer”, not “C# developer”. And even that can change to consultancy or similar pretty easily. Don’t sweat it, your main asset will be your transferable skills: understandings of User Interfaces, data integration, security etc. These are the difficult parts, and they’re what you carry with you between languages Languages are easy, out job isn’t about using C#: our job is developing good, secure, easy to use, high performance software.
A hurricane, last time I tried. That's when I gave up and just went back to being a web guy. Eeeeeeeeeeh. Glad I don't do this as a job.
Your goal is certainly achievable if you put in the effort. I recommend watching Venkat's videos: https://www.youtube.com/watch?v=SXmVym6L8dw&amp;list=PLAC325451207E3105
Yea, I find the same to be true for OpenXML SDK as well...
Remove stored procedures. Problem solved.
Entity Framework In Memory Database.... Problem solved. Don't clap, just throw money. 
https://docs.microsoft.com/en-us/windows/uwp/controls-and-patterns/tiles-and-notifications-windows-push-notification-services--wns--overview
Exactly. Remove all logic from the database. C# for the logic database for the data storage.
Ok. At first, your idea looked mostly like the EventAggregator at Prism Library. But there are some ideas that looks quite weird in an EventAggregator. * The Request / Response thing that you're doing (Func&lt;T, TResult&gt;). Why are you doing that? So when you publish a T, you're expecting an IEnumerable&lt;TResult&gt;? * Managing events in publisher thread looks dangerous. You're effectively coupling publisher to subscriber. What will you do if the subscriber just freezes? Well, as long as it's just optional... But it wouldn't be my default, in any case * The Intra process event signaling sounds interesting. Using Named Pipes? IPC? Why stop there? Why not just using a queuing technology to abstract the channel and just go distributed?
If you pass a reference type to a function and make an assignment inside the function to that variable you need the out parameter otherwise you will "lose" the assignment.
Unit test are the only kind of test you should need to write. If you find you need to write integration tests you've probably designed your system wrong. Integration tests should be a one off quick test that a new API or database is working as expected, then release the code and forget about it. They can't be run automatically and you can't trust that when they fail it's because a breaking change has been made to the code, not some other reason that might be completely irrelevant to the code you're working on. 
All it needs is another level of abstraction. e.g. have a configuration library? Have a parent exception type called ConfigurationException, only throw that as the checked exception. People who care about the sub-classes of can read the docs to attempt error recovery, or give the user a better idea, people who don't care about that the configuration just failed to load for whatever reason are forced to handle the case where the configuration can't be read, that they otherwise might not have been aware of.
These two videos by Veritasium explain it really well but you need to drop what you know and take it at face-value. I recommend watching Qbits video first. Qbits: https://www.youtube.com/watch?v=ZuvK-od647c Quantum Computer: https://www.youtube.com/watch?v=g_IaVepNDT4
One alternative to using AppDomains that I can suggest is an append-only approach: assuming that the reason you want hot-loading assemblies is to seamlessly provide updated versions without having to reboot, you can do the following: simply load in the new (updated) assemblies while leaving the old assemblies in memory. This is a usable approach for things like dynamic prototyping. You can use an IoC container to automatically reindex directories and updated the container registration parameters, so that new objects are created with updated versions of the types whereas existing objects can continue to use the old definitions.
Where the known state is "All tables are empty".
I've seen enough flaws revealed by integration tests to know that you're wrong.
Seems nice, I'm not sure I see the benefit over a backup/restore approach though. What am I missing ?
In theory yes, but when it comes to performance good optimized procedures outperform c# most of the time.
 XmlNodeList rows = worktables[index].FirstChild.SelectNodes("//Row", ns); You are passing in a `XmlNamespaceManager` now, but you're still not actually using any namespaces in your XPath. `Row` is not the same as `foo:Row`. And you don't need to add every namespace in the document to the `XmlNamespaceManager`, just the one you want to reference in your XPath.
One thing that important to keep in mind is that we are talking about a probability space, not real directions in what follows; The usual model (for a 2 state system) would be that each state is a point on a unit (radius 1) circle. The actual probability of finding it in a measurable state is the square of the projection of the current state onto the basis you are measuring it against. This directly comes from the core mathematics of quantum mechanics. A basis is a set of orthogonal axis in our probability space. So we can define a basis where 1 is the vertical axis and 0 is the horizontal. We could equally well define a basis where A is top right to bottom left, and B is top left to bottom right, at 45 degrees to the original. These multiple possible basis sets are critical to how quantum computing (and quantum key key exchange) work. Whenever you measure a state against a basis, you will find it in one of the basis states, with the probability defined as the square of the projection of the original state onto the possible measurement state. You can work out that projection with some simple Pythagoras. So a system in state A (at 45 degrees to the horizontal) would have a projection of 1/sqrt(2) onto state 1 (or state 0). The square just works out at 1/2, giving you the 50/50 odds. You can similarly see that state B would have the same result. This means we can easily set a system into such a 50/50 state by measuring it along a different basis set. In quantum computation this process is a logic gate - the Hadamard gate - that sets a qbit into a perfect superposition of 0 and 1. If we had a register of qbits and passed them through an array of such gates we would put that register into a perfect superposition of all possible values that such an n-bit register can represent. We can then do calculations with that state. With qbits you are usually talking about particle spin, which complicates this mental image by having real spacial elements. In this model, spin up would be 1 (vertical axis), spin down 0 (horizontal axis), and spins left and right be the set of axis at 45 degrees to the horizontal. If you are looking at, say, the polarisation of a single photon - as can be used in discussions of quantum key exchange - you can more directly map the probability based model I used onto physical properties. That can make it easier to grasp for beginners, but I'd personally try to leave out any classical considerations and just consider states in the abstract. Trying to tie things back to classical understanding is likely to trip you up when you are trying to get a grasp of the basics.
Then the area of code that failed should have been unit tested. Then you get a warning when you check in to the test environment before going live. 
I'm not arguing with that. I'm all for efficient stored procedures. Just don't do your logic in them.
Find a good mentor. Not someone to follow, someone who can steer you.
Thanks so much. I tested with `ss:Row` and it works without issues now. I will also change the code so I don't add all the namespaces.
Funnily you should ask... A proposal was just added to the C# language github repo about it: https://github.com/dotnet/csharplang/issues/947 Not my suggestion I just saw it... I never expect it to get into c#.
There is also the issue on User Voice. All my friends who are Java Drones and defend the insanity called checked exceptions have upvoted it just to troll me :)
How do you test that your sql query is correct? Not in a unit test. Doing that by hand is even dumber idea. Integration.
Also, keep in mind that the namespace shortcuts (`ss` etc.) are completely arbitrary and could change at any time, only the namespace URI (`urn:schemas-microsoft-com:office:spreadsheet`) matters. Your code should initialize the `XmlNamespaceManager` with constant values instead of copying them from the document.
Your code should handle it and that handling should be unit tested. You don't unit test the SQL from C# unless you're generating it using C#, then you test the generator.
So I should use `ns.AddNamespace("foo", "urn:schemas-microsoft-com:office:spreadsheet");` with foo being whatever I want? what if a file have a different URI?
Yes. The namespace URI of an element should never change, that would be a breaking change just like changing its name.
So we agree, those things are not unit testing but integration testing.
It doesn't matter what you call it, just what the intent is. If that's what you call integration testing then I'm all for it, but any test that depends on specific data being in a database is not a unit test by my definition and that's what I'm trying to discourage. Tests that depend on specific data existing in a database should not be written, and mock or stub implementations should be created to allow you to test, not resetting a database to have the 'correct' data or anything like that. 
I was going to say signalR but it sounds like you've already explored that. A few years back I rigged up a crude "service" type application using named pipes that transmitted serialized XML docs. Pretty simple and worked well. [pipes example](https://docs.microsoft.com/en-us/dotnet/standard/io/how-to-use-named-pipes-for-network-interprocess-communication)
You are right but... Performance is the last resort.
Ahhh, I like it. Then you'd only have to rarely bounce if there were enough updates to start making the memory messy. Best answer so far.
Yeah, we're working on refactoring all of our code to allow this to happen cleanly now. 
I didn’t say we had our logic in the stored procedures. We use stored procedures for security reasons by only granting execute permissions on the procs for the service account. It’s sometimes nice to run tests against the procs to make sure you didn’t forget to update them if you added a new column or changed the output in a release. 
Easier said then done and not my call. 
There are use cases where you'd have everything on the publisher thread, very high throughput cases where the workload is smaller than the overhead of running it asynchronously. Actually, that's kind of how Node and Windows UI applications work anyway. It's kinda difficult to blue sky this stuff because I've already got a bunch of preset ideas about how I'd do this, especially where you start crossing the physical divide. It's a bit of half a dozen technology types, it's a bit EA or Messenger or event queue like you'd find in any UI application, either at the OS level (message loop stylee) or higher as it might apply to communication between view models. Then there's WCF which sounds specific to cross machine communication, but was designed to avoid the distinction. Enterprise busses, Tibco, RabbitMQ, etc. Finally things like the Actor model, Akka.Net being a good example of how that would work. Technically it incorporates almost everything on that list. The bits it doesn't (weak reference specific stuff) don't fit with its design or could be used for stuff, but aren't really relevant at this level. A read of the Reactive Manifesto would help. And also remembering one guiding principle that Akka reiterates constantly which is "Avoid Exactly once messaging at all costs". It's as applicable in UI inter-vm messaging as it is in distributed systems. 
If your using the database for security your doing it wrong. Just stop using store procedures unless you really need to.
I think you’re missing the point again. We grant permissions to the Service Accounts that the application runs as in IIS not the individual users themselves. The procedures ensure they if someone were to gain access to the app tier which has direct access to the database they would only be able to execute procedures rather than being able to directly select or modify on the tables themselves. 
10 years ago I was a purist... But out of interest I've been doing in entity framework memory database tests of late. I can encapsulate an entire segment of business logic in a single test that would take unit tests a lot of interfaces and boiler plate. Unit tests have their place but how much I can write by doing 1/2 unit tests and 1/2 behaviour driven development is pretty god damn eye opening.
Is there any inheritance going on? I would rather have him inherit interfaces, and then implement them through composition (private class properties, ideally), rather than inheriting classes. It can get kinda silly, though. The ideal situation is to hide implementation and reduce the amount of copy-and-pasting (as long as coupling isn't a problem). If he's a copy and pasting a lot, that could be a problem. Usually people do this to "plan for the future." Maybe ask him what he's "planning" for?
Hard to say from what you've told us. Could very well be that the new guy has a case of interface-itis, which is pretty easy to develop with unit testing. Could also be that he's right: static methods complicate testing, after all, by coupling types to the extension class. I *would* say that I'm not currently a huge fan of single-method interfaces. An interface with a single method could be replaced, as an argument, with a delegate type with the right signature. There's a time and place, of course.
DI and unit testing with mocks will require a lot things to have interfaces but an interface for every single class seems like overkill. Extension methods are just static methods, I'm not sure why that would be hard to test. Do you both report to a more senior dev? 
Using XDocument instead of XmlDocument might help. You can query against a node's LocalName, ignoring namespaces altogether. 
Extension methods by themselves aren't hard to test, but testing code that _uses_ extension methods is difficult when those same extension methods have dependencies. They can make it very hard or impossible to introduce mocks.
It depends, some things benefit from interfaces, otherwise you are just making a bunch of mess. My rule-of-thumb in cs is, If I'm going to have N (where N is &gt;=3) number of things, and N number of things ALL do the same thing, then I'll try an abstract class, or if needed interface. Making one for every class just seems eh. WARNING: I have been writing CS for over 10 years now, and these are just my personal things, no ways a "law"
Say for example we have a method that we would use 100+ times across our project that formats a string in some way. In my mind this is ideal extension territory, but you're saying we should avoid it and using a normal method in it's place for the sake of unit testing?
It depends in what that method does. If it queries another service, resource internally then it will be hard to test. If it just deals with objects passed in then it is a good candidate for an extension method since it can be tested in isolation and doesnt depend on anything but input
Formatting a string sounds like there is an input constraint (it's a name, or specific serial number) and it has a specific output style (add dashes in particular spots) For me, the reason this is not a good candidate for an extension is the input constraint. It's not applicable to all inputs the way other string operators are. So I'd put this into a class that inherits string so I can enforce proper form and override the ToString method. As far as interfaces, they're good if you are using mocks for unit testing. It's not necessarily needed for every class. I worked with a programmer, once, who had to have the code organized in a very strict way, even when his conceptual model did not match the program we were writing. It was a struggle. He needed that personal model to survive. It was OK for a simple program that wrapped a database and presented edit fields for data entry, but he was helpless outside that narrow realm. Since the project lacked any leadership, it eventually crashed and burned because he simply couldn't adapt to change, and management wouldn't listen. 
/u/sarhoshamiral's reply is correct. Re-read what I wrote, it's when the extension methods utilize some otherwise-mockable dependency. Put it this way: if you can fully test the caller, then the extension method is fine. If you can't test the caller because the extension method introduces a call to a REST service (or whatever), then your extension method is harming your testability.
Have a look at http://materialdesigninxaml.net/ from /u/ButchersBoy. It's quite easy to use. There is also an example app with all features which you can use to copy-paste.
As others have said, it depends. If he's composing functionality, then interfaces make a lot of sense. Interface segregation principle also comes into effect, resulting in a higher number of smaller interfaces: don't make things implement stuff they don't need.
&gt;those same extension methods have dependencies. That's definitely going to be tricky, does the extension method do some sort of service location to create dependencies? If you use an mocking container, you might be able to populate it with a mock that can be found later with service location. 
Thd simple answer is no. If you write an interface there better be a damn good reason,
Metro in WPF -&gt; http://mahapps.com/
If the method has side effects, yes, it will be hard to test. If it doesn't have side effects (aka functionally pure) then no, it'll be fine to use as an extension as semantically it'd be no different to the code being in-line.
re: Interfaces - Dogmatism rarely, if ever, pays off. However if it's not slowing his productivity down, I wouldn't care. I've _never_ seen a scenario where I've thought "Thank god this class doesn't have an interface." re: Extensions - depends entirely on purpose, as posted elsewhere. A simple string formatter is absolutely perfect extension method territory. Presumably no dependencies except for the typical string dependencies (the string itself and CultureInfo). If the extension does any kind of domain based logic, and those items are not passed in as parameters, then that's a red flag. 
He means your English is broken. 
&gt; To give a bit of context: A recent task was to make a timer that wakes, checks to see if a certain datetime interval has been passed and then add an ID to a queue (for a worker to pick up and calculate, which is not handled by his code). In my opinion this can be implemented elegantly in a single class + a model or two, but it is split across 12 (yes, 12) files. That *sounds* excessive. OTOH, I can see an interface for getting the system date, an interface for whatever your queue is (it's a service bus, right? not just a Queue&lt;long&gt; that somebody's made global for some horrible reason?), and possibly an interface for whatever the object composing IDateProvider and IWorkQueue. I mean, I think you could probably reduce that further to Func&lt;IdType, DateTime, bool&gt; BuildConditionalIdEnqueuer( Func&lt;DateTime&gt; dateAccessor, Action&lt;IdType&gt; enqueuer ) =&gt; (id, threshold) =&gt; { if (threshold &gt; dateAccessor()) { enqueuer(id); return true; } return false; } but I'm sure you're oversimplifying your use case a bit to make your point (which is fine).
&gt; So I'd put this into a class that inherits string No, you would not. `System.String` is `sealed`, you can't inherit from it.
New guy should adapt to current culture or project will be big mess as everybody will do like they want. So some part of code will be done with one style, other with different. Supporting project like that will be really hard in the future. I suggest to sit down and talk about it. I mean if you really want unit tests, interfaces are nice thing. Do you want cover whole project with unit tests? I don't think so. You do some kind of planning what todo? Like planning sprints. So talk which functionality should be covered with unit tests. These 12 files. What are they? 6 classes ad 6 interfaces? How many properties/methods they have inside? Maybe he just doing really small classes, which is really good thing.
Whatever you do, make sure you have a Blend as well as Visual Studio. It makes working with WPF so much nicer. I hate XAML. I'm sure that I've sent so many curses hurtling through the universe at the team that developed XAML, they're all blind, bald and covered in pox. 
A good example of this would be [Dapper](https://github.com/StackExchange/Dapper). If you're using Dapper to make calls to your database, your code is very hard to test. void DoSomething() { /* some stuff here you might want to test */ _dbConn.Execute(some_query); /* other stuff you might want to test */ } Normally, you'd create a substitute for `_dbConn`, but `Execute` is an extension method that requires internal components that have to be "real". Nor can you mock `Execute` itself because it's an extension method and can't be overridden. (Note to the downvoter: I use Dapper whenever I can, I think it's the best. It just requires a lot of work to make things testable. /shrug)
You can use a website like [codefights](https://codefights.com/signup/tunJtjTFa6qyW5nQd/main) and check their Arcade section. You want the "Intro" stuff. They start you off with very simple problems and they get progressively harder. The best part is that once you've solved a problem you get to see how other people solved it. So you get to see other C# solutions (or even solutions using other languages)
Inexperience.
Here's an application I'm working on with a very simple style sheet (Blue.xaml) that you can steal: https://github.com/Grauenwolf/Tortuga-Drydock/tree/master/Tortuga.Drydock/Tortuga.Drydock I originally got it from CodePlex, but that site is dying so I don't know what happened to the original.
Sometimes I'll do an abstract base class + interface. The reason is the base class cuts repeats and boilerplate, but the interface gives you an escape if the base class becomes fragile in the future.
&gt; Could also be that he's right: static methods complicate testing, after all, by coupling types to the extension class. Bullshit. There is nothing hard to test about stateless, static methods.
Until they're not stateless.
&gt; In my opinion this can be implemented elegantly in a single class + a model or two, but it is split across 12 (yes, 12) files. Yep, that's a failed code review.
IMO if you're not using extension methods with interfaces you can be missing out. You can create trait/mixin-like code (interface + implementation) by using extension methods on top of interfaces. You can even combine several interfaces using generics. This breaks you free from fragile base classes while also saving you from writing an implementation in every single interface consumer.
Yeah, but then you invite trouble by having to keep your mock assumptions up to date. Why not just test with an actual database?
If his key argument is that an interface makes it easier to test, does he in fact create unit test for them?
&gt; For the small amount of code he writes, there seems to be interfaces coming out the wazoo. He doubles the file count while making it tedious to read. Rules for interfaces: * If you only have 1 class implementing the interface, delete it. * If all of the classes implementing the interface have the same base class, delete it. * If all of the classes implementing the interface should have the same base class, make said base class then delete the interface. implementing the interface 
I find it sad that so many people disagree with you. The rule for everything in a project should be "if you write it, there better be a damn good reason". We don't get paid per line of code.
&gt; If he's composing functionality, then interfaces make a lot of sense. No it doesn't. The class's public interface it just fine for that purpose. The ONLY reason you should be creating abstract interfaces is that you need polymorphism. The reason you need polymorphism may vary (common utility functions, generics, replacing dependencies with mocks, etc). But if you can't say "I need polymorphism between these 2 classes" then you don't need an interface.
&gt; I've never seen a scenario where I've thought "Thank god this class doesn't have an interface." I had plenty of cases where I've said, "Damn, this fucking class has an interface". Usually when I'm trying to do dead code analysis. Interfaces force all of the members to have the same accessibility as the interface itself (public or internal). This is a very bad thing because it breaks encapsulation of the assembly (by making too much public) and prevents tools from programmatically detecting unused code.
I can honestly say I've never seen a stateful extension method in the wild. Could you do it? Sure. But you could also create a constructor that formats your hard drive.
breaking news everyone
It might be just what you're used to. I can rattle off the basics of a UI in XAML in no time but doing the same thing in Blend takes me much longer. When it comes to animations, storyboards, etc. that's when I'd switch over to Blend.
Tbf doing what is hard is more interesting if it's a good attempt.
+1 for mahapps You can throw together something like this in minutes: https://i.gyazo.com/e09de9afa1878c267643866d2bfc363a.gif
I agree for the most part. Testing gets complicated when classes are directly calling static methods though. For example, a method that: 1. Calls a static method that takes a complex class as input 2. Does a bit of processing with a branch 3. Calls another static method that takes the result of step 2 4. Returns the output of a final static method that takes output from step 3 This requires you to create an object that will work for all three static methods. If they were methods on an interface you could easily mock the results of each and reduce testing complexity quite a bit.
challenge accepted
Study your butt off and get your C# certification. Once you have your certification you'll be able to find an entry level job https://www.microsoft.com/en-us/learning/exam-70-483.aspx
I've seen static APIs wrapping singletons: stupid stuff happens, and there wasn't much context when I wrote the original comment.
XAML is much faster and convenient than winform drag and drop. I learnt XAML Listview nested bindings with a tutor within two days. It's not that hard. Don't try to port your 'winform way of constructing UI' into wpf, they work differently, you will go insane and hate XAML if you do so. It's good to move forward! good luck.
Here's what some quick q&amp;a online got me. Interfaces are useful when: * Multiple unrelated classes share a behavior * De-coupling for Testing, IoC/Dependency Inversion * Implementation changes that can change a significant amount of code 1. Having a plane class and duck class that can both use the same IFly interface allows both classes to share similar functionality, allowing greater opportunity to share code. 2. Mocking and Testing isn't always easy, interfaces can simplify them. 3. Code to the interface, so the actual implementation is encapsulated, making changes easier to do. Note: Interfaces are a performance hit (minor point). Don't use them for data holder classes with no behaviors.
Unfortunately these projects are out of date and aren't super helpful. Fortunately, I was able to figure it out as documented [here](https://stackoverflow.com/questions/46273067/asp-net-core-2-0-resource-access-token). In particular, [this project](https://github.com/juunas11/aspnetcore2aadauth) got me on the right track.
`_dbConn` in your example should be an `IDbConnection` which can be mocked. Or rather, because you are doing databasey things you should be using a fast database to test with, and isolate your usages of dapper to be behind some kind of DAL class or interface that you can then mock. I would _never_ expect to see a raw `IDbConnection` + dapper in my domain, it should be isolated behind something that describes the intent, which I can then mock if I need to.
I see it as an open vs closed debate. If "there better be a damn good reason" for interfaces to even exist in your code base, that implies you have a very strong closed principle. IME more people prefer an open principle. So that could be why.
Does your choice of dead code analysis tool not determine 0 usages? Even if you are publishing a library, you should be getting a report of exposed methods/properties that you can then examine. &gt; Interfaces force all of the members to have the same accessibility as the interface itself (public or internal). Which is the very point of an interface, surely?
Eh, I agree with you, but it's kind of just kicking the can down the road. At some point, you have to point to a piece of code and say "I guess this does what it says, because I can't test it". You can _probably_ assume you're building the right query and passing the right parameters to it, but you can't be _certain_.
Hard to fall on anyones side until we see the code. They could be right. Specially if a lot of the code uses existing untestable components, like timer, etc. (and your current code-base is creaking under maintainance problems) I don't think I'm comfortable giving you license to wave a reddit post under their nose. You won't be the first junior dev to roll their eyes at a senior developer, or to writing a testable frame, just like you won't be the first teenager to declare they know it all. Who knows, you may be better than them, but your attitude may need some work. I digress. Why don't you just ask them?
I'd want a better level of confidence with something like Dapper than that. Especially as the SQL is hand carved.
The first point is quite contentious, particularly when you're using a IOC framework and Unit Tests.
Nothing wrong with interfaces, we just generally don't need them. They're just contracts of publicly facing API. They should not exist for each class, they should exist for each idea. For example in game design you'd use a IPickup and IInteractive interfaces to give any object in your world the ability to be picked up or interfaced with without having to have all that logic built into the base class. I would not build an IBaseItem, maybe an IItem... but that's still kind of unlikely.
&gt; I've never seen a scenario where I've thought "Thank god this class doesn't have an interface." I have. I say that every time "Go to definition" works meaningfully.
+1 for not trying to match to winforms. Databinding is similar ish, but thats where the similarity starts and ends.
I always use go to implementation. 
TIL
Then argue against stateful static methods, don't talk like it's an inherent problem of extension methods themselves.
I had an experience like this a few days ago. Inherited a code base from a different dev team, and started to notice "Wow, there seems to be a lot of interfaces in this fairly simple app". They'd created interfaces for literally everything including several that contained just a single property and no methods.
I personally don't care either way, as long as he's productive and others can read his code, who cares? However, it might be worth you + your team lead sitting down with him and going through your team's coding style and standards. If I were the new guy, I'd be very appreciative of that.
Mock classes are still classes. I see no conflict here.
That's an empty platitude, not an argument. 
In any case if the extension method is testable (ie, DI:d dependencies passed from using method), then there should be no problem testing the things using the extension. So the onus is then on reviewing people to not let the static-dependent methods be merged.
Right back at you. I wasn't trying to make an argument, merely speculating on why the downvotes.
Test it the way it's intended to be used. In this case I only care about the inputs to the 2nd and 3rd function that can be generated by the 1st. That can eliminate whole classes of edge cases that I'd otherwise have to test. (Assuming functions 2&amp;3 are private.)
Dammit Jory.
Public methods and methods required to implement an interface are considered to be in use. &gt; Which is the very point of an interface, surely? Yes, but that's not always for the better. A very effective way to make code easy to understand and maintain is to limit the visibility of methods as much as possible. Only expose the things you actually want others to use and you save them a lot of time. It also reduces your testing surface. Public methods need to be individually tested. Internal/private ones are tested via the public methods that use them. 
I disagree, vehemently. The problem with static methods is if they themselves have static method dependencies. Even when stateless, you could end up falling into the trap of testing too deep. Sure, the static method "AddTwoNumbers" is easy to test. However, once you get into the hell of "calculate yield" using only static methods, it ends up being a nightmare because any of the sub, sub, sub, calculating functions could break your top level unit test. You can make a really complex program using only static stateless methods. I know, because some of the projects I maintain did just that.
Maybe we're at cross purposes here. I've never advocated any kind of "public all the things" stance. What I do advocate is that if someone uses refactoring tools to extract an interface of all the _existing_ public members of a class, it's not a big deal.
Fair enough 
All instance methods are static functions that take the current object as a parameter. So any argument, other than code organization, against static functions also applies to instance methods.
&gt; Sure, the static method "AddTwoNumbers" is easy to test. However, once you get into the hell of "calculate yield" using only static methods, it ends up being a nightmare because any of the sub, sub, sub, calculating functions could break your top level unit test. Been there, done that. Black box test the yield inputs/outputs and don't touch the spinning gears inside unless you want to lose a finger.
IDBConnection can't be mocked in a reliable fashion. Do your mocks at a higher level or not at all.
Yea, that's a pretty new feature.
The problem I keep running into is 50 to 90% of those methods shouldn't have been public in the first place. (I do a lot of remediation on old code bases and failing projects.)
Just keep in mind that "code to the interface" doesn't necessarily mean an `interface`. The class's public interface is also an interface. What that expression really means is don't make everything public and don't subvert the public API using pointers/reflection.
It should be easy, open your .csproj file in notepad and change the version of TargetFramework to 1.1 also the PackageReference anything version 2.0 or you open the project, right click the solution and change the version to 1.1 then select the correct version of you packages on the Nuget
If you are in charge of the project and this isn't how you want things done then he is doing it wrong. There is a concept that gets referred to as Test Induced Design Damage where you end up damaging your code base, making it messy and harder to read in order to facilitate unit testing. There are basically two schools of thought on this, the unit testing purists would say that code that is easier to unit test is by definition better code so this is actually of benefit. People who prefer their code to be clean simple and short point out that extra code means extra bugs and extra cost of maintenance and generally slows the development process. Personally, I don't really like that style of coding and to my mind it breaks agile rules. If you are using some sort of agile process then you don't write code before it is needed and prematurely wrapping code in interfaces is doing just that. The unit tests are a tool to make your code better, when you start making your code worse to facilitate unit testing then to my mind you have got the cart before the horse. Lastly I would say that writing loads of code isn't being productive. Writing clean, readable, maintainable code is being productive. If he is taking 12 classes to do what could be done with a single class then to my eye that is bad code no matter how you cut it. If I was in charge of that project I would stomp down on that crap pretty hard. I will add one caveat though that anything involving time gets very messy to unit test and if you have a 100% unit test coverage requirement and you ask someone to do something involving time then expect a big nasty mess while they jump through the various nasty hoops involved in abstracting time away from their code. There was a great series of talks between Martin Fowler, Kent Beck and David Heinemeier Hansen a while back on this sort of thing. It's worth a look as it covers a lot of the issues you are seeing https://martinfowler.com/articles/is-tdd-dead/
Unit testing each piece individually will almost always be easier, more automatic, and reduce potential errors.
Extension methods are hard to test and you can't inject anything into them (like a logger) so I have mixed feelings about them. We use them, but only relatively simple tasks. On interfaces, I feel like they are only mandatory for types that will be exposed outside of the enclosing project/assembly. You absolutely don't need them for every class.
I don't think you and I are talking about the same thing.
My general (very) style guidelines: Interfaces for what needs to move between business layers, NOT DTOs, but functionality. That makes unit testing simple. Interfaces if you're going to have some very general broad concept, ex: public interface ICustomer { Guid CustomerId { get; } } That way code which needs to recognize "this belongs to a customer" doesn't really need to give a shit about what the object is, as long as it can match that interface and suck the ID out of it. ... that's about it, maybe a few other times depending on the circumstance
Honestly, I tend to make an interface for every single class that I'm using dependency injection with, because I'm controlling the constructor and don't want to deal with creating the hierarchy for other tests. I do, however, usually tend to just put the interface definition in the same file as the class it's going to be implemented on if I know that it's only going to be implemented by that class (at the start). If I know an interface will be implemented by many classes, I'll give it a file of it's own. There's lots of good reasons for this that I won't get into here, but in general I also agree that an interface for every class having it's own file is going a bit overboard, which is why I co-locate them now. With regards to extension methods, I love extension methods. They aren't necessarily harder to test, it's just you can't directly mock them, which is what I'm guessing the reasoning is there. But you can just mock the objects that the extension method is attached to and you are golden. I do it all the time. You'll have the exact same boilerplate mocking on the source object whether you have an extension method or not.
Remember the expression "code to the interface, not the implementation"? This is a good example of that. The interface is the yield function itself, that's where the bulk of your testing should go because at the end of the day that's all that matters. Now I'm not saying you can't test the implementation details, those internal helper functions, if you suspect that they have a problem. BUt don't write tests for the sake of writing tests, keep your end goal in mind. 
Composition doesn't require abstract interfaces. It does require an interface in the API sense, but that's not what we're talking about here.
Can you show me an example of something that uses composed functionality that doesn't make use of an interface or abstract class?
Thanks everyone, I'll check the links and ressources y'all gave me! I appreciate it !
I agree with you. Implementation details don't matter to a test, and they shouldn't. That is exactly what I am getting at in previous posts though. If I am testing *MethodThatCallsStaticMethod1* I don't care about what happens inside *StaticMethod1*. It might go off and do 500ms of computations to end up returning a boolean. I should be able to write a test that only cares about what happens inside *MethodThatCallsStaticMethod1* and that requires an instance method or function being passed in.
Um, every class and struct that isn't a primitive? I'm wondering what definition of composition you are using. Are you confusing composition with polymorphism or specialization?
&gt; If I am testing MethodThatCallsStaticMethod1 I don't care about what happens inside StaticMethod1. Then why does MethodThatCallsStaticMethod1 call StaticMethod1 in the first place? If it is important to the functionality of MethodThatCallsStaticMethod1 or its a false dependency that should be removed. As I've said before, **test your code in the way that you will be using it**.
This is a symptom of a "true believer." Tread carefully.
I feel sorry for you. You are screwed. Maybe take a look at xamarin? 
&gt; does the extension method do some sort of service location to create dependencies? This is [just, like, my opinion, man](https://www.youtube.com/watch?v=pWdd6_ZxX8c), but if you are resolving dependencies inside of an extension method, you should probably rethink how things are structured.
Well that's just horrific code which should never pass PR. Static methods of any sort are great for things which can be pure functions, are easy to test for that usage, and also should only be used for that.
When VS brought that feature in, it was the death blow to Resharper, for me. I haven't looked back since.
Was the app written for .Net or for .Core? How much money do they want to spend to make it work on Mac?
I second this. I tried blend for the basic UI design, and got very lost. But animations and whatnot are confusing as hell in xaml. It comes down to personal preference really
If you're using DI, I'd argue that the first point is almost straight-up wrong. The whole point of DI is to decouple yourself from what the dependency is. Sure, there may be only one implementation of `IProductService` now, but what if that changes in the future? It's a lot easier to change your DI registration than it is to go back and change everywhere you were resolving `ProductService` before. 
Mahapps is definitely the way to go for a metro look in a WPF app. Also for the back end, I swear by caliburn.micro. It's not required by any means, but it has my made my app development experience considerably better
I wrote it for .NET. There's no budget for this, just hoping that between Visual Studio for Mac and the fact that both OxyPlot and LiveCharts *claim* to be cross-platform, this would actually work.
https://en.wikipedia.org/wiki/Composition_over_inheritance
Exactly. Stateless methods are some of the easiest things to test there are. I don’t believe in interfaces just for the ability to unit test though. Just don’t need them. 
The members of a C++ `union` overlap in the same piece of memory, you are treating them as if they were consecutive fields. 
I was wondering what that was, I just googled it real quick and it said that C# doesn't have an implementation for that. What does this mean though..
It means that the entire union only takes up 4 bytes, but you are reading 2*4 offsetting everything else in the struct.
&gt; Then why does MethodThatCallsStaticMethod1 call StaticMethod1 in the first place? Because I care about the result public class LoginService { public IWebIO WebIO { get; } public LoginService(IWebIO webIO) { WebIO = webIO; } public Task&lt;string&gt; AttemptSignIn(string input) { var hashed = HashHelpers.GenerateHashedPassword(input, "generatedSalt"); return WebIO.SignIn(hashed); } } public static class HashHelpers { public static string GenerateHashedPassword(string input, string salt) { var result = input + salt; //use slow hash here return result; } } I don't care what hash is generated, I don't care what WebIO does, I just care that my method returns the result of WebIO.SignIn when it gets passed the result of HashHelpers.GenerateHashedPassword with input and hash. WebIO is stateful, HashHelpers is not, but both should be mocked for a unit test.
It sounds to me like you want to override the [get call for your property](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/properties) SOC so that it returns in the specific way that you need. Unfortunately I need more details on exactly what you're trying to do, because I'm just guessing at your project here. More code snippets would help. public class Individual { public string ID { get; set; } } public class ExtendedIndividual : Individual { public string SomeProperty { get; set; } public List&lt;SomeOtherClass&gt; SOC { get { return getSomeOtherClasses.Where ( x =&gt; x.Value == ExpectedValue).ToList () ; } set { // What do you want to do here? } } } 
Extension (and in general static) methods are good if they are pure - they take input and return output. They don't read files, don't write to the database, don't ask for user input, etc.
 &gt; Why don’t you just ask them? This is the correct answer
In this case, "ExpectedValue" would equal ID.
While I agree in principle, I often find that what is and ought are not in agreement.
I once put some conditional weak reference code around an interface to remove an 8 layer deep base class requirement from...well, nearly half the classes in the codebase. It wasn't pretty, but sometimes you start in the muck.
&gt;.NET Framework 4.7.1 has built-in support for .NET Standard 2.0. *Nice*, that's all I needed to hear. &gt;The System.ValueTuple types in .NET Framework 4.7.1 are now marked as Serializable This makes me happy, since I consider ValueTuple to be a core package for all of my projects. &gt; .NET Framework 4.7.1 introduces the IsReadOnlyAttribute for ReadOnlyReferences feature. This attribute will be used by the compiler to mark members that have readonly-ref return types or parameters. Didn't know I needed this, but now I do. &gt;[This new API](https://github.com/dotnet/corefx/issues/17116) provides a way to detect whether a particular runtime supports a certain feature or not. At compile time the API provides a way to do that statically through reflection. Makes cross-platform and deployment a little bit easier. That's going to be a sigh of relief for certain developers. &gt;This feature adds support for Portable PDBs in the .NET Framework. Libraries that generate code at runtime, like C# Scripting, would benefit from being able to detect whether the runtime supports Portable PDBs or not. Cool. 
You can override non-static method. You cannot override static methods. A class that looks like this private final SubCalc subCalc public MyClass(SubCalc subCalc) { ... } public double calcYeild(params) { return subCalc.calc(); } Will be far more testable than one composed of static methods doing the same thing. Why? because you can override the implementation of SubCalc before exercising calcYield. This allows you to play with known values and test only what "calcYield" does, not what "SubCalc" does. It has the added bonus that if you want to swap out, change up, or completely refactor how SubCalc works, you can do that without impacting the yield calc function or its tests. Again, I'm just going to say I've seen code that follows the fully static methods calling static methods, it is not fun at all and completely untestable. You simply can't wrangle the 1000s of fields that are interplaying with each other for a yield calculation to write any sort of non-brittle unit tests.
That is fine, if the inputs and outputs are small. In the case of yield, there are literally thousands of variables that go into the calculation. You can't just "black box" test it because you won't be testing deep or through enough.
YAGNI. And if you actually do at some vague future point, you’ll have saved more time by not having to touch two files when changing one class than you’ll lose by refactoring existing code to use the interface. 
&gt; YAGNI. Not always true - not in the slightest. I can think of a handful of examples where an interface was re-implemented, and then all we had to do was change the DI registration to start using it. Specifically, `IProductReviewService` comes to mind. Reviews for products were handled through a third-party. Because "business reasons," this third-party changed a number of times over the course of a couple of years. &gt; you’ll have saved more time by not having to touch two files Umm...I don't think so. The "two files" you would touch are: - 1) creating the new implementation of the interface - 2) changing the DI registration Creating a new class, and registering it with DI is, in my opinion, *less* work than re-working the old class to talk to the new provider. Also, with this way, the old class can stick around for historical reasons (maybe there's a back-end task that needs to talk to it for some unknown business reason). By no means am I an "interface all the things" kind of guy, but they definitely have a use-case.
https://i.imgur.com/vguKOmp.png
+1 for not trying to match winforms. WPF will drive you insane unless you can let go of your old habits. Everything is much easier when you use XAML correctly. I've worked at shops where they used WPF code with WinForms practices. It was an unbelievable nightmare.
That's not "composition", that's specialization.
Yea. I can't say I've done that one, but I'm sure I've had equally messy workarounds trying to break up old, crusty code.
Test driven development, it's a thing. Have you considered just talking to the guy? You say he's more experienced than you, does that also mean he's senior to you? Perhaps talking to him will shed light on another part of the project you're not aware of, or at the least why he's doing it. Either way, once you're informed you'll be better equipped to approach your superiors with a wtf.
No. Don't mock GenerateHashedPassword. That's just stupid. It's a pure function. There is absolutely no reason to mock it, especially once you've unit tested it. 
Yea, I know that there's a lot. I worked in the bond market for 5 years. I also know that the only thing that matters is matching the values you get from the Bloomberg terminal (in some cases even their bugs). 
I agree. My current project is so heavily dependent on DI that I have had to let go of my old preconceptions regarding interfaces. You simply have to use them to have any sanity in DI. The big reason we're using DI to begin with is that we need to prepare for the future where one implementation of `IProductService` turns into 3 different implementations depending on the deployment/needs of the user. We touch so many third party services that it's impossible to predict how our implementation will change. Better to handle it at the DI registration.
I can't really imagine anyone even having that idea, and it certainly isn't in the same universe as a good enough reason to just skip extension methods outright.
Both points, hammer meet nail head A good rule of thumb that I've followed that's served me well is, if the class is not meant to be internal or public *by design*, don't extract or use an interface. Ymmv
Remove the setter, and move the logic to the getter. Use lazy instantiation. Edit. Not sure a property is the right fit. Depending on the amount of code accociated with generating the list
Dude, it's a simple search-and-replace job. It will take you all of 5 minutes with a 90's era code editor. (I know because I used to do it in ASP/VBScript.) With a modern IDE, even less time. You're optimizing for something that probably won't happen while doubling the effort every time you add or alter a method on `ProductService`. 
&gt; I ask because he has been a developer for much longer than I, so it's conflicting to me. Unless you both have less than roughly 5 years of experience that doesn't mean anything. I've met people with 20 years more years experience than me who still don't understand the memory model or how dispose isn't the same as garbage collection. And I've met people with 6 years of experience whose insights make my APIs look embarrassing. Sure older people have seen more shit and have a deeper pool of knowledge to draw upon, so you shouldn't dismiss them out of hand. But if someone is a shitty programmer after 5 years they're probably going to be a shitty programmer after 40 years. And this guy sure sounds like a shitty programmer.
After testing an already implemented struct way of parsing it, I realized that the values add up, but what I don't understand is how you can (in c#) parse two DWORDS from 4 bytes
&gt; You're optimizing for something that probably won't happen It's not an optimization. It's architecting a project in a way that takes future business needs into account. This is a *key component* of structuring an enterprise application. &gt; while doubling the effort every time you add or alter a method ...the "extra effort" of having to maintain the interface is basically no effort at all. As I said in another reply, interfaces are not always the answer, but if it's something that is dependency injected, it's totally worth the extra two minutes it takes to create. Decoupling your concrete class from the code that is calling it is literally one of the major points of dependency injection.
This. I have a feeling that most people talking shit about DI and interfaces just haven't worked on a project where it's been useful/necessary to swap out what concrete class you're using. It's (marginally) more work to set up an interface for a service, but it pays off the minute there is a need for a new implementation of that service.
In general you should be writing isolation layers around third party API boundaries, whether or not that’s an interface is a different question. The point of YAGNI as a principle isn’t that you’ll never actually need it, it’s that most of the time you won’t and the work spent worrying about future complications isn’t just wasted time, it adds complexity for no real benefit. Complexity where it isn’t absolutely necessary is an enemy to be fought, not embraced. Overuse of interfaces ‘just in case’ adds meaningless boilerplate code that someone is going to have to spend time and cognitive effort maintaining. 
&gt;it pays off the minute there is a need The payoff of DI is an incredible feeling when you're under the gun with stress. Funny enough, it was a contractor that first schooled me on DI. I see so much misconception surrounding it around the net that it's no wonder I never encountered it in my studies.
I don't think isolation layers around third party APIs are a sufficient replacement for dependency injection. This is a situation where 'just in case' is not a gut feeling, it's a literal project decision made with the knowledge that the future will require swapping in and out hard classes. DI is also automated for the most part nowadays; it takes almost no extra work to employ it in your projects, other than taking time to set everything up correctly. This isn't optimization; it's an architecture decision.
There's just one DWORD and both fields technically have the same value, but typically only one of the fields is considered valid at any time depending on some condition (i.e. sometimes `VirtualSize` is filled and `PhysicalAddress` is ignored and vice versa). I'm not familiar with this API and don't know how this specific struct is used in practice.
&gt;Not sure a property is the right fit. Depending on the amount of code accociated with generating the list Agreed, but it's impossible to tell without more details from OP.
I am agreeing with others here as I dont really have enough info. I personally tend to "interface all the things" but I also have strict rules about the operational roles of components so I don't end up with "utility methods" written as statics, extensions what have you nor do I allow single method interfaces if I can avoid it. In many cases if you think you need an extension for a class you designed you might have missed something in the core design or you are compensating for poor role division. 
The value in DI is in not having to understand the dependency graph every time you need to use a class and in not having to update every usage when the graph changes. It’s orthogonal to whether or not you choose to wrap every injected class in an interface. This is not a personal attack on you or your work, but the only code that isn’t going to cause problems at some point down the line is code you never had to write*. * because you didn’t need it, not because you pulled in a third party dependency that has its own host of issues. However NIH is also stupid and everything has its own trade offs. 
It's just a few lines of code to get this list. Pretty quite to run. Here's the modified actual code: public class ExtendedIndividual : Individual { public static List&lt;CmcRelationship&gt; CommitteeMemberships { get { List&lt;CmcRelationship&gt; cmcRlts = new List&lt;CmcRelationship&gt;(); try { var generalRepository = IgnitionDependencyResolver.Current.GetService&lt;IGeneralRepository&gt;(); cmcRlts = generalRepository.GetAll&lt;CmcRelationship&gt;().Where( c =&gt; c.CustomerId == Id &amp;&amp; (c.StartDate == default(DateTime) || c.StartDate &lt; DateTime.Now) &amp;&amp; (c.EndDate == default(DateTime) || c.EndDate &gt; DateTime.Now) &amp;&amp; c.Status.ToString().ToLower() != "pending" ); } catch { cmcRlts = new List&lt;CmcRelationship&gt;(); } return cmcRlts; } } } How do I get c.CustomerId == Id to use the Id from the Individual?
&gt; It's architecting a project in a way that takes future business needs into account. Or in other words, fortune telling. The vast majority of the time those kinds of predictions turn out to be wrong and its just more cruft that has to be removed before you make the changes you actually need. &gt; Decoupling your concrete class from the code that is calling it is literally one of the major points of dependency injection. It's a technique, not a foundation. You don't always need to do it. 
If Wine works its probably the simplest solution, keeps you with a single codebase. You could also consider running a windows VM on the Mac
My unit tests now take 500ms * number of tests because my hash is intentionally slow. If I were to have any sort of branching or complex logic after the Generate call it would be a big problem. The following code requires many inputs and outputs to cover all possible branches. If this were not calling static methods, it would not be hard to test. In its current state it takes many different manual cases to completely test. public static decimal GetImportance(TodoItem todoItem) { var state = GetState(todoItem.StatusCode); if(state == State.Done) return 0; var multiplier = GetMultiplier(todoItem.Priority); var importance = ComputeImportanceValue(state, multiplier); return Convert.ToDecimal(importance); } public static State GetState(string statusCode) { if (statusCode == "00") return State.Todo; var comparison = string.Compare(statusCode, "99"); if (comparison == -1) return State.Doing; if (comparison == 0) return State.Done; throw new ArgumentException(nameof(statusCode)); } public static double GetMultiplier(int priority) { switch (priority) { case 0: return 1; case 1: return 2; case 2: return 2.5; case 3: return 4; case 4: return 10; default: return 1; } } public static double ComputeImportanceValue(State state, double multiplier) { var stateValue = state == State.Doing ? 1.2 : 1.0; if(stateValue &gt; 10) return 10; if(stateValue &lt; 3) return 3; return stateValue; } public class TodoItem { public string Name { get; set; } public string StatusCode { get; set; } public int Priority { get; set; } } public enum State { Todo, Doing, Done } Breaking this down is much simpler and more reliable. I can test each method individually and just confirm the two branches of GetImportance. Additionally, if a refactoring breaks GetState, one test turns red instead of ~13. 
&gt; My unit tests now take 500ms * number of tests because my hash is intentionally slow. If you think that's bad, wait until you see it in production. Tests don't just show logical errors, they also show performance problems.
If it can be an instance member, just do something like abstract string Foo { get; } override string Foo =&gt; "Bar"; If it needs to be static, there is no practical way to enforce it at the language level. The only way I can think of would be generics, but that would be real messy just for one value. In this case I think your best option is just to do it convention based with a `new`'ed member or an attribute. I suppose you could write a Roslyn analyzer for enforcement, if you really wanted to.
[removed]
It can be done but the code is ugly and requires abuse of static initializers and a DI framework. I did it once to replace a set of statics used by a piece of software that we were in the process of transitioning from global statics to DI. It's all pretty much 100% throwaway code though, nothing will really translate or can be used anywhere else but that static facade.
Anytime I'm implementing something like this, I always check pinvoke first: http://www.pinvoke.net/default.aspx/Structures.IMAGE_SECTION_HEADER To add on to your conversation with /u/tweq, a C++ `union` occupies a single block of memory equal to it's largest member. For example: union S { uint32_t a; // takes up 4 bytes uint16_t b; // takes up 2 bytes uint8_t c; // takes up 1 byte }; Because the largest member takes up 4 bytes, this `union` will only occupy 4 bytes at a time. That means if you declare a `S` object then assign a value to `b` (e.g., 0x1234) and then try to read the value from `c` you will get the lower byte (0x34 or 0x12; depending on endianness) of the value applied to `b`, and if you try to read the value from `a` you will get the the full, 4 bytes that the union occupies (0x00001234 or 0x12340000; depending on endianness). As you've already noted, C# doesn't have an equivalent to this. But, if you think about it in terms of memory, you know that the union in `IMAGE_SECTION_HEADER` only takes up 4 bytes, so you only need to read those 4 bytes once. Which means you either need to remove the read for `PhysicalAddress` or `VirtualSize`. You won't know which value is being used, however, so it doesn't matter which you remove. pinvoke uses `VirtualSize` and drops `PhysicalAddress`. Also, unless you're using an OLD version of C#, you don't have to do this: private string _name; public string Name { get { return _name; } set { _name = value; } } You can simply: public string Name { get; set; }
Why is all of that stuff exposed as public? Are you actually reusing it anywhere? At first glance I see one simple function unnecessarily split into a bunch of unnecessary micro-functions. The "Inline and Delete" refactoring key is going to get a lot of use. &gt; If this were not calling static methods, it would not be hard to test. It's not hard to test. Just create a data-driven test with a series of expected inputs and outputs. At first glance you'll need 72 lines for full coverage, probably a bit more for argument checking. I mean, sure if you were to create all 72 plus tests as individual test methods it would be a pain in the ass. But we're not newbies, we know how data-driven tests work.
Right. So how do you develop in C#, where a single codebase will work on Windows and Mac? I keep hearing this is possible, but I'm starting to get frustrated. Lets assume it's feasible to completely rewrite this app, or better yet plan ahead for the next one. What language, framework, IDE, etc, would you use?
Mocking extensions is hard. Also, with DI I'm impressed they've been able to avoid interfaces so much. 
As others have said, look to 3rd party libraries and controls for the biggest bang for the buck. When you need to diy or understand the nuts and bolts I would suggest Pro WPF in .NET 4.5 from APress. Its not really a read cover-to-cover kind of book but it is a fantastic reference with enough real-world examples to help get your head around MVVM and the frayed edges of the platform. 
If you have visual studio then look at xamarin. Other option is to build command line app. I personally would not bother porting anything graphical to Mac. If you are getting frustrated and nobody pays you for porting then you should consider your app dead. 
Oxyplot somewhat works with AvaloniaUI (at least it did before AvaloniaUI had switched to netstandard) since its API is quite similar to WPF. You might consider it as an option. Another option is to check if Mono's implementation of WinForms is compatible with OxyPlot. The main issue with Wine would be .NET's license agreement: you can't install it if you don't have a windows license for that machine.
Slow hashing is a feature, not a bug. That doesn't mean I want my tests to slow down.
I agree, grouping them into a common type tends to help a lot. 
What you can do is separate your "core" code like the calculations and everything from the platform code, pull all of the "core" code into PCL's (portable class libraries). Core code (such as calculations, lists and all of that - assuming your lists aren't using windows controls etc.,) has same codebase, anything platform specific needs to be rewritten though. It'd be a big refactor unless you wrote the code with cross-platform in mind. Not too bad though
Slow is a relative term. SHA512 has been benchmarked at ~180 M/s. That's still more than fast enough for unit testing. (The bad ones like MD5 are more in the 14 billion/s range.) http://thepasswordproject.com/oclhashcat_benchmarking
I think we may just have different ideas of clean code. If I received a PR with all of those methods combined I would reject it. Too much noise in one method; can be factored into code that reads like a book. More lines of code, yes. Easier to read and understand, yes (others may disagree). I love data driven tests but hate the idea of running one test 72 times and having multiple tests break if one line is wrong. I also hate that I could pretty easily miss a branch (although the tooling can likely tell us about that). &gt;Why is all of that stuff exposed as public? Are you actually reusing it anywhere? I may or may not be. I wouldn't create these as static methods if it were my code, I would create an interface that contains no state. I am a huge functional programming fan but C# just doesn't support it as well as I would like. I have gone down the static class &amp; delegate route with lackluster results. Too much noise for something that is really (x,y) =&gt; z . Having to pass in either *XYZ Delegate name* or *Func&lt;Type,Type&gt; name* is just not clean or fun to read in my opinion.
&gt; I love data driven tests but hate the idea of running one test 72 times and having multiple tests break if one line is wrong. Too bad, you have to do it anyways. Even if you have unit tests for each of the smaller functions, you still need to thoroughly test `GetImportance` itself. Even if all of those smaller functions are perfect, the way they combine into GetImportance may not be. It's the same as mocking out your service layer. Sure you can do it, but you still need to write the real tests that hit the database. &gt; I wouldn't create these as static methods if it were my code, I would create an interface that contains no state. Congratulations, you just added more code paths to test. (Unless there is literally just one implementation for that interface, in which case you've changed nothing.)
In this case you shouldn't really need to test `DoSomething()` as you're basically testing the database at that point. Mock the class that has `DoSomething()` and test the code that uses it.
It's easy enough with an in-memory database.
I use bcrypt which is ~100-300 ms if I remember correctly? Regardless, I don't need that running in my tests repeatedly if I have already tested is separately.
I've edited the example.
BTW unions *are* possible with C#, they just don't enjoy language-level support. Simply tag a struct with a [StructLayoutAttribute](https://msdn.microsoft.com/en-us/library/system.runtime.interopservices.structlayoutattribute.aspx) denoting `Explicit` layout control and set the [field offsets](https://msdn.microsoft.com/en-us/library/system.runtime.interopservices.fieldoffsetattribute.aspx) manually.
I was unaware of `FieldOffsetAttribute`. Thanks!
I don't think this is any better than the other solutions you've already described; but you could think about creating a custom attribute which you then apply to every relevant type. Can then query the attribute via basic refection, given a `Type` object.
&gt;Even if you have unit tests for each of the smaller functions, you still need to thoroughly test GetImportance itself. Even if all of those smaller functions are perfect, the way they combine into GetImportance may not be. My tests for GetImportance are *WhenStateIsDone_ShouldReturn0* and *WhenStateIsNotDone_ShouldReturnComputedImportance*. There is nothing else to test (assuming I don't care about exception handling). The code is changed to public class ImportanceCalculator { public ImportanceHelper Helper { get; set; } public ImportanceCalculator(ImportanceHelper helper) { Helper = helper; } public decimal GetImportance(TodoItem todoItem) { var state = Helper.GetState(todoItem.StatusCode); if (state == State.Done) return 0; var multiplier = Helper.GetMultiplier(todoItem.Priority); var importance = Helper.ComputeImportanceValue(state, multiplier); return Convert.ToDecimal(importance); } } This method doesn't know, nor should it, what happens in Helper. It doesn't care what GetMultiplier returns at all, all it does is pass it as an argument to ComputeImportanceValue. It does care what GetState returns, and my tests reflect that. &gt;It's the same as mocking out your service layer. Sure you can do it, but you still need to write the real tests that hit the database. Definitely &gt;Congratulations, you just added more code paths to test. (Unless there is literally just one implementation for that interface, in which case you've changed nothing.) No added code paths. There is one implementation, two if you don't use something like Moq or NSubstitute for your tests.
&gt; I can honestly say I've never seen a stateful extension method in the wild. Really? I’ve seen tons. For example, our code (workplace) has static methods to write to the event log. That’s stateful because it changes the state of my computer, and thus methods calling those static methods, can’t be tested in isolation. We are moving away from that, of course, and towards a completely dependency injected system, but there is a lot of legacy code.
State comes in many flavors. Writing to the screen, for example. So Console.WriteLine is static and stateful. 
&gt; The main issue with Wine would be .NET's license agreement: you can't install it if you don't have a windows license for that machine. Huh. First i've heard of that. So every time someone uses Wine to run a program on a non-Windows machine they're breaking the license agreement? Interesting.
Does it have to actually be a const ? One thing that popped into my mind was to create an extension method against either object and have a big switch for the type that returns the value or a extension for each type Edit: as my history shows my reading sucks and missed you said you tried this already 
&gt; what if that changes in the future? Then write the interface in the future. It's often the case that your second implementation introduces some new detail that you didn't (and couldn't possibly have) think of the first time. So if you had modeled the interface after the first implementation, you'd need to refactor it anyway to introduce the second. And if not? Honestly with Resharper, you just click "extract interface", check which methods you want, and you're done. I've found it plays just fine with DI, too. You can still register a class for DI, and all of its dependencies and dependents, without an interface.
I'm going through cleaning up the code to separate the calculations from the plotting engine anyway, in the hopes of perhaps moving to LiveCharts anyway. So this work is partially done and certainly not a problem. I was just hoping I could use a single codebase to do this - doesn't look like it's possible with this app. 
I've got Xamarin.Mac, so that I can write apps for the Mac. The main problem i'm running into is that LiveCharts (and apparently OxyPlot) don't support Xamarin.Mac. So I'm SOL. I think what I really need is a decent plotting tool that works in both Windows and Xamarin.Mac. The hunt continues...
&gt; So any argument, other than code organization, against static functions also applies to instance methods. Yes but not to *virtual* methods (and interface methods, which are also virtual).
Factor out the part that does the query, so you can stub it out to return an object you want to test with. I've been writing unit tests for exactly this design today.
&gt; Interfaces force all of the members to have the same accessibility as the interface itself (public or internal). You can explicitly implement interfacemembers, in which case they will be (super) private. I often do that for this reason, when I can’t make the class internal.
That code should be fine. Are you having issues with it? Also, you might want to check if cmcRlts != null so you're not going to your database every time you access that property.
Too little information to conclude that. 
Which is a good point. Extension methods should be light weight, like a string manipulation, not making other web calls, dB calls, etc. it’s a strong code smell when they do. 
Given that it's `const` ... https://www.codeproject.com/Articles/463508/NET-CLR-Injection-Modify-IL-Code-during-Run-time
Man, you are missing out. 
True, but in the context of testing virtual methods just give you more stuff to test.
Technically yes, but really event logs are not observable by the application so for more intents and purposes its still stateless. That said, I'm not against using DI for logs if it means that I'm capturing more context. While I may come across as anti-DI, I'll actually use it when I see a real benefit.
He might be trying to move your code to SOLID principles. So you have any god classes that do way more than one thing. Also the act of creating interfaces and refactoring is how some people learn the code. Still he needs to coordinate and understand the culture. I hate it when new devs come in. And just shit over everything because that's how they've always done it.
If we're going to continue this discussion you need to at least fix the obvious flaws like the null reference exceptions. You can't just throw on a naked, mutable property onto a class like that. Then if you turn on Code Analysis in Visual Studio it will warn you about the performance and usablility issues regarding instance methods that don't reference any instance fields. Have you every read the **.NET Framework Design Guidelines**? You really should because it covers this kind of scenario in pretty good detail.
Again, if you can't afford the performance hit of a given function when testing you probably can't afford it in production. 
Occam's Razor for Programmers If you have two implementations that produce the same observable outcome, choose the one that introduces the least number of concepts.
Yeah, missing out on slow performance, instability, and spurious warnings.
I don't know where you are trying to go with this. Hashing a password is slow on purpose. I want it to take a long time. However, I don't want my tests to continually run that code - it isn't necessary. In one case I am running on a server, in the other I am running literally every time I hit ctrl-s. Change 'hashing a password' to 'computing various information for reporting about a 100,000 element list': if I have tested that method there is no reason to call it directly from another method under test. It may take 10 seconds to run and that is fine, but I don't need extra tests running that code without reason.
I continuously run my database tests in the background. Literally thousands of tests. And it's not really a problem even on my cheap work laptop that's also running SQL Server in a VM. I find complaints about "slow unit tests" to be grossly exaggerated. &gt; if I have tested that method there is no reason to call it directly from another method under test. Again I will say **test your code the way you intend to use it**. You can't detect a bad interaction between functions A and B if A calls MockB in your tests.
Well you still need to test the database, just not here.
Why would you ever want to mock them? Extension methods should be free of side effects.
Oh, I'm being stupid. Just subclass ProductService with your new implementation. 
There's definitely possibilities, if you were okay with moving away from .NET's GUI platforms. You can call C# libraries from node.js and use electron 
&gt; Have you every read the .NET Framework Design Guidelines? You really should because it covers this kind of scenario in pretty good detail. Why so condescending? I didn't aim to write perfect code: I wrote enough to explain what I was talking about. I admin I should have thrown an 'I' on "ImportanceHelper" for clarity. Regardless, I don't recall any section that said "favor static methods over classes with interfaces". &gt;...performance and usablility issues regarding instance methods that don't reference any instance fields If performance is a problem I will handle it. YAGNI, at least I certainly haven't.
You are ignoring the downsides of that pattern. You have to write a lot more code to achieve the same goal. And the consumers of your class likewise have to write more code. That's why I insist of good code for examples. It often reveals flaws in a design. 
Yeah, I'm operating a little behind on VS2015 and net framework rather than core. I'm still new to development and I'm having a rough time adapting work the resources I have in place. Glad to hear you found a resolution. I'll be sure to check out those articles and posts to help my own knowledge!
Wasn't even aware this existed. Thank you for bringing this to my attention :)
Honestly? I wouldn't recommend joining it, there was a recent and sudden staff "change". It's why I'm looking for somewhere else.
&gt; You are ignoring the downsides of that pattern. You have to write a lot more code to achieve the same goal. And the consumers of your class likewise have to write more code. Show an example. I added 6 lines of interface and a constructor. The difference is negligible and easily made up for in gains from smaller, more concise tests. The tests you propose will add huge amounts of time and brittle code trying to handle every possible test case
&gt; I continuously run my database tests in the background. Literally thousands of tests. And it's not really a problem even on my cheap work laptop that's also running SQL Server in a VM. I wish I had the same experience but our integration tests take much longer to run. TFS takes an hour plus running our biggest builds. &gt;Again I will say test your code the way you intend to use it. You can't detect a bad interaction between functions A and B if A calls MockB in your tests. Again, I am not disagreeing with you. Integration tests are important for software quality. However, covering every possible interaction of methods is not an appropriate use of developer time would end up being impossible to maintain.
For a package, having an interface (particularly one that is just an abstraction of an already-created class) means you can never evolve. Interfaces can't change within a major version, and sometimes making a breaking change is just impossible. I try to only use interfaces very deliberately when there's some external dependency or where multiple implementations would be valid. This may mean that I can't mock things, but I can fake them without much extra work. Your tests shouldn't dictate that you write additional interfaces (in general, I'm opposed to writing special code just to test).
Every time you call the function, you now need to instantiate two objects. That's an unnecessary amount of overhead that must be paid each time the function is used. &gt; The difference is negligible and easily made up for in gains from smaller, more concise tests. Again, you still need the same high level tests. You can't just assume that it works together because you tested the pieces separately. Actually, you need more tests because you also have to cover the cases where the helper object is null. 
I want to be clear that I don't think I'm better than him and I respect him and his architectural ideas. I also wont be using any of this to frame or as an argument, it's purely to obtain opinions to see if I'm looking at it correctly. I will ask :)
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/conditional-operator
Thanks for your opinion. Very informative 
My major gripe is how slow he is. It took half a sprint to handle this simple timer because he spent so long structuring it in a way to make it easy to unit test. It also took him an eternity to understand the concept of the task and I basically had to pseudocode the whole thing for him. He's been programming for 15 years, which shadows my 5 and it's apparent in conversation. But when it comes down to actually writing code and completing tasks, he's slow and makes my job tedious. 
 m = condition ? a : b; is the same as if (condition) m = a; else m = b;
I understand what the operator does. What is confusing me is that "int userValue" is assigned to 2, the string says userValue is equal to one. Then we output "car - 2", now unless I'm overlooking or missing something here, I thought it would be "car - boat." The only thing I can think is that (userValue == 1) is referring to {1}"car". Otherwise, I am genuinely confused.
&gt; Every time you call the function, you now need to instantiate two objects. That's an unnecessary amount of overhead that must be paid each time the function is used. My dependencies are injected. Again, if performance became an issue I would handle it then, not before. &gt;Again, you still need the same high level tests. You can't just assume that it works together because you tested the pieces separately. I disagree and I think most others would disagree as well. It is impossible at any large scale to cover every case with integration tests. That is the whole point of unit tests - prove each unit works on its own and you should have a working system. You will be completely unable to unit test your entire system if it has any complexity. When your code has any number of branches your ability to generate a realistic number of tests disappears extremely quickly. There is no way I would allow a PR that used a unit test to test 72 different cases. Break that method up and test the pieces. Less brittle, more concise, easier to debug, and easier to understand.
That's one of the reasons why Wine is shipping Mono as its default .NET execution engine. And it's not like you can't use it at all, it's fine if you have a license activated for that computer (e. g. an OEM license key from preinstalled Windows).
The whole idea of interfaces was awesome, I was also one to interface all the things because I might need to provide a different concrete implementation in the future. Turns out, none of us are good at guessing the future so it just turns into a big waste of time unless you have a use case for it at the time of development. Customers want a product that works at an affordable price and a reasonable time line. (Just whole heartedly agreeing with grauenwolf...) 
Perhaps he has a Java background. I say that because I work at a Java shop (bleh), and their excessive use of interfaces is my biggest pet peeve. It seems to be common among enterprise Java developers, especially when using Spring. Many of those developers can't even explain why they're using an interface. For every class they write, it's just become a convention to extract an interface for it. I actually use interfaces pretty sparingly, especially in C#. I think YAGNI is criminally undervalued and too much time is spent trying to make every line of code adhere to every known design pattern and best practice article.
Maybe "true believer" is a little strong. People get introduced to something like unit tests and become *gung ho* over them. But gung ho can wear off, whereas true believer sticks a little harder. I'm perhaps going to get killed for saying this, but the problem with unit testing is when every single class becomes a "unit." Then, every single class that works with any others requires a mock. Then—on, and on, and on goes the craziness. If the guy is creating a body of code that is going to provide a service to other code, then that service ought to be treated as the unit. The service should have a very clean API, and that API should be testable. That API should maybe be contained by one interface, so that *it* can be mocked out. But inside that body of code, the tests should really only focus on the big picture. Providing an interface to pair with every class is *class explosion*—it's a code smell. I would try to work with the guy and see if he can be reasoned with before deciding whether he's gung ho or a true believer.
If there's anything I can help with don't hesitate to ask!
If you're testing the SQL, you need the same database you're going to use in production. 
As others have already brought up, interfaces are not bad. They really do make unit testing ALOT easier. Without them, you typically have to preconfigure your dependencies - usually via a database - resulting in a much larger test architecture to maintain. Furthermore, being able to mock up dependencies makes it extremely easy to test different configurations without having to recreate all of the dependencies in the database with every single option checked. One thing i haven't seen brought up with interfaces - if the functionality is going to be exposed to an external assembly, it's almost always better to use an interface. It's just a contract between assemblies that says "this is what I guarantee". In a perfect world where all assembly interactions are using only interfaces, this would allow for independent upgrades. For example, if AssemblyA exposes ISomeInterface and AssemblyB uses ISomeInterface, AssemblyA can upgrade its internal implementation or even the exposed interface at any point in time so long as they keep that interface contract. So you can upgrade to AssemblyA v1.1 without having to touch AssemblyB 1.0 (other than updating the reference). This is great in larger applications where there may be 100s of assemblies. They would all be able to upgrade at free will rather than having to wait until every assembly is ready. Theoretically you could do this without using interfaces, but it would be much more difficult. Now, I have no idea how the code looks so it's impossible to say whether or not it's over-engineering or actually has a use case, but I would really look into it before ragging on the guy.
In a certain sense, programming goes backwards. You give the computer a command and then it goes and looks for the values and rules of what the command was. You keep doing this until all the questions are answered. In this case, the command is : Console.WriteLine("{1} - {0}", userValue, message) ; This is saying write this string to the console. But it's using a format that is also saying evaluate the variables userValue and message and put them in the string. userValue is the first variable listed which means it's the variable at index 0. Thus it's what is used to replace {0}. message is the second variable listed so it is at index 1 and replaces {1}. So if we were to convert this into standard using old fashioned concatenation the command would look like: Console.WriteLine("" + message + " - " + userValue); userValue is the integer two, but ints get converted to strings when they're concatenated so we have: Console.WriteLine("" + message + " - 2"); So now we have to evaluate message. message is declared as a string but the value its assigned is actually an operation. The ?: operator is of the form that the first element is a condition (as in something that can be evaluted as true or false). Then you have two expressions. If the condition is true then you use the first expression, if the condition is false then you use the second expression. It's essentially a shortcut for an if-else. message is: (userValue == 1) ? "boat" : "car" We can see right away that it's going to be either "boat" or "car". Which one it is depends on the truth-value of the first statement. When you see an equality or inequality operator think of it not as a statement but as a question. (userValue == 1) is asking whether or not userValue equals 1. We know that it doesn't, it equals 2. So (userValue == 1) is false. So going back to evaluate message, we know that the condition of (userValue == 1) is false so that means we use the second choice, which is "car". So message is "car." So now we can put that into the string we're trying to construct: Console.WriteLine("" + "car" + " - 2"); So: Console.WriteLine("car - 2"); 
&gt; My dependencies are injected. Now you are adding DI for what's really a very simple function? I'd hate to see what you build when you do something complicated. 
Have you been following KickInteractive's thread? He turned what should have been a single function into two classes, and interface, and just now he's added a DI framework to the mix. All to avoid a simple data-driven unit test.
You sir, are the real mvp. Thank you for clearing that up in more layman way. 
Here is your silver https://m.imgur.com/gallery/sy9lVl4
&gt; If you only have 1 class implementing the interface, delete it. Unit tests would count as a second class using it so you wouldn't delete it. :-)
back when you had to roll your DI manually and mock/stub your own unit tests, this was probably correct. some people only ever learn one way to do things...
&gt; including several that contained just a single property and no methods. that's actually great usage. think about an INameable that has a single property "Name" and anywhere you want to guarantee an object has a Name, you can just pass it an INameable. in generics you'd even get to "where T : INameable". i'd argue the opposite scenario, where the IThing is a 1:1 mapping to the Thing class is worse usage.
Not just, like, your opinion, man; having a globally accessible dependency container that's used everywhere (even in extension methods) to resolve whatever is widely regarding as bad news for modularity and testability. 
Back when I programmed in C#, I was an interface for everything guy because being able to mock classes is invaluable. If I were to do it again, I'd try out [Virtuosity](https://github.com/Fody/Virtuosity) first, which does IL weaving to make everything virtual. It might be worth checking out.
Was pitching a style of architecture where IO and logic are separated to some coworkers today. Might try that as well
Since OP stated values need to be available via reflection, this is a decent approach.
Could I hijack this for a moment to ask, is there a good course that goes into classes, inheritance, and interfaces? With good examples. I am self taught and I know I need to improve here, just don't know where to look. Like is this taught in computer science II?
Simple enough that you suggested writing 72 integration tests to cover it?? You keep ignoring that integration testing every possible branch is just not viable. Unit test everything, integration test where applicable. How are you going to test a simple method that branches based on input? public static Outfit GetOutfit(Occasion occasion, Mood mood, bool isMale); public class Occasion { public Dress Dress { get; set; } public bool IsSummer { get; set; } public DayOfWeek DayOfWeek { get; set; } } public enum Dress { Casual, BusinessCasual, Formal } public enum Mood { Lazy, Normal } That is a simple case but could have many branches. Break it down into small, easy to test parts. Are you really going to cover the 100+ possible cases with an integration test? I frankly don't have the time nor motivation to maintain that amount of complexity. &gt;Now you are adding DI for what's really a very simple function? What is the excuse for not injecting a dependency? Easy and allows testable code. Like I said before, I am a big functional fan so DI is second nature.
== is a comparison operator. 1 == 2 returns false. 1 == 1 retruns true (userVal == 1) is either true or false
Thanks for the information, also I want to do it using a class and not a struct to learn how to parse it myself. And as far as the properties goes I want backwards compability where possible.
&gt; Test Induced Design Damage I've lived through this, had a programmer who was hell bent on tearing apart a project in flight to re-architect everything. There's a time and place for DI everywhere and IOC everywhere.... but not always. We shipped and have thousands of tests. That's great. But no, we don't have individual tests for every method. *And as project Architect I'm okay with that*. Readability is good, code coverage is good. Integration tests have to do something, right? I didn't know this term before, it's going into my holster for next time.
There's also one other problem, the string doesn't end up being .text but rather some odd characters, even though it is parsed as UTF8
I have to go back and redo this horrible, horrible assignment so I came back to reread the comments (and take it slooooowly) and I feel like such an idiot. WHAT THE HELL do I have going on here? I think I may have been drunk when I tried to write this. That's my story and I'm sticking to it. 
The hardest part about learning WPF/XAML for me was figuring out styling. I got the whole data binding, mvvm, and markup concepts really well, but learning to do styling properly (and offloading a lot of code from the code behind into the XAML) was a big mind curve. But, you might find the opposite - to each their own, right? Just wanted to give my two cents in case it helps!
I agree, writing to event logs affect external state. It's only when the state is internal that there is an issue with static methods affecting state.
Damn, I had the whole thing fine til they did the sneaky {1} - {0} to trip me up and make me say, 2 - car.
Extension methods break the whole modular code design.
It's kind of taught in CS, but Shawn Wunder... something at Pluralsight has a ton of courses related to that.
If a const needs to change between types it isn't a constant. By any definition. The right way is a property. It doesn't have to be public, it could even only be set by the constructor.
There are some things I miss, but I definitely don't miss my solution taking forever to load.
When I have this: public class Foo { public const string A = "Some value"; } public class Bar { new public const string A = "Another value."; } ... Bar inherits Foo.A but "hides" it with its own. In this example, I am not changing the value of the field but replacing the field altogether. The value I want describes a type and not an instance of that type. It makes sense for it to be a constant. Otherwise, to obtain the value I'm forced to implement and invoke a parameterless; that's a particular pain if I'm using reflection to get the value.
That makes me wish I had a goddamn intern. :(
Your problem here is more an issue with wanting to access it via reflection. Reflection is almost always the wrong answer. I'm not saying that it is in your use case since I don't know it, but the language is certainly not designed to be reflection friendly. For good reason. And this is coming from someone who owns a project that has to use reflection fairly deeply due to dynamically loading types and chains and segregating app domains etc.
I'm a big fan of attributes (particularly for use in initialization and it also can make for some pretty compact code). This solution makes it easier to work with when reflecting on the type, but I still can't enforce usage and I lose the ability to easily grab the value at runtime.
This is a bad practice. Interfaces are great when you have polymorphism but if you don't, they are unneeded complexity. It makes it harder to change the method signature (rename or add/remove parameters or even add a second method) Also, if they are Single Method interfaces, there is already a interface for them Either Action or Func However, I think there is a different piece of advice I would give you. Pair. I would suggest [Strong Style Pairing ](http://llewellynfalco.blogspot.fi/2014/06/llewellyns-strong-style-pairing.html) where you take the keyboard and type for him. Give it 2-5 days of just typing for him to understand his thought process and then switch and have him type for you for a few days. In the end you'll come to a common understanding. Might be his, might be yours, but usually it's a third combination that doesn't exist yet. That common understanding is worth more than anything else, and even if you waste the 2 weeks completely you'll be way ahead after 2-3 months because of it. Good luck.
&gt; I frankly don't have the time nor motivation to maintain that amount of complexity. Complexity? Again, it is just a data-driven test. You write one test with a list of inputs and matching outputs. The plan you came up with has far more moving pieces and thus more complexity.
It's dealing with time, so I imagine that there are test files and some mocks in order to break the static dependency on System and allow the functions to be unit tested. It's hard to say whether this is excessive without seeing what the person is doing and only having one side of the story.
This is very interesting. Have you done this before and what results did it yield? Just realized you wrote that article, heh.
Came here for the TL;DR, wasn't disappointed 
Do it all the time. Still struggle with being patience as I listen to methods and ways that I think I have a better answer for but that patience is always rewarded if I can manage it.
I agree with you; reflection can be abused in situations where it really isn't needed. I ain't the best engineer in the world, but I think I make a good case for using it. &amp;nbsp; I have a large number of files I need to read, the format of which has been used for *at least* 15 years. Over that time, this format has evolved with capricious changes and all sorts of idiosyncrasies. I don't have access to the original parser code base, but I imagine there's a decade's worth of ifs and aircraft carrier-sized switch statements. &amp;nbsp; The records have a 4-character signature followed by record data size (but sometimes it's header size PLUS data size), then a header of a structure that can change depending on record type, then subrecords and/or (possibly compressed) field data. Some fields are optional, some have specialized data types (such as strings that *must* be proceeded by byte length *and* be zero-terminated). &amp;nbsp; For a few reasons, I'm implementing these as types in my library. To keep them as thin &amp; clean as possible, the records are *mostly* described with attributes (the main two specifying header format and field order). But there are a couple of constant values that don't make sense to implement that way. &amp;nbsp; When I stream in records and a signature is encountered, the library checks if there is a corresponding record type. If there isn't, the record data is streamed into a generic record type. Otherwise, the corresponding type is reflected upon and that information is cached to: - Kick off async decompression streams and memory streams to parse subrecords, - Dynamically convert &amp; assign byte data to the appropriate fields, - Make my life easier. &amp;nbsp; I prototyped this out and it worked better than I expected. Fingers crossed that lasts. :P 
:) There's a bug in your parser?
It's sad irc under net is mostly dead these days. There you would've found lots of people to discuss lots of stuff... Discord feels weird for me... 
I can do everything inside Main. Beat that!
That code smells. Create a factory for making these object. Inject the repository in the constructor of the factory, and create a method that returns an instance when given an id
This. +100
Agree - Tuples are too loose in many cases (not all). I'd rather use a bool return type with out, or, return a class containing the needed values.
Haha, you’re not wrong there. To me, the upsides outweigh the down, but I sure wish I never got used to it. I’d have so much more available memory!
They’re going to have to hook resharper into Roslyn aren’t they? At the moment there’s two solution caches being built, which is patently ridiculous. Still, it save me loads of typing. 
&gt; string message = (userValue == 1) ? "boat" : "car"; Since the right side is an expression, it is evaluated before the assignment. As previously mentioned, ?: is basically a short form of an if statement. So, if you expand it out into a full if block, it would look like this: string message; if (userValue == 1) message = "boat"; else message = "car"; (note: I omitted the `{`s and `}`s because each part is only a single line) As for the rest of it, because the formatting parameter is "{1} - {0}", it reverses the order of the two variables passed to it.
Not in this case. It was massively over engineered. A very simple single function app with a couple of screens.
If I could modify that code, I would just modify the Individual class, which I cannot.
And not having an interface doesn't actually fix that in any way shape or form. Public methods and properties are a code contract whether you create an interface for them or not. They're just as abusable and just as difficult to pull back in whether they are in an interface or not.
https://www.reddit.com/r/csharp/comments/737uht/new_guy_joins_the_dev_team_creating_interfaces/dnocpu4/
Code that is tested is better code. Being easier to unit test is helpful in getting your code tested, but it's not a goal. Writing code in five super clean looking lines that can't be tested is crap. No one but the developers will ever see how pretty it is, but all your users will experience the thing you fucked up and didn't test. If you think that testable code violates agile then you've missed the point. Good test coverage is the only reason you can be agile because it allows you to safely pivot when requirements change. If you need an interface to test critical parts of your software then you need it and you need it now. Agile is about being able to respond to change and rapidly deliver value. Pretty code that's not adequately tested is not value. Pretty code is massively overvalued. Small file counts are massively overvalued.
Wat? Are you sure that it's not just the browser executing whatever monster script you have as soon as it's rendered?
Testability is a damned good reason. You're not paid to minimise your lines of code either.
Thank you everyone For your responses! I will take consideration of every single suggestion and I really DO appreciate your time and effort on helping me out! First thing I learned that I have to forget the way I worked with WinForm and try out XAML. Thank everyone once again!
I disabled js in the browser as well, ye. It seems to be on the asp side. Loading the file via the file system (locally) seems fine and withing a few hundred milliseconds.
It shows he's been a developer longer because he's following a style that was popular between 5 and 10 years ago. It's not a bad approach, if a bit dated. None of the progress since then has been a game changer so your colleague will benefit from consistency. I'm extrapolating a lot based on a little and I think you've provided the wrong information for us to make an informed decision. It feels like that's due to inexperience which is fine, you're questioning things which is one of the strengths of a good programmer. One example of "wrong information" in this case is focusing on how many files they used. With C# there "should" be one per entity (class, interface, whatever), so he has 12 entities. Does that include tests? That would be more useful to know. 
That makes sense. The reason it confused me is because I was taught the past that the code is read sequentially and that's the way I was looking at it.
Are you going through course as well?
If the script or page has a text field that looks like a you inserted malicious context for XSS (cross-site scripting) it will crash the page. This was called AntiXSS waaay back in the day and now called Request Validation. Check your Web.config. Perhaps this is it? https://msdn.microsoft.com/en-us/library/hh882339(v=vs.110).aspx
i promise that unless it's a 486DX4100, your server taking 20s to return anything is not normal behavior. did you build the box and install IIS yourself? if you don't know what's all installed on there (virus scanners, etc.) how are we supposed to know?
Is this a new asp.net 2.0 razor page by chance? Also need to see the script details probably to make a diagnosis. 
If this is a new project with VS2017, its probably the time it takes to attached to the browser's debugger that has to time out before it continues. You can disable that option in VS settings if you google how. If you have a slow machine, it could also be the time it take VS to bundle and minimify your script. If you are using an Angular or React template from VS 2017, then it could also be the Java Script Services template add ins taking time (they wire up your VS debugging to webpack and live browser updates). To help you for sure, we'd need to know what kind of project you are using, and how you are debugging.
it happens locally as well in iis
the script is already minified, it just seems that asp seems to render the raw transmitted html page before sending it and analysing the shit out of it. if i enable the trace feature tho, the page gets sent instantly
i already tried to disable all kind of validation using web config and the page settings on the top, but it still seems to scan the text. it includes an eval() tho if that matters
Again, what you describe sounds like something a request getting flagged. Do you receive a &lt; or &gt; or ` anywhere that is sent to that eval? RequestValidation does regex string matching, so it will find most trivial examples. Post your Web.config, but I cannot tell because your quick answer does not encourage us to help with minimal details, code, or steps to repro. Perhaps post the web.config with sensitive data removed? Sample code?
Whats more astonishing to me is that you want to use the "newest" technology and use WinForms... If you have plenty of time and want to learn something new use WPF (most of the concepts translate to UWP apps which is an added bonus). I would recommend using EF6 over EF Core for most things that don't need to be cross-platform as EF Core still lacks some mayor features like [GroupBy translation ](https://github.com/aspnet/EntityFrameworkCore/issues/2341). While EF6 will not get any new features it's still being [developed and maintained](https://github.com/aspnet/EntityFramework6/wiki/Roadmap) and for the most part they are similar enough that switching to EF Core in the future (when the feature gap is closed) shouldn't require much relearning.
Entity Framework 6 is still active and you should use that version: https://github.com/aspnet/EntityFramework6 EFCore is in a early stage that currently misses some very important feature like LazyLoading that you want to use for Desktop Apps and Many-To-Many mapping (without adding extra classes). For starting just create a new WinForms Project and add an "Entity Data Model" and play around with that. (ModelFirst) Next step would be to learn the Code First approach. Here is the official Doc from MS: http://msdn.com/data/ef 
i'd start over with a new project. add in whatever 3rd party DLLs and packages one at a time until you figure out which one is doing this. that's not normal. also, turn off all your computer's virus scanning
what kind of resources would you recommend to get started head first into a project? for someone who gets the general idea of WPF/XAML but lacks specific practices like having a code base that works well with MVVM and WPF specific data binding.
&gt; Whats more astonishing to me is that you want to use the "newest" technology and use WinForms... If you have plenty of time and want to learn something new use WPF (most of the concepts translate to UWP apps which is an added bonus). So much this. I often rant about this, it's so damn frustrating.
It seems to be asp, i can't fill a string variable with the page content without it getting scanned.
the web config only has &lt;httpRuntime="2.0" /&gt; and &lt;pages buffer="false" validateRequest="false" /&gt; but those don't help the string to sent not getting scanned. the file to transmit includes a full html markup and is valid. asp net only seems to act up when i uncomment javascript parts within it.
Now we're talking! What version of VS does you have handy? I usually get halfway decent debugging in VS2017 when I run the app in debug mode, all the way into the JS components when I debug it in IE (I hear others use Chrome, but I use the former for client concerns). Set a breakpoint on the codebehind for the page in question? You see no errors at all or you cannot debug it in prod or something?
For winforms.. It was not my choice, but a necessity. But it was the only thing I cannot change there. I will return to EF 6, as I ran into some stupid ValueTuple not exist error, I couldn't fix. 
Nah.
I agree.
&gt; non default constructor means it does not take in parameters. A default constructor takes no parameters. He wants you to write a "non default constructor", means a custom one that does accept parameters. According to the exercise it should expect a "long integer".
Someone did already, it's in a library.
Being lynched by the other members of your team is an "observable outcome".
okay thank you
A default constructor is the constructor that is automatically generated when your type does not contain any. You can write parameter-less non-default constructors.
&gt; Started with EF 6, but soon I understood that it is not in the active development and Ef Core is the future. It is the future, sure, but EF 6 is the now :)
&gt; And not having an interface doesn't actually fix that in any way shape or form. No, but it does make the remediation process harder. When I need to fix projects like this, I start by wiping out the accessibility modifiers. Then I add `protected`, `internal`, and `public` as needed until it compiles. That doesn't work if everything is bound up in abstract interfaces. *** A related problem is when a function return an interface instead of a class. If the interface is public, then all of its methods are public. That means I have to either make the internal functions public or perform an unsafe cast to get to class's internal interface. 
curl “http://www.nytimes.com” | grep -o -P “&lt;p&gt;.*&lt;/p&gt;” There. Didn’t even need a compile 
Oh well, i might actually start debugging it now with breakpoints. Visual Studio 2015 here. It's a normal web app on a local IIS server.But it completely fucks up transmitfile, writefile or response.write if the content includes some &lt;script&gt; tag.
Can you give me a example?
I was thinking along the lines of publishing an event, and the subscriber (maybe buggy, maybe not developed by you) gets into long processing, which makes the rest of the subscribers wait. And in the extreme case of an infinite loop or wait, your whole system gets stuck. I don't know. If you handle it with care, it's ok. But if it's something that will be used by other people... It can get hairy. Anyway, good concept
Default constructor simply means the constructor without parameters. If you don't specify a default constructor (or _any_) yourself, a default constructor is created. A self-written one that accepts no parameters is also a default constructor. https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/using-constructors &gt; A constructor that takes no parameters is called a default constructor.
I was just commenting on the terminology, it's not relevant to your homework. 
The singleton pattern. The method or property used to return the singleton instance first checks to see if the static instance already exists and, if not, instantiate it, thus the method or property isn't stateless.
How does this look? using System; using System.Collections.Generic; using System.Linq; using System.Text; namespace NmTimeClass { public class TimeClass { public long seconds; // Default constructor: public TimeClass() { seconds = 0; } // A constructor with two arguments: public TimeClass(int seconds) { long sec = this.seconds; } } } 
Hm, official language seems vary on this. For example, the spec says &gt;##Default constructors &gt;If a class contains no instance constructor declarations, a default instance constructor is automatically provided. That default constructor simply invokes the parameterless constructor of the direct base class. If the class is abstract then the declared accessibility for the default constructor is protected. Otherwise, the declared accessibility for the default constructor is public. Thus, the default constructor is always of the form Which seems to differentiate between "default constructor" and "parameterless constructor". Other places also seem to use "default constructor" exclusively to refer to the automatically generated ones. Then again, that doc explicitly calls it out as being the same, so what do I know.
That's why I'm convinced request validation happens somewhere. If you change it to script? Is it possible you have a WAF or you do browser testing on the same IIS box?
The doc snippet does not differentiate between default constructor and parameterless constructor. All it says is that a default constructor is provided if no instance constructor is declared. And methods like `Activator.CreateInstance(Type)` say they will invoke the default constructor. I've never seen a distinction between a self-written parameterless constructor and the compiler provided one. So I keep on going with "default constructor == parameterless constructor".
It says that the default constructor will call the base parameterless constructor. It doesn't explicitly say that there's a difference, but it uses different language for both of them. May just be a stylistic choice, of course. Anyway, that's the usage I've been familiar with, but it seems you're right.
Removed: Rule 4.
[Oh you two make my job so difficult.](https://i.imgur.com/Gu4XPII.jpg)
Nothing like this ever happened while I was moderator.
waf? I just confirmed the same phenomenia in firefox. Having the data transfer with "&lt;screept.*" delivers the site content within milliseconds, but having it with &lt;script takes 20 seconds to transfer. The browser is stuck at spinning, the content takes those 20 seconds inside asp apparently. Debugging the code was fine until the point where it was currentResponse.Write(filecontent) whith the script tags not uncommented.
Just import the System.ValueTuple nuget package to fix that issue. 
http://www.reactiongifs.com/r/heh.gif
Incredibly, they've already made it very clear that they will never use Roslyn. https://blog.jetbrains.com/dotnet/2014/04/10/resharper-and-roslyn-qa/
Done that and 10 more other fixes. Still useless
Not having interfaces out the wazoo usually makes me sad. I don't tend to go back and remove ones I "didn't need" because I can't predict the future and I often need them. I look at it this way. Just this year I've said: * **Hundreds of times**: "Damn, if I'd made this type implement an interface, this test would be easier to write. I guess I need to add one." * **Ones of times**: "Damn, this code is hard to understand because there's too much indirection." That said, every project's different, and you can certainly write bad DI code. If your types are large and serve many purposes, that's going to cause you a lot more trouble than the "clutter" of interfaces will. But that's also a case where interfaces don't help because it's harder to test anyway. So all I can say without sitting at your desk and looking over a lot of code is, "I, too, once thought there were too many interfaces in my project, and three years later I think there are not enough."
It should be an abstract, read-only property. When you have something in a base class that *almost every* derived type needs to change, that is not "common code". Think of it like saying, "all birds fly" then trying to resolve whether a Penguin is a Bird. "Penguins are special" also implies "not all birds can fly". It would be better for the base type to not define the behavior, then if you really don't want to duplicate the constant in the types that share a value, derive a 2nd-level class that has that constant for those to derive from.
&gt; If you have plenty of time and want to learn something new use WPF Can you recommend some good resources on learning WPF?
Wow. That’s three years ago. If they haven’t changed their mind yet, I suspect their product is going to be cannibalised. 
It's been quite a while since I learned WPF so I can't even really remember how I started, but I've often used [this site](https://www.wpftutorial.net/Home.html) as a reference, but honestly there are probably better tutorials/references out there. I would also recommend that when using WPF you should look into the MVVM pattern and frameworks that help you implement the pattern (like MVVM Light or Caliburn) sooner than later.
Web app firewall. Firefox does not use XSS protection buta Chrome has a mechanism some don't know of. FYI Strange because of exactly what you describe.
well no, it is the same in every browser there. It seems to be related to the HTMLTextWriter class and it's buffer or some feature related to the writer itself.
What are you trying to do with ValueTuple? Also if i remember correctly you need to update the Compilers package through Nuget to get the new C# 7 stuff working.
Nothing. It is just a bug. Been reported several times on stack overflow and GitHub. It usually occurs when you try to use EF core 2 in class library.
An interface passed via constructor is easier to maintain that 100s of integration test cases. I'd hate to see what your tests would look like when calculating anything remotely complex. God forbid a requirement change - you would need to update potentially thousands of test cases. Worrying about the performance of a virtual call, the overhead of an instantiated class, or the hardships of passing dependencies is ridiculous. Write clean, easy to maintain code, don't worry about stuff that rarely matters. Keep doing what you are doing but newcomers beware: unit tests and integration tests have different uses and both are important. It would be a mistake to fall into the pattern that grauenwolf describes.
I hang out here. I'd say it's the defacto C# Discord server. Quite active at that. https://discord.gg/QKU4JFM
I don’t want my children to be bullied
There actually are O(n) sorting algorithms. There isn't such a thing as O(n) comparison-based sorting algorithms, but there are non-comparison-based sorting algorithms, such as counting sort or radix sort, which are not bound by the lower limit of O(nlog(n)). Edit: lol this post is a week old. Oops. 
Then use a test instance of the same database you're going to use in production. If it's just the boundaries of your system it's not going to be a significant slowdown. You can make excuses for not testing code you write, but they're just excuses.
If no one wants to to help can someone please direct me to another forum?
The title cracked me up
What's wrong with split()? Just use .trim(']') when turning the strings into uris
You could use RegEx if you wanted: `Regex.Matches(”\[(.*?)\]”).Cast&lt;Match&gt;().Select(m =&gt; m.Groups[1].Value)`
_But our children!_
It's actually 15 files... without the tests. The only task it performs is: Timer to wake every x minutes -&gt; Check if a task needs calculating -&gt; Add to queue. For context, I wrote this which yields the exact same results: https://i.imgur.com/ePEWGbw.png
I really love his videos. Definitely a good start.
While not stateless internally, if you wrote it correctly it would be still be stateless from the perspective of the caller. (Baring any mutable state in the singleton itself.)
6 classes honestly doesn't seem like that much. I'd probably have minimum 2 or 3 classes that are just models for holding/passing data.
Yeh, and then the complaint should be about why static methods should be stateless. Blaming all static methods because of a few bad static methods doesn't seem senseable.
That guy does good stuff. Highly recommend for simplicity
Yes, that is what I do now, but to me it seems like this should be a LINQ thing, no?
Shoulda named the package "Bully." Missed opportunity
I'm not making an excuse, I'm pointing out that if testing the SQL is the point you can't use a different DB.
Well, for starters I'd do a project or two without any third party libraries - just vanilla WPF so that you can get a handle on it. Nothing comes right to the front of my mind when I try to think of learning resources here, there really is a ton of info out there. VS has the same wysiwyg designer for WPF as it does winforms, and you can keep the XAML open side by side with it. I'd go right in with the wysiwyg editor and Google for help when you run into an error. That's how I got going, I gradually found it easier and easier to work natively in the XAML, and after a year I couldn't use the wysiwyg anymore, XAML became too quick! I'm sorry if that's not how you learn best, it's just what I found for myself. As far as third party libraries go, if you've got a big project I'd recommend CSLA.NET for your business/data access laters, it works great with the MVVM pattern, if you end up liking that. That framework is definitely overkill for small apps though, but for large apps it makes everything pretty smooth down below.
Time really is the best solution to move from the basics into the wpf binding/mvvm ideas.
Very nice Is there something similar to this for python?
Sad!
I somewhat agree, except that WPF can hardly be considered new. In fact, many would argue that it's pretty dead (although that's not really correct either).
I don't recommend certifications. You will spend ages studying and pay lots of money for the exam, only to use less than 10% of that in practice. You can learn a lot more by NOT doing certifications.
I think http://www.wpf-tutorial.com/ does a good job of walking you through the available controls. It's a little lacking on MVVM though; the most it does is set the datacontext to the window itself instead of using an external viewmodel.
You do not have to use linq for everything... linq is just an easy way to work with sequences. You can use linq after you have split the string into a sequence of strings though.
He has a [Learn to Program series](https://www.youtube.com/watch?v=nwjAHQERL08&amp;list=PLGLfVvz_LVvTn3cK5e6LjhgGiSeVlIRwt) which uses Python. 
Their solution might be a tad verbose then ;) Yours has a few problems itself, although I don't know what MockCacheService is doing, it looks like it's somehow iterating over _goalCalculationQueue, but it isn't clear how it accessed it. Again, I'm guessing. If MockCacheService has a reference to this IntervalChecker and is callig ReturnGoalsToCalculate, the only public method, then you've got a mad death spiral going on there :) So first, Queue is not really thread safe. You''re Enqueueing stuff but I can't see anywhere you're dequeueing. Either way, those operations might cause a crash if they collide. Anyway, it looks like the queue is never emptied down, so every new job found just adds to it. That could be by design, but it raises the question of why use a Queue as opposed to something that doesn't look like it's waiting to be emptied. You've got a private method calling a public one. Generally speaking this is bad form. Also, there's no exception handling, but again, that could just have been left out for brevity. If your timer throws on a threadpool thread you'll see nothing except your app disappearing, again depending on what's consuming this. It depends on whether this class is consumed by other classes or will ultimately be running in a little process on its own. I would have made GetNextInterval a public static or an extension method and moved it off to a utility class. It's the kind of logic that's perfect for that. 
That's very useful. F# calls these [units of measure](http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/).
I've been working on better documentation for my command line parser library, **clipr**. Among other things, it supports custom converters (even for built-in types) and localization which are missing from most of the other libraries out there. https://github.com/nemec/clipr https://blog.nem.ec/clipr/
Check Corey Schafer stuff. IMHO best python tutorials on youtube.
What technology? WinForms, WPF, WebForms, MVC, HTML, third-party? Maybe try a lost focus / blur event? Then it doesn't matter how the text is entered 
I went through the whole series and I felt pretty good after. He does a great job introducing you to the syntax and after some practice in my own I felt ready to move on to some intermediate stuff.
Are you looking for someone to give you a project to do or are you looking for source code for a simple project that uses sql?
reported for spam
Removed: Rule 6, spam.
Removed: Rule 4. There are learning resources and project ideas at /r/learnprogramming. You can use a Console Application, WinForms, or WPF for a C# program that runs on Windows. You can use GitHub to host your source code.
Make something, anything. Just don't ask for someone to give it to you. U can make anything using a database, it could be as simple as the inventory of the groceries u keep in the house
U give us a url that u want to split on the [, but that url doesn't include it. U could also look at a uri-parser to give u all the info.from tjat uri
Hey Cristo, I'm struggling to implement this as I used to create an array which held all the cards. This was previously done with the following code: private Card[] allCards = (Card[])Enum.GetValues(typeof(Card)); However this now creates a System Argument Exception - Do you know how I could store all the cards in an array using the code you wrote above? Many thanks, Elliot [Edit] A list like this could be used to store the values : List&lt;Card&gt; all_Cards = new List&lt;Card&gt;() but the problem then becomes adding all the cards to the list. Does your var "cards" contain all the cards in the game?
Thank you!
Would you not want to just save the values into the text file, but refer to them in a list or array so you can just call their index value? If each record MUST have a distinct value, could it be assigned in the constructor of your class maybe? That way if the record isn't used you can just kill that instance and the value would be reset. (Sorry, I'm still relatively new to C# myself...not sure how to do exactly what you're asking off the top of my head)
My side project is to learn Reactive UI and Reactive Extensions. I've read the intro to RX website and the documentation (that I can ...) and am starting to try to apply it to some of the projects at work on the side. So far... I'm stuck :( https://stackoverflow.com/questions/46492665/how-to-use-reactivecommand-binding-to-a-button-to-trigger-an-different-action-on
Sounds like you're trying to do what an identity in a SQL Server database table would do for you, that is, assign the next available number to the record you're about to write. As I see it, you could write a quick function what would count the lines in the file just before you're about to write your row to it, which would work perfectly in an environment where you're guaranteed to be the only process writing to the file. Something like this: private int GetCountOfLinesInFile(string filePath) { if (File.Exists(filePath)) { return File.ReadAllLines(filePath).Length; } return 0; } That would work fine as long as you could make sure you can open the file, and that it exists, yada yada, however, someday that file is going to be huge and so you may need to switch to a method that doesn't attempt to read the whole file into memory like this one does. Another possibility that is much less hassle would be to use a Guid instead of an integer. This is guaranteed^* to be a globally unique identifier, so you'd generate one this way just as you're about to write to the text file. Guid g = Guid.NewGuid(); You can write it to the file with the ToString() function. ^* (there is some debate about whether this is actually correct but it has been in my experience)
I currently work on a FOSS modern Implementation of "Drug wars" with full support for Unix and Windows. Can't wait to release it :) Currently on a little delay since I want to participate in Hacktoberfest.
Does the EventArgs store the reason for the event maybe?
maybe use a method that assigns numbers only when you are saving? for example: static bool TrySavePersonList(List&lt;Person&gt; persons, string path) { try { int i = 1; var indexed = persons.Select(p =&gt; i++ + Environment.NewLine + p); //adds the index (+1) of the person to each .ToString() result File.WriteAllLines(path, indexed); return true; } catch (IOException) { return false; } } with `Person` being a simple model: class Person { public readonly string Name; public readonly string Adress; public readonly string PhoneNumber; public readonly string Country; public Person(string n, string a, string pn, string c) { Name = n; Adress = a; PhoneNumber = pn; Country = c; } public override string ToString() { return Name + Environment.NewLine + Adress + Environment.NewLine + PhoneNumber + Environment.NewLine + Country; } }
Sometimes I give my children poison pills and watch them die. So a bit of bullying won't hurt.
...Dapper I don't know why you insist on being so stubborn when it comes to interfaces. That's a pretty ridiculous claim that you should have known was BS before you typed it. 
SelectedIndexChanged?
This smells a lot like someone's homework. My recommendation is to pay attention more in class. If your teacher is doing their job they've given you the fundamentals to do the assignment already. If this isn't your homework, it's honestly a really bad implementation.
This idea that interfaces are only for unit testing is ridiculous. It decouples your code and makes it more flexible, whether you like it or not. If you've resigned yourself to having to rewrite large chunks of architecture every time a business requirement is added, then of course you don't see the point: because you've always done it the hard way. If you claim that your code doesn't need to accommodate change, you're kidding yourself in a stubborn attempt to win internet arguments.
I really love Derek's work. He's a great guy and takes time to respond or help his viewers. Great dude overall. And really knowledgeable. 
I'm trying to invent a language for touch screens really, it's supposed to be functional and purely visual. Having trouble settling on a look though. I have a conceptual brief somewhere but I don't want to share on Reddit yet. Also F# has me hard as a rock these days so I might switch it up a bit.
You can have the same spaghetti code with every class behind its interface. Even though you can mock each and every dependency in unit tests and you can swap out different implementations, you can still easily hit dead ends. It's really easy to create classes with a deep and also wide graph of dependencies, which DI containers can hide very well. It's also easy to create dependencies between seemingly not related types, like you have to call ISomething.Intialize() at the right time and you should pass IOtherThing.Do(ISomething). It's also really easy to mix up the direction of the dependencies. All I'm saying is interfaces are great tools, which meant to be used wisely and I get frustrated when people say I created these classes and interfaces because of decoupling and mvvm and whatnot and all I'm seeing is code which should be close together are split up and I have go through a lot of boilerplate code. Mostly when the class/classes will stay as is relatively forever. Sorry for the rant.
Is this homework? If so, do your own homework. If not, this is a really bad way to do whatever it is you want to do. You need to use a database, this is explicitly what they're for. Try [sqlite](http://blog.tigrangasparian.com/2012/02/09/getting-started-with-sqlite-in-c-part-one/). Very lightweight and great for beginners
WPF is a steaming pile of garbage and always has been. I’ve done a lot of consulting over the years and every company that has tried to go wpf has regretted it. The learning curve is huge and it absolutely requires designer help where as winforms you could make a passable UI from just programmers to satisfy business requirements.
WPF most certainly has a steeper learning curve, but it's the only bearable option for developing a maintainable and modular GUI with c# under Windows. Every GUI that is slightly more complicated than a bunch of textboxes and buttons is just a maintainability nightmare with WinForms. It's like recommending nothing but vanilla html/javascript to develop a complex web application, it's not like you can't do it but you will most certainly hate yourself a few month in the future.
wpf
Dapper modifies the state of the object is extends, but the extension methods themselves don't contain visible state. The same is true for the `.Add` extension method. &gt; I don't know why you insist on being so stubborn when it comes to interfaces. Because they are grossly overused. People have this stupid idea that when tell them that A needs to be decoupled from B that just adding an IB interface does the job. No, god damn it. When I say "decouple A from B" I mean "A should never call B because that's causing problems". Spray painting an interface on top of B doesn't do anything but change its color. And no, adding nearly worthless mock tests in your services does not mean you can skip writing all of the database integration tests I asked for. That just means you've doubled the amount of tests that need to be maintained. Finally, stop declaring that a function returns an interface when you know damn well what concrete type the function can return. Giving me a `CustomerCollection` is a hell of a lot more useful than an `IEnumerable&lt;Customer&gt;`. *** That's not to say I don't use interfaces. Look, I've got plenty of interfaces. But they are used to represent the common functionality across classes, not to replace the public interfaces the classes already have. https://github.com/docevaad/Chain/tree/master/Tortuga.Chain/Tortuga.Chain.Core.source/shared 
Put the combo box in a user control or inherit the control and just add a very simple event yourself. Takes 5 minutes and you can extend the hell out of it.
I'm building a database analyzer. (SQL Server and PostgreSQL, eventually MySQL as well). https://github.com/Grauenwolf/Tortuga-Drydock Currently I'm using WPF, but I'm looking forward to trying out the newer cross-platform XAML-based UI toolkits.
I use Bana's videos mostly when I want to get acquainted with a new language after having already grasped the basics of programming. I feel - humbly - that he's better for that type of student than one who is starting from scratch. I'm currently going through this tutorial in addition to Bana's playlists: [Learn C# by Building a Simple RPG](https://scottlilly.com/learn-c-by-building-a-simple-rpg-index/). Scott Lilly basically runs you through building a desktop application with basic structures before making it more complex with delegates, XML, and the like. 
There is no secure way to do that. If the safety of your database is really a concern, you better off putting it behind a REST service and implement some sort of authentication mechanism. This way you can fully control who can access the contents of your database, and to what extent.
Developing little library which does arithmetic on units. https://github.com/markovcd/UnitMath Planned features: 1. Defining any basic and derived units. 2. Parsing those units from strings like "3 kg" or "23.4 N/m^2". 3. Doing arithmetic on those values. 4. Automatically simplifying more complex units.
In the code above, the member _availableCards contains all the cards (until you start dealing). The Create Cards method, has a local variable named cards but this method is only used to first populate the deck. In the constructor: _availableCards = CreateCards();
First I said "clean readable maintainable" code was what to strive for. I notice you replaced that with "pretty" in much of your criticisms which is unfair. For example your last line you say "Pretty code is massively overvalued", replace that with "Clean readable maintainable code is massively overvalued" and your statement becomes obvious nonsense. You are mischaracterizing my statement about code quality which obviously matters as a statement about code aesthetics which obviously don't matter nearly as much just so you can dismiss it as being a merely aesthetic consideration. You seem to be taking my use of the word clean as if I meant "very short clever code". Since there is no absolutes then the definition of clean comes up. I would say simpler is cleaner, shorter is cleaner, better commented is cleaner, better structured is cleaner. All these are competing. Sometimes you can have a very short complicated solution or a longer simpler solution. Which is cleaner? It's a judgement call, personally I would err on the side of simpler over more complex. Your statement about code length being irrelevant is also obviously incorrect. Generally speaking, it is a lot cheaper and easier to maintain a 10,000 line code base spread over 100 files than it is to maintain a 50,000 line code base spread over 500 files. That's just obvious. And if it is true at the macro level it is also true at the micro level. There are certainly times when the longer solution can be both better and easier to maintain but all things being equal shorter is better. I'm sure you can even see this in your own work. I suspect when you sit down and plan out your code before you write it and take a little time to think through the potential issues that might come up before writing the code you will end up with a shorter, simpler, better solution than if you just plow right in and figure it out as you go. This is a case of the same developer tackling the same problem and producing a better shorter solution. Now if you come back and re-tackle that same problem a week later you can probably come up with an even better, even simpler, even shorter solution. Again, same developer, same problem better solution. It's certainly not always the case but in general, the more you understand the problem the simpler and shorter the solution gets. Yes, there will be exceptions but if it is true for any individual developer that if he tackles the same problem multiple times his solutions will tend to get better and shorter it is probably true for code in general that the shorter solutions are probably the better ones. As for unit tests, in general they are great but there are lots of situations where it just gets so messy that it becomes problematic. Timing dependent interactions is one, real time graphics, systems that interface with external sensors and devices, non-deterministic output etc.
I'll second using a service/Web API for your data access. You didn't indicate where your database is, but you didn't say you copied the database when you said what files you gave them, so I assume its on your computer. You may be able to get everyone on the same workgroup and connect via Windows authentication -- i.e. no user Id and password would be included in your connection strings. But, there's not enough information in your request to indicate if that would work.
I believe there are ways to encrypt the connection string section. Also, you might consider hard coding the strings in the source. Not ideal usually but for a simple app it solves your problem.
Oh well TIL. I thought the app.config was secure and the default place to put any sensitive data. What is the point of putting connection strings in there if they are not secure then? How exactly does a REST service work? I only have access to an online database so I do not own a server myself.
The database is an online one hosted by Microsoft Azure so the connection string is the Azure details, what other information would you need? See my response too about service in other comment.
Yeah that's what I would assume then. This is just a project for university so it's not THAT much of a problem but I'm still going to be giving it to some friends for them to use/test etc I'd guess just hard coding the strings would be the easiest, for now at least.
I have a side project of creating a [board game library](https://github.com/Hyftar/HBoard). I have been working on it bit by bit but my progress is very slow. Started that 3 years ago..
Because it is simple and it is enough in a lot of cases. As the other commenters pointed out, you can just hardcode your database credentials, or encrypt your config file. The problem with encryption is that now you need to secure the key to decrypt your config file, which you can't. A REST service is basically a HTTP server. The HTTP server sits between the application and the SQL database. The application can only access the database through the REST service. This way your application doesn't have to know how to connect to the SQL server. Depending on the contents of your database, it might be simpler to just hardcode the credentials. It doesn't provides any protection against person who can use a decompiler, but it works against regular users. If you go with the REST API way, I recommend you to do some research on the ASP.Net Web API. You will probably be able to reuse pieces from your existing application.
This has nothing to do with lambda expressions. You might implement it using lambda but the solution is not related to lambda.
&gt;Oh well TIL. I thought the app.config was secure and the default place to put any sensitive data. A human-readable file can never be "secure"
Just know people can use decompilers to get at this information still. Things like dotPeek and IL Spy
Thanks, will research it sometime but for now I will just hardcode the credentials as I do not have a place to put the service on. The database is just not so important information other than login details for the actually application.
True. I'm still a student at uni and we were always told to 'never hard code connection strings etc, always put it in the config'... well then, haha.
Yep i know :(
&gt; Oh well TIL. I thought the app.config was secure and the default place to put any sensitive data. As soon as the file is on the users system, it's not safe anymore. The user has access to it.
That sounds cool, can I make pull requests?
Just FYI, even your compiled code is not safe. I believe securing your data is not as simple as where you put connection strings. You need to create the appropriate user on your DB for the client connection and give them the proper read/write access. You also need to protect the database server itself (if it lives elsewhere). If it's a local db, then much of this may not matter -if the user is monkeying with their own data, who cares? If your db is remote, then you ultimately want to put it behind some code (in the form of a service or a server) that does the db access itself, and your users just call to it. ReST is one example, but there are other solutions. 
Hey, in azure you can deploy a web API project (even from visual Studio). That would be what hits your db. FYI "REST" is not a technical term. It is concerned with how you represent data operations. Look at WebAPI to get started and the rest (haha) will follow. If you Google "web API rest azure" i have no doubt that you will find some tutorials.( The rest is just beating your head against the wall and crying.) Azure makes it all much easier :p 
Yeah but this is really my first time sharing any project created with VS - I never knew the config file would be needed with, thought it might be compiled together or something.
&gt; in azure you can deploy a web API project I'll have to give it a gander some time then :D
I'm working on a relatively simple project where I can define application view layouts dynamically by drawing and resizing rectangles. Those view layouts will be distributed from a central configuration applications to all the users at runtime. The hard part for me is getting the drawing process to work the way I want it to. This is my first time writing anything using the drawing library or a picturebox, so keeping the flicker away, and also getting the boxes to smoothly grow all the way to the border or the next adjacent box regardless of mouse speed is proving to be a challenge. Once I finish the drawing aspect, the rest will be a breeze. 
You know, you could simply look into encrypting the credentials inside the app.config file This should get you started https://weblogs.asp.net/jongalloway/encrypting-passwords-in-a-net-app-config-file
A hardcoded connection string isn't secure either, but is obfuscated. Putting the info in app.config lets you easily change the backing db without recompling. You can switch between testing and production dbs, different users can use their own db, you can change servers, etc. The app.config is for configuration, not security.
Awesome thanks, will check that out
Encrypt the connection strings, passwords etc. It isn't 100% bullet proof because it is technically possible to find the encryption keys in the process memory with the right level of access, but that's quite a far-fetched possibility.
You can get a rest service up and running in like 38 lines of code. It's worth learning tbh!
Even if you compile it, .NET is very easy to decompile.
I completely disagree on the idea that winforms is impossible with any complex UI. It’s completely fine and I’ve seen many enterprise scale projects with very complex winform UI Work great. And in fact easier since ui element to code is straightforward. Where Winform however isn’t good at all is with scaling which becomes a big issue in modern high dpi monitors. Why do I know a lot about this? I owned gcs and richercomponents back in the day before I sold it that did UI controls in both winform, wpf and asp.net. 
How about having a second file that just records the last number used? Empty or missing file means start with 1. Technically, it's not multi-user or multithread safe in the slightest, but it'll be good enough for schoolwork. 
EF Core CLI, and EF Core Package Manager commands are separate. The docs are great, follow those to get yourself sorted. https://docs.microsoft.com/en-us/ef/core/miscellaneous/cli/
If you are trying to make a secure application you never connect to the database from the client. You need a server in between that handles requests from the client and runs the database query. For example: 1. Client Sends Login Info 2. Server Receives Login Info 3. Server Checks Login Info Against Database This way the database is never exposed to the client, it can only ask for things that you allow and the server can also validate that the data is formatted properly or that they have permission to access it.
As already stated, since you've already got your database in Azure just wrap with Web API. Then only the Web API can access the database. You could also give your friends specific credentials that allow them to do only what you want them to do, but I'd recommend the Web API direction.
Thanks for the advice my plan for submissions was to post simple things as just a file for code review but anything lager will be posted to GitHub with a full history of commits I fall into category 3 I have a passion and love to code I just get intimidated by people in category 1
We had a Linq library for JS that supported lazy eval back in 2011. https://linqjs.codeplex.com/
Yes, this is a LINQ query. Of course you can use every `selector` implementation styles you like. 
Yes that's what I'm saying. The problem of op is a logical problem. Lambda or LINQ are tools to achieve a solution, not a solution.
If my understanding of WPF was gained from using Blend, I'd probably hate WPF also. I've always just coded WPF by hand and usually don't even have the preview window showing. WPF, to me, is ingenious and I absolutely love the flexibility. To the OP, if you want to get a quick peek at its power, create a default DataTemplate for one of your custom classes and display it in a window. Learning to do that one thing will give you a good idea of how WPF works and should be used.
A 50,000 line code base, in all probability, does significantly more than a 10,000 line code base. More to do means more moving parts and more interactions to keep track of. It also means more developers and more communication overhead. Smaller is better, not shorter. Fewer features means less complexity, not fewer lines of code. Code is simplified when you understand the problem better, not when you cut lines. A new solution may also be fewer lines because with better understanding you can solve the problem doing less, but it may not be. Lines of code is a really leaky abstraction people use to try and determine things they really want to know. I/O is hard to test, but that's precisely why we interface things, so we can separate I/O from business logic and make the business logic testable. Sometimes that's not possible, but it's pretty rare. 
Nice. I will try this out next time write some command line code. 
&gt; This makes me happy, since I consider ValueTuple to be a core package for all of my projects. What are you normally using them for? 
Obviously this is one level of obfuscation, but where do you put the encryption key? It's going to be in plain text somewhere...
So sad my children have to endure this cyber bulling. Oh well it will make them stronger. 
Does it use iterators like this solution?
Connection strings by themselves are not necessarily insecure, because the users could sniff the network packets if they really wanted to find how your application is talking to your database server. What you could do, is create database users, and have the user log in within your application. Pretty basic, but it would then allow you to at least only let in certain users. Of course, what you would probably want to do, is have something that sits between your application and the DB, and simply presents an API. 
Could you explain what's wrong with this? Is it just an issue for production code? Like, if I was making this for myself this might not be a terrible way to go.
[removed]
[removed]
[removed]
Sure, why not.
Even if it would be compiled into the executable, you need to give that executable to the user. So the user has access to it, so he has access to the config.
JS iterators did not exist in 2011.
launchSettings.json is a file for Visual Studio to keep track of how you want to launch the app during development. It's not used by the .Net Core runtime or IIS Express. &gt; Additionally, is launching with IIS/IIS express using Kestrel + IIS and Project/Executable using just Kestrel? Yes.
That's awesome! It'd be cool to build a repository that can be used to generate the shape/items/rules of a game and then connect it to a web app that allows lobbies of strangers to fill up and play. My friend is learning Ajax and working on something similar for a game called Camel Cup. I get that building in the rules would likely take a few days per game (at least) but once you have a few games I think you could build a subscription-based service to allow monthly access. 
You mean something like sign language? I'm having trouble understanding what you mean. Why isn't normal text suitable? Is it meant to be inter-langual? 
You might be able to use the default resizing methods that apply to forms/picture boxes. See if you can't plug and play. 
Yeah I've worked with WCF before. Problem is I do not have a server to put the service on sadly.
Very cool and saved, gonna check this out tomorrow
I love breaking out logic like this. Do you know what this type of simplification is called? Is there a cheat sheet or resource for this somewhere? 
Great idea. This path took me from zero to hero in a few months. Leveraging that experience will keep your momentum up. 
If you cannot deploy a web service, the next closest alternative is to create an account in the database server for each person that needs access. Each database account will have to be configured to restrict access to the desired tables. The user will have to enter these credentials at the time of launching the application. It's not as secure as having a REST service as users can still execute arbitrary queries on the database tables. Use this setup only if your server has no exposure to the internet and your data is regularly backed up.
Databases are built for CRUD (Create, Read, Update, Delete) operations. They are much more efficient for this sort of work, and are much simpler to query. Good database engines can also handle concurrent access from multiple sources. A database engine can be configured to auto-increment the primary key, which would be the ID of the record, and in this case that's the "number". They also accept actual data types rather than just strings. Many more benefits.
&gt; Didn't know I needed this, but now I do. You do what? Need it or know that you do? What for? It's for a feature that isn't even in the language yet.
Thanks.
Which is what I'm getting at.
I just got another XML file that I need to read, which don't use any name spaces for their rows `&lt;Row&gt;`, so I attempted with XDocument. But I just get errors about invalid characters. `&lt;Data ss:Type="String"&gt;413101&amp;#x1F;_LB01_LC&lt;/Data&gt;` I'm starting to hate XML files. At this point, I give up and loop through everything. The code might be ugly, and inefficient. But since it's work related, I can't stop and try to find the prefect solution. Since I know this horrible solution. **Edit:** My solution: https://pastebin.com/V3rqXcJw Rows 25 to 76 
&gt;You've got a private method calling a public one. Generally speaking this is bad form. Not OP, but why is this bad form? 
Tried this in chrome 61 and firefox 57 and in both i got " numbers.where is not a function". What I'm I missing?
I’ve been working on my own little Blockchain because I wanted to learn more about how Bitcoin and the like work. The code is a mess and it’s not really exactly how Bitcoin works, but more of my own interpretation... but I’m learning. https://github.com/voxace/Blockchain/
Did you end up doing anything like this? Only reason I ask after so long is I’ve been working on one myself now.
If you're just writing data out to a file and then reading it again later, it's fine. However, what op wants to do, by giving every entry a unique ID, and being able to delete rows and get them by ID, is just a very complicated way of doing what a database does, but worse. If you want to search a database, a simple query will take milliseconds to execute and return, even on a huge database. However, for a large text file, you'd have to iterate through every single line of the file, looking for whatever it is you're looking for. This is way slower than a database. On top of that, the hooks for a database are so much cleaner, simpler, and easy to implement than a custom system for iterating, searching, and deleting rows from a text file. If this was in production code I would question whether the programmer even finished his first year of CS, but even for personal use you're using an overly complicated, slower, and more error prone solution to a problem that's already been solved. 
It suggests there's a problem else where, a code smell really. You can't test a private method* and if it's relying on the result of a public method then it won't be tested even if the public method changes and its test passes. It's common that that private method should either be public, or not even part of this class at all. I'd put 2 to 1 odds on it being a separation of concerns problem. *You can test private methods, there are frameworks that support it but it means your architecture is iffy. There are ways you decide whether a method should be public or private (ignore protected/internal for now). In the past access modifiers were used as gatekeepers to prevent idiots (other developers, but usually future us) from accessing code that fiddled with the internals. The reality was we were mixing a bunch of concerns together into a single huge class. In actual fact, "good" developers back then still followed practices we consider to be good now, so they weren't affected to the same extent. Those practices include small classes and short methods. With TDD there was a huge swing the other way. Everything must be public except for fields. Private methods became ways of moving repeated sections of code out of public methods or making long public methods more readable. This highlights a problem with how TDD was taught. TDD is supposed to INFORM the design. The design is shaped by TDD. The testability is a nice side effect, but the big gain is that your code is supposed to be easier to refactor. Because TDD informs the design people (idiots egged on by agile consultants) assumed that if they learned TDD (We'll teach you in 4 2 hour sessions!) you would somehow be able to skip all that pesky experiential learning the expensive developers use to write good software. It never works that way. TDD is hard. Just as hard as OOP without TDD, just with slightly different rules. /end rant. So you get a lot of bad code that has tests. If you look at this stupid bit of code public class Example1 { private List&lt;string&gt; _myList = new List&lt;string&gt;(); private object _myListLock = new object(); private void AddItemItemToMyList(string item) { lock (_myListLock) { _myList.Add(item); } } public void AddHouseToList(string house) { AddItemItemToMyList(house); } public void AddBricksToList(params string[] bricks) { foreach (var brick in bricks) AddItemItemToMyList(brick); } } We can test the two public methods, but both rely on a private method that we can't test. And anyway, we have two things going on here, two concerns. We have a higher level abstraction where we add houses and bricks to a repository and then controlled access to a repository. So the longer but more testable version is: public class Example2HighLevelAbstraction { private Example2RepoAccess _repo = new Example2RepoAccess(); public void AddHouseToList(string house) { _repo.AddItemItemToRepository(house); } public void AddBricksToList(params string[] bricks) { foreach (var brick in bricks) _repo.AddItemItemToRepository(brick); } } public class Example2RepoAccess { private readonly List&lt;string&gt; _repository = new List&lt;string&gt;(); private readonly object _repositoryLock = new object(); public void AddItemItemToRepository(string item) { lock (_repositoryLock) { _repository.Add(item); } } } Edit: I should add, this code is not really testable because the lists are never accessible to the outside. I'm just highlighting the refactoring of concerns. What interesting is that I didn't write a test before writing the code and the net result is code that doesn't pass a test :) Next up you might inject the repository via the constructor and make it an IRepository so you can use something mocky. When you follow this style, if you ever end up with a private method that calls a public one on the same class you can almost immediately assume it's a separation of concerns issue and certainly a testability issue. This also goes some way to answer OP's question about why a seemingly simple solution would not be better than a longer version. Example2 above is actually barely any longer, but if I followed through with an interface on repository and some injection it would be double or more. Does that help even slightly? I think the tl;dr is "It's a code smell indicating a problem with separation of concerns". 
Did you copy code from the 5th code segment, starting with: // define generator functions const whereGenerator = function* (isMatch) { for (const item of this) { console.log('filtering!'); if (isMatch(item)) { yield item; } } }; 
Thanks for the very detailed reply! I can very much see the benefit in relation to non-trivial repository access, but can't this result in excessive re-wrapping of all state on classes? *** &gt;In the past access modifiers were used as gatekeepers to prevent idiots (other developers, but usually future us) from accessing code that fiddled with the internals Is this style reaching that same goal by setting strict field access but public method on the instances they hold? E.g. previously I could not call: example1.AddItemItemToMyList(...) and now I cannot call: example2HighLevelAbstraction._repo.AddItemItemToRepository(...) and now I lose the negative of preventing testability (private methods), and I gain the benefits of ... a design that has smaller classes with more specific purpose? *** Doesn't that get complicated when you have more than one "repository"? Or if you have non-trivial interactions between multiple properties? 
Currently working on a logging library of mine and also an event planner with a giant calendar for the raspberrypi with avalonia (not on github yet.) https://github.com/icecream-burglar/waterlogged
missed that thing... working now. ty!
I literally just had this problem when going through a hands-on-lab for EF Core 2 and .NET Core 2. The command will only work in the base directory of the project (Where the csproj file is). I had to add this to mine to get it work.. &gt;&gt; &lt;ItemGroup&gt; &gt;&gt; &lt;DotNetCliToolReference Include="Microsoft.VisualStudio.Web.CodeGeneration.Tools" Version="2.0.0" /&gt; &gt;&gt; &lt;/ItemGroup&gt; 
You should to explain what you're trying to achieve in the first place, because to me it seems like you've created a whole class worth of methods that could've been simple one-liner queries. Despite the good method names your logic is difficult to follow.
Hardcoded in the application (i.e. in memory). Hence my disclaimer.
All programming languages are basically doing the same thing (move data from point A, transform it somehow, then output it somewhere). We seem to be in a race to minimize the effort required to accomplish this task. I have a sort of semantic interface in mind I guess to accomplish this. Because of the visual nature it is independent of language. I mean visual like Vizio more than sign language. But I don't think that UML diagrams are particularly good at conveying information in an intuitive manner. Clearly normal text is suitable but that's not the point. The point is to accomplish the task more efficiently, and intuitively for the sake of quality and to allow more people to have access to professional grade code.
I think that with a lot of tweaking you'd be able to with my library.
Welcome to 40 hours of C# and XML experience. I need to loop through each row in a XML file, and be able to read and change values from the columns, and the best way to do that for me, was to convert it whole thing into a 2D array. I had no idea that it's possible to run queries in a XML file. The end goal is to create a program that can take three xml files from a old database, and with them, create a new file that can be imported into a new database.
As an addendum, the credential check should happen in the database and the encrypted password from the client should be compared to the encrypted password in the db. The password from the DB should never be returned if it can be avoided. If it isn't possible, the encrypted password check should happen within the public-facing service. Basically, don't return the password from the DB all the way to the client and perform the check there -- just return some flag that describes "success" or "invalid username and/or password" or "banned/suspended/locked" etc.
I would write for the browser instead of for the OS. 
Xpath expressions let you specify the child node index.
Codes = s.Element("Codes").Elements("Code").Select(p=&gt; p.Value).ToList() Assuming your SiteViewModel has Codes as a List&lt;string&gt; or whatever...
Thanks :) &gt; Doesn't that get complicated when you have more than one "repository"? Or if you have non-trivial interactions between multiple properties? Yes is the short answer, this is part of debunking the myth that TDD or any mechanical methodology will remove the inherent complexity of coding. Coding is always part science and part art. So it's hard to describe a general purpose, all in one solution to the repository problem, or any reasonably large problem. If you're a fan of GoF or PEAA or DDD you have concepts like [Unit of work](https://martinfowler.com/eaaCatalog/unitOfWork.html) and aggregate roots. The implementation of these things gets really involved. It's common to see people using something like EntityFramework, which already implements a concept of repositories and Unit of Work and then wrap that into a bespoke "testable" interface driven mimic of the same thing. This is not a great approach. There is some magic sauce though. 1) What you have to do is **take each problem and evolve the code in a way that is amenable to change**. At the beginning a one page program with zero tests, with everything in a single file is fine in the sense that you can read it, understand it and replace it in an hour or two. It should still have tests though because: 2) When you write a test first it means you can express the problem simply enough to name a test. If that's not possible, your problem is too big, so magic sauce two is **if you can't express the problem in one line of your native language, you don't understand the problem or you have more than one problem** Understand and if necessary sub divide. 3) **Code is a liability not an asset** This is my mantra. It's an extension of number 1 really. Have you ever heard people say "We can't do that because we would have to change so much code"? Liability. Code is disposable and good design makes it more disposable. This is about coupling and cohesion (I almost wrote adhesion!). 4) The public interface should be intuitive for others (other developers and future us) to use and understand. So in a round about way this gets back to your question about: example2HighLevelAbstraction._repo.AddItemItemToRepository(...) and in a moment connected repository actions. The first problem is that making it public so it is testable means your test is no longer informing your design it is dictating the design. The distinction is frustrating because it begs the question "Then how do I know if my design is right????" The only reason you would want to call _repo.Add... directly on ...abstraction... is for the test. If that's not true then our design is wrong and the code would look different anyway. When you're chaining lots of objects together in a way that isn't describing a fluent interface it suggests a coupling problem. If you need to access Hospital.Hardware.Scanners.MRIs["upstairs"].Office.Telephone.AddressBook["Stacy"] then your code should probably have direct access to the hospital's telephone system. You *can* do it like the above, but if there's a problem with any of the interim steps, or code in any of those objects changes it might affect your code. That's bad. &gt; Doesn't that get complicated when you have more than one "repository"? Or if you have non-trivial interactions between multiple properties? In this case if you have multiple repositories my cack handed example code might be better. You could do this for example. Don't by the way, this is horrible code. Wrong on so many levels :) public class ExampleMultiRepo { private readonly Dictionary&lt;string, Example2RepoAccess&gt; _repos; public ExampleMultiRepo() { _repos = new Dictionary&lt;string, Example2RepoAccess&gt; { {"Red", new Example2RepoAccess()}, {"Amber", new Example2RepoAccess()}, {"Greem", new Example2RepoAccess()} }; } public void AddThing(string thingName, string thing) { _repos[thingName].AddItemItemToRepository(thing); } } If you've got multiple repositories and there are relationships and transactions involved then you're writing something that embodies a lot of the functionality of Entity Framework (as an example). EF follows UoW pattern among others, but what its design tells us is that there are separations between providers (i.e. SQL Server or Oracle) and the abstractions we use to access those providers. Also, if you're writing something of that level of complexity you can't do that in a day. I worked on a project where something like EF was baked in. Everything relied on its types. It was great for them at first because it was a quick solution and won over the users. It became a horrible scalability bottleneck and a lot of time was spent trying to work around it. It could have killed the project in the end. Once a developer goes through that they become averse to becoming locked into anything :) So again the **tl;dr** is make your design support change. This will give you the confidence to make changes which means the specific implementation risks are reduced. 
Ok, I think I understand. Very neat concept. 
don't know why you wouldn't just model your structured data in code. public class SitesModel { public SiteViewModel[] Sites { get; set; } } public class SiteViewModel { public List&lt;string&gt; Codes { get; set; } public string Name { get; set; } } var xmlPath = HostingEnvironment.MapPath("~/App_Data/sites.xml"); var serializer = new XmlSerializer(typeof(SitesModel)); using (var stream = new FileStream(xmlPath, FileMode.Open)) { var allSites = (SitesModel)serializer.Deserialize(stream); }
SelectNodes() is a query. Where do you get the XML files? To me it looks like they're being serialized incorrectly. If that process cannot be changed then you're gonna have to figure out how to sanitize the input, ie Regex replace &amp;#x1F; as it is an escaped html ascii character which isn't valid XML.
You do not need an IOC container. Web API routes follow a convention. Just create your controller, designate a RoutePrefix if desired, decorate your actions with a route (like "{id}"), and a HttpMethod (like "[HttpGet]"). Then you can access the id parameter in the method signature. Sorry on mobile I can't give a great example.
This is a task that LINQ handles quite nicely. XDocument is specifically created to use LINQ. This code does the same as yours. var xdoc = XDocument.Load(filepath); var rows = xdoc.Descendants().Where(e =&gt; e.Name.LocalName == "Row"); var columnNames = rows.First().Descendants().Where(e =&gt; e.Name.LocalName == "Data").Select(e =&gt; e.Value); var data = rows.Skip(1).Select(r =&gt; r.Descendants().Where(e =&gt; e.Name.LocalName == "Data").Select(e =&gt; e.Value).ToArray()); If it seems daunting just read them out loud in English and it will hopefully make more sense. The only confusing one is the last line where I add an extra Select call to turn the rows into an array of arrays.
Thanks a lot, it seems to work similarly to .stream() in Java. I will see if I can implement that tomorrow at work.
The people telling you to encrypt your config are giving you terrible advice. Obviously, for it to be of any use to the application, the application must be able to decrypt it. Therefore the machine it's running on can access it, and the user can access it. You cannot release any application in this state. The best advice you've had is to develop a web service. To do this, use Web API. You will need to have users register with your API, and only the API will know how to connect to the database. The API will run on a remote server, so the users will never know how to connect to the database. You will login to the API and receive a bearer token, which will be saved locally and sent with the Authorization header in any HTTP requests to your web service. This will involve some additional learning on top of what you've done. You say you have nowhere to host a web service, but Amazon will give you 12 months free access to many things, including a basic virtual machine. You can use this machine to host your web service. You can also use a free instance of Amazon RDS to host your database, rather than the rather-shoddy Azure SQL DB which I assume you're currently using. https://aws.amazon.com/free/
Provided the contents remain consistent, I'd second this.
Thanks, this makes sense. So obviously my ApiControllers cannot take any parameters into their constructors right? Because thats where Unity would have been supplying the parameters, but now there will be no such injector. 
I get them via e-mail or USB from my boss. I have no idea where they originally come from.
Yeah as far as I know that's correct. Note that my examples are referencing Web API 2.. they might have changed in .NET Core. You can create a parameterless constructor and instantiate member variable services or repositories to keep things tidy. However, when things start having multiple dependencies, it can get messy without an IOC container. I'm still undecided on if there's a better approach, though I'm sure someone with more experience can chime in. private readonly IProductService _productService; public MyController() { _productService = ProductServiceFactory.GetProductService(); // refactored to factory cause that's probably a better practice }
That's an interesting approach. How would you execute that? I mean, say I write something in, I don't know, JavaScript (my web dev experience is sorely lacking). How do I distribute this to my users? I mean, must I set up some sort of server for this as well? The hope is that this could be used as a program on a computer, not requiring a connection to an outside server. Is it possible to write a browser-based app that's entirely local?
More concerned as to why you don't want to follow basic principles
You might try ASP.Net Core MVC, which has a built-in IOC container.
I'm still learning to get used to C#, I see how this could be much better! Thanks!
This worked perfectly, thank you!
For me: Server, connected, no distribution. Buy a good chart control package. Someone else mentioned Electron, I'm not familiar with it, but I've seen it mentioned as a way to build desktop apps with web tech. 
1. You *should* be using an IOC container, it allows easy unit testing and very little extra weight compared to the benefits 2. You could write your own container, but you won't do it as well 3. You could do "poor mans DI", which is kind of a happy medium - you can still unit test and don't need a container: public class MyController : ApiController { protected ILogic Logic { get; private set; } public MyController(ILogic logic) { Logic = logic; } public MyController() : this(new LogicInstance()) { } } When unit testing you pass your logic mock, when running normally you call the parameterless constructor, which initializes your default implementation 
I'm gonna be that guy: Adding Ninject to your project is not complex, adding the nuget pacakage creates the code you need
Thanks!
Crank only tests persistent connections. You haven't said if you're using persistent connections, but most people use hubs. If you're using Hubs, then use qburst: https://github.com/QBurst/signalr-load-simulator In the Client application (in the qburst project), open Program.cs and change the parameters, and make it point to a method on your hub. This method doesn't need to do anything, but if it doesn't require authorization then the tool will be slightly easier to use. You can check that it's working by setting up a Resource Monitor trace for connections.
I'm pretty sure it is using persistent connections 
&gt; So obviously my ApiControllers cannot take any parameters into their **constructors** right? 
If I understand your comments correctly, you have files that are read that have strings that identify how to process them. You need the identifiers to be known during design time so you can use reflection to find the right record processor. I am confused on the requirement for reflection. Why is it required?
Fairly easy to check in your SignalR server are yoyu using Hubs or [Persistent Connections](https://github.com/SignalR/SignalR/wiki/QuickStart-Persistent-Connections)
Also note that in Visual Studio you can copy your XML to the clipboard and choose Edit-&gt;Past Special-&gt;XML as Classes and it'll create the necessary classes. https://improveandrepeat.com/2017/08/paste-xml-as-class-in-visual-studio-2017/
I can confirm it is
I agree. Controllers should not have arguments other than parsed route parameters. Controllers also should stay simple and call Services to do "real" job. The Services can accept arguments via constructors and Factory is a good pattern for this. EDIT: Also since this is WebApi it may make sense to consider functional style. Think of a request as a data and your code as a flow that transforms the data. The flow consists of a set of extension methods which are static. The request is a parameter for the first extension method which does its part and return transformed request which is a parameter to a second extension method and so on and so forth until you reach IO. I believe with this style there is no need for IoC container and no need to allocate graph of objects for every request.
&gt; _productService = ProductServiceFactory.GetProductService(); // refactored to factory cause that's probably a better practice Ah the "service locator" anti-pattern. (Which I totally use everywhere because it's quick and easy.)
&gt; You should be using an IOC container, it allows easy unit testing and very little extra weight compared to the benefits There are reasons for using an IOC container, but unit testing isn't one of them. The vast majority of your controllers should look like this: //Routing Info public Result Action(parameters) { return _FooService.Action(parameters); Just the bare minimum of boiler plate to satisfy ASP.NET and convert the HTTP request into a normal function call. *** All of your testing, unit or otherwise, can be then be done against a services library without the ASP.NET cruft getting in the way.
I wasn't recommending it, just answering his question, though I can see how my answer is unclear. For clarity, I'd recommend using an IOC container: private readonly IProductService _productService; public MyController(IProductService productService) { _productService = productService; }
Effort. If your code is already properly layered, you don't gain much by using an IOC container at the WebAPI level. If the IOC container is good enough, and your controllers are stateless, you avoid the cost of instantiating a new controller object for each request. And you don't have the ugliness of storing your service objects in a service locator (i.e. glorified global). But really, for small projects its not worth the cognitive overhead.
I actually would recommend it. I know that sounds weird, but bare with me. People who have only worked with IOC Containers often don't understand the problems that they were meant to solve. So they tend to overuse and abuse them. I've been on projects that only needed a simple DI phase during startup. Something that could easily have been hand-written with a flag to choose real or mock services. Instead that project had at least three different DI frameworks and who knows how many separate IOC Containers. Sorting out that mess was a nightmare.
Brilliant, Thanks Cristo, last time I promise! :)
IOC containers are incredibly easy to use, especially in stateless applications, and offer a lot of benefits over service locators. There is almost zero reason to recommend service locators over DI.
Agree, getting out of ASP and into a standard library is by far the easiest in terms of testing.
Why does the implementation matter when the end result is the same thing? E.g author could have used promises and async/await but still that would have been a form of lazy or deferred evaluation 
&gt; what if we don't want to bother with the complexity of a container? You can just ignore it, yes. &gt; Is it even possible to not use a container? Yes &gt; How will my API controllers get called? Basically (very simplistically) the webAPI will do the following new YourController().Action(parameters, from, route, or body) &gt; Will they have to be parameter-less? Yes &gt; What are the other considerations? That's it. Nothing more.
No, the only time I would recommend real service locators is for OS-installed components. For example, how OdbcClient and OleDbClient locate your database drivers. I would just say use static variables in Global.asax until it becomes a problem. The specific problem will help guide you to selecting the right DI pattern or framework for your application. 
You're right, it doesn't matter. The reason I'm interested in iterators specifically is because they're the equivalent of C#'s IEnumerable. I was just curious about it.
Dapper works well with mysql in my experience. Always use that when EF isnt an option. 
Omg, thank you for this. Does this work with json as well? I'm not at home to test myself.
I disagree. Having a model in the argument lets the controller do a lot of work for you, especially if the model is required. 
You suggesting implementing business logic in the controller?
https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation
xUnit database fixture combined with FluentMigrator to build the stored procedures, build the tables / indexes, and then seed it with some test data. All of which gets tested against an in-memory database instance that get shared across multiple tests.
From ops comment I took it as meaning not having DI at all
yep, there are paste special actions for both XML and JSON.
i think you're opening yourself up to more problems in order to potentially bypass having to update your code if certain schema changes occur if you don't do things this way. kind of the old statically vs dynamically typed argument; i'm in the statically typed camp.
Just want to point out that an efficient way to pull nodes from an XDocument is a custom iterator that reads a stream, as opposed to holding the entire document in memory and iterating over that. See: https://lennilobel.wordpress.com/2009/09/02/streaming-into-linq-to-xml-using-c-custom-iterators-and-xmlreader/
What exactly are you trying to do? 
Ah yes. The validation is built in controller's base class. It goes without saying. Some even say you always validate the input. Regardless.
I'm trying to code a traffic light with a data model and FSM in unity. The traffic light is supposed to transition from red to green, green to yellow, yellow to red, repeat. my traffic light in unity consists of a parent named "TrafficLight" and it has 3 children named "Green Light", "Yellow Light", and "Red Light" I'm trying to make it so that as time passes the traffic light will transition from one color to the next over a period of time. I think the issue has to do with the time.DeltaTime but I'm still pretty new to this. I appreciate your response and any help that you can give. Thank you
Does Linq not cover your needs? Use the nuget package Linq2DB it will allow connection to MySQL and has a script to generate classes modeled off of DB schema automatically. 
Any specific reason you need something _remote_? It's all pretty much the same... just additional latency and networking / permissions involved to secure things. I'd spin up a SQL Server 2016 (Or 2017 since it was just released) Developer Edition locally... do all your work on that, make sure it works, then deploy it to a cloud service and test it out. You can get some free hosting from Azure for a few months/a year (https://azure.microsoft.com/en-us/pricing/details/sql-database/) and I know sites like GearHost.com offer free hosting, but it's usually something like a few MB for each database... which might be enough to get by.
Yes, you can use WebAPI without an IOC container. Should you? That's another discussion.
While I'm a big fan of validation attributes, I don't necessarily want that done in the controller. It is easier to unit test the model's validation logic if it is self-contained. That's why I use a model base class that handles validation.
After using Debug.Log it looks like all of the individual times are going at the exact same time. (GetRedTime, GetYellowTime, GetGreenTime). They don't shut off. I think this is why when I run on Unity the traffic light just sits on Green. Any advice or fixes?
If you want a Micro ORM, the ORM "Massive" by Rob Conery and now maintained by Frans Bouma is pretty good and fits your requirements, I think. https://github.com/FransBouma/Massive 
Your code is far too complex for this. This is a very simple task. Using concepts you're already familiar with, here's what I recommend: track timeElapsed, as you are, but start it at zero. In the Update method, add time.deltaTime to timeElapsed, and when timeElapsed &gt;= 5, change the material on the green light. Then reset timeElapsed to zero, and repeat. If you like, you can set currState to the appropriate state as the lights change. I think you should get rid of everything else.
When you want to go live, Amazon RDS is a better alternative to Azure SQL DB, which isn't even proper SQL Server. RDS supports most SQL server functionality. The best option is to get a virtual machine and run it off that. Amazon gives you a lot of stuff free for 12 months.
I'm a big fan of "poor mans DI" and felt dirty using it, so thanks for validating me.
We created and use in production: http://github.com/okhosting/OKHOSTING.ORM
Yeah, test driven and stubbing is pretty much the only reason I write interfaces at all these days.
No I did get your point. I am guessing your not the architect so... All I can say is that is really horrific, I feel really sorry for you having to deal with that layer of boilerplate for such a tiny gain.
There are cases where being able to inject different functionality in production is great too, and of course a huge amount of the framework code you use used a lot of interfaces.
Syntactic sugar?
Yep, I strongly recommend Dapper to everyone using something providing an IDatabase interface. It's fast, and provides just the right level of automation/safe defaults not to get in your way. It also makes it very hard to get into a terrible situation that any automagic shit EF and it's ilk will get you. 
I like Dapper.SimpleCRUD to alleviate some of the annoyances that come with writing the basic select statements. I don't know that it works with MySQL, but it's pretty easy to port to most anything as long as it supports the same or similar functionality. There are others, too, but I like to point this out as it's the top criticism I've heard when I evangelize Dapper :)
Thanks for that :-)
Actually I'm finding that unit testing seems to be the main reason we might be forced to use Unity. Not that we would use Unity in the tests themselves. But the fact that Controllers cant have parameters without Unity means the Controllers arn't easily testable without Unity. So indirectly, we need Unity for testing reasons. In your example, where does _FooService come from? Is it a global singleton, or is it an object injected into the Controller constructor using Unity? Either way I like the idea of getting out of the Controller as fast as possible into "real" code.
I'd like to have that discussion. Lets say we have an extremely simple application. One Controller with 2 route actions. At what point would you say that Unity is overkill and not needed? Or would you just always use it no matter how trivial the application? 
&gt; In your example, where does _FooService come from? Is it a global singleton, or is it an object injected into the Controller constructor using Unity? Whatever you want. My point is that you should design your controllers so that they don't need to be unit tested. (You'll still want to test them through the UI.) *** Note that if you do go the global singleton route, use global.asax as that singleton. That already has life-cycle management hooked up and you can easily build your dependency tree without mucking about with frameworks. The biggest down side is that you lose the ability to see at a glance what dependencies each controller uses. So for larger projects a DI framework is the way to go. (This is probably the only time you'll hear me say that DI frameworks make code easier to follow.)
Really? I was under the assumption that Azure SQL DB was pretty much the same as (Enterprise) SQL Server, but have never used it personally. What do you lose with Azure? I will say for a novice just starting to learn, I would think either would work fine since you're probably just looking at some basic CRUD stuff.
No it's not the same as SQL Server. Here are some of the differences: https://docs.microsoft.com/en-us/azure/sql-database/sql-database-transact-sql-information Whilst RDS runs proper SQL server, it also has some of the same limitations, such as not being able to use FILESTREAM as there is no file system access. Azure SQL DB is also quite expensive for what you get. Not only are the instances much slower than RDS instances, but they can only handle one database. With RDS, you get more functionality and can create up to 50 databases per instance (SQL Server limitation). Azure SQL DB provides redundancy out of the box, which is why it's so expensive. With RDS, you're just running a virtual machine that has been abstracted, and there is no redundancy. You would handle redundancy by creating several RDS instances and adding them to an availability group. This way you get to decide your redundancy. 
Good to know. Thanks.
Poor man's DI is fine. It's really just composition.
Did that fix it for you?
I think it's all dependent on what you personally want to do. I've done simple applications without it and I didn't even bother with unit tests for them ;) Those also typically end up being applications I doubt ever gets touched again down the road or would only be touched by myself. If something more complex that I am also writing unit tests for, then absolutely IOC is the way to go. I would say that for any code that you are planning on adding to down the road or needing to refactor. Or any code where you aren't the only one that will be touching it.
&gt; In general however, if people are going to send you stuff that's not valid XML then they might as well not bother using XML at all, and the right solution to handling invalid XML is always to fix the program that created the stuff. By all means try to repair it, but first try to get the supplier to fix it. Quote from the internets that I wholeheartedly agree with. However, since this was something that I might later come across as a problem I decided to solve it. I hope I didn't make it too convoluted. static void Main(string[] args) { string xlData = File.ReadAllText(xlpath); string pattern = "(?:&amp;#x)(?&lt;hex&gt;\\w{1,})(?:;)"; string sanitizedXml = System.Text.RegularExpressions.Regex.Replace(xlData, pattern, Sanitize); var xdoc = XDocument.Parse(sanitizedXml); } static string Sanitize(System.Text.RegularExpressions.Match match) { return int.Parse(match.Groups["hex"].Value, System.Globalization.NumberStyles.HexNumber).ToString(); }
this is a helpful read
LINQ can definitely be considered a stream of objects. Extensive use of yield return. LINQ expressions act like queries which means that a variable will not hold any data until you actually execute the query by either looping or asking for the value. At the last line I force the LINQ query to execute right away by calling .ToArray() This is a neat way to make quite complex data queries without using much memory as you can chain variable results into new queries without leaving a bigger memory footprint.
I'm currently using NHibernate, but i'm eyeing Dapper
I think I understand what that pattern does, I'm just not sure why &lt;hex&gt; is there.
I didn't realize local functions handled allocations differently than anonymous functions, good to know.
Named group. The others ?: are non-captured groups. Which means only one group will exist in the match - the hex one, so I could've just indexed into the groups with 0. Naming for clarity. But the entire string is found so everything is replaced.
TIL ...
Ok, I just didn't know how you named groups. I always just used index numbers.
*Dapper* for smaller stuff, *ServiceStack.OrmLite* for larger stuff.
&gt; Everything must be public except for fields WHat? What is the point of having the private keyword then? internal? protected? All gone? All methods public? Does not this break encapsulation/abstraction if everyone knows about everyone?
Matrix supports IRC. Not quite dead :)
[removed]
Have a look at [Tresi](http://www.wcfstorm.com/wcf/learn-more-tresi.aspx). There’s a small tutorial on there about running performance tests on Hubs.
I just don't get local functions. As in use case. And they look ugly as hell. Function inside of a function. Crazy!
You are incrementing the time elapsed but the time elapsed isn't being used in the logic to transition the lights. You need to reorganize your code here. You've broken a few programming principles. For example, you've basically hard-coded your traffic light class when you didn't have to. public class TrafficLight { private int _CurrentIndex; public float MaxTime { get; set; } = 5f; public GameObject CurrentLight { get { return Lights[CurrentIndex]; } } private IList&lt;GameObject&gt; Lights { get; set; } private int CurrentIndex { get { return _CurrentIndex; } set { _CurrentIndex = value % Lights.Count(); } } private float Elapsed { get; set; } public TrafficLight(IList&lt;GameObject&gt; lights) { this.Lights = lights; } void Start() { //initialize lights if you don't want to pass them in via constructor } void Update() { Elapsed += Time.deltaTime; if (Elapsed &gt;= MaxTime) { Elapsed -= MaxTime; CurrentIndex += 1;) } } } That should be all you need. You just need to create the list of lights and pass it in the constructor. If you don't want to do that, remove the constructor and create the list of lights in the Start() method and assign it to Lights. Also, make sure Time.deltaTime is in seconds. If it is based on milliseconds, your lights will be transitioning too fast and it may look like a single color. To fix that, adjust the MaxTime to be milliseconds (so, for 5 seconds, you need 5000f). The current light can be accessed from the CurrentLight property.
I wish more people would do these
i could be wrong but i believe for local host it would be something like this: app -&gt; os network driver -&gt; app if you had used your computers ip then it would look something like app -&gt; os network driver -&gt; switch/router -&gt; network driver -&gt; app
That's actually specifically what I'm trying to determine. If it's "localhost" vs. "localcomputername" does the router end up involved?
A router is only involved if your computer has to send a packet to a different network/subnet. Your switch should only be involved if you need to send a packet to a different MAC address. Technically if you send traffic to your local IP address, your NIC should be smart enough not to actually send that traffic out to the switch. If you have a switch with port mirroring, you should be able to confirm this using Wireshark.
&gt; If you have a switch with port mirroring, you should be able to confirm this using Wireshark. Ahh, good call, thanks!
Please Comment me how to my video..
Packages to localhost/loopback never leave the local device and are processed within the OS's networking stack. Packages to the device's own IP address or host name will typically behave the same. But I believe it's at least *theoretically* possible for them to leave the device, e.g. if the operating system's routing table is misconfigured (which would be difficult to do accidentally), or if something is wrong with the DNS lookup.
Good to know. I'm trying to make sure the packets for some process to process communications stay "local". I tried named pipes but those seem impossible to stabilize if you're multithreading for some reason.
Yep. Traffic to 127.0.0.1 is sent over the loopback interface, which is a virtual network card in the OS. Unless there is a misconfiguration, that will never leave the system. Traffic to an IP bound to the same machine may leave the machine and come back depending on OS and driver implementation. Eg under certain configuration in Hyperv, traffic between VMs may be sent out to the physical switch and back, limiting performance between guest VMs to the physical port speed and requiring the port to be up and connected to a switch.
I am not familiar with the installer project in that link, but have you looked at using the [Windows Installer XML Toolset](http://wixtoolset.org)? It is free and open source and it has a VS extension so you can easily create WiX installer projects. However, there is a bit of a steep learning curve. It was developed by Rob Mensching who used to work for Microsoft -- many Microsoct products use WiX installers (I think even VS does). WiX has a built-in XML element to add registry keys.
Hmm. If you can't use the standard error streams and you can't modify the console app, have you checked to see if an event is written to the error logs? If that is a bust, if this entire process is executed interactively (that is, it isn't a background service), you can hack a solution by using Microsoft's UI Automation framework. The idea is that while the child process is executing, you'd continually attempt to detect the error dialog you shared in that link. If it is detected, you now have a means in which the parent process can know when the child process failed. You can grab the text and click a button on that window, all automatically, using UIA. It is definitely hacky, but you asked :-D
English would be a good start.
That screen means that your program invoked undefined behavior (it crashed). It also means that you have a debug build, so you should be able to debug it very easily. The program has a "hard" bug, not something that you can handle in any way except fixing it. I mean, you can try and even get some results, but you really **should not**. There is no exception there (there could be one if you ignore the assertion, not sure).
Every example I saw did t require the need for this, a private method to the class would have sufficed. If your worried about polluting the class scope, your class is simply doing to much to begin with. This was a horrible idea, and C# shouldn’t be trying to replicate JavaScript.
this has been my experience so far, traffic going to the computers ip will leave and come back (tho it looks like that may be different in windows 10)
It is "encapsulation" in functional programming
Please don't use English titles on your video if you don't speak English.
Thanks! And I agree! A staged code example with exercises (kata) can be very effective if it is simple and small, and provides examples of the changes needed. 
Removed: Rule 7. The feature (`var`) is over ten years old now and the video doesn't (as far as I can tell) cover any particularly novel use of the keyword. I would also suggest you tag future submissions with the spoken language used in the video narration. Also please familiarize yourself with the [guidelines for self-promotion on reddit](https://www.reddit.com/wiki/selfpromotion).
Can you not just create an async method to call using async/await when you need to send. This way the threads are handled for you. Then you simply have another thread constantly reading.
In no particular order of importance or relevance: - you don't *need* to create a brand new thread every time, .NET maintains a thread pool of reusable threads that are much cheaper to use (e.g. `Task.Run()`) - you don't need to either constantly loop or sleep in a thread to wait for something, there are efficient synchronization primitives like `AutoResetEvent` and semaphores - I haven't used them in ages, but as far as I know pipes are exposed as a `Stream` and thus can be with the usual asynchronous IO methods without having to manage threading yourself - have a look at `BlockingCollection`
I've been wanting this since .NET 1.0. I'm always creating little private functions that are only used in one place. Having to search all over for them in a class is a pain in the ass.
I'll dig into that. It was specifically while using the Stream "ReadLineAsync" and "WriteLineAsync" that I'm running into the problems. This is the error you get: The stream is currently in use by a previous operation on the stream. According to [this](https://refuctor.halbot.io/beware-of-using-file-stream-writelineasync-methods-2240d14a4c23), the problem is that "Async" isn't as "Async" as one would believe. 
I don't feel you have given enough information to properly help you, but yes you can pass a thread information. This is how you do it when you start the thread. https://msdn.microsoft.com/en-us/library/system.threading.parameterizedthreadstart(v=vs.110).aspx Other than that you just have some shared memory static or global to reference. This is with the assumption you know what you are doing as this can go bad quickly. You may not need to concern your self with the overhead of spinning up a new thread depending on how you implement your processes. The framework may have already done the expensive process of creating the threads for you and you effectively end up reusing them (Thread Pool). 
I'm not building the VC++ executable, and I can't modify it but I can run it in batches from a C# application making use of System.Diagnostics.Process. I don't really care what the error is, just that it failed execution. If it were a Console app that I wrote, in C++ or in C#, I'd catch the exceptions and exit with an exit code. Unfortunately it's not. If it were written in anything other than visual C++, I'd redirect the error, catch that through the process.ErrorDataReceived += CatchTheErrorMethod; and log the failed run and continue with the batch jobs.
&gt; If you can't use the standard error streams and you can't modify the console app, have you checked to see if an event is written to the error logs? Interesting, that is a clever sucky approach! &gt; if this entire process is executed interactively (that is, it isn't a background service) Batch/background only. That's actually a really good idea if VC++ error dialogs have a particular window name or something that I could pick out of the tasklist. That means I think that I'd have to put the Process off thread or in a background worker, since I'm currently using WaitForExit().
It’s a slight improvement on things that involve large, anonymous methods, offers advantages outlined in the article for things like yield and improves locality of reference for people reading your code when you split some common operations out this way. Like a lot of the recent C# features, this isn’t a huge benefit, but it is beneficial.
K, here's what I've got... Two separate executables. Both using my "ProcessConnection" class. When sending a message from process A to process B, here's my "SendMessage" method: public void SendMessage(string message) { try { Console.WriteLine("WriteLine " + message); var writeTask = Writer.WriteLineAsync(message); Console.WriteLine("Wait..."); writeTask.Wait(); Console.WriteLine("Flush " + message); writeTask = Writer.FlushAsync(); Console.WriteLine("Wait..."); writeTask.Wait(); } catch (Exception e) { Console.WriteLine("Error? " + e.Message); Error?.Invoke(Id, new Exception($"Could not send message. [{e.Message}]")); } } In the beginning, when the program is spinning up, everything works fine. I can send messages from A to B without a problem. However, as soon as I throw a timer into the mix, and the timer is attempting to use SendMessage, it gets as far as the "WriteLineAsync" and "locks up". Never gets to the following "Wait." I assumed this was a threading issue, but I'm open to suggestions. The read side is equally as straightforward: private void HandleConnection() { Connected?.Invoke(null, Id, null); Writer.AutoFlush = true; while (Pipe.IsConnected) { Console.WriteLine("ReadLine"); var readTask = Reader.ReadLineAsync(); Console.WriteLine("Wait"); readTask.Wait(); Console.WriteLine("ReadComplete"); var line = readTask.Result; Console.WriteLine("ReadLine: " + line); if (!string.IsNullOrEmpty(line)) MessageArrived?.Invoke(null, Id, line); } Disconnected?.Invoke(null, Id, "Connection closed remotely."); } It gets to the "wait" of the "ReadLineAsync" (which I would expect) but no further, which seems to me to mean that the WriteLineAsync isn't completing. (But only after the "sender" gets into the "Timer" portion. Everything else comes through fine.) Edit: It looks like the timer's client.SendMessage does get to the "wait" the first time, but each subsequent time halts at the .WriteLineAsync call. 
First things first. You have a debug build, hence the assert window. That window tells you that the program is borked, it doesn't work so badly that you don't know what it did. You don't even know whether it "failed execution". No, seriously... the assert window you see means exactly that... the program hit what is in native code world known as "undefined behavior ". You really need to get that fixed... he who gave you this seems incompetent. Why do I say this? Because a debug bulid like that can't possibly work at all on a non-development machine. Also because they gave you a buggy program...
Yeah, like I said before it's part art part science. If you've ever looked at philosophy that has many schools of often contradictory thought. They don't have to produce working software at the end of it, but if they did opposite schools of thought may produce equally functional software. And as I said before (probably with different phrasing), each architectural approach or programming style has dozens of caveats and conflicts and opportunities for creativity. It's experience that allows you to navigate them. There are two old but famous Javascript books (bear with me) called [Javascript the definitive guide](https://www.amazon.co.uk/JavaScript-Definitive-Guide-Guides/dp/0596805527) and [Javascript the good parts](https://www.amazon.co.uk/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742). "The good parts" is outdated really but the point was that you don't have to use a language feature just because the language has it. Encapsulation and abstraction still work. Abstraction is handled through interfaces rather than base classes and functionality is encapsulated within a class and separated by its concern. When you isolate functionality so it does one thing your dependence on lots of access modifiers is reduced. Private fields are fine unless you've gone functional. Don't test me on that because the functional people will come along and start arguing like the philosophers I alluded to earlier. Functional code talks about things the [purity](https://en.wikipedia.org/wiki/Pure_function) of a function. If a function's result must be the same for the same set of inputs then it can't rely on a bunch of private state. If you look at the wiki page on pure functions I linked above you can see it's disputed. Still. C# is arguably a hybrid functional language in that you can make it do things like a functional language would do. The actual amount of stuff you really need to keep as state is often less than you think (I'm not singling you out btw). Dependency injection frameworks remove much of the need to constantly new stuff up and store it for later. Functional approaches like currying functions move state from within a class to within a method which still preserves its purity. Edit: reactive programming and frameworks like RX further move from state to stream. So this new (or old, functional languages originated in the 70's? based on maths from the [30's](https://en.wikipedia.org/wiki/Lambda_calculus)) approach is being incorporated into new approaches. This is also why I keep interchanging the words architecture and paradigm among others. Patterns become as important as language features and render some language features situational if not obsolete. You asked specifically &gt; Does not this break encapsulation/abstraction if everyone knows about everyone? The question becomes, does it matter if everyone knows about everyone? The answer is both yes and no depending on which architectural paradigm you choose and how adeptly you apply it, because they all have flaws and weaknesses.
 Maybe closer to Record types? I I think units of measure are slightly different, as I read somewhere that they would be impossible to simulate in C# using a library, but I never read exactly why...
Yep. Traffic for localhost never leaves the machine. It's an optimization that was put in back in the Windows NT timeframe. 
How is the parent process executed? User double-clicks, task scheduler, or what?
You could make that argument on anything. Why have access modifiers? Make everything public and just don't use the methods that are supposed to be "private". After all, it works for Python.
Do a trace route and you'll see Windows always checks your host file first. 
`ErrorDataReceived` is a good way to catch error text from well-behaving programs (they write their errors to "standard error" stream, in C# visible as Console.Error. But to use that, that C++ program first needs to be well-behaved... and it isn't... BTW... it does not matter much that your "server" program is written in C++. The same effect can be achieved with many other programming languages, when he who writes them, does that badly... 
Often, a private method can (should?) be moved to a separate class and made public in order to make testing it easier. I fully expect that not everyone agrees, however.
FYI you need to watch out for proxies or virus scanners you have installed, too. There's one called BlueCoat that I know sometimes intercepts even localhost traffic to forward to its inspection software. If that software is sitting on another server in your LAN it tries to transparently proxy the connection back to your PC's network IP - which will fail if you're only bound to localhost. It's a real pain.
I'm not familiar with that. A steep learning curve isn't ideal right now, this project is just a little side project and I can't afford for it to distract me from unrelated stuff that's going on right now too. But I'll keep that site bookmarked so I can come back to it if I don't find a better solution - thanks.
It would probably depend on the full justification. Easier testing is probably not, by itself, a great justification for increasing the public surface of your API or service, but separation of concerns and loose coupling might be.
Well if you can afford to, security wise, you could run the child process as a debugger, and then you will get callbacks to debug events. https://msdn.microsoft.com/en-us/library/ms809754.aspx I don't know how well this API works with p/invoke. Also, you will need very high security privileges, so preferably don't grant yor entire process those. Maybe create a mediator process, called "saferunner" that has the required privileges and the only thing it does is run (and safely close on exception) the problematic console app.
If they are encrypted on the user's computer and that computer can decrypt them, then he is still no better off. You must use specific credentials for each user. So that only one user ever knows the credentials. So if you are able to create users on the database and each use types in the credentials, then that is OK. So it would then be up to the user to keep the computer secure. Also note that the decrypting the config file requires the application to run as an admin.
Use a smart select control that supports auto complete of some sort and have it query the API for matches instead of preloading it 
Yes.
If you are really hell bent on doing this, try the [`WebClient.DownloadString` method](https://msdn.microsoft.com/en-us/library/system.net.webclient.downloadstring%28v=vs.110%29.aspx) then parsing the resulting HTML. You could try to use regex to parse it, but do so [at your own peril](https://stackoverflow.com/a/1732454/1269654). Otherwise you could try an XML parser (various built-in methods of parsing XML) and hope that the website produces valid parsable XML. Otherwise you could do some dead simple `String.IndexOf` and `String.Substring` call that could work specifically for the NY Times front page. EDIT: But yeah, I would highly suggest you look into some of the existing libraries. At least something fairly standard like HTMLAgilityPack.
Lots of ways. SQL, Excel (auto-fill columns is a really useful feature for generating sequences of data). Or you could write a small program (in C# or SQL) to generate a bunch of insert statements.
&gt; misconfiguration Sometimes loopbacks are used for tunneling. ;)
The short answer is "no." When a network name is used, the first thing to happen is a system call to resolve the name. The OS knows that "localhost" is 127.0.0.1, and "localcomputername" is the same. This means the OS does not take further steps to resolve, which include checking the DNS cache, system hosts file, or making a DNS query. Your application will then communicate with 127.0.0.1, which other's have explained is a virtual network interface. Generally, loopback traffic stays in the loopback interface, system calls, and your application. There are ways to thwart this, however.
This is an excellent repository.
You're going to have to learn WiX if you plan to deploy programs written with .NET. Almost every shop I've worked at has used WiX to build their installers. I suppose that [Inno Setup](http://www.jrsoftware.org/isinfo.php) would probably do the job, but I have no experience using it. Good luck finding something better!
Removed: Rule 1, potentially Rule 2. There's some info on editing the IL of assemblies here: https://stackoverflow.com/questions/13796802/edit-net-assembly-and-recompile If you can do that, perhaps you can remove the `if` check, or simply change the mac address string literals to the new ones you want to use. Similarly, there's info there to extract the assembly into a new csproj. Doing so you can setup a new solution and perhaps setup the [project references](https://msdn.microsoft.com/ru-ru/library/ez524kew%28v=vs.80%29.aspx) that way. Ultimately, if the software is really simple, perhaps consider rewriting it from scratch, or using the decompiled source code in a new project. It's probably not maintainable long term otherwise. EDIT: Another option is to spoof the mac address on the computer you're installing to; changing it to the one hard-coded in the program: https://www.online-tech-tips.com/computer-tips/how-to-change-mac-address/ Maybe after it's installed you can switch the mac address back. Not sure if that would be viable for you. Ultimately though, this is a pretty odd situation, especially with no source code to rebuild it. What is up with it anyway? Some rudimentary, short-sighted anti-piracy check? Job security?
This is what is use all the time: https://www.generatedata.com
Preload the 3k as json with just the first and last name with the id of the record. Then use a library to do the auto complete. Assuming 3k records takes less than 1 second to return. Example auto complete library that I google searched: http://easyautocomplete.com/guide
That makes sense, I can do that. Thanks
If your static class is actually stateless, and the methods expect interfaces for parameters, is it still necessary to make these classes non-static? Is the primary goal of removing statics to reduce dependency requirements?
Removing statics clashes hard with my love for a more functional programming style. (Which is inherently extremely testable.) Moving state from static properties/fields to an object instance is something I would be in favor of, if that's the intent. Too much static state makes it really hard to keep track of what affects what and makes it difficult to isolate the program logic to effectively test it.
I hate the expression "loose coupling". Either it is coupled or it isn't.
This is kind of a dumb way to go about it, but I think the results would be interesting: Create (or find) a network speed test application and see how fast you can send data to a localhost endpoint. You should (I hope/think) find that you can send data to localhost much faster than your network infrastructure (nic + switch + router + cables etc) actually support. 
This is mostly correct. Being pedantic (apologies in advance), the request will hit the networking *layer* and will be routed back out without the need for any network devices/drivers to be present on the system. I.e., localhost works on machines without any NIC present.
Use auto complete select javascript component to fetch a filtered data. Make sure you add a delay, timeout function that waits till the user finishes typing, don't have the exact figure but it should be at least 8 seconds from the last key up event.Then fetch the data. You could also add a Minimum number of characters before searching if needed. In addition to that, in asp store the unfiltered list in memory to increase performance and reduce IO hits. 
Only once you go non static you ensure complete test isolation. Let's say you want to test the class Program, and it is static. In its static constructor it increments a private static variable called foo with 1. Now, how do you reset your test state in the next test that runs? Because when it needs to do the same again, foo will then be 2. Of course you can just decide to not have static state like that or have code that resets that state (although code just for testing purposes is silly in my opinion). But why are you interested in the static class? Can you try to elaborate? By the way, a static class is not stateless. It is just application scoped state, making it hard to reset between test runs. To answer your question though, no. Not if your method accepts interfaces as parameters. However, for dependencies you should instead inject them into the constructor of the class. This also allows you to use an IOC container or the concepts of auto faking. Edit: sorry, static constructors are of course only run once when the class is used the first time. I meant let's say we have some method that mutates the state, and that method is called in each test. Then the state is not reset between tests. 
Thanks! Let me know if you have any ideas of improving it. 
When I need communicate with a running thread, I'll sometimes pass data to/from it using Queues (with appropriate locking, or course).
Correct me if I'm mistaken, but static constructors are only called upon application start. Why would it run again (and increment foo)? I am envisaging a static like like the following contrived example. I wouldn't write such a [database] class in practice. public static class DatabaseUtils { public static DbConnection GetConnection(string connectionString) { /* ... */ return dbConnection; } public static DataTable ExecuteQuery(DbConnection connection) { /* ... */ return result; } }
I never see people recommend [Insight](https://github.com/jonwagner/Insight.Database), but it is by far the best micro orm I've ever used. I've never had issues with it and its incredibly simple to use.
&gt; Correct me if I'm mistaken, but static constructors are only called upon application start. It happens on the first call/reference to the static type in question. If the execution branch you take never loads the type then you will not trigger its static constructor. Be careful with this if your initial startup/data load is deterministic for some reason. 
Have you tried using F# yet? You might be happier with it. 
Got it, thanks.
Sorry, of course... I'm a bit tired. I made an edit to my post elaborating more. As for this case, think about what you actually save by making it static. You have: DatabaseUtils.GetConnection(...) Instead of: new DatabaseUtils().GetConnection(...) So you only save very few characters. I agree the static one looks prettier, and I would still use statics where the method is very very simple and doesn't have any class dependencies. For instance, a MathHelper.AddTwoNumbers(a, b) Because then it's still easy to test from the outside and doesn't require faking, and its name clearly tells what it does. 
Check out the comments on [this SO thread](https://stackoverflow.com/questions/28623141/when-using-filestream-writeasync-what-happens-when-the-method-is-called-again). Checking the [TextWriter classes remarks in the docs](https://msdn.microsoft.com/en-us/library/system.io.streamwriter(v=vs.110\).aspx#Remarks), it looks like they suggest a [synchronized wrapper](https://msdn.microsoft.com/en-us/library/system.io.textwriter.synchronized(v=vs.110\).aspx).
&gt; you have files that are read that have strings that identify how to process them. You need the identifiers to be known during design time so you can use reflection to find the right record processor. Not exactly. There is a single processor for all records. Here's a high level overview: - At init, reflection is used to link signatures to `Record` types, and those types fill a `Dictionary&lt;Type, RecordTypeInfo&gt;` used to cache reflection info. - Signatures are identified from the stream. Their corresponding types are reflected upon if they haven't been already. - Cached reflection info includes the type's constructor and an assignment-ordered list of `RecordPropertyInfo` objects. - The constructor is invoked and passed streamed binary record data; the base class uses the `RecordPropertyInfo` list to divide, convert, and assign data. &amp;nbsp; At most, this is a total of a page-and-a-half of code. This allows a `Record` class to be relatively thin: [Signature("SPSM")] [PropertyOrder(nameof(Foo), nameof(Bar))] public class SuperSimpleRecord : Record { public Int32 Foo { get; set; } public string Bar { get; set; } public SomeSimpleRecord(byte[] data) : base(data) { } } 
The windows API provides easy ways to get windows by title or class. The issue is modal message boxes like this have generic titles and usually use some class like #12345 (on phone can't recall exactly) which is generic and lots of windows could potentially match. You would then need to use send message or gettext API calls to read the application name from inside the window to go that route safely. 
It's nice, quite short with good supporting text and good use of git to illustrate the steps. Could you do me a favour and change the signature on the logger.Log method so it takes a summary string AND the exception? Good logging frameworks can be configured to extract information from the exception and format it correctly. If your signature only has a string parameter people tend to pass either ex.ToString it or just pass in the ex.Message so you lose stack :( It sounds minor but I bet this is going to be going around teams in no time and people will copy and paste, perpetuating the problem :) For a later refactoring you've got magic strings in there which should be configuratable, the path to the log file for example. I also don't see why you recreate the ICustomFileWriter every time you call the logger.log method. That seems wasteful. Again I imagine that's not the bit of the code you're demonstrating, but I looked at it and saw problems. Make sense? Helpful? 
Care to elaborate? The only times I've seen loopback being used for tunnelling is for a daemon (like SSH) to listen on, which it in turn passes on to a remote system. 
Not pedantic, that’s actually a very important distinction for this question for cases where there are multiple or zero adapters.
Got it, I think that's sound advice. My reluctance to rule out static entirely is based more on avoiding object allocation and adding to the GC's workload.
Yes, it's pretty simple on the surface. Example: your VPN is bound to 127.0.0.1, and your routes are set up to deliver certain traffic to 127.0.0.1 and from 127.0.0.1 to your real interface. Your applications are then tunneling through the VPN and loopback. It's been a long time since I've done anything with this, and I don't remember the "why."
Also look into the [TPL DataFlow library](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/dataflow-task-parallel-library). Similar to the BlockingCollection which is useful for the producer/consumer pattern, but more "pipeline" oriented.
Yeah, so that's daemons listening on the loopback interface. My point is still correct. 
Is the base class assigning data to its subclass when it processes the byte[] data? Using your example as an example, does the `Record` base class assign values to the `SuperSimpleRecord.Foo` and `SuperSimpleRecord.Bar` properties? I am assuming `GetType` is being used to get the key for the dictionary so you can then get the `RecordPropertyInfo`. The `RecordPropertyInfo` instance is then reflected upon so the base class knows how to assign the properties?
I used to do this as well, especially for the first many years. But then you realize that you can have a for loop creating 100.000 objects in less than 100 milliseconds, and that it allocates practically nothing in terms of memory (maybe a megabyte). Premature optimization is a bias every programmer has - we all want optimization. But in reality, readability is often more important unless you *actually have* a performance problem. Remember, 90% of our time developing is spent reading code, not writing it. And the business doesn't care if a function takes 10 milliseconds instead of 20 milliseconds to run, if performance is not a priority in that area. But of course if you're making a game or something else where nano-optimization is relevant, it may make sense.
Thanks for the feedback! Very kind of you! As for that signature, it needs to be simple to be easy to understand. This is not meant to be production code. Copy-paste programmers need to take the consequence of their actions if they really copy-paste something they don't understand. If this ends up in NSA's source code it's definitely not my problem. The reason I create a new ICustomFileWriter every time, is because I have decided to have the log level as part of the name of the file being used. The log level is given in the Log method as parameter, and the CustomFileWriter takes a path already at its constructor. This is far from ideal, but it resembles code you can easily find in production systems elsewhere. Remember that this is a kata - it is designed to demonstrate concepts. That being said, try making a pull request - maybe I'll change my mind when I see it in front of my eyes!
All packets, on every operating system that supports IP, go through the routing socket. The routing socket is the part of the network stack that is responsible for determining where the packet ends up. Every packet that is sent by an app or received by an interface is written to the routing socket. The routing socket looks at the routing table to determine where the packet goes, and that's true for every packet it ever processes. If you look at the routing table in any OS with even just a single network interface, you'll see that it's never empty. Why? Because the routing socket needs a route in order to match packets, otherwise they match nothing and get black holed. When does the routing socket determine that a packet should be delivered up the stack back to applications? When the packet matches a route, where that route specifies it should be written to an interface that has the same IP as the same destination address as the packet; or, if the route specifies the packet should be written to the loopback interface (depends on the OS). For example, here is the route table from a computer running Windows, which has a single real interface with the IP address 129.21.49.41: IPv4 Route Table =========================================================================== Active Routes: Network Destination Netmask Gateway Interface Metric 0.0.0.0 0.0.0.0 129.21.49.1 129.21.49.41 20 127.0.0.0 255.0.0.0 On-link 127.0.0.1 306 127.0.0.1 255.255.255.255 On-link 127.0.0.1 306 127.255.255.255 255.255.255.255 On-link 127.0.0.1 306 129.21.49.0 255.255.255.0 On-link 129.21.49.41 276 129.21.49.41 255.255.255.255 On-link 129.21.49.41 276 129.21.49.255 255.255.255.255 On-link 129.21.49.41 276 The `0.0.0.0 netmask 0.0.0.0` route is called the default route - it matches literally every destination. If no other route is a better match ("longest prefix match" being the term here), then the default route is hit, and the packet follows the route information from there. And in this case, the route says "write the packet out the interface with address '129.21.49.41', and put it in an ethernet frame that has the destination MAC address set to the MAC of the computer that is currently responding to the address '129.21.49.1'. What if I were to send a packet that is: from `any` address; to the address `129.21.49.41`? Well, three routes match that destination: 0.0.0.0 0.0.0.0 129.21.49.1 129.21.49.41 20 129.21.49.0 255.255.255.0 On-link 129.21.49.41 276 129.21.49.41 255.255.255.255 On-link 129.21.49.41 276 * The first route has a prefix match length of 0. * The second route has a prefix match length of 24. * The third route has a prefix match length of 32. The third route wins, because it has the longest prefix match. What does the route say? It says to write it out the interface "129.21.49.41".. but oh wait, that's the destination of the IP packet, so instead that packet will be sent up to be received by an application. Why is it complicated like this? * A computer can have more than one interface. * An interface can have more than one IP address. * A computer can generate and consume packets (act as a "host" in the terminology). * A computer can route packets between interfaces (act as a "router" in the terminology). Windows, Linux, FreeBSD, etc, can do all of these simultaneously. Packets can be routed between interfaces, packets can be sent by applications to be sent over an interface, an interface could receive packets that should go to an application, an application can send packets that it wants to be written directly to another application, etc. Edit: I'd like to mention that the routing socket behavior is actually a bit more complicated than I've already stated; there are some white lies in the above. Most route implementations support route flags, information that tells the routing socket more about what the route means; it depends on the particular implementation, but these flags are actually what dictates how the routes work. For instance, [in windows][1], a flag is used to specify whether the destination of the route is local, remote, or self: * `RTM_ROUTE_FLAGS_LOCAL 0x0010` Indicates a destination is on a directly reachable network. * `RTM_ROUTE_FLAGS_REMOTE 0x0020` Indicates that the destination is not on a directly reachable network. * `RTM_ROUTE_FLAGS_MYSELF 0x0040` Indicates the destination is one of the router's addresses. If the route has the LOCAL flag set, then it will: * Look up the destination IP in the packet. * Determine from the route which interface of ours we're going to send the packet from. * Perform an ARP lookup on that interface to find out what is the ethernet MAC address of the computer with that destination IP, performing neighbor discovery ("ARP WHO HAS") if it has to. * Put together an ethernet frame that has the source MAC address set to our interface's mac address. * ..and the destination MAC address set to the MAC address of the peer who is responding for the destination IP, which we found out during ARP. * Write that ethernet frame out the interface. If the route has the REMOTE flag set, then it will: * Look up the next hop/"gateway" field in the route to determine what IP address the packet should be routed to. * Perform all of the above, except using the next hop field in place of the packet's destination IP address. If the route has the MYSELF flag set, then it will forward that route up to applications. This is why there are these two routes: 129.21.49.0 255.255.255.0 On-link 129.21.49.41 276 129.21.49.41 255.255.255.255 On-link 129.21.49.41 276 They both match the `129.21.49.41` destination, and *both send it to the same place*. Technically, i only need the first route, right? Why does it have two when only one is needed? Well, no, we need both routes. The first route has the "LOCAL" flag set, meaning we're going to try to deliver it directly to some host on our network. The second route has the "MYSELF" flag set, meaning packets that match that route are going to get sent up to applications to be received by some socket. [1]: https://msdn.microsoft.com/en-us/library/windows/desktop/aa446766(v=vs.85).aspx
https://blogs.technet.microsoft.com/wincat/2012/12/05/fast-tcp-loopback-performance-and-low-latency-with-windows-server-2012-tcp-loopback-fast-path/ This covers it pretty well. There are socket options in win8+ that allow loopback to go just to the TCP level of the stack. Either way, loopback is a separate interface and will not go as far as the NIC (or even as far as the driver).
I was able to make that work, Thank you very much!
Oh, and as for the "wasteful" part - objects practically don't waste anything. Unless you're concerned about 10 bytes here and there. Remember it requires almost a 100.000 of these objects to just consume 1 megabyte - and it's collected by the garbage collector anyway. Be careful with premature optimization. I'll quote myself from another comment: "Premature optimization is a bias every programmer has - we all want optimization. But in reality, readability is often more important unless you actually have a performance problem. Remember, 90% of our time developing is spent reading code, not writing it. And the business doesn't care if a function takes 10 milliseconds instead of 20 milliseconds to run, if performance is not a priority in that area. But of course if you're making a game or something else where nano-optimization is relevant, it may make sense."
&gt; Is the base class assigning data to its subclass when it processes the byte[] data? Using your example as an example, does the Record base class assign values to the SuperSimpleRecord.Foo and SuperSimpleRecord.Bar properties? I am assuming GetType is being used to get the key for the dictionary so you can then get the RecordPropertyInfo. Right on all counts. &gt; The RecordPropertyInfo instance is then reflected upon so the base class knows how to assign the properties? `RecordPropertyInfo`, like `RecordTypeInfo`, contains cached reflection information, only for properties &amp; fields. When streaming in, this is essentially `MemberInfo`. At that point, reflection has provided the base class: the order binary data chunks are expected in, the members they correspond to, the size of each chunk, and the type to convert them to. That's the meat of how things work. There's more going on, such as additional attributes for validation purposes, async substreams, record headers, etc.
I've seen some badly configured enterprise proxies which do not appy a DIRECT route to 127.0.0.0/8, which usually means the http[s] requests to these end up connecting to the proxy, trying to connect to a closed port on the proxy, and failing miserably. So depending on which protocol you use and whether it uses the system proxy configuration, you might be surprised.
Wix is an absolute pain in the backside. It has horrific documentation. I wouldn't recommend it to anyone. Microsoft's installers are far simpler to get working.
I don't know much about registry keys, aside from Microsoft not wanting people to use them anymore. The registry is a bit of an old concept. Can't you use a file in your application directory instead?
Thanks, this is one I haven't heard of already. I'll try this one out tomorrow. Hopefully their motto is true: "Insight.Database is the .NET micro-ORM that nobody knows about because it's so easy, automatic, and fast, (and well-documented) that nobody asks questions about it on StackOverflow."
Definitely check out the auto interfaces feature! It's pretty much all I use for calls to the db. https://github.com/jonwagner/Insight.Database/wiki/Auto-Interface-Implementation
Of course. For me, it usually comes down to "is it any harder to write or test? No? Then do the more performant thing." Personally I think `DbUtils.Execute()` is more readable than `new DbUtils().Execute()`; the first time I saw this, in fact, I was confused and had to consider what was actually going on. As we discussed earlier, it's reasonable to write testable static methods when state is not a concern, so I don't see a reason not to do this in this case.
Sure, I wasn't refuting anything, just making a comment that sometimes it's intentional.
&gt; Step 1. Get rid of static sickness (convert statics to non-statics) &gt; &gt; This allows objects to actually have some form of "state" that is scoped to themselves and their own lifetime rather than being application-scoped. Essentially a static class is just "some functions and some global state operating somewhere" in your program. Statics also rarely actually save a lot of lines of code, and they can't be faked out. Not this shit again. Ok everybody, get ready to start writing `dim c = (new Math()).Log(a,b);`
&gt; Step 2. Apply manual dependency injection to non-static class dependencies where only one instance of a dependency per class is required 10 + new Program( 11 + new Logger( 12 + new MailSender()), 13 + new MailSender()) 14 + .Run(); Two copies of MailSender? Why? Do you just like wasting memory? And where's the actual configuration details for MailSender? They don't exist. Because that would require actually writing testable code instead of pseudo-SOLID garbage. + mailSender.SendMail("mathias.lorenzen@mailinator.com", logText); Oh look, hard-coded values. So is this a kata on how to make things less testable? 
&gt; Step 3. Apply manual dependency injection via factories for scenarios where creation of objects at runtime is required Let's see what that looks like: 10 new Program( 11 new Logger( 12 + new MailSender(), 13 + new CustomFileWriterFactory( 14 + new MailSender())), 13 15 new MailSender()) 14 16 .Run(); 15 17 } Oh for fucks sake. Now we've got 3 copies of MailSender floating around? And what about this factory? 93 + public class CustomFileWriterFactory 94 + { 95 + private readonly MailSender mailSender; 96 + 97 + public CustomFileWriterFactory( 98 + MailSender mailSender) 99 + { 100 + this.mailSender = mailSender; 101 + } 102 + 103 + public CustomFileWriter Create(string filePath) 104 + { 105 + return new CustomFileWriter( 106 + mailSender, 107 + filePath); 108 + } 109 + } 110 + No. Just no. 1. You don't need a whole class to do that. You could achieve the same thing with one line of code: Func&lt;string, CustomFileWriter&gt; createCfw = (filePath) =&gt; new CustomFileWriter(mailSender, filePath); 2. Making it harder to see the constructor call doesn't make it "more testable". It just makes you annoying. 3. The purpose of factory methods are to deal with scenarios such as: * object pooling * multiple possible constructed types * abstract factories (see System.Data for an example) They aren't meant to be used when you are calling a simple constructor. 
&gt; Step 4. Extract interfaces from classes and rely on what objects "do" - not what they "are" Yea, I would say that's good advice. Lets see how well you actually followed it: public class Program : IProgram public class Logger : ILogger public class MailSender : IMailSender public class CustomFileWriterFactory : ICustomFileWriterFactory public class CustomFileWriter : ICustomFileWriter Final score: 0 out of 5. Here's a hint for you. When there is a one-to-one mapping between your interfaces and your classes, you are probably doing something wrong.
That's not "premature optimization". That's just writing good code. And it's not a "nano-optimization". Excessive memory allocation is one of the most common causes of performance problems and is the hardest to fix after the fact.
Continuing my crusade against bad code: public void AppendLine(string line) { if (!File.Exists(FilePath)) { mailSender.SendMail("mathias.lorenzen@mailinator.com", "The file " + FilePath + " was created since it didn't exist."); File.WriteAllText(FilePath, ""); } File.SetAttributes(FilePath, FileAttributes.Normal); File.AppendAllLines(FilePath, new[] { line }); File.SetAttributes(FilePath, FileAttributes.ReadOnly); } Can you say "race condition"? 
Ok out of curiosity I've tried this myself. Locally, I get 9.96 Gbits/sec. Compare that to actually testing my LAN by transferring through the infrastructure, I get 0.93 GBits/sec, which is expected since I have gigabit networking equipment. 
&gt; Inheritance (especially used entirely for code-reuse and not polymorphism) can easily break a large part of the SOLID principles, and make your code hard to test. WTF? The Open/Closed principle is founded on inheritance. When it says "software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification" the word "extension" was referring to inheritance. I realize the definition of this has changed over the years, but it has never been anti-inheritance. 
&gt; A classic example is having some UserService which inherits from a BaseService to re-use methods that are defined on that base service. The reason this is bad for testability is that if you have 100 services and need to test them all, then all of the functionality defined in BaseService would have to be faked out and configured for all these 100 tests. No! The whole point of unit testing `BaseService` is so that you can confidently use its functionality in other classes, including its subclasses. Do you have even the faintest idea of what testing is for?
&gt; Example of inheritance converted to composition public class Foo { Bar bar; public void MainMethod() { bar.BaseMethod(); } } public class Bar { public void BaseMethod() { } } Can you say "Null Reference Exception"? And that aside, how is this any more testable? You are doing the exact same amount of work (or you would be once you fix your code). The unit test for `BaseMethod` is going to be exactly the same despite moving it to another class.
Unless there is a misconfiguration, **that will never leave the system**. It doesn't leave the system, until it's well past the loopback.
Agreed. I hate dealing with the registry. I do it all the time out of necessity, but it just feels like a lazy method of storing key/value pairs. Modern apps should use the app.config, or use an XML file in the AppData/ProgramData folders for example.
While I haven't had a chance to use any of these myself, these could help you out: [Bogus](https://github.com/bchavez/Bogus) [Faker-CS](https://github.com/slashdotdash/faker-cs)
I've given up using 'dotnet ef' anything on my current core 2.0 app, most of the commands apparently don't exist etc. The time I've wasted triple checking everything is up to date and configured correctly exceeds manually updating the database/models.
Now you're just being pedantic. There's no reason to be on the defense; I agree with you.