No idea: don't use the app, and don't have an Android device to download and test it.
Ic - no worries- thanks.
Ef core won’t make changes until you run a migration, then it will scaffold the changes in the db and then put the entry in the migrations table
There's a saying to the effect of "if you're the smartest person in a room you're in the wrong room". As others have said a huge piece of a successful career in software development ia acknowledging how little we actually know, and capitalizing on opportunities to learn more. Don't let it get you down, I'm sure there are things you could teach me just as there are things I could teach you. Keep at it, you've got this!
Someone who still does the majority of stuff in [ASP.NET](https://ASP.NET) Web Forms, using plain good ol' HTML, CSS and Javascript complemented by jQuery (UI) here. Dreaded amongst many developers I stumble upon because apparently, it's not the go-to way to do things anymore. I'm 33 and have been professionally programming for 15 years now, even longer as a hobby before that, and you know what? I stopped caring about 'comparing' to other developers at some point. I recently started working at a new place with dozens of developers, some being 'architects', some being the type of developer that always wants to use the newest of the newest frameworks, technologies, languages, design patterns, and so on. Funny thing is, all the 'outdated' shit I've made in those boring (yet proven) techniques works, it's lightning fast, doesn't require a crapload of dependencies to even run, it's maintainable, and it's not overly dependant on some framework or component set that might just get a complete overhaul tomorrow. I do think it's important to keep up and know what the 'cool kids' are into nowadays. But I don't know, every time I use some hot &amp; happening framework, language or whatever I either get annoyed by its limitations, the overhead, how slow and bulky it is and/or how hard and cumbersome it is to find/do anything. I've done my first Angular project in the past couple of months and I hated it. I hate how I'm supposed to be using .NET Core for anything rather than .NET Framework because it's multi platform even though I've always been developing stuff on a Windows machine, to be hosted on a Windows/IIS server. I dread having to bloat my web application with a bazillion frameworks and components because apparently it's 'easier' and widespread, even though at every place I've worked in the past couple of years they use something different. In the end, I get shit done and my code is robust. I've had many new developers able to work and become productive with my terribly outdated code in a matter of weeks. I can't care less what the next awesome developer prodigy tells me. I rather look at the \*business case\* and \*requirements\*, than desperately having to use the latest of the latest just because I can.
Thank you very much
&gt;Why do you continue writing? some gnats just don't have a life and keep buzzing no matter how much you "shoo" them away
&gt;some gnats just don't have a life and keep buzzing no matter how much you "shoo" them away Why do you continue writing?
You are a lot further along than I was at your age. As for math/3d, you learn that by studying it for years.
and buzzing
This will only work depending on how their object pooling code works. But a good solution to the problem if it’ll work with their solution.
I'm working in Smart Metering Company. Recently I Integrated our system with Oracle MDM (Metering Data Management System), so I had no other choice instead of writing soap services because Oracle MDM can only consume Soap Web Services using WSDL. Last year we moved our System from .Net Framework to .Net Core &amp; minimised 7 servers from 10 for handling the same number of Smart Meters Requests. That's one of the reason I wrote Soap services for MDM Integration using .Net Core as well.
When you first install it, it will ask you if you want to apply VS key bindings. Couldn't be easier.
Which update?
Rdier 2019.1
First off, `FormWindowState.Maximized` refers to when the form takes up the entire screen. You're going to want `FormWindowState.Normal`. Second off, you may want to set the form's `StartPosition` to `FormStartPosition.Manual` and set the position of the form yourself by getting the screen position and size from the `System.Windows.Forms.Screen` class. Here's an example (which I haven't tested, so it may need some tweaks): var screenBounds = Screen.PrimaryScreen.Bounds; int x = (screenBounds.Width - Width) / 2; int y = (screenBounds.Height - Height) / 2; Bounds = new Rectangle(x, y, Width, Height); Also, as others have said, you may want to use `Hide()` and `Show()` instead of just minimizing the form. Keep in mind that if you do this, you'll have to put the initial `Hide()` call in the `Shown` event and not the constructor or the `Load` event and use a flag to make sure it's only called once. // in the class bool initialHideRequired = true; void InitialHide(object sender, EventArgs e){ if (initialHideRequired){ Hide(); initialHideRequired = false; } } // in the constructor Shown += InitialHide;
For log file analysis I recommend elastic stack
unless you perform context.Database.EnsureDeleted() :D
I would not bother optimizing this unless it is really a bottleneck. Even then it could be too risky as objects in the list may be managed by the pool as well. Such objects could be reused by the pool thus causing some mysterious bugs.
Second this. It's possible to make a fragile ahk script (fixed positions, etc) or a robust one (click on controls based on internal name/ClassNN, checking status of control before interaction, etc.). Some techniques are harder depending on the target program
You should be able to divide both the height and width of the monitors resolution and plug the size of the form into it. This will center it. Or as you tried, set it to Centered in Visual Studio.
It also has potentially unintended side effects if people hold on to any `IEnumerator&lt;T&gt;` instances. A custom implementation of that may also be needed, but I can see that getting gnarly pretty quickly
The control is disabled so any message pumping is also halted. You would need to create a custom control or modify the buttons color.
u/knigitz
Both. For simple pulls, push and branching its convenient and works well. I even use it for some basic conflicts. However anything complex or important and I go back to cli as it doesn't hide what's going on like VS does.
There's a property you can set that says center and then there's center parent. You don't even need to do it in the code. You can do it in the designer.
Pro tip - don't use VS for git. Use external apps with nice GUI - like git extensions(windows only) or fork(mac/windows). Why? For sure at some time you will face complex problems... and those apps are capable to handle them. Second - if you will use some other IDE like vscode or just notepad++ you have common place to commit merge etc.
LiDAR acquisition company processing GPS solution for flight that uses fake mouse clicks to drive windows UI app? This is amazing. Is it 1995? Aren't there any accessible APIs or re-usable components that can do processing without relying on fake mouse clicks. &amp;#x200B; I wonder if this company also developed 737-Max software too?
The extension you reference is one of the most useful utilities available for VS - and it is useful for far more than git. For git I just use Team Explorer. It does 95% of what i need to do with git.
Or just learn the command line. It handles everything just fine.
What is the benefit to using `Hide()` and `Show()` opposed to `Minimize()` and `Normal()`?
Why can't you just implement it by using the default IEnumerator&lt;T&gt; and IEnumerator provided by List&lt;T&gt;. Or so the very basic for each(foo in bar){ yield return too; }
I use fork and I love it. Sometimes I have to go to the command line though.
I *hated* trying to wrestle with positioning form elements... It was a big reason why my company at the time switched to WPF.
I used the built in VS source control GUI at first, then I switched to SourceTree. I don't see the appeal of using Git from the command line, personally. It's much easier to get a quick visual of what's going on with a UI.
I haven't worked in C# in a while and I'm not too familiar with delegate but I hope I can help. I plan to edit this with more info but to start with I think you might be looking for [dependency injection](https://en.wikipedia.org/wiki/Dependency_injection)?
Theoretically: Use an X64 swap function on the backing array pointers in the List&lt;T&gt;
You, the API Dev, make the shared library and distribute it.
I use the command line almost exclusively with visual studio, I just keep git bash open, FYI start *.sln will open your sln too
It's a tiny program that I only plan on running on my own computer, so the user-base is pretty limited so I'm not too concerned about scaling issues haha.
You'd continue to enumerate through old contents of the underlying list is swapped while you're in a foreach loop. Could be solved by implementing a custom enumerator and performing a comparison every MoveNext call.
I'm guessing because WPF uses virtual pixels, which won't correspond to a screen pixel if your DPI scaling isn't at 100%.
git bash.
So you provide client api libraries for dotnet, java, python, javascript, php, c/c++, etc, etc, etc? Be realistic. WCF was made to solve real-world problems and scenarios. REST exists to not be WCF.
I provide a .net library and the endpoint. If they use something else it's on them.
As I've become more comfortable with it, there are a lot of things I find much faster in the CLI. However, I agree with you, there are many times when visualization is just far superior, and much faster, at least for me, and so I tend to have both open.
This is the classic “XY problem” your asking for help on your shoddy implementation rather than the problem you are trying to solve
This. Gtikraken just makes my life easier
I have tried many GUI tools for working with git. In the end they are never as flexible as the cli and I return to using it exclusively. I did use VS as a merge tool for far longer than I used it for anything else.
I always use the command line. I like knowing exactly what's going to be executed and it's simple enough.
Maybe it would be better to just create an extension method for List&lt;T&gt; then trying to create a new generic type then?
Please correct me if I'm wrong but are delegates out of date? I looked at the C# docs to see what they were an it was last updated in 2015? I think you can just use dependency injection in place of delegates. Here's a sample implementation of what I wrote: `namespace App` `{` `public class Program` `{` `public static void Main(string[] args)` `{` `//Your code goes here` `Item attacker = new Item();` `Item enemyWithShield = new Item();` `enemyWithShield.HasFireArmor = true;` `Item enemyWithoutShield = new Item();` `enemyWithShield.onDamage("Fire");` `enemyWithoutShield.onDamage("Fire");` `}` `}` `public class Item : MonoBehaviour {` `private bool _hasFireArmor = false;` `public bool HasFireArmor { get; set; }` `public void onDamage(string attackType){` `if(attackType=="Fire"){` `if(HasFireArmor){` `Console.WriteLine("Fire attack blocked by armor");` `} else {` `Console.WriteLine("Was damaged by fire!");` `}` `} else{` `Console.WriteLine("?? I don't know that one.");` `}` `}` `}` `interface MonoBehaviour{` `//placeholder so it compiles` `}` `}`
In the health data industry? XDS.b standards are still prevalent. All that is soap, right now I have to use WCF, and I hate it so much.
Why not use [Whack Whack Terminal](https://marketplace.visualstudio.com/items?itemName=DanielGriffen.WhackWhackTerminal)?
You can try Aspose.Cloud (please follow the links: https://products.aspose.cloud/words/net and/or https://docs.aspose.cloud/display/cellscloud/Convert+Excel+Workbook+to+Different+File+Formats). Here is a small snippet for DOC(x)-to-PDF conversion: ``` var wordsApi = new Aspose.Words.Cloud.Sdk.WordsApi(AppKey, AppSid); var saveOptionsData = new Aspose.Words.Cloud.Sdk.Model.SaveOptionsData { SaveFormat = "pdf", FileName = "destination.pdf" }; var request = new Aspose.Words.Cloud.Sdk.Model.Requests.PostDocumentSaveAsRequest("Hello world.docx", saveOptionsData); wordsApi.PostDocumentSaveAs(request); ``` You can also test the quality of the conversion on Aspose.App.
To hash is close, it is GetHashcode and Equals. Just make the list items implement Iequatable and tell VS to write the methods needed https://docs.microsoft.com/en-us/dotnet/api/system.iequatable-1?view=netframework-4.8
Team explorer built into visual studio
I mostly use Git Extensions: https://gitextensions.github.io/
I find that relying on GUI apps hides a lot of what’s really going on with git and for newbies this ultimately will stunt the development of their skills. I’d only recommend GUI apps for non-coders or people who are capable of achieving something through CLI but are in a situation where a GUI makes life easier for whatever reason.
Just switched to GIT from TFS using Visual Studio and it's an absolute nightmare compared to just using TFS. Everything you need to do takes three times as long.
Delegates are not outdated, just a finished feature. That would be like saying int is outdated because they haven’t changed it since like the first version. Delegates are just variables that can store functions themselves. This can definitely be used to modify behavior without changing code, like in event listening and the such. So it can be used to implement a form of dependency injection but is more general than that. Dependency injection usually involves passing in the classes that your class depends on so that your code doesn’t have to change even if your behavior does. I don’t see any example of that in your code. Having the enemy calculate the damage rather than yourself calculating the damage is more of dependency inversion than dependency injection, like the tell don’t ask paradigm. The reason I’m making this distinction is that there are frameworks that do dependency injection for you.
Ugh. Think about what screen pixels would mean when the window spans two monitors with different resolutions.
Same here. Every other tool is just too slow and bloated.
im having some troubles. Ive been giving it some tries those last days, but the cours dont want to play. I xant either download nor contact support.
There's an extension and you can use team explorer.
This would be such a huge win for C#. Thanks for posting it, I had no idea C# was considering it. That post seems kind of old though.
I uee SmartGit
The problem i'm trying to solve *is* the shoddy implementation. Right now i have a system that works, albeit it's sloppy and unsafe. I'd like to refine my bad solution into a good one before i continue designing my game. I tried looking online but i get more situational solutions, so i figured i'd try to find a more general approach here.
I as assuming here that you are using the data annotations as part of model validation for asp.net/asp.net core, there are two options, either build a custom data attribute or implement IValidatable object. There are example of both here : [http://www.prideparrot.com/blog/archive/2012/4/model\_validation\_in\_asp\_net\_mvc](http://www.prideparrot.com/blog/archive/2012/4/model_validation_in_asp_net_mvc)
I use GitKraken and git bash. The only git feature in Visual Studio i use is letting it display the current git branch on the status bar.
Your not going to find a 'safe and scalable' method to inject code... You want to modify your design to include armour classes as a concept instead of hack it in.
Ah no, I forgot to clarify that. It's part of a WPF MVVM application. But maybe this is still applicable for me?
WPF uses Device-Independen-Pixels which is a way to manage how an UI looks at different screen sizes and desktop resolutions. For a good rundown on the how and why: https://docs.microsoft.com/en-us/windows/desktop/learnwin32/dpi-and-device-independent-pixels
Thank you for mentioning dependency injection. I didn't fully understand the conceptual aspect of what i'm trying to achieve but that link really led me to a bunch of articles on good architecture designs that fit what i'm trying to achieve. The thing you suggested about having enemy.Damage(DamageType) check for armor is basically what i'm trying to achieve, but i want the Armor class to specify the conditions to enemy.Damage(). Ideally, enemy.Damage() as its written should have no idea Armor exists, but should be open to dependency on Armor or any other classes down the line that need to overwrite enemy.Damage() for their own purposes. So maybe in a month from now i add an item called 'Regen' that when worn, converts damage taken into recovered health. I want to make this change without having to modify Damage() directly in its class file, but rather modify the method from inside Regen.cs. &amp;#x200B; The problem i see with this approach is that if the Damage method is dependent on a bunch of anonymous implicit classes, each of the classes needs to be responsible for their own testing and error checks. Having 40 different classes each modifying the Damage method on runtime could lead to some side effects that might not be caught. This is where i'm hungry for knowledge: i want to find the best way to create an interface so that the arbitrary code injections can be safely ordered and monitored. I just don't know the best way to do this, but the link on Dependency injection definitely includes a lot of information on how i can do this.
&gt; That post seems kind of old though. Yeah, these kinds of features often take quite a long time.
Maybe using one level of indirection like a handle
This makes staging specific lines, resetting specific lines and managing branches a lot easier than using the CLI. Also its way easier to view the log and diffs with a GUI.
I use the built in git UIs. Takes two clicks to commit and push all my code. I use the command line if there are any issues I need to troubleshoot
I use tortoise git. It adds items to your context menus. Super easy to use. Anything that gets complex with I will fall back to the cli. https://tortoisegit.org
PoshGit as I like PowerShell, and the name amuses me 😀
Fully agree! Coming from someone perfectly comfortable in a *nix ssh environment. However, bigger fan of GitKraken over opposed to SourceTree - surprised it isn't mentioned yet
Doesn't changes database design at least you use migrations, but can change the data content of course.
I find it to be exactly the opposite for me. At the command line you're never misled by the sort of artificial graphical representation of the repo. I've tried SourceTree, GitKraken, a couple ofthers, none of them in my experience save me any time, while at the same time making simple things from the command ( like merge and, reset, stash-pop) way more cumbersome and error prone. To each their own, but I believe that competency at the command line would make someone more productive than a UI tool.
In the latest version .NET Core 3.0 we need to set EnableEndpointRouting `services.AddMvc(option =&gt; option.EnableEndpointRouting = false);`
So you use .net exclusively and don't use WCF? Explain to me the thought process there?
Then you're still getting used to git. Give it time. Microsoft bought github and included robust git support in its tools for a reason, and that reason is that git is the best version control system available, and its not even close. I came from an SVN TFS background myself, and its a shock to the system switching to git for a number of reasons, but since I had no choice I decided to stop worrying about who moved my cheese and I just learned how to use it. There is no way in hell I'd ever go back now. I wouldn't even be interested in working for a shop that used anything else, to be honest. Its a massive productivity booster for large projects especially.
We use TeamCity and Octopus Deploy and they are amazing tools. Automated builds and one-click deployment, so easy
It can be done using a temporary variable to hold one value
Well first of all it's 2019. Second of all JavaScript frameworks call my apis. If I need some desktop or console app then I'll make a shared dll with the models. Third of all it's 100x easier to make a rest API than a soap API
Cannot recommend this highly enough.
Same. And to be fair, the merge workflow in VS is pretty damn good actually, and I still use it for conflict resolution.
Yes! Simple and gets the job done.
I would add that even if you use it for a month and still hate it and want to use a graphical client, you'll have a more concrete understanding of what's *really happening* in the repo if you learn how to use the CLI, regardless of your intent to keep using it. I can't count how many times I've been brought in to help someone with a *git problem* only to have to point out that they didn't have a firm grasp of what was actually going on, and that is 100% on the GUI client obscuring the fact that they'd done something silly, like reset to a previous commit accidentally, or whatever.
This is one of my concerns. Later this year I'll be shepherding a team from TFVC to GIT. Most of them have a decade+ of experience with a centralized version control system and moving to the decentralized model of GIT is bound to cause some friction as people stumble and struggle trying to get used to it. Combine it with the ever present panic over whatever the current arbitrary deadline is and I am sure I will hear a lot of "Can't we just go back?" from people for the first several weeks. It is pretty clear that GIT is the path forward and at the moment I am trying to appeal to the dev's own sense of self preservation since odds are their next job will use GIT so no better time to learn than the present. Still, I just know in the back of my head that there are going to be a lot of growing pains similar to what Thelomen\_Toblakai is describing when we do make the switch.
https://en.wikipedia.org/wiki/Active_record_pattern
https://www.cakebuild.net
I moved us to TFS's implementation of Git which used for years. Last year we moved to DevOps (TFS in the Cloud). We generally don't use the command line except when things get screwed up. As a result, none of my team actually know the Git commands because we never really need to use them.
Ctrl, Ctrl + M Enter. Switch to changes. Tab, Tab. Write a commit message. CtrlQ, Ctrl +S (custom shortcut for Team. Git.CommitAndSync)
I use the posh git PowerShell extension and the command line and the git flow commands plus interactive rebasing for branch cleanup. If I want a cleaner visual diff, I publish my feature branch to the remote (either bitbucket or GitHub lately) and view my changes in a browser. For 99% of everything else the CLI is just fine.
Have you ever created a WCF service? It's the simplest and fastest way to get a set of services up and running. Seriously, you add a WCF service from the Add Item context menu. VS updates your config for you and stubs out the service contract, data contract and service. What could be easier?
Git in visual studio has got a lot better in the last couple of years for every day functionality but there's just no UI as good as the git command line, particularly when you get to anything slightly more advanced. I only used sourcetree to manage stashes and vs2019 does that now anyway. As with other atlassian products, I always found sourcetree a bit unstable e.g. for a few months you just couldn't create a stash with a space in the name, and sometimes when I select a branch or stash it still shows the old one, and when viewing large diffs it just gives up a few files in
Git automater also works wonders then it's just control shift z. Just have to get it of vs plug-in store thingy
Please link the section of Wikipedia that states what the word "active" in the name means. I'm not seeing it. I'm asking about the word active, not what the pattern is or how it's implemented. I know that.
I use it too. It's probably the ugliest interface out there (very '90s) but for me it's the most intuitive.
I just don’t understand why anyone would use a GUI for git at all. It hides functionality.
How would you handle the Math.Clamp situation?
Same here. Octopus has removed the free option, though, so it may not be for everyone. But yeah I've got a ton just automated away with these two. It's really made a difference.
There are a shocking number of developers out there who are very uncomfortable at a command prompt. It's depressing.
Azure DevOps is the name of the collection of tools. “DevOps” is a series of principals and ideas more than anything.
Bitbucket+Sourcetree
I use **too many** tools. They each have strengths and weaknesses. Sourcetree to browse commits, visualize branches, and move around branch pointers. Visual Studio's git tools to commit, merge, rebase or browse a specific files history. Kdiff3 to solve complicated merge conflicts. And command line tools for quick'n'easy stuff. VS git tools are better at auto-handling *proj and sln file conflicts than other tools. Kdiff3 is better at grouping conflicting lines than any other tool and isn't as easy thrown off by whitespace changes.
git, simple... lol
It’s gatekeeping, but if you’re not able to use a terminal for basic tasks, I don’t think you’re a developer.
http://xyproblem.info
We migrated off of Octopus due to their licensing changes. Our bill increased an insane amount. We’re on Azure DevOps now. I’m not a huge fan but we’re learning to adjust to its quirks.
I would probably create a class to represent the "inflict damage situation" it itself, including both the input information (who tries to deal the damage, to whom, how, and why) and the outcome that has been decided (how much damage, and why). Then, when inflicting damage, the situation object is created, and all components that could have an effect on the situation (maybe implementing a certain interface, or registerd with a certain event) are invoked, resulting in changes to the situation object. Afterwards, the outcome present in the situation object is applied.
dotnet build will restore nuget packages when you build. It shouldn't be any harder to build than dotnet build -c Release foo.sln
It would exist in my own namespace - `RedditWithBoners.Math.Clamp()` or have some other appropriately namespaced and named class like [LogLinear.Interpolate()](https://github.com/mathnet/mathnet-numerics/blob/master/src/Numerics/Interpolation/LogLinear.cs#L104).
I don't need a fancy solution. It's a pretty basic WPF desktop application. I want to configure ILMerge and perhaps compressing the binary. That's pretty much it. Thanks for the recommendation though!
I looked at Cake. Is there something this does which msbuild cannot?
You wouldn't get any argument out of me. The sad truth is that anyone who's completed a random javascript-framework-of-the-month bootcamp can get hired these days, without any breadth of knowledge about the other 99.99% of computer science topics. It seems like the quality of the talent pool has an inverse relationship to the number of people submitting resumes. But I could just be an old man yelling at kids to get off my lawn.
My project is a WPF desktop application. I'll look if there's a way to do that with a non-core .net project.
Ironically I find git bash to be far too bloated
"Better than SVN and TFS" != "best version control system available"
hggit + TortoiseHG
Making a rest service in .net core.
Show us yours then.
What do you use then? Git bash is the least bloated hit tool out there.
That's how I use it. VS Team Explorer for the basic commits &amp; pushes/pulls. Even creating new branches and shit. Other stuff, like git stack push/pop or other more complex branch management I'll do from the cli.
Git bash comes with bash and a bunch of unneeded Linux tools. Just straight up using git from the command line.
I'm not asking for help about Y... Y is an example of an inferior solution to X. I'm looking for superior solutions to X, not a superior solution to Y
dotnet build runs msbuild so it will still work. It's just a nicer cli. You don't need to actually use .net core at all to use it. Also you can just switch your csproj files to the SDK format even if they contain wpf now, which I highly recommend as PackageReference works a lot better than packages.config
I sometimes just use git bash as a linux shell if I'm unfortunate enough to be on a non-linux/windows os.
no not likely, c#ish code is just a bit nicer to work with
Which is fine, but installing a shell from another OS is strictly more bloated than just using the tool itself with the native tool. And if you're using windows for a non trivial amount of time then taking the time to learn PowerShell and the windows command line ecosystem is useful and will pay off.
Oh dear god this, OP. It's literally built into the product. Also, install the following extensions: - Gitflow - Git diff margin
J tried. I used only Windows for a long time and I actually originally switched to linux for the terminal. I'm a big fan of the terminal on linux (though I'm not the best at it). I can easily launch vim and then compile my C code with gcc/g++. Windows command line makes me want to kms. Windows command line is just dreadfully bad imo.
Really? Exactly what's easier? Explain why creating a REST service is easier. Is it debugging why a client cannot call your service because the json they submitted doesn't exactly match your defined object and thus your server just returns a 404 and they have no idea what's going wrong? I mean, didn't those JS developers use the metadata you exposed by default? Wait, I know, your services just got moved to another environment that requires guaranteed delivery and you need to change your configuration from hosting in http to message queues without writing new code. Because that's easy with REST. Oh, the network admins said your encrypted services are being intercepted by a MitM attack and you have until tomorrow morning fix it. Moving those services to encrypted binary packaging over raw TLS shouldn't be a problem at all.
I bought SmartGit licenses for everyone on my team. Best git client.
Git command line with got-flow.
This. Powershell is one of those things I feel like I should be better at than I am, so things like Posh Git encourage me to tweak my environment.
What you want to do is apply a buff when the item is equipped that reduces fire damage 100% then when you calculate fire damage you look for buffs against it. Injecting code is not what you want to do at all.
Not quite sure why you are explain in this.
It should always be self-documenting. I didn't intend to imply that was a bad idea. Ideally, good code should explain the "what" of your code. Comments should then explain the "why" if the implementation seems to not make sense, is counterintuitive, or complex.
All code should ideally be self-documenting/readable. It's good practice to do so, and explains _what_ the code is doing. My only issue is that even well written code could be complicated enough to warrant a comment explaining _why_ it was done a certain way.
GitKraken &gt; SourceTree here too. I'll switch between CLI and the UI sometimes, but GitSquid (what me and a buddy call the Kraken) is superior to SourceTree.
You’ll have to ask Martin Fowler but I take the meaning to be that the instantiated business object is directly coupled to an active database record. One row = one object with intrinsic create, read, update, and delete operations.
I bet you're a joy to work with.
This is totally wrong. There is no need to create an instance of a class by passing parameters to the constructor then call a parameterless method. It's calling a method with extra steps. If you want to di it you would create a ICalcualteCost interface that had a single method accepting those parameters. And inject it into the constructor. If not just make it a method.
Sourcetree is my go to Git app. It's easy to use, can easily see all of your repos in one place and if you need to get to the command line for more advanced stuff it's right there. I've found VS git integration is clunky imo.
Following is inspired by [https://en.wikipedia.org/wiki/Chain-of-responsibility\_pattern](https://en.wikipedia.org/wiki/Chain-of-responsibility_pattern) but probably not 100% as according to the spec. &amp;#x200B; What about having a chain of \`AttackHandler\` that receive and Attack "description" and may modify that attack and then pas it on to the next handler. So for example an "FireBolt gets passed to the first handler that happens to be the FireArmor that checks the Attack is something it can protect against, changes it to 0 damage and calls the subsequent Handler. Probably useful to make the Attack objects immutable.
Powershell Core + posh-git + tortoise git (just for the logs and merge conflicts)
I switched to [Sublime Merge](https://www.sublimemerge.com/) a few months ago an love its simplicity. Also, it can show you the actual Git commands executed, so it is useful for learning the Git command-line as well
Firstly you can shorten the assignment of those images by declaring the array = {image 1, image 2}; instead of having a line for each one (obvs replacing "image 1" with however you reference it now) the randomisation can be done by generating a random number using the rand function between 0 and the size of the array then using that to reference the corresponding image in the array. This should be able to be done in the OnButtonClick method
Same
Thank you. How would that rand function look? Something like Random rand = new Random(0, 51) if keeping my image list the same?
Check out 2019's stash support. It's much improved (as in now exists).
It'll stay the same regardless of if you change the list assignment that's just a slightly more concise way of doing it. I can't remember the rand function off the top of my head but I'm sure there's examples online
I have a few gripes with tortoise git. Like if you try to merge but have changes in your working directory it will silently as them to the merge. Also resetting a branch seems to default to keeping the working directory the same and I can't get the seeing to be different. Otherwise one of the best merging experiences of what I've tried though so I keep it around.
I will tell you my story in case you want to hear it. &amp;#x200B; Now that they have a project template called Windows Packaging Project, it really is quite easy. &amp;#x200B; I had so many problems with the Desktop Bridge (it was made with Windows 95 left over parts), that I requested a refund for my Windows Store account, which got my main email black listed from MS because some genius made the email address the primary key thinking developers have only one. &amp;#x200B; To make a tremendously long story shorter (and why I can't use twitter, it takes me 2,000 words to get to hello), I finally got my app in the store with a help of a MS engineer and I had to make a few changes to make it work on a Surface display (or laptop in general). I have a wide screen monitor and my big font displays had a few minor adjustments to fit on smaller monitors. &amp;#x200B; My only product in the store is called NFlate, which is a tool I think is really cool because you can drag folders you visit on a regular basis to your favorites like a browser, and as a developer I spend several hours per year browsing for files or more. This app also has a Font Selector, which Windows Explorer back to version 3.1, nor File Explorer in Windows "10" in 2019, so people like me with poor vision who remote into virtual machines that do not even have graphics cards and I can't read font size 8 due to my age and vision. &amp;#x200B; I thought I was doing something that might help other people use Windows better, specifically those with poor vision, but I have had 20 year old developers ask me why doesn't Windows do this? I have done worse things in my life than these things, and the price is $4.99 so I am not trying to profit off of people with poor vision, other than a slight motivation for me to work on it more. &amp;#x200B; Being my marketing skills are so bad I couldn't sell water to a bus load of billionaires who broke down in the desert in front of my house, I thought a free 30 day promotion to get some "good" reviews was the best way for me to get some word of mouth going for the app. &amp;#x200B; The very first person who I gave the app to, wrote a review 'This app no work' (verbatim quote I believe). Other wanting to slap this person silly because it was free, I asked as politely as possible what didn't work or what could I do to fix it, and I never got a response. Now if the app didn't work, MS would not have allowed it in the store, and I had to explain to my MS test engineer what my app does (like I did with you). For all I know this person has a competing file explorer project, or he was mad at life, but after my first review no one else has bothered to download my app, and MS has given me no remedy. If I was a person of lesser integrity, I would have paid 5 people $20 to try my app and say 'This guy is nuts, I use it every day and it saves me time at work. Or my boss bought it when I said it was $4.99, it didn't have time to listen to what it does.' &amp;#x200B; So my crime was to "sell" software that might help someone use Windows better, and I got paid zero because I tried a trial promotion of free. Had I charged $4.99, this same person, lets call him Fart Face because I don't remember his name, would probably not have bought my app and someone else might have instead and my opinion of the Windows Store might be different. &amp;#x200B; My second criticism is the fact my target audience was people with poor vision, I cannot read the font on my own page on the Windows Store: (end plug) [https://www.microsoft.com/en-us/p/nflate/9mv6hht176q7?activetab=pivot:overviewtab](https://www.microsoft.com/en-us/p/nflate/9mv6hht176q7?activetab=pivot:overviewtab) &amp;#x200B; The page design is so bad, I have about 20 apps I just gave away on GitHub: [https://github.com/DataJuggler/SharedRepo](https://github.com/DataJuggler/SharedRepo) &amp;#x200B; With open source I do not feel like I am spamming, but Reddit C#'s main thread treats me like I am selling flip phones or aluminum siding, when I am trying to tell people about 20 programs that are all free, and every C# developer will probably like at least one, or double their money back - end all plugs). &amp;#x200B; Now that is my take. If you have this thing called People Skills or Marketing Skills, and / or your apps are just something people actually want, or Fart Face doesn't sabotage your efforts, you might have a much better experience than I did. At least on GitHub I did not have to pay $20 to be told my apps do not work (developers have feelings to).
Where does bash fit in? I used git from the terminal but never have found the need for bash.
I use `git gui` to stage specific lines, if I need to.
I and most of my team work this way: [Con Emu](https://conemu.github.io/) + Powershell + [Post-Git](https://github.com/dahlbyk/posh-git)
Probably doesn't help anymore, but if you're concerned you could make a backup, but for a fact it does not, so no worries anyway.
I switched from TFS to git so I was used to a UI and sourcetree has been pretty nice. The visual studio git integration felt half finished to me.
You want colored damage and colored protection. This has probably been designed hundreds of times, which is not to say that the design is easy or obvious but just that there ought to be a number of designs to look at. I’d look into some roguelike codebase and you’ll probably find something. My codey-sense is telling me I’d try to turn my protection and damage into data types rather than manipulating hp values directly. I’d design a system to take a list of all my buffs and debuffs and a list of all current damages. Then based on the damage objects, determine what buffs apply, then finally decrement hp and what not. Why data types instead of immediate action? Because some buffs will stack and some won’t for instance. Buffs and debuffs could have nontrivial interactions and if they’ve already resolved themselves into the character’s stats then it’ll be difficult to manage buff/debuff interactions. And without that it may be easier for players to break the game by re-applying a buff n times for instance.
I'm not really sure what is going on with your code here, but I think you need to take less of a functional approach and more of an object oriented approach. You want a damage object that is defined by IDamage. IDamage should have a damage type and damage amount. You'll probably want other information such as from who and modifiers, but that is the bare minimum. Then on the object taking damage you'll want an ApplyDamage(IDamage damage) method. Your object should have some kind of list of damage modifiers, probably best to implement as a linked list. In the ApplyDamage method you should use that list to modify how much is applied to the objects health.
I use a command line on another monitor and decide for merge conflicts.
Integrated Git via TFS pane. As well as GitKraken. Only time I use CLI is when moving or renaming folders.
Agreed. GUI lets me jump around super fast to visually compare everything with a click of the mouse, including jumping between dozens of repos in seconds (I maintain a framework that sometimes requires updating over a hundred repos).
&gt; scaling This was my assumption, too.
One case, you can initially hide it and update stuff in the form before displaying it again without the risk of the user un-minimising the window. Or if you have a child form that you opened from your parent form and you want to keep its settings ready for when you open it again. It’s very tidy for many use cases.
Actually Blazor server side can do both on the newest previews. Even on the comments the author admits he was a few versions behind. You can render independent components on MVC views and Razor Pages and it'll work. On a razor page / mvc view you just call it like this: @(await @Html.RenderComponentAsync&lt;Component&gt;()) // With Initial State from the View @(await @Html.RenderComponentAsync&lt;Component&gt;(new { InitialState = 1 }) This is a very good thing imo as most sites don't really need to be 100% interactive and might just need to sprinkle a bit of interactivity as needed, which is done in the past via JQuery or Vue / React with some hax with their SPA routing to work properly. This method is way cleaner, and the Blazor team has plans to be able to use Tags instead of an Html helper in the future too.
Cake isn't necessary. I wouldn't recommend it. See [my blog post](https://pknopf.com/post/2019-03-10-you-dont-need-cake-anymore-the-way-to-build-dotnet-projects-going-forward/) on the matter.
C# is nicer, but you still likely don't need Cake. See [my blog post](https://pknopf.com/post/2019-03-10-you-dont-need-cake-anymore-the-way-to-build-dotnet-projects-going-forward/) on the matter.
If you have an interface for armor (IWearable) that has a method, `Damage Mitigate(Damage damage);` and Damage has a `Value` and an `Element` property, then your Player could simply loop through all IWearable and mitigate the incoming damage. If you want logic to be injected into the Armor class, consider having a base Armor class that sets Mitigate to `damage =&gt; damage.Value &lt; 0 ? damage.Value + this.AC : damage.Value` and provides a constructor overload to include it's own implementation by passing in, `Func&lt;Damage, Damage&gt;`. All in all, delegates don't seem like a bad way to go here. It let's you avoid creating a class for each item in the game. Consider putting your delegates/items into a factory so you can organize them. `player.Armor = ArmorFactory.FieryArmor;` (I've never done anything like this and I wrote this on mobile. It could be a rubbish suggestion but hopefully it can inspire something to help you).
My advice is to keep things simple. Just use ```cspoj```. See [my blog post](https://pknopf.com/post/2019-03-10-you-dont-need-cake-anymore-the-way-to-build-dotnet-projects-going-forward/) on the matter. Here is a simple project that takes this approach: https://github.com/qmlnet/qmlnet/blob/develop/build/scripts/Program.cs Keep your tooling dependencies minimal.
TFS integration. I have TortoiseGit installed, though. I like it better for dealing with merge conflicts.
This also works wonderfully with git repos hosted in Azure DevOps. If you're like our company and have a few hundred repos, Visual Studio makes it a lot easier to find the right repo to create pull requests or send links to other devs. If anyone is wondering, "Why on earth do you have several hundred repos?" that is the result of [microservices architecture](https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/) in an actual corporate setting.
Because you said &gt; last year we moved to DevOps DevOps isn’t product you can move to. Azure DevOps is.
You're being unnecessarily pedantic.
I used visual studio and then the command line for git. Then I switched to Rider (JetBrains) and they have a terminal window that is the shell and works perfectly. I felt that the got integration of visual studio felt like they were shoehorning it into a svn/tfs workflow.
I recommend checking out Azure DevOps! We use it at my workplace for builds/releases and I've started using it for my personal projects too. https://azure.microsoft.com/en-gb/services/devops/
WSL
Yeah, unless I'm trying to get freaky with some git commands (which I'm not 98% of the time) this is the easiest option by far
We learned that visual studio will create its own gitignore type file. That walks half a day of someone on my team figuring out why a file wasn’t be committed.
post your \_TranslateAttributes object. post your captured response. then get a thousand responses telling you how you're doing it wrong.
Wild guess: Record is a pure data type with no functionality. So active means with functionality. In this case, the record knows how to speak to its representation in the database?
I would recommend ordering the list randomly first and then iterating it over it normally. This should be faster than randomly accessing and removing elements (although in this case that seems unimportant) and has the benefit of not needing a secondary container to hold already used images.
 public class _TranslateAttributes { public DetectedLanguage detectedLanguage { get; set; } public List&lt;Translations&gt; translations { get; set; } } ////////////////////////////////////////////////////// {StatusCode: 200, ReasonPhrase: 'OK', Version: 1.1, Content: System.Net.Http.StreamContent, Headers: { X-MT-System: Microsoft X-RequestId: ******* Access-Control-Expose-Headers: X-RequestId X-Content-Type-Options: nosniff Strict-Transport-Security: max-age=31536000; includeSubDomains Age: 1 Connection: keep-alive Date: Mon, 06 May 2019 02:31:57 GMT Via: HTTPS/1.1 ***** Content-Length: 96 Content-Type: application/json; charset=utf-8 }} ///////////////////////// I hope I get at least one telling me how to fix it lol!
## SOLVED
I'm pretty new to any kind of automation and programming in general. How would I find out if there is an API or re-useable components? &amp;#x200B; Thanks for your response :-)
Sweet. I will take a look at it, thank you.
Thank you. I've looked at this and it looks like it might do the trick, with a considerable amount of time working through the docs. Thank you.
I've used wsl. I would say it's ok at best. It has quite a few problems with speed.
No, you’re just referencing the wrong thing. You can’t move to “DevOps”. You can embrace DevOps principals or work flows, but DevOps isn’t a product. Azure DevOps is the product. You’ll confuse people who haven’t heard of it before.
Git bash also allows you to run a number of linux terminal commands, rather than needing to learn special snowflake Windows’. Much better alternative for devs who need to temporarily use a Windows machine.
I moved the our company to using the online equivalent of TFS, which I clearly stated. The correlation of that is Azure DevOps. I at no point identified the development/business concepts of DevOps, but I was clearly referring to the product line within Microsoft catalog. Hence the brevity.
nice, thanks! we have only been using cake for about 2 years. we only pull in 2 addins, and 3 tools for cake, with about 15 targets/steps at about 500 lines. we then import it as a git submodule to our application projects, and it works reasonably well. prior to that we just had each step as a task in TFS, which wasnt the easiest thing to maintain at the time. its since improved with task groups, and conditional execution, but was always different to what a dev ran locally. we still use tfs, its just calls the single, version controlled cake file now.
You mean CMD.exe? Powershell is the windows shell now
No, you were clearly referring to DevOps, the principals, as you said “DevOps”.
PowerShell is still kind of a mess. I just use C# on linux and compile/run it with mono from the terminal.
Same here. Git from cmd works fine, Never understood the purpose of git bash.
while they are both great tools, id advise against defining your build process in your CI tool. It should be CI agnostic. If that makes sense.
I recently bought GitKraken Pro because I tried the free version and absolutely loved it. The UI is beautiful and the UX is super intuitive. It makes everything easy from branching and syncing with remote to rebases and cherry-picks to stashes and merge conflicts. The history tree is super easy to traverse with full commit messages and changes. The active changes are super easy to stage in hunks, by line, and even by selection. It is also incredibly easy to switch which repository is open
You found it yourself when trying to capture the response and finding there was none.
Correct haha. It was working when I was at the office, but I was on my laptop at home and I was getting the OK but it wasn't putting out anything, meaning it was deserializing just a null entry. Turns out the VPN was blocking it I guess.
" but the software we use is windows GUI based ". Some company built the software. Contact them, see what they have. If company is gone or does not have anything useful then there should be some competition that has something comparable.
I use github desktop outside of VS
There is no way PowerShell is a bigger mess than bash. What do you mean?
I quite like bash. I'm used to it and it makes more sense to me.
Context clues bro
You should think of PowerShell in the same way you think of C# as it's built off of .Net and uses the same standard library. Once you start understanding that, PowerShell makes a ton more sense. Also just fyi, I love bash a ton too and know it better than PowerShell, but I'm slowly migrating over. PowerShell has a lot of alias from bash commands to it's own commands to make the switch easier, and you can add more.
i am not familiar with native libraries, can someone explain why this thing is "cool"?
Mosh is AMAZING! Absolutely one of the best if not THE best lecturers out there. I havan't come across someone better than him yet. He organizes his courses so well, and the examples he gives are just on point. Can't recommend him enough!
Sorry for the late reply but we use GitVersion to keep track of version numbers and those are calculated via a git tag that starts as a basis and counts commits from there. There are many configurations however.
Thanks everyone. I was able to put together something that the instructor fully accepted.
Yes.
Random rand = new Random(); int index = rand.Next(0, 52); //max is exclusive
I really like VS Git and Azure DevOps, you get a ton of conveniences from very good tools. I use Sourcetree a bit to browse and diff.
I also use an add-on called (IIRC) 'Open Command Line', which opens any CMD/Powershell/git bash in the directory of your current file when you press Alt+Space. Very handy.
Except it was clear from the context that OP couldn’t possibly mean they’re moving to a DevOps company structure, and even mentioned TFS in parentheses. It’s very clear OP was referring to Azure DevOps. Why are you even arguing this?
Normally when you compile your .net class libraries, they can only be called by other .net applications. Native libraries are libraries that are usually generated by C/C++ code. They can be called by almost all of the languages and they don't require .net framework or any other thing to be installed.
If you install msysgit you get all the same tools. [Cmder](https://cmder.net) has it builtin.
For general purpose commit/push/create branch stuff, I just use the VS Git extension, plus TortoiseGit and the git CLI for slightly more involved stuff like interactive rebases.
https://www.reddit.com/r/csharp/comments/bl19cx/how_do_you_guys_use_git_with_visual_studio/emlbc3f/
still better than GitKraken that have a "shinny UI" ... but the UX oO man
Why not just say "Mercurial"? And either way, for me, nah. The whole "sacred history" thing sounds good on paper, causes much work (unnecessary from a git perspective) in practice from my admittedly limited use of it. Its all opinion anyway, so fair enough.
It's not the decentralized model that's a problem, it's Git's implementation of it. A few years ago, I worked at a place that switched from Subversion to Mercurial on short notice. We had some nontechnical users who'd been checking code into SVN, and it had taken a while to get them up to speed, so I was afraid it would take a while to retrain them after switching. Turns out I had nothing to worry about -- I literally only had to tell them to pull before updating and push after committing. We still used a central server, and for simple workflows, the interfaces of `hg` and `svn` are identical except for the push/pull step.
Dont disable the button. Clickig a disabled button makes no sense. Instead hook up all the events and run them based on the text of the button. So if they double click and it's not a number just return from the event handler etc.
The whole idea of rest is that two calls with the same input will give the same output. You apparently don't know what you're talking about.
So the issue is that your system is not up to date, not that it's technically unfeasible.... Even if it means the same.
Visual Studio builtin for: - staging - editing commit (unstage, update staged) - merge resolution (!) SmartGit for: - general repo awareness (we have 50+ repos..) - branch management - checkins/fetch/push - change tracking
The links are broken
Have you tried passing quotes in command line parameters? That's powershell scenario numero uno and it works the first time never.
Create a sp to decrease a single int property? That is massive overkill.
Our system is up to date, but the third party system (government platform) could be considered not up to date.
Not sure how but just checked on my phone as well they are working on my end.
Oh sorry, for some reason when I clicked them, it omitted a parentheses and it just gave a 404
Fixed links: https://docs.microsoft.com/en-us/previous-versions/msp-n-p/ff649152(v%3dpandp.10) https://docs.microsoft.com/en-us/previous-versions/msp-n-p/ff647790(v=pandp.10)#design-considerations
Why not use WSL on Windows? It's far more feature rich than git-bash when it comes to alternate utilities present?
Ooooh!
"Sacred history" thing? Are you talking about the way history editing used to be discouraged, way back in like 2007? Today, with phases and `hg evolve`, Mercurial's support for history editing is more fully functional _and_ safer than Git's.
I've always thought of it as the object is actively participating in moving itself into, and out of, the database. The object itself is doing the work. The opposite situation is where it's a "passive" object that is being moved around by some other object (a data mapper). Kind of like if you move to a new home. Do you rent a truck, load it yourself, and unload it yourself (active)? Or do you hire movers, and let them do all the work (not active)?
Try gitkraken. It doesn't integrate with VS, but it's amazing for resolving merge conflicts and the GUI is very intuitive. I use it for all my git projects. It's free for non-commercial use.
Command line with a bunch of aliases and SmartGit mostly for resolving merge conflicts.
I don't. I use the little thing in the side bar to see what is changed and what not, but commiting, pushing, pulling, branching, etc, it's all command line, and eventually gitg. Now, I'm not gonna argue that the git command line is great, cos' it ain't. But the alternatives aren't much better. You always eventually hit a wall, plus the feedback on GUIs for this kind of thing seems hard to get right. My usual workflow is, I use gitg (gitk, which is multiplatform and even comes with git on Windows, works too, I think) to visualize the commit tree, and to stage files. It has this great feature where you can stage specific parts of a file, like with git add -p, but with a much more intuitive UI. Them I will commit either with gitg, or on the command line. For branch operations I also find the visualization of gitg quite useful. Before doing some more complicated rebase or something like I'll fire up gitg, see where all the branches and commits are, plan my change run it, and refresh gitg to see if it ended up as I expected. So, TL;DR; Don't go full in graphical tools, bit pick a simple one to visualize the commit tree and branches and to do git add -p without wanting to kill yourself.
https://www.ducksters.com/kidsmath/solving_algebra_equations_with_addition_and_subtraction.php
Git bash + built-in Git GUI for Visual Studio. For me, it's totally sufficient.
I know how it works i just dont know how to code it !
https://docs.microsoft.com/en-us/dotnet/csharp/tutorials/intro-to-csharp/numbers-in-csharp
Just realized you're talking about visual studio, not visual studio code, so ignore the part about the little button on the side. The rest is the same, I've never relied on VS' at all for version control. Maybe I should, cos' sometimes you change branches too dramatically and the whole solution gets weird, but, anyway.
ax + b = 0 =&gt; ax = -b =&gt; x = -b/a Simply you let the user declare number a and b and you have a simple line of code that says x = -b/a and print out the result.
Ok thanks i try :)
Yeah Reddit breaks links with ( and ) in. There is a fix, as I asked about it a while ago, but I can't remember what it is :/
Remember to restrict the user from entering a zero for A
Thank you so much it worked:)
When a link has a ) that is part of the link, and you are using link format (as specified in the help under the textbox in the old version of reddit) it is like this: \[text\]\(https:\//docs.microsoft.com/en-us/previous-versions/msp-n-p/ff649152(v%3dpandp.10\\\) -&gt; [text](https://docs.microsoft.com/en-us/previous-versions/msp-n-p/ff649152(v%3dpandp.10\)) For writing the link directly no idea.
That's the one :)
Removed: Rule 4.
Because it wasn’t clear, especially if someone who doesn’t know that Azure DevOps exists
I use git kracken
Oh yeah actually forgot that part xD
It literally says: &gt; we moved to **DevOps (TFS in the Cloud)**.
You need Cake only if your build process is convoluted. If you go by straightforward path a simple `dotnet publish` is enough.
Yes, you shouldn’t to MS Word as “Word”, though that is more easily distinguishable seeing as how word the noun isn’t proper.
We use TFS builds and default template there is to run `nuget restore` and then run `msbuild`
I think your teacher would disagree with your interpretation of the phrase "self programmed".
So this is cool if you are just making a "low level" type of library, cause' you can reuse your c# knowledge instead of learning a lower level language?
Removed: Rule 4.
You can use something called decorators. they are even easier if you can use them in the context of CQS, too.
I know what bash is, just curious how it enhances the git experience over a terminal. Maybe it's just people who are more comfy with Linux in terms of navigating directories, and other simple things rather than bash's script capabilities.
I personally use sourcetree
SVG files are just XML when it comes down to it, can you still make sense of them that way by looking at attributes and adding elements directly?
You might be able to use System.Drawing.Common to get those existing libraries to work. It doesn't look like there's a fully featured, Core compatible SVG library out there yet.
What is your goal? Might help with the suggestion.
Windows doesn’t have a terminal, which is the niche it fills. Git Bash also has a few things inbuilt to aid with git, not as stylish as say powerlevel9k, but still informative, like showing what branch you’re on and the like. Coloring too.
Perfect answer. Thank you. In my head that's what I was thinking but you put it perfectly into words.
You're likely using the wrong event (TextChanged). Currently you have an infinite loop when changing TextBox1's Text-property. This should work (untested). using System; using System.Windows.Forms; namespace WindowsFormsApp1 { public partial class Form1 : Form { public Form1() { Random rnd = new Random(); int number = rnd.Next(0, 150); string[] lines = System.IO.File.ReadAllLines(@"E:\GER.txt"); textBox1.Text = lines[number]; } } }
Would be nice if someone else's code can be reused though
What does not work? &amp;#x200B; \- What are you trying to do? **TextBox1\_TextChanged** seems to run when something changes the text. But you are also changing the text from inside the method. \- Try to do `System.IO.File.ReadAllLines(@"E:\GER.txt");` once. \- Are you sure there are 150 lines in the file? Otherwiese do this: `int number = rnd.Next(0, lines.Length);` `textBox1.Text = lines[number];`
It's for generating code for Xamarin.Forms from SVGs on both Mac and Windows. The code will be hand-edited to e.g. change some elements to buttons later on.
It give me this error for line: textBox1.Text = lines[number]; "Object reference not set to an instance of an object.'"
Well hopefully my experience of moving between source code control systems will be as smooth as yours. The people are definitely capable of adjusting so it should all work out eventually. It's the time spent adjusting that concerns me.
Yes, there are such PRs in the works using this, e.g. https://github.com/vvvv/SVG/pull/415
I edited my post, try adding InitializeComponent(); in the constructor.
&gt; The whole idea It's just as easy to write stateful or stateless in WCF as REST. There are many REST services out there that require a session token that maintain state (which is often mutated asynchronously) . So what exactly is your point?
Rule 3 and Rule 4.
&gt; You need Cake only if your build process is convoluted But then you've made the problem worse!
textBox1.Text = lines[rnd.Next(0, lines.Length - 1)];
Over the years, I've found 2 main themes seem to emerge. 1. Know what the code you're calling is doing. Use a good tool like ILSpy or Reflector 2. Do less work. If your code does nothing, you can scale infinitely! e.g. https://github.com/kelseyhightower/nocode
I have been working on a tax reporting tool for crypto currency traders: [CryptoTrader.Tax](https://www.CryptoTrader.Tax) &amp;#x200B; It was build using .net core, has a postgres backend, and is deployed using kubernetes.
&gt; textBox1.Text = lines\[rnd.Next(0, lines.Length - 1)\]; 1. With a one-line it harder for the beginner to debug. 2. With `- 1` you take away the chance to show the last line.
As far I know, [Aspose.HTML](https://www.nuget.org/packages/Aspose.HTML/) for .NET and [AngleSharp](https://www.nuget.org/packages/AngleSharp/) can represent an SVG document as DOM object in .NET ( in both libs the corresponding class is called as SVGDocument). The first is a commercial lib, but the second is free.
Have you tried looking into the visitor pattern? It's quite common for this class of problem to be solved using VP. https://stackoverflow.com/questions/255214/when-should-i-use-the-visitor-design-pattern
Azure iot hub can be configured to use MQTT. There is C# library that you can use to leverage iot hub but it abstracts away most of the underlying protocol so I'm not sure if this would be suitable for your use-case.
Removed: Rule 3, Rule 4.
Removed: Spam. Please review and follow the [guidelines for self-promotion on reddit.](https://www.reddit.com/wiki/selfpromotion) Also duplicate of: https://www.reddit.com/r/csharp/comments/bgc5yi/mobile_repair_management_system_using_cnet/
For Xamarin, you could look at how SkiaSharp's SVG library does it. It doesn't render everything, but it seems to work decently after simplifying my SVGs. https://github.com/mono/SkiaSharp.Extended/tree/master/SkiaSharp.Extended.Svg
I do sometimes use wsl, but git bash is usually already installed
 var r = new Random(); var shuffle = cards.OrderBy(card =&gt; r.Next());
Well yes, if you have an async method which does not make any awaited calls, it will run synchronously. That shouldn't matter, since as I said the method which you actually want to continue running should be running on a different service. If you don't await the call, it won't wait for the response back from the service, and it will finish the method synchronously, which is what you want. &amp;#x200B; If you're trying to do all of this within the same service, that won't work. The controller will have to complete whatever task it is running before it can continue serving calls. If your method takes too long, eventually it will timeout, but if you don't await it, the connection will close. &amp;#x200B; If you have long-running tasks that you don't want to bog down your UI&lt; - &gt; server flow, you should be using a microservice architecture to perform those tasks, which allows you to fire-and-forget any tasks you need to perform. There are many alternatives like I mentioned, Hosted services, webjobs, someone also mentioned Azure Functions which I don't recommend but will achieve the same result. But you can't do it with the long-running task sitting on the same server as the task that calls it.
Just like in many languages and markups, you have to escape certain characters. For reddit, the escape character is `\`. So if a URL has parenthesis, you have to escape it like `https://someurl.com/somepath\(blah.10\)` or whatever.
# What if your job uses many unmanaged assemblies (some are actually needed, most should be managed)? Is there a tool that allows us to peek at unmanaged code? DotPeek can't open unmanaged. #2 true haha
I just use the Team Explorer window. It is built into Visual Studio. The only extension I have installed for git enables stashing since thay doesn't seem to be a built-in feature, though I don't know if it was implemented for VS2019 since I use VS2017.
Umm whay version of VS and NuGet are you running? VS should attempt to restore missing nuget packages on build. Further, unless I am misunderstanding what you mean by manually adding references, we don't need to manually add references when using nuget. If a project is using the packages.config format, then yeah, nuget doesn't automatically reference the dependency packages of a nuget package you've referenced. AFAIK, only projects using the `PackageReference` format will handle transient dependencies appropriately.
Perhaps, I didn't understand a original question right, but as I can see that topic starter wants to generate some XAML layout from SVG. So could you please explain how SkiaSharp can help with it?
There's an [Svg.Core](https://www.nuget.org/packages/Svg.Core/) nuget package that seems to be the vvvv/SVG library ported to .NET Core. The nuget package still links to the [vvvv/SVG](https://github.com/vvvv/SVG) github repository, but it seems like it's probably [mccg/Svg.Core](https://github.com/mccj/Svg.Core) based on the nuget author name.
It has parsing logic that can be a starting point in creating a parser if needed.
Why downvote?
In my opinion, yes... It is cool.
&gt; Today, we’re announcing that the next release after .NET Core 3.0 will be .NET 5. This will be the next big release in the .NET family. &gt; &gt; There will be just one .NET going forward, and you will be able to use it to target Windows, Linux, macOS, iOS, Android, tvOS, watchOS and WebAssembly and more.
This pleases me.
You will need a MQTT server and an MQTT Client to listen in on C#. I've had a good experience with RabbitMQ. For MQTT clients Microsoft has released their own library. I've used M2Mqtt and OpenNetCF. One big thing is to make sure you have some type of heartbeat to make sure your client is connected.
Zero based indexing. lines[149] is the 150th element in the array.
Seems good. I just hope they keep the regular .NET build model of 1 exe/dll rather than the .NET Core model of 1 exe/dll + 100 plain text files that are all necessary for execution.
i like this
!remindme 6 hours
I will be messaging you on [**2019-05-06 22:41:05 UTC**](http://www.wolframalpha.com/input/?i=2019-05-06 22:41:05 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/csharp/comments/ble53t/introducing_net_5/emnppwu/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/csharp/comments/ble53t/introducing_net_5/emnppwu/]%0A%0ARemindMe! 6 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! emnpurc) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
That’s only for standalone core development, you can install the .net core runtime and not deploy standalone and still only get a few files
Is this also the successor of the 4.X .Net Framework as well?
You truly deserve your username. REST being way easier to implement AND consume, if there's no specific reason to use SOAP, why would you do it ? YOU pretended that REST was "random", "not clear". I said it's not the case. YOU ask "what is your point". My clear point is "REST is better than SOAP". kthxbye;
It's just .net core
Even better. Starting with .NET Core 3 you can compile the app into a single .exe that doesn't even need an installed Framework anymore.
Hold up, so all .NET is merging into one? I mean that is amazing, get rid of confusion, but is it like .NET Framework turning into .NET Core and .NET Standard being dropped and it just gets renamed to .NET?
Yes.
It just means the next .net core will be called .net 5, and there will be no .net framework.
Interesting read.
Could this be the death of the Framework and the rise of Core?
If it can't do 100% of Framework 4.x, then I agree with you.
I'll believe it when I see it.
It's probably more accurate to say they won't be adding anything new to .NET Framework Framework is absolutely fucking everywhere and it'll take years, if not decades, for it to fade out of use. I imagine it'll continue to get security updates for some time yet.
&gt;There will be just one .NET going forward, and you will be able to use it to target Windows, Linux, macOS, iOS, Android, tvOS, watchOS and WebAssembly and more. So, yes.
I hope so. The dll hell of. Net core 2x is real. Standalone publish has dozens of dlls in output folder. Ugly as hell.
Yeah. It's all merging into one. This is no doubt the ideal path going forward.
Yeah sort of. As new. Net core gets all the features minus all the crust of old. Net, it'll become the one and only. Net going forward.
Sounds like they are not sure themselves.
This will hopefully end the discussion on whether Net Framework will continue to be developed beyond fixing security and major bugs. RIP.
They didn’t say what happens to Standard, I would assume it continues to go on, but not sure. It’s slightly separate thing anyway. But .NET, .NET Core, Mono, Xamarin will all be rolled into one. All platforms will have same things available (from the base, I’m sure UI things are still separate so no WPF for Linux etc). Can choose which runtime to use (Mono and CoreCLR will become interchangeable). More AOT compilation options. Etc.
Long time coming, it’s here finally. I like the move, hope it pans out well!
There isn't really anything to agree with. It's just a summary of what the announcement says. There will only be one type of .net, and that type is .net core. They used 5 so that people didn't confuse ".net 4" with ".net framework 4", and They dropped the "core" because there will be no "framework" with the same number to confuse it with, so it's really just an announcement saying ".net core 4 will be called .net 5"
So they're basically dropping the .NET Core brand again.
.Net core was a parallel implementation to .Net that let them start some bits from scratch. They worked on the parallel implementation until it met and exceeded the functionality of the original implementation. Now, they're swapping out the original implementation for the new implementation. ".Net 5" is `(.Net Core 3)++`. Framework is a dead end. Evidence: &gt; From the inception of the .NET Core project, we’ve added around fifty thousand .NET Framework APIs to the platform. *.NET Core 3.0 closes much of the remaining capability gap with .NET Framework 4.8*, enabling Windows Forms, WPF and Entity Framework 6. (emphasis added) &gt; Everything you love about .NET Core will continue to exist ... &gt; Feel free to continue to use the “.NET Core” name if you prefer it. &gt; We’re in the process of making CoreCLR and Mono drop-in replacements for one another. We will make it as simple as a build switch to choose between the different runtime options.
The .NET Core 3 single .exe approach is only for distribution, it extracts the .dll hell onto the disk when you first run it...
Doesn’t mean they are killing framework as far as security and stability updates go.
WCF is something that we use a lot at work, for example, and which isn’t on core.
I’m interested to see how this will affect building GUI applications. Will that still be Windows only? Will they go the Java way of it just looking mediocre on every platform? Or will they use native UI controls (which would be so, so cool)?
If there is no distinction between Core and Framework (etc.) then you really don't need Standard anymore.
Not necessarily, but they have said they're not going to make large changes to Framework and that new stuff will be in Core.
I don't think the Standard is going anywhere, but Microsoft will only have two implementations of the Standard now: Mono and CoreCLR.
After total unification true, but before that we still might have libraries etc that target different versions for backward compatibility or something, so I wouldn’t rule out it still existing. Hopefully they will get rid of it at some point, but it might also be yet another break in platforms. Of course they can just make .NET Standard 5 under the hood and go with that. Have to wait and see.
Sure.
Yes, it's already in maintenance mode as of 4.8. I wouldn't be surprised if they released up to 4.8.2 and then stopped.
I can see why they do that .NET core kinda implied to me that it's a kinda limited version of the .NET framework for cross platform use. (as in "limited to it's core") Only figured out recently that it's literally the successor to Framework.
&gt; Feel free to continue to use the “.NET Core” name if you prefer it. This is the only line I disagree with. Standardize the name. I don't want to deal with .NET (.NET Core 5), .NET Core (.NET Core &lt;5), .NET, etc. I almost wish they'd just rename the whole works. No one confuses WinForms for WPF for UWP. They're easily identifiable. Just name the new thing going forward something new and be done with it. Otherwise I see confusion in our future.
Same here. Our plan is to migrate all that to WebAPI built on .NET core currently. Hopefully we'll be in a good spot to just change the target framework when .NET 5 is released and it won't be a big deal.
If everything that runs on Framework today runs on NET 5, then it's just an upgrade to Framework for all intents and purposes. If instead I have to do a massive rewrite, then Framework is dead from my perspective. *** As an analogy, we didn't say Windows ME "died" when Windows XP came out. To ME users it was just the next upgrade.
.NET Framework is old and drags a lot of useless, old stuff around. For example the hundreds of overload functions from the pre-Generic and pre-"params" era. .NET Core brought a breath of fresh air, extreme performance enhancements with Span&lt;T&gt; and Memory&lt;T&gt; as well as SSE/AVX intrinsics. At the same time it became platform-independent and runs everywhere. The result: (new) backends all run on .NET core and frontends continue to run on .NET framework with WPF or WinForms. As well as browser-frontends also again on .ASP.NET Core. And this is the most frequently asked question: How do I connect .NET Core backend with .NET Framework? Well, that was the end of 4.8 and Standard 2.0. It doesn't work anymore. .NET Core 3 and Framework 4.8 do not want this. This is frustrating. Microsoft had to act. .NET Framework would be a dead end. .NET Core is better. So what's needed is done: .NET 5.0 so Core+Framework back together. But not mentioned in the message is that Microsoft plans a WPF on OpenGL. This allows UI under Linux (but not Mac). WPF is the same, only the layer is abstracted on DirectX and then split on DX and OpenGL. .NET 6.0
[Then have a look.](https://devblogs.microsoft.com/dotnet/announcing-net-core-3-0-preview-5/)
Not killing. They've worked hard in recent years to make their cross-platform .NET both cross-platform _and_ support all the classic .NET Framework tools, which means it can essentially supersede it. MS are bringing their .NET Core work back into the mainline .NET world, instead of continuing to support what is perceived as `.NET Lite-Edition` as a separate product.
Installing .NET 3.5, .NET 4.x and .NET 5 side-by-side will surely aid the confusion.
There are more platforms than .NET and .NET Core.
This makes me so happy
&gt;There will be just one .NET going forward, and you will be able to use it to target Windows, Linux, macOS, iOS, Android, tvOS, watchOS and WebAssembly and more. Yes, i thought they said a while ago that this was the plan for .net core.
i eagerly await this.
That's why I wrote etc.
What do you mean? No matter what happens, cross-platform standardized .NET is the future no matter what they call it or which path they take, of course the framework will die - there's no question mark needed, that's a given
Does webapi support SOAP stuff and WS-*?
Sure but they even make security and stability updates without even changing the version number these days.
dotnet core and mono are merging according to the article. i think standard is being vb6'd
They should have named the new version 'dotnet' or '.NET Platform' instead of '.NET'. &amp;#x200B; Naming it '.NET' is going to confuse *everyone* when they attempt to search for articles and documentation. Imagine trying to find information on [ASP.NET](https://ASP.NET) 5.0...what kind of results will you get?
Why does this make "modern" stuff harder to recognize? There is no .NET 5 today.
Microsoft naming strikes again.
ish, in so far as that mono is an implementation of the 4.x framework and is being merged with core
&gt; It's probably more accurate to say they won't be adding anything new to .NET Framework iirc they said this as framework wont be getting c# 8 or onward
But we have .NET, and that is associated for decades with the "old" stuff. ".NET Core" was a modern branding. And what about ASP.NET Core and Entity Framework Core? Will they all drop the suffix as well? Or will they keep it? What about the versioning? Right now all three frameworks have a common version, which makes updating a lot easier. But we had ASP.NET 5 already (as a preview) and Entity Framework 5.
I'm new to C# and completely lost lol.
I’m looking forward to .Net NT.
&gt;If instead I have to do a massive rewrite, then Framework is dead from my perspective. since mono will be there i dont expect massive ones. granted vb6 still runs today so i assume the framework will run too
*at MS headquarter:* Mission accomplished! 🎉
they already announced that c# 8 wont be on the framework just core so i assume so
So when they say merging mono and core, do they mean that you can switch between whether to use mono or core on the fly, or they will be installed together and you still need to develop for one or the other? I feel like I didnt comprehend or they didnt explain it well.
framework 4.8 will still be there like vb6 is
No and no.
The version of core matters even more than the normal framework though. Something you find that applies to 2.0 might not apply to 2.1 or 2.2. You still have to look at WHEN the content was posted anyway especially if you are not including any version info in your query. I don't think this itself makes it any more difficult that it already is. I do agree they have (and have for a long time) some issues with unifying versions and things that lag a release cycle behind (SSRS for example). I think the only one that is a real issue might be ASP.NET 5... However EF version is just that, the version of EF. It isn't directly tied to the framework version. You already have mis-matches in the version number between .net 4.x and EF 5/6. The best thing is to start dropping all of the different names for things and moving toward unification. Sure it may be a little confusing at first; but lets be realistic. It isn't exactly clearer than mud now anyway.
No. They announced that some features of C# 8.0 won't work on .NET Framework.
Yes of course.
Search for Entity Framework 5. ;-)
&gt; You already have mis-matches in the version number between .net 4.x and EF 5/6. But they got rid of that in the .NET Core eco-system. .NET Core, ASP.NET Core, EF Core, all had a common versioning. &gt; The best thing is to start dropping all of the different names for things and moving toward unification. They did exactly that with .NET Core (ASP.NET Core, EF Core, PowerShell Core). And now they're rowing back again.
They only did that WITHIN Core. Core doesn't cover everything and was never going to. That is the bigger issue. You need to do this for everything not just inside of the "core eco-system".
Thought so ;).
The .NET Core eco-system was their best option for unification. Move more towards it and align it with the rest (e.g. PowerShell Core). They could have made the "Core" branding the beacon of modern frameworks and cross-platform support.
It also works wonderfully with Bitbucket. Because that's what I do. I use Team Explorer with my repo's remote pointed to Bitbucket.
So should I still be looking to learn .net core after I learn c# basics?
Currently in C#, you build your project either with the .Net Core or .Net Framework SDKs (there's several versions, with .Net Core 2.2 and .Net Framework 4.7 being the latest major versions). The primary difference between the two is that .net Core is touted to be faster and cross platform, where .net Framework is the original C# framework and is Windows only. Net Core is a relatively new venture into the open source world for C#, where NF was closed source. With the changes to Entity Framework Core (entity framework is a library for interfacing to databases), the guy who posted this is basically saying that the name change convolutes things, which I agree with. I wish they'd just stick to .Net Core since that's the path they've taken everyone down the past 3 years or so.
Yes.
Thank you :)
My preference is to have a unique row id for every table, at least in the beginning. In the case of many to many tables you don't really need one, but if your system can't handle that extra field you have bigger issues. It makes life easier when you're debugging and reconciling data, even if it's a few seconds saved hand writing some reconciliation SQL. &amp;#x200B; Metadata is really helpful when you're trying to solve production issues, so feel free to add keys, timestamps, basically anything that will help you fix the system if it goes wrong. You sort of get a feel for what's required after a while, and add more than you think you need rather than less. Performance isn't worth anything if the system doesn't work. &amp;#x200B; So in order 1) Not really, but it's better to start with one because it makes support easier. 2) Supporting and continued development. 3) Yes. The link table is just two foreign keys.
The real Endgame right here.
&gt; If anyone is wondering, "Why on earth do you have several hundred repos?" Not at all strange. I have half that many on my personal github account so I'm not surprised a company would have even more! Side note - does TFS-git support folder organization of git repos? We're using TFVC and group our solutions (which I imagine would be individual repos) by e.g. "ETL", "Web", etc.
They're now the same thing. &gt; msysGit has been superseded by Git for Windows 2.x https://github.com/msysgit/msysgit
It will. This clearly means it won't be continued, and instead .NET Core will be the only framework (and will be renamed).
I think is the other way around. Now it just will be .net 5. Entitity framework I expect it will have its own version upgrade/merge.
Be prepared to have one hell of a time making SO issues for new framework things that won't be marked as duplicates of older non-applicable (but similar) questions...
I always add an id column because this makes handling the cross table easier in an oo environment. But there can be other reasons to. The cross table will often be promoted to an entity table by adding extra information like 'inserted by' which in this case would hold a reference to the user that inserted the row in the database . Also there can be situations where inserting multiple rows with the same values can be a valid use case (actor plays multiple roles in the same movie) but two rows with exactly the same value are theoretically the same as one row with those values. Introducing an id column solves that issue.
4/2 is not a number.
How do i fix this?
They appear to be killing significant parts of .NET Framework: * WebForms * WCF (server half) * WCF named pipes (is there a named pipes impl in general?) * Diagnostic event channels * CAS * a number of AppDomain features * System.CodeDom compilation * Remoting I don't know that any of that is a bad thing (maybe the CodeDom bit sucks, there is an open issue for it).
You'll need an expression parser/evaluator, there are some of them in github.
Are passive aggressive commit messages useful? I hope they are, because I do it all the damn time. Also, expletives.
Can u give an link
You're trying to parse expressions with methods that only know how to handle specifically formatted numbers as inputs. You need to either [write an equation parser](https://medium.com/@CantabileApp/writing-a-simple-math-expression-engine-in-c-d414de18d4ce) or split your inputs appropriately. You are already doing this by splitting `^` - you can do the same with `/`.
&gt; For example the hundreds of overload functions from the pre-Generic and pre-"params" era. Almost all of those are still around aren't they? I mean [`ArrayList`](https://github.com/dotnet/coreclr/blob/master/src/System.Private.CoreLib/shared/System/Collections/ArrayList.cs) still exists, as do `IList` and `IEnumerable`...
You've literally found used one potential solution in the way you split your x^y. Be careful with your operators, &amp; is a bitwise AND, you probably meant to use &amp;&amp;.
I kinda agree with almost all of this, but I think they should skip version 5 as well and go straight to .NET 6.
Mono and Xamarin are also discussed in the article
&gt; But not mentioned in the message is that Microsoft plans a WPF on OpenGL. This allows UI under Linux (but not Mac). WPF is the same, only the layer is abstracted on DirectX and then split on DX and OpenGL. .NET 6.0 What is the source for this?
Minor thing: .NET Framework 4.8 came out a couple of weeks ago
It caused more confusion than anything else (especially in the PowerShell realm)
Tell that to the people clinging to Windows 7 as it's about to lose official support.
&gt; 3.5 Wtf
Standard (Framework) is not going to get any further major updates, it won't even get many of the C# 8 language features. It is essentially obsolete, which sucks because there are areas of functionality not supported by Core yet (distributed transactions, WCF servers and more).
&gt; At startup, it copies all dependencies to a temp directory, and loads them for there. It only needs to unpack dependencies once. After that, startup is fast, without any penalty. That doesn't sound like a single executable. It sounds like packaging system that may or may not be housing dlls from one or more .net apps in a common .net framework "temp" location?
Right, and all of the things that seem to not work in .Net core in Active Directory environments and Windows systems...all still there, and supported in .Net 5? Alternatively...is this sort of stuff considered bloat for Linux applications that don't need those libraries? I'm curious about what their solution will look like.
You can use set them via another instance from dbcontext which got them in constructor.
[They plan to improve a bit on that in the future](https://github.com/dotnet/designs/blob/master/accepted/single-file/staging.md#2-run-from-bundle-msil) in that managed DLLs will not have to be extracted.
Stephen Taub from Microsoft WPF group mentioned it somewhere, can't find it right now... on mobile.
&gt; Zero based indexing. lines\[149\] is the 150th element in the array. Yes, true. No need to downvote me. What is the highest value `number` can have in `int number = rnd.Next(0, 150);` ?
To be fair though, they'll likely be searching for .NET 5.0 (rather than 4x). Hopefully MS gets its SEO monkeys in shape for this.
except for all the churn w/t .netstandard. Phasing all of that shit out should be fun for the OSS community.
Except it wasn't, not really. Core was (is) such a subset of the whole framework.
What do they mean by this: &gt;Java interoperability will be available on all platforms. Native support? Is this a new feature?
For the 0.100th time.
"Microsoft announces .NET is being rebranded to MS Oracle Java"
It pleases me too but I'm not holding my breath. This sounds too good to be true. Either the language will change so radically that it looks nothing like .NET 4, or this is a major exaggeration and they are missing a dozen asterisks.
Google - "Did you mean Entity Framework Core?"
Maintaining a robust, well-documented Standard is just as important as ever. .NET has decades ahead of it, and this new unified model will not, and should not, survive till the end. We can't abandon such a healthy API just because the ecosystem is coverging *now*.
150. An array with 150 elements (its length property) will throw a System.IndexOutOfRangeException if you try to access array[150]. The last element is located at array[149] because the first element is at array[0]. This is why the range for Random.Next(int, int) is 0 to 149 (array.Length - 1) above. Posts and comments get downvoted when they are inaccurate.
Per your logic you should downvote your comment then. The highest number is 149. 150 is the maxValue which is the **exclusive** upper bound. See [https://docs.microsoft.com/en-us/dotnet/api/system.random.next](https://docs.microsoft.com/en-us/dotnet/api/system.random.next?view=netframework-4.8)
then maybe stay 100% csharp :) https://nuke.build
This is the only thing that really caught my eye in the article. How exactly are they going to call Java from C# (and they claim vice-versa in the comments). The best I could find is [https://github.com/dotnet/core/issues/766](https://github.com/dotnet/core/issues/766). Maybe the two virtual machines pin references and pass those between each other until the function call is done? Or just copy by value the whole thing? Are they going the IKVM route and implementing a JVM that runs inside the CLR?
Welcome to .NET /C# !
Windows 10#
ah another case of damned if you do and damned if you dont
First there was dotnet framework, that's currently at version 4. Then they released dotnet core, currently at version 2, which is multiplatform and more "focused" than framework which was more "everything and the kitchen sink". Now it sounds like they're abandoning framework and letting core take over the whole thing, but to avoid number confusion they're skipping from 2 to 5
the news is so big but the noobs in this sub whining about confusion and stuff lmfao
&gt; There will be just one .NET .NET vHighlander. I can't wait for the fight scenes.
Is it supposed to be actually secure or just for show?
Not really. They just name the next release of core .NET 5. Well played Satya. Finally .NET will no longer be the but of the joke.
 EF Core becomes EF 7. EF 6 is good but mot the migrations.
Just stick with Core. Don’t worry about the old stuff it’s fading away. Thank god !
Deprecation between major versions is a pretty common thing in most of software engineering. Microsoft rarely does it, but I wouldn't make the argument that it's not true .NET 5 because they're removing some things. .NET 4.x will be supported for a long time to come for legacy customers.
Yeah, well, i hope they have good plans for that. I personaly mostly use .NET for Deskop and Game Development. I'm not doing web dev right now. .NET for game development is really good but could be better. It is lacking better support for game consoles. But I guess that is for the Community to implement. But better AOT support is a must.
Gotta love those 20MB "Hello World" Programs :D
I've seen banks that are still running XP. It's all relative.
After 3, before 4
Until you compile, and notice the messed up output.
&gt; I mean ArrayList still exists I freaking hope so...
\*Laughs in Mono\*
&gt; are you kids still using windows forms? Yup. Unless you want to convert 14 million lines?
Yes, this is going to make a lot of people very bitter. I know I'll still be writing code for .NET Framework 4.8 for the next few years, and missing out on all the new .NET 5+ stuff...
Why not return their permissions level when they login? Then based on that restrict the users options.. that's very basic stuff especially if you're going to be creating and managing users on the table side manually.
Whatever about being the butt of the joke, it's always been the best platform for development. If they could tool out vs for Mac as well as its Windows counterpart, it would be ground breaking
You sound *incredibly* mature and fun to be around.
It's the bits they're taking from mono. Mono already had to do at least some of that for Android / xamarin... That's why swift is on that same list.
They specifically denied this every time they were asked. It's specifically listed as a non- goal for wpf
You need to show us the code...
namespace EqFis_Proyecto { class Program { static void Main(string[] args) { double x1, x2, x3, a11, a12, a13, a21, a22, a23, a31, a32, a33, v1, v2, v3, p, lng2, lng3, g1, g2, g3, lng1, R, T; //Datos Iniciales x1 = .3;//mol acetona x2 = .3;//mol 2-butanona x3 =4;//mol etil-acetato p = 20.0;//atm a11 = 0; a12 = 1371.31; a13 = -292.975; a21 = -650.152; a22 = a11; a33 = a11; a23 = -405.21; a31 = 644.481; a32 = 2704.427; v1 = 73.52;//ml/mol v2 = 89.57;//ml/mol v3 = 97.79;//ml/mol R = 8.31147; T = 300; //Datos Criticos //Acetona (1) double tc1, pc1, w1, vc1, zc1; tc1 = 508.2;//K w1 = .307; pc1 = 47.01;//bar zc1 = 0.233; vc1 = 209;//cm3 mol-1 //2-butanona (2) double tc2, pc2, w2, vc2, zc2; //etil-acetato (3) double tc3, pc3, w3, vc3, zc3; tc3 = //Wilson: double al11, al12, al13, al21, al22, al23, al31, al32, al33; al11 = v1 * Math.Exp(-a11 / (R * T)) / v1; al12 = v2 * Math.Exp(-a12 / (R * T)) / v1; al13 = v3 * Math.Exp(-a13 / (R * T)) / v1; al21 = v1 * Math.Exp(-a21 / (R * T)) / v2; al22 = v2 * Math.Exp(-a22 / (R * T)) / v2; al23 = v3 * Math.Exp(-a23 / (R * T)) / v2; al31 = v1 * Math.Exp(-a31 / (R * T)) / v3; al32 = v2 * Math.Exp(-a32 / (R * T)) / v3; al33 = v3 * Math.Exp(-a33 / (R * T)) / v3; lng1 = 1 - Math.Log(x1 * al11 + x2 * al12 + x3 * al13) - x1 * al11 / (x1 + x2 * al12 + x3 * al13) - x2 * al21 / (x1 * al21 + x2 + x3 * al23) - x3 * al31 / (x1 * al31 + x2 * al32 + x3); lng2 = 1 - Math.Log(x1 * al21 + x2 * al22 + x3 * al23) - x1 * al12 / (x1 + x2 * al12 + x3 * al13) - x2 * al22 / (x1 * al21 + x2 + x3 * al23) - x3 * al32 / (x1 * al31 + x2 * al32 + x3); lng3 = 1 - Math.Log(x1 * al31 + x2 * al32 + x3 * al33) - x1 * al13 / (x1 + x2 * al12 + x3 * al13) - x2 * al23 / (x1 * al21 + x2 + x3 * al23) - x3 * al33 / (x1 * al31 + x2 * al32 + x3); g1 = Math.Exp(lng1); g2 = Math.Exp(lng2); g3 = Math.Exp(lng3); double ad; } } }
You have tc3 = Then nothing and start a new line.
Oh, wow that actually fixed it, I don’t understand why that would break it :/, I was planning to fill that later I didn’t think it would give me an error on the rest of the code
It cant parse the next few lines if it has an error on that scope. This might work if the unfinished bit was in a function, but within a given scope if there is one error it wont be able to reason about the rest of the code
Does it matter? Who's hanging out in their publish dir looking for beautiful art :)
No mention of aot compiling .net core web apps :(
Yes, but .NET 5 doesn’t replace UWP and Unity (best as I can tell), both of which are explicitly covered in .NET Standard.
Well your OpenFileDialog is simply obtaining the path to the file. Make your action function take a parameter for the path to the file and pass SelectedFile.Text to it.
I don't think .Net Standard is going away. Other companies/group could still provide other framework/runtime implementations that target exotic systems or offer alternative implementations of the core services (e.g. GC). It just means Microsoft will only work on one implementation going forward instead of splitting their team.
&gt; it's always been the best platform for development Wholeheartedly disagree. Prior to .NET Core, I loved C# as a language but wouldn't touch .NET with a 10 foot pole. Being limited to windows and having to deal with trash like IIS. However .NET Core is by far the best platform I've had the pleasure of using.
Yeah. I never understood the scare about having multiple dlls.
Will it be proper to save the file path to a global variable then? I'm just learning C-Sharp and coming from python (never done GUI before) so using globals unless strictly necessary is kind of frowned upon.
Glad to see .NET Framework dying finally. I'm not sure if I like the idea of dropping "Core" from .NET Core. It will make things harder to search. Currently if I specifically search for .net core, I get much more relevant results. I suppose things will improve over time as more .NET "5"Q&amp;A's appear. &amp;#x200B; I also find it odd that they are planning a major version release every year. Doesn't a major version imply there are breaking changes? Why do we need major releases every year?
#How to make a Hello World program a general end-user can double click on in Visual Studio 2019! ## .NET (Total size: 4KB, Total files: 1) 1.) F5 ##.NET Core (Total size: 58MB, Total files: 226) 1.) F5 2.) Navigate to the folder 3.) Navigate 3 folders up 4.) Copy the path 5.) Open a new command-line window, and navigate to the path you have pasted 6.) Paste "dotnet publish -c Release -r win10-x64" (You will need to memorize this)
I am hahaah. I like minimalism :)
Why? That type is completely useless and less efficient than its generic counterpart. I for one wished they would drop all the obsolete .net 1 types.
Hey, wait till they are using npm modules ;)
Good point. The confusion though might hurt adoption. Tough call.
I just checked - A .NET Core Hello World exe is 58MB and 226 files. The same in regular .NET is 4KB and 1 file.
Although that is because full framework is part of the OS.
.
Minor point, they are skipping from 3 to 5. .NET Core 3 is still planned for release later this year.
Yup - And that's why it's part of the OS. It wasn't before.
I agree with the version switch after dealing with angularjs vs angular search problem .
This comment contains no suggestions, only a heartfelt "thank you" to the OP: I've been looking for a simple, easy-to-open extension to Visual Studio that would open a Git Bash terminal to the project I'm currently working on \*forever\*, and the link you gave was \_exactly\_ what I've been looking for! THANK YOU!
&gt;What about Entity Framework Core? This all just seems to be without a clear path. Just like variables, naming can be hard, even at the product level.
It's the same direction Microsoft is taking overall. From what I hear there will be just Windows once the new OS drops. Regardless, I'm excited about that
IIS is the most used webserver in the world. What the hell are you talking about?
Reasonably secure.
Yes. What I am hoping for is recommendations to libraries that do most the work for me. Why reinvent the wheel?
First of all, apache and nginx are have far greater market share on public websites. Secondly, just because its popular, doesn't mean its the best. If your developing for .NET, you don't have a choice to use anything other than IIS.
IIS dwarfs Apache/Nginx overall https://www.comparitech.com/net-admin/iis-vs-apache/ You do get options other than IIS since ASP.NET moved to OWIN - you can host on any platform that supports that tech
Standard != Framework
 Does this mean that we will be able to bundle up a Windows desktop app and release it cross-platform to Linux or macOS and iOS? Very much doubt so...
other people: &gt; wtf no cross platform UI yet except winforms has been cross platform for over a decade. it's got that going for it.
It's (kind of) annoying for few odd internal applications that don't have the full installer pack / update package that are just stored on a server share drive for people to drag and drop onto their computer.
is this asp mvc? then look into making a class that inherits from AuthorizeAttribute then put a few roles like public, admin, etc then add it as an attribute on your C# controllers https://stackoverflow.com/questions/8829685/creating-a-authorizeattribute-what-do-i-need-to-know
Legacy is a real thing that exists. Not all businesses are 5 year old startups.
The variable doesn't need to be global, it just needs to be within the scope of both of the buttons, so on the same page / form possibly?
To expand a bit on this... This is the behavior for a "Self Contained" build. (AKA "Include the runtime for platform(s) specified in .csproj") Default behavior gives a 4608 byte file: https://i.imgur.com/oQxScqZ.png Specifying platform(s) in the csproj will cause the cli to produce self-contained build(s) for specified platform(s). It's just a default, assuming the deployment target has no runtime installed. This will result in the huge build. To get back to the minimal/runtime-free build, `--self-contained=false` (or whatever UI equivalent) is needed: https://i.imgur.com/uxrjvlF.png The difference between these two builds is `&lt;RuntimeIdentifier&gt;win-x64&lt;/RuntimeIdentifier&gt;` added to the csproj, and the highlighted cli parameter.
If I had to guess, more officially supported libraries from Microsoft maintainers.
By default, yes. https://www.reddit.com/r/csharp/comments/ble53t/introducing_net_5/emp5ibr/
Only ASP.NET Web API supports OWIN. Not a lot of choice.
And that will not change. .NET 5 will be a subset of the whole framework as well. They announced that no additional libraries from the .NET Framework will be ported (like WCF Server).
But we had EF 7 already. They announced the rename of EF7 to EFCore.. just to go back now.
They announced that no additional .NET API will be ported to .NET.
They announced that no additional .NET API will be ported to .NET, so there will be no WCF support on .NET.
No, it does not mean this at all.
Nope. The real successor is Super .Net Framework 2.0 Championship Edition.
A private variable in the same code as the form will do
When I'm stuck with slow computer that can't run VS well or having to use someone else computer to code, I usually spin up a cloud VM with VS. Depending on the pricing and if this can be hosted on premise, this could be my option in the future.
WCF on .Net Core is being developed more like an external library than being included in the framework itself. For the release which coincides with .Net Core 3.0, we're adding support for transport security with message credentials which includes WSHttpBinding for example. We're still porting more of WCF and will continue to do so.
After some rather confused investigation, it turns out that `--self-contained=false` was only introduced with .NET Core 2.2. A fully updated VS2019 comes standard with .NET Core 2.1, so this option is not available to users who don't subsequently download the SDK. Seems that VS2019 should update to 2.2 (Seeing as how it was released 7 months ago), and include this option in a nice dropdown menu somewhere :p
I'm trying 🤣
This... does put a smile on my face.
For all intents and purposes DNC 3+ is .NET 5.
.NET Framework, .NET Core, Xamarin and Mono all will be unified in **.NET 5**. Finally, the pain of fragmentation will go away!!
Source?
https://github.com/dotnet/wcf is the repo. Oh, and I'm the lead developer for WCF so I guess I'm the source :)
Aha ! Thanks for that info, didn't realize it was so new. I'd assumed the difference was VS including runtime identifier whatnot in new csproj files, making the bulky builds "default." (Which, after a quick check, is not the case.) TIL !
Would it kill them to embed the library and json file into the binary if you specified a Windows build so you still have 1 file? :p
What the hell is step 1-4? Are you a caveman? Don't you know how to shift+right click?
1 - Making sure it builds (Alternatively Control+Shift+B) 2 -&gt; 4 - Making sure you're at the correct location. If you simply right-click the .cs file and go "Open Containing Folder", you will be at the location of the .csproj, whilst the "dotnet publish" command requires you to be in the .sln folder for the default version of .NET Core installed with Visual Studio 2019.
I'm excited and terrified all at the same time.
Lol, indeed. Looking forward to those 3.0+ improvements for sure.
MS provides some authentication services included in Razor/MVC. You can start here: https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity?view=aspnetcore-2.2&amp;tabs=netcore-cli
ROFL - I didn't even read the 3.0 change notes when making those posts :p &gt; Default executables .NET Core now builds framework-dependent executables by default. This behavior is new for applications that use a globally installed version of .NET Core. Previously, only self-contained deployments would produce an executable. See - THIS is the stuff that will make the change seamless. It's the nuances that were introduced that severely annoyed people like myself and prevented the migration. VS made C# dev a breeze, and .NET Core messed everything up with having to walk through half a dozen hoops to end off with a worse result. I can deal with binaries being an extra 100kb or so - It's the excess command-line-only post-build compilation options and chance of missing files that was the annoying part.
THIIIIIS
&gt; But we had EF 7 already Not really, no. Google certainly isn't going to be confusing with the tiny amount of content out there referencing an EF 7 that never actually existed.
&gt; Ease of use for both the end-user and the developer. lol, how quickly everyone forgets why it was separated from the damn OS in the first place. Ease of use. Yeah right. I guess you never dealt with incompatibilities from .Net runtimes not being able to run side by side, aside from 2/4.
&gt; it turns out that --self-contained=false was only introduced with .NET Core 2.2 Maybe literally the command line switch. Otherwise you do it in the project file. I've been building non-self-contained .Net apps since Core v1.
They're wrong. This whole thread is full of misinformation.
&gt; does TFS-git support folder organization of git repos? Kind of, but it isn't as flexible as the TFVC folder structure. We use on-premises ADOS. I'd imagine cloud-based is almost the same, but I haven't used it in a few years. At the top level in the server is a list of collections. A few of our collections are archives of old TFS repos containing git or TFVC code from back when it was a huge pain to upgrade to newer versions of TFS/ADOS. Along with those are our primary collection and a few others. Inside each collection is a list of projects that group code and backlogs based on similar sections of the business. Each project has its own set of git repos. So you can have two layers (collection and project) that are kind-of like a folder structure with the repos underneath. We used to use TFVC and had a similar grouping that you use. When we switched to git, we broke them up by those groupings, and some of them ended up in git repos in different projects. I do not think any software engineers at our company would want to go back to TFVC now that we've switched to git, but that folder structure sure would be nice to have again. Build and release definitions in ADOS have them, but repos still do not. :(
Maybe I'm misunderstanding /u/Reelix, but I believe they're just flat out wrong. I've been building and deploying non-self-contained .Net Core apps since v1. (e.g. https://www.hanselman.com/blog/SelfcontainedNETCoreApplications.aspx) There seems to be some MS haters filling this thread with FUD and BS.
Shit I will be very happy if this means that in Unity I won't have to deal with Mono and Net incompatibilities when building for multiplatform including UWP.
We will be able to run asp.net on Android
Only one file to make sure is updated.
Why have two though?
But, they're getting all the stuff that doesn't work in core that does work in mono to work in core. Which should be everything you'd see most codebases and make migrating a framework project in easy
But everything from mono that isn't in dotnet core will be added. Which should make it easy.
What are you all talking about? Getting to run on the mono framework covers most legacy code. Removing the feature gap between dotNet core and mono does the same. Meaning much better portability of framework apps to dotNet 5
No it's getting all the crust. Mono implements a 4.x dotNet, which is merging with core. I would have actually expected a layer above that would have routed calls as expected, but this is interesting too
You’re right. Not sure why I was thinking the second value was inclusive. Gah. Unsettling to think I may have made that mistake in my code over the years.
Agreed. I wasn't sure if I'd be picking a runtime (mono or core), there would be a merged runtime, or if a new runtime will replace framework, core, and Xamarin current runtime
Somehow, as cool as this sounds, I don't think you'll be that kind of happy though I'd love to be wrong
This is more like framework embracing and extending core though. All that mono code merging in to implement 4.x in cross platform fashion
As a Sysadmin, dealing with the .NET Framework was not a fun experience.....
Last i read they even said they would reject PRs making wpf cross platform when they open sourced it, so really need a source on that one
1 - Press windows key 2 - Type "Calculator" Now you have a calculator to calculate numbers!
I've said this before, but it bears repeating. Microsoft would be better off if they dropped the entire marketing team and replaced it with a bunch of orangutans. Plus we'll be giving orangutans a fighting chance for survival from extinction by giving them gainful employment.
Maybe they did that already. It would certainly explain this decision.
Everything? I heavily doubt that .NET ..5.. will get AppDomain support and remoting.
There's an official blog post on the rename from EF 7 to EF Core. Now renaming EF Core to EF7 again would just be sill and confusing.
Technically nothing will change for them. It will just be a **lot** harder to explain the difference between .NET and .NET.
The .NET 5 announcement, while furiously shaking my head in disbelief.
".NET Core is the future!" also other post: "In the future there will be no .NET Core, only .NET!"
Reading: C# in Depth (4th Edition) by Jon Skeet SOA Patterns by Anton Rotem-Gal-Oz Watching: Application Instrumentation using Performance Counters by Jim Christopher on PluralSight
Lol, but true same here!
You disagree people should be free to still call it ".NET Core" if they prefer it? How do you want to take that freedom away?
My understanding is that the windows UI stuff is still just for windows. You'd need to use gtk# or something like that for a cross platform UI.
What's wrong with that? Sadly I don't have time to check out the entire announcement atm.
In the first versions of .NET Core (or just previwe? Not sure) they actually did drop a lot of legacy stuff. But too many people complained about it, so they added it back inside.
Microsoft successfully established the .NET Core brand, and now they announced that they will drop it again. They will rename the next .NET Core version after 3.0.0 to .NET 5, then release a new major version every year (.NET 6, .NET 7, .NET 8, .. probably skip .NET 9, .NET 10, ...), while adopting the NodeJS support schema (every even numbered version is a LTS version). Simultaneously they wrote in another post that ".NET Core is the future". I'm honestly getting tired of the constant renaming at Microsofts. They did not mention what happens with ASP.NET Core and Entity Framework Core.
&gt; Last i read they even said they would reject PRs making wpf cross platform when they open sourced it Which makes perfect sense. They'd need to support and maintain that version, which they have no interest in.
Droping "Core" name is one of the greatest fuckups MS is going to commit, wtf!!!
Because Core is associated with modernity of .NET
Sooooooo.... This is how Linux gets infected??
No problem. It's one of my lists of silly shitty mistakes one (I) can make with C#. Another one is the difference between `TimeSpan.Milliseconds` and `TimeSpan.FromMilliseconds` or That `Math.Round()` uses MidpointRounding.ToEven as default (aka "Banker's rounding). `Assert.AreEqual(1.13M, decimal.Round(1.125M, 2));` fails therefore.
"Hands-On Full-Stack Web Development with ASP.NET Core"
do you have any examples for this heartbeat? im not sure what you mean
Fast Visual Studio avaliable from browser even on shitty laptop is the dream as long as everything works as good as it does on desktop
Oh Really..? I missed that. Don't follow EF to closely to be honest. But just shows you how quick they can change names.. they've done it a few times no.. keep calm and carry on writing code :)
Not sure how much back context you have but for my self I started writing code before .NET and before C# - We were not getting a lot of love back then. It was different times, for sure... but the hate was flowing towards Microsoft..
&gt; keep calm and carry on writing code :) Honestly, these announcements make me feel like I want to move on to another eco-system. I've had a hard enough time to explain several times to various people why switching from .NET to .NET Core was a good decision. *Soon* I will have to explain why we need to switch from .NET Core back to .NET again.
Why do you need this? What problem are you trying to solve with this?
Users can write SQLs to perform tests on their tables and they save these SQLs for each test. I want to find out what tables and columns are covered in these tests.
Is the size difference really that much?
&gt; Feel free to continue to use the “.NET Core” name if you prefer it. Makes it sound like they're encouraging having multiple names for the same thing, which will only end up confusing people. I hope it doesn't turn into angular where there are multiple very similar names and I get confused as shit whenever I need to talk about it.
Your Singleton example is invalid. The return statement is outside of the getter implementation.
Thanks, fixed
thanks!
If file size **and** double click is so important to you, then you should just add a goddamn bat file.
It's not only legacy code ! Legacy code can be migrated. The problem is legacy *features*. We were very happy with `System.Reflection.Emit` in .NET Framework, but .NET Core doesn't support it properly and has no acceptable equivalent for our use case.
Will that work in community edition?
&gt; But Bill Gates was doing what he had to do.. very similar (but not as unfortunate) as Steve Jobs had to do, to get the business going. That doesn't explain why Microsoft spent untold amounts of advertising on tech sites that often were very anti-MS, while the guy who spent his entire life running the biggest ASP mailing lists site (the equivalent of StackExchange) had to beg for scraps.
Is it not important to you?
People will be bitter **because** nothing changes for them.
Good to see Unity mentioned a couple of times in there. Xamarin and Unity combined in one app is something I'd like to play with (not that sharing the same .Net is the only hurdle to that but it's a start).
Single abstraction for all requests allowing you to chain one or more decorators around any request. Some examples * Request logging * Authorisation * Caching * Audit logging * Error handling * Enhancing a request or response with extra data. If you want to log all requests that take more than say 300ms with a warning message you can do so with a single decorator. FYI You don't need mediatr for this(go read the source code). While not increadibly powerful compared to other solutions it also allows sending events that can have n handlers, e.g. Sending an sms and email notification when someonething happens.
Jumping to 5 just makes people confused too.
Turn on statistics to get the execution plan in XML format. Explanation and great example here: https://stackoverflow.com/a/25880171
.NET is 4KB because all the referenced libraries are pre-installed.
Right. Well you won’t be switching and you don’t have to explain that later. Switching from .net45 land to core was and is the best thing to do. No doubt about that. Performance and cross platform hand down the best reasons. The next version of “core” Will probably just be called .net 5. And it will be as easy as installing a side by side sdk as you are doing with core now. You won’t have to go through all the pain of explaining and refactoring code again. It all makes sense now really why they invested so heavily into side by side SDK’s - I always wondered what the point was from when it was called dot net next in alpha.
I've seen *people* run XP.
This is the worst thing about SO. It ages poorly. You end with answers that aren't relevant / correct killing off new ones.
Because Gates was a corporate closed minded greedy git. He got business booming for MS at the cost of the guys like the guy from the mailing list. It is why Joel Spolsky left, rage quitted actually. He went out to prove Gates needed to change or leave. Gates He would never have achieved this. And his successor Balmer was closely overlooked by Gates too. That’s why he was an epic fail too. Satya cut loose from Gates and rightly so.
I was thinking this too, I have some network admins who are smart enough about application side of the house to know we use [asp.net](https://asp.net) / Microsoft ".net" framework. And if they were more enterprising individuals (Typical Government Employees) they would update for security etc. reason to latest and greatest not realizing .NET 5 isn't upgrade to 3x/4.x frameworks.
Won't mobile and game consoles still require mono?
Yikes! I was reading about that last part in an article fairly recently... Yeah, name refactoring is not always the best approach to product branding.
Thanks, i'll look into making a fire and forget solution.
I imagine we'll see more than this and we'll see some of Xamarins "framework shrinking" tech ending up on netcore5 - the equivalent of javascript tree-shaking but for compiled applications.
I don't think that is what he was suggesting. I may be putting words in her/his mouth, but I read their comment as suggesting that Microsoft should 'take the lead' and call it what *they* think it should be called. This way, it helps to avoid confusion. If you leave something like the *name* of the framework open to individual personal preferences, people will have a hard time communicating what framework they are referring to (netfx, netstandard, netcore, net5, etc.) For example, once NET5 is an actual thing, I will interpret ".NET Core" to mean "legacy" .NET Core (v1 to v3). This problem will go away after some time has passed regardless, but people referring to NET5 as .NET Core will only serve to cause confusion around the the time NET5 is released. Personally, I believe that .NET Core and .NET Standard are going away as target frameworks (or rather, no new versions) and .NET Framework will again be the only real framework for most of us. It'll just be cross-platform now, among other significant changes. Ultimately, people are gonna call NET5 whatever they want to call it, but I think we will all eventually refer to it simply as "the .NET Framework".
They won't reach feature parity for a while because they were designed for different uses. Example: Mono is the runtime that fully supports AOT, which is required by iOS, webASM, and some game consoles. CoreCLR does not have the same level of AOT support.
I like this, but not without some disappointment. I wish they had went this direction to begin with to make things simpler and easy to understand. As an aside, does this mean things like WCF and a complete MEF implementation are going to be in NET5? Or have I missed something and both of those are already in/coming to .NET Standard/Core?
&gt;[...] is it like .NET Framework turning into .NET Core [...] Seems to me more like the classic .NET Framework is just going to stay put, and everybody **else** is merging into one. Classic .NET Framework is a minefield of compatibility concerns. To give an example of what this means, I spent an hour or so trying out `netcoreapp3.0` with our &gt;10-year-old WPF application. One thing I stumbled into was that we had a line that was checking a property type for a method named "Parse" using reflection. It happens to only matter for `System.Boolean`. - In `net472`, `System.Boolean` has just one method with that name: `System.Boolean.Parse(System.String)` - In `netcoreapp3.0`, there are two: that one and `System.Boolean.Parse(System.ReadOnlySpan&lt;System.Char&gt;)`. So in `net472`, we can (and did) get away with just looking for the one method named "Parse", but that same line throws an exception in `netcoreapp3.0`. Knowingly or not, the developer who wrote that line signed up for exactly this kind of error to happen if `System.Boolean` ever got another overload for "Parse", and I happily made the necessary code change to allow my experiment to continue. The reason why it's .NET Framework's problem is because .NET Framework has a policy of in-place upgrades. If some future version of the .NET Framework took the changes needed to implement `netstandard2.1`, then all it would take to break our application would be someone installing that newer .NET Framework version, or (worse) updating Windows to whichever version bundles that newer .NET Framework version. - **SOME** incompatibilities have been made opt-in / opt-out at the application level, but it seems highly unlikely that this would ever be one of them. Though, I might add, not strictly impossible... The solution seems to be, and was probably always intended to be, to leave that baggage behind for the sake of making a delightful experience for people moving forward.
I'm from Croatia (we have our own special chars like čćšđž) and we never use them in project/file names just because of situations like this - you never know when will MSBuild or any other tool included in build chain stop working or break in spectacular ways if they get a char that isn't ASCII....
Is your service doing work every 1 minute using a System.Threading.Timer? It's a little tricky, but I would implement a timer sets an AutoResetEvent "idleEvent" to say when the current iteration has completed. Then, when you detect the service is shutting down, call Dispose on the Timer, and wait for the flag to be set, like this: public bool Stop(HostControl control) { timer.Dispose(); while (!idleEvent.WaitOne(2000)) { log.Info("Waiting to stop"); if (timer.Elapsed.TotalMinutes &gt; 5.0) { log.Warn("Terminating service"); break; } control.RequestAdditionalTime(TimeSpan.FromSeconds(2.0)); } } Hope that helps get you started
That's for client side though. I believe most people are talking server side support?
I'm running into this issue as well. Any luck with solving it, not by refactoring the Stored Proc (Not an option in my situation). &amp;#x200B; Thank you!
Now so will .NET 5, and .NET 6, etc, etc. This changes nothing honestly in terms of what is the most current.
if WPF really works with .Net-Core on all operating systems, yes, .Net-Core is the future and i will be happy to make all my Java-Applications with .Net-Core applications and probably will never use java again. Please push this microsoft, please!
Check out [C# reference docs](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/access-modifiers)! I Urge you to open up your IDE of choice and play around with access modifiers, you're panicking and overthinking things. Write a quick class that just returns values and give things different accessibility modifiers. your logic is currently flawed(and i hope to god that's not the books definition because it's wrong) but some quick experimentation should let you test your theories. Sorry for being vague but i hate 'giving' answers in this scenario, you aren't going to learn if i just give you something to regurgitate. And a quick hint if your stuck; make a public interface or class and then when you inherit from it, implement the method as private or protected to trigger the inconsistent accessibility error.
&gt;idleEvent Thank you very much for ur replaying, a very good answer, am noob in C#, so i have read on some of the techniques you used gust right now ( Dispose , idleEvent ) where should the idelEvent wrote , i mean from microsoft docs its something like this :- public static event EventHandler Idle; how i will use this ? should i use it on the start method ? and what will be set to ? please help me , am very gratful for ur help and for sorry for my dumb questions am noob to c# Thank u very much and how i
Why? if it's the _only_ .NET, why would it need the qualifier "Core" ?
Would .NET Core 4 be less confusing? I don't think so, there's already a .NET 4. When Core is the only .NET, how would that numbering work?
So the best way to understand this is through example probably. First things first, understand the accessibility levels: 1. Public: All other classes can use this function / class / property 2. Internal: All classes within my same assembly can use this function / class / property 3. Protected: Only derived classes can use this function / class / property 4. Private: Only the containing class can use this function / class / property So, to understand _why_ you get compiler errors, let's come up with a contrived example: public class Foo { private class InnerFoo { public int X { get; set; } public int Y { get; set; } } public void Main() { var inner = new InnerFoo { X = 3, Y = 5 }; // do something with inner } } So far, this compiles, everything is okay. If I had another class in my project, I could do something like... public class Bar { public void Main() { var foo = new Foo(); foo.Main(); } } And it would use `InnerFoo` internally, but I don't need to know about that. Now, if I change it like this... public class Foo { private class InnerFoo { public int X { get; set; } public int Y { get; set; } } public void Main(InnerFoo inner) { // do something with inner } } This won't compile, but let's pretend for a second that it does. Okay, so now in my other class I have public class Bar { public void Main() { var foo = new Foo(); var inner = ...? foo.Main(inner); // ??? } } See, in this example, the `Bar` class literally can't execute Foo's `Main` function because it doesn't have access to create an `InnerFoo`. This would be _terrible_ design, and there's literally no reason to ever do this, so the C# developers just... don't let you. It's 100% of the time a mistake to do something like this. In this example, the only things that make sense are to either make `InnerFoo` public, or to make `Foo`'s `Main` function private. With this knowledge, it should be easy to answer your own questions :). For your edification, the answers to your question are, in order: &gt;!1) Yes, that's correct!&lt; &gt;!2) It's totally fine to go the other way!&lt; &gt;!3) See above!&lt;
Well it would make sense that Core 4 follows Core 3. I hear .Net 5, and I think continuation of the .Net branch, if you will, that’s on v4, which is Framework. Skipping version numbers requires the user to actually be told what is going on. You wouldn’t be able to intuitively say that .Net 5 is a continuation from Core 3. Personally, I think I would make much more sense to release Core 4 and Core 5, with .Net 6 being the time to switch the branding. That way, no one can conceivably think it’s connected to Framework, as Framework is on v4 and is, by then, a few years out of date.
r/learncsharp is a better sub for questions like this. 1. Correct. 2. That's fine. The issue is that everything that is exposed as part of the object's interface or method's signature has to be at least as visible as the object or method itself. 3. An internal method may take or return types that are public or internal. A protected or protected internal method may take or return types that are public or protected. A private method may take or return types that public, protected, or private. A public method may take or return public types. Methods on an internal object may take or return internal types, in addition to whatever restrictions go with their access modifiers. A private protected method may take or return any accessible type that is not private. A public type nested in an internal type is basically internal.
&gt; I read their comment as suggesting that Microsoft should 'take the lead' and call it what they think it should be called. They seem to be doing that, calling it ".NET 5" &gt; Personally, I understood the article to say that .NET Core and .NET Standard are going away as target frameworks (or rather, no new versions aside from what is already planned/developed) and .NET Framework will again be the only real framework for most of us. I read the article pretty much as the opposite: that .NET Framework is going away as target framework, and NET5 will be the only valid target -- though I'm not quite sure whether that'll be a target like netstandard is a target or like mono is. What people are going to call it is a bit to fickle for me to predict.
Not really. Dotnet core supports a lot of what framework supports though of course not all of it is cross platform, but this isn't framework. All indications are that technologies like WCF server and Webforms show no signs of being ported and framework code still absolutely will not run on any of these new runtimes. Framework is dead, the path forward to this will be through core, not through existing framework code.
I think you could take some code/learn from the following two projects: [https://github.com/migueldeicaza/gui.cs](https://github.com/migueldeicaza/gui.cs) [https://github.com/Haydend/ConsoleDraw](https://github.com/Haydend/ConsoleDraw)
T
Try searching for tutorials or problems without core and your gonna get garbage from 2013....simples but a big problem its like MS is retarded.. I know they lost search with bing but I mean come on..
The comment section on that post seems to be primarily people who need to publish WCF services. Solutions I can think of: 1. Switch to using some technology other than WCF (not always an option, as some commenters note). 2. Refactor the code so that the WCF part of your application is a minimal wrapper around the .NET Core part of your application using some kind of IPC. Both of those suck, but it's not like it all has to happen at once. .NET Framework 4.8 isn't going away any time soon, so those applications will still be fully functional in the meantime. We have plenty of warning... after this blog post, the only bad solution (in my opinion) would be to do nothing while holding out hope for Microsoft to change their minds and bring server-side WCF to .NET Core. I think it's still totally appropriate to voice objections at the same time that you actively work to reduce your dependency on this. It just doesn't seem likely that Microsoft would sign off on a blog post that says (paraphrasing) ".NET Core will never support server-side WCF" unless they really meant it.
More data on your question please. Frameworks, SQL type etc.
This has not been my experience. Further if you are looking for .net core without a version; you could get stuff that doesn't apply -- in fact it is far easier. The version actually matters a LOT more in .NET Core than it does in traditional.
It's essentially an ETL process, only loaded into a live ERP database. .NET framework. The input data is a CAD BOM with CSV format. The output is a BOM for ERP and gets loaded into a MySQL database. Before the loading step, the data will get validated by cscripts.
Well looks like we're getting a new terminal: https://techcrunch.com/2019/05/06/windows-gets-a-new-terminal/ With emojis 🤣
https://www.nuget.org/packages/Mono.Reflection/ ? The question for non core stuff is if mono supports it
No idea. Why is that?
But by November 2020 ?
This is exactly it. People are of course free to call it whatever they want -- they can call the whole thing Fish.Org for all I care. :) But this is Microsoft's framework to brand, and they can either choose a naming strategy that makes things clear or muddies things up. Changing the name to something distinct would make it immediately clear which version of .NET is being used. Saying "Feel free to use the old name" just encourages confusion down the road. As an example: imagine if Nissan issued a press release saying "Feel free to refer to our cars as Datsuns". And then they kept referring to them as Nissans themselves. (Not the best analogy because the brand was relaunched a few years ago, but for 27 years the whole brand didn't exist.) Ultimately, we're developers. Naming things is important in our code. It should hold true for the frameworks we use too.
This is the most ignorant comment I’ve ever read on this sub.
I think the naming of dotNet 5 shows that it is a step from dotNet 4, and mono parity will bring lots of 4.x framework support. You want webforms? You got it https://www.mono-project.com/docs/web/aspnet/ "Mono’s ASP.NET implementations supports two kinds of applications: Web Forms (Web Applications infrastructure). Web Services (the SOAP-based RPC system)." You want wcf? https://www.mono-project.com/docs/web/wcf/ "Nowadays WCF is part of the core Mono. "
As far as I'm aware, System.Reflection.Emit works just fine in .NET Core, and I've made plenty use of it. Of course, it doesn't work in AOT where there's no JIT available, but that's also the case with .NET Framework. Or am I missing something?
This is what I mean... The actual list of what's deprecated from framework is: the stuff that isn't in mono. Which isn't zero. But it's a lot less than what isn't in core
https://miniprofiler.com
My favorite was when they had Web Pages (webmatrix). Searching for web pages was awful
It will be a continuation of the v4 by the time they merge in all the mono stuff
There is no indication that Microsoft are planning to port Webforms or WCF server to the core platform. Converting MVC 5 or WebAPI 2 to their respective dotnet core successors is not exactly a massive rewrite, but still significantly different and requiring a enough change that you're not going to get things done in an afternoon. The old versions **will not work**. Configuration, logging and dependency injection have been significantly overhauled, requiring reasonably significant changes to how pieces are put together. Entity Framework Core is different enough that your projects may require moderately significant changes to move forward. Migrations are a complete rewrite. The old versions **will not work**. Test, build and deployment isn't wildly different, but there will be steps there too. Even a bog standard class library will at the very least require migrating to the new csproj format and retesting new major releases of libraries. And that's **now** with core 2.2 which hasn't moved dramatically away from framework. It might not be a massive rewrite, but it's not going to be upping a version number either. This absolutely **isn't** Framework 5, it's Core 5. Your code will almost certainly not run as is, or even after an automatic migration. If you're using certain products, frameworks or libraries it may not work at all and actually will require a massive rewrite. Framework is dead. You shouldn't be writing anything new in it than you absolutely have to. Write new code in core whenever you can, migrate shared libraries to dotnet standard. Move winforms, wpf, and uwp projects to core 3 and MVC apps to core 2 when possible. Start using EF Core in your framework projects where possible. All that stuff is reasonably achievable. For the stuff you can't migrate to core, you'll need a plan. Framework will *probably* remain supported for the next decade or more, but it's not going to move forward and the day you're not going to be able to run it on new platforms is going to come eventually. That's the reality.
I'm not sure, but perhaps the fact that your pointers aren't managed code makes them uncovered by default?
&gt; Converting MVC 5 or WebAPI 2 to their respective dotnet core successors is not exactly a massive rewrite Depends on what you are using it for. WCF does a hell of a lot more than just web services and much of its functionality has no WebAPI equivalent.
Okay, so what is your question again? How exactly do you want to improve it - do you mean performance-wise or?
I'm trying to find out a way to minimize manual scripting, and creating an interface that allows the user to somehow select 1 or more validation type(s) for each column. Whereas this is now done by a simple text input field that requires a full script to be written.
It was part of the OS because that's how Microsoft did everything back in the day. And it was a **massive** pain in the ass. Patching the runtime requires a system reboot, including security patches (at minimum an app restart us required. Running runtime versions in parallel isn't possible. Got a project that doesn't work in the latest runtime, you can't have it. Want to upgrade Windows without upgrading .NET or vice versa, good fucking luck if you're outside a limited band. To mitigate these problems, the pace of change was and is *glacially* slow. Want to run on Linux or MacOS, nope. Want to run in a container that's not several GB in size, nope. Ease of use it sure wasn't.
That's the server side repo as well. By that I mean they occasionally put server side on their road map, only to ignore it until forced to remove it again.
Could take the Mono implementation (incomplete) and turn it into something for .NET Core https://www.mono-project.com/docs/web/wcf/
https://gist.github.com/antonydeepak/4439232 mono.cecil is what I was thinking of
This is literary my first unsafe code, so I can't be sure. All I see is that some of them are considered not-covered. Just like line 145 in this picture and some others that were covered.
WCF server is dead, no indication it's going to happen. The path forward seems to be gprpc or rest Api. That paragraph is about taking MVC 5 and Web API to ASP.NET core. That said, WCF is Web services, it might be bundled away in a horrific mess of generated code and magic, but that's what it is.
Does coverage change if you surround the first `fixed`-block with curly brackets?
Programming in Haskell by Graham Hutton
Bringing the best of mono is not mono parity. There is absolutely indication of Mono parity at all. Beyond that, the Webforms library implements ASP.NET 2 (current is 4.5) and the WCF library is not remotely feature complete and is also ancient. If you can run your WCF app on that, it doesn't need WCF.
Nope. It stayed the same. There are other cases too. For example this function: https://i.imgur.com/bE6owMS.jpg
Well, then just create a template script that uses a json string as an input. The json string can contain columns, validation types etc. If you can't write an additional script, then I don't think anything 'proper' can be done around this subject.
WCF is also named pipes. And message queues. And TCP. And distributed transactions. And countless other things that web monkeys have never heard of.
Still, I didn't manage to make it work. I will resume my research and if eventually I find the resolve I'll update my post.
What you need it to do is specific to you and how you apply it. You probably won't find a library as all you need for a slapped together app is basic logic. This is you using a steering wheel as opposed to reinvinting the wheel. In your function If(user.isAdmin) { ...continue function } else { ...throw an exception } On your display of the menu if(user.isAdmin) { menu.adminview.show(); //enable or whatever } else { menu.adminview.hide(); //disable or whatever }
I don't know about those, but mono supports wcf and webforms.
WCF can do all those things, but it doesn't do any of them particularly well because at its core, it's a dotnet SOAP implementation, you can change the transport mechanism and to a limited extent the payload, but it's not RPC. It shares some patterns from CORBA, but it's not CORBA. It can do some pub sub, but the models it supports aren't particularly performant or scalable. I fully appreciate that people do things with WCF that are not strictly web services, but WCF doesn't do any of them very well. Named pipes are severely limited, and support for them is going throughout the Microsoft stack. There are a dozen better queuing systems than MSMQ, none of which require half the magic and overhead of WCF. Direct TCP connections are the bane of my existence, having to support a number of systems that use them. There are even significantly better ways to manage distributed transactions, not least of which is using backends that support them properly out of the box. I'm not a Web monkey, I've written a lot of code that doesn't look anything like a Web interface, but WCF is and incredibly complex and finicky way to solve those problems.
IL emitted with `System.Reflection.Emit` does run just fine in .NET Core. But when you mess up your IL generation and it fails with `System.InvalidProgramException`, or when it runs but gives you the wrong result, how do you debug ? With .NET Framework, you can just dump the dynamic assembly to a .dll and use PEVerify, ILVerify or dotPeek to investigate. With .NET Core, you cannot dump the assembly. The best you can do is access the IL bytes and squint at them very hard, which is orders of magnitude less productive. Right now, we run .NET Core on Linux, but we keep all code paths compatible with .NET Framework just to be able to debug our IL output, because that takes _less_ effort than trying to debug IL generation with .NET Core.
As far as I'm aware core doesn't run on those platforms. They use mono instead.
Wcf is supported in mono Webforms is supported in mono
mono has aot compilation, core does not (yet). ios forbids running a jit, so it requires aot.
Are you kidding? They said they want to make dotNet core a drop in replacement for mono. They also said that you would pick a mono or dotNet core runtime
Slight digression but I have to ask. Is there any possibility that TypeScript will become a .NET-runnable language? I've come to like it so much more than working in C#. And all the typing stuff makes it seem less like an insanely dynamic language and more feasible as a CLR implementation.
Mono appears to support saving dynamic assemblies (though I have not actually tested it).
For windows take a look at the class described [https://www.reddit.com/r/dotnetcore/comments/8ukl9x/maclinux\_equivalent\_of\_kernel32dll/](https://www.reddit.com/r/dotnetcore/comments/8ukl9x/maclinux_equivalent_of_kernel32dll/)
This is a well known pattern called the [https://en.wikipedia.org/wiki/Strategy\_pattern](https://en.wikipedia.org/wiki/Strategy_pattern)
What I've done in the past would be subscribe to a channel with the {clientId}/# then have a thread that would send a publish to {clientId}/ping. That way you know your client is receiving messages. That is how we found the best way to make sure it's listening. We also created a metrics for our clients so we can see messages processed/etc. That way we have a Health Monitor on all our WebJobs so if something is down we can have it looked at immediately.
Probably https://docs.microsoft.com/en-us/dotnet/core/
There are a lot of articles online with the differences between .Net Framework(what you call old .Net) and .Net Core. For example: [https://www.c-sharpcorner.com/article/difference-between-net-framework-and-net-core/](https://www.c-sharpcorner.com/article/difference-between-net-framework-and-net-core/) I think that the article that i listed will answer most of your questions. Basically .Net Core includes .Net Framework but it's also improved for modern use and is also open source.
You never needed the framework installed. You needed the runtime installed, either in the environment or bundled with the exe (self-contained).
Hey there, I feel ya. Check out this article: [https://www.c-sharpcorner.com/article/difference-between-net-framework-and-net-core/](https://www.c-sharpcorner.com/article/difference-between-net-framework-and-net-core/) &amp;#x200B; Then if you want to navigate to Microsoft, it has good pages on how to choose between [ASP.NET](https://ASP.NET) and [ASP.NET](https://ASP.NET) Core for developing a web application. There you go! Let me know if you have any questions about that article or questions about Core. I wouldn't worry about learning 'old' .NET. Just jump into C# and core (Which is now going to be rebranded as .NET 5 lol)
Thanks, but I’m more or so looking for how TUI and CLI’s are rendered from start to finish. I want to learn and recreate every layer.
Topshelf works a treat with Quartz.Net. There’s a specific NuGet package for it to schedule jobs. I don’t advise you write you’re own.
So wait a minute, should I not learn .Net Core then? I'm trying to get into C# development.
Dunno but anyone could bust out a compiler that converts TypeScript to IL.
You should learn .NET Core, yes.
Why exactly can't you dump the assembly? It's still just creating your AssemblyBuilder instance with the right config for also being able to emit to a file (AssemblyBuilderAccess.RunAndSave), and then calling AssemblyBuilder.Save() eventually, right? Or are you talking about the transient dynamic assembly used internally by stuff like DynamicMethod and such? If so, I had no idea .NET Framework had a way of dumping that to a DLL, that would be kind of neat.
I just had a class on Core and MVC, it seems like a good way to go.
Sure, but you won't gett much lower level then what I provided... those are the p/Invokes into the system libs required to place text into the console at arbitrary locations.... without those p/invokeable functions your stuck using console.write and console.setcursor which will be quite slow.
[Save() and RunAndSave are not supported on .NET Core](https://github.com/dotnet/corefx/issues/4491)
&gt;the problem is if i made it run every 1 minute , if 1m passed , You're not stopping the timer. When your 1 minute timer elapses and you start doing work, stop the timer. Then, when you're done doing work, start the timer again. private static Timer timer; public static void Main() { // Create a timer and set a two second interval. timer = new System.Timers.Timer(); timer.Interval = 2000; // Hook up the Elapsed event for the timer. timer.Elapsed += TimerEvent; // Start the timer timer.Enabled = true; } private static void OnTimedEvent(Object source, System.Timers.ElapsedEventArgs e) { timer.Stop(); DoYourWorkInHere(); timer.Start(); }
&gt; There are a dozen better queuing systems than MSMQ, Who said anything about MSMQ? With WCF I can generalize my code and write to any message queue. That's a big part of the design, a standardized infrastructure that can support any transport. Changing from one to the next is often just a configuration change. Yes there is a cost to this, but it's often worth it.
Does code coverage vary in Debug vs. Release? If so it might be that those statements get optimised away.
Not really? 3 is mostly up to date, besides done cross platform stuff. Besides, they should just keep it as Core until Framework is long dead so that no one is confused. Their versioning is a mess currently.
&gt; Chain one or more decorators around any request Thanks for replying! If you mean the [pipeline behaviors](https://github.com/jbogard/MediatR/wiki/Behaviors) (basically like Core Middleware?) that is an incredibly useful feature.
Of course, which is why i’m not willing to believe an opengl backend without a source
Oh, man, I didn't know that. That sucks, but it's good to know. I was in fact planning on using that feature pretty heavily in a project I've been thinking about, but I guess I'll have to reevaluate now how to achieve it, since I'm already pretty locked into using Core/.NET 5/whatever. Cheers for the heads up!
What's the purpose of the HTML?
Some of the search endpoints take a pretty complex JSON object as the payload. The examples are okay but I would really like to add a little helpful note at the top explaining what the payload should look like and a link to a 3rd party GitHub for more info.
&gt; This is literary my first unsafe code, so I can't be sure. All I see is that some of them are considered not-covered. Just like line 145 in this picture and some others that were covered. What happens if you split each variable declaration into its own fixed statement?
Nice, where and what level was the class at? Good luck!
Tested with release and the result was the same.
Then this should be part of your specification.
Still the same. Could it be a bug in VS.? This is a .Net Standard 2.0 library by the way testing with xunit (.Net core 2.0).
Do I want this Json Serializer? What are the pros or cons?
You mean by adding a crap ton of `SchemaFilter`s? Or am I missing a better way? I don't think its unreasonable to have a forward to your API. Not every API is the worlds perfect definition of RESTful. How useful is information overload in the form of 100 API endpoints you have to manually go through, expand and click "model"? That still makes it really easy to miss things like rowversions.
I'll admit that with Nuget, it makes it less painful, but it would be better not having to deploy a ton of 3rd party dependencies or dlls.
They are dropping the **Name** .Net Core. The technology of .Net Core will become the latest .NET with version 5.
It was an online class though a place called interface training, it was a good solid intro into MVC and Core.
Out if curiosity, what happens if you move the two variable assignments out of the fixed? Do they appear as covered lines?
He's right that is confusing
Merging in mono adds webforms, wcf, and lots of other stuff which was missing, providing an upgrade/tweak path for a much larger set of applications than core does. They're dropping the core, because they're inviting in legacy cruft they didn't used to have. Thus making it a successor to both framework and core
Ideally you'd be searching .NET 5
Be real. Net 5 would just get the defunct asp.Net 5 results.. The whole naming convention is now a code smell, hence the pushback
I don't know how to do that, is it even possible to assign an array to a pointer outside of `fixed`?
Or you just learn how to Google and filtr results for those since 2017?
That's the biggest "if" I have ever seen! 😁😁😁😁😁
Referencing different variables is not a repetition. The only part of your code repeated more than once is `x.date == null`, which you can pull out as follows: ``` var undatedObjects = Objects.Where(o =&gt; o.date == null); // perhaps compute this once with .ToList()? // Statement 1 var query = undatedObjects.Where(x =&gt; x.varible1 == this.variable1); //Statement 2 var query = undatedObjects.Where(x =&gt; x.variable2 == this.varible2); //Statement 3 var query = undatedObjects.Where (x =&gt; x.variable3 == this.variable3); ```
You can pretty much treat it just like a function named `function`: var result = function(value); // result gets value * value Lambda syntax for anonymous method is simpler, FWIW: Func&lt;float, float&gt; function = x =&gt; x * x;
OK, I've been doing GUI test automation for 20-mumble years, so here's my advice. 1) Don't go cheap. It looks like it should be quick and simple. It will start that way. It won't end that way. 2) For GUI testing, Ranorex or TestComplete look expensive. In the short run, they are. In the long run, they aren't. 3) If you don't write a framework in which all the controls are abstracted, each page/dialog has an object repository and each workflow lives in it's own function library, you won't get past 100 tests tops before maintenance eats you alive. A GUI test system that grows by the seat of its pants will die that way, and soon. If it's a straight windows winforms app, you might squeak by with AutoIT, however all the organizational requirements till apply. Abstract the controls, then the dialogs, then the workflows. If they use WPF, no test application will work terribly well. Neither will the application. Just saying.
But anything else has a native client aready that doesn't need horror and magic.
Right. And if you don't need to support multiple message queues it's probably better to just use the native client. But that is not the case for everyone.
You are using `double` when you should be using `int` (or `long`).
I'm sorry, I did not go through much of the article as it appears overly simplistic. The introduction paragraph just didn't have me.
I skimmed most of the article after Types of Instantiation. &gt; Types of Instantiations &gt; In 2019, software design evolved a little beyond the standard Factory/Singleton patterns that we learned in computer science degree. We’ve got inversion of control, static classes, and even extension methods. I just don't agree with this. I learned all of these when I was taking my Introduction to Object Oriented Programming course in my first year of college in 2005. None of these are new. So I'm not sure as to who the target audience is for this as you should be taught these things in Intro to OOP.
the line double rgv = Math.Floor(coinconverter / g); gives you the rgv value of 1.0 and you use this value with mod operator (%) which divides the first value with the second you get 0.0 as remaining result Are you sure you use the correct variable for the calculation of the remaining value. Shouldn't it be like the following? double remainder = coinconverter % g; because this would give you a remaining value of 6.
Yeah, it's called google.
When you say the colour is off by one, what exactly do you mean by that? Have you got any example code you could share?
Interesting... I studied in 2000 and we didn't learn dependency injection or extension methods. Maybe I don't remember though, it was a long time ago. Didn't consider the target audience when writing this, it's both for those who studied it and those who didn't I guess. Nowadays, half of the new programmers don't have CS degree anyway.
Hi there! I don't have sample code to share, it's too woven into the other code to easily extract. However while I was working on trying to figure this out, I did write some log files to give some indication as to what's going on here. [----------------------------(19, (1572, 480))----------------------------] Before (1) = Color [A=255, R=128, G=128, B=128] After (1) = Color [A=255, R=128, G=129, B=127] (x, y) = (1572,480) After (1, written) = Color [A=255, R=128, G=129, B=127] Before (2) = Color [A=255, R=128, G=128, B=128] After (2) = Color [A=255, R=128, G=129, B=129] (x, y) = (1573,480) After (2, written) = Color [A=255, R=128, G=129, B=129] [19 = 00011111] [----------------------------(19, (1572, 480))----------------------------] Colour (1) Original = Color [A=255, R=128, G=128, B=128] Colour (1) Modified = Color [A=255, R=128, G=130, B=128] Colour (2) Original = Color [A=255, R=128, G=128, B=128] Colour (2) Modified = Color [A=255, R=127, G=128, B=129] [19 = 00200101] What I would have expected to see was the colour as given on the line labelled 'After (1, written)' matching with the colour as given on the line 'Colour (1) Modified'. Ditto with 'After (2, written)' and 'Colour (2) Modified'. I've done some manual checking and the colour as given on those pixel coordinates in the same image matches the 'Modified' lines and not the 'written' lines, despite what the code is telling me. I'm at a loss for this one, I'm completely stumped!
This is a mapping issue from sql to orm, so I think it's better to dig into orm docs to better understand how does it work so you can resolve this as it may require a special DTO with annotations or something else for example
Razor.
Currently, I'm building a job application tracking app. I started getting the basic features of inputting the job info into separate arrays, being able to see the jobs you've applied for, and a help feature. I was struggling to find a decent way to save and load data to the arrays, so right now i'm stopping to take a break and ask for input. Anyone have a lead on what I could do? [repo Link](https://github.com/RobertGrimwood/Project-Novalis)
Razor is essentially just the language you use in the views, which is pretty much just C# code in your view that the razor engine compiles into html. Its still there in Core. MVC is the architecture for the entire web app. You would need to learn both if you want to build web apps in .net core.
No i meant the length and zero assignments inside the block spanned by the curly brackets of the fixed
Visual Studio Online -&gt; Visual Studio Team Services -&gt; Azure DevOps, bleh.
Nov 2024 - .Net 10
C# 7.0 introduced local functions, which can even more simplify the code. ``` void YourMethod() { float localFunction(float x) { return x*x; } float result = localFunction(2); // result = 4.0 } ```
Thank you very much dude for your comment, it was not vague ;) As many of my teachers say: programming is something you can't learn from the books, you have to do it yourself. You are right. Cheers! :)
Thank you for writing this detailed answer with some code to make me understand it better. It really helped. Hope you have a nice day!
Thank you for answering my three "points", I really appreciate it. I am starting to understand the concept behind this. Now I only need to practice :) Have a nice day to you!
Thank you for the explaination ;)
 string converter = Console.ReadLine(); double coinconverter =Convert.ToDouble (converter); You are on the right track, but this isn't quite right &amp;#x200B; I would first remove any decimals and commas a user might have input by String.Replace(converter, ".", ""); String.Replace(converter, ",",""); int coinConverter = Convert.ToInt32(converter) You want an int in the end rather than a double so you can divide other ints into it without issue. Once this is set up there are several ways to finish the solution, I would create a count variable for each coin type and just run loops - Ex. int dimeCount = 0; for (converter; converter &gt; 9; converter -= 10) { dimeCount++; }
I think everyone who works in it knows that 5 is going to be different.
I think one can only learn how to code in the industry by coding in the industry. Don't feel bad for not knowing stuff, I think most people started out in the area without knowing anything... I did at least
Don’t be afraid to ask if you don’t know something and be honest. Those qualities, along with being eager and willing to learn help tremendously. And be willing to work with others and open to what they have to say.
Thank you! I guess It’s because I have learnt a lot about C# as a language, its features, syntax, computer science in general and have made a few side projects to test real world ability - but it’s all the ‘how different in practice is it’ kind of fears, working agile, sprints, best-practices and such! I’m definitely eager to learn so will make sure I ask plenty of questions, although I get concerned my employer will think I’m asking too much and fail my probation! Perhaps I’m overthinking.
Thank you, I will ask when I’m unsure always. Just always cautious of asking ‘too much’ and then being perceived as incapable
What about Razor Pages that have no explicit controller?
It can give you a huge advantage if you communicate in the right way. Always ask yourself what your (team leader/boss/collegue) needs to know and what not, and how to lay out the things they need to know in the most efficient manner. They will be grateful that you are considerate of their time. Bad example: Hello, my code crashes as I was coding unimportant_helper_function56 in project UncriticalSideProject, here is my stacktrace. Good example: Hello, I found out that the library we agreed to use is incompatible to &lt;other library we use&gt;. I have already prepared a few possible solutions to this, can we discuss this at the next opportunity?
In general, asking a lot of questions is good. just don't ask the same questions all the time. If you're learning you're a good employee.
Excellent advice which I will definitely heed, thank you.
Or even more pretty: ``` void YourMethod() { float localFunction(float x) =&gt; x*x; float result = localFunction(2); // result = 4.0 } ```
If professional programmers knew everything they needed for every case they run into at work there would be no stack overflow. We're all continuously learning and plying our trade. Just keep the mentality that there's always more to learn, admit when you're wrong, incorporate new and better processes and paradigms into your work, and be engaging with your team and clients. Good luck.
Seems like less impostor syndrome - and more new job nerve's. You don't know what's up ahead and so you're worried that you will be unable to cope once you start. Once you start you'll being learning all the stuff you'll need to learn, and you'll be aware of all the things you need and all the things you don't know. After a while you're clearly suited for the role, you've delivered lots of stuff you've been promoted, people might be asking you questions on how todo things etc. At that point - you might still think "I hope they don't find me out." - and that's impostor syndrome.! Well done on getting the new role and I hope you enjoy the world of software development.
So much of developing an existing application is just making changes such that you don't break any functionality and that your new functionality works just fine.
&gt; constantly feel I don’t know enough and have got the job by chance (perhaps imposter syndrome). 7 years developing full time. I still feel like this.
As everyone says to you: don't be afraid to ask something. And one more tip: write down the answer so you will not need to ask the same thing twice.
Well, .Net core is supposed to be 100% crossplatform as far as i know, so it makes sense to make wpf crossplatform if it is included in .net-core. I don‘t need it now, i don‘t need it at release, but eventually, they should make wpf cross-platform. Especially cause C# could easily de-throne java if we get a good x-platform gui-framework like wpf.
I hope they do this lol
Stack your questions if they are not blocking your job. Continue other work in the meantime.
how is that more simplified code?
Maybe it's encoding or dealing with local display/gamma settings. https://docs.microsoft.com/en-us/dotnet/api/system.drawing.imaging.imageattributes.setgamma?view=netframework-4.8 I've been burned by this before, though I don't know if it was at the code level you're using (since you don't have code). I would strongly recommend you try isolating the code and create a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve) with which you can better debug, test on different machines, or ask for help with.
Im working on a project that I think is a pretty good approach. https://github.com/qmlnet/qmlnet
Then you have no architecture
When you report problems to your team lead, always complete a robust root cause analysis (RCA) and have a bunch of options available to propose to them. The first questions that come out of my mouth when someone reports a bug are, "what caused it?", and "what do we need to do to fix it Also, software is virtual. Which means, anything can be done given enough time. So, when pushed, say, "Yes, it can be done, if I am given enough time." And, do not compromise on the time you think it'll take to complete a task.
ORM - clearly it returns an object. But it also promises to map for you. For me that means it maps to something the type system can verify.
Afaik wpf in dotnet core is windows only
Your solution is to litterly filter search results through Google search syntax how many newbies are gonna do that this is a failure of branding and accessibility .
Depends on what I'm doing. If I just need to throw the values on the screen, say a report driven by a stored procedure, then I just use something dynamic such as DataTable.
BUT if your database does not return a value it sets the value to NULL which in somecases is not true, meaning another application layer such as the UI cant entirely trust the data.
&gt;Func&lt;float, float&gt; What's the reasoning behind this? First float represents param, and second the return type?
Thanks for your summary.
Is this a homework assignment of some kind? Because if so, you will become a better programmer more quickly if you learn how to debug these things on your own. Just run the debugger and step through each line and see what values change.
From my experience, I use object pooling in Unity games. But that's because creating a full blown Game Object is usually a more complicated process than a simple allocation. Whether or not object pooling is useful to you depends on your specific use case. It depends on a lot of factors, like how long it takes to create a new object vs. the time it takes to recycle one, how many objects you're making, memory constraints, etc. I would suggest that you always start your application with the assumption that you don't need object pooling, and then implement object pooling if it's necessary after measuring the performance impact. Object pooling often complicates logic and can sometimes lead to very subtle and weird bugs. So avoid it, unless you need it. As for threads, same deal. In a threaded environment, it's even more complicated and dangerous cause now you need to either provide locking mechanism for the object recycling system (which defeats the point of multi-threading to an extent), or you will have to manage an object pool per thread, which adds more complication. **TL;DR** Don't use it unless it's necessary, and make sure you measure the impact.
Dont try to make it sound as if it was difficult task. No, you do not have to use Google Serach Syntax, you actually can just click on UI. Anyway people from **Information techology** and especially programmers shouldnt have problem with that, lol.
Yes. Look at the Func&lt;&gt; definitions.
Congratulations!! 🎉 It's not imposter's syndrome. You just don't know enough. But here's a little secret: neither do most of us. We constantly have to read documentation, making sure everything is right. What's important is to keep learning from everything. Good luck!
Imo, because Func&lt;&gt; has never been very intuitive. Still useful for passing functions around as arguments though.
It's easier to read.
Learn to step through code with breakpoints. Visual studio is amazing at this but make sure you know how to do it. You might be asked to add a simple feature to an existing application, when you open up the code base you'll be like "oh fuck where do I even begin". That code base might have been written by lots of different people over the years and some parts of the code might not even be used anymore (programmers can be lazy tidying shit up). Using break points and walking through the code so you know which parts are running when can be invaluable in making an update. Don't feel incompetent when you look at a large code base, just remember it wasnt written in a day and some parts of it may have even been added by a newbie like yourself 😋
&gt;{ return x*x; } vs &gt;x =&gt; x * x;
Wow, good for you! What resource did you use to learn Entity Framework?
I feel like just a link to a readme page is warranted. IMO, the swagger is not meant to be a full tutorial on using the api, it’s a reference for ensuring proper definitions. I definitely like to see true example Json included when possible though.
``` isn't part of standard Markdown and not supported in reddit.
\`Func&lt;float, float&gt; function = x =&gt; x\*x;\` vs \`float function(float x) { return x\*x}\` or even, as /u/DavidBoone pointed, \`float function(float x) =&gt; x\*x;\` &amp;#x200B; Of course, if it was a case such as LINQ, I would definitely use lambdas.
Was not taught during my degree 1999-2003
When is null not null? Your constructor sound be able to handle your DB results.
In short, .NET Core is open-source cross-platform .NET Framework with new developer tooling (e.g., `dotnet` CLI) that breaks the old-school Microsoft’s way of doing things FOR a good reason. .NET Core is not that different from .NET Framework in terms of the Base Class Library (BCL). Your knowledge of the classes and namespaces of .NET in general are still applicable except for *some edge cases* due to cross-platform support. In fact, going forward the **.NET 5** is the convergence of .NET Core 3.0 and .NET Framework 5.0. And it is a great thing. I think this is the best time to be a .NET developer.
Yes. For `Func` types, the last type parameter is always the type returned. So, if you had a `Func&lt;float&gt;`, it would take *no* arguments, and return a `float`. For `Func&lt;float, float&gt;`, it takes a `float` argument, and returns a `float` value. For anonymous methods that return `void`, there is a similar group of generic delegates named `Action`, which only have type parameters for their argument (because they always return `void`). That is, a method that takes no arguments and returns nothing can be represented as an `Action`. A method that takes one float and returns nothing can be represented as an `Action&lt;float&gt;`, and so on.
It's supported by nu-Reddit, fellow user of old-Reddit.
Neither. As others have said they are they both use the same razor engine to parse the markup and render html. Razor pages obfuscate the underlying uses from the developer, there are use cases where less is more, but when you need to lift it can be problematic. Short simple site or page, a razor page may due. If you need to handle complex logic and possible side effects of how the page is rendered, stick with MVC. Now i said neither, and i stick too that, write api layers and use agnostic js front ends.
Datatable? You just gave half the csharp users PTSD...
Ewww. So Apollo and old reddit (a.k.a. the non-horrible web interface) now have a different API than new reddit?
If you need to use the object for something other than dumping straight to json output, use objects, otherwise, dynamic is fine...
here is my crappy attempt years ago for fun https://github.com/ckarcz/GraphicsEngine
Fun fact: in Core it is actually a fast data structure. For whatever reason they actually spent some time optimizing it. Framework version is still as slow as you remember.
Yes I do mean pipelines but the name escaped me and they are pretty much decorators in behaviour.
&gt; When is null not null? When it is missing. I've run into problems where null means "set the DB to null" and missing means "don't change this value". Or maybe null means no change and DBNull means set the DB to null. And of course most serializers do not understand either of these patterns.
Fun fact: Flash/Flex treated the string "null" as a null. Some people have Null as a real last name. I never met one, but I did work with Boris Blank.
I guess? I don't pay that much attention to the ins and outs of reddit's API: I only noticed this when I was looking for formatting information to do something else.
Be humble and honest. Don't let pride get in the way of asking for help.
The readability trade-off is debatable, I think. If it's a choice between an anonymous, expression lambda and a named local method, I don't think it's worth the bother unless the name carries a lot of critical information that isn't captured by the code. If it's a choice between having a multi-line, statement lambda and a local method, I will probably prefer the local method, *but* I might prefer a separate, non-local method to a local one if it's not *very* short.
It is: https://spec.commonmark.org/0.29/#fenced-code-blocks Just mobile version of reddit is broken (desktop web does work).
It is common to use buffer pools with applications that allocate large buffers frequently. Basically what happens is when they allocate in large object heap, the heap is not compacted by default and it suffers from fragmentation. So, the program's commit size will keep growing. What people do is to create a pool of buffers in the large object heap and using them for temporary allocations if they have to allocate in the large object heap. Here is an example https://www.codeproject.com/articles/3526/buffer-pool-object-pool
CommonMark != Markdown
IntelliCode works in all Visual Studio editions. Some features are in Preview right now so may change before they are finalised. The detection of repeated edits hasn’t shipped even in preview yet, but sign up at https://aka.ms/vsicsignup to be notified when it does
You don't need WCF to abstract away operations on a queue. That's programmer 101. And more importantly, as you probably know, WCF doesn't actually do any of this work, IIS does, and a dependency on IIS is not a great thing to have moving forward.
With ".NET" they mean .NET Framework or they will simplify the .NET Core name?
Well I'm still a bit fuzzy on what you r actual application of the SVG is for. Do you want to display the SVG image in XAML format? Do you want to auto generate a form/layout? Do you want to edit the SVG? Regardless here are some links: SVG to XAML: https://liftcodeplay.com/2015/09/14/converting-vectorsvg-images-into-xaml/ Check out XML Linq for easy XML parsing and writing: https://docs.microsoft.com/en-us/dotnet/api/system.xml.linq.xelement?view=netframework-4.8 You can also deserialize XML into a C# plain old code object: https://docs.microsoft.com/en-us/dotnet/standard/serialization/how-to-deserialize-an-object Hope that helps you out a little bit!
They're unifying the platforms: https://devblogs.microsoft.com/dotnet/introducing-net-5/
Looks like they're dropping Framework completely and renaming Core.
Well from what I've read/hear: 1) .Net Framework is already been dropped, or will be dropped soon, for support with .Net Core being the future of .Net 2) .Net Core will support Win Forms and more from .Net Framework in 3.0 and further. So I think you are right in that it will just be .Net, because with 1 and 2 you are basically back to .Net Framework but with the advancements of speed and cross platform supported.
.NET Core is now just .NET
Are you really that ignorant? WCF is in no way tied to IIS. Of the many, many projects that I used with WCF only one was a website, and even then my WCF endpoint was open directly instead of being hosted via IIS. All this shit talking and you literally don't know anything about it.
And you are lost
I just read the contents of a markdown file and stick it in Info. Works fine.
I use it when processing real time data streams second in order to reduce pressure on the GC.
Finally after 20 years getting to the.net that should have been there from the beginning. 20 years of a cross platform.net and Java would be really hurting right now
I wonder if the compiler had to emit something special for null to ensure proper behavior?
Can you please share a complete sample of the code? I can dig into it. My guess, though, is that it had to do with the fact that the arrays are fields. Note that `data` does not have this problem.
Did I say hosted in IIS, no, I said dependent on. Distributed transactions are implemented through IIS code. The default queue, the only one WCF makes sense for, requires IIS. It's effectively impossible to port the full WCF server implementation to any environment that doesn't have IIS. You don't need IIS to implement serialisation and deserialisation over TCP, but you don't need WCF for that either.
.NET Framework 4.8 will be the version of framework. It is .NET Core from there on out. [article](https://devblogs.microsoft.com/dotnet/net-core-is-the-future-of-net/)
CommonMark is a standard of markdown (cf RFC 7764) and Reddit is a member of that standard comity (source: https://commonmark.org/#who)
Just toss it in a collection (List&lt;T&gt;).
That was the first thing I tried but the stored proc returns a table with 3 columns. The first column is all the same value. The second column repeats a few times. The third column is distinct. Is it possible to return the 3rd column as a property of the 2nd?
I think that he means Razor Pages.
This will be harder to focus searches.
&gt; But how do I call this method? Can someone give an example? float result = function(5. 5);
Thank you all for you answers!
Or: Func&lt;float, float&gt; function = (float x) =&gt; { return x * x;};
what are you returning in the dynamic version if db return null? Whats us the diference between a null dynamic and a null object?
That's nothing to do with WCF. You have to figure out how to rearrange the data as objects first. WCF just sends what you give it.
Reminds me of *”Just Jack”* from *Will and Grace* show. 😁
Its a wcf project...
I haven't used WPF or C# in anything tangible yet, so I tried to do something a little better than a hello world without using tutorials. [I created a temperature converter.](https://i.imgur.com/LnT50dN.gif) [Here is the github repo.](https://github.com/The-Small-Long/temperature-converter) I know its kind of cliche, but I thought it would be a nice intro into C# and WPF. Also, will a cross-platform desktop solution be made for .net core?
WCF can't change the shape of your data. You need to do that yourself before you give it to WCF. If you can't understand that then I can't help you.
Very interesting. This holds for even a small trivial program: https://gist.github.com/airbreather/cc3c2740e89a9c21bb2005c0c66d6ca5 Running `calculate-coverage.bat` from there, I do indeed see missing coverage from those blocks. Now that we know there's **something** going on, let's load up this minimal repro in SharpLab and see if we can figure out what it might be. [Here it is](https://sharplab.io/#v2:EYLgxg9gTgpgtADwGwBYA0AXEBLANgHwAEBmAAkICZyBGAdgFgAoAbydPdIAcpsA3AQwwxSAV1wQAdgHMA2gF1SwcWADWpALykJMAO6jx0mdSRyA3EzYcSoiQGd+AM2GEUpACIQAkhgAUwAJ5C8qQAJoL8AJSW7KyMHPGkDtgIMCGkfoEwAFShGqHhUXEJ7EkpaT5iklI5wHlKEKqFxTHRCQC+rR2MbUA===), in case you want to follow along. The MSIL actually makes it quite clear why `DoIt` would not be fully covered. I'll do my best to "decompile" it into something that explains the branches (using some hand-waving for the parts that I can't describe in C#): public class Program { private ulong[] block = new ulong[16]; public unsafe void DoIt(byte[] data) { Runtime.Pin(data); byte* dataPointer = null; if (data != null &amp;&amp; data.Length != 0) { dataPointer = Runtime.AddressOfPinned(data); } Runtime.Pin(block); ulong* blockPointer = null; if (block != null &amp;&amp; block.Length != 0) { blockPointer = Runtime.AddressOfPinned(block); } } } Now it all makes sense: there's no way to pin a null reference, and since "`fixed (byte* b = block)`" is (roughly) shorthand for "`fixed (byte* b = &amp;block[0])`", you also need a special-case for "what if `block` is empty, and so `block[0]` doesn't exist?". So the short version is, there's code there that could theoretically be executed, you just need to make sure that each thing that gets `fixed` sees all possibilities of: - `null` reference - reference to an empty array - reference to a non-empty array Hope this helps!
Create simple test cases with ideally one Assert. Do not make a giant “test everything “-test. If you need to test different aspects of the same code, write a new test case, that keeps both unit, integration and UI test simple and easy to reason about.
They're already skipping 4, so I doubt they'd skip another number.
This was a great answer. I learned a couple of new things. Thanks a lot.
Performance is key, but also of note is that until now there hasn't been native Json support. One thing mentioned in a stream of theirs (well, more than one i'm sure... i digress...) is that dealing with potential compatibility issues of optimizing Newtonsoft.Json in all of the ways and other historic quirks just wasn't the reasonable thing to do. Cooking up something fresh without compatibility issues or quirks, but with all of the new goodies &amp; taking pointers from James is a win-win. more info (from last release) has a bit of info about the inniards: https://docs.microsoft.com/en-us/dotnet/core/whats-new/dotnet-core-3-0#fast-built-in-json-support
VS Code as well.
There both based on C. Microsoft used to have some online lessons you could go through in Visual Studio. That's were I learned.
Thenewboston channel on youtube... I remember when I took some online classes the instructor suggested that channel. https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/ might be useful https://docs.microsoft.com/en-us/dotnet/csharp/tutorials/
Why a markdown file?
Does the property allow null? Then you signed up for managing what null means.
But those sounds more like the problems you have with callers of your api, not with calling an orm to get or set to/from the database
I think they must use another name instead of .NET A brand new name
yes this please ask questions, and take notes if you need to.
Tips: Create "small" pull requests. Probably around 1-2 a day. This will make them easier to review and when someone tells you to change it, you won't have as much work to do. Write unit tests for as much as you can. If you haven't already, learn a test framework like nunit or xunit (preferably whichever one they will use) and a mocking framework like moq.
Basically, everyone is an imposter, with the exception being those who have stopped learning (which is not good in this profession). I've been doing this since VB6 and i still experience imposter syndrome.
Wpf/UWP yes =&gt; Create a template design of the menu and it should be included. Winform honestly no idea
You can get a book. Maybe something like 'C#7 Quick Syntax Reference'
Microsoft frequently skips the number 9 out of superstitious reasons.
This is **highly** unlikely. In a few years they will change the name and versioning pattern again.
Point 2 will be windows only.
its.. window's forms
Look up ATATA.
Then... pray? WinForms is not very good for customization of the UI.
The problem might be that your points array has fixed length 100. Try using a List&lt;Point&gt; instead and doing `points = pointList.ToArray()` after reading in all points.
The pattern is generally used anytime the allocation or initialization of a resource is overly expensive for hot code paths, so to avoid that cost it is done up front the instances are held in a pool for use later without incurring said startup cost. A concrete example I’ve often heard used is database connection handles: the act of connecting to a DB is orders of magnitude more than running queries against it and is therefore untenable to do when wanting to quickly run queries. Instead, you’d make a bunch of connections at startup and reuse those for queries, returning the open connection handles to the pool to use again later without having to reconnect.
Yes, this works, thank you!
Would Bing work?
Absorb all you can from coworkers but also study outside of work. Three very important books that will be over your head but you should none the less read repeatedly: Domain Driven Design -Eric Evans Clean Code -Robert C Martin Patterns of Enterprise Application Architecture -Martin Fowler Robert C Martin also has an easy quick read The Clean Coder which is about what it means to be a professional.
Also, go to Microsoft Virtual Academy and watch all the tutorials you can. These are not random stack overflow jabronis. These are experts.
They have to skip 4 to avoid any possible confusion with the current NET framework version.
thanks my main Problem is I've just a limeted time in so I will Focus wih c# and .asp core Framework. So I think it's better I've I'm good at least at one language instead know everything a bit
Not necessarily. they've finally cleaned up the mess now.
Just like angular.js and now angular. Ugh.
CommonMark is a fine spec, but “Standard Markdown” is… Markdown. Writing an RFC does not a standard make.
Like last time, when they announced the versioning plans for .NET Core going forward. That didn't last long...
There's a good guide [here](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm) that should help you to understand basic practical rasterization algorithms. It also includes finished code you can look at if the theory is too much/you don't have time for it. If you'd rather fix your current algorithm I'd need more code to look at, but my first instinct is that either you've missed a case of triangles this doesn't work for, or there's an issue converting float screen coordinates to integer pixel coordinates that leaves some holes due to truncation.
Because they still had .NET Framework and the Mono mess to get done with. Now that's cleared up.
If you say so... Does change the fact that \``` is supported by the default markdown implementation anyway. See https://babelmark.github.io/?text=%60%60%60%0Acode%0A%60%60%60 (esp. markdown101 and markdown102 entries)
Have you considered high-performance safe code instead? (System.Memory)
You're trying to access a member of a `null` reference. Step through your code, line by line, and check which reference is `null`.
I modified the code, and I'm getting the response from the YouTube part. The problem now is that I'm getting another NullReferenceException, but this time at Misc:119. This is Misc (the line marked \[!\] is line 119): public async Task BackgroundYouTubePoller() { try { for (int i = 0; i &lt; Config.bot.channels.Length; i++) { string prevID = Config.bot.channels[i].LatestVideoID; Console.WriteLine(Config.bot.channels[i].ChannelID); Channel chnl = await YouTubeUtils.GetLatestVideo(Config.bot.channels[i]); if (chnl == null) { return; } Config.bot.channels[i] = chnl; await Config.UpdateChannel(chnl); await Config.SaveConfig(); await ((ISocketMessageChannel)Context.Client.GetChannel(Config.bot.channelID)).SendMessageAsync("http://www.youtube.com/watch?v=" + chnl.LatestVideoID); if (prevID != Config.bot.channels[i].LatestVideoID) { await ((ISocketMessageChannel)Context.Client.GetChannel(Config.bot.channelID)).SendMessageAsync(Config.bot.uploadMessage); await ((ISocketMessageChannel)Context.Client.GetChannel(Config.bot.channelID)).SendMessageAsync("http://www.youtube.com/watch?v=" + chnl.LatestVideoID); } } } catch (Exception ex) { Console.WriteLine("Error executing BackgroundYouTubePoller:\n" + ex); } }
&gt;Does change the fact that \`\`\` is supported by the default markdown implementation anyway. See [https://babelmark.github.io/?text=%60%60%60%0Acode%0A%60%60%60](https://babelmark.github.io/?text=%60%60%60%0Acode%0A%60%60%60) (esp. markdown101 and markdown102 entries). That's interesting, actually, and seems more like an accidental behavior. The spec only mentions the four-spaces syntax: https://daringfireball.net/projects/markdown/syntax#precode &gt;Also that would not be considered a code block in that case. But Reddit does (except web viewer on mobile). Right, but that's my point. Surely the original intent was to _make_ it a code block, which CommonMark _would_ do. I wasn't on the web viewer on mobile; I was on ApolloApp, and the old reddit interface also behaves that way.
I've considered it, but since this is a part of a bigger netstandard library and netstandard 2.0 doesn't support these new features I've never looked into them. Also because the list of things I have been learning is huge, I kind of put it at the bottom of that list for now. Will probably explore it more with 2.1 or if my TOLEARN list grows smaller.
Happy Cake Day Coding_Enthusiast! Today is your day. Dance with fairies, ride a unicorn, swim with mermaids, and chase rainbows.
Thank you very much I'll try implementing a different algorithm but I would also like to try and fix mine. I'm currently using Reddit mobile but I'll upload more code as soon as I can. Also happy cake day
Keep in mind the API has a limit of 10k requests per day iirc, just letting you know
&gt;Quartz.Net How can i use this with topshelf is there any simple example which tells me what to to ?
what about the start and stop methods from the ServiceControl, should i write them any code ?
Ah cool! Someone replied! Haha, I'll take that ego boost, thank you. I wouldn't say I've learned entity framework, I'm still fumbling around with both MVC and Entity framework (all of the above listed technologies if I'm honest) But I used Mosh from Udemy. He's got some great feedback from people on here and I took their advice and I've used him for 3 x C# courses, (beginner, OOP and advanced) and also his MVC course, plus 100's of web pages, youtube tutorials etc to get the answers for more specific stuff. I can recommend it to anyone who is looking to learn C#.
oh wow that looks complicated asf
But then again, let's not cheer for a monoculture anymore than we already have (with github, for instance).
Well, not *now*, but next release.
They're not "dropping" .NET Framework, they're just not making any more releases for it. It's been known (or highly suspected) for a while. &amp;#x200B; .NET Core 3 supports WinForms and WPF *on Windows only.*
I read somewhere that you should treat pdf as images, which then explains why this isn't always so easy. I have to some extent had success with Textract using docker (I don't like to pay for these things)
You sound like a much more prepared coder than the average newbie so there is really nothing to worry about. You learn the most when working. When you start off the expectations are generally quite low so just take your time to learn.
Just like the previous two ...
The YouTubeExplode API doesn't use the GData APIs. It gets data from somewhere else (I don't know how it works).
SwaggerUI and ReDoc support markdown.
As opposed to many other languages, C# has very good documentation: not overly academic and to the point. The [Microsoft docs](https://docs.microsoft.com/en-us/dotnet/csharp/index) are a good place to start.
https://www.rahulpnath.com/blog/windows-service-using-topshelf-quartz-and-autofac/
Think it really depends on how the pdf was created. If it was just a straight scan of a document it might be hard. But, I have used itextsharp before and there maybe a way in that. See the following link. [https://stackoverflow.com/questions/15679958/how-to-read-table-from-pdf-using-itextsharp](https://stackoverflow.com/questions/15679958/how-to-read-table-from-pdf-using-itextsharp)
How are you doing what you have there? merely setting background and foreground colours is not enough. If you want to truly customize MenuStrips, ContextMenuStrips, and Toolstrips, you should either find a suitable ToolStripRenderer or create your own. By default there are a few included as part of the Framework- look for derivations of ToolstripRenderer. You can of course create your own- You might be able to simply derive from an existing one and only override OnRenderToolStripBackground, without having to implement all the more complex capabilities. Menus and Toolstrips is perhaps one of the few areas were Windows Forms provides a rather good amount of customization - But it is quite possible to create quite [interesting results](https://i.imgur.com/CYZLDlN.png)- (ignoring the XP-style icons, of course... I couldn't be bothered to make new ones so used some I had lying around...) You of course might notice that there is no "white background" here. If you want for example a solid yellow background, you could create a new ToolStripRenderer derived from ToolStripSystemRenderer or ToolStripProfessionalRenderer or whatever and merely override the OnRenderToolStripBackground routine to set your desired colour. protected override void OnRenderToolStripBackground(ToolStripRenderEventArgs e) { e.Graphics.FillRectangle(Brushes.Yellow, e.AffectedBounds); }
I wrote a small android game in Java. The only way to keep the GC from causing the frame rate from lurching was to pre-allocate pools of objects and return them to the pools when not in use. And that is right about this complicating things and causing weird bugs. Don’t unless you have to.
Or they could I don't know listen to their own customers? SOAP is probably not going away in our lifetimes. WS\* and its feature set is also still very much out there in the real world. To add to that - WCF is ubiquitous in Microsoft's own product stack. This decision smells more of team and project disfunction than Microsoft not wanting to do it. We have seen this before and it got us the toilet abortion of Windows 8 and Visual Studio 2012. Bringing WCF along has more pros than cons.
I like katalon recorder a lot. It's very good for getting you 80\~90% there for each test.
Thanks! Will dive into it.
I still can't believe it took until version 3 to get in process iis worked out. Yeah I'm not touching this turd until 2025.
Exactly.
Where's the pdf file coming from? If you can get the raw table data prior to the pdf file then it would be easier to convert to excel file. I've used Open XML in the MVC project to generate excel file and some other .NET projects. [https://docs.microsoft.com/en-us/office/open-xml/open-xml-sdk](https://docs.microsoft.com/en-us/office/open-xml/open-xml-sdk)
.NET Essence is slated to be released in 2023.
&gt; Or they could I don't know listen to their own customers? I agree that the decision seems a bit confusing, given the volume level of the people who have been responding this way about server-side WCF, and I did qualify my comment with: &gt;&gt; I think it's still totally appropriate to voice objections [...] I'm just trying to bring up productive ways to move forward that can work even if Microsoft doesn't change their mind. Or if it takes them a very long time to do so. Or if they do, but without full feature parity. &gt; Bringing WCF along has more pros than cons. I don't have a reference to the materials that the team used when making the decision, so I choose not to either agree or disagree here. What I will say is that the Mono team has [attempted](https://www.mono-project.com/docs/web/wcf) to reproduce this themselves multiple times over the years with only partial success. It would, of course, help porting efforts **tremendously** to have the source code of .NET Framework 4.8, but to me, that's strong support for the claim that porting this would require a larger investment than what seems reasonable.
"... the library parses raw page content and uses reverse-engineered AJAX requests to retrieve information. As it doesn't use the official API, there's also no need for an API key and there are no usage quotas." That's seems to be how it gets its data.
Not superstition, backwards compatibility because people look for "Windows 9" when checking for Windows 95/98.
Yep. That is the straightforward part. The deeper parts is the registering users, setting passwords, setting permissions, recovering passwords, changing passwords, etc.
That's an urban myth.
Something to keep in mind as you learn how to write software, software systems can get big and complex. I help maintain ~110 libraries/projects at work, totalling somewhere near 3 - 3.5 million lines of code. At that scale, you want the language to be able to shape the structure of your software to makes sure it is used in the right way. There are handfuls of developers from outside my team that are linking against my code that don't fully understand it. I want to do everything I can to prevent them from making easy mistakes. An old adage I love: if you want to see the structure of a company, look at their code.
All great tips. In addition, do your best to make tests understandable to someone seeing them for the first time. The code gets looked at quite a bit especially for a period of time after it was written. Clean code and good comments go a long way in test code.
You are making that claim based on what?
And just to punish you for this complaint, the next version will be called .
Same as you. There's never been a confirmation or proof for this claim.
&gt;An old adage I love: if you want to see the structure of a company, look at their code. But that takes years and years of experience in coding given the fact that I just started around a few months ago. Another question: being good in coding, is it a talent or an acquired skill?
A little bit of both, likely. Can you think logically? Can you learn to think like the machine? Are you naturally curious? If you've got both of those, the rest is just education.
&gt;Can you think logically? Can you learn to think like the machine? &gt;Are you naturally curious? Trying to rewire my mind that way...Is it too late?
If you eng to learn c#, I would recommend to stay away from Unity3D. It has old c# version and as some limitation (additional complexities) in oop. ASP and other framework are coming with own complexity which are not necessarily for learnings the language. I would suggest you to learn the c# in something very simple as console app (resources wise just use Ms docs) and one you are comfortable with language itself, learn a frameworks which you are interested in (ASP, ef, etc.)
Never
The Microsoft press books are pretty fantastic. [SOLID code](https://www.microsoftpressstore.com/store/solid-code-9780735625921) is one of my all time favorites. It’s fairly old, but the principles it teaches are a part of my daily life. Also, any answer given by Jon Skeet on Stack Overflow is worth a read, as is his blog. Once you’re more comfortable with the language, I’d recommend [design patterns](https://www.dofactory.com/net/design-patterns). That’ll get you communicating about heigh level abstractions
Thank you all
This might be an somewhat odd recommendation, but I suggest you start doing TDD, not only is it considered very good practice. It makes you write unit tests first (start VERY simple), and then *think* about how to make the tests pass. This thought process can help you get used to the language more. It may seem overwhelming, but keep at it, the only way to truly learn is by practicing.
What's more plausible? A. The rumor reported by multiple developers at Microsoft that they did it for backwards compatibility reasons B. All of those old applications which we know for a fact had bad version detection logic were magically fixed
I would focus on LINQ outside the ASP.NET setting to get familiar with it. LINQ (Language Integrated Query) allows you to do some amazing things and will definitively make your life easier Read trough [https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/query-syntax-and-method-syntax-in-linq](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/query-syntax-and-method-syntax-in-linq) for some more information, if you didn't already do this. &amp;#x200B; You don't have to learn Entity Framework, you could also give Dapper a try &amp;#x200B; When i was learning [ASP.NET](https://ASP.NET) i followed Mosh Hamedani's The Complete ASP.NET MVC 5 Course. He's a good ex-plainer and it seriously helped me.
So having dealt with PDFs a lot in the past. They can be a real pain. So first i would say do as stated previously and try to determine if its a "true" PDF in such that it is not just an image as this can provide additional options. I found that microsoft office suite usually does an exceptional job of interpreting PDFs. What i usually did was try to open one in microsoft word and see how it is interpreted then if it works well you can programmatically open each file with word. Once in word format you can access the datatable objects in the word file. However, if it does not open exactly as needed you can use the .net OCR libraries that can he accessed via interoperability. This process has typically been trial and error to figure out what gets you the optimal product. Obviously once this is in a word data table and it can be accessed via C# you can easily convert or write the requisite data to excel. https://www.codeproject.com/Articles/10130/OCR-with-Microsoft-Office Granted this is a simple methodology however it has worked well for me in the past. There are additional OCR projects out there that may work better.
so renaming win 10 then?
thats the second worst, the worst is the community. not looking forward to them getting butthurt if net5/core stuff isnt closed just because old framework stuff had a similar yet not at all applicable question. if the site admin isnt crappy enough to close them as they do now that is.
I am introducing a new feature of 'InsertAll', 'MergeAll' and 'UpdateAll' in version (&gt; 1.9.4) for RepoDb. &amp;#x200B; I notice that my first run of #RepoDb batch insert operation was quite slow, given the fact that I already do the packed-statements when inserting the data. &amp;#x200B; I also notice that #LLBLGen was "crazy" fast, outplaying the #EntityFramework by more than 200% in performance. This is a "well-writen" application when it comes to compilation of the statements. &amp;#x200B; So, I have started to play around with various test on my own development server. First, I notice that #LLBLGen "duration" on packed-inserts are always "0 ms", where I notice mine is always at "2 ms". SQL Profiler (Trace) give me this number. I also notice that #EntityFramework is very slow even to the fact that my statements that time are not yet compiled. &amp;#x200B; I did all 3 kind of compiled-expressions ('Clear/Create/Add', 'NameIndexer', 'IntIndexer') when it comes to delivering the correct DbParameters to the DbCommand object. I also created a small project to test "which" of the 3 are more faster. I found out that 'Clear/Create/Add' was a little faster compared the 2 (just few ms). So I merged this version out to the master branch. &amp;#x200B; Note: This triggers some failing to the master branch that I need to fix moving foward before releasing. &amp;#x200B; With all the 3 kind of compiled-expression that I wrote (which I spent a week, and I know it is very optimized - you can review this), still it is very slow when compared to #LLBLGen. So I wonder how #LLBLGen do the hack on here, or something in the process that I am missing. &amp;#x200B; Well, being promising of always bringing this library to the top, I never stopped. The solution was very simple, I packed the 'DbConnection' object into a 'DbTransaction' and that really mimics what #LLBLGen is doing. So I would expect that #LLBLGen is doing it as well (so do I on this version). &amp;#x200B; P.S: The figure above is only on my development machine and is not an actual figure (so please be aware of this). And also, I asked FransBouma on this, this will not be approved on the PR of #RawDataAccessBencher as the #RepoDb is not doing any change-tracking (but the 2 are). &amp;#x200B; Thank you FransBouma for the involvement on this, will definitely share the technique to everyone who is interested on learning.
This doesn't appear to be accurate, for example generic attributes won't make it in as seen [here](https://github.com/dotnet/roslyn/blob/master/docs/Language%20Feature%20Status.md).
Hi, everything might be changed. only in state Merged are 100% coming. I will check it out and update the last state.
They are almost a trillion dollar company with a long sordid history of creating expensive customer/developer dead ends. I dont see how addressing this debacle beyond “f you use grpc” is asking too much. This isnt the first time they totally botched new net core communications. The go to grpc if you use wcf comment though shows a complete lack of understanding what wcf is and why customers are so pissed off about its demise.
I think this is a little bit advanced for me now but I will keep in mind about your advice. Thank you u/elbowman79.
I always feel the need to challenge the basics, so forgive me if it sounds like a dumb question: the PDF are normally generated from a source. Are you able to use this source to generate the Excel instead? That would be ideal. Otherwise, generating from PDF will always be more unreliable, IMO.
By 2024 they'll have the Linux line of Windows products too that they'll need to on-board.
You can use \`System.Memory\` from .NET Standard 2.0 with the \[\`System.Memory\` NuGet package\]([https://www.nuget.org/packages/System.Memory/](https://www.nuget.org/packages/System.Memory/)).
@OP I have that course and its terrible. I really don't get the reviews. You will barely learn c#, but the biggest offender is how out of date it is regarding Unity versions, C# versions, etc. I learned 10x more with 2 hours in the MVA c# course then I did on that course after 2 weeks.
Wasn't it posted on Raymond Chen's blog?
you're welcome, I wouldn't remember the number of "s" to login on Reddit
Shocking...esp given the number of ppl who have bought the course and the reviews. Maybe it is for hardcore game dev ppl and not for C# dev. Thanks for the input though.
.ORG
I thought so, but I wasn't able to find it.
If you can, you can pass an instance of the `DbContext` to each service's method as well. You'll just have to modify the signatures of the appropriate methods. Aside from that, I think `DbContext` are registered as *scoped* dependencies, so I *think* that means that your services will be injected with the *same* instance of the context (for each request/response pipeline that is). If you can modify the context, then you should add some string property to it like this: public string Test { get; set; } and, in the first service, set its value to "Foobar". Then, in the second service, see what the value of the property is. If its foobar, then its the same instance. If its value isn't foobar, then it is a different instance. Still, I think it would be better to provide an instance of the context to the methods unless someone else has a better suggestion. However, I'd call save in each method, but I'd create a transaction scope from the context wrapping those service calls.
Thank you both. I will take a look
Thank you both. I shall take a look!
So here's how you would typically approach this problem: 1. You want to make your call to the database and get your **data object model**. This has all your EF attributes and is tightly coupled to your data source, i.e. entity framework. 2. Copy that data into a **business object model**. The business object model is a completely different class, and is separate from any data layer. You can pass this between your services and perform business logic and validation on this object at will. 3. When you're ready, convert your business object model back into your data model and save into EF. This allows you to pull the data from the DB and pass it between your services at will without worrying about your data layer. This is related to the repository pattern, which I suggest you read up on and implement. There are a lot of people who argue that EF doesn't need a repository pattern implementation, but in situations like this one it makes the entire system more robust and testable.
TDD is a bit dated, and it's not a good recommendation for someone who is starting out. It's a frustrating, time consuming exercise for experienced Devs to get comfortable with, and can easily make a new developer feel like they are drowning in order to do properly.
If you don't have tests, how do you answer the question "There is an error, is it in the part you wrote?" If you are a junior dev, you answer with confidence "no!" If you are a senior dev you answer with a wishy-washy "probably, let me look." If you have tests, you answer with "let me run my tests and I'll tell you. If my tests don't cover that condition I'll add a few to be sure it's not what I wrote."
😂😂😂
Benchmarks without corresponding code are not benchmarks that should be shared.
Depending on how low level you want to go, you could try: * [Godot](https://godotengine.org/) / [Unity](https://unity.com/): Full 3D+2D game engines that will do most of the lifting for you, leaving you to focus on the simulation aspect. * [MonoGame](http://www.monogame.net/): I think this is 2D focussed, a bit more lightweight but will still be quite quick to get something on-screen. * [OpenTK](https://opentk.net/): Low-level OpenGL bindings so you'll have to do a bit more boilerplate yourself, but can be rewarding if you want to use this project to learn how to work with graphics APIs directly. Hope that helps!
I would expect you know the popular RawDataAccessBencher?
The RepoDb test code is in there? I don't see it.
Does HL7 is related to this project?
You don't need full coverage to find where errors exist. There's a reason logging, validation, and error handling exist. If you're only able to find errors through a unit test, that's a major problem. Unit tests can help that process in some places, but they aren't the end all, be all. This is getting off topic, and doesn't address the fact that you shouldn't be recommending test driven development to someone learning.
They are dropping it as in "Windows has, and will continue to have, **a lot** of code running on the Framework. Core? Nyahhh... maybe later...
Hashtags don't work in Reddit comments.
Unqualified to have an opinion on most of this, but I’ll second the vote for Unity.
.BIZ
It's even easier - I have been using [https://hockeyapp.net/](https://hockeyapp.net/#s) on eary stages of development to make continious integration and provisioning on test devices as well. Go check it - it's free, just attach c# project repository
You should also compare SqlBulkInsert.
'Bulk-insert' is a different thing from the 'batch-inserts'. It should not be tested with this operations. Though, this is also a feature of RepoDb.
If you're testing "insert lots of stuff at once" implementations, SqlBulkCopy is one.
I guess we disagree. Teaching someone to write tests to both validate their code and force them to solve the problem before they write the code are extremely valuable.
Not on this testing, "bulk-insert" is a different thing from "batch-insert". Definitely, "bulk-insert" is much faster (as always). You are referring to a test "ORM1.BulkInsert" to "ORM2.BulkInsert" test.
Add to this list: can you break a problem down into atomic parts and then reconstruct it with those parts
Someone new doesn't even know what problems they should be testing for. It's putting the cart before the horse.
This is a fun idea. I tried to do it 20 years ago and got as far as a mesh of coloured triangles. Good luck!
To be fair, SBC is ADO and not in an ORM.
What exactly are you trying to achieve? Sorry but it's a bit unclear to me what you want to do with that URL in C#.
In this case you don’t need the backing variable, so just use an auto properly and no problem For the case when you have some getter or setter logic and would need it; readability and clearly expressing your meaning trumps and specific style guidelines. If the rest of the class is meant to go through the property to hit the getter and setter logic then putting them next to each other doesn’t really matter, if anything to almost want to downplay the existence of the backing variable. If the getter and setter logic is only for external clients and your class needs to bypass that then maybe put them closer together, maybe comment the reason why you need to set it directly Second point would be to consider consistency. Everyone has slightly different styles they like writing in, you can’t match everyone. So long as you are consistent with yourself, and preferably the rest of the project / team then slight deviations from other styles will be seen pretty quickly and the reader will just deal with it. The purpose of consistent style is to reduce the overhead while reading, we already have to parse and compile the code in our heads, so consistency helps us spend less time on unnecessary squinting to see what’s happening
What I'm trying to do is make a button that people will click that will gather an address and put the address into a google search for them. For instance, I have a script that grabs a business location and I'd like to add a google search query to that address, something like "Find pizza places near 100 Any Street, Anytown, DC"
This is just a thing you get used to. I've always put the fields above the property. It's also controversial but I use the `_underscore` convention for field names to really hammer home that they are fields, to me it helps. If I encountered code doing it the "bottom" way like you did it wouldn't bug me so much as long as *every* property did it. 99% of the time we don't care that the backing field exists at all so it really doesn't matter where it goes.
*they're
I’m happy to explain in more detail if needed. Thanks in advance!
It's OK to feel lost at the start. The thing is no matter where you start, whatever application framework you use assumes you know the fundamentals. So if you were starting in WinForms, you'd need a firm basis in events and at least one of the three major asynchronous programming models. The best thing to do is to *do*. Start with small applications, just a few different pages or API endpoints. Just focus on making it work. Other people are giving you good advice about TDD and other practices, but I think it's OK to say when you're feeling overwhelmed it's best to cut out any noise. Make it work. These programs will be bad. But you will get comfortable with the syntax over time. You'll find that pretty quickly you get used to how you add REST endpoints or new pages. Things that took a lot of reading and thinking will come naturally. *That's* when you should go back to your last few apps and try to do them better. What's "better"? Well, you could try to write them in a TDD manner. That will be new and overwhelming, but you already did the ASP parts so what will be new will be *just* the TDD. Repeat that process. Have 4 or 5 projects you know you can finish in a day or less. Every now and then, start one over but try to write it a different way. Or, maybe there's a new library you want to try. Add something that uses it as a feature. Etc. You can't get around that you're learning like 50 new things at the start, so do your best to keep that number small. Later, when you're not struggling to learn concepts, you can add more things to the pile.
Thank you everyone for your extremely kind and generous feedback, I appreciate it greatly. Note that I will take all of this on board and work hard to be a credit to the team and future teams I work in.
First you have to understand what the current directory of your exe/C# application is that is running. Then you need to determine the location of your data in relation to that. Combining those two together will give you the location of your data files. I am also betting that when you build your C# application that your data txt files are not being copied to your output folder. So you will want to look into how to copy content data in Visual Studio to output folder.
 public int MyProperty { get; set; } No need for backing property if you defining both a set and get
You don't want to await 20,000 times a second. You probably just want to use a BufferedStream.
You can’t be the interactivity, quick iterations, and immediate feedback the www.threejs.org (simplifies WebGL) gives you by hacking javascript+webGL in a browser. I much prefer C# over js, but in this case js wins. Check out the [examples, and the tiny amount of code it takes to implement them](https://threejs.org/examples/#webgl_physics_volume). N-bodies stuff: http://www.spacegoo.com/solar_system/ https://www.sw-engineering-candies.com/blog-1/n-body-simulation-of-a-growing-water-melon-in-a-box http://www.ibiblio.org/e-notes/webgl/gpu/n-toy.html
Interpolated verbatim strings have existed as $@"stuff{thing}" I'm not sure what is different with your listed @$ version.
Thank you for the answer. A buffered stream means I store the data first in an array and use the Append-function not everytime? Or is the approach with BaseStream.ReadAsyc wrong?
Is there a real difference with the Null Coalescing Assignment in your pdf vs variable = variable ?? expression; Would a non-null variable cause a re-assignment or would the compiler optimize and not re-assign at runtime?
That appears to be Visual Basic, not C#, so you might have better luck googling your problem with that in mind. Where is this script? In Excel, or a Visual Basic app, or do you want a web page? What is happening with your URL? Are you just going to show it so they can copy/paste? Have the browser automatically go there? etc...
var input = textBoxWithYourInput.Text; var searchQuery = $@“https://google.com/search?q=pizza+places+near+{input}”; And then something probably like; Process.Start(“chrome”, searchQuery); // chrome Process.Start(searchQuery); // use default browser Not the prettiest solution but will probably give you what you need?
Thanks for the response. I’ve tried countless different file paths I just don’t know what I’m doing wrong. I have set all the .txt files to Copy always in VS?
Just changing the handler from async void to synchronous looks like it will probably go a long way to solving your problem. only opening the file once should help with performance, and none of this should be on the UI thread so it shouldn't lock up the UI.
Personally I'd recommend creating an installation program for your program that includes and installs the relevant data files in a controllable place, for example in the user's appdata folder. Then in c# you can ask the system where the appdata folder is. There are many good choices for making an installer, but i use inno setup. If you don't expect these files to change, can you compile them or the data into your program directly? If you do expect them to change then storing them with your program is not a best practice.
Thanks for the reply. The program should be able to read the .txt data and sort it into an array in either ascending or descending order so none of the numbers in the file will change but the order will?
So the code is okay considering the asynchronous approach? At the moment the binary files I create have the right size even with 10kHz so it seems its performant enough at the moment. I was just irritated that the UI was unresponsive during recording.
- Ignore `SerialPort.BytesToRead` and `DataReceived` - Just use `BaseStream.ReadAsync` in a loop, reuse a preallocated buffer, don't allocate a new one for every read - Use `ConfigureAwait(false)` (but look up what it does beforehand) - Do not open and close the file for every single write, open it once and use that stream instance throughout
Then id move away from text files. Make the data into an appropriate collection in a new class. Then the data will be already in the right format and you won't have to parse the txt files at all.
Unfortunately I have to use the .txt file as this is homework. Would it be easier if I posted a full screenshot of the code as its less than 200 lines?
I've never really understood the need for summary comments on a property. For me, if they property is so complex that it cannot be named in a way that makes it very clear what it is, there's a problem.
First of all, the path should not have any starting `\`, because this makes it an absolute path, so it will eventually search on `C:\Data\`. Second, the `.txt` extension is not optional! You might hide it in File Explorer, but it's still there. Also, there's no need for parentheses, they don't do anything there. The line in question should be something like this: String path = "Data\\Low_256.txt"; Note that this assumes that your program will be at the output directory and the text files in a directory called "Data" inside that directory.
You'll find this helpful: Path.GetDirectoryName( Assembly.GetExecutingAssembly().Location). This will give you the current executing path of the executable and assuming that a user hasn't copied the exe away from the installed directory, you can build your path starting here.
Thanks for your response! This is the message i get when trying to run the application - https://imgur.com/4xCukRJ