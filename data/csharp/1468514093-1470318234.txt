You were correct, I was able to add that line and it worked great. My next question is next time how should I find that answer as a beginner? I spent probably 2-3 hours doing Google searches before I came here. Everything kept pointing me to this page https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.createuserwizard.duplicateusernameerrormessage(v=vs.110).aspx That had the get set stuff. Why would that be on the Microsoft site if it didn't need it? Or am I just too inexperienced to understand the doc?
&gt; Why would that be on the Microsoft site if it didn't need it? Or am I just too inexperienced to understand the doc? This. But don't let that dishearten you. Documentation is hard to read, and even harder to write. The Microsoft page describes how the `CreateUserWizard` class is implemented. The documentation is telling you what properties exist within that class. It also tells you how you can interact with them. `{ get; set; }` tells you that property can be both "get" and "set." See below: //let's say we have a class named "SomeClass" - let's get an instance of it var someClassInstance = new SomeClass(); //getting a property - whatever value is in "SomeProperty" will be assigned to the "somePropertyValue" variable var somePropertyValue = someClassInstance.SomeProperty; //setting a property - whatever we designate will be assigned to "SomeProperty" someClassInstance.SomeProperty = "some property value we want to assign"; Not all properties of a class have both "getters" and "setters," meaning that sometimes, a property can only be read -- it cannot be assigned to. The Microsoft documentation explicitly says `{ get; set; }` to denote that the property can be assigned to and read from. Now, how does this all tie in to your `CreateUserWizard`? By adding that line to your .aspx file (the one that actually sets `DuplicateUserNameErrorMessage` to your desired value), you are telling .NET that when it instantiates the `CreateUserWizard` class for that page, it also should set whatever properties you have defined in your markup (.aspx).
Which is fine until you want to view your code in something besides an IDE.
Compared to what? Having a broken and ugly formatting in your code? Even if it would be good to give people a choice, code doesn't usually look good with both a tabwidth of 4 **and** a tabwidth of 8. In the end it's just another part of your projects styleguide. Also I've worked with projects that used 2,4 and 8 spaces. And I'd take consistent formatting over my personal tabwidth preference any day. That said I like both 2 and 4 spaces quite well, 8 space projects feel a bit weird though.
I don't understand what you're trying to say. If the projects styleguide used tabs instead of spaces, it wouldn't matter because you dictate how much spacing you see with each tab. It also is more efficient since it saves one character as opposed to 2, or 4, or 8. I've never even heard of 8 space tabs before.
I trust you.
Option 2 lets you take advantage of generic parameter inference to eliminate redundancy. // generic parameter is redundant Factory.Set(() =&gt; new MyType()); If you're willing to put a `new()` constraint on the method, you could replace that call with Factory.Set&lt;MyType&gt;(); class Factory { public void Set&lt;MyType&gt;() where MyType: new() { // something very important } } So I like option 2.
Can you provide a pseudocode example of what you want in C#? I don't quite follow- `#ifdef` exists in C# too for example...
&gt; By using tabs on your project, you DONT have to worry about setting up an editor with your style guide. The tabs will just be however the editor likes it. Like already said, if the code was formatted with a tab width in 4 in mind it'll look really ugly for someone who has a tab width of 8 set as personal preference, so you'll still have to set your editor options according to the style guide. Consistency is more important than personal preference most of the time. On the other hand, even if the person looking at the code doesn't have his code set up for the code style, he'll at least get the same consistent good formatting as all the other people if you used spaces, with tabs it'll look out of place until he changes his settings. This is a point for spaces in my opinion. &gt; Honestly itd be best if the community found a standard and adhered to it for consistencys sake to avoid the very problem youre making. In an ideal world if we could start from scratch with no legacy code ever used, then maybe. It's never gonna happen though as there are already too many projects with differing coding styles around. Python with 4 spaces, Linux kernel with tabs and tab width of 8... &gt; Honestly in my opinion tabs are objectively better. There really is no positive (that i have heard) to using spaces that cant be solved by simply using tabs. In your opinion... in my opinion space is better. Opinions are clearly subjective, so I can't agree with you here. Also like I said already, with tabs you won't magically be able to avoid setting editor preference. **Edit:** Also the holy indentation war between tabs and spaces is as old as programming itself, even older than Vim vs. Emacs. If one were objectively better than the other we should have a clear favorite after a few decades now, shouldn't we? That's not the case and probably never will, people will always argue that one is objectively better than the other, whilst someone else will argue that the opposite is objectively better. And it's only objectively better in their opinion, but overall it's completely subjective. So as long as you can't persuade every programmer on the world to have the exact same personal preference you'll always have different coding styles.
You can provide multiple enum values backed by the same numerical values. There's no need to even use pre-processor blocks. 
That was my original thought, and it works well until you bind it to a ComboBox. When I filtered down the values to those that are "selectable" based on the category, it turns out that the internal machinery just binds the first enumeration value that has the same numerical values. So, if I filter it so that the ComboBox only displays DEFAULT, ValueC1, ValueC2, ValueC3, ValueC4 It will actually show DEFAULT, ValueA1, ValueA2, ValueA3, ValueA4 It took me a little to figure out what was going on when that happened! (The actual enumerations have 10-20 values apiece, and not all values overlap).
I doubt generic inference makes code harder to read in this case. Your lambda repeats the type name. Almost all of linq requires that language feature to be even remotely readable. And it's optional, so if there is a case where it's better to be explicit, you can still include it. Exactly. The `new()` constraint only exists for the default parameter-less constructor. If your objects required parameters in their constructors, or some other factory or builder method, you'd have to use the lambda.
Rather than binding your combo box straight to the enum, (how do you even do that?) I think you could bind to a filtered list that is computed at runtime.
It's been a long time since I've worked on any local ui like winforms or wpf, so I kind of forgot about that use case. That is a pretty good example. I'd guess re-entrancy bugs could get kind of nasty though. It sounds a bit like `DoEvents()` again.
I see what you're saying. To get around this, would it be possible to bind to a list of `ListItem` or something so that you can provide your own string representation as well as backing value? That way you could retain control over the string that gets presented.
Actually I might have misspoke partially, I don't think it is compiler magic that allows event handlers to work with return void. I forget the actual mechanism
We made the same decision ten years ago and I've taken a lot of flak for it because it's not "free". Other than the potential cost of servers, .NET has been an awesome platform and has allowed us to share a giant portion of our code across the desktop, web, and non-interactive services. 
"The virtue of the 3x await pattern is that all three of those processes can be running simultaneously, and the order that they complete is not relevant." This is just wrong! They will happen sequentially.
Technically not even they guarantee a new thread is created in most cases. You simply queue up tasks and let the system decide if it should create a new thread, run on another thread or even be run on the current thread. It all depends on the parameters used and which thread is the originating thread.
The three will definitely always happen sequentially, but they will not block the thread issuing the await. 
https://msdn.microsoft.com/en-us/magazine/jj991977.aspx It looks like you're right, some of the other documentation Ive read made it sound like it would actually run synchronously because it could not be awaited on.
I would assume so, but I haven't used Unity at all so I couldn't test it for you. :P
There might be a way around it, but something like this: void DoStuff(ISettings DI_Settings) { DI_Settings.doStuff(); } vs. void DoStuff() { Factory&lt;ISettings&gt;().Make().doStuff(); } We basically need to pass around settings for our connection strings and enabled/disabled features.
This site: http://norvig.com/ngrams/ might help. The files aren't necessarily in the format you asked for, but it's not difficult to change them.
`await` does not, but the function you are awaiting might. It isn't supposed to, but you can't know for sure without examining the code.
Your second example looks just like a static service locator which usually should be avoided. If DoStuff has a required dependency on ISettings, it's better to make that explicit in the method call.
So a few questions - what is wrong with the example on the MSDN page? I'm guessing you mean [this one?](https://msdn.microsoft.com/en-us/library/system.security.cryptography.rngcryptoserviceprovider.aspx). It has a "dice roll" example. Can you be a bit more specific on how you want it to be different or what is confusing? Is it the "IsFairRoll" part? Or the fact that it only generates random byte arrays (byte[]), and you want a more standard numerical type like int? (although I'd image for a dice roll, a byte should be plenty)
You can use [ConfigureAwait(false)](https://msdn.microsoft.com/en-us/library/system.threading.tasks.task.configureawait.aspx) on your Tasks if you don't need the original thread context.
There's a strong preference to avoid async void calls. This is done for readability and code maintainability because it communicates to the caller that the method is asynchronous.
Basically I want to be able to get a random integer between one and a number specified by the user. The example seems to do something completely different to what I desire. I ran the code and it's distributing 25000 between a number of different slots. I don't fully understand the code enough to make modifications to it. The three sections of the code appear to be all necessary. I'm sure there's a lot that I don't need, considering it's doing a lot more than giving a result of a number between 1 and X. 
It blocks execution of the next statement until the Task completes, but the underlying thread is not blocked. While waiting for an I/O bound task to complete, **there is no thread**. There is a lot of magic going on under the hood for I/O requests. Let's take the conceptual (aka synchronous/blocking) approach to reading a file. * You ask the .NET framework to read the file. * The .NET framework asks the OS. * The OS asks the driver. * The driver issues the request to the hardware. * Driver waits for response * Response is returned up the chain. Code looks like this: public string GetFileContents(Path filepath) { try { return File.ReadToEnd(filepath); } catch (IOException) { // Handle error } } public void DoSomething() { string contents = GetFileContents(filepath); MessageBox.Show(contents); } This code is easy to read, but it blocks the thread. I'll get into why that is not desirable later. It also isn't true. The OS and driver are always asynchronous, the .NET framework just makes it look otherwise by blocking your thread. Now, let's try that again with a bit more detail. In a fully asynchronous model (with OS level simplified): * You ask the .NET framework to make the request and you tell .NET to invoke Method A when a response is received. * The .NET framework stores the pointer to Method A and asks the OS to make the request. The .NET framework asks the OS to call method B when a response is received. * The OS stores the pointer to Method B and asks the driver to OS make the request. The OS asks the driver to call method C when a response is received. * The driver stores the pointer to Method C in association with the low-level protocol's identifier. It then operates the hardware, relinquishes the thread back to the OS. * The OS relinquishes the thread back to .NET. * .NET relinquishes the thread back to your application. * This thread exits or returns to the threadpool. * **Nothing is happening. No thread is processing anything. There is no thread.** * The hardware gets an interrupt signal. * The driver processes the interrupt signal. It gets the protocol identifier and the content. It looks up the callback method (method C) associated with the identifier and invokes it with the received content. * In method C, the OS looks up method B and invokes it with the received content. * In method B, .NET looks up method A and invokes it with the received content. In your application code before `async/await`, it would look like this: // Generic file read method public void BeginGetFileContents(Path filepath, Func&lt;string, object&gt; callback) { var callbackState = new GetFileContentsState { Callback = callback }; try { File.BeginReadToEnd(filepath, callbackState, this.EndGetFileContents); } catch (IOException) { // Handle error } } public void EndGetFileContents(IAsyncResult result, object state) { string fileContents; try { fileContents = File.EndReadToEnd(result); } catch (IOException) { // Handle error } var callbackState = (GetFileContentsState)state; if (state.Callback != null) { state.Callback(fileContents); } } public void BeginDoSomething() { this.BeginGetFileContent(filepath, this.EndDoSomething); } public void EndDoSomething(string contents) { MessageBox.Show(contents); } private class GetFileContentsState { public Func&lt;string&gt; Callback { get; set; } } This how you *should* have been writing before `async/await`. No threads are ever blocked while waiting for I/O. The problem is that you end up in callback hell really quickly. With `async/await`, you can rewrite as such: public async Task&lt;string&gt; GetFileContentsAsync(Path filepath) { try { return await File.ReadToEndAsync(filepath); } catch (IOException) { // Handle error } } public async Task DoSomethingAsync() { string contents = await GetFileContentsAsync(filepath); MessageBox.Show(contents); } This code as the same conceptual overhead as the blocking version, but `async/await` essentially generates all the Begin/End methods (it's more complex than that and .NET uses a re-entrant state machine, but conceptually, it is the same). Now, what are the benefits of all this asynchronous crap? You don't block threads. The threads that start the call return back to whence them come. There are several reasons why this is beneficial: 1. **Threads are a valuable resource.** A thread costs about 1MB of memory split between the OS and the program, and that needs to be allocated which is expensive when compared to not allocating them. In a 32 bit program, this can suck quite a bit of address space if you create lots of threads. Yielding threads back to callers allows them to be re-used. The .NET threadpool actively biases against creating new threads for this reason. 2. **Avoid context switches** If a thread blocks, the OS is going to try to schedule another thread on the CPU and that means a context switch is due. Context switches are really, really *expensive*. Yielding threads back to callers allows them to be re-used multiple times in the same CPU quantum. If a quantum is 35ms, then a single thread on a web server can typically handle 3-4 requests if the underlying requests are asynchronous. 3. **Keep applications responsive** In a GUI environment, only the UI thread is allowed to edit to the UI. If that thread is blocked waiting for a server halfway around the world to respond, then when the user tries to resize the window or type or click a button, then our good friend "This program isn't responding" pops up. Anytime a program appears unresponsive, it happens because the the GUI thread is blocked doing something else. `async/await` will even grab the GUI context for you by default so developers don't need to think about that. 4. **Allow web servers to scale** In a web server environment like ASP.NET, there is a threadpool. All requests are handled by that threadpool. If there are no threads available to process the request, then that request enters a queue. Eventually, requests will get dropped. If you block, the thread can't handle a new request while the thread itself is doing nothing. When doing I/O asynchronously, the thread returns to the threadpool and is available to start another request. Let's make this one more concrete. Let's say you have a web server that takes 250ms of processing, does a network call that takes 500ms, and then does another 250ms of processing. In that case, an asynchronous web server will be able to handle 2x as many calls in the same time period as the synchronous one. In real life, those numbers are much closer to 10ms of processing, 500ms of waiting, 10ms of processing. In that case, the asynchronous web server will handle **20x** as many requests in the same time period. Edit: Thanks for the gold stranger.
As an aside, if you want Thing1, Thing2, and Thing3 to run in parallel, then you can do so with Task.WhenAll Task t1 = Thing1Async(); Task t2 = Thing2Async(); Task t3 = Thing3Async(); await Task.WhenAll(t1,t2,t3); // Process results of t1,t2,t3.
I am not sure that link is working. Do they have something that shows how it is used? When I have been learning other languages I can normally research and it find the answer. Or is there a book you would recommend?
await means "do this on some other thread and when you're done come back to this thread and continue form the next line." This is not really how it works, but I think it explains the program flow... public async void btn_Click(object sender, EventArgs e) { string txt = await GetTheTextAsync(); lblText.Text = txt; } ...becomes... public async void btn_Click(object sender, EventArgs e) { // thread A DoThisOnAnotherThread("B", btn_Click(sender, e)); } public void btn_Click(object sender, EventArgs e) { // thread B do { string txt = GetTheText(); }(while txt == null); DoThisOnAnotherThread("A", AnonymousAfterAwaitMethod(txt)); } private void AnonymousAfterAwaitMethod(string txt) { // thread A lblText.Text = txt; } 
Seems like that would be a good use case for [PLINQ](https://msdn.microsoft.com/en-us/library/dd460688%28v=vs.110%29.aspx) since it is in parallel rather than concurrent.
Lets look at a method, async Task DoSomething() { var something1; doSomethingHere(); await AwaitIOBoundTask(); await AwaitAnIOBoundTaskThatDependsOnTheFirst(); somethingElse(); } You might think, what is the point of DoSomething being async? You might also think this would run exactly the same as if AwaitIOBoundTask and AwaitAnIOBoundTaskThatDependsOnTheFirst weren't async. Well what if we later called that method like this... var arrayOfTasks = someArray.Select(x =&gt; DoSomething()).ToArray(); Tasks.Wait(arrayOfTasks); //or await Tasks.WhenAll(arrayOfTasks); Depending on how how many Tasks are in our array and how long our IO operations take in DoSomething() we can dramatically increase performance beyond what threads could offer. I've used the above pattern to manage hundreds of devices exposing a REST API. I could query them all in 1 - 2 seconds. You can use the same pattern for pinging subnets. Additionally a SemaphoreSlim object can be useful to prevent over-saturating a network connection.
I wish I could express how much I appreciate this. I suppose I will have to fiddle with this for a while, as I don't immediately see how I can access it. I see that it is supposed to be creating a new object, right? I feel like my C# course glossed over classes and objects like it didn't matter. (This isn't a school-related project, FYI) 
The cool thing to think about though is that it is still relatively new. At least in the way it is currently implemented. Which means it has a lot of room for optimization and improvements. So while the trade-off may be poor performance now, with time and improvements by the dot net team that trade-off will just get lesser and lesser until it's almost gone. So if your code is written to properly take advantage of tasks, then you could reap the benefits of both non-blocking threads and performance later on. At least that's what I would think/hope/
From all I've read about it, it's not nearly random enough, due to the way it uses the system time as a seed. Number clumping tends to be the biggest issue, with patterns emerging. I do not want that at all.
I honestly don't know what "parallel rather than concurrent" means, but I'll still attempt to respond. Consider that what I was doing in my example was "naturally asynchronous" I/O--HTTP requests. You can make the requests in parallel, but as I said it just creates a 1:1 relationship between requests and threads. Since there's something outside the system to wait on, and the threads would just block doing nothing while waiting, by awaiting the responses you can have a many:1 relationship between requests and threads (well, I'm mixing my metaphors here, but 1+:1 anyway). Here's an SO answer by noted threading dude Stephen Cleary on the topic: [http://stackoverflow.com/a/17480285](http://stackoverflow.com/a/17480285).
This is perfect! I have an upcoming project which this helps knock off lots of development time! Thank you for this.
What specific pain are you having with the first example? In other words, what is the cost of having the dependency be a parameter?
Also, how do you ensure your factory has been configured to provide all the types you'll need at runtime? When the dependencies are explicit you get that for free at compile-time. With the service locator you don't find out till runtime unless you do some stupid tricks.
There's only a single built-in thread pool, the `ThreadPool`. ASP.NET uses it to handle their requests. 
&gt; From all I've read about it, it's not nearly random enough, due to the way it uses the system time as a seed. That's only an issue if you always create a new `Random` instance. Ideally you should just create one per thread and re-use it.
More than that. Since these methods don't return a task there's nowhere to store an exception so one being thrown from an `async void` method crashes the process.
Task.Run doesn't accept the parameters allowing to request a new thread (unlike Task.Factory.StartNew) so there's no case in which Task.Run directly creates a thread. It always uses the ThreadPool. 
I may have misunderstood so please correct me if I'm wrong. You want to perform an action depending on the values in one or more properties in one or more classes? I would think the best way to do this would be have the logic in your view model and have the Icommand implementation on the button check these properties and classes and act accordingly. 
if i want to use this .cs file in other projects ?
And in most cases that thread context isn't needed until back at the original user code call site.
It's probably best, then, to build Player into a separate library project. At that point, you can either reference the resulting DLL, or you can add the library project to each solution and reference it that way.
The issue was that we'd have to propogate the settings through a hierarchy of objects and it just ended up being everywhere. I didn't have so much of a problem with it as my coworker did, but this was just one of the potential solutions he came across in some resource he found.
You can't be doing things that in any way depend on each other or some common resource in parallel. Well you can, but you'll have to very carefully manage resource contention which can be very easy to mess up and cause deadlocks. If you're running into this, you probably don't have a good use case for parallel processing. Sometime it might be worth dealing with the complexity in critical sections of code though.
You would unit test it by calling `Factory&lt;ISettings&gt;().Set(() =&gt; new CustomSettings());` in each test. I don't think we'd be able to parallelize the tests with it.
Good point.
You couldn't parallelize it with that, without the usage of AppDomain / new process for each test. This wouldn't even be safe testing, because it would leave "dirty" residue from previous tests.
Why would the settings need to be propagated down the object graph? Are you newing up a service in one of the clients and passing the ISettings as a constructor arg?
Easy, just connect the dine to the model while you're prismically active
Be careful with your wording... *Task.WhenAll* still runs the tasks asynchronously on the same thread. 
Put your Player class in a separate project, the project type can be "class library". This will create a dll when you compile the project. In C#, unlike Python, you don't reference libraries through the source code (.cs file), but from the compiled binaries (e.g dll). There are two ways to do it, by referencing the dll or by referencing the project from another project. If you reference a project the player code will be compiled when you build your solution, but if you reference the dll you simply reuse the compiled code. After you have out your Player code in a class library, create a 2nd project, e.g a console application. In the tree view showing the code files, right click on the project and select add reference. Either add a reference to the project (if both are in the same solution) or browse to find the dll. You can now access player through using nnnnn;
 async Task DoSomething() { var obj = await GetObjAsync(); await DoIt(obj); } means conceptually this (simplified and renamed some things and used a `TaskCompletionSource` to make it easier to follow; the actual pattern is a little more complex mostly to avoid allocations): Task DoSomething() { var sm = new DoSomethingMachine(); sm.State = 0; sm.MoveNext(); return sm.Task(); } class DoSomethingMachine() { TaskCompletionSource&lt;int&gt; tsc = new TaskCompletionSource&lt;int&gt;(); public Task Task =&gt; tsc.Task; public int State; object obj; public void MoveNext() { switch (State) { case 0: GetObjAsync().ContinueWith(Continuation1); break; case 1: DoIt(obj).ContinueWith(Continuation2); break; } } void Continuation1(Task&lt;object&gt; t) { obj = t.Result; State = 1; MoveNext(); } void Continuation2(Task t) { tsc.SetResult(0); State = -1; } }
This is actually going to be implemented in a simulation I'm creating that will involve heredity and evolutionary traits. Multiple actors in the simulation will reproduce, generating new actors with randomized traits. This will keep going and based on programmed environmental factors, I'll see them either evolve or die in the attempt to fit their environment. The number of unique traits will number in the thousands, as I'd like to see if multiple different "species" result.
Most likely `Random` will be fine for your use then (assuming you use it correctly with a single instance). If you try to roll your own, there's a good chance there could be bugs or subtle issues (such as distribution issues noted by /u/davore) if not implemented correctly. Furthermore, apparently `Random` is a good deal faster than `RNGCryptoServiceProvider`, so that could help in your simulation if you're making many random numbers very rapidly over long periods of time. (EDIT: Although, this probably won't be a concern at this point Perhaps _most worthwhile_ though is the ability for you to provide a fixed seed. You can write test simulations that use the same fixed seed. With that, you can investigate bugs in your code, or make algorithm modifications and inspect the outputs without injecting true random variability into your tests. Sometimes it can be brutal to debug issues when you have random factors involved. Write up your program to track the starting seed (just use `var seed = Environment.TickCount; Random r = new Random(seed)` and store that `seed`; this is the same procedure used in the `Random` source code). Then when your program throws an error or produces results, also output the seed used in that run. When you need to repeat your results or debug an issue or investigate an unexpected output, you have a starting seed with which to reproduce the run. If you like, make your own wrapping class around the `Random` to feed you numbers. This way if you feel the need to replace `Random` with `RNGCryptoServiceProvider` (or another random implementation), it's trivial for you to do so and requires zero modification to the rest of your application.
The name of the assembly is in the project properties. It is literally the first text box there, and it is what controls the name of the assembly file that is created. Are you building on a remote server, or does this happen locally? If the latter, is there some reason you can't pick up the solution and drop it in a directory that's not down a 200-odd character path?
X-Post referenced from /r/vscode by /u/KSubedi [I created a VSCode extension to search, add and remove Nuget packages for .Net Core from within VSCode.](https://www.reddit.com/r/vscode/comments/4szfx4/i_created_a_vscode_extension_to_search_add_and/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Your statement doesn't make any sense. Context switching is a cost associated with new threads.
Not to be snarky here, but "runs tasks asynchronously on the same thread" is a bit of a contradiction in terms. Indeed, `Task.Whenall` doesn't *run* tasks at all; it simply waits for all of the supplied tasks to complete. Are you thinking of `Task.WaitAll`, which would block the calling thread until all tasks complete?
Lots of lists like these show up on reddit. This is an extraordinarily good one. Thanks OP!
I see. I thought the copy error was occurring as part of the build process. Good luck with your debugging, then.
And with the introduction of .Net Core, the whole "not free" aspect is a non issue now. I have not used Windows in the last 5 years, and I am currently using .Net to develop at work as well as for my personal projects on Macs. I'm excited for whats to come with ASP.NET Core and .NET Core. 
I learned most of what I know about c# from Venkat. And its completely free. https://www.youtube.com/watch?v=SXmVym6L8dw His goes over everything in detail at careful pace and many examples. I've made several mods for games on my own just from his basic course, and now I'm learning asp.net mvc with him. The sound is very low for his early videos, but its all gold IMO. I can't recommend his channel enough. I swear when I get my first fulltime job, my first paycheck is going to this man.
Awesome, thanks for this! I am pretty new to csharp/programming and this looks great.
Great list! Thanks!
And what does this have to do with C#? 
&gt; In the project you want to use the class in, you'll have to add a reference to the project that has the class. how do i achieve that , i mean , i don't have to put them all under one directory right ? EDIT: i did that , it works. thank you :) . a question though , why is it considered good for every class to have its own file ? 
The mass if-statements could also be refactored for brevity like this: lionPrice += chxLionDaycare.Checked ? dayCare : 0; lionPrice += chkLionHaircut.Checked ? hairCut : 0; lionPrice += chxLionDeclawing.Checked ? declawing : 0; lionPrice += chxLionFood.Checked ? food : 0; lionPrice += chxLionToys.Checked ? toys : 0; lionPrice += chxLionDental.Checked ? dental : 0; lionPrice += chxLionSurgeries.Checked ? surgeries : 0; lionPrice += chxLionVaccination.Checked ? vaccinations : 0; On another note, you should never use `double` for money, always `decimal`. Once you start multiplying and dividing `double` values you're going to end up with really strange rounding errors especially if you don't use epsilon comparisons. See [this StackOverflow post](http://stackoverflow.com/questions/1165761/decimal-vs-double-which-one-should-i-use-and-when) for more details. 
The code OP is asking about is less complicated than what it would take to do proper separation of concern and DI. If you try to do TDD without understanding OOP pretty well then it is going to cause you more problems than you solve. I am not trying to be mean to OP, but I doubt OP knows what a mocking library is or how to do TDD. It would be great for OP to learn, but it's not going to help OP solve conditional / sumnation issues in the short term.
I want to learn 100+ curses in C#.
might be nice if the column headers were clickable to sort the table...like, to get all the microsoft ones together, or all the free ones together or whatever - still, thank you for a great list
...but aren't they just about to scrap that json format and go back to .csproj? That said, what I really like about the VS package manager is detecting the availability of updates. (I actually like the JSON format).
Any suggestions where to learn this?
If you have the chance to make the time commitment (although it's self paced), I suggest you try out the DEV204x course on [edx.org](https://courses.edx.org/courses/course-v1:Microsoft+DEV204x+2015_T2/info). I'm not entirely sure if you can currently enroll (it's not displaying correctly for me on mobile) but if you can, it's a fantastic free course that really took my C# ability from basic, self taught, to being much more capable. It really helped to fill in the gaps in my knowledge.
Always try to think defensively about what you're trying to accomplish. In the real world, you could never take something away from me that I never had to begin with. If I never opted to have my lion vaccinated in the first place, why would you be giving me money for that? The problem domain, I think, falls into what I am probably incorrectly describing as State Abstraction. If I went to an ATM to check my balance and the program asks, "Did you deposit anything?" with the answer being "No", then this code being similarly applied might accidentally deduct money from my bank account. I am not saying everything has to be treated as a critical concept, but when you're dealing with people's money or lives, it is in your best interest to be as objective as possible. This is difficult and takes time, and also why I avoid life-critical and accounting software projects as often as I can. It is too easy to be wrong and the consequences can be irreconcilable.
I think you want to get rid of the mass of if checks entirely. As a general rule, adding more data to your application should not add more code. You could also imagine wanting to do more with each checkbox (for example, add lines to a bill), and the current approach would require lots of duplication. Consider instead the following approach: static Dictionary&lt;CheckBox, decimal&gt; servicePrices = new Dictionary&lt;CheckBox, decimal&gt;() {{chxLionDaycare, 300}, {chxLionHaircut, 100}, // ... }; private void btnCalculate_Click(object sender, EventArgs e) { decimal lionPrice = 0; foreach(CheckBox cb in servicePrices.Keys) { lionPrice += cb.Checked ? servicePrices[cb] : 0; } } A more OO-friendly to do it, though some might not like this approach, is to define a class called ServiceCheckbox that derives from Checkbox and also defines a price. You can then loop through all of the ServiceCheckboxes in the object and grab their prices. The advantage of this approach is that you can have compile-time safety that the prices shown to the user and the prices you calculate with are the same. In a real application, all of this would live in a database, but these approaches all demonstrate some important principles: don't duplicate logic, don't duplicate data, don't write code that grows or requires a rewrite when data changes.
Enrolled and started it now, thanks!
This has been the norm for 5 years or so. I don't think it can be fixed.
Absolutly. Have your on submit call a javascript function to display a loading image until the content is ready. Then load the new page, or display the content via ajax.
Step 1. Remove the razor templates. Use a regular html for element. Set the onsubmit element to call a javascript function. Function loadstuff { $('#loadingdiv').show (); //do async ajax post back here. //set on success to display content or open page. //handle on error too. }
Shiiiiiiit youre the man, that worked Thank you! Must have accidentally switched that setting, i didnt even know VS had that option. I wish it was that easy to fix the false XAML errors
The StackOverflow post: http://stackoverflow.com/questions/38417465/c-loading-icon-when-pressing-submit
As a beginner you should not ever use pointers. Can you share code with what exactly you mean and what you're doing?
Currently I haven't actually started. But I want to be able to get specific game data from the emulator, which will give the bot information about what it should do.
Your idea there seems like the easiest solution, given that there seems to be rather arbitrary combinations of categories and may or may not overlapping values.
If you do need to deal with interop, you can use unsafe code and IntPtr, but depending on what you need to do you may not need to.
Can't find it on mobile, but hit up YouTube. 
I've worked on a project that did this. It was horrible. Simply a maintenance headache for very little reason. IMO, your different versions should be entirely different sites ([how to](https://dotnetcodr.com/2013/12/12/web-service-versioning-in-iis/)) that way you don't need to rename and refactor whenever you publish a new version, you just publish it into a different folder. Another upside is that it is truly a snapshot - the entire api/logic/data access stack is in there, so you don't have a worry that MethodX called between v1 and v2 changed and was behaving differently. You do still need to be aware of breaking changes in your database though, so know that there are times when certain api versions will need to be shut down completely.
Tbh, pluralsight is your best bet. You can get 1 month free if memory serves but honestly? It is worth the investment. Some of the best education I have ever received, worth far more than the actual cost of it. 
If you make an account for the free visual studio, Microsoft will give you a free 6 month account.
If you make an account for the free visual studio, Microsoft will give you a free 6 month account for pluralsight.
Couple quick things: 1) I see try/catch blocks that don't do anything and just throw. Those can be safely removed with no change to the logic. 2) I would use the built-in IPAddress class when working with IP addresses instead of slinging them around as strings. 3) The NICManager class doesn't seem necessary. You already have the NetworkInterface built-in class to give you back NetworkInterface objects and sorting/filtering can be done with LINQ. IEnumerable&lt;NetworkInterfaceType&gt; nicTypes = new[] { NetworkInterfaceType.Ethernet, NetworkInterfaceType.Wireless80211, }; IEnumerable&lt;NetworkInterface&gt; nics = NetworkInterface.GetAllNetworkInterfaces() .Where(nic =&gt; nicTypes.Contains(nic.NetworkInterfaceType)) .OrderBy(nic =&gt; nic.Description); 4) The CheckIP function is unnecessary since you can use the built-in IPAddress.TryParse static method to tell you if the entered IP is valid: string mightBeAnIPAddress = "1.2.3.4"; IPAddress address; if (IPAddress.TryParse(mightBeAnIPAddress, out address)) { // The value was a valid IP address and the address variable is now populated. } else { // The value was not a valid IP Address. } 5) I see mention of an "IP Profile" which I would expect to see a separate class for. Looks like it's just a simple class with two properties: an IPAddress and a string description.
It's not a video series, but this book (which has a free web version) is great: http://gameprogrammingpatterns.com/
The Coding Blocks podcasts are also a pretty good source - although not videos. I've been making videos on YouTube, to demonstrate different design patterns with C# code. These are what I've got so far (I try to create about two videos a month). [Factory](https://www.youtube.com/watch?v=Y5X4odRW00M) [Singleton](https://www.youtube.com/watch?v=nAKN48JiGyQ) [Wrapper/Facade](https://www.youtube.com/watch?v=a2Qh10YjP6Y) [Memento](https://www.youtube.com/watch?v=ofp0o0J1dh0) [Data Mapper and Active Record](https://www.youtube.com/watch?v=xlSZDw5j4GM) 
Overload what? The set method in a new class? That kind of defeats the purpose of it.
Keep in mind that a lot of design patterns are not C# specific (none of the ones you mentioned are). Even the [Provider Model](https://en.wikipedia.org/wiki/Provider_model) is just based on an abstract factory pattern. Design patterns can mostly be used with any language if done properly. You don't have to focus your search for design patterns on just C#. You can look up tutorials for design patterns and apply them to your C# application, no matter what language they are written in. It will be especially easy if they are in Java, as they are so close, and there are a lot of Java resources for learning around.
Yeah plural sight is brilliant. Not worth the full price, but it is good.
Sure, I agree. It's a perspective issue. The additional cost of the source files is not worth a whopping double the cost of the subscription, but the standard account? Paying for itemized condensed professional education? $30 a month is far better than any college fee and far better than any college. The concept of paying 30 a month for video content online used to seem insane and laughable,..... but personally once I realized it is not tv shows I am paying for, it is literally a huge marked increase in my marketable skills, my worth as an employee and my personal level of education.... then yeah, worth it :D
Yeah, I think if I wasn't paying so much for my education I would probably have a subscription. I don't care much for Lynda.com if you've ever tried that, the lectures seem lazy 
We should celebrate by having a CSS design change.
Aside from the obvious reasons already mentioned, such as keeping the UI thread free while doing some work in the background, it's also used to maintain the flow of your code. For example with WPF/MVVM consider the following: public class ShowSaveFileDialogMessage : MessageBase { public string Title; public string Filter; public Action&lt;bool, string&gt; Callback; public string Filename; public string DefaultExt; public ShowSaveFileDialogMessage(string title, string filter, Action&lt;bool, string&gt; callback, string filename = "", string defaultExt = "") { Title = title; Filter = filter; Callback = callback; Filename = filename; DefaultExt = defaultExt; } } public class ShowOpenFileDialogBehavior : Behavior&lt;FrameworkElement&gt; { protected override void OnAttached() { base.OnAttached(); Messenger.Default.Register&lt;ShowOpenFileDialogMessage&gt;(this, ShowOpenFileDialog); } private void ShowOpenFileDialog(ShowOpenFileDialogMessage m) { var dialog = new OpenFileDialog() { Title = m.Title, Filter = m.Filter, DefaultExt = m.DefaultExt, Multiselect = m.Multiselect, InitialDirectory = Environment.GetFolderPath(Environment.SpecialFolder.MyDocuments) }; var owner = Window.GetWindow(AssociatedObject); var dialogResult = dialog.ShowDialog(owner).Value; m.Callback?.Invoke(dialogResult, dialog.FileNames); } } This allows you to send a message from the ViewModel to display a OpenFileDialog but you have to handle the result in a callback. This completely breaks the flow of your code and if you have a lot of nested callbacks (think JavaScript) it becomes pretty messy very fast. Another problem is that you cannot use the result outside of the callback public void Foo() { var message = new ShowOpenFileDialogMessage("Select a file", "*.doc", (confirmed, filename) =&gt; { if (confirmed) { //Do something with filename } }); MessengerInstance.Send(message); /* cannot use filename here, unless you add additional code * that waits for the callback for example using an AutoResetEvent or TaskCompletionSource */ } It doesn't block the UI thread, but it's not exactly clean either. However, you can easily wrap this like so: public static async Task&lt;Result&lt;string[]&gt;&gt; Send(string title, string filter, bool multiselect = false, string filename = "", string defaultExt = "", IMessenger messengerInstance = null) { var messenger = messengerInstance ?? Messenger.Default; var tcs = new TaskCompletionSource&lt;Result&lt;string[]&gt;&gt;(); var dialogMessage = new ShowOpenFileDialogMessage(title, filter, (c,s) =&gt; tcs.SetResult(new Result&lt;string[]&gt;(c, s)), multiselect, filename, defaultExt); messenger.Send(dialogMessage); return await tcs.Task; } Now you can rewrite the Foo method as: public void Foo() { var result = await ShowOpenFileDialogMessage.Send("Select a file", "*.doc", MessengerInstance) if (result.Confirmed) { //do something with result.Value } //The flow of your code is not broken and you can continue to use result.Filename } Showing an OpenFileDialog like this isn't about doing some heavy work on the background, it's just something that needs to hapen outside the normal flow of your code and async/await allows you to do so without breaking that flow (and keeping the UI thread clean as a bonus) /edit Result&lt;T&gt; is just a helper struct for this specific implementation, you could solve it any other way public struct Result&lt;T&gt; { public bool Confirmed { get; set; } public T Value { get; set; } public Result(bool confirmed, T value) : this() { Confirmed = confirmed; Value = value; } } 
C# examples might still provide an advantage. The strategy pattern will make more sense to a c# developer if it is using lambdas syntax and Funcs than if it is implemented in delegates or function pointers.
Design patterns are not language specific, they are language agnostic. http://www.tutorialspoint.com/design_pattern/design_pattern_overview.htm https://en.wikipedia.org/wiki/Software_design_pattern Might as well start there.
I think this could get messy. Very quickly. 
Better than what I was expecting! Good job!
The first sentence doesn't really help your case...100 hours is more than enough time to at least even accidentally discover an explanation of how classes work. This is anecdotal, obviously, but long before I learned C# in school, I self-taught myself a lot of C++, and classes were one of the things that appeared in pretty much any reference material. I learned them after maybe ~10 hours with the language, and it gets far more complex than C#.
Sorry, but i am a little confused by your first sentence: &gt; there's no way to specify the instance on which to invoke the &gt;method. Unless you plan to add a way to select that, it only makes &gt;sense for user to invoke static methods. I understand now that it probably does make more sense to make the methods static as i will only be executing the code inside once, but i was just a bit confused why it the methods have to be static? I was going to lists all the methods of a class, have the user select which method and then have the user manually enter each parameter.
Could you be a bit more specific about what i have to do?
If you have ReSharper you can use the NuGet search to do a full text search through all NuGet packages (i.e. Nuspec files) in the NuGet Gallery, and look for packages that have .NET Core dependencies or something of the like.
Not really. The old code simply becomes "archived" on its version. If some breaking change happens in the data layer or other outside service you just shut down that old version because of incompatibilities. Whenever you create a new version you want to have a sunset plan in mind for the old version(s). Keeping legacy apis around forever is not a good thing
a quick google found this: http://mp3splt.sourceforge.net/mp3splt_page/documentation/man.html run it with the Process class with args created from your UI.
All of it? That represents years of learning while in context. You could learn this by reading a pile of books while creating projects to work on the concepts as you go. Code Complete, a book on DI/IoC, and a book on TDD (specifically in that order) while having experience in a multi tier system would probably be a good start. You could have a superficial understanding of it by just reading up on the concepts through blog posts, examples, and videos / podcasts without the years of experience on the side, but its more about understanding *why* and *when* you want to do these things instead of *how* to do them. Not every project needs to use root composition DI with scoped lifecycles and 100% TDD code coverage (that would be overkill and a waste of time in some projects, and actively harmful in a select few others).
Don't have your visual studio handy to write an example..... But use reflection to enumerate the methods of a class. Then use reflection to enumerate the parameters of selected method. Then create logic to create a user input for said parameters. Then use reflection to invoke above method on a instance of a class, and pass said parameters. It's actually pretty easy. If I remember I'll post code tommorow. 
Thanks. Making the videos is helpful for me. It forces me into thinking deeper about the patterns (when to use them, the positives and negatives, etc.) - instead of just using them the way I typically do.
Be honest, did you lower the pitch? 
Yeah, it's the best! I use this heavily. Indeed, I'm not sure I'd cope without it
I publish as much as possible to internal NuGet repositories. Manage internal releases. To keep everything sane. On rare occasions i use git subtree.
Have you looked at the [MediaEditing UWP sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/MediaEditing)? It should allow trimming and clipping. [The code](https://github.com/Microsoft/Windows-universal-samples/blob/master/Samples/MediaEditing/cs/Scenario1_TrimAndSaveClip.xaml.cs) looks pretty simple too, and it doesn't require any 3rd party libraries. I haven't tried it with MP3, but it should work fine. Let me know!
Some people definitely do it wrong, but a lot of the time there isn't actually any way other work to do until you get the result back. For example, a lot of server side works flows are going to be sequential in regards to a particular request, rather than concurrent. In which case async await code doesn't provide any benefit to the time taken to complete individual requests, but it does mean that more requests can be served per thread.
You can use msbuild to interact with env variables. On mobile but I can follow up with some more specifics later 
do you mean apps to teach you it, or app / project ideas to make with c# that would help you learn
Lynda and Pluralsight's authors are on totally different levels. Pluralsight is worth it.
Im starting from scratch so what book(s) would you recommend aswell??
You don't have to use MVVM if you feel that it's unnecessary or overly complicated. The pattern is designed to make everything more fluid and modular. That kind of modularity requires you structure your program in a, frankly, pretty convoluted way. Feel free to work in a way that makes it more comfortable to develop for you/your team. Alternatively, if you do want to continue with the MVVM pattern but are having trouble understanding/implementing it, try one of the many MVVM frameworks that give you more to work with: [Prism](https://msdn.microsoft.com/en-us/library/gg406140.aspx) [Caliburn.Micro](http://caliburnmicro.com/) [MVVM Light](http://www.mvvmlight.net/) 
http://stackoverflow.com/questions/2734810/how-to-set-the-location-of-a-wpf-window A canvas and usercontrol aren't windows so it doesn't make much sense to set their location and expect the window location to change. &amp;nbsp; For really simple apps like this it's perfectly fine to use WinForms or WPF without MVVM.
They are counting something else, see https://github.com/edebill/modulecounts/issues/19
The start up time for a WPF project are in general a bit longer than WinForms (especially if you haven't done it before). But when you have all pieces it's a pretty smooth ride and you will see that it will go a lot faster than WinForms. So I would actually recommend to take the long way here and try to learn WPF/MVVM as you will benifit a lot from it in the future. Simply grab MVVM Light and look up some tutorials. It have all the necessary tools (like command, dependency injection, view model binding etc) to start and if you need anything more advanced later you can just switch.
Yes, I guess that would be best. 
Add and remove accessors are not thread safe by default. If you don't implement your own add/remove the c# compiler will use Interlocked.CompareExchange https://msdn.microsoft.com/en-us/library/system.threading.interlocked.compareexchange(v=vs.110).aspx to add and remove event handlers. CompareExchange is used to prevent any race conditions between updating the event’s backing field and reading from it.
&gt; I am using Visual Studio 2015, and anything with WebForms is normally an older version Pro tip: use the "Quick Launch" in the upper right to quickly figure out where a certain menu is. It's the easiest way that I've found to deal with menus that have moved since a previous version. &gt; this ended up being my first commit to our Github project Awesome! Glad I could help. Let me know if you have any other questions. I'm primarily a C# (specifically, MVC) guy, but also dabble in PHP (Laravel, Magento) a little.
Makes sense. &gt; If you don't implement your own add/remove the c# compiler will use Interlocked.CompareExchange to add and remove event handlers. I trust you, but I'm wondering if you have a reference for that. Also wouldn't that imply we *don't* need a lock for that example then?
While you are 100% correct, I wouldn't bother implementing locks for non-static events unless I was advertising the class as thread safe. 
Zork 
Amazing. I develop for multiple stacks. So this should very useful. Just made this as my startup page inside VS. thanks for sharing.
Your switch statement isn't inside a method of any kind. Place the code in a method and it should work. Sorry. On mobile so can't give a more detailed answer. Looking again at your code replace the "throw" statement in the method already there with your switch and then go from there. 
No, it's not stupid at all. I find that usually when you understand why one thing won't work, it makes it easier to understand something else that will.
All right, thank you. Do you know of any good resources on how exactly to set this up? I have not found any good actionable guides on the MSDN website. It's mostly just shallow discussion about what is possible.
You need to have the switch statement in some type of method 
The purpose of Wpf is to replace winforms, not coexist with it, so knowing that I'd plan on doing it the new way now instead of investing in the loser.
I can second the learning curve on on WPF with MVVM. I'm glad I learned it, but I spent a lot of time referencing other people's code to figure out what was going on (it was a team project) Push through!
I learned from: Murach's C# 2010, although I'm sure there's an updated version.
Alright when I try to build I get this error now... http://i.imgur.com/zlSn5Hs.png
Its just a basic hello world program... but in a complicated way
Well, T4 just lets you auto generate C# files from a template during build or in response to some IDE action. If you're just exposing environmental variables to your code, all you really need is a class with a bunch of `consts string`set to the value. T4 is just one way. You could also just accomplish it with a single MSBuild script that plops all the variables into a generated class file in obj, and has that file included in the build. Basically, doing IL stuff seems way more than is necessary. 
It executed, and I was met with the same error
I guess I misunderstood. I thought that variable could be declared on the fly and interpreted by the compiler based on the output... thanks for clearing it up 
If you're looking for the largest multiple of `x` that is less than `y`, you can just do `y - (y % x)`, which will subtract the remainder and give you what you're looking for. x= 5, y=33 `33 - (33 % 5) = 33 - 3 = 30` x=6, y=22 `21 - (21 % 6) = 22 - 4 = 18`
C# is strongly typed, you cannot assign a variable without first assigning it a type. Unless you use the "var" keyword before assignment. Then the type will be assigned at run-time but can still be checked at compile time (At least I think that's how that keyword works).
I think his overall question is just how a switch statement works. In this case though he should clean up the program before doing anything.
No idea about the StringFormat, but you could probably use a Converter, if it doesn't work :)
Coded Ui is on its way out. Most if microsofts new documentation is how to use web driver for browser tests. I think they will eventually stop supporting coded Ui for desktop as well.
Coded UI interacts with the desktop so it needs to be run in an interactive session (e.g. User logged in, screensaver and other things that can block your test from running not activated). You can achieve this through Microsoft's offerings (lab management or their new build definitions work also, I think), or you can home bake your own solution, but it won't be really easy.
Several reasons. 1. They want to prove to you the validity of the software. By providing the code transparently, you can see for yourself that it does what it says it does, and nothing more. 2. They want to entice you to contribute. If you want to improve something about the plugin, you are almost always welcome to submit your change in a pull request. Crowd sourcing your development can be extremely powerful, if properly managed. 3. They might be accepting feedback, bugs, ideas, etc. via GitHub issues. 4. They might hope you look at their other repositories and see something else you like.
I don't get why posts like this get down voted. Were not each of you, at some point in time, needing help understanding how to syntactically implement some language construct?
Most people will never implement an event accessor. 
Thanks, I'll have to research that
Why are you trying to write C++ in C#, instead of writing C#?
&gt; I thought that variable could be declared on the fly Well, yes, but a variable *declaration* is where you tell the compiler what the type of the variable is. &lt;type&gt; &lt;variableName&gt; [ = &lt;expression&gt;]; e.g.: int i; string s = "hello"; var screen = this.LoadPortletView("..."); You're not *declaring* a variable, you're just using it. On another note, a `switch` statement with only a default case is pretty useless. 
http://instasharp.org/Documentation/html/c688497b-86a9-4040-b9e0-addb972beed8.htm
This is just a reference layout("framework") for designers and you only use the icons, fonts and given color swatches. It is the task of a Designer to make this vision coming true by using Expression Blend.
At the end of the method, results[] contain the correct rotated list, but you haven't stored it anywhere. Store them back into items[]
I assume Thread thread = new Thread(injectJavascript); does not compile since `injectJavascript` has the wrong signature...
You could remove items from the end and add them back at the start: void Main() { var lst = new List&lt;int&gt; { 20, 30, 40, 50, 60, 70 }; // rotate right three times for (int i = 0; i &lt; 3; i++) { lst.Insert(0, lst.Last()); lst.RemoveAt(lst.Count - 1); } Console.WriteLine(String.Join(", ", lst)); } 
Yes, but where can I find the example with System.IdentityModel.Tokens.Jwt?
What are you trying to do? Because it sounds like exactly what the guy above said: &amp;gt; why are you writing c++ in c# So give more details on your problem, what you're trying to do, what is it you're trying to accomplish? Because I can almost guarantee with absolute certainty that you're doing it wrong right now. Are you trying to make a thread pool? An API? A website? There's already stuff for that and most of it is already built into suitable C# frameworks...
Exactly what I said. The SPA example within IdentityServer4 samples repo :/ I'm on mobile... 
&gt; I am not sure what is wrong with my code. Why do you think something's wrong with your code? You've not said what it does that you didn't expect (or doesn't do that you did expect). A clear problem description is really useful! Is Test8 (a poor name for a method, IMO, but that's another topic) supposed to modify `items` ? Because you're not doing anything to change the contents of `items`. Your rotated list of items is in `results`, but you don't do anything with `results`. And your method returns nothing. What is it that you actually want the method to achieve? You could either return `results` (thus changing the return type from `void` to `int[]`) or copy the contents of `results` into `items`. IMO returning the transformed list is preferable to modifying the passed-in list. 
Hi Graumm. When using a class type in C# you are implicitly making a request to the runtime to manage the memory for you (via GC). The concept of manual memory management with classes (as opposed to structs) is not one you should really even entertain. In practical terms, there is no general purpose way I know of to shallow copy a class type object's contents. You can not pin managed types on the GC heap (the runtime won't allow it) because it's an almost meaningless operation: References inside the pinned object would still be subject to change randomly by the GC, even if the object itself could not move. The best advice I can give you is to implement a private `CloneTo` method on the class/classes that you wish to pool. Don't use reflection, the overhead is far bigger than any overhead from extra garbage. If you have a lot of types that you want to implement this cloning behaviour on, then please consider the fact that C# is not the right language to be doing this in. Object pooling is a valid pattern in certain cases, but most of the time you want to be taking advantage of the GC rather than trying to circumvent it. Also, side-note: &gt; Can anyone help me on my journey to cache-coherency heaven? What you're trying to achieve is cache *locality*. *Coherency* refers to synchronization between cores/their caches in multithreaded scenarios.
Looks OK to me, except that you're creating an array instead of a list, and you're not returning anything at all. You either need to clear out `items` at the end and put the contents of `results` in there, or create a new list and return it.
yah this all seems natural and useful for something like EF or Automapper or any reference library. MY question was about repositories that are more of a post-compile usage (dont know what else to call it). Like compiling the visualstudio repo and then having a funcational but personal visual studio versionthat I build from within the default visual studio.
Lynda is TERRIBLE. I subscribed for one month and threw it away real fast. I do however like Code Schools, but am planning to ditch that for Pluralsight.
Alright guys. I'm going to tell my C++ brain to be quiet and err on the side of simplicity. I'm just going to maintain two lists for alive/dead components, and not try to memory manage. Some cache misses are better than letting the GC run rampant, though. I'm not going to allow new allocations because I'm going to hammer this code with untold thousands of objects generated procedurally inside of a game, and I don't want to deal with untimely GC stalls. I'm not going to try this unless there are noticeable problems, but if I find that this approach is causing tons of cache misses I think I can just throw a unique ID on my component type, assigned at pool allocation time, and periodically sort my alive/dead lists on that ID. It should theoretically keep my memory ~mostly linear.
try &lt;TextBox Text="{Binding Path=Price, StringFormat='{}{0:C}' }" /&gt;
Did he? I don't think he did.
I like to handle all my buttons like this: Add the following RelayCommand class to your project public class RelayCommand : ICommand { private Action&lt;object&gt; execute; private Predicate&lt;object&gt; canExecute; private event EventHandler CanExecuteChangedInternal; public RelayCommand(Action&lt;object&gt; execute) : this(execute, DefaultCanExecute) { } public RelayCommand(Action&lt;object&gt; execute, Predicate&lt;object&gt; canExecute) { if (execute == null) { throw new ArgumentNullException("execute"); } if (canExecute == null) { throw new ArgumentNullException("canExecute"); } this.execute = execute; this.canExecute = canExecute; } public event EventHandler CanExecuteChanged { add { CommandManager.RequerySuggested += value; this.CanExecuteChangedInternal += value; } remove { CommandManager.RequerySuggested -= value; this.CanExecuteChangedInternal -= value; } } public bool CanExecute(object parameter) { return this.canExecute != null &amp;&amp; this.canExecute(parameter); } public void Execute(object parameter) { this.execute(parameter); } public void OnCanExecuteChanged() { EventHandler handler = this.CanExecuteChangedInternal; if (handler != null) { //TODO Why did I comment this out? //DispatcherHelper.BeginInvokeOnUIThread(() =&gt; handler.Invoke(this, EventArgs.Empty)); handler.Invoke(this, EventArgs.Empty); } } public void Destroy() { this.canExecute = _ =&gt; false; this.execute = _ =&gt; { return; }; } private static bool DefaultCanExecute(object parameter) { return true; } } Then you define commands for each button in your view model like so: private bool canExecuteDelete { get { //if collection &gt; 1 return true else false } } private ICommand _DeleteCommand; public ICommand DeleteCommand { get { return _DeleteCommand; } set { _DeleteCommand= value; } } private void Delete(object value) { //perform your command. This could be calling to another class where you are reusing code } Finally I wire up the view in xaml: &lt;Button Width="40" DockPanel.Dock="Right" Margin="8" Content="Delete" Command="{Binding DeleteCommand}" /&gt;
It's already that..?
My git project may be a good start into messing with lower-level code in C#. https://github.com/lolp1/Process.NET
It wasn't supposed to compile. I just quickly typed something up as a sample. good observation though =p 
One simple way to do this is to render the fully expanded tables. Hide the details with CSS. Then use jquery or something simpler to slide open the tables on the relevant click event.
How about a few snippets on how to use this library in the Readme? Also maybe a brief description of how and why this makes network comms better or easier than just using TcpClient or UdpClient? 
Check out parent child tables on www.datatables.net https://www.datatables.net/examples/api/row_details.html
I've been a professional developer for almost 30 years, and it's only in the last decade where I've learned to listen to my instincts. A lot of the time if I don't feel like working on something it's because subconsciously I know I'm on the wrong track. Or I don't understand the problem completely. If I work on it now, I'm gonna fuck it up and have to redo it. Usually if I let it percolate a little bit, when I DO feel like working on it it just flows and it's right the first time. Fortunately until recently I have been able to set my own schedule and I was able to work this way. However, in my current job every minute is measured (for billing purposes) and I sometimes have to work on something even when I'm not really ready to. So in summary, that feeling can sometimes mean that you need to give yourself time to figure something out in the back of your mind. But unfortunately you aren't always allowed to do that. If you can, work on something else until you're ready.
I think this applies to every job. I usually just work on another project for a day or two. Sometimes I'll start a new simple project to teach myself something. Just last week I made a stupid chat app to teach myself ZeroMQ. All on company time! Not everyone may have that luxury. 
1. I saw 0 C# code. 2. Watching someone describe and then drag and drop winforms controls onto a winform is uninteresting and not related to the C# programming language at all (aside from the autogen code built in the form.cs). 3. Winforms is outdated. 
I understand it is all about monetisation, but I'm really not liking people creating videos for things which are better suited to traditional text-based web pages.
This happens to everybody, or at least to a lot of people. Two things that help me: * Realizing that discipline doesn't often follow motivation, but vice versa. That is, much of the time you won't feel immediately motivated to do something, but if you use the tiniest bit of discipline to get started on it, the motivation often builds up quickly after you get started. If you wait until you are motivated without any discipline, you might as well go back to bed. * Breaking tasks into the tiniest chunks possible and then just doing one of them. Sometimes I'll go so far as "I'll just open VS and create the project, or look at the existing code." One that is working for me now is "I will set a timer and work on it for 25 minutes." Usually after you've done one 25 minute chunk it's much easier to jump into a second one. You have a little momentum and, as above, your motivation has started building up.
Removed: Spam. (multiple accounts submitting or associating with fwait content)
Cocaine and speed unfortunately. 
Adderall, and realizing that sometimes boring tasks precede exciting tasks. It's a trade off. Half the things make me feel like a rockstar, the other half is a bit meh. I balance them out to stay motivated. It also helped me to actually take some time off here and there. First years I pretty much never used my vacation days. I still don't use a lot of them, but taking a day when I feel the onset of burnout really helps me. 
Small tasks. If you can sign off on a ticket every hour or two the inertia of getting things done can drag you along.
Sometimes, providing code that works out of the box is correlated with the number of helpful answers you get. 
Hey, nice idea in generating and compiling the necessary clone operation as an expression! I might just give this a go myself, since I use a lot of reflection. 
Note, that distance calculation is costly, even on a plane. (There's a reason why Quake 3 had [this](https://en.wikipedia.org/wiki/Fast_inverse_square_root#Overview_of_the_code)). On a sphere the trigonometric calculations make it even worse. Prefiltering is the key to fast and efficient code. If you don't have to go near the poles, you can heuristically determine for the vast majority of the points whether they are within the given distance from the midpoint. Distance in one dimension underestimates the total distance, obviously. You can use this. Say, you need points within a range of R around point P. Then any point with a north-south or east-west distance from P bigger than R is right out. (You can use the length of the longitude at P unless you're very close to the poles. If you're close to the poles (but not close enough that the pole is within R), use the length of the longitude that is R closer to the equator than P). Manhattan-distance, on the other hand (distance on both dimensions summed up) overestimates the actual distance. You can use this too. Anything with a Manhattan-distance smaller than R is in. (If you're near the poles, use the longitude R closer to the pole than P, otherwise just use the length of a longitude at P). These two steps will vastly reduce the necessary amount of calculations. Again, I have to caution you against using these when you're near the poles. (Or if R is very large.) These are heuristics that are designed for a Cartesian plane, and that falls apart when the curvature is large enough. (Additionally, if the curvature is small enough, like if you're only dealing with a single degree of difference and aren't close to the poles, and the required accuracy isn't "pinpoint", you can just map the polar coordinates to a Cartesian system.) Edit: if you're allowed to edit the DB, you could just transform the lat-long coordinates into 3D Cartesian coordinates and add those. These heuristics work in 3D as well, the remaining distance calculations will use the Pythagorean theorem (which is much faster), and it won't be sensitive to being near the poles anymore. If you go this way, however, you'll have to transform the requested distance into the radius of a sphere that intersects the sphere used for the Earth at points that are at a requested distance on the globe's surface from the midpoint. This sounds complicated, but in reality it's rather simple: transform the coordinates of the center point to Cartesian (you'll have to do that anyway), pick a point that is at the requested distance from that point in the North-South direction (basically: longitude is the same as the midpoint, latitude is the original's latitude - (range / 111 km)), transform that to Cartesian as well, and use its straight-line distance from the midpoint. The initial caching of the coordinates will take a long time, of course, but it will radically simplify the filtering. And of course if the distance of the points is requested instead of just the points that are within a certain range from the center, you'll still have to use the trigonometric calculations.
Removed: Rule 3. This is more appropriate for /r/programming. This is the second time you have had content removed under this rule and I suspect you didn't take or ignored the advice given to you last time. I recommend you start to take a more engaged approach to the /r/csharp community outside of your own content or at the very least familiarize yourself with Reddit's rules and policies regarding spam and self-promotion. Bottom line is Reddit is _not_ an advertising platform.
Removed: You got your answer.
Removed: You got your answer.
targets. for me it's targets: don't just work on stuff, give yourself small tasks and work on them one by one.
I usually lose interest half way through Visual Studio's extremely long boot time. 
I've wanted to push our CTO and team to using git rather than SVN; i've personally used git more and they more svn. Can you elaborate as to why git is better than svn? Anything that can help make the switch is definitely useful in my proposals
I find the work environment affects your productivity a great deal. I've been in places that use Agile project management and have teams of developers working together. With Agile you have a quick meeting every day with your team and discuss what you worked on the day before and what you will be working on that day. I find this very helpful at keeping everyone on track. It's also nice knowing that an entire project doesn't just rest on your shoulders. In places where you are silo'd (working on projects alone for long periods) I find it can be hard to get going some days. Especially if you're stuck on a difficult problem or doing the menial stuff of wiring everything up and testing.
&gt; Can you elaborate as to why git is better than svn? I haven't used SVN in a long, long time; but we went with git over TFVC when we upgrated our TFS servers because it handles branching much better. That has been the main win for us and is reason enough IMO to do it.
Sometimes it's like comparing the earth with the rest of the universe. Yet so much to discover/ to learn, yet we have so little time. It can feel so overwhelming. Anway, trying to learn as much as possible and trying to do things as best as possible keeps me motivated. 
Yeah, I was thinking the exact same thing about TFS. If you're a .NET shop, and you don't mind paying for it, TFS is pretty damn good. You really can't beat it's integration with Visual Studio, and the web portal is great.
And that's just 5 "Basic" user accounts. You can have as many stakeholders as you want. I've found these limits sufficient when working with clients and managers. Even then, a "Basic" user license isn't very expensive.
Doesn't have to be a vs. situation. We use TFS and OD together. TFS handles source control and builds and pushes build output into OD. OD then deploys. 
Sometimes I get stressed because of it. Then I take a brief moment to think why I should learn something. Most of the times it's because I think it's cool and perhaps may give a new insight, which is true. But then I just need to take a step down until my head is clear again. 
Look at his code for ideas about form and structure, and then delete it. Then, write your code from scratch. Doing it this way, you couldn't possibly copy his code, but you can hit the key points of the assignment.
Git is somewhat more robust and flexible when it comes to branching/merging, tags, and everything you'd associate a SCM with. The modern tech ecosystem is also much more friendly towards git; a number of tools are supporting very tight integrations with it. The normal comparison I make is that SVN is a folder tree with blind copies for history. Git actually handles things like a data structure. Do expect to have some severe culture shock when switching over; SVN users will often struggle to adapt. 
I was able to crank this one out a day earlier than I planed to. It ended up being a little bit more complex than I planned originally but I still think it's easy enough to follow. As usual, if you have any questions or suggestions, I'm all ears.
&gt; You need to get off SVN and switch to git ASAP. Why? Is SVN going to suddenly cease to exist next week? Besides the fact that SVN still better for some tasks (binaries, fine-grained access control), at the end of the day all that matters is whether or not the tool meets their needs, not yours. 
Why had I not thought of that? Thanks!
Agreed on everything, but... When does a minute not have 60 seconds, or a day not 24 hours?
Are you calling .DataBind() anywhere on your my_datagridview?
The new RELEASE tab on TFS helps a lot
Hmm ok.. Probably a technicality, but... Us changing our clocks, doesn't mean the internals of time changes. A day has always exactly 24 hours and a minute 60 seconds. It's just that in most calendars, at a certain point in time, we reset the current point in time in our calendar. (so on the day daylight saving time becomes active, that day still has 24 hours. We just move our clocks by one hour). Or to say it differently: we programmers don't have to account for leap seconds/daylight saving time when calculating the number of hours in a single day or seconds in a single minute. It's different when you are calculating passed time over two fixed dates. There you have to deal with shifted clocks (leap seconds occurred, daylight saving time active). Still, doesn't change the fact a (one) minute always has 60 seconds. small side note: POSIX/UNIX time never takes into account leap seconds.
Ah makes sense! Thank you!! I wish it wasnt internal, id like to fuck around with it and see if it makes a performance difference. And as for my string resources I used to use a bunch of static format methods and stored const strings, i feel like theres gotta be a cleaner way to do it.. 
Also the code in the post, is pretty much the entire code. I only left out the connection string and the datatable/datagridview constructors.
The project is a steam trade bot. Before you all say anything about that, it doesn't violate the terms of service, automation software only applies for market sniping bots. https://1drv.ms/u/s!ArzuzVDgUYcOgegz07dOfSbQ_4GZbA The .exe that you need to run is located in, \Steam Trade Botr\Bin\Debug. You may run into a antivirus issue as its trying to connect to steam but it will not harm your PC. If you are that worried scan it first or simply DO NOT run it. 
Octopus deploys. And is very good at it. TFS hosts your source, does builds, manages tickets, and deploys, and isn't terribly great at any of them versus specialized tools, in my opinion. I personally run a pipeline as follows. Mercurial (Hg) via BitBucket for hosting =&gt; TeamCity for building =&gt; Octopus Deploy for deploys You can swap out any of those components for something else, e.g. Hg for TFS, TeamCity for Jenkins, etc. 
Here is what I think I am doing. I take the csv file and read it line for line, using commas in the file to separate the data into columns. I add the first row of the csv to the DataTable my_datatable so that that data will be the headers of the columns. Then I read in each other row in the csv one by one and add them to the data table. After reading in the entire csv into my_datatable, I set the datasource for the DataGridView my_datagridview to my_datatable. So I am adding the data to the datatable and setting the datasource of the datagridview without the OleDBCommand object. However, I am trying to use the OleDbCommand object to actually create a table onto the oracle server and insert it with the data in the csv file with CREATE TABLE and INSERT SQL statements. When I add this into the code, the code no longer adds data to the datagridview, which is why the following lines are commented out in the code above //cmd.CommandText = createTable; //cmd.ExecuteNonQuery(); //cmd.CommandText = insertIntoTable; //cmd.ExecuteNonQuery(); createTable is a string variable where I have created a string containing a CREATE TABLE SQL statement that works in SQL Developer to create a table, and insertIntoTable also a string variable containing an INSERT SQL statement that is set to the current row's data in each loop then executed. And all of the INSERT statements also work in SQL Developer. The Console.WriteLine(createTable); and Console.WriteLine(insertIntoTable); lines are what I used to check what the SQL Statements looked like and to see if the statements were getting created correctly.
In my opinion the C# Programming Yellow book is pretty good. It's a free ebook which you can download here: http://www.robmiles.com/c-yellow-book/
Check the sidebar!
Do you have any experience in another programming language, or are you completely new to programming?
If you want to do it fast, use something like geohashing (https://en.wikipedia.org/wiki/Geohash) to group your data points into buckets. Then apply your distance algorithm to only those data points in the target bucket and those buckets around it (the number of buckets you have to search depends on large you chose your buckets to be). This way simple string comparisons (or even better a hash map) will pre filter your data 
I think you just described a significant part of my relationship... +1
I was just thinking this. Large projects tend to cause me to loose interest.
Next in the lineup is Compression, then after that I'll be doing some UDP examples.
Thanks for catching that (I forgot about it)! I'll make a note in the Recap Section.
if ((Number1 &lt; 0) != (Number2 &lt; 0))
if ((Number1 &lt; 0) ^ (Number2 &lt; 0)) [Logical 'Exclusive Or' operator](https://msdn.microsoft.com/en-us/library/zkacc7k1.aspx)
Are you looking for a XOR (Exclusive OR) comparison? if ((Number1 &lt; 0) ^ (Number2 &lt; 0)) {...}
Thanks. Exactly what I was looking for.
Good point. I didn't really think about that and just really put that line together for the question itself. 
Everyone is saying use xor, but for logic purposes you can also use not-equals. if ( (Number1&lt;0) != (Number2&lt;0) ) 
Removed: Rule 2, Rule 4. OneDrive is reporting it as a virus. Also, this is pretty much a duplicate of [your post here](https://www.reddit.com/r/csharp/comments/4tgo4e/help_unhandled_exception_issues/). Please keep additional comments/questions there unless there is a significantly new question to be made. In this case, since you don't have the source code, you're pretty much shit out of luck. Unless you are feeding garbage in (bad arguments/configuration to the program), then the error is in the program itself and you won't be able to fix it. I suggest you contact the owners of the SteamBot program you are using.
I am trying to put the data into a database. I am just learning for now. I will try to break the code into a couple methods and edit the code in the post tomorrow. 
Within the foreach, replace `input[s]` with just `s`. On each iteration, `s` is the next string in your array. So: foreach (string s in input) { s = Console.ReadLine(); } It's just a cleaner way of writing: for (int s = 0; s &lt; input.Length; s++) { input[s] = Console.ReadLine(); } To specifically answer your question, the error message is because `s` is a string within your foreach loop. The index (the value in square brackets) is expected to be an integer. Edit: Learning formatting here.
You are declaring you want to read 10 strings from the console, agreed? Then you'll need something like: var inputs = new String[ 10 ]; //allocate an array for 10 strings. for ( var i = 0; i &lt; inputs.Length; i++ ) { inputs[ i ] = Console.ReadLine(); } Console.WriteLine(); Console.WriteLine( "Echoing back inputs:" ); //confirm what you stored. foreach ( var s in inputs ) { Console.WriteLine( "\t" + s ); } Better yet would be to use a List(). var list = new List&lt; String &gt;( 10 ); //we want a list with the initial capacity of 10, but not limited to 10. for ( var i = 0; i &lt; 10; i++ ) { list.Add( Console.ReadLine() ); } Console.WriteLine(); Console.WriteLine( "Echoing back the list:" ); //confirm what you stored. foreach ( var s in list ) { Console.WriteLine( "\t" + s ); } 
I started 6~ months ago with no programming experience and I found this resource helpful. Its designed teaching the fundamentals of C# to absolute beginners. https://mva.microsoft.com/en-US/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC_2706218949 After I finished with that course I used the C# Yellow Book as a resource http://www.robmiles.com/c-yellow-book/ I'm still a noob but I know *a lot* more after using these resources. I think they are a great starting place 
https://wildermuth.com/2016/06/27/Converting-ASP-NET-Core-1-0-RC2-to-RTM-Bits https://weblog.west-wind.com/posts/2016/Jun/27/Upgrading-to-ASPNET-Core-RTM-from-RC2 http://proudmonkey.azurewebsites.net/asp-net-core-upgrading-asp-net-core-1-0-rc2-project-to-rtm/ http://www.talkingdotnet.com/quick-migration-guide-asp-net-core-rtm-rc2/
&gt; input[input.IndexOf(s)] = Console.ReadLine(); no.. don't do that.. :)
Taught me something new. Thanks!
If you are generating the original set of numbers organize them as a binary tree before you feed it into this part of the program. Binary trees were pretty much designed for this sort of thing. Edit: my apologies it's called a binary search tree
Unfortunately it's not equivalent, because of the case where one is &lt; 0 and the other is 0.
not the same logic as the original post - what if one of them is zero?
You are correct, primitives refer to all the basic data types [(wiki)](https://en.wikipedia.org/wiki/Primitive_data_type). Also, a `for` loop is useful whenever you're iterating over an array/list and want to keep track of what index you're currently on.
Number1 &amp;&amp; Number2 &amp;&amp; [Math.Sign](https://msdn.microsoft.com/en-us/library/system.math.sign(v=vs.110\).aspx)(Number1)==[Math.Sign](https://msdn.microsoft.com/en-us/library/system.math.sign(v=vs.110\).aspx)(Number2)
why not multiply? if((Number1 * Number2) &lt; 0) if one of them is 0 it's false and then one need to be negative and one positive?
`checked` can cause the expression to throw an exception for some inputs.
there is a twitch streamer called "handmade_hero" in his streams he shows how he programms and tells you how and why he does certain things. Quite entertaining :)
Personally, I would switch the groupings around. My brain sees the logic better when it's written like this: if((Number1 &lt; 0 &amp;&amp; Number2 &gt; 0) || (Number1 &gt; 0 &amp;&amp; Number2 &lt; 0)) Trying to simplify that will just make your code less readable.
http://www.geeksforgeeks.org/ covers a comprehensive list of data structures and algorithms.
I don't get your method for determining "closeness"... at first, you divide your given value by the list item (4/1), but after, you divide the list item by the given value (10/4). Most "closest to a set" problems I've seen use substraction and the absolute value of the result to identify the closest. In your example, 13/4 would be 3.25 which is also less than 4, but more than 2.5; and 1/4 is .25 making less than 4 and less than 2.5... why is either of those values not the correct answer?
You say you have an array with and unidentified length, but your example has 10 as the length. If you really don't know how many entries the user will make, you'd be better off using a list and then looping the input until the user tells you to stop: void Main() { var input = new List&lt;string&gt;(); string s; Console.WriteLine("Enter your data; enter an empty line to end."); while (true) { s = Console.ReadLine(); if (s == string.Empty) break; input.Add(s); } // here, input contains all given lines, no matter how many } That way, the list ends up being the exact size of the user input and he can enter more than 10 values if he wants.
Oh my... And how the heck does this help the OP other than stop the compiler errors...
Check out something like New Relic
This is why defensive programming practices are so important. It has never occurred to me to use any networking client as a singleton. If it has IDisposable, I expect the unexpected and with HttpClient, I always wrap it's usage within a using block. I would rather the performance "overhead" of instantiation if it means I can sleep at night knowing my code is adhering to the conventional wisdom of cleaning up after yourself. For all you new developers, please be skeptical of Singleton Pattern usages. I love the pattern, honestly I do, but anytime anyone says they're using it I have to ask "Why?" Many times I have found it was being used incorrectly and most recently discovered a memory leak in an application caused by someone who didnt understand the pattern and implemented it with a public constructor. Inside this constructor, event handlers were being subscribed to and because the class was never garbage collected, each time someone "newed-up" this class, yet another handler was created. Baffling.
The performance of non-singleton is very poor as I have indicated. There is a trade-off and I believe the optimum where we use Singleton while adding the changes prescribed. 
It is informative, but the need for caution still exists. Your use-case doesn't mention anything about how many requests are being made if I read the article correctly. If I am only making a handful of intermittent Http requests, why keep that object around indefinitely? Obviously you're making more than just a handful of requests, though.
I will post another post. I have mentioned extra 35ms latency but if you would like to see beautiful charts, and numbers, fine. Will do it.
&gt; please be skeptical of Singleton Pattern usages. I love the pattern, honestly I do You are kind-of misinterpreting this. What this means in this case is not a literal "global variable singleton, once instance for the whole app" pattern (why would you love that antipattern?!), but it means that for a particular api endpoint, I should create a `HttpClient` instance, pre-populate it with configuration such as default headers and base url, then re-use it for multiple requests. e.g. I might have a class called `OrdersApiClient` that configures and keeps a `HttpClient` for that group of related endpoints that all live under the base url `http://myapis.com/orders` and require the same auth headers. To do this, maybe you have a `private static HttpClient` in `OrdersApiClient`, maybe you configure your IoC container, maybe you want to use the *Factory Pattern*. This is good for performance. It only really matters under high load (i.e. when you make a lot to http requests to the same endpoint), but then it can make a difference.
Unless you plan to support UNIX and LINUX desktops, you should just go for WPF. Microsoft didn't abandon it like some are talking. There are a couple of new features that are coming to WPF, one of which will be that the Binding system from UWP will be ported to WPF.({x:Bind}).
See [here](http://stackoverflow.com/a/22561368/5599) or follow links from [Here](http://codereview.stackexchange.com/questions/69950/single-instance-of-reusable-httpclient/69954#69954)
Thanks! I think my biggest mistake was jumping into a project that used WPF and MVVM without knowing anything about either. I will probably just restart the whole learning progress, maybe my redoing some of my older programs with WPF.
This is not an exact example, but close enough: Imagine if you had a log plot with horizontal axis labeled 1, 10, 100, 1000 and you placed your finger on the physical midpoint between 1 and 1000. Your finger would land on around ~30 instead of numerical midpoint of ~500. So in my "closest" definition, numbers &gt; 30 would be closer to 1000 and numbers &lt; 30 would be closer to 1. Does that make more sense?
I would suggest creating a custom control. WPF gives you the power to create your own controls. For example: you can create a class that will replace the TextBox with your own control. So essentially it would be like &lt;customCtrls:NumberTextBox Text=""...&gt; And in this way you can pretty much do whatever you want. You can create all sorts of controls and implement them in your own way. In your xaml you will have to declare a namespace to your customCtrls folder so you can use the syntax above when creating your text box. Hope this helps you or at least push's you in the right direction. Best of luck to you!
Totally, another good exercise may be to covert your winforms programs to wpf. Re think how classes are structured and take it one step at a time. Once you get it, you will realize how easy programming could be. Feel free to send me an email if I'm allowed to post that or in a private message, I could also link you to my git hub where I have blackjack redone into a wpf mvvm project that you could take a look at!
So you want the difference on a log scale? Calculate all of the log values of the numbers and run the same algorithm I posted the first time around. Still in O(n).
I didn't mean emotions, like why will I force myself to use a specific way that does not allow me to be the most efficient as possible? All of my guidelines follow programming "best practices" but google, ms, all have their own styles. Probably because they were using someone else's and then they found what worked for them.
Go to the options of ReSharper. You can change it (and many other options) there.
I dug through the options a few times, the behavior is not affected by "built in type reference with a CLR type name or keyword", that just affects the inspection severity/underlining
Wait, VS is on github? I didn't know it was open source.
&gt; Many times I have found it was being used incorrectly and most recently discovered a memory leak in an application caused by someone who didnt understand the pattern and implemented it with a public constructor. A pattern implemented incorrectly does not make the pattern bad. I could said RAII is a bad pattern because someone once forgot to release a resource upon destruction. That said, Singletons *can* be used incorrectly, like anything can. That doesn't mean the pattern itself is bad, it's worst problem is that it's *easy* to misuse to poorly solve a problem that it's not really meant to solve. To clarify, my preference is to use an IoC container and define the life-cycle of my classes there. Sometimes I'll state that something is a singleton, but it's not really a singleton in the traditional sense as it will have a public constructor. This alone means it doesn't have most of the properties that make singletons bad.
*heh* Didn't even notice that. Been playing too much KSP.
Who said going against the grain is inefficient, not every style works for every developer. https://github.com/kiwidoggie/RimeSearchPlugin/blob/master/EbxSearchPlugin/SearchPlugin.cs Is an example and it's not following MS's style guidelines. The way that I write code allows me to have "code awareness" of each variable, where it is, where it's being used from etc just by looking at the labeling. When working on a very large project you spend way less time looking for variables and objects, where they come from, and where they are going. The code is old and not used anymore and has been fully changed/refactored but it's something quick.
You can just do: decimal z = 3M/4M; The 'M' signals the compiler, that 3 (4) is meant as an decimal. Actually it would be sufficient to just use one decimal, e.g. write: decimal z = 3M / 4 respective decimal z = 3 / 4M If you are using variables, you can do: decimal z = (decimal)x / decimal(y) 
Key terms from my comment are "at some point" and "usually assured."
I mean something like this, the ints should always be treated as decimal when doing division. class Int32 { override public static decimal operator /(Int32 a, Int32 b) { return Convert.ToDecimal(a) / Convert.ToDecimal(b); } }
That's not possible. "if you're going to create a custom binary operator, at least one of the parameter types (for the operands) has to be the same as the type you're declaring the operator" See [this answer](http://stackoverflow.com/questions/6437339/cant-overload-operator-for-object-class) on SO for details.
No, it's not possible. Someone wrote some StyleCop rules (http://stackoverflow.com/questions/13840428/how-to-be-warned-about-potential-arithmetic-errors-due-to-type-conversion) to warn about it, but it's only good for assigning to a variable on the line. (won't cover other cases like return values or where the type is declared on a separate line). You'll also have to modify it for `decimal` (it's for `double` right now, but that's a simple excercise) There are legitimate, good reasons for integer division existing and operating as it does. This is a common error, but nothing (as far as I know) can be done about it. Just be vigilant about your math and data types. EDIT: If you want a really painful solution, you could create extension methods or wrapper classes around your data types and force everyone to use them. For example: //extension methods int x = 3; int y = 4; decimal z = x.DivideBy(y); or //wrapper classes Integer x = 3; Integer y = 4; decimal z = x / y; But there's a good chance (imo) that this would be more prone to error and headaches, and could introduce some performance issues to boot. Not to mention it would be boggle the minds and simply be [bad code](https://blog.codinghorror.com/content/images/uploads/2009/02/6a0120a85dcdae970b012877707a45970c-pi.png). EDITx2: Another reason for integer division not being automatically treated as decimal is that the expression resultant type/behaviour is independent of the variable or return type being used. That is, the line: decimal z = x / y; Evaluates `x / y` independently of the `decimal z` declaration (also for good reason). Thus having `x / y` could result in a couple possible return types (`decimal`, `double`, `float`, and `int`) each with their own varying levels of precision and use. So `int / int` always yields an `int` (for this reason and other valid use case scenarios)
You have a **string**. You want to **split** it. Google that, and you can easily find the method `string.Split`, including documentation and examples.
####How important is LINQ Well, using LINQ is all fun and giggles. I mean, most of the C# developers I know love it, me included. But implementing it can be a real pain in the ass. I would say: It's a nice to have feature, but no must. ####How important are cancelable requests Go for it. It's typical convention in async APIs to have an optional CancellationToken as the last parameter. HttpClient also supports it, so it's not too hard for you to implement it. ####Multiple types for functions To be honest, I don't think I have ever seen this possibility. But even then, why should I use a untyped overload with an anonymous type or a dictionary, if I can just use the typed parameters? Doesn't really make sense to me. I would always use the typical parameter versions, no dictionary or anonymous types. POCO may be an option if you have a large number of optional parameters (may be the case for your "List" methods). #### Style for the API There are really only 2 possible ways for me: flatten or grouped. If I wanna execute the "MakeCall" functionality, then just provide it to me. No need to hide it behind a generic "catch all" method like: "Post&lt;Call&gt;(new MakeCallRequest())". The flatten and grouped styles have another nice advantage: They make it easy to explore the functionality of the C# API. I can just look at my client object and see what I can do, I don't have to search for the correct classes, IntelliSense will guide me to it. One thing that would drive me towards the flatten style is abstraction. It would be nice if your API is [abstracted behind an interface.](https://gist.github.com/avbel/781caf792885ca98d7a3e8af974a8697#gistcomment-1812836) That would allow me to use dependency-injection with your API and mock it in unit tests. Oh, and I don't think you absolutely have to aim for 1 HTTP request per API call. Having the call object instead of only the call id is just way more convenient. In this case, I would definitely go for 2 HTTP requests. ####Cross platform You should probably aim not for a PCL, but for a .NET Core DLL. This way your API is available on every current platform that supports the .NET standard, but also on every possible future platform. For your API you might be able to target .net standard 1.1 or even 1.0. One thing you have to consider here are your users. If they are like big enterprises that are slow adapting to new things, then it might be possible they are still running machines with Windows XP. And that could be a real dealbreaker for you, because Windows XP only supports up to .NET Framework 4 I think. So a .NET Core DLL will not work on Windows XP machines. ####A example I looked a bit at your current API version, and I really have to say: It seems like a good idea to me to make it more C#'ish. Because you got some really strange concepts in there. This is how the API might look like, if you apply my suggestions. https://gist.github.com/haefele/d876a5640d8e901955ea71c73e4ae6c4 To be honest, having all these methods in the ICatapultClient seems a little bit awkward, but my personal preference is: Have functionality and data split up, so you don't have to worry that the data instances you have, are in any way still attached to the functionality. It just makes my life easier, I don't have to be careful about the lifetime of my data objects in contrast to the functionality.
There are many ways to do this kind of query, the simplest would be a 3rd party tool, however if you want to do the operation yourself, a simple method would be to use IPC to do the communication. https://msdn.microsoft.com/en-us/library/system.runtime.remoting.channels.ipc.ipcchannel(v=vs.110).aspx problem we have is that you have not given us enough information, for example security requirements, can you install a service on the machine. what version of .net are you using, is it just for learning, etc other methods would be a messageQ, sockets, or even a file for each machine (however i would not recommend this method, as other things can interfere with the files) 
Uninstall R# :)
I haven't found one, and it is quite annoying; has been for years. I also like using the type names (I call it [Richter Style](http://stackoverflow.com/a/12863/58391)), but R# doesn't really support this in analysis.
Use VB where Int32/Int32 returns a Double and Int32\Int32 returns an integer.
It may be tied to this option: Code Editing -&gt; C# -&gt; Code Style -&gt; 'Built-in type' naming -&gt; "When referencing built-in type, prefer using" http://imgur.com/NmKt3Hp Checking 'Apply code style on completion' (at the top of the form) may help as well.
i don't have that problem and i'm using resharper ultimate 10 in vs 2015. if it helps, all of those things you're missing are categorized as 'keywords' in my pop-up with a gold key icon next to them.
ahh, same thing happens for me in that context. seems like a bug or oversight on jetbrains's part (keywords aren't included in that specific pop-up at all).
Well at least i know its not an R# setting i keep overlooking... maybe ill open an issue ticket thing for it with R#. Thanks!!
Does instantiating the HttpClient using the [constructor overload] (https://msdn.microsoft.com/en-us/library/hh875108.aspx) which allows you to specify that it not to dispose the inner HttpMessageHandler when it's disposed allow a persistent TCP connection across multiple HttpClient instances (assuming the same HttpMessageHandler is used to construct them all)?
Navigate to ReSharper -&gt; Options-&gt; Code Editing -&gt; Code Style -&gt; Built-in type naming -&gt; "when referencing build-in type, prefer using" and set it to "keyword." If you don't want R# to even think about changing the style that you've typed out, set the other drop down to "do not show." At least I'm 95% certain this is it. I do not think this is the default setting, but I vaguely recall having to change this setting when setting up my a dev environment recently. Would be really stupid if it is the default. 
Yep, Serilog is the answer. Structured logging makes searching and analyzing logs so much easier. And yes, it does have support for .NET Core.
The reason I hate the System types is because it is am annoyance. I don't use resharper and there are a few setting a which generate the aliases regardless so the aliases just seem to be more convenient. Plus, you don't actually gain anything in C# by using the System types.
It's what we use too. I just joined a new company and that is the current preferred logging tool for our dotnet core/ aspnet core project.
I suppose those points can be true. I still feel, after working in both styles for quite some time, that I prefer aliases. Less hassle. I have also not found myself having issues with type recognition via aliases but then again I don't pay much attention to whether or not I do!
Looking at the [source code](https://github.com/IdentityServer/IdentityServer3), searching for JWT, I found 201 matches in 25 files. So, yeah.
erm ... the windows updates, so that the OS is up2date
It's kind of for learning. It's for my mid term exams. We got to do some project and I thought a monitor would be a great idea. I don't actually know the security requirements tbh. Version of .Net is 4.5 
Use Microsoft.Extensions.Logging.Abstractions and one of the providers: Serilog, NLog, elmah : https://github.com/aspnet/Logging
I've been using VS with R# for 8 years now, and I never seen this behavior. The setting everyone is telling you to change (When referencing built-in type, prefer using) is the one that obviously works fine for you, once you're done typing it suggests you the keyword, that's what that setting does. The weird thing is the autocomplete. I don't think resharper is doing that. Are you sure you didn't install some other plug-ins? I just did reset settings on both VS and R# and autocomplete defaults to keywords. Try resetting settings (you can export the old ones to file so you can go back easily) and check if it still acts like this. Then reload old settings one by one (e.g. first VS then R#) and see who is to blame.
Exactly what it says on the tin!
Relevant: - Joel on Software - Things You Should Never Do (rewrite software from scratch): http://www.joelonsoftware.com/articles/fog0000000069.html - When is a big rewrite the answer: http://programmers.stackexchange.com/a/6303 - Why you should (almost) never rewrite your software: http://onstartups.com/tabid/3339/bid/2596/Why-You-Should-Almost-Never-Rewrite-Your-Software.aspx &gt; They did it by making the **single worst strategic mistake** that any software company can make: &gt; They decided to rewrite the code from scratch. Rewriting software will almost never fix your problems - It will just repeat them (slightly less worse). Instead you should focus on iterative and frequent improvements.
Be aware that this software uses iTextSharp 5.5.9, which has a sometimes surprising license model even though it is available as a nuget package. http://itextpdf.com/Pricing
I think later on when your mistakes are less severe this holds true. I have personally wrote a project where I am 99% positive that re-writing it was better and faster to get it where it needed to be than trying to scour over the mess it was fixing tiny problems and the issues that occur as a result of the fixes. 
You might be right in that every one is always 99% sure its better/faster. I don't disagree the thought of re-writing code should be considered heavily and clear benefits must be laid out that outweigh the negatives in some measurable form. &amp;nbsp; I'd like to think in my case I chose my brain over my heart when deciding to do the re-write. I had learned many lessons since year ago I began coding/working on it, and it had grown into a huge crap-storm slowly over time beyond imagination. &amp;nbsp; I did however post my projects code on Git, and shares it on several sites with reasons for why, and my concerns, goals, and plans for the re-write. It was a pretty universal "yes, re-write" and I do not regret it. Cut the code by 2/3rds, implemented a clean public documented API through interfaces, applied good test-driven development practices, upgraded to WPF, the list goes on. It was a positive experience from the prior months of attempted clean up bit by bit strategy. 
For the lazy &gt; "The iText AGPL license is for developers who wish to share their entire application source code with the open-source community as free software under the AGPL “copyleft” terms. As soon as you want to use iText in a closed source, proprietary environment, you have to purchase an iText commercial license of one of the types discussed above." Basically, if you use it on any proprietary software, you have to pay for it. 
Anyone know of a good PDF to Image library? Paid or not, I'm exploring all possibilities.
This is off-topic to what you're asking, but I have to ask what color scheme you're using in VS, did you get it from a site, or make it yourself? I want to try it.
I've used ImageMagick for this purpose, there's a command line utility or a dll :)
Removed: Rule 3. Maybe try /r/typescript instead.
You should post more code. Are you using a LINQ or Lambda query to retrieve SelectedTransaction? If so you may have to use an include statement to get the action_type table (ugh, hate underscores and all caps in databases, must be an old design). For instance, let's say you are just getting all transactions: var SelectedTransaction = db.Transactions(); You could do this instead: var SelectedTransaction = db.Transactions().Include(t =&gt; t.Action_Types) Make sure to do a using of this namespace for the include lambda syntax to be recognized: using System.Data.Entity;
I have installed VS 2013 ... and have the same error
Do you want the application to be highly extensible with minimal effort? Do yourself a favor and start out in WPF and focus on design patterns(MVVM, MVC) and make your life easy. :D It all depends on what type of application want and how you plan to use it in the future. Winforms no doubt is faster and easier to build simple applications with one or two windows. WPF is going to be the clear winner anything beyond that and not to mention writing xaml code makes for some really nice UI's.
https://www.reddit.com/r/csharp/comments/4qg60s/how_to_display_the_drive_space_on_multiple_remote/d4st4z1
We're currently using Tall Components PDF Rasterizer for our needs. Now and then it runs into some bizarre use of the PDF spec it can't handle, but by and large it has worked out well for us and the licensing is very reasonable for a commercial application.
Tools -&gt; Options -&gt; Productivity Power Tools -&gt; Custom Document Well Under "Sorting" uncheck "Most recently used"
Note: Productivity Power Tools is an extension. https://visualstudiogallery.msdn.microsoft.com/34ebc6a2-2777-421d-8914-e29c1dfa7f5d
Since I asked the question I owe the resolution.... Finally tracked it by turning on Detailed MS Build Output ... Got the following error: Error Build: File 'COMPUTE_PATHS_ONLY.ts' not found. Which led me to here: http://stackoverflow.com/questions/36083323/error-build-file-compute-paths-only-ts-not-found-in-visual-studio# Down to the order of installing Typescript: VS 2015 (which installed 1.8) TypeScript for 2013 was installed to get the 1.4 SDK MSBuild conflict then Pretty Shoddy Microsoft The whole rebuild happened cause I used Disk Cleanup in Windows Explorer which corrupted my 1 and only partition! :) 
Awesome, worked like a charm. Thanks!
This topic turned out to be convenient me because I have been having the same problem but somehow have been too lazy to do anything about it. Nice to have sanity in my CTRL + tabbing again. Also, I can't believe that this "improvement" was added by Productivity Power Tools. It's such a horrible, confusing, and unintuitive change.
Delphi was nice...but I switched away from it a decade ago... or more..
Property shorthand: class Car { public Car(string color) { Color = color; } public string Describe() { return "This car is " + Color; } public string Color {get; set;} } 
I don't know where the example comes from, but to add to what Sasken pointed out: later lessons or more advanced examples may demonstrate that you can use auto-properties and avoid declaring and updating such a private field directly. If the class were changed to implement that technique, you would have to change all the code referencing this.color
You can also make it read-only externally while allowing the containing class to write it: public string Color {get; private set;} 
&gt;Everyone is always 99 % positive that re-writing is the better and faster option, because - let's face it - that's the most fun. Realistically it's 99 % times the wrong choice. EA Sims is that 1%.
If I may add, it's just a general rule of thumb that the only things that should *ever* touch the instance member fields themselves are either the Properties (like in C#), or getters/setters. This principle applies to every OOP language. Even constructors should use properties or getters/setters, not touching the member fields directly. This ensures things like consistency as mentioned and even security.
To add to your list: https://cleancoders.com/episode/clean-code-episode-1/show 23:30 is a good place to start if you don't want to watch the whole thing. 
Putting only `get;` means `readonly`, not a private setter. http://ideone.com/LWWqrs. I find this far more useful than being able to remove a `private set;` because now if I want a readonly property, I don't have to either provide the backing field and implementation of `get` or say screw it and use `private set;`.
It seems like this would be really simple to prove/disprove. Did they provide anything to back it up?
Visual studio
What do you guys use new relic insights for? It seems like such a cool feature that we are not using to its full ability. We basically use it for monitoring page loads by account. Database perfomance. Amount of users logged in. The most popular pages. But it seems like we're scratching the surface of what it can do.
[removed]
Ranked by my rating (highest first): pluralsight, Lynda, Microsoft Virtual Academy, edx, coursera). Some cost $, some are free. 
Maybe it makes sense to somebody, but it's definitely a terrible default.
Seconding pluralsight. It's what got me into the ecosystem and up to speed on the basics.
&gt; virtual environment on Linux Thanks for the answer, are you able to explain it a bit more indepth? do you mean like the JVM? and what is .net's equivalent called?
By GDI output do you mean it provides a GDI/GDI+ device context to draw on? That is the holy grail for our application and we have ti resort to some dirty EMF hacks to support what we are doing now.
Native bytecode is an oxymoron. Bytecode is executed by a virtual machine, in this case, the CLR. .NET Core provides a version of the CLR that runs natively on Linux, whereas the full .NET Framework only runs on Windows because it includes classes that provide Windows-specific functionality. Your code is compiled to the exact same bytecode regardless of OS, and whichever CLR implementation you use will run the bytecode. Mono is an implementation of the CLR, too. It's not a huge abstraction layer. The JVM is very similar to the CLR as well. Obviously, it uses different languages like Java and Scala instead of C# and VB.NET, and it uses a different bytecode, but it does operate on the same basic principles. ASP.NET Core is going to have much faster performance than Node.js because C# is compiled to bytecode whereas JS is a purely interpreted language. Microsoft claims like 10x improvement. 
Would Netscape be the most popular browser to this day had they not rewritten it? What about Chrome? That was written from scratch since the Netscape days. What if Netscape did that? The rewrite wasn't a bad idea, it just didn't work out for business or technical reasons. What if Microsoft never rewrote windows and it was still a wrapper over DOS? It is true that rewrites often don't work out, but I don't think the idea itself is always terrible. You need to be aware of 2nd system effect and you need to fix the problems that led to a shitty code base in the first place. Not every company is capable of that.
It'll compile to CIL (Common Intermediate Language) which runs on the CLR (Common Language Runtime). It's similar to how Java compiles to bytecode which is then ran on the JVM. I feel like you and your friend should sit down and iron out the details of what you want to develop and *how*. Don't pick teams, just list out the pros and cons of the languages and tools and pick the ones that make the most sense.
this goes in the main? (whatever those public etc etc things are called) i have another variable that is called experience from a video game. When i run the program, I want to be able to initialize a variable of what my starting Exp was. The program runs immediately so exp will constantly grow, and im having trouble setting that initialization. i assume we do that in Main also? the only issue is the only way i can read the Exp is from another function (another public etc etc) and im not sure how the main and that public thing play together thanks!
The obly thing people need to work on is ensure the files are right.
Yea, you can place that in 'Main'. [Here](https://msdn.microsoft.com/en-us/library/acy3edy3.aspx) is some more information on 'Main' in C#/.NET. It is essentially the entrance point to your program. 'Main' is the first method that will be executed when running your program. Based on your comments I assume you might be a beginner. I think it would be useful for you to check out the tutorial linked to on the sidebar, [C# Fundamentals: Development for Absolute Beginners](https://channel9.msdn.com/Series/C-Fundamentals-for-Absolute-Beginners), for a more structured learning path. Or search online for any intro level C# tutorial. Sorry I'm pointing you to a tutorial. I was unable to think of a straightforward explanation for your questions about your 'experience' variable, due to what seems like a fundamental misunderstanding of some basic programming concepts.
FYI mono has a pretty low footprint if you only get what you need. On Debian and Debian-based systems the packages are quite granular so you can get mono-runtime and whatever libraries you need like libmono-system4.0-cil. If you get all mono packages it's going to start bringing in graphics-related dependencies.
Codeschool has a great new asp.net Mvc course for free.
C# has becoming popular because it's now open source, multiplatform with .NET core, and can be used to cover the entire stack (backend web with ASP.NET, windows desktop apps (and soon to be linux/macOS apps as well when an official GUI library comes out for .NET core), and mobile apps with Xamarin). It's also just a very nice language to work in that essentially improved upon the bad in Java, as well as adding many nice features that Java doesn't have.
Well, the type you put in new Task&lt;T&gt; is the type of its parameter. An async method returns either void or Task (and Task&lt;T&gt;). So if you want to pass an async method as a Task parameter, you're basically putting a Task in a Task. I don't really see another way to do that but your method, from the top of my head.
The error is quite clear: The method does not exist. That it works in .NET and not in Mono also shows the culprit: Mono does not implement this method. Try to see if you can use another method. Otherwise you're outta luck using that library with Mono.
Crap. I'll have a look and see what else I can do with it, pretty big show stopper.
Sure. Definitely not the typical use case. I know I can work with it that way, and that is essentially what my second example is doing. 'coldTask.Start();' in my example executes the Func&lt;Task&lt;bool&gt;&gt;. And that inner Task&lt;bool&gt; is returned when I call 'coldTask.Unwrap();'. The reason I'm asking about it is I ran into a use case someone else had written at work that was expecting to be passed an unstarted task representing the work to be done at a later time. And I/my coworkers were surprised to find no ways to create a cold Task that runs async code within (without blocking a thread/jumping through some hoops).
 any specific topic/misunderstanding you are referring to? [Variable declaration/use](https://channel9.msdn.com/series/C-Fundamentals-for-Absolute-Beginners/06), [Classes](https://channel9.msdn.com/series/C-Fundamentals-for-Absolute-Beginners/15), [Scope/Accessibility](https://channel9.msdn.com/series/C-Fundamentals-for-Absolute-Beginners/19) Based on the list, those lessons should help directly with the questions you had. But, my advice would be to start at the beginning (or episode 3 if you already have VisualStudio set up) and just work your way down the list. And if you run into a lesson you feel you already understand you can always skip it.
 You should really avoid that. Agreed. This is the &lt;.1% case. It was the first time I'd seen anyone use unstarted Tasks in our codebase.
There is a slight but important difference between the two. In your case the task will run in the current context (could be UI thread) and if there is an expensive synchronous operation before the await it will block. In the first case, the task can be something that is scheduled on background thread directly. It is easy to fix either to do what you want exactly but could be a hard to miss detail.
I find this is almost always the answer: Rx to the rescue! // straight duplication of your code Observable.Defer(async () =&gt; { await Task.Delay(1000); return Observable.Return(true); }); // the "Rx way" (although you probably aren't really sleeping for 1s...) Observable.Defer(() =&gt; Observable.Return(true).Delay(TimeSpan.FromMilliseconds(1000))); Either solution creates an `IObservable` that will execute only when `Subscribe`d to or `await`ed: await deferred.ToTask().ConfigureAwait(false); await deferred; // Rx can be awaited directly, too deferred.Subscribe(/* do something */);
Only if not making use of .NET CoreRT or Mono AOT.
&gt; Native bytecode is an oxymoron. Not when it is supported by micro-coded CPUs. .NET compiles to native code, MSIL is just a file format. On Windows there are NGEN, pre-.NET 4.6 JIT, RyuJIT, .NET Native, MDIL depending on the target platform. On GNU/Linux and Mac .NET Core makes use of JIT, and .NET CoreRT compiles to static binaries (yet to become stable). There is also the option to use Mono to generate static executables.
Yes of course, I'm out at the moment but I'll upload the source later on today. Would github be a good way to share it?
Do let us know after you post the source code. Did you use the whatsapp chat backup to plot this or did you use anything else ?
Check this out so you're not pushing your binaries: https://github.com/github/gitignore
"I had a huge architectural mistake" Was the mistake using node? Because I feel like that was the mistake :P
Makes sense
Just to let you all know, the source is in my other comment now. Enjoy :)
Thanks!
No, I love Node. The mistake was trying to cram an elephant inside a chicken coup. I used MongoDB for a relational database / graph.
Others have answered the compilation questions and such pretty well. I would personally rather write a web app in ASP.NET Core than Node.js. I've been doing C# and JS programming for several years, and the former is just much, much easier to work with. I have some experience trying to get our server to work on Mono, and it wasn't good, constant segfaults and really poor performance. Core seems to run much better. Over the coming months we'll be migrating our app to Core for Linux deployment.
Removed: Rule 5.
no bad, most peoples first app is Hello World even if they are a pro in another language, I would move your paths to the app config, and combine them with path.combine. but over all pretty good
https://www.visualstudio.com/en-us best deal on the web that I've seen. Sign up for a Microsoft account, sign in to get VS. Get their Dev Essentials offer (free) Get a free subscription to PluralSight and Digital Tutor for 3 months (PluralSight and Digital Tutors are under one company, now) I've been learning C# on Pluralsight for the past few weeks, and, yes, their tuts are a step-up from some on the web. I will purchase a sub to Pluralsight when my trial ends. My two cents. Good luck. 
It sounds like you installed Xamarin Studio, and the not the Xamarin plugin for Visual Studio. Download the installer for Visual Studio and run it, configure the options to install Xamarin for you.
I haven't actually, just did a whole load of googling! Thanks for the tip! I did have a look through the source code, first name isn't really a security problem.
I'll definitely look into that, appreciate the help.
The key to becoming good is realizing your limitations and starting small. I like the idea and execution. I can't speak for the code since I'm on mobile right now, but you should be proud of what you have achieved. 
No problem. Credit where credit is due. My only real gripe with the content on your site (and honestly, 90% of even successful blogs I see) is the lack of a clear "category : subject : topic" sort of set up in the blog entry's. I think it is absolutely amazing when I see a little category bar at the top of a blog site, where each one you click brings you to a new view of blogs only in that category. I think it is even better when they have a clear-cut subject : topic theme with high-quality medium frequency entries.
To add onto that, after you've extracted the logic from the UI/UX code, you can then learn WPF and just plug and play the UI :)
Honestly dude, if you're this stuck on implementing a straight forward DAG, this job is probably not for you. Take home interview questions should be fairly easy for you to complete. Not to mention you give no indication that you've tried ... well, anything.
I don't know, I did a lot of stuff for years before I ever needed to use graphs. I've done it, and I assume you also have, but it's not necessarily 'fairly easy' unless you know why you're doing it and what your end result is. Or at least being educated on it specifically. It stands to reason he never got into the entire 1/3 of a semester that is graph theory in a CS degree. Doesn't mean the job is above him, since most solutions to most problems are not graphs. The lack of trying... anything. I'm 100% with you on that.
GitHub would be a perfect way to share it.
Why handful? This is used in a server scenario when we sometimes serve 120 RPS... soon we will need to serve up up to 350 RPS.
Not really. Bear in mind, with singleton, the HttpClient itself never gets disposed so does not matter what value we set for the boolean flag.
Check out Unity 3D.
1) You should divide your main .cs file into several files. It's usually best to keep 1 class/interface in 1 file. It's easier to manage your code then. 2) map.getElement(blocX, blocY) == 1 It would be advisable to change this '1' to some kind of enum. It's easier to read and yet you are doing the same some because you are commenting what those magic constants mean. Look at line 307 for your comment for example. 3) int[,] plateau = new int[25, 80]; It's nice to remove all magic constant like those. If you will find out a good method for resizing your console you could control the size of the map by changing 2 variables. 4) You have comments like **&lt;DEBUG&gt;**. You can be interested in using #ifdef instead of commenting/decommenting blocks of code. Check this out : https://msdn.microsoft.com/pl-pl/library/2a1b21sf.aspx http://stackoverflow.com/questions/5149351/solution-wide-define I am too lazy to give more hints ;). I like the idea of green blocks which grow bigger when you shoot them. I did not play too much side scrool shooters, but I never heard of game using this idea. Keep up good work! :) 
Indeed, it's not suitable as a commercial app. The program reads chat files I have exported from whatsapp to a .txt so it wouldn't be up to date. Whatsapp's message encryption prevents any app using real time data unfortunately.
Yup - when you set your transform.position at the end you're setting the Z component to the X component :P
 transform.position = new Vector3(posX, posY, transform.position.x); You're feeding in the GameObject's `x` coordinate for its new `z` coordinate. This likely should be: transform.position = new Vector3(posX, posY, transform.position.z); EDIT: In the future, try running the game within the Unity Editor, selecting the object, and watching its transform values in the Unity Editor. Once you identify the values that are unexpectedly changing, start inspecting the code. Either add breakpoints or log out the changes in the values to isolate where the logic deviates from what you expect.
I don't follow the practice, but not because of performance. I just don't like to litter my class with properties, auto or not. I also like to be able to see private field access (lower case), whereas properties would always be upper case. A matter of taste. 
Sure, but there are many and often conflicting "best" practices :)
Yes, but the apparent property setter in the constructor is actually a backing field access, sugared up by the compiler :)
You can create gamrs in almost any programming language, e.g. Rollercoaster tycoon 1 was made in Assembly. So not only is it possible, but a lot of games are created in c# nowadays.
For general c# knowledge, I highly recommend [Jamie King's videos](https://m.youtube.com/user/1kingja/playlists?shelf_id=5&amp;sort=dd&amp;view=50), they are short on point examples anyone can understand. For vr, I don't have much experience but I would suggest you to look into a game engine like unity, there are plenty of vr tutorials. Download an example working code and change as you like to see what you can do with it. Dive right in. 
You don't need to implement a timer (that would mean writing your own Timer class from scratch), you just need to use the one provided by the .NET framework. There are multiple Timer classes, but if you're adding it using the Toolbox, you likely created a [System.Windows.Forms.Timer](https://msdn.microsoft.com/en-us/library/system.windows.forms.timer(v=vs.110\).aspx). As you can see in the documentation, a timer has an [Enabled](https://msdn.microsoft.com/en-us/library/system.windows.forms.timer.enabled(v=vs.110\).aspx) property that controls whether or not it's running. Your Timer should start with this property set to false, and you should only set it to true when the user clicks the exit button. Responding to that click, and exiting the application when the timer fires will require some basic knowledge about events and C# in general. You won't be able to do this by simply dragging and dropping things in the designer.
 private void button1_Click(object sender, EventArgs e) { errorBox.Text = "Thank You for Using Party Savings and Loan ATM. Have a Nice Day."; errorBox.Visible = true; timer1.Enabled = true; } this is what i have so far. The properties of the timer are set to 1000 interval enabled is false What i can't figure out is how to execute a this.close(); once the timer is finished.
Yes, I actually played it, is it C# behind it?
Actually I never thought about languages that way, I'm really new to programming. Thanks for enlighting me.
Removed: Rule 5.
Removed: Rule 5.
THank you. I didn't realize that you could double click on the timer after you have taken it from the toolbar to create the event handler that's where i was getting stuck. Thanks again
Removed: Rule 4. As stated, there are several help resources both in the side panel and in the sticky. You can also check out /r/learnprogramming.
Implement does not mean writing a new one from scratch, implement means "to use"
Everything, really. The motivation to build this library was to persist security-related metadata to New Relic Insights, for the purpose of analysis.
Then it wouldn't be bytecode anymore - it would be machine code. The very definition of bytecode is that it runs on a VM; if this VM's instruction set is then implemented in hardware it becomes machine code. 
Have fun reading Xerox PARC or Burroughs papers then, among many other possibilities. They refer to byte code to differentiate between instructions implemented using pure hardware gates and those that require a micro-coded implementation.
void main(){ calc_avg(1.2, 5, 9); } float calc_avg( int x1, int x2, int x3){ int avg = 0; avg = (x1 + x2 + x3)/3; return avg; } 
Really sounds like you want someone to do your homework for you. Also, this is a C# sub. Not a C sub. 
[What SO says](http://stackoverflow.com/a/4656611) A larger issue is that MAPIFolder is deprecated ([see the MSDN page](https://msdn.microsoft.com/en-us/library/microsoft.office.interop.outlook.mapifolder.aspx)), you should be using Outlook.Folder. If I were you, I would also import the Outlook namespaces in your `using` statements, retyping them on nearly every line is just wasteful and difficult to read. You've also got some code consistency issues: the local variables `myInbox`, `lines`, `line` are camel-case, but `Sender` and `ToSplit` are Pascal-cased. ------------- Continuing with style preference stuff, I would make it work somewhat like this: using System.Linq; using Microsoft.Office.Interop.Outlook; Application myApp = new Microsoft.Office.Interop.Outlook.ApplicationClass(); var inbox = myApp.Session.GetDefaultFolder(Outlook.OlDefaultFolders.olFolderInbox) as Folder; var mailItems = inbox.Items.Cast&lt;object&gt;().OfType&lt;MailItem&gt;().ToList(); if(mailItems.Any()) { // SenderEmailAddress and Body are defined as strings, you don't need to cast them var kentekens = mailItems.Where(e =&gt; e.SenderEmailAddress == "EMAIL@ADDRESS") .SelectMany(e =&gt; e.Body.Split(new[] { ':' }, StringSplitOptions.RemoveEmptyEntries)) .Where(line =&gt; line.Contains("schadenummer")) .Select(line =&gt; line.Trim().Substring(0, 6)) .ToList(); // english-izing variable names :) if(kentekens.Any()) { dataGridView2.Rows.AddRange(kentekens); } else { MessageBox.Show("There are no matching emails in your Inbox."); } } else { MessageBox.Show("There are no emails in your Inbox."); }
Yes. I've built one. You can have shitty programs in any language.
In the context of computer programming, "implement" absolutely means to create something from scratch, and not "to use".
To add to this pick the one that interests you most and start reading up on it. These are all relatively simple on their own, but it will probably feel like quite the undertaking to master them all at once. The nice thing is they all tie together well so once you learn one it will be that much easier to tackle the next, and so on. 
So what happened? You switched and you were presented with a project that was built around n-tier architecture and repository, or your were told to make such project from scratch?
Thanks for the support Bop and Sikh
Yes, several.
Yes. I've developed production applications (i.e. deployed to users, not just for fun/learning) in at least a dozen languages over 30+ years. I've seen well written and poorly written apps in almost all of them. I've seen maintainable and object-oriented and functional applications in assembly. And impossible-to-maintain, non-object-oriented applications in java and csharp. It's about the architecture and project standards more than the language. The language makes some things easier or harder. But I'll take a "great" architecture and "good" standards with a "bad" language over a "great" language and "good" architecutre any day.
It's sort of like asking if anyone has ever seen a well written novel in Spanish.
Yeah, surprised this hasn't gotten more love. Most devs I know and work with are big fans [myself included].
Also, I'm pretty sure nobody is claiming 10x speed improvements in general. I'm sure you'll find some microbenchmark with that kind of improvement, but you'll also find others where there's no difference, and some where .net is slower. I'd be willing to bet that on average you'll get better performance if you're reasonably competent at that kind of thing, but a 10x performance, especially for a "normal" website/webserver is too much to hope for. You'll be spending too much time waiting for I/O (disks, network) in the vast majority of cases to be able to achieve 10x, no matter what tech stack you switch to.
Try DateTime.ParseExact -- it will let you pass in a custom datetime format string. DateTime.ParseExact: https://msdn.microsoft.com/en-us/library/w2sa9yss(v=vs.110).aspx Custom DateTime Format Strings: https://msdn.microsoft.com/en-us/library/8kb3ddd4(v=vs.110).aspx The format string you want is gonna be pretty close to what you have there. Something like: "yyyyMMddHHmmssffff" (case-sensitive) You'd use it like this: http://csharppad.com/gist/e917a8478ddefc9501b83e7760681f5c 
Ugh Entity Framework... Lol I had to go through all that when I first started as well. A year later, I am comfortable with it however I am still not too aware of the internals of EF. I will add that it is really nice to have db stuff close to your Object oriented code. Sometimes I would just prefer to write standard SQL though. 
Lesson 1 - if you are using an ORM do not use the repository pattern.
The best thing I'd recommend around the repository design pattern is throwing it away and using something else - if you're using things like EF then it's borderline pointless. Have a look at CQRS.
Thanks so much! This worked like a charm! I didn't even stumble upon the ParseExact command. 
Thanks, didn't know about that!
What have you tried? Try looking into the options for inspecting if the postal code ends with an "x" (`String.EndsWidth`, `String.Substring`, [`string[] chars` indexer](https://msdn.microsoft.com/en-us/library/system.string.chars%28v=vs.110%29.aspx)). Once you know if you have one or two "x" characters, you can extract the first portion of the postal code (using `String.Substring`), then loop through 0 to 9, or 0 to 99 and append that to the extracted portion.
I have come up with the following code, that actually works: static void Main(string[] args) { string CapString = Console.ReadLine(); List&lt;string&gt; CapList = new List&lt;string&gt;(); if (CapString.IndexOf("xx") &gt; -1) { for (var i = 0; i &lt; 100; i ++) { var iString = i.ToString(); var NewCap = CapString.Replace("xx", iString.Length &lt; 2 ? "0" + iString : iString); CapList.Add(NewCap); } } else if (CapString.IndexOf("x") &gt; -1) { for (var i = 0; i &lt; 10; i++) { var NewCap = CapString.Replace("x", i.ToString()); CapList.Add(NewCap); } } else { CapList.Add(CapString); } foreach (var CapItem in CapList) { Console.WriteLine(CapItem); } } This will probably clear what I am trying to achieve. But, is there a more "elegant" and shorter way to do this?
Depends on what you consider elegant, but if it were me I'd be inclined to have a database table with each city and corresponding postal codes
If you're trying to understand the point of the repository pattern, be sure to looking to facade and IoC/Dependency Injection as well. I'd also look into SOLID design principles because it will likely create some pretty obvious talking points to design decisions made in the N-Tier architecture as well as MVC. For example "Why are things A and B separated when they could easily be boxed up in a single class?" "See: Single Responsibility Principle"
Thank you very much! Indeed I'm learning and I still didn't know about EndsWith and the ToString format! very useful :)
 IEnumerable&lt;string&gt; Allzips(string template) { var array = template.ToCharArray(); if (array[3] == 'x') // check the fourth character { for (int i='0'; i&lt;='9'; ++i) // iterate of chars not ints { array[3] = (char)i; for (int j='0'; j&lt;='9'; ++j) { array[4] = (char)j; yield return new string(array); } } } else if (array[4] == 'x') // else check the last character { for (int j='0'; j&lt;='9'; ++j) { array[4] = (char)j; yield return new string(array); } } else // else just return our input { yield return template; } } In place array modification with explicit string construction. I decided to use IEnumerable, but you could preallocate a List with 10 or 100 entries if you wanted. I also iterate over the character values themselves instead of integers and then printing and then concatenation.
(Reddit is giving me issues posting again, so I'm breaking this up to multiple posts, sorry) I personally try to separate my "repositories" from my "services", in that, I let repositories handle the more dirty work of accessing the database (or whatever storage medium) and the higher level services exposing _meaningful methods_ to the rest of the application. In that sense, I definitely prefer your option "B". Biggest reason is that it doesn't require intimate knowledge of what combination of parameters works or doesn't work. Anyone reading or learning the API can immediately know what the functions are supposed to do and how to properly call them without accessing/understanding the documentation. 
Solved! Perfect. It did the trick. I just replace byte b for an integer (int b) because fs.readbyte will return an integer from reading. Thank you a lot Hondros!!! Regards!
Thanks for the quick reply! At school we've (more or less) learned to create a Manager/Service (BL) per 'package'. The Manager class then uses Repositories (DAL) to persist, read and update objects to the database. The thing that bothers me with option B is, that your package contains more than one class. So a municipality package also contains MunicipalityMembers etc. If I would use option B for every time I want to do something extra/differently, it would lead me to a huge manger and repository class because of there being a large amount of methods. Would you then choose to create a repository (and a manager) per entity? This would easily allow an implementation of CRUD through a generic repository, and then each repository on it's own would require but the implementation of the things you want to do outside of CRUD.
Thanks for the quick reply! Personally thus far only R/U in CRUD bother me. A manager/service would create objects and the only thing a repository does is persist them to the database. The problem I have then is indeed with reading objects in a specific manner/updating a specific field of an object. Reading in a specific way requires you to add it to your Repository, IRepository, Manager and IManager, which then feels like I'm doing something bad because for just one thing I have to update several classes... Then again, just skipping repositories and talking to my context from inside my manager feels like I'm violating the Seperation of Concerns, because a manager contains logic (BL) and shouldn't be talking to the database directly. It's also one of the reasons why I at this current moment don't really want to try out OData since it requires you to use your DbContext inside your controller which just feels awfully wrong. Ignoring repositories and using the context in my managers would end up in an overload of methods aswell (I think), because it maintains several entities. If you add multiple contexts/services to this even more so. Or am I wrong here? I do indeed feel like the repositories do make my life difficult for close to no benefit as you've said....
Not sure if I fully follow. I would agree with /u/I_AM_AN_AEROPLANE's style to consider avoiding using explicit repositories and directly access EF within your services if that works out better for you. &gt; The thing that bothers me with option B is, that your package contains more than one class. So a municipality package also contains MunicipalityMembers etc. &gt; If I would use option B for every time I want to do something extra/differently, it would lead me to a huge manger and repository class because of there being a large amount of methods. It's ok having several services if necessary. I would argue that this isn't a bad thing having every data access documented and explicit. You have single entry points to your data layer and it can make things a bit easier if you wanted to support testing (replacing services with different testing implementations), or simply to add breakpoints or log where you are accessing the database. It also adds a a perfect place to add any kind of data I/O validation with meaningful context. Also, maybe it's a bit of a generalization, but if you're doing so many _different_ database operations that you feel your service layer would be overly bloated with too many classes/methods, perhaps that is an indication to improve the design, or making a decision that's more meaningful to _your specific context_ rather than a general discussion about CRUD/services/repositories. I think personally, even if I had that large number of database operations, I would want them _all_ meaningfully tracked and _expressed_ and not buried/hidden with generalized repository calls peppered throughout the application/UI layer. It's nice to be able to look at the service layer and have it express what the application/database is _supposed to do_, not what it _can do_ (and thus imply that it can accidentally do unexpected things). If you start scaling up so large that you feel it's too cumbersome to explicitly define every single database operation that should be accessed, then you also need to be considering maintainability (including readability and refactorability) and potential bugs. That all said, you can always do a bit of both. That is, you can expose to your application the service API that explicitly expresses each database operation, but internally those operations can call private/internal helper methods that are more generalized. (For example, `ReadMunicipality(string name, int zipCode)` could simply be a wrapper around `return ReadMunicipality(name, zipCode, null)`) How many different ways/operations do you expect to be implementing here for your application?
I see. Thanks for the explanation.
I think it might still create the state machine, or at least that seems slightly unrelated to this change.
&gt; I just replace byte b for an integer (int b) because fs.readbyte will return an integer from reading. This is because `fs.ReadByte()` returns `-1` if you tried to read past the end of the file. If you simply cast `-1` to a byte you'll end up with `0xff`. &gt; **Return Value** &gt; Type: [System.Int32](https://msdn.microsoft.com/en-us/library/system.int32%28v=vs.110%29.aspx) &gt; The byte, cast to an [Int32](https://msdn.microsoft.com/en-us/library/system.int32%28v=vs.110%29.aspx), or -1 if the end of the stream has been reached. https://msdn.microsoft.com/en-us/library/system.io.filestream.readbyte(v=vs.110).aspx
I use these all the time. I write code that takes Func types as parameters or returns them. I create local variables out of them sometimes instead of making a method. Occasionally I have private members that are dictionaries with some Func&lt;&gt; type as the value. Anybody who's used LINQ has likely called methods that take these types as parameters. (Select, Where, etc) You might discover use cases for them by looking at languages where it's more idiomatic to pass around functions as values. Javascript is a good example. Basically if you want to be able to specify a behavior when calling your code, (similar to the visitor or strategy patterns, where there's an inversion of behavior), then using one of these delegate types in your interface might make sense. Callbacks are another example. They're one of the best things to happen to C# imo.
Yeah, it's completely proper, and it works :)
Thank you, that clarify all my doubts
There is no enum value in that.
The state machine is always created for an async method, but it's a struct so it doesn't require an allocation. Only when the first asynchronous point is reached (i.e. the first `await` on an uncompleted `Task`/awaitable) does the state machine get boxed and moved to the heap. So in the synchronous case with `Task` only the `Task` instance is being allocated and with `ValueTask&lt;T&gt;` there are no allocations at all.
Visual Studio "15": https://www.visualstudio.com/en-us/downloads/visual-studio-next-downloads-vs.aspx
Nice. Is this ready for production? Can I start hosting production asp.net applications on my digital ocean 14.04 droplet?
I felt the need to talk about data compression a little before moving onto UDP. It not about networking necessarly, but an important topic none the less.
Sounds messy
Hopefully I can explain this one in brief... This approach is setup to keep in mind SOLID in mind. Repositories are isolated as simple query able interfaces to a 1-to-1 table or view. There can maybe be some medium level complexity queries (methods) that receive a couple parameters but a repository alone cannot involve more than one table or view (i.e SqlRepo&lt;T&gt;) regardless of if the action is read or write. For more complex queries, we'll blend those into something like a "Locator". Those have repositories and whatever other parameters passed into them in order to return the necessary result set. These come in handy a ton when you have a complex set of logic that is re-used in a number of places. For example, PastDueInvoiceLocator(IRepository&lt;Invoice&gt;, IRepository&lt;InvoiceStatus&gt;, int customerId). Note: most all business logic components abide by an ICommand interface that has an "object Execute()" method that everyone universally understands executes processing and delivers whatever payload is expected. So the object above would just be invoiceLocator.Execute(). All of that is typically wrapped in a "Coordinator" object that basically assembles all of your logical components and executes them in order. An API or Service end point is about as dumb as I can make it. It sets up and injects what we need into Coordinators and just waits for an object to come back to return to the client. 
Maybe try assigning the gif sources at runtime? Also, is a computer upgrade possible? I don't have any experience using animated gifs in .NET. (if they aren't animated, then something must not be right if you're experiencing this kind of slowdown.) EDIT: Perhaps I misunderstood: is the slowdown occurring in Visual Studio in the designer (before you compile)? Or is it happening when you try to run your program?
May be, but they are not the same and shouldn't title it as such.
I recommend using Docker with a DigitalOcean Ubuntu droplet for an ASP.NET Core application. There is a tutorial [here](https://hahoangv.wordpress.com/2016/05/23/asp-net-core-rc2-run-in-docker/) for using Docker with ASP.NET Core which is done on Windows, but the steps should be similar on Mac or Linux.
I did not try to "diss" Ubuntu. What makes you think I did?
Yes. And? He's using apt-get, which is not a Linux thing - but an Ubuntu thing (or debian, or whatever else distribution uses it). Depending on the Linux distribution it has to be installed differently. Saying this is how you install it on Linux is wrong. And there are many other distributions not supported.
It was for example sake :) I use what ever logger framework I feel like at the time, isn't that the beauty OOP code? I can throw any logger into my interface wired up in my app.. :p log4net or just a poco console log class ;)
TIL! Thanks!
Have you tried http://ditto-cp.sourceforge.net/ ?
How would you install .net core on "linux" then? Do a git clone and then compile it yourself? But neither git nor gcc are linux things.
Most people run the more popular distros. Ubuntu, mint, and Debian being the most famous. 
I've been using [ClipX](http://bluemars.org/clipx/) for more than a decade now. I absolutely love it. I can't not have it on my home or work PC.
I always thought it was cool to use `Func&lt;DateTime&gt;` to allow for testing code that depends on `System.DateTime`: public static class SystemTime { public static Func&lt;DateTime&gt; Now = () =&gt; DateTime.Now; } References [here](https://ayende.com/blog/3408/dealing-with-time-in-tests) and [here](http://blackrabbitcoder.net/archive/2011/12/22/c.net-fundamentals-unit-testing-with-funclttresultgt-generators.aspx)
Unbelievable that I did not know about this. I love it!
Yup, they're one of my most heavily used basic types, aside from the usual integer, floating point, string types, and collections (List&lt;T&gt; etc). There are so many uses for passing methods as parameters to be invoked in some other place (and time!) - they enable decoupling code in a way that would otherwise be extremely clumsy and verbose. These brought easily accessible functional programming to C#, and practically revolutionalised the language. They power lambda statements and expressions, and as such a large portion of LINQ. Absolutely essential to modern C#. 
You can clearly see in the video that the MS download page has multiple distros listed. [Here it is if you want to check it out for yourself.](https://www.microsoft.com/net/download) 
Well, if you want to be a pedantic twerp, Linux is the kernel. So where's your tutorial on installing .NET Core as part of the Linux kernel?
Upvote for "pedantic twerp" :)
&gt; NLog That'll work as well. 
Yup. Used to use Ctrl-Shift-V, but now it's ditto all day all night.
Thanks!
So what is the point of compression in the networking topic? To reduce the size of data sent? Doesn't it hinder the actual speed of transfer, as in wouldn't you have to compress every packet separately? These are genuine questions, I'm not so hot on networking at all. edit: eh, should've read a bit before asking, oh well
If you felt the need to mention compression streams then you should probably have an example where you use them in combination with NetworkStream to compress all data send over the network automatically ...
But that only passes the default value for the property, not whatever value the user set in the current instance
I assume there's some sort of technical reason Mono isn't included in the list of .Net officially supported on Linux?
Getting hold of a main form from a child form is actually pretty easy. Would have been difficult the other way round. Anyway, here you go: var mainForm = System.Windows.Forms.Application.OpenForms["MainForm"] as MainForm; //Get hold of the current instance of main form var propValue = mainForm.MyProperty; //Accessing the property
Happy Cake Day. :)
Oh wow, it actually is, thanks!
Do you have exactly the same version of office on both PCs? Because it seems to be looking for a specific dll 
I'm calling the SideForm using a method as follows: private void SideForm() { using (SideFormViewModel vm = new SideFormViewModel()) { IWindowView view = ServiceContainer.Instance.GetService&lt;IViewFactory&gt;().CreateSideFormView(); view.SetDataContext(vm); view.ShowDialog(); } }
I assume in CreateSideFormView you actually create that SideForm. You can add a MainForm parameter to the CreateSideFormView and pass the current instance of MainForm to it like this CreateSideFormView(this) and in the CreateSideFormView you can pass it forward to SideForm constructor.
I don't think .NET Core has any UI libraries at all, really, so even if you had OpenGL, you couldn't map your render context to a window.
Ditto is my jam
Is there any way to access the property within the SideArm class? My guidelines specify that I shouldn't add parameters to the CreateSideFormView method
He/She was joking about how the title says shit instead of shift...
Oh hell, I didn't even see that.
Not C#, but surprisingly [relevant](https://nicosantangelo.github.io/weaintfoundshit.js/). Wonder if it's possible to make a Visual Studio Extension that does the same thing when you call Where, FirstOrDefault, etc...
Anything here help? http://stackoverflow.com/questions/13576806/bitmap-save-generic-error
Since I can't see the details, I have to assume based on the section titles that they don't demonstrate how everything fits together in one large project. That's a lot of stuff to learn if you have no programming experience. You can see it and understand concepts, but not understand how/when to implement. Not saying it's a bad course, but be careful and maybe do some additional digging into concepts before you move on.
http://referencesource.microsoft.com/#mscorlib/system/threading/Tasks/Parallel.cs
I generally see this handled by keeping your settings in a separate, static object, so I think a singleton would be appropriate so long as those settings could be considered global, which sounds like what you're describing. This would eliminate the problem of the settings being *on* the main form thus needing to pass it around. Technically, you wouldn't want them to be individual values of the form anyway because that doesn't even fit your design semantic (since those values also apply to other objects). Some might try to make the argument that singletons are inherently bad because they read it somewhere on the internet. They're not ideal because they're tough to test, but I don't think that applies in this case. Settings are generally global and are simple values, so there's nothing to test. But you could always not do a singleton and just new it up on app start and call it a SettingsService and pass it around, but to be perfectly honest, that sounds like a lot of extra work with literally no gain. In all cases, I recommend against what most people are suggesting here which is having the child search for its parent, or injecting *this* to the child. You're creating an unnecessary dependency on the parent and potentially breaking encapsulation all due to the fact that you didn't model settings separate of the form like you probably should have. Plus, now you can never open that side window without an instance of the other window should you need to in the future or in doing so, you'd have to write additional behavior to deal with the lack of reference to the parent which makes the window modal :( want some parmesan with that spaghetti?
I have been searching the web and now on reddit and found your comment. I love tfs and I am planning on using git vc. Is the fact that its managed offline the major redeeming factor? I do understand why that's a big deal but is there any benefit for tfsvc? My research says no.
Didn't know about this, but not surprised. I wrote my own PasteManager program a long time ago to store previous copyings. Upgraded to handle images and filenames too tho.
.NET Core supports P/Invoke so there's no reason you couldn't call into a native library like SDL2 that does this for you.
Can't function without it. My colleagues are blown away by how useful it is, but never get around to installing it.
Or all the .net languages' documents only
Take a look at global keyboard hooks.
I really like those tutorials and find them super interesting, please keep them coming. :)
[removed]
From the VS 2015 top menu: Tools -&gt; Import Export Settings -&gt; Reset All Settings
I got bored and did it on my phone at some point, it is rather basic and doesn't really teach you about implementing the skills you learn in a real project, just snippets of code out of context.
OpenTK is not maintained anymore, is it?
Removed: Rule 8. While it's not against the rules to suggest a google search, try to be more encouraging to users in how to perform a correct search to find the content rather than imply that they haven't done any work at all and never do. For example, you could suggest in order to more easily find such sources in the future to include the keywords "C# reference source", or better yet "C# site:referencesource.microsoft.com"
¯\\\_(ツ)_/¯ Sorry, don't know what else to tell you beyond searching for more specific contexts (for example, you still haven't mentioned what platform you're using, or maybe testing on different computers and hardware/software configurations)
I work in a 'DevOps' role, so being able to make my own systems administration tools that integrate with windows well is useful to me. I've done a few things, IIS configuration and so on. I'm also curious about learning how to make my own Dashboards, to show service stats and more. I would eventually like to make my own page.
Fair enough. I stated the fact first thing, and added that bit in so that other people (like me, a few months ago) who do not use or know what a delegate was really could possibly get the basic concept and get interested in googling/trying to use it. If you ask me its not that nonsensical. Delegates in c# are just type safe function pointers.. "in the background are just an instance that represents a function". 
And the builds, is that what Microsoft Team Services considers an "Agent"?
Take a look at DotNetty - not on .NET Core yet but should be soon: https://github.com/azure/dotnetty
Lock the database when in local mode. Is the only thing that I can think of. Else maybe you could have local changes allowed but once you connect if there has been updates to the same tables. Then warn the user and get them to decide which update wins. I know thats about a hundred times more difficult then I'm giving it credit for. I would go for mysql main database with a cached local copy in sqllite. Depending on the size of the database and security issues etc downloading the whole database and then keeping it in sync personally sounds like a nigthmare. Sometimes you need to argue against arbitrary restrictions placed on you if they make no sense. It sounds like you actually need a website that people connect to rather then an application. 
Removed: Rule 3, Rule 6.
Appreciate that you will look into it. It would be a nice feature though! Look forward to seeing it implemented in the future! Could make it do something like FluentUri.From("http://example.com/somepath?foo=bar&amp;foo=baz").TryGetParams&lt;string[]&gt;("foo", out results); or FluentUri.From("http://example.com/somepath?foo=bar&amp;foo=baz").GetParams&lt;string[]&gt;("foo"); or for a single param FluentUri.From("http://example.com/somepath?foo=10").GetParam&lt;int&gt;("foo"); So you have to define what it should expect to return it as. Seems like it would be a reasonable way to do it. However I am not sure if the code base could support adding something like that. Just a suggestion :)
This. Particularly the guids+event sourcing. My experience with sync framework has been aweful though, I'd give that a miss.
Thanks for the links! One of the issues is posted by me by way.
After a quick look I didn't see anything MQTT related in the examples folder. Is this really supports MQTT?
DotNetty is a port of a popular Java library that makes network communication eg tcp udp etc. easier to deal with. So no pretty sure it has nothing to do with MQTT, you would need a library on top of this for that. For example the guys who make azure release many nuget lbraries and Azure message queue uses dotnetty.
There is a .NET Core package for M2MQTT but I had an issue with it while talking to AWS IoT (ended up finding a way to do everything in the AWS SDK so dropped it and didn't fix the problem). If I sent a message to a room immediately after connecting, it would send the message before connecting and therefore not send the message. (It would eat the error, too.) Similarly, if the connection was closed immediately after sending a message it would happen while the message was being sent, with similar results. This was just after Core was officially released, and the .net core NuGet package didn't look like an official release (and it wasn't), but keep that in mind (test for it) if you end up using M2MQTT. Other than this issue (which can be worked around, I guess), it worked pretty well.
I have honest doubts anyone would write code line it was initially in the first place. You got any real example?
Lucky me I guess, I've never seen such code in a real work environment.
&gt; How would you introduce programming, with C# in particular, to a complete coding novice? Leave out any higher concepts for now: Classes, objects, types and so on. Create the boilerplate for them and then show them how to write actual method implementations for now in a procedural manner. That would be my advice, anyway.
Writing some interfaces as targets to hit was my first thought. I'm concerned though that, while easier to teach, it might limit their own creative solutions. I don't want to be that asshole architect who hasn't touched a line of code in 10 years and yet thinks he can communicate his wisdom through UML diagrams. Edit: Ahh, that wasn't supposed to sound so bitter.
Sadly, if you work freelance you see this type of thing quite a bit. Maybe not to this extreme, but the most common issue I see with code that is written by an inexperienced programmer is over-complication. If I can take a 20-line function and reduce it down to two lines that are actually more robust, I consider it a good day. :) 
I'm not a teacher either, but when I've shown kids how to program, I started with very basic concepts. First, variables and how computer store data in memory (not the nuts and bolts of it, but how "string myName;" tells the computer to reserve some space called "myName" to put text there). Then I'll do a little input/output using the console. If they're very young, the simple "Enter you name:" ... "Hello, &lt;yourname&gt;" can keep them busy for a while as they add questions and eventually have the computer insult you while they laugh uncontrollably. Then it's on to if...then...else; that can be added easily to the question answer format, as the answer can vary based on input (ie, "How old are you" and "you're my age!", "you're old", "you're a dinosaur"... then loops (generally the first "hard" part from my very limited experience) and if they're still interested, maybe a simple game like Hangman. Since Hangman requires a list of words, I usually introduce lists at that point (used to be arrays, but lists are simpler... ) If the kid is old enough, I'll show him the various console methods to position the cursor and redraw the little stickman on screen. If it seems too complicated at that point, we can just scroll/clear the screen after every guess. It's been my experience that introducing OOP too soon makes their eyes glaze over... so I stick to simple procedural code to start. I'll show them functions once I see that they have similar code repeated many times. It seems to work better when concept are shown based on simple code they wrote than when it's introduced "artificially" with contrived examples. 
I haven't used `NAudio.Dsp.Complex` or anything to do with it. You should consult the documentation for that library to see how to construct a `Complex` using a float. That being said, if `Complex` is a [Complex Number](https://en.wikipedia.org/wiki/Complex_number) then it's unlikely to be constructable from a single float argument.
Yeah I've seen this kind of thing a few times, particularly with legacy code. A combination of limited experience, trying to code for potential future requirements that never materialized and bolting on a bunch of new functionality without refactoring. You can end up with some real over-complication. Llewellyn's other video with Woody Zuill is well worth a watch - [Practical Refactoring](https://www.youtube.com/watch?v=aWiwDdx_rdo), following a similar theme of refactoring without understanding but on a larger example. While both are quite extreme examples, it's not that far removed from some code I've worked with.
https://app.pluralsight.com/courses/teaching-kids-programming
Whats the inline hotkey he is using? I would use that fairly often.
Then you haven't had enough jobs yet!
It always amazes me that programmers always manage to check in code like that in the first place--but they do. Everybody should be doing this kind of stuff on their own code any time an opportunity presents itself. 
"silly programmer, there's no time for refactoring" - my boss
Code like that gets created when people try and predict the future. So this simple example was just showing two scores. Perhaps they thought, well if we add three scores we can extend this pretty easily. Premature Optimization. The fix is to always do the simplest thing that works. Stop trying to overanalyze what may or may not happen in the future. Write code for today. 
A lot of times code like this evolves. Perhaps this function was showing many different scores and then requirements changed to only show two. This is how code like this comes about. Most times though it's developers trying to prematurely optimize something that doesn't need it. 
It looks like you're rolling your own database. Before you get buried too deep in the mud, I would strongly suggest that you **don't reinvent the wheel**, and instead look into an existing database solution--like SQL Server Express, MySQL, or SQLite. Just about any database implementation you choose will have solved this problem already. &amp;nbsp; However, in the interest of actually answering your question, the below code should do what you want. It uses LINQ to more simply express the work being done. I haven't tested it, so it'll probably need to be tweaked some. public void InsertUsernameIfNew(string username) { var fileContent = File.ReadAllLines(deckFile); // Get all lines from deckFile bool fileContainsUsername = fileContent .Select(line =&gt; line.Split(',')[1]) // For each line in deckFile, split by ',' and take index[1]. .Any(fileUsername =&gt; fileUsername == username); // Take each result from .Select(...) and return true if ANY of them match the 'username' argument. if (fileContainsUsername) { return; } using (var writer = File.AppendText(deckFile)) // using (...) { } will call writer.Close() automatically. { var newLine = fileContent.Length + "," + username + ",1,,,,,,,2..."; writer.WriteLine(newLine); } }
TFS doesn't, to my understanding, support git - VS supports git (and yes, it works fairly well). Either way, I was talking about the TFS source "control" in this case. :)
You're the kind of dev I like working with. 
I know--it is hard, but sometimes code bases just need to be brought down to maintenance mode and eventually phased out after having been replaced by shiny new code. If it truly is that bad. Getting management to realize that, and then getting the business stakeholders to agree to build a new system usually takes an Act of God, but it does happen. At the company I was working at with the massive classes full of spaghetti code it was especially difficult because development management, who had the near implicit trust of the CEO and other business stakeholders, were the same ones who were largely responsible for the mess the system was in--they had been around for years and wrote the early code, thereby setting the standards for which everyone else would follow. So at that employer, the term "refactor" was especially politically loaded. You were essentially complaining about the quality of the code that was written by the people who now decide if you get a promotion. And if you looked at who got promoted to positions of significance (i.e. architects and managers with software engineer direct reports, etc) it was almost entirely all people who never spoke of refactoring, who never complained about the code, who were totally happy just propagating the same anti-patterns and spaghetti code without question. (This really pissed me off to no end...) At said company, it took the hiring of a minor celebrity (within the .Net world) software engineer / architect with major clout going way beyond our division (it was a very large company) to tell the decision makers of the situation-and-the loss of millions of dollars of revenue before a new system was started. And of course, it wasn't long after this that the right heads started to roll... Justice was served. It was nice. But, I digress.
It's hard to provide concrete advice without being on the inside there, especially since we have no real concept of the scale of changes, the web of impacts they might have, the number of people involved or affected by the refactor, and the skill level of the developers to each individually perform the refactors. Do you know how long it would take to perform the refactor, on its own, without taking into consideration development on other features? With the existing API, is it possible to perform the refactorings behind the scenes, that is, keep the existing API but apply the refactoring within the implementation of that API? Once the refactoring is complete, then you can push those individual API changes relatively quickly with (hopefully) minimal impact to other developers. You can list/identify all the areas that need to be refactored and whenever a developer will be working on that area (and ideally, no other developer is working on it simultaneously), it will be their job to also implement the refactorings? I think regardless, your organization needs to embrace the idea that refactoring to improve maintainability and maintain/improve ease of development should be an ongoing process. This usually means having high level automated tests that can ease refactoring and mitigate the possibility of introducing bugs, and empowering developers with the freedom, tools, and training to improve the code base wherever it warrants doing so. Treating refactoring as a monolithic, large, one-time (or rare) action is probably just going to cause headaches over time. Of course, that's probably the idealist in me; reality is very different and it sounds like it's possibly not too viable for you.
Fortunately for me, sort of, I was hired specifically to untangle the mess and build out the foundation of the 2.0 version. It's a tiny company at the very beginning of the transition from startup to real company. I only just started and I'm still learning the actual business and the code base while doing some maintenance tasks. Everything is so much more complicated than it needs to be. What's really annoying is that the people that built it (off shore contractors) got overly clever trying optimize stupid things that barely even matter while leaving the core system a tangled, slow as crap mess. There are so many methods that grab something from the db, pull the id off of it, pass that id to another method which uses it go back to the db and get the same record again. It's absurd how little activity bogs down the servers. I've got my work cut out for me. 
Yeah, put out the fires but don't make it perform so well that they no longer see a need for version 2.0. Wait... is that unethical? Hrm...
http://www.filedropper.com/portraitbuilder Scan the files/executables before using. Also, never used "File Dropper" before (just googled for some quick/dirty file hosting) so use at your own risk. EDIT: Both debug and release builds are included.
Start by writing your code in English, so other people will understand it.
I believe most of the code is in english, there might be some that I forgot to translate...
I know a lot of people around here are saying otherwise but even to me that for loop seems a little far fetched. It looked diabolical. I'm not expecting too much am I?
[removed]
Put this in your head. It will set it so it doesn't cache the page.. &lt;META HTTP-EQUIV="Expires" CONTENT="Tue, 01 Jan 1980 1:00:00 GMT"&gt; &lt;META HTTP-EQUIV="Pragma" CONTENT="no-cache"&gt;
Thank you. I would be learning more OOP soon so that I make better desitions.
Use XML comments on the top of methods and classes so that you can get intellisense on them. (Type /// on top of a method to automatically generate a template)
A lot of those public variables could be implemented as properties. Especially those that aren't intended to be modified from the outside. &gt; public static int numberOfErrors { get; private set; } . &gt; string season = "0" + seasonNum.ToString(); Appending 0 zero first could be done automagically using a format. 
Can you elaborate a little bit more?
Thank you! The third option worked! The issue I was running into was when i attempted to pull a string into.. string content = Convert.ToBase64String(readText); it gave me an error that I cant do string[] to string.. 
Probably. Most build systems distribute the work out to "Agents" to actually do the work of building so that many different things can be built on the same pool of resources.
As @andrewsmd87 already mentioned, I believe that the project is not disobeying the license iTextSharp
Thanks. No, it only works with S01E01 or S01E01.S01E02 or S01E01.E02 or S01E01E02 (for multi episodes). Haven't checked guessit. I wrote this because I was tired of changing certain strings to other, removing titles, etc. 
Thanks. But i feel it is more readable my version?
What kind of server? Microsoft SQL server? What you're trying to do is pretty simple but you need to know the specifics of your data source and a little bit of TSQL. 
That app uses the Device Portal webpage that your phone can host in Developer Mode and uses the REST calls that the webpage makes. this is all documented on [MSDN](https://msdn.microsoft.com/en-us/windows/uwp/debug-test-perf/device-portal-api-core).
The .ToString() method usually also has an overload which takes a string, which is commonly used to format the data in a way you want it. (2).ToString("D2"); // returns "02" as a string You can find a lot of possibilities here: https://msdn.microsoft.com/en-us/library/dwhawy9k(v=vs.110).aspx Edit: Added link.
Whoever wrote that code in the first place needs some re-education. 
You really are.
Thank you so much for the help. I am running into some issues I'm trying to work though, like the connection must have credentials, and then it must use a secure string for the password...silly things like that. Now when I connect to the database how do I select a certain table to find the actual dataset I'm using (there are two different tables on the server).
I think you're mixing up your terminology on me. DataSet is a container, its a collection of DataTable objects. In my code above, I cut out the middle man and just loaded up the rows into a DataTable via a direct TSQL 'Select' command. To select all columns and rows in a given table, you'd: SELECT * FROM tableName Obviously, to narrow that down to just the rows you want to see, you'd add a WHERE clause on there to limit the result set. As far as the username/password, this is frequently accomplished by loading the connection string from your Web.Config file or, for windows/desktop apps, the Settings file. That way you arent hard coding database credentials. You'd accomplish that by using the System.Configuration.ConfigurationManager object: SqlConnection conn = new SqlConnection(ConfigurationManager.AppSettings["ConnectionString"]); Where "ConnectionString" is the name of an XML node in your application's config/settings file, like: &lt;appSettings&gt; &lt;add key="ConnectionString" value="Server=azureDbAddress;InitialCatalog=DBName;Username=bob;password=!SecretSquirrel999$"/&gt; &lt;/appSettings&gt; 
There's two sides to this. I mean, don't paint yourself into corners either or you're just collecting tech debt. At some point, that debt might be called in and you WILL pay with interest and the argument against premature optimization isn't going to help anyone. IMO, at the start of a new project, someone needs to ask what the intended lifespan of the application is going to be. Is this an app that will be stood up and then left alone or is it something that's going to continue to evolve over the next 10 years? If it's the latter and you still take the "simplest answer works" route, I can almost guarantee you that you're just going to create more work for yourself. It's borrowed time. Imo, the best balance is to not add robustness that isn't needed, but still follow good design principles and have a standard. 1 hour of extra work today could and likely will save you 40 hours of work a year from now. That interest paid on tech debt is no joke. Case in point, we have a collection of integration libraries that aren't even a year old yet. A couple guys decided it was ok put business logic in this layer for the sake of time. Fine. Now that it's 8 months later, we were asked to move all of that stuff into a nuget package since it doesn't get updated often and it is also needed in a synchronization service that was created. Guess what? Can't. Because in order to accomplish that business logic, references to the data access layer were also put in there. Guess what else? There's also business logic inside of that data access layer. Crap. So now all of that has to be fixed in order to do a job that could have taken a few hours if only the developer had taken the time to put things where they belong. So why did he do that? Because it was simpler. So, there are other options to get this thing to work like... build the two solutions side by side so solution A is dependent on solution B, therefore has access to some binaries that are output. That would totally work but it just makes the problem worse. Why? Save time. Keep going down the road of shortcuts, and it will get exponentially worse over time. My last job refused to acknowledge this and it has gotten to the point where changing text in a single place is an 8 point story because of all the compounding issues caused by shortcuts that were taken over the last 6 years.
It does not, and it can be significantly faster.
You've got me curious - if it's not converting cases under the hood, how are the comparisons done? 
So when you build out the datasets using the designer, what is actually happening is that the TSQL commands that we are talking about are also created and are stored in the designer files. You can add Insert/Update/Delete commands to those pre-made ones, but it takes some digging into it to see what you need to do and how to call them when you need to. My examples are more the "I am controlling everything about the data access" kind of thinking. If you'd like to customize the designer output to do what you are asking, you should really, really watch the MSDN Forms over Data series of how-to videos. They go into much more detail than I can here. She is targeting VB developers, but ignore that because the process is identical for C# designer driven data binding. https://msdn.microsoft.com/en-us/vstudio/bb466226.aspx#formsoverdata 
There are two concerns. Performance and functionality. ToUpper will lose on both counts. At a minimum ToUpper() would create new strings , which is going to copy everything over. Since that copying is very expensive (especially for long strings) that is the main performance benefit of not doing it that way. Assuming that you are calling ToUpper on both halves, you are making two new strings, uppercasing as you go, then comparing, then having to collect both new string Possibly more imporatntly, if there is any chance there is non english input that you are going to be processing though, ToUpper will not work reliably. Compare is doing something quite a bit more complicated than uppercasing. Primarily to deal with many to many mappings between unicode character points (some languages have multiple characters for the same letter, where the letter position within the word determines the char, or accents, etc) In particular this is dangerous, because in some languages this mapping between upper and lower case versions is lossy. (eg, ToUpper().ToLower() might not be the same as ToLower()) String.Compare is essentially looping through the string, and picking the "master" unicode code point for every char. What that master is resolved as depends on your current culture settings, and which parameter to compare you are using (ordinalIgnoreCase vs CurrentCultureIgnoreCase etc) This doc page has some good examples of how some of those mappings work. https://msdn.microsoft.com/en-us/library/e6883c06.aspx Heres another good doc https://msdn.microsoft.com/en-us/library/ms973919.aspx Also, based on the newest reccomendations, string.Equals is for equality, string.Compare should only be used for sorting
It really sounds like you've never worked with a database before let alone hook up an app to it. There are a handful of concepts you'll have to understand so maybe you should start at the beginning. Check out this walkthrough for a high level overview: https://msdn.microsoft.com/en-us/library/jj943772.aspx You're also going to need to understand how relational databases work because all the C# code is going to do is send commands to the database and handle the data. That's not going to be very helpful if you don't know how to move around a database apart from the app code. Maybe this will help: https://mva.microsoft.com/en-US/training-courses/database-fundamentals-8243?l=TEBiexJy_5904984382
You can use SQLite and for a simple (relatively) file based solution. It supports features such as LINQ based queries and easy CRUD operations. It's also really performant. 
Essentially when you're under resourced you take the option that's the minimal change possible. After a few years and a bunch of changes you end up with something that works but maybe shouldn't. You can't really clean it up because you need testers from five different teams and there's no business requirements to fund that testing so it sits there and the rot grows and grows.
`Convert.ToBase64String(readText);` accepts a single string. You have a string array (multiple strings).
I'd use json. You get a bit more leniency when you want to de serialise them later. But.. What are you trying to accomplish? There's lots of reasons why using a db is a good idea. Is this a Web app? Doing disk io is gonna drag your site to the ground. 
Please do not pass input from a text box into a raw sql query string! 😬 Every time you do that a kitten dies. 
 string raiz = ""; if (System.Diagnostics.Debugger.IsAttached) { // if we are running under visualstudio, we use the C:\TEST\ folder for testing... raiz = "C:\\TEST\\"; } else { // else, we use the actual folder where the program was invoked from... raiz = Environment.CurrentDirectory; } This can also be created by using pre-processor directives like string raiz = Environment.CurrentDirectory; #ifdef DEBUG raiz = @"C:\Test\"; #endif Do make sure that the 'define debug' option is on in your project settings (build -&gt; first checkbox (Define DEBUG constant)(Only do this for the debug configuration)) or define it yourself using #define DEBUG 
*waaaaaah* white VS :Q
I figured 25.00usd for the first half hour then 30 bucks for the next half hour, the 50 for every hour after that.
1. `ChapterManager` is doing a lot. 2. Make it so your methods are functional and can stand alone. A good example of this is `LoadResolutions`. It should take in a path of what to read, and return you a list. 3. Avoid global variables. 4. This code has lots of potential to be refactored.
Why is csharp always the target for these low quality bullshit posts? We really need better rules
You can do that in one step. Or in more than two.
Weird that record types implement IStructuralEquatable. This generally makes the most sense for collections, but I suppose you can get "duck type structural equality" from it as well.
&gt; I wonder if x86 has a less rigorous coherency model, forcing the CLR writers to stick some extra guarantees in there? On the contrary, the memory model in x86 is unnecessarily strong, really. AFAIK, in x86 acquire, release and full barriers are all the same (full).
What does it mean to "write in hex"? :p
Or you simply use `string.Join` and the hole problem is solved.
Thanks. Regarding classes, shouldn't they be self contained? 
What would you like the additional rule(s) to be and how would you word them?
I tried compiling it with csc that comes with .NET Framework but it said it needed the latest version. Do you know in what folder to find msbuild? Thanks for you help.
The easier way is to just copy the list: foreach (TcpClient client in Server.listClients.ToList()) { ... Server.listClients.Remove(client); ... } but you have to, well, create a copy of the list with all the drawbacks (performance, memory etc)....
Ok, thanks!
Sure. I prefer the list to remove because it's easier to get, for example, a condensed log of what you're acting on, and is easier to debug.
Try "set localecho"
If/when these guys support the remaining .NET platforms, Realm seems like it would be a good solution: https://github.com/realm/realm-dotnet
Where? in telnet?
ForEach should only be used when you are not mutating the list itself. 
Yeah. It's been a LONG time since I have used Telnet, but if the server isn't set up to echo, you won't see what you type or what it responds. Or, I believe if echo is set up wrong you see everything twice. (But as I say, this is from memory from 30 years ago!).
Thanks! Very interesting.
Use some linq , oldlist = oldlist.where(x =&gt; x.Connected).ToList(); Easy. 
Two things jump out that are going to trip you up.. First is that you are looping over open network sockets on the UI thread. That's all kind of bad news. Second is that there's no easy to do this with `List&lt;T&gt;` because it is not a thread-safe collection. Once you get off the UI thread (and you should, start [here](https://msdn.microsoft.com/en-us/magazine/jj991977.aspx) with Stephen Cleary), you then have the situation where multiple background threads could be attempting to update the collection at once since the UI doesn't lock when you click the button the first time. Again, bad news. You could try to write some synchronization code or you could simply use a collection from the `System.Collections.Concurrent` namespace. Sadly there is no `ConcurrentList&lt;T&gt;`, but in a pinch a `ConcurrentDictionary&lt;T&gt;` will do. The last time I did this `ConcurrentDictionary&lt;T&gt;` was the way to go as I needed to keep track of the open connections by a GUID assigned to them anyway and we could have quite many. Even if you don't need that GUID identifier you can still iterate through a `ConcurrentDictionary&lt;TcpClient&gt;` and then use `TryRemove` method to remove during iteration just like you are doing here and that is perfectly safe. 
Unfortunately it ultimate delegates out to a native DLL, so we can't see how the comparison is actually done here.
Or you can do: for (int i = 0; i &lt; Server.listClients.Count - 1; i++) { if(dead) { Server.listClients.RemoveAt(i--); } }
Won't i now be skipping an entry if you do this? 
You are correct.
&gt; why someone smarter than me hasn't wrote a generally accepted solution to write objects/references to disk in a very simple way. They have, and they named it XML, Json and SQLite.
&lt;3 LINQ
&gt; `RemoveAt(i--);` https://dotnetfiddle.net/P9aj65 `i--` decrements `i`, then returns the *old* value. `--i` decrements `i`, then returns its *new* value. That bit of code is just a more concise way to do this: Server.listClients.RemvoeAt(i); i = i - 1;
In general, never mess with the enumerator when inside a foreach.
Not sure why you're using a synchronous method but ok (this WILL block the thread). Anyway i think the reason is that you're reading on the networkstream while it hasn't the data available and it block the whole thing, i haven't tried (and i haven't used a networkstream in a while) but i think you should use the networkstream's DataAvailable property. (see https://msdn.microsoft.com/en-us/library/system.net.sockets.networkstream.read(v=vs.100).aspx ) put if (!stream.DataAvailable) continue; and see what happen...
We do this when the DLLs are binary-compatible. Keep the AssemblyVersion set to some baseline version (like 3.5.0.0) but set AssemblyFileVersion (what you see in Windows Explorer) to the "real" version. That way you don't /have/ to recompile everything referencing it. I believe JSON.NET does this as well (Ref: http://james.newtonking.com/archive/2012/04/04/json-net-strong-naming-and-assembly-version-numbers )
Ok i will try diffrent ssubreddit 
The connection needs to be closed, then a new list needs to be generated. So it would need to be: oldlist = oldlist.ForEach(x =&gt; if(!x.Connected) x.Close;).Select(x =&gt; x.Connected).ToList();
Here's my first take at it.. seems to serialize and deserialize properly. The MyContractResolver might be overkill, lol. using Newtonsoft.Json; using Newtonsoft.Json.Serialization; public class A { public String Label; public IList&lt;B&gt; Bs = new List&lt;B&gt;(); }; public class C { public Int64 Id; public IList&lt;B&gt; Bs = new List&lt;B&gt;(); }; public class B { public Int64 Id; public String Label; } public class D { public A A { get; set; } public C C { get; set; } public D( A a, C c ) { this.A = a; this.C = c; } } private class MyContractResolver : DefaultContractResolver { protected override IList&lt;JsonProperty&gt; CreateProperties( Type type, MemberSerialization memberSerialization ) { var list = base.CreateProperties( type, memberSerialization ); foreach ( var prop in list ) { prop.Ignored = false; // Don't ignore any property } return list; } } public static JsonSerializerSettings Jss { get; } = new JsonSerializerSettings { ContractResolver = new MyContractResolver(), TypeNameHandling = TypeNameHandling.All, NullValueHandling = NullValueHandling.Ignore, DefaultValueHandling = DefaultValueHandling.IgnoreAndPopulate, ReferenceLoopHandling = ReferenceLoopHandling.Serialize, }; private static void TestSerialize() { var b = new B { Id = 1234, Label = "hello" }; var a = new A(); var c = new C(); a.Bs.Add( b ); c.Bs.Add( b ); var d = new D( a, c ); var sd = JsonConvert.SerializeObject( d, Formatting.Indented, Jss ); var ds = JsonConvert.DeserializeObject&lt;D&gt;( sd ); } 
LINQ still has to iterate that list and validate what's going on. If oldlist gets mutated while that runs, you'll get the same problem.
From MS: Entity Framework http://www.codeproject.com/Articles/363040/An-Introduction-to-Entity-Framework-for-Absolute-B Alternative: Dapper http://www.codeproject.com/Articles/212274/A-Look-at-Dapper-NET
I would start with a calculator. Or a text based decision game. They're not gonna care about oop or why its so good they want immediate results. Then maybe move on to animals with oop and a game. Something simple like display 5 random animals. Then ask the user a question. Like which animal is red. Or which ones have 4 legs. Snake to me seems too advanced.
Thank you! I should have known that... Brain fart, but I guess one liners can do that to you.
Dapper is my favorite. 
Dapper.
And I *don't* think you should *actually* roll your own serialization framework *except* as a learning exercise. It may show up some of the interesting wrinkles to the problem that aren't obvious from an initial think. If XML serialization is 95% of what you're after, the thing to do is probably to figure out what things need some help and work around those. You could, for instance, create a wrapper property specifically for serialization that, say, returned or set the TimeSpan as a number of milliseconds (or seconds, or or whatever makes sense for your use case). As far as streams go, you could be serializing to a bunch of different destinations--local disk, database blob, network, etc. (Or *from* a bunch of different destinations, including an embedded resource in your assembly.) Makes a lot of sense to let the user (i. e. you) sort out what sort of stream to use. Sorting out a generic solution for that is awkward, because the different use cases are all very different. So, there may be a simple, reusable piece of boilerplate that covers your particular use case, but one that could cover all the possible uses would probably be too complex to be worth the trouble.
&gt;The issue is that while this would be going on, normal development will still be going on in the master branch and we want to make sure that new work, bug fixes, etc are making it into the new branch This is hard to do. It's hard because your new architecture could just fix the bug anyway, so you could end up merging code that doesn't need to be there and just introduce a new bug. I would just suck it up and do the debugging/verification work twice: Treat every fix in master as a potential bug in the rewrite and verify in both places that it's fixed/not a problem. The most expensive time cost you will pay is when someone is currently rewriting a section and you have a bug in that section in master. You have to read the current rewrite code in that section to see if the bug fix is relevant but you also have to understand where that author is going with the rewrite because he may not be done and you may violate his assumptions. You'd be better off just handing that bug off to them because they've already paid the time cost of getting that rewritten code into their head and so they have context on whether the bug matters or not.
Let me rephrase that. I have a database displayed. User selects the row with the Id in it to receive into inventory. The text box just displays the fields selected and are not editable. The qty to receive I was going to do a drop down box for a qty (say 1-10). So I'm just using the text fields to hold the primary keys that I will look for in the second table. I hope that makes sense...should I not be doing it this way?
What if someone manipulates the post / get request and does something like drop tables? 
How could they manipulate it if the only thing they actually change is a drop down box? Everything else is acquired from grabbing the information from a non changeable datagridview. I tried to lock the pesky user out of all of it almost... edit: for clarity the datagridview passes the values from the table into a text box, which is read only, then the query to the second database uses the variables in those textboxes to get/manipulate data in the second table.
http://pastebin.com/2xy1w45V Nice first C#, Javier!
&gt; Conatins Is that a southern function? :P
I'm so confused....I'm not allowing the user to type anything in...they select from the list of available items, then select a drop down of set quantities, again not typing anything in. All my fields are non editable, just for display purposes. Or are we talking about possibly hacking into the actual program itself's source code? 
&gt; Don't use edmx with entity framework use the "code first"but you can still create the pocos from the existing database Can you elaborate on exactly what you mean here?
The difference between WriteLine and Write is that WriteLine will append a new line at end of your output and your cursor will be at the beginning of a new empty line instead the end of the current one.
Huh. OK. My lecturer was very upset by the fact that I used WriteLine instead of Write in my initial program. Thanks though
Just a useful tip: Ask your lecturer right away **why** he is upset. Let him explain it to you.
Definitely! Thanks once again guys. 
Since it appears to be established that it's a preference thing for your prof, I'll just say if you're not using the snippet "cw TAB TAB" for writeline, you should be. Start using those keyboard shortcuts now.
As stated by /u/poply, WriteLine is just Write with a new line automatically added at the end. In this case, here's the reason your professor probably cares: Your code output as is: &gt; Highest temp weekone &gt;72 &gt; Highest temp weektwo &gt; 79 &gt; 75 That works, but it might look better if the input is on the same line as the prompt, which you'll get if you use Write instead. &gt; Highest temp weekone 72 &gt; Highest temp weektwo 79 &gt; 75 You might also think about adding some slight tweaks and a label for the avg temp: &gt; Highest temp week one: 72 &gt; Highest temp week two: 79 &gt; Average temp: 75 Finally, calculated as is, you'll notice the average is rounded down, because it's using [integer division](http://www.dotnetperls.com/divide). If you divide by 2.0, it will output a double for the average and keep the .5 on the end. But do whatever your prof wants.
The continue statement passes control to the next iteration so it doesn't exceute the code after it :) while(true) { if(!statement) continue; //whatever } and while(true) { if(statement) { //whatever } } are equivalent
Another vote for dapper. A brilliant extension is dapper contrib too. 
Hehe... It was meant as a simple case to make him rationalize it out himself: It's not as simple to make a .save()! ;)
just guessing, as I didn't write the original code, but the GetScoreText() wasn't originally a method, it was a block of code in the for loop. Those extra 6-9 lines might be why the original programmer wanted the for loop in the 1st place.
Code issues aside, the physicist in me wants to know 1) if you are asking for Celsius or Fahrenheit; and 2) why you are finding the mean of the max.
&gt; If you want to still be able to use linq then entity framework is your best bet. Why? A lot of ORMs support Linq, have a faster runtime, allocate way less memory and support way more features, also with Linq. E.g. eager loading/nested queries they're not fetched efficiently with EF, using in-memory code in the projection is not supported in EF (while it is common, e.g. to postprocess a value before you store it in a property), no type conversions support, so mapping e.g. a bool on a char(1) or Numeric value (used a lot on oracle) is not supported. 'Best bet' ... no way. &gt; If you want to write your own SQL then dapper is the best bet. Why? There are other MicroORMs out there which are faster than Dapper. &gt; EF 7 is still in beta I think but supposed to be very fast and efficient. It lacks a lot of features (e.g. no group-by in the database, it's all done in-memory) and 'very fast' is subjective, e.g. [LLBLGen Pro](http://www.llblgen.com) is faster. Efficient: sure it's more efficient memory wise than EF6 but not by much. It's faster, but a lot of features aren't implemented yet: they do a lot of stuff still in memory (very inefficient) or not at all. Reading some data and writing some objects is supported, but any ORM does that properly. It's not as if ORMs are new on .NET: it's more or less a solved problem: there's no reason to use a .NET ORM which lacks features all over the place like with EF7/Core. 
Just convinced my boss to switch over. I argued that it was development time vs performance time, and 90% of our projects are constrained by the former.
I tried deleting and uninstalling Dropbox, to remove any trace from it, no Luck tries to install in a folder that doesn't even exist
your grid(s) display a count for the total records, but I'm confused why its labeled "Founded: ####" Founded is new to me. should it be Found, or simply Total Records: 
It's shorter, fewer lines of code, but that's not necessarily better. I would say that it's a good practice to put any and all initialization code in a constructor. That way when the class size grows, and you need to make a change to how the object is initialized, you have one place to go, rather than (possibly) scratching your head at not finding the code in the constructor, and eventually realizing that it's being initialized in this alternative manner.
Are you sure this is part of your C# course? Because **both** examples would **not even compile**. The first example: &gt; CS0568 Structs cannot contain explicit parameterless constructors The second example: &gt; CS0573 'Menu': cannot have instance property or field initializers in structs Structs do not support default initialization code, and this is by design. 
If you want to use the right tool for the right job and think that an ORM that uses LINQ is the tool that you want then I would like to argue that you are making the wrong choice in using a SQL database. If a SQL database is the right tool for your job then you want to easily have access to all of the powerful capabilities that such a database can give you. The best way to do this is to learn and use SQL (a micro-ORM like Dapper can help you get away from a lot of boilerplate cruft though, so do use one of those!). If you dont want to use SQL but really want to use a heavy-duty ORM that abstracts away all of that stuff then you should probably reconsider using a SQL database altogether. Go and have a look at all of the nosql options out there and see if you cant find something that fits your usecase better. Imho, every single time I have seen a good use case for entity framework - that same usecase has been much better filled by a nosql database option.
Why did this get downvoted? This is wise. Intellisense and msdn is mostly all one needs. Learn to use them asap. 
Notwithstanding what u/AngularBeginner has pointed out, if `Menu` here were a class, there'd be little-to-no practical difference. (I think there's a slight difference in execution order, but I don't remember the details well enough to say.) In practice, I usually initialize instance fields that don't require information from the constructor the second way.
https://msdn.microsoft.com/en-us/library/jj200620.aspx
&gt; I think there's a slight difference in execution order, but I don't remember the details well enough to say. The base class constructor is called before any code in the constructor, but after the field initializations. Since field initializers can only call static methods you'd need a rather convoluted setup to run into this difference, though.
&gt; I don't really like using ORMs. I'm old and prefer to do things the old fashioned way. &gt; However, ORMs do have their place. It's a case of 'the right tool for the right job'. I'd argue that today -- ORM vs raw SQL is almost not even a 'right tool for the job' but more 'whatever floats your boat'. ORMs do have some overhead -- but unless you are working with VERY complex objects and models (which 90% of the people building CRUD LOB apps are not) the development speed increase is worth the (smaller than it used to be) performance hit. I used to much prefer the older traditional ADO methods and even just hand adding parameters and stuff. After a while though; it is tedious and I don't feel like writing the same old boiler plate stuff over and over again for each object / model / query. Unless you have a magic solution you aren't sharing with the class :)
Can you provide some reasons or examples why SQL and LINQ are bad? "NOSQL" has its place... but I highly doubt it is better than EF for ALL domains. The choice to use a RDMS vs a document style database has less to do with wanting an ORM and more to do with data itself. Abstraction doesn't make NOSQL better by default.
If the order's not important, though, they could use `ConcurrentBag&lt;T&gt;`.
Most "Americans" aren't "Native American" either :p
Bad thing about `IDisposable`: It does not work async. Sometimes you need to clean up resources which may take some little time, which is not possible using `IDisposable`.
Why?
dont do that. keep the units small it will make it easier for changes, deployments etc. Keep things in atomic, autonomous verticals that can then be scaled horizontally within if necessary. Not worth the hassle IMHO. 
I was trying to refactor from some of my entityframework repository and my older code did some occasinal checks/ensure file or some other resource. I could live without it so it's kinda YAGNI, but I feel safe querying reflection data.
I've found it pretty easy to have a generic Json method in my project and it easy parses and reads/writes files. IT's almost painless. All you have to do is interate over them. There is a lot you can do with Json Library but after my first method I never complicated it beyond that.
I like to optimize for as little typing as possible, using safe, automated micro-refactorings, as Llewellyn has done here. Because that kind of refactoring is safe, I can do it even if I don't have good test coverage, as is the case in legacy code. Because the refactorings are tiny, I can do one whenever I want, without interrupting my work. I have tried to learn how to do as much of this with ReSharper as possible, and here's a video of the same sequence as OP but with more R#. https://www.youtube.com/watch?v=t3lQeJh7r2w
The two most important shortcuts when learning R# are: - ALT-ENTER (quick fix) - CTRL-SHIFT-R (refactor this) Both will give a list of possible operations based on the current cursor position. 
I have taught myself a few code smells to watch out for, and a few simple refactorings that can be done for those smells. I can see those bad patterns in any code, without reading to understand. Once that initial cleanup is done, if I try to read to understand, I am reading much simpler code, so it's easier and more likely that my understanding will be correct. 
Then isn't the example given in the article problematic, as the Dispose method attempts to delete a directory?
That's what I meant by re-education :)
The main reason is that when you are working at the abstraction level that most abstraction-heavy ORMs are working at then you are not really working relational anymore. You have abstracted it all away into a semi-document-oriented version instead. SQL is not bad. SQL is an amazing tool. For relational data. If you are not actually using a relational model, then you are getting mapping problems and performance problems that you might be able to avoid by switching the representation to something that actually fits what you are trying to do. I'm not saying "nosql all the things", I'm saying "nosql the things that are not a good fit for relational databases". LINQ is not bad. LINQ is an amazing tool. But imho it works best for in memory stuff. Linq to sql translation is generally quite bad, and it prevents you from taking advantage of database features that does not have a mapping into linq. So instead of being able to properly take advantage of every feature that your database can offer you are stuck with the stuff that is available through the linq abstraction. And when you get strange and slow queries it's harder to pull in your local friendly DBA who is a SQL magician and get help from him/her with optimizing your query since your query is in linq - not sql. The choice of an RDMS vs a nosql database has nothing to do with wanting an ORM. And nosql is _not_ the solution to all your problems. Which is what I wrote in my previous post as well. What I did state however was that when you are using SQL and you find yourself in the situation where using an abstraction-heavy ORM like EF feels like the best solution to the problem then you are generally in the situation where your data are no longer a good fit for the relational model. And in that case you should instead of trying to push data that isnt a good fit into an RDMS scout the alternatives and see if there is something that fits your usecase better. On the other hand if your data fits good for the relational model, then you most likely want the power and flexibility to use all the features that a good RDMS gives you. And in this case an abstraction-heavy ORM using LINQ will in most cases just be in your way, so then use Dapper or a similiar ORM that allows you to write your own queries and actually take full advantage of the RDMS that you most likely have paid a lot of money for. NoSql has its place, it's not better than Sql for all domains. Sql has its place, it's not better than NoSql for all domains. Even EF has its place, it's great for making throwaway prototypes. Given that they are actually thrown away. :)
Oh, I see. I figured that if the answer to the division was a double it wouldn't have a problem with it. Interesting, I was tempted on simply writing 1.333 but thought it was a bit lazy. Thanks for the answer.
right - so far, my understanding is that if your domain comprises graphs stored in a handful of tables with a thousand or so rows a piece, and a document database is not a better solution, you can get away with using a heavyweight ORM, and probably not otherwise, because: * if you have a lot of data, you need to design the queries and the indexes simultaneously in order to get decent performance, in which case adding ORM configuration is an extra step to work you've already essentially finished * if your domain doesn't typically involve object graphs, micro-ORMs solve the problem trivially, without the overhead of introducing a third tool but as you said, there's no good reason to limit yourself to one approach to different kinds of persistence problems.
I think that there are two things that make people write articles like these. 1. Someone got the idea that they may use an ORM without knowing SQL 2. People want to ORM everything. You are still allowed to use SQL with the ORM and you are even allowed to use ADO.NET or a micro orm aide by side.
They definitely can. I just tried to explain from the bottom up because there seem to be a lot of learners on this sub, so I didn't want to make any assumptions.
If it's just based on long running queries he could set them to end much earlier either globally or iirc based on connection as well. No reason to reinvent the wheel with a query tracking table and job to kill long running queries
Ravendb. Looks cool as shit. I have been wanting to test it
- Client requests token from whatever server is granting them - Client makes request to resource server, providing the token granted by the auth server usually in a cookie or in the authorization header - Resource server looks for the token wherever it's supposed to be then validates it. The validation procedure depends on how it was supposed to be set up. For example, some systems just verify the signature and if it passes, they call it good and trust all of the claims in the token. The auth server implements how to authenticate the user and how to build their claims (if claims are implemented at all). This is the most involved part. The client has to implement the access flow which is basically managing where it gets the token and how it presents it to the resource server. The resource server has to know when to check for the token (whether or not the endpoint is protected), where to get the token, how to parse it, how to validate it, and of course what to do with it -- which is usually to build a principal. I'm actually really unclear as to the actual question being asked here, that's just me throwing noodles at the wall.
Yeah I use ctrl shift r frequently for refactoring methods.
&gt; seasonEpisodeString = string.Format("S{0}E{1}", season, episode) Thanks, but I need to make season and episode 0 padded to the right, so it is S09 and not S1.
Agree. Look at the execution plan, and pay attention to/fix anything that isn't using a key or index. 
[removed]
The summary is at the top, namely the results per framework. Then below that is the raw data from which the results were calculated. Regarding support: most ORMs which aren't dead have support too, either through the vendor or through the team who wrote it. It's not as if these tools are brand new as well: most of them are highly mature and have most bugs fixed. As a lot of ORMs support Linq, it's not that hard to get started with a random ORM which supports it. There are always details to go over of course, but that's true for any framework used, be it a 3rd party grid control or a given dependency injection framework ;)
Go to the Resharper-Options - Environment - Intellisense - General and switch the "Use Intelligence"-Option to "Visual Studio". Restart VS, check if it works now. Then try to re-select the "Resharper"-Intellisense Option, restart VS and it most case this solves the problem.
&gt; How does exception handling factor into this, since in this example the Disposable pattern is used with exogenous resources? Is it ok to throw an exception from the Dispose method? Should the whole using block be enclosed in a try/catch block? Thanks for pointing it out. In real life, I prevent any exceptions to occur in the `Dispose` method. I probably should prevent running the Dispose code (deleting the folder), in case of any error during folder creation.
What do you mean? My code does exactly the same thing as yours. 
Cool idea. I will check its progress. Please provide a nuget too.
I foolishly omitted the parameters because i thought they weren't important. I am a little confused though as of to why you cannot initialize a variable the normal way in structs and also why constructors require parameters to be used with structs.
Looks good - just a FYI, there are a few similar plugins in the [Fody](https://github.com/Fody/Fody) plugin that may do the same - I need to open source my implementation for NLog on the [Tracer](https://github.com/csnemes/tracer) Fody plugin.
I'm not the author but I guess he isn't a native English speaker.
Long running queries shouldn't be a thing. Fix the query (likely will need an index or two, or query modification to use existing indexes). You could also potentially look at breaking it up into multiple smaller queries. If neither of the above helps, you could be dealing with excess load on your database server (other unrelated queries eating up memory or IO or CPU time and thereby making your query slower). Locking is a feature of modern databases, but can be slow and can (sometimes) hurt more than it helps. Turning locking off can help. Understand though, that locking is what keeps things "transactional". Telling the DB to not observe locks means you have to validate your own data. This usually works out OK when the consumer of the dataset is a human being rather than an automated process. If you're using MSSQL, using the "WITH (NOLOCK)" table query hint can work to make a slow query fast if you don't mind possibly displaying partial results once in a while. Parallelism is also a feature of modern databases that can sometimes hurt more than it helps (like locking). If you're using MSSQL, using the "OPTION MAXDOP 1" hint can work to make a parallel query faster (in some cases only) by disabling query parallelism for the current query.
&gt; Math.PI Though as tweq said, use Math.PI, it has a higher precision than your 5 decimal constant.
I intentionally didn't mention WITH (NOLOCK) as that gets used as a query band-aid a lot of the time because it's so easy. And like you said, it will affect what rows you get back, which is it's own problem. "Fixing my query is hard. But adding nolock is easy, so I did that." OP, use nolock only after looking at and correcting everything else that got mentioned in this thread. 
Implicit conversions never lose data. This is integer division, though, as others have explained :)
I would check then. Thanks.
I do a similar entry points marking with [ApprovalUtilities/SimpleLogger](https://github.com/approvals/ApprovalTests.Net/blob/master/ApprovalUtilities.Tests/LoggerTest.cs) I find the "using" to be easier to do and handles multiple returns better. using (Logger.MarkEntryPoints()) { ... } Also Found it very usefull to add extension method public static T Log&lt;T&gt;(this T t, string label, Func&lt;T, string&gt; log) This means you can log without creating a temp variable. for example return a.b.c.Log("c", c=&gt; c.Name).d.e; 
... Or, fully understand the implications of using WITH (NOLOCK) and use it appropriately. You are correct however, it is possible it may display partially committed data and therefore is transactionally inconsistent, which, if used incorrectly, could lead to problems.
Well that's why I recommend abstracting that away! Do they use graphing paper in school eg to draw triangles? Would be best to spin variants of what they've used.
Looks like Mono 3.4.0 is the earliest version where that ctor got added so if you can at least bump up to that version, it should work. https://github.com/mono/mono/commit/e511e29095e9e7df5e11b8a23d5fa8c9703749bd
Also any improvements you can suggest, please do! I'm still really new to C# and classes, so take lightly.
 ammo -= 3; Console.WriteLine(ammo); Wrap this in a for loop that counts down one at a time, three times.
Wow, thanks. I'm going to need to use this more often, since I have always used || to check all the cases, which could be impossible with larger words.
 for (int i = 0; i &lt; 3; i++) { ammo--; Console.WriteLine(ammo); }
Thanks. How are you finding the course so far?
&gt; for (int i = 1; i &lt; 3; i++) It works, although it only decreases by 2, instead of 3. So what I changed is: for (int i = 1; i &lt; 4; i++) Which then decreases it by three. Thanks! 
7/10. It's good but perhaps does not go as in depth as i had wished in some places, it's really helped me with some concepts though so far.
I'll take a look at the simplelogger project. thanks
Ah, come on. I thought it was funny..
it's not web. Okay so I just make a custom control that is basically a datagrid then I can load it into the frame. What would be the syntax of getting the controls data from the frame? Thanks for the help I'll look into it instead of pages cause there doesn't seem to be any help and I don't really understand MVVM yet.
The built in classes are the best. NodaTime is a port of JodaTime which addressed many problems with the Java Date/Time library, but those are problems .NET never had. It was only ported over by people who wanted the familiarity of the JodaTime classes. If you want a point in time, you are looking for `DateTimeOffset`. If you are looking to activate something at a specific point in time instead of activating it X seconds from now, use task scheduler/chron jobs instead of an in-process timer. In your example code, you are complaining about the time it takes to execute the statement, but you are measuring in seconds. The absolute worst-case delay you will see in terms of the delay from the ideal time is ~35 milliseconds, and that will only happen if you hit a context switch. Otherwise, you are talking about the difference of CPU ticks. Neither delay matters when you are measuring in seconds. Don't forget, neither Linux nor Windows are real-time operating systems, so anything using a timer needs to be comfortable with delays. My typical approach to unit testing a timer-based setup is to have the test signal a `SemaphoreSlim`. Here is the outline of what that would look like: public async Task TestMethod() { using(var semaphore = new SemaphoreSlim(0)) { var timerclass = new UnitUnderTestTimerClass(); timerClass.ProcessIn(TimeSpan.FromMilliseconds(50), () =&gt; semaphore.Release()); Assert.IsTrue(await semaphore.WaitAsync(TimeSpan.FromMilliseconds(150)), "Timeout!"); } }
I would correct spelling mistakes on your readme file, it is your project presentation after all and IMHO it should be as clear as possible because it is what many people will read first
This isn't such a bad idea. There is a tool called NsDepCop you can use https://nsdepcop.codeplex.com/
Post this to /r/roguelikedev
How did you calculate the ~35milliseconds? I'm not doubting it but rather curious to find out something new. 
stabil -&gt; stable
Environment.Exit only needs to be called once. If you don't need to do anything specific for a form when it closes, just call that. Alternatively, once all your forms are closed the application will quit automatically as the main thread finishes executing.
Sounds like you have a resource open.
It's the maximum length of a CPU quantum in Windows. 
And I don't find any of those arguments strong enough to reject the built-in classes. The proper technique is to use UTC and convert to local time as necessary. This removes all of the objections in that blog post.
If there is other fire modes, you might look at enums.
example being memory management, you could do it in C# but it normally is seen as unsafe. https://msdn.microsoft.com/en-us/library/aa288474(v=vs.71).aspx
This was a cool little mini-course. A good simple refresher on the basics of ASP.NET MVC. Thank you for sharing!
Then you are looking for `DateTime`. That records the timezone too, but serialization onto the wire or into a database can be a huge pain. Nothing server-side or in storage should deal with anything except UTC. The typical usage usage is to record `DateTimeOffset` in UTC and the use the `TimeZoneInfo` utility methods to convert to the user's local (or chosen) time. In a desktop environment, you can use `TimeZoneInfo.Local`. In a web environment, the client needs to tell you the preferred timezone, either automagically with Javascript or via a drop-down. I will firmly stand with my assertion that 99% of the time, the built-in classes are sufficient for the job, and I would only bring in another dependency if you absolutely cannot represent your operation with the built-in classes. With the System classes, you also get the bonus that almost every other class library in existence uses the built in ones while most Java libraries use Joda (or the new ones specified as part of JSR 310). Using Noda would require you to convert back and forth with the System classes all the time if the timestamp ever needs to cross a DLL boundary.
Had to double check and you are correct. Goes to show how little I use that one compared to DateTimeOffset. If you really need the time zone, record it. It's crazy simple to create a struct that contains a DateTimeOffset and a TimeZoneInfo. I don't need an external library for a niche case that can be solved by a struct definition.
Yeah that's what I ended up doing, thanks.
&gt; for (int i = 0; i &lt;= 3; i++) That loops 4 times, where i is 0, 1, 2 and 3. You meant: for (int i = 0; i &lt; 3; i++) 
Some hopefully constructive criticism; &gt; double ammo = 30; &gt; double mags = 3; Those should be: int ammo = 30; int mags = 3; Since those values will only ever be whole numbers. Unless you plan on having 10.3 rounds in 3.7 mags... &gt; Console.WriteLine("\nFire Away! Press Space to Insert&lt;0&gt;"); &gt; while (Console.ReadKey().Key == ConsoleKey.Insert) I don't understand the message, "Press Space to Insert&lt;0&gt;" - you're telling the user to press Space, but you're then waiting for the Insert key... &gt; if (SafeMode == true) When checking the value of a boolean, it's more readable (IMO) to do comparisons like this: if ( SafeMode ) // instead of if ( SafeMode == true ) if ( ! SafeMode ) // instead of if ( SafeMode == false ) Also, I notice you're only setting your `hits2` variable once, before you main loop, so it will always have the same value. Consider moving the line where you set its value to inside your `while` loop. `hits2` is a poor name for a variable, by the way (they do say that naming is one of the hardest things in computer science!). Personally I'd have called your `Random` variable something other than `hits` (because it's just generating random numbers), perhaps `rand`, then called the int variable `hits` instead of `hits2`, since it is counting the number of hits. If you ever find yourself choosing a variable name but tagging a number on the end because it clashes with another variable name, this is a [code smell](https://en.wikipedia.org/wiki/Code_smell), and you should re-consider your variable names. Don't underestimate the value of naming things correctly/well - variable &amp; method names (along with comments!) form an important part of your code's documentation, and future-you will thank current-you if your code is easy to understand and well commented. 
Right, it's not a big deal. I suppose the external library will save you a lot of boiler plate such as serialization, formatting etc. etc. that you'd have to write yourself as-needed. It's always a trade-off :)
Quartz is really good for scheduling jobs, you can test it by just writing a service / console app and make it send an email to yourself whenever your jobs are set to execute. I also find Itenso is a really good time library. https://www.nuget.org/packages/TimePeriodLibrary.NET/ http://www.codeproject.com/Articles/168662/Time-Period-Library-for-NET I use it to find gaps within a time line where I can schedule delivery jobs using the TimeGapCalculator. 
C# will be 10x easier to use. A bit more verbose with classes etc, but no need to worry about pointers, free or memcpy.
Thanks dude. Really appreciate the reply. I had started learning C assuming that C# is almost same. One of my brother suggested that C# is not for beginners and I should learn that after learning the basics of C.
Learning C is good for you. I think everybody should learn C because it teaches you the basics of how the machines you use all the time work in the end. It is a simple language because computers are simple but that doesn't mean it is easy to use because the things we build nowadays require a different degree of abstraction most of the time. It is incredibly valuable to see this.
&gt; Structs are on the stack not heap Not necessarily, it could easily end up on the heap, if not in your specific example. 
Yeah. You could perhaps get around this by passing in an Action&lt;Exception&gt; as a parameter to the constructor, so that if an exception occurs whilst disposing, the Action is called with the exception that occurred so that it may be handled. It's a bit dirty, but would work 
I tried many times to learn programming and I always failed - until I discovered c#! Somehow c# resonates well with my mind and learning it is a breeze and there is so much fun stuff (Web Apps, GUI Apps, Games/Unity3D) you can do with it :) So yeah, go with it!
I really like Code School's mix of videos, coding and creativity. Great work!
C# is a pretty clean, nice language. It also has a world-class FREE ide: Visual Studio community 2015. That's a microsoft product, very stable and useful. C# can also grow with you - it's a very powerful language.
The only problem with starting out with C# is that you'll get spoiled by a bunch of its features and by Visual Studio. Other languages and their environments are not as smooth. Doing PHP in Eclipse feels like a punishment by comparison.
Your game loop is inside the Engine constructor, therefore you have a constructor that never ends, this is clearly a misuse of the constructor. I would suggest to remove the loop code from the constructor and place it in a separate public method to be called by the Program.Main method. That Thread.Sleep(int.MaxValue - 2) is a bit odd to me, can you explain why you need it ? Also I'm having troubles reading what the Engine.Initinput method does, at first glance it looks like it creates a new Task forever to do some work depending on the key pressed. Basically (altough a bit incorrect, but I want to make a point) you are spawning new threads forever, which is a big performance hit and also it is not needed. If you need that parallel Task because the method Console.Readkey blocks the execution then use the property Console.KeyAvailable to evaluate when a key is pressed, when KeyAvailable is true ReadKey will not block. Remember that in a game almost everything happens synchronously so you almost never need threads to update your world, just update one thing after another sequentially. This is what caught my attention the most by looking at the Program.cs and Engine.cs files Keep improving and have fun !
Thanks for the replies, I'll keep at it then! :)
Thanks for the feedback :) But I'd prefer it was in form of issues on git... First: I think that my first plan was that constructor will end and then I needed the way of stopping the process from closing - Thread.Sleep(large number) Second: the InitInput does exactly that. It reads the key. Translates that key to the command. Translates that command to action and executes that action. I think the task is then over and is disposed. I think that's how tasks work, correct me if I'm wrong - actions are defined in the Screen.Screen class. Third: I don't really know how the games work, I'm just making it up as I go :) Once again thank you for the feedback and I hope you help out :) Branimir
A good sir on the git @tidusjar correct a lot of typos in readme file and I've corrected a lot of them in code, so it's better now Thanks for the feedback :)
Ayyy another VB6 to VB.net to C# developer!
Posted! Thanks for the feedback :)
C# is a good second language. For someone with literally zero experience, I would recommend VB, Lua, or Python.
Similar here, Started with VB3 then 5 and 6. Started VB.NET when the first beta versions came on, little while later I picked up a C# book and one week later I never looked back at VB.NET. 
I would say that C# is one of the best languages to start with. It's pretty clean, has a really nice free IDE to it(Visual Studio) and you will get the concept of programming easier with C# without having to worry about stuff that you don't need to worry(atleast for the beginning). However, when you start getting deeper C# can abstract you from certain things. (I wouldn't say that's a bad thing, but I would like to know what's going on behind the scene, if you are not interesting in what's happening behind the scene - even better)
You should start admitting it. Embrace your learning history! At the end of the day, what really matters is that we **did** get to CSharp eventually, no?
Please note that I am currently learning this language. Well, I have seen many people recommend this as first language so I decided to use it as my first. I only have like 4 weeks with it right now so I am pretty new. But well, I have had lots of fun so far and yeh, I guess that makes it good for me to learn atleast " I seem to remember most things easily cuz I love learning this beatiful language :D " Try it. If you dislike learning it then :/
This. So much this. I learned C# with he visual studio IDE as my first language and I thought every IDE would be as nice as visual studio from the on out. I have never felt so wrong.
Not sure HTML or CSS would help. They aren't really programming languages, they are markup languages like LaTex. Basically just used for making documents instead of programs. I'd say python is a good starting language. But I had no trouble learning c# as my first and I think it's much more useful.
I learned the bulk of my coding through CS degree in school. A lot of schools start with either C or Java. My school went the Java route. Java is far easier to understand initially (no pointers, etc) than C and I believe C# is far easier than java. If java is good for all the newbies at CS departments, the C# is also good for newbies! C# is very similar to java in "feel" but, in my humble opinion, is less verbose, cleaner, yet surprisingly sophisticated. Like some of the other commenters have mentioned, if you're on windows, the tooling for C# is incredible. As a beginner, that may actually be a downside, as there is a learning curve and they may distract you. But, the honest truth is, there are many languages that are a good starting point, and once you know the basics, switching to other languages becomes a lot easier. 
https://www.youtube.com/watch?v=zXqs6X0lzKI Explains a lot of the different paths and languages a developer can take.
We are legion!
LINQ (Language INtegrated Query) lets you do queries, kind of like SQL. Like this for example (example from MSDN): var numQuery = from num in numbers where (num % 2) == 0 select num; 
While it's probably true that C# may spoil you, it's a great way to teach object orientation and modern stuff such as lambda expressions without the ~~pain and suffering~~ problems with java. While javascript is another great language, creating things like menus and displays will take much longer and require you to also learn CSS positioning *(shrudder)* and HTML. I don't know python myself, so I can't really speak for it, but it may be a good language, too; you'll have to see for yourself.
There's two flavors of LINQ. Query syntax (looks like SQL) and Method syntax (methods with lambda expressions). // Method var names = collection.Where(item =&gt; item.Name == "Fred") .OrderBy(item =&gt; item.Age) .Select(item =&gt; item.Name); // Query var names = from item in collection where item.Name == "Fred" order by item.Age select item.Name; You can use either, but it seems like the method syntax is more popular and rots your brains less.
Do you have examples of these caveats? On the top of my head I can remember: *) usage of e.g. Count() &gt; 0 where .Any() would be more performant and in my opinion clearer. Similar extension methods can be made for .AtLeast(k), .AtMost(k) and .Exactly(k). *) OrderBy().First() instead of e.g. MoreLinq's TopBy(). Does not applies to IQueryable, as the method is eager and loads all the data in to memory. You don't want that for a 100gb table into memory. *) list = list.orderBy(e =&gt; e).Tolist(), where list.Sort() *might* be faster. 
More of a noteworthy FYI on why you'd entertain the uglier option. Depending on your implementation, the latter will be faster/more efficient if it is ran against an IQueryable surface vs IEnumerable. IQueryable will send your parameters down to the SQL back end and filter out the results "closer to the metal". While IEnumerable will bring back all results from the back end and will apply the filters and sorts server side. Unnecessary on smaller look ups but when managing larger data sets, it can really optimize things. 
Have you got a source for that? I was under the impression that the two syntaxes are homomorphic. As far as I've seen, the method syntax produces the same SQL as the query syntax. Although that might just be an entity framework thing as opposed to linq to SQL.
A lot of folks have mentioned the terseness and readability of the statements (both of which I agree with) but it's also worth noting that it steers more towards a functional (non-side effect) approach to querying / selecting / filtering things. So, you're more often saying "I want these, when this is true, in this order" rather than "go look at these things in turn, performing this operation on them, and potentially adding them to a list". You're less likely to introduce bugs relating to continue/break clauses, less likely to introduce bugs due to mutating state during a loop, that sort of thing. 
[Deferred execution](https://blogs.msdn.microsoft.com/charlie/2007/12/10/linq-and-deferred-execution/) is the archetypal easily-avoidable gotcha, in my experience.
More of a random link on the subject but his facts are straight: http://www.c-sharpcorner.com/UploadFile/a20beb/ienumerable-vs-iqueryable-in-linq/ I personally thought the same thing and had to watch queries rolling in on SQL Profiler to believe it myself a number of years ago. 
thank you for pointing the mistake
&gt; If you're sadistic and want to inflict suffering on other developers, then you should concentrate on Perl. *and masochistic*. Other devs won't be the only ones suffering.
In case anyone is interested, here is a public repository of extension methods that you can copy or contribute your own - http://extensionmethod.net/ 
You're conflating two things. Both Method and Query syntax can be used against an IQueryable&lt;T&gt; or an IEnumerable&lt;T&gt;. In the example above, if collection is the same object then both the Method-based and Query-based would behave the same.
Why you'd want to use it - It is a good way of building data transforms, one of the key things I find because it allows you to use several small intermediate steps without the "clutter" of several loops it usually becomes simpler to follow what is happening. After a while you realise a lot of the code you write is to transform data - so you end up using Linq a lot. I found Resharper invaluable to teaching me Linq as it would keep offering to replace loops with Linq equivalents 
My personal preference is to use the real type names for static member accesses. I think Resharper has an option for this practice as well.
I would lower case string but not Char in the above. 
Maybe, but you don't want to waste time performing an incorrect operation. 
Yep, you're correct. I just double checked some core repo code and that is definitely the case. 
Once you go linq you'll never go back.
A note on usage: Extension methods on classes shouldn't be in the same library as the class itself. This makes it harder to use the class and is unnecessary as you can directly modify the class. Extension methods on interfaces can of course be in the same library as the class itself.
Exactly. Programming is (I find) one of the subjects where learning the abstraction *first* is better and easier to get into.
OP here. Thank you for all of the information and great answers. LINQ seems very useful and a time-saver. 
This one gave me a chuckle, http://extensionmethod.net/csharp/int/israndom
I very much agree with this.
&gt; I am trying to save as much computing time as possible I guarantee you, you aren't. Personally I would use the int variant. It reads nicer.
I fucking hate gifs.
Another subjective opinion: The function name is `GetNumberCount()` but it calls `char.IsDigit()` instead of `char.IsNumber()` internally. Plus, both will return true for Unicode characters that are not in the ASCII 30-39 range, but that's a separate issue.
Until you work on a performance critical project. I miss linq. :(
Op here. So what's the difference between ienumerable vs iqueryable? I keep seeing these mentioned in this thread. Thanks. 
How is LINQ not performant? I can see it being a problem in LINQ to SQL where it's evaluating more than it should be or being used in place of better SQL options but for set operations I've found it as good if not better for compiled code running in a cross platform runtime. edit: This is for .NET running on a server in the 3.5+ runtime. I've never written in Unity for XBox. I did find the following in my subsequent research. http://jacksondunstan.com/articles/2994 This is performing the same operation (find a unique element in a set of 1024 elements) 10,000 times. LINQ took 584 ms total. Array took 49ms which is 10x slower but that's the highly optimized and idealized version of the operation (which may or may not be possible). TLDR: Profile your code before arbitrarily removing all traces of LINQ because it's "slow."
General-purpose code is almost always less performant than custom code. If you have a string or list manipulation task and you know the exact constraints on the list, it's almost always faster to write a loop that processes that string/list than to use LINQ or some other tool. What you gain with LINQ is ease of programming and shorter, more maintainable code. The cost for that convenience can sometimes be performance. In the vast majority of cases that's a no-brainer trade-off, but if performance is the #1 criteria then it's not a trade-off you can make.
Uninstallation of VS does not work. Your only option is to install again and hope that fixes your issue.
I typically use the extension methods for every day use. The query syntax, I reserve mostly for joins, aggregates and anonymous class returns because it's easier to read and understand.
Get pixel and stpixel are slow as fuck. Get raw buffer and work on that.
&gt; .Select(x =&gt; x &gt; 5) gives you the members greater than 5 I think you want the "Where" method there.
Could you explain a little more about what raw buffer is?
If you've not been working with asyc code previously, I feel like deferred execution is going to be one of the first things that hits you as you're learning LINQ.
Why would you be doing LINQ in a loop?
What languages do you know? Most of the ones I'm familiar with have some similar functions (like map in JS/Ruby is equivalent to Select in Linq, steams in Java have similar functionality, etc.)
It's definitely slower. For 90%+ of projects it doesn't matter, though.
Python, Obj-C, PHP, JS, SQL, bash, powershell. 
To be fair, you could do something nicer without Linq too: public IEnumerable&lt;int&gt; FindEvens(IEnumerable&lt;int&gt; input) { foreach(var item in input) { if (item % 2 == 0) { yield return item; } } }
No it's not. Linq methods are all lazily executed which means you might not see an exception where you'd normally expect to.
Great. So in JS you have array methods that let you do this kind of stuff, right? [1,2,3,4,5,6,7,8,9,10,].filter(function(x) { return x % 2 === 0; }) [2, 4, 6, 8, 10] You could do the same thing with C# and Linq like this: new {} [1,2,3,4,5,6,7,8,9,10,].Where(i =&gt; i % 2 == 0); Unlike the JS array functions, those, Linq statements are lazily executed. It's like lodash/underscore, if you've ever used those.
UI frameworks, games, graphics, audio, input, networking, computer vision... Many things have a performance critical processing loop.
Yup. I avoided using it until learning how the various lambda forms were expressed and composed. Now, a year or so later, I'm a functional master 😀 ... OK, getting that way, at least. About 50 percent of my code is written in a functional style now - Action and Func everywhere, lazy evaluation, custom iterators, currying, etc. Thanks, ReSharper! I never thought I'd actually like using functional constructs before LINQ, and being shown how to use it effectively by ReSharper. Basically, it showed me how to reformulate how I thought about a problem - and it's very good at this, because it literally rewrites your code into the functional form, so you can see the before vs. after.
Ha, I used to be terrified of selectmany. But it's sooo useful. After discovering that, it encouraged me to look into other monadic operations, without the trepidation I had previously. 
Yeah. Although select would work if, for some reason you wanted a sequence of boolean evaluation results corresponding to the source sequence. Could be useful for setting a flag of some kind, though this would be unusual. Where, Any, All, FirstOrDefault, or LastOrDefault would be more usual for this use. 
It's very likely that Photoshop uses GPU acceleration for a lot of the image processing algorithms.
It's a valuable tool. It's as if someone added database queries to your language - you can use words like where, order, select etc. Seeing as so much coding is dealing with sets of data it's very handy. However I've used linq with largish sets (tens of millions of items) and it's definitely faster and generates less garbage if you just code it yourself using for loops and if's. So if it's performance critical (for example part of a game engine) code it yourself; otherwise use Linq. 
Did you check the tutorials and documentation on the NuGet homepage? Or the numerous tutorials available on the world wide web? &gt; I need to generalize it so that it would work with any solution at my company. It's a simple namespace change - if the Alive page is in Service1.sln, the namespace must be Service1.Web. This will not work. It contains a assembly, the namespace is fixed upon compilation. Besides that: Why is that necessary? You can just import the namespace and be done - no need to have it the same.
Query comprehension syntax is also good for cartesian products. Very easy to understand vs SelectMany. 
They're similar. IEnumerable represents a collection whose elements are lazily evaluated. IQueryable represents a collection that is lazily evaluated. So infinite lists are possible via IEnumerable because each element is evaluated when used. IQueryable runs the query for the whole collection when an element is accessed. 
Bad developer. Don't paraphrase the quote; the rest of it is important.
&gt; It's crazy simple to create a struct that contains a DateTimeOffset and a TimeZoneInfo. That's like saying it is crazy to create a struct that contains a DateTime and an Offset and that we should instead always pass around two variables.
https://docs.nuget.org/create/creating-and-publishing-a-package
Hey now, don't prematurely optimize your code. Is there any reason why you can't go with linq, run a profiler, then rewrite the bits where it's simply not fast enough?
The best use for query comprehension syntax IMO is when you've got `let` clauses.
Or at least SIMD instructions.
Unnecessary allocation is a deal breaker for many projects. LINQ allocates a lot.
Is an. If (val == null) return; really a time waster?
Thank you i will give that a go!
Okay i'll have a look i've got this code which i've converted from vb: string line = null; StreamReader Input = default(StreamReader); string PolicyIdCode = null; ArrayList strFile = new ArrayList(); PolicyIdCode = txtboxWifiKey.Text; Input = File.OpenText(Dir); //Loops through the file while (Input.Peek != -1) { // Read the next available line line = Input.ReadLine; // Check to see if the line contains what you're looking for. // If not, add it to an ArrayList if (!line.Contains(PolicyIdCode)) { // If not, add it to an ArrayList strFile.Add(line); } Input.Close(); // Because we want to replace the content of the file, we first // need to delete it. if (File.Exists(Dir)) { File.Delete(Dir); } // Create a StreamWriter object with the same filename System.IO.StreamWriter objWriter = new System.IO.StreamWriter(Dir, false); // Iterate through the ArrayList foreach (string item in strFile) { // Write the current item in the ArrayList to the file. objWriter.WriteLine(item); } objWriter.Flush(); objWriter.Close(); } But i get an error at the while statement (while (Input.Peek != -1)) The error is: Operator '!=' cannot be applied to the operands of type 'method group' and 'int' 
and you can now build pretty much anything with C#. Android, iOS, Windows apps. Web sites and APIs that run on Windows, Linux and OSX. C# and .Net are even a better option than before.
tl;dr: Learn it but don't rely that it will always be there if you plan on taking your skills to a professional level. Specific answers: &gt; What is LINQ? LINQ is, to dumb it down some, a strongly typed method of accessing a collection of data. That collection can be List, a database, anything you can enumerate really. &gt; Why do you want to use it? Your code can be made to be clean and readable with it. LINQ also helps to prevent injections. If you don't know the little Bobby Tables joke, now would be a good time to laugh and learn. [Link here](https://xkcd.com/327/). There's *almost* no reason to not use LINQ when the LINQ option exists. You'll still want to learn SqlCommand and other things so you know how to use them if you plan on taking this to a professional skillset because legacy apps most certainly will not use LINQ. There are several LINQ to Action things out there, for instance LINQ to Amazon where you can query for books. There will be times you won't be able to use LINQ for obscure or new technologies, so don't plan on being able to rely it will always be there for you.
It's a serial buffer of bytes you manipulate. See my rotozoomer in C# source here for an example: https://github.com/FransBouma/CSRotoZoomer Or more specifically: https://github.com/FransBouma/CSRotoZoomer/blob/master/src/MainForm.cs#L126 and further. Your code is also not really efficient: read the full 32bit neighbor pixel in 1 go, and then blur the source image with the struct's values instead of reading R, G and B separately as that's 3 read operations which are slow, you can do that with 1. You read the value twice actually, very slow. So instead of: red += imageMap.GetPixel(h, v).R * imageMap.GetPixel(h, v).R; green += imageMap.GetPixel(h, v).G * imageMap.GetPixel(h, v).G; blue += imageMap.GetPixel(h, v).B * imageMap.GetPixel(h, v).G; do var pixel = imageMap.GetPixel(h, v); red += pixel.R * pixel.R; green += pixel.G * pixel.G; blue += pixel.B * pixel.B; 
It's a shame that there is no voting system on that site.
It used to be. LINQ statements are debuggable with Roslyn.
LINQ is a more terse, readable (generally) way to work with sets of data. Mostly it is used for filtering (`Where`, `Single`, `First`, etc) or conversions (`Select`, `SelectMany`, `ToDictionary`), and sometimes you get into more advanced pieces, like `Aggregate`, which collapses a set of things into a single one. Often these are combined fluently on top of each other: var activeEmails = users .Where(user =&gt; user.IsActive) .Select(user =&gt; user.Email) .Distinct() .OrderBy(email =&gt; email) .ToList(); Think about how much work that would be in a `for` loop. You have to create a list to hold the emails, loop through each user, do an `if` to check if they were active, another `if` to see if the email was already in the list, then another loop (or `List.Sort` if you're able) to determine the ordering. With LINQ it's 6 lines and very readable. Honestly LINQ is probably the best thing that Microsoft has made in years. Once you're comfortable with it you find yourself replacing loops in all sorts of places that you wouldn't expect.
In almost all cases this isn't going to be true. There is some overhead to the way LINQ uses to IQueryable and IEnumerable interface, but unless you already know a huge amount about your data set to an extent that's largely unrealistic. Even then you'd probably be better off implementing a LINQ extension or a comparator or a custom enumerable than hard coding a loop.
Except the entire point is that he doesn't. Until you measure your code you won't know where the real bottlenecks are and more importantly you won't know what you're improving on. Implementing custom code comes at a significant cost in terms of maintainability, reliability, and resources. If your custom code is only shaving off a couple ms it's either not worth using or you wrote it wrong. We've all had to work on some piece of shit dirty hack. If that hack is shaving off a tenth of a percent is it worth it? Probably not.
Well, that would work but what about a scenario where the directory was created successfully, files are created within the temporary directory, upon trying to dispose (delete) the directory there'a still a process accessing one of the files in the directory? That would still cause an exception, right?
Joins are indeed much easier to read in query syntax. Pro tip though for anyone querying against entity framework and not a normal collection. Assuming the proper relations exist you don't have to specify the joins. It's one of my favorite things about linq. 
Actually, in my personal case, assembly came before C. Admittedly it was 6510 assembler, but it had the appropriate impact. Nothing teaches how stupid a computer really is until you have to explain *everything* to it in fine detail.
I went for 68k assembly, using the Easy68k emulator. I made [Flappy Bird](http://serayen.com/less-extra-crappy-birds.png).
So I had a project I picked up because my lead dev was having issues. It required querying lots of data from a entity framework data context. The table had plenty of data, and we had a lot of filters to find the exact records we were looking for. He said the query was taking too long (he was enumerating over the results before applying each filter). Doing the filters in line would be really ugly. But doing it in linq and just adding on the filters worked out for me because of the lazy loading. Just build up the filters before enumerating
Are they ever. You can see the difference in speed in [this screenshot](http://i.imgur.com/OvFfPVX.png). The timings are accurate, as can be seen in [this screenshot](http://i.imgur.com/Y2z97xw.png) showing the console output.
The problem is that it's very easy to get taken in by whitespace implying structure incorrectly.
Part3 =7-(part1+part2)
In addition to what the others said, you should also take advantage of the (possible) [separability of your filter](https://en.wikipedia.org/wiki/Separable_filter). For example a Gaussian Blur filter is separable. It's faster to apply two 1D filters (horizontal and vertical) than a single 2D filter. EDIT: I've missed the point that you're using a box blur. It's easily separable! See the first example on the wikipedia link.
That's a good shout, thanks mate. I feel am bit silly but one of those things!
Part 3 could possibly be 7 - 2 (7/3), or 7 minus parts 1 and 2.
All the tutorials I've found including the one you linked to below seem to not do what I am looking for. They expect the entire project to become a nuget package (I only want a few files from my project to be in the nuget). I would move the files out of my larger project into their own project, but then they lose the assembly references that enable them to interact with my database and such. 
Yup, this issue caused the infamous iOS SSL bug
&gt;But then if I were to do the same to 11, it would end up 4,4,6 which is incorrect. why? 11/3 = 3 11/3 = 3 11/3 + 11%3 = 5 ...
You have a number of things going against you when comparing your speed to Photoshop: 1) Most of the photo editing apps out there are written in C++. It might not seem like a lot but C# vs C++ in terms of speed will almost always go in C++'s favor if the dev knows what they're doing. You can mitigate some of this by using unsafe code, pointers, etc. But all the nice features of C# like garbage collection, etc. will cause a slow down. 2) Many of those apps use the GPU to do the manipulation of the image. Using the GPU is an insane speed increase if you can use it for things like this. (look into [managedCUDA](https://github.com/kunzmi/managedCuda), [GpuLinq](https://github.com/nessos/GpuLinq/), etc.) 3) You are using GetPixel/SetPixel. These are very slow. Look into using pointers, LockBits/UnlockBits, as well as pointer arithmetic. 4) You're running on a single thread, multithread all the things. You can easily update an array safely as long as you're writing to a cell that isn't being read from. That means that as long as you have a copy of the image, you can read from the copy and write to output without issue. Also most algorithms dealing with images actually require pixel data from the unedited image. So this helps you so you don't propagate errors throughout the image. Other words of advice: Don't use Vector (SIMD "optimized" instructions) in C# and expect a speed increase. In C# SIMD is only supported in the RyuJIT compiler and in order to get access to them you need to use the Vector classes which are floating point based. However if your data is not inherently floating point based, which images aren't, you have to convert from an array of bytes to an array of doubles or floats and then back again (yay memory bloat). On top of that RyuJIT requires you to compile to 64bit. It is not available in 32bit or "Any CPU" mode. That may not be an issue for you though. But if you do need to run in 32bit or "Any CPU" you will actually see a speed decrease instead of an increase.
C# should evaluate 11/3 as 3. That is, int i = 11; int j = 3; var k = i / j; // 3 If my (dim) memories of my computer architecture class are both accurate and relevant, it probably isn't rounding. Integer division probably dumps the quotient and the remainder in separate registers, so that `/` and `%` probably perform the same operation, and then return from different locations. So, for 11 and 3, that ought to produce 3, 3, and 5. Which seems correct to me. ETA: a quick implementation with ints: IEnumerable&lt;int&gt; f(int n, int parts) { for (var i = 0; i &lt; parts - 1; i++) { yield return n / parts; } yield return (n / parts) + (n % parts); } EETA: because I'm bored: IEnumerable&lt;int&gt; g(int n, int parts) =&gt; Enumerable.Repeat(m / parts, parts).Select((x, i) =&gt; x + (i == parts - 1 ? m % parts : 0));
ATM machine
11/3 = 3.66666, which an int would show as 4
There is a way to ship simple source files via NuGet, but that is really not suggested. It would be just a simple copy-paste of the source file. NuGet packages operate on **assemblies**, and the whole project will create an assembly. If you really just want to ship parts as NuGet packages, then you should (as you attempted) move them into their own projects. And yes, you need to manage your dependencies (the references) accordingly. Perhaps it would be better to first learn about project management itself, before trying to go into package management. An understanding of project and assembly references is required to facilitate package management correctly.
It... really didn't.
I agree, it's just a time-sensitive thing. Thank you for the help though, that did clarify some things that I've been reading. Also, you can generalize the namespace with the `$RootNamespace$` project property. The MS documentation didn't elucidate how it works, but I did find some code examples and tested that it works. Edit: the $RootNamespace$ property doesn't actually fetch the solution name, but the fully qualified namespace where the generated class lives. 
No, when using integer math (or casting to an integer), it truncates the decimal portion. 3.66666 as an `int` would be 3. EDIT: To be clear, the algorithm/code you have already works _if_ you treat your numbers (both the numerator and divisor) as integers.
&gt; It's one of my favorite things about linq. Nitpick: That's an EF feature, not inherit to LINQ itself.
Just an FYI, you'll want to make sure the expression used in your `Math.Floor` is using floating point division not integer division (as you posted) otherwise it won't make a difference. As posted, it's essentially `Math.Floor(2)` and not doing any work whatsoever. Also, be careful when using `Math.Floor` in cases like this if you might have negative numbers. Reason being that `Floor` will round to the _lower_ number; so 2.3333 becomes 2, but -2.3333 becomes -3. If the intent is to trim the decimal portion, either cast to an `int` or use `Math.Truncate`.
Yup - and as a downstream effect, the majority of the time that code's going to be more readable, modifiable, and less prone to mistakes.
Do we really need to hear an admonition to profile every time someone talks about performance optimizations? Yes, it's of course true that you should measure and not just blindly optimize code outside the critical path. But it's not at all implausible to me that using Linq could be a bottleneck with huge sets of data.
If you implement `ExceptMultiplesOf()` as an extension method, then you can write: var matching = someNumbers.ExceptMultiplesOf(2).ExceptMultiplesOf(3);
I can't believe no one else has said this: Profile your code and see where your code is taking up a lot of time. Make that faster. Repeat. Trying to figure out by inspection may sometimes work in tiny codebases where there are glaring issues (e.g. GetPixel), but you need to know in advance what the costs of every single one of your operations is. That's not a realistic assumption and it doesn't scale. Make sure you are using release builds for performance tuning with no debugger attached. 
you could, but i wouldn't, unless this method is so essential/common to your domain that it's worth polluting the global namespace, or having to manage your namespace imports in order to avoid that.
No and you are entering into a world of pain unless you know what you are doing. Is there any reason you need to reinvent the distributed job scheduler wheel?
`IEnumerable&lt;T&gt;` is already "polluted" by 48 different methods just from `Enumerable`. I don't see how adding one more would be a bad thing. Coincidentally, I used LINQ and an extension method on `MethodInfo` to count them: typeof(Enumerable) .GetMethods() .Where(m =&gt; m.GetCustomAttribute&lt;ExtensionAttribute&gt;() != null) .Select(m =&gt; m.Name) .Distinct()
Every day people on reddit insist performance rarely matters. Every day I use software that is ridiculously slow. 
Thanks for the suggestion. The thing is all the model code is already written in C#. So it might be better to just keep everything in there. I'll check out some of the things you suggested, because it never hurts to look. Right now all the tasks are placed into the database, and each instance of the platform keeps looking for tasks. I'll look into how message queues work though.
You need to listen to /u/snuxoll. There are tens of thousands of man hours invested in solving all the concurrency problems you WILL have trying to use the DB as a message broker. C# can searalize to json, binary, whatever, which can be then consumed as a message body in a message queue. MSMQ is Microsoft's native message queueing system with out of the box .NET access. If you dont want to explore other systems, look into that one. I used it in an enterprise software I previously built and it worked like a champ. That said, I prefer redis, or zeroMQ are both great.
imo, it depends on what you plan to do after and how you learn if you want to learn a language first, so that languages you learn afterwards will be easy: C++ is the way to go, can be difficult to master but most languages, including c#, will seem easy afterwards, and in theory can only be more powerful than c#. it is generally agreed that c++ takes unnecessary extra effort to accomplish the same task as c# would, however, due to its age &amp;nbsp; c# is one of the most used languages at the moment and nearly any problem you have in any field will be a stackoverflow search away, so there is no problem with starting with it, except something like learning c++ after c# requires quite some habit breaking &amp;nbsp; many will suggest learning 'simplier' languages before will be easier, such as lua, basic or visual basic, or python. the choice is up to you, this is completely optional and starting with c# is not nearly a difficult task
I've had three machines grabbing batches, and so far haven't hit any concurrency problems. However, I'll be sure to look into it. I probably should have posted something about this before I put some work into it. I'll be sure to check out MSMQ for sure.
Ah yes, I had forgotten that one.
NT Technology
Some beneficial examples: * Using the extension method defined above: string myWords = "This is a sentence with some words."; Console.WriteLine(myWords.WordCount()); // 7 // Can also be called on a literal of the same type Console.WriteLine("This is another sentence with some words.".WordCount()); // 7 * Proof that `var` does not equal `Variant`: var i = 5; i = "Monkey"; // Compile error 
&gt; The more I thought about it I think I'm planning on just having the the individuals get their tasks from the database. I've done that before using SQL Dependency, which sends messages from the database to the worker services when something needs to be done. Then each worker grabs the top N tasks. (Transactional isolation prevents two workers from getting the same task.) It works great and I highly recommend the approach.
there's actually been two updates to that hotfix. they are on like revision #3 for the hotfix for Update 3. Each one of those is vital, especially if you are doing anything with the debugger for long periods of time. Hell. I think they just released another
Orleans would probably be easier for him to grok and then implement. http://dotnet.github.io/orleans/ A comparison: https://github.com/akka/akka-meta/blob/master/ComparisonWithOrleans.md If it were me I would setup a simple web role that read from a message queue (e.g. Azure Storage Queue), and then messaged actor grains to do the work on however many VMs required by the load. 
I remember there were some key differences between VB6 and VB.Net and instead of having to retrain my brain to avoid those pitfalls it was easier (and cooler?) to pick up C#. I don't remember what those similar but very different things were and I don't regret that change...
What I want is for the world to stop assuming, anytime someone asks a question on reddit, or stackoverflow, that they are doing premature optimization. It stifles their curiosity. They should be encouraged to explore performance differences so they can make smart choices, and they should be comfortable with higher performance options because performance is a feature, slow is a bug. Praise performance, encourage performance. If things out of your control are slow then it is even more important for you to do a good job to not add to the slowness, or find ways to be faster despite your limitations. Batteries everywhere cry out in pain, power plants strain, users wait. Efficiency is a form of correctness. Let us not waste precious cycles. 
Casting in a tight loop could be miserably slow, but the JIT is probably pretty good about that. That's what measurements are for, anyway.
That's debatable. HttpClient isn't what I'd call intuitive, especially compared to using an autogenerated proxy. But I will agree that advanced WCF is much harder than advanced WebAPI, both intrinsically and because the WCF documentation sucks.
Looks really interesting. I don't see any XML doc comments though... pretty please? :D
I agree that WCF is the gold standard in .net communication for the enterprise. It is so complicated though. If all you need is an api for REST in a website then use the webapi. 
I just [got the notification for an update to update 3](https://msdn.microsoft.com/en-us/library/mt752379.aspx) that you might be interested in.
I use Hangfire.io for my task scheduler.
For me, it was the move from modules and form based logic to the fully OOP system. I thought that there was no point relearning a semi bastardised version of the VB6 which I knew and loved. One of the benefits also, for me, was that VB6 needed only a tiny runtime. VB.NET dragged the entire .NET framework along with it which didn't exactly appeal to me if I was only using it for the Visual Basic aspect, so I thought it would be worthwhile to switch to the language created specifically for the framework.
it sounds like you might be rebuilding things which others may have already built very well. for example, instead of polling for tasks (who controls the polling? how do you make sure you don't send the same tasks to two different consumers?) you might try [message-driven work queues](https://www.rabbitmq.com/tutorials/tutorial-two-dotnet.html) which respond to new tasks which come in by sending them to an available consumer, rather than polling some poor RDBMS over and over.
You attend build conferences ? Its hard not to laugh when they start pushing a new thing as "this is it!".. You don't quite know why.. but in the back of your mind, it's just going "hey! They just f***ed me again!"
I use WCF in my Windows hosted service. It was a change from when our company's software was first developed using raw sockets. Its easy maintain, and havent had any issues really. It works in our situation because we use named pipes, so there really isnt much to get it up and running and doesnt need a cert installed to be secure.
Because the "forwarders" will forward from the apiset name to the underlying implementation DLL. Since the underlying implementation DLL can change in different versions of the OS, you can use the reverse forwarders to target the old implementation DLL (instead of the apiset) and it will forward to the new implementation DLL (which could be anywhere on the system).
Check out WebAPI 2
Linq2sql checking in....
Don't forget... * 7 layers of hooks on the server side to do special things to the request and response. * Forward compatibility with IExtensibleDataObject Interface. * Flexible authentication schemes. * Granular control over serialization/deserialization. * Easy client side proxy dependency injection/mocking via the service interface for unit testing.
WebAPI 2 is great for the server, but doesn't offer the client any help.
That's like saying, "get the chili chilito because 7-layer burrito uses too many napkins."
&gt; What's hard about httpClient.PostAsync&lt;MyRequestObject&gt;(url, cancellationToken)? There's a heck of a lot more to it than that. * Post or Get (or Put or Delete)? * URL generation * Payload as query parameters, body, or both * Figuring out what the request and response objects should look like * JSON parsing. (There are HttpClient helper methods for this, but they are in a weird library and inconsistently available.) * Connection pooling. (There's an ongoing debate about whether or not you should pool your HttpClient objects or dispose after use. Something about taking a performance hit, but I didn't read it carefully.) * Extracting error information from the response when the call fails. The boiler plate alone for an HttpClient code is significantly longer than that of a WCF call. 
&gt; Autogenerated proxies are easier when they work, and a bitch and a half to troubleshoot when they don't. Agreed. They piss me off so much that I wrote an article on how to avoid it: https://www.infoq.com/articles/WCF-Code-Sharing 
While I agree that WCF isn't necessary, it as some advantages such as being about to easily swap out which service bus you are using.
You're inflating the HttpClient complexities and minimizing the WCF complexities. &gt; Post or Get (or Put or Delete)? This is trivial, and optional. You can use POST for everything. The fact that you have the option to detail it out into a nice RESTful design is a feature, not a deteriment. &gt; URL generation You still need URL or connection/endpoint configuration with WCF. &gt; Payload as query parameters, body, or both Again, this is entirely optional. You can use body for everything. &gt; Figuring out what the request and response objects should look like This is exactly the same as WCF. You make a C# MyRequestObject and MyResponseObject class with properties as you like. &gt; JSON parsing. This is a complete non-issue. If you're not using the built-in stuff, it's still a one-liner with Newtonsoft JSON.Net. &gt; Connection pooling. Right, 'cuz you totally don't have to worry about any of that with WCF. /s &gt; Extracting error information from the response when the call fails. Err... why do you think this is somehow harder with HttpResponse than WCF? &gt; The boiler plate alone for an HttpClient code is significantly longer than that of a WCF call. Not in my experience. And certainly not once you add in all the "it's just config, not code" parts of WCF.
&gt; You can use POST for everything. Yea, but you lose a lot of advantages of using REST and you will find the vast majority of the tutorials don't do it that way. &gt; You still need URL or connection/endpoint configuration with WCF. Just a prefix. You don't have to figure out how routing works and where to substitute keys. &gt; Err... why do you think this is somehow harder with HttpResponse than WCF? Because WCF unwraps the contents of the HttpResponse and shoves everything you need into the exception object. &gt; And certainly not once you add in all the "it's just config, not code" parts of WCF. Ah, that's the rub. My answer is don't do that. Seriously, forget that WCF can be configured using app.config and do everything in code. Probably 80% of the complexity that beginners face come from that stupid configuration format.
What have you tried? Do any of the solutions from googling the problem fail or cause additional problems?
I've never googled this, but I'm in the exact same situation at work. I just assumed that VS2015 was super slow. Now I'm curious...
I haven't found any links that tell how to turn off AI for VS. To be clear I'm not talking about my own app, but literally VS itself. Hook up procmon to a running instance of vs 2015 and even when you aren't doing anything there is a steady stream of file accesses to files and directories that have "applicationinsight" in the path. Everything I've found about disabling AI is in regards to disabling it at compile time or through custom flags. I know there is an applicationinsights.config file, but I can't find one for devenv.exe.
Keep hacking away is about the best advice I can offer
Have you checked the extension manager? I believe it can be removed from there. 
Fair enough. I've been doing Web Development for to long.
Some discussion here: http://stackoverflow.com/questions/12680121/c-sharp-midpointrounding-down-to-zero Long story short, you might be best off implementing your own basic rounding function in the vein of [this](http://stackoverflow.com/a/12680878/1269654). I can't comment as to _why_ the option doesn't exist.
You mean a floor function? https://msdn.microsoft.com/en-us/library/e0b5f0xb(v=vs.110).aspx
Only for midpoint is what i'm talking about.
So if a number was 1.5 or 2.5, you want to round down, rather than round up? There is a function a for that... https://msdn.microsoft.com/en-us/library/ms131274(v=vs.110).aspx
Not at all implausible isn't good enough though. Certainly not enough to completely avoid a core language feature. LINQ is easy to fuck up, but so are all enumerators. A for loop is fast on an array, not so much on a linked list. Given how much of LINQ is built into the actual implementations you could even find that LINQ is horrible on one collection type or object type and great on another.
Ok, dude. I get it. I'm not advocating anyone avoiding Linq without identifying it as a cause for performance issues. But come on. If you've profiled and found using Where was too slow in one place, it's unlikely to do better in another place where the input is very similar. I also don't think iterating over a linked list is actually slow. It's random access that's the problem. Iterating either an array or a linked list is going to happen in linear time (although I suppose there can be some very low-level optimization going on related to how close together the physical memory is... this is even less likely to be a problem in a real program than Linq).
Chrome wouldn't start the download, but Edge did. FYI.
My concern isn't that that isn't the problem (it clearly is). My concern is that next time /u/djdylex has a perf problem he won't have any more general tools at his disposal other than ask Reddit. The general answer to "Why does something take a long time?" is "A profiler will tell you." and in this case it's fine to add "But in this case here's your problem". However you should always teach someone how to solve problems, even if it's easier for you to solve it for them.
True, in that sense it is still a proxy. What it is avoiding is the proxy methods that the generator creates. These methods are just thin wrappers around the actual WCF proxy channel, in effect creating a proxy (or indirection layer if you prefer) around another proxy.
The client story for REST isn't great. I would still recommend using WebHttpBinding on the client side or a WebAPI/MVC rest service.
I would also look at rabbitmq
Iterating over a linked list isn't slow. Running a for loop and getting List[x] is slow. A for loop is the worst possible way to process a linked list. That's the whole point. LINQ isn't a single thing it's a bunch of data structure specific implementations. Some may be fast some slow. What they all are though is tested and maintained. I can write a stable quick sort, but it'll be tested by me, so it could suck. The performance gains from rolling your own have to be significant, and they have to matter. I've done some basic testing. Running a for loop over an array and adding items to a list if they're multiples of 4. It's basically best case scenario for a for loop. LINQ is about twice as slow, but it's a difference of 300 ms or so on a hundred million records. Given it's a 2 ms difference on a million records I could probably optimise both queries better at that size. Is that worth it? Maybe, the code difference is a couple lines, but not doing the memory allocations properly cost me two orders of magnitude more than using LINQ in both methods. What about when you get more complicated though. Expression trees in LINQ are really easy. Implementing the same code with loops is fairly awful. Implementing my own sort implementation isn't exactly pretty either. Even is the twice as long carries through. Is that worth it? What if I don't know my data structures very well and I think doing a for loop with an indexer instead of a while has next on a linked list is OK. That's going to be a lot slower than LINQ. Refusal to use built in libraries generally comes from a belief that I am a better coder than whoever wrote the standard libraries. It's foolish and needs to be a last resort not a first resort.
The best part of MSMQ is the client side queue for guaranteed delivery. There's nearly no other systems that leverage queues on all sides of **every** wire (because its super difficult)
Huh, I never thought about that.
A decade and WCF still doesn't even have a decent outline of all its extensibility points, let alone full documentation to take advantage of it.
Look into [MBrace](http://mbrace.io/index.html). It might be a good fit for what you are trying to do.
I think a good foundation in raw C# will make learning Unity a lot easier. C# supports a lot of paradigms. It has imperative, object oriented and functional features. If you can grasp the core concepts, you should be in a good position to start learning any framework or even move to another language entirely.
Agreed, if the OP is happy to be tied to azure then reliable actors is also an interesting option.
Oh okay, i've managed to get it working :) thank you for your help!
I'll try to do it in the next few days - it's just a plugin for the Tracer plugin above, but using nlog instead of log4net.
Hah! I just come from a conference call discussing a bug most likely caused by this long path restriction. About damn time they got rid of that.
Many of our inhouse Services used WCF and new developments are to in WCF.
&gt; You have probably experienced and investigated the cause of a NullReferenceException. You don't say...
Meh, didn't really like it that much but It'll do if this is all we have in C# c:
Lots of wcf updates as well. Perhaps the Web api faithful will stop saying wcf is dead and finally admit what Microsoft says, that Web api isn't a replacement to wcf it's an alternative for rest apis. 
Space Engineers uses a Mono-based subset of the C# language in its in game 'terminals'
&gt; a huge code base that swallows exceptions all over the place So, 99% of code out there? I'm only partially joking. Frankly, very few people know [what](https://ericlippert.com/2014/03/03/living-with-unchecked-exceptions/) to [do](https://ericlippert.com/2014/03/06/living-with-unchecked-exceptions-part-two/) with caught exceptions. Logging the failure is better than nothing; it provides one way to monitor what's blowing up. The "proper error handling approach" isn't so clear.
We are working on replacing the Debug statements with NLog. By proper error handling I mean, if a save operation throws an exception, have the error flow up through the code, tell the user it failed and ask them if they want to try again--in addition to logging the exception.
I'm finding the whole thing very frustrating - and old fashioned. It's a new system set up by the client, and they appear to be using dreadful technology throughout. Their documentation even gave a number to call if you get stuck. I phoned it, and the chap on the other end didn't have a clue what I was talking about, let alone being able to help (he even asked me what an API was).
Well, it's easy enough to stop swallowing the exceptions and add catches on the upper-most GUI layer. Tricky bit is whether this has other side effects in the code base; parts that functioned _because_ (apparently non-critical) exceptions weren't thrown. In an ideal world, you can identify areas you want to rewrite/refactor, identify the areas access it, and write lovely little unit tests that pass with the existing code, refactor/rewrite, and keep those little tests green. Of course we live in the real world. I have no idea what "huge" means here, how deeply interwoven and cross-referenced these methods are, and how buggy (or not buggy) the existing code base is _for the user_. Best I can suggest is firstly don't break what isn't broken. What is _broken_, fix (painfully). Otherwise identify those critical/important aspects that you expect to fail in the future or you expect to be major headaches going forward in terms of API and maintenance. You'll probably want to refactor as you go; don't try to refactor everything at once. Get your software "working" relatively bug free; that way as you poke at each legacy method, you can see if and how it fails. Ideally, write automated tests as you go before you refactor individual components, but I understand that sometimes that just really isn't feasible. I'd recommend you take a look at [Working Effectively with Legacy Code by Michael Feathers](https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052). It could be pretty applicable for your situation. EDIT: Just to be clear, it's definitely safe and recommended to replace the `Debug.WriteLine` calls with `NLog` calls if that's your logging method, but don't change the throwing/swallowing behaviour yet or haphazardly as that would be a fundamental change with how it processes.
[removed]
Run the code with 'breakpoint on all exceptions' turned on and figure out what exceptions are actually happening, trap them separately then figure out how it should respond. 
Great tip! I do this. Love this feature in Visual Studio. Unfortunately, we don't have any automated testing to speak of and it isn't feasible to fully test all the app scenarios manually.
Sorry, let me clarify. If there's a particular aspect of the code that is "working" from the user's point of view; that is, it's fulfilling the desired application requirements, I wouldn't go about rewriting it because the code is wrong/broken. If the application is marching on, but not actually doing the work expected of it, then I would consider that broken and should be fixed. I get the feeling now that this is where you're at; you inherited a pretty much non-functioning application and are tasked with "making it work"? Sound about right?
there's all kinds of hacks built in to try and retrieve it via reflection and shit in the error logger. Whoever wrote this probably sat around complaining that C# exceptions don't include anything valuable but luckily they were smart enough to find it. I did take a stab at using Roslyn to rewrite it. That pattern is so copied and pasted I thought I could do it, but my skills fell short when I realized they had the other enterprise pattern of in some of the "newer" code. var current = System.Windows.Forms.Cursor.Current; System.Windows.Forms.Cursor.Current = System.Windows.Forms.Cursors.WaitCursor; try { // do stuff } catch (Exception ex) { throw ex; } finally { System.Windows.Forms.Cursor.Current = current }
chrome worked for me but I did go to the msdn downloads.
So *under the hood*, OpenIdConnect uses OAuth2 but the options available didn't show me a place to designate the various URLs, which I suppose means OIDC is very light and requires you to go through each of the Events and code them up? If I use IdentityServer, that would mean I need to use a database, correct? If so, I'm really trying to make an app that doesn't require long-term authentication (2-30 minutes at most) so I was trying to stay away from needing to deploy a DB. Sorry for all the questions, this whole Authen/Author and the various asp.net repos are starting to confuse me a bit. For instance, CookieAuthentication is in the Security.Authentication namespace but so is OAuth, which is apparently not supposed to be used for Authentication *but has been for a long time*. 
The end goal is to have a site that authenticates through oauth and stores the persistence side of oauth (tokens) in cookies/sessions instead of DB. I will look at your links.
You could try using the *dynamic* keyword (example: public void myFunction(object o){ dynamic obj = o; //do something with obj }
I've felt your pain. You are going to have to configure transport security by hand in the Xml configure. You need the cert installed and the xml config set to use it based on the install location,
Finally ClickOnce works together with TLS? That was always a PITA.
There definitely isn't an implementation of trig functions at the CPU level. Most of the time, trig functions reside in the Microsoft Visual C++ runtime library, msvcrt40.dll. I'm not sure if that's the case with C# or not, but .Net runs on top of lower-level DLL's and at some level (before the OS and well before the CPU) you'll find these kinds of functions. 
Yeah, ASP.Net has tried since its inception to "shield" developers from the guts of HTML, CSS, and JavaScript. To some extent it succeeded, if you only need to develop simple applications. But as soon as your requirements become more complex, you need to understand how Web applications really work.
We had a codebase like this at one point. Things would constantly go wrong in production and we would have absolutely no idea where or why. I eventually got fed up and deleted every single try/catch I came across. Our raygun account has been flooded with errors for the past few months, but little-by-little we're chipping away at them. We're in a much better place than we were a few months ago. Would I recommend this approach to others? Eh... the code is broken unfixable garbage already. You may as well turn it into broken fixable garbage.
Wat? CPU has trig functions built in from Intel 486 and even before there were coprocessors. "Runs before CPU"? What a nonsense. Any code is running on CPU including .NET code which get JIT or NGEN compiled to be executed directly by CPU.
How much Javascript should I know at this point before digging my teeth into ASP MVC? C# is the language I've devoted the most time to understanding, practicing, and learning and it seems like a daunting task to learn about a whole-nother language that I've never even touched before.
Honestly, you'll pick it up as you go along. The vast majority of JS that you'll write will be 3-line event handlers. These days most of the really complex stuff is in libraries that you can just use without knowing the details. Often the hardest part is deciding which of the bajillion libraries to choose. But with .Net MVC that choice has already been made for you anyway. It's probably more important to be able to READ JavaScript than to WRITE it. Same with HTML and CSS for that matter: it's not like you're gonna be typing the stuff in most of the time. But when something goes boom, you're gonna need to View Source and figure out why the generated HTML is doing what it's doing. And you need the basics of CSS because if you don't style your app it'll look like crap ;)
This is certainly true of Webforms, but MVC is fairly minimalistic as full stack frameworks go. One should be well versed in the front end before kicking off with ASP.net MVC.
I have now altered my code so that the Kernal is circular (which has actually increased performance), i tried researching filter separability but do not quite understand it, would i be able to separate filters for a circular kernal? [Here is my new circular kernal code](http://pastebin.com/sKxg8Yhj)
okay, that was good
I don't think so. A MxM kernel is separable if it can be written as the product of a Mx1 matrix and a 1xM matrix. A gaussian kernel is separable and gives the most pleasing visual result. You should try it out.
One thing I couldn't figure out regarding Pluralsight was whether they had exercises/assignments. If they do, can you vouch for their quality? I sometimes find the hardest part is I will learn something, but insufficiently hammer it into my head and I end up needing to go over the entire subject later when it comes up.
Most of the Unity tutorials show you some basic C# stuff. It's good enough to get a taste of the syntax. http://unity3d.com/learn/tutorials
 Where can I read about this (don't specify the joins)? Do you have a link or can you point me in the right google search? Thank you 
Global search and replace "Debug" with "Trace" and "ex.Message" with "ex". Implement a trace listener that sends the events to a global repository. Start aggregating the events and making a list of issues that need to be addressed with better code.
You're basically just *boxing* the parameter to make the interop work, and depending on what the function is supposed to do you wan't to *unbox* the parameter and verify it before moving on to what the method is supposed to do. Here's an example: public void DriveMyCar(object o) { Car myCar = o as Car; // Attempt to unbox o as a Car if (myCar == null) { throw new ArgumentException("Parameter 'o' must be of type 'Car'"); } car.Drive(); }
Take a look at this from microsoft msdn https://msdn.microsoft.com/en-us/library/ff648360.aspx
I thought Robocode had support for .Net and there was another game where you had to program some kind of AI who played the game. But I forgot the name :(
Thank you. I had actually narrowed my search down to those two books so it's nice to hear the opinion of someone with a similar skill maturity who has read both.
A client side transactional queue is amazing for reliability, it's sad that so few systems provide it 
&gt; Are there strategies you used to incrementally move a code base like this to a proper error handling approach? Yes. You need to chip away at these. One by one. That's the only way you'll improve it. Try-catches aren't bad. It's when they swallow the exception. I can only think of one case where an exception is swallowed in our code base. In all other cases we log the exception.
This is probably fixable by writing your own Roslyn analyzer to defect this. Actually there's probably already one out there. Actually look into StyleCop.Analyzers.
R# got me close. It would change it to a regular throw, then a second operation to mark it as a useless catch block. But only one-by-one. Perhaps the StyleCop ones will be a bit more aggressive. I'll check them out, thanks
I want to put emphasis on this. MVC 5 is great but don't spend all your time on it. ASP.NET Core has been released, you should focus on the latest technology so you have a leg up in the industry. I've seen some mentions of AngularJS also, learn Angular2 instead for the same reason.
Yes the Roslyn analyzer/fix can be applied across various scope levels from line, method, file, project... I have used this particular one to apply consistent coding style to hundreds of thousands of lines of code, in minutes. They are also not so difficult to write, so you can make your own "fix" where a regex search/replace would not be able to match properly. 
So a couple things: The reason I called out Count() as iterating the entire collection was to point out a potential inefficiency in doings something like if(coll.Count() &gt; 0) versus: if(coll.Any()) One would iterate the entire collection and then compare the numbers where the other one would only look far enough into the collection to determine if predicate evaluates to true, even if that ends up being false which means it'll iterate the entire collection. But... erm... that's kind of assumptive as well. Both Count() and Any() invoke the enumerator, so you can't really assume what the behavior is going to be. But I think List&lt;T&gt; will simply begin iterating the internal array. &amp;nbsp; Secondly, 'LINQ' is a bit ambigous for the statement I think. There are several methods in the LINQ library that do not defer anything. It's the query items (e.g. Where(), First(), Range() etc.) that defer. Basically any function that actually affects the contents of the resulting collection vs. functions that return info about that collection like Any(). For example Any() will call the MoveNext() on the enumerator of the source collection immediately and Any(Func&lt;T, bool&gt; predicate) actually calls a foreach loop on the source collection immediately. Same with All() &amp;nbsp; Thirdly, I stand corrected on the materialized List&lt;T&gt; example as not mattering after having downloaded the corefx source and looking for myself -- however, I'm not completely wrong. Once ToList() is called, the IEnumerable gets iterated into a materialized list (i.e. List&lt;T&gt; is an actual implementation. right?) so the enumerator will have been called for the entire collection -- any deferred execution will have been executed, but this isn't the same "deferred execution" provided by LINQ. So to clarify and elaborate on the topic with my recent findings: &amp;nbsp; The LINQ behavior is the same regardless of the collection type, however the behavior of the IEnumerable&lt;T&gt; source (on which LINQ is being performed) depends entirely on the implementation. For example, `Where(..)` always returns an instance of IEnumerable, but the implementation is actually a wrapper for the source collection's enumerator, so nothing actually gets executed. So when you start calling methods which call the enumerator, the behavior of the source collection's implementation will be run at that time. So if that means the collection simply exposes elements of an internal array, then it does just that; the execution that is deferred is unremarkable since it just returns the relevant element of the internal array. However, say the source implementation is a virtualizing list, then there may be some extra behavior that executes to update the internal list before returning a value. I think that would be a better example of deferred execution, although that doesn't really have anything to do with LINQ. I think it's probably easier to understand once "deferred execution" is explained as being "linq won't cause enumeration of the source collection", rather it literally just wraps your collection in a graph of predicates -- an elaborate decorator, really. It's a builder pattern that builds a decorator. Cool! &amp;nbsp; With that being said, I think that may have been my understanding of IQueryable. When `GetEnumerator()` is called on EnumerableQuery, for example; it is at that point that the expression tree is compiled into an IEnumerable from which the enumerator is returned -- and that enumerator holds the magic sauce for what happens when that source is enumerated, for example: an Entity Framework IQueryable implementation has a visitor that converts an expression tree into a SQL query. I tried to implement one of those once and it was ... crazy. So in that example, the compilation of the expression tree is the "deferred execution", Anyway, that was an educational bit of research that I had fun looking into :) So to clarify, it would appear that in the context of LINQ (not implementations of IEnumerable&lt;T&gt;), "deferred execution" simply means that the enumerator on the source collection will not be invoked as a result of invoking LINQ methods. The enumerator wrappers that LINQ query functions creates simply add a gate/filter to the elements being returned from the source collection's enumerator. 
That sounds like a problem with the implementation of the collection or the predicate, not LINQ.
Actually no, it's not LINQ that does it. The call to LINQ methods simply decorate the GetEnumerator() method of the source collection. What that decorator does is get data from the source collections enumerator and then applies the predicate to it in order to decide whether or not that value will be returned when the *decorator* is enumerated. Cool, huh? So for Queryables, the implementation of IQueryable in EF has an additional step that makes a call to a query provider which implements a visitor pattern (there's a factory method inside that figures this out). That provider isn't "smart" so much as it is designed to specifically convert the iterator created by Any() to emit an EXISTS sql query when the query is actually compiled. Sound confusing? It totally is. Try looking up how to implement your own LINQ provider. So it's still referred to as LINQ, but it doesn't come from the LINQ namespace, it's mostly just fancy IEnumerable implementations. I explain it in a different reply on this thread how the pattern works internally. The actual magic happens in the implementation of IEnumerable (the enumerator, specifically), whether it be IQueryable or something else. What LINQ actually is is a builder pattern that builds a decorator graph for the source collection's enumerator. I actually just discovered this tonight when I pulled down the source and looked closely at how it all works together. For example, Where() will look at the source collection and try to cast it to Iterator&lt;T&gt;, TSource&lt;T&gt; which is just an array, and IList&lt;T&gt;. Depending on which cast succeeds, it wraps it in a custom implementation of Iterator&lt;T&gt; which is the decorator that implements IEnumerable&lt;T&gt;. This is what is encapsulated as IEnumerable&lt;T&gt; and gets returned with each call to a query extension. So the way I actually see LINQ now is more of a pattern. When you say LINQ to Objects or LINQ to Entities, what it really comes down to is applying the LINQ builder pattern to one of any implementations of IEnumerable&lt;T&gt;. How the collections are actually materialized is still controlled by the implementation of IEnumerable&lt;T&gt; and that includes how an instance of IQueryable constructs a query. Most of these implementations are already provided to you by the framework (luckily lol).
Came here to say this without even reading the code :-D Ah, Game of Life... So many students, all falling into the same trap.
Really depends on what your app will be like. If you have static pages with old-school link navigation without fancy effects and validation and SPA transitions, you can get away with pretty much no JS at all.
I really wish you were joking, but instead i'll just go and cry in that corner over there, thinking about the average brownfield enterprise code base D:
Well, ended up buying it and it's looking great so far :)
For now I had done all of the communication on the same port. I'm realizing the client doesn't actually need to have a fixed port to receive data. I'll try using a random free port to talk to the client.
Check this website for awesome course deals: https://deals.creativebloq.com/
does the result of MapPath point to the actual file in question? Seems like that is where the issue lies
Couple other things you could check. Check the read permissions on the crt file, make sure you have them for the user the app is running as. If that doesn't look out of whack I would try loading the cert file with `File.ReadAllBytes()`. then passing the byte array into the 509 constructor. That could help determine if its an issue with accessing the file or the contents of the file. If you can't read the file using `System.IO` then thats your underlying problem you gotta fix (not sure how much help I can provide on that). If you can read the file and the x509 constructor fails when you pass in the byte array that might point to the cert file being corrupted
nice! which shortcut are you using to join the declaration and assignment?
Whatever you do, for the love of Gates, don't use spaces.
Your clients are all trying to use the same port, you can't do that on a single pc. You need to set up your clients so they can select their port if you're going to be testing on a single pc.