Someone loves WMI enough to write a helper library so those of us who don't can use it
heh, had me going there for a bit. :)
Seems like the simplest way would be to total each item type from the day before using a dictionary, then just sort them by amount descending.
Here's my take with a linq query. if (!string.IsNullOrEmpty(searchText)) { var distinctWords = searchText.Split(' ').Distinct(); var regex = "(" + String.Join("|", distinctWords) + ")"; activities = from activity in activities let matchValues = new [] { x.Text, x.Account.lastName, x.Account.firstName, x.Account.organization } where matchValues.Any(mv =&gt; Regex.Match(mv, regex, RegexOptions.IgnoreCase).Success); }
IÂ´ll take that reccomendation. That might be a better approach. Thanks!.
Must have missed it -- can you point me to a tool that lets me configure rules for C# on the same level as say, tslint for typescript, does? Down to chunks of shared 'standard' coding standard preferences? 
It's hard to make a reasonable code review without full context, however I suggest something as... public class Account { public int Id { get; set; } public string LastName { get; set; } public string FirstName { get; set; } public string Organization { get; set; } public IEnumerable&lt;string&gt; SearchableValues { get { yield return LastName; yield return FirstName; yield return Organization; } } } public class Activity { public int Id { get; set; } public string Text { get; set; } public Account Account { get; set; } public IEnumerable&lt;string&gt; SearchableValues { get { yield return Text; foreach (var x in Account.SearchableValues) { yield return x; } } } } public class ActivityService { public IEnumerable&lt;Activity&gt; Filter(IEnumerable&lt;Activity&gt; activities, string searchText) { var terms = new HashSet(searchText.Split(' ').Select(string::ToLower)); return activities.Where(activity =&gt; activity.SearchableValues.Any(v =&gt; terms.Has(v.ToLower()))); } } I didn't run this code so there can be many syntax errors. Consider this a C#-y pseudocode.
Well I'm pretty sure us doing someone's homework for them is not going to help them learn the material. Formatting and parameterizing database queries is usually part of the curriculum. I answered their question in another post pointing them in the right direction for solving their issue.. 
This is a well written and interesting article. Thank you!
Creating a [.editorconfig](https://docs.microsoft.com/en-us/visualstudio/ide/create-portable-custom-editor-options) file does part of this. [Reference](https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference) Also: project properties -&gt; [Code Analysis](https://msdn.microsoft.com/en-us/library/dd264925.aspx?f=255&amp;MSPPError=-2147217396) 
Wow. Now I start to see things clear. I think I'm gonna try this Moq framework you mentioned, and for my next project I will try to use this logic you exposed to me. You've been really helpful for me, thank you so much. I wish I'd be at your level of skill in C#... even after two years of developing full stack, I discover new things every day!
&gt; My main pet peeve though on spaces, is if I want to unindent I have to shift+tab instead of just hitting delete, as delete just deletes one space, not the whole indentation. Thats when I notice that its using spaces not tabs and it bugs me ;) I have VS set to spaces instead of tabs for our coding standards, and if I hit SHIFT+TAB it goes back one indentation. This works for aspx, cshtml, cs, or config files.
&gt; &gt; &gt; &gt; &gt; I have VS set to spaces instead of tabs for our coding standards, and if I hit SHIFT+TAB it goes back one indentation. I know, I often just hit delete to un-indent (since it works with tabs) but with spaces it just removes 1 of 4, so I then *have to use* shift+tab to unindent which is not my habit, which is why I prefer tabs.
But what if you have a whole block of code you need to indent/un-indent? Then you can highlight it as a block, and use either TAB or SHIFT+TAB to do so. Do you do that one line at a time?
Ok at a computer and there are a couple things I want to discuss. 1. Convert all your `double` objects that are dealing with currency into `decimal` objects. Doubles may have a higher float point, but they are less precise. What this means is that you can gain or lose fractions of a number during calculations. Those precision losses are incredibly dangerous when dealing with money and could get someone in trouble. Based on your above code, it looks like your are only using it to convert to and from strings, which most likely won't cause and issue, but I would just recommend getting in this habit 2. At this point, I wouldn't switch to binding which means you can't use an `IValueConverter`. Because of this I personally would change up how you're handling this. Subscribe to the `GotFocus` and `LostFocus` event and handle the formatting in there. In this example. When you click out of a box it converts the format into dollar currenty, but when you click in it converts back to a numbers for editing. You would have to add your own error handling and validation logic. //Add Reference to using System.Globalization; //Textbox Events private void myTextBox_GotFocus(object sender, RoutedEventArgs e) { decimal d;//ALWAYS work in decimal for currency if (decimal.TryParse(myTextBox.Text, NumberStyles.Currency, CultureInfo.GetCultureInfo("en-US"), out d)) { myTextBox.Text = d.ToString(); } } private void myTextBox_LostFocus(object sender, RoutedEventArgs e) { decimal d; //ALWAYS work in decimal for currency if (decimal.TryParse(myTextBox.Text, out d)) { myTextBox.Text = d.ToString("C", CultureInfo.GetCultureInfo("en-US")); } }
Thank you. Yeah so I started messing with lost and got focus. They only problem is Got Focus does not get triggered when the data is being pulled in from a database into the text fields. Which I have a work around for, it would be to format the string when I receive it from the database. Also, thanks for the double and decimal tip. I will redo the doubles. 
Msbuild takes environment variables straight into properties. If you set an environment variable to enableoutofprocbuild to true it will adhere to that. Devenv is just calling msbuild weirdly. 
What dependencies do you have for a control aka the View besides the ViewModel? Nothing should require injection on the View side as everything is designed to bind to the ViewModel. What you're seeing in your example of the VM factory is Service Location which is the Arse about Tit version of DI where the object requests its dependencies as opposed to having them injected. This is a pretty common strategy in WPF. So, skipping the DI bit, here's sort of how you'd make the above work. Here's a XAML window: &lt;Window x:Class="WpfApp1.MainWindow" xmlns="http://schemas.microsoft.com/winfx/2006/xaml/presentation" xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml" xmlns:d="http://schemas.microsoft.com/expression/blend/2008" xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006" xmlns:local="clr-namespace:WpfApp1" mc:Ignorable="d" Title="MainWindow" Height="450" Width="800" &gt; &lt;Window.Resources&gt; &lt;local:ViewModelFactory x:Key="Factory"/&gt; &lt;/Window.Resources&gt; &lt;Window.DataContext &gt; &lt;Binding Path="MakeMeAViewModel" Source="{StaticResource Factory}" /&gt; &lt;/Window.DataContext&gt; &lt;Grid&gt; &lt;TextBlock Text="{Binding Path=BooYa}"&gt;&lt;/TextBlock&gt; &lt;/Grid&gt; &lt;/Window&gt; Note it has a resource of ViewModelFactory and the DataContext has a binding. Here's the factory: public class ViewModelFactory { public TheViewModel MakeMeAViewModel { get { // DO ALL YOUR DI STUFF IN HERE return new TheViewModel(); } } } And this is returning a TheViewModel as defined here: public class TheViewModel { public string BooYa =&gt; "Boo!"; } Usually you'd have one resource for the VMF in the Application which makes the binding simpler, but it's useful to know the syntax for this way too. This is just one of many ways of doing it. What you'll find later is that where view models need to talk to each other, preferably via a messenger (hint) it becomes easier to just create factories that emit controls with their viewmodels in one go. It's less pure in the XAML sense, but it's much less hassle. 
For blocks I use shift tab yes. It's just muscle memory when deleting single (often empty) lines. That's when I notice I didn't go back a whole team but a single space.
Thanks! That helps a lot. Would you be able to demonstrate how? 
I see you have good taste.
Maybe something like if (!String.IsNullOrEmpty(searchText)) { var distinctWords = new List&lt;string&gt;(searchText.Split(' ').Distinct()); var regex = @"(" + String.Join("|", distinctWords.Select(Regex.Escape)) + ")"; activities = activities.Where(x =&gt; TestMatch(regex, x.Text, x.Account.lastName, x.Account.firstName, x.Account.organization)); } And a helper method of private bool TestMatch(string regex, params string[] values) { foreach (var v in values) if (Regex.IsMatch(v, regex, RegexOptions.IgnoreCase)) return true; return false; }
Okay... you're obviously not interested in learning anything, so I'm just going to pray to the programming gods that your teacher asks you to explain this single line of code: `new OrderRepository()` `.GetYesterdaysOrders()` `.SelectMany(x =&gt; x.orderLines)` `.GroupBy(x =&gt; x.itemName, (name, item) =&gt; new { Name = name, Quantity = item.Sum(x =&gt; x.quantity) })` `.OrderByDescending(x =&gt; x.Quantity).Select((x, i) =&gt; new {` [`x.Name`](https://x.Name)`, Shelf = i + 1 })` `.ToList()` `.ForEach(x =&gt; Console.WriteLine($"Shelf {x.Shelf}: {`[`x.Name`](https://x.Name)`}"));`
Glad I could help. Just let me know if you have anymore questions!
Oh man, you just made my favourite language even more interesting. Thank you for this\~!
You'd be really good at *practicing algorithm problems*. You need to not only understand the algorithms but also when to apply them. IMHO, the S.O.L.I.D programming principles (among others), architecture awareness and technology knowledge is more important unless you know the job you are interviewing for uses complicated algorithms.
There are multiple parts to coding. Practicing algorithms for 8 hours a day for 30 days strait will absolutely help you... but it won't cover all the bases. You'd definitely have a better understanding of the syntax of the language and you'll gain a lot of insight on how different problems are approached. But another part of programming that this may not help as well with is laying out a program structure and organizing classes and objects. Complex algorithms are lots of fun and very interesting... but realistically they only make up a small percentage of your total code base. There are tons of helpers, converters, simple data types and simple code that wraps around a few Complex Algorithms... Part of programming is implementing algorithms. Part of programming is organizing data. Part of programming is packaging data for an algorithm to consume... 
.editorconfig falls short in the capability it provides compared to tslint - it prescribes more about readability -Nothing about default switch in the reference, for instance. Code Analysis doesn't perform the same activities - is more about ensuring correct behavior, rather than consistent syntax/semantics. Roslynator is new to me and it looks like it fits the bill - but decidedly not a built-in visual studio capability...
Thanks, I took your extension method and ran with it. This was what I had in mind as well. The code was part of an existing base. There were like 5 or 6 methods that had the same RegEx comparison. the extension method simplified this greatly. \-E 
Oh OK, didn't know that! Will definitely try it asap
The debugger is your friend. Step through the code and make sure "path" and "address" are what you think they are. If that works out, then it's probably a permissions issue. 
I've logged the paths to the console to check them, and they match. I don't understand how it could be a permissions issue either, seeing as I have the manifest requesting to run at the "highest permission"
Weird. I still think you want to use the debugger rather than the console. Set a break point before File.OpenText and check File.Exists(path).
Will do
Ayy lmao I figured it out The method that created the file was Async, so the one that tried to open it ran first.
ã½à¼¼ àºÙÍàºà¼½ ï¾ Raise ur dongers! ^^Dongers ^^Raised: ^^35324 ^^Check ^^Out ^^/r/AyyLmao2DongerBot ^^For ^^More ^^Info
https://nerdparadise.com/programming/csharpforjavadevs I only glanced over it but it should get you on track. Also, if the interview questions focus on syntax instead of problem-solving, well... They might not have their priorities in order.
I definitely understand what you're talking about. I've built full a web app and deployed officially for my company, so it's definitely very important to know, and hard to get right without actually doing it and practicing. What else do you suggest I do other than solving the problems? 
Insufficient data for a meaningful answer.
Ok what details would you need 
Removed: Rule 4. "Checksum" is a concept. There is no standard method of calculating it. It could be an MD5 checksum, or an SHA256, or a CRC check, or any other variety of methods. So you would need to provide information like the checksum method you want to use, and code of your attempts.
Did you disable automatic calculation? if app is your Excel application object: app.Calculation = XlCalculation.xlCalculationManual; Remember to save its original value and restore it after. 4000 rows is pretty small, so if the above doesn't help, just read it into an array or list and do it in memory. No need for a db for that small amount of data.
Try this private void SetPosition(int a, int b) { SetCursorPos(a, b); } [DllImport("User32.dll")] private static extern bool SetCursorPos(int X, int Y); Borrowed from [stackoverflow](https://stackoverflow.com/questions/8185916/move-mouse-with-c-sharp) No idea if its absolute or relative, but those calcs are pretty easy to solve anyway.
I did yes. There was a trifecta of options if I remember: ScreenUpdating = false, Calculation = Manual, EnableEvents= false. I've read a little about two-dimensional arrays, but I can't seem to understand how to use one in this case. Could I "delete rows" from an array? In the meantime I'm going to look up how to store a spreadsheet into a 2D array. 
There's [another solution](https://stackoverflow.com/questions/8050825/how-to-move-mouse-cursor-using-c/8050847#8050847) in the comments that might work too without the DLLimport.
The `for` loop isn't slow, but perhaps your interop with Excel is. First thoughts might be to loop and identify rows to delete, then do a second loop where you nuke the rows. Beyond that, EPPlus is probably the easiest to use if you want to skip Excel interop altogether: var package = new ExcelPackage(new FileInfo("myFile.xlsx")); ExcelWorksheet sheet = package.Workbook.Worksheets[1]; //first worksheet var startRow = sheet.Dimension.Start.Row; var endRow = sheet.Dimension.End.Row; for (int row = endRow; row &gt;= startRow; row--) { var cellValue = sheet.Cells[row, 1].Value; //gets the cell value for the first column in the current row if (ShouldDeleteRow(cellValue)) //or whatever logic sheet.DeleteRow(row); } package.Save(); //or use "SaveAs" if you want to keep the original I do the loop in reverse here so as you delete rows you don't mess up your row number. I might also have perhaps an off-by-one error here or there, but hopefully this gets you started.
Removed: Rule 1. You can ask in our [monthly job postings thread](https://www.reddit.com/r/csharp/comments/8z7uuq/c_job_fair_july_2018/), or check out /r/learnprogramming, /r/learncsharp, or /r/ProgrammingBuddies, or /r/forhire.
It'll definitely be focused on problem solving, it's just that I'm going to have to be able to use C# effectively to solve the problem. Therefore I need to know how to use it.
read the article that /u/geek_on_two_wheels posted and then just port your school assignments over into c#. you can google "&lt;conceptYouKnow&gt; c#" to fill in the gaps. aside from the things that article mentions, i'd probably just bring up `var` as most .net houses are going to probably be using it extensively. the `var` keyword is shorthand that lets the compiler determine the appropriate type to use for you. the thing is still statically typed, it just saves you some typing and also makes refactoring a bit easier sometimes. `var list = new List&lt;string&gt;();` is equivalent to you writing `List&lt;string&gt; list = new List&lt;string&gt;();`, `var blah = SomeFunctionThatReturnsAString();` is the equivalent of `string blah = SomeFunctionThatReturnsAString();` and so on.
SOLID is useless bullshit. Probably L and D are the only ones with practical value. Everything else is so vague that everyone agrees and imagines he does it right. Single responsibility? Sure my class has single responsibility - compiling a C# program therefore I put the whole C# compiler in one file. It has only one reason to change when the C# specification changes. See I am very SOLID!
I have to say it: The code snippets look atrocious * Proportional font * Huge line spacing * 2 space indentation * No line numbers I really want to read this article but this formatting is really distracting
S - Helps to mitigate cascading changes to classed. O - Manages changes that are needed L - Ensures assumptions about inheritancw can be made and reduces logical errors I - modularizes the code to enable "coding to a contract", proper unit testing, logical boundaries, etc. D - ensures dependencies are clearly stated and enables better unit testing I am not sure if you are trolling or if you simply don't understand the principles.
As a programmer, you have the knowledge and power to change the style of code to what ever the hell you like, use your powers or lose them :)
What exactly are you suggesting? I don't quite understand your point
you know that the page is just html and css, you can find the classes for formatting the code and overwrite them, I used Tapermonkey in chrome to change the color, style , position etc. of pages/sites. With Firfox there used to be greasemonkey, or anything that runs a javascript code, you can even modify it with just a JavaScript Bookmarklet. For example look up contrast bookmarklet to see how to change the idiotic by design light gray font on white background that makes pages really hard to read. Let me know if you need more details.
How about making a list of 1D arrays, where each array is a row?
Or just copy and paste the code into your IDE so itâs formatted how you like.
My understanding is that params is just some nice syntactic sugar to save you having to create a new array (at least saving you typing it out) everytime you call your method. I think the compiled signature of the method would just have an array as the argument and in the compiled code every it was called those 'param arguments' would get put into a compiler generated array. That was always my understanding but i could easily be wrong 
I see what you mean, it's the Sheet.Rows[r].EntireRow.Delete(); line that slows everything down. If I didn't need to delete anything, the script would be fairly instant. So I'm a little unfamiliar with EPPlus. Is the var "package" basically the spreadsheet? And by setting it as a new ExcelPackage as my spreadsheet, it imports the data? Wow. I just got it to work. I just couldn't wrap my head around EPPlus for the longest time. I've adjusted your code to fit my project. I had to compare dates so I casted the values in DateTime and that seemed to work. Thank you for your easy to understand code. var package = new ExcelPackage(new FileInfo(path)); ExcelWorksheet sheet = package.Workbook.Worksheets[1]; //first worksheet var startRow = sheet.Dimension.Start.Row; var endRow = sheet.Dimension.End.Row; for (int row = endRow-1; row &gt; startRow; row--) { var checkin = (DateTime)(sheet.Cells[row, 9].Value); var checkout = (DateTime)(sheet.Cells[row, 10].Value); if (checkin &lt; dDate &amp;&amp; checkout &gt;= dDate) { } else { sheet.DeleteRow(row); } } package.Save(); 
EDIT: It's seems that I am on my way to solution. Now I see that in debug build I have 2 folders x86 and x64 with that file and in install folder I don't have rights to make folders and files? How can I fix it? Its WPF app
Or even a list of objects, so that each column is a property. Then query it with LINQ, and save the result back to Excel. How many columns you have?
https://www.reddit.com/r/csharp/comments/8xd673/systemiopipelines_high_performance_io_in_net/
Nobody had really mentioned any functional languages when I posted that, but yeah I would agree. They feel very different to use.
Seriously? Its perfectly readable. People sure are spoiled about stuff like this these days. Never would have made it on usenet. &lt;insert more old man rambling here&gt;.
This is correct, and the way to get around it is to write a wrapper method that takes a key and the `params`: void InvokeIt(int key, params string[] stuff) =&gt; cache[key](stuff); You can even make it an extension method with generic type parameter.
Iâd willing to bet the string isnât handling the path correctly. Maybe not adding the extra slashes for instance. The first method may be handling this. Debug and check and also use the immediate window while on a break.
Also are you running these one after the other without closing the file?
Could you give me some runnable code that shows this? I'm very new to this topic. 
Spoiled? It's called standard quality. I'm offering helpful criticism, since well-formatted snippets are an absolute standard among all blogs I've read over the past few years. You're giving me the impression that if you upload a blogpost you're entitled to eternal, unquestioned appreciation. I'm doing OP a favor.
Excuse me? This blog looks like crap and you're suggesting \*\*I\*\* am the one that should spend time configuring a fucking Tampermonkey script? That is completely backwards. OP wanted constructive criticism; I gave it. You're making it sound like it's my responsibility to properly format his blog lmfao.
Or just provide a sensibly formatted default style that doesn't use proportional fonts. Are you people all crazy? Is this some kind of organized troll?
Pastebin is blocked in some countries (because it is used for a lot more things than just code) so I always try using Gist. 
Honestly, if you *understand* an algorithm (the type of problem it solves, how reaches the solution, and what the complexity and costs are) and know *when to apply it*, there's nothing to "practice". There's really only two parts to algorithms: 1. Understanding and identifying the type of problem it solves so you know when it's a possible solution, and 2. Understanding the way it arrives at a solution and the complexity costs associated with the algorithm so you can make an educated decision about which fits best. In my experience, people most often struggle with the second point. Sorting algorithms are a classic example: most people just use whatever default sorting method they have, or the one they remember, or the first result in google for the search "best sort C#". However, they don't fully understand the sorting method and it's cost, so they may pick a sort that is less optimal for the data they're working with. In the .NET Framework Class Library, for example, Array.Sort() uses a hybrid sorting algorithm known as an [Introspective Sort, or *introsort*](https://en.wikipedia.org/wiki/Introsort) (prior to .NET 4.5 it used a simple [QuickSort](https://en.wikipedia.org/wiki/Quicksort)). One of the reasons this was introduced was because many programmers simply used the Sort() method everywhere, assuming it was of average or better efficiency, which in reality it was very *inefficient* in many situations. 
Take your styling preferences, codify them, them explore the fucking internet, now shit looks how you want it to look, yay no more complaints. if only...
Great answer, going to focus more on the theory as well now. 
Ninjacoder must be an ironic name.
You can also speed it up even faster by copying the data to a 2D array, iterate over that array, and then save the package back with only the good data. On movie right now, so I can't really give you a good example, but I'll try to fill something in later. Think of a 2D array as a matrix, where the first dimension is the row, and the second dimension is the column. Therefore if you wanted to access row 1 column 9, you would do: var column = array[0][8]; // because arrays start at 0 The reason I say that you might want to go the 2D array route is because as the number of rows get larger, the longer it takes to read. The way it's done above, you are doing individual reads to the file every time you access sheet.Cells[row, 9].Value. This access is extremely slow vs reading the sheet in its entirety in one go. For reference, I was working on something and was reading 12k rows, which ended up taking up to a few minutes doing individual access. Entire read took less than a second.
Here's what came to mind for me, w ithout knowing the context or how things could be refactored. this would replace your current "activities" assignment text. You can create a Regex instance once and re-use it for each test rather than calling the static method for each call, which reduces the amount of extra and repeating arguments that need to be specified in the code. Since the tests are all the same, and you just want to see if any are true, you can create an array and then use Any on that array to evaluate for each test string: Regex re = new Regex(regex,RegexOptions.IgnoreCase); activities = activities .Where(x =&gt; new String[] { x.Text, x.Account.lastName, x.Account.firstName, x.Account.organization } .Any((a) =&gt; re.IsMatch(a))); eg. You want activities where any of these string values from the activity are a regex match to the previously defined regular expression. 
Hey!!! This, I really like! 
That *is* runnable code, when `cache` is an `IDictionary&lt;int, Action&lt;string[]&gt;&gt;`. 
If you haven't already, you need to set up powershell remoting on the remote system.
Thanks. I connect to this server all the time in PS so Iâm positive that works.
99% of the blogs I come across have defaults that look good. If you think wanting a *monospaced font* for code snippets is being picky, I have no words. If your blog looks like that at least don't complain if it ends up dying.
I know you're looking for a tiny resource, and I've got nothing there, but if you change your mind and want something more full sized, The C# Players Guide by RB Whitaker is pretty great. He's got a lot of C#/MonoGame tutorials online for free as well, so if you're interested, check that before thinking about the guide (just to see if it clicks with you). Good luck with that pocket guide tho.
hey, thank you for the suggestion i'm at the moment doing an online tutorial on udemy which i was suggested by a friend of mine for c# in unity, once i've completed this i'll likely check out a full sized book so i appreciate the comment and i'll look into it! i just really like the idea of a book which would have a list of variables and what they do specifically, I see there are books called # 'C# 5.0 Pocket Reference: Instant Help for C# 5.0 Programmers' which go from 1.0-7.0 i believe, which is small based on references, but aren't sure where to start. i guess this is where i'm misunderstanding perhaps.. there's a 7.0.. would 7.0 be the most up to date version of what's possible with c# or would i start from 1.0..
DON'T START WITH 1.0
Sry, had to make sure you saw that. C#'s version numbers refer to what build it's in, and with each new version, things get better optimized, new libraries of helpful tools get added, and some behaviors get tweaked. There is no reason to code in anything but the current version if you're learning. And, if you still want to start lower down, then don't go lower than 4.5. XP has 4.5 support (I'm pretty sure). Everything that supports C# that you'll likely ever need has 4.5 support. + C# got a big facelift at 4.0 and really well refined at 4.5. I'd say go for whatever the current stable release is (I think it is 7.something), but if not, you want 4.5.
BTW, I'd suggest just checking Microsoft's online documentation whenever you have a question. Just search "c# (whatever thing here)" and you'll be able to get great explainations straight from the horse's mouth.
Ah i see, thank you so much for clarifying this!
Ahh I see. I didn't realize what the lambda did until now 
Be careful with this advice, there is significant value in creating tests within your solution that are called "integration" or functional tests. These can hit the endpoints and are valuable, if just as a sanity check. Integration tests have a much larger scope, so you need a lot less than your unit tests. 
Real programmers use no indents and write everything in a single line /s
To use C# .net effectively it takes years because the framework is crazy huge and gets improved all the time. (My opinion!) Furthermore to use it effectively for this specific company you would need to know what .net Version they are currently using because in my company we never directly upgraded to the latest version. Mostly I am still working with 4.0 so I don't think they will go that deep into the details. When you talk about 'focused on problem solving' it sounds for me like you should more look on how to use VisualStudio probably because this will be your main working tool and can be a pain if you don't know how to take the best out of it, but even here is the problem which version is the company using? But using the latest one could also be a benefit because you could be the guy to bring it into the company (maybe). When it comes to the differences I think you go well with this: [https://hackerbits.com/programming/top-10-differences-between-java-and-c/](https://hackerbits.com/programming/top-10-differences-between-java-and-c/) But I would not recommend to try to sell yourself as a C# pro when you are really new to it, just be honest. Wish you the best for your interview!
No "principle" can help you if it is so vague that you can always claim to be following it.
My point is that to not read the article simply because you donât like the way the code is formatted is ridiculous.
While it is interesting to read about topics like these, I'm going to have to side with you on the naive attempt at styling code. The surrounding div is inline styled with Consolas and since you don't see a monospaced font, I'm going to assume you're not viewing this on Windows, haha. Each line of code is in its own paragraph tag (there's your 1.5+ line spacing), and the container has no attempt at line numbers. So yeah. Content is worth scanning. Site is shit. 
Here is a book recommendation for technical prep: https://www.amazon.com/Adaptive-Code-via-principles-Developer-ebook/dp/B00OCLLYTY And here is a great article on salary negotiation: https://www.kalzumeus.com/2012/01/23/salary-negotiation/ Good luck on the interview.
I agree. However - the article is actually well worth reading. Worth powering through the formatting to learn something which is (for me, at least) new and interesting.
Yo mama
You aren't using Excel functions (formatting, formulas etc), but rather database functions (CRUD: create, read, update, delete) so I would recommend using database tools. In your case OLEDB which would be way faster than using Excel interop. I have only used OLEDB (plus Dapper) to do reads from an Excel file myself, but since you'd be treating it as a data source you might be able to just use a delete statement to remove the lines you want without actually reading the file yourself.
Yep, that's the three :) The easiest way to handle deletes in a two dimensional array is to make it one column wider than you need and use that to store whether the row is deleted. You can then count the undeleted rows, create a new array and copy the good rows into the new array. This has consequences because that will be two big arrays and you will end up on the large object heap. Alternatively use a List of rows (arrays) and you can delete the row and the use ToArray at the end which will give you a [][] (rather than a [,] ) It would then be simple enough to clear the entire range and paste the new data in. I believe, from memory that you can paste from an array into a range directly, but I can't remember whether that's a [][] or a [,]. If it's [,] then you can probably still do it row by row from the List and just paste each []. Finally you can use a [][] and swap the rows, moving the deleted ones to the end and then use Array.Resize, or something similar to trim off the dead ones. In case the brackets look weird: [] is a single dimension array. I.e. int[5] has five ints starting at 0 and going up to 4. [][] is an array of arrays (or Jagged array). Each row is a separate array and can have different lengths to the other rows. [,] is a two dimensional array and each row has the same number of values. This is the classic grid style array, but as mentioned, can cause memory issues if it exceeds 86k in size (that's bytes not items!) 
Oh god, have you heard of pastebin?
I don't have a book that you could use for this but you have just said 2 things which will fuck you over if you try to do both "I'm a begginer" and "dive straight into deep learning" get comfortable with the language before doing things like deep learning.
How do you expose the view model factory to xaml? I see you see its type in resources, but what do I do in App.xaml.cs to expose the actual instance of the factory? &lt;App.Resources&gt; &lt;local:ViewModelFactory x:Key="Factory"/&gt; &lt;/App.Resources&gt;
It sounds like a standard foreach loop would be better suited and more efficient, though your requirements aren't exactly clear and your code doesn't really match what you're saying. P.S. using Find like this is dangerous as if the productId exists more than once in the list only the first would be modified.
no you retard, you have the choice of changing what you don't like to what you like. On who upvoted me
I cannot reproduce the result shown here. Could someone else try? I downloaded [his project](https://github.com/NicklausBrain/GpGpuViaCs-2018) and installed CUDA 9.2. These are my results in Release mode: TPL: 00:00:00.2565923 AleaGPU: 00:00:00.3024662 ILGPU: 00:00:00.2975500 Here it looks like TPL is faster than the GPU alternatives. The results presented by the article: TPL: 00:00:00.737472333 AleaGPU: 00:00:00.4567708 ILGPU: 00:00:00.410849867 My hardware: * CPU: Intel 7700K * GPU: GTX 1080Ti.
Thats a real cool project you got there! Sadly I don't have any projects to showcase yet, but that's alright cause the site is representing us dutchies enough already ;)
Thanks :-). No worries. Just submit whenever you got something you want to show. Dutchies FTW!
This is at fault.. while (menuChoice == 1) { inputHouseholdInfo(); } it leaves the method but menuChoice is still 1. This should fix it. while (menuChoice == 1) { inputHouseholdInfo(); menuChoice = 0; }
Will do!
Thank you! Will try it in the morning!
For mostly historical reasons, more so than any other platform, most C# and [VB.NET](https://VB.NET) projects are private and/or require authentication. I wish there was a way to showcase private work in a semi-anonymized way. I am using Angular 6 with Angular Material together with [ASP.NET](https://ASP.NET) Core 2.1 on some internal projects, but I don't think there is an effective way to show off such projects when the authentication is tied to an organizational authentication scheme.
&gt; I don't think there is an effective way to show off such projects when the authentication is tied to an organizational authentication scheme That is a valid point. Personally, I can't see any straightforward way around that as well atm.
Although you could just submit your project with a screenshot and nice description, but without a public link. The public link is nog mandatory.
You are right. I did read it actually. Otherwise I wouldn't have made my comment in the first place.
CLR via C# will teach you some really good low level stuff. I reference it daily. https://play.google.com/store/books/details?id=36tCAwAAQBAJ&amp;source=productsearch&amp;utm_source=HA_Desktop_US&amp;utm_medium=SEM&amp;utm_campaign=PLA&amp;pcampaignid=MKTAD0930BO1&amp;gclid=CjwKCAjw7cDaBRBtEiwAsxprXWJwqlHllBqfgZfaDkXpHO6kmCksR3fgrsC1GZmkFtsD9XkGZXbZqBoC6MAQAvD_BwE&amp;gclsrc=aw.ds&amp;dclid=CKLImuH_qtwCFYyOswodOLkARw
 if (Regex.IsMatch(Text, regex, RegexOptions.IgnoreCase) || Account.IsMatch(regex)) return true; return false; Ewww
Thanks, I think I'll use this! I'll try to find the location of the window with .Left and .Top, I think there's a way...
There is a difference between changing the internal model to using Roslyn and supporting Roslyn analyzers. Doing the former, would theoretically allow for better performance, but is practically far from being feasible. However, Rider shows that ReSharper and Roslyn analyzers can live side-by-side without degrading performance so much, thanks to itâs architecture.
Here's what you do: 1. Download ReSharper 2. Reformat your code so humans can actually read it 3. Try pasting it somewhere again so the people you're begging for help can actually read the fucking code.
How does this compare to [https://discoverdot.net/](https://discoverdot.net/) ?
The main difference is that discoverdot.net is more of an automated news and open-source aggregator. Builtwithdot.net focusses more on "projects in the wild". Although there will be some overlap when talking about open-source projects for example.
Excelent project. Take your upvote
 This seems like a TLS version error to me. Make sure you are targeting .net 4.5 or higher or have the appropriate patches installed for earlier .net versions to support TLS1.2. Then try changing this: ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls | SecurityProtocolType.Tls11 | SecurityProtocolType.Tls12; to this ServicePointManager.SecurityProtocol =SecurityProtocolType.Tls12;
Where are you injecting the dependency for "ILogger"? You should avoid the compiler directive as much as possible. You can do something like this https://blogs.msdn.microsoft.com/kaushal/2013/05/22/http-to-https-redirects-on-iis-7-x-and-higher/ #if !DEBUG filters.Add(new RequireHttpsAttribute()); #endif
Ugh, solved it, can't believe it was so obvious but I just had to turn customErrors off in system.web &lt;customErrors mode="Off" /&gt;
I should have mentioned that it isn't a DI problem because I was having the same issue just newing up the logger. As far as the compiler directive, they're only really used in the config classes that get registered in App_Start. We have a service that gets DIed we can use inside the app itself. I actually prefer this approach over using the rewrite rules it just seems more compact/elegant.
At the very least, has he heard of reddit formatting? lol.
Instead of integers, you could also use an enum to aid in readability and maintenance: public enum MenuChoice { Invalid, InputHouseholdInfo, DetermineAssistance, DisplayHouseholdInfo, Exit } In order to get the enum from the integer that was input by the user, you'll cast it: MenuChoice selected = MenuChoice.Invalid; //you should try parse to validate input //and you should parse it to an int instead //of a double if (Int32.TryParse(Console.ReadLine(), out var numChoice) { selected = (MenuChoice) numChoice; //the cast } switch (selected) { case MenuChoice.InputHouseholdInfo: ... ... default: //if this is reached, then they entered an invalid menu option (like 0, 1.23, "foobar", etc) Console.WriteLine("Invalid menu option entered. Please enter an integer between 1 and 4."); //since we don't set the flag to true, it will prompt the menu again break; } And there we have it.
This is also my preference.
You're basically doing this: int i = 42; var obj = int.Parse(i.ToString()); You already have a collection of the data you want to modify, why throw that away by transforming it to its ids only, just to get the exact same object later (inefficient and unsafe if there are duplicate ids)? I'm not sure if I'm missing something but a simple `foreach` should be sufficient to solve your problem. foreach (var x in oDetails) { x.imageUrl = "imageUrl" + x.productId; x.productName = "productName" + x.productId; } (written on phone maybe i got some names wrong, but you get the idea) 
Furthermore, if it was just rotation, I can do it based on this:[https://www.codeproject.com/Articles/23257/Beginner-s-WPF-Animation-Tutorial](https://www.codeproject.com/Articles/23257/Beginner-s-WPF-Animation-Tutorial) However, to simulate shaking I want to add several rotations into a storyboard, but when I try to load it into my storyboard (like in the example code of my post) nothing happens
Solved. I just remembered this was fixed in Core 2.1!
Think about the problems they are attempting to solve and you'll have more than just a "vague" idea on when to apply them. They aren't perfect but they aren't as ambiguous as you are making them out to be.
Very cool. Iâve only got a crappy secret Santa app thatâs no longer hosted but Iâll keep my eye on this. 
How do you guys get to always buy a domain for every little site you create? Do you buy them somewhere super-cheap?
I'm tempted to put my F# Language Server on here, but i'm not quite sure how to show that off in screenshots! Also, I don't have a twitter handle, but linking to my github profile would make sense I think.
Sorry to bother, but what DNN stand for?
Hi, it seems like your answer is usually the fix in this case but when I added all security protocols I'm still getting the error :(
Not sure if I'm understanding you correctly, but you want to make sure you only use TLS1.2, don't try to use anything else.
Screenshots are not mandatory... But they do help to make the site a bit better looking :-). What meta category are you missing on the site that you would consider your project to part of?
I guess Tools/Tooling? It's an implementation of [https://langserver.org/](https://langserver.org/) for a niche language, using F#. It's technically a Console app, but it has no CLI. I'm not sure. What category would you say nuget.exe itself falls under? Or [http://www.omnisharp.net/](http://www.omnisharp.net/)?
âDeveloper toolsâ?
âDeveloper toolâ?
âDeveloper toolâ?
Sounds like "you will understand the principles when you understand the principles".
Ohhhhhhh gotcha, ok I changed it to just use TLS 1.2 and still throwing the error.
Ohhhhhhh gotcha, ok I changed it to just use TLS 1.2 and still throwing the error.
What does the crash report say?
That's it above :) XAML is just objects in XML, so the above says: There's an object of type App which has a property called Resources (which is a dictionary because it has a key) And into that dictionary we're creating an instance of ViewModelFactory with a key of Factory. Then in the other bit of code you'll see it binds to the MakeAViewModel property on the instance we declared as a static resource. This is better because you have one App, and lots of Views, so this way you have one Factory. In the view itself autocomplete will find the App's resources for you, so you should be able to do something like: &lt;Window .... DataContext={Binding Path="MakeAViewModel", Source="{StaticResource Â¬Â¬Â¬:Factory}" ... /&gt; What goes in Â¬Â¬Â¬ is the namespace alias for the path to app, similar to xmlns:local="clr-namespace:WpfApp1" My test app only had stuff in the root namespace of the WPF app, so actually that *local* namespace would have worked :) Does that make sense? I'm not at Visual Studio right now, otherwise I'd knock up a little example in there. It's all muscle memory to be honest, It's hard to do it without my fingers moving over a keyboard ;) 
I always forget as there are a few different relative positions, but [This stackoverflow](https://stackoverflow.com/questions/386731/get-absolute-position-of-element-within-the-window-in-wpf) seems to cover most of them :) 
DNN - DotNetNuke - a web application built on ASP. [https://en.wikipedia.org/wiki/DNN\_(software)](https://en.wikipedia.org/wiki/DNN_(software))
Looks like you posted a wikipedia article, let me summarize it for you... Click [here](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) if you'd like me to stop bugging you. ***** **[DNN (software)](https://en.wikipedia.org/wiki/DNN_(software))** &gt;DNN is a web content management system and web application framework based on Microsoft .NET. The DNN Platform Edition is open source. ***** **^([)** ^([About](https://np.reddit.com/r/ultimatewikibot/wiki/index)) **^(|)** ^([Source code](https://github.com/brrm/ultimatewikibot)) **^(|)** ^(Downvote to remove) **^(])** 
This is nice!
What framework version?
It's .Net 4.5
a quick google suggests: * uninstall/reinstall dotnet core itself * peek at `~/Library/Logs/VisualStudio/7.0` * try to be less snarky, as frustrating as bugs may be. 
See [this ongoing thread](https://www.reddit.com/r/xamarindevelopers/comments/8zmo6b/does_anyone_else_find_vs_for_mac_unusable/), it's a shitshow and has been getting progressively worse over the past few months. The current best workflow I've found is to use VSCode for writing code, and only use VS for Mac if you are compiling. Features that don't currently work: * Intellisense * Refactoring * Quick fixes * Syntax highlighting
Google domains. I get both of mine for $12 dollars/each per year. 
I've added "Developer tool" as a project category. Does that work for you?
The EPPlus seems to be working pretty quickly, I just couldn't fathom the importing was as easy as "package = new ExcelPackage". I saw 2D arrays mentioned a few times in my search, and I am interested. I was wondering though, how do I get my spreadsheet data imported into an array? I can only imagine building the array cell by cell, something like array[i][j] = cells(i,j).value. I can see how deleting "rows" might work after that, but it's the importing from the spreadsheet, and exporting it back, that I have a hard time visualizing. 
Description that have more than "web app" or "mobile app" would help.
What do you suggest?
Don't run with sharp objects. That's a principle. You can argue about what constitutes running or what is considered a sharp object, but if you don't understand the *why* behind the principle you'll miss the point completely. In this case, don't run with sharp objects *because* you increase your risk of maiming yourself.
It's not a lambda, it's an [expression-bodied method](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/expression-bodied-members), which was syntactic sugar added in C# 6. I think this is what the generic type extension method should look like, although I'm not in front of a C# compiler right now: TReturn InvokeIt&lt;TValue, TReturn&gt;(this IDictionary&lt;int, Func&lt;TReturn, TValue[]&gt;&gt; dict, int key, params TValue[] stuff) =&gt; dict[key](stuff);
I would suggest that people provide a sensible description of what they made. I'm not going to click on each project to try to figure out what it is.
Good point. Will look into it.
Your site's SSL cert is fubar by the looks of it. Also OpenDNS has you marked as malware.
I had the same thought. We're using .net Core with AWS Lambda and angular on the front end pursuing a DDD appraoch. But there's quite a bit of IP involved and company secret sauce I can't readily share. But its cool IMHO. 
Hm, strange. Using LetsEncrypt for SSL. Will look into it thanks.
Yeah, you donât serialize Actions.
&gt;Finally there is also the option of having two csproj files, one for each configuration. I don't like this approach because most of the time I need to make changes to both. In addition to the approach of having multiple csproj files, it's also possible to have one csproj file that works radically different depending on the command line arguments given to msbuild. As an example of one of the (many, many) things that can be done, using conditionals in the XML of your csproj files can allow you to target different files to compile and build based on command line arguments: in something.csproj: &lt;ItemGroup&gt; &lt;None Condition="'$(PAYTIER)'=='FREE'" Include="app.free.config"&gt;&lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;&lt;/None&gt; &lt;None Condition="'$(PAYTIER)'=='PREMIUM'" Include="app.premium.config" /&gt;&lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;&lt;/None&gt; &lt;Compile Condition="'$(PAYTIER)'=='PREMIUM'" Include="premiumOnlyClass.cs" /&gt; [...] &lt;/ItemGroup&gt; in code, load whichever one exists from command line to build with FREE config settings: msbuild something.csproj /p:PAYTIER=FREE from command line to build with PREMIUM config settings: msbuild something.csproj /p:PAYTIER=PREMIUM
Note that the SSL cert might be my company's security blocking it but normally it gets past the handshake portion. But then again this is the first time I've had it come back as marked for malware. So it could be that the domain was marked as malware by more than just OpenDNS, which is what I checked it with, prior to you owning it. I forget which one our security uses, Google maybe? So you may just want to reach out to some of the DNS/security sites and let them know that they're blocking you.
Ok. Thanks for the update!
Yeah, I have used some conditions like that within my csproj. A lot of this is to have compiler flags in the code. #if FREE DisplayAd(); #ENDIF This will be grey if my project file has PREMIUM as its compiler flag. If I want to view this code with syntax highlighting, I'll have to either go replace PREMIUM with FREE in the settings, create multiple project configurations, or create multiple project files. I am not sure what the best approach is. 
Your foreach is wrong. The values sit provides aren't the indexes, it's the actual values in the enumerable, in turn. Remove NUMBER[j] in the WriteLine and replace it with j.
Removed: Rule 4. You already got an answer, which is probably correct. In the future, include the error message text, the line it's occuring on, the desired behaviour you want, and the current incorrect behaviour it's demonstrating. Also, please indent your code so it's readable on reddit.
&gt; try to be less snarky, as frustrating as bugs may be. This.
Just tried submitting my project and got an error. ## The page you were looking for cannot be served. If you are the application owner check the logs for more information.
you shouldnt, but unfortunately you can
Very interesting. Seems like they should have used a different serialization method.
 &lt;Button Grid.Row="1" Grid.Column="1" Width="50" Height="50" RenderTransformOrigin="0.5,0.5" &gt; &lt;Button.RenderTransform&gt; &lt;RotateTransform/&gt; &lt;/Button.RenderTransform&gt; &lt;Button.Style&gt; &lt;Style TargetType="{x:Type Button}"&gt; &lt;Style.Triggers&gt; &lt;MultiDataTrigger&gt; &lt;MultiDataTrigger.Conditions&gt; &lt;Condition Binding="{Binding YourCheckboxBooleanPropertyOnTheViewModel}" Value="True"/&gt; &lt;Condition Binding="{Binding IsButtonPressedBoolProperty}" Value="True"/&gt; &lt;/MultiDataTrigger.Conditions&gt; &lt;MultiDataTrigger.EnterActions&gt; &lt;BeginStoryboard x:Name="BeginStoryboardName"&gt; &lt;Storyboard&gt; &lt;DoubleAnimation Duration="0:0:1" To="45" Storyboard.TargetProperty="(Button.RenderTransform).(RotateTransform.Angle)"/&gt; &lt;/Storyboard&gt; &lt;/BeginStoryboard&gt; &lt;/MultiDataTrigger.EnterActions&gt; &lt;MultiDataTrigger.ExitActions&gt; &lt;BeginStoryboard x:Name="EndStoryboardName"&gt; &lt;Storyboard&gt; &lt;DoubleAnimation Duration="0:0:1" To="0" Storyboard.TargetProperty="(Button.RenderTransform).(RotateTransform.Angle)"/&gt; &lt;/Storyboard&gt; &lt;/BeginStoryboard&gt; &lt;/MultiDataTrigger.ExitActions&gt; &lt;/MultiDataTrigger&gt; &lt;/Style.Triggers&gt; &lt;/Style&gt; &lt;/Button.Style&gt; &lt;/Button&gt;
Will check it out. Thanks. Currently afk.
&gt; services.AddHttpClient("configured-inner-handler") .ConfigurePrimaryHttpMessageHandler(() =&gt; { return new HttpClientHandler() { AllowAutoRedirect = false, UseDefaultCredentials = true }; }); https://docs.microsoft.com/en-us/aspnet/core/fundamentals/http-requests?view=aspnetcore-2.1#configure-the-httpmessagehandler 
Given that cookies are just another header, I used the header.
Thanks, that lets me pass the cookie container to the ctor of HttpClientHandler, but I'm not sure how to get a reference to it from the HttpClient that gets injected.
The question is: Does this optimization violate the spec (i.e. it's a bug) or not?
submitted!
If you have the text in gridview hide the text, add a asp:template field with a button and then use a row command on the gridview to get the hidden text value then response.redirect to it 
&gt;arr\["targetid"\] = 1; If you have two items that have the same data they will only be stored once in a dictionary , json will be the best bet 
On the one hand, they were relying on compiler internals (knowingly or not). On the other hand, * the toolchain should probably make it harder to accidentally serialize delegates, and * the error message is bad, in that unspeakable names* shouldn't appear, and * the unspeakable name appearing suggests that this use case wasn't deliberated properly. I would suggest filing a bug with the Roslyn project. *) Compiler-generated C# code tends to be prefixed with `&lt;`, which is illegal for third parties to use.
Thanks for the reply man, I just took my hyperlinked text and created a query string and had it paste that information in thorough a text box query string 
FWIW, they still haven't committed to which versions pre-Windows 10 this will run on, and they _have_ stated that this will _not_ deliver full support for `Span&lt;T&gt;`.
This should be fixed now
Read Exam-ref 70-483 Microsoft book, Richter CLR via C#, some blog posts (there are many) on how to prepare for this exam, take some online tests. For experienced developer this exam is quite easy(Iâve got 900+/1000 easily ). 
You cannot, apparently. What do you need it for? Can you inject it as well?
Nope. Still broken. I'm not entering anything unusual. Looks like your validation for the form is broken or something. I can PM you a screenshot if you'd like. 
So you made a production change without testing it locally or even in a model environment? If this hasnât bitten you before now Iâm actually shocked.
Can you give some examples of how you use material? We looked into it a little, but we couldn't figure out any good uses for our app.
Shouldn't make any difference at all. Having tons of files in a directory will definitely slow some operations down (listing folder contents for example). But the file name is a direct access identifier and won't require any iteration.
Interesting thanks!
It would be very nice to have a description of the project when browsing, at least on mobile there isn't one there. Great job!
**Company:** [Homely](https://www.homely.com.au) **Job:** Senior .NET / Back End Developer **Location:** Melbourne, Australia **Allows remote:** No **Visa:** No **URL:** [Apply here](https://www.seek.com.au/job/36591602?type=standout) **Description:** Posting here might be a long shot especially since we are looking for someone who is able to work in the Melbourne office (in Australia) But, if you're interested please have a read of the job description in the URL link above :) I've recently joined Homely as an Android Developer and I can vouch that we have an amazing dev team that's great to work with! Apply in the URL link above or if you have any questions send me a PM.
Just a side suggestion, if it's on a mechanical hdd, doing a defrag might make it a little bit faster. Especially if you have lots of files
Yes, definitely. Even if your direct reads aren't affected, it will cripple other operations. https://serverfault.com/questions/98235/how-many-files-in-a-directory-is-too-many-downloading-data-from-net
I'm a bit old school, but I thought NTFS stored files in a linked list. So to get the the last file, you had to read through the entire list. Am I way to old here? Also, I know that if you open in something like Explorer, it tries to sort the list by filename which will slow rendering down a TON, but this may not effect apps that simply need to open a known filename. 
Hate it when that happens
The NTFS directory structure is stored as a B+ tree, so looking up a file by name is reasonably quick. The tree entry will have the file record number, which is that file's index in the master file table (basically a constant time array lookup). From there, the MFT record will have the file's data runs (where the file data is actually stored on disk).
If you really need to do this, a "better" way is to use more folders, with a digest of the unique filename or identifier: For example, given a filename like this: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.txt ..."split" the filename, and build a tree: C:\datafolder\e3b0\c442\98fc\1c14\9afb\f4c8\996f\b924\27ae\41e4\649b\934c\a495\991b\7852\b855.txt This may be "faster" in some situations. 
Oh hmmm...i'm confused. You are saying that accessing the file with its file path will slow down the read operation? No doubt other operations are affected, but in this scenario I'm really just curious about accessing a file from its file path. If I understand your link correctly, the fellas there were saying that trying to access a file by name would be affected. I don't believe that is the same as accessing a file through its path.
IS looking up a file by name different than looking it up via its file path? In my mind, looking it up by name means searching the directory, as opposed to using the file path with references the file's address on the hard-drive. I'm not sure if I'm receiving conflicting answers from people... and I'm too dumb to know who is stupid.
Questions like this are not well suited to "in theory" answers. Do a benchmark. Computers are weird things, that's the only way to know.
And this is why computer science majors don't get laid in college. 
Today you are interested in accessing it by the file path. Tomorrow when something goes wrong and you need to see a list of files...
I know MVC5 was mentioned above, but if you ever move to .NET Core, those IIS tricks aren't necessarily going to work.
At least they found an integration test they needed to write... ...something the other integration tests had missed, despite the issue affecting âhundrds of classesâ
If you're opening and reading the file based on an absolute path, then no. At worst, the speed at which the file fragment locations are tracked down might be a tad slower but the reading of the file would be unaffected. It also shouldn't matter whether you have a billion files in one folder or a billion folders with one file. That is except for directory enumeration. Defrag of rotational drives may help a little, or a lot. Just depends. Like someone else mentioned, testing is the best way to find out for sure. 
Bug was brought up a year ago: [https://github.com/dotnet/roslyn/issues/20315](https://github.com/dotnet/roslyn/issues/20315)
Yes. Especially in .net. Your fastest option would be to use an interop to this API. https://docs.microsoft.com/en-us/windows/desktop/FileIO/listing-the-files-in-a-directory
My guess is it depends on how much caching is done (I have no knowledge of this layer). Assuming zero caching, you would always start at the root directory, and each directory hop from the root directory would be a O(log n) operation. In practice, I'd assume a frequently accessed directory is certainly going to be cached, allowing you to skip those hops. On old versions of Windows, you'd want to disable 8.3 short filenames, as those would force a linear search of a directory, but those have been obsolete for a very long time.
&gt;go fast and break things. All the things.
Wait I'm less informed of these things. I thought they were only doing new releases with Core?
From what I've seen from the linked release notes, it's mostly bug fixes and some quality improvements. No new features. If you have existing app running and want to know if it will break you, you have the chance to know.
Especially in .Net? Can you explain why that is? 
Sorry sometimes I completely skip the explanation. Take a look at this. https://stackoverflow.com/q/26321366/1146246 Basically the .Net file object is doing a lot more than just getting the file and it slows things down a lot.
Just read Wikipedia. The concepts are simple enough, but the devil is in the details that are learned by experience. You need to carefully plan how to wrap/unwrap (with locks, muteness, semaphores, etc) any and all blocks of code/data/resources/variables that can be accessed by simultaneous threads. In practice itâs tricky because mistakes will manifest as seemingly random and unrepeatle behaviour.
To clarify, this is specifically for Angular Material, which is a library with controls that implement material design and not just the 'material design' spec itself... For internal apps we liked the animations on the form input boxes and buttons and when navigating between tabs using the tab navigation router integrations (we use a lot of route and query parameters to enable next/back and link sharing). The modals and data table controls also save time when they are appropriate (data table can't handle large data sets without using paging). The tooltips look nice too. Its nice to get all of these things for free and wrapped up in a way that works together with Angular without much fuss. It's basically how we would use Bootstrap back on old postback Razor pages, but with more interactivity and programmability available when we want it.
I really like Automapper and it works exactly as advertised, but I have an unpopular opinion: Automaker takes compile-time detectable bugs and turns them into runtime bugs. For my use cases, I've started just adding implicit/explicit conversion methods to my type where I would have used Automapper before. When someone changes part of a class that now makes it unmappable to another type, it's an instant compiler notification instead of a difficult to trace exception a few days later. Anyway, I understand that Automapper has some super fancy use cases that I'm not using it for, but I don't recommend it just to save a few lines whenever you have to unpack an object into another type. 
Do you mean the amount of packages on maven central compared to nuget or the functionality of maven central?
If you're asking how the "button" on screen relates to the Button object... the short answer is that there is no direct connection. The Application is responsible for handling mouse input, detecting which Button (or other view) that it belongs to and calling MouseEvent on that view (which will ultimately invoke your Clicked delegate if you click a button). You can see this in action here: [https://github.com/migueldeicaza/gui.cs/blob/master/Terminal.Gui/Core.cs#L1762](https://github.com/migueldeicaza/gui.cs/blob/master/Terminal.Gui/Core.cs#L1762) I didn't look into how keyboard input is handled, but it stands to reason it is similar.
Joe Duffy - Concurrent Programming on Windows if you want to know how things are working under the hood (you will learn a ton and won't all be about windows). It sounds like you're not looking for not quite such a deep dive though so maybe just the sections on threading/concurrency in the very excellent CLR via C# - Jeffery Richter or C# in depth - Jon Skeet.
Which ones do you use?
That is *way* overkill but you have the right idea. The hash is represented in base 16, so assuming a uniformly distributed hash function there are 16^4 possible combinations for a first-level folder. Given 10M input files that's only ~150 files per folder, which is no problem for performance. Even 10x that per folder would still perform fine, probably.
This was my takeaway too, and why I predominantly didn't use it. I try to be correct by construction wherever possible and AutoMapper is just anathema to that.
Careful OP, with millions of files the B-Tree will get pretty large and directory listings will get really slow. Accessing files *will* also slow since the path lookup will take longer, but as others have said, B-Trees are still fast. The real danger here is index fragmentation. If you add to many files to a directory without defragmenting it, it will exceed the maximum index fragments for that folder, and you'll get into a bad state where the folder can't be defragged, and you can't add more files. Moving or deleting files will become your only option.
When syntax highlighting doesn't even work, what's the point?
Pretty sure somewhere I have Concurrent Programming and definitely have CLR via C#. Recommend them both. Havenât used C# in Depth. 
Please do!
Looking into this. Thanks!
They must work for Valve 
It works, thanks a lot! 
Made some updates. How do you like it?
I've made some updates. What do you think?
&gt; access a file by name would be affected. I donât believe that is the same as accessing a file through its path. It is, or rather, all accesses are by path internally.
what would you test here? we upgraded our build tools and it exposed some behaviour that relied on compiler internals in a few places that we're not under a heavy integration test (as the problem occurred in the pipeline to saving session state in the external provider) the cost of integration testing that deep on a large code base would be very heavy, and manually regression testing an entire system is not feasible on every commit, what would you recommend?
the pattern that could have this problem existed in many, the actual usage (lambda without closure assigned to serializable property) was present in a handful
This is a great idea - I expect we'll get a lot of parsers (CSV, JSON, XML) in the near future that will outperform existing ones. I also expect a lot of bugs to start with so, you know, *caveat emptor*... :/
Move without a destination folder does a rename. As far as I know, it shouldn't work if the destination file already exist - so you shouldn't have vanishing files, just renamed ones.
File.Move in System.IO is well documented [here on MSDN](https://msdn.microsoft.com/en-us/library/system.io.file.move(v=vs.110).aspx). Reading from that documentation, the method accepts both absolute and relative paths. In the event no absolute path is provided, the current working directory is used. You can obtain the current working directory with System.IO.Directory.GetCurrentDirectory().
[this one is short and sweet and free](http://www.albahari.com/threading/) from the author of C# in a nutshell. It's sufficiently detailed that you'll get a grasp of the fundamentals.
Skeet (C# in depth) is a great writer. 
Thanks, I should have read the documentation more carefully. I suspected that relative file names may have been at play but had two different projects opened and was looking in the wrong directory!
Glad my google-fu could help you :)
You should read up on data structures in C#, but following your current layout, assistanceNeeded should be an array too, like the other household variables, and each element should be set the same as well. 
I always found it very difficult to benchmark high-performance CSV parsers, because there is no canonical API. The DelimiterSeparatedTextParser from OP constructs a `List&lt;List&lt;(offset,length)&gt;&gt;` of cells ; the FastCsvPackage exposes an enumerator-like object that exposes individual cells as `string` ; other parsers allow mapping columns to the fields of a class, and create one instance per line... If you're talking about high-performance, you need to consider what the rest of the processing will look like, and pick an API that gives you data in the best format for that processing. An `IEnumerable&lt;MyClass&gt;` or even an `IEnumerable&lt;string[]&gt;` probably won't be the right choice. A method like `int Read(Memory&lt;MyStruct&gt;) ` is better (no memory allocations, everything is packed tight together), but maybe instead a family of overloads`int Read&lt;T1,T2,T3&gt;(Memory&lt;T1&gt; m1, Memory&lt;T2&gt; m2, Memory&lt;T3&gt; m3)` where T1..T3 are primitive types (`float`, `int`, etc) is even better. Parsing numbers or dates also takes time. Decoding UTF-8 to `string`, too. Are there any tricks that you can use ? Maybe a better benchmark example would be: struct Product { public string Sku; public string Category; public float BasePrice; public float PromoRate; } struct PriceChoice { public string Sku; public float Price; } Product[] products = ReadProductsFromCsv(); var top3Categories = products .GroupBy(p =&gt; p.Category) .OrderByDescending(g =&gt; g.Count()) .Take(3) .Select(g =&gt; g.Key) .ToArray(); // Apply promo to top 3 categories PriceChoice[] choices = products .Select(p =&gt; new PriceChoice { Sku = p.Sku, Price = top3Categories.Contains(p.Category) ? p.BasePrice * p.PromoRate : p.BasePrice }).ToArray(); WritePriceChoicesToCsv(choices); Now, make this code run as fast as possible on a 4GB UTF-8 CSV non-seekable stream (because `GZipStream` is non-seekable, and a 4GB CSV file will usually be a `.csv.gz`). You're allowed to change everything, even write things to a local SSD, only the contents of the output CSV matter. Bonus benchmark category: using less than 100MB working memory. 
Heh, yeah :-) It's been a while since I've had to do something like this, but I've had to do it back in the day on a few projects. If I recall, it was where we needed to stash arbitrary files into a cache-like structure. And as it was on Linux, we couldn't simply dump them all into the same directory. I seem to remember that things got weird and slow after a couple of thousand files in one directory. Oddly enough, the files themselves were being referenced from a database anyway. If the files generate good hashes for names, then you get a good, even spread. Realistically, if the files are small, and contain only textual data, a proper database is better. Or at the very least, some sort of proper repository.
Configuring all the maps on startup and a call to AssertConfigurationIsValid will cover those scenarios. Not as great as compile time errors, but should catch the obvious ones. It'll also catch issues manual mapping would miss like skipped properties. Issues you are describing sound a lot like what would pop up if you were using AutoMapper in the really old static config and probably even creating the maps automatically. It's come a long way since then.
&gt; I am honestly afraid to touch it and mess it up You need to be able to muck around with it to learn. You can do that safely if you use some kind of source control. Visual Studio Online is one easy way to get that. If you've got time you should look at using source control, it's a skill you'll definitely need in the real world, though sadly College/Uni doesn't seem to teach it. Failing that you can always use good old copy and paste (to keep a copy safe somewhere). You mustn't be afraid to try things.
And he should take a look on unit testing beside the suggestion of r/damonous I really would the build the housholds as objects
Removed: Rule 4. You may have to provide more context as to what you're testing, and ideally also let us know which ones you've tried or dismissed and why.
I've tried wrapping my head around mvvm, but I failed. I can get the desired behaviour by changing styles of my buttons during runtime when user checks the checkbox but this is far from an elegant solution. Do you think something like this could work instead?: &lt;Style TargetType="{x:Type Button}" x:Key='Shaker'&gt; &lt;Setter Property="RenderTransformOrigin" Value="0.5 0.5" /&gt; &lt;Setter Property="RenderTransform"&gt; &lt;Setter.Value&gt; &lt;RotateTransform /&gt; &lt;/Setter.Value&gt; &lt;/Setter&gt; &lt;Style.Triggers&gt; &lt;MultiDataTrigger&gt; &lt;MultiDataTrigger.Conditions&gt; &lt;Condition Binding='{Binding RelativeSource={RelativeSource Self}, Path=IsPressed}' Value='True'/&gt; &lt;Condition Binding='{Binding ElementName=ShakeButton, Path=IsPressed}' Value='True' /&gt; &lt;/MultiDataTrigger.Conditions&gt; &lt;MultiDataTrigger.EnterActions&gt; &lt;BeginStoryboard&gt; &lt;Storyboard TargetProperty="RenderTransform.Angle"&gt; &lt;DoubleAnimation From="0" To="5" Duration="0:0:0.05" AutoReverse="True" FillBehavior="Stop" /&gt; &lt;DoubleAnimation BeginTime="0:0:0.05" From="5" To="-5" Duration="0:0:0.1" AutoReverse="True" FillBehavior="Stop" /&gt; &lt;DoubleAnimation BeginTime="0:0:0.2" From="-5" To="0" Duration="0:0:0.1" AutoReverse="False" FillBehavior="Stop" /&gt; &lt;/Storyboard&gt; &lt;/BeginStoryboard&gt; &lt;/MultiDataTrigger.EnterActions&gt; &lt;/MultiDataTrigger&gt; &lt;/Style.Triggers&gt; &lt;/Style&gt; How could I Bind to my checkbox, which is on a different view/xaml file?
&gt; I also expect a lot of bugs to start with so, you know, caveat emptor... :/ Well, lots of stuff inside of .NET Core 2.1 has switched to start using `Span&lt;T&gt;` internally, so it's already being put to use in a major way. The preview "fast span" in 2.0 did have [at least one code-gen bug](https://github.com/dotnet/coreclr/issues/16470)... I ran into this in one of my first serious attempts to use `Span&lt;T&gt;` to speed up some algorithm (I'd been playing around with it for [over a year](https://github.com/airbreather/AirBreather.Common/blob/b2a2d69c084f4bf9a941592ef6ac973bd3eaf847/Source/AirBreather.Common/AirBreather.Common/Danger/MyImmutableArrayExtensions.cs#L27-L39) at that point, though, heh).
It really depends on the file system. IIRC on NTFS or FAT 32 the answer is yes. On Ext2/3/4 the answer is no. I used to work for a company who's SVN repo took 45 minutes to check out on Windows and 30 seconds to check out on Linux.
A streaming interface aka pull parsers like the one used here, is very fast. But once you start talking trees like JSON and XML, things get a lot more complicated and a lot slower fast. XML is in a bit different boat, you can implement a small subset fast, the rest only gets more and more difficult to do and hence slow. Slices aka what Span is, won't create bugs by itself. Experience on the other hand says, it prevents it :)
When you create the button with your intent, then it is "that" button and your event handler should match that intent: var myOpenDialogButton = new Button(); myOpenDialogButton.Click += myOpenDialogButtonClicked; void myOpenDialogButtonClicked() =&gt; this.OpenSomeDialog(); win.Add(myOpenDialogButton, ...);
&gt; I believe that OP's improvements over the libraries of today are actually coming from the shortcuts it takes. e.g., it doesn't appear to handle quoted fields (quotes should be stripped, and delimiters / line breaks inside quoted fields should be ignored... this REALLY REALLY MATTERS when embedding a floating-point value on, e.g., de-DE). Yup, this. It also probably assumes that all text is one-byte. Good luck with variable-width encodings like UTF-8. That's not relevant for machine-readable strings, but add a human-readable product name, a comment/description field, etc., and oops, your naÃ¯ve parser just broke.
I need to pass some cookies in the request, passing them as a header works.
Ya, that helps. LOLs: https://builtwithdot.net/project/15/bf-for-wp 
Arithmetic operations on types smaller than an int result in the them being widened to an int for performance reasons. Processors have fast native operations that do 32bit calculations very quickly. For example, when you try to add two bytes together, you are actually adding two ints together as the bytes are cast to ints before the addition. The == operator is no different; for performance, the two bytes are cast to ints before being compared.
Primitive values generally compare equality with a `ceq` instruction (the compiler knows the `==` operator for two bytes and replaces it with a specific instruction). MSIL keeps track of the size of the int datatype (`uint8` in this case) so the final x86 machine code for a method like public static bool M(byte a, byte b) { return a==b; } becomes: C.M(Byte, Byte) L0000: and ecx, 0xff L0006: and edx, 0xff L000c: cmp ecx, edx L000e: setz al L0011: movzx eax, al L0014: ret IL is: .method public hidebysig static bool M ( uint8 a, uint8 b ) cil managed { .maxstack 8 IL_0000: ldarg.0 IL_0001: ldarg.1 IL_0002: ceq IL_0004: ret }
Sure it can be quick, however you are saying that it does use the System.Int32 which still costs more resources.
Personally, I only use Microsoft's recommended rules, as well as a few extra rules that we've made ourselves. So I have no suggestions.
ChurchOfTheNewEpoch said that it actually uses System.Int32, which I myself initially assumed to be the case sadly. But are you telling me the oppossite or do not understand your answer. Because you are saying that it uses the actual size of the byte datatype (UInt8)? So what is it, please explain in a noob-friendly manner. I don't know what ceq instructions are, nor what MSIL means and also machine code, and IL is far beyond my knowledge.
Yavapai College is looking for a Full-Stack Web applications Developer with a strong background in .Net MVC. I'm one of the current devs and can answer any questions about work environment but in short it's a great group of bright people and if programming is your passion you will enjoy this position. Go ahead...apply....here are the links for more official information: [Yavapai College Homepage](https://www.yc.edu) [Information Technology Department Homepage](https://www.yc.edu/v5content/information-technology-services/default.htm) [Job Description Link #1](https://www.governmentjobs.com/careers/ycedu/jobs/2112724/applications-developer?category[0]=IT%20and%20Computers&amp;sort=PositionTitle%7CAscending&amp;pagetype=jobOpportunitiesJobs) [Job Description Link #2](https://agency.governmentjobs.com/ycedu/job_bulletin.cfm?jobID=2112724&amp;sharedWindow=0)
Not sure what 'item' is and that would be useful to know what exactly is happening. This code worked for me though. `myNestedDict.Add(1, new Dictionary&lt;int, string&gt; { { 0, "" } })`
'new' up the nested dictionary separately (on it's own line). var theActualNestedDict = new Dictionary&lt;int, string&gt;(); theActualNestedDict.Add([item.id](https://item.id), item.heading); myNestedDict.Add(1, theActualNestedDict);
Unless you are working on a microprocessor, the extra resources consumed won't make a dent in your system. That is why speed is prioritized. 
The casting operations might result in the creation of two more ints on the stack, so yes, you would temporarily have an extra 8 bytes of memory used. Alternatively, IL/CLR magic may just put the bytes straight into cpu registers, in which case there wouldn't be increase memory usage.
Why should the operation be any faster than the same operation on a smaller datatype? I just think that this way it would only lower the potential of the available resources. However the comment from the user tragicshark below seems to tell the opposite, do you have anything to add there to help me decide which answer to accept? Because at the moment I'm guessing that you are correct, however I hope you aren't. xP
&gt; I believe that OP's improvements over the libraries of today are actually coming from the shortcuts it takes. e.g., it doesn't appear to handle quoted fields (quotes should be stripped, and delimiters / line breaks inside quoted fields should be ignored... this REALLY REALLY MATTERS when embedding a floating-point value on, e.g., de-DE) I'm actually not convinced on this. I agree that it's important for any "real" CSV parser to handle these things, but I don't think it would make it 2x or 3x more expensive (the perf of the next fastest reader I found). It may make it a little more expensive for the extra equality checks, but even then only the first character in the value would need to be checked, not the whole value. I'd still need to go char by char, and keep some small stack state for whether I was currently inside a quoted string or not. Handing quotes actually might force me to optimize a bit more. Currently I'm scanning the whole content twice as I'm scanning for the record-delimiter, then slicing off that record and scanning again for distinct values. So if I just scan once and keep that small amount of state on the stack to figure out where I currently am, it may be a net win, or at least similar performance to the current impl. I think the main way that my current impl is cheating is that the entire content needs to be loaded into memory already. So it couldn't handle a 100GB file, while some of these other libraries certainly could. But that's why I'll be looking at using System.IO.Pipelines next :)
&gt; It may make it a little more expensive for the extra equality checks, but even then only the first character in the value would need to be checked, not the whole value. How would you check for multi-line quoted text without seeking ahead, which will significantly impair performance?
Machine code is the stuff a processor executes. It is actually raw bytes that have particular meanings but it is extremely rare for anyone to deal with it at that level. Instead most of us look at "assembly instructions" which are human readable instructions that map to this machine code. On x86 (the most common processor architecture used by .NET) the machine code is represented by assembly instructions targeting a "register machine" which means the instructions interact with registers of a defined size to perform whatever task they represent. For example `and ecx, 0xff` performs a bitwise AND operation between the value in the `ecx` register and the value `0xff` then stores the result in the `ecx` register. Since these registers have defined widths, you must use different registers for 8 bit operations vs 16 bit vs 32 vs 64 vs ... or have some other mechanism to keep track of what you are doing in the language. MSIL (MicroSoft Intermediate Language) aka CIL (Common Intermediate Language) is the bytecode language that all .NET code compiles to. It is then turned into machine code by the CLR (Common Language Runtime) in a process known as JIT compilation (Just In Time). The CLR is a stack based virtual machine and MSIL is sort of an assembly language designed for this environment. MSIL instructions mostly resolve around pushing and popping operations on "the" stack. For example `ldarg.0` is an instruction to load argument 0 to the method onto the stack. `ldarg.1` similarly loads argument 1 onto the stack. The language describes parameters as having types and the runtime keeps track of what type is in what position on the stack so the same instruction `ldarg.0` is used regardless of what type the parameter is. `ceq` pops the top 2 values from the stack and compares them then pushes the result back on the stack. 
You'll note that in the real X86 instructions (the stuff that runs on your real cpu), the values are being handled in 32 bit registers - eax, ebx, ecx, edx are the 32 bit versions of the a, b, c, d registers.
Like the base comment said, processors can perform operations faster with integers than with bytes. So the fastest way is to throw it in an empty 32/64 bit register, depending on if the processor is 32 or 64 bits. The alternative, performing the operation as bytes, would mean the processor would put the byte in a register shared with other bytes. Performing arithmetic in that case takes longer, since it has to isolate parts of the register instead of performing it on the entire register. 
It's because operations like addition, subtraction, multiplication, etc are performed by actual physical hardware. That means that if your ALU (https://en.wikipedia.org/wiki/Arithmetic_logic_unit) operates on 32bit inputs, sending it 8bit inputs doesn't make any difference. Basically, you have no choice. Try allocating a byte and an int you'll notice you're consuming the same amount of memory.
Looks like you posted a wikipedia article, let me summarize it for you... Click [here](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) if you'd like me to stop bugging you. ***** **[Arithmetic logic unit](https://en.wikipedia.org/wiki/Arithmetic_logic_unit)** &gt;An arithmetic logic unit (ALU) is a combinational digital electronic circuit that performs arithmetic and bitwise operations on integer binary numbers. This is in contrast to a floating-point unit (FPU), which operates on floating point numbers. An ALU is a fundamental building block of many types of computing circuits, including the central processing unit (CPU) of computers, FPUs, and graphics processing units (GPUs). A single CPU, FPU or GPU may contain multiple ALUs. [Image](https://upload.wikimedia.org/wikipedia/commons/0/0f/ALU_block.gif) ***** **^([)** ^([About](https://np.reddit.com/r/ultimatewikibot/wiki/index)) **^(|)** ^([Source code](https://github.com/brrm/ultimatewikibot)) **^(|)** ^(Downvote to remove) **^(])** 
x86 processors (intel/amd) are designed to do many 32 bit operations directly in hardware in parallel on 32 bits (or even up to 512 bits for some operations). Due to that, a 16 bit or 8 bit operation is no faster or slower. Back up in the .NET `System.Byte` vs `System.Int32` `==` operator land, the correct answer is neither `Byte.Equals` nor `Int32.Equals` is invoked because the compiler sees that the left and right side are both "primitive" values (data types directly understood by the runtime) and instead emits an instruction to tell the runtime to compare the values and test for equality.
&gt;How could I Bind to my checkbox, which is on a different view/xaml file? xaml without MVVM sucks. I'd recommend you a tutorial. like https://www.youtube.com/watch?v=U2ZvZwDZmJU If you don't implement INotifyProptertyChanged you have to walk the visual tree. You bind up to the last unique common Ancestor and then walk the array of children and childrens children etc down. It sucks &lt;MultiDataTrigger.Conditions&gt; &lt;Condition Binding="{Binding YourCheckboxBooleanPropertyOnTheViewModel}" Value="True"/&gt; &lt;Condition Binding="{Binding Path=Children[0].Children[0].IsChecked, RelativeSource={RelativeSource Mode=FindAncestor ,AncestorType=local:MainWindow}}" Value="True"/&gt; &lt;/MultiDataTrigger.Conditions&gt; 
You have a GuiContext... this is some object that keeps track of all the widgets that the gui needs to track. Each widget contains a set of children widgets. When you click on the screen it determines if there are any controls under the mouse at top zlevel that responds to mouse clicks. In order to determine if a control responds to mouse clicks... All controls have an event handler OnClick or some such. An Event Handler is a delegate. A delegate is... in essense as variable function. I.E... instead of pointing to a particular memory location to store data, it points to a particular memory location as the entry point of a function. The delegate has a partiuclar method signiture as well. I.E a Delegate can point at both void Print(int a) or void PrettyPrint(int a) but can't point at both void Print(int a) and void PrettyPrint(int a, int b) because there method signatures are different. If I didn't use delegates I could search and replace all calls to Print(int a) with calls to PrettyPrint(int a)... I wouldn't have to change anything about the code except the name of the function being called. Delegates are variables. This means that each instance has it's owns value... so just like Object.Width can be different between two instances of the exact same class Object.OnMouse(...) can point to different functions in different instances of the exact same class. So, when you put win.Add(new Button,,,) you are adding a specific instance of the button class to the context/widget/window called win. so, lets say you have Btn b1=new Button(1,1,"OK"); b1.Clicked+=()=&gt;{Console.Window.WriteLine("Clicked OK");} Btn b2=new Button(2,2,"BAD"); b2.Clicked+=()=&gt;{Console.Window.WriteLine("Clicked BAD");} win.Add(b1); win.Add(b2); Then, sometime someone clicks somewhere... at some point win gets called to handle the mouse click and it will do something like foreach(widget w in widgets) if (w.ContainsPoint(MouseClickLocation)) { if (w.Clicked!=null) w.Clicked(&lt;...parameters to send to eventhandler..&gt;); } 
It likely doesn't even make a difference because stack values are aligned to word boundaries as well, so two individual byte variables will take up 4 bytes each already and no additional casting is happening in the JITed code. 
Removed: Rule 4. Accessing the UI layer in WPF must be done in the main application thread. If you want to access the UI from a background thread, the easiest is to delegate it through the application dispatcher. There are a variety of answers/ways to do that here: https://stackoverflow.com/questions/11625208/accessing-ui-main-thread-safely-in-wpf
Ahh, that makes sense, I didn't know that.
My issue is that the WPF is being done in the main thread, in the same part, but when the method with the loop is linked to the main thread it just fails to run properly 
Did not expect such detail, thanks alot!
Yup, so the code you have in the background thread needs to elevate the call (I think) to `InitializeComponent` using the dispatcher first. You should also include the error messages you're getting.
Is the movzx eax, al instruction faster than and eax, 0xff?
I want to say that the squid cache on Linux commonly did this, and you could tune it. I remember playing around with the value (usually did 8 bits per directory level). Fortunately, ext4 came out and replaced ext3/ext2, so it was far less of an issue (and NTFS also got better over time).
You could create unit tests on manual maps to know it was skipped.
Oh I'll try googling that then! Also there is no error message. Catch doesn't do anything either it just does nothing . I wasn't sure whether the fact im threading mattered or not 
Somewhat ELI5: For this example to work, I need you to imagine that the "processor" is an actual human being, and that the "instruction" comes served in a package â from a chute, with very specific dimensions. An instruction package may for instance contain: "Tell me whether `32` is `greater than` `10`", or "`assign` `5` to `x`" From the processor's perspective, it doesn't matter if the package is large or small, he just performs the instruction he is told. From the package perspective, well... the package doesn't have any, its just... a package. Which leaves whoever is designing the packages which gets thrown down the chute to decide: Do I simplify, and make my packages the same size... or do I complicate things, and make different size packages? In this case, this is the language/framework developer. They might decide (for simplicities sake), that the smallest possible "package" is 10x10 cm, because the processor doesn't care. The only caveat is that the "package dispatcher" might need to have slightly larger boxes in store. Now, this is definitely not an accurate depiction of how processor's work, but it might outline the general idea of why this decision was made.
Are you trying to open a new window? If so, then you probably need to do something like: var myWindow = new MyWindow(); myWindow.Show();
&gt;I keep getting error saying that the parameters are wrong. Well, that's your problem then. Either `item.id` is not an `int`, or `item.heading` is not a `string`.
No it's the same window. The theory is the the window will open given the command right at the start. Then it will allow clients to connect and send information 
Thanks, that looks a bit tricky but I appreciate you taking the time to point me at it. I'm making a mouse free interface, and wow to my surprise you can even use a mouse! Mouse support sounds like a version 2 of my program. Thanks again for getting back to me with the info. 
Interesting, so in a way I am creating an object of sorts with the even associated with it before I add it to the window. Thank you very much for that, I kept looking at it where I was supposed to get an action / event after the fact! 
Thank you very much for the comprehensive answer and examples. In a way I am making the button with it's events before I add it. I was looking at it the other way, like somehow I defined the window, and then was supposed to capture the events - honestly I don't know. Your example makes it very clear, and I've already got some buttons clicking doing stuff. Thanks again. Now onto figure out how I refresh or redraw the entire window with new elements based on an event (:
I read through a beginners guide on MVVM and while I don't understand what every keyword fully entails, I understood it enough to bind the checkbox IsChecked to a model with INotifyPropertyChanged. This untangled a horrible mix of styles and if statements. Thanks a lot, it feels great to see it running so smoothly!
It could be. It might be a more compact instruction. Instructions that refer to registers tend to be very compact because there are so few registers.
of course you can. And I'm sure you could also write some code for your manual mapping that gives your mapping code a consistent API to use, give it some clean error message, and then add DI support and oh crap you've just created a slower, less feature rich and self supported version of AutoMapper.
&gt; so in a way I am creating an object of sorts Not of some sorts. It is what you're doing. You are creating the button object with a function being called when the button is clicked. Then you simply add it to the window object and let it magically wire it up for you.
Thank you for your comment! There are may be two reasons why your CPU outperforms GPU in this particular example. 1. The input data was too simple for your CPU, and the interaction between managed code and CUDA consumed more that reasonable amount of time; 2. I am almost sure that my utilization of the available API even being trivial and straightforward wasn't optimal. I am currently investigating this topic in spare time and I will publish an update if I found a more proficient way of doing the job.
 =) that's good to hear, glad i could help! Future things to learn to make Binding easier: -Value Converters -Dependency Properties 
Fix nested dictionary initializer: new Dictionary&lt;int, string&gt; { [item.id] = item.heading } 
For the record, it might be a good idea to abstract away the fact that you're working with nested dictionaries by wrapping the second dictionary in an object perhaps. Nested dictionaries are no fun to work with.
[https://software.intel.com/sites/landingpage/IntrinsicsGuide/#techs=AVX,AVX2&amp;text=add&amp;expand=109](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#techs=AVX,AVX2&amp;text=add&amp;expand=109)
CustomControls don't break MVVM. All controls are essentially custom controls at some level. [look at this](https://kittencode.wordpress.com/2013/06/11/wpf-class-hierarchy-diagram-1-2/) and you'll get an idea of how the hierarchy works.
Absolutely. I've witnessed it myself in a directory with over 100,000 files. 
No, manually map everything is way faster performance wise. Reflection in unit tests so tests fail if new ones are added and not mapped. I'm starting to hate any automappers nowadays since it's never 100% obvious what is going on.
Would it be easier to have Dictionary&lt;Tuple&lt;int,int&gt;,string&gt;?
CurrentValue property in your viewmodel, button command bound to some increment command in your viewmodel that increments CurrentValue, display bound to CurrentValue. although i'm not quite sure what you're talking about when it comes to 'CustomControls' vs 'UserControls'.
It doesn't cost more resources because these values will be held in CPU registers, which are a fixed size regardless of what kind of data is inside.
Not even so much HOW he reads it as much as the fact that it's TYPED very poorly and clearly not to be heard, but seen. The verbiage chosen is not conducive to good verbal communication.
Bin an instance of your enum from the viewmodel to the content of your button. On click (bound command) switch your enum to the next one (or the first if it was the last enum value).
The fact that this outperforms string.split by a decent margin while doing almost the same thing tells me maybe string.split needs some span love too!
Not if he needs to perform lookups on the inner dictionary
Language servers are fascinating to me (and I'm working on a few) so would love to see more. :)
Same here. I often think of a domain name and eventually find a project for it. The $12/yr price point makes it easy to pick up a bunch of different names (most of which I end up with for only a year -- if by that time I don't have a use for it I obviously don't need it).
nuget is the .net package manager. you'll generally see a packages.config file for older projects and that information will just exist inside of the .csproj file for newer projects. i don't have any unity experience though, so i'm not sure if the same applies for unity projects.
Hey, I've been troubleshooting this for the last couple of days as I have been facing the same problem. I found this solution to work for me: https://developercommunity.visualstudio.com/content/problem/252901/visual-studio-2017-for-mac-75-build-1255-crashes-w.html I hope it fixes it for you too.
I think those are the intrinsics now in System.Runtime.Intrinsics (currently in preview for Core 2.1) https://github.com/dotnet/announcements/issues/60 https://github.com/dotnet/corefx/blob/master/src/System.Runtime.Intrinsics.Experimental/ref/System.Runtime.Intrinsics.cs for example `PADDB mm, mm/m64` is `Simd.Add&lt;T&gt;(Vector64&lt;T&gt; left, Vector64&lt;T&gt; right)` where `T` is `byte` 
Modern intel cpus may eliminate a `MOVZX r32, r8` instruction entirely. So yes it is possibly 1 clock cycle faster. Page 186 of the agner tables: https://www.agner.org/optimize/instruction_tables.pdf
Seems like that is the way things used to be and everybody hated it. Now, hovering your mouse over the tab displays the entire path.
Nobody has mentioned the `RuntimeBinderException`. This should be a compile-time error, not a runtime exception. Are you working with `dynamic` code?
yup
Unfortunately Visual Studio doesn't have any options to do this. The closest you're going to get is Productivity Power Tools can color code tabs based on project or using ReSharper. I prefer ReSharper and using `ctrl+,` which brings up Recent Files which also shows their solution folder and project next to the file names. It also has fuzzy search capabilities.
The the references that don't belong to the GAC (framework libraries) and are not COM are copied (unless configured otherwise) to the bin/debug or bin/release
It will depend on the current implementation class and the return type of GetInterfaceC. If GetInterfaceC returns type IInterfaceC, your code will not compile. If it returns a class that implements IInterfaceC, the type of var will be the return type of the GetValue function that class implements implicitly, because no class can implement both IInterfaceA and IInterfaceB implicitly; at least one of the definitions will need to be explicit. But maybe the more important question is why would you do this?
Have you tried it? Because the compiler should spit back a warning about the call to IInterfaceC.GetValue() being ambiguous. The caller will need to cast to either IInterfaceA or IInterfaceB.
Nuget or nugetout. In more detail, the project files can reference packages from nuget (or nuget-compatible feeds like myget) - versions, names, etc, are managed from there using PackageReference elements. Typically, the IDE comes with a visual manager - both Rider and VS have this.
Anyone know the name of that extension which would replace the Window peek thumbnail with just the solution/project name?
This isnât the code being executed, your exception is in an indexer and in a dynamic. Youâre making a test case, but itâs not whatâs actually giving you problems.
Maybe this: [https://marketplace.visualstudio.com/items?itemName=mayerwin.RenameVisualStudioWindowTitle](https://marketplace.visualstudio.com/items?itemName=mayerwin.RenameVisualStudioWindowTitle)
I think that if the first character for a value is a quote, just keep seeking until you find another quote. Ignore commas and newlines. If there is no end quote, then it's just invalid CSV. Eg: # Valid and obvious Foo, Bar, "Baz" # Valid and the 3rd field is mulit-line Foo, Bar, "Baz More 3rd field content" # Invalid, as the 3rd field's quote is never closed Foo, Bar, "Baz A, B, C Now if in that case you wanted the 3rd value to literally be `"Baz`, you should do `""Baz`.
&gt; I'm actually not convinced on this. [...] I don't think it would make it 2x or 3x more expensive (the perf of the next fastest reader I found). Maybe you're right. It's hard to say, since performance is really tricky to predict even when the code is in front of you, let alone before it's written. One thing that I can safely say is that adding support for things that the other parsers support can only make the benchmark more representative of the implementation differences. It's also all but certain that adding this support would make your implementation slower than it would have been without that support. Also, side note, I don't quite understand why [this](https://github.com/dfederm/DelimiterSeparatedTextParser/blob/4a59ba29c3944d6fa42e486d467a3ae3943ceade/src/DsvParser.cs#L19) needs to be a fancy encoded `long` instead of just leaving it as `(int, int)`. The latter is a struct that's the same size as the former, and my guess is that [these issues](https://github.com/dotnet/coreclr/blob/7df363ab08c1b21e18f68d95724c9172d30adbee/Documentation/design-docs/first-class-structs.md) wouldn't impact your code so badly that it's faster to do bit twiddling than to just eat the cost of the JIT not being as good as it could be.
Can an interface that has methods with the same name and parameter list but different return types even be implemented?
&gt; I always found it very difficult to benchmark high-performance CSV parsers, because there is no canonical API. Not only that, but there's not even a single formal CSV specification. [RFC 4180](https://tools.ietf.org/html/rfc4180) is the closest we can get, and that just comes right out and says (emphasis mine): &gt; While there are various specifications and implementations for the CSV format [...], **there is no formal specification in existence**, which allows for a wide variety of interpretations of CSV files. This section **documents the format that seems to be followed by most implementations**
Explicitly, yes. public class D : IInterfaceC { int IInterfaceA(string key) =&gt; key.GetHashCode(); char IInterfaceB(string key) =&gt; key.FirstOrDefault(); }
Sure, why shouldn't it be possible? Need to use explicit interface implementation tho.
Ah right, forgot about that.
Without much context it sounds like bad UX to do something like that because it's not immediately obvious to the end user. What about something like a combo box?
A method has an API (signature). A type has an API. An assembly has an API. etc. Unit tests are done at the class level. Unless we define "application" to mean anything from classes to entire systems, the author doesn't understand what a unit test is. How do you cleanly unit test a class that makes a database call without mocking the type that does the call?
What if you just want to use a C# library on Github? Does Nuget support this?
If there's a a C# library on GitHub, chances are that author has released it on nuget. If they haven't, I tend to just skip it and look for a package that *is* on Nuget.
I'm looking for examples as well and which design pattern to use (MVVM, MVC, etc.).
I actually tried a struct instead of a long, but it made the performance worse somehow. I'll try an `(int, int)` and see if that's handled differently. I don't understand how my bitshifting and masking could possibly be faster than a struct, but I couldn't dispute the numbers.
Since you're using the Unity game engine, the only built-in dependency manager is Unity's Asset Store. Unity-related assets from C# scripts, 3D models, audio, etc, are packaged and can be imported. The problem is that the Asset Store doesn't include things from the NuGet package manager. As others have mentioned, NuGet is .NET's package manager which has all the things you'd find in pip or npm, and it's easy to work with when you're doing a regular .NET application. Unity by itself is incapable of handling NuGet packages, but there's some projects out there like https://github.com/GlitchEnzo/NuGetForUnity where they created a UI in Unity to install NuGet packages. I haven't tested it myself, but you could give it a try. If you want to import projects from github, you may have to dive a bit deeper into how Unity works. Best case is that their script is open and you can just copy it into your project. However, if you're stuck with a DLL, you'll have to read up on Unity's plugin system that lets you load DLLs into the project. As a side note, I work with both .NET applications and Unity, and they're developed with similar languages, but different environments. If you want to use Unity to learn the basics of C#, keep in mind that Unity's version of C# is a bit behind, so you won't have things like async/await, null coalescing operators, etc. They've recently upgraded to a .NET 4.6 compatible framework, which should help when importing some packages.
Wow, there are some realistic insightful ideas about testing on this guyâs blog, thanks for sharing!
Here is the awesome book on unit tests: xUnit Test Patterns: Refactoring Test Code It is more than 10 years old but it is golden and have not aged a bit. Classic.
I skimmed through it looking for the horrible stuff so many people teach and thought I found it, but on actually reading it the guy is good :) I know that sounds a bit weird, but it's an uphill battle breaking the bad habits of devs who learned from crappy agile coaches using unrealistic examples :( He's talking more about classical TDD rather than Mockist TDD, which is what I do anyway. You just end up with a load of brittle tautological crap otherwise.
&gt;to import projec This, unity has no package management currently. all libraries and dependencies must be copied into the unity project by you, manually, or by a third party tool. Unity is working on this issue with a new Package Manager, but its not ready. I second that you should set your project to use the .net 4.6 scripting back-end, as the 3.5 version is very far behind. Some advice for managing dependencies in unity: Unity will only recognize assemblies (dll's) that are in the same folder as dependencies, except in the case of folders called 'Plugins'. If you use any dll's in your project, I highly encourage you to always put them in a 'Plugins' folder. (you can make a 'Plugins' folder wherever you like)
Will always upvote anything by Vladimir Khorikov. He has an incredible gift of being profoundly insightful while keeping things extremely simple and easy to understand. 
I don't understand how am I supposed to test inner-system communications then. Not test them at all? Use actual implementation?
&gt;I don't understand how my bitshifting and masking could possibly be faster than a struct, but I couldn't dispute the numbers. Heh, maybe it's "those issues" that I'd linked after all :-).
There are good points, but this doesn't fit all scenarios. The API I am working on now, for example, has a few endpoints that accept an ID and return NoContent. That's it. However, internally that API gathers a bunch of data and runs though a bunch of evaluations and potentially fires off a series further calls to other systems - all unseen to the original caller. For this I have a bunch of "fragile" tests. The evaluation rules are dynamic, and the permutation of ways in which they can be run makes end-to-end testing untenable - it takes far less tests to unit test individual evaluations and spot-test particular combinations.
You don't test inner communication explicitly. You test the resulting behavior of that communication from another "client" that consumes the API.
Edit, worked it out! With the toolbox open, select the desired code snippet, right-click, then select "Rename Item" , then you can edit the code snippet in its entirety.
&gt;internally that API gathers a bunch of data and runs though a bunch of evaluations and potentially fires off a series further calls to other systems - all unseen to the original caller Khorikov's claim is that these "further calls to other systems" are the legitimate reasons to do mocking, because those **are** parts of your system that are observable externally.
&gt;Wait I'm less informed of these things. I thought they were only doing new releases with Core? As I understand it, .NET Fat is still going to get some attention. JIT wizard Andy Ayers suggested [over here](https://stackoverflow.com/questions/5812099/why-does-calling-an-explicit-interface-implementation-on-a-value-type-cause-it-t/51338291#comment89672243_51338291) that some of the JIT improvements that the Core team has made are likely to be ported to .NET Fat in the coming releases. It's just going to be slower-going.
ReturnArrayMethod() has no parameters, yet you're calling it with DummyArray as a parameter.
I think I understand! I have one more question that's kind of related to this. So, I'm creating a viewmodel and setting the view's data context to it. If I'm observing a list, how do I set the viewmodel's model property to the element that specific view is representing? In other words, I have a listbox with its itemsource set to a list of models. I have a datatemplate, and inside it I have a custom control that requires a viewmodel. Usually, the element that has been added to the model list is automatically passed to the view so binding is easy. How do I access that model that has been added to the list so I can see the view's data context to the viewmodel, and the viewmodel's model property to the model?
Doesn't that violate the principal that a unit test is supposed to test a single "unit" of code? I've always been told that if a single test hits multiple internal components, that it is a poor unit test.
Sure, and those have end to end tests. My point still stands on the evaluations though. It's entirely internal, still requires testing, but is better tested by small unit tests than large integration tests 
Windows authentication is good enough, and eliminates the need for storing a password. In situations where you can't use Windows auth (looking at you, AS400 integration), I typically prompt the user for credentials and modify the connection string at runtime. Never ever ever ever ever ever store a plaintext password in your app.config OR embed a password in your compiled application. Either of those approaches are a great way to have your account compromised.
I think the idea is that inner components are part of the same unit. You call an API. It produces a result. The methods that produce that result could be in one class, or could be refactored (up front, or later) into several classes, but that should not impact the result of the API. Thatâs a unit. As compared to: You call an API. It produces a result. As well as using methods in one or more of your classes to get that result, those methods also call methods in a class written by a different person, a different team, bought in from elsewhere, reused from another project, etc etc etc. In other words, those classes werenât written explicitly to produce, or to help produce, the result of this particular API. They are external components, and you should probably mock them.
That's sounds like what I know of as an "integration test". For me, unit tests test individual units of code, while integration tests test behavior between, and across multiple units. This has definitely given me something to think about though. Thank you.
Just a suggestion, but if you find yourself reusing the same pieces of code over and over consider rolling it into a method. Then just call those methods instead of copy pasting the same code all over the place. This will allow you to make improvements to those pieces of code without having to find all places that you ended up copying it to.
you can compile the github project and manually add the reference to the project.
You can make the datacontext of the parent available as a static resource which can be consumed by the children, or, my prefered method is to use a private messenger instance created by the parent which is passed to the children. This gives bidirectional communication in a testable environment. I'm watching fighters do silly takeoffs at the moment, so if that doesn't give you enough for google-fu, I might be able to knock up an example later or tomorrow morning :) 
Please donât take anything I say as gospel, Iâm not an expert! But my understanding is that an integration test would test the interface between two specific units, apart from the rest of the system. As for the reason why it makes sense to use this definition of a âunitâ: imagine you tested each class as an individual unit. You have a class which is part of an API (but not the public facing class), but you refactor that API and split that class into several other classes. Youâve just broken all your tests! Thatâs no problem, you say. You just refactor your tests too! But thatâs a bad habit. Because if your unit tests always test your public API, you should know never to refactor them unless absolutely necessary or youâll break your clients. And if you get into the habit of expecting to refactor tests, itâs easier to break your clients without realising. Hence the advice to treat a group of classes that work together as a unit.
Hm, hadn't thought of that! :) Thanks man!
Ok but what does a 'client' mean? Lets assume I have few classes that together make some external functionality for a client. Should I just treat them all as a single unit? How would tests in which I do help me with refactoring individual classes? If I break something during refactoring, tests will tell me that my 'external API' doesn't work but it won't help much with fixing my individual classes. Wouldn't that be counter productive? What if those 'implementation details' consist of several different classes?
If you're really using the same code over and over again in different projects, you can just create a utility project/assembly and add it to any future projects. I generally don't add the code unless I've used it at least five times. Just keep it in source control and it will grow as you do.
My new hurdle is how do I redraw the entire screen haha... I only need to display a bit of info so I ended up making a dialog only to find it can only render buttons! haha good times. If I get anything useful happening I'll post it here. 
Why is it bad to store password in config? I cant see the problem sure if someone get access to the source code but that should never happend...
The parent being the data template? This is what my data template looks like: &lt;ListBox.ItemTemplate&gt; &lt;DataTemplate DataType="ValueConditionModel"&gt; &lt;local:ValueConditionView/&gt; &lt;/DataTemplate&gt; In ValueConditionView, I its data context to ValueConditionViewModel. The listbox is observing a list of ValueConditionModel. I tried to access the parent inside my ValueConditionView, but it's null.
Guys, think there is a miscommunication, I am very much a beginner right now, trying to get to grips with the basics :)
It's trivial to decompile a .NET application and browse through the source code. Check out the application "ILSpy" if you want to see how easy it is. This allows someone to extract the plaintext credentials from your application with very little effort at all. Same thing with storing it in the config file. That gets installed alongside your compiled executable, and is literally just XML. All it takes to extract a password from the config is opening and reading the file.
Remeber that object-oriented programming is all about code reuse. If you see yourself continually using the same snippet of code, then add it to a method body or object. If it is a piece of code that you frequently use in various projects, consider making a .dll class library file that you can import into all of your projects.
Basically, if you are reusing code for several different projects, try creating a new project that only contains the reusable code. That way, you can reference it in all your other projects. Where you save the actual project files can vary. Initially you might just want to have it locally. The guy above gives an alternative suggestion which is storing it in the cloud using git, svn, mercurial, etc., And then create a private nuget package. You can google more about git and version control, and nuget and packages :)
I'm surprised the author doesn't go on to explain the difference between "white box" and "black box" testing. He's advocating "black box" over "white box" here, but both are valid depending on your goals. Techniques are not one size fits all; you need to be pragmatic about your own specific situation and constraints.
You're right, but you've made the assumption that everything needs to be *unit* tested, and that's not correct. This is not an easy thing to solve. The problem with writing unit tests around methods that coordinate with dependencies is that you end up having to mock a lot of things. This always prompts the question, "So what? Mocking is easy." Except it's not. Any enterprise developer that tries to write unit tests will tell you that every time they write mock-heavy tests they start getting dozens if not hundreds of tests failing all at once every time they try to add a new feature or refactor. I've got a project at work where this mistake was made over a year ago. I still spend more time fixing broken unit tests than I do bugs or adding new features. I'm definitely not saying you should write one integration test per happy-path feature of your code and call it a day. However, you would be wise to consider what benefit you actually get by *unit* testing an `AbcService`that does *nothing* other than call on an implementation of `XyzService` to perform some other work and `AbcRepository` to get the data it needs then maybe save it again. In that example, `AbcService` would be better served with an integration test that uses your actual implementation of `XyzService` as well as the easiest way to cut off `AbcRepository` from going to the database (which might mean mocking in a fixture or a fake). You might even use dependency injection just as you would in production code so you don't really need to test `AbcService` from the inside out. You definitely should unit test around domain logic and places where mocking isn't necessary due to a lack of dependencies, but don't fight your future self by unit testing a method that needs many mocks. Integration tests don't have to go through *everything*, so it will contain some mocks, but you don't have to mock as much because you won't test every piece in isolation. *EDIT* I'll add to this and say that mocking is a failure point in a unit test because it **requires** knowledge of implementation details. This is unavoidable sometimes, but by mitigating the use of mocks you'll save yourself a lot of time in maintaining tests.
Sorry Iâm afraid google translate didnât do a great job, most of them are very confusingly written :-/
edit: should be ok rn ;)
"Interface in the classroom" you might have a typo here. What kind of developper are you looking for with these questions?
Fixed. I added source, that's post from programming forum and topic is named "Trully advanced C# questions", so I'd call them "Wizards"
In your specifically described scenario, sure. I don't know what your code looks like, but I also wonder if you could have avoided evaluations and calls to external dependencies in the same place. Any calculations are done in a separate class that knows what to do. That class is purely unit tested. Calls to external systems are done in another. It contains no logic, just takes inputs as to what to send to the other systems. It might call on other classes to map results back (they are unit tested on their own). There is no point in unit testing this class. A facade wires them up together, interweaving calls between the first and second. This class is integration tested. Some tests would call on the external services, some would just mock your code that does. However, by reducing the mocks to this one area, you've saved yourself from mocking everywhere (and future headaches). Just because it's testable doesn't mean it's good code.
Most of these seem largely trivial and irrelevant to being a good C# developer. I would rather understand how someone understands higher level concepts. I don't want to spend my day arguing the minutiae of the internals of .Net with someone when I have to build a large system. These types make poor coworkers. 
Agreed. Most of these are memorizing things that could be easily answered by 'reference the msdn.'
Or he could just create a project template that includes his helper libraries. 
Where would you store the password? 
Well, the point of those questions is collecting "interesting things" that rarely somebody knows, not "the most useful things" or something along these lines. People are throwing jokes about using it during interview, cuz generally people aren't able to answer those questions. But, of course some of those things should be known for good dev. e.g &gt;What is the difference between const and readonly?
As i said if they dont get access to the source code... you protect the source code eg hosting on a server and not public in github :) so how can they access the config file? I Will still use the config file to store connectiinstrings and password...
If you release the executable, you effectively release the source code. CIL is surprisingly legible, even if you take steps to obfuscate it. Your config file is installed alongside your application. If your password is in the config file, it can be extracted without effort. If you would like a demonstration, send me an MSI for one of your projects containing an embedded password. I will send you the password for the account. I have a spare 10 minutes or so Â¯\\\_(ã)\_/Â¯
What the fuck is this crap? Anyone attending a C# interview in the near future almost none of these are questions you will be asked, even if I limit it to the ones which honour grammar.
Well, I try not to. But on the rare occasions when I've had to, I encrypt (yes encrypt, not hash. Has to be reversible) the password and store it in a custom XML file. The key can either be a different PSK or a private key stored in the windows keystore. It's not perfect, but it makes it more difficult to recover the password.
Right, there are some that are fine questions, but it seems a vast majority are gotcha trivia about internals that you'll never really need to know to be a very successful dev even into senior and architecture positions. Judging someone on their ability to answer the questions on this list would be a significant mistake during hiring.
This would be trivial to do with the win32 api using either send message/wm_settext or a setwindowtitle call 
Keep the password out of source code, which is checked in and might not be as controlled as you like. As long as it is in a config file and Ops can change it when they install in prod, you're probably OK. Using integrated NTLM auth to the database is better. But if you think about the main threat that would result in someone snarling the password from the config file, they are either able to view arbitrary files or execute code or commands on the web server. In the file viewing case, encryption raises the bar a bit (at some point the attacker will find the file with the decryption code and key), but a trusted connection to the db is better. In the case of code or command injection, the attacker can just reuse your connection to the db, all you do with fancy crypto is slow them down a little.
Lol if i host my executable on a server as i said how can you decompile it? But sure if i send you the executable then you can decompile it perhaps.. the point is if you selfhost your app or eg azure then its safe on the other side if you distribute your code to other then you need to be more carefull about it...
Would you believe that some applications are actually run on a client's computer?
This entire thread has been in relation to a win forms app... A client side application... No one mentioned storing server side passwords etc securely. 
What makes you think they're in the same place? They are deeply separated classes that only relate by virtue of the model bringing them together. The evaluations are done as a series of adapter patterns, the calls to other systems is a chain of responsibility 
Ah, we were talking about different things here. I mostly develop client-side software, so that's immediately where I jump to. In the case of server-side software, it's about acceptable risk. I'm inclined to agree with you. If someone has compromised your infrastructure to the point where they can read your config file, you likely have much bigger concerns than the fact your DB user password is hanging out in your config file.
No worries! Welcome to the land of books, Google and StackOverflow!
We use managed service accounts to connect to the DB. In this model, the server and database are named in the web.config, the username and password are not.
Grammar is terrible, questions are awful and will do nothing aside from piss off applicants. Let me know where you work so I know to never submit my resume. 
You need to have a static class, there you can put static methods, variables which can be reach based on your get;set configuration. Be aware, that static objects are initiated at runtime so if you variables changes a lot I suggested not to use it static instances. And static objects are initialised with their default values( given in constructor or just nulls). So to summarise static class would give you exactly what you ask, it doesnât have to be declared or passed as variable.
hmm i thinked that static class would lead me too doom , duno will try that too i guess , if it dosent work out will cry here more , ty i guess
I would say if something is needed by every request, such as a list of strings, you should be caching them and serving then like that. I.e. Don't keep them in memory and use them on each request, store them in a cache. This could be as simple as a file on the server if they are a read only list, or something like redis/memcache for quick access cached items. That way you don't run into issues using static objects if you don't need them, and you arent sharing 1 objects across multiple Requests. 
I'm still learning so I may be wrong, but I'll give it a shot. You can create a singleton using dependency injection. First you create an interface for your class: public interface IMyChatRoom { List&lt;string&gt; Words { get; set; } } Then make sure you class implements the interface: public class MyChatRoom : IMyChatRoom { public List&lt;string&gt; Words { get; set; } = new List&lt;string&gt;(); } Then in startup.cs inside the ConfigureServices method, you can add it by writing this line: services.AddSingleton&lt;IMyChatRoom, MyChatRoom&gt;(); You should be able to use the singleton in your controller by injecting it in the constructor: public class HomeController : Controller { private IMyChatRoom _myChatRoom; public HomeController(IMyChatRoom myChatRoom) { _myChatRoom = myChatRoom; } }
There is no difference between an array initialized by a variable or one initialized by a constant. Look at the IL and youâll see. The compiler doesnât really care where a variable comes from when you pass it as a parameter, as long as the type is fitting.
A password or encryption key or other form of **secret** is something that you should keep out of the source code. Source code is easy to decompile or is shared much more freely than a password. It also would make it difficult to rotate your credentials, since it is embedded in the source code. For a smaller company, it is probably easiest to use Windows Authentication and setup a user with the least amount of privileged necessary for the applications functions. At larger companies there is typically a service that manages secrets and allows certain machines and users the ability to retrieve and decrypt the secrets for an application at run-time. While these secrets can be accessed from the host machine itself, they would be encrypted during transfer and decrypted right before use. It also allows for the keys to be rotated on a regular basis. Here's some reading you can do on AWS KeyManagementService, for example. [https://docs.aws.amazon.com/kms/latest/developerguide/overview.html](https://docs.aws.amazon.com/kms/latest/developerguide/overview.html)
Sorry, I wasn't clear. When I said variable array, I meant, variable-length arrays....not sure if that makes a difference?
There is no variable length array in C#. Arrays always have a fixed length during their lifetime. There exist pseudo-variablesized arrays like the List&lt;T&gt; class which is just an array wrapper that copies stuff from a smaller array into a bigger array when it reaches its capacity. This is all I can say to you. If you could give me an example of what you mean, I can probably elaborate more.
https://imgur.com/a/LDWRb3P (taken from the C# 7.0 For Dummies....)
I sorry to tell you I canât read the text... imgurs jpeg ruined the text, at least on my phone. I will try to read it on my computer later.
Oh, if you hover over it, it has a magnifying glass icon and that zooms right in....
Not on iOS unfortunately...
Shit, sorry
Multiple internal components can perform a single unit of code.
In the article, adding a product to an order and updating the users last purchased item i would consider a unit test. Even though its manipulating 3 classes.
Removed: Spam. Please review the [Guidelines for self-promotion on reddit.](https://www.reddit.com/wiki/selfpromotion)
What about Github âgists?â Is this a viable solution?
All that's doing is declaring an array with a size specified elsewhere - the array's size itself after construction is still very much fixed. It cannot grow, and it cannot shrink. Calling "initializing an array with a nonconstant size" a "variable-length array" is very misleading.
"static" is exactly what you are looking for. You can keep public class MyChatRoom {} as-is, but declare it as static when you use it public static MyChatRoom MyActualChatRoom = new MyChatRoom(); 
You can make a union but itâs butt ugly. 
This will work, however, the interface isn't necessary. You can reference the class directly. services.AddSingleton&lt;MyChatRoom&gt;(); Then in the controller: public HomeController(MyChatRoom myChatRoom) 
As others have mentioned, consider starting a new project to use as a common/utility library. Mine is called &lt;company name&gt;.Common, and it contains namespaces for different types of utilities. Cryptography for my helper classes to handle encryption/decryption, different namespaces for 3rd party product API's I've integrated with, a stats namespace for classes I've made to implement exponential moving averages and such. It's really great keeping this stuff centralized and reuse it as you'll find you improve it over time, and you'll frequently say "oh I have a tool for that" and just reference and use it. It's liberating to be able to tackle a new problem without having to trudge through the easy stuff you've already done before.
ðððððððððððððððð Peeeeeeeeeeee
This question just seems like nonsense.
Pandora - Classic Rock Workout Radio
You sir, you just seem like nonsense! (:
Should have stressed, international.
focusatwill.com - my must have while programming!
I listen to BrainFM on occasion. Kind of neat. There's also a cafe chatter station you can Google for. The ambiance is nice.
This belongs to r/UIGore Might seem a bit harsh but there is absolutely no excuse for that abomination of an UI, it just takes special effort to make it look like a kids game, even if the tool itself is somewhat useful. 
Ok ok, I need proof you are a human and not a bot! haha been on trial for like 30 minutes or so, cool shit. electro bach is solid, though their mixing is shit. thanks so much for the link
me bot..no..(learn dart!) 
Interface allows better testing though.
Do you really need a programming language for this? Wouldn't buttons be more intuitive than forcing your users to learn "BQL". Think about who your audience is. GIMP can already do all of these things for free and probably better than your program does it, so anyone using your program would probably be a less tech savvy person, who isn't going to want to or be able to use BQL.
Looks like DVD playing software from the early 00âs.
A few suggestions, skipping the criticism; Drop the background and place 'transparency' blocks behind the image, ~15x15px background blocks with white/light gray, just imitate GIMP or paint.net, same target audience I suppose. Create a small sidebar on the right with UI controls, no/minimal styling (or copy GIMP/Paint.net). If you like your concept of 'BQL', keep it and improve it, but allow UI controls (dropdowns, numeric inputs, etc) to compose the query in the background so that all features are available without learning 'BQL'. Only display the textarea for 'BQL' input when the user wants to use this feature, don't display it by default. 'BQL' is the only feature you have over other tools, I can imagine a remote use-case in which you would like to reuse a query to process similar pictures. Good luck.
Sorry, I was just quoting the book...in my defence, I am trying to grapple with concepts and terms that are at present, beyond my understanding. Your comments have been invaluable for me finally beginning to comprehend this quagmire :)
I sort of agree with some of the other comments. Perhaps they're a bit harsh, but that's what you're going to get and it's more honest for people to say what they're actually thinking rather than trying to protect your feelings. You've tried to be creative with the UI, but I don't think it's paid off. People have certain expectations of what tools should look like and unless you can come up with something fairly revolutionary, I'd stick to a safer design. Also tend to agree over the BQL comments. It just seems like a bit of an over complication. Sure, there's the argument that it could give a deeper level of flexilbility, but is that needed? Photoshop does this perfectly well without needing a query language. It sounds a bit like a solution looking for a problem. Don't be disheartened though, perhaps if you used a panel based approach with dynamic refreshing of the result through tweaking of settings via input boxes/sliders/checkboxes you could have something here.
Maybe you're looking for [this?](https://marketplace.visualstudio.com/items?itemName=vs-publisher-2795.SnippetDesigner)
A gateway API is part of a micro-service architecture.
From what i understand gateway is fancy way to say that an endpoint in the project is going to call multiple other apis.
You likely want to use the HttpClientFactory introduced in 2.1 for the outbound requests from the gateway: https://blogs.msdn.microsoft.com/webdev/2018/02/28/asp-net-core-2-1-preview1-introducing-httpclient-factory/ https://github.com/aspnet/HttpClientFactory/wiki/Consumption-Patterns
So you're pretty much making a micro-service there anyway
Believe me, I didn't make the decision not to use controls lightly. I am a controls developer, that is my specialty for Windows Forms, and I had planned on creating controls for everything. The reason I choose not to is with query language, I can do everything in a fraction of the time. I purposely set out to not try and compete with Photoshop, Paint.Net, Gimp, etc. as this is a specialty tool, used by those that want to use it. If you think this is too complicated, than this tool is probably not for you. Hide Pixels Where Total Between 720 And 740 Thanks for all your feedback, as with all the tools I wrote, I only write them because I have a use for them. If others do, great, if not, that isn't my motivation when I write something. Building a 'Query Builder' would not be that hard, just SQL is such an easy language to learn, anyone can learn it if they want to. SQL Server is not for everyone, that is why I make $65 per hour, part time from home. Learning skills is something that separates you from the pack. 
You can change the background color: Set Background White Set Background 40 80 120 (RGB Values) Set Background Null (erase background). And no, I don't want the gray and white transparency, that makes it harder to tell what is erased.
Ok, use Gimp if you like it. I didn't like Gimp. 
I am a controls developer, and I started to create controls, but I can't add a control for every use case. Text I can parse anything in a few seconds, controls take weeks or longer, and this isn't designed for all audiences. 
A few people seem to have a few things wrong about architecture, I thought I'd just reply directly to the OP and clear things up. The term gateway API, or API Gateway (AWS) or API Management (Azure) is a fancy frontend. It has no scaling functionality for whatever is behind it. When they say they're built for scale, they mean that service itself is scaled and will be performant no matter the load you throw at it. I think what you're thinking of is load balancing. There are so many products out there to choose from it would be fruitless to go over them. This is when all requests go into one server/cluster and the sole responsibility of that layer is to determine where to send the call based on a subset of identical servers who are able to take the call. This can be separated out by a gateway API, which you can configure multiple web applications behind the gateway and you set up rules to tell the gateway who to forward the request to (typically by the path, like api/v1/ goes to your v1 cluster and api/v2 goes to your v2 cluster). You can configure a load balancer many different ways, and some products offer abilities others don't. The most common way that is shared across most, if not all, is round robin. This is where the load balancer gets a request and it sends each request to a different machine down the list, repeating the list once it's at the bottom. This is how monolithic applications will scale their web servers. You can run multiple instances of web servers and distribute the load among them with a common endpoint, which is the load balancer. With a REST API, this isn't a problem off the bat. But with any design where you're storing session state, this is immediately a problem. You might log in on server A and get a session there but when your next request gets sent and goes to any server but A, the session isn't be tracked there. But! People smarter than us have solved that already with caching. The most popular is Redis, and there's a baked in way to store session state using Redis in [ASP.NET](https://ASP.NET) ([Redis Cache Session State Provider](https://docs.microsoft.com/en-us/azure/redis-cache/cache-aspnet-session-state-provider)). Better explanations and illustrations are available at Azure's Load Balancer doc: [https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-overview](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-overview) But if you have any follow-up questions, let me know and I'll do my best. I currently use Azure Load Balancer on a Service Fabric application that auto-scales. We also use API Management to protect it and take the SSL load off the web servers. So it's important to note these 2 techs are not mutually exclusive to use. You can put a gateway in front of the load balancer. If you're going the on prem route, check out F5's products. They're pretty stellar. I also count about 12 uniquely different load balancing options on Azure available from several companies. And to answer the question about a useful library, these topics are all based on architecture, so there won't be one. There's 2 sides to performant web apps: scalability (architecture) and performance (code). If you want performant code, there are countless examples out there. For [Asp.net](https://Asp.net) Core, the very minimum is using async/await. Once your traffic reading the upper bounds of what the machine can handle, that's when you need to scale out (more machines) or up (better hardware in current machines). Scaling up creates downtime, scaling out doesn't have to.
Check your project properties and make sure you're compiling as a 64-bit application. 
I thought about this, and I should try it anyway, but if that's the issue, wouldn't that mean I'm generating about 2GB of data here? That's pretty extreme, no? My app only uses about 45MB when I'm not seeing this issue. And thanks for posting!
These are super-nerd C# questions. Most C# developers are not, and do not want to be, super-nerds. Myself included.
Will try this too, it sounds more legit way then just using a static class, worst case will learn something from reading about "using dependency injection"
am trying to make a simple game first time so plan to use websockets and i think storing stuff on file and reading it eavry time will slow me too much and it kinda sounds dumb :) , tought for something else it would probbaly be usable :)
I've never looked into the actual cause of the error, but I only get this exception when I compile as 32-bit. Compiling as a 64-biy application always fixes it for me. You're right, though. It always gets raised way before the actual memory utilization warrants it. If you look into it and find out why, can you let me know? Now I'm curious.
Don't really know what you're talking about. Your UI is dead simple (a set of buttons + a text input control in a single window) so I don't see why you would make your own control. What I'm complaining about, is the fact that you took time to download these ugly buttons from the internet when the default interface, or system included fonts/icons (like Segoe MDL2) have everything you need. I'd rather use the Windows XP OS default WinForms theme than those ugly buttons. And Windows XP is almost 17 years old now. I'm only a high school student, but I've made beautiful applications with the [Metro Framework](https://github.com/dennismagno/metroframework-modern-ui) framework for Forms by only replacing a few lines. 
You and me both. I'll have to compile as 64 bit and see if it fixes things; I hope it does. If it does, I'll have to find out if I can ask someone at MS for more detail.
If you're just using it in-house for a few people, you could argue that it's ok to keep the connection string on their machines; still, this could create risks, like someone getting the app from them, or maybe they intentionally sabotage things. Standard procedure is to have the user log into your app, which logs into a web service, which performs operations within their bounds. To get an SSL connection, you need a certificate. Use LetsEncrypt though Win-ACME-Simple to get a certificate for your server: https://github.com/PKISharp/win-acme Now you can do a https connection from client to server. Token and Windows authentication are both fine. Set up whichever is easiest. EDIT: This blog post may help you with your certificate: https://weblog.west-wind.com/posts/2016/Feb/22/Using-Lets-Encrypt-with-IIS-on-Windows The LetsEncrypt-Win-Simple app he uses is now called Win-ACME, linked above, and it looks a bit different, but it's quite easy to use.
What is it you're attempting to accomplish here? I can't seem to make sense of it. It get WHAT you want MVVM to do for you, but what is the purpose of this particular user control?
Search for "attached behaviors". They will allow you to add custom behavior to any usercontrol. The logic is basically: You write a static class with a dependency property. When the property is set you register your mouse event handler to the control. Then in xaml you add your new property to any control you want to have that behavior.
Firstly, good for you for recognizing that microservices is only truly useful in a small subset of problems. The term gateway is somewhat ambiguous as you are using it here. Perhaps you mean it this way: // SomeClient is a magic client that talks to any service // that implments ICustomerService whether it be REST, // WCF, or an in-process call to a database. // SomeClient is dynamic - it can find any provider that // implements ICustomerService on the fly in real time. public void GetCustomer(IServiceClient&lt;ICustomerService&gt; client) { // make a call to any service that implements ICustomerService // if a provider does not respond, fall back to a different one: Customer customer = client.GetCustomer(10); } In the code above we can think of SomeClient as a gateway to ALL of our APIs across all transports and providers: Make a WebAPI call: Customer customer = client.GetCustomer(10); Read from a MSSQL database: Customer customer = client.GetCustomer(10); // yup, same client Read from a MySQL database: Customer customer = client.GetCustomer(10); // yup, same client Put a request on a service bus: Customer customer = client.GetCustomer(10); // yup, same client An architecture as described above is truly scaleable since new transports and providers can be tacked on with no change in the application. The reason for this of course is that `SomeClient` sits between all your APIs and your app. Is such an architecture possible? Yes it is and it is in fact pretty simple to make. The trick to such a design is that you must consolidate all of your business logic into your service layer. This is a good practice even if you don't need the flexibility of a gateway-type client being discussed here. If you have business logic in your controllers or viewmodels it is only accessable to the presentation layer that consumes those objects. Move it down to your service layer so that everyone can use it. Next, you need to think about dependency injection. It's going to be a nightmare to register and resolve all the services you need to talk to all those providers across all those transports, right? And you can't REALLY do it on the fly in real time, right? Yes you can, and at is pretty simple to do. But you have have to start at the bottom and work your way up. This is where the discussion gets a little more technical. I actually wrote a client called AdaptiveClient that does what is being discussed here. You can keep reading about it [here](https://github.com/leaderanalytics/AdaptiveClient). You can download a fully functional demo [here](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon). 
We are doing it now and the library is performing well. Will soon update you about this performance benchmark.
Extensive unit testing and integration is done and is all check-in on our repository. This is just and FYI. [https://github.com/RepoDb](https://github.com/RepoDb)
That's the London school's (mockist) definition. The Chicago school (classicist) defines a unit as a unit of behavior, not code. That unit can span across one class or more, that doesn't matter. A unit test then is something that runs independently from other tests (i.e doesn't hit external dependencies), not something that tests a single unit of code.
This program uses a Pixel Database, so SQL type language is the best way to access / manipulate the data. Metro is the ugliest user interface ever invented. As to why would I make my own control? Exactly, I didn't have to, the query language takes care of all that. But to build a Query builder, would require a set of controls, and it is more complicated to parse than just text. As for Windows XP and your name calling of my buttons, your age doesn't give you enough experience to have a legitimate opinion. There is a reason kids can't vote. 
Great work! I look forward to sharing my current project when finished. 
You could look into quartz.net. https://www.quartz-scheduler.net/ Usually a worker like this is run as a daemon or service. There are other hosting paradigms like azure workers as well.
More information needed. But initially I would consider having a specific call you can make to your web service which would trigger the necessary retrieval, and schedule curl to make that call on whatever interval you prefer. To guard against the scheduled call failing to execute, you could also keep a "lastUpdated" value that you check every time a user calls up your service to make sure it is up to date. If the last update was more than 25 hours ago, the 24 hour scheduled call must have failed so do an update before returning to the user. It'll be annoyingly slow that one time, but hopefully it never happens.
Data isn't required to be up to date it's okay even if it's a month old.
Dude, thatâs a weird reply. It starts off normal and then you start going off about how much you earn. Donât forget most people in this sub are probably professional developers. If youâre launching a tool and most people are giving honest, but tough critiques, Iâd listen and think about whether it can be made more appealing instead of telling folks itâs too complicated for them. Thatâs not what people are saying.
In that case, I'm not aware of a specific caching library (I'm sure there's a good one out there) but I'd probably make the call for information through the cache and then let thr cache do an occasional asynchronous update. It'll always return whatever information is available immediately, but occasionally it will see the information is older than X so it'll update it in the background so the next caller gets the new information. This will mean that if nobody calls the API in a year, they could get year old data, but if it's called daily, it'll always be up to date.
Incremet a value that is in a textbox by using the mousewheel. 
&gt;WPF app Which .NET Framework version? The WPF clipboard was buggy in early versions. &gt;I believe it can be locked by other applications Any use of the clipboard locks it for other applications. It's global, so by necessity, all reads and writes are as well. &gt;I also believe it needs to be read from an STA thread, which I'm creating inside a Task.Run just so that I can avoid blocking the UI whilst I wait for the text from the clipboard. That should work. &gt;At first I had a 50ms sleep, and thought ok, maybe the memory is building up too quick. Maybe these COMExceptions have tonnes of data and aren't being garbage collected. So I increased it to 500ms, no luck. Given that you assume the problem to be inside the COMExceptions, why swallow the exceptions? At least log them somewhere. If your problem is indeed that another application is writing to it, the COMException will tell you as much.
That's a great idea. Thanks
These are mostly terrible questions that no one would ever ask.
Cool. Looking forward to it :-).
OK, I did not know about these rules. I read them and I'll as from now I'll respect them. 
I did ask for feedback, which I got and I will take it (and throw it out like most feedback because I wrote it the way the gives it the most power and flexibility). As for people thinking this syntax is complicated: Hide Pixels Where X &lt; 200 Y Between 50 And 120 If that is too complicated for people to learn, then I am sorry they probably shouldn't be attempting to be a programmer. A user interface was my first idea, but it was not as powerful as what can be done with text. Access has a query builder, but it only does a subset of what SQL syntax can do. If no one else wants to use it or learn how to do it, then that is not my concern. Thanks for your feedback (see article above as to what is done with it).
Alright, I'm back, having read the page you uploaded. I'm completely with [u/JargonTheRed](https://www.reddit.com/r/csharp/comments/90oncr/no_overload_for_method_takes_one/e2t7jnr/) here: The book is using the word *variable* falsly at this point. Arrays can't be variable in size by definition in C#. Resizing an array means you have to copy the whole chunk of data to a new location and add some more space behind it. The length of an array is defined at runtime and can therefore use variables of Int32 as initializer, but can't change its size upon creation. This would for me be a case where I stopped reading a book, but I actually never read a book about the C# language, so I can't really say anything good or bad about any.
Calling it a "World Preview" seems unnecessarily agrandizing.
So you want to populate a listbox, and have a unique item in the box per model from your list?
Well, the list is full of models, and I want to use a viewmodel and a view to display the model. The problem is how do I retrieve the model the view is assigned to? 
&gt;I also can't replicate it on other machines I can't seem to cause issues with it on my system either after a number of attempts. Could it be related to other WPF applications serializing instances to the clipboard? Apparently that is a common cause of OutOfMemoryExceptions when dealing with the WPF Clipboard class. As I understand it those issues result in garbage data which the WPF clipboard tries to "understand" as a serialized instance which can involve instantiation of large memory segments due to the corruption, which could mean occurrences are significantly reduced when running 64-bit. (Afterwards I imagine the clipboard would determine that there is nothing "valid" and give up trying to recreate the instance and the large data it allocated would be disposed)
&gt;It has no scaling functionality for whatever is behind it. When they say they're built for scale, they mean that service itself is scaled and will be performant no matter the load you throw at it. This is really a great point. I think what you are saying is that the architecture itself has no feature or characteristic that makes it any more or less scalable than any other architecture. The "scaling" comes from throwing hardware at the problem when things get slow. So it is kind of like saying "My app writes directly to a database. It's scalable - if it gets slow I just add more memory to the server."
If you want to use a stream of bytes, look at the buffered stream type. If you want to aggregate objects, you could subscribe to an event that buffers or groups events. There's also react extensions that have an iobservable that helps with subscribing and listening to events
NEXT!
I'd say your sample breaks the MVVM standard, on the user control part. should look something like (but it wont be word perfect) class ListItemModel { } class ListItemViewModel : BindableObject { private Model _model; public Model Model { get =&gt; _model; set { Set(ref _model, value, "Model"); } } } class ListItemView : UserControl { public View() { InitializeComponent(); DataContext = viewModel; } } &lt;ListBox.ItemTemplate itemsource="{Binding Model}"&gt; &lt;DataTemplate &gt; &lt;local:ListItemView/&gt; &lt;/DataTemplate&gt; &lt;/ListBox.ItemTemplate&gt;
&gt; Sorry sometimes I completely skip the explanation. &gt; &gt; Take a look at this. https://stackoverflow.com/q/26321366/1146246 &gt; &gt; Basically the .Net file object is doing a lot more than just getting the file and it slows things down a lot. Not sure how but my reply ended up in another comment thread. Sorry sometimes I completely skip the explanation. Take a look at this. https://stackoverflow.com/q/26321366/1146246 Basically the .Net file object is doing a lot more than just getting the file and it slows things down a lot.
Interesting. Thanks for following up! 
&gt;If that is too complicated for people to learn, then I am sorry they probably shouldn't be attempting to be a programmer. You're missing the point. It's not about complexity because there is none. This tool does literally ONE thing: makes backgrounds of images transparent. In your own example, in the first 2 minutes of your video you edit the "BQL" by changing a value and then doing it again, and then doing it again and you're still miles from the result. What in this workflow is either more efficient or more granular than using a slider (with dynamic preview) or another more suitable approach? There's no reason to need a domain specific language for such a simple task.You've literally taken something that existing tools do well, and made it less intuitive. In your own video you gave up at one point and started again and this is a demo you made that is supposed to show off your work! I started out really feeling a bit bad about some of the criticism and trying to help, but with your slightly odd responses and defensive attitude you're not winning anyone over here. &gt;If no one else wants to use it or learn how to do it, then that is not my concern. Why post it to reddit calling it a "World Preview" and asking for beta testers then? Nothing adds up here.
If you intend to leverage .Net core fully then thats the way to go 
BTW you can eliminate the `Task.Run()` by using a [`TaskCompletionSource&lt;string&gt;`](https://stackoverflow.com/q/15316613/1925996).
I have never heard that word aggrandize before. I will count that as my word for the day. I didn't share the video on any other celestial body, so World Preview was accurate as far as geographical jurisdiction. I am sure I am not the first marketer to attempt to aggrandize something. 
I don't see an Itemsource property on ItemTemplate? How and why are you doing this? &lt;ListBox.ItemTemplate itemsource="{Binding Model}"&gt;
You do now show that you have bound the GridView itself to dynamicwallpapers or is that part left out?
I'm using a program called [CodeBank](http://zeraha.org/2011/06/codebank-hierachical-source-code-snippet-database/) from Nikola Dachev, which while old and unsupported does everything I need. It has a couple of bugs. I have a folder per language, an entry per element. The top window is always reserved for comments / description, followed by a bottom window for the code. It does code highlights well enough and is fast enough. Also, if / when if does, the whole data is stored in XML - so I could program something to read it. Also, my code bank file is in my Dropbox, so even if I need it on a mac, I can open the xml with VSCode or another editor and search inside it. It's been on my list of projects to replace it with my own, but since codebank does what I want and works, I've not felt the urge to rewrite it myself. 
Sounds like you need a message bus. Consider RabbitMQ, Kafka, Azure Service Bus, etc.
0 1 3 4 
The loop will continue so long as the evaluator is true, at which point it will terminate.
I had a quick look up at what VM HOARDING is and tbh if you felt the need to ask what that is in an interview, now that I know what it is Iâd be concerned about what compelled you enough to feel I as a developer needed to know that before employment. Too many of those questions are too over the top or obscure to be of any value, unless youâre looking for a developer with a particular set of skills then a lot of those questions are worthless imho. 
So does it does go 0, 1 and terminate at 2?
It'll exit when the condition evaluates to false, so will just do 0 1.
0, 1, (break). "for" is essentially a while loop with syntactic sugar to force you to remember to use an iterator and locks the scope of it (i). The middle part is your *break condition.* Same thing as writing this: int i = 0; while (i != 2) { // code goes here i++; } Not all languages have "for", so you simply use a "while." edit: thinking of scope, it's actually more like this: { int i = 0; while (i != 2) { // code goes here i++; } } which keeps the scope of "i" limited to the loop. After a for loop "i" is out of scope, but with the original while loop code it is not.
Correct. The initializer (int i = 0) is executed first. Then the predicate is evaluated (i != 2), if it is true the code block is executed. Then the incrementer is executed (i++), then the predicate is evaluated again. This continues until the predicate evaluates to false.
for (variable = initial value, condition, incrementation) {do something;}, is the equivalent of variable = initial value; while(condition){do something; incrementation;}, so it'll stop when 2==0, "i" will take values 0 and 1 (just in case no other code is changing "i" inside the loop)
Thanks for the tip.
&gt; Given that you assume the problem to be inside the COMExceptions, why swallow the exceptions? At least log them somewhere. &gt; &gt; If your problem is indeed that another application is writing to it, the COMException will tell you as much. Good point. I think I may have swallowed them because they didn't seem useful, but I could look into that again.
Attach a debugger and step through it. Look at the values of the variables and think about what's changing. This snippet of code is as simple as it gets and it's really hard to get good at programming without trying it for yourself and actually seeing and understanding what's happening. 
Consider building a producer-consumer queue. Message busses (as others said) are one particular type of producer consumer queue. https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem
Looks like you posted a wikipedia article, let me summarize it for you... I also respond to comments containing "wikibot what is [topic]?"... Click [here](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) if you'd like me to stop bugging you. ***** **[Producerâconsumer problem](https://en.wikipedia.org/wiki/Producerâconsumer_problem)** &gt;In computing, the producerâconsumer problem is a classic example of a multi-process synchronization problem. The problem describes two processes, the producer and the consumer, who share a common, fixed-size buffer used as a queue. The producer's job is to generate data, put it into the buffer, and start again. At the same time, the consumer is consuming the data, one piece at a time. The problem is to make sure that the producer won't try to add data into the buffer if it's full and that the consumer won't try to remove data from an empty buffer. ***** **^([)** ^([About](https://www.reddit.com/user/ultimatewikibot/comments/90r969/about/ )) **^(|)** ^([Source code](https://github.com/brrm/ultimatewikibot)) **^(|)** ^(Downvote to remove) **^(])** 
I don't know how to do any of these things in any other tool, that is why I wrote it. I have never seen a tool lets you change colors by a range of values, hence replace all reds &gt; 200 and less than 230 but with a total &lt; 450 to a specific color, or erase only those colors. I use it every day, and find it useful, if others don't, then sorry to bother everyone. 
What do you mean "get into google"? Where did you apply the location? A C# program? Google maps? I don't understand your question at all :S
Whoever said I was trying to win anyone over? Happiness is about not giving a shit what anyone else thinks. 
So the key point here to understand, to make a true reusable user control it CANNOT have a viewmodel. I think you have already discovered why. Any logic needs to be moved to code behind. If your control needs to respond to an action and run a command, remember how a button works in this situation. The command is supplied to the user control through binding to the views data context. The user control needs to define a dependency property so consumers can feed ot the command, then in code behind of the user control call the supplied command at the appropriate time.
Two things that I see that you haven't shown. 1) Your gridview doesn't have a binding to you observable collection, and 2) Your control/window etc doesn't have a data context sent.
He must be talking about a job opportunity
Hmm yes that makes sense. If that's the case, then he should probably ask someone inside the company. 
Removed: Rule 3. Perhaps /r/cscareerquestions would be a more appropriate place to ask.
It's good you're providing useful answers, but a lot of us don't want to pay for services / microservices. How to build and implement/host your message bus would be a very resourceful answer. You're putting OP in the right idea though!
You don't have to pay to use RabbitMQ or Kafka. They aren't services, they're open source implementations of a protocol. 
I generally don't recommend Kafka but in this case it sounds like the right tool for the job. You can enforce ordering of events, and it handles that number of events no problems. We do several magnitudes more than that daily.
Try calling `Clipboard.Flush();` after each read?
Jesus, and here I am thinking I'm hot shit for knowing how to use 'using' blocks and tagging .ConfigureAwait(false) onto my internal API/library calls.
I've been in your situation so many times I can't even count them! One thing that worked for me is this: try to solve a problem you may have. For example: I was trying to keep notes of my fuel expenses, so I figured out I would write my own app to do just that. This simple thing gave me a full lesson on the entire stack (currently developing in ASP.NET Core 2.1 for the backend, with EF Core and SQL Server for the DB part, and Vue.js for the frontend) and it's been amazing so far! Try to ask yourself this question: is there something I do daily or weekly that I would love to simplify in some way? Try to write down a list of those things if you can, and then sort out what you would like to start on. Let me know if this is of any help, and best of luck ;)
I have this same issue. I have zero motivation to do 'to-do list apps' and the other go-to recommendations. I'm not a strict beginner, roughly the same C# experience as you, and I have a good amount of python knowledge. There's just nothing I do on a daily basis right now that I'd like to automate, script, or write a gui for. I've done quite a few projects, and when I find something even remotely motivating, I can lose myself in it (in the good sense) easily. Its just this lull between that sucks. I'm doing some of the advanced stuff on pluralsight, etc, but I'd really like a more full-featured project to implement it in. It would be nice if they had half-assed, decently sized project code to work with for these classes rather than small, straight to the point, yet contrived examples. I'm thankful for what they do have, I just wish there was more.
It sounds like it's time to do a training course. Try pluralsight, or this book: [http://csharpindepth.com/](http://csharpindepth.com/)
Sorry my eyes went right to the "Azure" suggestion...
Oh man, in this situation I heal myself with a some (maybe 4 or 5) 100 ml portion of vodka (we used to name it like "stakan") and listen to mb Three Days Grace - Never Too Late or something like this. Then you waking up in the morning, walking to the kitchen, drink some water. And you are newborned! Sit in your favorite armchair, take a little time just seeing into wall. Ok, now you hdd is defragmented and you are ready for doing something new. Now i'm trying to do kinda seech recognizer, planning the structure of desktop app. Maybe you will be interested in it
I highly recommend downloading the source code of the project you're looking at and viewing it in Visual Studio rather than exploring it from GitHub's web interface. Visual Studio will make it much easier to understand as code will be shown as part of projects and solutions rather than individual files in folders. It also makes it easier to spot patterns (the implementation behind interfaces used, for example) and follow the code path between classes.
Be sure to check if those exceptions have an InnerException as well, and if they do, if that InnerException has an InnerException, and so on.
A for each loop will be faster. But to be honest it will make very little difference. Don't fall into the trap of pre-optimising. Get it working in the cleanest simplest way and optimise if it becomes a performance issue.
StyleCop and Roslynator are great. Also Codemaid is awesome for organising your code.
Weâre in the same boat, so many âtodo appsâ tutorials and so little âenterpriseâ apps... Iâm looking forward to create a tutorial for a bigger app if someone is interested, Iâm just out of ideas on what to do...
so the Observable Collection consists of a file name and an image Uri `public class DynamicWallpaper` `{` `public string fileName;` `public Uri thumnailUri;` `public DynamicWallpaper(string name, Uri imgUri)` `{` `fileName = name;` `thumnailUri = imgUri;` `}` `public string SelectedString { get; set; }` `}` and this is how I binded GridView to this collection `&lt;GridView x:Name="DynamicGridView" IsItemClickEnabled="True" IsSwipeEnabled="False" CanDragItems="False" SelectionMode="Single" ItemClick="Dynamic_ItemClick" ItemsSource="{Binding Source={Dynamicwallpapers}}"&gt;` `&lt;GridView.ItemTemplate&gt;` `&lt;DataTemplate&gt;` `&lt;StackPanel&gt;` `&lt;Image Source="{Binding Path=thumnailUri}" Stretch="None" /&gt;` `&lt;TextBlock Text="{Binding fileName}" Margin="0,5" /&gt;` `&lt;/StackPanel&gt;` `&lt;/DataTemplate&gt;` `&lt;/GridView.ItemTemplate&gt;` `&lt;/GridView&gt;` and this is how I am loading the folders `public async void LoadThemes()` `{` `StorageFolder localFolder = Windows.Storage.ApplicationData.Current.LocalFolder;` `await localFolder.CreateFolderAsync("Dynamic", CreationCollisionOption.OpenIfExists);` `StorageFolder dynamicFolder = await localFolder.GetFolderAsync("Dynamic");` `var themes = await dynamicFolder.GetFoldersAsync();` `foreach (var theme in themes)` `{` `var thumbnail = await theme.GetFileAsync("Thumnail.png");` `dynamicwallpapers.Add(new DynamicWallpaper(`[`theme.Name`](https://theme.Name)`, (new Uri($"ms-appx:///Dynamic/{`[`theme.Name`](https://theme.Name)`}/Thumnail.png"))));` `}` `}` I have changed the way I send Uris to the collection so I can use them as image sources 
This was the very first thing I tried. However, this gave me the same error.
"Item" is taken from a "dynamic" object. As written in my code, I've tried with the "item.id" and I manually casted the reply I got from "item.id" into an "int". However, I got the same error. I have dynamic data to work with.
So your solution would be to create another WPF-Project without MVVM and use it as a library for UserControls and CustomControls? 
Create a personal cloud system to keep all of your files in, that you can explore and edit from any device. This'll give you some experience in a lot of different areas
Games via Unity are another intermediate way to mess around with C# more. Blowing things up holds my attention better then parsing text. 
What larger projects have you been looking at? It'd be helpful to know what you're hoping to get into long-term to advise you on next steps.
1. Find work. 2. Find company where you would really like to work and ask what you need to understand, learn it by making simple applications with those stuff and go to point 1. 3. Create a product you would like to use, make it with assumption that you are going to sell it (variant of point 1 with you as boss). 4. Define a product you would like to use, define what you need to make it, learn it by making multiple small application, go to point 3. 
 No reason to create another project.
The Read method will return how many bytes it read, and you might have to keep calling it til you've read the amount you need. The buffer being 1024 bytes just specifies the max amount it can read per call. Read makes no promise that it'll read more than one byte (return value of 0 means end of stream). Read the docs again. And mind the offset/length params for the Read calls.
&gt;the value of the stream variable is either the entire stream length of the file Not sure what you mean by this? &gt; or just the integer 1024 (a byte array of [0, 4, 0, 0]). Or how the hell you managed that. Anyway, the purpose of `Stream.Read` is to fill a buffer with *up to* N bytes. It does *not* guarantee that it will fill the entire buffer (even if more data is available), nor does it make any claims about how much data any particular stream implementation stores in its own internal buffers in advance. `FileStream` has a default buffer size of 4096, you can [specify a different one in the constructor](https://docs.microsoft.com/en-us/dotnet/api/system.io.filestream.-ctor).
&gt; or how the hell you managed that Probably because I tried BitConverter.ConvertToBase64String, since md5 can't operate on byte[] directly. This is my first time working on something like this so I'm still trying to figure out how to make this all fit together.
Thanks
I would say that there's nothing wrong about not doing _"big"_ projects on your own. Sure, it would help a lot, but what helped me was learning more about design patterns, SOLID principles, software architecture and stuff like that. With a strong knowledge about things above and platform you use (which can be learned from small focused projects), every bigger project is just a matter of time you put in it.
I use C# at work to create [b2b software](https://en.wikipedia.org/wiki/Business_software). I recommend you to get a job.
I'm afraid it's very messy at the moment as I have lots of demand for new features from users and not enough time to tidy! If you're interested in the language server, it's a generic F# server you can find it here: [https://github.com/tboby/cwtools-vscode/tree/master/src/LSP](https://github.com/tboby/cwtools-vscode/tree/master/src/LSP) and then my implementation is here: [https://github.com/tboby/cwtools-vscode/blob/master/src/Main/Program.fs](https://github.com/tboby/cwtools-vscode/blob/master/src/Main/Program.fs) and the analysis library is here: [https://github.com/tboby/cwtools/tree/master/CWTools](https://github.com/tboby/cwtools/tree/master/CWTools) The language it supports is Paradox Interactive's game modding language, which you can see an example of here: [https://stellaris.paradoxwikis.com/Event\_modding#Example\_Events](https://stellaris.paradoxwikis.com/Event_modding#Example_Events). It's somewhere between a data structure and a scripting language, which has made it very interesting to build support for. Some (old) gifs: [https://i.imgur.com/EPb4XSL.gif](https://i.imgur.com/EPb4XSL.gif) [https://i.imgur.com/qeyMSyo.gif](https://i.imgur.com/qeyMSyo.gif) [https://i.imgur.com/IaqoFgF.png](https://i.imgur.com/IaqoFgF.png)
oh, then item.id is not an int, or item.heading is not a string.
Damn, my toolbox keeps getting wiped/deleted :(
I would go take a look a the eshoponweb project, and the eshoponcontainers project, see if you can create them and truly understand them, if you can, you're probably ready for a job in c#
A solution I've found was to move the trigger into the ControlTemplate from Style. Is the TargetName now in scope? Not entirely sure how this resolved the issue but I'm happy with the results. The only issue I need to figure out now is how to round the corners of the rectangles properly &lt;Style TargetType="Button" x:Key='Circular'&gt; &lt;!--Set to true to not get any properties from the themes.--&gt; &lt;Setter Property="OverridesDefaultStyle" Value="True" /&gt; &lt;Setter Property="Template"&gt; &lt;Setter.Value&gt; &lt;ControlTemplate TargetType="Button"&gt; &lt;Grid&gt; &lt;Border x:Name='_bottom' CornerRadius='5' BorderBrush="Black" BorderThickness="0,0,0,2"&gt; &lt;Rectangle Fill="Gray" /&gt; &lt;/Border&gt; &lt;Border x:Name='_top' CornerRadius='5' BorderBrush="Black" BorderThickness="0,0,0,2" Margin='0,0,0,10'&gt; &lt;Grid&gt; &lt;Rectangle Fill="LightGray" /&gt; &lt;ContentPresenter ContentTemplate="{TemplateBinding ContentTemplate}" Content="{TemplateBinding Content}" HorizontalAlignment="Center" VerticalAlignment="Center" /&gt; &lt;/Grid&gt; &lt;/Border&gt; &lt;/Grid&gt; &lt;ControlTemplate.Triggers&gt; &lt;MultiDataTrigger&gt; &lt;MultiDataTrigger.Conditions&gt; &lt;Condition Binding='{Binding RelativeSource={RelativeSource Self}, Path=IsPressed}' Value='True' /&gt; &lt;/MultiDataTrigger.Conditions&gt; &lt;MultiDataTrigger.EnterActions&gt; &lt;BeginStoryboard&gt; &lt;Storyboard&gt; &lt;ThicknessAnimation Storyboard.TargetProperty="Margin" Storyboard.TargetName="_top" Duration="0:0:0.1" From="0,0,0,10" To="0,10,0,0" /&gt; &lt;ThicknessAnimation Storyboard.TargetProperty="Margin" Storyboard.TargetName="_bottom" Duration="0:0:0.1" From="0,0,0,0" To="0,10,0,0" /&gt; &lt;/Storyboard&gt; &lt;/BeginStoryboard&gt; &lt;/MultiDataTrigger.EnterActions&gt; &lt;MultiDataTrigger.ExitActions&gt; &lt;BeginStoryboard&gt; &lt;Storyboard&gt; &lt;ThicknessAnimation Storyboard.TargetProperty="Margin" Storyboard.TargetName="_top" Duration="0:0:0.1" From="0,10,0,0" To="0,0,0,10" /&gt; &lt;ThicknessAnimation Storyboard.TargetProperty="Margin" Storyboard.TargetName="_bottom" Duration="0:0:0.1" From="0,10,0,0" To="0,0,0,0" /&gt; &lt;/Storyboard&gt; &lt;/BeginStoryboard&gt; &lt;/MultiDataTrigger.ExitActions&gt; &lt;/MultiDataTrigger&gt; &lt;/ControlTemplate.Triggers&gt; &lt;/ControlTemplate&gt; &lt;/Setter.Value&gt; &lt;/Setter&gt; &lt;/Style&gt;
To avoid a NullReferenceException I'd just return an empty List&lt;Tuple&lt;DateTime, DateTime&gt;&gt;. 
lmao I'm 15
You can have a default clause in your switch statement. Put your return null in there
Find one FOSS project and double down on learning it and start contributing to it now. Save all of this as from what it sounds like, you're pretty far above most people your age.
IMO, it depends whether the method should "allow" for arguments that doesn't match any cases. If it shouldn't, I would recommend throwing an exception, since that would make it easy to locate where something went wrong, rather than sending a null scrambling down the drain. If it should allow for it, I think an empty list is a appropriate return, since it shows that nothing is wrong, just that the method procedure didn't produce any results. Just my 2 cents 
Personally, I'd be looking to change the type of `placement.TimeSheetFrequency` to an `enum` if at all possible, since this will reduce the likelihood of such a situation arising. However, it won't eliminate it completely, and you still need to consider it. So you have three choices: - Return an empty `List&lt;Tuple&lt;DateTime, DateTime&gt;&gt; - Throw and exception - Return `null`, as you are currently doing The choice is ultimately yours, but some pros/cons of each to consider: - The empty list guarantees that there's always a valid return value. If the frequency isn't one that's recognised, there's nothing in the list. This will prevent exceptions - but it will also mean there's no way for the caller to detect if something's gone wrong, since it can't tell the difference between an empty list (due to an invalid frequency) or an empty list (due to a valid frequency but no data). - Throwing an exception is a very clear message that having a frequency you didn't expect is not allowed. But it puts the onus on the code that calls this method to catch and deal with this exception appropriately. - Returning `null` still places the onus on the code that calls the method to deal with the problem. But it would indicate that perhaps having a frequency that's not on the list is not something wrong with the data, it's just a case that you've chosen not to handle
In cases like this, the convention is to always return an empty list. As an example, you want to have a list of all people whose favorite color is brown. If there are no people whose favorite color is brown, then the result is an empty list. `null` has a different meaning, if it has a meaning at all. An empty list is still "the list of all people whose favorite color is brown".
&gt;try to solve a problem you may have. This is one of the most useful things here. Here's an example of something like this I JUST went through. I've been downloading a bunch of compressed files into a directory. They each go into their own folders so going in and right clicking each one, unrar then deleting the rar files was annoying. So I made an app to take care of that for me. After the basic functionality was done I decided to go fancy, adding dependency injection to it, then DevExpress controller since I have a license from work. Every time I use it I think, what can be better. First was that I was using just an EndsWith('.rar') to identify rar files, so I figured, seems like a good time to learn a bit about regex, so now I have a regex matching pattern that will take care of most rar files like r01, part1, .rar etc. Slowly building it into an overly developed bloated app but who cares? I've been learning a bunch with it and I still use it all the time, so win win. I have a short to do list I want done, I know how to do it and I've done it many times before, but practice is always good so I'll do it soon enough.
Depending on what you want to do with the events stream processing might be the best choice over event messaging. Here is a brief article on stream processing. https://wso2.com/library/articles/2018/05/what-is-stream-processing/ I got the idea of Stream processing from the book Designing Data Intensive Applications. https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/ref=sr_1_1?ie=UTF8&amp;qid=1532356233&amp;sr=8-1 
 **for (var i = 0; i &lt; numbers.Length; i++)** and then **Convert.ToInt32(numbers\[(i + 1)\]))** Think of a length of 10 elements, from 0 to 9. You are in position 9, which is &lt;numbers.length. Then you try to compare it with a element in (i+1) == 10, there is no sutch index in the array. Positions in your array of length 10: 0 1 2 3 4 5 6 7 8 9 (there is no place for 9+1 index) You are about to learn one of the oldest flames of programation.
I'm on my phone but I assume numbers(i+1) in your conditionals is causing it on your last iteration (when i=numbers.Length -1
Initially i = 0 -&gt; go inside the braces, at the end of the braces increment i by 1. Then i=1 -&gt; go inside the braces, at the end of the braces increment i by 1. Then i=2 -&gt; So don't go inside the braces. Continues execution after the braces end. Interestingly it would have been an endless loop if i were incremented in a way that i never hits the checked value. For example; for (int i = 1; i != 12; i=i+2) { } 
Also, your code wonât find the maximum input, but rather print the larger of the last two elements
A good lesson to learn, though also happens to be unnecessary to the actual solution, but it is good to mess up sometimes to learn a lesson or two.
Ye, I just sat on my code for a few more minutes and I had realised that. Thank you so much! 
Have you tried Up-For-Grabs/Good-First-Issue issues in OSS Projects? These are meant to be dealt by newcomers trying to get a grip on large architectures by providing a well defined, reproducable issue to be dealt with.
Thanks! I talked to a friend and I had realised that my code will be much simpler this way: output = 0; for (var i = 0; i &lt; (numbers.Length); i++) { var number = Convert.ToInt32(numbers\[i\]); if (number &gt; output) output = number; } Console.WriteLine("The maximum number out of all is {0}", output); And it works, i'm kinda happy lol
Your reading bytes into buffer from the stream and then using the stream. You need to work against buffer not the stream.
I'd do it like this... int output = input.Split( ',' ).Select( num =&gt; int.Parse( num ) ).Max(); Or if you wanna do it the long way... int output = 0; var numbers = input.Split( ',' ).Select(number =&gt; int.Parse(number)).ToArray(); for(int ix = 0 ; ix &lt; numbers.Count() ; ix++ ) { int number = numbers[ ix ]; if(ix == 0 || number &gt; output) { output = number; } } I check if ix is 0 and then set it because the highest number may not necessarily be greater than 0.
Maybe the Book of the runtime can help you? It contains in-depth information about how the runtime is organized. [https://github.com/dotnet/coreclr/blob/master/Documentation/botr/README.md](https://github.com/dotnet/coreclr/blob/master/Documentation/botr/README.md)
It's kind of too early for me to understand the second line. I have no Idea was Select neither what .ToArray does. Nevertheless, thank you for trying to help me! I'll try to use that tip you gave me.
Not to worry, glad I could help. Make sure you set on first cycle or you answer won't account for negatives. ToArray does exactly what it says on the tin. It takes an IEnumerable collection and converts it to a simple array. Select allows you to *select* what you want from each element in an IEnumerable collection by passing in a function (the lambda *number =&gt; int.Parse(number)* in my case) and returning that as a new collection.
How can I work with the buffer though? I probably should have posted this in r/learncsharp but since I'm here already I figured I'd ask. The buffer is just an empty array of 1024 bytes, correct? Because when I tried FileStream.CopyTo(buffer) but I got a System.OutOfMemoryException because I tried to copy a 25mb file into 1024 bytes of memory. Is there a way to copy the filestream to a new filestream, but only copy the first 1024 bytes? This is completely new territory for me, I just started learning c# a few months ago so I apologize for not knowing too much. 
I'm not 100% on this, but I believe `BIT_SBLK_GC_RESERVE` is only set during garbage collection for objects that the GC has determined to be pinned elsewhere (i.e. it encountered a pinned reference to this object during the sweep phase).
&gt; Edit\* For the absolute life of me, I cannot get the code to format properly on this new reddit Select the code, click the three dots next to the quotation marks, and then the button with the T in the top left.
See if this guy ever got the help he asked for: [https://www.reddit.com/r/jobbit/comments/8z0ydo/hiring\_rewriteupdate\_old\_gaming\_plugin\_quick\_cash/](https://www.reddit.com/r/jobbit/comments/8z0ydo/hiring_rewriteupdate_old_gaming_plugin_quick_cash/)
Despite what people tell you significant open source projects are in fact very hard to get into even for experienced devs. In fact I think the advice to learn by looking at open source project is bullshit unless the projects are very small in scope.
That's fair enough, Thank you! A slight follow up, surely if I just did a post-condition check such as `if(list != null)` would more or less be the same as `if(list.count &gt; 0)` I guess there is still room for a NullReference to be throw if the code was ever used by another programmer who isn't familiar with the program flow.
Try inputting -1, -2, -3..!
How does the GC know it's pinned?
It won't work, because output = 0, I know.. It'll write ..... is 0 
Correct..!
The GC recursively walks all references connected to GC roots and marks all objects it encounters, so it knows what objects are still alive and which can be garbage collected. It also looks for variables with the `pinned` modifier (`fixed` statement in C#) while doing this.
I hate to rain on your parade (especially since this looks to be your first blog post), but `makecert` is deprecated (see [top of this page](https://docs.microsoft.com/en-gb/windows/desktop/SecCrypto/makecert)). It's been replaced with the Powershell cmd `New-SelfSignedCertificate`. Perhaps your next blog post could be on that? :)
You need to use the Stream.Read method. Have a Google for read first x bytes from stream. Then you need to do your hash against the buffer. If the method won't take a byte[] turn it into a MemoryStream and pass that.
An easier way to understand the lambda (`=&gt;`) is to think of it as a mini nameless function/method. The part before is/are the parameter/s, and the part after is the value of what you are returning. For example, (x =&gt; x*x) will square x.
In addition to what /u/atokamak said, here's another good trick to use: think of the degenerate/extreme cases. For example - what happens when the array has zero elements? How about a single element? In that case, it's even easier to see that you're always comparing the first two. The good thing about this trick is it forces you to think about the non-standard cases, which are often the easiest to mess up. In a lot of cases though, it's actually easier to reason through. (Plus these are the exact cases you want to write unit tests for, but you'll get there in due time.)
This is exactly what I meant. Found myself so many times needing something and the existing solutions didn't meet my needs. It feels so rewarding to start writing your own app suited to your needs and learn as you go.
I'm actually really glad that someone commented on this post! I was sure there was another simpler way to do what I wrote in the post, but didn't know how to do it (didn't even know that `makecert` was deprecated). I'll surely take a look at your suggestion and when I'll have the adequate skills with it I will write another blog post! ;) Thanks again!
First off, knowing as much as you know at 15 is awesome! I work with folk twice your age that are at a comparable skill level. Several are still working on building endpoints that you've described, so know that you're not behind by any means. With that, you should take some time to build something you enjoy, and not force yourself to learn things. It's clear that you have a passion for programming. It's also clear that you're skilled enough to build at least small applications. Here are my recommendations: * Find a developer group in your area. I live in a smaller city and we have several groups that focus on joint development. If you can't find a local one, there are many online as well. The benefit here is that you can directly learn from other more experienced developers and they will be more than happy to help a new member. Most of these groups work on more entertaining projects that can vary in size. Even if the project is huge, they do a great job of handing off smaller pieces based on your skill set. This is one of the best ways to learn. You will have experienced developers who have a view of the overall design, to gauge your skill set, and allow you to develop pieces that fit into the project but aren't too overwhelming. If you have questions, absolutely ask them. If you're having trouble, absolutely ask for help. If things are too easy, absolutely tell them so they can give you bigger pieces. There are plenty of groups like this and most would to have someone as experienced as yourself help out. Any projects like this look really good on a resume as well. * Someone else mentioned trying out some Unity projects. This is a separation from enterprise applications, but is still a good way to pick up on the larger pieces. It introduces more graphical elements, but you're still working a lot with objects and interfaces. There are also tons of projects ranging from super small, to very large. I would also recommend this if you're at all interested in video games. It helps explain many pieces and anything you build can go into a portfolio if you decide to jump into that industry at any point. * Lastly, don't worry about getting a job now. You don't need to both yourself with work unless you're looking to make some money. Instead, find companies around that are willing to take you on as an intern. Places like financial institutions, local colleges, hospitals, all have developers on staff. Shadowing them will show you what the actual day to day looks like for a developer and gives you first hand experience. They would almost definitely let you help with programs as well. This will show you review process, QA, agiles methodology, and other things that will help you build on what you already know. Some even pay interns depending on the level of work you do. Now, this isn't something that will take a lot of time. It may only be one day a well, but that alone can be super helpful. 
Ditto on most of this! Another good trick to learn more about how a project works, is to look at its tests (not its source), it will also likely improve your TDD skills, and get you in the "test"-mindset. Also: If you feel your C# basics are sharp enough, and that you have decent enough understanding of the ecosystem, then I'd say you should try to specialize on some particular application of C# / .NET. For instance: Do you want to work with the web, games, desktop apps, or is mobile apps more your thing? Each field has its own depth, and is often extremely complex and intriguing in itself (C# aside). Also, *C# is only the "language" of what is being expressed*, it says nothing about the *content*. Different fields revolve around different ideas, and they all use their own paradigms, standards and conventions. A game in C# is extremely different "in shape" from a web application. â Two books, written in the same language, but in *very different genres*. So if you are confused after jumping between OS projects on GitHub, well... that might be why! I guess the TL;DR version is: Where do actually want to apply your skills? 
If you're doing something for each item returned, you don't need any special logic. Just do something for each item and the list, and if it is 0 times, that is fine.
yup, that's termed scaling up. I suppose I should have included that the easiest way to scale in the cloud is by using PaaS solutions like [Azure App Services](https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling) or [AWS Elastic Beanstalk](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.as.html). You deploy directly to these services and the cloud provider controls the actual application running. You control the parameters to which the application runs, like environment variables, security, scaling settings, deployment, networking, ssl, etc. They're a really simple way to host a web application. They are a bit more expensive than if you got a DigitalOcean droplet or Linode VPS, but the hands off approach is worth it for most people. Take, for instance, how Linode upgraded my Linux server last weekend and on restart Docker did not fully come up and 2 of my sites were down for a few minutes. This doesn't happen in Azure App Services. If a server fails, heck if a rack of servers fail, you won't even notice (Based on your SLA). You get automatic updates without knowing. There are free versions of these PaaS's too ([Azure ](https://azure.microsoft.com/en-us/pricing/details/app-service/windows/)/ [AWS](https://aws.amazon.com/elasticbeanstalk/pricing/)) with only a few restrictions. I do tons of demos this way and I can dispose of the entire app just as quickly as I created it. These free tiers are not meant for production. But when you want to go live, you can literally flip a switch, scale up, and add a custom domain and you're good to go with the same instance you were just testing on.
Thanks everyone for explaining this very simple function to me. I guess I wasn't thinking and I am used to seeing i &lt; 3 in the termination clause. PS: what does syntactical sugar mean?
&gt; `.Select( num =&gt; int.Parse( num ) )` Why so much bloat? .Select(int.Parse) 
Create a maxValue variable, if the current value in your loop is higher assign the current value. When the end of the loop is reached youâll have your answer. Thereâs no reason to worry about the next value or previous values of the loop, those donât matter unless you sort the loop before hand then the highest would always be the last value anyway. Which leads to the second suggestion, sort the loop before you get max. var numbers = input.Split(',', SplitOptions.IgnoreEmpty).Select(r =&gt; Int32.Parse(r)).OrderBy(o =&gt; o); var maxValue = numbers.Last(); Or var maxValue = numbers.Max(); 
0 would still be the highest value
Syntactic Sugar is a feature in a programming language feature that makes doing certain types of operations easier, but not required. FOr example, a "for" statement in C# is not really necessary, as a "while" loop can certainly do the exact same thing, but it looks waaay nice with the for loop, so you could call the "for" statement some form of syntactic sugar. Another great example for C# syntactic sugar are extension methods. In reality they are just a static class method like every other class method, but in the language it makes it look like you can extend an non-extendable class (a "sealed" class). Lambda expressions, also, are a form of syntactic sugar for anonymous functions, they are an extreme shorthand that makes it easy to write a small anonymous function for us in something like LINQ methods.
Which is the correct answer, -1 is LESS THAN 0. 
Haha good point, will use that in future
I'm just curious what the purpose of this is?
Just out of pure curiosity: What is this for? Obviously unblittable objects are usually unblittable because they potentially contain other GC references, so I'm just wondering what you're implementing.
Also can spin up a quick console app with Console.Writeline(i) in there and a Console.ReadLine() *after* the loop.
Get a youth work permit.
 .Select(int.Parse).Max() Ok, I see you're ready for the next level. .Max(int.Parse)
I made a Pointer type that works with reference types, but the problem is that if the GC compacts the heap, the Pointer will become invalid. cc /u/Ravek
&gt; I made a Pointer type that works with reference types Can we go one 'why' deeper here?
&gt; but the problem is that if the GC compacts the heap, the Pointer will become invalid. Yes this is why you can't do it in the first place. So is it fair to assume, given your original question, that you're trying to implement some kind of pointer that pins all references all the way down?
Of course it can: https://msdn.microsoft.com/en-us/library/s02tk69a(v=vs.110).aspx
You set a default and call break;
Hey man, first off don't worry just yet. You still have a lot of time to apply yourself if you're looking to get into C# professionally or any programming. Can you expand a bit on Business Informatics? I've not heard of a degree with that title. I can assume what it is but what are the main concepts the degree emphasizes on? Secondly, I'm not a C# professional either just yet so I am in a similar position. I took a quick look at your Pokemon Class. It looks like the main issue with it is its size. A lot of that stuff really shouldn't be in the Pokemon class. So try to logically split the class members into their own classes. One quick example I see is the **experience** methods could probably all go into its own class that the Pokemon class then uses. The method ExperienceIncreaseForNextLevel() determines the amount of exp for a Pokemon to level up. I would put that in its own ExperienceSystem (or something) class and pass in the Pokemon type to then determine that. Another one could be to separate out the Pokemon attributes (height, weight, etc) to its own class Attributes then have every Pokemon inherit that class. Also when you near \~8 or so parameters in a method, you should step back and think, is there a better way to write this? I'm not saying you wont ever need 8 params, but in most cases especially for beginners, its probably best to refactor the method all together. Try and look at **Object Oriented Programming** in c#. I think that would help you out tremendously. Heres a few beginner resources I used: [https://www.amazon.com/C-Players-Guide-3rd/dp/0985580135/ref=pd\_lpo\_sbs\_14\_t\_0?\_encoding=UTF8&amp;psc=1&amp;refRID=ECA94ZAWY8GJTREX7CPE](https://www.amazon.com/C-Players-Guide-3rd/dp/0985580135/ref=pd_lpo_sbs_14_t_0?_encoding=UTF8&amp;psc=1&amp;refRID=ECA94ZAWY8GJTREX7CPE) [http://www.csharpcourse.com/](http://www.csharpcourse.com/) C# Players guide was really helpful for me to understand some very basic programming (not just c#) concepts.
I've played around with my idea from the previous comment a bit, and this seems to work. I couldn't for the life of me tell you if this is reliable or sensible, though: public static class ObjectPinner { private static readonly Action&lt;object, Action&lt;object&gt;&gt; PinImpl = CreatePinImpl(); private static Action&lt;object, Action&lt;object&gt;&gt; CreatePinImpl() { var method = new DynamicMethod("InvokeWhilePinnedImpl", typeof(void), new[] { typeof(object), typeof(Action&lt;object&gt;) }, typeof(ObjectPinner).Module); var il = method.GetILGenerator(); // create a pinned local variable of type object // this wouldn't be valid in C#, but the runtime doesn't complain about the IL var local = il.DeclareLocal(typeof(object), pinned: true); // store first argument obj in the pinned local variable il.Emit(OpCodes.Ldarg_0); il.Emit(OpCodes.Stloc_0); // invoke the delegate il.Emit(OpCodes.Ldarg_1); il.Emit(OpCodes.Ldarg_0); il.EmitCall(OpCodes.Callvirt, typeof(Action&lt;object&gt;).GetMethod("Invoke"), null); il.Emit(OpCodes.Ret); return (Action&lt;object, Action&lt;object&gt;&gt;)method.CreateDelegate(typeof(Action&lt;object, Action&lt;object&gt;&gt;)); } // obj will be *temporarily* pinned while action is being invoked public static void InvokeWhilePinned(object obj, Action&lt;object&gt; action) { PinImpl(obj, action); } }
Use VS Code on Mac. Works just fine with the recommended extensions.
Shouldn it be `that : !that`?
So, Business Informatics is basically a CS degree where the math core is swapped out for a business core, and is a bit less focused on programming. I've taken some courses from CS and CIS though (network operating systems, networking 1 and 2, desktop operating systems, and a few others like that). Here are a look at the degree - [http://coursecat.isu.edu/undergraduate/business/informatics/#programstext](http://coursecat.isu.edu/undergraduate/business/informatics/#programstext) I'll take a look at that book for sure.
No principle can help you if you think it's bullshit. I think you should trash SOLID. It helped me understand some important things when scaling architecture, and sometimes I decide on a refactor because the code is in breach of SOLID, but I agree with you that it is an assessment with several valid perspectives in most instances. Software development is rarely as clean as pattern descriptions imply.
Yep, that works. Thanks! 
It's kind of hard to know without more context what your code is doing, but a few thoughts: * what stuck out immediately, as LondonPilot mentioned, is that `TimeSheetFrequency` should be an enum. If you're switching over a string, as you appear to be, that's a code smell. An enum: * makes you more productive, as your IDE will auto-expand possible values (type `sw`, tab twice, type `placement.TimeSheetFrequency`, then press the down arrow, and `case` statements for all possible values get generated) * makes refactoring easier, as renaming values automatically adjusts the switch statement * avoids bugs, as removing values automatically generates a compile-time error, rather than throwing at runtime. * the other smell I see here is the Tuple of two `DateTime`s. (Moreover, as this is the .NET 4.0-style tuple rather tan the more recent `ValueTuple` syntax, the members can't actually get named.) Tuples are convenient for when you really want to associate two values with each other, but the more cynical take is they're more of a cop-out of a _real_ type. You should at the very least consider moving to the more modern syntax, which should hopefully make your intent a _little_ clearer. Instead of `new List&lt;Tuple&lt;DateTime, DateTime&gt;&gt;`, consider `new List&lt;(DateTime From, DateTime Till)&gt;`. At least, I assume that's what the two timestamps mean. It's honestly quite unclear. What you _really_ should be doing is a real type, whose property members make the intent clear. (Also, as another nitpick, if it's Frequency.Weekly, it should also be Frequency.Month**ly**.)
"question is to be that or not to be not that"?
Just FYI, you can do this backward in WebAPI and it's completely useless because you can't use something like dictionary&lt;int, string&gt; for an enumerated value as a json object... 
Highly recommend this one. Unity3d is a great way to learn more that can produce fund results. Also there is a silly number of official tutorials (hrs and hrs, with videos) that can expose you to game Dev and C#. At the end of each tutorial, challenge yourself to make that basic game you just made into something more interesting. Also, in the unity store you can find lots of free assets. Assets you can download and then play with the code.
Sounds interesting, if you ever finish it, I'd love to see it.
Glad to see my blog article is still useful, even years after I wrote it! :D
Why not use ref locals and ref returns, and all of the other pointer-like features of csharp (eg, span)?
Rectangle has RadiusX and RadiusY properties to round the corners
Have a read about *ByvalTStr* [here](https://msdn.microsoft.com/query/dev11.query?appId=Dev11IDEF1&amp;l=EN-US&amp;k=k(System.Runtime.InteropServices.UnmanagedType.ByValTStr\);k(TargetFrameworkMoniker-.NETFramework,Version%3Dv4.6.1\);k(DevLang-csharp\)&amp;rd=true).
C# developer with 10 years experience. I'm not exactly sure what you're trying to achieve with these projects - can you elaborate? As for the Pokemon one. This is just one horrendously giant class. A class should do one thing and one thing very well. It should also be very clear what it does just by giving it a once over, or perhaps just the name. The methods you've written are clear though and seem to achieve that their method names indicate.
Well I don't know... The Liskov substitution principle is very clear cut. If only the rest of SOLID was so good.
For C# I prefer Richard Clayderman. For Python I prefer The Bee Gees. For JavaScript I just tap my foot and beat my head against a wall.
At that point your option is to either use the smallest possible value or initialize it to your first element. 
If you're not implementing logic within your getters/setters, you can get away with using self-implemented properties aka properties without a private backing field. It'll help cut down on the number of fields significantly. Later, you can add logic to prevent misuse of properties and use private backing fields at that point. This is a hotly debated topic but I think you could do with considerably fewer comments. Your property names are self explanatory such that the comments effectively just reiterate what we know from the property name. The constructor is kind of enormous. My personal maximum for a constructor or method is 4 parameters. More than that and I'll rethink the class and consider breaking the parameters out into an "options" class where it makes sense. In your case, I'd consider defining a nice serializable set of classes to define the different Pokemon, and then store the Pokemon definitions in XML. At runtime you would load the Pokemon from XML and deserialize them into the proper objects to work with. So you would effectively never instantiate a Pokemon from code directly. As it has mentioned, each class should ideally do one thing. So consider what "things" your project must do, and with what kinds of objects it should do things with, name them all (actually write it down), and think about the program structure and how all those nouns and verbs should fit together. Clean Code and The Clean Coder are my favorite books. I highly recommend them.
Thank you for your article. May I suggest you also look at Autofac which solves the problem very elegently using keys (this is psudo code I am writing from memory): builder.RegisterType&lt;Formatter&gt;().Keyed&lt;IFormatter&gt;("basic"); builder.RegisterType&lt;FancyFormatter&gt;().Keyed&lt;IFormatter&gt;("fancy"); In your class you inject `Func&lt;string,IFormmater&gt;`. public class MyController { public MyController(Func&lt;string, IFormatter&gt; formatterFactory) { //.. } public ActionResult&lt;string&gt; Get(bool fancy) { IFormatter formatter = formatterFactory(fancy ? "fancy" : "basic"); formatter.Format(...); } } 
My trouble is that I VASTLY prefer non video tutorials and the vast majority of unity tutorials i find are all videos. I did find some decent looking text ones Iâve started looking through, but always open to recommendations
In that case try codeproject there are alot of text based tutorials there. Just have to search a bit for them.
That's great advice
Not sure if this will be enough, but look into the `DataType` setting [here](https://docs.microsoft.com/en-us/dotnet/api/system.xml.serialization.xmlelementattribute?view=netframework-4.7.2).
I wouldn't use a Timer because if your API is run say in IIS, it may shutdown because of the app pool, so you'd lose the timer... I would suggest creating a separate service like a Windows Service and having there the logic to call the API once a day or so. In this way you can even catch the errors and you're able to separate this logic from the API one.
Good point. As of now for every request I check if 24 has passed and if so I asynchronously update data. (It's not important data to be up to date). Are there any advantages to creating separate service aside separation of logic from API?
I donât know the exact steps you take to do this, but I assume that every time that the API is called, before returning 200 with the result, you do the synchronization logic. I would separate that sync logic from the rest of the API primarily so it could run faster, but other reasons could be that you want to do this sync on another server or another context for example. If you have to maintain the API as is without changing anything another solution could be to have a cronjob or something like that calling the API every 24 hours or so.
Datatype only allows hexBinary and base64Binary if it's byte\[\]. 
This unfortunately does not allow conversion the input to unicode. I get the string read as random symbols because it's not using the correct codepage.
Thank s
&gt; C# will ever vectorize your code It does. I ran a test back them, I created a simple Vector3D struct (3 float). When I ran it against the System.Numerics.Vector3 (which is known to use SIMD) my struct was faster for some operation, and was equal to the remaining. Conclusion: Either System.Numerics.Vector3 doesn't use SIMD on an SIMD capable CPU, or C# does vectorize your types.
In the memory, it is 1 byte, in the CPU (registers) it is 32 bytes.
I'm not sure, but probably \_\_arglist is not implemented in mono.
Hold my beer, I love refactoring legacy code. I like to try to keep files under 200 lines long if possible. There are thousands of ways to do whatever you're doing (I actually have no idea what you're doing) with Pokemon but the quickest and safest way would be to break up your Pokemon class. You can read hundreds of books on how to refactor code but the best teacher is by example. So: Cut out the `Show*` methods out into their own class e.g. `StatsService` so you can call `statsService.ShowEVs(somePokemonObject)`. I would also do the same with `IncreasePokemonsEffortValue*`, `IncreasePokemonStats`, and `GenerateIndividualValues` by cutting them out into their own service again, in an effort to **reduce the amount of logic contained in the Pokemon file** (important point). Put all the enums into their own file as well. Put `List&lt;Move&gt; _MovesLearnedByHM` and friends into their own [POCO ](https://en.wikipedia.org/wiki/Plain_old_CLR_object)e.g. `PokemonMoveConfig`. Do the same with the Pokemon's stats and base stats, IVs,EVs -- use a `PokemonStats` POCO that has Attack, SpecialAttack, Defense etc. Try extending that theory elsewhere yourself to reduce the amount of properties on that class. Always use auto getters and setters. Code smell: don't put logic in getters/setters and if you do weird things in getters or setters make it a regular method. E.g. instead of `somePokemon.Level = 6` do `somePokemon.UpdateLevel(6)` since the setter for Level does some jank. Definitely cut out the constructors like the others here have said, and set the properties when instantiating, e.g. var pkmn = new Pokemon { Name = "whatever", Level = 0, Nickname = "you get the point." }; That should help make that class a little more readable.
&gt; Later, you can add logic to prevent misuse of properties and use private backing fields at that point. This. Changing what the get and set do doesn't change the API/ABI, but switching a class variable to a property does (and thus requires a recompile of everything that uses it).
"Unit" is like Agile and teenager sex, everyone talks about it, everybody say they do it, nobody do it correctly or understand the tradeoffs of their actions. This conversation summons [Wittgenstein's Beetle](https://medium.com/@fagnerbrack/wittgenstein-s-beetle-in-software-engineering-dcea89a5db92) at its peak. See [this code](http://jsfiddle.net/fagnerbrack/n0t6pof9/) from [a post](https://medium.com/@fagnerbrack/how-to-mock-the-network-with-nock-and-javascript-to-test-parts-of-a-system-you-need-a-good-design-9432c9c05a30) I've written using JavaScript (lol-javascript-blah-blah... forgive me father for I have sin). The test doesn't "Mock" the \`findPostsTitle()\` method internally. Instead, it implements an \`InMemoryDataSource\`. You simplify the code to be just \`ListOfPostsTitle(HttpServerDataSource()).toString(asHtml)\`. Then the test would use \`ListOfPostsTitle(InMemoryDataSource()).toString(asHtml)\`. You can "unit" test \`asHtml()\` and use it in test and prod. The \`ListOfPostsTitle()\` tests will just use a lot of components together to see if they fit. Is that a unit tes? Is that an integration test? Honestly, who cares? I only differentiate tests that run faster and give me more meaningful error messages from tests that run slowly and give me more cryptic error messages. I run the first every time I make a change and I have more of it, I run the second before doing the commit and I have little of it. The [test pyramid](https://martinfowler.com/bliki/TestPyramid.html), etc. I wrote this very fast so I didn't have time to make it shorter. Cheers
CharSet.Unicode doesn't do it either?
I prefer Blend Behaviors for this. public class TextBoxChangesDoubleValueOnScrollBehavior : Behavior&lt;TextBox&gt; { private static double Scale { get { if (Keyboard.IsKeyDown(Key.LeftCtrl) || Keyboard.IsKeyDown(Key.RightCtrl)) return 10; if (Keyboard.IsKeyDown(Key.LeftShift) || Keyboard.IsKeyDown(Key.RightShift)) return 0.1; if (Keyboard.IsKeyDown(Key.LeftAlt) || Keyboard.IsKeyDown(Key.RightAlt)) return 0.01; return 1; } } protected override void OnAttached() { base.OnAttached(); AssociatedObject.MouseWheel += TextBoxOnMouseWheel; } protected override void OnDetaching() { base.OnDetaching(); AssociatedObject.MouseWheel -= TextBoxOnMouseWheel; } private static void TextBoxOnMouseWheel(object sender, MouseWheelEventArgs e) { var textBox = (TextBox)sender; if (double.TryParse(textBox.Text, out var currentValue)) { var increment = e.Delta / 1200D * Scale; var newValue = Math.Round(currentValue + increment, 5); textBox.Text = newValue.ToString(CultureInfo.CurrentCulture); e.Handled = true; // Prevents the scrollviewer from scrolling if TextBox is contained in a scrollviewer } } } &lt;TextBox Text="{Binding SomeDoubleValue}"&gt; &lt;i:Interaction.Behaviors&gt; &lt;behaviors:TextBoxChangesDoubleValueOnScrollBehavior/&gt; &lt;/i:Interaction.Behaviors&gt; &lt;/TextBox&gt; You also need to add an alias for the namespace 'i': xmlns:i="clr-namespace:System.Windows.Interactivity;assembly=System.Windows.Interactivity" No need to add a reference to the assembly because MVVM Light already does. I recommend not using ALT though, as it's used by windows for focusing the menu.
Thanks, that worked perfectly!
Just curious, why didn't you use the encoder for the code page used to encode the string into bytes? ``` var encoding = Encoding.GetEncoding(949); var s = encoding.GetString(data.pName); ``` 
Doesn't seem any better: "ïµï«ê»\\ua7baï¶îë³\\udac0îê¦°1" While it really should be "ëí´í¸ë²¨ë¼í ë¨ìì¥ê°1" And when i try to serialize this data as xml, it crashes with ": The surrogate pair (0xDAC0, 0xE5C0) is invalid. A high surrogate character (0xD800 - 0xDBFF) must always be paired with a low surrogate character (0xDC00 - 0xDFFF)."
What does your string look like encoded in the byte array?
This would require me to loop over the nested data from a large number of files with different structures to update the value before serialize.
Hard to copy it from VS in a decent format but: [0]181byte [1]240byte [2]198byte [3]250byte [4]198byte [5]174byte [6]186byte [7]167byte [8]182byte [9]243byte [10]197byte [11]228byte [12]179byte [13]178byte [14]192byte [15]218byte [16]192byte [17]229byte [18]176byte [19]169byte [20]49byte [21]0byte [22]0byte [23]0byte [24]0byte [25]0byte [26]0byte [27]0byte [28]0byte [29]0byte [30]0byte [31]0byte 
That doesn't look proper to me. I get completely different values when encoding that string as unicode. If you try Encoding.Unicode.GetString on that data you just get gibberish. How do you generate that binary file?
I don't generate the data i work with pregenerated - and rather old files. I know the text is valid if i use a hex editor with encoding support. 
You might get your wish by implementing `IXmlSerializable`. Maybe this serializer will work better: https://github.com/wojtpl2/ExtendedXmlSerializer (Does it have to be XML at all, though?)
Ah, right, the string is encoded in code page 949. From what I can find there's no way to tell the marshaller to deal with that. I think you'll need to roll your own PtrToStructure in that case.
Tried going for custom Marshal - but that apparently disables/breaks Marshal.SizeOf - so i can no longer get the size of the structure to load the data.
Are you doing your own ICustomMarshaler? For multiple types or this specific one only?
Only wanted for this one, but using ICustomMarshaler broke Marshal.SizeOf(). for (var i = 0; i &lt; headerItemCount; i++) { var x = Marshal.SizeOf(fieldType.GetElementType()); byte[] bytes = br.ReadBytes(Marshal.SizeOf(fieldType.GetElementType())); GCHandle handle = GCHandle.Alloc(bytes, GCHandleType.Pinned); items.SetValue(Marshal.PtrToStructure(handle.AddrOfPinnedObject(), fieldType.GetElementType()), i); handle.Free(); } Apaprently C# does not support it when you use ICustomMarshaler.
The only solution I see is: 1. Keep your structs as-is (with `byte[]`) 2. Create a new set of classes that shadow your structures, but with `string` instead of `byte[]` 3. Use a mapper (e.g. AutoMapper or something more light-weight) to map between the structs and your classes and use custom conversion from the `byte[]` properties to `string` (and vice versa) 
If it's only for that specific struct I wouldn't bother with ICustomMarshaler, just write your own PtrToStructure method. If you then leave the MarshalAs attributes SizeOf will keep working. Although, the size is fixed, so might as well hard code it...
Not just this one similar 32 byte string would show up in around ~20 other structs in various places.
Ah ok, bummer. Did you implement *int GetNativeDataSize();* properly in the custom marshaler?
Yes, I think it was in some official docs somewhere aswell that sizeof was not supported with custom marshal.
Great... I still think rolling your own PtrToStructure is the way to go then. Instead of applying your custom marshaler for all those structs, you replace that single call with another. Should be the same amount of work, unless you read the same struct in multiple places of course.
Submitted - nice one :D
*Maybe&lt;T&gt;*, yuck haha. This'll be great with nullable reference types though.
You know what? I've just created a repository for you to take a look at: [https://github.com/FagnerMartinsBrack/nsa-secret-report](https://github.com/FagnerMartinsBrack/nsa-secret-report) It shows two designs, one with one test per file. The other one test and many files. You can see the problems I guess. Code speaks more than words sometimes...
One of the two hardest problems in computer science. Naming things. Cache invalidation. Off by one errors.
You probably want to initialize output as int.MinValue, not zero. 
Thanks. I'll take a look later today.
Many functional languages use a similar pattern to this. F# has a type that is an "optional". 
Usually you wouldn't. But keep in mind that this is not a local variable, it's a member variable. So theoretically, in a multi-threaded scenario, it could be overwritten between the assignment and the null-check. Tho it could also be overwritten after the null-check... But yeah: Usually you wouldn't. And I don't think it makes sense here.
F# also forbids `null` in general. When your language, and the corresponding framework, is designed around this it works much better.
I would say it's probably because someone thinks that if there's an error (illegal ipAddress or port) while creating the listener it will be *null*. There will be an Exception thrown. I would also refactor it to have one responsibility: start the listener. Creating IPEndPoint and TcpListener should be the responsibility of other methods.
Maybe&lt;T&gt; is one of my favourite types now. Most people would never access the value of a nullable type before they check the HasValue property, but they won't always check reference types for null.
Yeah good point. I like the idea too, just not the aesthetics of Maybe&lt;T&gt;...
https://www.reddit.com/r/learncsharp/comments/8zz029/centering_mouse_cursor_on_window/
Mostly a matter of getting used to it. Maybe&lt;User&gt; GetUserById(int id) This expresses so much intent. It's not an error necessarily that you didn't find the expected user. If you have a proper Maybe implementation you don't need to do anything special in the function. Maybe&lt;User&gt; GetUserById(int id) { User user = ... return user; }
This is already standard operating procedure in a ton of modern languages. It's a little awkward in C# but can be nice with the right syntax. Think about it more like this: what if C# used nullable reference types, but emitted compiler errors if you did not check for null before use every time. That's how optionals like `Maybe&lt;T&gt;` work: they force you to explicitly state either: * Do this behavior if there is no value. * I so strongly believe there is a value at this point, I would like you to throw an exception if there isn't. It makes it *harder* to program because you have to stop to be explicit. That's a good thing in a language that tries to make safety guarantees like C#. In Swift there's lots of syntax sugar to handle the equivalent. For example you can: if let userInput = txtName?.text { // Has value } else { // No value } In C#, most optional APIs I've seen use lambdas to try and get something like that. I wish we had syntax sugar for things like this instead of 4 different ways to define a property: txtName.Text.Match( (input) =&gt; { // has a value }, () =&gt; { // has no value } ); Maybe after 5 or 6 more auto-property syntaxes we'll get around to catching up with 5 years ago. 
An arbitrary class *could* overload the `==` operator to make it do something weird. But 1) this is a bad idea and 2) I'm pretty sure `TcpListener` doesn't do this. It's worth noting that operators aren't dynamically resolved, so operator overloading couldn't generally be done in a derived class, not that it matters here anyway. I think this code is just bad, and its author should feel bad.
&gt;Code smell: don't put logic in getters/setters and if you do weird things in getters or setters make it a regular method I don't like this as a hard and fast rule. Granted, using regular methods does make the code more readable in the case of complex logic, sometimes there are actions that you want to perform every time a property is set (increment a counter, for instance) that don't necessarily merit mucking up the implementation with a separate member. Given that logic inside getters and setters compile as if they were separate methods anyway, you're not gaining an awful lot by going out of your way to define a separate method for something simple. I also personally think that logic in setters related to polymorphism and data validation leads to clearer code when assigning to a property. Object.SomePositiveInt = 3 is perfectly readable, and you can still allow the code to be validated at runtime without the added baggage of an extra method. As with anything, it's a spectrum. I don't think "always use auto getters and setters", or indeed "always use" anything is helpful advice to give a fledgling coder. Features exist for a reason, and you should consider each one as a tool in your belt to be used, however infrequently, when appropriate.
I'm unable to see how that's relevant, sorry.
Well this still works for me. My best guess is one of the types on your dynamic object isn't what you think it should be. `dynamic dynamicObject = new System.Dynamic.ExpandoObject();` [`dynamicObject.id`](https://dynamicObject.id) `= 1;` `dynamicObject.heading = "heading";` `myNestedDict.Add(1, new Dictionary&lt;int, string&gt; { {` [`dynamicObject.id`](https://dynamicObject.id)`, dynamicObject.heading } });`
That's unfortunate.
You could always do if(findElement(id, out var value)) { //Element found. value will not be null }
I have the desired coordinates, it's the position setting that behaves weirdly. This code works on a bunch of my friend's computers, but not on mine.
After a certain point in the article, I felt like I was reading something written by what Joel Spolsky likes to call "architecture astronauts."
Yeah buy you'll need Jon Bailey to narrate your code
https://en.wikipedia.org/wiki/Projectile_motion
The [SUVAT equations for rectilinear motion](https://en.m.wikipedia.org/wiki/Equations_of_motion#Constant_translational_acceleration_in_a_straight_line) should be what you're looking for. Acceleration in X (initial shot - air resistance) and Y (initial shot - gravity) can be separated in to two one-dimensional problems.
Non-Mobile link: https://en.wikipedia.org/wiki/Equations_of_motion#Constant_translational_acceleration_in_a_straight_line *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^203479
 That's not true though. API Gateways are used (primarily) for managing micro-service architectures. The architecture is made for scaling, it is much faster to put up and tear down smaller services, smaller services allow for more instances than a monolithic application so you can scale horizontally better, and usually each microservice even has its own database, which (for the most part) removes that bottle neck. It's not just about adding more hardware, the architecture, even though requires more memory up front, scales to more memory MUCH better than monolithic.
Yep, there is no valid reason to do it.
Depends on what you're doing. Creating the solution on its own allows you to create a non standard hierarchy of folders for your projects. Sometimes it's just easier to think about that if you do it in steps. I quite often start with an empty solution and add bits from there. For one project it will create the solution for you. Most importantly it's a choice and one you can ignore if you wish.
 That's not a Gateway, that's just good design practice. A Gateway routes incoming routes to new internal routes to be handled internally in the server (and sometimes does more, like authorization handling, etc).
It moves at 1000?/? along its entire path? 1000?/? straight up? Is it ballistic or powered? In a vacuum? Is it at the same elevation as the target?
&gt; F# also forbids null in general. No it doesn't. It will happily accept `Some(null)` for an `Optional&lt;String&gt;` value.
&gt; That's how optionals like Maybe&lt;T&gt; work: they force you to explicitly state either: No they don't. At least not in C# (or Java). Now you just have two nulls to check for, `null` and `None`.
Removed: Rule 4.
Not if the Maybe type is a struct.
This may sound rude, but I really don't mean it that way. What you learned in school really shouldn't be language specific. All the concepts you learned in Java transfer to C#. You should be able to pick it up in no time with next to no studying. You should just apply to junior positions and explain you've used Java before and are willing to learn c#. You will pick it up on the job. 
Look into .NET Core. Itâs cross platform and is probably the way forward for Microsoft tech stack. 
If there's an exception then the null check will never be reached anyway.
Yeah, I have noticed that. A lot of these tutorial videos, as I'm watching it, I know the concepts and what they're trying to do. I just want to get in the habit of knowing the proper syntax on the fly and not think of how it's written in java and then look up how C# writes it
Thank you! I will take a look into that! 
Intellisense and ReSharper help a lot. That just comes with experience, honestly. I've been coding in c# for 2 years and still occasionally have to look up a thing or two. 
The null check is pointless. "new object()" can't return null. I assume TcpListener was once constructed using a static method (which can return null) and someone forgot to remove the null check.
The problem is probably not with getting the mouse position itself, but the GetWindowTop and GetWindowLeft methods. These need to account for the windows DPI scaling.
Realistically if you've used a similar language before, give yourself about a week to make a minor project for whatever you like to get a basic familiarity with the syntax. Java and C# are close enough (barring build issues) that you should pick it up super fast. Companies looking for C# devs also tend to look for folks who are familiar with and can use LINQ and lambda expressions, so brush up on those and you're golden.
True, but I still see the occasional error from Nullable&lt;T&gt;. And it still doesn't prevent you from returning a null in the other case. At the end of the day no Maybe type is going to have a measurable impact without compiler support. 
If you want that job, don't only look for C# knowledge. You should also have 10 years worth of Angular experience. That'll do it
Not in the library I'm using. It represents its `Option&lt;T&gt;` as a struct, and the 'zero' instance is equivalent to None. Of course, that carries many implications with it. Implications that don't need to be there with features like non-nullable reference types or "Optionals are a native feature". There might be some games you can play with implicit conversions to help, too. If `null` implicitly converts to and from `None` you can kind of sidestep around it. I don't really care to see how/if that actually works, it was just a passing thought. Honestly null handling and a lack of native optional types is one of the places where I feel C# showing its age the most. Since it carries a heavy backwards compat cross I think it'll be years before it can really present a solution.
Lol the saddest part is that job actually ask for things like that. 10 years of experience in a tech that's only been out for 8 years. 
I think his point was that the language starts with nulls as being forbidden, and then allows them in only specific circumstances - opt-in, instead of opt-out. 
That would have been nice; but it wasn't what was actually built.
I take it you haven't been following C# 8. Non-nullable reference types are on the roadmap.
Yes you can override equals, and your case sounds like a case where you maybe should. Maybe comparing lists works if you take their hash code, but better try it, I'm not sure myself there. A quick start for hash codes and overriding equals might be this stackoverflow thread: https://stackoverflow.com/questions/9317582/correct-way-to-override-equals-and-gethashcode
well the first thing is why are you doing this? it smells and chances are there's a better way. otherwise, just wrap your collection in a class and implement the relevant interfaces.
I've seen them and looked at the specs. I'm working in a very large codebase that already has a lot of nullable reference types. It's not going to be a fast or painless switch, and my understanding at this point is you can only mix and match at assembly boundaries. It's a Xamarin project. We already have a bewildering array of assemblies. I can't add fuel to the fire for this, so it's a feature that won't benefit me until I do a ton of work. :/
Are you really sure you need to do this? I canât think of a use case for it. I guess you could just make your own class using the list interface and override based on your needs. 
Don't do this unless you've done the diagnostics to determine that memory allocation is a bottleneck. I've seen so many premature attempts at pooling and caching, which then turn into bugs or actually degrade performance. If you have a measurable performance problem, AND you understand the difference between memory usage bottleneck and a memory allocation bottleneck enough to determine which is the true issue, then go for it.
True, it is going to be even more painful than .net and generics. But I think so will be worth the effort.
I was expecting a "why". I've got two variables that go together and their values determine a couple of other values so I made a method in the middle with a dictionary and a lookup that returns a struct of the values. Maybe it's convoluted but I was sick of writing so many if (... &amp;&amp; ...) || (... &amp;&amp; ...)....
At this point don't be clever. Just look at each number in the array (a for loop just like the one you used to populate it. That's all they want. If you want to get clever, then maintain an ordered list and keep the largest and smallest number in that list somewhere. That way if you have a list with a largest number of 75 and a smallest of 4, you know that 1 is smaller than the smallest and 76 is larger than the largest. You also know that 70 is closer to the largest and you can start looking in the list at that point. Cleverer still, maintain the average value to give you extra info If the average is high, start looking higher. These are still all really simple things, but we've all been there, so hold on and it will become clear in time :) 
Just an idea: Could you separate your big number into mantissa and exponent? For example, 89849874984534967898435246374873543678974415241335435 can be rewritten as 8.9849874984534967898435246374873543678974415241335435 Ã 10^52 (according to Wolfram Alpha), which you can store as a float (8.9849..., mantissa) and int (52, exponent).
If you can use LINQ, you can group by the number itself, and filter out the groups containing 1 or fewer entries, then select down to just the key for each group. If you're stuck with loops and such, make a Dictionary&lt;int, int&gt;(), where the key is your number, and the value is how many times it appears in the array. Loop through the array, using TryGetValue() to get the current count associated with the number. Conveniently, you don't need to check the true/false return, because the count will be 0 if it's not in the dictionary, yet, and assigning a value to dictionary key using the indexer will add it if it's not present. Once you have that, you can filter down to the keys where the associated value is greater than 1. Alternately, you could create a couple HashSet&lt;int&gt; objects. Loop through the array. If the current value is not in set A, add it only to set A. If it's in set A, but not set B, add it to set B. If it's in set A and set B, do nothing. Once you've walked through the whole array, set B contains all your duplicated values.
Explain more, it still sounds iffy :) I'm guessing you're saying that if a value is in a list of values it should return a key? Thus the key on a list with the value returned? If that's the case, it's not the worst way of doing it.
Did this for my comp science project. Can't remember the exact code but standard form is the way to go
&gt; since there is no Array.Contains There is, just another notation: var itemExists = Array.contains(array, item); Source: https://msdn.microsoft.com/en-us/library/bb384015.aspx
You can provide your own `IEqualityComparer&lt;T&gt;`, yes. The docs have an example of implementing one and using it in a dictionary: https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.iequalitycomparer-1
Can we stop using name honest? All of functional world who came up with this concept uses "pure". Thanks in advance 
Clearly you don't have the right coordinates if the position isn't right. WPF size values are not the same as pixels.
This is the way I'd do it. Check if the mantissa is &gt; 10.0, then take the floor of mantissa/10.0 and add it to the exponent. Using double instead of float would help perverse some precision.
Exactly, there would be an Exception that isn't catched in here, and the program would bomb unless whatever calls Start catches it. The null check would never be called.
Seems simple to me. But how do you calculate things with them? Something like 8.9e52\*2e48 would be 17.8e100. So would you do a While-Loop now? Something like: \`While (mantissa&gt;=10) { mantissa= mantissa/10; exponent=exponent+1; }\` If that is correct, my example would end up like that: While (17.8&gt;=10) &lt;-- This is true, so Loop is now active { mantissa = 17/10; &lt;-- New Mantissa would be 1.7 exponent = 100 + 1; &lt;-- New Exponent would be 101 } Now the Mantissa is &lt; 10, so Loop is not triggered again. Final "Number": 1.78e101.
Isn't that only in JScript? There is no Array.contains method in C#, and it doesn't even follow the naming convention used in the language.
Oh, you might be right! I am not sure. I googled for c# array contains and didn't check further. Sorry if wrong!
You should be able to use LINQ for this: https://msdn.microsoft.com/en-us/library/bb352880(v=vs.110).aspx ``` //At the top of your source file using System.Linq; //In your code numbers.Contains(value) ```
a concrete example would be super beneficial.
You're looking for [System.Numerics.BigInteger](https://msdn.microsoft.com/en-us/library/system.numerics.biginteger(v=vs.110).aspx) You can use it exactly like int or long except that it doesn't have a max (or min) value.
I thought ReSharper was being phased out? 
Learn about simple chemical stoichiometric equations and write a solver for coefficients. If you don't get the math, you can brute-force it. Once you understand the math (linear algebra) make it better. 
Who hurt you?
&gt; I've got two variables that go together and their values determine a couple of other values Then why not Dictionary&lt;string, Dictionary&lt;string, string&gt;&gt;?
Um, that's already what floating point numbers do.
I tried the method in that making my own List type and overriding the equals method but the code never got called. Not sure why. I did find a solution though.
The article differentiates a pure function from an honest one. You can have a pure dishonest function for example.
F#. It promised me freedom from null reference exceptions, but it was lies, all lies.
Thanks a million. I used the method in that doc and it works. I've pasted the solution in op.
Don't need linq for this. `Array.IndexOf(numbers, value) &gt;= 0`
Yes, but by storing the exponent externally your float has more bits available for the actual mantissa. I think what floats can store is precise enough for any mantissa in a clicker game, and ints as exponents should be vast enough to allow for hilarious growth. I don't think it would work with floats alone. Or would it?
Nullable reference types, in an upcoming version of C#, will stop a lot of this problem
What limits are you breaking? The 53 bit precision that double gives you, or really its *massive* 600+ orders of magnitude range?
But would that still see something like 1E+902 as a number?
The next version of C# will support nullable reference types, and do exactly this.
It will replace the need of Maybe&lt;T&gt;, yes. I imagine the adoption will take a while after it's released. Working with legacy projects will probably still see it's use (Maybe&lt;T&gt;)
I see that but still for me is another artificial concept which only exist in c#. Purity is enough
&gt; its massive 600+ orders of magnitude range I want to be able to "create" number up to **real infinity** for now, because I don't want to add some soft reset thing that always triggers when you get close to the limit of 1.79e308.
You don't really get more bits of precision out of a float by not using its exponent. I also doubt anyone ever *really* needs the full range of a `double` (but you might easily want more precision.) Using a BigInteger with a separate exponent integer to build your own floating point type isn't a terrible idea if you want more precision and/or range.
 Maybe&lt;User&gt; GetUserById(int id) { User user = _repository.Users.FirstOrDefault(u =&gt; u.Id == id); return user; } This method is honest, but impure because of IO. 
It's for some directory syncing I'm doing. I have two attributes from the source and if those two attributes are say 1 and 2 then I have to set attribute a to 739 and b to 936, if the two attributes are 6 and 876, i have to set a to 432 and b to 654 and so on and so on down a huge list. Thought it better to make a data structure and query it essentially rather than writing huge if/else blocks.
I've got another reply but it's not a magic bullet. Good language support for optionals is something any project could pick up and start using. Nullable reference types look like a nightmare if you already have a large codebase, since the syntax for non-nullables is basically the default syntax if you aren't using that feature. It will be good for new codebases, but I don't expect I'll be able to use it for a long time.
But you'd have to make complex calculations if you calculated something like 1E+500-2E+499, because the game doesnt look at these numbers the way it would look at **real numbers**, so you'd have to compare *if* that calculation had *any* impact to the amount after the calculation. I read something about saving some RAM/CPU etc in these games, because no computer actually calculates 1E+500-1E+400. Something like if(exponentCost&lt;exponentGold-3) maybe?? So if your upgrade costs E497, and you have E500, it would end up with 9.999E500 gold after the purchase. Everything beyond that doesnt seem useful to me (like "You have 9.9999999999987E500 gold")
Or you can "cast" your array to list and then use the .Contains method on the list: var arr = new int[] { 1, 2, 3 }; var lst = new List&lt;int&gt;(); lst.AddRange(arr); // the "cast" var cont3 = lst.Contains(3); // true var cont4 = lst.Contains(4); // false But I prefer your way. LINQ is great!
Use Linq and Count the Distinct items of the array.
It's to show you that can be done. I've fielded questions on newbie forums for a long time, and it's not uncommon to find someone who has gone quite a long time without realizing you can have multiple projects in one solution. This tutorial makes it clear that it's possible by making you go through similar steps. Also, if I remember right, the directory structure ends up a little nicer if you go this route, or you at least have more control over it. I haven't set up a multi-project solution in a long time, but I remember this was a trick to getting it how I wanted it. There's not a technical reason to do it. If you JUST want a Class Library project, then use that.
As a SWE I agree with this adviceâI was hired for my .Net experience but in the last 6 months Iâve worked with Java, C#, Python, Bash, and TypeScript, and probably some other stuff Iâm forgetting. That being said, many recruiters will tend to supply hiring managers with only a handful of the closest matching resumes for a given job posting. This is true even for Junior positions. iI you see a lot of âobject oriented programmingâ in job postings, then great! If youâre seeing X or Y language specific postings then youâre going to be better off applying with that language on your resume. 
&gt; there is no Array.Contains or something like that There actually is (as of .NET 2.0), but due to a historical quirk, you don't see it.* ((IList&lt;int&gt;)numbers).Contains() // this should work As others have pointed out, you can also import `System.Linq` (as of .NET 3.5), whose `Contains` implementation will in this case just act as an overload to the above, i.e. do the same without performance overhead. *) Namely, arrays came before generics. Arrays in .NET 2.0 did gain the implementation of `IList&lt;T&gt;`, but it's provided, oddly enough, at runtime, not at compile time.
Damn, alright. Well, you'll want to look into arbitrary-precision arithmetic then. BigInteger is the only thing you get out of the box in .NET that will help you there. If you want to use techniques that might be more efficient you'd have to implement them yourself or find a third party library.
That tells you if it's there once. The question is to find if the same value is there two or more times.
&gt;An arbitrary class could overload the `==` operator to make it do something weird. I don't believe overloading a `null` equality comparison is possible. (And if it were, it would, as you say, be a horrible idea.) This is almost surely a multithreading safeguard.
What is the "number limit" given by BigInteger? How do I implement these BigIntegers into the code?
Yeah, I sort of figured it would be something like that (not second guessing, your example is specific :) ) Your approach is good, although I'd go the other way and key on a sorted has of id's. It doesn't sound like you need the ids (attributes) after you get them, so hash them, but remember to order them first. You'll still have the same issues you will get currently if someone adds an item to a list I think. Does a list of 1,2,3 = a list of 1, 2, 3, 4? 
IO monad if you are monading. If you are following clean code rules and apply pure functions then what else do you exactly need
&gt;I've got two variables that go together and their values determine a couple of other values This sounds like a candidate for a tuple, not a collection. Which incidentally, due to automatic implementation of equality in value tuples, would probably also solve your problem. If on C# 7, give this a shot: var dict = new Dictionary&lt;(string valA, string valB), string&gt;{{ ( "val1", "val2" ), "ret"} }; Also, _please_ name your variables more meaningfully. `dict` and `ret` answer what they are, which I can already see, rather than why they exist, which I cannot.
1000 meters per second horizontal to the direction the cannon aims. Balistic too
&gt; 1E+902 as a number? You could easily format your output that way if you want. You could even parse scientific notation as input using something like n * BigInteger.Pow(10, m) for nE+m. I don't really understand what your question is asking, though.
&gt; I want to be able to "create" number up to real infinity for now I don't understand what problem you're trying to solve here, but you could put your number in a `byte[]`? 
The concept of IO monad doesn't really exist in C#, and there will always be some impure functions because we need data into our program. I'm not sure if I would like to mark methods as [Pure], and what the effect of that would be really, but making methods honest makes it much easier to reason about code, even if they aren't pure. Pure functions on the other hand are super useful because they are easy to unit test, and you should of course try to make as many of those as you can, but it's a bad thing to mix the concepts of pure and honest.
I don't believe its `if` statement will become Objective-C-/Swift-like in that a null is equal to false. The terse syntax of Swift here is kind of nice (also, the `guard` statement on top of it): if let userInput = txtName.text // if txtName.txt has a value, assign that value to `userInput`. If not, just move onâ¦ We can go somewhere similar with C# 7's pattern matching: if (txtName?.text is string userInput)
You do kind of need a real `GetHashCode` implementation. Right now you return the hash code of the equality comparer as the hash code of every list, so they all collide and the dictionary has to compare every list every time. Just XOR the hash code of every string in the list together or something like that.
You kind of have to brute force this. Since there are only 5 elements it's not worth being clever. The brute force technique is to start at the first element, then compare it to every other element. If you find a match, you know the same object is there at least twice. If there are no matches, you start at the second element, then compare to all the rest. This is a classic nested for loop: Now, think about For loops. If you use ONE for loop, it kind of means "visit each element of the array". for (int left = 0; left &lt; array.Length; left++) { } In this case, we don't want to visit EVERY element of the array: we don't have to visit the last one, since there's nothing left to compare it to. for (int left = 0; left &lt; array.Length - 1; left++) { } OK. But once we pick that index, we want to compare it to every OTHER element inside the array. Think about it. That means "start at left+1 and move to the end." Another for loop! for (int left = 0; left &lt; array.Length - 1; left++) { for (int right = 0; right &lt; array.Length; right++) { } } Now, inside that loop, you compare left to right. If they aren't equal, you have to keep going. If they ARE equal, you found a match and need to report it. Here's some skeleton of a hint, see if you can fill in the blanks: bool found = false; for (int left = 0; left &lt; array.Length - 1; left++) { for (int right = 0; right &lt; array.Length; right++) { // If the item on the left and the item on the right are the same, we found a match... if (???) { found = true; break; // Stop looping! } } } if (found) { // Match found! } else { // No matches! } It's really awkward to use built-in C# methods for this. And if you sit and analyze them like a computer scientist, they all tend to run "as slow as" this or worse. In this case, you might use `IndexOf()` since it can be told to start looking past a certain index. But it really does the same thing as the inner loop from my algorithm, so while it looks shorter it does the same amount of work. The only way to make this "smarter" or "more clever" is to change how the data is stored. For example, if you sort the array, you don't need 2 for loops, you can always compare left to left+1. Believe it or not, for large arrays you can make sorting then checking this way faster than the nested for loops. But the fastest technique would be to rely on a class like HashSet to help you detect collisions. HOWEVER, implementations will vary wildly depending on if you want to detect all duplicates or various other things. I imagine the nested for loops are what your exercise wanted. 
Ok I made a class, since my original assumptions were wrong and I wanted to figure it out. I have a feeling it's just a clone of BigInteger, which other people are mentioning. [Here's a pastebin of it.](https://pastebin.com/39EmT8cX) It's pretty much the same thing you were going for, but the while loops are replaced by Math.Log10(). I added + and - operators, not sure if they're optimal but the small amount of testing I did on it got the right results.
You can use Count for this: https://msdn.microsoft.com/en-us/library/bb535181(v=vs.110).aspx if (numbers.Count(number =&gt; number == value) &gt; 1) { //value occurs more than once in array }
I canât help thinking that a lot of the problems being addressed here would be better addressed using XML comments. A good description on a method can keep the method âhonestâ (to use the authorâs word), without adding any extra complexity. The caller gets to see the XML comment in Intellisense when they write their method call. The author/modifier of the method sees the XML comment above the method code. Both know exactly what the contract is based on the contents of the comment. Even the author signs off this article by admitting the solution doesnât scale, and promises to explain how to fix this in a future article. But the fix already exists! I enjoyed reading it, and the first half or two-thirds of the article was useful, but it descending into a functional programming fantasy land after that.
+1 for showing how this type of code can occur.
This is a better way of doing it.
Why not use a hashmap?
I'll check that out when I get to my PC. Looks promising! 
What I am asking is: When I try to add 1E+307 to 1.7E+308, it leads me to "System.OverflowException", because 1.7E+308+1E+307 = 1.8E+308 which is higher than the double-maxValue. As BigInteger "in theory removes max- and minValue", will it be able to calculate with numbers like 1E+902 the same way as it would calculate 1+1?
Someone has probably already mentioned this but have you tried using tuples?
BigInteger can grow as large as your memory allows. https://msdn.microsoft.com/en-us/library/system.numerics.biginteger.aspx#Remarks
There is no Maybe as well.
True, it's still going to be `O(n^2)` plus the overhead of using a lambda. 
True, but it can be created. Perhaps I'm dense, but I can't see any reasonable way to represent the IO monad.
Wait, what? Where did you read that? Resharper is made by Jetbrains, and I haven't seen any announcements from them that say anything about phasing it out.
&gt; will it be able to calculate with numbers like 1E+902 the same way as it would calculate 1+1? Short answer: yes. Long answer: it doesn't work the same under the hood (calculating 10 + 10 will be quicker with ints than with bigintegers, calculating 1e900 + 1e900 will be impossible with ints but fine with bigintegers, bigintegers will take up more space as their value grows, ints will not, etc.), but the behavior will appear identical.
&gt; I don't believe overloading a null equality comparison is possible. You're actually wrong. ``` using System; using static System.Console; public class Program { public static void Main() { Bad instance = new Bad(); WriteLine(instance == null); } } class Bad { public static bool operator ==(Bad a, Bad b) { WriteLine("Fancy operator equality executing..."); return true; } public static bool operator !=(Bad a, Bad b) =&gt; !(a == b); public override bool Equals(object other) { WriteLine("Fancy method equality executing..."); return true; } public override int GetHashCode() =&gt; 0; } ``` [Try it online!](https://tio.run/##pZBPT8MwDMXv@RTeTpkEFfdqHJj4cwAJiQPnNLXWoDQeiTOoUD97SdewTgjBAd9iv@f3c3Q410EPQwzGbeGpC4xtKaZXYMVG52axIRfIYinELlY29bVVIcCjp61XLXwISJVH2bknU8ODMk6u8nysK1WDcUniNMIaHL6NLbkqj4pnbxjvjUM565IwWptFveiFmPLHbT9lV0QWaIdeMflkl6NQnR301SnOHLa8SVHdbMLXqKzhDvAddeT0JUVRLE84PXL0DthH/OL6C2TxHWR9CQupxvuqvDnbaY/emxqnBdcjS5BUvaBmIG7Q/3pEi9xQ/d8TjgzGMdwi36nQbKhGeeC@KEU/DJ8 "C# (Visual C# Compiler) â Try It Online") 
&gt; I only have a Mac BootCamp? 
Did you override the `GetHashCode` method too (and properly)? For performance, hash codes are compared and unless they are equal, there will be no call to the equals method.
There is implementation on GitHub: https://github.com/louthy/csharp-monad And I still don't see any difference between SOLID and immutability vs "honest" thingy. But I have to admit that is a neat set of things to consider on code review.
Learn Node.js or Laravel 
Ok. This answer is enough for me. Now I only need a little code sample, because I'm not able to make my game work with these BigIntegers. Tried everything, but it always finds an error somewhere.
Because there is no key-value relation! An ``ISet`` is *the* way to go! 
Oh yeah sorry. This is what i was talking about
So.. make your methods as honest as reasonable, but no more?
Learn ASP.NET Core
Full Stack JS is the present and future.
In my area (EU), there are probably as many jobs as a Java dev as there are for .NET devs.. Is it really that different over there? Other than that, I was kind of in the same boat last year. We got Java classes at school, and then some (basic) JS, a bit of Angular, and I took some courses on Android (Java) and iOS (Swift) as well. Also got a bit of .NET, but not a whole lot. Ended up applying for a .NET dev position (mainly Cloud Development in Azure), explained them that I could practically use all the experience I got in Java in .NET as well, just the syntax that was going to be a small 'problem' that wouldn't take too long to fix anyways. Got hired, never looked back at Java haha :) IMO, .NET is way easier to work with, C# is nice to write in, good documentation... I can't complain at all. So by all means, try to go for .NET jobs as well (doesn't mean that you can't apply for Java dev jons in the meantime as well, of course). For your problems with the Pluralsight stuff and so on, use Bootcamp to get Windows up-and-running too. If you're gonna be doing .NET, you might as well familiarize yourself with Windows too, as that's the go-to OS for that, obviously! Some other tips, mention that you can and have worked with git (if you can't/haven't, then jump on that right now, even more important than C# syntax!), and that you have also used other langs like Python etc, so they know that you are willing and able to learn new stuff. First job is the hardest to get IMO, from that point off you have experience which will (arguably) help you a lot more in the future :) Good luck!
There are a lot of Java jobs out here too, but there's a lot of competition for them as well. I noticed that for junior level, there seems to be a shortage of people who know C# and want to work with it. I did some phone interviews too for C# positions and they were way easier than the ones I did for a Java role. There's so many people worried about being pigeon-holed into being a .NET developer. It's insane. Thanks so much for your help! I really appreciate your advice. Makes me even more excited to start learning C# and .NET! 
Floating point variables have an "infinity" value, which isn't used in integers. Use BigInteger constructors or static methods. BigInteger grosseZahl = new BigInteger(Geld); If you're not going to need fractional values, I'd avoid using doubles anywhere and just use BigInteger everywhere; it will be *much* more precise when working with large numbers.
 I've done some projects with Node.js and found it really interesting. What's making me lean towards ASP.NET Core is that all the bootcamp grads and self taught developers go into Full Stack JS. There's so much competition in that stack to the point where I've seen some companies list salary as low as $40k for a junior role.
&gt; I have a feeling it's just a clone of BigInteger Nope, BigInteger runs off of an int and a uint array.
&gt;Laravel You suggest full stack JS, then offer a non-full stack JS solution. Huh.
Feel free to hit me up here with questions, whether or not it's about the jobs or the languages :) still a junior so more or less in the same boat, just a year more experience ;)
Thanks! I appreciate that! I'll be hitting you up for sure!
Create a comparer impementing IEquality&lt;T&gt; and call .Distinct(new MyObjectComparer)
Well... the title says that, yes. But in the post is says that they donât want to reach the state of having it more than once, to ask for another number if the given one is already present.
Unity assets aren't "dependencies"; they themselves are the content, from the asset store or not. Or maybe you're talking about .NET dependency management. That's all handled in your project's .csproj file with PackageReference tags. You don't need to worry about adding PackageReferences as your IDE/CLI will add that to your .csproj when you install packages. And you still don't have to worry about requirements once you distribute the app as in .NET you generally ship your app with it's dependencies, which will be checked/restored when you compile. (it'll only restore dependencies specified in the .csproj, so don't screw with it or your app might not build at all.)
I always ask for help after I read the msds docs. I understand some but I feel like im clueless and never know how to phrase my question. This sub gives me anxiety lmfao
Except in this case he wants to know if the item is already in there twice or more, so I think the value could be the count and you just check for count &gt;= 2. 
VSCode provides all the same functionality as VS17 (on Mac, the PC version is way better). And it's faster overall. Go use that. If you insist on using a big boy IDE like your smartass attitude implies, go hop on someone's liscense server and install Rider. (ok no joke it runs really well on Mac)
Read the post again: he inputs 5 numbers and when something got input twice it should show an error msg
Linq is definitely your friend in this case. 
Try FtpWebRequest request = (FtpWebRequest)WebRequest.Create(RemotUri); request.Method = WebRequestMethods.Ftp.ListDirectory; FtpWebResponse response = (FtpWebResponse) request.GetResponse(); var reader = new StreamReader(response.GetResponseStream(), System.Text.Encoding.UTF8) var fileList = reader.ReadToEnd(); Console.WriteLine(fileList); reader.Close() response.Close(); Also see: https://msdn.microsoft.com/en-us/library/system.net.webrequestmethods.ftp(v=vs.110).aspx https://msdn.microsoft.com/en-us/library/system.net.ftpwebrequest.method(v=vs.110).aspx https://msdn.microsoft.com/en-us/library/system.net.ftpwebresponse(v=vs.110).aspx
Whenever you animate anything, the process is always draw, move, erase, repeat. Looks like you're skipping the "erase" step.
You do realise we have no idea what are you doing? post relevant code
Did you read the article? It's not about C#. It's about whether the method signature lies about its implementation. And you can have lies in, say, Java or Python.
How about loading the items into an iset and checking if the entry already exists? 
Removed: Rule 4. Please include the relevant code that you have.
You don't need LINQ for this. You don't need to brute-force. You just need to use the right data structure. In this case, that structure is a `HashSet&lt;int&gt;`. var set = new HashSet&lt;int&gt;(); Console.WriteLine("Please enter 5 different numbers"); while(set.Count &lt; 5) { var input = Console.ReadLine(); if(!int.TryParse(input, out int val)) { Console.WriteLine($"{input} is not a number."); } else if (set.Contains(val)) { Console.WriteLine($"{val} has already been entered."); } else { set.Add(val); } } foreach(var val in set) Console.WriteLine(val);
Ok just reading over the code,this is attempting to request the file directory of the particular uri , and returns it to the console?
Use a while statement (inside the for statement) with the condition that what the user entered is not in the array. So that the for statement does not proceed until the user enters something valid.
Or entry-level jobs that require 5 years experience. Donât let that stop you from applying, as theyâre just trying to weed out all the self-conscious potential applicants. 
https://msdn.microsoft.com/en-us/library/dd412075(v=vs.110).aspx Return Value Type: System.Boolean true if the element is added to the set; false if the element is already in the set. Just throw an error if the result is false. 
Sorry all, I meant to post this in the Unity Development subreddit!
N-tier applications are not microservices and they are not monolithic when constructed properly. "Microservice or Monolithic" is a false dilemma - please be specific.
Exactly my thoughts as well. This is the whole point of the xml comment blocks, why act like they don't exist?
This is the best solution as it shows a clear intent. It will be easy to understand for anyone reading this code and harder to create bugs if anyone starts to change the code.
How would you do this? If list.count == list.Distinct().Count()? I was going to advice groupby which is probably less performant. If list.GroupBy().Any(grouping =&gt; grouping.Count() &gt; 1)
Please be careful when using webclient and httpclient. Despite their implementations as IDisposable, a new WebClient will create a TCP connection. If you have a batch of a few hundred of these at the same time, you can hit your OS limits for sockets available. Consider using a static httpclient or webclient on a class
I know these comments were from over a week ago but I keep coming back to them for my research and they have helped immensely. Again thank you so much! I am very eager to learn and I couldn't have asked for a better explanation/walkthrough. I really appreciate it!
Types defined in F# are optional by default (unless annotated with AllowNullLiteralAttribute). All .NET framework reference types (including `string`) are assumed to be nullable. I don't see what the alternative would be other than disallowing all .NET types.
They could have expressed .NET types as `Option&lt;T&gt;` unless proven to be non-nullable. It would have been annoying, but accurate. Or at the very least made `Nullable&lt;int&gt;` and `Option&lt;int&gt;` compatible. WTF are these different types? Oh, right. Because for some stupid reason they decided that `Option&lt;T&gt;` had to be a reference type. Yea, don't you love unnecessary GC pressure.
Didn't know this existed. Thanks! Would like to see a calculator implemented using this.
Sort then check adjacent.
&gt;Or at the very least made `Nullable` and `Option` compatible. WTF are these different types? Nullability is considered to be a difference concept to optional values. There are scenarios where `Some null` will be a valid value. &gt;Oh, right. Because for some stupid reason they decided that `Option` had to be a reference type. Yea, don't you love unnecessary GC pressure. ValueOption also exists IIRC
Removed: Rule 4. You'll need to identify the error messages associated with the crash, describe what the desired output of the program is, what the current output is (more specifically than "some gibberish"), what inputs you're using (you've just posted a class, but not the inputs you're feeding it) and ideally produce a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve) for us to work with.
&gt; There are scenarios where Some null will be a valid value. No, there isn't. I can't think of any possible way you could convince me that `Some null` was a good design decision.
This looks problematic: public decimal CurrentSalary { get { return _currentSalary; } private set { if (value &gt;= 0) CurrentSalary = value; else { const string ParamName1 = "DOB"; throw new ArgumentOutOfRangeException(ParamName1, "current salary Must be &gt;= 0"); } _currentSalary = value; } } Looks like a stack overflow waiting to happen, which is an exception that does not get handled -- it will typically crash a program. Have you tried running this in VS? This spot in particular: if (value &gt;= 0) CurrentSalary = value; When you set CurrentSalary = value, you call the CurrentSalary setter...which sets CurrentSalary = value and boom you have an infinite loop. Use: _currentSalary = value; 
&gt;No, there isn't. I can't think of any possible way you could convince me that `Some null` was a good design decision. The real reason is that the language designers didn't want basic types like `string`, `Seq&lt;'T&gt;` to require pattern matching everywhere in native F# code. let private printString str = match str with | Some s -&gt; printfn "%s" s | None -&gt; () // literally never happens in pure F# code printString "foo" Compare to: let private printString = printfn "%s" printString "foo"
I misread this, earlier. If you're really restricted to an using an array and searching through it, yourself, you'll need to do a couple things: * Assign your new number to a local variable, instead of assigning it into the array, directly. It doesn't make much difference to the performance or behavior of the loop (if it's not already in the array, we'll assign it at the end), but it's easier for most people to think about. * Use a loop inside your existing loop to search through the part of the array that you have already filled with prompted numbers. This is, conveniently, everything in the array from 0 to i - 1, or `for (var j = 0; j &lt; i; j++)`. You will also need a boolean variable to track if the new number was found--you should initialize it to `false`. If the searched position (`numbers[j]`) matches your new number, set your boolean variable to `true`. If you're feeling clever or ambitious, exit this loop (and *only* this loop--it's not hard) when the value has been found, so you don't have to search the whole range. * Now that you know if the number is in the array, you can decide whether to assign it to the position in the array, or print a warning and try again. Note that if you are going to try again, you should decrement `i` so that the next pass through your `for` loop will attempt to set the same position in your array that the current pass was trying to set. The other, correct solutions here mostly rely on data structures, and I have a feeling that's a little outside the scope of what you're up to.
That I can believe.
I appreciate the notion of picking the right tool for the job, but since you're already checking if the set contains the item for the error message, you could just use a List or even an array with no other changes. Using a set doesn't really do anything for us in this situation. 
Well, if there were more than 5 elements we might see the benefit of the O(1) lookup time. We could change the if statement to take advantage of the Add method's return type. else if (!set.Add(val)) { Console.WriteLine($"{val} has already been entered."); } An array or list will be less performant when processing a lot more elements, but that's not really an issue here.
LINQ is bad performance why for this either way but I'd still advise it as long as the array is small enough.
It was written in .net context. But fair enough but still if you adopt immutability and solid principles then you are also wirtting "honest" functions. You don't have "lies", you have bad code.
&gt; Just in case the stream of C# 7 point releases hasn't given you enough to think about, let's have a look at what might be in C# 8. Nullable reference types? Shapes? Extension everything?
The only program I know works for sure is [rtmpdump](https://en.wikipedia.org/wiki/RTMPDump) but I don't know if there is a Windows version, or if it compiles on Windows.
And know my tool does not do only 1 thing, did you even watch the video? It also does up dates and normalizes pixelated images.
1&gt; Declare variable i = 0 2&gt; If variable i does not equal 2 then 3&gt; increment variable by 1
I just write the check as if(SomeMethod() is Customer customer) { //Use customer } //Perhaps handle not found This way no wrapper is used
In general this way is okay, I myself would make it the same. But you need to mind two things: 1. In EntityA you just need the "public EntityB EntityB { get; set;}" property for a proper m : n relation. The "public int EntityBId { get; set; }" is optionally and can be added, if you want to access only the Id of EntityB, without loading the navigation property (better performance). 2. In your DbContext you should override the OnModelCreating method and add an explicit declaration of your relation in the entity method syntax (or however it is called): ``` modelBuilder.Entity&lt;EntityA&gt;().HasRequired(x =&gt; x.EntityB).WithMany(); // when using the explicit foreign key column: modelBuilder.Entity&lt;EntityA&gt;().HasRequired(x =&gt; x.EntityB).WithMany().HasForeignKey(x =&gt; x.EntityBId); // configure cascade delete modelBuilder.Entity&lt;EntityA&gt;().HasRequired(x =&gt; x.EntityB).WithMany().WillCascadeOnDelete([true / false]); ```
Shouldn't use sorted set. Hashset is what you want. Sorted set is a very specific case and slower. It implies an order is required.
Actually, Linq2Objects pretty much loops through your array the same way you would have if you had to do it manually. There is no performance hit between looping through objects and using Linq2Objects. Linq2SQL on the other hand can be a beast if you don't use it correctly. Looping through an IQueryable will execute the same query over and over for every record it expects, where calling ToList() before your loop will execute once and loop in memory. 
I have refactored this a bit to use Linq. A lot of people might advise against using Linq for this kind of this, however Linq is brillliant to work with any type of collection. C# generics collections have basically replaced arrays and the dreaded "OutOfRange" exception in my daily life. Console.WriteLine("Please enter 5 different numbers"); var numbers = new List&lt;int&gt;(); for (var i = 0; i &lt; 5; i++) { var input = Convert.ToInt32(Console.ReadLine()); if(!numbers.Any(p=&gt; p == input) numbers.Add(input); else Console.WriteLine("Number {0} already added", input); } numbers.OrderBy(p=&gt;p); foreach (var n in numbers) Console.WriteLine(n);
Hashset is the best answer.
What I mean is that all the LINQ operations suggested require iterating through all entries instead of ending early if more than 1 match exists. Although perhaps someone knows an efficient LINQ operation that doesn't require this.
Thank you, this looks promising! I should be able to wrap librtmp and create my own rtmp server to receive the stream, and not bother with the client side of things. 
thanks!
&gt; Happiness is about not giving a shit what anyone else thinks. If thereâs one thing Iâve learned in life itâs that people who keep insisting this are usually the most triggered of all. That and the fact that youâve now replied to the same comment 3 separate times.
&gt; I would say it's probably because someone thinks that if there's an error (illegal ipAddress or port) while creating the listener it will be null. There will be an Exception thrown. I figured the IpEndpoint and the listener, when their instances are created, would throw an error if, for example, the ip address is invalid (the endpoint couldn't then be created - I assume it has internal logic to ensure this - and therefore the listener couldn't be created without an endpoint to use).
This was a really good explanation, thank you!
so if the only other migration is an "init" migration, and the "last migration" is my custom migration, i can reverse my custom migration by doing: dotnet ef database update init so my FOLLOW-UP QUESTION IS: the approach discussed in ryan's article (referenced in my first post) puts custom migration class file(s) under a CustomMigrations folder in the project containing the ApplicationDbContext.cs file. i did not have to do any kind of dotnet ef migrations add custom\_blah for my custom migrations. a "dotnet ef database update" just seems to pick up all my custom migrations and these custom migrations seem to execute as the last set of migrations. and also, apparently, by naming my custom migrations "systematically", i can get them executed in the order i want (migration named \[Migration("CustomIShouldBeFirst")\] executes before \[Migration("CustomIShouldBeSecond"\], etc). WHAT IF I want to reverse only one or a few of my specific custom migrations? How to do this ?? What's the suggested tactic or approach??? Thanks for helping!
I did post a slight refactor of the code that checks the input before adding it to the array/list. The linq Any() operator returns much like a top 1 query does in SQL, if it detects anything, it returns true without continuing the iteration.
At some point, too much syntatic sugar rots your teeth.
&gt;Nullable reference types? Wat? Thats sounds really lame to me considering, that we have ? and ?? operators.
Multiplying by dx and dy (declared as doubles) solved the scaling issue. Thanks a lot!
it's actually quite neat. They've set it up as a optional feature and it only generates warnings (which you can upgrade to errors). great for new code bases and still works nicely for old code. the warnings smartly detect possible NRE throughout your code which is just incredible.
I think it's hard to find what you want in enterprise world of .net. Try to look at startups ( a bit risky change) or writing you own pet projects that uses the latest technologies. Because I don't think that big enterprise projects will move to .net core in the nearest future because of the speed how it changes, it's not something they are looking for
I heard Skeet talk about it and I got really excited too. no more checking for null at the top of a function call. You can bake it in as a compile time check, woohoo!
&gt; Also replacing the current references to "non-nullable" would break fuckton of code bases. I mean, do you _really_ think _nobody_ in the multi-year process of dozens of people fine-tuning this feature's spec has thought about backwards compatibility? They have. In fact, getting that part right is perhaps the key reason the feature has taken a long time. Nullable reference types didn't arise as a quick Twitter quip. It has been carefully considered.
I haven't heard about what they are doing with ranges and substrings, that was a pleasant surprise. It is also good to hear they are providing a way to specify null handling behavior for library authors. I am seriously excited about nullable ref types.
You can find a number of software engineering jobs that requires C#, .NET. If you want to make your career in this field then you can join [Dot Net application development](http://alphaonedev.com/c-dot-net/) course and learn different coding languages. 
Thanks for reading the article. I have mentioned XML comments in the article as one way to make a method honest. But in my opinion, this should not be the first choice. Which makes you more comfortable? A method that takes a string representing search criteria with an XML comment explaining valid things to have inside such string? Or a method that takes a CustomerSearchCriteria object that is designed in a such a way that invalid search criteria are not representable? With time, comments can become out of sync with the code. A developer might add an additional search criteria and forget to update the comments. However, with a strongly typed search criteria object, the developer have to modify that type to add support to the new way, or other wise he/she cannot support such new way of searching. This is one example of how a strong type system can help.
Why not check the array for an existing value during entering? I know it doesn't fit very well with creating a method to check the array, but it gets the job done.
But noone is forcing you to eat the sugar.
Hopefully this time they will update LINQ to handle all the new expressions.
&gt; Thanks for reading the article. No, thank you for replying. &gt; Which makes you more comfortable? A method that takes a string representing search criteria with an XML comment explaining valid things to have inside such string? Or a method that takes a CustomerSearchCriteria object that is designed in a such a way that invalid search criteria are not representable? On this particular example, I agree with you. But another example from the article is the `CalculateDiscount` method, where you suggest that the signature should be `public static (Discount discount, int numberOfTimesStatusUsed) CalculateDiscount(Cart cart, Customer customer)`. It took me a moment to get my head around that signature, but maybe that's because I haven't used tuples very much. But once I understood the signature, more and more questions/problems arose. The calling method is now responsible for updating the number of times the discount was used - what if it doesn't do that correctly? What if there are 100 calling methods that all use this method, and just 1 of those doesn't update it correctly? This is a classic example of code that is not DRY, all in an attempt to write pure functional code to save having to write a comment. Eventually, a method is going to have to update the object - you explain in the article how this would be one of the very few impure methods, the one that kicks off the whole method chain. But what if the `CalculateDiscount` method is nested 100 method-calls deep in the call stack - do we have to pass the number of times the status was used all the way up the call stack? What if just one of the methods in question fails to do this? And what if there are multiple paths through that call stack? I could go and on. As I said, there's a lot of good stuff in the article, and after reading the introduction I was beginning to wonder whether to share it with my students as background reading into some good practices. But this devotion to making every method pure is, IMHO, completely wrong. It introduces many more problems, and more complex problems, than the problem it solves, even before considering that there's a pretty good solution that already exists in the form of XML comments. That's not to say functional programming is bad - it's a great thing where the problem is inherently functional in nature. But it's the wrong solution the problem you're trying to address here, I'm afraid.
&gt; I mean, do you really think nobody in the multi-year process of dozens of people fine-tuning this feature's spec has thought about backwards compatibility? Based on the .net standard debacle, specifically with Span&lt;T&gt; and dependency chains, there are doubts...
Using a Set is important as it directly tells the next guy (or you) what you tried to achieve. List is a fantastic tool but the .NET toolbox is rich and you should use the right tool for the job.
You are right, but it's seldom a good thing to optimize in beforehand. According to the current demams we expect only a few items in the collection. Better to prioritize code that is easy to understand. If/when things is starting to run slow or if there demands changes, that's when you start optimizing.
If i remember correctly EF migrations support UP and DOWN Methods, so if you go "dotnet ef migrate update \*MyPreviousMigration\*" it should properly undo the custom migration, if the DOWN method is done properly Please correct me if i'm wrong.
Big enterprises usually depend on the quality and maturity of their technologies. Every single mistake could cost them a lot of money. That's why they very rarely go for the latest newest shiny tech. Good companies periodically catch up, at least if it's possible with their codebase. If you want faster innovation, you should look at startups or greenfield projects. Startups are generally more willing to do bigger changes and jumps. I like the new featueres too, but I also realize the value of stability. New tech is nice to work with, until you encounter a bug in some edge case, which is not fixed yet. Working with a more stable technologies minimizes such risks.
Dude, we don't choose the source codes we maintain. 
What debacle is that?
I work for a company that let developers choose new .net technologies in new projects, but we have a legacy system that is difficult to apply some "cutting edge" technology. A friend of mine works in a company that uses .net core in production for some large projects and he is very happy working there. For sure, is more difficult to apply "cutting edge" technologies working on enterprise environment than in a startup, but I think that things are changing fast for us. Recently i had the same feeling you're having right now, but i decided to give a chance to the .Net because in my opinion, it's very nice and i really love it.
https://github.com/dotnet/standard/issues/682
I agree. One of the selling features of Perl was that there were a billion ways to accomplish the same thing. To me, that was a major downside not a selling feature. You could have 10 years of experience in Perl and still not understand a "hello world" program that someone wrote using weird language features / syntax sugars that you havn't heard of yet.
What if you have to do a code review for someone who did eat the sugar? Every serious C# developer is going to have to be familiar with ALL the sugar. So they should be careful how much they add.
So the "debacle" here is that a new feature that's currently available on one platform isn't immediately available on other platforms?
Basically if youâre a library developer targeting the net standard, when netcore reved and started using span types, which arenât part of the standard, and your library happened to expose a type that indirectly exposed span, you had/have to back out and target core/framework/mono directly Which they have later said theyâre resolving by having a net core standard 2.1 one day, but in the interim non updated libs are broken on framework 
I understand the risky of getting out a big company and trying some startup. I was thinking about doing it, but I just don't see many startups using .net.
A friend of mine calls F# "C# 9". I think he may be off by a version or two, but it does seem like C# is trending that direction.
Yeah, this right here. We only upgrade .net on projects once a version has been out for about a year or so to make sure it is stable in the market and there aren't many critical issues in the framework itself.
&gt;Basically if youâre a library developer targeting the net standard, when netcore reved and started using span types, which arenât part of the standard, and your library happened to expose a type that indirectly exposed span, you had/have to back out and target core/framework/mono directly Well, yes, because none of the implementors of .NET Standard actually _had_ Span when they came out, because Span wasn't a thing yet. You can use your bleeding-edge feature on a bleeding-edge platform like Core, but not on a conservative one like Framework. That's .NET Standard working exactly as intended. If you want to use Span, compile your library against .NET Core. One can criticize that .NET Framework 4.8 _still_ won't include Span, but that's not on .NET Standard.
That's what he said, Noone is forcing you to eat the sugar.
Yeah I like that better. 
I'm more worried about the cognitive load this puts on developers than the idea that they'll become too dependent on it to think about what they're doing.
This isn't about a one implementation having more than other implementations - e.g. span, or conversely, behavior on framework that doesn't exist in core. That part is fine - span is just an example of the situation, not a criticism. But the lack of foresight is that .net standard 2.0 is only valid for a single, point-in-time release. consumers of the 2.0 libs either need to backtrack or the lib needs to be updated - which to lib devs, effectively broke backcomp - thus hence the confusion in the linked thread.
You can use releases after Standard 2.0 were published... but you have to use the feature set that Standard 2.0. You can't backport future features into a past standard. That's crazy talk.
&gt;But the lack of foresight is that .net standard 2.0 is only valid for a single, point-in-time release. How else would it work? &gt; consumers of the 2.0 libs either need to backtrack or the lib needs to be updated - which to lib devs, effectively broke backcomp No, it didn't. What broke something is that someone promised to match .NET Standard 2.0 but then tried to add features that _weren't_ in .NET Standard 2.0.
Working with the newest technologies will change nothing. Your current technologies were new once. I do not have the answer. I have +10 years experience in .net (in Spain). I have worked for (successful) startups, worked for international projects, greenfields, as subcontracto rfor statal public companies... and always the same. It's the enterprise life. Things starts as greenfields, someone in the way leaves, other gets frustrated, code becomes brown, you try to warn directors but no one cares unless it costs nothing to the company. It doesn't change even across different countries. Im trying to move to Plc programming. I will earn less money and it will take a time and money cost I do not have but things will be more technical, less dependant in human behaviour or political decision. Less evolving with time.
&gt; Is it just me or does property-based pattern matching introduce a degree of duck typing into the language? C# already has duck typing (which I'm not happy with). For example, `foreach` doesn't operate on types that implement `IEnumerable`; it operates on types that have a `GetEnumerator()` method. They're also considering moving `using` towards this. It currently requires `IDisposable`, but [will probably soon work](https://github.com/dotnet/csharplang/issues/1623) on anything that implements `Dispose()`.
[http://youarelistening.to/](http://youarelistening.to/) police scanners and ambient music
There many more examoples than that, even (collection and dictionary initializers, await, deconstruction...). You can't use duck typing for any custom functionality though, which annoys me every now and then. Relaxing the limitations of interfaces and extensions (shapes or whatever they are calling them in the upcoming versions) might go long way towards alleviating those.
Well, yes and no. They acknowledged in the video that they went a little crazy with the pattern matching in their example. So, if you're doing a code review on code that literally says Student s =&gt; $"{s.FirstName}, Student of Dr. {s.Advisor.LastName}", { LastName: "Campbell", FirstName: string fn } =&gt; $"Let's go ahead and enroll {fn}!" then that code may be correct, but it's also subjectively bad. You don't have to review for correctness only; clarity also matters. This is hard to read for little obvious gain. I _do_ personally wish for a `switch` expression that's more powerful than the ternary operator and closer to T-SQL's `case when`, directly assigning different values depending on conditions. But I also think there's a case of too much, and Mats's demo, as he acknowledged, was a bit much.
It is hard to understand you. I will try anyway. You have two arguments, fullftp\_dir and filename. It seems you understood you have to pass a remote uri dir but that's not the case. The first argument is a uri to a remote file, it will include dir and filename. The second argument is the name for the downloaded file in your current file system. You should post an example of RemotUri. You do not seem to use any type of autenthication, you can try downloading these uri from Chrome or Explorer and see their correctness.
\&gt; How else would it work? Dunno, break up the standard into smaller chunks that someone suggested? Change the name from "standard" to "bridge" that indicates that if you want a library to target across a specific fx/core/mono release target this, otherwise, you'll need to release separate versions of your lib that target each platform individually. \&gt;No, it didn't. What broke something is that someone promised to match .NET Standard 2.0 but then tried to add features that *weren't* in .NET Standard 2.0. Kinda, it cripples lib developers, but you're right in saying that lib developers can't expect to be on the edge either.
&gt; Just in case the stream of C# 7 point releases hasn't given you enough to think about If the stream of releases excited you, can I interest you inâ¦ [async streams](https://github.com/dotnet/csharplang/blob/master/proposals/async-streams.md)?
I see no reason why these language features should depend on interfaces. Interfaces are for us to use to describe restrictions and polymorphism to the compiler. The compiler can already do binding of features to methods at compile time, there's no need to use interfaces for that behavior.
&gt;I don't know if I'm just unlucky, but every company that I worked was just some boring brown field projects. You're not unlucky. You're just facing the reality of enterprise: * most of the stuff employees at enterprises actually need is pretty boring. They don't need blockchain or machine learning or cloud or anything. They have mundane repetitive tasks, and now they wish some of those mundane repetitive tasks could be done by a machine. And unless someone comes out with another great tool like the spreadsheet where much of the task can simply be coded by the user themselves, someone else will have to do the job. * an IT department is tasked with keeping stuff going. All the fancy technology in the world isn't going to change that making changes to systems has effects. Even if .NET Core were unquestionably better (which it is not â it has downsides), it would still be _different_ enough that you need to train staff to use or maintain it, and you need to check if machines can run it. So you're going to pick, as an IT department, a technology that won't change as frequently, because it saves money and effort better spent elsewhere. * technologies like .NET Core don't make apps better. Good apps make apps better. .NET Core might make you, the developer, better at writing apps, but ultimately, you can write a terrible app in .NET Core and an astounding app in .NET Framework 3.5. I have colleagues who get flabbergasted and/or whiney when I tell them that, no, we're not targeting .NET Core in this app; in fact, we're not even targeting .NET 4.7, and no, you're not going to require Windows 10 or even Windows 7, because _plenty of our actual customers_ are on Windows 7, and retargeting your app to work on it will be a heck of a lot less effort than making all those customers move. It sucks for a developer who wants to toy with the hot new stuff. On the other hand, hey, we _do_ get most of the recent C# features, for free, because almost all of them don't require runtime changes, and for those that require framework changes, NuGet packages are often available for backporting.
It looks super cool
The problem that I see is in your `Get` method: ```if (filter != null) { query.Where(filter); }``` `IQueryable::Where()` doesnât modify the object, it returns a new, filtered instance. You arenât doing anything with the returned value, so your filter is effectively not being applied. What you probably need is: ```if (filter != null) { query = query.Where(filter); }```
Oh my... That is definitely it. I stared at that for probably 10 minutes and didn't even notice. Thank you!!! 
Honestly it depends on which "the market" you're talking about. In enterprises, both .NET and Java are mature and considered stable. There may be an objective victor, but most companies have decided on one or the other and are going to ride it until they're forced to change. Big enterprises are also stable and mature, so they don't invest in large-scale greenfield projects unless they have to. They were good at it when they were small and agile, but now they are large and maybe have shareholders. They can't take risks like they used to. So if you choose this path, .NET devs will always be welcome, but you might not be doing stuff that's exciting to describe to your friends. Smaller companies are harder to predict. They are smaller, more agile, and can take more risks. That means in addition to .NET and Java, they might also be using Node, Ruby, Python, or other environments friendlier to prototyping and churn. They tend to be still finding their niche, which means you'll be more likely to work on greenfield stuff. But really C# is a frustrating language for this kind of prototyping, so you probably don't see many people choosing it at first. The more general "the market" is much more chaotic. We don't even know, for sure, if desktop applications are going to survive the next few years. Even people who think they don't aren't sure which of the competing replacements will win. Will we go full mobile? Will AR advancements change the paradigm? Nobody has anything but guesses. This is why you tend to see people gravitate towards JS and HTML: no matter which platform "wins", that combination works on it. But even that has churn. Do you pick a mobile-focused framework like React? Do you pick a desktop-focused framework like Electron? If you want "safe and boring", .NET in the enterprise is a good choice. If you want "exciting", nothing is a safe bet. 
Yes, though instead of displaying it to the console, you could process the list of filenames to find the one you want.
It all depends on what you are doing (and you have to benchmark things for yourself). You can do non real time encoding easily. [Unity Recommendations](https://docs.microsoft.com/en-us/windows/mixed-reality/performance-recommendations-for-unity) [Default struct equality](https://blogs.msdn.microsoft.com/seteplia/2018/07/17/performance-implications-of-default-struct-equality-in-c/) [Serilization](https://aloiskraus.wordpress.com/2017/04/23/the-definitive-serialization-performance-guide/) [Matt Warren's gists](https://gist.github.com/mattwarren) [Functions with explicit throw statments aren't inlined](https://stackoverflow.com/questions/17225169/is-the-stack-trace-of-function-that-has-been-inlined-preserved-on-a-thrown-excep) [Array Pools](http://adamsitnik.com/Array-Pool/) [c#/dotnet core 2.1 vs c++](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/csharpcore-gpp.html) .NET's regex engine is terrible when it comes to speed and that isn't going to change until somebody re-writes it.
You don't mention what your original data is, so it's hard to comment without guessing. It does sound like you are dealing with a stream rather than blocks. If you aren't already using a binary protocol for your data, that's the first step. Make source data as small as possible by defining a byte[] pattern for your data vs using serialization of objects (I'm just guessing you might be doing that).
You simply aren't going to get good compression ratios on a packet level. There just isn't enough information to compress. You may even *increase* your packet sizes by trying to compress those 200 bytes. On top of that, even with a very fast compression algorithm, it might just be quicker to send small amounts of data over the network than to compress it and then send it. Are you sure you aren't doing some unneeded [premature optimization](http://wiki.c2.com/?PrematureOptimization)? You might be better off spending your time on client-side caching, optimizing or better serializing your network data, and simply decreasing the amount or frequency of your network traffic.
The limiting factor for a lot of calculation intensive applications (like video encoding) is access to hardware SIMD instructions (SSE/AVX). Direct access to them is currently being implemented; you can try them now in the .NET Core 3.0 nightlies and it is generally possible to match the performance of equivalent native implementations.
I'm willing to disagree- I'm a Junior Developer, still very much beginning and have a ton to learn. I got started by just diving into it. Yes, you'll want to start small and understand what you're doing and get used to the syntax. However, my first C# project was just a fork (call a process that calls other processes/programs, including itself, endless loop). Bad, I know, but it allowed me to understand loops, and process starting. I would say that calling other processes/programs from C# is relatively beginning. It opens a lot of doors to more knowledge and understanding. Although, it definitely depends how that person learns.
What you want is the null coalescing operator "??"
https://github.com/dotnet/csharplang/issues/34 https://github.com/dotnet/csharplang/blob/master/proposals/null-coalescing-assignment.md
I know that I CAN do that, but it's not DRY, resulting in two references to the variable, thus: `a = a ?? 2;` `b = b ?? 3;`
Awesome - this would be great - nice to see that they're also considering &amp;= and |= etc. as well.
What he/she wants is a shortcut to `x = x ?? y`, which has precedent as `x = x * y` is equivalent to `x *= y`. As pointed out by /u/tweq, it--along with assignment for the binary boolean operators--has already been proposed.
 int? a; int? b = 1; a = a ?? 2; b = b ?? 3; In case it's not obvious how the null coalescing operator can be used for this.
And it even supports UWP apps!
Note that just like with Java, there isn't ONE .NET Runtime, rather multiple flavours of it, with different kinds of GC, JIT and AOT support. Regarding stuff to avoid for performance, anything that requires boxing. So no LINQ, foreach, converting value types to interfaces in hot paths. Also make use of unmagened memory, or disable the GC for critical performance regions. Thanks to the Rosylin based compiler, there are some compiler plugins (analysers) that can help you: https://github.com/Microsoft/RoslynClrHeapAllocationAnalyzer &gt; For example, can video encoding/streaming be reasonably done in C# today? Most likely, you could always go down to unsafe C style code for that part of code and there is some kind of SIMD support. Also on Windows 10 UWP apps, .NET applications are compiled AOT to native code, so you wouldn't have the JIT variable on that kind of processing.
Yeah, I should have mentioned that. I added a `Answer to comments` paragraph to my question! :)
See the `Answer to comments` paragraph I added to my question :)
Wouldn't it make more sense for the operator to be ??= instead of ?=
Of course, if C# ever did reach "feature parity" with F#, it would be so bloated and monstrous that no one from either camp would want to use it (some here seem to feel it's already on that path). That's why the old argument of "Why should I use F# when I could just wait for C# to get F#'s features?" never made any sense to me. Languages are more than just agglomerations of features.
Use List&lt;int&gt; - all List&lt;T&gt; instances have a .Contains() method that will let you know if the item is already in the list.
I like these additions but also feel like the language is getting more bloated with new syntax in every release
Probably going to need to see your code to understand where things might be going wrong. Where are you calling dependency.Start() and dependency.Stop()?
Have you ever made a deep learning algorithm? If not, kindly fuck off. A fork bomb is the easiest shit, you didn't dive in, you slowly walked in. If you are just beginning, Don't try to do something that experienced devs would have difficulty with. Source : I'm a developer
Didnt mean to push any buttons. Thought "deep learning" was just a manner of how much you try to learn at one time. Like I said, still a ton to learn. A fork was my first, but not my only/best/whatever. 
Why? Why do you think that you need to compress your data stream? What problem are you trying to solve? By the sounds of things you've already spent a fair amount of time optimizing your network protocol. At this point what you're left with is pretty information dense and is not a good candidate for compression.
See the `Example` paragraph. There **are** quite a few scenarios left where compression can make a notable difference. But doing optimizations like re-using IDs or something manually would take waaay too much work (not to mention that all of it would be wasted as soon as there's one little change regarding IDs or objects, so a full compression layer is optimal). As for reasons: 1) Pretty much every byte transferred costs money. I don't think compressing to 30% is realistic in real world scenarios, but 60% should definitely be achievable! And that pretty much directly translates to -40% spent on traffic. 2) Peer to peer is not an option 3) Even though it's not a mobile game, it is still supposed to work even on very weak connections like mobile 3G. There are lots of players who don't have access to 10MB/s connections for various reasons.... 
I should have put a more direct question in my first reply: how much traffic are you seeing with a typical connection?
&gt;Compression is an absolute standard layer of every network protocol for good reasons (see above). Even simple protocols like HTTP support at least gzip (and pretty much every website makes use of that). Websites use gzip because websites are written in some form of text format. Text is inherently highly compressible because there's a lot of bits wasted just to make things easier for us humans to read it. &gt;Compression is just such a low-hanging fruit compared to everything else that can be done. It's robust, "implement and forget", and immediately gives notable gains that directly translate to better performance and money saved. Compression is not some magic bullet that you can just add to anything and see instant gains. In particular your situation is almost perfect storm of when compression is not going to work. The only thing I can think of that would be worse is if you were trying to compress an MP4 stream. &gt;Anyway, I'm not sure why I even have to justify my approach haha. Because we're trying to save you a lot of time and frustration and if we can actually tackle the real problem you have rather than the solution you think you need to the problem you have then we can both end up happy.
Yes this is true! I heard that in my last presentation about C# 8, but if you learn the new syntax and the new consturcts then really you can write in C# more compact and readable code. Look to LINQ or Lambda Expressions at the begin it was like magic but for today you need it everywhere and really make your code looking better.
Every new syntactic sugar is welcome.
Hm, that very much depends on what's going on in the game. Standing alone, out of view range of other players, in some zone with some NPCs... maybe 3KB/s. But that's not the scenarios I'm optimizing for. I'm optimizing for crazy fights. Lets assume multiple players (3-6), one boss, and ~30 other units (additional enemies). All of them moving and casting abilities/spells. Also, most scripts (for spells, units, other entities like coins and obstacles, and generic "map scripts") have to replicate some state to the clients quite often. From things like units moving in range of the aura of another unit causing whole cascades of effect changes, over spawning/despawning of units, to replication of some pathing and physics.... There's just a lot going on. So traffic going as high as 40KB/s is not even all that unusual! The individual things are optimized; but there's quite simply just a number of things going on by design.
That seem awfully high. Are you sending full updates of all object with each server tick?
Alright, fair enough. However: &gt; Compression is not some magic bullet that you can just add to anything and see instant gains. In particular your situation is almost perfect storm of when compression is not going to work. The only thing I can think of that would be worse is if you were trying to compress an MP4 stream. So as mentioned in the opening post, I tried LZ4(hc) In my tests, some real-world traffic dumps are compressible to 30% (granted, a case where not much really happens except for some NPCs walking the same route, some people chatting, and an NPC saying the same few sentences on repeat.). On other, more interesting traffic dumps, I got down to ~85% at least. Which is still a big improvement that I don't want to throw away. How do you reconcile this with `perfect storm of when compression is not going to work` ? It does work, maybe not as well as compressing text, but it's still an improvement, no?
:) and pattern matching is not only syntax sugar it is a powerful technique, I really love it! 
How were you doing these traffic dump compression tests? Something is not adding up here. Either you're data is not binary or you're sending a ton of redundant data and in the later case the solution is to simply not send the redundant data.
No, pretty much everything is in delta updates. Lists get inserts/removed, transforms have special encoding (already talked about that in my first post), updates to simple values like health or various flags are grouped. Some script objects (those that exist on the client as well) can of course only send their individual field values together with names, since the structure of the object can change. The network IDs each object has are pretty large (8 bytes). I don't think the last two things can really be improved. But by intuition alone, compression is a good match for the inefficiencies there (which my tests have confirmed)
Wow... 
It *sounds* like you're doing everything right which puzzles me. One last shot in the dark: when something is moving are you sending an updated position with each tick or are you sending a position + velocity vector to the client? I still maintain that compression is not a good match, but feel free to prove me wrong and write an awesome blog post about it.
Huh? Objects being serialized into a binary format doesn't magically remove all redundancies. Once you have multiple messages and not just individual ones, you'll get redundancies, its just unavoidable. See the "Example" part in my original post. That should make it more clear. That's exactly what compression is for. "not sending redundant data" is not a solution. It literally means "write your own compressor", but that is simply not feasible. I'm building a game, not a new compression algorithm. Sure I could somehow keep track of IDs I previously sent, and then assign even shorter ids to them and all that. But that's exactly what a compression algorithm **already** does, except it does it better than me most likely, and more optimized. 
lol "she". we know that isn't true
A compression algorithm can only make those optimizations off of already known values, not unknown or future values. It also has to transmit that information to the client so that the client can uncompress the data in the same way it was compressed. In the case when you're looking at packet sized chunks of data the overhead of communicating that to the client is usually more than the gain you make with the compression.
Getting there! I have temporarily given up on implementing an RTMP server and am using SRS for now. I have a client working and it is able to receive the RTMP live stream. If I dump the bytes received directly to a file (FLV) it plays back beautifully in VLC. But I need to figure out how to get the raw h264 bytes from the FLV byte stream. Time to look into the FLV/RTMP specifications haha...
For NPCs they have a mode where they follow waypoints, so only a vector3 array + a few 8byte time-stamps are transmitted. If they follow dynamic objects they either get a new path every 0.5 sec, or a target to directly move to (if there are no obstacles to to be walked around) Players are too unpredictable, but movements are often small, so it sends special transform deltas which are smaller than full transform updates. Most of the time a Delta1_XZ_RotateY can be sent. That's 2 byte header + 3bytes for the position and rotation delta + 8byte for the objectID + 4 byte timestamp. There's some velocity information when a player is jumping/falling/gliding, but if that's included its a whole different packet type anyway. Velocity is often just 1 byte per axis because it's not used much except for interpolation/extrapolation. Anyway, I'm sure movement stuff is optimized pretty well. Sharing/shortening object IDs however is not, and that's not something that can realistically be fixed by me. Maybe I could group all updates to script-variables into some sort of "the following var updates are all for scriptObject ID xyz...". But there are not many variables per object anyway... Juding by how often each message type is sent, and the size grouped by message type, it's really not one single thing that's. &gt; but feel free to prove me wrong and write an awesome blog post about it. I'll try, I guess. 
no, Deep learning is not how you learn it is a very complex thing to do, I see that your response was just a misunderstanding. - Will
&gt; The calling method is now responsible for updating the number of times the discount was used - what if it doesn't do that correctly? Then the developer has made a mistake that he should not have made. The CalculateDiscount method does not promise to record the new numberOfTimesStatusUsed. Other code would do that. Even outside of the world of FP, there is concept called [Command Query Separation (CQS)](https://en.wikipedia.org/wiki/Command%E2%80%93query_separation). This concept states that a single method should either return data (and cause no side effects), or cause some side effect (without returning data). Please note that CQS does not required methods which return data to be pure. The benefits of CQS are already well know. To adhere to CQS, the developer could invoke a command after calling CalculateDiscount to record the new numberOfTimesStatusUsed. If we want to keep the calling method potentially-pure, such command can be injected as a function to the method. How to make this scale is a topic I am going to discuss in another article. There is another question: What happens if the caller invokes CalculateDiscount twice (the impure version)? Maybe the caller is only calling the method to see the amount of the discount to use it to make further decisions before actually deciding on how to proceed. Calling the method twice might make the numberOfTimesStatusUsed value be incremented twice unintentionally. &gt; This is a classic example of code that is not DRY I am not sure about this. As I discussed above, maybe some consumers don't want the numberOfTimesStatusUsed to be updated (recorded). You can always create a method that calls the CalculateDiscount method, and then calls another command to record the change. To make the new method potentially pure, the command will be injected into such method. These leads to the next question(s). &gt; do we have to pass the number of times the status was used all the way up the call stack? I will also add the following to your question: Do we have to pass any function parameters (like the command I talked about above) all the way down the call stack? I think that these are the most important questions. I mentioned these problems at the end of the article. I plan to write another article just to answer these questions. The answer really does require a whole article. But if you want a quick answer, the solution is a special type of Dependency Injection. &gt; Code reviews should prevent this &gt; source control can quickly show what's been changed and not commented so that the comments can be corrected Just take a look at methods in the .NET framework. Today I was working with the EventLog class. Consider [this constructor](https://msdn.microsoft.com/en-us/library/wzz7td9t(v=vs.110).aspx). The machineName parameter can be used to specify the machine to which we want to write events (or read events). I remembered that there was a special value for this parameter that will make the EventLog connect to the local machine (because I used it before), but I forget the exact value. Was it null? Or an empty string? Or maybe a "."? I had to go to MSDN and look at the example to know that it was the ".". So, XML comments for methods in the .NET framework don't make them honest enough. I suspect that such code is code reviewed. I am not sure how much reviewers pay attention to such details. It is very easy for such mistakes to pass through code reviews and even the approach you suggested relating to source control monitoring. It is much better to use the type system here to make methods honest. For example, the machineName parameter can become a discriminated union like this: type Machine = | LocalMachine | AnotherMachine of string I hope you see this is much more powerful. 
Agreed, given its use in the conditional statement you'd almost expect a ?= b to have to do with a's truthiness instead of it being null
I've always liked C# because it's easy to write readable, easy to maintain code and in general, I immediately know what's going on when looking at a C# code snippet whereas in order languages I often find myself having to lookup method names which are abbreviated and/or contain arguments in a weird order. Not quite digging the recursive patterns with tuples. Much like the other poster here I feel like the language's becoming more bloated with every release. I'm fine with the shorthand ternary notations, expression bodies and null propagation because they're short, but please, let's not obsessively try to make shorthand notations for everything. I'd rather go through a 100 lines of code that is written beautifully, than 10 lines that are abbreviated and shortened as much as possible. It's 2018 FFS, we haven't needed to conserve bytes in our source files for decades now.
Use arrays when possible, List&lt;T&gt; when arrays aren't possible. Iterate over collections with for loops, not foreach. use collection.length IN the for loop as this will help the compiler elide bounds checks. Don't use LINQ on arrays and Lists or other object collections. Consider something like [https://github.com/jackmott/LinqFaster](https://github.com/jackmott/LinqFaster) , which is convenient like linq but faster, and also offers parallel and simd enhanced options. Understand when and how structs can improve performance and then use them appropriately. Learn about the new SIMD intrinsic instructions. Learn to use benchmarkdotnet so you can try things and see what is actually faster.
there is one place that foreach is ok - plain arrays. In fact it can be a good idea as it ensures you don't screw up array bounds elision.
Removed: Rule 5.