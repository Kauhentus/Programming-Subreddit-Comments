In WPF I have been using backing properties so I can add "OnPropertyChanged" to the Setter
In WPF I have been using backing properties so I can add "OnPropertyChanged" to the Setter
ok so here is the basic code: private void Draw_Triangle(Face face, params Vertex[] _v) { Vector3 a = _v[1] - _v[0]; Vector3 b = _v[2] - _v[0]; Vector3 a_n = _v[1].Normal - _v[0].Normal; Vector3 b_n = _v[2].Normal - _v[0].Normal; float max_difference = Math.Max(a.Get_Length_2(), b.Get_Length_2()); for (float i = 0; i &lt;= 1; i += 1 / max_difference) Draw_Line(_v[0] + i * a, _v[0] + i * b, face); } (The Vector3 class is pretty much copied from unity)
that looks like a totally separate issue. don't ever do anything directly with console.readline except store it in a variable. then you can do some basic checking before passing it on to another function. especially since there is user input involved you should put that convert inside a try..catch. also use bool success = int.TryParse(input, out int result); with that it won't throw an exception if the format is bad, and you can decide using success what to do. if success is true, result contains your number.
ah, one of those problems that makes you do certain things even if they aren't best practice. First go look at the build directory (inside your project folder, there is bin, and go from there). when VS copied the file to your output as you told it to as a build action, did it keep the folder structure or no? see the comment from u/TypingintheMountains below for a good way for your program to know where it is running from, then apply Path.Combine on that and what you learn about where the file is relative to your exe.
`/// &lt;summary&gt;` `/// The Count Enable By Admin For Power User` `/// &lt;/summary&gt;` `public int CountEnableByAdminForPowerUser {set;get;}`
Just don't place field and property together. Group the fields somewhere all the way down. They're an unimportant implementation detail.
You could use a Fody add-in so you don't need to do that yourself https://github.com/Fody/PropertyChanged/blob/master/readme.md
Sad!!
why is the op being downvoted this much?
I organize my classes so that public and non-public members are segregated, with the public members at the top of the file. When reviewing a class, I first want to see its public API without my view being muddled by other implementation details. The only exception to this is usually constants - since constant values may need to be changed (hence the reason for making them constants in the first place), I typically put those at the very top of a class file where they can be easily found. So, if you followed this pattern, all of your public properties would be grouped together at the top of the file and all of your private backing fields would be similarly grouped together after its public members, much like what you've suggested (except applied as a pattern to the entire class file). I extend this pattern further by grouping together fields, then properties, and finally methods (in their respective public and non-public sections). I find that this helps a lot with maintaining my "mental picture" of the class and its overall functionality.
I just use underscores because I hate `this`. I almost never use `this`, only rare cases are when I need to pass the current instance to somewhere.
You skipped the first point of his answer: &gt; First you have to understand what the current directory of your exe/C# application is that is running.
I believe C# 8.0 relaxes the special character order.
&gt; .NET Core 3 supports WinForms and WPF on Windows only. That still chafes - the point of .NET Core was cross-platform (in my mind).
see https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.process.start?view=netframework-4.8 basically, in C# `Process.Start(URL)`
Thanks
Thank you, this was a great help!
It's for people that can't remember the order of the characters.
You can use System.Reflection to get the current location of the DLL: string assemblyLocation=Path.GetDirectoryName(Assembly.GetExecutingAssembly().Location);
Sure, I know. Doesn't change the fact that he should **understand** the problem first.
I made an alternative to Dapper for fun and learning. [https://github.com/perfectsquircle/toadstool](https://github.com/perfectsquircle/toadstool) It started out as an easier way to manage connections and transactions while using a repository pattern. Sharing a transaction on a single connection across different repositories gets a pretty messy (without resorting to TransactionScope), and Dapper doesn't have any concessions for this. Next thing I knew it turned into a mico ORM. It's probably not nearly as fast as Dapper nor as complete, but it's fun and it's mine. ```csharp var stockItems = await context .Select("stock_item_id", "stock_item_name") .From("warehouse.stock_items") .Where("supplier_id").EqualTo(2) .OrderBy("stock_item_name") .ToListAsync&lt;StockItem&gt;(); ``` I'm kind of curious if anyone would want to use something like this.
Yes. SQL Can be used everywhere
Thanks, could you recommend a beginner friendly course?
What is the Config Object? The null reference is either the Config object itself is null, doubtful since you obviously have a reference too it about that line, or something inside SaveConfig is null, so take a look inside SaveConfig
W3 has a MySQL tutorial I used a lot
https://www.w3schools.com/sql/
Thanks, this was really helpful as I got lost on what to do now
Screenshots of text are probably not the best medium of reproduction. In any case, I suspect that `_pouRepository` is `null`. You can't generally call methods on null references. The part of the code where `_pouRepository` originally comes from isn't included. If you still don't know what to do, I'd recommend attaching a debugger, and breaking where `GeneratePOUs` is constructed.
Yeah sorry I meant to reply to OPs comment. I agree.
First thing: install MySQL. Second thing: follow the tutorial. Whenever you're stuck, go to Google. Rather, go to duckduckgo. Also codeacademy had an interactive SQL tutorial. Try to focus on SQL And I as it is the one used as a base by everyone. And have fun
Yeah sorry I'm new to this sub. Don't really know the best way to do this. &amp;#x200B; \_pouRepository is originally here: public IRepository&lt;POU&gt; _pouRepository { get; set; } public SoftwareComponentsAppService(IRepository&lt;SoftwareComponent&gt; repository, IRepository&lt;POU&gt; pouRepository) : base(repository) { _pouRepository = pouRepository; } Ignore the SoftwareComponent stuff. That works fine.
Yes Object pools are extremely useful, and are still in use today. &amp;#x200B; The ADO layers in .Net use object pools for connections, as well as most No-Sql libraries. Pretty much anytime you attempt to create a new SqlConnection/DbConnection the underlying layers are attempting to use a connection pool. &amp;#x200B; The Managed thread pool is just another pooled resource collection, happens to be Threads. While the internals might be slightly different the usage and patterns are the same. &amp;#x200B; [https://github.com/jcanady20/DatabaseCopy/blob/05b8e8b9f8232a2176869e6990b5131d9a043fb8/DataBaseCopy/BusinessObjects/ObjectPool.cs](https://github.com/jcanady20/DatabaseCopy/blob/05b8e8b9f8232a2176869e6990b5131d9a043fb8/DataBaseCopy/BusinessObjects/ObjectPool.cs)
Looks like it is probably null at as an a parameter value to the `SoftwareComponentsAppService` constructor then. You need to follow this back to where it's being invoked, and provide some value other than null.
Databases as nice but not must have, so it's bauxite up to you what you want to move next. Since you are currently in c# I would suggest to learn ASP or wpf (depends again on your interest) first. In case you really want to learn it I would suggest w3 school for understanding basic Syntax (which you will probably forget once you learn ASP) Also note that many ASP tutorials and book are using ORM Entity Framework, which overtakes good portion of sql
Please note that different databases uses different sql Syntax. What will work fine in MySQL might not work in ms sql (t-sql)
Thanks. Going to do some more debugging. This is a bit of a tricky one for me as I have lots of variables that could be causing this. I'll check back later with some results. Not sure where it is being invoked yet.
So what exactly should I take up?
If you set a breakpoint, you'll be able to use the Call Stack window under debugging to see all the parent calls the led to this.
I love that auto-correct changed "basically" (I assume) to bauxite :)
Don't use TopShelf, Setting up a windows Service ([example](https://github.com/jcanady20/Scheduler.Service/blob/master/Scheduler.Service.Host/SchedulerService.cs)) is ridiculously easy, and shouldn't rely on third party libraries. All a Windows service is is a class that implements ServiceBase from System. ServiceProcess. Simply override Start and Stop and if you want to get really fancy you can even do Pause/Continue. Installation of the service can be done with [sc.exe](https://support.microsoft.com/en-us/help/251192/how-to-create-a-windows-service-by-using-sc-exe) utility or that .Net utility that no one remembers. You can also do it yourself, without any hassle as well. Here's an [installer class](https://github.com/jcanady20/Scheduler.Service/blob/master/Scheduler.Service.Host/ServiceInstaller.cs) all ready for you, just copy/paste and Add a reference to System.Configuration.Installers Here's a [sample app](https://github.com/jcanady20/Scheduler.Service/tree/master/Scheduler.Service.Host) that handles all this for you.
Ty for pointing it out
Ah. I've found the cause. Some more debugging actually reveals it's an issue in the Create method I was calling. I know how to fix this. Thanks for the help! Here's the error if you are interested: [https://imgur.com/a/uZ2pNMk](https://imgur.com/a/uZ2pNMk)
If you certainly want to learn sql next, learn basics (create, update, select, etc) as much as I remember simple statements are more universal. When you start nested queries the diffence start to come. Which sql you want to learn is depending on cost/performance. I believe Ms sql is the fastest, but for larger projects it becomes very expensive.
Thanks :)
Absolutely.
I would recommend T SQL (aka microsofts SQL) https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017 or use Visual Studio https://www.codeproject.com/articles/825831/sql-server-database-development-in-visual-studio
I will look into this. I am not versed in debugging... but looks like im about to be :)
If you only interested in that information after the fact, then the Sys [DMV'](https://docs.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/system-dynamic-management-views?view=sql-server-2017)s are you're best option. These views allow you to query pretty much everything you would want to know about any given execution. The views capture query plans, session details, etc and allow you to parse/diagnosis a wide range of issues. However keep in mind that DMV's are reset when SQL server is restarted. So you will need to maintain your own store if you want to maintain those details across server resets. SELECT UseCounts, Cacheobjtype, Objtype, TEXT, query_plan FROM sys.dm_exec_cached_plans CROSS APPLY sys.dm_exec_sql_text(plan_handle) CROSS APPLY sys.dm_exec_query_plan(plan_handle) &amp;#x200B; You can get more details here but this is only an example. You should be able to get details down to the session it was executed from and by whom. Once you have query\_plan here, its just an XML blob, you can either change the query here, and parse it on the server, or pull it back to C# and parse it there.
I have got to kindly disagree about the fact that SQL isn't "must have". Databases are the core of what makes most of the software engineering field what it is. Understanding at least the basic concepts will make you a better developer for sure and I'd go further to say an understanding of indexes and how querying works can be tremendously helpful! I think that learning ASP or WPF without learning SQL isn't helpful at all, but that both could be learned roughly at the same time! Also, I think learning SQL before EF is important because otherwise you won't understand how to properly use EF without throwing performance away
Yes - learn SQL. It will benefit you in pretty much any stack/technology you may end up transitioning to. &amp;#x200B; And if nothing else, it will give you the ability to call out DBAs on their nonsense. (kidding) (mostly)
99% of legacy API
Ah, very slick.
Can you post your test harness and whatever benchmarks you do currently have? Even if they're in a sorry state it would help. There's a number of things that seem kind of suspect in your code, but which are justifiable if they're actually effecting the performance or correctness.
In my opinion, you should move into [ASP.NET](https://ASP.NET) next, starting to fill in the SQL where it's called for, and follow up with a SQL deep dive. To me that would be an ideal learning path that develops well. I recommend looking into the newest .NET Core Framework. That may be a really good starting point for you. Good luck on your journeys!
Depends on what you want to focus. The differences tend to be not very noticeable (until they). If you get stuck in one, you can find someone in Google or DDG or Stack Overflow with the answer.
I wish VS had a way to just hide the backers like a filter on the solution explorer. (if there is and I missed it please do share :))
Units for one thing. Knowing if a property is in seconds or milliseconds is a big help. And you can't always rename a property.
`#region` Some code formatters will automatically add them.
I agree with that. If it we're a pain in the ass, I would consider moving them into a partial class file.
If I recall correctly, Linq requires using `this`. For example, public int ActiveRecords =&gt; this.Where(x=&gt;x.IsActive).Count(); Can't say I use it any other time.
No, you shouldn't.
True, it is different. But it is still an important to be able to see those differences in terms of performance.
I recommend SQL Server or PostgreSQL. MySQL is more likely to lead you to bad habits.
I believe the difference is mostly in syntax. However, I'm not sure about this case. x.y.z ??= foo(); How many times is the `y` getter invoked? That's probably another difference.
OP always include line numbers when sniping codes so it's easy to refer. &amp;#x200B; 1) When dealing with files you should always confirm file exists before reading from it else you app will throw exceptions &amp;#x200B; so you need to add a check right before string\[\] lines = .. line that check if file exists `if(!File.Exists(path))` `{` `Console.WriteLine($"File not found {path}");` `}` Let's call your "Data" directory as resources, you have two options for this. 1) You can make assumption it stores into some system path than you can hardcode the path (bad practice). or 2) You can copy entire "Data" directory into output directory and use reference path. if you copy "Data" into output directory you can create "baseDirectory" path for execution directory You can copy entire "Directory" to output folder by right clicking going to properties and selecting copy to output always `string baseDirectory = AppDomain.CurrentDomain.BaseDirectory;` &amp;#x200B; and build file path using this directory. &amp;#x200B; `string low256Path = Path.Combine(baseDirectory, @"Data\Low_256.txt");` `if(!File.Exists(low256Path))` `{` `Console.WriteLine($"File not found {low256Path}");` `}` now again do file path check if file exists do your logic.
I miss Windows Phone. I found that Android easily makes 20 to 30 times more autocorrect mistakes than WP. Seriously, I never understood why people said "Sorry, I'm using mobile" to justify their spelling errors until I got my new android phone. Now it does random crap like changing ok to ht.
If you are using EF without knowing SQL, you are probably doing it wrong. At the very least you need to know how to read SQL to understand whether or not EF is generating the right query.
**SQL for Dummies** is the book I learned from. In one weekend I went from having no clue to being able to use it effectively for my personal projects.
I have never used any other mobile phone than Android but I love how auto-correct works. I suck at typing on a phone so I use auto-correct for everything. I use the Swiftkey keyboard instead of the default one; I wonder if that makes a difference.
Surprised what's his face hasn't posted negative comments yet
&gt; I am using is still C#, and I guess that is where my problems are..**.the foundation is not strong. And hence I was thinking of doing some more work on my C# knowledge and skill**. I would say pick up a copy of [Essential C# by Mark Michaelis](https://www.amazon.com/Essential-7-0-Addison-Wesley-Microsoft-Technology/dp/1509303588) and start doing example in it. I used to do at least one example from the book everyday and learn each concept. The code examples are small enough to do in 20-30 minutes and you can run it. Not only you will learn C# but get familiar with .NET libraries.
Might be the brand, I don't know. But I do see it change valid words far too often. Currently I am using SwiftKey, which is slightly better than the built in one.
How necessary is in depth SQL knowledge with .NET? With Python/Django for example you just create a model class for any different db models you want to manage. It's all done in Python, no actual SQL.
Ah /u/6demon401 kind of answered this below.
Not having looked at your code, or knowing stylet, i'd start by making a class or struct that describes the visual element's plc data. If its just x and y probably PointF is sufficient. Then in the viewmodel you have a collection of these, probably a List&lt;YourObjects&gt;. The plc is basically your data source for the view model. The class or struct is your model. Its up to the view (either the xaml or the code behind) to satisfy the concern of how to display it. The viewmodel probably shouldn't care about the view at all if possible. From the view you can respond to a generic event that the list has changed, the use the view model collection to update the view. If your collection is an observablecollection, you could have the view subscribe to the collection changed event.
&gt; the popular RawDataAccessBencher What a weird coincidence that top search results point to your project.
True. I just improved performance on my own site by moving certain things from EF to a sql stored proc. Took two seconds off a page load time. Sql is definitely required for software dev
#
.NET MVC has a similar kind of technology where you interact with the database without SQL. However, that doesn't mean nobody is using SQL anymore. Not everyone running .NET is running an MVC app. I've worked for two companies using .NET and neither company is using MVC only. Chances are, you're going to need to write some SQL eventually, and you will probably find yourself playing with data here and there. If you're feeling like learning SQL next is the next step for you, do it. It's foundational. However, if I had to learn it all over again I'd layer .NET on top of C# before I dove into the SQL rabbit hole. :)
My recent win took a process that literally ran for hours and reduced it to less than 5 seconds. Same amount of work was accomplished, but by using a stored proc call I turned literally tens of thousands of database calls into one round-trip that handled everything server-side.
Thanks this is exactly what I needed to know. I used to be decently familiar with MySQL about 10 years ago using php / pdo / mysqli etc. But since I started working with Python primarily I haven't had to use it. I was hoping I could jump into .net without having to relearn anything immediately.
I train new hires at work and so far I've found the best way to teach linq is to give the trainee a few empty functions, tell them what the function should do, and then have them do it using linq query syntax and letting resharper refactor it to method syntax. Might give that a try and see how it work for you.
If you are wanting to become web developer then learning SQL is a requirement. Just about everything connects to a database to storage. If you are going the .NET route then start with SQL Server and study up on TSQL. It should not take long to learn the basics but knowing SQL will help you if you use Entity Framework or any other abstraction layer.
Adding to the advices here, besides learning SQL also learn proper database design. It will help you a lot in maintaining your databases.
That’s actually how i currently have it, is there a way to dynamically generate things on a view from XAML?
I would recommend sqlite
Unless you’re working on a library for the public or you’re accepting specific parameters, code comments are useless and end up getting striped from your final assemblies after complication.
IMO there is no language that needs to be understood better by all levels of developer than SQL. Not only will it teach you how databases work so that you can in turn write better code, it is used in pretty much any real-world application. Anything that has some kind of persistence is 99% of the time backed with some flavor of SQL database. You should learn it.
I would agree with your disagreement. EF is a great tool to have not because it allows you to skip the need to know SQL, but because it abstracts the SQL to a more convenient level. Still have to know it first, and honestly for most applications the syntax is not too hard.
Unless creating and disposing an object is taxing, you’re okay. Garbage collection will be more than efficient. As mentioned above, when making video games it’s a different situation as game objects can be spawned by the thousands and is quite heavy on the CPU to initialize and destroy when all you can do is just disable and enable again instead of reallocating memory.
SQL is one of the languages that is almost a requirement in programming fields because it's used EVERYWHERE.
I mainly dig through GitHub or just decompile private projects.
You should be using a `TimeSpan` in that situation, or some other type that encapsulates units so you aren't defining domain rules in your documentation or class member names. Use the type system!!
By storing the file path as a global variable. Caching the file directly is unnecessary memory used up for something that may not even be used. This is what I did for a canvas application I designed for concept artists.
&gt; You should be using a _TimeSpan_ in that situation True. (I don’t understand why so many Timeout APIs use int. Including many of Microsoft’s. Poor design.) But, for other information, not so much. Is a distance in meters? An angle in degrees? C# has no units of measure, so the API doc / IntelliSense XML comment should say.
Or you can run MVC with SQL, and it makes far more sense to do so.
this is perhaps the most pathetic PRAW freshman comp sci bot I've seen yet in my 9 years on this site... and that says alot.
It doesn't really become relevant until you start using more intermediate features. I wouldn't worry about it for now. Most SQLs are _pretty much_ interchangeable.
That's not always an option. Besides legacy APIs that I can't change, in the past I worked with low level hardware interfaces that barely understood that integers and floats were different data types.
I strongly disagree. They show up in code completion, making them useful for larger internal projects.
SQL is good but I prefer using code first migrations rather than writing sql by hand
I recommend just learning the basics of SQL and then move on to LINQ since it’s much better.
It really depends on what you want to do with SQL. Basic CRUD? I think you could almost pick that up by osmosis. Reporting, ETL, administration, business intelligence/analytics? Better get started on SQL. I’ll second someone else’s sentiment that moving into ASP.NET (and then an SPA with a ASP.NET backend!) would be time well spent and you’ll learn sql along that track
ASP interfaces well with MS SQL Server. Visual Studio 2017 has SQL Server Express integrated. PHP interfaces well with MySQL.
Learning LINQ to SQL after basics of C# and SQL? Could you recommend a recource..
It may be. I have not worked with MVC since college, where we didn't write SQL with it. So you may be entirely correct.
Learn things when you need to learn them. Learn SQL when you're doing relational database work. It's fine.
Learn everything. Its nothing to hello world in most languages. Do that at least, for anything you hear about. Put more time into the stuff you _keep_ hearing about. The things you find yourself using often, master them. It may seem like a lot, now, but this industry requires continual learning and the ones that succeed are good at learning. You will learn to learn. It gets easier.
&gt; Is a distance in meters? An angle in degrees? C# has no units of measure I've used the [UnitsNet](https://github.com/angularsen/UnitsNet) library in many projects. There's tons of different units of measure and it explicitly defines intent in your code. Obviously not as good as F#'s built in units of measure, but hey I work with what I've got.
Late to the party but I'll throw in. I have worked on many different projects and some portion of the data storage had been a relational sql database, many of them the only backing data store. Can you get buy without it? Maybe. Can you become a senior developer or architect? No, at least not in my opinion. Should you learn it next? It depends. What are you trying to accomplish with the learning? In the abstract learning sql will be valuable. if you are trying to get a front end web development job Javascript / type script, html, and css may be the better choice to focus your time. If sql furthers you to your goal, then I would suggest sql server (developer edition is free) since all but one c# application I have worked on used sql server for its main data store (the most recent microservice I wrote is using AWS RDS with Amazon's version of my sql since it was there and I only needed a couple tables for authentication) Most of the implementations are similar enough that the differences are few and really come in when doing more advanced things like finding gaps in a time sequence, not every day things like basic crud queries.
I assume what you’re referring to is EF, which you can choose to use or not. It’s entirely separate.
I learned something today! Much obliged!
They show up in code completion through an XML file, not the assembly itself. And as I said before, unless it’s a major product or public, it’s useless. Programmers 90% of the time remember their work or still have the code to it. I never use code comments unless I’m releasing something as open source, and not once have I ran into situations where I “didn’t know” how my own code worked.
Your own code? That's a laugh. I can't remember the last time I worked on a code base where even a quarter of the code was mine.
SQL might be the most ubiquitous language out there.
Okay, that’s understandable, but is OP working on a large project that is open to the public, trending, or is being touched by a team of programmers? No. There’s no sense in trying to compare a professional development workflow to someone that is just starting out.
As a beginner, it doesn't really matter. Relational database concepts are 95% similar across servers. If you are seeking a job in a Microsoft shop doing .NET, then you will almost certainly want to learn SQL Server.
Yea, how dare we suggest that he develop good habits.
I agree. SQL Server has some really nice community editions that are free of charge. You get basically the real deal interface to learn with. Between that and Visual Studio Community Edition there’s almost no reason not to.
Cool! That’s interesting way to broaden the understanding
&gt;MySQL is more likely to lead you to bad habits. May you expand on that?
https://youtu.be/7S_tz1z_5bA
There's a version that you can only license through most any decent asp server provider that's like 30 bucks a month. It is fully capable of handling most projects, even big ones. It's not free but it's not 600 bucks a month.
w3schools isnt affiliated with w3
And how dare we not start from A and not from X? I’m sure there are way better habits to be developed than focusing on code comments.
I found the HeadFirst series on SQL helpful: https://www.amazon.com/Head-First-SQL-Brain-Learners/dp/0596526849 The stock photo of the person on the cover is silly, but if you can get past the cover, the book itself is quite good.
Indeed. Understanding data models for relational databases before you start designing database structures with production consequences is pretty important. I've gone the wrong order and now I'm cleaning up my own messes. Granted, I'm self taught but still. If I only knew then what I know now...
offhand, that's out of my knowledge range. I'd probably start looking at usercontrols or datatemplates, but reading the stylet docs makes me think that if you had a collection of viewmodels you could have stylet find views for all of them i have no idea how to represent that in xaml though.
You’ll need a database of some sort eventually. SQL is among the most common dbls. I would suggest SQLite. It’s extremely simple, though I’ve heard it doesn’t scale well.
My vote is on Postgres. Postgres is [open source](https://github.com/postgres/postgres), so if you're feeling extra ambitious you could look to see how it works under the hood.
Unfortunately I dont have the source of the pdf.
Neat concept. I personally would use Dapper over this because with Dapper or EntityFramework I can write an @String statement and copy paste my already written SQL script into it and it runs fine, and I can add $variables to replace content in that statement. I mainly use Dapper and EF to manipulate the data after it comes from the DB, not any query logic itself, but that's why I would not use it. Still really cool framework and some people will find this useful. I can see this being very useful for delayed queries, where a query is built as a user is performing some actions then run once some condition is met.
I don't understand this complaint. ".net 5 " + whatever your search is
Do note that they're separate and having a good understanding of how sql works is crucial to developing fast code and designing good table structure. You won't need it all right away, but definitely dive deeper than linq once you're ready.
Honestly, I don't think he has a faintest chance of understanding the code. But postgresql does have the most comprehensive support of the SQL standard.
Lot's of reasons such as it doesn't honor check constraints.
That means your method is calling itself every time it's invoked.
Maybe some day. :) Hell, I'm sure I wouldn't be able to understand the code either. Certainly not in its entirety. But it's nice to have the option to look, IMHO. Who knows, maybe MSFT will keep up their open source roll and open up SQL server too. I would definitely say SSMS is way better than pgAdmin at the moment, though. And personally, I much prefer the additional features (json support, indexes on expressions, etc) of postgres. Not sure if that's the best thing to push on a beginner who's just trying to learn SQL, though.
Why can't you learn both? During my undergraduate, every class I showed up too required a different language. C, C++, Pascal, Oberon, Modula-II, LISP, ... &amp;#x200B; I took data structures, they used C++, in Systems Programming we used C, in Compiler Design, we used Oberon written in Pascal. &amp;#x200B; They didn't teach the language, with the exception of CSCI 1020, which I was able to skip. &amp;#x200B; A language is a language. Learn how it all works, and the language is a tool. &amp;#x200B; Focus on learning the mathematics, don't worry about the languages. The language will come naturally after you know the mathematics. &amp;#x200B; In the words of a very wise professor: "About the use of language: it is impossible to sharpen a pencil with a blunt axe. It is equally vain to try to do it with ten blunt axes instead." -Dijkstra &amp;#x200B; PS. If you never took one of his courses, you really missed out.
FYI: You can put indexes on expressions in SQL Server indirectly. Either create a computed column or a view, then add your index.
May want to store that datetime as a datetimeoffset.
Yeah, but I included the exit statement for when nothing is found
Open `C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC#\Snippets\1033\Visual C#\propfull.snippet` and edit the snippet as you wish.
True. I prefer postgres's way of doing it (just tossing it in an index directly), but they do fulfill the same goal. There are other things too (like licensing/$), but I didn't really want to start going off on a huge list. And I could probably make a list in the other direction too, for things SQL server has that postgres doesn't (like SSMS), but this doesn't seem like the place for it. Just pick one and learn SQL. And if OP knows what tools they want to use later (entity framework? dapper?), that might help direct them as well.
From my experience, a couple SQL questions are usually mixed in when doing C#/.NET interviews. So from that aspect it's worthwhile learning basic SQL up to the different joins at least.
doesnt seem to work
FYI: https://devblogs.microsoft.com/dotnet/introducing-the-new-microsoftdatasqlclient/
What doesn't work? Specifically what did you try? Do you get an error? What happens?
I would load them in to memory ( one at a time.if possible) then parse them into an array. From there, use `Array.sort()` then output them to file.
My (apparently unpopular based on the other answers) is a resounding no. SQL should be very very very low on your priority list, it is completely abstracted away by entity framework and that’s great. Learn linq (to objects, and no writing a couple queries doesn’t mean you know it, REALLY learn it, when i teach it i make sure that the person who learnt it could reimplement it). Then learn entity framework core, and some day down the road if you really need it for an edge case learn SQL. I’m well versed in T-SQL, i handle full stack (not just dev but also ops) and i haven’t had (and am glad for it) to touch SQL signficantly in the past 10 years. Also buy LINQpad, it’s one of the best investment you can make, cheap as hell and will be perfect for those cases you need to interact with databases for scripting outside of your project
Hey thanks for taking a look. I really should update the README with more examples, because what you're describing is still totally possible, I intentionally left it pretty flexible. var query = @"SELECT stock_item_id, stock_item_name FROM warehouse.stock_items WHERE supplier_id = @supplierId ORDER BY stock_item_id"; var results = await context .Query(query) .WithParameter("supplierId", 2) .ToListAsync&lt;StockItem&gt;();
All it will do is call itself till the end, but the stack gets full waaaaaay before that. Run it in small chunks of maybe 256, not the whole thing at once. Then, run that function till you get to the end. Whatever you do, NEVER make a function call itself unless you are 100% sure it will only do so at max 6 or 7 times.
FYI: Calling `.Result`on tasks is generally a bad idea. You should be awaiting these tasks to get their value.
I would recommend learning Entity Framework as for me, databases (at least simple ones) are moving towards a code-first paradigm
What is wrong with that comment?
I guess people hates reality :) - you are an ORM developer and ‘BulkInsert’ is a different thing. BulkInsert would result ‘0.02 ms’ on here, where is the justice comparing that 2 ‘batch inserts’?
Have I made a fault on that comment? Because of the word “popular”?
MS SQL for sure.
I'm no expert on this and someone smarter may be able to correct me but I believe this is O(n!) and similar to trying to brute force the [traveling salesman problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem) &amp;#x200B; if current cell = 6 return total paths + 1 else if next cell can be moved to (all 4 directions) call recursively else return 0 So: we call the function and it can move to another cell so we call the function and it can move to another cell so we call the function and it can move to another cell For each cell you're rerunning the check for every cell recursively. &amp;#x200B; You've accidentally come up with something that sounds easy in theory but is actually really hard.
Oh, I did not know this, yes I just made a search in Google. Okay, so this is it :). Thanks!
Well, a bit surprised why the first comment and my succeeding comments were downvoted. Never know what is wrong actually :) - but somebody says the “popular points to my project”?
Thanks, but, if there is any other ORM that implements Bulk, then I can do it compared with RepoDb Bulk operation :), and again no on this kind of test because they are far different. Bulk is different from a Batch
Ignore the above comment. I'm a developer (25) who learnt mySQL at 15 through the w3 website. When it came to learning TSQL (I use this a lot commercially) you can easily transfer the concepts. After a day of googling how to do X in Y, you'll easily be able to use either.
I actually did use BenchmarkDotNet later on to make sure. It's just that it is slow for my purposes which was to change a little and check quickly to see the results so I used a simple warm up, loop, record time, loop, ... throw away times that are much bigger than the average (`outliner`) and report the final result. Also I'm not yet fully comfortable with how I should use BenchmarkDotNet. Here is the result with BenchmarkDotNet using a byte array with length = 33 (the code is the same as BenchmarkDotNet for comparing SHA and MD5): [SHA256](https://gist.github.com/Coding-Enthusiast/dbcbe197a6ad74ee61de90c5c9920061#gistcomment-2912581) [SHA256 of SHA256 or double SHA256](https://gist.github.com/Coding-Enthusiast/dbcbe197a6ad74ee61de90c5c9920061#gistcomment-2912583)
You must be pretty new to the sub then :p
Yup - Because they realized that if you want 1,000 mini apps all doing different things you don't want that taking up 58GB - So you take what is common, split it off, and you drop from 58GB to 1.2GB
File size is important to anyone who doesn't have a 1TB SSD (Which is almost everyone), and double-clicking is so important to almost any Windows / Mac user ever.
Yup. .NET Core by default includes the entire runtime in the build
I never said you should use orm with known sql.
There was actually someone who an app to open Windows Calculator, press the buttons, and OCR the result. They were trying to make the least efficient calculator they could ;D
Which you rather have a 60MB minimum install for every .exe and DLL on the users system?
You definitely should learn SQL, it's essential if you want to build a website or just work for a company. Start by making some queries (SELECT, INSERT, UPDATE, DELETE). After you do that go to more advance SQL and learn how JOINs work (all of them not just inner join). And after you cover that you should move to stored procedures and functions. When you are done try building an app with everything you learned, c# and SQL, but don't use entity framework or any ORM, try simple c# and build your own object in code that will be mapped to the database tables. And also make use of sql procedures in the app, it will really help you out. Good luck with it.
The final image shows [this](https://www.hanselman.com/blog/content/binary/Windows-Live-Writer/e1da3755ebc9_13130/image_9.png) - Which has 3 required dll's and 3 required .json files. Self-contained is just that - "self contained" - 1 file. Not 7.
&gt; and then your Hello World won't be 60MB and 200 files, obviously. Get it to be 1 file - I dare you.
For someone who just understood oop concept and doesn't know any language, sql is mostly usless and probably will quickly be forgotten. Again it depends on context. If you have no stable background and just starting to learn some tech, jumping right away to sql I w would say only makes it more. And yes, you learn sql before using any orm (ef), never I suggested otherwise
Yes do it. Sql is the basis. Even is you go nosql or entity framework (which is hidden sql), everything is defined in comparison to sql. And you are undoubtly going to work with sql one day. Not knowing it would be a severe lack. It is not that difficult and can prove to be very efficient in many cases. Have fun :)
True, but that has also issues. Going with 100% reference libraries makes you program vulnerable to changes through windows updates and potential GAC issues (which are rare, but still happen). Also, the common parts that you are referring to still have versions, so it’s not a safe assumption that all of your “mini apps” will use the same versions of the secomponents.
You can learn basic sql features. Mostly your have to know how to write typical query. You can master it in a couple of weeks
I managed to fix it, it's working now.
If you plan to work with c# you might want to play with SQL Server instead. It is used by most companies using .NET. The actual sql is almost the same.
I know but my Angular front end needs to be able to read it. That’s why it is a string. I suppose I could run .ToString on the get method. Lots of Lazy coding in this app. I need to rework most things once I’ve got the main stuff running.
You can’t put a timespan into a config file
You can’t put a timespan into a config file
The methods are all override methods (I’m using a library for the AppServices) and IIRC you can’t use await in an override unless it’s an async.
That would just be lipstick on a pig. I wish we would get addressable auto-fields in properties in C#. There's a proposal for it for a long time already, but it gets ignored by the team. Instead we get near useless shit like the using-directive...
In C# 8.1 they will relax the language even more, then you can write `$"@` or `"@$` or `"@$`.
&gt; Whatever you do, NEVER make a function call itself unless you are 100% sure it will only do so at max 6 or 7 times. Does C# and .NET still not support tail-recursive methods?
That is a good point.
There's no such thing as "the SQL standard".
&gt; SQL became a standard of the American National Standards Institute (ANSI) in 1986, and of the International Organization for Standardization (ISO) in 1987.
YES Of course!
dBeaver community edition is great for postgresql.
.NET supports tail recursion (F# would be a damn useless functional language without it), but the C# compiler does not emit relevant CLR. Apparently implementing tail recursion in C#'s jitter is hard.
Your algorithm is incorrect. The stack overflow is caused by going back and forth through the same cells. It's easy to show that for example for a map like this: 1 1 1 1 1 0 0 1 1 1 1 1 You will be going from 1,1 to 1,2 and back indefinitely. Since your method is recursive, every call takes up space on the stack which eventually runs out. The code looks weird to me, I assume that by 6 you mark the exit from the map, but it's unclear. The `paths` variable is useless as it stands, it never changes until the algorithm returns, which means that you always return the initial value + 1 (if you ever return). For a problem of finding a path through zeroes you might to want to look into the DFS or BFS algorithm. The former will determine if a path exists and may be easier to implement with a simple recursion. The latter uses a queue and has the benefit of finding the _shortest_ path, if it exists. Both are linear in the size of the map.
I don't think that "6 or 7" times is good advice at all. Default CLR stack size is 1MB for 32-bit and 4MB for 64-bit. That's _a lot_ for most recursive functions, so attempting to run a DFS on a medium-sized graph would easily fit in this constraint. Going by the spirit of not optimizing things preemptively, you should only ever care about eliminating recursion if it causes your app to have an SO. Then you may take your time to reimplent it in an iterative style. Unless you're working with large data that will be most likely unnecessary. But "whatever you do, NEVER make a function that calls itself indefinitely, forever" would be a good advice, quite obviously I think.
If you really need to hide a bunch of fields because of clutter, your class is probably too long anyway. However I'm pretty sure that ReSharper can be configured to put all private fields at the very bottom of the file.
[`#region` is evil and a design smell.](https://enterprisecraftsmanship.com/2015/12/08/c-regions-is-a-design-smell/)
They do, which is unfortunate. CMIIW, but I think there's no reason the compiler couldn't deduce `this` here.
&gt; W3 Praise W3, i always end up on that site ...
Clean Code has a chapter on how you should only ever use javadoc-style comments on public APIs. However, one has to remember, that on larger team projects where you establish interfaces between parts of the codebase, these interfaces may end up being practically public, even though technically internal.
Literally never heard of it.
It is of Type Task&lt;T&gt; so there is no issue to just "prepend" async to it. This allows you to "await" inside of it. &amp;#x200B; you can easily "override" a Task&lt;T&gt; Method and prepend async to it.
in C# 8.2 it will be even better `"myString {0} {my variable}".AsInterpolatedVerbatimString();` now the caller can define if it will be verbatim and / or interpolated!
Why is it static and not member of view model!
Yes.
This. Then for the differences he should get like the animal book [SQL Pocket Guide](http://shop.oreilly.com/product/0636920013471.do), that succinctly describes the different syntaxes.
&gt;public string Test { get; set; } That was clever :P Thx
I'd go with T-SQL (for MS SQL) since you're already working with c#. It does translate though, so you can transfer that know how to mysql and others.
Murdoch's SQL book is really solid, would highly recommend it. I just finished the first one.
The OP code is not tail recursive anyway.
A few advices: * don't use multi-dimensional arrays (`int [,]`) as they are much more expensive than jagged arrays, because of bound checking. * try to write an iterative version of your algorithm, to remove the recursion * keep a collection of already visited cells to not go in circle (you might need to roll back in some cases though) Have a look at the A* algorithm.
I'm now stuck trying to implement a part where the user can search for a number from the. txt files via the console. The code i've written just isn't showing in the console for some reason? [https://imgur.com/7PFySXf](https://imgur.com/7PFySXf)
Stuff like that is a crutch. It’s not good to always rely on the tool to do your job. There are cases where the tool can’t handle the requirements, or functions don’t map well, etc
Tail recursion isn’t magic. The loop needs to be written very specifically for the compiler to understand it
Binding Mode=TwoWay ?
Yes. MS SQL developer edition is free.
/u/lets-get-dangerous answer would be the ideal solution. However, if that's not an option the EF Core documentation has a section about [transactions](https://docs.microsoft.com/en-us/ef/core/saving/transactions). You could do something like this in your Controller: using (var transaction = context.Database.BeginTransaction()) { try { serviceA.DoSomething(); // Might call SaveChangesAsync() serviceB.DoSomething(); // Might call SaveChangesAsync() transaction.Commit(); } catch (Exception) { // TODO: Handle failure } } // transaction scope ends here. If Commit() wasn't called, the transaction will be rolled back.
DataTemplates defining what each viewmodel looks like plus an item control to display the list. It's a bit hard to help without knowing what the layout is. OP, can you post some screenshots of the working prototype?
Also don't forget the Express and developer versions which are both free but they come with limitations For developer you can't use it in production And express puts limits on the amount of ram, CPU and total DB size
Sorry, I don't understand your question.
His code is an attempt at depth first search, but is missing the ability to detect if it has already been down that path. Adding a set to the parameters and adding and removing the current node will make it easy to check.
Postgres online practice exercises were a good place for me to go to, when I had to practice queries without installing and setting up the database and tools. Http://www.pgexercises.com
Try documents stores.. bloody SQL becomes a nightmare to manage later. Most things I think of now could have run much better, easier to change models and if you need to do shitty analytics, pull data from document store into SQL db
While I do not like it personally I feel that you are exaggerating.
Yes you can. Store it as a string that's acceptable to Timespan.parse.
Please kill me now. I am a developer. I don't care how the database works. Just like I don't care how the bits are written to NTFS or EXT4. I wish Mongo was more used. It makes lives so much easier for devs
Doesnt mean it should be.. The amount of companies I worked for regret using it and all new project I work with now avoid it as the plague. Why.. It does not scale.. and Cloud SQL costs a fuck ton of money for what really Mongo or Neo4j can do
Until you have developed all the skills in design and architecture that let you write magically perfect code, you're going to need to keep notes on what you have. &amp;#x200B; \*Especially\* in the internal implementation details.
So this is what i have right now, it is a VERY rough proof of concept prototype, in no way shape or form is this a final design, https://imgur.com/a/v7Esn20 The elements I'm dynamically placing are a bit hard to see so I highlighted them, the image and the number and the position of the elements will change regularly. this is what I currently have in my codebehind of this view. I fire an event from the viewmodel to the view with the model as an event message. But I would prefer to have zero code in the code behind and do everything from the viewmodel. Partly because thats good design and partly because this will be maintained by people with minimal to no CS training so anything I can do to make their life easier is a good thing. I hadn't thought of having stylet manage the multiple views so I am looking into that right now. namespace OPCVisualizer.Pages { /// &lt;summary&gt; /// Interaction logic for ShellView.xaml /// &lt;/summary&gt; public partial class ShellView : Window, IHandle&lt;VisualizeEvent&gt; { private IEventAggregator eventAggregator; public ShellView(IEventAggregator eventAggregator) { this.eventAggregator = eventAggregator; this.eventAggregator.Subscribe(this); InitializeComponent(); } public void Handle(VisualizeEvent message) { foreach (var P in message.MimicLoadingModel.P) { Button Pneumatic = new Button(); Canvas.SetLeft(Pneumatic, P.diXCoordinate); Canvas.SetTop(Pneumatic, P.diYCoordinate); Pneumatic.Height = 10; Pneumatic.Width = 10; VisualizeCanvas.Children.Add(Pneumatic); } foreach (var S in message.MimicLoadingModel.S) { Button Sensor = new Button(); Canvas.SetLeft(Sensor, S.diXCoordinate); Canvas.SetTop(Sensor, S.diYCoordinate); Sensor.Height = 10; Sensor.Width = 10; VisualizeCanvas.Children.Add(Sensor); } } } }
Why not bind to a property in the MainWindowViewModel which sets the correct value on the CharacterManager.SelectedCharcter property.
Any statement "X is evil" is exaggerating in this industry, however it cerainly is a design smell.
Where is the database that you actually want updated stored on the machine relative to the code? Also, can you post what your connection string looks like?
If you can remove every instance of it using an automatic rule and have zero affect on the compiled code then it isn't a design issue at all. Whether or not you alphabetized your properties matters infinitely more to the design. (Especially the stupid serializers that require XML attributes to be in the same order.)
Why does the PHP script care how it’s being run?
Wow I hope this is sarcasm.
This question got me curious! Might I ask how the current unit tests are done, if they are not automated? Do you have a suite of tests in a framework x that you run manually, and you need to migrate them to NUnit / Selenium? If yes, which framework are they use at the moment? Thanks!
Honestly I didn't think about that. I use a task runner called Robo which I run from git, but I guess I could run it with cmd. Thanks for replying
You don’t need to run it through cmd. I see people do that all the time. Just run the PHP process and tell it which script to run. No need to waste time running cmd just to run another exe.
Whoa, would that require the string declared at compile time or is this really for converting text to code at runtime?
Thank you. I'm a beginner so just having somewhere to start researching is a big help.
I use this class: `using System;` `using System.Collections.Generic;` `using System.Diagnostics;` `using System.Linq;` `using System.Text;` `using System.Threading.Tasks;` &amp;#x200B; `namespace LinuxCommand` `{` `public static class LinuxCommand` `{` `public static string Bash( this string cmd )` `{` `var escapedArgs = cmd.Replace( "\"", "\\\"" );` &amp;#x200B; `var process = new Process()` `{` `StartInfo = new ProcessStartInfo` `{` `FileName = "/bin/bash",` `Arguments = $"-c \"{escapedArgs}\"",` `RedirectStandardOutput = true,` `UseShellExecute = false,` `CreateNoWindow = true,` `}` `};` `process.Start();` `string result = process.StandardOutput.ReadToEnd();` `process.WaitForExit();` `return result;` `}` `}` `}` Invoke it like so (unmounting a USB drive. Modify for your command): `String eject_cmd = "sudo /bin/umount " + DriveWithZipEsc;` `String result = String.Empty;` `result = eject_cmd.Bash(); // unmount`
Well. How many times have looked at the source code for any SDK. I Use Linq to read form a repo. I don’t care if it’s entity, mongo, files, memory stream. If you want proper queries for SQL then you bring a SQL guy. The amount of times I had to rip out somebodies effort to improve SQL performance exist kills me. SQL requires careful consideration on normalisation, indexing , partitioning. I talking about real company news even at small level. The amount of times I fixed performance issues by not using SQL as a quick win is beyond me. I’m fed up with shitty SQL implementations done by really good devs what turn out to have mediocre SQL knowledge which can be avoided by getting one good SQL guy using ETL’s and much better ways to read and write.
Hey, guys thanks a lot for the help. I have been putting everyone's ideas, pretty fun to see what it does. I'm learning on my own, just got stuck for a good amount of time lol. I tried reading some help on the windows C# learning but couldn't quite understand.
Agreed. You can have a property on the VM that is just a proxy to the other static property. On another note, can INotifyPropertyChanged be used for a static property?
Just add the `async`modifier to the method signature, that won’t interfere with your override.
So I'm looking into this but I'm not sure what I have to run. What I run in git is "robo parallel:run", I have Robo installed globally, but in the installation directory I can't find any exe's. I'm sorry for being noob.
You may consider using [CliWrap](https://github.com/Tyrrrz/CliWrap) for dealing with CLIs. It handles a lot of stuff and some corner cases. Assuming I understood what you were trying to achieve and also that you don't need `git bash` and can instead run `robo` directly: var result = await Cli.Wrap("D:\\Programas\\xampp\\htdocs\\robo2\\robo") .SetArguments("parallel:run") .ExecuteAsync();
I'm fairly certain you could use something like &lt;DataTemplate DataType="{x:Type viewmodel-namespace:IndicatorViewmodel}"&gt; &lt;view-namespace:IndicatorUserControl /&gt; &lt;/DataTemplate&gt; And then &lt;ItemsControl ItemsSource="{Binding IndicatorList}"&gt; &lt;ItemsControl.ItemsPanel&gt; &lt;ItemsPanelTemplate&gt; &lt;Canvas IsItemsHost="True" /&gt; &lt;/ItemsPanelTemplate&gt; &lt;/ItemsControl.ItemsPanel&gt; &lt;/ItemsControl&gt; Where your IndicatorViewmodel has an X and Y on it, while IndicatorList is an ObservableCollection (if you'll be dynamically adding to it at runtime). At least, I think that might get you closer to where you want to be. It's definitely a tricky situation.
Exactly. SQL Server can perform something like a cross or outer apply instantly for complex dashboards, reporting, etc. An ORM would fall over trying to produce a similar dataset. A good developer knows when it's good to use an ORM vs when to leverage raw SQL.
I'll give that a try, thank you so much!
I'm a MSSQL DBA of 15 years. Really, all you need to know as a developer is: * How to write proper SELECT statements * How to write proper INSERT/UPDATE/DELETE statements (and how this differs from running a SELECT) * What the different types of JOINs are (INNER, LEFT/RIGHT OUTER, FULL, CROSS), why you would use each type, and things to be cautious of with JOINs. * How to do all of the above statements, but with JOINs thrown in the mix * A basic understanding of what a "database transaction" is and what the implications and limitations of that are Really, though, if you are using C#/.NET, you should probably figure out, or at least take a look at a thing called "EntityFramework" - It is what is called an "ORM" ([O]bject -&gt; [R]elational db [M]apping) - if you feed it a table design with multiple tables (aka "database schema"), it will likely be able to create you (generate the code for you) some C# classes that relate to the data in your tables (each "class" is one row of data), with each C# object's properties being one of the "fields" in that row of data. Then you just use those C# classes in your code. Easy.
I get what you are saying, but that's a junior developer mentality. To get to the next level you need to be willing to consider all the things that can go wrong with a technology. For example with a file system you can accidentally write a file path that's longer than 255 characters and get yourself into trouble. Or you could accidentally fill up the hard drive or write a file over 4 gb and get yourself into trouble. Or you can accidentally delete or overwrite files because you don't understand the difference between relative and absolute paths. This is nothing compared to what you can accidentally do with a database because you lack an understanding of how it works.
Thanks a lot
Did you just say that SQL doesn't scale and then immediately turn around and recommend Mongo? Oh my...
So it is being stored in the same file as the code, my connection string is &amp;#x200B; "Data Source=(LocalDB)\\\\MSSQLLocalDB;AttachDbFilename=|DataDirectory|Database.mdf;" + "Integrated Security=True";
Fixed performance issues by not using SQL? That doesn't sound right at all.
Knowing which parts of SQL are intensive and which ones aren't, and how databases are built will help with writing code which performs well. How to split your tables, how to prevent common pitfalls, that kind of thing. I haven't done much SQL but that basic knowledge has helped me a lot keeping some LINQ and normal SQL performant and clear.
I’m sure it did when I tried it. I remember I had a reason for not using it asynchronously but can’t remember why. I’ll try later when I get back home.
If you are using C#, I would use Microsoft SQL over MySQL - it just integrates better with .NET.
Postgres is nice and all but MSSQL is easier to work with from .NET than Postgres is. Agree with MySQL leading to bad habits.
I wasn't very familiar with LocalDB so I read this article on stack overflow: [https://stackoverflow.com/questions/12187068/where-is-datadirectory-defined](https://stackoverflow.com/questions/12187068/where-is-datadirectory-defined) . It sounds like you know generally what's going on here but I can't tell if you realize all of the repercussions of those limitations from a design standpoint. Based on the title of this post it sounds like maybe not. &amp;#x200B; Your data is definitely being persisted. If you look at what you've built from the standpoint of a system that has been deployed to Production, your code will have been built once and every time someone runs the application it will be reading data from the database in the bin folder. It will never get rebuilt so the user's data will never be lost. You've built a system that persists data just fine. &amp;#x200B; Your problem as a developer is that when you clean and rebuild the mdf file in your bin folder (which has all of the edits in it since the last build) is getting nuked and replaced. There's nothing about this that's not intended from a technology design standpoint. &amp;#x200B; If, for development, you *actually* want the data in your database to persist between clean/rebuilds you have options. I'm sure there are many ways to go about this but the two ones that stick out to me are as follows. 1. Don't use LocalDB. As the article explains, it is a known limitation that this file exists in a directory that will get overwritten when the solution is rebuilt. You can look into SQL Express so the MDF file lives outside of your application directory. 2. You can probably hack this to work with some form of [pre-build event](https://docs.microsoft.com/en-us/visualstudio/ide/specifying-custom-build-events-in-visual-studio?view=vs-2019). As a general rule though, that's not a great solution as they tend to be finicky.
try number[number.Length-1] = 20;
I think I might have actually come to a very similar solution as you I came up with this &lt;ItemsControl ItemsSource="{Binding Items}"&gt; &lt;ItemsControl.ItemTemplate&gt; &lt;DataTemplate&gt; &lt;ContentControl s:View.Model="{Binding}" VerticalContentAlignment="Stretch" HorizontalContentAlignment="Stretch" IsTabStop="False" /&gt; &lt;/DataTemplate&gt; &lt;/ItemsControl.ItemTemplate&gt; &lt;/ItemsControl&gt; and then i have the shellviewmodel placing sensor views where they need to go. I bound the propoerties of the buttons in the sensor view to properties in the viewmodel which i can then construct in the shellviewmodel.
Yes, for simple concepts. On more complex issues, MySQL is the farthest away from the "other relational db engines" - MSSQL/Postgres/Oracle/DB2 - and it behaves differently than the others under certain scenarios (one mentioned above is CHECK constraints). It can lead to bad database design habits if you initially learn on MySQL and you avoid certain DB features because they don't work / work differently on MySQL.
Remember that since arrays start from 0, the length of the array will always be one higher than the index of its last element. So trying to access array[array.Length] will always give you an error.
As others have said, but just to put it another way - you're effectively trying to access number\[10\]. Array indexing starts from zero, so in an array of length 10, the arrays range from 0...9.
ok but i dont understand when it try to make new array value and the length is 1 so number[number.Length] = 20; should be the same as number[1] = 20;
Thank you for your excellent response, I definitely agree LocalDB is a terrible option and shouldn’t be used but it’s a requirement for the class project, my main problem is that the dataset is pulling from the data in the main file folder not the bin folder so I’m losing the functionality of datasets because even though my crud operations are functioning, they’re updating that bin file not the actual file and the dataset reads from that main file that never gets updated any ideas of how to fix this?
Huh?
For an array, number.Length gives you the number of array indices you allocated. number.Length in your example gives you 10, even though you've only filled number[0].
No, number[number.Length - 1] = 20 is what you want. Array indexes start at 0. The “zeroth” index of an array is the first element.
When you created the array you msde it with a length of 10. This makes whatvis basically an array of length 10 thatis empty. When you do numbers[numbers.Length] = 20 thats the same as trying numbers[10] = 20 not numbers[1] = 20. And like the original comment said, arrays are zero indexed so 0-9
You've instantiated an array with a capacity of 10 so numbers.Length gives you 10 and not 1.
I think you are misunderstanding how the Length property of an array works. In the code you give, your array "number" has a Length of 10, since that is what you declare it as: int[] number = new int[10]; When you declare an array in C# its size is fixed as whatever you declare it as, so in your program, number.Length == 10 and always will. You can access elements number[0] ... number[9] inclusive, but anything higher or lower than that will always be an error. You don't need to write anything into those elements to be able to access them - they are initialised to 0 when you declare the array - and the array neither knows nor cares which elements you have written anything into yourself after declaring it. You will need to keep track of that yourself if that is information you need.
Thanks alot for all the help
Thank you! Saving this as reference
Nice! Yep, same thing except I like to separate out my data templates into a single file so I know what can be shown with a content presenter and what needs declared.
That is exactly what I ended up doing, ty so much I hadn't even considered that for some reason.
Arrays start at zero. Just because you have 10 items in your array doesn't mean you're allowed to access numbers[10]. Your last element in your array is numbers[9], or numbers[numbers.length-1].
Well, the thought process is that the SelectedCharacter is something that is going to be used all over the program, so having it as a static property in the CharacterManager makes it easy to access. Odds are I'll end up just linking it up with a property in the ViewModel.
Yeah that's what I'll probably end up doing. If I could get away with it in XAML then that would be ideal but oh well.
Mode=TwoWay didn't work in my testing :(
Yea I know.. my bad. But IMHO.. it scales better (and cheaper) than SQL - But I also use EventStore so I can spin up new nodes with seperate stores by just replaying history and as long as EventStore is securely backed up everything can burn down and I can just create a new AKS cluster, replay and we are back in business.
Did you try the debugger and step through each line? You know that there is different between comparing integer and string? "8 " is not equal to "8" if both are strings. &amp;#x200B; I would break down your code in to few different methods &amp;#x200B; 1) Method 1 - Read lines from the file and store in integer array -&gt; does line has one integer value or multiple via spaces? 2) Method 2 - take integer array and target array and return matching new array with matching numbers It's a homework so you should try to do few small console apps and put all together at end. :)
Fair enough but it's more or less meaningless as if you read a few words after it says &gt;Despite the existence of such standards, most SQL code is not completely portable among different database systems without adjustments. Hardly a standard in the way people would associate with other languages. You can't take SQL from mysql and use it on SQL server for example.
I get this error: [https://imgur.com/a/Kga4H4p](https://imgur.com/a/Kga4H4p) I need to return base.Update but cannot edit the update method as it is in a library I cannot modify.
I can see where you attempted to do that, but that code never executes.
Why not register it as a Singleton service in a dependency injection container?
Fuck
Use [`Double.TryParse`](https://docs.microsoft.com/en-us/dotnet/api/system.double.tryparse?view=netframework-4.8) instead. With it, it can report whether or not the input was successfully converted to a number without throwing an exception and crashing. Check the examples there.
You're parsing your console input to a double, without making sure it's actually a double. If a non-double is inputted, then the double.Parse line will throw an error. You need to use the TryParse method. Then you'll know if the input is what you're expecting, and if not you can handle it by showing your own error message without crashing the application.
what happens if you do Dimensions\[1\].\*something\*?? Like "Dimensions\[1\].Text" ? or .Value?
You can use the System Diagnosis.Process class. It takes arguments. On my phone so can't post sample code.
Tbh though, i dont understand your original array, or why you have done "string \[\]\[\]Dimensions" namespace ConsoleApp1 { class Program { static void Main(string[] args) { Console.WriteLine(args[1]); } } }
I just looked up what that is! I'll look Into doing this, it seems like it's exactly what I need
Use a loop. the inside put a tryparse or the try block
I think the Nand and Nor logic in the [`LogicalExpressionConverter`](https://github.com/haavamoa/xaml-code-experiences/blob/master/xaml.experiences/resources/converters/logicalexpressionconverter/Resources/Converters/LogicalExpressionConverter.cs) is wrong. Nand should be either `!bools.All(b =&gt; b)` or `bools.Any(b =&gt; !b)`, while Nor should be `bools.All(b =&gt; !b)`, or equivalently `!bools.Any(b =&gt; b)`
This worked. But how do I access the 2d elements in c#? As when I am typing Console.WriteLine(args[5, 0]) it says wrong number of indices inside []; expected 1
https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/arrays/jagged-arrays https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/arrays/multidimensional-arrays
Are you positive about that? That doesn't sound right. DataDirectory is supposed to represent the directory that the exe is in. Usually permissioning is set up so that apps don't by default have access to things outside of their own folder so I'd think it wouldn't be looking to do that either.
Post the full code to the method.
This method is converting my 2d arrays to 1d arrays, so it is not correct
 public override Task&lt;SoftwareComponentDto&gt; Update(SoftwareComponentDto input) { string currenttime = DateTime.Now.ToString("dd/MM/yyyy HH:mm:ss"); string UserId = AbpSession.UserId.ToString(); var currentuser = _userManager.FindByIdAsync(UserId).Result; input.ModifiedOn = currenttime; input.ModifiedBy = currentuser.FullName; input.IsReleased = false; input.ReleasedOn = null; input.ReleasedBy = null; if (input.XMLCode == null) { //Keep XML on Blob } else { string entityId = input.Id.ToString(); string fileid = entityId + AbpSession.TenantId.ToString(); string _filename = fileid + "XMLExport.xml"; XMlWriterService.GenerateSoftwareXMLFile(fileid, input.XMLCode); input.XMLCode = null; } if (input.IsGenerated) { string entityId = input.Id.ToString(); string fileid = entityId + AbpSession.TenantId.ToString(); XMlWriterService.Download(fileid); var pougenerationengine = new GeneratePOUs(_pouRepository, _session, _objectMapper, input.Id); //pougenerationengine.AddChildComponentsFromConfig(); pougenerationengine.AddChildComponentsFromConfig(); XMlWriterService.Delete(fileid); input.GeneratedOn = currenttime; input.GeneratedBy = currentuser.FullName; } else { var pougenerationengine = new GeneratePOUs(_pouRepository, _session, _objectMapper, input.Id); //pougenerationengine.AddChildComponentsFromConfig(); pougenerationengine.DeleteRelatedPOUs(input.Id); input.GeneratedOn = null; input.GeneratedBy = null; } if (input.IsReleased) { input.ReleasedOn = currenttime; input.ReleasedBy = currentuser.FullName; } return base.Update(input); } I am returning base.Update which is the method in the DLL I have referenced. I need to return this as otherwise the entity will not save to the database correctly.
What does Update return? Make that async too if it returns a Task
Update is a method in the ASP Boiler Plate framework. I cannot edit it without decompiling and recompiling the referenced DLLs. All of my app services in my API inherit from the [AsyncCrudAppService](https://aspnetboilerplate.com/api-docs/html/T_Abp_Application_Services_AsyncCrudAppService_4.htm).
Did you add `await` to the call and remove the `.Result`?
The JSON consists of an array containing objects, so you should tell Json.NET to deserialize to an array (or other collection) of objects.
Yeah. The return expression is Task&lt;POUDto&gt; but it must be async Task&lt;POUDTO&gt;. Unfortunately I cannot change this.
Why can’t you add async? That won’t conflict with your inheritance. I’m confused
So I'd just have to change jsonCERecipe CERecipeDataTable = JsonConvert.DeserializeObject&lt;jsonCERecipe&gt;(formSourceText.Lines.ToString()); to jsonCERecipe[] CERecipeDataTable = JsonConvert.DeserializeObject&lt;jsonCERecipe[]&gt;(formSourceText.Lines.ToString()); Or am I too noob to figure this out
I’m returning a method that is in the framework in a DLL I cannot update (it has source protection). The framework is open source so I could compile the DLLs myself but that’s just too much work for little result and time is a huge constraint for me currently.
maybe you could also use JArray.Parse if the root is an array and you want to have some sort of dynamic control over the deserialized object.
Try it and find out
Bloody hell, I can't find a decent source of documentation to explain how to actually use that. Every article I find is written in a way to communicate the information to people who already know what the information is and how to work with it.
No I mean in your Create() method. The error message you showed earlier shouldn’t happen if you mark Create() as async and await the call instead of calling .Result
That’s what I did and I got the error. I’ll check this again later as I may have made a mistake.
ahh, if only my company would spring for ReSharper... or for making better classes :-P but good to know.
Does [this](https://www.newtonsoft.com/json/help/html/ReadMultipleContentWithJsonReader.htm) not work? string json = @"{ 'name': 'Admin' }{ 'name': 'Publisher' }"; IList&lt;Role&gt; roles = new List&lt;Role&gt;(); JsonTextReader reader = new JsonTextReader(new StringReader(json)); reader.SupportMultipleContent = true; while (true) { if (!reader.Read()) { break; } JsonSerializer serializer = new JsonSerializer(); Role role = serializer.Deserialize&lt;Role&gt;(reader); roles.Add(role); } foreach (Role role in roles) { Console.WriteLine(role.Name); } // Admin // Publisher
That doesn't make much sense to me, what with there being no documentation. There is this: https://www.newtonsoft.com/json/help/html/SerializingJSON.htm But that's only for serializing one object. What I want to do, is serialize the entire text, not a single object.
&gt; I packed the 'DbConnection' object with a 'DbTransaction' (if this is not given by the caller) and that really mimics what #LLBLGen is doing That makes sense. Implicit transactions would be used otherwise, which means each insert needs to hit the disk before the next starts.
I have new versions and it is much faster than on this post. There is an additional layer of caching in between.
This a hack, though transaction is really needed on batch operations for ACID.
Doesnae work. &gt;Newtonsoft.Json.JsonReaderException: 'Unexpected character encountered while parsing value: S. Path '', line 0, position 0.'
If you're trying to consume the soap service, you can add a service reference to the project. This will give you classes and methods to use the service.
It's been around for a few years. It primarily tests how fast the materializer (result set to objects) of an ORM. I've found it useful for fixing performance issues in my own ORM.
I'll look into that, thanks
I write ORMs. I've found that most of the crud code can use the same SQL generator. So for me the standard works.
I see you're using labels. It's considered bad practice to use goto/labels in C#. Try to avoid them whenever you can. You should use methods instead.
Here, I've used your needs as an example and built out deserialization using a part of your json file. Then updated the IngredientID and returned it. I'll get you a better write up later, but does this help? https://dotnetfiddle.net/nWw8te
The issue is actually the `TextBox.Lines.ToString()`, the result of which is simply `"System.String[]"`. You're looking for the `TextBox.Text` property instead (or `String.Join()`/`String.Concat()` for when you really need to combine an array of strings into a single string).
[A link on the same page](https://www.newtonsoft.com/json/help/html/SerializingCollections.htm)
If what you're reading in is not technically JSON (lacks a root node), then the important thing is setting the [`SupportMultipleContent`](https://www.newtonsoft.com/json/help/html/P_Newtonsoft_Json_JsonReader_SupportMultipleContent.htm) property to `true` and then reading in the file stream. &amp;nbsp; If you're looking to deserialize a fragment of JSON, see [this sample](https://www.newtonsoft.com/json/help/html/SerializingJSONFragments.htm).
You are right, I’m going to use do while loop.
I don't think it's actually a bug. If you take a look at [DbType's docs](https://docs.microsoft.com/en-us/dotnet/api/system.data.dbtype?view=netframework-4.8), you'll see that DbType.Time has the following comment &gt; A type representing a SQL Server DateTime value. If you want to use a SQL Server time value, use Time.
Have you tested the code? That would fail in insert.
Aye that does help a wee bit. Rather than using an array, I should use a list. That solves the first problem. I should have included a screenshot of the program, to give a better idea of what I'm attempting to create: https://i.imgur.com/rIfQfIY.png The user presses the **Load** button, which loads two text files, one containing the integer values for specific items, and the other containing the name of those items. The names are then loaded into the drop-down boxes, where the user can then select an ID to change to another one. They then paste in the JSON data into the left text box. After that, they then press **Begin**. The JSON data is loaded, with any ID matches in Ingredient1ID, Ingredient2ID, Ingredient3ID, or Ingredient4ID having their value changed. The result is then punted out to the text box in the right, where the user can then copy the modified JSON data to the clipboard. My snag is, after modifying the JSON data, punting it back into text and placing it into the text box. I figured I could use the JsonConvert.Serialize function, but that is for outputting the text to a file. I've been googling hard, and either the results either deal with outputting a single data entry as text, or writing the entire JSON data to a text file.
Aaah, now it works. But there's one problem; the formatting of the text. The resulting JSON text data is void of any indentation. https://i.imgur.com/aLnOSYg.png Is there a way to fix that?
It's not a file stream. Rather, it's JSON text data copied from a data base, which is then put into a text box, has some values changed, and put into another text box that the user can then copy-paste back to the data base.
The three hardest problems in programming are out by one errors and naming things.
I think the dataset issue may have been fixed with a refresh/ load event I didn’t get a chance to try it yet though, thanks for your responses!
Look at the overloads. It provides a way to pass formatting options.
You can't possibly have a json object without a root object even if that root object is an array of objects.... \[{"K1":"V1"}, {"k2"}:{"V2"}\] is a json object with an array as a root object and two json objects with a single key each as the objects in the array. {"K1":"V1"} is a json file with a single key and value it is only a root object. &amp;#x200B; They have returned to you an array of 1 of the objects that you are parsing. So you have to deserialize it into an array of that object. There might always be only a single object in the array... but I don't know for certain b/c that depends on the sending process.
myval points to a string object. so does list0. when you set myval to a new string, you made myval point to a new string object. the behavior you are expecting is that you have modified the original string object, wich you can’t really do. you can store a string as an array of chars instead, then modify that.
First of all, you should avoid List&lt;object&gt; unless you really will be creating a list of arbitrary objects with no other relationship. Based on your short example code, List&lt;string&gt; would be what you want unless that’s not possible. You can’t do what you want directly with strings, since C# strings behave largely like value types in all but name. However what you can do is make a small wrapper class: public class StringWrapper { public string Value { get; set; } } Then make your list be of &lt;StringWrapper&gt;, myVal would be a StringWrapper instance, where you set Value to “HelloWorld.” Editing MyValue.Value will edit in both places like you want simply because you’ve wrapped the string inside of a reference type (the class you made).
In this specific code, no. It's sort of possible with [`ref` locals](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/ref-returns) and arrays (but not lists), but there are limits to where and how those can be used. A simple workaround would be to use a wrapper object: class Foo { public object Value { get; set; } } var MyVal = new Foo { Value = "HelloWorld" }; var objList = new List&lt;Foo&gt;(); objList.Add(MyVal); MyVal.Value = "HelloWorld2"; Console.WriteLine(objList[0].Value);
I don't know the upper limit, but it's at least a few thousand before the editor for the database won't let you copy the rows as JSON data. Here's a copy-paste with a few rows rather than just one: https://pastebin.com/nPq7n3BR You'll see that there's no base object.
Aye, there's Formatting.Indented, and there is a function called Indentation, but I can't find any code that uses it in order to learn how to call it.
SerializeObject has an overload that accepts the formatting as an argument.
HelloWorld2 is a string.... the list is a list... the list will never have the value of a string. The list will contain string values... It's not clear here what you are attempting to do... so it's not really possible to tell you how to do it. &amp;#x200B; Are you trying to keep MyValue equal to the latest value inserted into the list? &amp;#x200B; List&lt;Object&gt; objList =new List&lt;Object&gt;(); void AddItem(String item){ objList.Add(item); return item;} void main(){ String lastVal = AddItem("HelloWorld"); //objList = \[{"HelloWorld"}\] lastVal="HelloWorld" &amp;#x200B; lastVal = AddItem("HelloWorld2"); //objList=\[{"HelloWorld"} {"HelloWorld2"}\] lastVal = "HelloWorld2" } &amp;#x200B; or Static T lastItem&lt;T&gt;(this T lst){ if (lst==null || lst.Count==0) return String.Empty; return lst\[lst.count-1\];} void Main(){ List&lt;Object&gt; objList=new List&lt;Object&gt;(); //lastItem returns "" objList.Add("HelloWorld"); //lastItem returns "HelloWorld" objList.Add("HelloWorld2"); //lastItem returns "HelloWorld2" } &amp;#x200B; Are you trying to modify the value of the string after you inserted it into the list? You can only modify the value of a variable in a list if the variable in the list is a reference type. class MyClass{ String Title{get;set;} } &amp;#x200B; struct MyStruct{ String Title{get;set;} } &amp;#x200B; void main(){ List&lt;MyClass&gt; myClasses=new List&lt;MyClass&gt;(); List&lt;MyStruct&gt; myStruct=new List&lt;MyStruct&gt;(); &amp;#x200B; myClass myC = new myClass(){ Title="Class"}; MyStruct myS = new MyStruct(){Title = "Struct"}; myClasses.Add(myC); myStructs.Add(myS); &amp;#x200B; myC.Title+=" Changed" myS.Title+=" Changed" &amp;#x200B; Console.WriteLine($"{MyClasses\[0\].Title}") // Outputs "Class Changed" Console.WriteLine($"{MyStructs\[0\].Title}") //Outputs "Struct" } &amp;#x200B; I believe (though I have not tested) that c# treats strings as a value type in this scenario...
I looked at the json you provided in the previous post. There is a base object. The base object is an array.
I did but it looks like I didn't spend enough time to understand the problem. There's small discussion on https://stackoverflow.com/questions/41510660/sqlparameter-dbtype-date-sqldbtype-datetime-conversion/49778259#49778259 which seems to indicate it's being done intentionally for backwards compatibility purposes
&gt; [{"K1":"V1"}, {"k2"}:{"V2"}] is a json object with an array as a root object and two json objects with a single key each as the objects in the array. It's a json array, not a "json object with an array as a root object".
&gt; Bloody hell, I can't find a decent source of documentation to explain how to actually use that. https://www.newtonsoft.com/json/help/html/T_Newtonsoft_Json_Linq_JArray.htm
That's not his fault. RawDataAccessBencher is created by Frans Bouma.
It's a great project.
I suppose a Json array is not a Jason object? A Jason object can not have a key with a jason array as a value? Just as an array is a subclass of object a jason array is a subclass of jason object
The documentation there is lacking so much detail it's little more than automatically generated documentation. Compare this: https://www.newtonsoft.com/json/help/html/M_Newtonsoft_Json_Linq_JArray__ctor_2.htm To this: https://geck.bethsoft.com/index.php?title=RefMapArrayGetSize
It's neither a JSON object, nor a jason object. Check the specification: https://www.json.org/
That last MyVal assignment is now a *reference to a new string*. The reference in the list is still the original reference to the first string. see u/musical_bear's note on a wrapper class.
You could do something even lazier and just find the text in the original text file, replace it and save. Haha
Absolutely. Not enough people know SQL, and those who do don't know enough of it. Do yourself the favor.
Oh trust me, I've done that before when I was looking at ASCII 3D models. Rather than spend a month draining the emotional state of the poor sods that know how to program, I just treated it like a big ol' text file and used substrings to find all the values I wanted. But this is a wee bit less intensive, so I wanted to work with JSON properly, and if I decide in another project to parse the text data manually, I'll do that. Probably will tbh.
No they're expecting the string to act like reference types do. But strings don't work like other reference types.
I used to agree with the no codebehind concept, but i now no longer think a codebehind is inherently evil. As long as the codebehind is doing work that is only concerned with the view, then there is a place for it. A recent example from one of my plc HMIs is a page that shows a bunch of part measurements as graphs and also as a table. Occasionally the user wants to look at more rows in the table at onceso we have a grid splitter they can pull to cover some charts temporarily while looking at the table. We also have a button that toggles the position of the splitter between the default position (showing the charts) and the maximum position (all table). This is purely view based so the view model shouldn't know about it. In the original version of it, the viewmodel did have properties for this position and then the splitter was connected with Binding. Sure its purely philosophical, but i found that it let me take things out of my viewmodel that tightly coupled to the view, which i think of as more of a problem than having a view only concern handled by a code behind. It's just down to how yoy define what the viewmodel represents. For me it is not a model of the view. It is a model of the data to be presented by a view.
&gt; I’ve found that **most**... &gt; So for me the standard works. Hmmmm...
I do some things that other ORMs don't such as server side upserts and echoing the inserted/updated row atomically. Stuff that is outside the standard.
&gt; If you can remove every instance of it using an automatic rule and have zero affect on the compiled code then it isn't a design issue at all. I don't really see how this is an argument. If you need to use regions to organize parts of your class, there's a fair chance your class's responsibility isn't well defined. That's the meaning of a "design smell" -- seeing regions in code is more often an indicator of a poorly designed class than not.
Not even that. The string object itself should work as a reference but thats no problem because strings are reference types (or how was that? String is somehow special...) but the assignment operator acting on a string should change it‘s underlying value but not it‘s reference. And this is neither possible with a string nor any other reference type. The assignment operator always changes the reference. You always need the wrapper to separate reference of the object and reference/value of the value of an object.
Yeah good point. Edit: Actually I think you can if you pass a reference type by ref into a method. But I think that's the only way.
When you select something, does your setter in the selected property fire?
Also instead of writing console.writeline(“”); to get a new line. You can write console.write(“\n enter a number”); \n makes a new like when it is in a string. Saves you repeating code
Yeah I'm building a custom IDE which compiles my user's code using Roslyn. My goal here is an object watch list to support debugging without Visual Studio or VSCode. So far it works amazingly well for stepping through code and displaying the initial value of the variables after they are declared but I'm losing the values of locally declared primitive variables after they are changed. This may be more headache than its worth. Breakpoints and code stepping may well be enough but I hoped to see how far I could take it.
True enough. Here's the thing though — every few months, OP comes in and tells us about another new release of RepoDb, and how fast it is, and how much greater than other ORMs it is, and… those threads tend not to go so well.
Because with anonymous names do not have a reputation to protect, so the social mores around civility go out the door. Again, not his problem. I have not really seen any particular comments where the OP comes across brash. (Forgivingly) clueless earlier on, maybe, but that has changed as people have pointed out to him how to improve. My impression is mpendon is the kind of developer I'd want to work with.
 jsonCERecipe CERecipeDataTable = JsonConvert.DeserializeObject&lt;**dynamic**\&gt;(formSourceText.Lines.ToString()) ?
int[] numbers = new int[5] creates an array with 5 elements. Those are: numbers[0] numbers[1] numbers[2] numbers[3] numbers[4] numbers.length will return 5, the number of elements in the array. numbers[numbers.length] is equivalent to numbers[5], which is not on the list above. That's why it doesn't work. You need to use numbers[numbers.length -1] to get the last element
Hi, can you find out what you need to communicate with? WCF supports communication with literally anything, but in its simplest form you can write a client and server in a page of code. &amp;#x200B; Juval Lowry wrote the textbook for WCF. Also, google Dev Essentials. It's a free Microsoft thing which comes with a free (short term) sub to PluralSight. They probably have a WCF course, and certainly have courses on everything else you need.
No, it doesn't. I set a break point in the setter and changed the SelectedValue and it didn't break.
Either Mode=Two way, or UpdatePropertySource=PropertyChanged &amp;#x200B; The only way you can respond back to the property is with the two way binding, If you have two way, does it enter the setter? or what is it that doesn't work?
let me check in a bit, I'm busy moving my things out of my apartment currently. Last time I tried to do a two way binding it threw a strange error IIRC, I don't remember what it said.
Dude, you gotta toss that creepy animation.
Visual Studio Community Edition is free
 Visual Studio Community is free but you must make a Microsoft account and login in Visual studio and activate it (for free). Visual Studio Code is also free but VS community is better for C# development.
Truncate table [tablename]
Thank you!
Use a Drop Table command and then re-create it. You should have the SQL handy for creating before you delete the table, which you can use SQL or VS to get.
Your safest bet is with truncate table. An alternative is to alter the table and set the auto-increment to 1.
Yeah. I know that re-assigning the value creates a new string in memory and the address of the variable is completely different. I'm hoping someone with more knowledge than I (without changing data types) can advise me on how or if this is possible. I'm looking into using the UNSAFE keyword and seeing if maybe I can figure something out with that.
I will add my two cents since I just watched an entire Build conference, and for the first time I feel old and obsolete. &amp;#x200B; C# / SQL are my primary (and sad face, only skills? I am learning animation since Reddit hates me when I advertise open source projects,, due to guberment control that hates open source because the taxable income on open source is not very high). SQL is the best backend data source, unless you have so much data that you have more data than earth has particles like guberments, or the handful of companies that control Reddit, and every other technology company by dangling this type of money called Billions, that all developers will sell out too, and their only requirement is to down vote open source projects, because open source projects can't be taxed, and this hurts their bottom line. &amp;#x200B; Reddit moderators want to control everything you see, and if a great open source tool like DataTier.Net comes along, and they can't tax it, they will call me a spammer just like I was selling flip phones or aluminium siding (full disclosure without spell check I couldn't spell tin foil, so some tech is ok as long as Freedom of Speech, a right that many a greater man than I am have died protecting is not infringed upon). Let the people of Reddit decide without down voting blindly which I have seen proof my own almost blind eyes. A 20 minute minutes gets down votes 4 minutes after uploading due to tools from the 23rd century (ask John titor if you known when he is now). &amp;#x200B; Jed Clampett was distracted by a new kind of money called Millions, and that worked in the 60's, but in the 2100+ it takes billions to make good hearted developers sell out to the bankers and the powers that be. &amp;#x200B; But to answer your question, yes SQL is the way to go. The question you have to ask after that is do you want to be like everyone else, and be able to get a high paying job using Entity Framework? Or are you an adventurer type, that knows that an all stored procedure driven data tier, that you the superior human instructs which ones to call and where, and most importantly when and what? Or are you going to just take your paycheck like everyone else (and me at my day job) and use Entity Framework because Microsoft recommends you do so? These are the same people that hide file types because they thing we are all stupid. &amp;#x200B; If you are not distracted by capitalistic ways, and you know that the best code is what really matters, then DataTier.Net will be like Yoda was to Luke. &amp;#x200B; DataTier.Net (Be afraid not you, as Yoda himself would guide you). [https://github.com/DataJuggler/SharedRepo](https://github.com/DataJuggler/SharedRepo)
No dave... Just no.
TIL: It resets the auto increment seed as well.
Well that’s what I assumed OP meant by “primary key”.
Thank you for hurting my feelings, when all I was trying to was give away free code. &amp;#x200B; I am sorry you don't like the character. I am a programmer not an animator. He is supposed to look creepy I guess. &amp;#x200B; His name is Codey. Get It? Codey. My name is Corby, that is my alter ego in animated form. It was just a way to hopefully make Google not hide all my stuff since I watched an Alex Jones video once. OK, twice. &amp;#x200B; Now they put in some alt right non conformist wears a Klan outfit for entertainment category. Or I am just boring, but the code is what I am trying to give away (not sell). &amp;#x200B; Thanks for your suggestion, if I were more interesting myself I wouldn't try 3D Animation.
Do a Google search on reset identity
This may be an instance of [the x y problem] (https://en.m.wikipedia.org/wiki/XY_problem). why do you need to hold on to the reference to a reference? what actual problem are you needing to solve?
You can bind the DataSource to an ObservableCollection of Type x and bind SelectedItem to a property of type x. There are lots of examples with code. Just google.
Okay awesome, thanks for the reply. Right now I'm looking just at a simple client-server so I can get a feel for the framework, but eventually I'll need to do communication between multiple services. I also might need to tap into MSMQ so I can troubleshoot other applications utilizing MSMQ
Visual Studio Community or Rider EAP (Early access program), (yes eap is free)
Why do you care? The Id should never mean anything special to your application. If you're relying on your ID's to have a special meaning or business purpose, you're doing it wrong!
Yeah, dude, I'm sorry. But I'm giving you feedback in a lighthearted way. Your humor just didn't land. If you're not up for the jokes about your animation, then don't put the animation in there. It's not the focus and it makes your project seem like a low-budget thing someone churned out in their weekend. You made something that competes with Entity Framework. You're a 1-man show. You're NEVER EVER EVER EVER going to be able to compete with EF as a solo developer. But you want to give this to other people? So their projects are limited by whatever you don't have the time to implement? Like, I get building something cool, but you should open with _WHY_ you're building it when an obvious solution that's supported by msft exists. Also, you need to see a therapist. Right away.
Because Im doing an assignment and that is part of the requirements to use the primary key in a specific way. Its not great but then neither is having to learn windows forms at this point and yet here I am.
Read this tutorial, and I guarantee that you will have sufficient knowledge to solve your problem :) [https://www.tutorialspoint.com/mvvm/index.htm](https://www.tutorialspoint.com/mvvm/index.htm) If you have any specific questions after giving it a go, I'd be happy to help! Just PM me.
Please note that WCF is legacy technology. Only use it if it's already in use in your software. Not for new projects. The current technology is ASP.NET Core Web API.
Use WPF data binding. Create a Model (class) called Team.cs or something similar. Give it a Name, Time, and Score property. Bind these properties to columns in your table. &amp;#x200B; A good resource that will get you on the right path: [https://www.tutorialspoint.com/mvvm/index.htm](https://www.tutorialspoint.com/mvvm/index.htm) Specifically, the WPF data binding part will help you with attaching your list to the table.
i don't think they all it Web Api anymore, do they? it's just *a* web api.
can, and is. it's everywhere. learn it, you'll want it.
still would be an interesting datapoint.
You should probably be using a [Datagrid](https://docs.microsoft.com/en-us/dotnet/api/system.windows.controls.datagrid?redirectedfrom=MSDN&amp;view=netframework-4.8), unless you have some special use-case?
otherwise known as recursive backtracking. op look that up.
*Well*... if you're willing to move into unsafe territory and beyond there are ways, e.g. the `System.CompilerServices.Unsafe` package: public unsafe struct UnsafeLocalRef { private readonly void* _ptr; private readonly ReadValueDelegate _delegate; public object CurrentValue =&gt; _delegate(_ptr); private UnsafeLocalRef(void* ptr, ReadValueDelegate readDelegate) { _ptr = ptr; _delegate = readDelegate; } public static UnsafeLocalRef Create&lt;T&gt;(ref T local) { return new UnsafeLocalRef(Unsafe.AsPointer(ref local), ptr =&gt; Unsafe.Read&lt;T&gt;(ptr)); } private delegate object ReadValueDelegate(void* ptr); } void Foo() { int a = 0; string b = null; var ra = UnsafeLocalRef.Create(ref a); var rb = UnsafeLocalRef.Create(ref b); a = 1; b = "abc"; Console.WriteLine(ra.CurrentValue); Console.WriteLine(rb.CurrentValue); } That'll probably work. Definitely not really something I'd actually want to rely on, though. Also, locals lifted into closures need to be treated differently, since the closure instances can be moved by the GC which invalidates the pointers.
THIS IS BRILLIANT. Thank you so much Kind Stranger.
 public static double GetDouble(string msg) { AskForInput(msg); double d; while (!double.TryParse(Console.ReadLine(), out d)) { InvalidFormatError(); AskForInput(msg); } return d; }
 public static double GetDouble(string msg) { Console.Write(msg); double d; while (!double.TryParse(Console.ReadLine(), out d)) { Console.ForegroundColor = ConsoleColor.Red; Console.WriteLine("Invalid input."); Console.ResetColor(); Console.Write(msg); } return d; }
I saw they might even be dropping it with .net 5, if I understood the blog post correctly.
For sql server you don't have to truncate the table (though it is the easiest option). There's and alter you can perform that reseeds the identity column.
Not exactly dropping it. .NET 5 is essentially .NET Core 4. .NET Core already doesn't support WCF so it will effectively continue to not support it.
Alright so there's several comments already about how to do this but it's important for you to understand why this didn't work so I'll try to explain that. When you declare a variable, the compiler basically says "I need to make room in memory to store this value in". So `MyVal` gets a particular piece of memory, and in that memory is stored a reference to the string `"HelloWorld"`. Let's say that `MyVal`'s address is 0x42 and the string it points to is 0x52. When you do objList.Add(MyVal), what is stored in the list is the value stored in MyVal, not MyVal itself. The value stored in MyVal is `0x52`, the pointer to the string `"HelloWorld"`. Then you do `MyVal="HelloWorld2"`. `MyVal` still has the address `0x42`, and let's say that `"HelloWorld2"` is at 0x62`. So previously we had 0x42:0x52, now we have 0x42:0x62. But what we stored in the list was `0x52`, which is complete unaffected by the assignment `=`. The list still holds `0x52`, which still points to `"HelloWorld"`.
Could you explain your questions little further? I’ve used IS4 before (and am currently), however probably not in a “complex” situation
For those, like me, who does not know what an STS is, it appears they are referring to this: https://en.wikipedia.org/wiki/Security_token_service /u/hhjhjkhjkl can you please add a link to an explanation when using an acronym in the future? Not everyone knows all the jargon, so may help you perhaps get better answers when requesting help in the future. As for your question, you may also want to look into a hosted service like Auth0 (disclaimer: I worked for them before) or Okta. Many customers use both these with success every day. Both have quickstarts that demonstrate how to use it across different platforms.
There's nothing wrong with learning windows forms. Still billions of lines of code out there for it.
Try implementing INotifyPropertyChanged interface
Adding the service as a service reference was mentioned, but you could also use svcutil.exe instead to generate a web service proxy. The benefit of this approach is you have more control how the proxy is generated. https://docs.microsoft.com/en-us/dotnet/framework/wcf/servicemodel-metadata-utility-tool-svcutil-exe
If I remember right, WCF uses classes internally and formats them into XML under the hood with no code from your side to influence the formatting. The formatting is defined by the classes and attributes on classes and properties. &amp;#x200B; One "trick" is to copy the contents of an example XML file and paste it in Visual Studio into a .cs file using "Paste Special" / "Xml as Classes". This generates them (including some attributes ) that should give you an ok starting point how the classes should look like.
Hi, I would recommend you 2 platforms, Strata Scratch and Datacamp! Datacamp provides video tutorials &amp; coding challenges on R, Python and Statistics, but expensive. And Stratascratch provides the exercises with the questions come from technical interviews taken from companies so all the questions are relevant to working on a job. I found it really helpful when I was practicing for my SQL interviews.
We're currently using IdentityServer4 to secure multiple single page apps, several different apis, and a few cookie based traditional web apps. It's been nice to rely on it to do the heavy lifting. We have been using strictly the open source project (nuget packages) and have talked about springing for the paid for administration module. It would probably make our life easier. In fact we've definitely spent over $10k worth of developer time getting everything configured and the various updates to the application over time as we spin up new apis, grants, or clients. &amp;#x200B; I should also mention we our previous auth system still holds account information and while our IdentityServer4 handles the authentication. Behind the scenes it still does credential checks against our old system.
I believe vid/pid is device type specific. If you want to work on my with this type of USB device you can get vid and pid from device manager (see drivers info). Though I will assume there might be much easier way 😅
this might help [https://www.newtonsoft.com/json/help/html/P\_Newtonsoft\_Json\_JsonReader\_SupportMultipleContent.htm](https://www.newtonsoft.com/json/help/html/P_Newtonsoft_Json_JsonReader_SupportMultipleContent.htm)
I now got the answer, seems it is known already and for compatibility (as you mentioned). But seriously, it is failing. In anyway, I asked them to close this one if they think it is not necesarry, or if they prefer the developers to always do the work-around.
We use IDS4 for federated login with azure AD. Works great. Definitely a learning curve if you’re new to Oauth2. There is no one size fits all for complex scenarios, so not sure if you’re looking for anything other than “we use it, and it works!”
Firstly, I am not an actor nor popular for you (many) to follow. I used this thread as a start point of showcase of my creation. My promise to everybody who “directly” knows me is efficiency and performance, and to convince them why “this” thing over the other. Because I can leverage the thing of being the “lightweight” with much more to offer. There may be some 2 more posts moving forward and I am done with it, no more updates on this sub-reddit group regarding this project. I just swallow all that downvotes, as that is the people (“developers”) reaction into it. But I am happy that still I was managed to bring that to the top. And again, this will NOT be approved on PR on this bencher, because I am lightweight-ORM and they are full-ORM. And that is a fair thing in my view point. :)
&gt; Self-contained is just that - "self-contained" - 1 file. No, not in this context it doesn't. "Self-contained" in this context means a build of a .Net application that includes the .Net Core runtime in its build output and deployment folder.
I'm not sure if there is something in the BCL to do this, but you can certainly do it with pinvoke https://docs.microsoft.com/en-us/windows-hardware/drivers/install/enumerating-installed-device-interface-classes
**No.** Just don't.
Did you take a look at his example file? He does not have multiple content, he just has an array at root instead of an object.
Wow, that's a huge task for someone struggling with the basics. Good luck!
Bulk 0.1 MS (20000 rows), whereas iteration take 2-3 secs. I am stressing this, bulk is not batch (it ignore something behind the scene), I know that since it is one of common operation in Data Access and it is also my feature. And again, there is “NO” point of including that, it is a “DIFFERENT” thing. IMHO
If you made the fastest C# ORM in the world wouldn't you be proud? And once every few months isn't all that often.
&gt; If you made the fastest C# ORM in the world wouldn’t you be proud? I would. &gt; it takes time to learn how to talk about your work without sounding like an ass. (A skill I admittedly am still working on.) We all are! Which is kind of my point. OP makes posts that are controversial (in reddit terms, i.e. mixture of upvotes and downvotes), and should try to read the room a little more, but also not feel discouraged. I don’t personally need yet another ORM, but it’s great to have options, and cool to have a little pet project.
&gt; I am not posting other things except RepoDb only, because I do not have interest and intention to talk except for this. That is why all my post are related to this. I think you should reconsider this part. Engage with other folks‘ stuff. Lots of cool things happening. Blazor, for instance.
Can you explain the "why should i use this?" and then the "why like this?". Listen i dont want to mock you but this looks like it took many many hours with a questionable result.
I am very active even in most meetups, but NOT if to refer into this group, just so you would understand. My interest here are only for RepoDb. I can be active if I want to, but is just a bit busy (and RepoDb is eating most of my time after work). After the core features of this library, then I will be very active then.
What flow do you use for your SPA apps? Authorization code with PKCE or Implicit?
I use identify server 3. I love it. We have around 20k users that log in with Facebook, twitter , and local accounts and authorize to around 5 other apps. I'd upgrade to 4 but we run with less than one full time developer.
Assuming you want to edit values in ui: List as I can remember wasn't really meant for editing entries by default, so unless you absolutely have to to use list, I'll suggest datagrid. In case you need a list, you will need to overwrite default templates, so that you can set the values. General : To add value Best approach will be binding the collection to the list or datagrid and notify when it needs to update it.
Authorisation code with PKCE
Not allowed. You can only use an alias if you specify all of the type parameters. My recommendation is to create a subclass instead.
This is the space that is hard to penetrate as people used into it already (even in the IT world). But on my side, it is all about improving the wheel, my future blog would explain why this thing exists.
We are using Azure AD B2C which is Microsofts STP service. It was a bit hard in the beginning tobget behind everything due to messy documentation but its getting better. Overall I would recommend it.
That's a shame that C# doesn't support this considering how trivial and useful it is. Oh well, thanks for the info!
 public static bool IsNull(params object[] objs) { foreach (var t in objs) { if (t == null) return true; } return false; } If you want to avoid the allocation of the array then ye you can fallback to hand written
This is the way to go.
I second this. If we knew the end goal we might have a whole other solution entirely that works better
Why don't you create a type deriving from Dictionary&lt;Range&lt;TKey&gt;, TValue&gt;?
Like this? https://github.com/qmlnet/qmlnet
What would be the use case for something like that? Using QT libs in .NET Core?
Mostly just lazy developers, who don’t want to get their hands dirty in C++, just like there is PyQt
Yeah exactly this. Now I don’t have cool ideas anymore haha
Theres possibility that in the future ill have to add some eyecandy (like a design between the entries separating them). I think that datagrid might limit that possibility
No worries. If you can avoid using MSMQ do. It works, but it has weird issues. Things like, you can lose ownership of a queue in some situations and this completely stops everything. RabbitMQ is free and gives you a lot of reliable flexibility.
Bind JUCE framework instead, it is pretty cool in terms of desktop development.
But you need to sign in after 30 days, which he likely meant. So it's free as in "no money", but you pay with your data.
.OrderBy(x =&gt; x. Name).ToList();
I don't think what you're passing in as arguments is of any use to C#
Have an array containing your answers, then just use `IndexOf` to find the index of a specific answer. Bonus is that you can use it for your filtering as well.
Generate a descendant class ``` public class RangeDictionary&lt;T, U&gt; : Dictionary&lt;Range&lt;T&gt;, U&gt; { } ```
The question's targeted at people who have had to implement some sort of identity scenario in the past. Anyone who's done that knows what an STS is, just as they will also know what SAML is, or OAuth, or what an IdP is.
I didnt quite understood what you want. So you want to have input keys for different actions, but evertime an input key is pressed you want the key needed to be pressed randomly changed?
Added code completion to my T4Editor project/extension. Still working on this, but already pretty statisfied with the results! &amp;#x200B; [https://marketplace.visualstudio.com/items?itemName=TimMaes.t4editor](https://marketplace.visualstudio.com/items?itemName=TimMaes.t4editor) [https://github.com/Epsilekt/T4Editor](https://github.com/Epsilekt/T4Editor)
It seems a pretty logical inclusion indeed - it seems a natural extension. Though I imagine this does deviate from the original intention of the `using` aliasing feature. If I recall correctly, it was originally meant to prevent namespace and class name ambiguity. The new intention and scope of aliases like this would have to be defined pretty clearly, I think. What's nice about your suggested feature is that it doesn't really create a new ambiguous situation, where you alias a class to an already existing class. This is already a possible situation with the current aliasing, and shouldn't complicate things.
`truncate` comes with heavy restrictions, most notable being the target table can't be FK target. Situation might be different on different SQL engines. https://docs.microsoft.com/en-us/sql/t-sql/statements/truncate-table-transact-sql?view=sql-server-2017
auth0. Still a bit of config to get to grips with but the docs are pretty good now and generally it was one of the least painful parts of that project.
&gt; of an array wor is there then a command that you can use to see how many values there are indside an array?
Yes, pretty much. Here's an example: https://www.kidztype.com/typing-pilot_b4c792ebe.html
IIRC, there is an overload of select that accepts an expression with an index and value input - i.e `.Select((index, value) =&gt; $”{index}. {value}”)`
Lets see. First string array with all keycodes you want is needed. Then you need a string for each action of your game. Put the action strings into the if conditions representing them. At last you need to assign a random string of your array to the action strings on initialisation and every time you have done an action to a single action string. You can easily get a random value by using Random.range(0, array.length). If you need further derail feel free to ask.
You could have 2 variables of type KeyCode for leftInputKey and rightInputKey in your script. Then replace the first code snippet in your post with this: if (Input.GetKeyDown(leftInputKey)) { MoveLane(false); // TODO: Set leftInputKey to some random KeyCode. } if (Input.GetKeyDown(rightInputKey)) { MoveLane(true); // TODO: Set rightInputKey to some random KeyCode. } Then you just need to set the leftInputKey and rightInputKey to something random. It would be best to create an array of all the keys you want, in Awake/Start, because truly random would probably give you unexpected keys. You can find other threads explaining how to get random values from an array without repetition.
Yep. Supposing you have an answers list of ordered acceptable answers, I might even do `answers.Where(config.Questions.Contains)`
Sudoku should be easy to make, provided you know/find an algorithm for providing the initial board layout. Also a good opportunity to write a sudoku solving algorithm.
I will look into that!
Yeah exactly this. Now I don’t have cool ideas anymore haha
To iterate on the idea, if you can target `netcoreapp2.1` (I think) or higher, you can do it with spans (no need for `S.R.CS.U` / `unsafe`), **and** you can return the original ref so that you can update the local variable through `CurrentValue` as well: using System; using System.Runtime.InteropServices; public static class LocalRef { public static LocalRef&lt;T&gt; Create&lt;T&gt;(ref T local) =&gt; new LocalRef&lt;T&gt;(ref local); } public readonly ref struct LocalRef&lt;T&gt; { private readonly Span&lt;T&gt; _span; public LocalRef(ref T local) =&gt; _span = MemoryMarshal.CreateSpan(ref local, 1); public ref T CurrentValue =&gt; ref MemoryMarshal.GetReference(_span); } public static class Program { public static void Main() { int a = 0; string b = null; var ra = LocalRef.Create(ref a); var rb = LocalRef.Create(ref b); a = 1; b = "abc"; Console.WriteLine(ra.CurrentValue); Console.WriteLine(rb.CurrentValue); ra.CurrentValue = 123; rb.CurrentValue = "def"; Console.WriteLine(a); Console.WriteLine(b); } }
I just thought if you could use a command that could take value of how many values there are inside of a array for example; int[] number = {1, 3, 6, 9}; and then the command will say four beacuse there are 4 values in the array
Using number.Length will return the size of your array, which in this case is 10. What you would need to do is iterate through the array and keep a count of the values. Since you have only assigned values to four of the items, the rest will be 0 by default because that is the default value of an integer. This should do the trick: var count = 0; foreach (var item in number) { if (item &gt; 0) { count++; } } Console.WriteLine($"The number of items in the array is: {count}"); Console.ReadKey();
I think you can make it more straightforward, add writability, and make it work on architectures that don't fix up unaligned reads / writes for you automatically, without any loss of what little generality there is. I also wouldn't use it in an application that I cared about: using System; using System.Runtime.CompilerServices; public static class UnsafeLocalRef { public static UnsafeLocalRef&lt;T&gt; Create&lt;T&gt;(ref T local) =&gt; new UnsafeLocalRef&lt;T&gt;(ref local); } public unsafe sealed class UnsafeLocalRef&lt;T&gt; { private readonly void* _ptr; public unsafe UnsafeLocalRef(ref T local) =&gt; _ptr = Unsafe.AsPointer(ref local); public T CurrentValue { get =&gt; Unsafe.ReadUnaligned&lt;T&gt;(_ptr); set =&gt; Unsafe.WriteUnaligned(_ptr, value); } } public static class Program { public static void Main() { int a = 0; string b = null; var ra = UnsafeLocalRef.Create(ref a); var rb = UnsafeLocalRef.Create(ref b); a = 1; b = "abc"; Console.WriteLine(ra.CurrentValue); Console.WriteLine(rb.CurrentValue); ra.CurrentValue = 123; rb.CurrentValue = "def"; Console.WriteLine(a); Console.WriteLine(b); } }
Creating a new type requires redefining the constructors and has other implications
Since this is only meant to be used for locals on the stack, they should always be aligned as required by the architecture. The loss of strong typing can indeed be avoided and actually makes the code simpler, I just added the boxing so references to different types could be stored in a list together similar to what the OP showed.
Bit late but this is the main reasin why i ve never typed a single git command. Maybe for the worse but served me well so far.
I'm sorry, but why? The console is beautiful. Why would you want to just a console in WPF? It's not a very good fit, imo.
What are the downsides to thread.sleep that this prevents?
I know quite a decent bit about OAuth, JWT, IdentityServer and creating auth implementations in .NET but I've never heard about STS before. Most of the people that view a thread like this are not coming here to answer the OPs question, but to see the discussion to learn and partake in the parts they understand. I think asking OP to clarify a term isn't unreasonable. It opens more the question easier to address for people with partial knowledge and clarifies, because security token service isn't even the only software security related interpretation of STS (it could also mean Station to Station protocol, or Strict Transport Security).
Take a look at Task.Delay(x)
Any reason not to just throw something in an async method and await Task.Delay instead?
As I understand it Application.DoEvents() gives your UI elements a chance to do queued background tasks like painting and the like. Thread.Sleep() makes your application unresponsive.
For educational purposes
Like I said, I worked for Auth0 for many years. For many years I was the maintainer of the [OWIN OAuth Providers repository](https://developers.google.com/docs/api/reference/rest/v1/EmbeddedObject#imageproperties) and I also implemented some of the providers in the newer [AspNet.Security.OAuth.Providers](https://github.com/aspnet-contrib/AspNet.Security.OAuth.Providers). I very much know what OAuth, SAML and an IdP is. But I have never heard the term STS used before. So, given that, I am very much a person "who have had to implement some sort of identity scenario in the past". So it appears the question is aimed at me. Being able to communicate clearly helps you get questions answered more easily. Refraining from using unnecessary jargon, or clarifying what it is when using it, will only help get better answers. Not only that, others viewing the question and answers can learn more about these things.
To the down voters of my post, good luck with your If something.Id == 6 then this else that code!
Excuse me, but I'm having some real trouble with the code. I'm not a programmer so I struggle a bit with the syntax. I declared this at the top of my script: private KeyCode leftInputKey = KeyCode.A; private KeyCode rightInputKey = KeyCode.B; Is this what you mean by "2 variables of type KeyCode" Then I made an array in Start() with my inputs: string[] inputs = new string[26]; inputs[0] = "KeyCode.A"; inputs[1] = "KeyCode.B"; inputs[2] = "KeyCode.C"; inputs[3] = "KeyCode.D"; inputs[4] = "KeyCode.E"; inputs[5] = "KeyCode.F"; inputs[6] = "KeyCode.G"; inputs[7] = "KeyCode.H"; inputs[8] = "KeyCode.I"; inputs[9] = "KeyCode.J"; inputs[10] = "KeyCode.K"; inputs[11] = "KeyCode.L"; inputs[12] = "KeyCode.M"; inputs[13] = "KeyCode.N"; inputs[14] = "KeyCode.O"; inputs[15] = "KeyCode.P"; inputs[16] = "KeyCode.Q"; inputs[17] = "KeyCode.R"; inputs[18] = "KeyCode.S"; inputs[19] = "KeyCode.T"; inputs[20] = "KeyCode.U"; inputs[21] = "KeyCode.V"; inputs[22] = "KeyCode.W"; inputs[23] = "KeyCode.X"; inputs[24] = "KeyCode.Y"; inputs[25] = "KeyCode.Z"; Then I don't know what to do when I need to replace the TODO-comment line with setting a new KeyCode from the array. I really don't know how to set a new should I use a { get; set; }? or something like Random rand = new Random(); string index = rand.ToString(inputs.Length); (obviously this give an error) leftInputKey = rand.Next(inputs.Length); Please don't laugh lmao. Thank you
Removed: Rule 3.
Removed: Rule 4. Grab Visual Studio Community 2017: http://www.visualstudio.com/products/visual-studio-community-vs You do need to make a Microsoft account, but there's no charge and you don't have to purchase a license.
Thank you. I'm a complete beginner when it comes to this, struggling a bit. Is this what you mean with an String Array: string[] inputs = new string[26]; inputs[0] = "KeyCode.A"; inputs[1] = "KeyCode.B"; inputs[2] = "KeyCode.C"; inputs[3] = "KeyCode.D"; inputs[4] = "KeyCode.E"; inputs[5] = "KeyCode.F"; inputs[6] = "KeyCode.G"; inputs[7] = "KeyCode.H"; inputs[8] = "KeyCode.I"; inputs[9] = "KeyCode.J"; inputs[10] = "KeyCode.K"; inputs[11] = "KeyCode.L"; inputs[12] = "KeyCode.M"; inputs[13] = "KeyCode.N"; inputs[14] = "KeyCode.O"; inputs[15] = "KeyCode.P"; inputs[16] = "KeyCode.Q"; inputs[17] = "KeyCode.R"; inputs[18] = "KeyCode.S"; inputs[19] = "KeyCode.T"; inputs[20] = "KeyCode.U"; inputs[21] = "KeyCode.V"; inputs[22] = "KeyCode.W"; inputs[23] = "KeyCode.X"; inputs[24] = "KeyCode.Y"; inputs[25] = "KeyCode.Z"; Do I then have to declare right, left, jump and duck with strings in the beggning of my script? Like private KeyCode leftInputKey = KeyCode.A; private KeyCode rightInputKey = KeyCode.B; private KeyCode upInputKey = KeyCode.C; private KeyCode downInputKey = KeyCode.D; Or with actual strings something like private string leftInputKey = KeyCode.A; private string rightInputKey = KeyCode.B; private string upInputKey = KeyCode.C; private string downInputKey = KeyCode.D;
Two properties, One for the "ItemsSource" and one for the Selected Item One way binding for the item source, and two way for the selected item.
&gt;lol i knew i'd get a response like this, but hey dynamic is there for a reason right?
Yeah, it's for interop with dynamic languages, not for lazyness.
Truth.
I think this is pretty neat! Using the object-oriented nature of PS to create context menus for those objects etc. is a cool idea
Why *not?* Suppose I want to embed a console in my WPF application, similar to the way Visual Studio exposes the Nuget Package Manager Console. A console control like this would be very helpful, especially if you have a library of Powershell cmdlets you want to expose.
Sorry just looked into documentation. The array should also be from type keycode and you can remove the quotation marks. Then you can go with the Keycode action you made *private KeyCode action.....
You're much closer to the answer than you think! The `leftInputKey` and `rightInputKey` is 100% correct. The `inputs array` you'll want to have as `KeyCode[]`, `not string[]`. The `Input.GetKeyDown` method can accept both types, but using the `KeyCode` enum is more foolproof, since you can't accidentally have typos. A little trick with creating arrays, you can do it this way too: private KeyCode[] inputs = new KeyCode[] { KeyCode.A, KeyCode.B, KeyCode.C, etc... }; That way, you don't have to mess with the index numbers or define the array length! &amp;#x200B; I'm not sure where you are creating this array, but it's best to do it just once, instead of in Update, because you only need to create it once instead of every frame. So create a `private KeyCode[] inputs`, just like `leftInputKey` and `rightInputKey` and you can fill it up in the same place as you define it. I've already done that in the code snippet above. &amp;#x200B; For getting a new random key, you could create a method like this: private KeyCode GetNewRandomKey(KeyCode excludeKey) { KeyCode newRandomKeyCode; do { newRandomKeyCode = inputs[Random.Range(0, inputs.Length)]; } while (newRandomKeyCode == excludeKey); return newRandomKeyCode; } Then call this method where the `// TODO` comment is, like this: if (Input.GetKeyDown(leftInputKey)) { MoveLane(false); leftInputKey = GetNewRandomKey(leftInputKey); } if (Input.GetKeyDown(rightInputKey)) { MoveLane(true); rightInputKey = GetNewRandomKey(rightInputKey); } &amp;#x200B; What the `GetNewRandomKey` method does is it uses `Random.Range` to get a random index between 0 and the length of the `inputs` array and then checks if this random key is the same as the last key. If it is the same, it loops again to get a new random key. Otherwise it returns the new random key.
Isnt this a busy waiting loop??? its gonna be eating up CPU cycles, where sleep will tell windows (etc) to not re-active the thread until the time has elapsed. To be critical, if you want to do it this way (and not with await / async like another poster suggested, which is the 'correct' way), i would at least reduce WaitSec to WaitMilliSec(secs\*1000);
You can make [custom styles](https://docs.microsoft.com/en-us/dotnet/framework/wpf/controls/styling-and-templating) for any xaml object and modify it's properties.
&gt;Since this is only meant to be used for locals on the stack, they should always be aligned as required by the architecture. I was thinking about fields of a struct-typed local variable when I made the comment about alignment, though it's largely academic since this is such a bad idea to begin with :-)
This is why you don't do work on the UI Thread.
This code is indicative of a poor design elsewhere in your system. What are you actually trying to solve?
I see your point about the NuGet Package Manager Console, but that's a double-edged sword: they could have just delivered it using PowerShell directly, instead of building their own hosting component. The intellisense is actually different, and less featured than what PowerShell users would normally get with PSReadLine. Now, granted, the intellisense is *better* than what PowerShell users had available to them at the time that component was introduced, but it's actually less featured now. Another alternative use-case is what Azure is doing with their cloud shell. That's also a compelling argument, but it's also a bit different. In that case, your only alternative is to host a VM and use SSH or something similar, and with the cloud shell (or whatever it's called), Microsoft can manage containerizing and packaging something a shell that's compatible with your environment. Which brings me back to my original point: I don't think this is a good fit, because you actually *remove* functionality from the hands of users by trying to do this yourself. From a UX perspective, I think it makes more sense to just provide an "Open PowerShell" option, than trying to host a shell in either WinForms or WPF, because you're targeting the Windows Desktop anyway.
&gt;Edit: someone posted a strongly typed by-ref version using spans, but I can't see the comment right now. Not sure if it's deleted or due to the reddit CDN issues. That was me. I posted it before realizing that it wouldn't even kinda-partially work with `List&lt;T&gt;` under any circumstances, which is what OP is doing, so I deleted it.
Honestly, you're a saint. It really works, and you explained it so good I understand what I'm doing. Thank you very much, you have my eternal gratitude
Or just learn how to use Timers / multithreading / async&amp;await / old BeginXXX-EndXXX or even Callbacks &amp;#x200B; Application.DoEvents(); is almost ALWAYS the wrong choice. Because it means, you are using you UI-Thread for non UI Work that is blocking.
&gt; Bind these properties to columns in your table. But he has no Table, he just has some Grids with some RowDefinitions and ColumnDefinitions &amp;#x200B; There is a lot wrong in this "Design"-Code. It looks good, but can't really be used properly programmatically
&gt; At a minimum, I would promote the definition of the event handler for text_box.KeyDown to its own method rather than using a rather lengthy anonymous handler inside your constructor. So that lambda expression actually started out really small. Then a case for handling folders was added. Then a case for files... Etc. :-) Thanks for the suggestions and comments!
&gt; I would also promote your locally scoped functions in the constructor to proper member functions. Yup. In a pinch, when trying new approaches out, I tend to go with a locally scoped function first and then promote it to a method as appropriate. Another good point, thanks!
Can you use this to load a native DLL into your own .NET process and then P/Invoke it?
&gt; Also, if you really wanted more work to do, you could use more idiomatic WPF concepts like templates, behaviors, adorners, etc. Yes, it would be *very* interesting to see a version of this that is written in a more traditional WPF style, using XAML, etc.
Only if you need something other than the default constructor. If that's acceptable, you're good to go.
Oh you mean sleeping on the ui thread. Yeah, thats not a good plan. If recommend that the desire to have a long sleep or the need to call your helper function here (which is indeed better than sleeping the UI thread) would be a code smell and an opportunity to move the work to a background task or some other mechanism to get it off the UI thread.
This library would be for adding functionality to or monitoring activity in a third-party program you don't control. It seems like a lot of hoops to jump through if you already control the process - why not just load and call the DLL directly?
Couldn't they, on program exit, copy the db off somewhere, then on program entry copy it back to the build directory?
&gt;So that lambda expression actually started out really small. Hehehe don't they always? Keep it up, man!
TBH, functions like *HideDllFromPeb()* and *RandomiseDllHeaders()* sound a little sinister and spyware-ish (I suppose they could be useful for reverse engineering...?) What use cases did you create this for?
Thanks for this!
Not exactly an alias but close enough (low cost wrapper) public struct RangedDictionary&lt;TKey, TValue&gt; { public Dictionary&lt;Range&lt;TKey&gt;, TValue&gt; Dictionary { get; } public RangedDictionary(int capacity = 1) { Dictionary = new Dictionary&lt;Range&lt;TKey&gt;, TValue&gt;(capacity); } public static implicit operator Dictionary&lt;Range&lt;TKey&gt;, TValue&gt; (RangedDictionary&lt;TKey, TValue&gt; range) { return range.Value; } } And you could decide to re implement part of the IDictionary&lt;Range&lt;TKey&gt;, TValue&gt; that you want.
You can just pinvoke LoadLibrary.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/dotnet] [Some improvements to my freely available toolbox](https://www.reddit.com/r/dotnet/comments/bmz8ye/some_improvements_to_my_freely_available_toolbox/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Windows requires you to load native DLLs from the filesystem. This library allows you to load them from memory, which enables some interesting things. One simple use case is making a single file .EXE with an embedded native DLL.
Not if the DLL is in memory, not in a file.
Ah cool. That’s what we are also doing.. and no refresh tokens as well? Also with the awful iframe stuff? I read the draft they are working on for SPA and was surprised by the recommendation to use cookies, hehe.
WPF. Just because you can, doesn't mean you *should.*
Injecting DLLs is often a big part of hacking video games. Aim bots, MMORPG bots, you name it. If you are going "in process" you might want to hide from any safeguards the developer may have put in place (WARDEN from WoW for example).
I second this. We had some legacy selenium based tests that were really hard to maintain and had a lot of boilerplate code everywhere. Atata makes selenium tests less painful and the docs are quite ok to get started.
C++ users get to have their templated using statements, I feel C# could implement it if they feel like it.
That's just normal XML... they are called attributes
Honestly I have no idea. This is all I could pull up. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/?view=aspnetcore-2.2#eventsource-provider From the article here is the Logging.EventSource library - Microsoft.Extensions.Logging.EventSource When I hear EventSource I automatically think Server-sent Events, though. Which this is not. This seems to mean something different, but along similar lines. It might be used to source where certain actions/events are coming from. Events such as logging and Event Tracing for starters. So, if you want to grab the ETW events emitted by ASP.NET you could use the above library to do so. Hopefully someone else has a clearer answer. I haven't used MediatR. It seems to be using the Service Locator pattern rather than the Mediator pattern. Meaning, instead of passing in a ton of Objects/Containers to your constructor you just need to pass the Service Locator which then allows you grab objects/events/services. It feels like MediatR would be debatable for clean architecture as the Service Locator pattern has been argued to death in the past. Just do a search. So, I have no idea but hopefully this helps.
So it definitely is xml node attributes but do you have any guides on how to return it like this in an xml response?
What do you mean? You want some code? You are going to need to be ALOT more specific. Respond with what? In what language? XML is just a serialisation technique, your question doesn't make sense without more context around it. You mention WCF, one of the points is that it does this for you, why aren't you using the wcf onjexts?
Removed: Rule 4. You'll have to provide more/better context about what platform(s) you're using, what you're trying to achieve, and why.
Hey ! Lucky for you, I started a project a couple of months ago implementing all what you mentioned, I dropped it to start other things as it was more of a PoC for this stack. Let's start with event sourcing. .NET has a very good trch for ES, called Event Store. It's a stream DB that persists events for you, and is very efficient, here https://eventstore.org. As for what is ES, basically instead of persisting an object's state as it is, you persist the events applied to an object. When you then want to retrieve an entity, you basically create it in it's initial state, and re-apply all the events related to that specific instance of that entity. Al this is hidden by a generic repo i created, just like any repo you have a Get(id) and a Save(Entity). The get like i said will retrieve the events stored, apply them to the clean entity and return it, the save will store the uncomitted events on that entity. Look into my CommandServices and Domain Entities ( the Buddy &amp; Group aggregates are a good example ). The good thing about combining this with f.e. mediator, is that 1 handler has 1 responsability, and if you have multiple thing going on, a command generates an event, and you can listen to outcoming events and create new commands from those events, resulting in a chain of events of multiple things need to happen. It's complicated to setup, but once you have it up and running, everything becomes quite easy and quick to implement. Here's my repo: https://github.com/BusschaertTanguy/Hubby.Backend Hope this can get you on your way ! If you have more questions, feel free to ask !
The gist of event sourcing is that you don't store the current state of your entity in the database, you store the list of actions that have led the entity to be in its current state. Then to fetch the entity, you fetch all the events and "replay" them to get to the current state. Along the way you can take snapshots to speed up the replay process.
Thank you very much for a detailed explanation! I understand the concept now. However &gt;When you then want to retrieve an entity, you basically create it in it's initial state, and re-apply all the events related to that specific instance of that entity. I am a little vague about the use cases of this approach. Re-applying actions every time seems to be detrimental to app's performance. There must be a reason why we need this functionality?
&gt; My understanding: • we implement a bunch of Query / Command Handlers • we inject MediatR into controllers • every request has it's own Handler - MediatR calls the handler we need • controller actions are tiny • all relevant validation logic and business logic is kept inside Handler • we fetch data - we use Query Handler • we change system state - we use Command Handler All good. This is exactly what we are doing in a new project, except that validation is done as a pipeline behavior (as much as possible) before the Handler. Honestly I think DDD is just a fancy name for the results (or consequences) of this approach. I haven't seen any benefit of investigating exactly what additional benefits DDD would incur. If there is some additional information that I'm missing I'd love to know. The little I've heard about event sourcing, it's mainly applied to how multiple microservices communicate between them. So instead of a monolith database, they each have their own database **that no other service can modify**. Then they just emit events to a stream (like AWS Kinesis?) and the other services respond by updating their database and doing whatever logic is required. This would require you (the developer and stakeholders) to be OK with this thing termed "eventual consistency", because there is no monolith database that is the single source of truth, there is this period of inconsistency before the other microservices respond to the emitted event. Maybe that's fine...?
Made me smile, I know the feeling!
That's what the whole Event Store does for you, you can implement it on your own, but those guys really nailed on the performances, I think there are some benchmarks around and it's just incredibly fast. You can have more details about this whole stack here: Overview: https://lostechies.com/gabrielschenker/2015/05/26/event-sourcing-revisited/ Your aggregate implementarion https://lostechies.com/gabrielschenker/2015/06/06/event-sourcing-applied-the-aggregate/ Your services https://lostechies.com/gabrielschenker/2015/06/13/event-sourcing-applied-the-application-service/ The repository ( both a custom sql and an event store impl ) https://lostechies.com/gabrielschenker/2015/07/13/event-sourcing-applied-the-repository/ How to keep your read model in sync https://lostechies.com/gabrielschenker/2015/07/16/event-sourcing-applied-the-read-model/ The only difference being that he ain't using mediator, but that should be fairly easy, you split up your servixe in handlers.
In theory, using pe file format... You could write you're own dll loader and be completely hidden from windows API functions. I call the concept a dynamic process based root kit. Be a lot of work though. It's easier to just inject you're own asm and do asm rewrites. Much harder to detect.
IoC? No. Dependency injection? Absolutely. My point was that the way many people think about this stuff has changed.
Looking closer at your question, and specifically your desire to do this in the context of an expression-bodied property, I put together [some examples](https://dotnetfiddle.net/mG9mye) of ways to do this. Good luck!
About 6 months ago I started my dev journey. So far I have been mostly fixing bugs and adding small pieces to an existent API. I want now to create a tool to help my manager with his weekly reports: every day we have a standup meeting, he takes notes and at the end of the week write a report with them. I want to write a small piece of software that I can use to write down my standup update, and send it to him via email/slack/whatever. As a bonus, this could be my very first github personal project. Is this something a beginner could possibly do? I never built _anything_ from scratch, never worked with a GUI, never managed files with C#. What should _absolutely_ need to know before starting a project like this? Thanks a bunch!
&gt; What is Event Sourcing? https://youtu.be/WwrCGP96-P8?t=4131 Basically a append only list of events that have occurred that maintains a list of changes to make to the state of the system that allows you to return to the state at a particular time or query for specific use cases that were not originally known to be valuable. Greg Young has several videos about this where he uses querying for medical patients who suffer from something after a period of time. &gt; Are there libraries/framework for Event Sourcing? It would depend on the approach you use. If you use a single table to hold the events then any ORM can be used as the event source. If you want a stream based approach then Kafka may suit your needs. But specifically for .NET? I have not found any. &gt; How is it achieved - where are we supposed to put the code? Wherever a state change occurs. If you are using MediatR this would be in the RequestHandler. &gt; Are there any code examples covering Event Sourcing? Best I have found is: https://github.com/dotnet-architecture/eShopOnContainers but it does seem to take liberties compared to what others say should happen. &gt; Are we supposed to use Event Handlers? Not C# event handlers (https://docs.microsoft.com/en-us/dotnet/api/system.eventhandler-1?view=netframework-4.8) but the same pattern, yes. &gt; Does Observer pattern come into play in this case? Yes. This is a good way of thinking about it. This is the 'reactive' programming: https://github.com/TomasMikula/ReactFX http://reactivex.io/
&gt; I am a little vague about the use cases of this approach. Re-applying actions every time seems to be detrimental to app's performance. There must be a reason why we need this functionality? You can 'snapshot' the state as well. Recommend watching Greg Young as he explains it using financial/accounting data that may relate well: https://www.youtube.com/watch?v=I3uH3iiiDqY
Ah, financial data that is. I see. Thank you very much!
This is f*cking stupid.
There's a distinct lack of comments and documentation. Even something as simple as a line comment explaining what each function does can make code much more maintainable, this is especially important if ever it becomes a collab effort. &amp;#x200B; Also use those catch statements to output to console if an error occurs can help with debugging when it occurs.
We use Keycloak for SSO with our .NET applications.
Also malware :)
So is this kinda like what cheat/trainer/mod developers do to make internal cheat menus for games?
First you will need to extract text from the PDF: * [Pdfsharp Apache 2.0](https://github.com/empira/PDFsharp) * [PdfPig Apache 2.0](https://github.com/UglyToad/PdfPig) * [docnet MIT](https://github.com/GowenGit/docnet) * [iTextSharp 4.1.6 LGPL](https://github.com/VahidN/iTextSharp.LGPLv2.Core) * [iTextSharp v7 AGPL](https://github.com/itext/itext7-dotnet) Use any of these libraries (commercial ones are the best, however you can test the free ones (MIT/Apache/LGPL) and use them if they work. Once you extract the text, use the [Open XML SDK](https://github.com/OfficeDev/Open-XML-SDK) to generate a table. Commercial solutions exist that do exactly what you want: * [Bytescout PdfExtractorSdk](https://bytescout.com/products/developer/pdfextractorsdk/convert-pdf-to-excel-csv) * [Sautinsoft PDF Focus](https://www.sautin.com/products/components/pdffocus/pdf-to-excel-programmatically-c-sharp.php) * [Rasteredge XDoc.PDF](http://www.rasteredge.com/how-to/csharp-imaging/pdf-converting/) * [Cometdocs REST API](https://www.cometdocs.com/conversionApiTools) However, do note that these commercial solutions may not work well with PDF containing images, and in general will not work well in a .NET Core Linux server environment (because USUALLY these commercial libraries use System.Drawing which requires GDI - only fully supported on Windows, and restricted in Azure even on Windows)
Honestly? I can see where "UWP is dead" sentiment comes from. The pain starts all the way back in WPF. I was there when WPF released. I was using it even before it released. I believed Microsoft when they said they were delivering the new application framework for Windows. I already had a few years of WinForms experience, but I was fine with throwing that away for WPF given the features I was gaining. Then... nothing really happened. It was slow. The text was blurry. MS denied there were any troubles at all. There was a vibrant, excited community but no real flagship applications. That changed when Evernote rewrote their entire app to be WPF. Yay, right? It was short-lived. Within months, Evernote publicly denounced WPF for exactly the blurry text that MS insisted was not their problem. A hotfix a few weeks later had a small bullet point: "Addressed an issue that sometimes caused blurry text." Too little, too late. By the time I was moving into Silverlight it was still true there were no obvious extant apps using WPF. Supposedly it was really popular for LOB apps. My company at the time bet pretty hard on Silverlight. Then there was the infamous "HTML5 everything" Build or Mix or whatever conference. Then there was the Silverlight PM explaining that we should consider HTML5 a more viable cross-platform solution. Then Microsoft fired the PM for lying. Then Microsoft announced they were discontinuing Silverlight? I sort of stopped writing Windows applications at this point. This was around when The-Framework-That-Couldn't-Be-Named-Metro released. What'd they call it, "Modern Windows Applications?" It only ran on Windows 8. MS offered significant bounties for people to port apps. It didn't work. Users didn't want Windows 8 because there weren't compelling devices. Users didn't want MWAs because they only ran on Windows 8. Devs didn't want to write MWAs because there weren't users. So Win10 rebranded MWAs as UWP. Same problem, only now Vista was aging enough people had to upgrade to Win10. The Surface is a compelling device, so people are sort of ready to use UWP. But at the same time, HTML5 has become really viable as an app platform. Slack, Discord, even Microsoft apps like Skype and Teams are using HTML/JS instead of UWP becuase it kind of matters if you can run on Mac/Linux. So while MS might be increasing their investment in UWP, they're also investing heavily *against* it: * I can't name a significant MS product that hasn't been ported to Mac/Linux. * UWP can't run on Mac/Linux. * Xamarin Forms looks like a way to use a UWP-like framework cross-platform, but cross-platform desktop support's been "coming soon" for years. * MS has no Xamarin Forms apps in the wild. * Some of MS's biggest products like Skype aren't using UWP or Xamarin Forms. * MS just discontinued Edge, their last IE version, in favor of adopting Chromium. Chromium is the browser that runs Electron apps with a Node backend. * MS is working hard on .NET Core, which works cross-platform. * There's Blazor, which runs .NET Core apps in browsers. Like Chromium. Almost like they're planning an Electron competitor with a C# backend. * Even if they don't use Blazor, it's easy to imagine an Electron-like framework linking a Chromium browser to an ASP .NET Core backend. It's the same thing. So to me it looks like there's 3 places MS could place their bets: Xamarin+UWP, Chromium+.NET Core, Electron. I don't see them stacking their chips on one. Instead they're carefully dividing their chips between them all. So I'm not really comfortable betting a long-term project on any of these. For all we know, UWP has a successor in the works already. It'll be similar but different, familiar but new. I'll wait until whatever dang framework they settle on also works on my MacBook. Until then my personal apps are Electron, and I'm getting interested in Flutter. I don't think UWP is dead, but I can't think of a good reason to invest in it yet. History tells me nothing is too young for MS to murder.
Don't say "I'll refactor this later" cause you will forget about that :)
I originally started the project with this idea in my mind, however, I have shifted away from this idea as I no longer play many games.
An older version of my library actually did exactly this, using an asm stub that syscalled the winapi function instead calling it directly. I decided to remove this though due to several reasons, but partially because I realised if someone is monitoring a winapi functions globally, they probably also have a hook on syscalls, therefore it's kind of useless.
The answers below give pretty accurate answers, but yes, you can definitely load a native DLL into your own .NET process and PInvoke the functions. One thing to note is though is if you are using the ManualMap method, you will need to manually parse the headers of the DLL from the returned pointer to get your exported functions and I haven't yet added functionality to add the mapped DLL into several undocumented winapi structs. For example, your DLL would not show up in the process module list as of now.
You would totally correct in the sinister part. I originally started this project as a tool for cheat developers to load their cheats into games and so having ways to hide their DLL after loading it into a process makes it a lot harder for an anti cheat their DLL (assuming they don't detect the actual loading itself.)
Or just use [Directory.GetCurrentDirectory](https://docs.microsoft.com/en-us/dotnet/api/system.io.directory.getcurrentdirectory?view=netframework-4.8).
Would you mind adding an example to the docs for invoking a method within the newly injected dll?
The docs actually haven't been updated for the latest version I will do this later today and be sure to include this for you :)
Awesome, this is a very cool project, I'm looking forward to poking around under the hood.
Neither of them are becoming cross-platform. They're still Windows only and still use the same GDI+/DirectX APIs they've always used.
As of now, WPF in .Net Core 3 is Windows only and uses DirectX for rendering. You can get the preview releases and build WPF applications currently, so if you wanted to try things out for yourself, you certainly can. &amp;#x200B; WinForms in .Net Core 3 is also Windows only and is still using GDI+, so no hardware acceleration.
The only desktop cross-platform GUI framework MS has ever blessed is HTML5 with a JavaScript backend. So no. There aren't any plans (I'm aware of) to make WinForms *or* WPF work on anything but Windows. They'd rather you use UWP and hang on the promise that one day Xamarin will make that work on Linux/Mac, it's been promised for years now. But it's more likely either Blazor or something like "a .NET Core webserver attached to Chromium like Electron does with Node" are going to arrive before that.
Dang... Thanks for the info. However... Mono allows you to run Winforms on Mac/Linux. I thought one of the primary goals of .Net Core was to make C# cross platform (so you didn't need mono to run C# code on Mac/Linux anymore). Is there any documentation outlining what components of .Net Core are cross platform and what are not? I wonder how much of the current .Net Core 2.0 is already non-cross-platform.
C# is cross platform WinForms/WPF is basically like pinvoking into native windows libraries. C# and runtime is cross-platform, but those libraries aren't.
I recommend using the adapter pattern for this.
This is a cool project, nice one! I’m gonna have a look about later and see what can be learned, kinda intrigued by the hiding dll aspect!
I can't find one place that has cohesive documentation outlining what is or is not cross-platform, I was referencing the README files from Github linked below. It is my understanding that Windows specific projects (Winforms, WPF, UWP) will only run in the Windows ecosystem while other project types (Web App, Console, Library) run on Windows/Mac/Linux. https://github.com/dotnet/wpf/blob/master/Documentation/contributing.md &gt; We also do not intend to accept contributions that provide cross-platform implementations for Windows Forms or WPF. https://github.com/dotnet/winforms/blob/master/README.md Here's a useful update for WPF as well if you are interested in following along with the progress that the team is making: https://github.com/dotnet/wpf/issues/607
Thanks man!
Lying? He’s right.
- You need a [message loop](https://docs.microsoft.com/en-us/dotnet/api/system.windows.forms.application.run) - You must not permanently block the UI thread with a sleep or anything else
You are a saint. Solved!
Please correct me if am wrong, all my information from podcast episode I've listened to it a while ago, This sound like a use case for Apache kafka, AFAIK it's only in enterprise level to need to use that type of architecture, ex: games, heavy logging, social networks... I don't know more, If you don't need it, then you will end up adding unnecessary overhead, load to your app (CQRS, Mediatr) It's always good to learn new technoogy, architecture, for me personally, it's to far to pay off soon, Good luck
I don’t use posh for admin related stuff but have you imported the module containing new-localuser? The error is pretty clear
Just pass the parameter to octopack to override the version from gitversion. That's hardly a limitation.
if you need a comment for every function then either you are not spending enough time naming your functions or you are not respecting the single responsibility principle. Comments should be few and far between and only say why something is needed not what it does (with the exceptions of very complicated regex or some unreadable math.) https://www.amazon.com/Clean-Coder-Conduct-Professional-Programmers/dp/0137081073
You could design your own loader and use writeprocessmemory to load the door, mapping it yourself and working out all it's pointers etc. It would be hard, but super awesome.
You would use a while loop :) C# is descended from C. It has most of the same constructs.
I know, but how do I handle it since the inputs are strings? And did I do the conversions correctly?
Look up the TryParse functions. They are amazing.
I got it! I have one more question if you don't mind... I'm trying to round the output, I have Math.round(percentFat,2) but it rounds it to the nearest whole number, not 2 decimal places.. Any suggestions?
Some parts of gdi are hw accelerated since Windows 7, which many people don't know https://en.wikipedia.org/wiki/Graphics_Device_Interface#Windows_7 Those features should theoretically also be the same in gdi+ then
There's a Math.Round overload that allows you to specify how many decimals to keep.
Thanks so much for all your help, I think I got it!
If you like text adventures, how about some development tools? * [ZILF](https://bitbucket.org/jmcgrew/zilf): A compiler for ZIL, the language Zork was written in. * [ZLR](https://bitbucket.org/jmcgrew/zlr): A Z-machine interpreter and debugger, used in the ZIL vscode extension. * [Guncho](https://bitbucket.org/jmcgrew/guncho): A multiplayer text adventure hosting system.
[removed]
Oh that's what my ManualMap method does. I manually do what LoadLibrary or equivalent would do. I dont add any references to any of the structures that the winapi functions use, as far as the process itself doesn't know that the module is loaded in the process.
Can you point me to where exactly is the event sourcing related code in the eShopInContainers repo. I can't seem to find it.
This is really cool...I have been trying to workout how I could read some information from an application that uses custom controls. Would this library be able to access the data and return it to another application?
You would have to set up some form of IPC such as a named pipe to achieve this but yes it is definitely possible.
Is there any documentation (even if high level steps) how you'd go about doing this?
That’s a really awkward approach, why would you involve scripting at all when you’re already in a windows app? Do it through APIs not by launching a separate script
While I haven't had to deal with automating build numbers, doing a quick research perhaps something as simple as git describe (https://linux.die.net/man/1/git-describe) Would be enough to get a unique build id?
Msdn has some good documentation on pipes but you can also find good examples by searching something like IPC DLL injection
Apologies in advance, I looked over the code, but only on my phone. Overall, I felt it was reasonably good for its purpose, a script to help do something useful for you. I think the other comments are valid if you are going to maintain it for a while. If you are looking to improve your skills, I have a few suggestions. 1) You are mixing a few different threading models. "async" methods are expecting you to be using Tasks, and can use async/await keywords which work with methods that return tasks. Definitely consider using them. ThreadPool is from the older APIs. Still works, but isn't really used in modern c# code. 2) It is awesome that you are using Monitor Wait/Pulse for synchronization. Seriously, it's rare I see it in people's code (way more common to see thread sleeps). I did notice you were using local objects to lock on for the wait, though. Typically lock objects are static so that they are accessible to all functions in the class. In order for the pulse to signal the waiting thread, it has to have a handle to the same object. In the case of the downloader, where I saw the code in question, this would be situation to use tasks and async/await. 3) In launcher example, you have a thread that updates various portions of the UI and then sleeps for 100ms. Since you are looking to avoid bad habits, this would be a place to think of ways to improve. Ideally, you are only updating things you need to, not everything. If you move to that model, you can use a Monitor.Wait with a timeout instead of a sleep, so it can be interrupted if it needs an update. 4) Last thing I would classify as a bad habit would be code consistency. Sometimes functions are capitalized, sometimes not. Lots of variables are public but not using properties for accessing them from outside the class. These things don't matter in a personal project, but if you want to show this to a potential employer, it would be a lot more impressive to show consistency. It's a way to show that you care about the code you write to others, even if it doesn't have any effect on the runtime behavior. Keep up the good work. I loved Planetside back in the day!
I only took a quick look and here are my suggestions * Don't use hardcoded strings, especially for configuration settings. You should use config files for this * Learn how to write proper commit messages
The nice thing about GitVersion is that your commits themselves can help version, instead of relying solely on a development process to do it. It can obviously be done other ways, but having a way to keep version ordering sane when merging across branches is its key benefit. If it doesn't fit your workflow, don't force it.
Definitely an r/PowerShell question, but hey, .NET is .NET. :) The cmdlets that you want are part of PowerShell 5. To check your version, type this into a regular PS window: $PSVersionTable.PSVersion If it returns anything lower than 5.1, install this: [Windows Management Framework 5.1](https://www.microsoft.com/en-us/download/details.aspx?id=54616). The form shouldn't be affecting this one way or the other, as far as I know.
The other comments are correct. This is solving a problem that is caused by a poor threading model, rather than something that should be reused. The UI thread should, ideally, only be used by UI activities. If you need something to wait for a while, then that waiting should happen on another thread and a notification that the waiting has occurred should be dispatched to the UI thread after said wait. This can be as simple as a boolean shared between threads (as long as only one thread is changing its state and the other is checking it, you should be pretty safe). If you are ever considering using Thread.Sleep,you should almost always be using Monitor.Wait with a timeout,so that it can be interrupted in case you don't end up wanting to wait the entire sleep duration for whatever reason. Someone else mentioned Task.Delay, and internally, that uses the method I described.
I heard this question at build, they said that right now are focused on releasing the framework and then they will add features
that looks more like odata than graphql. but a proper graphql compliant library on top of webapi controller would help a lot of devs.
If your goal is to learn [ASP.NET](https://ASP.NET), then keep at that. I don't think you can "Forget C#" \*and\* focus on [ASP.NET](https://ASP.NET), but I don't see a reason why you can't continue to learn C# through your experience. &amp;#x200B; As others have mentioned, don't go to Unity to learn C#. It will confuse you way more than it will help, and there are a lot of features unique to Unity that behave differently than they would in a normal C# app. &amp;#x200B; Based on your post, what you need most is practice. If you need a course to give you structure, then do that! If you can think of a ton of random projects on your own, do that's fine too. &amp;#x200B; Don't get caught up in the technologies right now. All of the technologies you are overwhelmed by in [ASP.NET](https://ASP.NET) are solutions to problems you haven't been exposed to yet. By practicing, you will be encounter new situations, and then those technologies will make more sense. Also, I highly recommend keeping a C# console app project going when you're developing. [ASP.NET](https://ASP.NET) adds a ton of complexity to the "flow" of the code. If something is confusing you, practice it in your console app to get it working and switch back to the [ASP.NET](https://ASP.NET) part when you're comfortable.
You left out Unity3D. don't get me wrong, getting folks to pitch how .NET devs should and shouldn't work is done via what templates we used to put in Visual Studio when you went File-&gt;New-&gt; Project So i'd suggest devs that do the work need to expand beyond what Microsoft team tell you to use. You'll see a wider spectrum of offerings. &amp;#x200B; Back to Unity3d. I was on the Silverlight/WPF team and we tried a lot to achieve parity with what this product solves today, and you have to remember that games have 2D menu issues with network etc. Unity3D solves that, and you also get to x-publish / x-platform by focusing on screens not multiple projects or how xml describes the UI. &amp;#x200B; Furthermore, the XAML spec isn't settle so be careful on your adoption curve... as until Microsoft settles their bets on UWP/XAMARIN/WPF converge moment, its not exactly a sure bet going forward on the "what". &amp;#x200B; An attempt was made on the standards but it was later put in the too hard pile and backed out into the "Principles of a standard" wishy/washy basket.
The part I like about git version is that if done right every commit in your repo will have a unique build version. Such that I can go to any commit and build the software with gitversion and get the appropriate version. I don't have to rely on determining the version on my own because git version figures it out based on my git history. This is extremely important in product level development and configuration management.
The MS Store version of Skype is a WinRT/UWP app using React Native. Just look at the suspend/resume behavior in the task manager when you minimize them, or switch to tablet mode. They also respond to Win+Shift+Enter for fullscreen, and the taskbar unhides when you hover over it. They also don't have minimize/restore/maximize buttons in the title bar during tablet mode. And they also lack the "Run as Administrator" option. All of this classifies them as proper WinRT/UWP apps. All the media outlets that reported and are still reporting that it's not UWP anymore are wrong. It only uses Electron on non-Win10 desktop platforms.
Good points. I left out Unity because I was thinking along the lines of Line Business Applications, and cryptocurrency apps in particular. Although you have a point there in that the crypto community is big on Unity. I know of at least one game that implements one of my libraries for hardware wallet integration with Unity. Silverlight was a great platform and it was a bitterly sore loss when Microsoft pried it out of our hands. I think C# with Wasm will be a poor excuse for what Silverlight already was but I also understand why the industry had to move away from in browser plugins. &gt; An attempt was made on the standards but it was later put in the too hard pile and backed out into the "Principles of a standard" wishy/washy basket. 100% correct. I even met with people at Microsoft on pursuing the XAML Standard and was in the process of contributing. However, the standard just lost momentum as a focus. It's a huge shame because XAML is probably Microsoft's biggest asset as a technology. I don't think they even realise how powerful it is.
Key feature for me: it produces deterministic version numbers. I get the same version number from a local build as I get on my build server. Bonus: it nicely integrates with 3rd party build systems like Cake and Nuke (which I use), so I can get access to the version number inside my build script.
&gt; Security is now a huge consideration when it comes to app development deployment. Desktops are lagging behind phones in that many applications still require the user to download the application as an installer and then install manually. This is a colossal problem and any developer that ignores this issue does so at their own peril. If a user is forced to download apps from the internet, they are being exposed to Malware, losing control of application level permissions, and opening their computers up to spyware and so on that is not vetted by any authority. As users become more savvy, less and less will tolerate this situation and will opt for apps that are deployed via the App Stores or in a browser. This is naive. App stores aren’t more secure than a standard installer. The App Store just hides the details from you. How do you think the app gets from the store to you? It’s all just internet downloads.
Debug it.
&gt; App stores aren’t more secure than a standard installer. Incorrect. &gt; How do you think the app gets from the store to you? I would answer, but... &gt; It’s all just internet downloads. Correct. If you don't understand, there's really not much that can be said to explain it to you. It's security 101. If a user is downloading an installer from some website, there is no way for the user to guarantee that the package is the genuine package. However, if the user downloads it from a trusted source, then barring some unforeseen issue, it can be guaranteed that the package is genuine, and most likely malware free. DNS attacks and other not so sophisticated attacks can easily fool a user in to downloading a non-genuine package. To say that App Stores aren't more secure is just silly.
Also make sure it is using the rounding algorithm you want.
Very cool!
I think a download site with https is more or less as trustworthy. The main benefit with uwp apps is in the app security model in my opinion. So that access to certain capabilities are blocked by permissions. Also clean uninstall is big. The app store is actually detrimental because it takes 30% of the revenue, and the side loading experience is very poor. The user needs to enable it in the settings and there is no good setup out of the box (a powershell script, seriously?). This hinders adoption of the app model by vendors. Apps in the store will be scanned/tested to some degree but for me that is not the most important part.
https://youtu.be/2moh18sh5p4 https://youtu.be/ZTKGRJy5P2M
https://blog.stephencleary.com/2012/02/async-and-await.html
There's two parts: what you think you're downloading, and what you're actually downloading. From an app store, you can trust that what you get is what you expected to get - maybe it's a bad buggy app with insecurities, but it hasn't been tampered with. From 'any website', you have no basis for trusting the source of the content. HTTPS doesn't address this problem in any way.
you Need to using System; and a Namespace
@ [johnnysaucepn](https://www.reddit.com/user/johnnysaucepn) is right. \&gt; I think a download site with https is more or less as trustworthy. I see. So, because a site implements encryption, it is trustworthy? Well, good luck with that. \&gt; The app store is actually detrimental because it takes 30% of the revenue That's just wildly speculative, but revenue has nothing to do with security. \&gt; Apps in the store will be scanned/tested to some degree but for me that is not the most important part. OK. So, basically security is not really important for you.
So you are saying that when I download Visual Studio from https Microsoft.com with a browser I don't know what I will get? How would an attack work? Note that applications themselves are signed as well. (Mandatory for uwp) I get it that for a random publisher there might be the question if you trust them. But a secure app model, clean uninstall, a virus scanner and a bit of common sense can do most of what an app store can.
&gt; So you are saying that when I download Visual Studio from https Microsoft.com with a browser I don't know what I will get? It's possible. Yes. [https://en.wikipedia.org/wiki/DNS\_spoofing](https://en.wikipedia.org/wiki/DNS_spoofing) But, the more likely scenario is simple social engineering. For example, an email that tells someone to download Visual Studio from some website that looks like a legit Microsoft website but is actually hosting a malware laden version of VS. &gt; a virus scanner and a bit of common sense can do most of what an app store can. Are you being serious?
1) Https is not only about encryption but also about authenticity. So if it says it is Microsoft or Autodesk then I trust it is them. 2) If you would read the part after what you quoted you can see my point was that it hinders adoption of the safer uwp model because side loading uwp is not feasible in many situations. And for some businesses the app store is not feasible because of the 30% cut. 3) An app store is not a guarantee that software is safe. Just like a virus scanner might not detect all malware.
From the linked wiki page: This kind of attack can be mitigated at the transport layer or application layer by performing end-to-end validation once a connection is established. A common example of this is the use of Transport Layer Security and digital signatures. For example, by using HTTPS (the secure version of HTTP), users may check whether the server's digital certificate is valid and belongs to a website's expected owner. 
Unity dev here. I’d rather use something else than uGUi any day.
Once you're comfortable with the basics, David Fowler put together a list of common mistakes and how to avoid them [here](https://github.com/davidfowl/AspNetCoreDiagnosticScenarios/blob/master/AsyncGuidance.md) It's aimed at .Net Core developers but it's applicable to all C# development.
Thanks, I forgot about Tim Corey for a second. He is just amazing.
Thanks, this is really awesome.
Cool, I will definitely check it out. Thanks!
Btw, there is also a cool C++ library for web UI development - Wt (Web Toolkit), it is very similar to Qt in terms of developing with it, but you do web UI elements instead of desktop widgets. Maybe you'll be interested to bind it to .NET.
Truncate needs special permissions on the table (or user or DB etc) to run. Not just delete permissions. It also bypasses the SQL logs, unlike the delete statement, which might be something to consider
You can also run a DNS attack or MITM attack against an App Store. The only guarantee that they have is SSL, which is also provided by regular download sites. There’s no inherent safety in App Store delivery. You trust r because of the marketing, but it’s no safer than a regular download
There is also [Eto Forms](https://github.com/picoe/Eto), which is in my opinion nicer to use than Avalonia, you can create whole GUI like in Winforms with code behind or using json or xaml. For example Monogame Pipeline Tool is written with this.
Unity being a game engine doesn’t make ideal for business apps due to how it’s designed to execute updates every frame. It’s eats batteries for breakfast
Can’t help you without the code.
using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; &amp;#x200B; namespace NumSystems { class Program { static int exp(int a,int b) { int c = 1; while (b != 0) { c = c \* a; b--; } return c; } &amp;#x200B; static void Main(string\[\] args) { char\[\] pole = new char\[20\]; int sys, num, rem, i; &amp;#x200B; Console.WriteLine("Set the amount of digits in the final system."); sys = int.Parse(Console.ReadLine()); Console.WriteLine("Set the number to convert."); num = int.Parse(Console.ReadLine()); &amp;#x200B; if (sys &gt; 10) { for (i = 0; num != 0; i++) { rem = num % sys; num = num / sys; if (rem &gt;= 10) { switch (rem) { case 10: pole\[i\] = 'A'; break; case 11: pole\[i\] = 'B'; break; case 12: pole\[i\] = 'C'; break; case 13: pole\[i\] = 'D'; break; case 14: pole\[i\] = 'E'; break; case 15: pole\[i\] = 'F'; break; } } else { pole\[i\] = (char)rem; } &amp;#x200B; } } else { for (i = 0; num != 0; i++) { rem = num % sys; pole\[i\] = (char)rem; num = num / sys; &amp;#x200B; } } &amp;#x200B; for (int j = i; j != 0; j--) { Console.Write(pole\[j\].ToString()); } Console.ReadKey(); } } }
Check console code page (chcp command), check font of the console.
[https://imgur.com/jd1GJ2O](https://imgur.com/jd1GJ2O)
1. Get the value out of the textbox 2. Get the value out of the file 3. Compare them 4. Act on the result
 (char)rem What do you think this line does?
I thought the value of int rem is converted to a char by this
What bit exactly are you having issues with or are you hoping someone is going to write it for you?
Tried changing them but the output is still not correct
Yes, that is what happens. But converting the integer `8` will not result in the character `'8'`. Instead it will be the character representing backspace. See any arbitrary ASCII table: http://www.asciitable.com/ If you want the character `'8'`, then you need the integer `56`. An easy way to achieve what you want is to just add `'0'` to your number. The character will be converted to its integer representation `48`, your value is added (e.g. `8`) and you get the integer representing your digit (e.g. `56`).
I know what I have to do, from a previous comment. But I’ve been trying and struggling, still very new to c# and coding. If you could write it out it would be a huge help, if not I understand
Being new is fine, but getting someone to write it for you isn’t going to teach you anything. Instead of asking for someone to do it for you why not post what you have or explain what part of it you are stumbling with so someone can give pointers, that way you are doing and will learn more than if someone just gives you the working code.
Will do, thanks
if(condition = true) do stuff else do something else
So I used this [https://imgur.com/KBTrHmr](https://imgur.com/KBTrHmr) and it worked. Thank you so much!!
Also, please don't paste screenshots of code. Just post the code. Either directly in Reddit (with an empty line between code and text, and each line indented by 4 spaces) or in one of the numerous paste pages, e.g.: https://gist.github.com/ https://sharplab.io/ https://dotnetfiddle.net/ https://pastebin.com/
I did and i thought it was unclear so I deleted the message but ok
even if you change codepage to 8-bits? https://en.wikipedia.org/wiki/Windows_code_page#List
No it wasn't the problem.. look at the other comments there was a problem in the code
&gt;Microsoft uses a mix of products internally to build apps. Generally there is no enforcement of using a particular technology for a product in mobile development, it’s whatever each engineering team feels comfortable with I think for larger productive software products, the poster mentions a concern for a long term stable standard that is able to be well on a solid stable supported baseline of solid guides and standards with little hotfix needs. The poster mentions Macbook, which means possibly the poster's targeting vectors are Apple exclusive. This is where a lack of a long term mobile hardware standard has hampered stable app development with ever demanding processor specification increases. Is this supposed to be considerate for what would be "thin" cost effective handheld networked client hardware? Developing strictly on a Macbook doesn't give the usability of a Surface, for example. You can see the poster very much willfully turning a blind view to those devices by slandering Windows 8.
ah, pole\[i\] = (char) rem? OK
Unity isn’t really just a game engine anymore... Update every frame is only performed on scripts with the Update method, so it can be completely ignored :) I made Holopipe, alone, for 7++ platforms, including hmd, phones, desktop, using just one build and one ui. Adaptive performance and ecs fixes the battery-hunger, as well as good code. And optimization is a breeze with the profiler!
Somebody is actually offering long term mentoring for free (non profit)? Pardon me if I didn't understand that part.
We are a global hedge fund hiring a full-time junior .Net Developer. Please PM me with your résumé and contact details if you are interested. New York City based. \- Member of the 5-person core technology team, responsible for the architecture, implementation, and maintenance of the fundamental components of our proprietary technology. \- 2-4 years of experience preferred. \- C# required, JavaScript or Python a plus.
The common sense part is where it all fails. A model where the user is less likely to screw up *is* safer.
I have my doubts about this but maybe its just me being cynical
 Jon Skeet on async https://codeblog.jonskeet.uk/category/async/
Thank you for using the free mentorship program, brought to you by taco bell. If the taco doesnt ding, then you get a dong. Please ask your question. //Question... Before you get that answer, please enjoy this short video about our favorite hamburgers at carl's jr..........
Yep.
Why?
&gt;Uno &gt;Render Type: Pixel Perfect. The platform takes control of rendering and does not rely on native components to render. As far as I understood, that's wrong. They are using native UI elements. Put in a Textblock in XAML, it's a UILabel in iOs and a TextView iun Android. They do make it pixel perfect across platform though, but I know they are ways to use the native styles.
I'm not arguing that an app store isn't safer. My point is that it would be safer if they supported the uwp app model better without using the store, since using the Microsoft app store is not possible for every developer. For instance a vendor that sells hardware with software to support that. Using the store has two big problems: 1) giving away 30% revenue with no mayor benefit to the vendor, and 2) people without the hardware could get access to (buy) the software (for instance a competitor could analyse it). In this case there is already trust between the vendor and customer, https &amp; code signing verify that the software has not been tampered with, capabilities prevent access to stuff you don't want to share and clean uninstall makes sure you can easily opt-out if there is a problem. In this case the app store isn't that much safer. The same goes for publishers that already earned my trust, for example Microsoft/Adobe/Autodesk/Google/Valve. If using the store was (close to) free and I could decide who gets access to my software then it would be a no-brainer, but that is not the situation currently.
&gt; The app store is actually detrimental because it takes 30% of the revenue, and the side loading experience is very poor. It's not 30% anymore.
Removed: Rule 4.
Most, if not all, at least intermediate developers know that the best way to learn anything in programming is by doing; by testing. Courses usually only cover basics for this reason so you have something to stand on and not totally lost. "Intermediate" courses consists mostly of just patterns and/or basics in common frameworks, which can easily be found online and why intermediate courses aren't as common. If they aren't intermediate or above, should they really be mentoring? I'm not saying that newbies can't teach but the chances that they get and teach something wrong is way bigger. If they do and the client finds out the trust will decrease and so the services reputation. Long term mentoring would be the latter scenario, but if that's the case wouldn't just providing basics and telling them to improve by exploring by themselves be better? Or at the most teach them how to google/read docs? It would also let them deal with a lot more people. Long term mentoring is also very time craving, which is why it often costs money. Why are these people offering it for free? What are they getting out of it? If they are offering a non-shitty service it won't be easy and no one will do that for a long time without some kind of payback. While you might say "the growth of the students" that's not enough. If you ask any teacher if they would do it for free they would always say no, and those people are the ones most passionate about teaching others and about their growth. So what are they getting of doing it? Where does this come from? Those are at least my thoughts
I mean, if you don't have things that need to happen in parallel (for example, you're just synchronously using tasks), then there isn't really a point to using them. The only time in recent memory where I had to use `Task` was with the `HttpClient` class interacting with REST APIs.
&gt; giving away 30% revenue with no mayor benefit to the vendor It's not 30% anymore. https://www.windowscentral.com/microsoft-store-now-gives-app-developers-bigger-cut-revenue
The developing community consists of a lot of people who are willing to help others. In fact, teaching is the best way to learn. The tutoring/mentoring is based on an online course, we offer exercises, give feedback on exercises, answer questions, discuss about architecture styles or best practises, etc. We try to stay small - or at least to have the same amount of mentees per mentor. Therefore, they really get to know each other. At the end of the day the most effort is given by the mentees, not by the mentors. The mentors are just willing to give up some of their time to teach. Maybe in the future we could have other cool features of our discord such as challenge between mentors and their mentees, or bigger group projects. Knowledge is free.
I stand corrected on the fees, it is quite a bit lower now. For non-games 5% with deep link and 15% when customer comes from a promotion. Not clear for me which one applies when a user searches for your app in the store... Regarding side loading, correct me if I'm wrong, this requires the user to: 1) Enable side loading in the Windows settings under the option "For developers". 2) User must install your developer certificate. (done by next point) 3) Visual Studio only generates a Powershell script (Add-AppDevPackage.ps1) to facilitate the install, it doesn't provide a GUI setup. The script requires user to right click the script to run it. Compared to a standard win32 setup this is a poor experience in my opinion. Also the setup consists of many files, not a single file setup, so user must unzip the files first. If there is a better way I'd be very interested to hear it :)
You'll need to save the value outside of the program. Probably simplest is in a text file you can write on exit and read on open. Look into System.IO and StreamWriter and StreamReader classes.
Adobe XD is a full proper WinRT/UWP app distributed outside the MS Store, and the enduser doesn't have to deal with any of what you describe.
You have to declare variable "num" outside of method and assign value (0 ?). Your code likely does not even compile, right?
The use of a distrubution platform is not a "no mayor benefit". It is natural that the maintainer asks for a cut of transaction going through the platform they maintain. While you can argue about the size of said cut and the feasibility of business through the platform, I don't agree that having it or going through https sites is the same thing. A site can authenticate itself as someone else and you have to check manually to be safe, you're still in a generally dangerous territory. You can instead be much surer that ContosoAwesomeApp on the store is actually from Contoso. Discoverability of apps in a store vs looking through the web is also a factor, most importantly for consumers to find something that solves their need. So, they're very different thing. Having containerized UWP would be better then the exe wild west? Sure! But that is not an argument against the store.
Adobe XD download is an .exe file. I don't know if the app is uwp, but the installer is a traditional win32 app. So this breaks the benefits of the uwp model.
To me, Stephen Cleary is _the_ expert on async/await in .Net. His articles are gold.
Yup it doesnt. But I didnt assign a value yet, because it would reset the int to that value every time I run the program
If you can spend a few bucks, I highly recommend his cookbook (link available on his blog).
Not for coding, but I have 16GB for running virtual machines, docker containers and such locally.
You shouldn't be doing work on the ui thread at all. Async await is what you want.
My first question would be: why a laptop for coding? If you are so concerned about performance and capability to upgrade, then a desktop is a better choice. For half the price you can have a much better/performant machine. If you need a nomadic solution because of travel (or else), and since you are - by your own description - a beginner code, I would suggest buying a good desktop and a relatively cheap laptop/ultrabook. Do your main work on the desktop and use the laptop only when travelling, to fix bugs or stuff. Back to your question about RAM. Unless you intend to program application that needs a lot of memory (e.g. games, big data, etc.), you will most likely be limited by CPU rather than memory. 8 GB is already decent. Better save the extra money for something else.
No. Get what you can afford and go from there. Can't offer an opinion on that processor.
The app is full proper WinRT/UWP, but the installer is a traditional Win32 app yes, since it's part of the Adobe launcher thing. There is also that new MSIX format that's supposed to improve app distribution, but i haven't looked deeply into that yet.
I go to a high school where they teach coding and they said I must get a laptop for my summer internship. I go away from home pretty much every weekend which is why a desktop is not an option, even though I know how much better the price to peformance is.
What do you mean exactly by mentoring? A description of the process and the services offered would be nice. Currently, it just looks like free advertising, which I think is against the rules in that subreddit (even if your service is free).
Don't understand me wrong, I'm not against the store. But I think Microsoft is not making side loading easy and that hurts the adoption of uwp packages. In my case (hardware &amp; software vendor) the software distribution platform does not add a lot of benefits since we already need to distribute the hardware anyway. Software is the easy part. I think the store is mainly beneficial for discoverability of game and utility apps for a broad audience.
That's not enough. The key feature with an App Store distribution model is package signing. Creating an account provides you with a signing key or certificate. Only packages signed with said key can be uploaded to your account, and the key is used to validate that the package is downloaded correctly. When downloading the same key is used to verify that the package you've downloaded matches the signature on the package.
You honestly don't need a powerhouses of a machine. 8gb is more than sufficient for most applications
It's not necessary, but depending on what you do it can be hugely beneficial.
So I don't think 16GB of RAM is necessary for coding, you could easily accomplish the same tasks with 8GB. The difference is load/compile times. If you're running multiple applications, or have several chrome tabs open, or are compiling things on the fly (re: JS frameworks) then you'll feel the difference. That being said, I'm a software engineer and I've worked with an 8GB RAM laptop for work. It's doable. Try looking at refurbished laptops or even last year's, or 2 years ago, Ultrabooks. Having a 6th, 7th, 8th gen it won't make too much a difference. And it'll save it easily a few hundred
No
so instead of asking on "programmers hangout" on discord or here on reddit or on stack overflow where thousands and thousands of skilled people can give you input, you offer me one dude?
But by using win32 you lose the promise of the app being limited by the security system in uwp and clean uninstall. Then why even bother? I am aware of msix, that looks pretty cool but haven't tested it myself either. Not sure if it could wrap the uwp install. It is actually quite opposite to making uwp better, it is making win32 have some of the uwp benefits. It is much appreciated tech, but also one less reason to choose for uwp.
It depends on your stack. If you're thinking of using typescript, dotnet, and have a medium to large database on 8gb, memory will quickly become your bottleneck. I know because I had to upgrade to 16gb myself.
How do you use visual studio professionally with only a couple gigs of ram With only firefox and steam open (no games) (plus virus scanner) i'm at 5.5 gigs being used....add sql server into the mix,a couple VS instances,np++, a ton of stack overflow tabs... I just don't see how people can program so little ram, has to be killing your hd lifespan
Since the variable is a local, it won't even save it between clicks.
There are plenty of reasons for choosing UWP. https://www.reddit.com/r/Surface/comments/bmjwkm/microsoft_says_its_still_fully_supporting_uwp/emzgz87/
It still repaints the screen, doesn't it? Render-by-damage (where only the parts of the screen that changed get repainted) is a pretty hard problem, but desktop UI APIs are designed around it. Have engines are not because they almost always need to repaint the screen anyway (imagine turning your head sightly in an FPS - even though nothing has really changed, nearly every pixel of output has, and figuring out exactly which ones would be more expensive than just repainting the ones that haven't too.) But when it's a pretty fixed UI that knows exactly what it needs to update and exactly when (like repainting a textbox - or even the spot occupied by a character - on the value changing) that's much cheaper. And actually, the app can go completely to sleep and wait for the OS to notify it of events until there are some, whereas have engines typically don't use eventing the same way (they actively poll the current input state every frame, typically with a lower latency API like DirectInput.) All that to say - yeah, Unity is great, and sure it's heavily optimized for its purpose, but that purpose is geared toward hard problems that require intensive resource utilization, and it's likely to be much less efficient at softer problems than platforms meant for them would.
This isn't for questions, but for following a course, making exercises (we provide), getting feedback on your exercises, discussions, and much more.
You can Code with 8 Gb of Ram but you should know : Windows Regulates the Ram ussage with percentece. example : &amp;#x200B; OS takes 15 %; Services 10 %; visual Studio 35%; Debugger 10 %; SQL Server 10 %; word 10 %; reserve 10%; &amp;#x200B; So it does matter for the Performance. I when I worked with 8 GB i had an avg usage of 7.5 GB. Since I have 16 GB my Memory usage is by 9 when I start Visual Studio and when I work it's avg 12 GB
I use a Dell Inspiron laptop with i3 processor, 4GB RAM and 1TB HDD. This is what I use routinely: 1. Dual booting with Ubuntu (Linux) and Windows-10 installed on 2 different partitions, I mostly use the former for software development and latter for gaming. The third partition is for data. 2. Have installed multiple stacks such as LAMP (apache, php, mysql), node/npm, java/maven and mono (csharp), git, google apis, etc. All working happily in buzzing speed! 3. Running docker and VirtualBox too (laptop has hyperv support but its fairly common these days, I think). 4. Use GIMP and Inkscape sometimes for image editing and they also work without any problems.
In win forms you can save things into the app settings. Search winforms application settings.
I meant it more as the instance of VS only needs a couple gigs. I guess I meant to say that 8GB would likely be fine for a high schoolers computer
Unless you'll be running _a lot_ of background processes (or a Google Chrome with 20 tabs), then 8GB won't be much of a problem. If I were to invest into something, I'd look for something with an SSD, to keep the OS, VS and projects on that drive. The quality of life improvement (launch times, compilation times, etc.) is amazing, you'll be spending a lot less time looking at the screen doing nothing. As for the CPU, 8th gen i5 is a very solid pick, it would last long even if you were building a gaming PC. Just make sure it's not the low-voltage version (names ending with 'U', like i5-8250U).
 It will all depend on what you want to work in. Are you in college or university? Learning on your own? What area would you like to program in?
Through the last couple of years, I've been through this exact journey, and I completely know how you feel. It was a paradigm shift for me as well, and those are hard, but worth it. To answer your questions: _What is event sourcing?_ Basically it's about storing *changes* to state instead of just the *current* state. _ES libraries for .net core?_ I've used CQRSlite because it is simple and maps well to many explanations of ES. It's database agnostic, so you'll have to implement your own IEventStore. I used another library called Marten, which itself also is a full fledged event sourcing library. I've stuck with CQRSlite because of it's simplicity and nice abstractions. _Where do we put the code?_ With CQRS/ES in an aspnet project you need to get a whole bunch of boilerplate infrastructure code in place before you start feeling productive. From there, little code lives the aspnet controllers which is simply a http boundary (as opposed to for example a message queue boundary). Most code lives in one or more domain projects which have very clean cut boundaries and knows nothing about infrastructure implementation details. _ES example projects?_ Yes many, but they all have different flavors so none of them look alike, which make them hard to learn from, in my opinion. Best bet here is pluralsights courses. I liked Dino Esposito and Vladimir Khorikovs courses on that topic. _Are we supposed to use EventHandlers?_ Yes, those are used at the message queue boundary (even if it's an in process queue) and for projecting events into your read/query models. _Observer pattern relation?_ I haven't found any relevant application of the observer pattern when using CQRS the way Mediatr and CQRSlite does. I hope that makes sense. If not, let me know and I'll try to elaborate.
Buy whatever amount of ram you are comfy spending. If you go by "what do I need?" you will inevitably need more in the future.
updated
so in general, i can replace you by a book, a course or even a website
Last year I was in the same dilemma; I end up with Dell Inspiron 15 7000 with 8th gen core i5 and 8GB DDR4 (single dim) and 250GB solid state. I bought one laptop that will allow me to upgrade RAM in the future. So far I don't see my self upgrading my RAM. Here are my results how end up with this laptop. I wanted something &lt;$1000 dollars. The only option in Apple was MacBook Air, which was out of question due to outdated spec. &amp;#x200B; My usages was going to be learning Windows Development Java or/and C#. I mostly do book examples and/or Pluralsight courses. I had no intention to use to produce money (if that's the case I would buy a desktop). &amp;#x200B; HDD Size: At my work I have 250GB solid state and I never needed to update it. So I know 250GB sufficient for my usage. &amp;#x200B; Processor core i5 8th Gen I learn that 8th gen process double the tread and i5 was sufficient for my needs. &amp;#x200B; Memory 8 GB DDR4 This was a bit concerning but I did enough research and reached the conclusion that I will buy 8GB which can be upgraded to 16GB. &amp;#x200B; So far I have been running 2-3 Visual Studio Communiy 2017 instance and don't see any issues. I have also use Intelli J and VS studio and VS studio code side by side. &amp;#x200B; So far I have been happy with this laptop; the original cost was 1000+ but I bought using 10% student discount while on sale. So it saved me \~350 dollars. &amp;#x200B; I would suggest buy a laptop that you can upgrade HDD and RAM with 8th Gen i5 or i7.
Individuals coded for like a decade on 640K ram. So no, it is not necessary for coding. Having extra RAM is often a crutch that allows companies to reduce the cost of developing applications. Instead of spending hundreds of hours to optimizing routines and algorithms so that they minimize memory consumption you just throw more resources at the problem. This means that applications in general are bloated but from an economics perspective it makes perfect sense.
I’d go for 16GB and a slightly larger laptop if that’s an option. Chrome with a few tabs easily eat 8GB of RAM..
Light, powerful, cheap..pick 2 In other words don't get an ultrabook unless that's more important to you than power and price. Limiting yourself to 8GB is not a good choice for coding in general unless it's just going to be a hobby.
Chrome is a beast whose eternal &amp; everlasting hunger shall never be satiated.
Well, depends. If you are OK with using a lightweight text editor like VS Code, you don't need it. However, if you like IntelliJ's products GO FOR IT. I used to have an 8 GB computer and it always lagged on IntelliJ In my opinion, Jetbrains products are much better because of all their features and their autosave.
This may not be quite what you want, but I code all over the place... by remoting into my desktop.
If you plan on using visual studio with moderately large solutions, then yes.
I'm using 2 different computers for work. Both have similar processor and SSD drives, one has 16 Gb of RAM and the other 8 Gb. I don't notice any difference between the 2 and get the work done. Get a cheap refurbished computer and pop an SSD in there, which is much more important IMO.
Check out, [https://cqrs.nu/](https://cqrs.nu/) , contains a complete sample for a CQRS, Event-Sourced system including a unique testing framework using the BDD given-when-then notation.
This is probably the easiest and quicket method to solve your specific problem. However, once you want to expand the amount of data that you want to save outside of an application lifecycle, you should research "persistence". examples include but are not limited to: databases, sqlite, writing to file.
I'm actually curious why they don't push Unity as an app-making platform. Seems with a bit of retooling, stripping down features... could work pretty well.
Depends on a stack and workflow. If you're doing some python scripts in vim you'll be fine with much less than 8 gigs, if you're doing java/.net with say intellij/visual studio with some additional things running in the background like mentioned in this topic docker, database management tools and whatnot, have lots of browser tabs open, you'll need more but still if you take it easy this kind of development can also be done with 8 gigs. You can upgrade if a need arises. So 8 would be fine, 16 is preferable in my opinion. Whatever you go for get an ssd though.
This. I've upgraded to 32GB ram because I'm constantly running virtual machines locally. So my opinion is 8GB would definitely not be enough in some scenarios.
visual studio is limited to 4 gigs of ram usage because of 32 bit architecture
Not a requirement. Can it make some things more convenient when trying to run many things at once? Yes I use an 8th gen i7 with 16gb. I like to have the ability to go nuts, but not necessary to get the job done.
I'm using unity and visual studio 2019 and 8 gb is fine.
I have 16gb in my Dev machine. Really required when you have severall iis sites, VS, SQLMS, Outlook and chrome all running. So not really for coding but for running my local environment yes.
Lol a few tabs
No SQL server on the local machine, I mostly only have one VS instance only (very rare when opening two), no np++, and rarely have more than ten tabs opened. It can be done, especially for OP who want to use it in high school, they won't do anything like this.
yes
It really depends on what you are coding with and the size of your projects. For small beginner stuff 8GB is plenty, I'm running 8GB on a laptop with a dual-core 4th-gen mobile i7. I use Visual Studio, Android Studio, Netbeans, Brackets, and run GIMP and a few other things on it. It does pretty well, but compile times are pretty nasty compared to my desktop, especially Android Studio Gradle builds. It's still perfectly usable though, the interface is responsive and I don't have hardly any trouble. On the other hand if you are working in SQL (or any database really) and making a huge number of entries 8GB might become the absolute limiting factor. I run a copy of Windows Server in a HyperV VM for my SQL database, and I allocate 16GB to it at all times, 8GB became a bottleneck on it after awhile.
If your tight csnt run the game, neither can anyone else. Most people dont have 16 gigs of ram. Code to the standard.
Sqlite. You can run it in memory with your application. If the list isn't very large, json file using newtonsoft
Closures, learn them
The 30 tabs of stack exchange that are open...
Database is generally your bottleneck. For dev, yes I feel it's warranted. For actual production, you shouldn't need that ( assuming your db is on an independent server) unless you're serving millions of users
What model are you looking at?
Being new to all of this, the app settings seems like the most straightforward option until it becomes a problem.
Yes you can get by with 8Gb...but it's worth checking that your laptop has free slot(s) so you could upgrade in future. WAY MORE important is ensuring it has an SSD...even if you have too little RAM it at least ensures 'paging to disk' is multiple times faster than an HDD. One tip right now is buying a minimum RAM and SSD laptop (so 4/8Gb &amp; 128Gb SSD) \*ensuring you can upgrade\* and doing it yourself; RAM and SSD prices are super low at the moment so you can get a great deal by doing that.
Package signing....you mean the same exact feature that executables already have? When you install something, it tells you who built it (if properly configured). That’s using the MS package signing server for verification
Depends on what you want to do? Running docker containers? Certainly yes. Running VMs? Yes also. Running databases - also yes! If you just do some client/server application or web dev - no.
Don't use Chrome?
Just max it out.
Like everyone else said, it really just depends. For coding itself? Not really. If you're processing large amounts of data with your code? Probably. When I first started at my current company, I was writing scripts in Python to download/format/output large volumes of data (datasets were over 6GB on disc). Before I figured out how to paginate the data when downloading and before I did memory optimization, I would sometimes see as much as 12-13GB being used by the system. If I didn't have the space to handle that, it would have made developing the final script more difficult as I would have had to worry about optimization before everything was functioning.
!!!
You can get away with 8 but i personally would go for 16gb At the moment my laptop uses 13,4gb I’m using xcode+iphone simulator Vmware fusion(win10+ visual studio preview) Fusion360 And mysqlworkbench Normally I also have Visual studio preview for mac open
We need 16 gigs, but that's because due to circumstances, I need to be able to have Visual Studio Code, Visual Studio 2017, Sql Server Management Studio, and Chrome open. On top of the IT's choice in Anti-virus and patching taking up 20% of memory at all times. I'm fortunate that we finally got rid of the xproj projects, so I don't have to have visual studio 2015 open as well.
If you only have one copy of it open, true. Then there's legacy enterprise where you end up with two or even three of it open, and weep.
No, it doesn't. But it *could* look like it does because of **memory compression**. Windows regulates the RAM usage by compressing memory when needed. This takes performance, of course. My own example: Had 12 GB ram on my computer and everything i needed: Big VS solution with 5 asp.net projects and a bunch of class libraries and tools, firefox, chrome, music player, nodejs, mysql, iis express, etc.. All this took 10 GB and a big part of it was compressed, according to task manager. Upgraded to 32 GB recently, and the same workload only takes 14 GB (and only 80 mb is compressed now). It didn't scale up in percentage. Btw, there is also a big memory usage improvement in VS2019. Started them up and ran the projects, VS2019 only took half as much memory as 2017. Even more performance by turning off various extensions and features. After I did that the same workload runs fine on my Surface laptop (8 GB ram, i5 cpu) too, but it eats up my battery. I try to stay on VSCode projects when on my laptop.
You can never have too much memory or storage space. *ALWAYS* max them both out, the preference being whatever cannot be upgraded later, having the highest priority. With that said, I have had problems with less than 16Gb of RAM when it comes to Visual Studio, especially if you want to run a lot of plugins. Virtual machines will also plump up your requirements.
Points 1 and 3 deal mostly with energy efficiency. While it is nice to have it is not really a selling point in my line of work. Suspending the app is actually more work for me since I must add the permissions and code to disable it during data recording and analysis. Point 3 further points at input methods and mobile devices. Touch/pen is not used that much on pc yet. Basic touch stuff works with wpf as well. Also .net core 3 apps get access to winrt libraries. If we want to make a mobile app uwp is not relevant, probably would create a Xamarin frontend on top of our libraries. Point 2 is moot since side loading without win32 installer is not feasible as discussed before.
This is probably the best answer, thanks!
Try it yourself at dotnetfiddle.net
Don't assume how I weigh anything, please.
Visual studio spawns a crapload of other services and programs though.
Show me powerful and cheap
The Visual Studio team talked about this. They intentionally are leaving it as 32 bit, because they can offload a lot of the additional workload to separate processes. Basically Visual Studio is now a collection of microservices. It's scales much better that way.
That is really hard to answer. You can do small projects and emacs + command line to compile and you can get by with much less. I remember doing that on hardware that people would laugh at today. Visual Studio is a beast, if you plan on using it you need some juice and ram. If you add something like Resharper and you want the UI to be responsive it takes more resources. Then you might need to run some kinda database and whatever middleware you need. Perhaps you run it directly or you might be running it under virtualisation or constainers Those need ram to run . I had a 16GB laptop at work and it is now getting replaced with a 32GB model. It was simply not enough for the work I do. But it involves running a lot fo containers, and a lot of unit test and integrations tests. I would not go lower than 16GB is you are doing Vs Studio development.
What do you think of the thinkpad E590? Is an i5 8565u sufficient or should I go with the i7 8565u? I don't think that the upgrade is worth it, and are the U processors with 15W sufficitent or should I look for the H series?
The method comment on the corefx github repository explains it really well: // Searches an array for a given element using a binary search algorithm. // Elements of the array are compared to the search value using the // IComparable interface, which must be implemented by all elements // of the array and the given search value. This method assumes that the // array is already sorted according to the IComparable interface; // if this is not the case, the result will be incorrect. // // The method returns the index of the given value in the array. If the // array does not contain the given value, the method returns a negative // integer. The bitwise complement operator (~) can be applied to a // negative result to produce the index of the first element (if any) that // is larger than the given search value. You can find the relevant source here: [https://github.com/dotnet/corefx/blob/master/src/Common/src/CoreLib/System/Array.cs#L392](https://github.com/dotnet/corefx/blob/master/src/Common/src/CoreLib/System/Array.cs#L392)
[Here.](https://dotnetfiddle.net/abU1AU) This return -3. How ?
I would say yes. Good luck running visual studio on a cheap laptop
It's necessary if you're like me and have 80 stack overflow tabs open
The array must be sorted, as the documentation clearly states.
Thanks, but the negative return is still a little unclear to me. Would you mind elaborating it with an example?
This is the part that you skipped when reading: &gt; This method assumes that the array is already sorted
I know you said it is too expensive, but if you can find an older 16GB RAM XPS that's in your price range 2nd hand maybe go for it. I'm not sure, I've just been using one myself and it's perfect, wish I bought one with a graphics card in it though at 15"
https://docs.microsoft.com/en-us/dotnet/api/system.array.binarysearch
Laptop manufacturers mark up the price of RAM and SSDs like CRAZY. My advice would be to buy a laptop that you can upgrade yourself. You’ll save money and have fun upgrading it! Search for ASUS F510UA on Amazon. You can upgrade both RAM and storage, and it’s a clean looking laptop. It doesn’t have a dedicated GPU if you care about that. Other than that, you can get an Acer or Dell laptop with GPUs that are reasonably priced and upgradable. I strictly buy ASUS laptops though, so I don’t have any experience with those companies. Good luck!
The documentation for the function explains how it decides which negative value it returns. https://docs.microsoft.com/en-us/dotnet/api/system.array.binarysearch?view=netframework-4.8 If it can't find the value in the array, it needs to return an obviously invalid value. Since array indices cannot be negative, that is *why* it returns a negative number. The interesting implementation detail is that the negative number has some additional meaning besides it not being able to find the item. It actually finds the index where that item would be if it *had* found the item. You can then bitwise compliment (~index) to make it positive and use that as the position to insert the new item if you need.
The U processors are dual core and H is quad. Take that into account
I did all my coding for a midsize C# project on a MBP with 8 GB RAM. I also ran VMs on it and it managed quite well. I previously had a laptop with 8 GB that I also used for coding (since upgraded to 16 GB). That said, I only got 8 GB for the MBP because they were already too expensive. If I was buying a laptop today I would definitely try hard to find one with 16 GB at a reasonable price. With PCs there are many options so you should be able to do so.
Check out “serialization”
[Here ](https://dotnetfiddle.net/JVEMxN) is another example of a sorted array. This returns -3. So I think I have figured it out. If the element is not present in the array, it looks for the index of the value which is larger than the given search value, and adds a negative before the index and returns it. I mean, in the above example. I tried to search 5 in the array. 6 was the closest higher value which is at index 3. So it returns -3. Is it? Or if we look from the end, 6 is at -3 hence it returns -3.
Async/await does not exist to achieve parallelism. It's primary use is to offload processing time from the CPU to the hardware servicing a unit of work. For example, async/await can be used to retrieve database records while allowing a UI to remain responsive, and without involving threads. I highly recommend learning how it works and why it exists - you will be a better developer for it.
I do know the how and why. I don't do UI work so I e never needed it.
https://referencesource.microsoft.com/#mscorlib/system/collections/generic/arraysorthelper.cs,211
This might be interesting to you: [https://docs.microsoft.com/en-us/dotnet/api/system.int32.tryparse?view=netframework-4.8](https://docs.microsoft.com/en-us/dotnet/api/system.int32.tryparse?view=netframework-4.8)
As someone who came from a traditional standard threading background to C#, I've found articles like [this one](https://blogs.msdn.microsoft.com/seteplia/2017/11/30/dissecting-the-async-methods-in-c/) that discuss in detail how `await` effectively cleaves a method into two halves via a small state machine has really helped my understanding. [This is another](https://weblogs.asp.net/dixin/understanding-c-sharp-async-await-1-compilation) great in-depth writeup as well. Lastly, [this](https://stackify.com/csharp-async-await-task-performance/) is a great writeup discussing these constructs from more of a debugging/profiling perspective (which was initially how I got into my personal deep-dive on the subject: debugging `await`ed code was infuriating as it never stayed in the same thread!)
Actually the new whiskey lake i5 is an eight thread quad core that boosts up to 3.4GHz with a 1.6 base clock while the i7 boosts up to 4.0-4.2(not sure) whit a base clock of 1.8. (Quad core aswell)
You clearly don't.
This may be your observation, but it isn't how memory management works. Applications generally either use memory or don't, but some will greedily consume more if it is available by caching things to improve performance. SQL server is the prime example of this.
Crutch? You look at it the wrong way. They had to be really inventive, and do a lot of cludgy workarounds, and cut their apps down to the absolutely minimum, just to be able to do very basic stuff. It isn't realistic today because you can't just throw any average programmer at the problem for X amount of hours to get a program lean enough to run on a 640K. And the kind of programmers who can do this and find it fun, there arent enough of them around for every software developer company.
Interesting. So with that approach it can go over 4 gigs? Can you point me to some materials about it, since which version does VS behave like that?
So basically one thing that you are missing there is that if you get inputs that are not integers, like "I think maybe four? Yeah, four" or "4.00" causes problems for your code. In simple case like this, you can approach this with something like if( diceThrow =="1" || diceThrow =="2" || diceThrow =="3" || diceThrow =="4") {dotheactualwork} else {handleanerrorsituation}, but obviously that only works when you have a **very** limited amount of valid inputs. Increase the number to even 10 and this becomes a big mess.
Keep it as simple as you can for as long as you can. If the list will be “small” (less than hundreds of thousands) then just use a text file. No need for even something as complicated as SQLite.
FWIW I hate programming on laptops unless it's on a desk. So IMO desktops are superior unless you have more than one desk to code at. I had no problem using 8gb on 64bit windows 7 for the past few years. I have VS, VS Code, firefox, chrome and discord all opened at the same time and memory usage is around 6gb. I don't have any databases running (if I do I use my VPS on a remote machine, sqlite is my go to database). Chrome eats up the most memory, this seems fine though. I suspect 8gb is enough unless you're doing some hardcore things
One thing I'd suggest to do from the very beginning is to use functions. For example here, try to create a function that actually handles the valid case, like for example void handlevalidcase() { PrintColorMessage([ConsoleColor.Red](https://consolecolor.red/), "Kasta minst en tärning(at least one dice)"); return; } This helps you to concentrate on one task at a time. For example here, you have a couple of tasks: Verify the input, Handle good input and Handle bad input. It also helps you to test the code. And if you feel the code file size gets out of hand, it is very easy to move them to a different file, class or even a different project.
Everyone is saying no but I just upgraded from 16 to 32 gb. 15 was doable but I'm usually using around 20GB. Visual studio plus sql server, no VMs. It's a largeish solution though. Depends what you're doing.
&gt;int numberofdice = 0; &gt; &gt;string diceThrow = Console.ReadLine(); &gt; &gt;numberofdice = Int32.Parse(diceThrow); &lt;-- i was thinking that this already made it an int. Or am i wrong?
I run 8GB and am fine
It makes it an int \_IF\_ the input can be converted to an int. This parse throws an error, but that tryparse allows you to handle an invalid input without actually making exceptions.
Yes. Why? - Chrome (with many tabs and some YouTube) - Spotify for music - Slack (which is basically chrome) - word/excel or libre office - visual studio with extensions - resharper - vs code (which is basically chrome) - azure data studio (which is basically chrome) - SSMS - onenote/evernote for notes - notepad++ for log viewing / file parsing - kdiff3 for diffs - gitextensions for git - powershell / cmd / cmder - outlook And you are done. I have constantly occupied around 11GB. Of course I can close apps to save RAM but it is inefficient and time consuming. PS nowadays phones with Android have 8GB. I would go for minimum 16GB RAM. It's now worth to bother what app should I close to run this elastic search locally (recommend 2GB of RAM ;-)). PS2 I've didn't mentioned any docker / vm etc.
This is almost exactly my stack and 8gb is by no means enough. It will easily gobble up 16gb but is at least usable.
So it should look like this? Which i understand like if not int output message, if int continue as usual? if (!int.TryParse(diceThrow,out numberofdice)) { PrintColorMessage([ConsoleColor.Red](https://ConsoleColor.Red), "Mata in ett nummer(insert number)"); }
It depends on what you're developing. If you need to run hardware emulators or run a lot of VMs to test your work then probably. Otherwise 8 should be fine.
I have recently updated my compinfo project... [Display basic computer info](https://github.com/jftuga/compinfo)
SharpDX works great if you wanna go low level Direct3D. D3D is all about speed and not ease of use, though.
Closures are not the solution to his problem. Serialization and persistence.
Yeah, try to also add that else-part there and test with something good (like "1") and something bad (like "thisisnotanumber") Also, try to - just to test it out - get rid of this line: string diceThrow = Console.ReadLine(); Can you do the same thing with this if (!int.TryParse(Console.ReadLine(), out numberofdice)) Whether that's better practice or more clear is a different subject, but still. At least you'll see whether it works.
That's is what they said. I must be wrong and I will correct what I have said when I have more time.
Chrome will hoover up 8GB if it thinks RAM is just sitting there unused. Chrome will also run in low memory environments just fine.
I recently heard about this when reading about resharper performance. Here's the article I was reading. https://blog.jetbrains.com/dotnet/2018/05/29/taking-resharper-process-resharper-performance-series/
Most of that RAM will be used for 30+ open Chrome tabs..... lol
You don't need to return on a void method, btw
Yeah. I run the dotnet react stack and some other projects simultaneously. These processes (electron, browsers, typescript, dotnet, node) will request tons of memory overhead, making it look like they're using a significant amount of memory, but the various processes will generally give it right back if other processes come along requesting memory. If you don't push 80%, memory is not your bottleneck. If you go over 80% regularly with this stack and 16gb ram, I'd be concerned. That doesn't count the docker process, which you dedicate a specific amount of memory when it starts up depending on config.
It depends. If you want it to last for several years, its inevitable that you will grow into larger projects, so I recommend the 16gb if at all possible. The processor should be fine for most tasks.
I would definitely not get an ultrabook for coding. I would recommend a 17" laptop, or 15" at the very least.
I can do medium sized projects with 8gb fine however this is without resharper installed.
Maybe this code snippet will help you with the negative value: var data = new[] { 0, 10, 22,67,120,300,543}; var indexOf120 = Array.BinarySearch(data, 120); Console.WriteLine("Position of the value 120: " + indexOf120); var indexOfValueLargerThan140 = Array.BinarySearch(data, 140); Console.WriteLine("Position of the value 140: " + indexOfValueLargerThan140); Console.WriteLine("Position of the first value greater than 140: " + ~indexOfValueLargerThan140 + ", value: " + data[~indexOfValueLargerThan140]); As you can see you can use the operator \~ on the negative value to get the index of the first element in the array which is bigger than the value you searched for. Because of the way binarysearch works this information is already available when the value cannot be found and this information might be of use to the caller of the method so the method doesn't return a fixed -1 like other search methods do when a value cannot be found.
welcome to the journey!
I would say yes unless you are doing light coding. I regularly run multiple instances of visual studio which eats up 8GB RAM very fast.
Well, we are working with multiple APIs running in Visual Studio as well as the front end running in VS code. Say 4 APIs with the UI and chrome completely wipes out my work desktop CPU &amp;16gb ram. As an alternative, we use a server and run the APIs in IIS and deploy whenever we need to test something properly.
I'm overall with you, but that last line is completely incorrect. The 8th Gen was when they went from dual core on notebooks to quad core. Massive performance boost, especially for running many things at once (ide, node, browser tabs, etc). I'm using a 7th Gen notebook at work and the compile times for angular are terrible if there's a few other things running (even something as simple as running a YouTube video while compiling will double compile times due to lack of cpu cores)
Ehm... Citation?
There really isn't a better option these days. Firefox is only marginally better
Everyone will say 8 is not enough. However, if you're creative and offload stuff to cloud, there's no reason you can't run most of your development on 8GB. Yes, visual studio is a little big, but it front loads a lot of stuff so most of the work is done on project load. It's great to have enough money to do the big machine, but I don't think it's absolutely necessary.
Hmm. Yeah I think you are right. Does normal C require it?
Nope.
16? we run 32 GB at my job...
Will you use resharper?
Check out Brave. It's based on Chromium and it's a lot leaner than Google Chrome. Their mobile apps are solid too. https://brave.com
Yeah you're def gonna want an 8th Gen unless you're willing to get a ultra thick workstation type laptop of an older generation. Any reasonably recent 4 core Intel will be great. 2 cores is a bit limiting though so avoid that. As for the main question, you're really gonna want something upgradeable. 8gb is a minimum these days with 16 being the recommended for dev. If you expect the laptop to last a few more years you might need to upgrade to 24gb or even 32gb at some point in the future so you'll want something you can upgrade. At the very least get 16gb now and it'll still be usable in a few years, albeit not ideal.
Not so bad with 1 solution. If you are working in more than 1 then only having 8 can become a real annoyance
I've checked it out before, haven't used it in a while though so I'll give it another shot
Don't mess around with memory or processor power--your time is far more valuable than a laptop. Building contractor's don't show up to work with wimpy tools that aren't powerful enough for the job. Get yourself the proper tools so that you are not hindered by your hardware. And no, I do not think 8GB of RAM is nearly enough to develop with visual studio. Sure, it's probably fine for a single instance of visual studio with a small project open but any non-trivial project will require multiple visual studio instances, resharper, 20+ open browser tabs, IIS, SQL Server Management Studio, and other third party tools, not to mention Outlook and other office apps. 8GB just simply not enough to run all that. 16GB is the absolute minimum required to be productive while developing on windows IMNSHO but you'd be better of with 24 or 32GB.
I have no idea then where I got that one :)
Are you doing backend stuff only? If you've got your backend running in an ide, with angular running too and linters, 8gb gets really tight. With a bare minimum on my setup I'm at 80% ram (out of 8gb). That's angular cli, dotnet core backend running from cli, neovim with ale linting, and 4 chrome tabs for my email and the web app. If I open a few stack overflow tabs or documentation I'm screwed. Note I'm not even using an IDE in this instance and it's that tight. You're really gonna want the headroom.
Doesn't Unity have a pretty steep learning curve?
Define way to expensive? What exactly are you looking for? As most have said -- it depends on what you are working on -- but I see zero reason to not get 16GB of ram. Having more is almost never bad. I've been using 32 for a long time in my laptops. While it isn't required to have 16GB I would say that 8 is the minimum and 16 is a base recommendation. Not a laptop but my current desktop has 64GB. My current usage is ~25% and I only have 6 Chrome tabs open! I do also have 2x IntelliJ, 2x Visual Studio, and 3x VS Code windows open. I am not currently running any containers or databases locally. My machine is basically idle right now with a twitch window running as I type this out. So take that into consideration; your machine will use as much memory as you give it. Having more is never a bad thing.
Sometimes teachers will insist on having a return statement in the codebase, just for their own sanity. Maybe the place you learned from taught that as a "good practice" or something
Don't know your budget; but you can get a Carbon X1 6th Gen today /w a i7-8550U, 16GB of ram, and 256GB SSD for just shy of $1400 with coupons and stuff.
I saw it and It's so shitty that I have the 1400$ for it but I live in Europe and after tax it would go up to 1890 which I can't afford. Too bad it's not upgradable so I could get the base model eith 8GBs and upgrade it later on :/
I would not recommend less than 16GB for doing anything more than local coding (not running any service like NodeJS or TS compiler). I wouldn’t recommend less than 16GB for pretty much any reason if for no other concern than future proofing.
It depends on what you are doing for sure. But it is also important to understand that most stacks will use memory if it is available. .NET for example will use GBs of memory for a simple app if the machine has 512GB of RAM (trust me I’ve seen it). As soon as memory pressure comes in, apps might (and should) start to release memory.
I’ve learned that I almost always have decent internet connection. That means you can setup a Remote Desktop solution with a really solid desktop and just have the laptop act as your terminal.
It's possible, yeah.
Did they? I was under the impression it was using native controls underneath. At least, that's what I understood. I may well be in the wrong.
I sometimes run multiple instances of visual studio, and along with vm's that can chew up your ram really quick
Depends. I've been developing a UWP music player app with a sql database on my old surface pro 2 with 4gb on ram and a 128 ssd. Compiling takes forever and the fans spin up while debugging, but it's totally doable if not a super great experience. 8gb should be fine for a little bit longer, especially if you have a nice NVMe ssd to use the swap file on. 16gb would be nice and future proof, but if I'm on a tight budget, I'd be ok with 8gb.
I have 16Gb in an I7. Running angular(Ionic) + jest and vscode sometimes feels slow...
Was going to suggest this same thing if no one else mentioned it. I use an old Acer Aspire 5535 to remote in, and it's seamless and doesn't lag at all. It's also way cheaper to build a nice desktop than a nice laptop.
Also working with that kind of stack, I've seen it climb above 20 Gig. I'm never really monitoring RAM usage, so the average may be above or below that.
I thought the issue was scoping and that's why the var was getting reset Edit: there is also the problem that the var is never initialized
When you have 50 chrome tabs open, an IDE running, and a vm with several services running in background, you know you are doing some serious development work. And ram is never enough, 16g is minimum.
I used a 4GB laptop for a year and it was fine, DDR3 not sure what speed but probably less than 1600mhz
You should have read the title before being snarky. This is a starting programmer who just wanted to know how to persist data outside of the execution of their application. You then replied with snark, with the wrong information. Please treat your fellows with more kindness, they deserve it, and so do you. We're all learning together, we're just at different places.
That was a phenomenal resource, thank you for the link.
Be careful with discarding it right away. It is after all, just a part of the application And who knows, maybe if you've made your mark on the product, you/the team can propose to bring this to the next level using a more up-to-date tech. On an additional note: Winforms is easy and clean. If the customer is happy and doesn't require the added value of a more modern UI, then that's also fine. You probably have to ask yourself what direction you want to go. Full-stack, backend, frontend, cloud, ... Just remember; it should increase your knowledge. If it doesn't, then don't do it, unless you're just getting started as a contracter. Then just have the starting cash can help you on your way. Anyway, just my ramblings. Not sure what they're worth :P
Its really not that bad. I use a 5 year old laptop i5 and it's totally fine. 1 or 2 seconds doesn't have me in an anxiety attack.
I have done some backend stuff and done .net core projects. I mentions my usage is learning purposes. I normally have 2-3 ide instance running, few powershell session opens with chrome with 8-10 tabs. My memory usage does go above 80% but I don't see my laptop struggling.
???
People seem to be saying that 8gb is enough if you are willing to offload stuff. However don't forget you want to futureproof your machine, and ram will always be your bottleneck in the future. Get as much ram as you can.
Consider putting your setting loading/saving methods in an interface, so you can easily switch out the method of persistence in the future. Might be a useful application to learn the benefits of interfaces!
You could code some very big things with 16GB of ram. &amp;#x200B; Or a simple website which has to run a webserver, database, web browser, and your code editor all at the same time might start to overwhelm it. &amp;#x200B; Since 16GB isn't super expensive I would go ahead and find something with that much, or at least that is upgradeable.
Depends on your tool set. Are you going to use the full Visual Studio or VSCode? What about reSharper? What support apps will you have open regularly? &amp;#x200B; I use Visual Studio with reSharper. Typically I'll have a hand full of browsers/tabs open, SSMS, 2 instances of Visual Studio, one or two instances of VS code or Notepad ++ (just depends), and the typical Outlook and Teams open. I have 16GB with a quad core i5 and it can lag significantly at times (though I'm not sure if it's my software or the crapware my company adds for "security")
Btw, WinForms can be designed in a modern way. Idk what this 'modern ui' fuss is about. WinForms is modern. It's just that it uses a different rendering algorithm (GDI) than WPF. Also the development of WPF is more ordered and structured than WinForms. However, WPF takes more development time and requires more skills in different areas because it uses MVC type approach. // Start: Rant // Stop pointing out WinForms aren't *ModernUI*. The user interface is as modern as WPF in terms of looks and their moderness depends on the developers. WPF can be made as crap looking as it gets, and vise versa. WPF also renders faster and is better in terms of structured development, less so in development time. **Don't spray out terms like 'modern ui' 'better' etc without writing your reasons to write so** This shit gets annoying when everyone jumps on a boat and starts saying WinForms ain't *ModernUI*. What the fuck do you mean by *ModernUI*. Is it the UX, is it the way UI is maintained, is it the rendering algorithm. If it's UX design, then WinForms is modern and perfect for prototyping basic ideas, not interactive design, but basic design prototypes and applications. WinForms is also harder to maintain of it's big application. // End: Rant //
The coding IDE can also consume a lot of ram, I visual studio with resharper is easy 8GB alone, and the you have all the other tools running too, not even to mention browser with all your stackoverflow pages.
I code on Linux, 8 GB is an overkill for me. I need to have multiple containers running and about hundred chromium tabs to run out. I usually use around 4GB. My setup is pretty bare bones though.
Once they authenticate, you have their identity. From there, you should allow them to change their details since they’re still authorizing with their identity. Depends on what auth flow you use and what auth framework you use.
If your memory is going above 80% regularly, it means windows is swapping. It can swap quite quickly on an SSD so you might not notice it but things like quick app switching and such will be less responsive not to mention the wear you're putting on your SSD by swapping.
Older tech works. It's been tested. It's older technology and older code, but Source code doesn't rust. It still needs to be maintained, and customers and people using it need/want new features added to it. A lot of people are dedicated to always using the latest tech, and seemingly ignoring, and telling people to ignore, older stuff. As if older technologies, platforms, and frameworks have cooties or something. As If somehow, the moment X+1 dropped, X became unusable. Funnily enough, Oftentimes they aren't the people maintaining it. a new tech comes out, they realize the current one at their job is boring, And they can't convince those dumb managers that they should rewrite the entire 5-million line codebase to use the latest whizbang technologies and frameworks. So they find another job using it, They work there for a while- then a new tech comes out, they realize the current one at their job is boring- and so on. They are constantly "moving on" leaving behind code that *somebody* needs to maintain. They have their "Eureka!" moments, then move on and leave other people to deal with it. Frankly, I think they don't actually give a shit about their users. It's all about chasing that next big thing, that next "rush" from when they finally understand a new tech. Some projects are too big in scope to properly "upgrade"- you'll just constantly be playing catch up. Where I work we are still basically working on a "rewrite" that *was started in 2001*. The company itself has been around since the 80's. They've lost count of the number of upstart competitors sprang up and died. They inevitably see our niche, see that our current software is Windows Forms, and figure customers will jump at anything using WPF or UWP or a web app/app, etc. But they forget that the software needs to actually *answer the needs for the business*. We still have many customers using our *OLD* software- and when I say old, I mean, it is written in BASIC and is accessed through a text-only terminal. You think we haven't tried to convince them to switch to our software, which can migrate everything to the new product? And these fucking kids come in with a web app and don't understand why they don't want to buy their product, pay them support, manually re-enter 50,000 items, oh and we don't have X,Y,Z and 12 other features you consider absolutely critical for your day-to-day business, but our software uses react.js and is a responsive web app, so we know you'll switch from that crusty ol Windows Forms programs you are using... Where are you going? I can only imagine them commiserating later. "What happened guys, it was like they didn't CARE that Windows forms was old? How come they didn't start clapping when we said that our software used Modern UI? " Those new companies all misunderstood what business customer's need. They need software that helps their business run. That's it. That's all the matters. Even if there is a way of migrating their existing data and it supports all the same features, they aren't going to buy a new system, switch everybody over to it, retrain staff- all because "your current one uses older tech". For fucks sake we can bring over old databases and implement most of the featureset of our old software, (Function keys often do the same thing in the same modules, etc.) And we still have a hard sell to bring our current customers to the new system. I can only imagine these fresh devs going in for their proposal/demo, seeing that the company's current software is some text-only terminal and expecting an easy sale. "Do you support Shortbuy? what about understock? Can we freeze inventory by department? what about by line code? Can we mark items in an order and being back-ordered and then later have the system process and create Purchase Orders automatically? What do you mean you don't have purchase orders. Get out of my office. F1 doesn't go back? Yes normally it is for help but we use it to go back. We need that. You don't have it? You're dead to me. Watkins, throw this dead body outside for me please before it stinks up my office" That is not to say that software should stay the same forever- just that at least in terms of business software, it should be primarily guided by user needs and wants. Usually that "latest and greatest" framework happens to have the least testing and is largely impressive primarily from a technical standpoint, but not necessarily in practice.
No I was terse. There is a difference. Why should i eli5 it when there are a million better explanations of it available. I gave them a valid starting point. I was simply talking about a different issue than you.
Honestly for c#/.net I would go for 16 if possible. Even with 16gb visual studio sometimes lags and running VMs and docker images can be taxing on an 8gb system. If your goal is to keep this machine for 7 years then get as much RAN as you can afford.
Others have linked the msdn doc page. The reason why something is negative is sometimes you want to find the closest number that isn't over and sometimes you don't (positive value). Lets say you have a text document. Some lines are longer than others. Maybe you have a list that has the offset of each line (ie "abc\n\t\n" 3 and 5 would be the offset). You might want to search what line a specific word is. This would be a perfect use case for binary search and obviously a word isn't a newline so it'd never be in the list (and always return negative)
Even if you don't use it for current tasks, your system uses it for tons of tasks.
Where I am at right now we don't give out machines with less than 32gb. I couldn't imagine coding on 8gb, Def upgrade to 16 if you can
In the good old days 16kb was good enough for any ZX-81 programmer. Hell! Even 8kb was plenty. 😁
You could add Id of your user to jwt token as a claim : see this: https://github.com/ActualDennis/VibeChat/blob/master/VibeChat/VibeChat.Server/AuthHelpers/JwtHelper.cs Then your claim may be accessed in your controller via User.Claims.
&gt; The Visual Studio team talked about this. They intentionally are leaving it as 32 bit That's… kind of a positive PR spin. &gt;they can offload a lot of the additional workload to separate processes. Basically Visual Studio is now a collection of microservices. It's scales much better that way. Sure. What they're doing is moving work bit by bit into their own processes. At some point, this will probably flip: the core UI shell will be much simpler to port to 64-bit, and the remaining 32-bit-specific code will instead get loaded into one of those temporary processes.
As someone who runs VS in an 8 GB VM: if you need Visual Studio, you can get by with 8 GB, but 16 will feel much smoother.
An argument for both sides - https://www.howtogeek.com/200334/windows-10-includes-a-linux-style-package-manager-named-oneget/ - nuget is coming to desktop outside visual studio/windows are going to get package manager. Best of both worlds - customization options and no store nonsense from standard setups like msi/inno/whatever you use currently and verified source of signed stuff just like your average app store...
It's not the web browser that causes these problems, it's websites. If you open chrome's task manager (I imagine other browsers have similar), you can see exactly which tabs are using RAM and CPU.
I think most of the issue with doing anything *new* with WinForms is that the person would yet again create logic strongly coupled with the UI. Sure, you can make that mistake anywhere, but WinForms kinda forces anyone down that path. MVVM is hard. This means the separation of concerns is lacking and you're left with an application you'd definitely have to re-write to move to any other kind of platform. What's the point of making a WinForms app when you could have the exact same development process in WPF (by writing the logic in code-behind and strong coupling) when the latter is easier to refactor in the future?
If you're on windows, you can either use the (upcoming?) insider version that runs linux docker natively, or lcow right now.
CLR via C# by Jeffrey Richter.
Respository. Haha sry, can't unsee!
&gt;(Console.ReadLine(), out numberofdice)) will try. May i ask if you have any tips on if numberofdice &lt; 1; numberofdice &gt; 4); ? Simpy put, i want input value between 1-4
It will make it harder to find work in the future. IMHO winforms is kind of shit, its a throwback to vb6 and needs to die.
You can do it either way. JWT is meant to be able to contain any info you want to pass. So you could literally encode the role-per-room information in the token if you wanted, or have multiple tokens. Why? Well if you think of each chat room as its own tenant, and each chat room shouldn't be able to access the others' user data, then being able to read their own claims would allow them to judge without giving that part of the app access to the main user database. Having separate tokens would make it so separate sections of the site wouldn't even know if your user belongs to any other parts. I would probably do it that way honestly, as it would nicely separate your concerns. You could have a different endpoint for each tenant (chat room), and a single main authorization endpoint. This main auth endpoint sends back a single main token with user name. The client then sends the global user token when authorizing with a chat room endpoint, and the chat room sends back a role based authorization token that can be used for future requests to the endpoint. You don't ever have to send the role. But it helps when you're trying to perform an action and don't want the endpoint to have to go through the arduous process of making a request to the db for no other reason than to look up permissions.
For general purpose coding, no: although there are lots of scenarios where a developer would use &gt;8GB of RAM. I can fairly easily push above 8GB with a couple of Visual Studio instances with big projects, plus debugging, plus a VM for testing and a database client (SSMS is pretty hungry). Throw in a browser for testing and StackExchange/documentation, and usually something like a photo editor, and 16GB is pretty useful I have 16GB in both my work and home machines. I could probably use 32GB if I wanted to and have done with my old work machine (different job), but I found that it wasn't actually necessary and I just used it to be lazy and leave application windows open for months at a time.
Interesting, I'll have to look into that!
We've landed the moon with less
I have 32 gb for running lossa docker containers , 8gb jvm instances, etcetc. Worth every penny. Necessary, no. But nice to have.
Yes thats true. WPF is better for most cases. WPF is also being supported more by Microsoft, so I guess future is bright for optimizations too! As you pointed out, accessing properties through the sidebar is very useful for new learners and they can view/edit the relevant changes in xaml as well. I think MVVM encourages good practices, easier to maintain and scale.
Just bought a new MacBook Pro with i9 and 32GB and absolutely love it. It’s overkill for a Mac but since I have to run Windows in it, it’s perfect. If you’re running Windows in a PC, I would say 16GB would be the absolute lowest RAM I would attempt. I highly recommend a Mac for coding, though.
Very well said! I've worked with Air Traffic Control Systems around the world that were written decades ago and look horrible by modern UI standards ...but these systems do an insane job and they do it insanely well. No one using them or benefiting from their use gives two shits whether they have a modern UI or not. These ATC systems are ugly as fuck on the front end, but their sophistication and reliability is completely unrelated to its appearance.
Well, assuming integers, numberofdice &lt; 1; numberofdice &gt; 4 is giving you 2 and 3. 1 is not greater than one. Four is not smaller than 4. So numberofdice &lt;= 1; numberofdice &gt;= 4 is closer to what you want. Always test your code with the limits i.e. 1 and 4 in this case.
Visual Studio is 32bit, so can only address around 3GB.
A single Visual Studio instance can only address around 3GB or RAM.
You can increase your virtual memory size (if you have an ssd) and you will be fine. [This is me right now.](https://i.imgur.com/lriJprs.png)
It's not necessary but it helps a lot.
As a webdev who uses visual studio and mssql management studio in parallel: yes. 2 of my coworkers only have 8gb and whenever there is a slowdown in a common operation (which happens a LOT) it’s because of the lacking ram. If you only do light console app development maybe 8 is fine.
If they have stored procedures it's already a bad sign.
Check your memory usage in task manager on your current device and determine for yourself while taking into consideration your current RAM specs. It's usually not necessary, though, depending on what you're doing. Perhaps you could buy the model with 8GB and insert more later if needed, installing RAM into a laptop isn't very difficult.
Yeah, you'll be fine. But your virtual memory is nowhere near as optimal of a transient caching mechanism as your real memory. It works, but it's slower. The larger your projects, the more obvious it becomes. You can definitely survive that way, but when you have the option of buying more ram, the time you'll save not being delayed by the degraded performance of your virtual memory will pay off very quickly both monetarily and in terms of productivity.
2-3 instances of visual studio, sql server, postman and a couple of chrome tabs is enough to bring my 16 GB think pad to 90% RAM usage. And this is not that unique. I’d say unless you are only going to code some minor college assignments you’ll need at least 16, especially if you want it to last at least 2-3 years. Having only 8 without being able to upgrade will bite you pretty fast. That said, I agree with the suggestion of building a decent PC and remote into it with whatever laptop you’ve got. That’s where the screen resolution becomes pretty important.
I run into issues w/ 16GB so I just opted for 32GB when upgrading my desktop. It's actually quite nice to have all that memory available when you need it.
also this is exactly the sort of thing sqlite is great for. that may be too advanced here, but it's definitely the way to go.
[Glassdoor.com](https://Glassdoor.com) my guy
Just chucking it out there that compensation can be a little tricky. I make just under the median in my area but work 30 hour weeks and get 8 weeks off a year. I'd much rather have that than some of my die-for-the-company friends at other places making 20k more.
I understand, it's true, but when i was in need to build the package i was thinking on graphql. Maybe later i'll rename the package. Thanks for the comment!
WinForms may be old, but it still has no worthy successor. There's nothing wrong with using it and it will still be widely used in the foreseeable future.
You are correct that main process itself (devenv.exe) is 32bit but there are a lot of side processes that are 32 or 64bit depending on situation. Also when you do a build, those are not running in devenv.exe anymore. So it can consume a lot more than 3GB.
[https://www.reddit.com/r/csharp/comments/bncmea/do_you_think_16gb_of_ram_is_necessary_for_coding/en4szhs](Work is offloaded to other processes that, in total, address far more than 3GB.)
Take a look at QmlNet. https://github.com/qmlnet/qmlnet It is cross platform, hardware accelerated and uses .NET Core.
I'm the author of QmlNet. Feel free to ask any questions.
And if it gets stolen. Easy replacement and nothing of value was lost.
For Puerto Rico: https://estadisticas.pr/en/inventario-de-estadisticas/empleos-y-salarios-cubiertos
&gt; You can increase your virtual memory size Windows will automatically do this for you. The only reason to touch pagefile settings is if you have multiple disks/partitions and need to move the pagefile to another.
Mine didn't. It just started crashing whatever program it couldn't fit in after a certain point.
Depends on what you are coding.
Glassdoor is not good when evaluating companies that offer non-salary compensation like stocks unfortunately. I've seen it be incorrect by a huge amount (\~80%).
The common causes for that are that either someone else changed it to manual management, or there wasn't enough disk space free. I cant count the number of times I've received low disk space alerts on machines, and when investigating found that some runaway process (or processes) have eaten all the memory and kept going forcing windows to keep increasing the pagefile.
Short answer: yes. Long answer: multiple asp.net MVC applications, solr installations, dozens of SQL databases, visual studio, virtual machines, mobile emulators... This is just a handful of the things I have installed on my work machine. Running the environment is very memory intensive sometimes, but the application I am building rarely is. For instance, the last website I built typically consumes less than 256mb of memory on the content delivery servers, and it has an aggressive amount of in-memory caching. IIS, Visual Studio, and a properly tuned SQL installation (e.g., throttled) will easily consume 8gb of memory. IMO, 16gb is the minimum required by a software engineer. Don't get anything with memory soldered to the motherboard, unless you require an Apple computer. Processor speed can be very important or can be negligible depending upon what you're building.
yes
If you're doing web development and using electron apps like slack and vscode you should get as much as possible.
Are you hiring?
5 years ago laptop mostly used 45W CPU. Now most laptop use 15W CPU unless it's a gaming laptop.
Desktop i7-8700.
Undo/redo is very application specific. Everything that is “done” must move the state of the data model from one state to another, and if you want to implement undo/redo, you must capture the information necessary to do make that transition as well as the opposite of what you did and store it in a stack. Any library you find will only get you so far; ultimately you must provide the mechanism to do and undo actions. Good luck!
I don't know if there's a library for it as typically the effects of undo/redo are pretty application specific. Two basic options you can do to roll your own. First you can make use of a "command" pattern. Beyond the more [formalized definition](https://en.wikipedia.org/wiki/Command_pattern) it really just means you have to encapsulate the _actions_ you want to apply to your JSON data. Write a "command" to do a specific action, _and_ to know how to do the reverse of that action. For example: public class ChangeValueCommand : ICommand { private string OldValue; private readonly string NewValue; private readonly string Key; public ChangeValueCommand(string key, string newValue) { this.Key = key; this.NewValue = newValue; } public void Execute(JSONobject obj) { this.OldValue = obj[this.Key]; Redo(obj); } public void Redo(JSONobject obj) { obj[this.Key] = this.NewValue; } public void Undo(JSONobject obj) { obj[this.Key] = this.OldValue; } } Syntax for your JSON operations will obviously be different, this is just for examples. You can design the command API however you want, in this case I separate the "Execute" (being the initial execution of the command) from the "Redo" (even though they are typically the same) as a way to record the original state before the command was executed. You would then writeup some kind of "CommandManager" or something better named that could maintain a `Stack&lt;ICommand&gt; Commands`. As you execute commands, you add them to the stack. As you "undo", you pop the top command off the stack, execute its `Undo()` method, then push it onto a `Stack&lt;ICommand&gt; Redo`. If you then do a "redo", you do the opposite: pop the command off the `Redo` stack, invoke its `Redo()` method, and push it back onto the main `Commands` stack. If at any time you execute a _new_ command, you can clear out the "Redo" stack. Another option if you want to avoid implementing the "Undo/Redo" methods in terms of updating state, you could just record a copy of the JSON data. For this use case scenario, it would probably be fine. Copy the JSON object/text for each commands as they execute, "Undo" would just be grabbing that snapshot of JSON data and using it instead. (And vice-versa for Redo)
Don't disregard old tech. The highest paid people I know are maintaining legacy COBOL and LISP codes, and some VB6 applications. There may be tons of new and hip frameworks/tech coming out every month but there are multimillion-dollar industries still relying on these tried and tested platforms.
Are you in socal or Philly?
The i5 8265u is fine. Just don't limit yourself to 8GB RAM. And get a 500GB SSD.
You are right. I have corrected the article. I mean they said it uses native controls.
Pro-tip: you are using "XmlSerializer", which does things you might not expect, and will create "but it works on my machine" problems. It creates and deletes a temporary DLL which requires: * 1 - the executing process to have access to the temp folder * 2 - explicit garbage collections so the DLL can be deleted Research these 2 searches for more details: https://duckduckgo.com/?q=xmlserializer+file+permission https://duckduckgo.com/?q=xmlserializer+file+access
I think 32GB is necessary, but then again I run a very large stack.
I'm sure. My desktop is the lastest gen and I see the difference. But I disagree that my laptop is as bad as the guy I replied to implied. It's slower, but not a bit of the UI locks up or anything like that. It does have an SSD and 16gb though.
90% of programming is learning how to write correct, efficient a clear functions. Most of the rest is not really that hard to understand when it's appropriate to use it.
Instead of using their phone number or email, generate a unique identifier and use that, and store the phone/email as a field
Resharper is a fiend for resources.
Yeh. I have an old i5 based dell laptop with 8gb of ram and a fast ssd. VS runs fine. Add Resharper and it is game over. The other one that destroys processors is gulp / webpack
This. Every person should be stored as an entity with a unique identifier despite their separate details.
Are you even in the US?
Where in SoCal exactly?? =)
Is not needed by any stretchz but it can be useful.
There's a metric asston of WinForm code in the enterprise and there's no shortage of new development being done on the framework. I'll believe WinForms is dead when the component vendors stop supporting. it.
Definitely, 8GB can run it but that is not enough if you are running VS and SSMS together and with some docker containers (and maybe VM), it would just simply annoy you once you get to sit and you are into it. You need a much more higher specs (16 G) would be enough, but still, the higher the better.
Levels.fyi
As someone who often has to run three or four solutions on may machine at a time, yes. Oh hell yes.
Do you hire remote?
San Diego
Just check job listings, most have a salary attached. Recruiters also try to get you the best salary cus they make more money then. At large companies you can build up yearly 3% raises, I suppose you can factor that in. Without stock options most companies limit salaries no matter what level position you are in.
I'm currently in your condition. Starting with .NET Framework, and then will gradually transform to .NET Core. I know .NET Core is the future, and [it'll become the ONLY official way from 2020](https://devblogs.microsoft.com/dotnet/introducing-net-5/). Then why am I still learning .NET Framework?! The answer is: **Job Market!** Regular job of a developer is more likely to maintain, rewrite, and sometimes add new codes rather than building greenfield projects from the ground up. Though .NET Core is mature enough and getting a lot of traction lately, the number of projects in .NET Framework is humongous compared to it. Somebody needs to maintain those projects. So you'll find a lot of job openings asking for the .NET Framework knowledge. They prefer if you've the .NET Core knowledge, but they **require** the Framework knowledge more. Yes, there are many jobs solely dedicated to .NET Core, but compared to the .NET Framework, it's tiny. Please don't get me wrong, I'm not against the .NET Core, rather I think it's one of the most beautiful, effective, well-engineered, light-weight, and futuristic techs out there, an absolute piece of art from Microsoft. BUT anyone trying to get a job in the Software Development industry with C#, s/he has to get his/her hands dirty with .NET Framework in the upcoming years; *no escape route,* sorry! Even after joining as a .NET Core developer, when there will be no new projects in hand or no .NET Core projects to maintain, an old client may show up with a 15-year-old-Framework-project, just for some feature upgrade, you won't be able to deny looking into that codebase. So better prepare yourself from the beginning. If your goal is to build something on your own or develop some pet projects, choose whatever you want (I'd prefer .NET Core here). BUT if you want a job, consider .NET Framework and Core **both**, cheers!
The stackoverflow developer survey should be a good starting point
This is the most comprehensive site IMO
Been a while since I used Visual Studio, but I used to have several VS's open a time, each with sometimes large projects. That alone made me unhappy with 8GB. I am currently running with 64GB, as I have several VM's I'm running - and memory is cheap
I can think of multiple ways to interpret your question. Perhaps you may wish to clarify, if the other responses here don't help you.
Depends on country but at least in the UK it gets tricky not comparing apples and oranges. I earn below the average, not by much, but I get 43 days holiday, work 36 hours a week, have an 8/18% pension, no core hours, can work from home regularly, get to travel a lot, etc. Devs are in high demand so a 30%+ payrise would be entirely possible but I'd lose a lot of other benefits.
Install blind and brag/cry about your TC.
I might want to contribute, what’s a good task for someone unfamiliar with the code base?
And it highly depends on the location. In Manchester, I earn about 30-50% less than I would earn in London, but in exchange, I live 15 minutes from my workplace and the rent is MUCH cheaper.
Stored procedures are waaay faster than doing the logic on the .net side and even faster if you throw an ORM into the mix.
you shouldn't be committing the DLLs, those should be defined as a dependency somewhere and then pulled in at some point
Call me crazy but this explanation isn’t complicated at all if you already know what inheritance is. Usually in OOP they will teach you that right after covering classes, constructors, methods and properties. That’s also the same time when they skim through some important comparisons, e.g. structs vs classes, etc. It’s only after linear inheritance chains when things get a slightly more complicated and that’s where interfaces come into play. But at this point all the previously mentioned stuff should be familiar to you.
What do you mean by committing them? I just googled it and it said to just add resource &gt; then select the dll. Is there a way to do that progmatically?
Thanks I haven't had any issues yet but I will check that out. What would you recccomend to serialise items?
This is a good one: https://github.com/qmlnet/qmlnet/issues/15
fafff
Don't forget that if you let them change their email address then you open the system up to account hijacking, where if a user can gain access to an account, they can change the email address and prevent recovery by the original owner. If you store passwords you also have to store them securely with salted sha256+ hashes, etc, and even then you probably won't have multi factor authentication. Consider not even storing identity yourself. There are plenty of OAuth providers you can use. If you just let users sign in with Microsoft and Google OAuth, that will cover most people and you won't have to worry about any of the details above.
I'd say check the union websites for the respective countries - in Norway we've mainly got tekna.no and nito.no.
using oauth login alone isn't enough, it's also good to have a local login. but i was thinking of a case whereby the user doesn't have access to his email address and he's about to login. is there any technique that can be applied in such scenario?
There is a sticky thread in one of the developer subreddits with people posting their new positions, experience and salary.
Also keep in mind that companies are paying recruiters so they eat a small but of that salary.
Could you link us?
Thanks for your sharing.
This really depends on the user. For me, 16GB is working completely fine, since I'm not regularly using virtual machines as others have mentioned. I mostly use Visual Studio and Unity(with vr).
Just remember: Any yearly paycheck adjustments below the Consumer Price Index and/or Inflation Rate (I think they were the same or always close) is a PAYCUT. If that is not uniformly applied to everyone, GET OUT AS QUICKLY AS POSSIBLE AND DO NOT GENERATE ANY NEW VALUE FOR YOUR CURRENT EMPLOYER.
Yes I know. I studied machine architecture at university and have a very high appreciation of software that is memory efficient. I agree that the web browsing experience could be improved, in particular I hate it when things on a web page appear or move without my permission. But it's not the browser's fault, and for any of the major web browsers, you will see someone complaining about RAM useage, when in reality the RAM useage is either due to the webpage itself, or due to the browser trying to optimize or pre-render a really inefficient web page. Chrome is essentially just an extremely optimised javascript compiler (V8) running in each tab, and pretty much every webpage is more of an application than a web page. Similar to if you were running a .net CLR on every tab. The memory usage is up to the web page designer, not chrome. For example, if I write a C# program that holds on to references long after they are needed, and objects are not released as a result, and does lots of unneccessary calculations again and again in a loop, then my program will waste memory. Exactly the same thing with some web app.
If you're a beginner coder, I would argue that your choice of language is going to affect this. If you're choosing a compiled language, like C based ones, then your compile time is going to be affected. On the other hand, if you're using Python or JavaScript then 8GB is going to be more than plenty. You definitely won't need to worry about docker for your own hobby projects, only if you're planning to make your software deployable on machines other than your own, and database-wise the answer is the same; if you're working on only your own stuff, then something like MySQL will run fine on 8gb. If you're planning to use this laptop in a work environment, then yeah the other comments are probably more helpful, and you'll need to consider your stack. This is just coming from someone who's been hobby coding for six years rather than someone who's worked in the area, so I feel my advice pertains to you more
https://www.google.com/search?q=stack+overflow+developer+survey
Why is it good to have a local login? Why would you want to let someone log in to an account if they don't have access to the email address to that account? I don't have access to your email address, do you want me logging in to all your accounts? How about if someone gets your password from a past data breach, uses it to log in to a site changes your email address so you can't recover it (and often creates a new account with your email address so that if you even try you get the wrong account) There is a balance between security and usability, but it's very easy to invalidate all security, to the point of not even being worth using logins at all, or it even being a bad thing if you don't do it right, due to data breaches, having to support users that can't log in, etc. Using OAuth makes almost all the complexity of how to handle auth properly someone else's responsibility, and they will be hiring experts and following security best practices.
I am software architect and I totally get what you are saying. The real issue I think is the hype of SPA apps that actually move most of the logic from the backend to the poor user browser, and in the process using million js libraries, some even for trivial work like isarray.js. I always favour simple postback to the server to do the hard lifting. It can be optimized better etc, and using the js for what it's meant to do - simple work.
If you're gonna be sassy, may as well do it properly... [http://lmgtfy.com/?q=stackoverflow+developer+survey](http://lmgtfy.com/?q=stackoverflow+developer+survey)
From the docs &gt; the negative number returned is the bitwise complement of the index of the first element that is larger than value In the [two's complement](https://en.wikipedia.org/wiki/Two%27s_complement) system like most programming languages use, a bitwise inversion ends up being one higher than the negative version of the same number. i.e. for an 8-bit value (which goes from -127 to 128), 1 (`0000 0001`) and -2 (`1111 1110`) are bitwise inversions. In this case, it's returning -3 because array index 2 has the value 6.
Thanks!!
Thanks for all these links, I'll definitely check them out.
With the effort it took for you to be a dick, you could have just posted the actual link. https://insights.stackoverflow.com/survey/2019
in Chrome...
Most of what you've said is true, but I feel the need to point out that unless you're running an enterprise database on it, SSD wear is just not a thing anymore. You'd have to write the entire disk ever day for about 30 years to kill a modern SSD and the controller is going to give out waaaaay before that happens, and it's not going to be load that does it. You still want to avoid swapping, it's a shitty experience, and even an SSD is several orders of magnitude slower than memory access, but wearing out your SSD just isn't going to happen.
Necessary but not sufficient
Tying permissions into the JWT structure often comes back to bite you. Any time a user is made an admin of another room you somehow need to provide them a new token which can get complex. Better to tie tokens to identity and lookup permissions in the database.
VS Code is lightweight?? Nope. When you add plugins like C#, Ionide and open a medium sized project, things go awful. VS Code and all it's plugins are written in JavaScript which runs on Chromium, so memory usage easily spikes to 4 GB. JavaScript is eating the world.