The simplest answer is to convert to string then reverse, but there are much more effective ways of solving this problem that don't involve strings. If you get your input as a number, try to do this within the int realm. That will make it much more interesting. Also, as the other commenters have been saying, you need to show a lot more in your description like examples and your code and what you've tried.
That's definitely not the exact one. https://github.com/dotnet/csharplang/issues/288 That's the actual one, the C# repo seems to have multiple on-going issues to track features.
Didnt realize I was in Csharp sub. Downvotes make sense. I used .NET since beta over 15 years ago and still use Visual Studio, but Visual Studio Code with Electron is my goto editor for anything not .NET. It's only the most popular IDE so your hate comment makes no sense in term of Electron usage. Angular's binding framework very familiar for C# and MVVM devs. And TypeScript is a dream for .NET OOP devs using web tech. I also Co-founded the Houston .NET Users group. The current couple downvotes and hate comment are pretty silly, esp w no explanations.
Plus uwp apps aren't really intended to be distributed outside the app store. There is an option to make it work, but it might be disabled at any time.
They've been discussing how to clean that up but never get around to doing it, the multiple issues issue is a killer
I assume you're referring to the Windows store? Microsoft now offers [Desktop Bridge](https://developer.microsoft.com/en-us/windows/bridges/desktop), software which converts existing apps into packages compatible with the Windows Store. There are also native UWP desktop games. Being published on the Windows store really has nothing to do with whether the app is a desktop app. It simply means that it is neither a web app (which have HTML interfaces are are meant to be hosted remotely) nor a mobile app (defined mostly by the design constraints introduced by the form factor).
Your viewmodel could have a SelectedNewsID property, and your combobox sets SelectedValuePath="NewsID" and SelectedValue="{Binding SelectedNewsID}"
The "Cloud" means "outside of my LAN"... Servers are Servers but "The Cloud" isn't your PC...
Introducing ClearSkies - The Cloudless Soution! This revolutionary infrastructure model leverages in-house resources to bring you fast and easy access to your data!
Electron tho :(
Both are from same person. However you feel about the actual features, I think disorganized disaster is a good way to describe what I see there. I've think I may have even started to avoid reading the github discussions :S 
&gt; massively complex rendering tasks Current browser tech fails to smoothly scroll at 60 FPS. You don't need much to break web technologies.
Linq2Db.
It may be easier to use the buttons MouseDown event to start a Timer and then stop the timer using the MouseUp event and record the elapsed time from the Timer in the XML file instead of trying to watch a bool.
VSCode opens and loads all panels in 1 or 2 seconds for me. Don't know what type of project and how big you are loading, and your machine. Works better than VS for Angular. Old .NET stuff, yeah I use VS.
Cool! I was mostly making sure [ASP.NET](https://ASP.NET) Core works the same way.
Try the courses on pluralsight.com, you can have a 3 months free trial 
The problem with electron is, that it is pretts easy to create a bad performing application with memory leaks. Just try to use Slack a full day. It will eat you RAM like the worst stoned guy on a food rampage. 
I edited out a lot of comments about it because I felt I was going off track, but I feel like the 2006-2010 period is a big reason why MS is struggling now. I bet 6 years of my career on WPF and Silverlight, and they couldn't get their story straight. One month it was WPF all the way. The next "Well, Silverlight smart clients are probably the future." Then it was, "Uh... Silverlight's going to sunset so you should consider HTML/JS". Then it was, "No, that's wrong, we fired the guy, Silverlight is your platform!" Then it was, "Actually we fired him for announcing Silverlight is gone too early, we'll let you know when we have an answer, probably Metro?" Then, "Wait, sorry, we're so desperate we forgot to check the trademarks on Metro..." My Twitter feed went from 300 ASP.NET/WinForms client developers to 100 Ruby devs, 80 Obj-C devs, 15 MVPs, and 5 Microsoft employees. Only 20 people on that feed talked about how alive and well the Windows client ecosystem was. Guess which 20? I haven't touched a Windows client in 5 years.
Okay then, I'll bite. Why don't his other objections "stand up".
Yeah, I agree, just like cross platform tools: quick and easy are great. On the other hand, recommending web tech for desktop is how we got Open JavaScript servers in our Bitcoin wallets. [https://www.reddit.com/r/Bitcoin/comments/7ooack/critical\_electrum\_vulnerability/](https://www.reddit.com/r/Bitcoin/comments/7ooack/critical_electrum_vulnerability/)
&gt; IHostedService is there a tutorial somewhere for this? this seems really interesting
C# is probably one of the only languages that's community driven on GitHub, instead of being controlled by a single BDFL. So when Microsoft makes stupid decisions or when people post stupid suggestions, we are not afraid to press the thumbs down button. Examples: * [Microsoft's decision to stop supporting ASP.NET Core on .NET Framework](https://github.com/aspnet/AspNetCore/issues/2022#issuecomment-299536123) * [Someone's genius suggestion to make semicolons optional](https://github.com/dotnet/csharplang/issues/496 ) * [Someone's suggestion to add a `then` keyword](https://github.com/dotnet/csharplang/issues/1619) * [Default Interface Methods](https://github.com/dotnet/csharplang/issues/288) * [Rude Arch Linux user who couldn't compile .NET Core](https://github.com/dotnet/corefx/issues/19447 ) 
VSCode rocks. Recommend w the one dark pro theme extension. I've used slack app before also, wasn't too bad for me, but others w low ram and loading huge solutions in IDE and building could have problems
Don't dismiss the web. Been learning Javascript React for the last couple months (after 5 years of WPF) and Im just mind. blown. So much creativity, packages, resources, libraries... It's like an explosion In my old job, we phased out all the WPF front end with Angular. C# was still kept as the backend (libraries, microservices, etc) If I was starting a new project, I would have to really be convinced to use WPF. I just don't see what JavaScript can't handle. Job-wise, C# and WPF can pay a LOT. Mainly because it's hard to find people. The younger generation wants to work on cooler stuff. WPF is fine but don't make it your one trick pony. Never stop learning
Depends on who you ask. There are still a lot of people writing new WinForms applications because they believe it has better performance or a lower development cost.
There is but no new app get started today in WPF. It's all maintaining legacy code.
UWP is not ready for line of business applications. It may be someday, but there are a lot of missing features that people regard as core functionality.
That has changed. Even really heavy apps (trading, analytics) are being replaced by web apps. Don't ask me how I know...
&gt; I edited out a lot of comments about it because I felt I was going off track, but I feel like the 2006-2010 period is a big reason why MS is struggling now. &amp;#x200B; Also known as that period where nobody could make a nice, future proof app for anything, not even the web. At least until HTML5 became more widespread and then came the Javascript days \*shudders\*. &amp;#x200B; Also something to keep in mind, it was around this time that turmoil in "developers" was high regarding whether touch screen support should be a first class citizen or be exclusively relegated to mobile (not even web at this point, everyone was doing the [m.site.com](https://m.site.com) thing). Remember, remember, the 5th of November, when **Google publicly fought against** the standardization of UI inputs. &amp;#x200B; &gt; I bet 6 years of my career on WPF and Silverlight, Ouch. Those were terrible times. I just got off MFC and was just browsing this new tech and experiment with it. &amp;#x200B; &gt; I haven't touched a Windows client in 5 years, and if I need a GUI today I'm writing Electron apps. &amp;#x200B; Need a quick app with a gui the other. Took me 15 minutes to compile my first working prototype on UWP . Of course it helps that already have my own template for UWP that takes care of most boiler plate stuff, like app life-cycle and reactive UI. Of course, on UWP those things are cheap or free. &amp;#x200B; &gt;I tried Xamarin for 4.8 of those years. I believed in it once, but now that .NET Core is taking off it seems MS is trying to bet on a Windows-only ecosystem again. For 11 of the last 12 months, Intellisense didn't work in VS for Mac. That's all I needed to know. &amp;#x200B; I'll take your word for it. As for the Windows-only ecosystem again, well frankly, I've grown more and more disenchanted with Linux and other than MacOs, there are no real alternatives. I think I'll go for TempleOS next. &amp;#x200B; &gt;I don't do Xamarin anymore, and have talked a dozen friends out of starting projects in it. &amp;#x200B; Kudos. Friends don't let friends start projects on cross-platform tools. &amp;#x200B; &gt; &gt; &gt; But XAML still works. If you know WPF, and have some reason to want to use Xamarin, it only takes a week or two to be able to write simple apps. Then, after 5 or 6 years of addressing Xamarin's shortcomings and learning both Android and iOS native dev, you'll be able to write complex apps with it &amp;#x200B; Ahaha. This has been my experience, there are seasons you can make so much money just doing freelance work, rebuilding a native app from scratch in shorter time frame for one of their release.
I'm reading the lines, but he meant 'desktop apps' as non-web-desktop apps, using proprietary, incompatible language like C#. Those are slowly dying (will take years). When is the last time you installed an app on your PC, like Photoshop? 
&gt;Furthermore, the future of .Net is dot net core, and the 4.8.x line will be the final full framework release, and ‘WPF support’ whatever that means, won’t land until 3.0 (next year). It means you can run your WPF applications on .NET Core on Windows. &gt;I would not start a new WPF project until it is supported on .Net core; you would literally be creating a new project that is already legacy as soon as it exists. Not really. Just make sure that .NET Standard libraries are used and you'll be fine since you can transition to .NET Core 3.0 when it is released. There may be some things that may make it a little harder than just a straight change but most of the code should be reusable. &gt;What you know in WPF isn’t entirely a waste, but it’s certainly not ‘modern best practice’; that is, for now, ‘wait and see, and use something else for now, like QT’. Are you suggesting using Qt bindings to .NET or to use C++ with Qt?
&gt;How do you know that most users prefer web or mobile apps? How can users prefer "mobile apps" in desktop if mobile apps are for mobile devices? Users don't care if its an app or a PWA. What they care is responsiveness. Look no further than Facebooks own numbers when they replaced their web-wrapper with a proper native app. The UI was almost the same, the difference was clicking on something now took 0.1 seconds, instead of 5, and user engagement went through the roof.
&gt;proprietary, incompatible language like C# 2016 called. They want their Roslyn back.
&gt; I hate reading making me fall sleep You'll have a hard time learning anything then. Anyway, have a look at [this](https://www.reddit.com/r/dotnet/comments/9ondqj/beginner_with_no_programming_background/e7v8ldm/?context=0 ) comment of mine that has links to a few free and official video courses. 
Sorry to have to say this, but you're delusional. I used to be a C#/WPF developer for a Fortune 100 company doing mission-critical, heavy analytics and reporting. The LAST app that I thought would be replaced by a web app. I thought there was NO WAY this could be done. We threw away our millions of lines of WPF code within 2 years to switch to angular. It is amazing to code and blazingly FAST. Developers and users love it. Microsoft can't compete with the million of developers building components and libraries and releasing them for free. There are no browser-specific tweaks today anymore, thanks to polyfills and browser standardization. Your knowledge is outdated by about a decade. You're missing out on a revolution. I know it's scary, but that's not a reason to not open one's eyes..
Mistaken. Core 3 will have Windows only addons for WPF and WinForms 
How about a data grid, the workhorse of all LOB applications? I think it was announced last quarter that we finally have one in beta. 
It sounds as if you have configured for lazy loading disabled, for instance in a DbContext constructor: this.Configuration.LazyLoadingEnabled = false; With lazy loading disabled you would get an Invoice with a loaded Customer from using (var db = GetContext()) { var invoice = (from i in db.Invoices join c in Customers on i.CustomerId equals c.CustomerId where i.InvoiceId == someInvoiceId select i).SingleOrDefault() }
oh wow, now that's disappointing.. 
Consider the cursor leaving the button while still pressed also. There could be some undesirable behaviour there.
ew 
And that's probably smart from a business perspective. Makes sure the maintenance will be done through your company :) Thanks for replying. There is no right or wrong answer. But I'm just trying to give my two cents in that I think that we are living a revolution.
Removed: Rule 4. You'll probably have to provide more code related to how you bind that data table to your CSV file, and how you write/export that CSV file.
You're missing a whole other sector of the market: professionals.
Removed: Rule 4.
2016 is 10 years too late. JavaScript has won the front-end battle. Sure there's some room on the backend for now. We're talking about WPF here It's normal to be scared. I understand. I was there a few months ago. That's what IT is all about, never stop learning and growing. 
I understand. But our app was an internal app, used by about 200 employees only. Was CPU and processing heavy, the last app I thought would be moved to wrb. But that happened. Theb is coming hard in that area too.
I used to work for an internal app. Not a web app. I'm NOT talking end-consumer apps. That's obvious that the battle is lost there. I think the discussion is will WPF even survive in professional settings, or if electron etc. might win this war too. Having seen both sides, I think it will (and again, I spent 10 years learning C#, including WPF)
Why would it?
You can attach commands and behaviors to pretty much all of Telerik's controls IIRC.
Are you using Include in your calls? You must use something like _context.Customers.Include(c =&gt; c.Invoices) when calling it. This is typical EF Core behavior.
Just google it.
When you say on the back-end, you're saying I need to invest in an infrastructure that will parse very large files 10-100MB, validate them, etc. Why when this can be done for free on my users' machines? They already have the CPU/RAM power. What about displaying 100k-1mil rows in a grid? Not trivial on the web AFAIK. Yes you can page, etc. In either case that still puts a lot of load on the servers. What if you want to dynamically group those 1 million rows by any of the columns? Again solutions exist on the web, but they all rely on partial rendering of the data one way or another and load on the servers, with a lot of chatter. I'm not sh*tting on web. But I am not sold that the web is everything, and there is no room for anything else anymore.
&gt; no new app get started today in WPF That's a bold, misinformed, blanket-statement Cotton, let's see if it pays off for him. 
I've been using WPF for years (I switched from WinForms once WPF came out basically), and it's my go-to UI tech over WinForms for Windows Desktop apps. I don't need UWP (and from what I've read, it's too restrictive for my purposes), I prefer it over WinForms, and short of abandoning desktop apps or going to Electron (HTML/CSS/JavaScript) I don't see it going anywhere soon. Some thoughts about the technology in general, though (I don't know how relevant it is since you said you've been using it for a few years, take it or leave it :)): * Like others said, "Windows" and "Desktop". Take that for what it's worth. * It sometimes feels like I have to spend more time tweaking and/or writing XAML to get what I want than to just... get what I want. I hate writing XAML (I've never liked the whole XML syntax, personally, though it is good for what it does), so this always bugs me. There are plenty of good frameworks out there that give a better UI look-and-feel and don't require rewriting everything in XAML though, like the Material Design library and MahApps, so this can be mitigated pretty easily. * MVVM makes a lot of hard things easy (databinding fields)... and somehow makes a lot of extremely common scenarios ridiculously difficult (dialog management, button events -- why do I have to keep writing `ICommand` implementations because there isn't one out of the box?). You don't *have* to use MVVM, but WPF works really well with it. Again, there are plenty of MVVM libraries to mitigate this. * Related to this, the closer you get to using "pure" MVVM (i.e., no cheats) the more you get tangled up in this. You could handle button events in code-behind, for example, or you could go the Command route. * Ultimately, I like WPF. You can certainly make it do what you need right out of the box, but it's starting to feel like to make it work *well* these days (especially on the look-and-feel side, since the controls do look somewhat dated and simple to me) you need some sort of external library, unless you want to spend ages doing tedious work re-inventing the wheel.
cloud based is meaningless nonsense.
I wasn't - this is getting me closer! I started with /u/NLindbom's suggestion to enable lazy loading (a bit different in core but not too bad to set up) but I was getting circular reference issues. So per stackoverflow I added this to my mvc service: but it did not fix the issue. So then I thought lets back out of those changes so I reverted, then added .Include(i =&gt; i.Invoices) but I'm still getting the same circular reference. I will continue to look for a solution but I think you and /u/jocq hit the nail on the head with the include statement - I was not familiar with that and it makes sense why it is necessary. Thanks for pointing that out.
Because it's really inefficient. Everything is run through a Chrome instance. Sounds cool for developing, but the price is paid by users.
for playing around? Sure. For making money, no, do not do, unless you either like being unemployed or want to be stuck on "the legacy system" for the only company around that's still using desktop apps. I say this all sadly.
You def want those json options. It's pretty standard to include them. And you definitely should use .Include lazy loading is a bit more advanced. 
I liked Bob Tabors free courses on Microsoft Academy. Started there as a C# newbie with minimal OOP experience.
I strongly recommend avoiding lazy loading
WinForms for me. It ain't going anywhere. Then again, I work in enterprise dev. Shit that came out 5 years ago is cutting edge for most of our customers.
There are many kinds of line of business applications. Plus there is Telerik, DevExpress, ComponentOne.
True, but the concepts are quite similar. I never understood the complaint. Sure it isn't possible to copy paste code between Silverlight, WPF, Xamarin and UWP. Still the foundations are the same, XML UI description language, templates, triggers, data binding. It is a matter to think at architecture level and less at code details.
Vue.js already does it. Forget wpf, don't ways your careers on it if you want to grow. 
Dishonest. 
Visual studio should be competely moved to Electron, vs code is thriving.
you're going into the wrong profession if you hate reading so much lol
&gt; no new app get started today in WPF We just started a completely new codebase in WPF a few months ago. Part of a six-figure revenue product.
No, they don't need to be in the same assemblies as your views. And as a matter of fact I tend to prefer having separate presentation(s), presentation logic (VMs), domain and infrastructure completely separate.
&gt; better performance Hmm. I suppose this is hard to measure, but I'd still be curious about examples.
I understand. Maybe I was being a little over-dramatic.
&gt; Didnt realize I was in Csharp sub. Downvotes make sense. …what? Electron's flaws have absolutely nothing to do with developer culture. Electron is bad from a _UX_ point of view. &gt; I used .NET since beta over 15 years ago and still use Visual Studio, but Visual Studio Code with Electron is my goto editor for anything not .NET. VS Code is pretty good _despite_ Electron, not because of it.
Slack is a great example of taking up a crazy amount of resources (it's a goddamn chat client) while integrating very poorly into the OS.
Please, sweet Sagan's ghost, no. VS is a hog enough as it is, to the point where loading a few of the very large solutions we have at work start getting close to the 32 bit process memory limit.
My point is they are not rare like he said. Pretty simple.
they aren't **JUST** servers if I say, my website runs on a server that means it runs in one place like Atlanta. If I say cloud then the provider has a solution that will have my application exist all over the world. So people in Europe are hitting local machines and people in California are hitting different machines. It means I can scale up or down my usage instantly. &amp;#x200B; So one someone says the cloud, they don't mean just a server they mean all the architecture that make up the cloud services.
For me myself personally. Yes WPF is perfect for what I use it for which is building desktop applications to expand my C# knowledge. My job is working on a piece of ASP.NET MVC software. My previous knowledge of MVVM has helped me to get to grips quite easily with MVC. I am simply asking if WPF is still good because nobody else who I work with seems to use it they seem to still think that WinForms is king.
&gt; bringing Winforms to .NetCore It's worth noting that WPF and WinForms support in .NET Core 3.0 is still limited to only Windows, unfortunately.
Part of the reason it's such a hog is because they've included a lot of different technologies into Visual Studio and some of the UI is even rendered in HTML. I agree. VS should not be in Electron. I have a feeling that we'll see a faster dotnet core conversion in the future. Maybe it won't happen next year but it might happen in 3 to 5 years from now.
WPF as a technology isn't going away. They're working on making it run on dotnet core 3.0, which is due out next year. It's absolutely worth using and knowing. 
I dream of being able to write Silverlight again. Being able to work in a purpose built UI framework rather than the cobbled together mess that was HTML+JS was great. 
I feel you, even though I never had the chance to work with Silverlight. That's why I avoid doing any website work. 
It will also automatically load navigation properties where the entities have already been loaded. When serialising it's better to use a fresh object I find. Especially for Web. 
Netflix isn't running their backend in Node. What they're doing is running the proxy layer in Node, which then calls Java services to do the real heavy lifting.
Fair enough, but there are servers involved :)
That's not true at all. Microsoft is still talking about features on the roadmap for WPF.
Can you post your code on Github?
As a UWP peasent, I never got hooked on DataGrid so my data layout solutions don't need it. Custom controls with MVVM are fun :D
&gt; JavaScript has won the front-end battle. No contesting that. It's definitely better than the previous champion, PHP. 
Thanks, I'll try VSCode one of these days. I don't have much use, as I already use VS for everything.
I know that very well. No problems in VS Code 😋
Php does not (and has never) ran on the client.
I've been developing enterprise desktop apps in Microsofts ecosystem for about 20 years, starting with MFC, then moving onto WinForms and finally WPF. The last few years, I actually ended up having to slowly jump ship and start implementing more and more clients in Javascript (technically speaking Typescript, I still can't stomach typeless languages after spending over a decade developing in C#). Why? We need our software to work on multiple platforms. Targeting windows desktop is no longer enough. Sure, ideally you'd have native apps for each platform (iOS, Android, Windows), but when I can save the company 3x dev time by implementing back-end in Asp.NET Core, and the front-end in Angular, it's a nobrainer. Especially if you're dealing with LoB applications, where UX takes a backseat to functionality.
I just built an app in WPF. For the government. Not all applications are consumer-facing line-of-business apps.
In that case you could also use MouseLeave and abort your timer if they leave without actually clicking the button. 
Slack is not a great app. Not at 1.5 GB of ram and more cpu usage than web server.
Wpf is the worst framework I've ever had to deal with from a usability and rapid development standpoint. And it's limited in it's capability ( windows desktop only?!?!). I never ever want to work on a WPF app again. Not only is it nay impossible to find super proficient devs that know it's very obtuse and specific syntax, moving elements around on the same xaml file can actually require you to build out a shitton more code in a complicated way then is necessary... Check out scoping on the view model heirarchy... It's truly utter garbage in my honest opinion 
A \*Computer Scientist. bu dum tss What about Political Science majors? &amp;#x200B;
I dont. I rely on a very good end-user agreement written by my lawyer.
I don't think there is really a strict qualification associated with "Scientist" like there is for "Doctor". You could call yourself a "Scientist" before you even got your degree, but once you have the degree you are now a "Bachelor of Science". Its not like "Doctor" which means you have obtained a technical qualification, ie your PHD. &amp;#x200B; Sort of like the title "Programmer"... It describes what you do with your time. Personally I'd find it odd if you described yourself as a Scientist rather than Programmer.
Removing "whitelist", "blacklist" and many other terms is a "policheck" reaction item to terms that could be considered offensive. See also "master"/"slave". While some might consider it too politically correct to bother, it really doesn't come anywhere near the same level as some of the others in the list.
I'm not a fan of DRM, but if you must implement it you need to do so in a way that makes sense for the products usage. What market is your product in and what is a brief use case for it? That'll help people give you constructive advice. &amp;#x200B; For example: Always on DRM makes no sense for an app that oil field workers use out in the boonies of North Dakota, but makes perfect sense for a competitive multiplayer game.
Not sure if they still do it, but 3M used to use your degree as your title on business cards. So you'd be **sligo987, Computer Scientist** 
Do you use the scientific method?
No one else has given a direct answer, so here's one. No.
This has long been a peeve of mine. For the vast majority of us, a "computer science" education is wrong. What we do isn't science at all, it's engineering. We need a whole lot more concentration on things like documentation, specification of requirements, modeling, and that kind of thing - whereas most of the math, and a bunch of theory of automata and stuff isn't really so important. So: no, I don't think so. You're an engineer, at least if you're doing it right, and unless you're an academic doing research.
The title **Scientist** is ambiguous. Some would consider you a computer scientist due to your degree, while others may define it by your job/position. People like titles; It makes them feel special, even if they're not.
Use accounts with keys. When the software is installed, you can link it to your account and it checks for a valid license. The key should just be for scenarios where a connection to your server is not possible (or by choice). Best advice I can give you is to look around and see how everyone is doing it. Also, make that EULA iron-clad - it *will* pay off in the long run.
If you implement a fake version of DbConnection, you can construct a DataContext with it and then use the DataContext.GetCommand API to get a DbCommand instance that is initialized with the SQL query and parameters from your LINQ query.
&gt; I never understood the complaint To me, having 4 different tools all named the same, from the same company but all have minor differences and aren't fully compatible with each other is crazy. There was talk about XAML Standard but I haven't kept up with that so I don't know if that is still a thing and how much there is work towards it. 
Thanks for this reply, gives me a lot of &gt; Typically exposes ICommands Yep using this correctly at least :P &gt; and data, via public properties, that its view might want to display. So the ViewModel shouldn't have logic behind a specific exposed property? &gt; Within a ViewModel is where you call services to retrieve the appropriate data, and perform the appropriate operations. Caching could be done here, or in a service related to that, depending on other factors Cool so think I'm doing that okay for now. Just my main problem is not have Models &amp; Database models requiring dependency on Services - like the `DisplayName` 'the' problem -- where would you recommend I do this? &gt; And the reason I asked about the controllers is because that generally is part of MVC or some other paradigm, instead of MVVM. So they're actually just models and services, I just wanted to separate them from Services and trying to be fancy haha. So about that screenshot.. I forgot .. here they are.. [First](https://i.imgur.com/t4UC2Qt.png) [Second](https://i.imgur.com/t4UC2Qt.png)
You're a "computer scientist." Ironically, majors that have the word "science" in the title are almost never about science. Compare: Biology, Chemistry, Physics, Computer Science, Social Science, Political Science
what's the source then?
If you have a master's or doctorate, you might be a computer scientist. If you have a bachelor's, congratulations: you are a programmer.
I don't know why I'm bothering given that you called me an asshole after showing no indication you actually looked for it, but sure, here you go: https://www.infoworld.com/article/3261084/web-development/how-to-implement-background-processing-in-aspnet-core.html Here's another one: https://www.hanselman.com/blog/ASPNETCoreArchitectDavidFowlersHiddenGemsIn21.aspx Have a good day. 
&gt; While some might consider it too politically correct to bother, it really doesn't come anywhere near the same level as some of the others in the list.
We have Alexa she can read for us
The thing I miss most about using WPF (I switched over to mobile/Xamarin a while back) was the amazing Expression editor. I very rarely had to actually edit xaml manually; I used the editor for everything and it was so crazy efficient once you got good at it. Drag/drop data-binding, behaviors, storyboard animations, visual states, etc. I feel like people dismiss the visual editor. Do you not use it?
They are begging to not implement those. It's all begrudgingly. 
They are begging to not implement those. It's all begrudgingly. 
sure I saw those too. now go look at OPs original comment and see that there is quite a bit more stuff to what OP was saying was possible than the two tutorials you provided. fyi, saying "just google it" is rude and a good sign you are an asshole. you should have tried picking up some skills in human interactions along with programming, but maybe you are just on the spectrum and are unaware. if so, my apologies.
Computer Science is a "science" in name only. So, no. You are not. Unless you are doing research somewhere. Coding web apps or programming a game doesnt make you a scientist 
Seems like it's exactly what was being discussed in the thread, running a local web service and using a web front end as the GUI. I think it is pretty universal that when asking for help with a technical issue online, you mention what you've done to resolve it yourself. Perhaps I was being a bit too harsh, but I do stand by the fact that they seem to be if not exactly what you were looking for, close enough to extrapolate. Either way, I'm think I'm done with this line of conversation. I hope those links help.
Second Bob Tabor and the academy. Everything there to get started. Not free but the only other person who I felt was on Bob's level is Mosh Hamedani on Udemy.
&gt; policheck Open source project. Internal closed source tool. Way to go. It's still blocking some PRs in various MS repos as of today. Definitely not intrusive. &gt; considered offensive Considered offensive by *American* customers who are not aware of technical terms used by hundreds of millions of people of color around the world. &gt; it really doesn't come anywhere near the same level as some of the others in the list. It's by far the smallest change in the list that reflects a very dystopian ideology with the worst effect on society. It is Americentrism in a nutshell. 
The current sample makes use of the Material Design theme, it looks to me that you can do anything in QML that you would normally be able to do if you were doing everything in C++/QML. 
Sorry I should've been more clear, the ViewModel should do all those things you're doing- exposing actions it can perform via commands, data its view may need to bind to via properties, and then all of the logic to execute those commands and get that data that it needs. So it definitely should have all the logic. The data models should not have any of that, like you said. But check out my comment two comments ago- the DisplayName "The" problem should probably be handled with an IValueConverter, or in the codebehind somehow. You can read more about converters [here](https://www.reddit.com/r/csharp/comments/4qhww5/mvvmwpf_where_does_ivalueconverter_fit_in/) and [here](https://www.wpf-tutorial.com/data-binding/value-conversion-with-ivalueconverter/). But basically they let you create an object (that would live in the "View" concern of MVVM) that converts data based on how it needs to be displayed. A ViewModel might expose a boolean, but you need that to be a `Visibility.Hidden` or `Visibility.Shown` enum for your XAML- you use a converter for that. Similarly, you can do string manipulation with them. There's a whole library that does a lot of the string specific stuff called [Humanizer](https://github.com/Humanizr/Humanizer) if you end up having a ton of localization to deal with. Controllers as a name is confusing, since those folders in a project tend to correspond to architecture and Model-View-Controller is different than MVVM, but thats just my thoughts. Do you.
I hypothesize that the the code will be shite, I observe the code and conclude my hypothesis is correct based on the fact that the code is shite.
Gmail has 1 billion active users. Even if 10% of these users are unhappy, it still means that 900 million users think it is scrolling well enough for their needs. At the end of the day, you can decide to be angry, but in today's world, you're fighting a battle that only you care about.
No. Only call yourself a Computer Scientist when you are well versed with at least Mathematics, Theoretical Computer Science, Physics AND have contributed a lot to the field of CS. Most people well versed in Computer Science (theory) are usually Physicists and Mathematicians - and that's what they call themselves nowadays. So for now "Computer Scientist" is a term that's only used for physicists and mathematicians, [John von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann) and [Dijkstra](https://en.wikipedia.org/wiki/Edsger_W._Dijkstra) could call themselves Computer Scientists without 
Be highly exploitable.
From initial tutorials when I was a beginner, the gist of it seemed to be able to separate designers from developers and not have each others work break the other's. Turns out devs are left to design their stuff anyway, never enough budget to hire actual designers with some proper UX knowledge. Engineers I worked with even scoffed when I mentioned "user experience" as if it was a buzzword similar to "synergy."
Yeah I never got the json serializer to ignore reference loops. But what you can do is define your own DefaultContractResolver. Like this: https://github.com/rigatron/WebApiMappings/blob/master/WebApi/JsonConverters/CustomContractResolver.cs And then when you want to serialize you can ignore the circular references explicitly by saying var jsonResolver = new CustomContractResolver(); jsonResolver.IgnoreProperty(typeof(EntityModels.Order), "Customer"); 
&gt; most users prefer web or mobile application you mean most **developers**, right?
Well already have VS code, and Visual Studio has a huge ecosystem surrounding it, so I think it's good to keep them differentiated. If they re-wrote Visual Studio then would have to totally re-design everything like SSRS, SSIS, reSharper, SSMS, doesn't seem worth it since if someone wants a lighter cross-platform IDE they already have VS Code.
U can never go wrong with a “for dummies” book
Ah, you probably hit the nail on the head with the file IO.... but in general...multi-threading should increase throughput on a machine that has multiple processors, it's only single processor machines that gain only responsiveness gains right? But even with multiple processors only one thread can communicate with the drive at a time? Ok... but, long reach... what if each thread locked to a different physical drive? Could that let them be processed in parallel? 
There are a lot of special software products, frameworks etc. who offer this kind of service. Just search for "licensing .net " . For example [http://xheo.com/products/copy-protection](http://xheo.com/products/copy-protection) . Not the best or worse, just take a look to understand what this product can, how much it can costs.
Maybe you would get increased throughput on pure calculations. But if you have to do a lot of I/O, even if it's to RAM, you're going to have contention for resources and potentially an overall slowdown.
sign for an academy in your country
Hit the nail on the head, the SJW nonsense is just spreading everywhere.
https://mva.microsoft.com/en-US/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC_2706218949
Thanks, I'll be sure to follow through this course
 I am having trouble finding anything talking about the object life-cycle. Since students should be a reference I would expect you wont execute until you actually do something with it.
The answer is even more complicated in general. First, creating threads takes time and resources. That's why thread pools exist: to try and cut down on that overhead. Next, thread synchronization has costs. If you need locks or other structures to protect shared data, that will introduce overhead. If you need to interact with the UI, that introduces overhead due to marshaling. Finally, having *n* cores doesn't mean you're free to use *n* threads simultaneously. You're sharing the machine with thousands of other processes, and you'll get whatever resources the OS decides to give to you. Put these all together and the answer to "in general" is "there is no guarantee adding threads will increase throughput". It is only after you start to examine specific contexts that you can decide if multiple threads help or hinder you. In this specific context, the disk is a shared resource. If only one thing can access the disk at a time, threads will be slower because they are more overhead constrained by the same thing. You might be able to do better *if* `ProcessFile()` has specific semantics. Maybe what it does is load data from the file, then do work on the data. The "load data" part can't be parallelized, because there is only one disk. However, if you can fit all of the data into memory, maybe "load data" on one thread, then "process data" on multiple threads will yield results. This will only be true, though, if the costs of "process data" are smaller than the costs of "adding threads".
I've tried Blend a few times, especially early on, and ran into weird problems trying to create certain things. I would try to customize something to be an auto-width, and instead I'd get something like `width="243.92"`. It got annoying and I was having FrontPage flashbacks (remember that? :)) so I just resorted to doing it all manually. Then I got used to doing it manually and, frankly, forgot all about Blend. I really should go back to using that. It'd probably make things much better. :)
/u/tweq is presumably suggesting that the client has the map. You're checking whether you can grab a lock on an object reserved for the destination path on your machine. Paths don't make great keys though, there are a lot of casing/relative evaluation shenanigans that can make non-equivalent strings evaluate to the same file on disk. And then there are also all the problems from the other comments about not being able to guarantee file system exclusivity.
Parameterful ~ Parameterised (or parameterized if you're naasty)
If you never need to join these tables in-database, you could try to generate a new DBContext class at runtime (or startup, for previously added tables) using System.Reflection.Emit.TypeBuilder for each of the tables you create in your database. If you do need to join the tables in-database, you'll need to do something similar but replace the DBContext class with a new one from the TypeBuilder on each change (and update your dependency injection to point to the new type).
The sidebar to the right has good resources for learning. If you are on mobile or new reddit style - heres a link to see the sidebar easily - https://old.reddit.com/r/csharp/comments/9p32r6/c_beginner/ 
I've been enjoying Scott Lilly's C# RPG tutorial. https://scottlilly.com/build-a-cwpf-rpg/
Most important rule to avoid Thread/ThreadPool starvation: **100% of the threads your code starts must finish faster than requests are coming in.** This is a truism, but people overlook it quite often. If you ever use `Task.Run` (or StartNew) to "kick something off in the background" and that thing takes longer to finish that your average request, you have created a scalability bottleneck due to potential thread starvation. It will only show up when you have a level of traffic to expose it, but the longer that "background" task takes, the earlier it will show up. For example, say you have a simple web service that accepts a request, calls out to two other APIs, and also calls a very slow SendNotification API that takes 10 seconds. You might be tempted to implement it as public async Task&lt;FooResult&gt; ProcessFoo(FooRequest request) { Task&lt;BarResult&gt; t1 = CallServiceBarAsync(request.Bar); // 100ms Task&lt;BazResult&gt; t2 = CallServiceBazAsync(request.Baz); // 50ms Task throwAway = Task.Run(SendNotificationSlow); // 10s var barResult = await t1; var bazResult = await t2; return new FooResult(barResult, bazResult); } Unfortunately, you will run out of threads with something as little as a steady 30qps (maybe even 10qps, I haven't done the math) for long enough, what to speak of a quick ramp-up to 100s of QPS. Even though your server is returning a response in around 100ms, it's still taking 10s for all the Tasks to finish and return their threads to the threadpool. Using `Task.Run` to fire-and-forget in a web service is almost never the right thing to do. The other thing you'll notice in this examples is that we're doing CallServiceBar/Baz in parallel to shave off a little latency. This, too, is something you need to be careful with. Doing things in parallel can hurt overall scalability if you do it unwisely. If CallServiceBar/BazAsync are using `Task.Run` or otherwise occupying a thread internally, then you're sacrificing a tiny bit of overall scalability in favor of reduced latency. *The webserver already does every request in parallel*, and consuming threads inside your own code occupies threads that could be used elsewhere (including other places inside your own code). If you are saving a lot of latency and latency is a priority, then it's worth it. If you shave off enough latency to finish the request and return all the threads faster, then it may still be worth it. But doing everything you possibly can do in parallel just because you can is not the right course of action.
By what you are typing, you are never retrieving the data. You are only setting a default value. This wouldn't be ideal way on handling the data. Have you looked into: https://docs.microsoft.com/en-us/aspnet/core/performance/caching/memory?view=aspnetcore-2.1 
EntityFramework loads into memory when something such as .ToList() is called on the context. your current var students is a Lazy&lt;&gt; waiting to be loaded, so if the implementation tries to just save it at the moment - you will get nothing. If you do var students = dbcontext.students.ToList();, you should be fine saving the objects. The objects returned are just the model you set in DbSet&lt;&gt;. Do note though - that for that same context, it will have the tracking information for that student, so do not try and pass those models back into say Remove() when you pull it back out of your MemoryCache.
Sooner. It's going to be in .NET Core 3
&gt; but in general...multi-threading should increase throughput on a machine that has multiple processors Only if CPU processing speed is the bottleneck in the first place. Threads are not free. Switching between threads requires a "context switch", which stalls the processing throughput in a big way if it happens too often. A CPU can only process data as fast as you can feed it, no matter how many threads you use. Physical hard drives are really, really slow and doing anything other than a single streaming read or write at a time will only making them slower. Once you get past the hard drive bottleneck, you still have to deal with the fact that the RAM may not be able to feed the CPU fast enough. The IO bus on the motherboard may be a bottleneck as well, which is only one reason why "server class" hardware is more expensive than low-end consumer gear. Finally, what are you doing *with* the data once you've processed it? POSTing to a web service? That's going to be a bottleneck!
&gt; In these situations, i would usually use two threads. &gt; &gt; One which reads the file and loads it into memory, and one which processes the in-memory file. The more general approach is the Producer/Consumer pattern (see `BlockingCollection&lt;T&gt;` for the built-in implementation in C#). Your "two threads" approach is just 1 Producer + 1 Consumer, but you can go ahead and have *n* Producers and *m* Consumers, depending on whichever is faster and how much can be done in parallel.
That's way more code than you need to write. Use this instead: Parallel.ForEach( FilesToProcess, f=&gt; ProcessFile(f, opts)); 1. This will automatically determine the correct number of threads (within a reasonable margin of error) for the task. 2. This will ensure that work is shared between threads so you don't have to worry about all of the large files being stuck on one thread. 3. There is very little risk of screwing up the code.
&gt; so do not try and pass those models back into say Remove() when you pull it back out of your MemoryCache. Unless you attach it to another context. 
I worked for a company that actually used separate designers. It can be effective, but its really expensive.
Still my go to for business environments running on Windows. It’s great for when you need live displays of tons of data. 
They are happy because 1. It is free 2. The spam filter works reasonably well They don't necessarily use the web UI, let alone like it.
Holy shit that is awesome.
Second this. If you really need DRM of any sort, you should use a lib, not roll your own.
To add to this, every time you iterate through an IQueryable (such as DbSet in this case) the query will be executed and streamed over (chunk by chunk however the driver implements it). That's done internally when you call .ToList() or .ToArray() and so on. It's an important detail when dealing with asynchronous applications and foreach loops with sub-queries. :)
First, this is why async await exists, your code can be much cleaner and simpler using the newer language constructs :) Second, depends on what size of file you're reading and your hardware. It won't matter how many threads you have, your hard disk has a certain throughput it cant exceed and if you're capping that out as it is it won't get any faster, your other threads will simply get locked up waiting. Think of how one download usually goes fast while the others you have at the same time get pretty slow.
Do you need indexing on custom fields? If not, you can create a general purpose table with all customer fields stored as a JSON string. In our system, we have a metadata system like this for various purposes. Otherwise, you will have to make extensive use of reflection and find some way to execute the EF tooling in code and that won't be easy. But since you're apparently creating types dynamically, you must be already going down the reflection rabbit hole. You can also just do your SQL manually. My opinion, if you're still within the design stages of your project, reconsider your choice of tooling. EF is not the right tool for this kind of job. You're better served with a dynamic programming language like Ruby or Node where you can exploit metaprogramming to your benefits, than struggle getting a typed programming language ORM to fit an inherently dynamic workload.
EF already caches things in the context in memory unless you are disposing the context or have configured it to be AsNoTracking. Also you can pull the students out of the memory cache and see what it is in the debugger to see if the IQueryable gets executed when you add the students to the memory cache. 
This is exactly what I’ve been looking for! Thank you for this!
I am learning CSharp right now as well. I am using the documentation on Microsofts website. Pretty easy to follow. I also read this subreddit to get more exposure.
This proves my point. Building a successful product is more than building native desktop apps. That's one aspect but rarely enough of a differentiator for most people.
What's not there yet for Xamarin?
My comp Sci professor used to say "If you have to put scientist in your name, you're not really a scientist'
I didn't know this! Unfortunately this is for an ASP.NET application so it's a new context per request.
That's what I figured, I just wanted to find out if anyone knew any better.
Apparently if it's the same context, entity framework will cache it and not actually query the DB.
Others have pointed out other ways to do this. I'll point out what went wrong: if (threadPool[i]!=null &amp;&amp; !threadPool[i].IsAlive) { threadPool[i].Join(); threadPool[i] = null; } This check means that no thread other than thread 0 will get utilized. The first item will get added to 0 start execution. The second item will wait until the 0th thread is done and then the second item will start running on thread 0. This will continue until the Queue is empty. It's an even more expensive way to do single-threading.
There is science the subject and science the activity. He is talking about science the subject.
I'll consider you a scientist bro.
There are a few software license vendors that you can look into. I know wibu and sentinel both have simple license wrappers that just encompass your exe and enforce a license check, which is the fastest way to get up and running. 
&gt; You are an engineer. Fuck that. Unless you suffered through statics, dynamics, thermodynamics, calculus I II III, chemistry I II, linear algebra, physics I II III, and statistics you are not an engineer. While comp sci’s were cruising through soft humanities electives, engineers were busting their balls crunching PDEs.
&gt; unless 
Threads are good for parallel CPU calculation. Tasks are better suited for I/O parallel processing (they don't necessarily start new threads). Then: 1. Mesure 2. Mesure again 3. Use `Parallel.ForEach` as a first option 4. Mesure 5. Mesure again 6. Compare metrics 7. Try to find a bottleneck and play with Parallel.ForEach options (maximum concurrency, whether you need a custom partitioner, etc.) 8. Rinse and repeat
It's true, WPF is great because of the awesome UI framework around XAML and the ease of creating applications with extremely intuitive auto-layout controls, independent resolution, composition, and a lot more. UWP takes all of that and adds even more control and performance to the UI with the same XAML framework. However, UWP is *far* more than what WPF is in that allows multiple languages to be used together (think native C++ and C# libraries working seamlessly together), automatic asynchronous function calling with very easy semantics, the choice of native performance with C++ that WPF doesn't easily work with, and just a ton more that UWP offers. If you are developing a *Windows* application from scratch... UWP is the way to go. All of the new functionality of Windows is being added to UWP at this point. I think the *real* question is whether you develop a Windows specific application or a web application these days. Certainly, for the best *Application* performance and OS integration, UWP is the best choice. If you are developing a *System* application, it's best to use a win32 based application for now; although, it's even better to use a UWP front end with a Windows service as the backend (with win32 and/or powershell). MS will be coming out with devices that *only* runs UWP in the future... I've personally seen one of them at the last major company I worked with that is co-developing some of the technology. As Windows developers, we've been told time and time again that UWP is the future, and MS is doubling down on it. Don't listen to the haters out there... MS' entire strategy of devices hinges on UWP for Windows development. That said, for a client application, I would develop web applications first, if it makes sense and is appropriate for the medium. 
I was a triple major in biology, political science, and philosophy (with a focus on the philosophy of science) and I have no idea what this means. I would greatly appreciate being enlightened. What is the "subject of science" as distinct from science the activity, what is in its purview, and how are those things different from those things that political science and social science study?
Doubt any cs program requires the quintessential engg courses in statics, dynamics, and thermo.
Why don't you use several Stored Procedures that does what you want? Just concat the SQL commands with the table name (that is a parameter) and use sp_executesql. https://docs.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/sp-executesql-transact-sql
Worth it if you can dedicate the time. Tons of .net videos over all kinds of very useful stuff.
 If you're purely trying to not write SQL, EF is the only real way to go. If you just want typed objects, you could also look at Dapper. You write manual sql, but you still get typed objects at the end.
I think it is pretty self-explanatory. It is the difference between a noun and a verb. There is this thing called science (noun, subject of science), and there is the action of doing science (verb, science the activity). 
&gt;which worked but, as we all know, has some weird bugs or design issues What exactly are you doing that brings our weirdness in EF? I've used EF Core/6 rather extensively and most issues I've had were my own fault. 
I've tried lots of things but always end up coming back to sending SQL to the database because SQL is the only thing that ALWAYS works no matter what no exceptions.
* Context lifetime (It's a bad idea to use one context over the whole application) * Modifying relations (navigation properties) is really weird with detache objects (has to be attached first, the relation has to be found using `Find()`, and the set again) I don't know, those issues make sense from the design side of EF, but as a user this is just weird.
I guess I don't particularly find these designs odd. Entity Framework as a whole is actually pretty damn lenient with its change tracking mechanisms -- you can hide the DbObject inside a collection or anonymous object and the all-seeing ChangeTracker will still find it. Granted -- the ChangeTracker is a source of slowness if used unwisely.
So what subjects are science and why are social/political science not science?
Dude I also use and love VS Code but you are comparing apples to oranges here. Each one has it's use case.
Hint: did you see the form, or enter anything? `myNewForm.Show()` or better `ShowDialog()` if available. (Waits until form is closed, before continuing the lines of code that showed it.
ITT: a lot of gatekeeping.
No, he instead wants to use `await Task.WhenAll()` to stay in Task/Async world
Literally just realised how many hours I've wasted without this...
But wouldn't that incur a lot of overhead for data manipulation where you use auto properties instead of public fields, since there would be at least another functioncall inside the setter. Think of manipulating millions of items, eg Path-finding or something else.
Definitely need to call ToList to retrieve the related entities I would also add that you’re better to have your caching as a method with DI. I don’t know how far you plan on taking your application but if your application ends up being load balanced then you would want a distributed caching technique (redis or other) and you may way to swap out your in memory caching. 
I stepped through the code, it does not restrict initialization to threadPool[0] I updated the code only so it didn't require Values outside the example class Program { public static void Main() { String chars = "ABCDEFGHIJKLMNOP"; rng = new Random(100); Queue&lt;String&gt; FilesToProcess = new Queue&lt;String&gt;(); foreach (char c in chars) FilesToProcess.Enqueue($"{c}"); Thread[] threadPool = new Thread[8]; while (FilesToProcess.Count &gt; 0) { for (int i = 0; i &lt; 8; i++) { if (threadPool[i] != null &amp;&amp; !threadPool[i].IsAlive) { threadPool[i].Join(); threadPool[i] = null; } if (threadPool[i] == null &amp;&amp; FilesToProcess.Count &gt; 0) { threadPool[i] = new Thread(new ParameterizedThreadStart(ProcessFile)); //ProcessFileThreadArgs targs = new ProcessFileThreadArgs(FilesToProcess.Dequeue(), opts); threadPool[i].Start(FilesToProcess.Dequeue()); } } } foreach (Thread t in threadPool) { if (t != null) t.Join(); } Console.WriteLine("Done"); Console.ReadKey(); } static Random rng; public static void ProcessFile(object i) { int wait = rng.Next(10000); Console.WriteLine($"Starting wait: {i}"); System.Threading.Thread.Sleep(wait); Console.WriteLine($"Ending wait: {i}"); } } Output class Program { public static void Main() { String chars = "ABCDEFGHIJKLMNOP"; rng = new Random(100); Queue&lt;String&gt; FilesToProcess = new Queue&lt;String&gt;(); foreach (char c in chars) FilesToProcess.Enqueue($"{c}"); Thread[] threadPool = new Thread[8]; while (FilesToProcess.Count &gt; 0) { for (int i = 0; i &lt; 8; i++) { if (threadPool[i] != null &amp;&amp; !threadPool[i].IsAlive) { threadPool[i].Join(); threadPool[i] = null; } if (threadPool[i] == null &amp;&amp; FilesToProcess.Count &gt; 0) { threadPool[i] = new Thread(new ParameterizedThreadStart(ProcessFile)); //ProcessFileThreadArgs targs = new ProcessFileThreadArgs(FilesToProcess.Dequeue(), opts); threadPool[i].Start(FilesToProcess.Dequeue()); } } } foreach (Thread t in threadPool) { if (t != null) t.Join(); } Console.WriteLine("Done"); Console.ReadKey(); } static Random rng; public static void ProcessFile(object i) { int wait = rng.Next(10000); Console.WriteLine($"Starting wait: {i}"); System.Threading.Thread.Sleep(wait); Console.WriteLine($"Ending wait: {i}"); } } 
It’s not a silver bullet, though. If the work is mostly I/O bound, it won’t really make the best scheduling decisions. 
What does a static variable for a method even look like, and how do you define that scope in C?
public void functionA(void) { static int totalTimesFunctionRun=0; totalTimesFunctionRun++; } That is how you do it in c.
C# does not support local static variables, as you’ve discovered. The alternative is to move the variables to class scope with unique names. I don’t know that there’s a “preferred” naming convention. 
You might want to check out the TPL Dataflow library. [Here's a blog with examples](http://blog.i3arnon.com/2016/05/23/tpl-dataflow/)
I like that one :) Only those in the know will understand!
I think in this case you’d probably want to declare those variables as private static, to prevent external access. 
Yes, but if I had fifty different methods with that same variable, it gets clunky. I need to make new names, and manually change them by hand. Something that should not take any time is taking me considerable time.
Yes but you could simply just have a private global static depending on the environment 
For fire-and-forget would you recommend `QueueBackgroundWorkItem` or something like `Hangfire`?
It’s not a myth I’ve dealt with both for a long time and I’d much rather be handed a winforms app to maintain than a wpf one.
Not wasted. You got to experience working with manual threads, a skill that is still needed even when we use this kind of thing most of the time.
Yes, remember the times when companies didn't offload their front-end processing on their users? Good times.
You could use a static property that used RTTI (run time type info) to work out the method called from and update a static dictionary keyed on the method. There would be a performance impact but it means less tedious code changes.
Electron is cancer. And you want to spread it.
 A functional call takes nano seconds, and regardless, auto property getters are inlined, the compiler is smart enough to know that an auto property is just a public field in disguise. There is no performance penalty. Here is my gist: [https://gist.github.com/Dispersia/d446f4a6b43831597befc8a1aac09b4f](https://gist.github.com/Dispersia/d446f4a6b43831597befc8a1aac09b4f) &amp;#x200B; here is the results: Method | Mean | Error | StdDev | \---------------------- |---------:|---------:|---------:| TestClassAutoProperty | 503.1 ms | 2.613 ms | 2.4410 ms | TestClassField | 504.0 ms | 1.073 ms | 0.8376 ms | &amp;#x200B; &amp;#x200B;
Because the only thing they do is display numbers. Trust me, on the financial world, it's either a web front script mess or an ASIC. There is no middle ground.
I mean, the browser is still a desktop app, at least, right?
Bingo. Users don't care what it is, they just get pissed when they click to open facebook and it takes 15 seconds to load.
Exactly, one of the reasons the web is so shitty today is because the server work has been mostly offloaded to the client.
Cannot deny that. One thing is business, one thing is making proper software. But don't come justifying technical decisions with popularity. That's not how engineering works.
Bingo.
Regardless of where the image is stored, db or web folder, you could set up a page (I see aspx so assume not MVC) that reads the image byte data either from the db or web folder, and then returns the array as a file, Telerik won't know or care where the image is actually coming from. You would point your telerik module at your new page something like: &amp;#x200B; control.Src = "yourlocalhost/Home.aspx?fileId=1 &amp;#x200B; control.Src = "yourlocalhost/Home.aspx?filename=yourfilename.jpg" &amp;#x200B; My example uses the default home page, but you could set up one specifically to return images. &amp;#x200B; Something like below: &amp;#x200B; `protected void Page_Load(object sender, EventArgs e) {` &amp;#x200B; `string filesDatabaseId = Request.QueryString["fileID"];` `//OR` `string filename = Request.QueryString["filename"];` &amp;#x200B; `//Hard coding for the example` `filename = "black heron.jpg";` `//Read file from web folder` `string filepath = @"C:\temp\" + filename;` &amp;#x200B; &amp;#x200B; `//Read byte[] that you have saved in database using the filesDatabaseId` &amp;#x200B; &amp;#x200B; `//Either way you end up with a byte array you can return` `byte[] fileData = File.ReadAllBytes(filepath);` &amp;#x200B; `Response.Buffer = true;` `Response.Clear();` `//Set the return content type to that of the image you are serving` `Response.ContentType = "image/jpeg";` `Response.Expires = 0;` `//Return the byte array` `Response.BinaryWrite(fileData);` &amp;#x200B; &amp;#x200B; `}` &amp;#x200B; Hope it's useful, someone else might have a better approach. &amp;#x200B;
&gt;Gmail has 1 billion active users. Even if 10% of these users are unhappy, it still means that 900 million users think it is scrolling well enough for their needs. This thought scares me. This younger generation has no empathy. All you think about is yourself. Who cares about 100 millions users right? The amount of man-hours just fighting with computers every day, are enough to send a man to the moon every month. But you? You don't care. "Works on my machine". 100 million people losing 1 minute a day due to UI frustrations amounts to a LOT of waste, stress, and lost money.
The only thing you can really do is lift the variable to a scope that makes sense in C#, and method scoped static variables simply do not make sense. Beyond that though, I think you're approaching this whole process the wrong way. Taking C++ code one to one into C# is going to result in horrible, unmaintainable C# code, and is effectively a complete waste of time. You may as well just call the original C code. It's also insane to write code like this as one gigantic mega project. Porting is no different than any other kind of coding. Write and test this code piece by piece. There's no reason to implement the whole thing in one go.
Firstly you should never use \`new Thread()\`, if you want to work with raw threads then use ThreadPool.QueueUserWorkItem() - [threadpool docs](https://www.google.co.uk/search?q=queuenewuserworkitem&amp;rlz=1C1CHBF_en-GBGB799GB799&amp;oq=queuenewuserworkitem&amp;aqs=chrome..69i57j0l2.5850j0j7&amp;sourceid=chrome&amp;ie=UTF-8) \- the reason being is when starting a new thread you're actually allocating a lot of resource to it when it spawns. Using the thread pool, you let it decide what to give you and how much. This makes it far more efficient. Also, remember that when you're doing IO to disk, the fast possible speed you can go at is the disk. So make sure you're not firehosing it.
Use async / await
This is actually a really good suggestion when you a) have more than a handful of methods that follow the pattern, and b) speed isn't massively critical. i.e. have a `private static Dictionary&lt;string, int&gt; _callCounters;`
This needs much more up votes. Was not aware it was a thing even
Not sure why you're being DV'd because this is completely correct. VB.Net supports this is well, but there's some CLR hackery involved to make it work as expected.
How can it be private and have global scope?
Far and away the best suggestion IMO. You can even use C#'s `nameof` operator to make this even easier: ``` private static Dictionary&lt;string, int&gt; _callCounters; public static void functionA() { _callCounters[nameof(functionA)] = _callCounters[nameof(functionA)] + 1; } ``` If you use an aspect-oriented framework like PostSharp, this becomes as simple as adding an attribute to every method you wish to instrument.
I'm looking at it from an Asp.net perspective. If you have a private global static in the controller. Any method in that controller can access it. Others outside it cannot 
I noticed this myself. I won maybe 1 or two seconds from what initially took 11 seconds.
Hence, "programmer joke"...
Do you know what the IL looks like for it?
Why don't you just port the code to C++/CLI?
It depends on a number of factors, async comes with overheads but the general rule is if working is waiting on an IO block then use async, because it can do multiple things using the same thread while doing the waits. If it’s cpu bound then you need multiple cores active, the performance advantage of course is limited by the standard mutex/locks/semaphore mechanisms of the OS. Not every combination of work load is guaranteed to give a performance advantage, particularly tons of short calls like read line. Async is good for making multiple simultaneous network requests, multi thread is good for processing, in theory it can help with multi network calls too, but it has a higher over head and I expect couldn’t handle nearly the same volume as async. Threading is quite limited in how many your app can kick off and maintain due to the thread needing to be active on a core whilst async could probably handle 100x the throughput.
How do you reference that later, for logging or whatever? Do you have to use the method scope anyway? Or does the method log it?
Probably means global to the class, eg a private static member as opposed to a method variable 
Very true, but you could use method info as the key instead. Alright I've never needed to retrieve the method info in the method that's actual executing. I'm sure it's possible though.
+1 Though this is pretty obvious by now for many of you, I’ll still repeat this as I saw someone implementing try/catch/finally incorrectly citing compile time errors: Since C# 6, you don’t have to Task.GetAwaiter().GetResult() or invoke Task.Result in catch and finally; await works!
https://www.reddit.com/r/dotnet/comments/9ondqj/beginner_with_no_programming_background/e7v8ldm/?context=0
for each static method with static variable create its own class: public void functionA(void) { static int totalTimesFunctionRun=0; totalTimesFunctionRun++; } into private static class functionA_Wrapper { private static int totalTimesFunctionRun=0; public static void Invoke() { totalTimesFunctionRun++; } } public void functionA() =&gt; functionA_Wrapper.Invoke(); 
Believe Eto wraps that for me but would have to check.
I've considered it. I've not used XAML before though. Assuming I could consume raw XAML at runtime to create a window would leave some interesting options on the table.
Much easier than i thought... System.Reflection.MethodBase.GetCurrentMethod();
Removed: Rule 4.
&gt; new reddit style Damnit. I knew I was forgetting something. RemindMe! 12 Hours
I will be messaging you on [**2018-10-19 00:29:40 UTC**](http://www.wolframalpha.com/input/?i=2018-10-19 00:29:40 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/csharp/comments/9p32r6/c_beginner/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/csharp/comments/9p32r6/c_beginner/]%0A%0ARemindMe! 12 Hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Are you trying to build a dynamic form and let the user decide column types and names? EF is not really designed or setup to do this and I think you'll hit many walls going down this route.
WPF isn't going to be cross platform, even with .NET Core 3.
This question is analogous to "Is HTML programming?", which is analogous to "Is a hot dog a sandwich?" That is to say, it is a competition of dictionary entries and too-narrow categorizations. I'm not a social/political science major, but I've heard this argument before and I feel like it boils down to this: To people in general, science is believed to find truths. "If I put this element in solution with that element, I get this compound in this proportion". You can try it a thousand times and it will be right a thousand times. Those people imagine trying that with people. "Ask this question a thousand times and you'll get two thousand different answers." In a nutshell, that means "not a science" to them. If they were required to take a few more humanities courses, they might disagree. There are a lot of things one can do to manipulate specific reactions out of large populations, right? I mean, surely at some point in history we'd have evidence that people, by and large, will believe a false statement *while observing the evidence it is false.* Definitely doesn't happen repeatedly.
This is super dangerous for web applications. Why not just make it a local variable or pass it in
Change it to a single static dictionary at the class level. static Dictionary&lt;string, int&gt; methodCallCounts = new Dictionary&lt;string, int&gt;(); Now it's simpler and flexible! Each method that wants to store it's count is using the same static variable keeping it nice and clean.
Derp. You're right, I overcomplicated that.
How is requirement #2 implemented?
- by education - yes - by experience - ? - by occupation - ? hopefully you got the idea; you need to provide more info.
Thanks for your response! (sorry for my late reply) The reason I was considering doing everything in C# and only storing the initial values in SQL was due to my stored procedure being dynamic. I'm very much of a beginner with both C# and SQL and have done something like this in VBA in MS Access (which was still really gross). I have two tables (tblCust and tblID). tblCust holds just the customer information (id number, name, address, contact, etc.) while tblID holds balance information (id number, balance, date) . My stored procedure joins tblCust to tblID on the associated id numbers, then creates a pivot table to show the average of balance per month for the past three years. I'm needing to take that stored procedure's result, and find the percent difference (something like (month1 / month2) \* 100) and then that must be sent to another Excel worksheet. The calculation itself, I'm not sure if it will cause a whole lot of performance issues or not. I'll take a look into Entity Framework! Thanks for the tip 
Not appropriate, because a static method variable in VB is tied to the instance, which is not the same behavior you would see in C# or C++. 
I'm trying something like this: &amp;#x200B; LoaderClass { static ConcurrentDictionary&lt;string, string&gt; eventIds static ConcurrentDictionary&lt;string, string&gt; currentDownloads LoaderClass() { EventProcessorClass(eventIds, currentDownloads); } } EventProcessorClass { private ConcurrentDictionary&lt;string, string&gt; _eventIds; private static ConcurrentDictionary&lt;string, string&gt; _currentDownloads; EventProcessorClass(ConcurrentDictionary&lt;string, string&gt; eventIds, ConcurrentDictionary&lt;string, string&gt; currentDownloads) { _eventIds = eventIds; _currentDownloads = currentDownloads; //then used in various public/private/async methods wrapped in tasks } } I'm not sure how / when I 'm going to clear these collections out, I'm just trying to get the first step working. Thoughts? &amp;#x200B;
Computer Science is such a misnomer - lol Disclaimer, I have a BS in CS :-p
hah, I just forgot that they renamed it Visual Studio Blend, dropping the Expression bit. :) 
There were always a few 'tricks' you needed to know in order to NOT generate horrible xaml, which most people didn't bother to learn, so they assumed it was bad. Many of these things were fixed over time, but probably not all of them. The thing is, I do a lot of (xamarin forms) xaml by hand these days, and it's not that bad as long as long as you're doing fairly simple stuff. It was when you had complex views with lots of visual states and custom animations between each of those states that Blend became SUPER handy. But even with the simple stuff, it was still much more fun.
You can build that functionality into the class if you just build a dictionary and use reflection to get the method names as a key.
He's being downvoted because he's wrong. Static in non-shared methods are bound to the instance. https://docs.microsoft.com/en-us/dotnet/visual-basic/language-reference/modifiers/static &gt; When you declare a static variable in a procedure that isn't Shared, only one copy of the variable is available for each instance of the class.
No, it isn't the same functionality. Unless you don't consider access protection a function of the language (Public, private, internal, etc...). In C, that static variable will be scoped to the method. Very useful in implementing [PoLP](https://en.wikipedia.org/wiki/Principle_of_least_privilege).
Did that a few years back. It is NOT an easy way. Would not recommend to anybody. 
I find it way easier than struggling around with P/Invoke declarations. It all depends where one is coming from. I got my first C++ compiler in 1992.
I believe grauenwolf and myself are talking about this scenario: &gt; When you declare a static variable in a Shared procedure, only one copy of the static variable is available for the whole application. You call a Shared procedure by using the class name, not a variable that points to an instance of the class. Because why would you even declare a non-shared method and then use a static in it? VB is just *weird*, man.
I've made the assumption that someone porting C to C# is smart enough to know that they should not take all of their advice from comments on an anonymous internet forum.
Rather than porting the code, can you not write tests that cover its behaviour and then freely implement it "the right way" in C#?
Static locals in C++ are static even in non-static methods. Therefore it is not appropriate to suggest that they use this vb.net feature.
If you want to learn it the right way, read this book. I warn you, it is deeply technical. But there is no better source. https://www.amazon.com/Concurrent-Programming-Windows-Joe-Duffy/dp/032143482X
Oh right. It's been too long since I programmed in VB.
I may be mistaken, but this is how "work stealing queues" was explained to me. Lets say there is 100 items and the runtime decides that 4 threads are appropriate. It will create 4 queues, one per thread, with 25 items each. This way the various queues are not fighting over locks. (Lock contention wouldn't be an issue here, but for CPU bound work you could spend more time waiting on locks than on actual work if there was one queue.) But that leads to the possible imbalance problem. So if a thread does finish everything in its queue, it can "steal work" (that's the real term) from another queue. I don't know if it steals just one item or a percentage of the remainder. 
lambda, use lambdas as they support closures which is what you're trying to do. 
Looking for developers for a sass finance application in Reading UK We have build a custom risk analysis platform for finding risk in payment and supplier data, we are looking to expand in many areas so all skill levels welcome. Languages: * c# * sql * typescript Platforms * dotnet core * react * azure * vsts(Azure devops) Please send me a message if you want any more details or to apply!
I think you're approaching this the wrong way - you shouldn't be relying upon knowledge of the underlying enumerator - that's kind of the whole point of the interface. Instead, if you're looking to promote a specific usage of the code, I suggest either using concrete classes (so the developer knows what type it is) or wrapping them in separate interfaces that offer more understanding to the consumer - for example: IEnumerable&lt;int&gt; someEnumerable = SomeInfiniteSeries(); // people calling someEnumerable.Count() don't know why it's completely locking the CPU until int.MaxValue! public interface InfiniteSeries&lt;T&gt; { IEnumerable&lt;T&gt; Take(int count); } public class InfiniteSeriesWrapper : InfiniteSeries&lt;T&gt; { private IEnumerable&lt;T&gt; _source = null public InfiniteSeriesWrapper(IEnumerable&lt;T&gt; source) { _source = source; } public IEnumerable&lt;T&gt; Take(int count) { return _source.Take(count); } } // in this way, you can literally prevent someone from doing something 'bad' by your contract interfaces var infiniteSeries = new InfiniteSeriesWrapper(someEnumerable); // infiniteSeries.ToList() doesnt exist! It's kind of basic 'pit-of-success' philosophy - design your code such that consumers *or other developers on your team* can't mess it up.
I would try my hardest to avoid P/Invokes and mixed code. Except maybe for a really small APIs. For one C+/CLI forces dynamic linking which means that instead of one C++ DLL or EXE you get a bunch of dependencies and in C++ switching from static linking to dynamic one with DLLs is not fun.
Convert these functions to static classes. For example this: void MyFunction() { static int myStatic = 1; } would become public class MyFunction { static int myStatic = 1; public static void MyFunction() { } }
Hello, thank you for your time writing this out. However I do not think this will work with a Windows form App. I choose regex because it worked the moment I would place a incorrect character into the field. The I suppose it might be my fault. The complete code is this. &amp;#x200B; private void name\_TextChanged(object sender, EventsArgs E) { if (System.Text.RegularExpressions.Regex.IsMatch(textBox1.Text, @"\^\[a-zA-Z\]+$")); { [MessageBox.Show](https://messagebox.show/)("Letters only please"); textBox1.Text = textBox1.Text.Remove(textBox1.Text.Length - 1); } } &amp;#x200B; And for every text box I need that. I think the consolewriteline would happen at the end of the program rather than at the error point.
You shouldnt be using static variables at all. They are glorified global variables, they break encapsulation and they are death to testability. Avoid them the best you can, and you can be a better programmer than that. 
&gt;What about Political Science majors? Don't you have to have a job to be considered a scientist?
I wouldn't say that. If you are building a long-running task, especially one that literally runs until the application exists, then you should not use a thread-pool thread. That needs to be on its own dedicated thread or you'll starve the thread pool. 
If you're targeting enterprise you need to make sure what you use is production ready and heavily battle tested. That's why WinForms / wpf are still used so heavily. Honestly you would likely be better off creating a web app unless it has to be desktop 100%. As a desktop developer trapped in a web dev job it feels weird saying this. But it is the way things are moving.
Some types of applications just shouldn't be used in a web environment in my personal opinions. This type of project is one of them. I too feel the pull to really learn some more in the web realm because of the shift but think I will stand my ground on this one. &amp;#x200B; If all else fails the way I am building this the front end switch from desktop to web really shouldn't be a huge hassle and definitely not a complete rebuild so the option is still there.
Ok, average balance is a tough problem, but possible. If you really want a daily-weighted average for a given month it would take some consideration, but this may give you some ideas: with tblCust (id, [name]) as ( select 1, 'bob' union select 2, 'joe') , tablId (id, balance, [date]) as (select 1, cast(500 as float), parse('2018-07-01' as datetimeoffset) union select 1, 100, parse('2018-08-01' as datetimeoffset) union select 1, 200, parse('2018-09-01' as datetimeoffset) union select 1, 220, parse('2018-09-15' as datetimeoffset) union select 1, 228, parse('2018-09-16' as datetimeoffset) union select 1, 250, parse('2018-10-01' as datetimeoffset) union select 2, 99999, parse('2018-07-01' as datetimeoffset) union select 2, 200, parse('2018-08-01' as datetimeoffset) union select 2, 200, parse('2018-09-01' as datetimeoffset) union select 2, 200, parse('2018-10-01' as datetimeoffset) union select 2, 211, parse('2018-10-01' as datetimeoffset) ) select distinct c.id, c.name, avg(b.balance) over (partition by DATEPART(month, b.date)) avg_bal, DATEPART(month, b.date) month_number from tblcust c join tablId b on c.id = b.id where b.date &gt; GETDATE()-(30*3) /* may need to find first of month? */ 
Why would you expect that?
I love the pit-of-success. It's sometimes hard to write code with the pit-of-success in mind as a convenience to *myself*, so I thought I'd give it a shot. void Main() { Func&lt;int,int&gt; squares_provider=(i)=&gt;i*i; InfiniteSeries&lt;int&gt; series=new InfiniteSeries&lt;int&gt;(squares_provider); /*foreach(var v in series) //compiler error! { Console.WriteLine(v); }*/ foreach(var v in series.Section(3,8)) { Console.WriteLine(v); } } public class InfiniteSeries&lt;T&gt; { Func&lt;int,T&gt; _provider; public InfiniteSeries(Func&lt;int,T&gt;provider) { _provider=provider; } public IEnumerable&lt;T&gt; Section(int start,int length) { for(int i=start;i&lt;start+length;i++) { yield return _provider(i); } } } 
Good idea, bad assumption. :) But you can only solution for the constraints you know, right?
I read this two seconds after thinking of it. Seems like the most natural way of doing things. 
In C#, structs are ValueType while classes are reference types. When being copied around, t2 of struct gets a *copy* of everything in t1 of struct, while t2 of class gets a *copy of reference* to the same Point instance on the heap that t1 also points to. 
That's because people write garbage code like this: IEnumerable&lt;Customer&gt; GetCustomers() return new List&lt;Customer&gt;(){...}; There is no justification for returning an `IEnumerable&lt;T&gt;` when you know what the concrete type is. 1. As you discovered, it removes vital information about the return type. 2. It hurts performance. Calls through interfaces are slower than calls to non-virtual public methods. 3. It hurts performance because you can't use the special enumerators that `List&lt;T&gt;` exposes. 4. It hurts performance because people have to make defensive copies (`ToList`) since they don't know its behavior. 5. You may need some of the other methods/properties on the returned type. Some common myths. * Returning it as an `IEnumerable&lt;T&gt;` makes it read-only. No it doesn't. It gives the illusion of being read-only, but as soon as you use any kind of reflection (e.g. data binding) the trust becomes apparent. * It allows me to change the implementation later. One, you can always do that. Two, if you do change the implementation, say from a list to a lazy enumerator, that's going to have effects on the code which need to be dealt with. (Such as defensive copies.) Conclusion: Only return an object as an `IEnumerable&lt;T&gt;` when you are returning a lazy enumerator. Otherwise return the most specific type you can. Which may be a concrete type or another interface such as IList&lt;T&gt;.
I agree with you in theory, and I normally try to approach code using a pit-of-success mentality (hence why I'm asking this question!). However Enumerable&lt;T&gt; has been pretty much designed to be ergonomic and nice to use, so there's actually a pretty compelling reason to expose it directly instead of wrapping it in your own interface - for example being able to call foreach (var result in GetResults()) { DoSomeProcessing(result); } Unfortunately because Linq implements `.Count()` which if you're not paying attention, is very similar to the `.Count` property on a collection type, exposing this interface feels like a risk. The best way I've found of encapsulating this while keeping some of the iteration ergonomics is something like: void ProcessEntities(Action&lt;Result&gt; processFunc) { foreach (var result in GetResults()) { processFunc(result); } } This is still less ergonomic though - exception handling becomes slightly less clear, and more complex logic can be a pain.
&gt; Obviously when you think about it, this behaviour is necessary, but in a codebase where lists and enumerables are used fairly interchangeably, it can be easy to make this mistake and hard to communicate cases where this should not be done. This is because many (most?) C# developers weren't correctly educated on this subject. They see IEnumerables as simple wrappers of C-like arrays, not as Haskell-like monads. I'm actually sick of so many unnecessary calls to `.ToArray()` and `.ToList()` in pretty much every large-scale C# codebase I maintained. I'm sick of methods that accept an array argument where it could be an IEnumerable (so the called needs to convert its IEnumerable to an array because the programmer who implemented the method is dumb). You know what? I stopped fighting. I just accepted people will use arrays, lists and IEnumerables without actually understanding the differences. In codebases I maintain alone I make the best use of abstractions I can, but in [mostly old] codebases full of broken abstractions I take a deep breath and go with the flow. Another thing that grinds my gears is the use of low level concurrency techniques where higher abstractions could be used. We rarely need `new Thread(() =&gt; ...)` nowdays.
A tip, among a tons of others you'll have to learn along the way: when trying to debug something and asking for help, always include the line that produced the exception. Right now, it indeed seems that the exception would have been thrown on the `Remove` line, but as I understand it, it is thrown BEFORE the MessageBox shows up?
Structs have value type semantics. Point t2 = t1 copies the values of struct t1 into t2. Likewise, the same happens when you use them as method parameters. t1 and t2 are unique copies, changes made to t2 won't do anything on t1. Classes have reference type semantics. {Class} Point t2 = t1 assigns the pointer t1 to t2. Now t1 and t2 point to the same memory address. They reference and operate on the same memory location.
Em yes basically here reference is pointer. t2 and t1 point to the same object. So yes if in class code t3=t2 and t3.x=0 then t1.x and t2.x would also be zero. 
Hello, I have given all of the code related to the error. However no, the exception is thrown after the message box shows up. What is supposed to happen; and does happen when I have an "Numbers-only" text box is, an illegal character is entered, an Messagebox appears explaining that its numbers only, then the illegal character is deleted. However what happens when I enter an illegal character for my "letters-only" box is I enter the illegal character, the messagebox explaining that it is "letters only" shows up, then Microsoft Visual studio opens the code and gives me the error " System.ArgumentOutOfRangeException: "StartIndex cannot be less than zero. Parameter name: startIndex'" &amp;#x200B; It then will not delete the illegal character. &amp;#x200B; Thank you for responding.
Yeah, hangfire creates it's own thread pool, although the main advantage is job durability and horizontal scaling.
This is probably serious overkill, but there is a way to implement something that effectively gives you real static local variables in C#. In System.Runtime.CompilerServices there are attributes that let you reference data about the code itself that is done at compile time so it's possible to construct a dictionary track static local variables by this data. Here's an implementation of it I did. public static class StaticLocal&lt;T&gt; { static StaticLocal() { dictionary = new Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt;(); } public class Access { public T Value { get; set; } public Access(T value) { Value = value; } public override string ToString() { return Value.ToString(); } public static implicit operator T(Access obj) { return obj.Value; } } public static Access Init(T value, [CallerFilePath]string callingFile = "", [CallerMemberName]string callingMethod = "", [CallerLineNumber]int lineNumber = -1) { var firstKey = lineNumber; var secondKey = callingFile + '.' + callingMethod; if (!dictionary.ContainsKey(firstKey)) dictionary.Add(firstKey, new Dictionary&lt;string, Access&gt;()); if (!dictionary[firstKey].ContainsKey(secondKey)) dictionary[firstKey].Add(secondKey, new Access(value)); return dictionary[firstKey][secondKey]; } private static Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt; dictionary; } Calling StaticLocal.Init(value) will either create a new entry for the method calling it, on that particular line, or (if it already exists) return a reference to an Access&lt;T&gt; object containing the value. The value passed to Unit will be ignored if the reference already exists. Of course, this is not thread safe and is less efficient than simply storing the value in a private field. It does simulate the same sort of usage available in other languages though. This is probably most useful as a warning that you should try something different, rather than foist a feature upon it that the language doesn't support.
note: foreach is slower and allocates on collections. The difference is small, and the amount of code/typing is reduced, so if you are doing a lot of work in the loop, or it isn't a perf critical section, maybe don't worry about it. If it is a hot loop with not much work done inside, the overhead of iterating can be a large % of total work. Or if the loop happens often the GC pressure might matter. foreach on arrays is not slower, and doesn't allocate, so you can always feel free to use foreach there. &amp;#x200B; &amp;#x200B; &amp;#x200B;
I've lost track of the number of times I needed to write this: IList&lt;T&gt; ToSafeList&lt;T&gt;(IEnumerable&lt;T&gt; source) if( source is IList&lt;T&gt;) return (IList&lt;T&gt;)source; else return source.ToList(); 
Or even just geography types in SQL Server. Man, I hate working with that so much.
You forget to mention this trick: static void IncrementCount([CallerMemberName] string methodName = null) It really reduces the error count.
This is probably serious overkill, but there is a way to implement something that effectively gives you real static local variables in C#. In System.Runtime.CompilerServices there are attributes that let you reference data about the code itself that is done at compile time so it's possible to construct a dictionary track static local variables by this data. Here's an implementation of it I did. ` public static class StaticLocal&lt;T&gt; ` { ` static StaticLocal() ` { ` dictionary = new Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt;(); ` } ` ` public class Access ` { ` public T Value { get; set; } ` public Access(T value) ` { ` Value = value; ` } ` public override string ToString() ` { ` return Value.ToString(); ` } ` public static implicit operator T(Access obj) ` { ` return obj.Value; ` } ` } ` public static Access Init(T value, [CallerFilePath]string callingFile = "", ` [CallerMemberName]string callingMethod = "", ` [CallerLineNumber]int lineNumber = -1) ` { ` var firstKey = lineNumber; ` var secondKey = callingFile + '.' + callingMethod; ` if (!dictionary.ContainsKey(firstKey)) ` dictionary.Add(firstKey, new Dictionary&lt;string, Access&gt;()); ` if (!dictionary[firstKey].ContainsKey(secondKey)) ` dictionary[firstKey].Add(secondKey, new Access(value)); ` return dictionary[firstKey][secondKey]; ` } ` ` private static Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt; dictionary; ` } Calling StaticLocal.Init(value) will either create a new entry for the method calling it, on that particular line, or (if it already exists) return a reference to an Access&lt;T&gt; object containing the value. The value passed to Unit will be ignored if the reference already exists. Of course, this is not thread safe and is less efficient than simply storing the value in a private field. It does simulate the same sort of usage available in other languages though. This is probably most useful as a warning that you should try something different, rather than foist a feature upon it that the language doesn't support.
Yes they are global variables, but sometimes that's what's needed. It is better to learn how to use them correctly than to run in fear.
The only way to use them correctly is to use them as an example of how bad code can be written, and to educate newbie how not to write their program. 
This is probably serious overkill, but there is a way to implement something that effectively gives you real static local variables in C#. In System.Runtime.CompilerServices there are attributes that let you reference data about the code itself that is done at compile time so it's possible to construct a dictionary track static local variables by this data. Here's an implementation of it I did. ` public static class StaticLocal&lt;T&gt;` ` {` ` static StaticLocal()` ` {` ` dictionary = new Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt;();` ` }` `` ` public class Access` ` {` ` public T Value { get; set; }` ` public Access(T value)` ` {` ` Value = value;` ` }` ` public override string ToString()` ` {` ` return Value.ToString();` ` }` `` ` public static implicit operator T(Access obj)` ` {` ` return obj.Value;` ` }` ` }` `` ` public static Access Init(T value,` ` [CallerFilePath]string callingFile = "",` ` [CallerMemberName]string callingMethod = "", ` [CallerLineNumber]int lineNumber = -1)` ` {` ` var firstKey = lineNumber;` ` var secondKey = callingFile + '.' + callingMethod;` ` if (!dictionary.ContainsKey(firstKey))` ` dictionary.Add(firstKey, new Dictionary&lt;string, Access&gt;());` ` if (!dictionary[firstKey].ContainsKey(secondKey))` ` dictionary[firstKey].Add(secondKey, new Access(value));` ` return dictionary[firstKey][secondKey];` ` }` `` ` private static Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt; dictionary;` ` }` Calling StaticLocal.Init(value) will either create a new entry for the method calling it, on that particular line, or (if it already exists) return a reference to an Access&lt;T&gt; object containing the value. The value passed to Unit will be ignored if the reference already exists. Of course, this is not thread safe and is less efficient than simply storing the value in a private field. It does simulate the same sort of usage available in other languages though. This is probably most useful as a warning that you should try something different, rather than foist a feature upon it that the language doesn't support.
You can't remove an element from an array, arrays have set sizes so int\[8\] always has 8 ints in it, each type has a "default" which for int is 0.
Wait, doesn't that mean that the source enumerable (in this case IList) will get modified by any subsequent modifications to the returned value? Wouldn't you need to clone it to get consistent results between ILists and other enumerables? The only reasons I could think of for converting to a list are 1: to modify it in some way, 2: to access an element by index or 3: call a library method which requires a list, and options 1 and 3 could both affect the original collection.
A reference is basically a pointer, just not as scary, since it is managed for you by the garbage collector in the runtime.
I think you can use the LAG to do this pretty easily. Linked above.
&gt;if (collection.count() &gt; 0) doSomething(); If I had a penny for every time I saw that...
Why `ToSafeList` and not `ToFastList`? I don't see any safety involved here. Are you on the .NET Framework? If you're on .NET Core, [you don't need that anymore](https://github.com/dotnet/corefx/blob/7fc25c833afbfbdd3a7d035922d4d0cda4edd5b7/src/System.Linq/src/System/Linq/ToCollection.cs#L23-L31).
Thanks!
I believe you just have to check if the string is empty before calling Remove then. WinForms events can be a bit wonky at times, and it's possible it's called twice, producing the error you're witnessing. Actually, you should check at the start of the event method, so the message box doesn't appear for empty strings, and on a more minor note, to avoid performing a Regex instruction on empty strings. I doubt it cost much performance wise, but it still is something. Also, you can use `sender` to retrieve the text box that fired the event; this way, you can use the following method for every text box that needs it without changing it. Here's how it should look: private void name_TextChanged(object sender, EventsArgs E) { var textBox = sender as TextBox; if (textBox.Text.Length == 0) return; if (System.Text.RegularExpressions.Regex.IsMatch(textBox.Text, @"^[a-zA-Z]+$")); { MessageBox.Show("Letters only please"); textBox.Text = textBox.Text.Remove(textBox.Text.Length - 1); } }
Gonna have to disagree a bit, but I understand where you're coming from.
Forgive the exageration for the argument's sake.
Use Slack for a week. Come back to me them (if you still have the RAM)
Good point! It's pretty farfetched to think that kind of optimization would come bite you later, it would require some wild changes to the db. I have a bad habit of abusing Single/ SingleOrDefault I realize.
You could try a Linq Join and Select. Or keep your arrays and use a third collection(List) that you add your results to for final output.
Just a tip: instead of removing from A why not create a new variable and add whatever values should be saved to that. Also, your code using lists is going to cause problems too because you would remove from _firstList, which would mean that your indices change in _firstList but you don't account for that in your code. There is also no guarantee that the numbers would be in the same position in each list. Finally, you could also use Linq (include System.Linq namespace) and boil this down to 1 statement: `a.Where(x =&gt; !b.Contains(x)).ToArray();`
 return a.Except(b).ToArray(); Uses one of LINQ's set operators. Codewars is cool. Once you get the code to work, do read the other accepted answers as you will learn a butt load from them. I can't remember how CodeWars does namespaces, but I'm sure it supports LINQ as I remember seeing solutions using it. using System.Linq; should be in there somewhere I imagine.
Oh nice! That's actually a pretty good compromise then. I had assumed that foreach was dependent on the interface.
[https://github.com/ViGEm/HidGuardian](https://github.com/ViGEm/HidGuardian)
If you structure your solution correctly it shouldn't be hard to switch over like you said. I think the reason they are gaining popularity, particularly in enterprise, is lack of having to install and update applications. It is very convenient to only update in one place. But using web can add huge complexity depending on the project. So many things are just easier in a desktop application. And the Web infrastructure was never designed to host full apps.
Indeed, this is actually what I was going to suggest next. Structural matching for enumeration
I’ve gone back and forth about it over the years with other devs I’ve worked with. In the end of the day I’d rather assume my db constraints like a unique index was in place instead of paying the cost each query. Then again I’ve used sources that were not from SQL where I did want to verify with single instead of first 
In short, `IEnumerable` doesn't tell us anything about two important qualities of our collection: * Is it bounded? * Is the cost of enumeration per-item or up-front? If a collection's bounded/unbounded status is unknown, then obviously `Count()` and full-iteration methods like `ToArray()` or `OrderBy()` aren't safe. You can sort of sidestep this, in a hypothetical "generic enumerable" situation, by using `Take(n)`, where *n* is some reasonable maximum you will allow. The cost of enumeration is interesting and not obvious. Imagine a simple Fibonacci sequence generator. Each iteration is O(1), because you need only do a simple addition based on the current state. Now imagine a generator that returns the rows from a database query over a high-latency connection. It might spend 2-3 seconds waiting for the first item to arrive, then every iteration becomes O(1). You can't defer the initial hit, so deferred execution isn't as valuable! (Also worth noting: sometimes deferred execution helps you save memory, etc.) So `IEnumerable` doesn't help us with either problem, but most people work on context and aren't working with "an arbitrary `IEnumerable`". Usually, the person that queries a generator like `DigitsOfPi` understands it's likely they are getting an infinite sequence and behaves accordingly. Developers who ask a DbContext for AllCustomers generally know there might be a latency spike. If you want more explicit assurances, you have to write your own interfaces/types that provide it. For example, `IUnboundedEnumerable` and `IBoundedEnumerable`. It's "tedious" but not "hard" to implement extension methods to give you LINQ operators that make sense for each. Overall, I think .NET developers overuse LINQ and `IEnumerable`. There are many use cases where it's contextually sensible to return a bounded, indexable collection. So return an array, or `ICollection`, or `ReadOnlyCollection`. All of these work with LINQ just fine, and they explicitly say "I am bounded and can be indexed". But in the end, the people using your code are going to have to be responsible with the enumerables they use. You can only control the code you write. They need to learn what is dangerous, and that LINQ isn't a tool to be used at all times.
I understand it. However I do think that a lot of that complexity comes with complex UI with Xamarin.Forms. In that regard- you're pretty spot on. Traditional platform-specific Xamarin is hard to argue against, in my opinion, outside of the notion that it gets you closer to 60-70% code share, and you still need individual platform expertise. And at that point you're arguing about how much "extra" development you want to do on separate UX or platform-specific features, versus the drawbacks of non-native experience and performance- the extent of which I know people tend to debate about.
Then your programming experience is limited. They shouldn't be used when there is a more appropriate alternative, but sometimes there isn't one.
This is probably overkill but it is possible to use some of the attributes in `System.Runtime.CompilerServices` to accomplish something much the same thing by using a static dictionary that references the exact the location in the code where it's being accessed from and uses that to access the data. Observe, &lt;pre&gt;&lt;code&gt; public static class StaticLocal&lt;T&gt; { static StaticLocal() { dictionary = new Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt;(); } public class Access { public T Value { get; set; } public Access(T value) { Value = value; } public override string ToString() { return Value.ToString(); } public static implicit operator T(Access obj) { return obj.Value; } } public static Access Init(T value, [CallerFilePath]string callingFile = "", [CallerMemberName]string callingMethod = "", [CallerLineNumber]int lineNumber = -1) { var firstKey = lineNumber; var secondKey = callingFile + '.' + callingMethod; if (!dictionary.ContainsKey(firstKey)) dictionary.Add(firstKey, new Dictionary&lt;string, Access&gt;()); if (!dictionary[firstKey].ContainsKey(secondKey)) dictionary[firstKey].Add(secondKey, new Access(value)); return dictionary[firstKey][secondKey]; } private static Dictionary&lt;int, Dictionary&lt;string, Access&gt;&gt; dictionary; } &lt;/code&gt;&lt;/pre&gt; This is, of course, massively inefficient, but it does simulate the way you would use static local variables quite well.
I think WinForms is sort of on the same boat as WPF though. Supposedly it will be easily ported to .Net Core 3.0 but we will have to wait and see. 
have you verified that `env.EnvironmentName` is 'Development' when you run your app?
Thanks!
2 things: &amp;#x200B; 1) Is it super important that you save the images to the database as a byte array? It is a lot easier to create an image as a file and then put the images path as a field in a database, then feed your control the database record as a path. 2) Have you checked the event log on the server(if possible)? Usually the event log offers a lot more information regarding why something failed.
Because it was making some library calls safe. These calls could could have side effects if enumerated twice. A really bad situation.
My assumption is is that you just want a standalone .exe without dlls etc? If so I would highly recommend [https://www.nuget.org/packages/Costura.Fody/](https://www.nuget.org/packages/Costura.Fody/) All that is needed is to create an XML file in your project root that includes: `&lt;?xml version="1.0" encoding="utf-8"?&gt;` `&lt;Weavers&gt;` `&lt;Costura /&gt;` `&lt;/Weavers&gt;` Then set the resources you want included to "Copy Local" in Visual Studio. I've used this for DLLs but I'm sure it would work for other file types.
I have. If you follow the last line in my post for reproduction you will see this: Lord_Zero@MyMachine MINGW64 ~/Desktop/test $ dotnet watch run watch : Started Using launch settings from C:\Users\Lord_Zero\Desktop\test\Properties\launchSettings.json... **1** &lt;------- THIS SHOULD BE 0. Hosting environment: **Development** Content root path: C:\Users\Lord_Zero\Desktop\test Now listening on: http://localhost:5010 Application started. Press Ctrl+C to shut down.
Who knows? I know the library was making network calls, but I didn't know access to the source code. I needed to make sure that double enumeration didn't trigger a network call.
I'd find it odd if CodeWars allowed to use LINQ when you're not even allowed to use `List&lt;T&gt;`
&gt; that returns type IEnumerator or IEnumerator&lt;T&gt;. that returns a type *that looks like* IEnumerator or IEnumerator&lt;T&gt;. It is very liberal here.
There's also CallerMemberName, which is an attribute you can add on a parameter to a logging method and populates with the ... uh, caller member name. Something like: private void LogMethodCall([CallerMemberName] methodName = "") { // Increment your dictionary, or whatever... // You can even make it conditional for debug, if you want. } It's actually *required* to be an optional parameter with an empty default, and the runtime will populate it.
Not sure if it matters, I personally haven't tried, however you have an upper case `Roles` in the appsettings.{Environment}.json file where as in the appsettings.json its just `roles`
I specifically put it’s for multiple simultaneous calls, even so even ETLs can often be multi threaded particularly if the T is significant
Something that not everyone realizes: "stack" and "heap" don't really have meaning in C# - it's all implementation detail. See Eric Lippert's [blog](https://blogs.msdn.microsoft.com/ericlippert/2009/04/27/the-stack-is-an-implementation-detail-part-one/) [posts](https://blogs.msdn.microsoft.com/ericlippert/2010/09/30/the-truth-about-value-types/).
That looks like a nice read, thanks.
The real fun was when I started smoke testing the methods and discovered that the vast majority of them were just stubs. Many couldn't be implemented, as in never going to happen, because the database didn't have the necessary information. Thankfully I was only on the project for a week while someone else was on vacation. Never underestimate the value of some well placed smoke tests to prove the system you are integrating against actually exists.
Things on the stack have a scope controlled lifetime. Things on the heap have a GC controlled lifetime. The reference to an object lives on the stack, but the object itself is on the heap. The reference goes away once the scope closes, but the object goes away whenever the GC gets around to finding out about it.
I know you know your stuff, so I'm confused by your advice. The general consensus is to return the least specific type possible to lessen the burden on anyone consuming your code. This means removing certain reference requirements, removing exposure to the underlying implementation, and avoiding situations where the consumer may need to convert types due to the specificity. Why do you recommend the opposite here?
The way C# uses the stack and heap is entirely an implementation detail. There's no reason value types _must_ be stack objects.
Struct vs. Class is value vs. reference semantics. This is a big thing for a lot of people as they approach programming, and it's best explained by analogy. Let's say you have a big warehouse and lots of shelves. You have numbered aisles, and the shelves on each aisle also have numbers indicating bins. So if I tell you there are basketballs in aisle 3, bin 14, you know exactly where to go and find basketballs. Now, imagine I write "aisle 3, bin 14" on a piece of paper. That paper is not a basketball. It is, in a way, instructions for finding a bin of basketballs. You can put the piece of paper on a copy machine and make 100 copies. That does not make 100 basketballs. It merely makes 100 pieces of paper that tell a person where to find basketballs. There can be more pieces of paper than there are basketballs. The warehouse can burn down, and the papers will still exist, even though the aisles and shelves and basketballs don't. That piece of paper is a "reference type". It is not the thing you want, but instead instructions for where that thing is located in computer memory. When you have a reference type and you see this line: var basketball = new Basketball(); What has happened is this: 1. Memory for a Basketball is allocated, and its constructor is run. 2. The address of that Basketball is written on a piece of paper. 3. That piece of paper is stored in the variable `basketball`. (This is way more explicit in 'harder' languages like C: they have a special variable type that is always a piece of paper.) So then if you have these lines of code: var basketball = new Basketball(); var otherBall = basketball; Remember, `basketball` is not actually a Basketball. It's a piece of paper with the location of a Basketball on it. So `basketball` and `otherBall` are two pieces of paper with the same address on them, and there is one Basketball at that address. That also means if you change the Basketball using one variable, someone who uses the other variable will find the same changed Basketball if they go to the address. OK, so how are structs different? They are value types. That means the computer does not use pieces of paper with their address on it, and it changes what happens when you use the `=` assignment operator, among other things. Let's repeat the lines of code for reference, and say that now `Basketball` is a struct. var basketball = new Basketball(); var otherBall = basketball; Here is what these lines do: 1. Memory for a new Basketball is allocated and initialized. 2. The computer writes "`basketball`" on it with a pen. 3. Memory for another Basketball is allocated and iniitalized. 4. The computer writes "`otherBall`" on this one. Now we have two Basketballs in two variables. There is no way to have two variables that refer to the same value type. So if you use `=`, a copy is made. This can be very expensive and wasteful, especially since it happens in many situations you might not realize it's happening in. This knowledge tends to be most useful in a classroom. In more than 99% of C# professional development, this is the rule for deciding if you should use a class or struct: * Use a class. But for some reason, a lot of classrooms feel like it's worth spending a disproportionate amount of time on teaching you how to use them. It's kind of like if every driver's license exam required you to demonstrate how perform the 100,000 mile maintenance on an automatic transmission.
XamForms + ReactiveUI, you can share a lot of logic between platforms, and just create views for each platform. 
Try not to call it a pointer; these are either reference or value types, and overloading the definition of pointer can lead to confusion down the road. As an example, think about how you would describe the \`out\` and \`ref\` keywords following your statement.
&gt; The general consensus is to return the least specific type possible to lessen the burden on anyone consuming your code. I would call that a "popular misconception". It in no way "lessens the burden" on the consuming code. If anything it increases the burden because there are times when you need to add type checks to see what you can actually do with the value. &gt; avoiding situations where the consumer may need to convert types due to the specificity Though often repeated, that is pure nonsense. Consider the scenario where someone returns a value, which you then want to pass to as a parameter in a method. Return Type Method Parameter Allowed? IEnumerable&lt;int&gt; IEnumerable&lt;int&gt; Yes IEnumerable&lt;int&gt; List&lt;int&gt; No IEnumerable&lt;int&gt; ICollection&lt;int&gt; No ICollection&lt;int&gt; IEnumerable&lt;int&gt; Yes ICollection&lt;int&gt; ICollection&lt;int&gt; Yes ICollection&lt;int&gt; List&lt;int&gt; No List&lt;int&gt; IEnumerable&lt;int&gt; Yes List&lt;int&gt; ICollection&lt;int&gt; Yes List&lt;int&gt; List&lt;int&gt; Yes As you can see, as you make the return type more specific it can be used in more situations. Conversely, the narrower you make the parameter, the more situations it can be used it. Conclusion: **Be as explicit as possible for return types, and as liberal as possible for parameters.** 
Yes, and if you use structs incorrectly it results in them getting copied into the heap and obliterating any performance advantage. It's the same blob of memory the difference is just how it is managed.
While you're right, your comments make it sound like the memory location of the objects is effectively random, which isn't the case. [This article](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/choosing-between-class-and-struct) has a half-decent rundown on it.
&gt; &gt; &gt; &gt; avoiding situations where the consumer may need to convert types due to the specificity P.S. Another way to think of this is that the consumer can always safely cast it to an interface. public List&lt;int&gt; GetList()... var a = GetList(); IList&lt;int&gt; b = GetList(); IReadonlyList&lt;int&gt; c = GetList(); ICollection&lt;int&gt; d = GetList(); IEnumerable&lt;int&gt; e = GetList(); public IEnumerable&lt;int&gt; GetEnumerator()... var a = GetEnumerator(); IList&lt;int&gt; b = GetEnumerator(); //Compiler error IReadonlyList&lt;int&gt; c = GetEnumerator(); //Compiler error ICollection&lt;int&gt; d = GetEnumerator(); //Compiler error IEnumerable&lt;int&gt; e = GetEnumerator(); 
It dates back to C# 1.0 when we didn't have IEnumerable&lt;T&gt;/IEnumerator&lt;T&gt;. To avoid boxing integers, they had to use this "looks like an enumerator" rule.
Sorry about that. 
It also makes some optimizations possible, since interface calls are slower in most cases. It’s not great from a developer perspective, though, since it adds “magic” to the type system. 
four spaces before makes it a code: I'm indented four spaces and have a blank line above { I'm indented 8 characters! The brace is a red herring :) 
I usually post code directly from my IDE class Program { static void Main(string[] args) { // The code provided will print ‘Hello World’ to the console. // Press Ctrl+F5 (or go to Debug &gt; Start Without Debugging) to run your app. Console.WriteLine("Hello World!"); Console.ReadKey(); // Go to http://aka.ms/dotnet-get-started-console to continue learning how to build a console app! } }
This is a terrific analogy and explanation. 
I don't think he's trying to use closures
LINQ has even an Except method: https://docs.microsoft.com/en-us/dotnet/api/system.linq.enumerable.except?view=netframework-4.7.2
Even when the same person is doing both jobs, MVVM can be helpful. It allows you to test the bejeezus out of your UI logic without having to run a UI test.
I always use a class 
With four spaces: Code block Second line Did this work?
alternative? This is literally every second line in one of my projects
if (collection.Any()) DoSomething(); 
Fwiw if it really is a collection, not only an enumerable, there is an efficient Count property. Count() is an extension method of IEnumerable and thus requires enumerating the entire sequence.
 if (list.Any())
Windows Presentation Foundation cookbook, it was released recently and contains different recipes to create your wpf app, starting from the basic concepts to the more advanced stuff like multithreading 
You can also use a backtick character to format inline in code `like this`, so not apostrophes, backticks: ` Or you can format blocks by surrounding them between three backticks ``` like this ``` This is a basic form of the Markdown formatting language, there are a few variants. On GitHub for example, you can tell the formatter the language to format and use code hghlighting when using the three backticks: ``````csharp public class X { } ``` 
&gt;The general consensus is to return the least specific type possible to lessen the burden on anyone consuming your code It's actually not. Be broad in what you accept, be specific in what you return. However, there are valid cases where it's sensible to restrict the exposed functionality.
&gt; because there are times when you need to add type checks to see what you can actually do with the value. That's equally bad though. *That* is relying on implementation details. If an `IEnumerable` is exposed, you treat as an `IEnumerable`. Doing instance type checks is how to get into trouble.
Ha! 
On a side-note since you mention conversions: Due to its read-write access `List&lt;T&gt;` does not support variance, which can be a valid reason to use `IEnumerable&lt;T&gt;` as well.
Are you asking about interface default methods? [Explicit interface implementation](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/interfaces/explicit-interface-implementation) is done on a class. I'm going to answer assuming you mean the new (C# 8) way of defining interface methods with a default implementation. Interfaces are supposed to define a contract: a class that implements this interface has these instance methods. The fact that the interface can now provide a default version of one or more of the instance methods it asserts will be present in the class does not change that. Behavior is still ultimately defined by the classes, but now for each class you can choose to provide an implementation or use the default one from the interface if that suits your purpose.
That’s ClickOnce, which is actually literally the technique used *in part* by Chrome. Chrome then does various other hacks. ClickOnce has lots of l terrible pitfall, but is fine for beginner purposes.
As a parameter, yes. Though `IReadOnlyList&lt;out T&gt;` is even better because it promises a fast `Count` operation and can be safely enumerated multiple times. As a return type? No, not at all. Because again you can always cast a `List&lt;T&gt;` or other collection to an `IEnumerable&lt;T&gt;` when needed. 
Yes, adding type checks are bad. But you wouldn't need to if the method declared the real return type up front. An unfortunately common misconception is the idea that a concrete type is automatically "an implementation detail" and should be avoided at all costs. Which is bad because those costs are very high while the benefits are often non-existent. 
&gt; In that case you are either knowing what you are doing or asking for trouble. On the contrary, it happens quite often by accident. For example, when you are using data binding in WPF the data grid control will see that the collection is mutable and render the UI accordingly. It doesn't even know that the variable was originally as an IEnumerable; it just looks at all of the interfaces the object exposes. 
&gt; &gt; Specifically, it means don't use pointers (or later, reflection) to manipulate the private fields in a data structure. &gt; &gt; Not, it doesn't. It means you should not rely on implementation details but only on what is explicitly exposed or documented. That's the same thing. 
Porting is fine but it creates a new product you have to support and maintain in the new language ecosystem. That means writing the code in a way that's appropriate for that ecosystem.
ILMerge?
If you have a lot of code, [make a gist](https://gist.github.com/) and link that instead. It's painful to read more than a few snippets in Reddit comments.
Assuming you are talking about the new stuff in C# 8, it, in essence, allows you to move functionality that previously HAD to be done using and abstract class to the interface. IMHO it means the code is cleaner. If you need to implement an interface, you don't need to know about the abstract class the implements most of the functionality that makes your life easier, just implement the interface with the minimum number of members necessary.
It looks like you have two different buttons, one that sets a value to true and one that doesn't do anything unless that value is true. Neither of these automatically does anything when the other one is pressed, so you'd have to alternate between the two buttons so that "aaa" gets set to true. It's also worth noting that the second if condition in your thing_Click method is never going to get hit since you set the variable to false before it: private void thing_Click(object sender, EventArgs e) { buttonSelection.Enabled = false; calculatingStatus.Text = "Enter a number"; //lets say this number is "20" if (aaa == true) //theoretically when nextCalculationStep is pressed, it sets "aaa" as true { aaa = false; //then it sets "aaa" as false calculatorNumbers.Text = Convert.ToString(input1); //stores "input1" as "20" calculatorNumbers.Clear(); //clears "calculatorNumbers" (where the numbers are stored)... calculatingStatus.Text = "Enter another number"; //lets say this number is "5" if (aaa == true) //then theoretically when the button is clicked again, "aaa" is true again and continues { calculatorNumbers.Text = Convert.ToString(input2); //stores "5" as input2 answer1 = input1 * input2; //stores answer1 as (20 x 5 = 100), so answer1 == "100" mainAnswer = Convert.ToString(answer1); //converts answer1 (double) to a string in mainAnswer answerCalculation.Text = mainAnswer; //outputs mainAnswer (which should be 100) in a label. } } } You hit the first "if" and set aaa to false if it was true. You then do some other stuff, none of which changes aaa. Lastly, it checks aaa again, and finds that it's still false. If you want to be able to hit a single button and have it progress, you're going to need to set it up differently.
If you are going to port 1:1, you should seriously consider working out how to build it into separate libraries, and bind to those first.
how would i set it up differently? i've tried using (in nextcalculationstep) int aaa == aaa + 1; and in the if bits, ive tried: if (aaa == 1), do the first bit if (aaa == 2), do the next bit but that doesnt work either.
Explicit interface implementation is useful in a very narrow set of scenarios. In those scenarios it's not a code smell. If you find your code base has many of them, that might be a code smell.
&gt; terrific is terrific good or bad?
Good
I honestly just like that you can now slap a "throw NewNotImplementedException()" on added interface methods so that you don't break a bunch of compilations on functionality that isn't used yet.
It is not code smell, but it does require we are more deliberate with how we think about interfaces and represent interfaces to learners. I think this starts with emphasizing the main feature of interfaces which is everything defined in an interface has to be public. When you emphasize that point, and demonstrate how every other feature of interfaces is just a side-effect of this feature it will give people a better understanding of what an interface actually is and how to use it. As long as you conform to the SOLID principles adding default methods should never result in code smell. 
I wasn't talking about C#8, just about explicit interface implementations when a class shares two interfaces with the same signature. I'm mostly basing this off of [This article](https://blogs.msdn.microsoft.com/csharpfaq/2004/03/07/why-doesnt-c-support-multiple-inheritance/). My understanding was that C# language designers made the intentional decision not to include multiple parent classes in the language to avoid conflicts between parent members. By not including multiple base classes they opted for simplicity and uniformity over complexity and flexibility. IE C# programs have an expected way of working. Classes define behavior and interfaces define an API. &amp;#x200B; I think explicit interfaces (not talking about C#8) undermine that. They imply that the function of interfaces is related to the implementation. It just seems like there is a disconnect between the rationale behind interfaces in the first place. If you are designing your objects "correctly" your interfaces have nothing to do with the implementation... because that is the responsibility of the base class. &amp;#x200B; C#8 default methods further abandon the concept of interfaces being separate from the implementation. I'm not necessarily against it, it just seems contrary to the original philosophy. While not the topic of my OP, default interface methods also seem like they go against the initial philosophy behind dissalowing MI.
I wasn't talking about default methods in C#8, I'm talking about Explicit Interface Implementations when a class inherits from two interfaces with methods that have the same signature. I'm not saying I believe they are bad (I don't know what to think yet), just that the reasoning behind Explicit interfaces seems contrary to the decision to disallow multiple inheritance of classes. The interface "should" say nothing about the implementation, but explicit interfaces imply that there is a need for a class to provide separate implementations for identical interface method signatures.
Not if the underlying concrete type implements ICollection. Then Linq will access its Count property. It still incurs extra type checking overhead (until the default interface implementations language feature is released) and using Count() should be avoided unless it’s the only thing that makes sense (e.g. you don’t do anything with the collection except count its elements) because code should be as close to what is conceptually going on as possible.
About the only justification I can think of for spinning it off into separate classes is so that each class can be implemented the exact same way. But ironically, shared code becomes really messy in this situation because statics don't play nicely with inheritance or interfaces. If you did want to have a common codebase, one trick is to use a generic-typed helper class and have the static variables live there. This works because every instance of a generic type is a standalone class with an independent set of static variables. That said, I think OP needs to reevaluate what it is they're trying to accomplish. It sounds like they're just trying to avoid declaring tens or hundreds of separately named static variables, in which case declaring tens or hundreds of new types instead would almost certainly be a misuse of the type system.
Isn’t the point that he doesn’t want to ToList an IList because it will copy the entire thing?
If you find yourself with explicit implementations, the first thing you should ask yourself is "what behavior am I trying to contractually define, and why does it seemingly overlap another contract?" It could be that you're just using poor/inadequate naming conventions, and that you need to be a bit more descriptive about your method names. This is a minor smell and generally easily fixed early on. It could be that you are trying to define the same behavior in multiple interfaces, in which case you should be asking yourself if you need to separate that method into it's own interface that is applied separately. IEnumerable and IEnumerable&lt;T&gt; are good examples of this situation: they expose only one method, GetEnumerator(). This is a favorable option compared to each collection interface defining and implementing the same thing. It could also be a legitimate need. In the Identity 2.0 framework, there are interfaces to define custom stores and managers as what are essentially facades. Some of those store interfaces have overlapping method signatures, like GetByName() or GetById() that you're forced to implement, which means at least one of them will be an explicit implementation. 
I do not follow... Why would explicit interface implantation imply that function of an interface is related to its implementation? If anything, when class implement interface explicitly, I feel it goes in other direction. When you have explicit implementation, you cannot use reference to a class to access interface methods, which encourages you to use interface in client code...
Thanks everyone for your input! I ended up taking /u/elite5472's suggestion to reconsider what tools I'm using and I'm now looking into using MongoDB for my database solution as it seems like a much better fit given the type of data I need to store. Thanks again!
This is very cool--thanks for sharing. Do you have an application in mind for this? How do you handle more complex scenarios like event-driven form changes? E.g. I select one drop-down field value and it filters another drop-down's list of options?
Pretty sure all subreddits follow the same markdown rules. Google "Reddit Markdown" for specifics.
Try setting the Policy = null. You’ll have to check the policy object fir null before drilling into roles, but you should probably do that in a dynamic object anyway. 
Sometimes its useful when its to hide an "ugly" interface, like `IValueConverter`, frequently used with WPF. The methods of the interface have 4 parameters, but usually only two are used and they are of type `object`, also the return type is `object`. When implementing this interface I usually make it explicit and calling another public method with better parameters and correct parameter and return types.
I'm don't understand your use case. Why can't admins just edit the appsettings.Production.json? The point of appsettings is to apply to all configurations and should be less specific than the environment appsettings. What your trying to do is still perfectly achievable using the current behavior, you just need to leave roles empty in appsettings and let the admins apply roles in Production.appsettings.json. Why is that not an option? &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
This is the best course of action I think. By default you are given appsettings and appsettings.Development so people like me probably try to stick to the defaults. Also my environments are not driven by environment variables outside of Development so I think we want to load up appsettings with the defaults and override with Development.json for things like verbose logging and connection strings. This means if we venture outside of the defaults we have to edit project.cs and register an additional configuration like Production since there's no production environment variables in our environment.
Either way it's not intuitive until you go to empty something and realize that's not how it works 
That won't work. Another poster in here is correct, you can not remove variables because of the way it's mapped over as key value pairs.
If even string hashes are prohibitively expensive, then you are in such a tight loop that you shouldn't be humoring any solution other than dedicated static variables. If you don't want to deal with the mess of managing that, there's always the option of injecting boilerplate as a post-process, like with [PostSharp](https://www.postsharp.net/), so that you never have to look at the dirty inner workings of it. I'm not personally a fan of magic switcharoo frameworks like that, but it all just depends on what you are and aren't willing to compromise on.
You could just implement a MyInt class that inherits from Integer and modify the get and set methods, maybe?
If I did that and methods would call for an integer, I still would have to change code around.
Typed this on an iPhone, so sorry for any formatting issues. public class MyInt : Integer { // private int to hold value private int _value; // expose the int via your custom logic here public int Value { get { // custom logic here return this._value + 573628; } set { // custom logic here this._value = value - 637292; } } Then use it like this. MyInt x = new MyInt(); // this will use the custom set method x.Value = 6; // this would use the custom get method int y = x.Value 
&gt; if (collection.Any()) { DoSomething(); }
The objections to multiple inheritance are not philosophical, they are pragmatic. Multiple inheritance incurs a high complexity cost on both the language implementers and the consuming programmers, so they seek more economical solutions first. As noted in the article, multiple interfaces are effective at addressing the vast majority of cases where it may be needed; explicit interfaces are a necessary part to make it work well, as otherwise avoiding conflicts between interfaces would be quite burdensome, and fortunately they come at a pretty low complexity cost. Default interface methods further carve away at the MI problem space, and they do so with a cost that it still much less than full blown MI. They certainly don't get nearly as much bang for the buck as explicit multiple interfaces did, but that's why they're coming in C# 8 rather than 1.0.
not inherits, implements. you are saying this class can fit either interface, so you have to specify what code to run for which usage.
Why are you tinkering there?
&gt; I think explicit interfaces (not talking about C#8) undermine that. &gt; C#8 default methods further abandon the concept of interfaces being separate from the implementation. That was never the concept to begin with. That was never the focus. What matters is that interfaces represent a contract of what is available - and that does not change. &gt; default interface methods also seem like they go against the initial philosophy behind dissalowing MI. Why? There is still no MI possible.
&gt; I can find such documentation for other subreddit but not here. Click the "formatting help" link. It's site wide.
You can inherit from Integer, it's a sealed type.
&gt; if (collection.Any()) { &gt; DoSomething(); &gt; }
Yeah everyone else beat me to it but you want .Any() which exits after checking if there is a first result :)
big deal, you either get spied on by the Americans or the Chinese 😂
&gt; You can copy/paste directly from VisualStudio,, provided your code is indented. This assumes that the class is part of a namespace and that the namespace is not copied.
But that still consumes the first item in the collection, right? Or is it smart enough to leave it be?
You typoed can’t into can :)
https://media.giphy.com/media/xT5LMzIK1AdZJ4cYW4/giphy.gif
Are you talking about the .Any()? IIRC (and it's been a while since I looked at the linq source) .Any() requests a new enumerator, calls MoveNext() on the new iterator (which returns a bool) and then returns the value returned by MoveNext (which indicates whether there was an element for it to advance on to) and ditches the enumerator it requested. It never (as far as I'm aware but I could be wrong) attempts to read any of the values in the collection however the initial MoveNext call will cause the underlying enumerable to go and retrieve the first element, so if it's representing a db query or similar it will still potentially be an expensive operation, but it's almost certainly cheaper than evaluating the entire enumerable.
&gt; I think this starts with emphasizing the main feature of interfaces which is everything defined in an interface has to be public. But that is not the main feature. It's not even true. When you use explicit interface implementation then those methods are not public.
Note to readers, this is very general advice, structs do have their uses and you should understand the tradeoffs and performance characteristics of each (heap vs stack / value vs reference) before you consider yourself no longer a beginner programmer. To me it's a bit like linked list vs array. You can force either to do the job of the other but they both exist for a reason.
Yes, my gripe with this is that I'm not sure one item from an enumerable will then be consumed (or in other words, lost). 
Yeah, every time you request a new enumerator from an ienunerable, it resets to the start position (-1) so you (usually) don't have to worry about Count / Any / ToList type methods from moving the start position
&gt; I also have a Thread.sleep between opening the image and closing it so shouldn't that resolve the problem you mentioned? No. The `Thread.Sleep` will block the thread from doing anything. But for all the GUI stuff to work the thread must be free to perform the work.
Yeah man. This looks promising. I don't need this stuff immediately right now, but down the road a few weeks. You pegged it right on the money.
If you really want to have fun with structs, try: //if Point is a class var a = new Point[] { new Point(1, 1) }; a[0].x = 5; Console.WriteLine(a[0].x); //outputs 5 var l = new List&lt;Point&gt; { new Point(1, 1) }; l[0].x = 5; Console.WriteLine(l[0].x); //outputs 5 //if Point is a struct var a = new Point[] { new Point(1, 1) }; a[0].x = 5; Console.WriteLine(a[0].x); //outputs 5 var l = new List&lt;Point&gt; { new Point(1, 1) }; l[0].x = 5; Console.WriteLine(l[0].x); //outputs 1 
You got it :)
&gt; Please don't get curious why I am tinkering here. REEEEEEEE
I think you'd be happy to hear that F# has [units of measure](https://fsharpforfunandprofit.com/posts/units-of-measure/)
https://docs.microsoft.com/en-us/dotnet/api/system.text.stringbuilder?view=netframework-4.7 https://docs.microsoft.com/en-us/dotnet/api/system.char?view=netframework-4.7#methods
Ah, thank you very much
Assuming we are talking about [https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/interfaces/explicit-interface-implementation](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/interfaces/explicit-interface-implementation) Typical use case is this: Two different developers in different libraries create two interfaces with matching method name and I need to implement both interfaces. It's just bad luck. If it happens a lot in your own interfaces, you probably need more descriptive names. 
If it's crashing then it's not performance related, it is invalid code. For performance, can you isolate the function and do some Performance Profiling with Visual Studio? You can't improve performance without knowing what eats up time. 
 var text = "something like this"; var textmixedcase = string.Join("", text.Select((ch, i) =&gt; i % 2 == 0 ? System.Char.ToLower(ch) : System.Char.ToUpper(ch)));
If you want something very brief you can also use the linq select extension (map function in most other languages). It does hinder readability though. string text = "something like this"; string textmixedcase = new string(text.Select((c, i) =&gt; i % 2 == 0 ? char.ToLower(c) : char.ToUpper(c)).ToArray()); 
It certainly needs some refactoring, so I will have to take the time to get it sorted. Is there any decent books on the GoF stuff?
Be aware that this should not be used for foreign languages. As soon as you have characters consisting of more than one `char` this solution will not work anymore.
I wish my team would refer to me as a precious developer. In all seriousness, need to see the code. Also, when you say crash, what does that mean? Is there an exception thrown?
A .NET `char` represents a character as a UTF-16 code unit. https://docs.microsoft.com/en-us/dotnet/api/system.char?view=netframework-4.7.2 Assuming that one character equals one `char` is fairly naive and outdated. Please raise awareness of proper Unicode support!
It's a web api end point it just throws a 500 error, all wrapped up in a try catch finally. Oh and that was a typo should have read previous (I'm on the app). I will see what I can do to get the code in the question.
You are saying it is crashing then asking for performance tips. Is the crash caused by out of memory error or something timing out? &amp;#x200B; Performance wise, if you are iterating over a 5000+ long collection often, be sure that the list is either an Array or List&lt;T&gt;. If it is a List&lt;T&gt; use a for loop not a foreach, and be sure you are getting array bounds elisions by iterating from 0 to collection.Count. &amp;#x200B; Be sure you aren't iterating over the short list when checking each of the 5000 things against it. Use a Dictionary instead. &amp;#x200B; Can you cache things so you don't have to recompute them? &amp;#x200B; &amp;#x200B; &amp;#x200B;
It's a web api end point it just throws a 500 error, all wrapped up in a try catch finally. Oh and that was a typo should have read previous (I'm on the app). I will see what I can do to get the code in the question.
1. Fix whatever is making it crash. This is most critical. 2. Consider how it looks up and manipulates items. For example, would a dictionary make sense? Is updating an item possibly causing expensive memory reallocations? (Hint: learn about computational complexity/"Big O" - there are tools that can calculate this for you.) Sadly, Linq is not always your friend. 3. Refactor, unit test, etc. Just because it has to perform all these steps doesn't mean they should all be in one method. 4. "precious developer" lol
They did a good job of baking in Unicode support from the start. It was a big thing to me at the time.
Precious was a typo should have read previous, though I am gonna become precious in a sense that I'll be so stressed out I might just blow hahaha. Yeah refactoring and SOC is a must here, it hasn't been followed at all. Definitely a memory issue. Unfortunately unit testing was never put in place for any of the 30 something projects the last set of developers wrote, because at the time an acting MD said it was a waste of time writing code to test code when you should just write it properly in the first place ... He has left so I am slowly introducing it where I apply any fixes or updates. 
Given that the most common unicode characters only use one code point and this is pretty much a toy function he's probably pretty safe. 
Yeah, missed the part where he wanted SpongeBob case. 
Unfortunately not, though I will certainly put in place. 
[According to Merriam-Webster it's both](https://i.imgur.com/DZ1Eb0d.jpg)
- Use a `HashSet&lt;T&gt;` instead of a `List&lt;T&gt;`. - No need to split into an array when you're just going to take the first 6 characters anyway. You can skip that entire step and just use the `guidString`. - `SubString` is not a valid method on the type `string`. You probably mean `Substring`. - `iems` is not a valid reference. You probably mean `_items`. Your code does not compile. And lastly: **You lied. The code will generate 51 elements.**
You can run a long running thread with Task.Factory.StartNew passing long running to it! That is preferable 
so debug the endpoint and look what the catch gets?
One of the most common things I see from junior devs is queries in loops which generally has poor performance. If you have a foreach check to make sure they aren't querying in that loop. Look into Loading the data before the loop (assuming it can safely fit in memory and then use that). 
It's generally a bad idea to only keep a section of a GUID.
Additionally, the code will actually generate somewhere between 1 and 51 elements with no assurances of the exact number.
From my experience, ASPNET core runs on a toaster. Even T2 Micro virtual machines with 1 core and 1gb of ram in AWS run our asynchronous, 20k+ line of code apis no problem. And that’s exactly why they tout it as cloud friendly. See, cloud is not some mystical magic computing device, but high availability servers on expensive data-centers. Less is more for these applications. But that also means you can run it even in a tiny little raspberry pi no problems. Unlike, say, a tomcat server ;)
Yeah, this isn't a loop in a loop. The short list data makes a call to a WCF service then with that list in memory it gets the master list (also in memory) and then attempts the foreach on the master list. I started debugging about about an hour ago and it's still cycling through the loop!
lel all suggestions taken on board and I've updated the code. Thanks for helping to make it better.
If you are working with in memory lists there has to be something else going on. Good luck can't help without seeing code. 
Can you get the logs from the app at the time of the crash? If there aren't any logs asking a global error handler would help. https://www.codeproject.com/Articles/899342/WCF-Global-Exception-Handling Write the full error to a file using a library like log4net. That will give you a stack trace. There are memory profilers from jetbrains and others that can give you an idea where the issues are if you suspect memory overflow and the logs will help you narrow it down. After you track down the error, if you need suggestions post here. I'd suggest putting some kind of monitoring tool like new relic or dynatrace on it to keep tabs on its behavior.
Just using the suggestions without actually **understanding** them won't help much. **Why** do you use a `HashSet&lt;&gt;` now instead of a `List&lt;&gt;`? The reason was so you could make use of the `Contains()` method operating on O(1), instead of using `Any()` operating at O(n). Or alternative using the `Add()` method that returns whether the element is new and was added (`true`) or already exists and was not added (`false`).
If you can write a trivial application that isn't just a benchmark and demonstrates a noticeable improvement in some metric by using structs, I'll believe you. The "value vs. reference type" understanding is important, but I've never seen it explained as a "rule of thumb" that works in a significant number of cases as opposed to "some rough guidelines" that become relevant in something like 5% of non-trivial programs.
First step is figure out exactly what that error is. Performance may not be the issue. Check the logs or repro in debug and visual studio will take you straight to the error. 
I mean I threw the code together in like 3 minutes after about that much time thinking about it for a requirement on a project at work... It did what I needed so I didn't think about very far past that. 
At first I thought this for/foreach idea just sounded dumb, intuitively it should generate very little difference but I decided to look it up. Turns out it’s a REALLY dumb idea because on 10 million iterations it would add .5 milliseconds in processing difference https://www.dotnetperls.com/for-foreach Unless I’ve missed your point, why even bother with such a micro optimization? On 5k iterations you’d need to use the query performance counter to even track the speed difference
If you don't want to recompile it, and it's private page/site - just turn on detailed remote errors on IIS. There's a couple of settings that need changing. (turn off friendly error messages in the browser too, so they show the full message) You should then get a yellow screen of death with very useful info. Or just attach a debugger. Or just check your event viewer logs, for IIS errors. Because it's a 500, the error details will be in there.
Unfortunately I can't do that, it's a public facing site and the companies "baby". I will have to dig into the logs, a local copy just ran without the crash but it seems to be different under the live environment. 
Yeah I get that, I think I will have to look for logs in order to find the exception but I suspect it's a memory / timeout issue that causes it. 
&gt; use a for loop not a for each I'll take bad advice that doesn't matter for 200 Alex
First of all, I'm assuming this is an optimization question. So let's start by making an optimized version of your own code: static string ToMixedCase_Optimized(string text) { char[] mixedCase = new char[text.Length]; bool toUpper = false; //first char is upper case for (int i = 0; i &lt; text.Length; i++) { char ch = text[i]; mixedCase[i] = toUpper ? char.ToUpper(ch) : char.ToLower(ch); toUpper = !toUpper; } return new string(mixedCase); } The main benefits of this version are removing the modulus calculation (using a boolean to toggle upper/lower is much faster) and removing all the string conversions and allocations. 10M iterations of your original code take 33.4 seconds to run on my machine. This optimized version takes 6.2. But we can do better. If you know you'll only be dealing with [ASCII text](http://www.asciitable.com/) (not unicode), consider the following: const int lower_a = 97; //ASCII "a" const int lower_z = 122; //ASCII "z" const int upper_A = 65; //ASCII "A" const int upper_Z = 90; //ASCII "Z" const int upper_offset = 32; //amount to decrement to turn an upper case to lower in ASCII static string ToMixedCase_ASCII(string text) { var bytes = Encoding.ASCII.GetBytes(text); bool toUpper = false; //first char is upper case for (int x = 0; x &lt; bytes.Length; x++) { if (toUpper &amp;&amp; bytes[x] &lt;= lower_z &amp;&amp; bytes[x] &gt;= lower_a) bytes[x] -= upper_offset; else if (!toUpper &amp;&amp; bytes[x] &lt;= upper_Z &amp;&amp; bytes[x] &gt;= upper_A) bytes[x] += upper_offset; toUpper = !toUpper; } return Encoding.ASCII.GetString(bytes); } This accomplishes the same output but much more rapidly, producing the same 10M iterations in just 1.65 seconds. You can check out the code [here](https://github.com/dipique/mixed-case).
Not exactly pseudo-code, but: 1\. Establish two values such that your equation is positive for one and negative for the other (taking sufficiently large positive and negative numbers should work for any "sane" equation) 2\. Determine the average of the two 3\. Check the value of your equation for the average. If it's: * sufficiently close to 0 - return the average as your solution * negative - replace your "negative" number with the average * positive - replace your "positive" number with the average 4\. Go back to point 2.
if you can be a computer engineer without an engineering degree or engineering cert, why can't you be a scientist with a computer science degree ....
Microsoft docs also contain a page on exactly this https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/choosing-between-class-and-struct :) 
https://stackoverflow.com/a/781/516419
These are all great tips. I really like the one about the fresh install to keep yourself comfortable with the environment rather than doing it once and forgetting how.
Having read back through your description of the application, and with my past experiences dealing with apps like this, let me describe how I suspect this monstrosity currently works and then some ways to fix it. * WCF call receives the "short list", which is a collection of in-stock products and stock levels * The method makes a database call, maybe using EF or some similar ORM, to load all of the products from the database into a collection * The method loops over each item in this collection, looks it up (by id or product number) in the short list, and updates the item accordingly * The method stuffs the collection back into the database, accepting all of the changes to the items Here's how I would probably handle this - handwaving away a lot of details of course: * Depending how many items are in the short list, I would probably use the unique IDs from those items to zero out the stock on absent items directly in the database. I.e. 1) `var ids = shortList.Select(i =&gt; i.ItemId).Distinct().ToList();` 2) Stored procedure or whatever: `UPDATE item_stock SET inventory_on_hand = 0 WHERE item_id NOT IN (ids)` * Alternatively, you might be able to temporarily zero out *everything*, and then let the next steps update the stock on hand. * Make a dictionary of the in-stock items for faster and safer lookup: `var itemDictionary = shortList.ToDictionary(s =&gt; s.ItemId, s =&gt; s);` * `Parallel.ForEach(ids, id =&gt; UpdateStock(itemDictionary[id]));` * UpdateStock takes an item, looks it up in the database by id, updates the stock for that item, and saves it back to the database My reasoning: * Getting all of the items from the database into an EF collection is going to be massive, slow, and possibly throw out-of-memory errors either during retrieval or when a reallocation happens while updating objects * That said, *there is no inherent relationship between items* so they can be processed individually in parallel. Parallel.ForEach (or whatever mechanism you choose) will only work if you aren't updating a shared collection. So they need to stand alone. * Reading from a dictionary (when you're not modifying the object in the dictionary) can be done safely across threads. Updating a collection cannot, at least not without some expensive synchronization tooling that completely blows out the reason for working in parallel in the first place. Sorry for the wall of text. While I definitely think some of the Gang of Four stuff is helpful, it's also generic and can be difficult to identify exactly which patterns will apply to your specific case.
ElasticSearch is a good replacement. 
&gt; I wrote a whole project of about 70,000 lines with .get() calling .get() function on when I wanted the value, and .put() when I wanted to set the value. One question: why? 
&gt; If it is a List&lt;T&gt; use a for loop not a foreach I’ve never heard this one before. Seems silly but I’ll bite. Are you telling me that the ListIterator is not just incrementing an index just like a for loop would?
Wishing you good luck!
correct. The compiler special cases arrays to do what you would expect, but on IEnumerables there is a little runtime cost and a little allocation. check out the IL or assembly output sometime, or look at the linq source. Most people think I'm crazy but its a simple default approach to take with minimal increase in code/typing. If its a performance-ish area I just always do a for loop. 
`Guid.NewGuid()`
One reason I recommend using an explicit thread is that you can name it, which really helps with debugging. Do they offer that with `Task.Factory.StartNew`? 
At a quick glance, you should save changes outside of the loop, rather than in it. But also debug it/look at the logs and see what your actual error is before assuming it's a performance issue. Then profile your code to see what the slow parts are.
You might want to take a step back and consider how this gets handled from a business perspective. I assume payroll is currently being calculated - how are they doing it? The software you end up writing should be an implementation of the business domain, therefore the business domain should guide you. I highly recommend [Domain-Driven Design](https://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215) for learning how to have the business, domain, *and* technical requirements guide your design.
I'd love to see the use case where this makes a material difference in performance.
No, I think he wants an index library like Lucene core and not an index server like Elasticsearch or Solr - both use Lucene as their index engine.
It is on the order of 1ms of time wasted for every 200k elements you iterate over. Or if you repeatedly do the foreach loop you also have the allocation and gc pressure that can become significant. use cases where this is significant abound as well as ones where it does not. It isn't significantly more typing or more complex either so why not just default to it? 
He didn’t seem to specify. I’ve migrated from using lucene to using elastic. Utilizing the Nest package from nuget. I enjoyed working with that far more than I did working with lucene.net. But it depends on his requirements, just offering suggestions. 
Do you need to call MessageWorkflow and _catalogManager,SaveChanges() if the stock level has not changed?
I just did a test on loop performance. I saved 161ms over 100M iterations, or 1.5 millionths of a ms. That is iterating over booleans. Iterating over a class instead had a performance penalty of about 3 millions of a ms per iteration. If your code is even remotely more readable or maintainable with a `foreach`, don't hesitate to use it.
I would start my search with nuget packages that have "Licensing" in their title.
Yeah that's a typo from the post I had to mess about to get it to format as a code block, ignore that. It deffo works.
Oh
It's not a code smell at all. For implementers, the interfaces are at fault for having overlap. Not a code smell. For interface definers, it's quite likely just a coincidence that there's any overlap. And sometimes, for trivial things, overlap is intended (like a "Name" property or something). So it's not a code smell here either.
Thanks. Nice to know I’m still useless 👍🏻
Which version of Sitefinity is this?
[This](https://github.com/garethrbrown/.net-licence-key-generator) might help.
Concurrent/Parallel is two people making two phone-calls at once. Asynchronous is one person making a phone call, then asking the person at the other end to call them back.
https://stackoverflow.com/questions/4844637/what-is-the-difference-between-concurrency-parallelism-and-asynchronous-methods. My take: **Concurrent** &gt; used within the context of describing managing a shared resource between processes or threads. E.g. accessing data in a List or Dictionary at the same time, but for different purposes, is usually referred to as _Concurrent access_ or _concurrent exectution_. See last sentence on Parallel, too. **Parallel** &gt; usually used within the context of running similar/the same tasks multiple times, concurrently. E.g. executing multiple HTTP requests _concurrently_ such that the requests are not executed in serial. Almost synonymous with _Concurrent_ really, but there are subtle contextual differences that would mean I think of one over the other. **Asynchronous** &gt; usually used within the context of a potentially long running process or thread, that you can yield and "come back to" when it is ready to proceed to prevent blocking the current thread. Not really concurrent, nor parallel related at all, but certainly permits easier management of parallel/concurrent tasks.
Some code points still do use more than one `char`, though: var s = "\u1b100"; Console.WriteLine(s.Length); Console.WriteLine(s[0] == s[1]); Basically anything in one of [these blocks](http://www.fileformat.info/info/unicode/block/index.htm) that starts after U+FFFF
As others are saying, you should fix the crashes before worrying about performance. You need to look at exactly what exception is being thrown when it crashes. Since this method is heavily using LINQ I'd bet a $20 bill that you are getting a null reference exception on something that's returning null. Example: var sparePartType = _ecommerceManager.GetProductTypes().Single(x =&gt; x.Title == "Spare Part"); If GetProductTypes() ever returns a null, you will get a null reference exception when you call .Single on a null. You need to check for null before calling a method. var sparePartType = (_ecommerceManager.GetProductTypes() != null) ? _ecommerceManager.GetProductTypes().Single(x =&gt; x.Title == "Spare Part") : null; Or maybe var sparePartType = _ecommerceManager.GetProductTypes().Default(new Whatever() {x = 1}).Single(x =&gt; x.Title == "Spare Part");
I used Infralution: http://infralution.com/products/licensing_system.html 
I appreciate it =) 
Hello! &amp;#x200B; I want to attempt your quizzes, but I don't want to create an account for it. Maybe try to create a test you can try without logging in? People could then see if they are loving it and then create an account. 
Not readable
Maybe to help us point you in the right direction, what are you doing with the control? A one time rendering? Can users pan/zoom in (i.e. do you need vector-based drawing)? Can they click to select things? Do you update the color/content frequently or infrequently or at all? I didn't dig too deeply into everything that Piccolo2d provides, but maybe SVG and [the new Edge-Based WebView controls](https://blogs.windows.com/msedgedev/2018/05/09/modern-webview-winforms-wpf-apps/)? I know Edge had some SVG rendering issues a couple years back but performance has improved quite a bit lately, it may be viable now.
Hi Triterium, thanks for suggestion. I'll surely try to add this soon. 
Thanks, I used it and it did the job perfectly.
I tried commenting out the thread.sleep but the same thing occurs. That's why I don't think it has to do with it
Wow, that's a neat piece of software. It looks like the source code link is broken unfortunately. 
Users can pan and soon as well as move the objects. It is important that it maintains a coordinate accurate representation as you can move and set the coordinates and it will update the backing game data. I have it draw polygons (in this pic squares and circles, but 2D volumes are pretty complex). 
[Rhino Licensing](https://github.com/ayende/rhino-licensing) might be worth a look, with a relevant summary of things to consider [here](https://www.hibernatingrhinos.com/oss/rhino-licensing)
.NET is generally not good at this, it has one of the highest cold start times. You can search on Google about it. BenchmarkDotNet tries to ignore the effect of the JIT compilation times, AFAIK. Every time you make a request, .NET has to JIT compile IL to native code and then process your request, because the app has to shut down every time. .NET Core 2.2 has tiered compilation which will make startup times a lot faster but it's still not as fast as JS. 
&gt; but I want to do this from within the client application You need to justify this statement before anyone can help you, because it's not common at all. What happens if you add a server or one of the servers goes down? You would have to update the client code, which can be really difficult. A load balancer abstracts the number of servers behind a service, which is super ideal.
Agreed but the load balancer is also the single point of failure here. If the load balancer goes down then access to all servers goes down as well if I am not mistaken. The available servers and their config are coming from Consul template so the config of the client application would be updated as soon as a server gets added.
Load balancers don't fail nearly as often as the application servers do. They're designed for high availability, redundancy, and failover. You are absolutely not going to design a better system than them on your own. Huge organizations view a load balancer as a single point of failure as an acceptable risk, since it's a well understood availability problem that they can solve.
Thanks that makes sense. If they accept it as a single point of failure then how do they get around it? An example or resource to further study on this would be really appreciated.
If it goes down, pretty much the entire company would scramble to fix it. That being said, I've never seen an entire high availability load balancing setup completely go offline, but I see application servers break down, need restarted, hang, need replaced, or simply need to stop receiving production traffic on a daily basis. If you are trying to make a highly available system, I would start by looking at https://en.wikipedia.org/wiki/High_availability#System_design
concurrent: several things happening in the same general time space. your operating system is concurrent. parallel: several of the same thing happening together as a batch, being processed more than one at a time. your video card is parallel async: i'll get back to you when it's ready. node and most network hook things are async.
You are only highly unlikely to get duplicates if you use the entire GUID. Using a substring of a GUID reduces that guarantee significantly. You wouldn't be able to use your code here for a database primary key, not without first querying all existing primary keys and storing those in a hashset as well.
I don’t think they do, but I don’t thinking naming the thread gives you that much benefit
**The** GoF book: [*Design Patterns: Elements of Reusable Object-Oriented Software*](https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8) by "The Gang of Four" (Gamma, Vlissides, Johnson, and Helm)
&gt; If they accept it as a single point of failure then how do they get around it? You can have hardware load balancers paired for redundancy. Software load balancers are generally implemented as large collections of independent or semi-independent nodes, so they are rarely an effective single point of failure.
&gt; Agreed but the load balancer is also the single point of failure here. In your proposed implementation, the client code is a single point of failure because a bug in your load balancing logic could prevent any traffic from reaching any of your application servers. At least with a hardware load balancer, you can have direct monitoring of the load balancer's health; if you push a bad client update, you'll simply stop receiving traffic and not know why.
Give [SkiaSharp](https://github.com/mono/SkiaSharp) a try.
It certainly isn't a deal breaker.
The following code does 10 million iterations in about 1100 milliseconds. char\* ToMixedCase\_Optimized(char\* text) { char \*mixedCase = NULL; if (text != NULL) { int len = strlen(text); mixedCase = calloc(len+1, sizeof(\*text)); if (mixedCase != NULL) { int toUpper = 0; //first char is upper case for (int i = 0; i &lt; len; i++) { char ch = text\[i\]; mixedCase\[i\] = toUpper ? toupper(ch) : tolower(ch); toUpper = !toUpper; } } } return mixedCase; } &amp;#x200B;
Thanks for mentioning the difference between hardware and software load balancers. It's really easy for me to forget the difference because my company's network team makes such heavy efforts to abstract it from us.
Also load balancers do one thing and one do that one thing - balance the load of incoming requests to one or more web servers in the back end (or behind your "castle walls") As said by others, if it fails, it is usually hardware failure, and that can be swapped easily or has some redundancy already set in place.
i hold to the same definitions as described in this talk: https://blog.golang.org/concurrency-is-not-parallelism granted this seems to go (heh) against the common belief that concurrent and parallel mean roughly the same thing as shown by the other responses here. so, concurrent in this context is that your system is capable of managing multiple things at the same time but that it isn't actually processing those things in parallel. it's basically just breaking all of those things down into tasks and scheduling those tasks to run one at a time. it's concurrent because it's not completing all of the tasks for one thing before it starts completing tasks for another thing. this is how the Task system in C# works unless you specifically state that you want a task to run on a separate thread. parallel is literally having multiple things running at the same exact time which is accomplished in programming via the use of threads. to piggy-back on /u/FacticiusVir's analogy, concurrent is making multiple phone calls to the same person who happens to have a fleet of administrative assistants. those administrative assistants process each call and come up with work that needs to be done by the person and puts it in a prioritized queue. the person then starts doing work based on what's in the queue. the whole time the callers are waiting on the line for verification that the work was done before hanging up. parallel is that the person has cloned her/himself and just handles multiple phone calls and the associated work at once. asynchronous would be the callers asking to be called back when the work is done rather than waiting on the line, as /u/FaciticiusVir stated.
&gt; It's really easy for me to forget the difference because my company's network team makes such heavy efforts to abstract it from us. There's a huge amount of complexity involved in networking that ends up not mattering to 90+% of developers (and 99.99+% of end users), so this is pretty common (and understandable).
You can implement the [Simplex Method](https://en.m.wikipedia.org/wiki/Simplex_algorithm). Also, if you want, you can use [Google‘s OR-Tools](https://developers.google.com/optimization/lp), they are an amazing package for defining problems and calling into solvers with MPS and other export formats.
Huh, TIL. Thanks for sharing! 
It's definitely a distinction worth making, but I've always heard that described (especially in older, OS-level discussions) as multi-tasking vs. multi-processing.
Agreed. Dunno how easy it will be to get working with WPF, but SkiaSharp excels at vector-based rendering.
What do you mean by "recognise the exception"? Are you getting a compile-time error, is the code running but doesn't stop when you expect it to? Is the code running, then stopping suddenly without reporting an error? Please give more detail.
The reason this isn't compiling is that you have some code outside any class definition. On line 111, you have the closing brace for the \`Run\` class. But then on the next line, you have \` ConsoleKeyInfo cki; \`. This declaration isn't legal outside of a class. It looks like it was also intended to be inside a method. I believe there some additional logic bugs with the rest of the code, but you'll have a better chance of figuring those out after you can get it to compile and run.
And some pseudo code http://www.cs.toronto.edu/~avner/teaching/S5-2411/ln/lecture4.pdf
You've got some responses here already. I know it can be a bit much just straight recommending a book, but if you want to learn more, you should read "Concurrency in C# Cookbook" by Stephen Cleary ;if you want to learn the ins and outs of this stuff. It's a really good book, and it's such an important and powerful part of C#.
Sorry, what I meant was that everything works perfectly, except for the exception, for example if I enter a negative number it does not catch it. 
Are you stepping through the code at run-time? Also, what is supposed to "catch it", I don't see a try catch statement anywhere.
It sounds like you need something like [round-robin DNS](https://en.wikipedia.org/wiki/Round-robin_DNS). I'm not familiar with Consul, but I searched that + Consul and they have a [DNS discovery layer](https://www.hashicorp.com/blog/load-balancing-strategies-for-consul). &gt;"Each time the application or kernel resolves that DNS entry, it will receive a randomized round-robin response of a list of IP addresses which correspond to healthy services in the cluster." Then, when a request fails due to a server issue, you can resolve the DNS entry again and get a fresh IP for a healthy server.
&gt; if (toUpper &amp;&amp; bytes[x] &lt;= lower_z &amp;&amp; bytes[x] &gt;= lower_a) &gt; bytes[x] -= upper_offset; &gt; else if (!toUpper &amp;&amp; bytes[x] &lt;= upper_Z &amp;&amp; bytes[x] &gt;= upper_A) &gt; bytes[x] += upper_offset; &gt; You can do without all that bounds checking. If you know you're working with ASCII, simple bit manipulation is sufficient: static public char ToLowerAscii(this char c) =&gt; (char)(c | 0x0020); static public char ToUpperAscii(this char c) =&gt; (char)(c &amp; 0xFFDF); 
Well I suppose I dont understand how to make an exception work, could you please show me?
That’s why SLA 99.5% is considered all time availability. 0.5% are left to theoretically possible failures which in this case applies to load balancer, something you won’t need to care in practical terms.
You have two options... a) Use a load balancer like haproxy, 2 of them, w/ keep-alived b) Write your own client side round robin like you said. To do B is very simple. Step 1) keep track of hits, and do hits % 4, if you have 4 api servers. Then hit api[result]. Boom. They will take turns. Step 2) You need a process that monitors if those endpoints are alive. A timer can do this. Maintain a list of available ips and a list of all ips. Hope that helps. I've done it both ways, it just depends on the job and the resources at your disposal. 
Await Task.run(() =&gt;{getfiles() ;}) ;
There is no async file listing API, not in .NET and not in Windows itself as far as I know. Easiest workaround is to to do it on another thread.
Your instinct is right. You want to get a service to take care of licensing for you. If you google .net software licensing you will see there are plenty of options out there. There is a big range in cost so look around. I won't promote any particular one but be aware nothing you do yourself can come close to people spending their lives dedicated to making a secure licensing service. Disclaimer: I work for a .net licensing company
To paraphrase my professor in Operation Systems: "Concurrent processes switch context very quickly which creates the illusion of them running at the same time. Parallel processes run concurrently."
Using EnumerateFiles is probably more useful than an async GetFiles would be.
All you do is create a custom exception. When you enter in a number, you should check to see if the number is negative, then you need to throw NegativeNumberException; A good way to handle this would be to have one central function for reading input, and call that from your Checking and Savings Account functions. If could read something like this. Try{ var input = ReadInputFunction(); }Catch(NegativeNumberException e){ //Tell the user they entered a negative number } Then you could define ReadInput (name permitting) like this static int readInput(){ int res = Console.ReadLine(); if(res &lt; 0) throw NegativeNumberException; return res; }
Hello, Thank you for your advice. I updated my code. Did you mean like this? &amp;#x200B; [https://gist.github.com/Somethingsomethingusername1/58f1b0650285537f89a9fbf9ccfb609c](https://gist.github.com/Somethingsomethingusername1/58f1b0650285537f89a9fbf9ccfb609c) &amp;#x200B; (Check checking.)
&gt;You can do without all that bounds checking You have to bounds check because there are characters other than letters, such as punctuation, that are valid ASCII characters. An apostrophe should not become an @ symbol if it's in a lower case position. If there's a way around that I'm all ears. &gt;There's also no reason to convert your string to bytes I'm not, really. `string text` is immutable (as arguments ought to be), so I am creating a mutable array of bytes and, in the process, converting from unicode to ASCII. Once manipulated, those bytes can be copied very efficiently into the (unicode) return string. These pieces could also be handled manually, but handling encoding, endianness, and null terminations was more than I wanted to deal with for the sake of getting mixed case output. &gt;You can also do better than Marshal.Copy. cpblk for example. Possibly? I usually use `Buffer.BlockCopy` for managed types and `Marshal.Copy` for unmanaged types, but some Googling indicates that `cpblk` and `memcpy` are more performant in certain scenarios. &gt;You can probably even squeak a tad more throughput out by eliminating the if.. else, too. I just tried it but wasn't able to improve the performance that way, although perhaps if I ran thousands of samples it would indicate a small improvement.
Close. It just boils down to you need to 'throw' the exception still. So anytime you read in a number you should validate that it is positive. If it's not, then you would throw new NegativeNumberException(); You also need to 'catch' the exception or else your application will break, because an exception was raised. Try{ var numberInput = Convert.ToInt32(Console.ReadLine()); if(numberInput &lt; 0) throw new NegativeNumberException(); }Catch(NegativeNumberException e){ //Tell the user they entered a negative number }
Why was this downvoted? OP, stop making this subreddit do your homework for you and get studying. That link is exactly what you should be reading.
Thank you for your fast response, I updated it again. &amp;#x200B; [https://gist.github.com/Somethingsomethingusername1/58f1b0650285537f89a9fbf9ccfb609c](https://gist.github.com/Somethingsomethingusername1/58f1b0650285537f89a9fbf9ccfb609c)
What do you feel is wrong with your approach? I don't really know enough about your use case to say it is good or bad.
Aah my mistake, I should read the docs!
This is like saying you shouldn’t run a firewall because if it goes down requests won’t reach the server.
Why is this downvoted?
This is not really the same as true async. You are just moving it to a task to conform to be able to write 'await' but it will still block a thread, just not necessarily your current thread.
Licensing keys are a whole lot more complicated than that.
You sound like "I have a piece of wood I'd like to cut in half, but I don't wanna use a saw. I want to use a hammer. Is that dumb? Yes, unless you explain your constraints more, it sound pretty dumb. 
Do you have only one client ever?
I might be wrong on this, but internally I think lists may use arrays, the list interface may just be prettiness to hide the implementation of inserts and resizes ect
yes, the C# List collection is array backed. But when you do a foreach on a raw array, the compiler just turns it into a forloop. When you do it on a List, it actually uses the enumerator and there is a tiny bit of overhead.
Sounds just more like inexperience with infrastructure 
Yeah that part really isn’t even necessary honestly
I totally agree with this statement. I see this too much often : “we improved performance and made the task a sync”. As a developer I like to take a look at the code and see how they approached the problem to realize they made a function, wrapped the call in a Async.Run and added the await statement. Sometimes they also do rework the entire flow and make a good job. Work people I don’t hate me (:
I think the semi colon there is a typo from where I pasted the code in. As for a profiler I would havd to use the visual studio in built one, not something I've really had to do before but I am sure it's not too taxing to learn how. 
I think that's the key here, in point B he is going to have to write his own in app load balancer. Preferably accounting for sessions and all the other points made in other comments. Which are all things already built into purpose built hardware and software load balancers.
As long as the number of files in your directory is reasonable. Start talking 10's of thousands, or 100K+ and you'll be waiting a *long* time for that call to complete. Try it on a directory with 1M files (yeah, I know - it happens sometimes though) and you'll be waiting days.
..which is what EnumerateFiles does. Note that it doesn’t say GetFiles. 
If you really want to achieve it for some reason, just contact one at random using a good random function. But use a load balancer.
&gt; ..which is what EnumerateFiles does What does EnumerateFiles do? Call FindFirstFileEx? Because it does not do that. Go read the source code, or try it on an excessively large directory. It ultimately calls FindFirstFile, and there is a *very large* difference in how quickly FindFirstFile and FindFirstFileEx return when called on directories with tens of thousands of entries or more in them.
Oh would you like it to be three lines? Each part of the ternary its own helper local function and the initial .Select test to be a Func&lt;string, bool&gt;? any C# programmer past 2 years can easily read the above.
That's why I use CodeRush.
This sounds invigorating.
I like Resharper mainly for the hotkeys. Creating folders, classes, interfaces, extract variable, move statements/methods up/down, override method and so on. It means I don't have to use my mouse while programming which speeds things up tremendously.
I haven't used Resharper, but Visual Studio's modularly extensible unit test plugin system seems extremely brittle and prone to failure in a surprising number of mysterious ways. The most common of which is that all the tests just disappear entirely from the test explorer. As for resharper, I think the main reason it's so slow, is that it refuses to use roslyn or any of the existing partial parsing stuff exposed by MS, instead opting to use their own hand-built parser/static analyzer. That means VS is parsing all the source twice.
&gt; The available servers and their config are coming from Consul template so the config of the client application This seems like the correct use for something like [Netflix's Ribbon](https://github.com/Netflix/ribbon). Although not in dot net I have a system which sounds similar to your use case. We have the client using a ribbon like library to proxy requests in a load balanced way using information provided by Consul's service discovery. It's backed by DNS SRV records provided by Consul. I am not sure if this pattern will work for your use case, but it may be something worth considering.
Oh I know why it's slow, and you are correct. This is also what makes ReSharper crash the damn thing when VS runs out of memory, given that ReSharper runs in the same process space.
&gt; Asynchronous is one person making a phone call, then asking the person at the other end to call them back. Or just text messaging. You both don't need to be on the line at the same time in order to communicate.
Attention now cuz this is a very common misconception. Await is not blocking. For example if this piece of code is put inside an function/event handler that is situated in the UI thread it wont choke the thread, Async-await works like a relay race of two people, the async function/task will run up until it gives the baton to the await call and as soon as the away call ends it gives back initiative. The one liner i delivered through phone is not perfect but it works, you can remove the await keyword and let both run at the same time if this is what you will. In any case, for more info on multithreaded access of the filesystem i think people should check out those two docs: https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-iterate-file-directories-with-the-parallel-class https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/tpl-and-traditional-async-programming 
I recommend Rider. I feel like its the best parts of resharper and vs code.
I like VS too much. I'm a sucker.
Yes. And XUnit.
Soul mates.
I would do Task.Factory.StartNew depending if it's a long running task
I've had Roslynator downloaded, just haven't bothered yet. Enjoying it?
If its that heavy of an execution then think smart and break down file acquisition to different chunks and assign them to different threads, i suggest you follow the two links i posted somewhere in this reply tree, they talk on how to leverage plinq to get the job done. After all there Is a way on how file explorer will open 5k files in a flicker of an eye, and i dont think this way can be replicated in a single line of code. 
Very much and it doesn't slowdown Visual Studio at all.
Removed: Rule 4. Here are some examples of how to work with DataTables: https://www.dotnetperls.com/datatable
What exactly have you tried so far, and what specific issues have you encountered? The Microsoft [documentation on DataTable](https://docs.microsoft.com/en-us/dotnet/api/system.data.datatable?view=netframework-4.7.2) contains examples that can help you. Additionally, [searching key terms](http://lmgtfy.com/?q=insert+array+into+a+datatable+C%23) from your title produces numerous other code examples that can help you.
Um thanks
I have to be the only person in the world that doesn't have issues with Resharper's performance.... It feels like I must be in the twilight zone or something. I do think it has one of the best test runner setups out there too.
\&gt; The most common of which is that all the tests just disappear entirely from the test explorer. &amp;#x200B; I was interviewing for a job once in which they had me build a class library with unit tests in front of 5 people. It was a simple class library with a single function, however when I went to run my unit tests (from MSTest) the test explorer just didn't show my unit tests! Myself and the 5 other developers in the room had never seen that happen before and we got to spend 5 minutes poking around before just restarting VS to resolve the issue.
To add: C# GUID bits are probably not generated using a secure random number generator. This stackoverflow answer would be a good way to generate your own type 4 GUID using a secure random generator though: https://stackoverflow.com/a/50456283
I use coderush as well. Yet to find a good reason to insert a picture in my existing code comments, but I will find a reason one of these days!
What features were you missing? The only think I’ve run into is including files into the build folder in core. Also slightly annoying is it’s autostepping into 3rd party code. I wish there was a quick toggle to stop or allow that. 
Putting aside the fact that coupling your application to the hardware and communication stack you intend to use sounds like incompetence, I genuinely don't even comprehend how you can't solve this problem. Make a request to one, if the request returns an invalid status code request from the next. It's a bloody do/while loop dude - coding 101.
Are you running some super computer as a dev box? 24 cores @6GHz with 1TB of DDR8 ram?
I have no issues with it either, I9 7900x 64GB ddr4 4333mhz, 1TB Samsung 970 Pro, windows 10, 2x GTX 1080ti's works flawlessly and no slow downs. 
I'm stuck using Rider for a project. It's been about 2 months now. I simply can't comprehend how people are recommending it. I also spent a lot of time developing PHP using PHPStorm, so I'm familiar with Jetbrains IDEs. Rider is totally subpar. 
Yeah I've never tried it, but it doesn't seem at all ready to compete with VS yet. On an unrelated note, I think I just figured out why JetBrains is named like it is: NetBeans JetBrains
Rider doesn't allow you to add web service references, so I found myself having to go back to Visual studio everytime I wanted to add one, or have it included in intellisense to work with. &amp;#x200B; Also Rider randomly stopped letting me create new projects since all the templates disappeared. So I found myself having to go into Visual studio everytime I wanted to create a new project anyway. &amp;#x200B; I also always upgrade the latest and greatest [.](https://ASP.NEt)NET core core versions and sometimes Rider was lacking support so I had to go into Visual studio to set my framework versions. &amp;#x200B; Sometimes rider randomly broke or threw errors when trying to add NuGet packages whereas I would go into Visual studio and add them no problem. &amp;#x200B; I love rider, but having to jump back and forth kind of defeated the purpose and with ReSharper available most of the advantages of Rider can be brought into Visual Studio as well &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; What I really want to discuss is ReSharper's test runner. Why is it the only one that seems to work when everything else craps out? What alternatives exist? We use [NCrunch](https://www.ncrunch.net/) at work and it's really nice. Tests are executed in the background without having to explicitly rebuild and it shows code coverage. 
A little rough to read but the part that isn’t working for you is you’re not actually calling ReadInput(). Change line 75 from console.readline to readinput()
I think most people who recommend that kind of stuff refuse to us Visual Studio, and just want to use a text editor.
I hope not when you have an i9 and 64GB RAM.
if you have win10 I recommend [Win2D](https://github.com/Microsoft/Win2D). api is quite solid and is from the guy that wrote XNA, so it's worth considering. 
Might be a stupid question but what is ReSharper used for in development? I've used VS 2017 a lot, for uses from WPF applications to SQL interfaces and I haven't had to use it yet. Is it highly specialized? 
Concurrency is the ability of a program to execute two code paths independently. Parallelism is the ability of the environment to run two independent code paths simultaneously. So, concurrency is a particularity of the program, while parallelization is a particularity of the environment where the program is run. If a concurrent program is run in a multi-core environment then it's run in parallel. Now, asynchrony is a term I don't see very often in formal computer science academic works. I think it's a broader, informal term generally used as a synonym of concurrency. --- Edsger Dijkstra is considered the father of concurrency in computer science. Go read some of his work, he is a genius and deserves our love. If you'd like to go deeper. go learn π-calculus. It's, hum, like λ-calculus, but concurrent.
Hello, thank you very much for your time, and I took your advice. Something that happened after I changed that is now i get an error for try and catch that says they "do not exist in the current format." do you know why that is? I thought I had set them up in the exception class. 
woosh
Missing your brackets at line 13 when you throw exception.
&gt;So generally, I think it's, "I hold these degrees as less valuable than mine and will fight for it because I have to have a hierarchy." I see it more like this: there are the hard sciences (Biology, Chemisty and Physics); and then there are social sciences. A degree in a hard science is inherently more valuable due to the increased difficulty. Any social science is going to be a sidegrade to these. I feel that it's fair to see things this way.
2.8gzh with 32gb ram. No issues here. 
I'm surprised! My team has been using Rider for quite a while now, and I rarely go into VS anymore.
He also uses a Razer mouse for extra precision when converting strings to floats.
In defense of ReSharper. It is an awesome learning tool. Every time I see squiggly lines I hover with my mouse and learn or remember something. I learned so much while using it that I would hate to see it disappear. But then it is a hog sometimes. 
I love resharper but it crashes Visual Studio for me about once every couple of hours unless I restart. On both my work laptop and my home PC. No idea what causes it. Really annoying.
You wrote something in 3 minutes and had the internet review it. I'm not really sure what you were expecting.
FindFirstFile and FindFirstFileEx don't have any performance difference with regards to the actual function call (FindFirstFile and FindFirstFileEx itself). The performance difference is a cumulative effect between the performance of FindNextFile with FindFirstFile and FindFirstFileEx. By way of example, I went ahead and did exactly what you suggested they do- " Try it on a directory with 1M files (yeah, I know - it happens sometimes though)"- I filled a directory with one million text files Which was actually annoying to wait for. Then started enumerating via EnumerateFiles() (It does, as you stated, use FindFirstFile()). There was no wait time. I wasn't waiting forever for EnumerateFiles() to return, it was (perceptually) immediately inside the foreach loop with the first result when stepping through. The performance difference between the two exists. But that performance difference applies to the retrieval of each element, and is not necessarily constrained to large directories- just far more pronounced with them. With FindFirstFileEx you can specify FIND_FIRST_EX_LARGE_FETCH, and/or use the FindExInfoBasic flag to increase the performance of the operation as a whole. Specifically, this is most useful for networked drives. For obvious reasons with large directories with many files, this can greatly increase the performance of the overall enumeration, even with a Local Disk. However, it's also possible that this performance difference could be somewhat inconsequential. It depends what is being done with each element. Instead of operating directly on the files within the foreach loop, they could be added to a concurrentqueue for processing by a separate task/background worker/thread. In that case, as long as the enumeration is able to keep up with the processing, it's not going to have wide performance implications on the overall program. 
Bro- I hope I’m not out of line here in telling you to go fuck yourself.
I don't have any issues with resharper either. Does every one in the world have big 10k lines code files or something? 😅 I've been using it for around 4 years.
32 GB? Damn. I've got SQL Server boxes in production with only a quarter of that.
You get much of the same experience by turning on VS code analysis. 
I also have no issues with resharper performance, and love using it
I have an 2017 i7 HEDT from Silicon Lottery running at 5 GHz on 6 cores, 64GB of ram. Resharper is so slow, I’ve stopped using it altogether. But other products from JetBrains more than compensate. I haven’t used Rider, by from PyCharm to Goland - the products are really good. Despite an NVME drive the startup time is still 30 to 60 seconds. Will possibly upgrade to the new i9 when it comes out on SL. It’s all about single core perf, don’t let anyone tell you different. One core saturated, rest just idle...
I myself can't get around the insanity that Rider is an IDE built with and running on Java to work on C# for .net! The overhead just makes no logical sense to me.
Sorry for the offtopic question, but which editor (and which theme) is this in the screen? Looks beautiful
nah actually have a logitech G610 mouse razer mouses suck ass..
LOL nah just 3x 28 inch Samsung monitors with 2ms lol.
28.0 inches ≈ 71.1 centimetres ^(1 inch = 2.54cm) ^(I'm a bot. Downvote to remove.) _____ ^| ^[Info](https://www.reddit.com/user/Bot_Metric/comments/8lt7af/i_am_a_bot/) ^| ^[PM](https://www.reddit.com/message/compose?to=Ttime5) ^| ^[Stats](http://botmetric.pythonanywhere.com) ^| ^[Opt-out](https://www.reddit.com/message/compose?to=Bot_Metric&amp;subject=Don't%20reply%20to%20me&amp;message=If%20you%20send%20this%20message,%20I%20will%20no%20longer%20reply%20to%20your%20comments%20and%20posts.) ^| ^[v.4.4.6](https://www.reddit.com/user/Bot_Metric/comments/8o9vgz/updates/) ^|
Lol Not at all 🤣🤣🤣
I hope the joke was obvious. I have seen some horrors in legacy code.
Gotta spend money to make money! 
Are all your solutions 5 projects or something?
It's the memory usage. Take this shit out of my 32-bit VS process already. But I can't go without it. Roslynator just isn't the same. All the time lost waiting for it is easily earned back with "implement in derived classes".
Consultant here. I'm currently working for [huge international European power company] and more specifically on a tool they let companies use to analyze their power consumption in great detail. Let me tell you, the code base is fucking huge. We're not talking tens of thousands, but hundreds of thousands of lines of mostly C#. On top of that were handling data sets with a few billions of entries, and servers up the wazoo to handle it all. Resharper isn't doing great (on the virtual machine I sandboxed windows 10 on) in my 1 year old Dell XPS 15. Not great, but it definitely works.
100k lines per file? 
&gt;As for the fact the other thread being "blocked" because it will call getfiles anyway, this is weird claim to make too, I mean is int x=1+1; considered blocking? Why wouldn't it be? What other code can run on the same thread before that action completes? Isn't it blocking by definition based on the fact that the answer is none? The `Task.Run` method utilizes a thread pool to make the work non-blocking. I think the commenter you replied to was running on the assumption that it didn't. If all it did was append the task to a queue in the same thread, then it would clearly still block that thread as soon as the task came up. Whether or not some work is blocking is a relative thing.
Move to dotnet core. Then you can just run `dotnet watch test` in a terminal and never look back. 
Just get Rider
Right now the thing that resharper does that I can't do without is that it autocompletes namespaces that aren't loaded in the current file yet. Plain VS presently will offer to add using statements if you use a reference that isn't in the current file, but that's only after you type the full name. That, it's code style suggestions and advanced warnings are really the only reason I put up with the hitches and slowdown it adds.
I found even disabling ReSharper didn't help much. Completely uninstalled and everything is better now. Visual Studio test runner with xunit seems much more reliable in the latest releases.
more code per file = less files - think smarter /s
Well I have 176 projects in the solution. C++ and C# mixed. It's slow. Very slow.
its really just a productivity tool, you don't really "need" it in the same way as for example Visual Studio but its nice to have
Meanwhile I'm a solo C# developer in a historically Delphi shop just wondering what Resharper does that makes it so great. (I convinced my boss to let me start a new project in C# instead of the ancient behemoth that is Delphi, and as a result I'm pretty much self-taught and had no mentor in C#)
Is Codewars still buggy or has been improved? The last time I checked it was so buggy that it was denying any correct solution for it.
I got setup with (core 2 duo, 8 gb ram) my first internship so am still finding reasons to stay. 
I've always used CodeRush, but the latest visual studio updates seem to have broken it.
Preferences -&gt; Build, Execution, Deployment -&gt; Debugger -&gt; Uncheck 'Enable external source debug'
Yeah visual studio community edition is what you need.
Learn .net core. It's really cut back to just the essentials and much easier to learn as a beginner. No real reason to use framework for web development anymore unless you have legacy stuff to support. 
Are you a student?
Yep, the free one is called Community, it's what you're looking for. In, like 2015 it was called Express but that was essentially dumbed down. Community has most of the bells and whistles of the Professional version, missing 1 or 2 features you won't notice until you really go into the ecosystem. 
Who isn't it an option for?
What? No, don't move from standard. That's perfect!
Problems that I have with VS's xunit test runner... Duplicated facts, tests not running with no feedback as to why, slow code lens updates. I really, REALLY miss Resharper's test runner but (despite owning a licence), I will never let R# back onto my machine, due to the performance issues it causes. Roslynator's not perfect, but it is getting there!
Yeah, this way you just block _another_ thread. Most probably OP wants the UI thread to not block, wants to report progress or display partial results. Not blocking the UI required only to don't await the operation. The latter two depends on whether you want to report only by enumerating subdirectories too. In that case, you can manually use recursion in the directories. Most probably though it's not async because the underlying async operation does not worth the extra allocations. So you can just use simple enumeration, as it should be yield returning the results one by one.
If tests still won't work it is helpful to check if test are run on the same processor architecture as it is set in tested projects configuration. To run on different processor architecture: Test-&gt;Test settings - &gt;default processor arch
No but I'm going to go back soon.
They likely don't want to pay for both.
I switched to Rider, and haven't looked back since. Rider is amazingly faster than VS + R#. The only thing I'm missing is NCrunch. 
If your university has "Microsoft Imagine" (previously Dreamspark), you might be able to get VS 2017 Enterprise. It's not very different from community, but it does have some nice profiling tools and other enterprise features that are nice to play around with.
&gt; Why do I keep unsuspending ReSharper when I know I'm just gonna shake violently? You need to have faith that you *can* be efficient without ReSharper. Watch [these](https://www.youtube.com/playlist?list=PLRAdsfhKI4OWNOSfS7EUu5GRAVmze1t2y) for inspiration. Interestingly, Immo uses VS Code, indents his code manually and, when asked why he doesn't auto-format, answers, "I don't know how to"!
Live coding is a very different thing
Our sql boxes all run 256gb and we’re a tiny company
Ahhh, great! Thank you!
A lot! &amp;#x200B;
One client said SQL Server was way too underpowered and they needed to replace it with an 8-node Hadoop cluster. They were running a single SQL Server box with 8 GB RAM.
I think they meant Framework, the standard way things used to be.
Visual Studio Community Edition is great and free. don’t worry about the advanced features in Professional and Enterprise for now. All Visual Studio installments are based of the same installer and you can always add/remove features and upgrades. Start simple, otherwise you’ll find the weekly updates a pain. I would also recommend a simpler IDE such as VS Code or Sublime as a supplement. Less clutter, better performance and so on. Beginners tip for VS: Learn some basic keyboard shortcuts early on Here are some that are useful, but less known (IMHO): Go to anything: Ctrl + T Quick search: Ctrl + Q (includes windows) Go back: Ctrl - Next error in error list: F8 I could go on forever, but here is a comprehensive keyboard shortcuts list: [Visual Studio 2017 keyboard shortcuts ](http://visualstudioshortcuts.com/2017/) 
My home box from 3y ago is 40G.. But yeah, employers are dumb that way. I would not get 4G into work comp 10y ago until I had 2G leftovers from home upgrade
The thing that causes sluggishness is not ReSharper, it's due to visual studio team refusing to give users the option to disable Roslyn. The whole "modular" bs is ... well, bs if it's not possible to completely remove the code analysis bit. The other issue is that VS is only 32bit so large solutions suffer. Rider is lightning fast cos there's just one analyser and it can run as 64bit and not be limited by memory space forcing constant swapping. I agree that VS has more features but I wished the VS team focused more on stability and bugs than features. Rider is catching up, and there is no better c# IDE on osx or Linux.
Unless you are in a mac... in which case I would recommend you visual studio for mac. vscode is also pretty good for .net core on linux or macos. 
We too. But the there are problems with core 2.1. So we are back to vs runner
Can't use net core for xamarin. 
Of course you can. Write all the logic in a .Net standard library and reference that from the Xamarin project. Then unit test the library. Simple. It's also a better design because if you love from Xamarin you just switch out the UI for whatever you want to use next.
You can use a net standard library fine, and I do . But not net core. 
Hah yea. They pumped our new laptops because our new dev environment requires it a VM service. I don't do that development (centered around a CMS, so I just get a lot of RAM for no reason. However we were on 16gb and had no issues either. Our offshore using 4gb had to disable Resharper. 
Man it’s nice not having to deal with Visual Studio anymore. So glad JetBrains releases Rider.
SQL Server is not new and shiny. It's far too run of the mill for people to appreciate just how powerful it is. Source: Lots of years experience. Only just truly started to learn SQL Server.
Split that into several repos... Pin dependencies...
That is very true. Though I think there's a Rider+ReSharper bundle that's a pretty cheaper upgrade. But yeah, it didn't come out of my pocket so I didn't think of the cost so much.
I don't either.
Also AxoCover is nice.
It's the dumbest thing but what I need most from ReSharper is finding files quickly by name. There's just no plug-ins or extensions that do this (without freezing up). 
Visual studio with C# is the best. The debugger is out of this world. Nothing i've seen compares to it.
ReSharper performs a lot better for me since I turned off solution-wide analysis. I still get warnings, errors, and refactors in the editor, so ¯\\\_(ツ)\_/¯ We don't use the ReSharper test runner. We have NCrunch, and also experimented with the built-in test runner in VS2017. The built in one is noticeably faster - when it works. However, its default failure mode is to disappear entirely. With NCrunch you always have a status icon and window. We also have some custom analysis rules in Roslyn, but intentionally didn't overlap with ReSharper any more than necessary.
Its not weird, community is the free version. 
I too work for a large company. On a legacy project with some huge files, huge functions, etc. I'm constantly extracting functions, creating smaller classes, and moving them into their own files. It improves resharper performance, and also improves code readability and reduces code duplication.
I don't have problems either. It definitely increases solution load time, but once that is done I have no problems. 
[Roslynator.](https://marketplace.visualstudio.com/items?itemName=josefpihrt.Roslynator2017)
Codegen'd.
Yeah, they rewrote the test runner framework for 2017 and... it isn't great.
Not actually a debate. .Net core is the way to go 100% of the time. 
Around 8 million LoC with 70 projects solution dev here. i7 4th gen, 16 RAM, SSD, and reshaper is pretty much flawless. Just killing it's cache one or twice per month to maintain performance. 
As the other people have suggested in this thread learn .NET Core. In regards to ASP, go for ASP.NET Core (MVC &amp; Web API is a part of the framework and not treated as two separate things anymore). ASP.NET Core is a complete rewrite of ASP.NET and the next step in the ASP.NET evolution. If you are getting started today it makes sense to start with the latest. Although .NET Core and ASP.NET Core can be confusing it is worth the trouble, and the fact that its open source means that you can follow the development and learn a lot. Follow the repositories on GitHub, and read the issues and discussions, as well as the code. I’ve found that to be a great way to learn and understand more about programming and the many decisions we need to make. A few tips: You should know is that ASP.NET Core can target the full .NET frameworks, or .NET Core- therefore when you create a new project you’ll have to choose. Generally I recommend targeting .NET core, unless you need something specific from the full .NET framework that is otherwise not available or replaceable. Microsoft has a lot of good resources on the topic, and the documentation has improved a lot. Make sure you always double check that you are reading the right version of the docs, as the framework has undergone a lot of breaking changes (in particular in the version prior to 2.0). This is also why you’ll find conflicting information online, and examples that might not run. Stick to 2.0 and up, and leave older versions alone. Microsoft Virtual Academy is great! Pluralsight (disclaimer: I’m a Pluralsight author myself) also has a lot of learning material, but make sure it’s up to date as I mentioned earlier. You can great a 30 day trial, if your schools doesn’t have a license with them. Some courses on Pluralsight are free through Microsoft. A final tip: Don’t be scared to reach out to framework devs at Microsoft (many of them are active on Twitter). David and Damian on the ASP team are great and always willing to answer questions, regardless if it’s from senior developers or newbs. Feel free to DM me if you have questions or are looking for more resources,I’m very active in the community and always happy to help. I’m currently writing a book on migrating from ASP.NET to ASP.NET Core so if you want more information about that I have a lot of it (but it might be overkill if you are just starting out). Best of luck
Oh no, absolutely not per file. Anyone who does that deserves a visit from Liam Neeson. I meant in the project as a whole.
I like this one.
What overhead...? 
??
This is concerning because that's hella expensive. Is the company newer? It's hard to imagine a tiny company would need that much horsepower.
This would require re-architecting the product ownership of the whole company. In most cases 176 projects means, there's projects that are only projects because someone wanted to produce 1 namespace per project. Or seperate certain types of classes. You only need projects for entry points (StartUp, DLLExport,...) or when two separate entrypoints share code but their entry points. Producing projects two keep # of class files and all that is gonna bite you in the ass one way or another. I manage around 900 csproj and vcxprojs at my shop - every issue i do i try to let go of at least 1 project. By my estimation i can reduce to something like 80 projects. The rest has no reason to exist.
Monodevelop is available on Linux too which is basically Visual Studio for Mac but it doesn't have all the features. It's pretty good though. I use VSCode personally but wanted to put this out there as another option. 
Visual Studio Community is almost on par with Pro anyway as far as features. I use pro at work and community at home and normally don't see any difference. The missing codelense is all I see that is different and for my home projects I don't need it. Oddly, it's included in VSCode by default. 
Roslynator adds new analyzers and refactorings that are available in normal refactoring menu (Ctrl+. or click lamp). For other stuff I just use Visual Studio's own functionality (shortcuts) that they are actively making better. Example I use "Go to All" a lot (Ctrl+T or Ctrl+,). For sharing coding style setting etc. with team I use .editorconfig and roslynator.config
Ahh, the good old Task FooAsync() { Task.Run(Foo); } approach. Hey look, ma, I made all my code async with a simple regex!
Nice
I wouldn't go that way. In all my years, I have *never* seen a shop replace a database with a different one, requiring a data layer rewrite so it could handle both at once. What I have seen, is they'll add a new database server, and slowly migrate features over. Same applies for database helper frameworks like EF or Dapper. By the time the code is written and in production, the business won't spend the money to rewrite it. They'll add a new library, not remove/replace one. Pick an approach that solves the problems you have and doesn't appear to prevent future changes. Don't anticipate problems you don't have.
have your business logic contracts (models and service interfaces) in a separate library from their implementations: * MyCompany.Project.BusinessLogic * MyCompany.Project.BusinessLogic.EntityFramework what people will tend to answer is there is no need to have a DataAccess layer that is between these two libraries because it doesn't really add much real life benefits. you won't ever actually swap out your database or ORM etc. but if you do want to do that it's generally done with the repository pattern.
Or don't want to use both. 
This, and if there is a move from say SQL Server to Oracle what I have seen is that the stored procedures are ported, as needed, and the connection string is changed. Rather easy, relatively. A good data model is good regardless of the server
Oh I know about that, I wish there was a little toggle for it right by the step through code commands. 
Now that MSSQL has sequence objects, that port would become much easier.
I call it vanilla. :( Microsoft needs to work on their naming strategy.
Try SQL Server to PostgreSQL, it's a pita &gt;_&lt; It's interesting your mention Oracle. We have teams still actively working with it, but I can't say I've spoken to a lot of industry peers who see Oracle as a strategic investment. 
The java runtime, not the dev environment. You likely already have JRE installed anyway
I'd curious why it was a pain. As for Oracle, yea it's expensive as F! However, if you are dealing with MASSIVE amounts of data, then it very much can be worth the cost. Back in the late 90s I developed Wells Fargo's ATM management software (some details: http://www.blissgig.com/default.aspx?id=27) and it was everything about the atms, except for transaction info, and while it was a decent amount of data, we did not NEED to use Oracle, but since it was the standard db in the company's data centers it made sense that those who monitored it knew that software. However, the transaction data for the ATMs did NEED to use Oracle because of how much info is handled. Me, I have generally used MS SQL Server for the past 20+ years, but there are other good choices
Stored procs mostly. People just seemed to slip in a dozen T-SQL stored procs every time they had to develop something, for no good reason, and without telling anyone. It made the whole thing bitter :/ I'm with you I think. Pretty much all my Oracle experience was with legacy stuff, and that hasn't reared its head in a decade? It's still there, but I can't imagine a meeting with anyone proposing "an Oracle backend" would go well :/
Repository (reads) + unit of work (writes) should do as these simply abstract/ separate your infrastructure concerns from the core app. That way your DAL can easily swap sources/ ORMs without affecting other app layers. 
&gt; The thing that causes sluggishness is not ReSharper It literally is. &gt; it’s due to visual studio team refusing to give users the option to disable Roslyn And… end up with no code analysis, no IntelliSense, no compiler, ? Roslyn is basically the engine behind the entire C#/VB compiler Stack as of VS 2015 and newer. At that point, just switch IDEs? &gt; well, bs if it’s not possible to completely remove the code analysis bit. It’s on JetBrains to hook into Roslyn’s code analysis, just like tools like Roslynator do.
Yeah, for all the talk about data abstraction I've also never seen anyone switch databases for their own products I have, however, seen products offered that work with different DBMS, and use an abstraction layer to create something resembling plug-n-play for the client. We had one product at a previous company that was somewhere between off the shelf and bespoke, and worked with several different database backends depending on what the customer used - we were dealing with companies much bigger than we were, so we couldn't dictate the DBMS for them.
Sure, make a simple WPF application that only concerns itself with UI stuff. Write all logic in a dotnet standard library, reference that from your UI and test the library with xunit in dotnet core. Don't test the UI layer and you're all good. 
You'd have to align Vector3 to 16 bytes, then they'd fit together in LightData just fine. Consider creating a struct called Aligned16Vector3 with implicit cast operators to/from Vector3. From what I've seen, most of the time those values are expanded out to Vector4 or other values are snuck in there between the vectors.
Don't functions in postgresql work the same as stored procedure in mssql?
Then why not just do the library in .NET standard?
Without specific examples, I can't tell you what you should have done. What I *can* say is that programming is all about providing solutions to a problem domain andthat simpler code != more maintainable (though it can be). What I mean is that, sometimes, the problem domain is "how can I make this program more flexible/extendable" and not just "how can I make the program do what it needs to do". It really depends on the context of the program, though. For example, if you use DI for a "Hello World" console app, you've over-engineered the solution.
Asp net core for sure. Also you might want to look into Blazor, a new c# web kit
Enterprise is about $20000 per dev per year otherwise. It's a really fantastic tool with some incredible features you will not believe you could live without. Enjoy it while you have the student license.
Visual Studio Code is nice too. 
Code first, analyse, then refactor either to a pattern /architecture if the problem domain calls for it. Over engineering or over patternification will cause confusion and unnecessary obfuscation.
Some examples we used DI, respected SOLID, used Migrations, did UnitTests, Mocks etc but for queues we used tables. We had access to RabbitMQ but that would increase the complexity of our deploys and the things that a new hire would need to learn. So it went out of our stack. That type of decision seems wrong at first but worked like a charm.
The testing features of resharper are pretty much the only thing I like. Code coverage and Test Sessions and especially not having to build the project for VS to recognize a new test are awesome. I hate how resharper hides what methods you can overload when inheriting. Its intellisense is far worse than VS default. Also I find stepping into external dolls that you have loaded seems to be hit or miss.
How did you use tables instead of a message queue like RabbitMQ? That does *seem* like a bad decision at face value unless you didn't need many of the benefits that a proper MQ like RabbitMQ would provide. 
Is there much benefit to stored procedures, given that the db can cache queries?
We handled atomicity, retries, ack and more. The query is really simple and for our needs it is working really nice. The thing is, we drove every decision based on the simplest approach and this is an example of something that seems wrong at first.
Yes yes yes! We kind of did underengineering and it was good!
This!
Visual Studio has that built in, at least in VS17.
Totally agree. We used all the standard stuff like DI, UnitTest, layers etc. But we only added things that clearly had value. We understand the importance of DRY and made our decisions based on that. If it is business rule we would use some approach to avoid repeat it. But for simple cases we would just write the stuff again, think some small template, instead of inheritance. I can say that new developers like it because of it simplicity. 
First, I'm pretty sure the context is meant to be created for a single unit of work, and thus not shared. But you mentioned that you do not control the scope, so not important. However, before calling return false, you can call context.Rollback(); which will rollback the changes made, and ensure you don't get a partial save.
Show the brightest example of using simple solution instead of some pattern or violation of some fundamental principle(like SOLID, DRY, etc.) that in your opinion gives more readability/flexibility/maintainability. 
This sounds more like you should be using a dedicated thread and queue. But there is too little information to say more about it. Can you share more information?
It is not what we did but what we decided to avoid. The part related to DRY is that we used a copy and paste approach for some structure code, we did that on the first time and didn’t found any necessity to make it better. What we found after some years is that the possible problems relate to this approach never occurred or wasn’t that bad. On the other hand if we started doing more complex things to premature improve our code we could end up opening space to even more complexity. It is more about the culture of avoid any complexity by default that I am defending here. In our case we found that the problems related to underengineering is way better then overengineering. Let me add here that we understand dry, we know how important is this principle and took care to respect it when it was important for us (e g business logic)
I think this is the most useful response. It's true that it is uncommon to swap out the database, although my team is currently considering it and it won't be easy because of how tightly the app is coupled to SQL Server. It's very little work to program to an interface and inject in the DB implementation that, in my opinion, you might as well just do it. 
The op didn't say if this was EF 6 or EF Core. I don't think EF Core has a rollback option on the context.
I think where this kind of thing is more common is moving legacy apps into the cloud. Our team wanted to move from SQL Server to Azure SQL but it's not so simple. But to your point, the apps are legacy so it's a little bit too late to abstract the data layer.
Guess... public struct LightData { public Vector3 Position; private byte UnusedSpacer1; public Vector3 AmbientColor; private byte UnusedSpacer2; public Vector3 DiffuseColor; private byte UnusedSpacer3; public Vector3 SpecularColor; private byte UnusedSpacer4; } Here's the problem though. At some point someone is going to use CodeMaid or a similar tool to "sort" all of the properties. Which is going to break everything unless you have explicit layouts specified. I've don't it to myself before when the stupid serializer expected XML attributes to be in the same order as the properties. (Which is a real WTF moment.)
True for me. We want to but it's not worth the rewriting. A simple abstraction could have made this easy.
&gt; Write all logic in a dotnet standard library He literally said that.
I agree with an earlier answer given: don’t abstract away the data access framework. You’ll probably never change it anyway. Not by pulling the plug and plug in something else. What I would suggest instead, is to slice your software vertically, so that ui, logic and data for one separate part of your app is as independent from the rest of your app as possible (as possible = given the size, time, need, money etc) That way, you can create ‘the next’ feature slice with whatever data access layer you find suitable, or you can switch out the data access part of one slice at a time in stead of having to switch everything in one go. But there is a difference between not abstracting away the data layer and letting it bleed through the whole stack... &lt;TODO: fill in common phrases about ‘balance’ and ‘it all depends’ /&gt;
VS for Mac is super buggy and has a terrible debugger.
Switched over in vs 2017 after my R# license expired. Needed a decent test runner and coverage tool. And somehow, someone, at Jetbrains thought that they need to bundle everything together. I really like dotCover and other tools and started to dislike but coderush sort of solved this for me. And it's very fast as well. 
90% of what R# does at 0% of the cost.
Interesting that there can be such stark differences compared to for example that exact spec or higher machine but with drastically fewer projects - this seems to be a problem for everyone apart from a few people. Can you describe what project types they are? I have a suspicion that ASP.NET MVC projects are a root cause of a lot of people's problems - coupled with the fact that things like Razor is so piss poorly implemented in VS anyway, it can only make it worse.
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/expressions#operator-precedence-and-associativity
Honestly I have mixed feelings are CR. Yes it's fast, but the old, slow version of CR had more features. They are still working on converting everything it used to do to Roslyn. 
VS Community. Most instructional manuals assume that you have this or better.
Hi. When I wrote a game engine a while back I also needed to align certain structs on an N-byte boundary, for SSE. Here's how I did it, hopefully it's useful for you: https://github.com/Egodystonic/EscapeLizards/blob/master/Core/Interop/AlignedAllocation.cs And here's my Vector4 too: https://github.com/Egodystonic/EscapeLizards/blob/master/Core/Math/Vector4.cs
I use VsVim extensively with ReSharper.
Congrats. OP specifiably mentioned .NET Core. Core ≠ Standard.
https://www.reddit.com/r/csharp/comments/9pp6qn/lets_talk_resharper/e84rmpx/
&gt; Why? There is still no MI possible. Because disallowing MI prevents conflicting behaviors being inherited from two parent classes. If interfaces methods with the same signature are implemented explicitly, that means the interface is doing more than defining a contract. Calling an explicitly implemented interface requires the call to be made on the interface, not the class. &amp;#x200B; &amp;#x200B;
Both. Consider Code an extensible text editor you'd open instead of notepad, when there's no need to open Studio. You get it opened quick and it offers intellisense. Good stuff.
&gt; I do not follow... Why would explicit interface implantation imply that function of an interface is related to its implementation? Because in order for there to be a need to use Explicit interfaces at all, it must be important for there to be specific implementations for each interface. While its still the class that determines the implementation details, it makes the code less clear and readable... Its not obvious which interface method you are invoking. Edit: To be honest, as I wrote that I find my argument less compelling :S I suppose its still the class thats defining the implementation, not the interface. &amp;#x200B; &amp;#x200B;
Thanks! 
[https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/interfaces/explicit-interface-implementation](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/interfaces/explicit-interface-implementation) &amp;#x200B; The title should probably be "Are Explicit Interface Implementations Code Smell?", but this is what I'm refering to. Lots took it as a question about C#8 and that's my bad.
Thanks for the examples!
I think though that if you need to implement both interfaces, you can do so with one method. I didn't think interfaces were supposed to imply any implementation specifics
I looked for evidence to back me up but didn't really find any... I think though that Explicitly Implented Interface Methods are still public. They just belong to the Interface instance and not the class
What changes does context.Rollback() actually roll back though? Wouldn't it roll back all changes made within the scope of the context object, making this potentially also affect previous changes? The context object is injected via a dependency injection (Unity framework). I'm not exactly sure what this does or what sort of implications this has for the scope of the object. I'm a relatively new developer and also new to this codebase. I can ask this question to other people on my team, it just kind of struck me during the weekend because i wrote this code close to the end of the day on friday. 
We're working in .Net framework still so we're using EF 6, sorry for not specifying
I'm writing a shrinkwrap application that will run on the desktop. MySQL is now as popular as MSSQL server so I want my app to target both of them. How to do this? Well, it is actually pretty simple if you use an a robust DI container like Autofac. Using Entity Framework makes it even easier but you can use good old Repository Pattern if that suites your needs. I have abstracted the pattern into a small utility called [AdaptiveClient](https://github.com/leaderanalytics/adaptiveclient) that is available as a nuget package. You can inject clients for different database platforms as well as different transports: In-process, WCF, REST, WebService, etc. You can do this on the fly and actually fall back across platforms or transports. There is also a [fully functional demo](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon). 
No, you can only return a single selection in postgresql. It's a pain.
I haven't checked documentation, but afaik it should roll back changes since the last save. Think as it as an implicit START TRANSACTION. SaveChanges is commit. Rollback is, well, rollback.
If the context is injected during class construction there's a very strong chance that the scope is restricted to the operations you're performing, so you shouldn't have to worry about any changes happening outside of your code blocks since those should have their own instance of the context. You should obviously confirm this with the senior devs on your project since it's impossible for me to know the validity of this assumption, but I'd be surprised if the data context existed beyond the scope of each single request.
Ef core isnt restricted to .Net core. I would suggest keeping it on your radar. 
This is the correct response. The reason why so many applications are unable to target multiple database platforms is because their business logic is all tied up in the presentation layer. Utilities like [AdaptiveClient](https://github.com/leaderanalytics/adaptiveclient) make the job much easier but it can be done without them. 
Long story really. The take away is that it's not the path to happiness because you can't keep scaling upwards. Our biggest issue was replacing procs that "did" stuff. SQL as RPC is a shitty paradigm but (pun intended) it persists. It's an oldish app and over the years people have tried to reinvent the wheel, trying to solve performance issues entirely unrelated to roads or road/wheel interactions. It's tiresome with hindsight, but so is not winning the lottery :) 99% of the scalability issues we ran into were resolved by scaling outwards and by avoiding the (record of truth) DB altogether. 
\*puts away the satanic candles\* Let's try your idea first.
Repository is abstraction of the data layer, service layer is abstraction of the business logic, it consumes the data layer abstraction. In practice it is often OK to merge the data layer into your service layer if you don't need to support multiple data stores
Two things: * [`GetFiles` literally calls the same implementation of `EnumerateFiles`](https://referencesource.microsoft.com/#mscorlib/system/io/directory.cs,0e5cd32f1daea6e5), then `new List&lt;T&gt;`, then `ToArray()` on that. As such, 1) it is one of those APIs that really shouldn't exist any more since .NET 3.5, and 2) it will invariably be slower, as it has to materialize the entire result. * NTFS actually does get slow enumerating over existing files / creating files within a directory containing many files, especially if you have short file name creation turned on (which was the default until rather recently) and have [more than 300,000 files in that directory](https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc781134(v=ws.10)).
I've seen it happen once but in general it is worth the risk to skip that abstraction. The service layer is much more important as I have seen the web layer replaced multiple times even for a single project and if the service layer is built properly the web layer can be changed without changed to the service layer.
Yep, but PostgreSQL doesn't do T-SQL (nor should it) so you have to rewrite them. Plus the little buggers tend to hide. You can add a stored proc as an entity in an EF model and it can call UDFs or other stored procs :/ 
&gt; I've decided to just use explicit layout. I thought surely in C# there would be a way to automate this with a simple attribute, but sadly not. Maybe it's something to suggest since it's not really an uncommon problem. But there already is... the `[FieldOffset(16)]` you already show being used.
There are situations where explicit implementation of interfaces is required (such as name clash between two interfaces), but it can be used when not needed -- I actually like implementing interfaces explicitly -- this way, you cannot use implementation (class) in place of interface, so you are actually forced to think in terms of contracts (interfaces) in client code.
In the case of `if (!list?.Any() ?? true)`, the compiler is probably going to lift that into a form that will look closer to: `(list != null ? !list.Any() : true)`. Same is true for `(!list?.Any() ?? false)`. In that case if list is null you'll have wind up right into the null coalesce and get a false. for `!(list?.Any() ?? false)`, I'm guessing that comes out to `!(list != null ? list.Any() : false)`
the CTRL + comma? It works very swiftly in a 40+ project solution.
If I’m working in .net core I enjoy working in Code else I use Visual Studio. You’re more feature packed in VS community but I enjoy the light weight nature of Code I also enjoy Code for angular / typescript projects 
Those are class libraries. From my experience with MVC projects - the only problem I encounter on a regular basis - syntax highlight is broken 24/7 :) Also, reshaper often messes up with referenced libraries in .NET Core projects. One more point - it's really sucks with TypeScript (i.e. Angular components).
It's uncommon to swap out the DB and slightly less uncommon to swap out the DB access method (EF, Dapper, etc...)... but having an abstraction also allows you to write tests without requiring access to a real DB to run them.
Just an FYI: That's coming in .NET Core 3.0.
If you're using a mature ORM like EF or NHibernate, those are already the abstraction for the database. You can use most of modern databases with EF or NHibernate. You could technically even switch the database. If you want to abstract from the orm or data access technology then yes, you should do what /u/noicedream suggests. IMO it's not worth the effort. Most of the recommendations of abstracting the ORM tool come from a time when it made sense because there weren't clear chocies. Nowadays IMO it takes extra work and if you need to use some ORM specific low level stuff (ex: EF AutoDetectChanges = false) you'd had to also abstract that too, and sometimes it wouldn't make sense on other ORM tool.
Agree. Scalability is a huge reason to abstract or at least isolate your service/data layer. For example you write a desktop app that is used internally but now you want to expose some or all of the service layer as a web API. If your service layer is properly constructed wrapping it a REST or WCF API is usually pretty simple.
Tbh VS opens quick enough not to be an issue anyway...
Works terrible for me on a roughly 2 million loc project, not including tons of node_modules folders which don't seem to filter out. 
I've projects at work that take up to a minute to open
Guess it depends on what you're doing... true. Most of the stuff I open up is &lt;100k lines and not that many files.
Community is what you want. Paid versions come with neat tools that are useful for a professional work environment, but that's about the only difference. 
Weird. It's always performed well with me, although I'm not aware of the actual LOC of the solutions at my work.
Thanks for the blogpost. I heard [SignalR is having a hard time](https://www.reddit.com/r/csharp/comments/9gqbg9/the_future_of_aspnet_signalr/) - you think it's wise to use it?
Yep, MVC is just terrible. I actively avoid it if I can - to the point I'm less interested in job adverts that mention it... I'm sick of it. Yeah it seems JS/TS can really screw with R# a lot. I first noticed it in the typical MVC app with a generic "Scripts" folder with hundreds of copy pasted files in.
Totally agree. Otherwise you have public everything as opposed to a nice entry point that hides everything else.
SLC Utah USA finance company in need of a junior. We use c#, framework, SQL server, asp dot net, forms, MVC, Xamarin Forms for mobile, wpf, nunit, a little angular. For CI/CD we use AzureDevOps. I'm not HR or anything, just a dev that knows we need to hire someone. Excellent people and work-life balance. Hit me up
&gt; are the files that are 10,000 - 30,000 lines long Yep. Can hardly blame R# for that; yikes that is just a bad idea. We have a legacy application that has a couple classes that are around 7k lines and that felt insane to me.
Yea I mean I don't know how many lines, a lot of files are probably sub 500 lines but it's probably hundreds of files. I'm sure resharper doesn't help
(Part 1 of 2. Character limit) &amp;#x200B; So contrary to what a lot of people have posted, I actually have seen several companies do some of the following: &amp;#x200B; \* Change from MySQL to MS SQL, MS SQL (or parts of) to MongoDB, etc. \* Replace the source of reads from a transactional database to a data warehouse (but obviously not of writes). \* Split reads to a database to requests from other services with new, different reads to local databases (usually as a circuit-breaker in case the other service is down). &amp;#x200B; All in all, these things could all lead to either using a different data reading technology, or otherwise greatly impact the implementation of the data layer. &amp;#x200B; Now, here's what I try to emphasize to my teams. Just because the source of data, or the shape of data, changes, that does not change how the business operates. The way the rest of the business functions (eg, sales department, customer service, management, etc) might not be changing at all. What that translates to in our code is that, just because we're making a monumental change in how we're handling and processing our data does not mean that our business logic layer (which represents the actual business, not our technological brilliance) should change. In fact, the hope is that it does not change at all until there is an actual business need for it to change. &amp;#x200B; If your data access technology is balls-deep in your business layer, including the data models and artifacts like relying on lazy-loading of relationships, any of those data migration or technological shifts can cause significant pain. In fact, this can lead to such migrations being considered too expensive, being scrapped, and possibly hamstringing the company's ability to adapt to new and important technologies (such as reporting, data analytics, business intelligence, and feature growth). &amp;#x200B; To answer your question as to how to make different patterns work together (and which patterns we've used), I'll first cover some of the more basic ones and what they are meant to do. &amp;#x200B; \* \*\*Repository Pattern\*\* \\- A repository should be treated as a "collection" of a \*business entity\*. I emphasize that because it's important to note that if your business entities are separate from your data models, the repository is expected to return business entities. Data models being separate from business entities is usually the case if you have multiple data sources, or the shape of your data models or tables do not match the business entities. This also allows for flexibility in changing your data structures with fewer risks of affecting "uninterested" sections of your business logic. Apart from working as a collection of business entities, a repository can also represent common queries of that collection. For example, if you have an Orders repository, and you commonly get Orders by the customer, your Order repository could have a \`GetByCustomer(customer)\` method. Now, while your repository knows the structure of your business entities and your data models, it should not be used to make specific changes to them. IOW, you shouldn't have something like \`OrdersRepository.AddTaxesToOrders(orders)\`. That would be giving the repository too much responsibility and no longer functioning like a repository. You wouldn't expect to tell an \`ICollection&lt;string&gt;\` to pad every string in it until it was 20 characters long, for example. You could write a loop (or even using method extensions from LINQ) to do so, but it's not something that the collection itself would implement. The collection shouldn't know what business logic applies to the entities it holds. This can be a pretty tricky balance to maintain. Now, because repositories are meant to return business entities, the contract of a repository should be defined in the business logic layer (usually as an interface) but be implemented in the data access layer (where you have either entity framework, dapper, etc). This means that the business layer is a dependency of the data access layer, and not the other way around (thus achieving inversion of control). \* \*\*Unit of Work Pattern\*\* \\- You'll often find that you might want to make changes to multiple data sources as a single flow or event of the business. What's more, if one should fail, you would expect any previous successful changes to revert or otherwise adjust appropriately. This is where the Unit of Work pattern comes in. The unit of work pattern is meant to abstract the fact that changes can happen in multiple systems as part of a single unit of work, but that we must allow for some of them to fail. Different data sources have different ways of handling this, but apart from trying to abstract that, you also don't necessarily want to keep track of every dependency you used in a unit of work and revert them manually if something fails. So the actual unit of work implementation is meant to handle all of that, giving you one place from which you can say "everything went well, commit" or "something somewhere failed, rollback". As such, most unit of work pattern objects are usually the source from which you obtain repository dependencies (or else the repository should expect the UoW as a dependency). \* \*\*Builder Pattern\*\* \\- So, I've actually started using the builder pattern to help give the business layer more control over the granularity of the data it receives from its repositories which giving the data access layer extra utility in using things like LINQ and Entity Framework's late binding. So a builder pattern essentially having a builder object that has methods with "knowledge" of the entity it is building. A modern example of a builder pattern is used by [ASP.NET](https://ASP.NET) Core in the Startup class when "building" the \`IServiceCollection\`. Using extension methods, you have things like \`.AddMvc()\` or \`.AddEntityFramework()\`. So, the way I used the builder pattern was to have a repository return a \`&lt;SpecificEnttity&gt;QueryBuilder\` instead of just a collection of entities, and the builder could then be used to better-filter the data before it ever leaves the database. This allowed me to give \`IQueryable\`-like control to the business layer without letting the data model leak into the business layer. &amp;#x200B; Let me give you an example of what I mean. First, however, let me emphasize that if you feel pretty confident that you can safely use your business entities as the data models, or that the data models are fairly concrete and not at all likely to change, then you may as well return an \`IQueryable\`. That is still a healthy abstraction that can be used by many ORMs. That being said, if you do feel the need to add a solid separation between your data models and your business layer...
(Part 2 of 2) First, let's define a very simple Order repository. ```csharp interface IOrderRepository : IRepository&lt;Order&gt; { IOrderQueryBuilder GetByCustomer(Customer customer); } ``` And then a builder ```csharp interface IQueryBuilder&lt;T&gt; { IEnumerable&lt;T&gt; Build(); } interface IOrderQueryBuilder : IQueryBuilder&lt;Order&gt; { IOrderQueryBuilder PlacedAfter(DateTime date); IOrderQueryBuilder PlacedBefore(DateTime date); IOrderQueryBuilder WithTotalEqualToOrGT(decimal amount); } ``` And then we have the implementation of the builder in the data layer using EF. ```csharp class EfOrderQueryBuilder : IOrderQueryBuilder { private readonly IQueryable&lt;Data.Order&gt; _orderQuery; public EfOrderQueryBuilder(IQueryable&lt;Data.Order&gt; orderQuery) { _orderQuery = orderQuery; } public IOrderQueryBuilder PlacedAfter(DateTime date) { _orderQuery = _orderQuery.Where(o =&gt; o.OrderDate &lt; date); return this; } public IOrderQueryBuilder PlacedBefore(DateTime date) { _orderQuery = _orderQuery.Where(o =&gt; o.OrderDate &gt; date); return this; } public IOrderQueryBuilder WithTotalEqualToOrGT(decimal amount) { _orderQuery = _orderQuery.Where(o =&gt; o.Total =&gt; amount); return this; } public IEnumerable&lt;Order&gt; Build() { var dataOrders = _orderQuery.ToList(); var businessOrders = Mapper.Map&lt;Order&gt;(dataOrders); // I'm assuming some AutoMapper here. This can obviously be replaced by custom logic, or ignored if Data.Order inherits from Order. return businessOrders; } } ``` And briefly the order repository ```csharp class EfOrderRepository : IOrderRepository { private readonly DbSet&lt;Data.Order&gt; _orderTable; public EfOrderRepository(DbSet&lt;Data.Order&gt; orderTable) // can also just take in a DbContext or whatever { _orderTable = orderTable; } public IOrderQueryBuilder GetByCustomer(Customer customer) { return new EfOrderQueryBuilder(_orderTable.Where(o =&gt; o.CustomerId == customer.Id)); } } ``` Sorry for such a massive post, there's a lot I just thought might be useful here and so just went on. But hopefully this is useful! I would like to end by saying that software is very opinioated. It's not an exact science and the implementation should really meet the needs of the problem it's trying to solve. Your situation may not fit anything that I said, and it may only fit part of what I said. At the end of the day, though, I would like to emphasize two things. 1. Software architecture &amp; design, for the sake of architecture / design, is a waste of time. Don't over-complicate a problem by adding longevity or scalability to something that will never need it. 2. Know the problems that you are trying to solve. If what you're trying to solve is a key component to a business and it's going to grow and adapt with the business, make sure you've added the patterns you need to make sure that future development does not stall, smother or choke the business. When learning microservices, one of the things you hear a lot is "minimal but complete", and that is a very difficult balancing act. Under-building software and over-building software are both painful and should be avoided, but knowing where that line is takes time and understanding. Not just of software and design patterns, but actually moreso of the business. To that end, I do recommend giving Domain-Driven Design a read. More than anything else, I think its focus on business and need-oriented development will help make for better decisions.
I don't have quite that much horsepower ;) I have a T470p with i7-7700HQ, 16GB, and an 860EVO. I usually have multiple copies of VS open, multiple SSMS, VS Code, Outlook, enough Chrome tabs to choke a donkey. Chrome is the real pisser...
Reasons to stay at your internship? I'd be having trouble too... those specs are borderline criminal these days.
10s of millions of LOC, 300+ projects in the biggest solution. Dual xeon, 32GB ram. ReSharper just plain sucks. Even the smaller solutions cause problems.
Wow that was quite a read but helpful nonetheless! Having described Repository Pattern the next question is how do you architect an app such that the repository can be substituted at will? Perhaps even on the fly as the app is running? I will argue that this is not over-engineering by any stretch. As several others have pointed out, once a company commits to a database platform it is pretty near impossible to get them to change and they tend to purchase products that fit in with their enterprise architecture and employee skill set. So if you are a software development company and you are selling/integrating products to these companies you want your product to target all the databases your potential clients might use. You also want your services to be available via many different transports. For example for those accessing your services over a LAN you want an in-process API. You also want APIs for those using REST, WCF, etc. So the question of how to abstract the repo (and for all practical purposes, the service layer also) is very important.
Does NCrunch work with XUnit?
Ctrl+, followed by "f myfilename." The "f" restricts to file names, and it's pretty quick.
I figure at least part of that reason to not choose Oracle is the future need to sue them. Or be sued by them. Especially if you run VMWare pretty much anywhere in your organization. http://houseofbrick.com/mars-vs-oracle/ The "Mars" mentioned is the candy maker. 
Literally everyone supporting code more than a year old.
Trust me, I've gone through all the lists of performance changes already. It is what it is.
&gt; Vector3s are 3 floats. So they are only 12 bytes when I want 16...I did some reading and found that you can specify a packing size like so...My understanding is that it should pad each field out to 16 bytes. But when Marshalling it or viewing the data written to the buffer it's not padded at all and is just 48 bytes of data. It's an easy mistake to make, but Pack=16 is behaving exactly as specified. [The documentation says](https://docs.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.structlayoutattribute.pack?redirectedfrom=MSDN&amp;view=netframework-4.7.2): &gt; The Pack field controls the alignment of a type's fields in memory. It affects both LayoutKind.Sequential and LayoutKind.Explicit. By default, the value is 0, indicating the default packing size for the current platform. The value of Pack must be 0, 1, 2, 4, 8, 16, 32, 64, or 128: &gt; The fields of a type instance are aligned by using the following rules: &gt; The alignment of the type is the size of its largest element (1, 2, 4, 8, etc., bytes) or the specified packing size, whichever is smaller. &gt; .... That last part is important. The alignment for Vector3's (12bytes) with Pack=16 is 12 bytes, the size of the largest element which is smaller than the specified Pack size.
Thanks for the rec.
There are too many variables in people's use cases. I work on a lot of very large code based, so it doesn't work for me.
A large part of it is regional. In my area, there are a ton of .NET and Java jobs, but python is virtually nonexistent.
Actually, GUID’s can be used for authoritative licensing systems and is just as secure and easy to implement if you have your own database and payment processor.
Your observations are in line with the [StackOverflow data](https://qph.fs.quoracdn.net/main-qimg-c83c084bbb7dcdb0af9cb0d62380e516). Java's edge over C# probably largely comes from Android development. Python has exploded in popularity, probably because it's being leveraged in areas like data science and artificial intelligence. C# is still in a good place overall, but it's dropped off slightly.
Whoa...thank you for showing me that! Definitely gave me a better understanding of the programming world. 
Java has been around a long time, and the JVM has been available on many platforms for a long time, and has had great performance for a long time. &amp;#x200B; C# has only recently been available in a first class fashion on linux and mac, with .NET core, and performance has only recently (over the last few years) gotten on par (and perhaps surpassed) the JVM. &amp;#x200B; Python's popularity is an accident of history, I think. I don't get it =) &amp;#x200B;
python is my language of choice for scripts. it's everywhere. it's sort of a perpetual motion machine. i use it because it is everywhere, it is everywhere because it is popular. but would never write my servers in anything not statically typed. java or c# for me.
It heavily depends on the field you're into. I program large-scale enterprise systems (the so called ERPs), and in this context we mostly use C#, Visual Basic, Java and Delphi. I'm also a computer scientist, and in scientific programming we use a lot of Python, R and matlab. You should see what's used in the field you like and go for it. C# --and the .net ecosystem as a whole-- is an excellent choice of you plan to work with enterprise systems.
Yeah there seems to be a ton of .Net jobs in Houston. While I believe Austin is a great place to be a Python dev.
So like modules that have their own layers(if they need it) instead of one central component separated by ui, business, and data layer?
&gt; if some other method calls "SaveChanges()" on the _context because the context is an object that we inject I recommend newing up and disposing your db context in each "unit of work" i.e. method call. This is the simplest example: public bool Save(..) { using(Context db = new DbContext()) { // your work, after which db is disposed } } However there may be times when you need to share a context between calls i.e. you call SaveBlog and SavePosts as one call. This is a bit more complex. In fewest words instruct your DI container to inject a single instance of DbContext "per lifetimescope (Autofac nomenclature)". [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient) provides a utility for this. See also [functional demo](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon). 
perl used to have that space. I wonder when it lost the scripting space.
&gt;It's easy to learn, easy to write, has lots of nice modules available, runs everywhere and is easily integrated with C This is true of many things. &gt;I often write web scrappers for some personal and academic projects and Python is the best tool for this. Try F# with a type provider some time! 
For some of us it never lost that space. :)
Because people that wrote Perl had the saying "good Perl is indistinguishable from line noise."
Come to state government: You're either writing COBOL on legacy mainframes or .NET
Oh for sure. 1 minute isn't that bad when I leave it open all week. I just wouldn't call it fast.
More accurate data would be the developer survey in my opinion. The graph you linked is based on question views which doesn't necessarily mean the language is more popular. It could just mean it's harder to learn or documentation is inadequate so people seek answers on Stack Overflow. According to the 2018 developer survey, C# ranks at 34.4% compared with 38.8% for python for languages used by developers. [https://insights.stackoverflow.com/survey/2018/#most-popular-technologies](https://insights.stackoverflow.com/survey/2018/#most-popular-technologies) &amp;#x200B; I think personally think C# will grow market share over the next decade and probably pass java within the next 15 years now that is it open source and has been rewritten from the ground up.
Oh yeah for sure a minute isn't bad, especially when I usually leave it open all week, but it feels like an eternity when you need to open it
Their website says it does. We use nUnit.
&gt; I could use powershell but nah how dare
Same here. Everywhere I turn online it's Python this or (backend) JavaScript that but I'd be unemployed if I tried going that route. It's C#, Java, PHP or starve in my area.
It's less about the language itself in isolation, than about who uses what and why. There's a large employer here that's seen as "a Java shop". If you want to work there, you're probably going to be working on things that are already written in Java. They're old and enterprisey and their big systems probably predate when all the new cool languages got popular. There's a smaller employer here (that a lot of people I know work for) that's a Ruby shop. My own employer uses a mix of something you've probably never heard of (that system dates back to the 80s) and C# (some of our other more recent systems). There's another mid-size employer here that seems to use a bit of everything (and also employs several people I know). They're an outlier, but have some seriously cool shit. &amp;#x200B; I occasionally play with Perl6 or other weird things (Haskell, Erlang, Ocaml, etc) in my spare time. No matter how cool they are, I'd never suggest them for at-work use. This has nothing to do with the languages themselves, and everything to do with the fact that nobody else here knows them.
I think it depends on the type of companies that exist in the area. We have a lot of .NET and Java but we also have a lot of financial institutions too. 
As far as I know C# doesn't support aligning individual variables in a struct. But even if it did it's best not to use LayoutKind.Sequential for complex structs. Sequential can do things like making your first variable start at offset 8(!) rather than 0 and other fun stuff that takes hours to debug.
Lua is a small language that has traits of python, ruby and JavaScript. While it's easy to learn, it has some neat concepts built in (arrays starting with 1 is not such one) like coroutines (not comparable with c# coroutines - those ones are really cheap fakes of real coroutines). The thing I've seen in lua but in no other language ever is the debug API though and I think it's brilliant: the debug API provides functions that allow retrieving values from the stack next to the obvious stack trace strings. Next to that there's a function that allows defining a lambda function that gets called on debug actions such as functions getting called, returning or stepping through code lines or based on how many instruction cycles have been spent. The implications of having such an API are many. For instance, you can program an automated debugger: your test version runs with debugging enabled all the time, as if your application was always connected to a debugger. When something wrong happens, you could either offer a user interface asking if you want to hook to a debugger or you could take a stack trace snapshot and send it to a machine. You could also build a watchdog function that gets called every few millions of instruction cycles being spent and assume if it gets called without certain events happened that your code is stuck in an infinite loop. From there on you can trigger the debugging part I mentioned before. There's more to it that can be interesting to learn if you manage to not hate its verbose syntax and arrays starting at one - but I think it can be worthwhile to learn something that feels very different to a point where you don't like it for the mere reason of difference. It's a very small language (footprint in runtime is a few megabytes, next to only few hundred kilobytes of code itself) and it used to be more popular in game development for that reason than it is by now.
Oh man, this is something really easy to do in C/C++. Just give it the packed/ align attributes. However, not sure how it works in c#
This is how I feel too. Python is cool and "fun" but I honestly hate it. It just feels "loose" to me. I like my strict and straightforward rules. To be fair I'm just a junior dev and don't have tons of experience with it.
Appreciate the comment. So if I'm just starting to learn (about to start C# after finishing a school class with programming fundementals), I should go ahead and opt to learn .NET Core instead? I have pluralsight access with my school as well.
If it's that bad you really need to break your solutions up, consider publishing packages to a private nuget, etc.
It's great for prototyping. When I need to play around with some ideas I always use Python, even if I plan to implement the final thing in another language.
Also, Lua has such a beautiful name. It means "Moon" in Portuguese.
It's great for writing scripts, but terrible for writing software. Other languages caught up to its power, without its natural obfuscation. Python, in particular, provided the power of perl with the polar opposite philosophy when it came to readability.
I couldn't find any. You could write a library wrapper that can be used in c#. Also, here is a MSN link about using c++ with c# with CLR (using c++ and c# code in the same project. https://social.msdn.microsoft.com/Forums/en-US/f18d1d1c-0d14-4ff2-8244-337f58818ef9/how-to-use-c-code-in-c?forum=vssmartdevicesvbcs
Poor decisions by the Perl maintenance group. They toom forever to make a decision on how to go forward with the langauge and then broke backwards compatibility once Python had already started eating it's market share
c# is very popular is my area. If really depends on the region and the discipline. I find smaller dev houses lean on open source products and larger ones lean on Microsoft products. Big companies like support agreements and someone to call. Open source doesn't generally give you that, instead it's forum posts etc. That doesn't make one any better then the other, but in my region (upstate new york) C# is the skillset to have.
I think you under estimate the penetration of windows and gravitation towards a microsoft native dev environment when windows is the primary operating system. C# has been around since around 2000. That's 18 years. Yes java has been around "longer" but it was not as mature as c# was out of the gate. There was a lot of confusion about what java really was in the 90s. C# came out very functional and with purpose and really took off in 2005. Microsoft dev tools in general got adopted by many large corporations because they were very easy to implement. Visual Basic was dead simple. ASP was crazy easy to get a web site going, ASP.NET extended that to support more functionality. While none of these toolsets are amazing, they did enable people with low skills to get into the game and just like Windows server, that ease helped dominate a large part of the market for years. 
because C# generally implies a .NET stack and the Valley isn't a fan of Microsoft's traditionally closed source software. 
**WARNING** when I go to this site, my Malwarebytes is alerting that it is blocked due to malware. I am not sure if there is or not but Malwarebytes has always been extremely good in its detection for me. For those viewing take it as you wish.
Lots of .net in Austin, not sure what you're talking about.
I would like to speak in favour of the Python culture. Python culture discourages complexity and encourages understanding. I think culture is the most important factor in project success and I appreciate the Python culture. 
I saw that, I'm honestly not sure how I feel about it. If they're already starting to pull back on the platform independence.
Anything more than a page or two of code really needs static typing and a good IDE with intellisense (or equiv).
Definitely regional. I have actually never seen Python mentioned in any job ads here (Norway). C# / .NET and Java all the time, though.
Visual studio supports LINQ to foreach directly https://docs.microsoft.com/en-us/visualstudio/ide/reference/convert-linq-to-foreach?view=vs-2017 Roslynator does support LINQ call optimization and equals generation is supported by Visual Studio https://docs.microsoft.com/en-us/visualstudio/ide/reference/generate-equals-gethashcode-methods?view=vs-2017 For dispose there is I think there is only this analyzer https://docs.microsoft.com/en-us/visualstudio/code-quality/ca1063-implement-idisposable-correctly?view=vs-2017 and these guidelines https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/dispose-pattern and https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/implementing-dispose Here is list of all analyzers, refactorings and code fixes Roslynator supports https://github.com/JosefPihrt/Roslynator
I agree it is a bit odd. And seems like a pain.
That would be awesome. It's XAML based right?
God can you imagine? We do a lot of containerisation. If it won't go in a container it gets a big red mark against it. Being sued for it would not go down well!
It is true that learning one language makes it easier to pick up many others. I don't know about now, but in the past the comp sci classes you took in school in no way prepared you for the private business world- even something as simple as manuevering an IDE. They were still teaching cobol, perl, open source c++ when the world was moving into the world wide web. At that time most general jobs outside of academia were looking for VB, VB script, JavaScript, and Java. The biggest problem with learning new languages is not the syntax, it's the quirks, the development environment, the libraries, and WTF went wrong - things you gain when working with a language for a long time. I am a c# guy, but work offers training so I delved into python - granted, I didn't go deep, but it seemed to me to be a kitchen sink language, with folks throwing more and more disparate parts in to meet specific needs. Buy I fully admit that learning vs actually utilizing in my every day work may have skewed my impressions. 
&gt; Python's popularity is an accident of history, I think. I don't get it =) Python is the de facto language of the whole Data Science community. Python combined with Jupyter notebooks gives you everything you need for that. 
Uhm I guess thats regional aswell. Over here every single highschool and university is like 95%+ JAVA.
"I get paid to write lua" Said no one ever 
Very interesting and well written. Cool to read about all these new things in an actual use case! 
Fair enough, it's a funky little language
The success of Python is partly because it's used as a learning language, and it's data science specialization. It can be used in other environments but if you wonder why it's SO popular, it's because nowadays pretty much everyone learn to program in Python.
I found something in stackoverflow, and i did, i just wanted to have the tables(accounts where is the orders of the costumer in a db) because i just was with the buttons but i hadn't had the table(accounts) to vinculate
Opposite here in Norway. Tons of demand for C# since you can use it for basicly anything. Its an amazing language to know cause you can jump into whatever language next and be comfortable quickly.
I like to create.
I can't spell sudo.
Ah fair enough
Nowhere is a great place to be a Python dev. People will pay you to be on one Austin though, it seems.
I'm a step further away from the users, and nothing is as urgent. Sometimes I get weeks to fix bugs.
Try adding UpdateSourceTrigger=PropertyChanged the the binding `SelectedItem="{x:Bind ioVM.SelectedInteractableObject, Mode=TwoWay, UpdateSourceTrigger=PropertyChanged}"` &amp;#x200B;
I'm not sure I do, but I don't know a thing about sysadmining =) &amp;#x200B;
&gt; I could use powershell but nah Coming from a POSIX background, I thought I would absolutely hate Powershell. After creating a few modules and scripts for Windows, it is growing on me. It is certainly much better than writing scripts in Windows batch. 
Keep in mind that since Stack Overflow was made by people who use and like C#, C# was initially overrepresented there. So its share of questions going does doesn't necessarily mean C# is getting less popular.
The point I was trying to make was to use a new context for each operation. That way you don't have to worry about MethodB interfering with MethodA. Injecting DbContext is the correct way. 
I'm not on-call at most programming jobs. I dont have a dozen managers and the owner standing over my shoulder when something goes wrong. The pay is better. I don't have to go desk to desk listening to people complain about a topic they know little about. Programming is generally a more creative job. I don't normally need to do things within a maintenance window off hours. I don't need to argue with people over permissions. ... etc etc...
How is that relevant here?
No changes sadly :( &amp;#x200B; I can set ioVM.SelectedInteractableObject in the VM in code, it will perfectly update in the View, but I can't change it in the View by pressing the button. &amp;#x200B; It seems pressing on the Button doesn't notify GridView.SelectedItem. &amp;#x200B; It's very strange...
&gt; desk to desk listening to people complain about a topic they know little about. ... and then be told that you're wrong when you come with a solution.
I always wondered why "Lua". Then someone told me once: "Without the Earth, the Moon would be just another rock in space." Pretty insightful considering that Lua is often embedded into other applications.
I find it way more fun. Sysadmin just seems tedious and unenjoyable. Programming on the other hand I can easily lose track of time for hours and hours just having fun problem solving and creating something I can be proud of. 
I see tons of Javascript / Typescript + another major la guage ( Java, .NET, or python) demand recently for various reasons. Corporations are using various client -side frameworks now. Some are even using Node on the server side.
It's an entirely different job?
Everyday the lines between sysadmin and programming gets blurred . Especially as the devops culture promotes automation. In my area it’s rare to find a pure Sysadmin, these days systems architects and developers are writing all kinds of neat script and applications to automate all aspects of the sys admin role . 
it really depend a lot of what are you doing, enterprise use .NET and Java more than python in some areas, because of the services Microsoft offer, like Azure ... , I'm a C# user to and I guess that is not enough to learn one programming language .
I thought because of the "why do people look over c#?"?
Altogether!
Pseudo /s
SysAdmin is a babysitting job where you are on call all the time. It is an important job, it needs to be done, and done well...and it encapsulates a lot of things I hate. 1. Repetitive tasks (checking servers, patches, etc) that can’t be automated. 2. Status reports 3. Constant paranoia (with public sites, are we being hacked) 4. Being over something but not seen as competent to make changes (assuming your company has custom software it is maintaining.
We're just going back to the way it was. Sortof. First their was the Mathematician. The Mathematecian had their time "wasted" programming computers, so they hired Programmers. I believe at that time it was mostly women. The Mathematecian was still having their time "wasted" figuring out alorithms, so they took someone with a little advanced math and made them a Computer Scientist. The Computer Scientist was general enough to be able to assemble the computer, get it up and running, programming it, and getting output from it and interfacing with users. At some point the CS was "wasting" their time on interacting with users, so they hired someone to hand the printouts to people. Eventually, the CS person was "wasting" their time with mundane tasks like taking backups, fixing and configuring hardware, and putting things together, so they hired a "System Administrator". Management also determined that CS couldn't be trusted, so the SA acted as a gatekeeper. When computer networking started, the CS and SA worked together to get things working, because it was the CS people that came up with the protocols (since they are algorithms). At some point, the CS was "wasting" time with this network shit, so they gave it to the SA to deal with. The SA didn't want it and someone else figured Plug-and-Play and DHCP would be the solution so now there wasn't a need for the SA to do it, it was all hardware. The SA and CS stayed in their lanes for a while, the CS capable of doing al of the work of the SA, but the SA had to act as the gatekeeper to the CS. The CS got a little busy in this 'waterfall' thing and needed someone to check their programs so they created the "Quality Assurance" position. After a decade or so, someone realized you need security on a network and no one was watching that, so they created the "Network Engineer" who will now be the gatekeeper to SA, CS, and QA. If they want to do anything on the network, they have to go through the NE. Eventually all this security shit got complicated and someone created the "Information Security Specialist" who was created to oversee the SA, CS, QA and NE. The whole time the CS person has the capability of doing everyone else's job, but we want the CS person to now focus on software. The CS got better and better, built more tools and frameworks. Someone notice that CS people are "wasting" their time assembling blocks together, and making new pointless languages again and again, so they created the "DevOps" position because they didn't see the value in QA and since the CS person can do everyone else's job and they're "wasting" their time creating languages. Or something like that. DevOps is just a way to collapse positions back together because we're "wasting" money being efficient already.
That's usually how I explain my job to people. People usually are confused at what a "Software Engineer" and so say "Oh, so like tech support." And I say "No, I'm the person who *creates* the tech to support." Creating is way more fun and intimate to the end user.
I fixed the issue... if you are interested: &amp;#x200B; In the View I added this code, to make sure button gets focused, also made sure that ViewModel's SelectedInteractableObject are filled with the selected data.. private void btnSelectInteractableObject_Click(object sender, RoutedEventArgs e) { Button btnSender = sender as Button; btnSender.Focus(FocusState.Pointer); //made the button get focus. ioVM.SelectedInteractableObject = btnSender.DataContext as Model.InteractableObject; //Seems like SelectedItem is too "shy" to notify the ViewModel, so I did it this way... } &amp;#x200B; But this was not enough... &amp;#x200B; I also changed my ViewModel properties: this.OnPropertyChanged("SelectedInteractableObjects"); PropertyChanged needs to get name of public property, and not the private one. &amp;#x200B; I prefered SelectedItem just share data by it self, but I guess some helping code behind the View can work too...
Fair enough but I don't think sysadmins deal with hardware much either.
:)
I fixed the issue if you are interested... it's in the comments.
OPs profile is filled with stupid questions asked exactly on different subreddits. Can you report a user? 
I never call myself an engineer unless I'm licensed to be one.
tfw you were promised to work with hardware but you end up writing Dockerfiles and Ansible playbooks/roles/modules which includes programming in Python... Enough reasons to get an identity crisis I would say
&gt; that can’t be automated ew 
Because I need to be naked to be a good sysadmin.
Also it pays better.
I started off my career in network engineering and sys admin, programming just for fun on my own time... ...then it dawned on me... I've NEVER set up a directory service or a distributed file system or an email server or a dns service for fun. I write code for fun all the time. I hack projects for fun all the time. I learn new languages for fun all the time. I changed careers about 7 years ago. Never looked back.
¯\_(ツ)_/¯ I get what you mean, but it's the title I have so if I am talking to someone, I use the title I was given. 
No on call rotation.
Are there any jurisdictions that license software engineers?
&gt; ¯\\_(ツ)_/¯ 
If you have an engineering degree from an accredited engineering school where you learned a lot about how to build software, then how does it make you look silly? I get that there’s a wide range of experience and education that leads to people becoming developers, but some of us actually do have the background to call ourselves engineers. Doesn’t apply to everyone, but there are plenty of developers than earned it. 
I've had years of SQL Server (and some other platforms) experience in tuning, development, maintenance, troubleshooting, etc. Our current sysadmin knows almost none of this stuff, so I'm in a position to deal with this stuff regularly while also dealing with the current sysadmin's insecurities around me doing it. I've mentioned on so many occasions that I have zero interest in his job, but I constantly have to battle for permissions and access to things that are relevant to optimizing or diagnosing database issues. I'm also regularly managing services, needing to administer web hosts, and various permissions. It all really depends on what type of development you're doing, and how much the other personnel is capable of doing for you (and how fast... my guy is a detriment and a bottleneck generally).
Should stay my full name when I got to the motary?
wat is computer
Electrical engineer here. I use the title software engineer and refuse to be called developer.
Yeah, but then one of the larger problems facing Computer Science right now is a lack of understanding of human problems. We keep spending resources on machine-learning algorithms that end up having racial/sexist biases. We build social networks and are shocked they are used by state actors for everything from disrupting elections to organizing genocides. Second-year social science students are like, "Yeah, what did you expect? This has happened before with every technology and it's what we study." Maybe it's fair to change the way we look at them.
I don't see that as a particularly difficult problem to grasp. I feel like anyone could understand that social networks can be leveraged to manipulate people, without the person learning expending too much effort. Compare that with understanding Special Relativity, a first-year Physics course, which is very difficult.
How is babby formed?
Then you're development. Engineering teams consist of more than developers.
bitch lasagna
If your work resembles engineering as in programming engineering or low level things, that's feasible. If you are building business applications, you are not an engineer. Mostly it's credentialed professionals who object to the terminology. I just think the titles are silly if you aren't doing engineering work.
I suppose it all depends on the person. Speaking from experience, I changed from infrastructure support/implementation of 12 years to developer for one reason...it's rare to feel a sense of accomplishment at the end of a working day. It took a lot of hard work to come in on a salary which met our financial needs but it was worth it. I actually owe so much to you guys for getting me here (see my posts) so thanks again!! 
Many folks who develop business applications have the credentials and have built low level software to get here. 
Oh woops. 
Some of us do both. :)
It's also about the perception by others. I deal with clients sometimes who get shitty about it. I'm not in any way diminishing your skills or capabilities. It's more about front facing things.
I do both
Why do people prefer Mountain Dew over Mellow Yellow?
I can't easily examine the code but I can tell you two things... 1) If the class you're trying to access is in a different assembly, you need to add a reference to that assembly. 2) If the class you're trying to access is in a different namespace, you need to either fully qualify the class name, or add a using for that namespace. #2 usually also implies #1. Good luck!
I have experience from both sides of the fence and if your sysadmin doesn't appear to be a bottleneck he's either not doing his job or he's the god of sysadmins and you should build him a shrine. Imagine someone having full access to your code and can edit it without change tracking. That's pretty much what it's like giving someone administrator privileges in your domain. One thing that I found different between being a developer and sysadmin is the thanks you get. It's not like I'm drowning in complements being a developer, but it does happen. Sysadmin on the other hand is a thankless job. If you do everything right no one will know you exist, if something goes wrong... you get the drift.
The default accessibility of any class member is private.
Specifically, the fields x, y, and d in Prisera are private because you have not specified an access modifier for them. To make this code work, you can declare them as: `public int x;` `public int y;` `public int d;` Then code in Mapa.Krok() and Mapa.vypismapu() can access these fields. (PS I'm thrilled that my two years of Russian enabled me to understand a lot of this!)
Python is easy to get to grips with but difficult for advanced software features. E.g. I feel that threading is non-sensical when compared with C#'s simple and powerful threading features. It has good scientific support for some simulations and graphs however; though those simulations don't run very well with Python.
I agree with most of that. The difference here is that the owner actually asked that I handle SQL maintenance and tuning. I used to have a Network Administrator role before jumping the fence. To do this requires local administrator rights (or explicit rights to certain folders, ability to install or upgrade, and run perfmon tasks), as well as Sysadmin role in SQL. Additionally, I manage several hosts and VMs, and I'm always needing to explain that I'm experienced, and that I work there as a trusted employee. It's an understaffed department of 2 supporting around 200 users, and lots of gear and applications. One would think that additional help would be welcome. 
I want to be a developer for this reason. I love creating so much. Still stuck being QA though :/ Writing automation is the only creating I can do.
I don't recommend anyone confuse themselves with preview technologies without good reason, personally.
Because Microsoft and Windows. Also note that language is not everything. There is the ecosystem of libraries and frameworks.
Its healthy to be informed on new technology coming out in the near(ish) future. I should have perhaps added something to that affect. 
Well why does someone prefer carpenter over barista?
Start applying, it's the maybe the only way you'll get out of that. People who write automated tests are badly needed because no one wants to it.
Use the FindWindow api call. Below, replace "AppTitle" with the formname you are trying to check for. `using System.Runtime.InteropServices;` `[DllImportAttribute("User32.dll")]` `private static extern int FindWindow(String ClassName, String WindowName);` `int hWnd = FindWindow(null, "AppTitle");` `if (hWnd &gt; 0)` `return true;` 
It varies widely by engineering field (and state law), but most of the estimates I've seen, only 10-20% of engineering grads get their PE. For Civil Engineers the rate is much higher, but most engineering jobs don't have a public safety element to them.
I%20know%20test%20automation%20isn%27t%20everyone%27s%20cup%20of%20tea%2C%20but%20it%27s%20an%20extremely%20valuable%20skill%20if%20you%20do%20it%20well.%20To%20be%20fair%2C%20I%20didn%27t%20enjoy%20UI%20automation%20much%2C%20but%20testing%20APIs%2C%20backend%20services%2C%20and%20serverless%20functions%20have%20required%20a%20lot%20of%20problem%20solving%20and%20development.%20In%20my%20current%20dev%20role%20I%20still%20do%20a%20lot%20of%20automation%20which%20has%20earned%20a%20lot%20of%20good%20will%20with%20my%20current%20team.%20Just%20keep%20learning%20and%20make%20sure%20your%20leaders%20know%20you%20really%20want%20to%20end%20up%20doing%20more%20feature%20development.
&gt; I've NEVER set up a directory service or a distributed file system or an email server or a dns service for fun. As a current sysadmin who's studying web design for a career change, I can completely agree with this. Ugh.
Sure, come save me and 200 other engineers years of effort of migrating 18 years of code.
Yeah I'm trying to move up to being a developer with my current company. I actually interviewed already internally, but they felt I wasn't quite ready yet. I had a good code solution that fulfilled all the interview code challenge requirements. Back-end written in ASP.NET, front-end written in React. Everything compiled, ran, and (again) met all written requirements, but they felt I was lacking in OOP skills since I didn't show good inversion of control in some areas, and also my SQL knowledge is pretty barebones. (All our developers are fullstack and "senior level", at least on paper anyway). I'm going to try again in a couple months. Hopefully then it'll go better. Becoming a dev has been a dream of mine for a long time.
Sounds like you're on the right track. Keep it up!
Thank you :)
Man, y'all got a pretty dismal view of systems administration. Maybe it's because this is c# and there's a lean more towards a windows ecosystem. I worked as a unix systems admin for years, and the things that made it really enjoyable was learning about operating systems, and at least for a long time, automating myself out of work. I had a number of jobs, where I could go three or four months at a time coming in, checking my email, keep an eye on the monitoring system, and... that was it. It gave me a ton of free time to do other stuff. After a while that became really boring, but at the time it was a pretty big draw. 
Oh for sure, we've been slowly pushing into an internal NuGet but it takes time that's better spent elsewhere right now
Why would you think that? It's basically made by people with a unix background.
The challenge of detecting if a Visual is being clipped is not a trivial task. The stack overflow answer is one approach to detecting if an element is clipped relative to some ancestor. However, clipping may not be caused by direct parents. The challenge is that you have to detect which one of an element's ancestors/containers is causing the clipping. For example, if you have a Grid with too many items, the Grid will still size itself to the minimum possible to accommodate all children; if the Grid then becomes too tall or too wide, the Grid itself will clip inside it's parent, or perhaps further above the tree. Additionally, if you give a Grid column a specific size that is too small for its contents, then the element itself will be clipped even though ActualWidth of the element will show the size of column. For example, if a button has a fixed width of 200, but the column has a fixed width of 100, ActualWidth of the button will be 100, and the code in the stack overflow answer will not detect any clipping, even though the button is clearly clipped. Detecting overlapping elements is an entirely different beast altogether.
Hey some sysadmins get to create processes too. Like on the DevOps side we get to create the release management process and the environments you get to use!
So what do you do now? Still a sysadmin?
It depends on the day. On the days when I’m given a PBI on an already in production SPWA that has a maze of dependencies and I can’t get it to build, I wish I was a syseng or sysadmin again. But on days when I’ve come up with a really simple, elegant solution to a complex problem with my cases, and a few of them edge, I enjoy being a software eng. 
If it’s an availability concern, which seems strange, you might want to write the value to a config file and not access the DB directly. If it’s a perf concern use the application cache.
Because money.
It pays. Its a job to me xD nothing else
Well, it was mostly a misunderstanding concepts and conventions. For example, text processing vs structured content. Once I started to understand things, it got easier.
And worse management. I just signed on to fix something that was created with the same lack of requirements and quickie sales job I'd seen in agencies twenty years ago. Not much has changed. Except they're writing agile stories or whatever without regard to the fact that they have no idea what the underlying data looks like.
Leave and come back in a year. Your QA experience will serve you well.
here is the basic cache pattern: public async Task&lt;DataProvider&gt; GetDataProvider(int dataProviderID) { // look in the cache DataProvider result = Cache.DataProviderCache.Get(0, dataProviderID.ToString()); if (result != null) return result; // if found in cache return it // not found in cache so get it from db result = await db.DataProviders.FirstOrDefaultAsync(x =&gt; x.ID == dataProviderID &amp;&amp; x.Active); // if found in db add it too cache in case we need it again if (result != null) Cache.DataProviderCache.Set(result); return result; }
It's really not about getting a cheat and use it to get an advantage because there is so many cheats out already that are bullet proff. I just want to have a passion about my projects and strive for an end goal, without this I would just quit a project after a week
Well this is kind of a big question. With something like CS Go keep in mind your account WILL be banned. So don’t use your main account or your steam account. Also keep in mind some really smart people are writing software you couldn’t conceive of to try to track cheaters. That said, one simple cheat is just to draw a reticle in the center of your screen overlay. That always shows up, so you can “no scope” in the game. Writing a memory editor that hooks into a process will work for single player games, it works on a process of elimination. So you’d scan for all memory locations with 100 if you had 100 health, then lose 1 health, and scan that collection for all values that are now 99, and so on. 