I was sort of hoping they'd go with if (animal is Dog) animal.Bark(); Of course that's sort of confusing because you could have: IList&lt;T&gt; x; if (x is Dog) Y(x) And now x is a type T : Dog, IList&lt;T&gt;, sort of and there's an ambiguity between T(Dog) and T(IList&lt;T&gt;)
Why would `IClonable` be a fiasco? If I go out of my way because I need a *real* copy, then deep copying is what I need to do no matter the performance implications.
The example automatically creates equality that compares each property for equality.
You made my point right there. The whole purpose of an interface is to provide a contract about what a type can do. The `IClonable` interface [makes no guarantees](https://msdn.microsoft.com/en-us/library/system.icloneable(v=vs.110).aspx) if it is a deep copy or a shallow copy, it just makes a guarantee that "Supports cloning, which creates a new instance of a class with the same value as an existing instance." It even explicitely says "It does not specify whether the cloning operation performs a deep copy, a shallow copy, or something in between". So if you write a function that takes in `IClonable` instances, and you are expecting them to do a deep clone on on a `.Clone()` call, you are going to be in for a rude awakening. You also can't guarantee that the implementer has done a deep clone through the complete object graph, so you may think a deep clone happened but the clone only went 2 levels deep.
It would be super awesome if you did up some kind of tutorial for how those button click animations/flashes are achieved, looks really nifty.
What have you tried?
Then start with a simpler task. Make a console application that lists the drives on the computer. Make a console application that, given a directory, crawls up its parents and lists them out.
&gt; maybe if you're implementing a math library for fun or something and you need to keep things like pi and e around. That sort of thing is really about the only good reason I can think of. When I haven't refactored this sort of thing out, it's because I only have so much patience for picking up somebody else's garbage.
This looks great. Any particular reason you went with the Material Design style over MDL2, given that you were developing for Surface devices?
 IEnumerable&lt;T&gt; Alternate&lt;T&gt;(params IEnumerable&lt;T&gt;[] sources) { return from x in sources from y in x.Select(Tuple.Create&lt;T, int&gt;) orderby y.Item2 ascending select y.Item1; }
Thank you for this suggestion. I will probably end up going with serilog + seq.
Unfortunately, you're not providing enough context around the scenario that you're in to give you a definitive answer. When you're looking at the lines of code you've shown, the answer is most likely "no." Interfaces come in handy when your system starts to grow more complicated. Or when you start to write highly integrated tests. For example, let's say that you introduce a class that can Crack things. You might end up with something like this: public class Cracker { public Cracker(Rock rock) {} // ... omitted ... } Nice. Now let's say you introduce another object that can be cracked (Glass?) Do we write another class to do that? public class GlassCracker { public GlassCracker(Glass glass) {} } Yikes ... this is starting to smell pretty bad. There are multiple ways to fix this, but one such way is to introduce an interface. public interface ICrackable { void Crack(); } now we can refactor our original Cracker class to accept an interface rather than a concrete type (Rock, Glass, etc.) public class Cracker { public Cracker(ICrackable thing) {} // ... omitted ... } Now we're getting somewhere. Now let's say that our "Crack" method is really fancy. It makes a web call out to some public service you're hosting on the internet. And so every time you crack some object ... information is sent off to that service and something happens. This is a bad situation to be in for tests. What this translates to is that when you write code around your Cracker class, every time it gets executed, it's going to send of a web request. That is, arguably, not a good way to test. Not to worry ... interface and mocking/stubbing to the rescue! There are plenty of libraries out there to help with this, one of the most popular is: Moq. Which would allow you to write a test like this: // This is PSEUDOCODE and will not compile public void ShouldCrackAnObject() { var mock = new Mock&lt;ICrackable&gt;(); mock.Verify(x =&gt; x.Crack()); var cracker = new Cracker(mock); } This is what is referred to as "Mocking." It's basically just overriding the "Crack" method, so that in a test YOU control what it does, because in the test you're writing -- you don't particularly _care_ what it does. Obviously, there are much more advanced scenarios that come in to play with mocking, stubbing, integration tests, etc ... but that is a much bigger scope. Anyways, hope this helps a bit ... *Keep in mind that none of the above code is really tested or compiled. Just typing from memory.*
&gt; do you think i overdid it with the animations No, not really. I'm all for transition animations, which appears to be what you're using the most. The click animations are a bit much for me personally, but it's not bad. Overall though, you did an excellent job and it looks great. You should be proud of it.
&gt; only because it seems C# changes can effect .NET changes I haven't seen any serious proposals for .NET changes from the C# team, though [there is a discussion about them](https://github.com/dotnet/roslyn/issues/420). (And higher kinded types are on that list, on the very bottom.)
I'll take that! this can't come out soon enough 
It's beautiful! Proof that good ol' desktop programs can be pretty too.
On the array slices, don't we already have those/aren't they easily implementable as a derived class of array?
&gt; I am doing my best to really try to learn SOLID principles Don't do that; it will just lead you astray. What you should be studying is the Framework Design Guidelines. Rather than wishy-washy bullshit answers that you get from SOLID, it has in depth discussions on exactly the kinds of questions you are having. I strongly recommend the book version, as it has plenty of commentary on why the rules exist: https://www.amazon.com/Framework-Design-Guidelines-Conventions-Libraries/dp/0321545613/ref=sr_1_1?ie=UTF8&amp;qid=1466783395&amp;sr=8-1&amp;keywords=net+framework+design+guidelines There is also a free online version with just the rules themselves. https://msdn.microsoft.com/en-us/library/ms229042(v=vs.110).aspx
They are "tuples", not `Tuples`. 
Based on what you've presented here, absolutely not. I'm a huge advocate of interfaces but the proper usage of an interface is right there in the name: "interface". If you plan on creating a method that needs to be able to work with a set of functionality rather than a member of a particular object family, use an interface. If you're coding up something that is going to act as a dependency for another class (e.g. a data store), then use and interface so that you can test that class without being coupled to the store implementation. If there is no foreseeable gain from creating an interface, don't bother because you're just creating trash in that it serves no purpose.
Something like this is coming in C# 7, but as of now, I'm not sure there's an easy way to do this, other than a wrapper class. Ideally, the wrapper class would implement INotifyPropertyChanged so that observers can monitor changes in value-typed properties. I'd call the wrapper `ObservableProperty&lt;T&gt;` or something like that.
Sorry I phrased that wrong. What I meant is that I suppose that they are using the same namespace and that this is the cause of the problem.
I can confirm I am not using the same namespace in both projects.
I added the xml namespace for the control like this; *Mahapps Controls* xmlns:Controls="clr-namespace:MahApps.Metro.Controls;assembly=MahApps.Metro" **Custom Controls** xmlns:Controls1="clr-namespace:_UI.Controls" and now it's working fine. Thought it will help someone if i posted here
Thank u :)
Is this in some kind of designer file?
It always depends on context. One way of achieving clean, readable, extensible code is to adhere to the [SOLID principles](https://en.wikipedia.org/wiki/SOLID_(object-oriented_design\)). For your question the Open/closed principle will most likely help you out: * Does outside code need the return value for essential usage? If not then make the function a private void and modify the internal variables. * Is this a critical output that other code essentially needs? Then make it public and return something.
Yes it is.
Oh wow. This is beautiful. Nice work!
Designer files are auto generated. They are not intended to be edited by hand. You usually have 2 options for setting these. Depending on the type of file, you can usually set a property in a designer somewhere (properties window, double clicking the parent of the .designer.cs file, something) that will persist this in the future. In some situations, you can create a partial class file for the same name (most designer classes are generated as partial classes), so that you can add behavior in a file that is not auto generated. The first option is likely what you want.
Another great reply :) Thanks. Your thought process was thought-provoking for me.
You can best thank me by spreading the word. I find it very frustrating that SOLID is taking center stage with the FDG is a much better set of guidelines. And I'm not just talking about .NET programming. With minor changes, you can apply the DFG to any statically typed OOP or OOP/Functional Hybrid language.
Don't know why you got downvoted, since the OP asked, "I'm wondering if it's best to just stick to git repo in TFS", and you answered that directly.
It's reddit, downvotes have momentum. I was serious though. There is a reason that Microsoft recommends git for version control over TFSVC. TFS is a great project planning tool, but the source control is lousy. It's best to steer clear and use git, plus the integration with Visual Studio is fantastic.
As with any tool, you can do just about anything you want with it. So, use whatever tool your team is most comfortable with. And since your team is just you, even better. :)
Git is annoying, though. But then so is TFS. I prefer Mercurial :)
Okay so i put together how i would do this. I made a 3 state indicator a little bounce morph animation and a color fade animation. --- First, make a new class like this: https://gist.github.com/CCRed95/4d064b949d2987312f7dc172969ff783 --- Now make this helper class to bind to your LevelState property as a VisualState https://gist.github.com/CCRed95/e166c21bf650dea348d6402c187e70b6 --- Okay now heres the thing that contains the style. Make your App.xaml look like this: https://gist.github.com/CCRed95/0b94eaaa124361a7bd07b05f1986f602 Any questions or have no idea whats going on/how it works, feel free to let me know!
Or svn. But do use something, even if you're lone. 
Mercurial is far more sane. Although github is far superior to bit bucket.
Tfs was not built on the ashes of source safe. Source safe was a bought product and Microsoft built tfs from scratch. But you are also confusing the tfs project management stuff with the vc. There is no issue with got in tfs. It works like any other git vc. The issue tracking, the build tools, the analysis - this is the great stuff.
How do you get all that from the open/closed principle? The OCP states open for extension closed for modification. How does any of what you said apply to that? Are you talking about properties vs. fields, where the former is accessible outside the object and the latter is accessible inside? To clarify, I'm a hardware engineer and I use C# to make GUIs for utility purpose. I feel like a lot of these kind of "principles" aren't very helpful for someone like me.
Nothing in the OCP applies to this situation. There is absolutely no mention of visibility rules in OCP. There is, however, plenty of information in the .NET Framework Design Guidelines.
Hardware engineer here. I realize that in general people don't screw around with "unsafe" memory operations here, but I do it all the time. If I want to know where in memory things are going to be, I just force the locations with things like malloc, etc. and use pointers in unsafe context. Saves me a lot of trouble constantly switching back and forth between firmware development with C and GUI development with C#.
It looks like they just want C# to become F#
Look into using JWT
Highly debatable.
where would one go to learn about these design patterns? Any recommendations? 
This comment lacks direction on how to provide something meaningful. 
Framework Design Guidelines. Free "just the rules" version: https://msdn.microsoft.com/en-us/library/ms229042(v=vs.110).aspx Full text with detailed explanations: https://www.amazon.com/Framework-Design-Guidelines-Conventions-Libraries/dp/0321545613
Agree. I used Source Safe back when it was a One Tree product (pre-"Visual") The only connection between the two is Brian Harry, who was one of the principles at One Tree, and is now in charge of TFS. 
1. Pedantic 2. Agreed, but the caller doesn't know that the object state isn't required. 3. Miniscule except for very performance sensitive situations. 4. Anything that starts with CA is not a compiler warning. Those are from code analysis. It's a hint, not a rule. 5. OK...so? They're hints, not rules. Aka, considers, not do's. ~~None of those 3 reasons are enforced by the compiler, see 4 and 5 above.~~ The reason it's debatable for non-factory methods is testability. How is a static method faked or mocked when needed? Shims suck.
All warning are from "code analysis". Sometimes that code analysis is done by the compiler itself, sometimes by a post-compilation step, but either way it is still code analysis. It is true that all CA warnings were originally post-compilation using FXCop. But these days more and more of those rules are being re-implemented by the Roslyn compiler. When they do that they don't change the ID number, as that would break backwards compatibility. Why I am talking about this? Because at the end of the day it doesn't matter if the rule is checked by Roslyn or FXCop. All that matters is that the rule exists for a reason.
&gt; The reason it's debatable for non-factory methods is testability. First of all, testability does not necessarily require mocks. You don't need to mock any pure function in order to write a unit test. That's part of the reason why we prefer pure functions to ones that mutate state. Secondly, if you do have code that should be mocked then you are going to express that in the form of virtual methods exposed by an abstract interface or abstract base class. In either case, the fact that the method is virtual precludes making it static. So again, no choice needs to be made. 
It exists as something to consider, not blindly do all the time. None of the rules that are reported beginning with CA have been implemented as compiler rules. Either FXCop is still running in those projects post compilation or the analyzer has been added to the project.
Where did I say that was possible?
Whoops. Was stuck on my 4 and 5 responses. My bad.
Not worth arguing I guess. It's not a hard and fast rule, is only to enhance performance and can safely be ignored all the time.
There is no point to using `Parallel.ForEach` when you just immediately prevent parallelization with a lock, you're just adding useless overhead by doing that. You can try to separate IO and CPU bound tasks so that one doesn't have to wait on the other, although that will only make a difference if the CPU work is actually a significant portion. Parallelizing IO often doesn't really help, and depending on the storage it might actually hurt performance due to seek times. Caching in RAM won't speed things up unless you actually have to access the files multiple times, which doesn't sound like it's the case from your description. I mean, you'd still have to wait for your cache to fill.
Pretty much this. I would profile your read, write, and edit code. If edit is significant you can parallelize it however you want. Most likely you are severely limited by IO. Play with how long it. Takes to read in and save different amounts of files per action. It may or may not make a difference, but besides changing HOW you read/write I think this is the only other big optimazation you could make. There are many ways to read in files, and much performance MIGHT be gained in that area.
An Immutable type is a type that cannot be mutated (read: changed). Like `string`
What I ended up doing was making Effect an empty interface, and then each other interface implements its own Source property. Source is then used internally instead of passed as an argument. 
Lets say you have these classes: * EverythingService * Foo * FooBar * Widget * Device * WidgetFoo EverythingService has 30 functions. * Foo and FooBar use functions 1 thru 15 * Widget and Device use functions 16 thru 30 * WidgetFoo use all 30 functions. Right now if you change the signature of function 1, Widget and Device have to be recompiled even though they couldn't care less about function 1. **Interface Segregation Principle** EverythingService gets 2 headers: * EverythingLow.h has functions 1 thru 15 * EverythingHigh.h has functions 16 thru 30 Now if you touch function 1, which lives in EverythingLow.h, only Foo, FooBar, and WidgetFoo need to be recompiled. Widget and Device only use EverythingHigh.h, so they are fine. **** **Applying SRP to Java/.NET** In .NET the unit of compilation is an assembly. In Java it is usually thought to be a Jar file. So SRP in a Java/.NET context would be how you organize your classes in assembly/JAR files in large projects to reduce how often they need to be recompiled. For example, frequently changed classes shouldn't be in an assembly/JAR that is referenced by all other assemblies/JARs. 
sure, I made a video a while back that does exactly this: https://www.youtube.com/watch?v=IfKysjyXr-8
You don't need to override interfaces, so that's why that part doesn't work. You can have interfaces simply implement another interface without actually implementing them. The class that implements the child interface will have to implement both interfaces. Generics aren't going to help because you won't know what the type is if you're just iterating through a list of them like that. And if they can differ, then you're really going to be out of luck. It seems to me that the problem could probably be solved by creating an interface for the parts of the source that you really care about, maybe spend time on trying to generalize those pieces a bit better. For instance, city could implement an interface that have whatever pieces you need and then replace City with that interface. Then City, Town, Region, or whatever can all implement that interface and effect can call the functions on that instead. But without actually seeing the bigger picture, it's hard to say for sure. Just looking at the example, I don't know what the "c" is in c.ExecuteEffect, but if it's an instance of City, then it looks super circular. Or lemme word it like this: What is so different about a city effect from a different effect that it would warrant a different interface? On a side note, please name your interfaces prefixed with an "I" (e.g. IEffect, ICityEffect, etc)
I think that makes sense, though I'm not sure I understand why recompiling on the calling classes is necessary if they only use the unmodified portions.
Awesome thanks!
You don't think that mindset is an important thing that products can share? I remember in one presentation BH explained why we had to suffer through the batshit insaneness of their diff/merge window. He said that's because every christmas/thanksgiving his brother asks if it's still in product because he did it. I get that's kind of "in jest". But FFS. That shit ruined developers daily life in maaaaany SS versions and in TFS it took I think until 2013 for them to replace that abomination. That's something that you have to live with daily and they didn't think it's a worthwhile thing to fix.
Well there are two flavors of SOLID: the literal one that no one even attempts to follow and the watered down one that means "do whatever you were going to do anyways and call it SOLID". SRP: Meaningless because no one knows what a "responsibility" is, let alone how to count it. OCP: An extreme form of OOP where every class is inheritable and you never add features to an existing class except by extending (i.e. inheriting) from it. In practice it is diluted to mean everything from composition to extension methods to accepting delegates as a parameter. The closed part of OCP has somehow morphed into immutable objects when not ignored completely. ISP: Originally a trick to improve C/C++ compilation times by splitting up header files, now it vaguely means "interfaces good, big interfaces bad". LSP: Ok, I haven't seen anyone fuck that up. DI: Not wishy-washy, just wrong. Wrapping your dependencies in abstract interfaces doesn't magically remove coupling. The same runtime dependencies are still there; they are just harder to work with.
Why were you mocking the object? Think carefully about your answer. If it is "because it represented a piece of hardware" then cool. If it was "because I don't have a stable test database" then maybe ok, but you should fix that as soon as reasonable. If it is because some idiot told you to mock every class except the one under test, then you need to stop listening to that person. Classes that are entirely in memory should never be mocked. Not even Random (though you should give it a seed). 
I'm passionate about good API design. That means paying attention to details such as the difference between a static and instance methods and the rules for choosing between them. And really this isn't a hard concept.
Yep. But it is important to understand the difference between subjective guidelines and objective rules. So much of our craft is based on experience and intuition that concrete, easy to follow rules are hard to come by. So when we do have one it shouldn't be blown off by saying "it's debatable" as if that's a real argument.
Ok. So what's so different about the source? Can the members of those sources be abstracted to a common interface?
Don't worry about CPU. This is a disk IO problem. You can parallelise all you like, your disk's IO is still screwed. So, stage one, you need to get all of the files from one storage location in SERIES into a ConcurrentQueue (for IO efficiency), pick off the queue in parallel using multiple queue consumers, then write output to a DIFFERENT storage location (ideally a different storage location per thread, but this may not be necessary) Stage two: So where's the bottleneck now? It's on the input IO, so now you need to have multiple input flows. Depending on your hardware, and the performance of your app right now, you may want to split this over multiple disks, multiple machines etc.
That is what task schedulers do now. Task schedulers are way more complex and much smarter, they interrogate queues, optimize read/write patterns, learn load requirements, understand hardware, do read ahead, lots of cool stuff... a whole world of optimizations and works of brilliant developers lives there. Mine on the other hand is basically looking at 3 numbers that effective get leveled out to 0-100. Mine is dumb and chunky and easy to write. The value in mine is I have outside knowledge on queue depth and know they just loading 100,000,000 tasks concurrently would be bad. 
You need to use some sort of collection, e.g. a [`Dictionary&lt;string, string&gt;`](https://msdn.microsoft.com/en-us/library/xfhwa508(v=vs.110\).aspx#Anchor_8).
You got down voted and I think it's because Azure Batch is suited to compute (CPU) bound problems. This an IO bound problem. I wouldn't want to know the cost just to round trip all those the files.
I'd use System.Data.DataTable 
You are pre-optimizing here. Write the code in the most simplest way first, and then benchmark it.
Thank you guys.. But, I need to create variables in runtime so that I can bind "ParameterAttribute" to that variable. I have to display those variables as parameters to user at runtime. That's why using collections such as dictionary won't work out. Use Case Example : -Catname -Dogname etc should be dynamically displayed if user selects domestic as an option (-Animal domestic)
Why have Source as a property on the effect, and also take source as a parameter to the method? If you don't need to pass City as a parameter, you can do something like this: public interface IEffect { void Execute(); } public class CityEffect : IEffect { public CityEffect(City source) { _source = source; } public void Execute() { //... } } That would let you keep a List&lt;IEffect&gt; that could store City effects as well as other kinds of effects.
Forget the implementation. Pretend the API you are trying to create already exists. How would you like to use it? I don't fully understand your problem. But trying to use the API if I pretend it exists looks something like this:- var london = new LondonCity(); london.ApplyEffect(new RainEffect()); london.ApplyEffect(new SnowEffect()); Which gives me the implementation of this:- public class SnowEffect : IEffect { } public interface IEffect { } public class RainEffect : IEffect { } public interface ICity { void ApplyEffect(IEffect effect); } public class LondonCity : ICity { public void ApplyEffect(IEffect effect) { } }
Honestly, unless you're stuck with TFS (work etc) I would really, really, REALLY just avoid it. Git is integrated in VS (though there's also TortoiseGit, which while ugly offers an interface that's considerably more straightforward for certain purposes) and its basic usage is a lot less fickle and cumbersome. There's also Mercurial if you want to try something different. I've found that Mercurial offers a nice balance of user-friendliness and power, and TortoiseHg is great. Source: have used TFS for 2 years at work, Git and Hg personally.
If that's the actual code, it means nothing and nothing matters.
Agreed, and I thought about bringing that up, but I still think it's a valid option, depending on OP's goals. If his goal is to process the backlog of these files once, then Azure Batch presents a compelling way to quickly set that up and get it done. If each file takes 1 second to process (likely higher), it would take almost 2 weeks to run through all of them. In compute resources, I wouldn't suggest going with a node size bigger than A1, maybe A2 if benchmarks showed a marked improvement. If we again assume 1s per file, that would be $17/34 for the compute resources, respectively. If we assume 5 MB average file size, that would be 5 TB input. Assume as well 5 TB output. It would depend on how quickly it could be done, which depends on how big you make the pool.\* Lets assume a modest number, like 100. Again assuming 1s per file, that cuts the total time down to less than 3 hours. Assuming this can be done in a day, storage (and put/list/create operation costs) should cost less than $20. That's not a great assumption, though, because: &gt; I wouldn't want to know the cost just to round trip all those the files. Left this last for a reason. It would be the most expensive factor. Import/export is $80 per device. Assuming 1 5TB drive in and out, that would be $160 + shipping. On top of that, you're still charged for egress, which would be $435 for 5 TB. :/ It would also take 4-5 days each way. Still, I think it could be done for less than $1,000. If they're time critical business files, it might be worth the expense, especially with a less conservative assumption on the time to process each file. \* No sense in skimping on the size of the pool. The compute resources are the same - cost of 100 days on 1 VM == cost of 1 day on 100 VMs.
A lot depends on how long it takes to read, process, and write each file. If that takes even 3 seconds, it would take over a month to process locally. ~8 hours in Azure with a pool of 100.
I'm surprised this has not been mentioned yet: Use **Directory.EnumerateFiles** instead of Directory.GetFiles. var files = Directory.EnumerateFiles( dir, "*.pdf", SearchOption.AllDirectories );
Great, I'll read this and the re-read it again.
Thanks for that, my question here is all about my personal improvement and a lot of people have provided great feedback. What you say makes sense. But what if you absolutely knew that a variable would only be modified by one function alone and never be touched again unless it needed updating in which case it would use that same function to update it? 
It's a task that will need to be performed fairly often so I am trying to do it right. If it were one off I'd probably just make it all synchronous and go home, in fact I think I have done that a time or two in the past :)
[Stephen Cleary](http://blog.stephencleary.com/2013/11/there-is-no-thread.html) explain the details better than I can. Short answer for your specific example is that once you execute GetStringAsync you are waiting on I/O for the result but the thread isn't. The method invocation is considered complete and the thread moves on to the next thing, and the next, and the next until you tell it that it has to wait for I/O to finish with an await statement. 
Cool, I am looking into TPL Dataflow now. It looks like a pretty straight forward way to handle exactly what I am after. Thanks!
while(ram &gt;0) { StreamReader sr = new StreamReader(path); ram--; }
http://blog.stephencleary.com/2012/02/async-and-await.html Stephen Cleary is the expert on Async and Await. His explanations are by far the best (IMO).
I didn't have a test database at that moment and I didn't want to be forced to set all of the properties since hat was done through the constructor. I've since setup a small test database (just a TSV file for now) of about 20 objects which are a just a subset of the 300k or so from the full database. 
Oh God, here we go again with the SOLID "principles". SOLID is like those cooking instructions you get at the back of pre-cooked meals that allow you get "great" food in two steps: 1) Remove packaging 2) Microwave for 15 minutes. I'll point you to a tweet from Kent Beck that will teach you more than the SOLID crap in fewer than 140 characters: https://twitter.com/KentBeck/status/728958067094659072 "An object is a limited scope in which to analyze state changes. Sharing mutable state with other objects breaks this." 
oops yeah i did! I wrote that in the context of my huge framework so i was using resources that were scattered all over the place. add this as an xmlns at the top of your app.xaml xmlns:po="http://schemas.microsoft.com/winfx/2006/xaml/presentation/options"&gt; and add this as a resource by your brushes and stuff &lt;DropShadowEffect x:Key="shadowDelta2" BlurRadius="8" ShadowDepth="1.5" Direction="270" Color="{StaticResource MaterialDesignShadow}" Opacity=".42" po:Freeze="True" /&gt; 
http://www.hardcodet.net/tag/scheduling Ive used this a few times, very light weight. Cant testify to the quality of the code, but I had no issues running it .net or mono.
Hangfire is just fine without ASP.NET. That's just how the project started. 
Does there need to be an update if nothing in these pdf's changed since the last time the job ran? 
I'm using hangfire in a desktop app, runs only in the task tray monitoring a server, it has been working just fine using an in memory datastore. It runs a recurring job every five minutes, has been working great running for the past few months. I really like it and have done a few tests with multi client and server scenarios. I look forward to using it more in the future. I just wish it had a way to run a job on all servers, for example to invalidate cached data and force a reload.
Assuming your dgview is bound to a data source, like a datatable, I would suggest filtering the source. Data loaded into the dgview is going to trigger rendering operations for each row which are going to consume a much larger amount of processing time compared to your filtering operations. Look up virtual mode. You can stagger these rendering operations over time and update the dgview as needed.
This is some good clean code, thanks. Legit question though- how would the processing of this differ from using Parallel.ForEach? 
Hey! So I was working on a full example of implementing the struct Idea I explained, and I came across some reflection based stuff in the .NET library that handles attributes applied at runtime without any of the stuff I was talking about! Its funny since I wasn't able to find much about this outside of MSDN. Its the Activator.CreateInstance method - it allows you to pass instances of attributes. I haven't tested the following code since I don't have access to an IDE at the moment. The following is an example I created showing how you could implement this strictly for strings. class SomeAttributeA : Attribute { public SomeAttributeA(int SomeAttributeFlagOrSomething) { // stuff } } class SomeAttributeB : Attribute { } // For Activator: using System; class Program { public void Main(string[] args) { // Create a new string that is activated with attributes [SomeAttributeA(20)] and [SomeAttributeB] string someCoolString = CreateObject(type: typeof(string), defaultValue: "this is an attributed string", parameters: {new SomeAttributeA(20), new SomeAttributeB() }); } public object CreateString(Type type, object defaultValue = null, object[] attributes = new object[] {}, object[] parameters = new object[] {}) { object newVal = null; if (attributes.Length &gt; 0) { // Go through each object in the attributes array and ensure that // it inherits from Attribute. foreach (object attr in attributes) { if (typeof(Attribute).IsAssignableFrom(attr.GetType())) throw new NotSupportedException("The type \"" + attr.GetType().Name + "\" does not inherit from Attribute/is not an attribute."); } // Since the exception wasnt thrown and there are more than 0 attributes // activate the instance using the array of attributes newVal = Activator.CreateInstance(type, parameters, attributes); } else { // Otherwise, call it without attributes. newVal = Activator.CreateInstance(type, parameters); } if (newVal == null || defaultValue != null) { newVal = value; } return newVal; } } You could probably use a Generic Type Function too e.g. public T Create&lt;T&gt;(T value, ...) P.S. You can use structs for the Type as well, but that implies that the struct is mutable. I'm totally okay with that since I prefer a data oriented approach to software design, but if you're following the strict guidelines that the .NET framework implements for typical object oriented design - your structs should not be mutable and you should use classes not structs for this CreateObject function.
It uses HttpWebRequest. Somewhere down at the bottom of the stack are IO completion ports.
The reading and writing of the files would occur as [async I/O](http://blog.stephencleary.com/2013/11/there-is-no-thread.html) instead of normal CPU threads freeing up the CPU to keep processing files. That may be overkill since I assume the CPU will be waiting on files to read/write most of the time. Anyway, combining this code with the producer/consumer pattern as others suggested would be very efficient.
How had I not found this! It looks very interesting, thanks. How has it been for you to use? Does it support different platforms, eg windows service, console, wpf as well as ASP.NET?
This is now my favorite comment in a programming sub.
This is gold. Thanks a lot. I followed following steps, 1. I used type builder to build the type with my class and also I was able to assign custom attributes to my class. 2. Then I used create instance to create an object with my required type and attribute. 3. Then used Runtimedefinedparameterdictionary to create my dynamic parameters. Tadaaa.. Done.. 
OK so what am I doing wrong here? I run it and it exits right away... using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using FluentScheduler; namespace ScheduledCodeTest { public class Program { public static void Main(string[] args) { JobManager.Initialize(new ScheduleSetup()); JobManager.Start(); } } public class ScheduleSetup : Registry { public ScheduleSetup() { // Schedule an IJob to run once, delayed by a specific time interval Schedule&lt;MyJob&gt;().ToRunOnceIn(5).Seconds(); } } public class MyJob : IJob { public void Execute() { Console.WriteLine($"Executed at {DateTime.Now}"); } } }
&gt; Again, I'm going to say you absolutely aren't aware of immutability if you have the questions you have. I really have no idea why you intend on fighting me about what I do and do not know about immutability when you apparently have zero understanding of the context in which I originally started, and you seem to be taking this way out of context and intend on trying to "prove" that I don't know what immutability is while at the same time completely misunderstanding the whole context from this thread. &gt;Look into immutability, what it says, and what benefits it has, and you'll clearly see that the situation you're describing is not an immutable data structure. What does this actually have to do with anything. The situation I'm describing, the exact sentence you quoted, is saying that the new C# 7 "with" operator is not an operator that only deals with the C# 7 version of records, which are immutable outside of reflection hacking. Since you can use that operator outside of C# 7 immutable records that means that there is no way for consumers to know if the "with" operator is a shallow or deep copy. Since the "with" operator has nothing to do with the C# 7 immutable record type, and can be used with regular C# classes, that means there is zero relationship between the "with" operator and C# 7 immutable types, and the fact that they were brought up together in the original post did not make sense. That's it. Your whole rant seems to miss this.
I just rewrote a Windows Service that executed jobs at specified times using Quartz.NET and changed it to a simple console app that we set up in task scheduler to run every 5 minutes that uses NCrontab + a per-job cron expression + the timestamp of when the job last ran to calculate whether a particular job needs to be run this time. Simple and effective and I was able to jettison a TOOOOOOOOOON of extra glue code that interfaced with Quartz.NET. Might not work in all situations but it worked great for this one and is way simpler than a full-blown scheduler implementation.
I am working on WinForms. Is "Init" Same as "InitializeComponent()" function in winforms?
Hang fire hands down. I execute close to 12,000,000 workflows a week with it. It is great for load balancing and redundancy across pool of servers.
More or less. Though there is a `Main` method that kicks off your forms, or you can use your form's constructor. Some more info and options for you here: http://stackoverflow.com/questions/8992837/where-is-the-main-method-in-a-forms-application
This might help as well https://msdn.microsoft.com/en-us/library/system.dynamic.expandoobject%28v=vs.110%29.aspx?f=255&amp;MSPPError=-2147217396 dynamic sampleObject = new ExpandoObject(); sampleObject.number = 10; sampleObject.Increment = (Action)(() =&gt; { sampleObject.number++; }); // Before calling the Increment method. Console.WriteLine(sampleObject.number); sampleObject.Increment(); // After calling the Increment method. Console.WriteLine(sampleObject.number); // This code example produces the following output: // 10 // 11 Not sure if it suits your needs, but take a look anyway. 
http://i.imgur.com/7L5I2Tr.png This is the code as best as I could get it to look. 
C# is a statically typed language (mostly), you cannot use the contents of a string variable as an identifier like this. In the case of resources. you can access resources by name via the methods of their `ResourceManager`, e.g. `Resources.ResourceManager.GetString(SelectedStory)`.
Thank you! This completely solves my problem.
Why?
I agree, although most people will not be designing frameworks. Most that write on this sub, at least. 
DateTime dob = Convert.ToDateTime("1991/06/30"); int years = DateTime.Now.Year - dob.Year; dob = dob.AddYears(years); DateTime check = DateTime.Now.AddMonths(1); if ((dob &gt; DateTime.Now) &amp;&amp; (dob &lt;= check)) { lblCustomerBirthdayAlert.Text = ("[Your birthday is coming this month! Collect a cash voucher from us!]"); } else { lblCustomerBirthdayAlert.Text = (""); } But this code is on the .Master page. Is there anyway to replace the 1991/06/30 to a user birthdate from SQL database?
Is [this](http://www.c-sharpcorner.com/article/crud-Asp-Net-web-api-with-entity-framework-in-Asp-Net-mvc/) the article you wanted to share? If so, this made me scream internally: public IEnumerable&lt;Customer&gt; findAll() { try { HttpClient client = new HttpClient(); client.BaseAddress = new Uri(Base_URL); client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("application/json")); HttpResponseMessage response = client.GetAsync("customers").Result; if (response.IsSuccessStatusCode) return response.Content.ReadAsAsync&lt;IEnumerable&lt;Customer&gt;&gt;().Result; return null; } catch { return null; } } 1. The method should be called `FindAll` 2. Why call `async` methods synchronously? You're just blocking the current thread of execution that IIS has created for the request, whereas you could also be taking advantage of the CLR's thread pool 3. You're returning `null` if the HTTP request fails or if there is an `Exception` thrown, but you don't actually handle this case, so you could potentially pass a null reference to your controller and your Razor view I don't say this to be mean, but you should remove this article, as it will result in beginners learning a number of bad practices.
Thanks :D
Hash the password with a salt. 
&gt; How does PHP come into play? What does it do? It reads the encrypted password from the database. I want to futureproof it and make sure it can write too.
You can use [Rfc2898DeriveBytes](https://msdn.microsoft.com/en-us/library/system.security.cryptography.rfc2898derivebytes.aspx) on the C# side and [hash_pbkdf2](http://php.net/manual/de/function.hash-pbkdf2.php) (with "sha1" as the algorithm) on the PHP side. 
I actually found codewars.com a great place for practicing the basics of different languages. Most of the drills and practice problems are set up for several languages.
Syntax, and learning that stuff is in the correct spot. (Java's api's are notoriously messy in compared to C# impo)
Maybe pressing Start+Up on the keyboard to maximize the app?
Fuck, i also realized MaterialDesignShadow is in another spot. Thats just a pure black Color object.
I think he wants a programmable / automated way of doing it.
It's interesting that you mention IntelliJ as I've been trying to get Resharper working because I love it's code completion, however it keeps disabling that feature and it becomes a pain in the arse.
I did want a programmable way but ive programmed the automation to hit Windows + Up at the Test Initialise area and this fixed it so thanks frSlick for triggering the mind! :) Keyboard.PressModifierKeys(ModifierKeys.Windows); Keyboard.SendKeys("{UP}"); For reference!
Yeah, do a database query. There are several ways to perform database queries and plenty of resources online, but you should reference the learning materials you've used up until now to do the query in the way the class was taught.
I've switched between C# and java several times during my career. The syntax is close enough that when you come up against differences, the compiler will let you know and you can google the C# equivalent. The biggest differences will be found in the frameworks. things like LINQ, EF, ASP.NET, Collections, etc. Luckily they are all well documented. I'd say skip the book and start building an app.
You should take a look to Project Rider then : https://www.jetbrains.com/rider/
As I'm willing to learn ( again ) C# after several years of Java, I just started reading a book about it. There are so much similarities that reading the book is made very fast and usually, it's more about spotting the differences than actually learning anything new. I'm not in a hurry hence I have the time to do so. So far, I've learned a thing or two, but not relevant enough to justify the time it took. Things might get more interesting with advanced topics though.
This is always the answer. One way hashing. Never should be able to decrypt passwords.
When you override `ToString()`, you're overriding it from `Object`, the root of all types in C#. `StringBuilder` then uses this method internally. The `ToString()` method in your interface is redundant and confusing. Unless you do an explicit implementation, the base `Object.ToString()` will always be called anyway.
&gt; Ok, your only point is that you want to violate encapsulation by having callers understand the implementation of a method. Whatever. I stand by that class/library designers can feel free to implement it in any way they feel (shallow or deep) depending on whether they have (designed) immutable classes or not. That's the summary. I'm not wanting to violate any form of encapsulation. In fact am arguing that the ambiguity of `IClonable` and the `with` operator means that the language designers want you to violate encapsulation by forcing the you to understand the implementation in order to know if their usage is going to cause bugs or not. Since the operations are ambiguous *by design* you cannot know for sure if it's going to be a shallow or deep copy without looking at the implementation and that is why it is bad to bake into the language itself. Instead it should be explicit about what kind of copy it is, or force class designers to create their own method for cloning/copying data out so that it is a bug on the class implementor's side if the class designer does not document what type of cloning operation it is doing.
It isn't just for capital-F frameworks; these guidelines are applicable for any application that's large enough to divide into multiple projects. 
Sorry, misunderstood what you mean. Good call, it definitely makes that section a lot cleaner without having any of that in there. Thanks!
Honestly? I'm not sure what kind I want to end up doing. I just want to keep learning. My background right now is entirely in-class with basic projects, which isn't helping me in the job hunt because my experience is limited in that way. Basically, I'm looking to learn and practice enough to make myself more marketable.
Don't do that! Use hashing and salting instead (BCrypt and other libraries can do that for you)! **If there is any way to recover the password an atacker will find and abuse it!**
Don't see where you are instantiating notecanvas. It's trying to run the clear() method on something that is null. Maybe you can do a notecanvas = new . If that is handled somewhere else, just do a simple null check before running that line
Environment as in architecture? Or something like request.servervariables ? What will you be changing?
Just dev, uat, prod etc environments. My last project was java where we used them for a million configurations, but right now all I know is that the connection strings will be different for at least 6 environments. I looked at some transformations for the web config, but no example on stackoverlow would work.. I think tfs might have prevented the file writes? Not sure, but didn't work. In any case it seems like it should be trivial but all I can find is Request.ServerVariables
it means you might be able to switch to core and get better performance in the current code base, and have access to newer .net features that mono doesn't support yet. But .net core may not have every thing you use in mono either. 
It's only gone out of scope because you intended to bring it out of scope trying to argue I don't know what immutability was lol. Only now it's finally back to my original point, which you seem to be totally in agreement with is that the `with` operator needs to have very clear guidance on if it should be implemented as a shallow or deep copy, and somehow make that clear so that users are motivated to follow that guidance and not deviate it so consumers of it who have not spent hours going through guidance documentation can understand what type of copy they are going to perform. It's important to understand that an API will be consumed by users of all knowledge levels and many will not just assume it's a "shallow clone and should only be used in certain circumstances". As of right now I could not find anything that says the `With` operator has any guidance what so ever, nor if it's geared towards immutable types or not. And yes, I went through the C# 7 RFCs on githup pretty extensively and comments, but they have also made it extremely difficult to find information for.
Hard to say given we really have no idea what you've learned, what your skill level is, and to what scale of an application is appropriate. As a general area, perhaps consider making a utility that someone might use with their computer. Maybe a program that lets you launch multiple programs with one shortcut link (so you boot up your computer, click the program, and it launches your email, web browser, visual studio, etc.), or a music library, or some widget/program that monitors some RSS feed for you.
Well...not zero. You do have access to a turing complete language =) (yes I know) 
There is a lot of discussion around this: [Proposal for minimalistic imaging platform](https://github.com/dotnet/corefx/issues/5921). But for now, Microsoft doesnt work in it: [Create core geometry, drawing and imaging libraries](https://github.com/dotnet/corefxlab/issues/86).
What's your degree and what are you looking to do: sling code, web, mobile, apis, databases, data science, etc? There are a lot of different fields of expertise out there and my suggestions would be to explore them and focus on the areas that are most interesting to you. Your career is going to be richer if you're excited and naturally curious about the problems your solving and you can land jobs in those areas. 15 years in the industry (startups, enterprise, etc) and rarely do I see a UML diagram. YMMV, but it's been rare for me. If you land a job at an enterprise/process heavy place, then maybe that'll happen. In my experience, side projects have always been more interesting if they're fueled by a natural curiosity vs. just needing to get a job. And employers will pick up that as well. Curious about all the hype around node? Build a little API, maybe even build a mobile app to consume it. Wondering what "big data" is all about, there are tons of datasets out there that you can download and crunch numbers on (data sets - https://aws.amazon.com/public-data-sets/). Another thing you could try, is to come up with a real world problem, something that you've thought of, or something that bugs you and try to come up for a solution for it. Bug in chrome? Or wish you had a desktop app to keep notes? For example, I was recently annoyed that I couldn't search emojis by synonyms and natural language words, so I built a database of emojis with synonyms and an API to search them. I also picked a language (node) that I was curious about, since I've mostly worked in .NET. Another option is to find an opensource project you're curious about, scroll through the issue list, try to solve it and submit a pull request - https://github.com/trending As for your original question, here are some sites that have problems you can solve: * some fun and interesting math problems - https://projecteuler.net/ * http://exercism.io/ * https://www.hackerrank.com/
As a C# developer, one of the hardest things when having to develop in other languages, is how shitty their IDE's are compared to Visual Studio.
&gt; That part wasn't out of scope because you asked what immutability was Please read my original reply again. Here I'll quote the relevant part: &gt; I know what the definition of an immutable type is, I meant what he is referring to as an immutable type in that instance. In the context that I was talking about (the with operator) him bringing up immutable type didn't make any sense. Let me rephrase my original question which you keep on bringing up. "What's an immutable type?" should have been "What's an immutable type [in this context]?". &gt; Well, let me clarify it for you. It's designed for immutable objects. For mutable objects, we have the = (assignment) operator. Why this is confusing for you, I cannot fathom. Because at no point in the article nor any of my googling can I find this to be official in any way, shape or form. All I see is you, as an individual developer, saying that. You seem convinced that this operator should be only used with C# 7 records and other implicitely immutable classes but there is nothing enforcing this and nothing that makes it really clear that it's the primary use case (just like there was nothing really helping in defining how `IClonable` should work. On the outset it looks like an extremely simple syntax to clone a POCO and I see nothing outside of "best practice" guidance that would make people not support it for mutable classes. In fact I can see many excellent use cases in which I need to grab a POCO from a database and create X copies with different information to store back in the database. Therefore, just because in your mind this is something that is crystal clear, it will not be clear to most developers using the operator and (re)implementing the operator, and therefore that should give a huge pause. It's the same logic that the language designers used to not have fall through in case statements, and many other examples of the language designers trying to make sure that people don't shoot themselves in the foot accidentally (and back-peddling from ambiguity, such as `IClonable`). &gt; CONSUMERS SHOULD NOT CARE ABOUT IMPLEMENTATION DETAILS I 100% agree. Glad we are in agreement about this even though you keep trying to make it seem like we aren't. You seem to be contradicting this statement though. The problem that you seem to be talking past is that `with` operator is extremely implementation dependent. If the user just assumes they understand the `with` operator and it is functionally different on a design level from implementation to implementation, then the bugs will occur through no fault of the consumer or implementer. So either users shouldn't care about the implementation details and thus this is a bad situation we are putting people in, or users should understand the implementation details of the `with` implementations and this is a non-issue. You can't have it both ways. 
Thank u :) it's working 
Best way is to take something you've made and rewrite it in C#.
Windows services have simular issues, plus a whole can of other ones. You can do automatic deployments fine, remove the old task and add a new one for instance. My experience is that shouldnt use windows services for something that runs on a schedule, use a existing scheduler for that (like the windows scheduler).
I really hope I'm misunderstanding this solution: &gt; **Ignoring null pointer exceptions** &gt; &gt; The programming language examples discussed above are on one side of extremity: calling a null pointer produces a runtime crash, and you have to opt-out case by case to recover. On the other side of extremity is an idea to ignore a null dereference and continue execution. This is an opt-in solution where you have to produce an exception yourself if you need to. &gt; &gt; For a programmer who is used to deal with null pointer exceptions this might sound crazy, but this idea has proven itself to work well in production. Objective-C runtime and thus most Mac OS and iOS applications are running this way. Several things are great about this strategy: &gt; &gt; * A program can recover itself from an unexpected error if a higher level code works with the null condition. In other cases an operation finishes as if nothing has happened, because later calls to null are ignored too. &gt; * Disgusting null pointer exception errors are not thrown upon a user. &gt; * The app stays alive and might continue doing other useful stuff. &gt; * Null-checks can be avoided producing more compact and readable while still correct code. Is this saying that code ignores null checking and exceptions are essentially ignored. The program continues executing producing null return values, doing nothing on method calls (on null instances), etc? This seems absurdly dangerous to me. _"The app stays alive and might continue doing other useful stuff"_ might as well read _"The app stays alive and might continue doing other extremely dangerous/harmful/undefined stuff perhaps unnoticed by the user."_ And because the app isn't really "failing", the errors go unnoticed/unreported to the developer so you never really know how significant the problems are or when they occur and makes it even more difficult to debug when the user reports some weird undefined behaviour. This is the behaviour in Flash ActionScript (at least ActionScript 2.0) and it was brutal to deal with. All in all though, my first thought that if a developer is dealing with "Null reference exceptions Hell", then it suggests a serious deficiency in their application design, their code quality, and perhaps the usefulness of their testing. At least in the C#.NET world; could be a different story with other languages/runtimes/platforms. Of course, I'm just a big fan of fail fast in general and ignoring the null case altogether (because the code design usually doesn't use nulls as valid values). In general, if a developer has the discipline to stop using nulls in their code, null reference exceptions tend to also go away. Null reference exceptions rarely make it past initial development and testing stages.
Yes I did, sorry about that.
C# (.net core or otherwise) and Java both compile to a virtual machine bytecode that will run on any platform that has a runtime for the bytecode. 
Why are you even using a LINQ query and a conditional operator for this instead of a simple `foreach` and `if`/ `else`?
&gt; Your inability to Google or understand is not my problem. I solve this by simplifying it for you so you don't have to think. If you cannot trust me, then you have to become more capable. See this document describing with Thank you for posting that because that document 100% proves my point. No where in there does it say that the with-expression should be only workable available for records, nor does it say anything about strong immutability. public class Class1 { public int X { get; set;}} public class Class2 { public int X { get; private set;} public void Add(int num) { X += num;} } public class Class3 { public string[] Values { get; private set;} public Class3(string commaDelimitedValues) { Values = commaDelemitedValues.split(new[] {";"}, StringSplitOptions.RemoveEmptyEntries); } } public class Record1(int X); public class Record2(Record1 R1, Class1 C1, Class2 C2, Class3 C3); public class Record3(Record1 R1, Class1 C1, Class2 C2, Class3 C3) : Record2(R1, C1, C2, C3); public class WasARecordButNoLonger(Class1 C1) { public WasARecordButNoLonger(Class1 C1) : this(C1) {} public WasARecordButNoLonger With(Class1 C1) =&gt; new WasARecordButNoLonger(C1); } public abstract AbstractRecord(string Name); public class ConcreteRecord : AbstractRecord { private string _name; private readonly Dictionary&lt;string, string&gt; _values; public ConcreteRecord(string name, Dictionary&lt;string, string&gt; values) : this(name) { _name = name; _values = values; } public string DoStuff() { // Do something with _values } // Since an abstract record forces re-implementation of this public override AbstractRecord With(string name) { return new ConcreteRecord(name); } } // Somewhere else way out in the code var record2 = new Record2(r1Instance, c1Instance, c2Instance, c3Instance); var exRecord = new WasARecordButNoLonger(c1Instance); var concrete = new ConcreteRecord("abc"); var copiedRecord2 = record with { new Record1(5) }; var copiedExRecord = exRecord with { c1Instance2 }; var copiedConcrete = concrete with { "cdefg" }; // Concrete then has to be recasted into typeof(ConcreteRecord) What happens in this scenario based on everything you see in that RFC. Now imagine that you don't know the implementation details of c1, c2, or c3 instances (because as we both agree, you shouldn't have to know the details of the implementation) and tell me how a normal programmer is supposed to reason about what the consequences of that with call will be? Now think if `Class1` is defined in library A, `Record2` is defined in library B, and you are working on application C. So you can go on and on all day about the theory of immutability, and hand wave around that I am abusing the syntax, but the fact of the matter is the spec as you linked me is 100% open to these scenarios and does not resolve any ambiguity. This means that to completely reason about my code I must have full understanding of what is going on under the hood when I do a `with-expression` or even calling the `With()` method, especially since intellisense *WILL NOT TELL ME* what's a record and what is not a record. Therefore, this is opening up a lot of iffy scenarios that will cause leaky abstractions. And again, since the specification mentions no where that `with-expression` should only be used for records, there is no reason to assume that I shouldn't implement a `With` method myself to take advantage of the syntax on non-records. In fact it's encouraged to retain binary compatibility when you need to extend records (it explicitly says that in the spec). *Edit* Oh yeah and one other scenario. If a record takes a mutable `struct`, tell me what a reasonable programmer will expect to happen after the `with` expression/method happens. 
yes. and F# is microsoft's scala 
&gt; Is it so that the maintainer of that library needs to compile a version that's compatible with .NET Core separately? Yes, they would need to publish a package that is compatible with .net core. This isn't always possible right away as there are still some features not available in .net core that are in .net 4.6 and below. If your project targets .net core (as in you want to be able to run on any machine linux/mac/windows) you can only import packages that depend on .net core. Since the package in question requires .net framework 4.0 or higher you cant import it. You could either change your package to .net40 or above (meaning only runs on windows, and maybe mono) or find a package that does what you need on .net core. For these reasons it may be a few years before a lot of larger projects make the switch, and rightfully so. We are planning on making the switch as soon as SignalR and EF are working completely on .net core so probably sometime next year.
was it 900 years ago? It might have been true then. But before Java was jitted I don't know if .net existed. Maybe there was some overlap. 
I just needed to change the return type of my method to IEnumberable&lt;string&gt;
The complete code can be found here: http://codereview.stackexchange.com/questions/133250/parsing-remote-text-file-and-inserting-into-database-table if anyone is interested in doing a code review, thanks.
Just another point of view: Why? With unit tests you want to test the unit. The unit is the public API. Everything you want to test in the private/protected methods should be testable through the public methods - otherwise your unit is too large and does too much.
But how retrieve they birthdays from database from a .master page?
Got it — many thanks!
I have to disagree, slightly. Private methods are definitely off limits, but protected methods are still part of the visible API and as such should be tested. You do need to create a subclass with a helper method to expose it however.
With respect to private methods: 1. Don't. 2. Reflection. 3. Don't. 4. internal + InternalsVisibleTo 5. Don't. Test the public behavior, not the interior implementation if you possibly can. With regards to protected methods, derive a child class and go to town. public class TypeWithProtectedMethod { protected void Foo() {} } // Meanwhile, in unit test land public class TestClass : TypeWithProtectedMethod { public new void Foo() { base.Foo(); } } [TestMethod] public void TestFoo() { new TestClass.Foo(); }
Frankly, I just have bitter frustration and resentment towards you at this point (a feature of you continually failing to acknowledge unimpeachable statements) and I have no desire read any points you have to make. Especially since you seem to be under the false impression that the document I linked to supports you in any way. I, unfortunately, do not feel equipped to convince you. I feel you've made it very clear you have no intention of being open to being convinced nor open to information so you're just wasting my time at this point. If you feel you have a valid concern, [open up an issue in Github](https://github.com/dotnet/roslyn/issues) as this is an open process where _you_ could make a difference, but not in some comments on reddit. Unfortunately, you're just complaining to the wrong person as I can't do _anything_ about this. And I'm certainly not going to open up an issue for you when I believe your concerns are completely invalid as I would personally be embarrassed for expressing this concern as it shows an abundant amount of ignorance (willful and otherwise) and lack of forethought. But perhaps someone else will feel differently. I'm hopeful that the ones you would complain to would see your complaints as baseless as I do so that progress can continue to be made on the C# language. But you don't have a lack of options and you certainly don't have to rely on just myself to show that you're mistaken. Maybe after a few more say that you've missed something fundamental you'll be prompted to reevaluate your thoughts and figure out that you've made a few errors in your reasoning and, hopefully, see your selective blindness on the matter.
Write a WPF application that downloads a weather forecast and displays some nice graphics. Modularise and abstract your code and follow some design patterns. Look up dependency injection. Just doing that teaches you a hell of a lot and an AS/A level student doing that deserves full marks unless your teacher is too stupid to know what any of that is in which case best of luck.
Hardly. 
The headline says "private/protected", and InternalsVisibleTo doesn't work for those. 
&gt; When I crate a new instance of ClassA, and call ToString() on it, it calls IMyInterface.ToString(). No it doesn't. Only if you create it like this: `IMyInterface x = new ClassA()`. If you do `new ClassA().ToString()` it doesn't call the interface method. 
It doesn't hide the default implementation since he's implementing it explicitly. It will only hide it if the instance is contained in an interface-typed variable or parameter or field. 
.NET Core is build from the same source code as the Windows Version of .NET but it is missing some pieces, mostly GUI components as far as I know. You'll have to check the documentation to see if anything is missing that you need. Mono is a completely different codebase. I would not recommend switching to .NET Core in the first version. You can try it but it is propably not stable enough to move a production system to it yet. But .NET Core will propably replace Mono when it is ready.
That sounds like a good idea . im tempted to do this . but one question is that if you had time how would you expand the project ? thanks 
i like the sound of the music player . i was thinking that i could try grab all the music from the pc and then store the data in a database . and you can play songs from there . but thanks for the great idea :D 
&gt;Mono is a completely different codebase. This isn't 100% true any more - I definitely remember Miguel de Icaza saying at some point that when the whole open sourcing process of .NET began, the mono engineers at Xamarin went through and looked at Microsoft's reference implementation and swapped out some of their code for Microsoft code if they felt it was more optimal, or just better architected. 
Probably because I started with the thought I had to download the file then open and read it. Still learning...
I agree (to an extent) with the both of you. The protected methods (or more explicitly, the behaviour they encapsulate) should be tested, yes, but you should strive to limit yourself to when it is used as part of the very explicitly public API of the object being tested. If it's protected, it's very rarely going to be used by itself, otherwise that's an indicator it shouldn't be protected in the first place. Of course there are huge exceptions, I understand. Anyone with the displeasure of using/testing ASPX codebehind may have a nervous twitch by now.
I don't test private/protected methods - but there is a caveat. I also don't *design* private/protected methods, at least not up-front I don't. I extract them *after* I have implemented the system under test. (red-green-refactor cycle - this extraction is part of the refactor stage.) Thus the code being extracted started life in a public method, and now all I am doing is refactoring to reduce duplication or whatever. So this means I've already got the tests to show if I break anything.
https://www.microsoft.com/cognitive-services/en-us/apis
Yes, that's what I wrote in my reply to him as well. Fair enough, but that's not exactly "normally" :)
I'm actually surprised by the response only testing public methods. I'm with you, test everything. Often the public method may consist of a few internal method calls. I find it easier to write a few tests for each of the internal methods, to test them in isolation and then one or two at the public api level. The thought to only test the public methods had actually never occurred to me.
&gt;As an exercise, just ask people how they feel about VB.NET. Umm, I feel like there are very good reasons for people to not like VB
A+ delicious CopyPasta
Your checkedItems variable is a collection and not a single item. You will want to iterate over it using a foreach(var item in checkedItems){ } and do something to each item.
If you try to uninstall Update 3 from the control panel, you might get a "Repair"? I haven't tried yet but that is something that we can do to many installs.
Ha, actually I'm dealing with a codebase that has been updated by many people over the past like 15 years(there is A LOT of crappy code). I didn't think I needed a StringBuilder anymore so once I got rid of it it took me a long time to realize why calling .ToString() isn't working right :(
You didn't give a lot of details but here's what works for me: we use ASP.NET Web API json which requires me to add this header to Postman when I use verbs like POST, PUT, PATCH: Content-Type application/json
I've tried removing MonoGame from Xamarin Studio and re adding it but for some reason it doesn't show up in packages I have installed nor does it show up in packages that I can install. I also tried removing the reference but when I go in and look for references I can add it doesn't show up there either.
From what I gathered, the idea is to introduce the nullable reference type at first and build on it on subsequent releases. There wouldn't be tons of warnings, just in situations where a null reference exception is pretty much guaranteed.
Remove it and re install it?
&gt; it is propably not stable enough to move a production system to it yet I think a lot of developers and companies that have already done just that would probably disagree. Yes, it's v1 but the team has been extremely transparent and open through the process of development, and it shows. To toss v1 aside and say it isn't production ready isn't doing it justice. Just like all things, if you're considering it, do the necessary development and testing in a lower-life cycle to make the determination whether or not to go into prod with it.
Yes, it was initially a Microsoft's implementation of Java, then Sun sued Microsoft for it and Microsoft said "fuck it, we'll make our own Java, with delegates and value types". 
My understanding is that .NET core does not supersede the frameworks at this time. The .NET frameworks will still be available for some time (maybe forever) including the Mono Framework. In fact if you are creating desktop apps in C# for Mac OS, then Mono is your only choice right now. You certainly could move your console apps to .NET core. In our shop (mostly web apps) new projects will be .NET core but we aren't spending any time moving old projects away from the frameworks. 
As far as I know, there are no plans for Xamarin to drop Mono, which means that Mono will probably survive.
&gt; To toss v1 aside and say it isn't production ready isn't doing it justice. I'd quantify it more by saying it isn't production ready for current .net devs. There's a definite learning curve and you really want to make sure you evaluate what's missing. You don't want to get halfway into a project only to find out a library you assumed existed in .NET Core doesn't. 
solved: 2 weeks of R scripting was enough to confuse me to forget how static classes work...
EF Core 1.0 was released with RTM and Signal R is due in Q3 2016
Take a look at Fiddler. You can use that to intercept the traffic and then inspect it / replay it later Bonus - it's free: http://www.telerik.com/fiddler
this isn't just C#, it's just floating point arith so you are learning more than just C# here. more float 101 fun - try adding .1 to a float in a for loop and print out the value in each iteration. float value = 0; for (var i = 0; i &lt; 20; i++) { value += .1f; Console.WriteLine(value); }
OP, thanks for making this post - I hadn't heard of .NET Core and now I need to look at it. I didn't know Microsoft was developing an interplatform version of C#.
Probably the most significant factor is _what_ you're automating. For example, if there is heavy disk I/O, then that may be the bottleneck regardless of language/platform used. Perhaps even Windows is a bottleneck and using Mono/.NET Core or Python on a Linux box would yield better results (again, regardless of language) Furthermore, you're running this task _weekly_; so how much is performance an issue for you? If it's something you kick off at Saturday 2am, and it runs until 2:30am, then performance is a non-issue. At this point, you probably ought to consider what language/platform is most appropriate for the work being done, which you feel will be more maintainable going forward, and which you personally just want to learn. I'd also confirm what you're saying that if the implementation is done poorly, then the language comparison is irrelevant. But I'd go further to say that if you don't know either language, then your implementation will almost certainly be poor and/or unoptimized, not utilizing the language/runtime/platform to its fullest capacity. So bottom line, unless you provide more information about _what_ you're automating, the only recommendation I can provide is choose the language/platform that interests you the most.
I'm automating database pulls and then emailing the results...so remote database interaction and local SMTP server usage
I would definitely start investigating it as a serious alternative, yes.
thanks for clarifying.
I think /r/ProgrammerTIL would like this
In the short term, I think so, because it has momentum and direction that (I percieve) Mono lacks. In the medium term, it is a gamble either way. Either Mono will swallow .Net Core (unlikely, but possible) or .Net Core will swallow Mono. The bellweather for this is Xamarin, so keep your eyes on Xamarin. When Xamarin switches, you know that .Net Core will swallow Mono and not the other way around. In the long term, it really doesn't matter. The two will merge into one at some point, or become so similar that effectively the only large difference will be namespace. You really cannot go wrong in switching. Then you'll be able to say you know both.
By default, classes are tested for reference equality, i.e. whether they're the same *instance* and not whether they contain the same values. To use value equality, override the classes' `Equals` method and implement your desired equality logic there.
A lot of good stuff in this blog: https://leastprivilege.com/. The blog references their own implementation but the code samples and ideas are usually applicable. I can't recall the exact post, but I used it years ago to integrate a webapi with an existing authentication system.
this would be a simple powershell script ... maybe like maximum 30 lines of code, absolute maximum, for what you have described (and honestly, it could probably be a one liner in powershell)
properties is a list of a class that contains only strings. I only need to test 1 string in the class to see if the whole object is a duplicate. properties = properties .Select(p =&gt; p).Distinct().ToList(); This syntax has something to do with LinQ? is there a good tutorial or reference material to become familiar with it? 
Monogame is one of the game frameworks for game development on the new XBox version. http://news.xbox.com/2016/03/14/letter-chris-charla-idxbox-updates-gdc/ http://www.davevoyles.com/monogame-3-4-is-out-has-support-for-windows-10-and-that-will-include-xbox-one/ Also Xamarin is now a Microsoft business unit, so I expect with time both codebases will eventually be merged.
Thanks I ended up getting something working, although I have no Idea what the GetHashCode is used for, I guess distinct uses it? would it be better programming to just not create an item in the list if its a duplicate?
Thanks! I will check them out. I have never used their Identity server but from what I understand it is Open Source and available as a NuGet package.
Not sure I fully understand what you're asking. Are you asking how you can use a different class instead of `ArrowProjectile`? That other classes use the same code, but that one line they want to look for different "projectile" types?
Correct. Let me know if it would help to show the entire method.
Yup, please show the full method. Thanks. EDIT: It would also be nice to see what your second implementation and use case scenario would look like.
Implementation in the base class(BaseWeapon) http://pastebin.com/JxsZHxs5 Set target overwride http://pastebin.com/8YNmvA2p Subclass #1 ArrowWeapon: enemyHealth.futureHealth -= projectile.GetComponent&lt;ArrowProjectile&gt;().damage; Subclass 2# CannonWeapon enemyHealth.futureHealth -= projectile.GetComponent&lt;CannoProjectile&gt;().damage;
If you already have dot net you already have the c# compiler , find the folder of the latest dot net version you have installed , head to the bin folder , and you will see a lot of exe's and one of them should be csc.exe , if he's not there try a different version of dot net , once you made sure the csc.exe file is there add that bin folder to your system path variable (if you don't know how to do that google how to do it ) and now just type in the cmd csc.exe file.cs , and it will conpile it into an exe for you , that you can now run
Well, perhaps the simplest change you can make is to create a separate `protectec abstract` method to retrieve the damage and each subclass can override that: protected void Shoot(GameObject currentTarget) { ... float projectileDamage = GetProjectileDamage(projectile); enemyHealth.futureHealth -= projectileDamage ... } protected abstract float GetProjectileDamage(GameObject projectile); Subclasses would override the method: ArrowWeapon: protected override float GetProjectileDamage(GameObject projectile) { return projectile.GetComponent&lt;ArrowProjectile&gt;().damage; } CannonWeapon: protected override float GetProjectileDamage(GameObject projectile) { return projectile.GetComponent&lt;CannonProjectile&gt;().damage; } I can't speculate too much if this is the best way to do it, or if your game warrants a more significant overhaul, but maybe this will work for you with the minimum amount of impact and assumptions.
What's your objection to InternalsVisibleTo a test class? Is it just the possibility of sloppiness/temptation to make stuff that _should_ be private internal instead? I find myself using it occasionally, as I tend to occasionally have assemblies with a handful of internal classes (data structures tailor-made to a task, say), where not exposing them to my test classes would shoehorn me into writing integration tests, rather than testing units. Edit: saw you answer this in a later reply; fair points were made. I'm still not 100% convinced that there's no place for InternalsVisibleTo in testing, but I'll chew on the arguments from maintainability and duplicated coverage
This and another big thing is the lack of DataTable's (and all the associated data objects you usually use with them) Any legacy app will probably be using these, so it's no small task to move away.
Removed: Rule 1ish. Regardless, I think this is a question/post more appropriate for /r/cscareerquestions. Good luck!
&gt; I'm still not 100% convinced that there's no place for InternalsVisibleTo in testing That's because there *is*, but mainly in cases where the alternative (refactoring the public interface for testability) is too risky/time-consuming to undertake. It shouldn't be your first resort, but it beats the hell out of not testing anything at all. Additionally: `InternalsVisibleTo` exposes an assembly's internal bits to any assembly with the right *name* (unless you're using signed assemblies on both ends, in which case you can match on the strong name key), which is a potential security problem. (Edited: access is by assembly name if the assemblies aren't signed.) The once or twice I've taken that route, I `#if`'d the attribute so it was only in the assembly's debug build, and just didn't build the tests as part of the release. This worked OK *for my situation*, but I'm not wild about conditional compilation (Heisenbugs!), and it means not being able to test the release build directly. This sort of thing does not fill my heart with confidence and warm feelings, but circumstances sometimes require it.
 &gt; '4. internal + InternalsVisibleTo Always this method. There's immense value to testing internals, never let anyone tell you otherwise. 
I completely understand why you removed it, although the article perfectly applies to NullReferenceException and has C# examples. NullPointerException is identical to NullReferenceException in practice, and I mention in the foreword that those are synonyms. The whole idea of my blog is that different languages programmers communities should learn from each other by comparing themselves with the others and finding approaches to common problems. By restricting me to post to /r/programming only you severely limiting this. I know that many stubborn developers don't want to hear anything about the other languages, but I'm sure that they want to be compared and competitive with other technologies. My point is to unite and discuss commonalities together. Your response to that is very offensive. There's only a few people who would be interested in the other languages, because of such community "segregation", but I'd still like to find them, and yes, I have to go in all 9 different subreddits for that! I'm trying to say that it's not spam, but actually an attempt to unite communities by learning from each other. I got good feedback from the subreddits including /r/csharp that helps to improve the article, while /r/programming comments were mostly chuckles. 
I appreciate that. I should convey the point better in the beginning. My main point however was that our compilers should be better at fixing this problem instead of leaving it sensitive to human errors. There is though a chapter about mitigation solutions that I propose. Mentioning code contracts is a good idea.
There is multiple ways to get c# to be native. It's actually the default for release builds now for all modern applications. You can also use the .net native pipe line to force it on legacy projects. But for what he is doing it doesn't matter.
I am of the opinion that the .NET framework will eventually be entirely replaced by .NET core in the next 5-10 years. We'll have to one day explain to junior developers what the .NET framework was, and how totally impossible it was to make clean ports of our code from platform to platform. They'll laugh at the inequities we face today with ignorant, disgusting faces.
Any reason in particular you're using Xamarin Studio instead of Visual Studio Community 2015?
There's a great open source implementation called [IdentityServer3](https://github.com/IdentityServer/IdentityServer3). I can't recommend it enough as implementing OAuth yourself is quite an undertaking. I've implemented IdentityServer3 and just plugged my own custom user authentication routine into it without any issue.
I think you can iterate any child controls using 'Controls' property. You also can use 'Tag' property where you can attach any hint value in any control With those two, you can share common handler routine for multiple child controls
On a semi-related learning note- I would highly recommend using double instead of float- floats tend to lose accuracy after a few operations. Doubles will also lose accuracy, but not as quickly. Otherwise they behave similarly, so it's easy to swap in double. Consider float to be for special use cases only.
There are times where the extra precision doesn't really matter or the extra memory used can cause perf issues eg due to cache. But I definitely prefer double just because of better coverage in the math library. That would probably change if a certain proposal on gh were implemented adding eg float.Sqrt(value). Either way, you shouldn't be using floating point if perfect precision is necessary (classic example us money). Things like decimal exist for that purpose (never had to use in my life). In computational geometry, for example, increasing precision means maybe rarer brokenness due to fp error but is still a bandaid.
If losing accuracy (for currency for example) is your concern then the recommendation should be to use decimal rather than either float or double.
I switched a few months ago (around start of year) but would recommend no. Too much in flux, need to wait for library package support, tooling isn't there (eg dotcover test code coverage), etc. It's not mature.
I hope that's how it goes. I think that might even be the plan. Of course MS might forget the whole thing tomorrow. :-) 
Look up the modulus/modulo operator.
Thanks @mungk .. any guides on how to implement IdentityServer3? Sounds like what you did is just was I am looking for.
I agree .. those are great tutorials. I am having a hard time separating out the use of ASP Identity though. Any tips on how you did it? Any chance you could expand a little more on what you mean by "issuing tokens without any validation at all"? Thanks again for the reply. So much better here than the snobs at Stack Overflow.
Fair enough. I just assumed since you were using Windows that Visual Studio would be the go-to program. But Xamarin Studio makes sense if you're trying to reach a wider audience. EDIT: Have you looked into Visual Studio Code? That'll support Linux too.
Second this series, it's what I ended up using as a guide. Part 5 was the part I was looking for
Rather than start the installer and try to programmatically go through it, you should see if the installer offers a way to do what you want without bringing up a UI in the first place. Many installers offer this kind of user-free installation. 
[yaaaaay](https://www.reddit.com/r/ProgrammerTIL/comments/4qdm2c/cmaybe_all_languagesfloats_you_can_divide_them_by/)
I know you were kidding, and Microsoft might have axed many products and projects in the past, but I can't think of the last time they dropped support for a developer platform after they released it.
But is it the default? It is for c# now.
No I am talking about the new default for modern C# apps which is native compilation to assembly rather than IL. I agree it would be rare, normal speed differences are between 3-15x faster in my tests.
.Net native requires no .net runtime. It embeds a native GC inside the exe and performs static linking. You are thinking of the older Ngen tech... From the .net Native blog &gt; During precompilation, required portions of the .NET Framework are statically linked into your app. This allows the app to run with app-local libraries of the .NET Framework. The .NET Native runtime is optimized for static precompilation and thus is able to offer superior performance. .NET Native uses the same back end as the C++ compiler, which is optimized for static precompilation scenarios. 
(Reddit is giving me errors posting this, so I'll have to make multiple comments) &gt; How do you measure the reputation? Would more karma help or are there some requirements? If first, what karma level do I need to post here? Reputation/karma is irrelevant. Your comment/link karma does not restrict posting/commenting privileges on /r/csharp. &gt;I see that "Rule 5: Do not frequently spam your own blogs or tools", but I just post like 1 page per month. Is it too frequent? Your rule text says once a week actually. There is no hard and fast rule, the rules are flexible and left to the moderator's discretion to remove content for the betterment of the subreddit. In your case, Rule 5 was invoked due to widespread submission of your post to a lot of subreddits. While cross-posting is permitted, posting the same link to 9 (at the time, the tally is now up to 13) is way over the top. Once a week is just a guideline. Typically if a poster is predominantly or only submitting and commenting on their own content, then the rules will be applied more harshly. If a user is submitting from a variety of sources (of which they are unaffiliated) and are engaging in conversation/comments in a variety of submissions, then the rules tend to be applied more leniently. Essentially, if you are a user of the subreddit first that engages with the membership with more-or-less altruistic intent, and thus essentially respect your fellow developer/subscriber here, you will be met with respect. If you are using Reddit _primarily_ as a promotional medium to plug your own content/blog/product, you'll be viewed as an _advertiser_ and not afforded much leeway.
You are thinking of the older Ngen tech. .Net native requires no .net runtime and it embeds a native GC and runtime. From the .net Native blog &gt; During precompilation, required portions of the .NET Framework are statically linked into your app. This allows the app to run with app-local libraries of the .NET Framework. The .NET Native runtime is optimized for static precompilation and thus is able to offer superior performance. .NET Native uses the same back end as the C++ compiler, which is optimized for static precompilation scenarios. 
&gt; If I come across other related materials, would it help to post them as well? Yes, absolutely, post other related materials that are not your own. /r/csharp only exists because people post worthwhile/interesting/new content that other people _want_ to read. Don't only post stuff because you want it to be read for your personal gain (e.g., page views on your blog), post stuff for the betterment of your fellow developer. &gt; Also I don't quite understand a point about "self-promotion". Do you want that I ask somebody to post here, or it's just that you don't want any kind of promotion? I felt like this "self" means something bad. &gt; From your side author postings should be more valuable, because it's much less like spam and the author can engage in discussions first-hand much better. Also I don't get any money out of it. It's like volunteer activity to basically entertain your people and give some ideas. That's nice and all, but Reddit is not a platform for advertising. The moderator on /r/javascript gave you some advice (https://www.reddit.com/r/javascript/comments/4q5dyk/null_undefined_typeerror_hell/d4qveug). I recommend you read through (fully) both links they provided there. And yes, we do treat original content made by authors here posted here as valuable. If we were to take Reddit's baseline spam rules (greater than 10% of your submissions are your own content, then you are likely a spammer) then a lot of good content being submitted here to /r/csharp would be blocked and many users banned. All we ask is that these authors try to not cross the threshold into spam territory, that they try to make submissions that are highly relevant to C#, and ideally try to engage with /r/csharp outside their own content.
&gt; Re Xamarin, currently they use Mono, but I can see this changing in the near future - more and more of the full framework is being ported into packages for NuGet - and this is the model that Core uses. Mono using .NET Core will not happen before things like [LLILC](https://github.com/dotnet/llilc) mature to the point where they can produce full AoT binaries for iOS, that seems like years off from now so near term doesn't sound realistic to me - maybe in 2-3 years. 
It's very hard to find a Windows machine without .NET installed, since some version of .NET comes since Vista iirc?
 var image = (Bitmap)Properties.Resources.ResourceManager.GetObject("name");
Overriding ToString is the easiest solution. Also, you can specify a DisplayMemberPath, which is the name of a property that needs to be displayed. As a last alternative, which is the most solid I think, you can define a DataTemplate for your type. In there you can choose what needs to be displayed and how, using all the bells and whistles WPF provides. Lets say we have this data class: public class Data { public int Number {get; set;} public string Description {get; set;} } Then you can do something like this: &lt;ListBox&gt; &lt;ListBox.ItemTemplate&gt; &lt;DataTemplate TargetType="Data"&gt; &lt;Grid Height="30"&gt; &lt;Grid.ColumnDefinitions&gt; &lt;ColumnDefinition Width="30" /&gt; &lt;ColumnDefinition Width="*" /&gt; &lt;/Grid.ColumnDefinitions&gt; &lt;TextBlock Grid.Column="0" Text="{Binding Number}" FontSize="15" /&gt; &lt;TextBlock Grid.Column="1" Text="{Binding Description}" /&gt; &lt;/Grid&gt; &lt;/DataTemplate&gt; &lt;/ListBox.ItemTemplate&gt; &lt;/ListBox&gt;
Yup
This and if you use any third party libraries you have to check if they also work with a different runtime. I remember the first time I wanted to switch from Sun JDK6 to OpenJDK6 which failed because some libraries used internal functions from the JDK and where not compatible with other runtimes. At the release of OpenJDK7 the problems where finally fixed but it is possible that the same thing could happen to some C# libraries with .NET Core.
Only the third party libraries but if there are some features missing from .NET Core which is available in the full .NET version, then I don't think that you can get this with a nuget package yet.
Xamarin already produces AoT binaries for iOS, do they not? I've not used it much for iOS, but that's my understanding of it... since iOS does not allow dynamic code execution. However - yes, LLILC is a different beast, more similar to .NET Native (in fact I expect Unity are probably kinda pissed that they spent so much effort on it, now) In any case you can compile a Core-type class library using PCL platform identifiers (or perhaps netstandard - not sure how that works with Xamarin quite yet but if it doesn't currently work then that'd be a very high priority thing) and you can then import it in a Xamarin project, so you can share code between the two. 
It isn't the default, you have to target UWP, and handle edge cases that won't work any more. See: https://msdn.microsoft.com/en-us/library/dn600165(v=vs.110).aspx 
As I said it is the default for modern c# apps (uwp) and I am yet to encounter any edge cases thus far and we use loads of reflection in our games, (reflection used to be a problem for .net native).
The Imaging library is not very complete in Mono, either. We had to write our own image scaler, for example.
That's pretty standard semantic versioning. Major.Minor.Patch-Label-Build.
It's always been MS's Java. The main difference is that the loader used to be built into Windows, and now it's a standalone executable that can run on other platforms.
Dependencies can have dependencies. NETCore.App has a lot of them. It's like listing all of the package.json files in a node_modules directory.
Removed: Rule 3, Rule 6.
I guarantee it's possible to do, I've seen it done. I'm wanting to do the same l. I'm kinda friends with one of the devs (steam, and he's helped me before) so I'll ask him how he did it. 
You would prefer if it weren't explicit about dependencies?
Yeah they're basically API exploration and discovery tools to self document your web service. Configuration is quick and it's really helpful in making service calls.
I have visual studio code however I have one problem with it. I can write the code but I cannot seem to compile it. Any solutions?
Thanks so much for the detailed reply! It was very helpful. Wish I could allot more up-votes :)
You should explore the possibilities of command line tool psexec, and also to explore how to communicate with command line. After that, the rest is how you will organize your config data
I think you need to setup some command line compilation, and I believe you can then automate that with "tasks" in VSCode.
No problem. Hope you figure it out. Feel free to PM me if you have more questions.
Setting the DisplayMemberPath on the ListBox is the way to do it. If it is more complicated than a single property you could create a readonly property (just a get). Or you could create an ItemTemplate. I prefer to do stuff like this in XAML. I think it keeps the code looking cleaner. 
As you can see from the comments, there are two ways to go about this -- either use `ToString()` or `ListBox.DisplayMemberPath`. It depends on what you want to do. Personally, I find `ToString()` easier, as it gives me more flexibility about what exactly I want to display, but you could bind `DisplayMemberPath` to a custom property and it's all the same. I think it's largely a matter of personal taste.
I'd prefer fewer dependencies. For example, I recently wrote a simple app. It was, according to the VS analytics tool, less than 500 lines of code. However, when I compiled it, it compiled into something like 50 files, and nearly 40mb. Of these, 30 files were necessary for redistribution. The reason was that I used Microsoft PRISM and SQLite in the app. I grant you that, in this case, there wasn't much I could do about it -- once I decided to use those libraries, I was doomed. But it's indicative of, I think, a larger problem: we as programmers are happily accepting the most ridiculous of bloat for things that make our lives marginally easier. I could have avoided PRISM entirely given how little of I used, and I could probably have avoided SQLite as well in favor of using built-in .NET libraries and a custom data file (the data that was being stored was quite small). The fact that I didn't even think of it is telling -- we as programmers are generally in favor of using libraries to do things that we could do ourselves just as easily. Not that I'm against libraries -- especially in complex coding situations, it's much better to use something tried and tested than it is to reinvent the wheel. But for something simple, doing so ends up generating 6500-line "Hello, world!" programs. And something like that is frankly ridiculous. It's "Hello, world!" for god's sake -- you can find complete implementations of it in a few lines on Wikipedia. I personally think this is a bad trend.
I would recommend using https://www.autoitscript.com/site/autoit/ It is built for automating tasks and does a really good job at this. If you have to do it with C# it is certainly possible, but more difficult at least in my experience. 
All the installers frameworks (there are just a few of them) support this. I think in most cases the checkbox / prompts are only shown when the value isn't present. So you supply a answer file and then the installers skip all the prompts - or just takes the defaults. Sometimes there are tools that will help you figure out what the answer file will look like. A lot of programs publish it on the website. For example this is some of the switches that come with acrobat reader: /sAll Silent Mode for product /sPB Silent Mode with Progress Bar for product /rs Reboot Suppress /rps Reboot Prompt Suppress /ini "PATH" Alternative initialization file /sl "LANG_ID" Set Language; LANG_ID - Code in decimal digits /l Enable Error Logging. Log file Bootstrap.log will be generated in temp directory /msi[Command line] Parameters for MSIEXEC AdobeReaderInstallFile.exe /sAll /rs /l /msi "/qb-! /norestart ALLUSERS=1 EULA_ACCEPT=YES SUPPRESS_APP_LAUNCH=YES" To answer your post, in c# you can use the automation library to simulate mouse moves and keyboard clicks. That is a pain in the ass. Also, its purposely made a little hard since installers are a malware vector, so you have to make sure you handle UAC prompts. On that page it looks like if you cannot build a answers file they suggest using AutoIT that will do the writing of the automation code for you.
Another great option is AutoHotKey.
No idea, why this post is getting downvoted. I'm also not agreeing what Pyran is saying, but guys, seriously, he just wrote his view. Don't downvote posts, just because you have another opinion...
So the obvious question is... why not just delay the `Show()` method until you actually want to show the window? I don't think you can do what you want to do. When you `Show()` a window it has to create an entirely new visual tree, measure, arrange and render all of the elements of it before it can process the visibility of the WPF window. They made a rather reasonable assumption in the `Window` class that if you're showing it, then it should be visible.
The window is a messaging center for the app. I have a threadpool that tails a log file and sends messages to the viewmodel of the alert window to display them. Trying to use .show() only when needed could lead to a race condition, where two or more threads try to show it at the same time. Not sure how best to handle it.
Assuming you don't need something too performant for this: // Some logic here // Now it's time to show the window lock(myWindow) { if(myWindow.Visibility != Visibility.Visible) { myWindow.Show(); } } // Keep going
Depends on how you're making the ViewModel.
If you wanted the first column to resize to the content of what's in it instead of designating a fixed size you can do: &lt;ListBox&gt; &lt;ListBox.ItemTemplate&gt; &lt;DataTemplate TargetType="Data"&gt; &lt;Grid Height="30" IsSharedSizeScope="true"&gt; &lt;Grid.ColumnDefinitions&gt; &lt;ColumnDefinition Width="Auto" SharedSizeGroup="group1"/&gt; &lt;ColumnDefinition Width="*" /&gt; &lt;/Grid.ColumnDefinitions&gt; &lt;TextBlock Grid.Column="0" Text="{Binding Number}" FontSize="15" /&gt; &lt;TextBlock Grid.Column="1" Text="{Binding Description}" /&gt; &lt;/Grid&gt; &lt;/DataTemplate&gt; &lt;/ListBox.ItemTemplate&gt; &lt;/ListBox&gt;
Yea it's a desktop app. I'm loading a list of pictures from two directories (Comparing to see if filenames match, If they match it loads the filename into this list). I want someone to click through this list and when it clicks it loads the pictures side by side. Basically a high level photo comparison tool. It's mainly going to be used as a sanity check for some very bad interns...
You use IValueConverter to convert from a known value to a UI-specific value. So your ViewModel would have a boolean called IsBorderVisible for instance, and the converter would have the output of type Visibility. Generally any view-specific properties can be 'inferred' via the converter from a known state. You don't want to store that view-specific info on the Model or ViewModel. Thus converters.
Oh, in that case you don't even need `Process.Start()`. You can load up the files in question, read them into a Bitmap, and bind the Bitmaps to controls on your form. It's actually pretty easy. EDIT: Fun fact -- Reddit can't handle URLs with parentheses in them well. Try these: **Image.FromFile**: https://msdn.microsoft.com/en-us/library/4sahykhd(v=vs.110).aspx **Image.FromStream**: https://msdn.microsoft.com/en-us/library/93z9ee4x(v=vs.110).aspx
Sounds good but slightly confusing are there any videos that can show me how to do this.
This is making entirely too much sense. Now I just need to get the folder browser selection working and generating two unique lists of files and then get the logic to iterate through one list with values of the other. This is going to be a fun evening project. 
I use them all the time and while I generally can get around without them in alot of cases they're generally cleaner if you can reuse them. I use some simpler ones like an 'invertable' boolean to visibility converter that takes a parameter so I can set it to turn visibility on or off on true and the opposite on false for example. I've also used them for a few more complex situation such as applying a mathematical operation on a control like so. MaxWidth="{Binding ElementName=ParentControl, Path=ActualWidth, Converter={StaticResource AdditionSubtractionConverter}, ConverterParameter=-25} Where the converter takes a +/- a number and returns the result of said operation. In this particular case to give me more flexibility on the sizing of a control within a control. So in summary there are plenty of good usages of them out there.
Have fun, posts results/code?
Removed: Rule 5.
Another Fun Fact: You can remove the part in parentheses from the URLs and they still work. 
Yeah, They never really drop support for this stuff. It just sits around on MSDN forever and never gets updated. You can still get FoxPro 6. :-) They probably haven't specifically dropped support but once they give up on something life is hard for anybody still hanging on. 
I pretty much only use ValueConverters to convert to/from visibility and boolean values, but there are other niche uses for them from time to time. That said, this is a "more WPF way" to do your above snippet without a converter at all: &lt;Border&gt; &lt;Border.Style&gt; &lt;Style TargetType="Border"&gt; &lt;Setter Property="BorderBrush" Value="Red" /&gt; &lt;Style.Triggers&gt; &lt;DataTrigger Binding="{Binding IsRed}" Value="false"&gt; &lt;Setter Property="BorderBrush" Value="Blue" /&gt; &lt;/DataTrigger&gt; &lt;/Style.Triggers&gt; &lt;/Style&gt; &lt;/Border.Style&gt; &lt;/Border&gt; 
The default setting within setting within visual studio is set to false. It is remembering a true persistently despite this. The synchronize button that is meant to correct this is not working. This isn't an issue of me using the settings correctly. This is a bug within visual studio that isn't associating my settings file with all of the locations it is supposed to. See the other comment reply for further details (as that seems to be the bug in question)
That would explain it, though they mentioned it being an issue after windows 8 and I'm on 7. Any idea what they mean by setting "CompanyData to something meaningful". What would be something meaningful? ***EDIT:*** Got it. Went in to regedit and navigated to HLEY_LOCAL_MACHINE / SOFTWARE / Microsoft / Windows NT / CurrentVersion and added a value to "Registered Organization". Then I went in to AssemblyInfo.CS and entered the same value for AssemblyCompany
Just a heads up, if you're using WPF and not WinForms, you might come across a problem if you try to display the image without freezing it first. Here's the code I use to pull an image from a relative location and set it up to be displayed in a &lt;Image&gt;. It's not async, but it's easy to setup for that if you want. For my solution I needed it to execute on the calling thread: private BitmapImage GetImageFromRelativeLocation(string location) { if (!File.Exists(location)) return null; var image = new BitmapImage(); image.BeginInit(); image.UriSource = new Uri(location); image.CacheOption = BitmapCacheOption.OnLoad; image.EndInit(); // If I don't freeze the image, it won't be accessible from other threads, causing the program to blow up image.Freeze(); return image; }
Why not just compare the first few hundred bytes (and store the hashed results as you process the list). If there is a dup, hash the full data set and compare both results? I wrote a similar program in c++ or something (can't remember) so I could call all the dupe photographs on my hard drive. It worked splendidly.
The pictures are different, but similar. Think Head shots with backgrounds that have changed.
I appreciate the linked resources. This may be a dumb question, but does the speed have anything to do with C# being on Windows, or would this speed advantage largely persist even if the .NET framework hypothetically was ported on other OSes without the use of tools like Mono (as I understand it, it beginning to become fully open source will help with the cross-platform goal)
This has nothing to do with the OP, _or_ .net Core. In response to your digression: I understand the preference for fewer dependencies, especially after spending time with the Node/NPM ecosystem. They don't have a nice standard library and must include packages for things even C programmers take for granted. But your complaint about what gets added with PRISM and SQLite - you're really arguing _against_ fewer dependencies. PRISM contains a boatload of functionality, and any 500-line program can only be using very little of that. If PRISM were split into separate packages by feature, you'd end up having more packages with fewer and/or smaller binary files.
There are many things you can solve using XAML however there are cases where you need the extra flexibility of ValueConverters. Me personally, I don't feel it violates MVVM in any way. While styles can also be re-used in different projects, for example by putting them in a separate library, it's (in my own opinion) much easier to do that with ValueConverters. There's one ValueConverter I've come to use a lot: public class NullImageConverter : IValueConverter { public object Convert(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture) { if (value == null || String.IsNullOrEmpty(value.ToString())) { return DependencyProperty.UnsetValue; } else { return value; } } public object ConvertBack(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture) { throw new NotImplementedException(); } } If you have an application that uses a lot of Images and does so by binding the Source property to a string, it can really improve the performance of your app if there are Images that are unavailable (for example from online sources) Others that come to mind are converters that take a `Bitmap` and convert them to an `ImageSource` or converters that allow you to make comparisons otherwise not possible with XAML. public class BitmapToImageSourceConverter : IValueConverter { public object Convert(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture) { var bitmap = value as Bitmap; if (bitmap != null) { using (var stream = new MemoryStream()) { bitmap.Save(stream, ImageFormat.Png); var image = new BitmapImage(); image.BeginInit(); image.CacheOption = BitmapCacheOption.OnLoad; image.StreamSource = stream; image.EndInit(); bitmap = null; return image; } } else { return null; } } public object ConvertBack(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture) { throw new NotImplementedException(); } } --- public object Convert(object value, Type targetType, object parameter, CultureInfo culture) { var left = System.Convert.ToDouble(value); var right = System.Convert.ToDouble(parameter); return left &gt; right; } If you can get away with using XAML (that isn't a mile long) and you have no need to re-use them, as in: it's very specific to a given View, go ahead and do it and remember ValueConverters are available if you need a little extra flexibility. 
Juval Löwy's The Zen of Architecture is at the top of my list. 
Attributes are, principally, metadata, do I don't feel like an attribute should do much of anything on its lonesome. (And when would that logic execute? When the class is loaded, maybe? I'd have to do some testing to know.) I have used attributes as markers for other class to find using reflection, and then do stuff about, like calling the decorated methods. That works fine, but will feel really, really clunky; may be slow; and will be hard for the next programmer to understand.
Thanks for this. Makes me think I should put a little more time into revising and cleaning up my tests!
For *collection manipulation* you can use a common interface. For whatever BL you have, you can use real classes (B knows about immediately connecting A and x*C). 
Each node should know how to handle that call on its own. That's why people are telling you to use an interface. 
Using `ConfigureAwait(false)` is sometimes dangerous - especially when you're trying to do GUI stuff. Not using `ConfigureAwait(false)` is always a safe bet.
&gt; Not using `ConfigureAwait(false)` is always a safe bet. No, absolutely not. Not using `ConfigureAwait(false)` is sometimes dangerous - it can lead to deadlocks. Understanding `ConfigureAwait(false)` is the best bet. It's a library. That library does not access any shared context. There's no need to use `ConfigureAwait(true)` (default). In the UI parts of the code, sure, but there is no UI access here. It's also slightly improving performance if you use `ConfigureAwait(false)`. If you always use true (like you suggest), then the synchronization context **always** has to be passed - even when it's not used. And in UI applications it means every concatenation must be executed on the UI thread - even when it serves no purpose.
[XPath Examples](https://msdn.microsoft.com/en-us/library/ms256086(v=vs.110\).aspx) Use: `"/Settings/Databasename"`
Attributes are constructed when they are first being looked for with reflection. That is, when you first call GetCustomAttributes&lt;MyAttribute&gt;()
yeah, but apart from taste it think the usage is also different. for my purposes overriding ToString() method is the fastest and easiest way of doing it with smaller number of lines of code added. but based on /u/Wiezy_Krwi comment here i read more about [Data Templating](https://msdn.microsoft.com/en-us/library/ms742521(v=vs.110).aspx) and i find it so useful for example achieving something like [This](https://i-msdn.sec.s-msft.com/dynimg/IC26558.jpeg) with a ListBox is awesome. 
Why do you wrap your repository with a repository? What are your goals?
Still, the shunt is probably the better way to go. You don't want to permanently change your application's default settings just for testing a scenario. Humans forget things.
The need for List&lt;object&gt; etc. should be very rare, or there is a problem in your design, in my opinion. You can almost always use stronger types.
 public interface INode { List&lt;INode&gt; DoTheThing(INode n); } public A : INode { public List&lt;INode&gt; DoTheThing(INode n) { var dNode = n as D; // or throw an exception, if that's appropriate for your use case. if (dNode == null) { return new List&lt;INode&gt;(); } var results = new List&lt;INode&gt;(); // do things that produce additional D objects and stuff them into list return results; } } public B : INode { public List&lt;INode&gt; DoTheThing(INode n) { var dNode = n as A; // or throw an exception, if that's appropriate for your use case. if (dNode == null) { return new List&lt;INode&gt;(); } var results = new List&lt;INode&gt;(); // do things that produce additional A objects and stuff them into list return results; } } // etc Hypothetically. It's more-or-less the Strategy pattern.
You're clearly not understanding what is happening here. The default setting is supposed to be false, and that is what the internal default is set to. When you run the application in debug mode and make a save, it still saves it persistently. In the Settings configuration page, there is a button called "Synchronize" which is supposed to reset this persistence back to your original defaults. There is a bug, however, causing it to *not* reset those defaults meaning, until I finally found the settings files deep in the hidden appdata folder, I could not reset these settings at all to do further testing. Sure, I could just take that setting out of my code for testing and replace it with a "false", but a.) that isn't fixing the actual problem, and I'm not interested in a band-aid and b.) part of what im testing is directly responsible for flipping that switch, so taking the switch out of the equation is a useless endeavor 
Patterns of enterprise architecture by Martin Fowler is a good book, it gives you a good set 'rule of thumb's to consider. Hop on Amazon and just look up some highly rated books. 'Refactoring' by Martin Fowler is also a good one I recommend to my team. Architecting applications by Dino Esposito is also one of my favorites and comes highly recommended.
That seems to be a large number of handles. Perhaps refactoring your app to release some would be the simplest way? 
Okay, I understand. Thank you for clearing that up, it makes a lot of sense now. 
I know there's a monadic one named Sprache, but I'm not familiar with the problem space and can't offer anything as far as suggestions from use.
It's a common practice. A typical scenario is for some framework code calling code will inspect an object for attributes of a specific base type (e.g. ValidationAttribute) and then call a method (e.g. .Validate(ValidationContext vc, object value). The method implementation lives inside the attribute code and works against other objects that have been passed in. https://github.com/ASP-NET-MVC/aspnetwebstack/blob/master/src/System.Web.Http/AuthorizeAttribute.cs Don't reference static properties/methods inside the attribute method though, pass the values in from the calling code. 
Sometimes smart people do very stupid things. Like making nuget packages for trivial things. It should boil down to "right tool for the right job", not "let's just use things because they're there". Some have a tendency to overcomplicate things, like trying to code for the one in a million case. Your best bet is to simply ask him why he feels that a certain thing is the way to go, and see if there's a valid reason behind it. 
Besides what /u/dazzford said, [this](http://stackoverflow.com/questions/9723470/whats-the-upper-limit-on-gdi-objects-for-one-process-in-windows-7) might be helpful to you.
No, it's not much more expensive. It's **hardly** any more expensive. TimeSpan is a struct, so no allocation happens. `Thread.Sleep(TimeSpan)` just calls `Thread.Sleep(int)`. So you merely have a few method calls more, but **much** more expressive code. Besides that: You're using fucking `Thread.Sleep`, so performance clearly does not matter at all.
That's generally the case in other domains, too, I find (I haven't done much UI work). Detecting and preventing the problem is usually more effective, easier to read, and more efficient than trying, failing, and catching the exception. And, the rest of the time, Hjelberg's comment about the ratio of `try { } finally { }` to `try { } catch { }` seems fairly on target.
I remember there was a library called Ironic, which lets you define a context free grammar and parse it, but I haven't actually used it.
Thank you for this tutorial! I have been waiting for this stuff a long time!:)
I'll review those and make the changes I see fit. Thanks for the advice!
Shouldn't `ConfigureAwait(false)` only be used when the method it is used within accesses only local variables, or thread safe things? Using `ConfigureAwait(false)` is very often incorrect - `ConfigureAwait(true)` *is* usually always safe, unless the caller does something silly like synchronously waiting for the task to complete on the calling thread. It's practically impossible to deadlock unless you're doing something wrong.
Haven't used Parslet but [ANTLR](https://github.com/tunnelvisionlabs/antlr4cs), [Irony](http://irony.codeplex.com/), etc. work pretty well. That said, I don't know the grammar you're using (LALR(1)? LL(1)?) nor do I know your use case exactly. If you just need a simple grammar then I go with Irony usually. If I need to compile it down, add multiple passes for optimization, etc. then I usually go ANTLR. If I'm doing something where I need to compile down to the CLR then combo of ANTLR to get the tree and convert to a C# equivalent and [Roslyn](https://github.com/dotnet/roslyn) to compile down the rest of the way.
&gt; What if tomorrow, they decide they want to switch from SQL Server to a NoSql solution. Or maybe the company doesn't renew their license contract with Oracle and suddenly every application in the company has to switch to SQL Server in a year to avoid $1M in contract extensions...
We created a markup language specifically for this application. The application is a configuration life-cycle management application for text based configurations for appliances and network hardware, the markup was created to ensure flexibility. 
Thanks for the feed back, I will definitely have a look at each.
I can't speak to setting up unit testing for Xamarin, but I can comment about unit testing on device, especially for Xamarin/Mono. I've run into compiler and/or runtime bugs that didn't exhibit running on desktop (full .NET runtime), and ultimately there's no substitute to making sure the code you wrote executes as expected on the device/platform it's to be run on. Sometimes its even as simple as a `MissingMethodException` where the DLLs on the target platform don't have a particular method implementation that existed on Windows. That said, the cycle time to run a test and get results, and how you work with and debug those results can really tank trying to run it on device. In the past, I've setup simultaneous unit testing (using the Project Linker extension and sharing code between platforms) so during development and building, I can run the tests fast on-the-fly within Visual Studio and debug logical (code bug) issues easily. Then occasionally, say, before pushing commits, I'll take the time to run all the tests on the target platform to make sure I don't run into any issues at runtime. Also serves as a good sanity check when debugging issues found by users/testers. (e.g., "How are they getting this bug? My unit test running on my desktop works fine!")
I just finished. This was actually rather fun and easy. I'm way out of practice with code, but this was a lot of fun to do. My teribble GUI: http://imgur.com/a/FyRcF Code is at: http://pastebin.com/W4wQz8a7 
Yep, it's really good! It's a parser combinator 
FParsec is F# and is my favorite .NET parser library hands down: http://www.quanttec.com/fparsec/tutorial.html
Great tutorial
Thanks!
foreach loops are [magic](https://msdn.microsoft.com/en-us/library/aa288257%28v=vs.71%29.aspx?f=255&amp;MSPPError=-2147217396). Basically what happens is your compiled code looks something like this: List&lt;int&gt; ints = new List&lt;int&gt;() { 1, 2, 3 }; IEnumerator enm = ints.GetEnumerator(); while(enm.MoveNext()) { int i = (int)enm.Current; Console.WriteLine(i); ints = null; } Console.WriteLine("DONE"); It's easy to see here how you implicitly capture a reference to the list via its enumerator so even though `ints` is null, your code will still work. As you might expect, if instead of setting it to null your loop body appends to the list, it will fail just like modifying a foreach loop.
It seems like the SRP (single responsibility principle) may be violated here. Can you share more about why InstructionController needs to talk to ScheduleService?
This is the correct way to do case-insensitive string comparison. Unfortunately, most people use "ToUpper()".
$1M? Must be a pretty small shop.
Why oh why are you not using the built in Async functionality? 
There is another option which may be appropriate(I'm not recommending it, just pointing out the option). You could move the shared function to a separate class and have both the Instruction and Schedule services call it from there.
&gt; I'd rather just inject one service in the instructions controller That seems like a silly limitation. As long as the controller is still cohesive, there is no reason to limit it to only referencing one service class. *** &gt; •Call the method from the schedule service from the instruction service and expose a method in the instruction service to do this. (I feel this breaks OOP and I'd feel dirty doing it.) That's fine. And don't worry about "breaking OOP". Your service classes aren't OOP-style classes in the first place, nor should they be. Ideally they are stateless (or nearly stateless) container that you can put functions in. If this happens a lot, you can also create a base class that is shared between multiple services. Then push the shared method into it. I don't do that lightly, but sometimes it is the cleanest route.
&gt; •Duplicate the one method in my schedule service to the instruction service so that only one service is needed in my instruction controller Don't do that. You'll never remember to keep the two versions in sync and you'll regret the decision later.
It is very common for controllers to rely on multiple services. 
You can and you can't do this. I actually kind of hope I missed something, this is technically wrong, and someone will correct me. But here's what I think. While Xamarin uses Mono, it is a different Mono platform than what runs on your desktop, sort of like being a different PCL. That's why the runner runs on the device: if it's going to reference Xamarin bits it needs to be on the right platform. It seems bizarre until you think that for it to run on Desktop, there'd need to be a Windows implementation of MonoDroid, and that's even more bizarre. When you run tests from the desktop, you'll be on a non-Xamarin platform. That means any dependencies on Xamarin libraries probably won't work. What you /can/ do about it is have a separate library in your project with the rule "cannot reference anything platform specific". You can test [i]that[/i] code without using a device. For things that need platform logic like, say, GPS, you'll need to create an interface/abstract class in the library to represent it and implementations in the runtime/test libraries to provide the concretions. Which, if you're targeting multiple platforms, you were probably doing anyway. And this does introduce potential problems as your unit test references on desktop won't be [i]exactly[/i] the same as the production references. In theory it should be the same code. In practice, that takes some luck. 
So a good example is in your frmMain.cs class. I would have made an I/O class to shorten the methods up a lot, and improve readability. Then I'd have a class to store the NICs and IPs, and their associated data. This would help encapsulation a LOT. Then btn_saveClick would naturally pass the results of a method to a method in the IO class. Super tired right now, but those are some reasonably simple examples. PS: Don't pluralize your class names. "IPs" and "NICs" as class names breaks convention in probably every language.
Look at Irony. I maintain the NuGet package. It's easy and quick to use.
Out of curiosity -- what about YAML or Json didn't provide enough flexibility?
What you have written so far looks good to me, what you probably want to change when you get more code though is to move non-ui logic into helper classes, similar to where you were going with IPs.cs. Also I would avoid a namespace named classes because it's redundant when almost everything in c# is classes. You said that it was hard to extract methods from your form and put them in other classes, a reason for that might be that you try to extract code that does to much and have a lot of dependencies. Edit: to answer your question: your codebase is to small to really benefit.
You haven't come in and answered a single question I've asked. Rather you've sat here and ignored my question and told me to do some other random procedure to get around the issue. That isn't helpful.
I'm showing you a better way. Don't rely on a broken tool.
This is not a tutorial. This is a snippet of code which is bad. Blog layout is terrible, naming conventions are terrible and overall code structure is terrible. I would recommend you to learn about it before you teach others. 
&gt;ignore the actual problem and do something else no. go away. you're not being helpful. I've fixed it myself now. You're nothing more than bothersome
Just quit replying if I'm so bothersome
k
Thinking to self: self, will he do it?
Pretty much the example I was thinking of right there.
You need to recreate p each time
Personally, I liked the giant thumbs up and down. :) In your code, use directory.**EnumerateFiles** instead of directory.**GetFiles**. (When you get a large number of files, you'll see the difference.) Line 39: You might want to look into using an asynch/await Task.Run() so your gui doesn't lock up while doing the file search. Line 57: the .Count() shouldn't be needed for the foreach loop. Line 121: I haven't looked into it, but I think "return fi.Name.GetHashCode()" will be shorter?
Thank you for your response. As far as I understand, OOP is that one should make objects that may be reused to reduce redundant code. Thus the focus on inheritance and polymorphism. Turning that into practice with small projects I find quite tricky, but even so I know I need to expand my knowledge. Thank you for your input.
Definitely sounds like HW to me as well. Check into async and await || TAP and there are others... But, I agree with u/Tangled2 you should use the built in async functionality since dealing in the classical Thread handling methodology is just a pitfall these days compared to the more robust applicable paradigms we have implemented in .net now. Good luck.
Thank you for you detailed answer. The plans was the following: CLASS: IPs - - Method: LoadIpProfileFromFile() - Method: DeleteIpProfile() - Method: SortIpProfileByIpOrDescription() - Method: AddIpProfile() - Method: SaveIpProfile() \. I was starting of with the "LoadIpsFromFile() when I got into the struggle of getting that List&lt;string&gt; to a comboBox. Might be that List&lt;string&gt; isnt the right tool to get the job done. Again. Thanks for your response. 
Thank you for the detailed response. The program is a mess and as you mention the readabiltiy is quite the scarecrow right now. I'll attempt to make changes towards your answer. I've tried hard to make use of classes but I believe I've failed to plan properly. Again, thank you.
Thank you for the input. Appreciate it. You mentioned: "a reason for that might be that you try to extract code that does to much and have a lot of dependencies." And I completely agree. I try to achieve too much with one method and that might be why I fail to get anything usefull out of my classes. I'll change the classnames too. Again, thank you for your response. 
You haven't modified the collection. You've just removed *one* reference to it. The collection itself is unmodified. If you had saved another reference to the list, and tried to add an element to *that* one, it would throw. List&lt;int&gt; ints = new List&lt;int&gt;() { 1, 2, 3 }; var other = ints; foreach (int i in ints) { Console.WriteLine(i); ints = null; other.Add(99); } Console.WriteLine("DONE");
Any idea when/if Irony will be ported to .NET Core. I'm actually working with the requester on choosing a parsing framework, but ideally we would want something that is supported by .NET Core so that it can be deployed to Linux.
Probably never unless you do it.
Try doing the same with a normal for loop. foreach is a bit special
Go have a look at the Windows event log. There should be events from the service control manager. 
where do I find that?
basically the only custom code there is if (curData.DbConnectOK()) { ServiceBase.Run(ServicesToRun); } else { Environment.Exit(1); } and it's goes straight to the "ServiceBase.Run(ServicesToRun)" part
For Windows 7: Start -&gt; Right-click Computer -&gt; Manage -&gt; click arrow next to Event Viewer -&gt; click arrow next to Window Logs -&gt; System There's probably an easier way to get to it, but this works. 
Whats in the start method of your service? You shouldn't run your code here, this method should start a new thread in which you should run your code. The start method should complete within a few seconds. 
Sorry, I don't have the knowledge to help you troubleshoot your problem. I was just responding to your question of how to see system events.
&gt; For example, in a prototyping phase you might stub out a repository and simply have it write to disk instead of the DB because you can more quickly iterate on the saved data by storing it as JSON while the data set is small and replace the implementation with real DB access later, once the dust is settled. You should throw away a prototype after building it ;) But that aside, why keep a more complex architecture around just because you had to prototype something? Doesn't make sense. Mind you, software often has a long life: it's maintained for years. All that time you have to live with an abstraction that has no reason to be there other than it was helpful during prototyping. &gt; Also, it's not unreasonable to expect you might change databases or ORMs in the future (for example, switching to or from EF/Dapper). In this case, having wrapped your ORM will save you time converting every piece of data access. No it doesn't, because of what I said: no ORM is the same. myCustomer.Orders.Add(myOrder); // with which ORMs is the following true after the line above var isEqual = myOrder.Customer==myCustomer; Simple example. This can cost you a LOT as it breaks at runtime. There are many of these subtle differences, like: var customers = from c in ctx.Customers join o in ctx.Orders on c.CustomerId equals o.CustomerId where o.EmployeeId == 2 select c; Which ORM gives duplicates in 'customers' ? Doing a count on that set in memory will differ. Sure you'll test the crap out of your code, but you will miss these little things. There's no way you can predict which differences will show their ugly head in your code. This means moving from one ORM to another or other ways of doing data-access has deep consequences, almost like changing your UI framework. You won't do that for simple reasons but only if you really really have to. Which is rare. Same goes for databases. Every DB can do Crud. Not every DB can do the SQL you have in a view you use, or efficient paging you need, or sequenced fields based on a shared sequence. The little details will break your app when you move. Not to mention not every ORM supports every DB or even if they do, in full. These wrappers are nice ideas on paper, no-one will need them in practice. 
Services default to the LocalSystem account, which is a "super user". The only reason you'd change it to something else is when you want to grant a specific privilege or use a limited account. https://msdn.microsoft.com/en-us/library/windows/desktop/ms684190(v=vs.85).aspx 
I don't have a whole lot of experience with Xamarin, but I created an app w/ unit tests about a year ago. It used MvvmCross and we had the solution split up with a Core project containing all the business logic. I created a new library project using 4.5 framework and added NSubstitute / NUnit and created the unit tests around our "Core" project. So it is very possible to have this run on the desktop during build.
Can you provide a bit more of an example? What, exactly, do you need from Element2 in Element4? Are you sure that the thing is available when the bindings are resolved? A big help debugging bindings (for me at least) is to use the PresentationTraceSources.TraceLevel attached property, which will spit out a mess of binding information to the Output window of VS. {Binding ElementName=foo, PresentationTraceSources.TraceLevel=High} What output do you get from that for your various attempts?
I'm writing a .net core app at work, and found MailKit to be easily as simple to use as System.Net.Mail, with the added benefit of it actually working!
In my test classes I have to mock up two services. I have two parameters on the constructor of my controller. I guess mainly it's my OCD at keeping stuff clean and tidy
Congrats on the new release! Also, when the heck did you start working for Microsoft?
or when you install it
Where are you seeing that dependency?
Yea, man. There is just too much wrong with Java. The way Oracle is going it will be dead very shortly. It will be thought of like Flash - the tool we didn't need but couldn't hardly live without for a time. 
Wow, that's gotta be exciting! :D
Are you using an Ajax request to query your web api?
Just troubleshooting using Postman - so Http requests!
It sucks because it is extremely verbose. While C# has been getting 'cooler' over time ( it has an Elvis operator now) java has been very slow to evolve. But the death of Java EE would affect everyone, irrespective of what tech you use in your day to day work. Its an interesting time when java( oracle) is evil and c#(MS ) is the good guy. A cross platform Visual Studio would be a checkmate to Java. 
Here's a [link](https://technet.microsoft.com/en-us/library/cc756344\(v=ws.10\).aspx) to the Technet article about the ID 7000 error, it has a couple of tips and a couple of further steps for troubleshooting. (I can't help programming-wise, but I'm used to googling error codes.)
Off-Topic: I love the Friends themed Getting Started for MailKit.
So you are saving and reading in quick succession. And logging in every call? Sounds like a threading issue maybe? You have multiple instances accessing the same record, reading and writing. Each time a new thread is created a new log in is made. This is just a theory. Check the scope, lifetime and threading concerns around your DB service maybe.
Java's type-erasure implementation for generics is just awful. Something&lt;T&gt; just becomes Domething&lt;Object&gt; at run-time meaning things the new() constraint couldn't be implemented and I think there aren't any generic constraints at all. Finally you cant have two generics with different generic type parameters.
They discontinued support for XNA game engine and passed it along to their community as their responsibility.
/u/blgrnboy Make it happen. 
Wait... Elvis operator? 
Dude works for Xamarin, so I guess he ended up there when Xamarin got bought.
Why fighting to be superior to a competitor, instead of fighting to be a good tool Why opposition, no need to start a war, you are free to use what ever thing you want, java is fine, you write once, and it runs everywhere, it's free And Kotlin solved every problem you may have had with java, FYI
Oooooh I get ya :P
Here you go. very simply service example. https://github.com/jcanady20/TestBench 
Are you re-using the context across all requests, or creating a new context upon each request?
If you're wondering why your question has no replies, it's probably because it doesn't seem to be relevant to a C# programming subreddit. You might want to find a subreddit related to Windows Media Player for a question like this. 
That's ternary tho
no particular order: https://twitter.com/DeborahKurata https://twitter.com/SimonCropp https://twitter.com/julielerman https://twitter.com/shanselman 
Thank you this is just the overview I was looking for.
Thanks
Nick Craver 
https://twitter.com/msdevshow
Jimmy Bogard Jeremy Miller Ayende Dan Tuppeny Scott Hunter Sayed Ibraham Myself but good luck on that one
I didn't know the top three, thanks for that!
Jimmy is a good follow. His blog posts and opinions avoid the ivory tower bullshit but are still very real world based. That's kind of hard to find. 
yes.
Sorry I neglected your actual question: I would say knowing design patterns inside and out will enable you to go from where you are now to where ever you want to be. I have found otherwise competent programmers who lack exposure to design patterns tend to introduce more bugs into a system or project than they are willing to fix.
Reusing I'm pretty sure I use EF wrapped in Unit of Work/Repository Pattern My MVC app has been using this without issues
The default behavior of EF is to cache the entities retrieved. Besides that, the `DbContext` is designed to be short lived. Ideally you would create one per HTTP request. You should NOT just have a single instance used across all requests - that's a disaster waiting to happen.
Learn how to test and debug your code. Like inside and out. Also investigate DRY and SOLID. I really like Clean Code by Bob Martin as a book. Spend some time learning functional design as a counter to OO. (favor compositions over inheritance). Learn relational databases inside and out. Never rely on having a dba to do that for you. One part of coding is "getting things done", but doing them well will get you farther. People don't complain about missing features nearly as much as they complain about bugs.
Maybe it needs a config file?
&gt; operator? Exactly
I like the SnallWorld word for this, "decline".
How is this related to C# again?
Look up Onion Architecture. Many N-tier devs (myself included) spend their entire career trying to figure out what actually goes in the business logic layer. Onion makes it explicit and vital to isolate the logic from the infrastructure. I've been developing for over 20 years and this architecture was a game changer for me...a little too late, as I'm past the apex of my career (management). A great companion to Onion is the book Domain-driven design, by Eric J. Evans. It focuses on the isolation of business logic conceptually, which plugs right into the Onion Architecture as a framework.
The whole scrum board was a custom implementation where I literally rendered everything manually (post-it's, dividing lines, ...), for the drag and drop I just did some simple coordinate checking on click and when releasing I checked what coordinates the mouse was at within the canvas. Nothing special, probably very inefficient but it was fun :P
1.) Browse around the YouTube API for information on get_video_info 2.) For the selected video, open the get_video_info file and search for instances of audio%252Fwebm 3.) The link to the audio stream for the video should be close by that you can download and use Disclaimer: Only download audio that you have rights to
Well, the application is written in C#
Removed: Rule 3. Maybe try /r/dotnet, or maybe some of the freelancing/hiring subreddits, or maybe give it a shot yourself. (You can do colour themes in Visual Studio and there are extensions that can help you with that too I believe).
Some suggestions and comments: * Goto statements are simply unneeded if the architecture is well thought out in advance. It's usually a huge code smell, but it's a very tempting trap to dive into as an amateur before you start learning proper design patterns. Generally I see amateur programmers trying to use goto instead of simply learning how loops work. * Consider breaking out each thing into its own file. Having everything live in Program.cs is a bit of a nightmare when you move into situations where you are trying to merge changes in source control, especially with other developers. It also makes it easier to find the section you want since it will live in its own file. * You are correct in assuming Convert.ToString isn't needed. [Console.ReadLine](https://msdn.microsoft.com/en-us/library/system.console.readline(v=vs.110\).aspx) returns a string already: answers = Console.ReadLine(); * Storing the answers in an array isn't what allows you to check whether the answer is upper or lowercase, your if/else block and use of the logical OR (double pipe, ||) operator is what does this. * Instead of checking both lower and uppercase equality, just use [string.ToUpper](https://msdn.microsoft.com/en-us/library/system.string.toupper(v=vs.110\).aspx) or [string.ToLower](https://msdn.microsoft.com/en-us/library/system.string.tolower(v=vs.110\).aspx) on your answer, like so: if (answers.ToLower() == "n") //do something * The reason it doesn't actually print anything when you answer jibberish for the quiz game is because there's no flow in your program to check for that. The easiest way to support a default output would be to just throw in an "else" block at the end: else { Console.WriteLine("Incorrect response, please try again."); } * Consider swapping to Visual Studio Community. It's free and Intellisense should help you out a lot.
Awesome video! I remember doing something very similar with C when I first started programming. You're really doing well so far. Karathos gave some great suggestions on the specific problems you're having. On a more general note, try using the debugger to step through your code if you're having issues. Learning to use that tool is incredibly important. Nice work! PS - One good way to crash a program is to try dividing by zero. You'll have to outsmart the compiler though because it won't let you do "int crash = 1/0;"
Great answer. Best part is that these are all learned qualities. I actually just wrote some software that I was pretty excited about and when I showed a prototype/proof of concept to the CTO he wasn't very fond of it. It's good to be able to accept criticism. 
Even better, just throw new NotImplementedException("do something here in the future!"); That way, you'll know exactly why there's an error (you're coming back to it), and it'll have a nice reminder message if you ever call it.
Have you worked in any other language? You could try something like scalla and learn about actors using akka. Try implementing a Web chat program. 
You should look up how to calculate expressions using postfix notation. It's not very complicated and you can avoid the "enter 1 number, enter another number, enter operation" (which is actually essentially postfix). The basic gist is that you push numbers to a stack and when you get to an operator, you pop two results and then perform the calculation and push that back to the stack. So `3 4 + 5 -` would be `3 + 4 - 5` or `3 4 - 5 *` would be `(3 - 4) * 5`. This is a good exercise because it'll introduce you to a common data structure called a stack. A stack is what it sounds like, you're stacking things on top of each other and you can only access things on top. So like a stack of books: you put one down, then another on top of it. You can only access the one on top. This is known as "first in, last out" (FILO) since the first object pushed will be the last to be popped. A related structure is a queue which is the same concept as a line of people at a bank. The first person in line is the first helped. This is known as "first in, first out" (FIFO). You can go further than that and parse infix notation and perform the calculation. This is a better learning exercise IMO, since it'll prepare you for CS courses like data structures and compilers. The algorithm can be implemented with stack knowledge, though. I suggest building the parser by hand and then look into a tool like ANTLR (basically builds a parser for ya). Just curious but why are you using Xamarin Studio on Windows? Check out VS community. *Really* hard to beat VS2015 as an IDE. As a learner, I wouldn't worry too much about which IDE to use but VS is really nice. Overall though keep going at it. Great way to learn is to just do it and figure out how to do things "better".
Just because your program is written in C# it doesn't mean it's a C# question. You're trying to get media player to do something, so it's a media player issue. Once you know *what* you need to do in media player this is a good place to ask about how you'd go about doing it in C#. Being able to identify the problem domain is an important skill in programming.
audio%252Fwebm%253B%2Bcodecs%253D%2522vorbis%2522%26url The link that follows is the URL. Note that you will also need the signature.
I have been doing some gpu programming with Cudafy.net, but it's very limited when compiling to opencl. Do you have any good resources on gpu programming for opencl or any other way that is not dependent on a single vendor?
I don't have experience with opencl, but you could go the route of calling native C++ AMP. It's not pretty, but it works.
Why not use Akka with C#?
I don't think C++ interop is the way to go for me.
I do not recommend performing case insensitive comparison by using ToUpper or ToLower. If you must, use only ToUpper. For one, it causes an allocation of a new string just to perform a comparison, which seems a little silly and is a bad habit to get into. For two, it may fail in other situations where unicode characters outside the ASCII subset are used - not all languages have reversible letters. The ["Turkish i"][1] being the best example. Instead, I recommend getting into the habit of using the String.Compare static function with the proper culture treatment parameter. No allocations, and it always works. Write an extension method if you want to make it easier to invoke. [1]: https://msdn.microsoft.com/en-us/library/ms973919.aspx 
Apologies SaveChanges is invoked at the end of each unit of work thus ensuring the lifetime of the dbcontext is short lived
Shit your comment is making me do some serious soul-searching 
Checkout http://hangfire.io/
[removed]
Just a wild guess. If you can't set the directory programmatically, the only other way I can think of is an entry in the app.config or an XML config file specific to this library.
Unity is probably your best bet.
Does he have an asset store? The reason I like Unity is because I don't have to learn 3d modeling. I can get models from the store. Does MonoGame have something similar? 
Thanks I'll check them both out.
Thanks I'll take a look at the tutorials and see what I find.
Thanks. It no longer return error but the value does not load and the checkbox remain unchecked. I checked regedit.exe again and the dword was 1 whwich means true. is there something wrong with my code?
Thanks, I'll check it out when I get the chance. 
Did you not learn from your mistakes last time your videos were removed from this subreddit? Your entire post history is you spamming your youtube videos in a number of subreddits, this definitely violated Reddit's spam rules. https://www.reddit.com/r/csharp/comments/4qi7tj/writing_a_multiuse_application_in_c_1_ptx_coding/d4t8msk
I agree with the other guy just use Unity 5
Thanks! EDIT: I started p everytime i typed a command and then closed it, but i need to keep all the resources attached to the process. Is there a way to save those recources?
Yeah, but what's the value of `rkey.GetValue("DecDebugInfo")`? Try outputting that and see if it's the value you expect it to be.
If the message box says "True", then it's probably not an integer. Is it a string with the text "True"?
If you're making a 2d game, I'd suggest Duality. If you're making a 3d game, I'd suggest Unity3d. They have similar editors, but unfortunately, Duality doesn't have cross-platform support. But if you're feeling up to it... https://github.com/AdamsLair/duality
IntercoolerJS and cut out all the bullshit. Aurelia if for some reason IC couldn't cut it 
&gt; I don't know much of javascript, just a little of the basics If you are not familiar with JavaScript, I would recommend getting really comfortable with that before delving into any frameworks. I know frameworks are catchy and they look good on a resume but if you don't know the underlying language, it's just going to cause you more pain in the long term.
Looks like you have a proper boolean value then, that's good. If you assign it to your checkbox and it's still not changing, then you probably have a problem elsewhere in your program.
Always stick with ones that have biger community, meaning Angular. Ok, some will say that React is a better choice, bit its not a full framework like Angular.
 public static event Action SafetyShutdown { add { lock (eventDispatcherSyncObj) { safetyShutdown += value; } } remove { lock (eventDispatcherSyncObj) { safetyShutdown -= value; } } } internal static void TriggerSafetyShutdown() { var safetyShutdownLocal; lock (eventDispatcherSyncObj) { safetyShutdownLocal = safetyShutdown; } if (safetyShutdownLocal != null) safetyShutdownLocal(); } Auto-implemented event assignments are thread safe by default, no need to implement manual locking. I also don't see what the lock in the second method is supposed to do, since reference reads are atomic.
Interesting read. When's part two out?
I need to look into it again, but that wasn't always the case. I had to implement this at a job about 10 years ago because when you add your second callback, the delegate gets changed under the hood to a linked list, and is no longer thread-safe. 
Fair enough. I am trying, each time, to reduce the pontification in each post; though it's hard as the thorough (but wordy :D) vernacular is something I feel is important for good explanations.
Removed: Rule 8. As /u/Canthros stated, if you are feeling harassed, report the user to the moderators and/or use the built-in reporting features. If you feel the user is in violation of Reddit's rules, then report him to the Reddit admins as well. Calling people out like this is not worthwhile and your conduct towards him is not admirable either.
You can also create your array then shuffle it. A Fisher-Yates algorithm is not very hard to implement. You can try mine on [.NETFiddle](https://dotnetfiddle.net/omUm96). The code was updated after a review from /u/AngularBeginner. Feel free to add more improvement! using System; using System.Collections.Generic; using System.Linq; public class Program { public static void Main() { var array = Enumerable.Range(1,9).Shuffle(); //array.Shuffle(); foreach (var item in array) Console.Write(item); } } public static class Extensions { // Fisher Yates // picks your favorite or make yours // To use like Enumerable.OrderBy(): // var foo = array.Shuffle(); public static IEnumerable&lt;T&gt; Shuffle&lt;T&gt;(this IEnumerable&lt;T&gt; collection) { var list = new List&lt;T&gt;(collection); var random = new Random(); for (var i = list.Count; i &gt; 1; i--) { var j = random.Next(i); var tmp = list[j]; list[j] = list[i - 1]; list[i - 1] = tmp; } return list; } // To use like List&lt;T&gt;.Sort(): // array.Shuffle(); public static void Shuffle&lt;T&gt;(this IList&lt;T&gt; list) { var random = new Random(); for (var i = list.Count; i &gt; 1; i--) { var j = random.Next(i); var tmp = list[j]; list[j] = list[i - 1]; list[i - 1] = tmp; } } } output 782934165
Perhaps you can create a class called NetworkInterfaceController and InternetProtocolAddress? IPA class has a constructor which accepts an IPAdress instance and the NIC class accepts a NetworkInterface instance. From there, you can add the methods to change IP, update DHCP etc to the classes themselves and keep separation of concerns. That way in your form class, your code can be limited to updating GUI.
I'm actually talking about the internal implementation of delegates. As you say, it was a long time ago (and in a galaxy far far away), and might have changed since then. But when you add a callback to a delegate the first time, a object is created to hold that value. When you add your second and subsequent callbacks, that object gets turned into a linked list, and your first callback becomes the first item in it. At invocation time, the runtime walks the linked list calling each callback in turn. And that isn't (wasn't) thread-safe.
That doesn't sound right. I don't see why it would be a linked list, especially since it would be constructed in the wrong order.
Perfect answer. I've chosen React over Angular 2 because Angular 2 still needs some time to get the same level in community support and examples for integrating with various frameworks, e.g. threejs. By the way: JSX is **the only** sane way to write HTML. How can you assume React has forced me into it? Seriously: JSX is no problem at all. Support for JSX is available in all of the famous JS IDEs like WebStorm, Sublime, Atom, VS Code ...
As far as I know it uses a simple array, but delegates are immutable anyway, so it doesn't really matter for thread safety how the list is implemented. A new object isn't just created on the first add, every subsequent one creates a new delegate instance representing the combination of the two.
My eyes! Here, have some .....,,,,,,,. Head First C# is a popular one. Also, there is a cool [interactive tutorial](https://www.microsoft.com/net/tutorials/csharp/getting-started) for beginners.
As a beginner into C# who has purposefully steered away from MT applications, I found this very interesting and fairly easy to follow. A lot of the concepts related to MT (and even delegates/events) are something I'm still very new to, but I enjoyed the read and am looking forward to later parts. Thanks a lot!
Support for JSX is required. Other frameworks do not force IDEs and other tools to know about them. This is why I call it poor engineering. After all you couldn't use TypeScript with JSX for half an year because it needs specific support and the syntax clashes with typescript's syntax for casting. TypeScript needed clever magic to make it work. All this because they refused to put quotes around the html in jsx or let people put it in separate files.
I don't know if that's possible, but what you *can* do is just hit shift-enter when everything is in order and you want to go to the next line.
As I can see EF Core SQLight provider (Microsoft.EntityFrameworkCore.SQLite) have dependency on Microsoft.Data.Sqlite so I guess this package should be all right.
Seems inefficient, but ok. 
&gt; it's saving urls to IE's history, when I don't want it to for reasons. For reasons. (͡ ° ͜ʖ ͡ °) Here's an article on how to manipulate the history: http://www.codeproject.com/Articles/7500/The-Tiny-Wrapper-Class-for-URL-History-Interface-i
Thanks man, this was a great help.
Microsoft Visual C# 2013 Step by Step by John Sharp. Do a web search for the C# Yellow Book - it's a free ebook that explains stuff quite well (though it has a lot of irritating 'humour' if you ask me). The C# Pocket Reference is good too. You can get an older copy (e.g. C# 5.0) pretty cheap. It is basically a summary/reference version of the C# In a Nutshell book (which is huge and pricey). If you want to save money, go for C#5.0 rather then the newer C#6.0 books, as you'll be able to find 2nd hand copies way cheaper (the language is the same, C#6.0 just has a few new bits and pieces you can easily find about online).
Indeed. I will edit.
I agree, the guy is a massive faggot and you should see the very mature comments he replies to me with LOL. He looks like hes pretty autistic in his videos.
Does it matter that much? I used 2013 and 2015 and it didn't feel/look different since i'm not doing the most advanced things, so a novice isn't going to run into problems I think. Maybe some structuring has changed for templates and creating new files, but it's still really intuitive. 
Hi all, Just an update ... have found the issue. Turns out Dispose wasn't been invoked ... Due to incorrect configuration of DI (unity) Thanks all for your help! Keith. 
Go with [Vue](http://vuejs.org/). Easy to [learn](http://www.vuecasts.com) and easy to use. If you don't find vue to suit your tastes, then i will recommend react. Angular 1 is quite popular but it has many quirks. also many of its tutorials are obsolete. Angular 2 is not even released. Its official tutorials and docs *force* you to learn typescript and use RxJs. 
Removed: Rule 4. Tonnes of tutorials out there on how to work with GridViews. Make an attempt and if you still have issues post a more specific question outlining what you tried and what did/didn't work.
Can't test currently but I would guess the javascript is a problem. Normally WebBrowser Object is a IE7 engine.
The page works fine, but what you are trying to do is wrong. I would guess that the data you are retrieving is being escaped by part of the process, or that you're not displaying it correctly. Basically, somewhere along the line, a &lt; is converted to &amp;amp;lt; , and so on for every tag. That or you're displaying it inside a control that doesn't understand html However, what you're trying to do is likely to be , at best, violating the terms of service, if not breaking a few laws too. If a site hasn't got a publicly accessible API, you're probably not supposed to access it programmatically.
"Solved" so for any one reading this looking for the answer, I wasn't able to get the windows media player to go transparent but I was able to find a work around. I had to use adobe after effects thought. Use adobe after effects to render the video as a PNG sequence (you could later use photoshop to combine it into a gif, but i didnt do that so it might have some problems), save the PNG sequence to its own folder. On the form have a picture box, have its back ground set to transparent or to what ever the form's transparency key is. Youll need a method that iterates through each picture of the PNG sequence, use W = 1000/F where w is the amount of time the program needs to wait before changing the picture and F is the desired frame rate, to determine how long it needs to wait before switching pictures. After the method changes the picture you'll want to call GC.collect() to run the garbage collector, the program will start taking up alot of memory if you dont. Run that method in a new thread or else you wont be able to have you program do anything while the "video" is running. For sound I guess you could just have a WMP start playing audio when the video starts playing but youd have to sync it up
This one really made me walking away with a better understanding of how c#. Most books I struggle getting through. I went went through the whole book. 
And if you're really sick of IE, why not embed Chrome? :) https://github.com/cefsharp/CefSharp
In Visual Studio, the Home and End keys will move you to the beginning and ending of the line, respectively.
Well modern frameworks use either typescript or es6 which have classes finally which means rudimentary type safety. Angular 2 programming requires little classical JavaScript. They use a custom API for most stuff which although verbose is simpler than callback hell
I have programmed in C(++)/Java and Assembler, next to that PHP and Ruby aswell but never really liked that, might look into Akka :) Thanks!
Elasticsearch really looks interesting! I have some basic knowledge of Angular but I am not a fan of how it is currently structured, however Angular 2.0 makes up for that so far! I know refactoring legacy code is a 'big' thing as old systems need an upgrade and that's probably what starters get to do as their first job but where would one look for older software systems to fiddle around with? :)
Here are my two recommendations based on what you're starting with: https://amzn.com/1430249358 - Beginning C# Object Oriented Programming by Dan Clark It's circa 2013, but that shouldn't matter too much. The point of this book is to get you understanding the fundamentals which haven't changed a bit in a while. I can't speak to the effectiveness of this book, personally (I came from C++, so for me it was more about learning how inheritance patterns in C# differed and this book wouldn't have worked for me), but I've recommended it to other people looking to get a start in programming and it has been well received. The goal with this book is to get to the point where you can read a serious book on C# and this provides that pretty well. After that, head right over to: https://amzn.com/1491927062 C# 6.0 in a Nutshell - by Joseph Albahari and Ben Albahari (O'Reilly Press). I own every edition of the C# in a Nutshell series and have read each (speed reader - lots of skimming/scanning since each edition has a lot of repeat content). I'm a huge fan of the "in a Nutshell" books - the "signal to noise" ratio of these books is very high - they're excellent books for people who prefer/are best at learning via books - think of it as an "AP Course". It'll take you a while to get through (the last guy who successfully completed both took 9 months front to back at about 20 hours a week using a strategy that involved reading the book about 4 times [topic for another post] -- it was for a job, so he had no choice but to learn). When you're done, though, you'll understand a large percentage of C# code and be able to write many different kinds of applications. From there, it's time to head toward the particular discipline you'll be developing most frequently with (ASP.Net MVC, etc) or target certain areas (multithreading/thread safety is usually a good place to go next if you have no particular target).
*Nuts*, you're making me want to change my recommendation. I forgot about this book! A coworker of mine who blows through books indicated this was a really good choice due to the way it is organized. I haven't, personally, read it, but I trust this guy's assessment as a fellow book-junkie.
Agreed - 2013 or 2015 at a beginner level isn't going to be much different. I'd pick a good book that's a few versions behind over an inferior one that's very up-to-date. Other than the ?. operator (which is really easy to understand and might be better learning later since it somewhat abstracts away the *null* problem), there's not a lot that'll be missing in a 2013 book.
No. .NET Core is the next version of the .NET framework. EDIT: okay okay. Sorry guys. Point is, it's definitely not just for IoT
Get C# players guide 2nd edition - best reviews of any C# book on amazon. Ive tried other books and this one is the best in all regards, perfect for beginners all the way up (its like a 380 page book). U can find the pdf online for free easily If u wish to do that too..
Microsoft open-sourced the .Net framework and put it on Github. It used to be called .Net 5.0 or some such, but around the time they open-sourced it, they renamed it Core. It *is* .Net now. One of the nice things about .Net Core is that you can finally cook real binaries--that is, binaries with the CLR baked right in. Mmmm. Just like Grandpa used to make. Another nice thing is that the compiler can cook linux, mac, or windows binaries using the same code. On the other hand, it's fairly new, and you spend a lot of time trying to use NuGet libraries only to discover that they have not been updated yet. Of course, you're a programmer; go get the freakin' source code and fix it yourself. But, it makes more sense for the dev teams to do it, since they know the requirements, and also if you have to do that for every package, that's very time-consuming. There are some (many) rough edges. They will smooth out. .Net Core is where you want to be moving forward, but right now, if you make the switch, be aware you are on the bleeding edge. Well, somewhat. Depends on how you look at it. The BLEEDING edge might be Mono, from a certain perspective.
It's an alternative implementation of .NET. It isn't the next version of the .NET Framework, though early branding have that false impression. Think of it like Silverlight or Universal Apps for Windows. It has many of the same APIs, but enough of it is different that you can't always port code between them. Do not think of it as Mono. Mono is meant to be an exact match of the .NET Framework (though it isn't 100% there yet).
That's the wrong way to think about it. .NET Framework and .NET Core will evolve side by side for an indeterminate amount of time.
My understanding is that Core is a lightweight universal version of .NET, whereas Framework is the full-featured Windows version. 
That may be the end result, but it's still too soon to tell what direction Microsoft will ultimately go in.
Your best bet would be to use: https://github.com/praeclarum/sqlite-net It was developed to be as cross platform as possible (.NET/mono/xamarin/etc..) so it's less likely to have dependencies that are not available in .NET Core This is the library we use all the time just haven't tried it on .NET Core yet.
At the moment only a few windows linked features like DirectoryServices, WPF and WinForms are not being ported.
Most libraries packaged for the older portable frameworks should work, you'll just declare an import for the older framework. The tooling is in preview. It works, certainly, but it's missing some important features and is technically unreleased.
We are using .Net Core for a greenfield application. Tooling is _there_, and is definitely better since last week, but we are enhancing it with Cake (http://cakebuild.net/). We kind of want to be on the forefront for the whole organization, so the bumps in the road are not too big a deal. Library support is a little spotty right now, but the basics are there and useable.
But it is the future of .net surely, regardless of how they branded they still have to support the current version for a little longer but I really doubt we'll see a version 5 of the current framework. 
Search for .Net Native. https://blogs.msdn.microsoft.com/dotnet/2014/04/02/announcing-net-native-preview/
Mono isn't an implementation of the .NET Framework (I'm sure you know this but I'll point it out for anyone confused), it's an implementation of the Common Language Infrastructure (CLI). .NET Core is an implementation of it as well.
&gt; Microsoft open-sourced the .Net framework and put it on Github. It used to be called .Net 5.0 or some such, but around the time they open-sourced it, they renamed it Core. It is .Net now. Nope. It's a rewrite of .NET, and only a subset. For now it's an alternative, and not THE .NET framework. Also only parts of .NET are open-sourced. &gt; One of the nice things about .Net Core is that you can finally cook real binaries--that is, binaries with the CLR baked right in. Nope. That's not possible yet. But what is possible (and what you likely mean) is that you can deploy the runtime together with your application.
Awesome thanks for that link, hadn't seen those tutorials before.
I'm not contradicting you, but do you have a source for that or is it intuition? 
Mono tracks the APIs exposed by the .NET Framework, not just what's in the CLI.
There is far too much in the .NET Framework to abandon it like that. For example: * Windows Forms * WPF * Windows Services While they may move more parts of the .NET Framework into multi-targeted NuGet packages, I can't see them abandoning it in the manner you suggest.
Maybe an organizer application for your sports club. With an calender, a task list, upcomming birthdays, an overview of the different administrative positions, push notifications to your inner circle for meetings.
It's a build system that is nicer to use than MSBuild.
If you integrate a customer service chat, you can have SignalR in you webshop. :)
No it's not. They'll exist beside each other for a long time because Core has so many features stripped out. It's a good choice for cross platform server side development, but has no UI framework and 'legacy' APIs like DataTables/Views are not coming over. .Net is here to stay for a very long time on Windows Native 
This is the most accurate ELI5 for the current and foreseeable future
I can't comment on Angular / Angular 2 as I haven't used them, but I really enjoy working with React. Give it a go!
Could you elaborate on this a little. What was the incorrect configuration of dependancy injection. I dabe in Web api and dependancy injection so you have my curiosity. 
https://github.com/dotnet/corefx/blob/master/Documentation/architecture/net-core-applications.md https://github.com/dotnet/corefx/blob/master/Documentation/architecture/net-platform-standard.md 
Is there any good integration with TeamCity?
You could maybe cover a bunch of these by walking through implementing, say, IEnumerable&lt;T&gt;, IList&lt;T&gt; and ICollection&lt;T&gt; or something.
NancyFX and ASP.NET Web API both can be hosted on OWIN.
Which one should I use?
How will it be any different to using IE? I keep running into script errors with the current control and I cannot be effed fixing them.
[Mirror](https://cheatdeath.github.io/research-bittorrent-doc/) and [HN post](https://news.ycombinator.com/item?id=12035568).
&gt; It's a rewrite of .NET... Are you really sure? Where is the reference to a legit information source? 
I wouldn't use it if you're in mid-stride with any projects. Just converted a project over and lost about a weeks of worth just in getting everything reconfigured. I would use it going forward on brand new projects. You're going to use fun and useful tools like Glimpse and Browser link though. So, there's that. 
The *new .NET Core* is the name of a branch from Version 5.0 of the *old original .NET*. They implemented some new features to make .NET Core multi plattform compatible to run on Windows, Linux and MacOS! For the first release of .NET Core *they had to drop* everything that was still too complicated or too expensive to make it compatible, like WinForms and WPF, but they are still progressing. .NET Core Scenarious: - ASP.NET Core web apps - Universal Windows Platform apps - Server-side programming - Command-line apps - Libraries .NET Core does not implement: - Windows Forms - WPF The development on both (the old origianl .NET and the new .NET Core) continuous. (I wonder if there will emerge a new term for the old original .NET in the near future, something like ".NET legacy", or something like this, just the distingush it from .NET Core)
https://validator.w3.org/docs/why.html
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Announcing MimeKit and MailKit 1.4.0 for .NET Core 1.0 \[cross post from \/r\/csharp\]](https://np.reddit.com/r/programming/comments/4rcdxn/announcing_mimekit_and_mailkit_140_for_net_core/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Hey, I'd second this. For fundamental OOP concepts, it's better to stick with desktop apps. After that, you can keep doing apps or go down other paths like web applications to adopt more advanced techniques and design patterns.
I use glimpse and browser link for several years now...
I was wrong, apparently. ASP.NET is almost a complete rewrite (https://blogs.msdn.microsoft.com/webdev/2016/02/01/an-update-on-asp-net-core-and-net-core/), .NET not.
Check our the corert repo on github. It seems to work well for small applications but probably has plenty of work left to support stuff.
Wow, you just made me feel a lot better about my place as a programmer. Job hunting is rather humbling because it reminds you of how much you really don't know outside of the bubble of your workplace.
.NET Core is essentially this, as it grew out of "Katana"/OWIN. Otherwise, you can run Nancy. If you can, use Core, but Nancy can be pretty good - and it supports Razor. 
What about MVC, is there any for example template engine that I can use with ASP.NET Web API
Another PVS spam post.
For Core or Nancy? Both support Razor - the ASP.NET template engine Core supports MVC and Web API; actually, it unifies them - one controller type handles both. Output type is determined by what you return - whether it's a view, or JSON/XML (eg, if you return an object, it would be serialised to one of those, which depends on what the client asked for in their 'Accept' HTTP header). Nancy is a little different, as it does it's own routing IIRC, but yes you'll be able to do that with it. 
A bluetooth ODBII code reader database lookup tool. If you know how to communicate over a simple serial port, you can query a automobile bluetooth ODBII reader to read the code, then lookup the code and give a human readable error.
I used to care, but I just don't anymore. If you want data- it's there for you 
In this case, I would not move to core quite yet. Give it some more time. 
If it's an app that'll run in some sort of host as a mobile or desktop app (e.g. Electron) then it's not the worst thing. However, for public-facing websites, it's important and it quite frankly pisses me off that people don't take it seriously.
BTW, there is also a MonoTorrent library for .NET. Despite the name it can be compiled by Visual Studio. The original library was abandoned a while ago and seems to be buggy, but I was able to make a very simple .NET client with WinForms UI using this fork: https://github.com/ErtyHackward/monotorrent
Any chance you could move away from stored procs all together and use some kind of ORM? I'm loving the new Entity Framework (version 6+). With the Code First reverse engineer it's very easy to implement. If you have logic in your stored procs I could see why you would need to keep them though.
I second this. Story: I had to make a chess program in college to read an existing game and recreate the game step by step. Sounds simple but the language used to record chess matches ([Chess Notation](https://en.wikipedia.org/wiki/Chess_notation)) assumes a great deal. Long story short I programmed it using basically no OO concepts and it became this spaghetti code mess that was impossible to debug. Chess pieces got lost or fell off the board. After that something clicked for me, these concepts matter and I should learn when to use them correctly. My two cents learn inheritance first it's hands down the most important OO concept. Also you need a project any project but something to drive you. Those stupid Cat Object inherits from type Pet bla bla is great but it won't sink in until you do a real project.
If you like gaming, check out some of the developer websites. They often have api's exposed so third party devs can make apps. That's always a fun one. Bungie's Destiny is one I'm currently working on, and it is entertaining and challenging. 
If you're making over $100,000 off of Unity, $1,500 is definitely affordable and worth it.
&gt; Is there Typescript/Javascript support in Rider? No and why would there be? They already have WebStorm for that. Rider is for C# only.
It is very dull in the .net land, its either MailDotNet MailSharp or MailNet. I bet they are all already taken.
The term I keep hearing is ".NET everywhere." By refactoring, modularizing, and open-sourcing the .NET framework, and acquiring Xamarin, Microsoft is positioning .NET Core to be the defacto for all types of developers and platforms.
The Internet has decided it's not a thing
I HAVE narrowed it down it's the ConfigNode stuff, but I don't see why that would errored.
See my edits. I don't see how it could be in the `ConfigNode` blocks ala: var res = new ConfigNode("RESOURCE"); res.AddValue("name", "Oxygen"); res.AddValue("amount", 3 * crew_capacity); //3 days of oxygen for each kerbal. res.AddValue("maxAmount", 3 * crew_capacity); prefab.Resources.Add(res); Only way I can think of getting a NRE in these blocks are: 1. modified the reference to `prefab.Resources` between the `if` check earlier and these lines here 2. if the `prefab.Resources.Equals` is actually an extension method that lies to you about it being null 3. if the NRE is actually happening in the `ConfigNode` constructor 4. if the NRE is actually happening within the `ConfigNode.AddValue` method. 5. `prefab.Resources.Add` method throwing a NRE (but I doubt this) If it's none of these, then I would be so bold to suggest that the exception isn't being thrown from those lines.
I get that feeling, but that ties into my other questions. Mono runs on Linux, Mac, Windows, iOS, and Android. It's open-source and accepting contributions. Why do we need an MS de facto implementation? Why can't they start contributing heavily to Mono and leverage that people are already using it, and already have toolchains/processes for working with it? 
What have you tried so far? Because this just sounds like a usage of ObservableCollection&lt;Pet&gt;
I believe the biggest reason is because Microsoft offers a 100% top to bottom integrated development stack, and they don't want to contribute to something that they do not have 100% control over. That is important, because among other things, two of the biggest hurdles Microsoft is trying to push past are legacy codebase compatibility and unmanaged obsolescence scenarios (a good example would be the Windows XZP fiasco where companies refused to upgrade "because it works").
Microsoft's .NET compiler and runtime usually performs better than Mono .NET (though I'm sure you can find specific cases where it does not) Anyway, there is code shared between them already, so you could say they are doing exactly what you said. 
It absolutely is that. OP are you getting any errors? In MVVM (which I assume you are using) it can be hard to see the errors as they occur at run time*. Check the output window. *To reduce the pain of things like this it is a good idea to have a design time data layer that allows you to see what is happening on the designer. 
I'm in the pub so I'll give explaining inheritance a go. Let's say you are making a system for a veterinarian surgery. You are making the appointment screen. You want to have a drop down with all the animals who are registered at the surgery so you can select which one is coming in for the appointment. You have a few types of animals registered at the surgery. A dog, cat, mouse and bat. So you've got 4 classes of animal there. One for each type. They are all different animals so will have different properties. Dog will have bark volume. Cat will have favourite prey. Mouse will have RPM in a wheel and bat will have wing span. So how can you make them all turn into one thing that you can use to show in a list? What you do is see what they have in common. You can't have wing span as a property because dogs don't have wings. But you could make a class like this. I'm on a phone so it might be error prone. And it will be pseudo code. Public class animal Property name Property height Property owner End class So, you could make a class for each animal that inherits this class. Like this. Public class bat : animal Property wingspan End class Now because every bat inherits animal every bat will have a name, height and owner as well by virtue of inheritance. So you could have a list of type animal, which by polymorphism, would allow you to add all the different animals to it. You wouldn't be able to 'see' the non animal properties. But you could add them to the list. However, for something like this you would want an interface. I'm going to the bar now so I'll wife the next bit in a minute. Sorry for typos. 
Glad it helped. Got to be honest; I'm getting a bit drunk to keep typing on my phone. Can someone else give the example with an interface instead of inheritance? Thanks guys. 
CSV? Or any delimited format. XML would be nice too.
This smells like a homework assignment or a sample product generator. I wouldn't use an actual filetype for this. I would generate a class called sample data that has a property of Dictionary&lt;string, Dictionary&lt;string, List&lt;string&gt;&gt;&gt; The outer key is the item type, the inner key is the attribute name, and the list is the collection of possible attribute values. I would then create an instance of this object in code that initializes its dictionary collection with a couple sample values, then use Json.NET to serialize it to a json file. You will be left with a file that you can manually modify that has a relatively simple format, which you then can reload at runtime in your application with a simple Json.net deserialize command. Thats the high level of one way to do it. If you need something that follows set based semantics, then I would use multiple csv files instead. You can edit the list in Excel in that case.
You can do something like this: foreach (DataRow row in Datatable.Rows) { if (row["Type"].ToString() == "A") { var valueofTypeA = row["Total"].Value } if (row["Type"].ToString() == "B") { var valueofTypeB = row["Total"].Value } } int finalValue = valueofTypeA / (valueofTypeA/valueofTypeB); This was just a super basic solution to it. But to answer your question, yes you can read the values from a data table.
Unfortunately, using EF is not a real option as my solution needs to integrate seamlessly and easily with an existing code base that is entirely built on calling stored procedures with inconsistent inputs, outputs, and yes, there are some sprocs that contain logic also. I'm trying to build a single entry point for all DAL access that allows for permissions, caching, etc that is easy to read, maintain, and integrate into a legacy web forms app. The solution I came up with is..unlike any code I've seen before but I'm struggling to think of a better way to do this.
My first C# job was as a Unity 3D developer (strongly recoment trying that too). I began programming LONG ago in python and I always just thought up something I wanted to create then kind of guessed, googled, and improvised to create it. Also going to school and getting a CS degree 110% worth it.
Okay yeah I think something like this is what I need. Going to look at it again tomorrow. Thanks for the reply! 
Check out https://anclafs.com/. It's tracking which libraries and frameworks have .NET Core and ASP.NET Core support. 
Honestly? Don't worry about the file format. Instead, try to code your program to _not care_ about the file or the format. Choose a format (whatever is easiest for you to use at the moment) and separate the reading/loading concerns with the application business logic. Once you've done that, it's trivial for you to change the file/format, or to support multiple formats simultaneously. Learning how to incorporate this concept of "separation of concerns" early on will benefit you far more in the long term (applicable to almost any program you make) than this particular file format now (where file formats will probably always be changing for the domain you're using, and generally make up a very, very small proportion of any program's code/concerns).
CSV is one I haven't looked at. I'll have to have a look at it. XML I've seen compared to YAML. I've been looking at both of those and I'm wondering if one would work better than the other.
Alright. It looks like CSV is the easiest one to work with, provided that I can use something other than a comma to separate fields. It appears I can, so I'll just work with that for now. I appreciate the advice. This is my first non-school program that I've been planning and don't want it to be garbage. 
Is your application the one that is eventually going to be modifying these lists of attributes? 
Removed: Rule 3. Congratulations on the job! I think you'll find that /r/cscareerquestions is probably the best place to find answers to your questions.
The article mention dotnet.exe and corehost.exe. I guess that i what /u/AngularBeginner is talking about?
Because they've had years to do that and by and large it hasn't happened to a standard that developers are willing to embrace.
I'd recommend [UrhoSharp](https://www.nuget.org/packages/UrhoSharp/). It is backed by Xamarin and seems to be their alternative to MonoGame. Read the license if you have any concerns, it is quite short and free.
Did you wrap it with &lt;?xml version="1.0" encoding="utf-8" ?&gt; &lt;nlog xmlns="http://www.nlog-project.org/schemas/NLog.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt; YOUR RULES... &lt;/nlog&gt; 
Please avoid the infinite while loops. There is really never any **good** reason to have one of those. If you do have one, there is probably a better solution. I would have a dedicated thread that monitors a concurrent queue for incoming and outgoing commands. The queue would be processed by the serial port manager unless there are no commands then it would just sleep on it. Keep track of the thread(s) so that you can release them when you are done.
Yes, sorry, I was just showing the meat and potatoes. The config file was generated when I installed NLog, and I added those rules and targets.
&gt; Unless you need an out or ref parameter, there's virtually no reason why you would use a delegate instead of a Func parameter. - You can name a delegate. - You can name the parameters in a delegate. - You can properly document the delegate, all parameters and the return type. `Func&lt;&gt;` is great for generic simple cases. For slightly more complex cases a delegate is the good option.
CSV is a simple way. Or you can try SQLite for more features.
[removed]
Thank you! A good article
oh, sorry I misunderstood ;P . start up a asp.net project (a tutorial on this can be easily found) then try for an extremely basic interface. two controller methods and a list to keep everything. then slowly add to that. maybe start with setting up a room system then going for some kind of repository to save the chats. a login/user system (built into asp.net and there are plenty of tutorials). after that the next steps should come naturaly. I'm going to try and find my original project and post it (it's been years since I originally made it)
Not sure if this is the best suggestion (due to skill level) but it sounds like a Windows Service would help. You can check out TopShelf, it will allow a simple console app to be ran and installed like a service.
Last question, any good tutorials how can I build Web Api with Katana?
It would be easier to help if you posted the code somewhere.
https://github.com/ProGameDesigns/TestCode/tree/master/Challenge25
I implemented it and it works. Thanks so much. One more question, how can I use Razor Engine with Web API? I've found https://github.com/WebApiContrib/WebApiContrib.Formatting.Razor but do not know how to implement.
Removed: Rule 3. Maybe this is more relevant for /r/cscareerquestions or /r/programming or maybe /r/technology.
Great post. I would love to see a post explaining the different terms like thread-safe, atomic, volatile, ...
&gt;&gt; Why is Microsoft making a new open-source .NET instead of contributing to Mono? &gt; As others below have pointed out, they are doing both. You're right. As I mentioned in a related discussion a few days ago when Microsoft started to open source .NET last year, the mono developers (aka Xamarin for the most part) went through the Microsoft reference implementation and copied chunks out of it where they felt MS had created a better or more optimal implementation. Miguel de Icaza is on record as saying this. There's plenty of overlap between the two these days, and now that Xamarin and Microsoft are the same company I expect this collaboration will increase even further.
I don't understand what you're wanting to do, and I'm not entirely sure you do either - and besides, I don't have the time, nor the inclination, to go through it step by step. Web API is for making APIs. Razor is a templating engine, for GUIs. They *can* be used together, but not without MVC driving the GUI (not meaningfully, anyway...) as well. Web API is not supposed to be a full GUI engine - because its for APIs. If you want to generate web GUIs, and you want to do it with Razor, you'll have to follow my previous suggestions of looking at .NET Core, or Nancy.
I did like this but it throws a null exception.Please correct me if i've done something wrong Dog class [Export(typeof(Pet))] class Dog:Pet{ Dog dog = new Dog(); string name{get {return "Max";}} string breed{get {return "ABC";}} string color{get {return "ABC";}} } CS public partial class Window1 : Window { List&lt;Pet&gt; pets; public Window1(IEnumerable&lt;Pet&gt; pet){ this.pets = new List&lt;Pet&gt;(pet); this.DataContext = pets; InitializeComponent(); } } public IList&lt;Pet&gt; Pets { get { return this.pets; } } XAML ItemsSource="{Binding Pets} 
1. Yes. CSS and HTML at least. Javascript is highly recommended, otherwise you wouldn't be able to do any client side interactions. Don't burn a lot of time on Single Page Application frameworks (like angular and react) until you've gotten your bearings on javascript. 2. No. Everyone needs a developer these days. Full stack developer makes you more marketable, however will not prevent you from getting a backend job if you dont know it. Knowing full stack means you can do more than people who know just front or just backend. It also means you can design applications on your own in your spare time without needing to work with other people. 3. keep learning and try to build something. Take a desktop app you've made and try to make a web based version of it. While learning on your own isnt always going to cut it, take a job and work with other peoples stuff. Read other peoples code to see how they do it. Voat.co, for example, is open source, its a great way to see how someone has used MVC , entity framework, .net user management. When I was first learning MVC I used it as a reference to see "how did they do X?" https://github.com/voat/voat 4. Personally, I think C# is easier than C/C++ because you dont need to worry about pointers and memory management. It's also an *almost* Java like language. PhP is easy just because there is less runtime overhead and can just work. C# is a general purpose programming language that can do *anything* you want. Its no better or no worse that many other languages, however because its interpreted/compiled it is slower than C/C++. Most cases that's not too much of a worry because things are I/O limited. (database and hard disk access is slow by comparison) the key thing about .NET, while recently it has been open sourced so that it can be run on linux or mac, for now, it's still mostly a Windows based language. Your code can only be run and compiled on windows and most of the tooling available is only targeted for the windows operating system. If you can, I'm assuming you're in the UK, move to a bigger tech centric city (or if possible the US) NYC is desperate to hire anyone who even knows what a database is. 
A lot of full stack places expect you to be strong in one area but be familiar with the other areas so that you can pick up all kinds of tasks. since you have be away from the game for a while, I would suggest you build a portfolio, some mvc apps and put the source code on github and deploy it on azure. That would show recruiters that you can do full-stack development. Plus the whole "cloud" buzz that is adds to your resume. Check this out for free azure credit. https://www.visualstudio.com/en-us/products/visual-studio-dev-essentials-vs.aspx 
Post the _entire_ exception, including message, stack trace, and inner exceptions. (that is, catch the exception and log out the result of `myException.ToString()`; it will get all this information for you)
Sorry for that. I used comma as decimal separator in my first paragraph by mistake. 
OK, I like this explanation. I very much like the idea of paring the Framework down to some very basic runtime libraries and making everything else a package you pull in if needed. I hope the approach is adopted by Mono, or that MS's goal isn't to run over Mono and end it.
Yes. try { Application.Run(new Form1()); } catch (Exception ex) { Console.WriteLine(ex.ToString()); //or maybe MessageBox.Show? Or File.WriteAllText? Debug.Write? } You may need to change how you output the data so you can access it. You can also put a breakpoint within the `catch` block and you can inspect the exception information with the debugger.
Thank you very much for hand-holding me through that! :) Here is what I got, and I just don't know enough to understand the problem (and again, Google hasn't helped) Exception thrown: 'System.IndexOutOfRangeException' in System.Windows.Forms.dll System.IndexOutOfRangeException: Index -1 does not have a value. at System.Windows.Forms.CurrencyManager.get_Item(Int32 index) at System.Windows.Forms.CurrencyManager.get_Current() at System.Windows.Forms.DataGridView.DataGridViewDataConnection.OnRowEnter(DataGridViewCellEventArgs e) at System.Windows.Forms.DataGridView.OnRowEnter(DataGridViewCell&amp; dataGridViewCell, Int32 columnIndex, Int32 rowIndex, Boolean canCreateNewRow, Boolean validationFailureOccurred) at System.Windows.Forms.DataGridView.SetCurrentCellAddressCore(Int32 columnIndex, Int32 rowIndex, Boolean setAnchorCellAddress, Boolean validateCurrentCell, Boolean throughMouseClick) at System.Windows.Forms.DataGridView.OnCellMouseDown(HitTestInfo hti, Boolean isShiftDown, Boolean isControlDown) at System.Windows.Forms.DataGridView.OnCellMouseDown(DataGridViewCellMouseEventArgs e) at System.Windows.Forms.DataGridView.OnMouseDown(MouseEventArgs e) at System.Windows.Forms.Control.WmMouseDown(Message&amp; m, MouseButtons button, Int32 clicks) at System.Windows.Forms.Control.WndProc(Message&amp; m) at System.Windows.Forms.DataGridView.WndProc(Message&amp; m) at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message&amp; m) at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message&amp; m) at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam) at System.Windows.Forms.UnsafeNativeMethods.DispatchMessageW(MSG&amp; msg) at System.Windows.Forms.Application.ComponentManager.System.Windows.Forms.UnsafeNativeMethods.IMsoComponentManager.FPushMessageLoop(IntPtr dwComponentID, Int32 reason, Int32 pvLoopData) at System.Windows.Forms.Application.ThreadContext.RunMessageLoopInner(Int32 reason, ApplicationContext context) at System.Windows.Forms.Application.ThreadContext.RunMessageLoop(Int32 reason, ApplicationContext context) at System.Windows.Forms.Application.Run(Form mainForm)
Well, that sucks. Could be a bug in the WinForms framework code itself. You might have to work around it (maybe by rebinding/rebuilding the datagrid entirely?).
Haha - I did completely delete the datagrid and then rebind it to the CellClick function. 
Or, do as I did - sell your soul and dig deeper to the ASP.net. Is is easy to make a neat looking webpage what you can show, and very easy to get a decent position on a web dev field, and if you find a small company, you can do a LOT of things (I work as a web dev, manage our windows server, develop for android, and do desktop app as well). It is very-very hard to get into the game dev field, especially if you planning to get money as well.
&gt; Your code can only be run and compiled on windows Wrong. Mono and .NET core, anyone?
Did that work?
[I think this may be what you're looking for](https://msdn.microsoft.com/en-us/library/4edbef7e.aspx)
Okay. If you want the *whole line*, you're going to need to use some anchors an groups. Probably makes your regex look like this: ^.*hello.*-a.*$ but you'll also want to include `RegexOptions.Multiline` when creating your `Regex` object to get the right behavior (by default, `^` and `$` match the beginning and end of the string, respectively). Depending on what you're up to, you may need to look into grouping, but, by then, it's probably time to read up on regexes on MSDN.
.... yes. Twice. You're still wrong. &gt;Your code can only be run and compiled on windows and most of the tooling available is only targeted for the windows operating system. VS is Windows only. VScode and SharpDevelop are multiplatform. Mono includes a compiler, and you obviously *can* run your code on other platforms... what even
I don't know what "RButton" is. It's not on the list of [valid SendKeys commands](https://msdn.microsoft.com/en-us/library/system.windows.forms.sendkeys\(v=vs.110\).aspx).
Alternately, you could break up the original string into lines, and then return the ones that match your original regular expression. This can be done pretty easily with a `StringReader`, but it's going to be more verbose (and net you a collection of `string` values instead of `Match` objects): static IEnumerable&lt;string&gt; GetLinesFromString(string s) { // prevents null string from being passed to StringReader if (string.IsNullOrEmpty(s)) { yield break; } using (var reader = new StringReader(s)) { string line; while ((line = reader.ReadLine()) != null) { yield return line; } } } // elsewhere var regex = new Regex("hello.*-a"); return GetLinesFromString(str).Where(regex.IsMatch);
Pinvoke is so cool, ill check this out. Once i tried to use it to interface directly with a Motorola barcode scanner and it worked perfectly 99% of the time but then would occasionally throw a "ExecutionEngineException" or something like that. I think it had to do with me trying to pass a pointer to a StringBuilder as a char[]... Debugging is tough especially if youre trying to use functions that you didnt write and its an obscure library without examples online. Thanks for the write up.
you can code with them, however the tooling is still focused mostly on windows platform. VSCode is not great when compared to the functionality of visual studio. It's like using sublime text for C#. Not great. 
This is why it's silly for them to have a dozen different IDE's - nobody does just one thing anymore. They should be building a singular JetBrains IDE that seamlessly handles Java, C#, SQL, Javascript, web dev, etc...
:D System.Web.Security.Membership.GeneratePassword(15, 2);
My Drunk Coding should be a YouTube channel. MArk B. 
I am a newer developer relative to people who do this for a living, so I have not published applications yet. However, I would still be surprised if they rejected anything using pinvoke. Not that I doubt you, but I would like to see their reasoning if you have a link where they state that. Pinvoke is used all over internally in a lot of library's. It is perfectly acceptable to use it in your application when done correctly. 
My concern with that code would be that none of that should be public as a managed interop impl. You really shouldn't expose `IntPtr` if you can avoid it.
Indeed it does! See [the documentation on named and optional parameters](https://msdn.microsoft.com/en-us/library/dd264739.aspx) on MSDN.
Yes int add(int a, int b, int c = 0) =&gt; a + b + c; Go about 1/2 way down on this page to see info for Optional Arguments: https://msdn.microsoft.com/en-us/library/dd264739.aspx
Ta-da: public int AddSomeNumbers(int a, int b, int c = 0) =&gt; a + b + c; AddSomeNumbers(1, 1, 1) // 3 AddSomeNumbers(2, 2) // 4 We also have named arguments, which can simplify dealing with multiple defaulted arguments: public AddSomeNumbers(int a = 0, int b = 0, int c = 0) =&gt; a + b + c; AddSomeNumbers(c : 1, b : 2) // 3 It's easily googled, but [FYI](https://msdn.microsoft.com/en-us/library/dd264739.aspx).
IntelliJ IDEA does that, apart from C#, basically.
If your working with a COM DLL that has no documentation. Use Dependency Walker to find the entry point. As an example, I will pull in the User32.dll you referenced on your blog. There is actually two flash window methods within there. [Also, you can specify the ordinal as opposed to the name](https://msdn.microsoft.com/en-us/library/f5xe74x8%28v=vs.110%29.aspx). Function: FlashWindow Ordinal: 1760 Function: FlashWindowEx Ordinal: 1761 [Dependency Walker 2.2](http://www.dependencywalker.com/)
In a real project, you should likely prefer to make your pinvokes and any such native interaction internal. Then you can wrap classes around them and make sure they use proper dispose patterns.
If you turn on Managed Code Analysis it nags you to put all your imported methods in a class called `NativeMethods`.
Robert C. Martin, Principles, Patterns, Practices (This has a C# Version) Martin Fowler Refactoring and other books by these authors
Angular ignored it, Aurelia ignored it. Vue, polymer, That's what I pulled up in about 75 seconds 
I highly prefer they be inside a file named after the module they are located in, aka User32.cs etc. Example: https://github.com/lolp1/Process.NET/tree/master/src/Process.NET/Native
.NET and mono will continue to be developed and supported - they are very much still relevant. They worked well for so many years and will continue to do so in the right scenarios. Another cool thing about .NET Core is powershell in to a Raspberry PI with it installed and type dotnet new then dotnet run. If you pop a website on a pi you could use dotnet CLI to run up Kestrel and host from there - because all the tools and things are in the packages, including Kestrel web server which you can choose to include when you distro you app. 
You should try [Stylet](https://github.com/canton7/Stylet), borrows a lot of good stuff from Caliburn.Micro, without the convention based binding magic. And there's built in support for INotifyErrorDataInfo, which is nice.
TYSM for the link!
Pretty sure the SQLite implementation uses it so it can't be all.
P/Invoke is neat, but most of the time I find it to be black magic; something I know exists, but never had the courage to actually try.
Well, I would say learning to use native code helps learn more than just the underlying foundation of windows. Learning to use the interop capability C# has will likely teach you a lot about C++ and C, which is still used all over the place regardless of windows.
Fair enough. That is code I wouldn't want inexperienced hands going anywhere near though. That GreyMagic WoW exploit code is neat still.
Managed apps that use PInvoke are bound by the same restrictions that native apps (eg C++) are bound to, the only difference is that the C++ apps call the API directly, and managed goes through the PInvoke layer. .NET at the lower layers uses a lot of PInvoke too. Just like with managed code, exactly what you can use depends on the "Capabilities" you give the app in its manifest (ie, does it need Location services, internet access, etc), these are what show up in the Store. If an app tries to call things that it doesn't have permission to call, it gets a security exception, and if you submit an app that has obvious calls to APIs that it hasn't declared it needs in the manifest, it'll probably get rejected from the store. Then, there are a bunch of APIs that are completely off limits for UWP.
I feel like the book *Adaptive Code via C#* was a great resource for me to advance to the next level as a developer. It covers all the topics you mentioned and helped me understand how to write more maintainable, well architected code. [Adaptive Code via C#](https://www.amazon.com/gp/aw/d/0735683204/ref=mp_s_a_1_3?ie=UTF8&amp;qid=1467858664&amp;sr=8-3&amp;pi=SY200_QL40&amp;keywords=c+design+patterns&amp;dpPl=1&amp;dpID=51I13xOnnGL&amp;ref=plSrch)
[removed]
Another quiz that doesn't tell you the right answer (though you could just keep randomly guessing) and doesn't tell you why. Correct answer is #4: `oten == oi` will return `false`. Why? Let's break down each answer: ---------- `ni.Equals(oi)` This will make a virtual call to the [`Nullable&lt;int&gt;.Equals(object other)` override](https://msdn.microsoft.com/en-us/library/c7b1e4z6%28v=vs.110%29.aspx), and while they are technically different objects (because of the boxing operation), the documentation states that this returns `true` if: &gt; The `HasValue` property is `true`, and the value returned by the `Value` property is equal to the `other` parameter. In this case, `Value` is the integer `10`, and it will call `Int32.Equals(object other)` which will cast/check against the boxed integer passed in and compare its `10` value. (and `10 == 10`) ---------- `oi.Equals(ni)` Almost identical IL code and reasoning to the above answer. The resultant IL is _slightly_ different: this one does a standard `box` on `ni`, then makes a `callvirt` on `oi.Equals(object other)`. The first answer, instead of boxing, emits a [`Constrained`](https://msdn.microsoft.com/en-us/library/system.reflection.emit.opcodes.constrained%28v=vs.110%29.aspx) OpCode which (if I understand correctly) is just a fancy way for the runtime to determine if it needs to box (or copy) the generic type so that the virtual call executes properly. But for all intents and purposes here, these first two answers are identical. ---------- `oten.Equals(oi)` Easy. These are just both boxed `Int32` values, so it makes a virtual call to `Object.Equals` which compares their values. (again, similar to the first two answers but since there is no `Nullable&lt;T&gt;` involved, it skips the wrapping `Nullable&lt;int&gt;.Equals` check). And again, `10 == 10` so this returns `true` as well. ---------- `nni.Equals(onni)` I'll skip the 4th answer and jump to the 5th one here. This returns `true` because like the first answer, you're making a virtual call to `Nullable&lt;T&gt;.Equals(object other)` where the documentation states: &gt; The `HasValue` property is `false`, and the `other` parameter is `null`. That is, two `null` values are equal by definition. So, `null == null` so this returns `true`. By the way, you can see this in the [reference source code](http://referencesource.microsoft.com/#mscorlib/system/nullable.cs) too: public override bool Equals(object other) { if (!hasValue) return other == null; if (other == null) return false; return value.Equals(other); } The first line there `if (!hasValue) return other == null;` is what is handling this case. ---------- `oten == oi` This is the "correct" answer in that it returns `false`. When you break down the call, it looks like it should be a boxed integer `10` again comparing against the nullable integer `10`, which is similar to answer 3 (and well, the others too). But why is this `false` and the others `true`? Reason being (and the underlying purpose/lesson of this quiz/blog entry) is that using _operator overloads_ (in this case `==`) must be _statically determined at compile time._* In all the other answers, a _virtual_ call is made to either `Nullable&lt;int&gt;.Equals` or `Object.Equals` which are overridden and check for the `null` case, and otherwise ultimately call `Int32.Equals` which will perform the value comparison. However in this case, a statically compiled call is made. In doing so, the compiler checks the _compile time_ types being compared: object oten object oi These are both objects, so it can't infer any `==` overloads that exist on `Int32`, or replace the comparison with an in-place check against `Nullable&lt;int&gt;.GetValueOrDefault()` and `Nullable&lt;int&gt;.HasValue` (which is a neat micro-optimization, and I swear I read it on Eric Lippert's blog but for the life of me I can't find it right now). So all it can do is fall back on `Object.ReferenceEquals(object objA, object objB)` which will check for reference equality. In this case, because the values have been boxed, they are different references and will result in `false`. \* Note that if you actually type these as `dynamic`, the Dynamic Language Runtime will kick in and at runtime perform some reflection trickery and actually find the correct `==` operator overload and invoke it as though you had strongly typed the two arguments in the first place, resulting in a return value of `true`.
If you were in the profession for 8 years and have't picked it up naturally by now, then I wouldn't bother. This is not something you "learn" its something you "understand". If you try to apply principles, patterns or practices without fully understanding what problem they solve, then it will make more damage than good. Or maybe you DO understand those concepts, you just don't know their names and how they are called by other developers. Also, did you ever work in a team? I believe lots of "architecture" boils down to being able to understand other people's code and being able to communicate the design quickly and sufficiently. Did you ever want to rip your hard out reading someone else's code?
He should definitely pick up a few books and learn the names of those patterns. If he has been working professionally for 8 years and those concepts haven't come up occasionally in discussion with his team(s), then maybe he isn't working in an environment that is doing his career any favors. I see this come up often in developers who end up in production support. Companies like to throw their hard working dependable JR/mid developers into production support and then seem baffled when 3-5 years later those employees end up under-skilled in architecture compared to feature/new-project developers. You can't learn as much about arranging dependencies in your code when your whole focus is completing production support tickets...its not like "implement loosely coupled plugin architecture with DI/IOC" ever ends up for on a ticket for those teams.
F# is very popular with those who use it. I believe F# users like their language more than C# users. Certainly C# programmers can learn F#. And certainly any program I have written in C# could also be written in F#. Many more people use C# than F# and this is not changing significantly. Predictions are not entirely reliable, especially when they are about the future. 
Must be something wrong with code wars mono version. I just tried it on a Raspberry Pi and on my windows 10 machine and the output is the same: Output: 2 3 Input: 3, output 3 Mono version: Mono JIT compiler version 4.4.0 (Stable 4.4.0.40/f8474c4 Mon Mar 28 07:42:47 MDT 2016) Copyright (C) 2002-2014 Novell, Inc, Xamarin Inc and Contributors. www.mono-project.com TLS: __thread SIGSEGV: normal Notifications: epoll Architecture: armel,vfp+hard Disabled: none Misc: softdebug LLVM: supported, not enabled. GC: sgen 
Not without better tooling and a sea change in industry practices. C# is pretty entrenched. F# is a nice language, though. Interface with the .NET platform can be a bit clunky (Options everywhere!), but I found it pretty comfortable for doing simple stuff, at least, after a brief adjustment period.
Not even! If you weren't born knowing how dependency injection works, you'll never be able to bro down!
Removed: Rule 7.
Awesome! Thanks for your work on this.
I am surprised that you removed the blog. In response to your previous comment that blog does not provide any explanation: it does have have 2 buttons - hint, explanation. The blog is a quiz; It has to keep certain information hidden until explicitly asked by user. 
Sorry, I didn't notice the "Hint" or "Explanation" buttons. Maybe they can be made more apparent? I think I completely glossed right over them thinking they were social media sharing buttons. I undeleted the submission. EDIT: Though, you might do well to participate in /r/csharp (and Reddit in general) outside of your own self-promotion posts so you aren't considered a spammer. I recommend that you read [Reddit's rules](http://www.reddit.com/rules), and particularly their sections on ["What constitutes spam?"](https://www.reddit.com/wiki/faq#wiki_what_constitutes_spam.3F) and [Reddit's guidelines for self promotion](https://www.reddit.com/wiki/selfpromotion).
You can do this in a 1 liner: XDocument d = XDocument.Load("test.xml"); var c = d.Root.Descendants("tree").Select(x =&gt; new Entry() { id = int.Parse(x.Descendants("id").First().Value.Trim()), number = x.Descendants("number").Select(b =&gt; int.Parse(b.Value)).ToArray&lt;int&gt;(), data = x.Descendants("description").First().Value.Trim() }); I did a brief test and this works. What it does is gets the descendent nodes of the xml document that are "entry" and then it does the same for the individual fields you need. Let me know if you have any questions. Edit: this provides an ienumerable of entry. It also doesn't do much checking so be wary kf that
Hello, I am still analyzing, what to do, but I llike this api wrapper from @jogai-san, gaming is option too but didn't game long time ago. I saw wolfram alpha has api, good old wolram is smart, so I could do something with that but still not sure. Todo list with google calendar API is possible too
Can I read and write the entire program to a single line? I can then use regex to insert new lines since every datafield starts with a GUID I can find using regex.
Thanks for the great work, going to take a peek at it now
Options as I see them. 1. Use Odata, and have appropriate client side tools that can use Odata api. There is good support for linq query mapping... as long as you do not need aggregate operations. http://www.odata.org/ 2. Use dynamic linq to parse a string to an expression. There are packages for this, and the parser code is available as a sample with visual studio installs. https://github.com/kahanu/System.Linq.Dynamic 3. Instead of writing a string parser, just take the the filter object, loop over its properties and map to an expression. On injections: If you parse to an expression tree, and use something like EF then you do not have to worry about linq/sql injections. You would be white listing what expressions are allowed (AND, OR, Select, etc) and that is the same result as just building the query in code. Dynamic linq's parameterized .Where("foo = {0}", 'BAR') as secure as the normal .Where(x =&gt; x.Foo = 'Bar'). However, if you use the compiler, Rosyln, or something like CsScript and dynamically compile the query to run it, you are open to every form of code injection.
Without looking at your post Im going to go ahead of saying the bug is not with the framework (trust me I've checked a hundred times).
I discovered today that F# 4.0 has `toObj` and `toNullable` methods for Option types. That would definitely make the Interop smoother. 
You can alias `Func&lt;string, string&gt;` with `FubarSelector` instead of declaring a full blown delegate. 
Removed: Rule 4. You're going to have to just start diving in. Plenty of resources available online on how to work with login systems (try to use a 3rd party authentication provider, say that hooks in with Facebook or Twitch), how to work with databases, and so on. If you have any questions about _specific_ issues that you encounter while making your attempt, then feel free to post questions about those isolated issues.
I would recommend not getting a book yet as .NET Core 1.0 is still really new/subject to change/best practices may not be established just yet/ still gaining popularity. 
Thanks for the explanation. I guess im confused on why all class functions wouldn't be public.
There are some functions I simply do not want other classes to be able to use, but if I use the class as the base for inheritance, I want to the new class to still be able to use it. It's easier to understand, for me at least, when you think about variables. Some variables should just not be exposed to outside sources or exposed only in special ways (via a method).
To hide implementation details that you dont want exposed to other classes, mostly if you plan on having other developers use your code For example public class Animal() { private int Age; private bool isAlive; public Animal() { age = 1; isAlive = true; } public void Age() { if(isAlive) { age++; if(age &gt; 100) { Die(); } } } private void Die() { isAlive = false; } } Here you see that if YOU were to create an Animal, the only method you can call is "Age()"; That way, I can be sure to control that you only do things the way I want. So basically, you're forced to do something like public class Main() { Animal a = new Animal(); a.Age(); } You cannot call a.Die(), triggering a death before I want you to be able to.
Let's say you're writing an API and you have internal functions that may change over time. Internally you may want to rewrite your application without breaking compatibility with those utilizing your API. By marking functions/variables you can restrict people from relying on a potentially changing API. You can then expose stable public functions that you intend to be used. This also benefits intellisense, as it will only show the usable set of methods/properties/fields. You can still use reflection to access private/internal.
Python subscribes to the "we're all grownups here" philosophy and allows the developer to access members which he is not supposed to access. The Python language does not have the concept baked in the language itself but programmers use convention and try to play nice. C# subscribes to the "most people are idiots" philosophy and tries to slap you as much as possible if you try to do something stupid. therefore when you write a class you say which members are private and which are public and if someone misuses them they get a compile-time error. Obviously C# does it right. Most people are indeed idiots and will do stupid things if they are not slapped.
You know, software patterns were first formalized in the mid 90s and people had been programming professionally for 20-30 years before that. Some knowledge, especially formal knowledge, doesn't just appear in your mind spontaneously. 
There are many reasons, here are 2: 1. providing various contracts on how a type works; for example if you have an immutable tuple type, it might be more efficient to not actually have an immutable type behind the scenes (one such example is `string`; there are ways to actually mutate them with unsafe code and reflection, but from a public api perspective a string is immutable) 2. Sharing thread-unsafe code in members of a class that is otherwise thread safe. If for example you were able to manipulate the lock object that a type uses, you can cause deadlocks or potentially even gain access to data you weren't supposed to be able to get.
Thanks for your work. I have been using the library and really like it so far.
Thanks, I'll try it out.
`public` - visible to everybody, everywhere. `private` - visible only to objects of this type. `protected` - visible only to this type and its children. `internal` - visible to everybody in this assembly. `protected internal` - visible to everybody in this assembly, and to children of this type (regardless of what assembly they're in). A type (class, struct, interface, enum) directly under a namespace may be `public` or `internal`. A type nested under another type may also be `private`, `protected`, or `protected internal`. This sort of access control allows one to encapsulate and hide information, which makes for looser coupling of types and methods. Also, if the class explicitly implements an interface, the interface methods are only going to be available if the class is first assigned to a reference of the interface type. Like so: public interface IFoo { void Foo(); } public class ExplicitlyImplementsIFoo : IFoo { void IFoo.Foo() {} public void Bar() {} } var x = new ExplicitlyImplementsIFoo(); //x.Foo(); // won't compile! x.Bar(); IFoo foo = x; // or var foo = (IFoo) x; or var foo = x as IFoo; Note that x is IFoo will return true. foo.Foo(); All of this can be worked around with reflection. Using reflection to access non-public parts of an object is pretty gross, though. Not tremendously difficult. Just gross.
So, I don't know anything about RNGCryptoServiceProvider, but if it uses a random number generator it's better to initialize it as a class-level static field and use it in methods. The reason for this is that if two RNGs are instantiated too closely to each other they could use the same seed and thus output the same sequence of "random" numbers. So something like this: public class foo { private static Random _rng = new Random(); public void bar() { // Use _rng here } public void blah() { // Use _rng here, too } } If this doesn't apply here, you can disregard this comment. :)
Wish there was a plugin like this for remote debugging of Mono! Seriously, how on earth can one not exist? Sure there are occasional rumours of one, but it apparently only works in Xamarin Studio or MonoDevelop. Really weird they never made one for VS, and I guess they don't have any motivation to now with them being bought by MS. Really sucks, would be so useful for debugging my C# code running on embedded Linux ARM boards.
Agreed. Although if you already understand C#, the [documentation](https://aspnet-aspnet.readthedocs-hosted.com/en/latest/intro.html) includes example snippets and solutions from GitHub.
Ooooo, this was well done. Thanks a lot, I understand it now :D
Alright, im starting to see the bigger picture here. Thank you.
After you have downloadet and installed mono in your Windows system you should be able to Switch to target mono in the project settings 
does this work for UWP?
If the project is an internal dependency used in one solution then you don't have to worry about it. If the project is an internal dependency shared across multiple solutions then you still don't need to worry about it (the solution will get the updated bits when it gets rebuilt). If the project is used as an external dependency then you might want to look at making it a NuGet package and managing versioning that way (even if you only just maintain it in a private repository or folder). Obviously all of your projects should have unit tests that verify baseline functionality at the very least.
If you create a library project, and make it a "project reference" in other projects; then the dependent projects will take any update to the library as soon as the library changes. In terms of ease of dependency and version management, it goes like this: Project References &gt; NuGet References &gt; Direct DLL references. That last one is called "DLL hell" and should be avoided.
Ahh makes a lot of sense. Didn't really realize the project reference, and just assumed I was stuck with DLL hell. I'll look into that. I'll just have to figure out how to make sure everyone keeps using the latest version with version control, so they don't accidentally publish with an older version.
If only this was Xamarin Forms compatible because I just started my first project in it!
Am entry level developer. Can confirm I am an idiot.
As a note, those Wrox books are great as reference material, but I would not recommend them to "learn" a language. I had one for a programming course once, and it was useless to me.
The official term is "pit of success". But yes, .NET does go out of its way to make it hard to do the wrong thing.
Basically, it's all about a design philosophy that focuses on limiting users (i.e. other people using your code) to the bare minimum required for your classes to produce the desired functionality. It's about limiting the ways in which other people can break your code and produce unintended behavior. If you're not using a class the right way, you don't have to wait until it bugs out during runtime to find out that you need to double check the documentation. The main use case for the `private` modifier is to control the state of an object. Marking a member variable of a class as private, and then making public functions that control what values can be assigned to those variables. Imagine you had a time class, that is supposed to represent a value using the 24 hours per day time system. You would have variables in the object represent a number of hours and a number of minutes, and you would want to enforce that the hours variable cannot be any higher than 12 or 24, for example. C# in particular has properties, which simplifies the interface for these variables. Private functions are a lot rarer, in my experience. The only time you'd ever want to have a function be private is if it's just some bit of code that you've factored out of your other functions, that wouldn't necessarily make sense to be called from outside of the class.
I never made a wrapper class before. I did a quick google search and it seems a little confusing. Do you know any good tutorials for learning on how to make a wrapper class? Thanks a lot!
Check my latest EDITx3, that might help.
Roslyn? No idea.
I used pInvoke system calls to automate a GUI program at where I work. The GUI is old so there is no API for it for automation purposes. At the very start of the program I lock the keyboard and mouse from the user just in case the mouse is moved. It then finds, moves, and resizes the GUI program so any position clicks are correct. It then goes through a list of clicks and keyboard inputs and when finished it emails the the group email of all the devs, releases the mouse and keyboard and exits. If an error occurs, it emails us with the exact error message, releases the kb and mouse and exits
If worse comes to worse, you could probably check out the 3.1 branch on the StructureMap Github project and look at the documentation there. Why can't you use 4.x though? I don't see any reason it wouldn't work with MVC 5...
DevOps lead here. Humility. You will go far. It's the self-proclaimed geniuses that screw things up.
Correct answer
Started with php(school + german 'ausbildung', without OOP) and did a year of c# ... how are people even allowed to start with php. I understand so many things now that I have started with c# and visual studio beating me the fuck up when I have a wrong scope.
yeah, I guess so. Like this: http://www.tugberkugurlu.com/archive/compiling-c-sharp-code-into-memory-and-executing-it-with-roslyn Generate a method concatenating the right strings and pass the db context into it returning a list. Looks like fun to do, but would it be a stable option for real production use?
* Angular 1 is renowned for failing to support standards and initial accessibility support was terrible. I'm hardly surprised * Same with Aurelia. In fact, I don't even know what it offers over Angular 1 * Fair enough * Polymer is based upon Web Components, not HTML. Totally different concept.
Hey. I saw that there seems to be a question similar to yours with some answers referring to LINQ. http://stackoverflow.com/questions/6467798/how-to-merge-2-xml-files-with-c-sharp?rq=1 I've done something similar in Java, where I made use of the [DOM](https://msdn.microsoft.com/en-us/library/hf9hbf87(v=vs.110\).aspx) sort of the same way the LINQ does. Another link in that thread I linked points to [this](https://support.microsoft.com/en-us/kb/311530), which looks like what you've been using to begin with. I'm not entirely sure where your problem lies in using this. It seems like you're trying to read the XML for the first dataset several times both before and within your foreach loop. As you can see in the example in the Microsoft tutorial, they only merge the second dataset into the first once, and then call the WriteXml for the first dataset.
The problem is that it works fine for 2 files. It's difficult for me to create loop for datasets and in any situation it creates some weird XML file. And ds2 needs to be merged into already created XMl file, this is why im trying to read XML. But thanks for help anyway! :)
C# supports optional parameters, but I'd like to caution against their use. It's almost always a bad idea to use these. In your example, I'd instead recommend using an set of numbers as a parameter, or possible a `params` argument `int AddSomeNumbers(params int[] nums) =&gt; nums.Sum();` which you'd use as as `AddSomeNumbers(1,2,3,4)`. The most important problem to (in my eyes) is that they discourage encapsulation and thus encourage messy code. There are also have some technical issues, and they furthermore don't play well with other language features. So, problems... - they make it less painful to define methods with many parameters. But nobody wants to wrap a method with many parameters, because you need to copy that huge argument string. Oh, and if you do, then it's a pain to ever change the order of the arguments (because you are going to keep the two methods in sync, right?) or worse, you end up with several methods taking mostly the same but not quite arguments with small, arbitrary, bug-prone differences. You **want** it to be painful to have many parameters - instead, **use an object** to store all those parameters. - they're defined at the method, and *only* that method can use that definition. For example, if you need to *wrap* that method (i.e. encapsulate it) and want to pass along all those arguments, you'll need to copy the default value to the second method. Oh, and of course you'll need to keep those multiple places in code in sync or else you'll have really confusing behavior. Imagine e.g. needing to define `PrintAverageOf(string label, int a, int b, c=0)`, and then dealing with both changes you want to make to the underlying `AddSomeNumbers` and e.g. making the `label` optional too... Instead, **use an object** - which can support default values, and crucially can either have multiple methods defined on it, or have multiple methods taking it as a parameter. - they need to be placed at the end of the parameter list, regardless of whether that makes sense for your use case. E.g. a `PrintAverageOf(string label="Average: ", int a, int b=0, c=0, d=0)` is not valid. Instead (you may sense a refrain here) **use an object**; Field order is orthogonal to whether they're default or not, and not just that, order isn't as important because members are named. - There are complicated technical reasons that mean changing the default value can cause surprising problems if you use multiple projects (dll's) and don't always recompile everything. That's a a bit of a corner case, but the problem is that although they're defined by the call**ee**, they're resolved (compile-time) by the call**er**, which means that if you compile against a different version than you run against the method may in fact have a different default value depending on which code path calls the method. Really rare, but really confusing if it happens. Instead.... **use an object** which doesn't have this problem. The constructor and/or field defaults are always defined and controlled by the defining class or struct, regardless of the code creating it, even in the face of asking-for-pain build processes. - Optional arguments enable code to handle multiple scenarios in one method. But doing so is a violation of SRP (the single-responsibility-principle), which typically leads to maintenance headaches (Much has been written about SRP, so I'm not going to go into more detail here). - Optional arguments are defined by "the" method - except that if you're as precise as a compiler, that's not actually very clear. What happens when you mix overloads with optional arguments? How about default values in defined in overridden methods? How about optional arguments with `params` arguments? More complexity == bad, and sometimes buggy. Even if you know all the rules, making yourself think about these interactions while coding is just a waste of time. (My rule is to write code any idiot can support, since chances are you're going to be that idiot yourself, and why make life hard on yourself?) - Optional arguments must be compile-time constants, which encourages nasty hacks like using `null` where it's really not appropriate just so you can replace that null with the *real* default later - silently hiding bugs that inject null from elsewhere, and complicating null-ability reasoning throughout your codebase. My rule of thumb is to never use optional arguments unless there are overwhelming usability advantages. And I'm talking methods you define once but use *at least* hundreds of times, and where it's very unlikely that you'll want to wrap it and/or ever evolve the API. Even then, often overloads are better: yes, it's annoying, but there may be efficiency gains, and if you're talking at least hundreds of usages, then small annoyances once hardly matter much. Even better: use objects! It's truly trivial to define a `class SomeNumbers { public int a, b, c; }` with an (extension or instance) method `Add` - and hey, if you do that, you get names, and have a coding pattern that properly scales to many parameters, and you can encapsulate it, etc (see above list of optional argument downsides). 
Thanks, I'll take a look at this. 
Do you do any magic for improving WPF animation quality? Your stuff looks so smooth. My stuff is choppy sometimes especially with material morph animations and when rendering at 4k, im suspicious of DropShadowEffect for affecting animation and rendering quality. Also did you override your global Timeline/Storyboard DesiredFramerate or just leave it at default?
In XAML, you declare "enemyResources". In C#, you try to use "EnemyResources". The languages are case sensitive, so you'll have to make sure they match.
How are you hosting this Page? It should be inside a Frame or Nav Window - may be the error is in that host container?
I copied your code into a Windows 10 application. A few things: You use "random.Next(...)", but I don't see anywhere that random is ever declared. You have a "text_changed" event that doesn't have a corresponding event in the code-behind. After I fixed those problems, the app builds. It doesn't actually do anything, but it runs.
From the comments, at this point I would suggest restarting from scratch. Start with the blank page that's produced by Visual Studio as part of the default template, run the application, make sure it works. Then add one control/part at a time, re-running and confirming it works. Keep up the process until it crashes again (then you can dive deep and repost the issue here) or you finish the exercise without errors. If you do manage to get it working, then maybe you can do a 1:1 comparison of your broken application with the working one and if you're lucky, perhaps the issue will be apparent.
I don't actually know. For me, random.Next() shows as an already declared function and I can use it. It even showed me a very relevant error when I missed a parenthesis. See, I'm so new to this I pretty much have no idea. The book was like "hey, put this code into the IDE" and I did that. 
Roslyn itself? Sure. Policing what your team tries to dynamically compile, ensuring security, and making sure you have error handling will be important. 
Hmm, it works in localhost already. So i guess this is not my problem. 
Smart git 
Probably, I want to give it a shot to this community to see if there is anyone who may be doing network programming as of late to give some insights.
I get that, I think the cryptography on never roll your own is mostly about writing your own algorithm which I didn't do, because I used BouncyCastle library for all of those algorithms you see here. As for Scheme, it's a lot like TLS, but taken in different approach to how many time key exchange happens and how keys are stored in password protected database (similar to SQLite.)
Removed: Rule 3. As suggested, /r/netsec and /r/crypto are better bets to get better opinions on the matter.
It's written and is for C#, so I can't write anything that adjacent to C#?
&gt; I think the cryptography on never roll your own is mostly about writing your own algorithm Not just that, it includes combining algorithms in different ways. Just because you used trusted library X for the actual cryptography implementation doesn't mean that **how** you use it is correct, and the devil is in the details.
But isn't this what the linq solution is doing? Union selecting the second time in to the first? You should be able to just union as many xml datasets as need be, Union isn't limited to one dataset. 
Maybe provide source code and a write up for it, but as it stands, the content of what you've posted and the questions you're asking are about security/cryptography theory and have nothing to do with C# whatsoever.
For additional clarity, I'm using tags to flag bugs and features that came from salesforce and I want to automatically email the associated clients and our tech support team when those items are being worked on and/or completed.
I couldn't find anything. Wound up just using the rest api to do what I needed.
I think there is a missing line on the top, that is required for all xml files: &lt;?xml version="1.0" encoding="UTF-8"?&gt; It's probably different for xaml so check out what it is in a default file.
Yeah I've used a bit of the alert settings, but mostly with regard to the team rooms which is directly for my own team. I'd really like to alert outside stakeholders about changes.
Well, if I remember on Monday morning, I'll pm you any pertinent code I have. Pm me if I forget.
Microsoft Engineer here on "why it happened": Visual Studio doesn't always play nice with XAML, and a lot of times even just restarting VS clears up the problem. This varies from product to product, with products like WPF seeing fewer errors and God-forsaken products like Windows Workflow seeing regular mysterious issues.
An alternative to wix might be inno setup which can launch a bundled exe (and you can provide a checkbox to ask permission if you want). 
Will do thanks buddy
Because some people can only start with PHP, or only capable of starting with PHP lol. PHP is a poorly designed languages, it has improved a lot from before but even now its still sub-par compared to most languages. However, it has low barrier of entry, the LAMP server cheap hosting options are available with little competition. This was especially important in the early days of web programming, and PHP grew in popularity quickly in the late 90s and early 00s. Moreover, there are too many libraries and open source software/applications written in PHP. If you want your own application to integrate properly with popular open source software, you may have to write in PHP. PHP has reached a state that is essentially too big to fail, unless dramatic turns of events happen. And just as the author of 'The PHP Singularity' pointed out: &gt; If you want to produce free-as-in-whatever code that runs on virtually every server in the world with zero friction or configuration hassles, PHP is damn near your only option. So you see, even for advanced coders/programmers, they still have to consider PHP for practical reasons. Its a vicious cycle, and cannot be broken unless something drastic happens. C# going to Linux is a step forward, but I am afraid it may be too late(it would've made a bigger difference back in the old classic ASP days, which used to run only on Windows servers). Read the article 'The PHP Singularity' and you will understand more: https://blog.codinghorror.com/the-php-singularity/ 
Not the original question, but if I had to guess on that XamarinStudio issue, that issue is most likely caused by your Desktop Scaling setting. A lot of apps don't scale correctly, and most new computers are set to more then 100% scaling. If you set scaling to 100%, that might fix the problem. Only issue then is everything on screen is going to be smaller.
Well in Python they are all grownups and nobody is violating it. Ha! Hahahaha!
It's a Universal Windows app.
The default code doesn't have this line, at least not in Visual Studio 2015. I may have missed is though.
I edited StackOverflow question, it should be clearer :)
This is slowly becoming no longer the case. The idea of "drop PHP files on your LAMP server" is going away in favour of dedicated app servers, and reverse proxies and containers to tie it all together.
C# Interactive. Very helpful to be able to play with an idea a little bit without needing a whole other "sandbox" solution. A close second for me is "Go to Implementation" on interfaces. My company grew from its original size using contractors. Contractors are usually all right, but some have no earthly business using a damn keyboard. Peeking behind an interface helps catch implementation defects that were never properly unit tested against.
Evaluating lambdas while debugging.
That's in 2015 already
Ohh right. I don't understand why Microsoft can't name things properly.
Can you read all text into a string, split it into an array, removing all empty entries and then apply your logic? string fileText = File.ReadAllText("Test.txt"); var fileTextArray = fileText.Split(new string[] { "\r\n" }, StringSplitOptions.RemoveEmptyEntries); Pseudo code written from my phone, but I think you get the point.
I know that. It's still bad naming.
Yeah, I actually double checked it before I started this thread so I didn't make a mistake. But I guess they're gonna change it to visual studio 2016/17 later? If they don't plan to just go with version name from now on. 
Very helpful.
I'm guessing you haven't reset the 'correct' variable and then your while loop is terminating. Have you tried single-stepping through your code in the debugger? That will give you lots of insight into what's happening. Some other thoughts: * check out the 'break' keyword. It lets you exit from the loop (rather than waiting to get to the end of the loop). It will let you get rid of the 'correct' variable * check out the 'switch' statement. It simplifies many if-else-if-else-if-etc statements... and makes the code a little cleaner. But not really worth using if you've only got two options. * in terms of gameplay, if your inputs are always from a fixed set of choices, consider using Console.ReadKey instead of Console.ReadLine (e.g. present options like "Press Y for Yes, N for No") * Advanced: as you improve as a programmer you'll learn to separate your program data from your program structure... so your game 'screens', choices, and next steps would be described in a class instance and your game code would keep track of the current screen and present the attached options edit: formatting
Thx so much dude, I am gonna check it out!!
Also, If-elseif is helpful because it can skip code. Back to back ifs like your example are pointless because it can't be both values.
If you are using "else if", you are doing it wrong. Use "switch / case" wherever possible instead.
I see thx!
Is this only from update 3 then? I read the title as "new VS 15 features" as compared to old versions of VS.
Thanks for the input! And yes, I'm using the latest version. I update VS the moment I notice a new update :D
Edit and continue is insanely useful for animation, but it keeps crashing for me. Blend 15 is also super buggy on both my home and work dev PCs
They also called VS2015 VS "14" up until it was an RC. More than a few people also believed that it was VS2014 and were quite confused when it "missed being released in 2014" edit: example: https://blogs.msdn.microsoft.com/somasegar/2014/06/03/visual-studio-14-ctp/ &gt; The pace of updates is pretty impressive. I hope by the end of the year I will be able to use most of C++14 features in VS 2014 and &gt; It says it has known compatibility issues.. how about seeding a VM with VS 2014 installed to test out? etc.
Didn't realize it, my company skipped the version!
If those two code snippets are in the same method, make sure that `correct` is reset before the block. This will be easier to keep track of if the `correct = 0;` statements occur immediately before use, instead of immediately after. Even better would be to split these into separate functions, use a `boolean` instead of an `int`. It may even be worth sticking the comparison in the `while` loop condition, instead of setting a variable. var isCorrect = false; while (!isCorrect) { var input = Console.ReadLine(); if (string.Equals(input, "yes", StringComparison.OrdinalIgnoreCase)) { isCorrect = true; } else if (string.Equals(input, "no", StringComparison.OrdinalIgnoreCase)) { isCorrect = true; } } Finally: you don't need the `else` branch if it's empty.
I feel your pain. We had to choose between ASP.NET Core MVC and ASP.NET Web API for our microservices, and we ended up going with the non-Core stuff. We wrote a blog post [here](https://blog.uship.com/shippingcode/self-hosting-a-net-api-choosing-between-owin-with-asp-net-web-api-and-asp-net-core-mvc-1-0/) about our decision and how to set up OWIN as an alternative that should map over to Core somewhat decently once all the kinks are worked out. That being said, I have high hopes for the new stuff to be successful soon.
Yeah I'm definitely venting a little after taking a break from debugging a few of my controllers that just weren't accepting params... But I still do have high hopes. Hope is just a little low at the moment.
How would you traverse the tables? You mean as in iterate IDs with something like a for loop? Why would you want to do that?How does it select by ID with them? The GUID is the ID. But to be honest, it depends on what you mean when you say "ID". For example, are you talking about the record's primary key, or are you talking about an Entity's unique identifier? Or are you calling the same thing for the sake of conversation? There are a few different schools of thought on this, but I'll speak from a personal point of view... Depending on your design methodology, one could argue that an Entity's ID should be assigned by the domain rather than auto-incremented by the database. The reasoning being that by using an Identity within the app domain, you are coupling your app domain to the data implementation. If that were to ever change.... it... might not be so easy. So in DDD, for example, the domain would assign the ID and it would be a GUID because they're global and can be used in any data implementation and don't need to be generated by the DBMS. If your implementation is a SQL database, then you may still want your primary key to be an integer and you're free to do so, but your application's domain would know nothing of this integer because that is an implementation detail. Some swear by GUIDs as for IDs (it's in no way some new fangled concept), and I'm slowly starting to adopt the same thought. In DDD, it's a must. But it also seems like it would make data integrity easier to maintain during things like data migration and such. I haven't stopped using auto-incremented integers as PKs yet, but I'm wondering... they're both just 32-bit value types, so what's the real difference other than readability? I haven't done my homework on performance implications but it was my understanding that there isn't any.
We use core for our new platform and its been all good for us. The occasional headache here and there but it's by no means a failure. I love being able to dev in OSX while the rest of the team can use whatever they are comfortable with. All our builds and deployments are still all automated too. Sorry to hear you don't like it but we love it.
Could you elaborate a bit on what exactly is going wrong with the web api, because i like working with webapi 2? I've tinkered with core mvc a bit and didn't really run into problems, no clue about webapi though. 
&gt; I started a project about a month ago So you started before 1.0 version was released? Maybe you shouldn't use pre-release software if you're not willing to accept pre-release quality. &gt; I'm non-stop debugging errors that shouldn't be happening. Couldn't you be more vague? From what you said, I can't tell whether those were actual issues in libraries, issues with tooling (which is still in preview), whether it's just because it's different from what you know, or whether those are your mistakes. &gt; And even worse there is next to no documentation on anything. There are still some holes in the documentation, but I think they're pretty small. Also, way to be non-specific again. &gt; It feels like everything that I use to do in earlier versions is completely changed and I'm stuck looking for different ways to do something extremely simple. That was the promise of ASP.NET Core: that it's going to be new and different and in exchange you gain modularity, efficiency, and being cross-platform. If that does not seem like a good trade-off to you, then you should stay with ASP.NET, it's not going away. &gt; I completely regret my decision to choose Web API Core as my backend framework. Maybe the problem is that no such thing exists?
Uhm, Guids are 128-bit integers, not 32-bit.
&gt; Are they actually a sort of dictionary, with the GUID as the Key and an int string as the value? Simply: yes, but implementation is not the same as in Dictionary class. 
Let's see some code and the problems you were having. 
1. Your class is initialized, the constructor runs. 2. Your view is initialized. It binds to the observable collection in the property. Since you did not assign anything up to this point, the value is `null`. 3. Now your `Initialize` method is running and you assign something to the property. Since the property does **NOT** implement the property changed notification, the view is not informed about the new value in the property. By setting the collection in the constructor you assign a value to the property before the view binds on it.
awsome, thx dude!
that's pretty much what i figured thanks for the clarity. i've moved forward in dev more in the last hour than i had for the previous four lol.
Look into Visual Studio Express and SQL Server Express. They are free.
I use Visual Studio community for everything already, but SQL Server Express still requires a Windows license. I want to use Core so I can host it on a Linux machine.
ah, okay. Sorry I'm a long time Windows developer, so I can't be too much help on this. It will help others if you can be more specific about the issue you are having with getting MySQL to work with .Net.
I haven't actually tried it (I use MSSQL), but [PostgreSQL](https://www.postgresql.org/) via [Npgsql](http://www.npgsql.org/doc/efcore.html) is supposed to be fairly well supported if you're trying to avoid licensing fees and MySQL isn't working for you.
Oh awesome! I've never worked with PostgreSQL, but I'm sure I can figure it out. I'll definitely give this a try!
For non-production you can use the developer version for free: https://blogs.technet.microsoft.com/dataplatforminsider/2016/03/31/microsoft-sql-server-developer-edition-is-now-free/
The Git integration happens automatically when Visual Studio sees a .git folder in the working directory. If you are already editing your Mono project in Visual Studio then you just have to open Team Explorer to see the Git controls. I'm not sure you can use Visual Studio without an sln file, however. You could make a new project "from existing code" to make a solution, or an alternative is to use Visual Studio Code, which has Git integration and uses folders instead of an sln file. 
I know this is not what you asked for but in my experience, just using git bash is way safer ... Open git bash (you can just type git bash in the start menu ) and navigate to your solution. Git pull will pull the latest version. Git commit -a will commit the changes and git push will push to your remote. With that you have 80% of all operations...
Keep an eye on Sql Sever 2016 as it is being ported to Linux. 
No, you need either to use EF7 with it or target e.g. NET4.6
[Protobuild](https://github.com/Protobuild/Protobuild) Is kinda like cmake for C#. This will let you setup a checked-in source project definition that protobuild can generate solution files from (and mono / whatever solutions for your friends) [Babun](http://babun.github.io/) Super painless cygwin/linux tools on windows, including git. Not needed, but it's super neato. As far as your actual question goes, there are a few ways to skin it. Protobuild is one way. Another is to create a directory in the repo that's named "Windows" or "Visual Studio" or something similar and create &amp; maintain the solution file there. Another is to go commando &amp; never check in the solution file, relying on maintaining a good local copy. If you want to keep whatever solution/project structure that your friends are using in sync with yours, you're going to need a solution similar to Protobuild. That is, a common, platform agnostic definition that can generate platform-dependent definitions, and keep *that* up to date. 
Why do you want to use VS git integration? At best, it's a minor convenience, and it hides a lot of the actual power that comes from using git from you. The SYNC button was a terrible idea by Microsoft since that isn't how git works. You should already be able to do things like view the history of a file without a sln file. If you need a GUI I recommend SourceTree (particularly since you are using BitBucket). For merge conflict resolution I recommend P4Merge (just the merge/diff tool, not the entire Perforce toolset).
This might be a little late. But you can use VS Git integration without an sln file, but you will have to open and edit the file separately and lose pretty much everything that Visual Studio can offer to you (Intellisense, project build...). You can still click on Team Explorer tab and choose Sync/Changes... etc and then see the changes in there without any trouble. I'm not sure if that what you are looking for. But if you want to just edit the files and then sync it back to the git repo without going through the whole git command line, you can do it through VS, but I would recommend VS' little brother - The [Visual Studio Online](https://www.visualstudio.com/en-us/products/what-is-visual-studio-online-vs.aspx) to do such a thing. 
I'm currently using GitKraken for basic git operations (for basic pull, commit, push stuff it's faster than command line). Have you tried that? I ought to give SourceTree a go, the beauty of git is you can change easily.
Last I used it, the latest version of mySQL was just broke with EF. This was a year or so ago so I'm certain it's fixed by now, but it was a pain to figure out. So just keep in mind that it has been known to just be broken.
SQL server express is free. You can get a SQL server developer license for free. If you just want to learn EF, the actual database doesn't matter much. E: just looked, they made the developer edition free. Just use that. If you want to go to production, you'll have to either buy a license or use a different platform. E2: and I just saw you want this on a Linux machine. Unfortunately i don't think there are developer editions of Windows Server. MySQL *can* work with EF just fine. However I did have issues with a certain version and haven't tried anything with Core, yet.
You don't have to dig such deeper on Routing, if default routing mechanism fits your needs, and probably it does. It is a mistake to go in such detail under the title "fundamentals", imho. i would stick with asp.net core. it has a significant paradigm shift. the key topics to understand are; configuration (Startup.Configure()), dependency injection (Startup.ConfigureServices()), async fashion (Task&lt;&gt; pattern), message handlers, filters. After fully understanding the upper core, and building some projects with it, you could try to learn customization of underlying default services like route, controller and action selection, or maybe you could build some http modules. even self-hosting and owin would be postponed.
Because if you added a Gender, you would have to modify code. See my top-level post for how to do selection with enums, not horrific else-if chaining.
VS git integration is great when you're checking in a bunch of files and want to cleanup them (reorder &amp; remove extra usings) before checking. Those are available in the diff view and you can stage the file when you're done.
Yeah...some full screen storyboards tend to just cut-out on full screen 4k...
So is C# interactive.......
thanks so much.
ah, good to know. 
I am trying to follow the tutorials but got some error. http://stackoverflow.com/questions/38306791/ef-core-does-not-work
&gt; P4Merge How does that compare to kdiff3? 
&gt; The SYNC button was a terrible idea by Microsoft since that isn't how git works. GitHub does it the same, though. Even VS is better here because you can still pull and push independently, but in GitHub it's always both.
Or get Git Extensions. It's a gui for git and it's pretty robust and loads better than visual studio.
Do yourself a favor and just use SourceTree. You're already using BitBucket. https://www.sourcetreeapp.com/
You can read your input with `Console.ReadLine()` from your your console. After that can use `Convert.ToInt32()` or `Int32.TryParse()` to convert your input into a number.
how do I read an integer as an index in an array?
Is UWP any better?
I'm not an expert on API stuff, I've only recently started learning it. But I'm going to try because I have an idea. I *believe* that because you're passing the "testing" variable within brackets in JSON, the controller is trying to read it as an anonymous object (new { value = "testing123" };). So either "value" needs to be passed in the URI (/api/testing/testing123), or you need to set up the Post method to handle either an anonymous object (that's a DTO, I guess?) or a dedicated DTO.
I'm not really understanding what you are trying to accomplish. Do you mean just read the file and display it's contents on another page? If so, yes that is possible, but why are you doing it that way, you'd essentially have to serve up the page twice every time someone views it. But yes, it is technically possible. 
That's not entirely my goal. My goal is to learn how to do this properly haha. So downloading it then displaying is better? 
Is it a web forms web site or MVC? Why is the page outside your project when you publish?
They're coming from a LAMP background, my experience with working with folks from that community is that they want everything for free, so paying for anything is highly unlikely.
I see, ya I learnt a bit about enums but never thought of using them. Always nice to learn more!. thx
Your method expects: a string. Your postman call sends: An object. That does not match.
Not sure exactly what you are looking for, but the Music Store tutorial is excellent and is available for both C#/MVC and F#/SuaveIO http://www.asp.net/mvc/overview/older-versions/mvc-music-store/mvc-music-store-part-1 https://www.gitbook.com/book/theimowski/suave-music-store/details Going through both can be a very interesting way to compare the approaches 
Yeah, I read that UWP doesnt support custom TypeConverters or MultiBindings/MultiValueConverters, I dont know how id do without those things. The AdaptiveTriggers and Setters in VisualStates are cool though.
I thought that OT was trying to use VS as some sort of Git UI and try to avoid creating a sln file. But if creating a sln is okay then it is much straight forward i guess. 
I had checked out Pluralsight, but honestly most of the programs they are showing are for Java. Granted I can go through it and apply it to C# but I really wanted a Visual Studio approach to it. Also FYI , you can get 6 months free of Pluralsight from here: https://absolute-sharepoint.com/2015/12/free-pluralsight-6-month-subscription.html 
Call `Environment.GetFolderPath(Environment.SpecialFolder.LocalApplicationData)` and create a folder for your application under the path that function returns.
From a marketability standpoint, if you want people to look at and contribute to your code then you might want to target .NET Core instead of Mono. It might be difficult to get buy-in on a web project on Mono right now. As far as using an ORM and database approaches, a lot of that depends on how large the project is that you are working on. How many types of entities will be in your project? How many types of database will you support (just Maria/MySQL?). Do you plan to strongly separate your domain logic from your persistence logic?
And we should also celebrate the ease of interoperability between languages in the clr compared to doing interop with C code or other languages 
This is an hour long. Is there a summary available?
derp. it was late.
i'm not sure but i believe it's for security against running unknown scripts. Just like running macros on word and excel files are disabled by default. Try adding this in the begining of the file and see if it helps (it's what i do but i never tried to run the file from linkpad): Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
I've run a .NET site that connects to a Postgres database on both Linux and Windows. Super easy to setup and get working.
Why is it essential to have integration for that? Move the files, then check it in to your version control. Any good version control will work independently of your IDE. Integration, if done well, can add efficiency. Visual Studio git integration was not done well, IMO.
And git add -p or a GUI like SourceTree can do the same thing but better. I'm not totally against using the Visual Studio integration, I just don't think it was done well.
Entity Framework doesn't require the graphical tools at all. Now this is with VS and under Windows; so it might not be what you are looking for... Mono is usually a little bit behind .NET on MS. As another poster said; I'd suggest trying to work with .NET core at this point. http://www.ryadel.com/en/asp-net-setup-mvc5-website-mysql-entity-framework-6-code-first-vs2013/
summary is: Go Native
GitKraken is great, but its clearly new software and has a few bugs. Usually that just requires a restart though.
No, whatever reworking that is available in VS (resharper, recompile, retest) isn't available in cmdline or SourceTree. SourceTree is also likely to just add "File Status" as anything else.
Use entity framework code first. And I'd choose VScode on linux but I've never worked with monodevelop. https://www.microsoft.com/net/core#ubuntu (last item links to vscode) 
I felt the project.json was a step in the right direction. No more having to manually add files to the .csproj project file. Human readable JSON rather than XML. But no. Here's the link to the official obituary: https://blogs.msdn.microsoft.com/dotnet/2016/05/23/changes-to-project-json/
&gt; Human readable JSON rather than XML. XML is also human readable. Besides that, XML has some benefits that JSON does not has: - You can add documentation inline. JSON does not allow to add comments. This point is really really important to me personally. The project.json is **now** already complex. You can include file globs, exclude file globs, include specific files. You can pin versions of dependencies. You can include tools. There's plenty of reason why you'd want to add documentation to your project file, documenting changes and decisions for developers looking at this in 2 years. - You don't have to have two line changes when adding a line in an array/list. JSON requires you to have a comma between entries. Means you need to add a comma before the last entry. Depends a lot on the formatting, but the most common formatting is to add it to the end. Personally I'd prefer something like JSON5, TOML or YAML instead. JSON itself is good for automated data serialization - but not for stuff that **humans** need to adjust manually. The hate for XML is exaggerated anyway. The biggest issue is not XML, but the **complexity** of the csproj file. And that is something they promised to reduce massively.
It's not about XML. Sure XML is vastly more verbose than JSON and has the problem that there is always two ways to do something, but the main problem with csproj and related formats is that they are not declarative.
I think they chose JSON because so few people ever put comments in the .csproj file and because with how many web APIs take JSON, more web developers are now comfortable editing json by hand. That said, I agree with your other points. YAML probably would have been a better choice and more common for the industry. XML has the downside of a much more complicated specification, it's more verbose, and cluttered...but its also very accurate and maps well to many oop model representations.
Very interesting. I'm going to have to try this at work!
It seems quite nice, keep the good work.
Yeah, I've pretty much done something similar with my VS setup. I removed all but the standard toolbar and then placed a few much-needed buttons on there; and then I put all my pop-out windows on one side of the screen. That being said I like having the Solution Explorer permanently open because I feel a bit 'lost' without it. [Screenshot!](http://i.imgur.com/qMvhQXW.png)
I feel you there. I'm building this big complicated thing to run the back end of our system. I'm only building the most important parts while the gaps are being filled in by offshore guys. If I don't give them an example of how to do everything they need to do, they make a terrible mess of things. They can't even handle slight variations of things they've already done. It's slowing me down like crazy.
Or just drag one window to your 2nd monitor.
Reddit is already over there.
Hence the third display. Actually, I have a 21:9 in the middle between two 16:9s, and VS2015 is very usable (with my modifications to make it more like Xcode) on the 21:9 because there is space for wide toolbars, panels, double code windows, etc. For any devs out there looking for new displays, I cannot recommend 21:9 more. You can fit so many files side by side using just VSCode, as in 3, and have them all wide enough to read without too much horizontal scrolling, even without wrapping. I would still recommend a second (or maybe two more) 16:9 display, just for music/reference material/reddit.
"Hide Main Menu" is an essential extension for me. I access the menu bar so rarely, and when I do, it is still accessible under Alt. My studio (I don't like the autohide windows): http://imgur.com/a/ixLGO It is also great habit to use the full screen mode (Alt+Shift+Enter). It hides the VS title bar and windows toolbar and other then that, it it is like a second Visual Studio layout. I use this to move all the subwindows (with exception of file layout) to a second screen (http://imgur.com/a/SfHNf). It is amazing tool to let you to get "in the zone". EDIT: I need to hide the navigation pane, I never use it. Moar screen space!
Definitely some good stuff in here, although I'm not looking for an extremely basic editor out of my IDE. If I did, I'd switch to any number of text editors that have C# plugins. I liked cutting out the margins where the breakpoint bullet point is placed (highlights line red instead for BP). I think I'm going to give hiding the main menu and toolbars a try. EDIT I'm also curious if there is an extension or option somewhere to create a shortcut for enabling/disabling CodeLens. It absolutely gets in the way when I'm working on something alone, but I find it very useful when working on a collaborative project. Didn't seem like it from the shortcuts menu. ALT+` will open up the menu quickly to disable it *when it's already enabled*, but that goes away once it's disabled. Seems like CTRL+Q to get to the search bar and typing 'codelens' will get you there fairly quickly though.
I'm not alone in the world! I only use line numbers, when I analyze crash reports, or exception logs. I'm also planning to get rid of ReSharper. It's about time.
It still removes the title bar and system toolbar, improving your focus. 
I'm still trying to find a way to fit VSCode into my workflow, because I really like the direction it's heading. I totally agree that it's great to have an editor that starts up quickly, unlike VS, but working in VS is such a delight, that leaving is difficult. I can't bring myself to get away from Sublime Text for very quick and simple text-editor actions. It loads so fast, but I'm not a huge fan of the environment because it takes so much work to customize it.
No, it depends on which version of the .NET framework you target in your project. Each Visual Studio has a default version associated with it, and new projects will automatically target that version, however you should be able to target older versions. I don't know if you can target newer versions unless they specifically put out a service pack or other update for VS, though.
In VS you can use older version of C#, but no official way to use the newer ones. So with VS 2015 I can use the ISO-1 version, up to C# 6, while on VS 2013 it's ISO-1 up to C# 5. By default new project created on each VS will be set with the latest C# version, the setting will persist even when the project is opened on different VS, and it can be changed manually anytime.
ok thanks :)
Sure, but I'd argue that is part of development, not part of staging your files for check in. Of course you would use Visual Studio for code changes. 
I can confirm this too. I'm using C# 6 features in Silverlight projects. Most (all?) of the C# 6 features are just syntax sugar and compile to standard IL code.
Or... Alt+Shift+Enter and you go full screen. 
a migration is right this one public partial class rolePermiso : DbMigration { public override void Up() { CreateTable( "dbo.Roles", c =&gt; new { Id = c.String(nullable: false, maxLength: 128), Name = c.String(nullable: false, maxLength: 256), }) .PrimaryKey(t =&gt; t.Id) .Index(t =&gt; t.Name, unique: true, name: "RoleNameIndex"); CreateTable( "dbo.UserRole", c =&gt; new { UserId = c.String(nullable: false, maxLength: 128), RoleId = c.String(nullable: false, maxLength: 128), }) .PrimaryKey(t =&gt; new { t.UserId, t.RoleId }) .ForeignKey("dbo.Roles", t =&gt; t.RoleId, cascadeDelete: true) .ForeignKey("dbo.Users", t =&gt; t.UserId, cascadeDelete: true) .Index(t =&gt; t.UserId) .Index(t =&gt; t.RoleId); CreateTable( "dbo.Users", c =&gt; new { Id = c.String(nullable: false, maxLength: 128), Email = c.String(maxLength: 256), EmailConfirmed = c.Boolean(nullable: false), PasswordHash = c.String(), SecurityStamp = c.String(), PhoneNumber = c.String(), PhoneNumberConfirmed = c.Boolean(nullable: false), TwoFactorEnabled = c.Boolean(nullable: false), LockoutEndDateUtc = c.DateTime(), LockoutEnabled = c.Boolean(nullable: false), AccessFailedCount = c.Int(nullable: false), UserName = c.String(nullable: false, maxLength: 256), }) .PrimaryKey(t =&gt; t.Id) .Index(t =&gt; t.UserName, unique: true, name: "UserNameIndex"); CreateTable( "dbo.UserClaim", c =&gt; new { Id = c.Int(nullable: false, identity: true), UserId = c.String(nullable: false, maxLength: 128), ClaimType = c.String(), ClaimValue = c.String(), }) .PrimaryKey(t =&gt; t.Id) .ForeignKey("dbo.Users", t =&gt; t.UserId, cascadeDelete: true) .Index(t =&gt; t.UserId); CreateTable( "dbo.UserLogin", c =&gt; new { LoginProvider = c.String(nullable: false, maxLength: 128), ProviderKey = c.String(nullable: false, maxLength: 128), UserId = c.String(nullable: false, maxLength: 128), }) .PrimaryKey(t =&gt; new { t.LoginProvider, t.ProviderKey, t.UserId }) .ForeignKey("dbo.Users", t =&gt; t.UserId, cascadeDelete: true) .Index(t =&gt; t.UserId); } public override void Down() { DropForeignKey("dbo.UserRole", "UserId", "dbo.Users"); DropForeignKey("dbo.UserLogin", "UserId", "dbo.Users"); DropForeignKey("dbo.UserClaim", "UserId", "dbo.Users"); DropForeignKey("dbo.UserRole", "RoleId", "dbo.Roles"); DropIndex("dbo.UserLogin", new[] { "UserId" }); DropIndex("dbo.UserClaim", new[] { "UserId" }); DropIndex("dbo.Users", "UserNameIndex"); DropIndex("dbo.UserRole", new[] { "RoleId" }); DropIndex("dbo.UserRole", new[] { "UserId" }); DropIndex("dbo.Roles", "RoleNameIndex"); DropTable("dbo.UserLogin"); DropTable("dbo.UserClaim"); DropTable("dbo.Users"); DropTable("dbo.UserRole"); DropTable("dbo.Roles"); } }
 public partial class rolePermiso : DbMigration { public override void Up() { CreateTable( "dbo.Roles", c =&gt; new { Id = c.String(nullable: false, maxLength: 128), Name = c.String(nullable: false, maxLength: 256), }) .PrimaryKey(t =&gt; t.Id) .Index(t =&gt; t.Name, unique: true, name: "RoleNameIndex"); CreateTable( "dbo.UserRole", c =&gt; new { UserId = c.String(nullable: false, maxLength: 128), RoleId = c.String(nullable: false, maxLength: 128), }) .PrimaryKey(t =&gt; new { t.UserId, t.RoleId }) .ForeignKey("dbo.Roles", t =&gt; t.RoleId, cascadeDelete: true) .ForeignKey("dbo.Users", t =&gt; t.UserId, cascadeDelete: true) .Index(t =&gt; t.UserId) .Index(t =&gt; t.RoleId); CreateTable( "dbo.Users", c =&gt; new { Id = c.String(nullable: false, maxLength: 128), Email = c.String(maxLength: 256), EmailConfirmed = c.Boolean(nullable: false), PasswordHash = c.String(), SecurityStamp = c.String(), PhoneNumber = c.String(), PhoneNumberConfirmed = c.Boolean(nullable: false), TwoFactorEnabled = c.Boolean(nullable: false), LockoutEndDateUtc = c.DateTime(), LockoutEnabled = c.Boolean(nullable: false), AccessFailedCount = c.Int(nullable: false), UserName = c.String(nullable: false, maxLength: 256), }) .PrimaryKey(t =&gt; t.Id) .Index(t =&gt; t.UserName, unique: true, name: "UserNameIndex"); CreateTable( "dbo.UserClaim", c =&gt; new { Id = c.Int(nullable: false, identity: true), UserId = c.String(nullable: false, maxLength: 128), ClaimType = c.String(), ClaimValue = c.String(), }) .PrimaryKey(t =&gt; t.Id) .ForeignKey("dbo.Users", t =&gt; t.UserId, cascadeDelete: true) .Index(t =&gt; t.UserId); CreateTable( "dbo.UserLogin", c =&gt; new { LoginProvider = c.String(nullable: false, maxLength: 128), ProviderKey = c.String(nullable: false, maxLength: 128), UserId = c.String(nullable: false, maxLength: 128), }) .PrimaryKey(t =&gt; new { t.LoginProvider, t.ProviderKey, t.UserId }) .ForeignKey("dbo.Users", t =&gt; t.UserId, cascadeDelete: true) .Index(t =&gt; t.UserId); } public override void Down() { DropForeignKey("dbo.UserRole", "UserId", "dbo.Users"); DropForeignKey("dbo.UserLogin", "UserId", "dbo.Users"); DropForeignKey("dbo.UserClaim", "UserId", "dbo.Users"); DropForeignKey("dbo.UserRole", "RoleId", "dbo.Roles"); DropIndex("dbo.UserLogin", new[] { "UserId" }); DropIndex("dbo.UserClaim", new[] { "UserId" }); DropIndex("dbo.Users", "UserNameIndex"); DropIndex("dbo.UserRole", new[] { "RoleId" }); DropIndex("dbo.UserRole", new[] { "UserId" }); DropIndex("dbo.Roles", "RoleNameIndex"); DropTable("dbo.UserLogin"); DropTable("dbo.UserClaim"); DropTable("dbo.Users"); DropTable("dbo.UserRole"); DropTable("dbo.Roles"); } }
You should speak with them about getting you an MSDN subscription.
probably the Program's installation directory can be the best place to store that kind of files, plus it's much easier than other methods (such as %appData%. something like: Your-Program-Installation-Folder\Data\{Your file} will do.
&gt; I'm also planning to get rid of ReSharper. It's about time. Why?? When i dont have R# i code at like 40% efficiency and i get annoyed at everything
my two cents.. - dont use {T} in your generic class filenames ever. just name it normally. see List&lt;T&gt; from msft is simply List.cs https://github.com/dotnet/corefx/blob/master/src/System.Collections/src/System/Collections/Generic/List.cs - if you want to split the files it should be XXX.cs and XXXBase.cs (exactly as the class names are) - you may combine the two files if the base isnt really used elsewhere; judgment call. At the end of the day it needs to be easy to find/navigate to. Any dev should be able to 'find in solution' 'find in folder' and 'ctrl-,' so this isnt an issue.
Looks pretty nice :)
I would put them both in one file if both classes are the same name.
Thanks. Glad you like it!
That looks quite interesting. I will give it a try for more next prototype.
Oh thank God. One of my few .NET experiences had me wrapping a RESTful API and I found C# horrendous for building up URIs.
Never knew I needed this until now. Hot damn.
To be honest I'm not as familiar with the portable fork, but I've been using it in a new Xamarin.Forms app over the last few days and it has fulfilled all my needs so far. 
This is like hot electric sex!
I think I'd be better off learning the concepts over again as I'm a bit rusty. I used to program in VB but that hardly counts.
Are you looking for paid or free resources? If paid, I can point you to some really nice courses on C#.
Very nice. Thanks for sharing this!
BTW, I am assuming you've already downloaded the Express tools to poke around with, yes?
Been using prefix for about a month now. It is quite handy. But one word of warning - it currently doesn't play well with dottrace
[removed]
Thanks, I'm glad you like it! The reason I designed it this way is because I anticipate that building a string URI will in fact be more common than building a `Uri` instance, so readability being one of the main goals of the library, that case deserves a convenience method. But it is really just a matter of personal preference. I like this: FluentUriBuilder .From("http://reddit.com") .Path("r/csharp") .ToString(); More than this: FluentUriBuilder .From("http://reddit.com") .Path("r/csharp") .Build().AbsoluteUri; Because the former makes the intent of the code clearer.
Remember counting starts at 0, not 1. So entering two is Sachiel. So you have 18 names, but Lilin sits at index 17 as Adam is index 0. using System; namespace Reddit_Help_Console { class Program { static void Main() { string[] angleNames = { "Adam", "Lilith", "Sachiel", "Shamshel", "Ramiel", "Gaghiel", "Israfel", "Sandalphon", "Matarael", "Sahaquiel", "Ireul", "Leliel", "Bardiel", "Zeruel", "Arael", "Armisael", "Tabris", "Lilin"}; var userInput = Console.ReadLine(); int index; if (int.TryParse(userInput, out index) &amp;&amp; index &lt; angleNames.Length) { Console.WriteLine(angleNames[index]); } } } }
Technically, it depends on the compiler, but that's bundled up with Visual Studio. Visual Studio can target earlier versions of the framework, but you're still able to use any language features that don't depend on classes from later versions of the Framework. So, if you were using VS 2010, you could still build an app against .Net 2, and use some features of C# 4, like `var`, but you wouldn't have access to, say, LINQ.
There was an original project which also had convention based routing against a domain model which used the code that became FF to create a generic UI. It became monolithic, and I extracted FF (and also my data tables library, and some others) into a standalone project/nuget. Since then I've used FF many times on many projects without using the routing stuff as it's dead easy to use in any MVC project.
I really loved my start - just mostly programming with a book. Mostly solving problems rather than learning c#. [Here is what I did in the first month without any previous experience.](http://pastebin.com/2x3B3Aik)
I rarely create uri's in .NET, but this looks awesome. It is clearly a massive improvement, well done! I **will** remember this if I ever need to create them :)
I don't know GameSparks.Api, but my guess is that it is not the lambda expression that is the problem. But the .Send() method returns void (is this true?) and you are trying to bind the result to AuthenticationResponse authResponse.
It's not the lambda. What you've written is an attempt to assign the result of calling the `Send` method to a variable. That method returns void hence the error. `Send` is asynchronous, which is why there's a callback (the lambda that starts with `authResp =&gt;`). Notice that you have the authentication response there. If you just delete the assignment on the first line then the code will compile. Again, this is an asynchronous function so you can't get the result and just assign it as if it's synchronous. If you need that variable for something later then you need to make your calling function also asynchronous, probably using async/await. 
So clean, I really like it. Good job!
Nice job. My only suggestion is to offer a non-fluent interface, since method chaining is a point of contention with some people. E.g. have a plain object that provides the same utility but can be setup the traditional way and/or instantiated with an object initializer. And then have an adapter class that wraps it and provides the fluent interface.
Good work. I have dabbled in this domain myself with a `UriQry` utility helper for URI query parameters. If you find it useful you are free to use it, code availabel under MIT license from the blog http://csharpandsuch.tumblr.com/post/93983913468/query-string-params-collection
I've got a 34' 21:9 and i'm looking at picking some companion monitors because it's just not enough space. Win 10's multiple desktops have helped a bit though! those things are a godsend
Thanks, I'll consider doing it in the next version.
* What plug-ins are you running? * Is VS, any plug-ins, and their respective cache locations on SSDs? * Does this happen with any intellisense command or just with custom frameworks and APIs? * Have you monitored your PC for resource contention when you've done this?
Awesome, glad to hear it!
Does VB in VS 2015 act the same way or is it still quick? It may be a VS issue rather than a VB to C# issue. 
Nice. Can it also parse a url? For instance if I want to add, remove, or check querystring parameters? 
strings are not ideal for primary keys because SQL server creates a clustered index on the primary key. This means the index is sorted. With Strings you may cause a re-sort every time you enter a new record unless you make the new string alphabetically greater than the previous each time. With an auto-incrementing integer that won't happen.
If someone takes issue with fluent syntax, they should probably just avoid something called *Fluent*UriBuilder.
Isn't ... Isn't that just UriBuilder, then? If you don't like fluent interfaces, don't use fluent components. 
Have you tried VS without R# lately? Visual Studio 2015 Update 3 does a lot of the things Resharper used to do. It depends greatly on what R# features you use, but it is possible that you wouldn't need it any more. 
That def. seems better, but imagine you have a program that is connecting to multiple databases. What would the best way be? Right now I have a project for each "database" that is using Entity, and a folder with a DAL and another folder with Service. The external UI program has no idea about the DAL and only works with the service. IS this about right? It makes sense to me.
&gt; I can assure you that is **somewhat** normal. Edited, This can be caused my many things. If you are designing/writing on a laptop in power-savings or any kind of low power it lags behind without any plugins. If you have something like ReSharper installed or PVS-Studio, it will also slow down a bit. It comes and goes sometimes even on my gaming pc. I fix the code and it will have the error there for 1-30s after I fixed it. Mainly cleaning/rebuilding the project and restarting VS fixes it. I've seen it a lot less since 2015.3 tho, but it happened almost every single time in 2015.2 I went to write a C#/C++ project. Obviously its not supposed to happen, but if you are just wondering if you were the only person having this problem, you aren't.
2015 still takes some time to start for me on a SSD, fresh install. I read somewhere that disabling the auto-internet fetching stuff for news and whatnot speeds it up a ton.
When the Check Engine light is on, I also buy a new car instead of checking the engine.
Right now it's vanilla except for NuGet, without anything actually "Got" yet. It happens with anything - it was just coincidecne I was working on an API in the example. Yea I have 16gb of ram, Samsung SSD, and an i5 6500 - Tons of cpu/mem free while it's being laggy
good idea
Ha you know what, I'm not sure - I went directly from VS2010 with VB to 2015 with C#. I'll play with this soon and get back.
Apparently everyone uses this - it's like a smarter intellisense for C#? I'm still looking to solve the original problem though.
I think you're after a service. Taking a simple MVC example: * The Controller calls a service * The Service calls the Repository * The Repository deals with the DB and returns data to the Service * The Service manipulates data and returns to Controller * Controller generates a model from the data and returns the view/Httpresponse/JSON/Whatever Repositories should only be accessed via services. You might want to read up on onion architecture as that would probably fit your solution. 
I looked at the Command pattern, but it seemed like more work than what it was worth to me. I also looked at the Mediator pattern, but again I think it's a bit much for what I want to do. I couldn't figure out how to reliably get a "SortBy" command sent to the auxiliary class that was flexible enough to sort by anything in the result set (That's for the command pattern). Sometimes I want to sort the data returned, sometimes I want to filter, sometimes absolutely nothing needs to be done and I can return the result set as is. I'm starting to think that I should just have each repo have an Auxiliary class within it, and just code the Auxiliary class specifically for each repo. That seems clumsy and ugly though and was hoping to possibly find an elegant solution.
Holy shit thank you so much. It's like a god damn light bulb just went off. I was thinking: controller -&gt; repo -&gt; auxiliary -&gt; controller and never even stopped to think about controller -&gt; auxiliary -&gt; repo -&gt; auxiliary -&gt; controller. THANK YOU!
This is true-ish if you use a clustered index (you can do funky with stuff with PAD_INDEX or fill factor if you go unclustered). Worth reading this: http://stackoverflow.com/questions/517579/strings-as-primary-keys-in-sql-database For me it's really important that my ORM doesn't have to hit a db to create a new id, as that messes with Unit of Work/Persistence Ignorance. It's a trade off though. Worth reading up on the hilo id generator approach: http://joseoncode.com/2011/03/23/hilo-for-entityframework/ NHibernate has a handy guid.comb id strategy, where it creates consequtive guids http://nhibernate.info/blog/2009/05/21/using-the-guid-comb-identifier-strategy.html , not sure if this exists for EF. There's also SnowMaker, a distributed, standalone hilo generator you can use: https://blog.tatham.oddie.com.au/2011/07/14/released-snowmaker-a-unique-id-generator-for-azure-or-any-other-cloud-hosting-environment/
Resharper's great, but I suspect it's likely to make OP's particular problem worse, rather than better.
You are looking for the decorator pattern 
Nice Job! 
Oh that one is easy. You add a indirection reduction module between the various layers. Duh. 
&gt; The problem here, is that any logic that is in the same method as a DB call is not unit-testable, as I don't know of any way to mock out just part of a method. Then don't unit test it. You need to test the stored procedure anyways, so just include that as part of the test that ensures you are calling the stored procedure correctly. "Use the right tool for the job" applies to testing as well. 
The problem is, that currently the repositories have a lot of business logic within their methods, that we would be much better off getting under test for future changes. This is enterprise level software that goes out to Fortune 500 companies, and we want to be able to easily extend and change whatever we want in the future confidently and with as little error as possible. We need the unit tests to show our business stake-holders that we are confident of our changes, plus it gives us as developers peace of mind as well.
Search Github for something that may interested you and request a pull
I just mean that when I start a new project it creates it in spaces. I cannot find the configuration for this. My settings don't change, it just still uses spaces in the projects it creates.
There's nothing to change the templates. Use CodeMaid. 
I'm not saying to not test it. I'm saying that you can test it with something else. 
I don't know of a template, but here's what I would do. 1. Create a new Console Application from the Visual Studio new project templates 2. Do some research on log4net and implement it into the console application by following one of the many, many guides online. 3. Do some research on Entity Framework for database access. If you already have a database you can generate your data layer. If you don't, you could learn SQL or try EF code first. 4. Play around and glue everything together until it works how you want it to. That's the basic getting started guide. You'll learn 100x more by implementing them yourself than by downloading the template.
Are you using webforms or MVC. What type of validation are you using? 
Webforms and the only validators on this text box I see are RegularExpressionValidator and RequiredFieldValidator.
I would but the company site is in web forms. If I can't figure this out a migration to MVC would probably be a little much for me. 
I think in this case, OP is Richard
I've never used Webforms, but after reading a bit, it looks you should override this value in your CreateUserWizard code.
Just clone the repo. No need to request a pull unless you have something to contribute back to it.
you don't want to simply move service code into entities and call it rich or else you will likely lose cohesion (see: Single Responsibility Principle). Service code is still service code. The anemic model is when you remove logic that an entity should own from the model itself, leaving behind a wimpy dto. There are are many cases where the logic doesn't make sense in any particular entity. Those going into service classes (even within the domain). Usually, these services will take a number of entities and mediate between them to produce a result. Also, application services and domain services should be respected as separate concepts. Also, I wouldn't recommend cutting out the service layer since that is probably the most important abstraction. If you're returning domain objects to your controller, you're basically pulling out the guts of your domain. That domain should be protected imo. The service layer is the "Do things layer" and it should encapsulate what happens and how they happen without exposing the domain, because by exposing the domain, you open the door to the application being able to subvert the domain rules. / Domain presentation -&gt; application/service \ Data Access -&gt; Data Implementation So the presentation layer only knows about the application/service layer. It has no access to domain objects. The application layer knows about everything about your implementation so that it can control the flow of data and which data access implementations are used by the domain set. The domain's data access is abstracted to interfaces which are implemented in your service layer by adapting the repository implementations. /u/brocccooli, I wouldn't necessarily just consider adding methods to an entity class as "clutter" right off the bat, either. If the entity should own a process, then that process really should be part of the entity. That's what the reference to the anemic model is really getting at. "What can this entity do if it were a real world object" is really what you should be thinking. It's actually a bit more complex to make that determination than most people give it credit for, I think, but it really should be a constant topic of discussion. Basically all business logic (that is: logic that the business actually asked for) should be modeled and executed in the domain. All of the logic that we write as developers to tie the technical details to the business details should happen in the application/service layer (e.g. which data implementation to use, if this goes to queue or if it executes now, etc). Data persistence should be available to the domain and the service layer but not the presentation layer. The domain should be available to the data layer and the service layer but not the presentation layer. Now, if you want to get down and dirty, then look into Domain Driven Design. It'll lead you to a slightly different pattern, I think that can't be accurate modeled here in ascii. Of course this applies to complex systems or systems that are likely to grow and actively evolve 
I thought VS made a tab equal to 4 spaces by default so that it didn't matter which was used. I've never run into issues with new projects. Even with templates in spaces, they were spaced the same as a tab so there really wasn't much of an issue. Or am I missing something?
You are going to get into the not so fun world of Lightweight Directory Access Protocol - aka LDAP - queries. I wrote a project waaaay back in the day that that did some basic lookup stuff that you can see here [(look at ADGroupListUpdate)](http://slickticket.codeplex.com/SourceControl/latest#SlickTicket.WebUI/App_Code/utils.cs). It's really not that bad once you get into it, just a bit convoluted, try taking a view at [this video](https://www.youtube.com/watch?v=9iRs71ovZ_U) as it seems pretty simple to follow. After that I would just google "C# LDAP Query _____" where you fill in the blank with whatever you actually want to do. I hope that helps at least point you in the correct direction! 
The [DirectoryServices](https://msdn.microsoft.com/en-us/library/system.directoryservices\(v=vs.110\).aspx) namespace covers this stuff. In particular the [DirectorySearcher](https://msdn.microsoft.com/en-us/library/system.directoryservices.directorysearcher\(v=vs.110\).aspx) class can be used to query AD with [LDAP search filter syntax](https://msdn.microsoft.com/en-us/library/aa746475\(v=vs.85\).aspx).
Thanks, I'll check it out.
I'm with you until EF. Is that always the way to go? 
Jesus mother of fuck that switch statement.....
I can second that using the classes in the DirectoryServices namespace is your best bet. Without that you'll have to right LDAP queries which are much more troublesome.
That seems like it *ought* work, but if you've got two `MyClass` types in different namespaces in your project or solution, you may be creating a list of the wrong one. ETA: although, double-check that you're actually indexing the list properly. If you actually wrote list.Run(); instead, that would produce an error that might look like what you're describing, too.
I can access all the variables of the class though. So I know for sure that it's the right class. However, any method that I create just won't show up, meaning I can't call it. If I were to, for example, call one of the properties of the class, it would return the exact value that I have set. 
Sorry for the ignorance but what the hell is the difference between spaces and tabbing? Just the speed in which you indent? 
Is your method public?
Yes, it is public. One thing to note is that I can find and call the method with expected result if I were to access the instance directly: x.Run(); // No errors 
A working open source project you can use as a reference is bugtracker.net. 
So I have an excel addin we deploy to a share and i can see the dependencies there in their own folder. It appears that my application I am deploying is wrapping everything up in the setup.exe. Does this show a sign of something incorrectly configured in Visual Studio. Do you have any examples/suggestions for what i should be doing related to configuring MIME types?
Thanks :) I will fix it.
http://stackoverflow.com/questions/18709532/backgroundworker-progresschanged-event-not-on-dispatcher-thread Might not be the _exact_ same cause of your error, but the OP's workaround/solution will probably work for you.
Dapper doesn't abstract too much, it mostly spares you lines of code that look like this: thing.Id= Convert.ToInt(sqlDataReader["Id"]); thing.Name = sqlDataReader["Name "].ToString( ); Instead you map directly to your object like this: var thing = conn.Query&lt;Thing&gt;("GetByIdProcName", new { id }); Those mappings are handled automatically, but you're on your own for making your objects and calling sprocs/queries. For me it prevents a bunch of rework when you, for example, add a property. For learning ASP, the template projects that come with the newest versions of Visual Studio are quite good, if maybe a bit large in scope. I am also old school crud and there's a lot of magic in MVC. For example you have to have disparate code files named precisely for things to work, and precisely named folders in the solution. We old school guys are used to leaning on the compiler for things like that, but in MVC apps it leaves a bit to trial and error. You're never too old to learn it, it's a bit like your first few times trying to find your gate in an airport. You're bombarded with signs and sensory overload, but if you can keep your focus on the "Gate C7" signs in the kaleidoscope of imagery you'll get there. MVC is the same way. There's a lot of stuff, but you have to have sharp questions and know exactly what you're trying to do in the most incremental step possible. The later versions of MVC are much better. The [attribute routing](https://blogs.msdn.microsoft.com/webdev/2013/10/17/attribute-routing-in-asp-net-mvc-5/) can take a lot of magic away. It really all starts with routing. We all have impostor syndrome to varying degrees. I would suggest learning and implementing dependency injection, maybe start with Unity. DI is one of the (perhaps THE) main things you can do to make your apps first class instead of feeling like a hobby project. It separates things out and lets you work on modules that are loosely coupled. You can test these modules easy, and replace them without rewriting the whole application. It turns spaghetti code into something orderly. Perhaps the best reason is that DI is a common pattern among software developers, so if you write something you want other devs to work on they don't have to wonder much about "how the heck this guy put the app together". Part of DI is a set of guidelines to get started. [Here is an example](http://geekswithblogs.net/danielggarcia/archive/2014/01/23/introduction-to-dependency-injection-with-unity.aspx) of a relatively basic Unity application. Hope that all makes sense!
&gt; but for various reasons i would like to avoid complex objects in the root object Why? I ask because... &gt; and plus I was just curious if there was a good way of standardizing this. Because what you just posted more or less _is_ the standard good way of doing this. I think you'll need to provide better context as to why you're asking and the larger reasons why you aren't keen on having "complex objects" in your root object.
It's a mental exercise. If this is the best way, then fine. I'm just surprised I couldn't think of anything better, especially if address was going to get more complicated. 
Hard to say that this "is the best way" without more context. As with most programming, it can be difficult to state in absolute terms, what is "best" since what is "best" is typically very dependent on the _actual_ scenario a developer is facing. That said, in general, what you're asking (group properties with a common association so that they can be used in multiple instances) is the basic definition/justification of creating a class. This is a textbook example (and solution) of fixing a common code smell.
Removed: Rule 4.
Well think about it. How would an address get more complicated (zip/postal code, country, etc.) and when would you want that complication on home but not work or vice versa? I can't think of anything that you'd want on one but not the other. Even something like a "care of" line may have a place in either address.
Mixing tabs and spaces, what could possibly go wrong :D
&gt; The controllers job is to orchestrate the domain and application services The reason I disagree with this is that the controller in MVC and WPF, for example, both physically reside in the presentation layer. The service layer I speak of may have it's own controller(s). Then the PL controller still delegates to the service controllers so it's still doing its job. &gt; The domain is encapsulated by having all entity property setters internal to the domain The is actually addressed by DDD practitioners. The problem is that simply exposing them still allows reference to the object graph's members and its members' members. So it's not encapsulated at all. DDD rules state that nothing can hold a reference to a domain object property unless it is an aggregate root and that you should design in such a way that helps enforce this. &gt; and all public methods (whether on persistent entities or domain service objects**) strongly hardened to ensure they are called in a valid way This would be an aggregate root. Transactional boundaries that enforce invariants when affecting state. The other rule is that all changes to state are supposed to occur through the aggregate root. you can't really enforce that if you have domain objects floating around all over your solution. &gt; I question the need for the word service in domain service objects, they are just non persisted chunks of domain logic I actually agree. However, everything in the domain layer uses a ubiquitous language so it's whatever the domain expert and development team agree on. For example, we had a "HSMService" domain object because while an HSM is really a technical concept, it was also an entity frequently referred to by the business, so we kept it in the domain. The HSMService would "Do" things like `hsmService.TriggerBillingEvent()` and `hsmService.InjectKeys(myHardwareDevice)`. So these all fit business vernacular and processes. For what it's worth, I usually treat my service layer as an application layer, separate of the presentation layer. It contains the bulk of the application's functionality, some of which are delegated to the domain. For example, queuing an operation is functionality, but not of the domain. So by abstracting it into an application layer, I can reuse it with any presentation layer that targets the same framework. For example, I can use it in a web application, a desktop application, and a web api without duplicating any functionality. If I wanted to use it with windows universal app, then I'd have to roll a new app layer though since data implementations would be different (i.e. my app layer can't adapt ADO implementations and still compile for universal), but I could still reuse the domain if created it as a PCL (which you really should). Plus if you did the domain the way you're supposed to (business logic only, no external technology or libraries), then this shouldn't be an issue. While most would argue that a "Service Layer" and "Application Layer" are often the same thing, I think the difference in name makes a huge difference in how you view it's place in the puzzle. Fun to think about.
Thanks, I should get around to watching that. 
Are you performing your logic with SQL or C#? If C#: if (inputDate &gt; FRMDATE &amp;&amp; inputDate &lt; TODATE) { // Do stuff } If you're using SQL, you can use "BETWEEN" to determine if a datetime is between two numbers. It looks like you may be storing FRMDATE and TODATE as plain text not a datetime, which can make things a little more challenging. If this is the case, you'll need to use CONVERT in your query. 
can you explain in code mean i saved date in string format how to compare two string inputdate&gt;frodate? 
Thank goodness it's illegal in Python
Don't save the date as a string. Save it as a date.
Meh. Data integrity is never important...
Sidewaffle has a number of templates: http://sidewaffle.com/ Console app with logging: https://github.com/serilog/serilog/wiki/Getting-Started#example-application
Usually by suggesting to replace all of one by the other on opening the file, yes.
&gt; i saved date in string format Don't do that! Data should be stored and manipulated in the most natural format. In this case you're storing a date, and both C# and databases provide a native type for dealing with dates and times easily. If you're storing a date/time in a database, use a column of type `DateTime`. When using Dates &amp; Times in C# code use a variable of type `DateTime`. If, at some point in the process, you need to convert from a string to a DateTime or back (this is usually done at the UI level) you can use something like: // Convert date string to DateTime object DateTime dt = DateTime.Parse( "01-02-2016" ); // Convert DateTime object to string Console.WriteLine( dt.ToShortDateString() ); // Compare 2 dates (where date1 and date2 are both of type DateTime) if (date1 &gt; date2) { ... } EDIT: [See here for some DateTime examples](http://www.dotnetperls.com/datetime) There are plenty of good reasons for using the DateTime type and not strings when it comes to dealing with dates and times. Remember: - not everyone lives in the same timezone - not everyone writes their dates in the same format; to me (in the UK), 2/3/2016 is the 2nd of March. to someone in the US it's the 3rd of February - not all minutes have 60 seconds - not all days have 24 hours - not all years have 365 days Dealing with dates &amp; times is one of those things that initially seems simple, but is actually very hard to get right. 
No, there's absolutely no speed difference at all. You'll probably use the tab key in both cases as well. In any decent editor you'll be able to configure what gets inserted when you press the tab key. I use 4 spaces instead of the '\t' tab character for my personal editor settings. The main reason why I prefer spaces is that 4 spaces will always take the same amount of space. The '\t' tab character on the other hand is configurable and depends on the program/settings. So if I nicely allign and format my code (assuming a tabwidth of 4 spaces for myself) it looks all beautiful. Then someone else comes along with tabwidth set to 8 spaces and the xode will look all over the place and ugly since the aligning and formatting completely got messed up.
This is not a Forms thing, it's an Object Oriented Programming thing. This is the constructor, it is the code that is called when an object is instantiated. 
That is what I posted in my original comments, public virtual string DuplicateUserNameErrorMessage { get; set; } What I am asking though is how do I do that? What is put in for get and set?
Looks like the api returns an array of posts, not a single object. Try this instead: JsonConvert.DeserializeObject&lt;Danbooru[]&gt;(s) or JsonConvert.DeserializeObject&lt;List&lt;Danbooru&gt;&gt;(s) then just use the first (and probably only on your case) item from the result. 
According to the top answer here: http://stackoverflow.com/questions/24531741/c-sharp-clickonce-application-prerequisites-any-sure-way-to-determine-the-list The setup.exe is the thing that include the prerequisites and the user has to run that first. Is this really old, is this guy wrong?
You are awesome. The link you provided led me down the right path and it's now obvious to me what I did wrong. Thank you!
"I recently used it to call down some data from API" If you can do this, why not just convert to objects and format it into csv? (Don't forget your Trims!)
Very well documented! I actually made a library recently to easily implement TCP &amp; UDP communications in any C# program. Including text and image transport. [Github page](https://github.com/kernelle/Network). It also includes a project of mine 'Network Peripherals' which I use to control 2 PC's at once. One simple press to switch your keyboard and mouse input to a second PC.
So, use a string and: * index padding * fillfactors * periodically and regularly rebuild the index or use an int.
You don't need to change the ` { get; set; }` at all. That is simply defining an [auto property](https://msdn.microsoft.com/en-us/library/bb384054.aspx) named `DuplicateUserNameErrorMessage` in the class `CreateUserWizrad`. I haven't used Webforms in a long time, and have never used the `CreateUserWizard` class, however, it looks like you can specify your error message in the markup (.aspx). See [this post](http://forums.asp.net/t/1278695.aspx?DuplicateUserNameErrorMessage+doesn+t+work+in+CreateUserWizard) for more details (about a third of the way down, you'll see the markup for the wizard). Basically, your `CreateUserWizard` element should look something like this: &lt;asp:CreateUserWizard ID="yourId" CompleteSuccessText="Your success message" UnknownErrorMessage="Your 'unknown error' message." DuplicateUserNameErrorMessage="Your 'duplicate user name' message." runat="server"&gt; I've removed a bunch of the properties for the sake of brevity, but that should get you started. 