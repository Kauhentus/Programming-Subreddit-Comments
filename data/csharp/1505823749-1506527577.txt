Try it in conjunction with TypeLite to auto generate type def files for your c# models you are returning from your REST API
+1
I made a post on this a couple months ago. In case anyone is interested in some more details and some gotchas, take a look: https://www.reddit.com/r/csharp/comments/6u4rua/xpost_rvscode_running_csharp_in_visual_studio/ Also, since then, I've found that the dotnet-script project is a better option than scriptcs moving forward (especially since they're working on .Net Core 2.0 support as we speak - and I actually already have it working with their netcore20 feature branch). https://github.com/filipw/dotnet-script Also, it looks like there's overlap in the folks who worked on the scriptcs project that are now working on the dotnet-script project. Show the dotnet-script project some love! 
Ok after long searching i got answer to question number two. &gt;What about Excel - .Net Core interop ? I heard that C# is great to combine with excel and that you can write custom add-ins. My main reason for choosing C# is cause i want to replace my VBA financial code with C# cause it got too big to maintain. No, because VSTO (Visual Studio Tools for Office) works using COM model that is not crossplaform thus not supported with .Net Core
C# is the best backend and Angular is the best frontend - the best stick together!
1) yes. The languages are the same. 2) no idea. However, I know .net framework will work with excel. The code is virtually the same. 3) yes
Really pretty lipstick.
Wish you had posted this earlier as I just took the exam last week :)) Take a look here: https://www.examcollection.com/70-483.html Get yourself a monthly license and start studying
While it's true that writing VSTO plugins will require the full .net framework, you can still access Excel from an external application using .net core by referencing the interop assembly.
Well, that would *work*, but essentially it would mean the whole timing coordination becomes a mess once it hits multiple equal values, because anything else that hits while it's still coordinating the deadlock gets held off, so the rest of the objects then all have to be rescheduled. If your duplicate values occur near the beginning of the set then the rescheduling time could be significant, and if there are several duplicates in the set then it rapidly becomes significant. This is a cool concept that's nigh impossible to implement well, isn't it? (p.s. have an upvote for thinking about this creatively.)
Yeah, this comment chain just goes to show that spaghetti sort was not meant to be run on a classical computer.
I haven't used core yet.
But do be careful as some of the answers there are incorrect.
aiotestking, Apress: C# and .NET Framework, the green book, the Wrox book, the Oreilly C# book. Should be all.
EPPlus.Core for excel in core
Late for the party: about 5 years ago I worked for a very short while for a company that had a CRM that sounds very similar to yours and it was developed in MS LightSwitch. Now I'm not really sure what's come of that framework but I do remember that it was really easy to use and the development time was very short. Maybe you could look into it and see if it fits your needs. 
I think we've also established that it wasn't well thought out for handling duplicate values. I've done some work in parallel computing, and there aren't a lot of good solutions for duplicate values. 
Ya, it doesn't turn JS into C#, but still much better than plain javascript
Sure there are O(n) sorting algorithms, there just aren't any comparison sort algorithms that are O(n). Look at radix sort, for example. Spaghetti sort isn't a comparison sort algorithm, so there's no reason it can't be O(n).
Then you will love TypeScript.
Yeach, you can checkout the sources, compile it and exe file to PATH.
Angular has been around since 2010, react has been around since 2013. That's what I meant by more mature. So yes, it is in fact more mature. I just used React as an example, I know next to nothing about it other than it's the new buzzword that I don't give a crap about from our front end devs who seem to argue all the time about using React or Angular - so sorry if I misspoke on the terminology.
So you say you don't know anything about React, but say Angular is more mature simply by the timeline? That's really silly. Just because it's been around for a little while longer it doesn't mean it's more mature. Frankly the first version of AngularJS was a shitfest (which was the reason for the huge rewrite and dropped functionalities), while the first ReactJS versions were quite stable.
Can't believe guys you downvoted me so much, I was just kidding, seriously man....I am a professional c# developer working on wpf and winforms along with .Net framework. My colleges here work on xamarin big time...anyways, kinda okay. 
You should inject the data context in the constructor, and let the dependency injection framework handle the lifetime of those objects. In other words, don't bother with using {} or IDisposables. See https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection#disposing-of-services fpoor more.
I already told you the context of what I meant by more mature and you're still debating what I meant by it? Come on. My point here was that a shop might have used angular because it was out and something else out there might not have been thus they want to stick with something they are already using, I just chose to use React as an example of something that is more "new". You can do something else with your time than telling someone on the internet they are wrong.
My personal take on this is that Angular was "first" for a specific definition of first. It was one of the early frameworks, it gained a lot of support very quickly and a lot of companies hitched their wagon to it pretty damn fast. On the C# side there were a lot of courses and tutorials on making Angular work with C# on places like VisualStudio.Net and Channel9, etc, so it sort of had Microsoft's blessing. So tl;dr it wasn't technical it was timing and momentum.
Noted now. Your point did not come across because you decided to make up a new meaning for the word mature.
If you write a 'ThrowIfNull' method and stick it in a global static class I will call you and idiot on the internet. Use if(arg == null) throw new ArgumentNullException(nameof(arg)); Literally one line. Informs static analysis that the value past it can't be null. Are you assigning the value? Use var local = arg ?? throw new ArgumentNullException(nameof(arg)); Same story. One line. Informs static analysis. I don't have to go hunt down possible side effects. Should you use constrained generics instead of object if you are doing anything to the object? Yes. But this is a stupid example that someone may take as a 'good idea'.
I got really annoyed when for my first PS script I had to spend half of the day googling how to invoke another command with command line parameters. I used cmd, bat, rexx and a few unix script flavors before that and having to spend so much time on a trivial task really drove me nuts. It was easier to get the list of files recursively, parse their names and create list in PS than to invoke one command on one file. This is the reason why I call PS syntax a piece of crap. 
Check the DirectX samples for UWP.
When I see 'ThrowIfNull' I'm grateful that my refactoring tools include "Inline and Delete Function".
While I don't do this, if you go into the MS Corefx repo you'll see this in some places. I'm unsure when or why it's justifiable, it would be interesting if the .NET maintainers published something on this.
I was able to find a [cpp](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/Simple3DGameDX) example but no C# sample project, so I don't know what you are referring to.
Sorry, English isn't my first language.
[Last pull to Corefx](https://github.com/dotnet/corefx/pull/24140/commits/415249bafb74d13f68ce0c0db02641d5cb30c7e6) uses the style I recommend. Down to a comment to use nameof.
What if i hate using if statements without brackets? :D 
For Excel, you should check out what OpenXML can do for you. I know you can create Excel files with. I have it in a .net standard 2.0 project, but I think it can work in 1.3 too. 
If you want to format it... if(arg == null) { throw new ArgumentNullException(nameof(arg)); } I don't really care. Just sucks if you have 3 or 4 of them in a row. My personal style is I always use brackets unless it is a conditional on a terminating statement. So... if(boolean) DoSomeWork(); That's bad. But... if(areWeDoneYet) return/break/throw; That's fine. Do what everyone you have to work with wants, or what you can convince them to want. Most important part of style is that it is relatively consistent across the project.
 I highly disagree. It removes most of the nuisances of Javascript, lack of types, classes (not all browsers support ES6), and prototypes, and gives much better potential for intellisense support. TypeScript is a very pleasant language to write in.
There doesn't appear to be a standardization. Personally I just generate throws with Resharper, and it uses nameof unlike that pr you linked, I'm just asking WHY sometimes [MS does this](https://github.com/dotnet/coreclr/blob/master/src/mscorlib/shared/System/BitConverter.cs#L230) in coreclr or corefx. There doesn't appear to be guidance on why and when they prefer to throw like that. Maybe they do some IL rewriting or post-build stuff? I don't know. I'm just curious and a single PR from Corefx isn't going to quell that curiosity.
Same here. I have co-workers who focus on "imporovments" and don't take the time to learn design patters. What I end up getting is functions and classes everywhere with no organization.
Haha, framed!
 These tests are bad, but that isn't because a throw method is a bad thing. The CLR will not inline methods that contain a `throw` statement (or expression in the newest version of C#). Thus the `[MethodImpl(MethodImplOptions.NoInlining)]` attribute here is pointless. That said you shouldn't have a `ThrowIfNull` method like so: public void ThrowIfNull(object arg) { if(arg == null) { throw new ArgumentNullException(); } } which would be used as: public void Foo(object arg) { ThrowIfNull(arg); ... } Because this version always makes a call to the `ThrowIfNull` method even if `Foo` becomes inlined. Much better would be: public static void ThrowArgNull(object arg) { throw new ArgumentNullException(); } public void Foo(object arg) { if(arg == null) { ThrowArgNull(arg); } ... } because in this version if `Foo` gets inlined and arg is not null, the call never happens (and likely branch prediction will avoid clearing out the pipeline).
One should note that Angular had a complete and backward compatibility breaking rewrite in 2016. So if you're going to measure maturity by elapsed time then it would highly depend on which Angular version you're talking about.
The sample you provided does not use the NuGet package, it just adds a web reference to the ebay webservice.
I would imagine most shops (like the one I'm in) simply decided to upgrade to the newer versions because once again, it's something their teams were already familiar with. Not saying there wouldn't have been a debate, because I know in ours there most certainly was.
Jesus christ you're a dolt. You can "quote" me as much as you want but the fact of the matter is you are no comprehending, you're just arguing so I'm done with this conversation. I addressed everything that I needed addressed and now I'm wasting both of our time trying make it click for you. You're jaded. You're wrong. Get out of my field. I'm out.
I see. Which sample uses the nuget package then?
Wow, that's exactly what I was looking for. Thanks.
Theres XanderUI, unlocks alot of great controls, animations and components for winforms. https://github.com/Ricky310711/XanderUI/tree/master Heres a few youtube video's, MacOS controls, iOS and Android controls even ported, the graphs are probably one of the nicest looking controls -https://www.youtube.com/watch?v=CBqz9GItNmA -https://www.youtube.com/watch?v=mz_AGoVeB_A
To be fair, is xamarin really that niche? Compared to say forms or WPF these days.
Part of the motivation in CoreFX/CoreCLR is that when you use resources for formatting exception messages then inline throws start generating a lot of code. So we often use throw helpers which the jit won't inline to cut down on the total amount of generated code. Also in a library there tend to be many overloads/methods that have common error cases so these methods end up getting used pretty heavily.
To this: https://github.com/Microsoft/Windows-universal-samples/blob/master/Samples/Simple3DGameDX/cpp/Common/DirectXSample.h inline void ThrowIfFailed(HRESULT hr) { if (FAILED(hr)) { // Set a breakpoint on this line to catch DX API errors. throw Platform::Exception::CreateException(hr); } }
That's C++ not C#. Style best practices are different because the tool chains are different.
So only the C# dev is idiot
There are many idiots.
It wasn't an easy decision from what I can tell. Shops that were still new to Angular had it easy, but shops that had significant Angular codebases were now faced with the decision of either keeping with the old Angular (and risk depreciation) or rewrite the whole thing in the new Angular with all the cost that entails. There was a huge stink over it when it was announced last year. I know some front end devs forswore using Angular again and moved to other frameworks.
That makes sense. You could also call Shutdown on the writing socket which should trigger the server then closing the connection. Either way works.
Hey! That's a really awesome response, thank you! I've just been learning about JIT inlining today and how to take advantage of it for performance improvements utilizing the semi-new MethodImplOptions.AggressiveInlining. That's interesting to hear that such micro considerations go into how the JIT may inline something and I can understand the bloat inlined exceptions may cause with large logging information or strings. Very interesting stuff! I don't have a knack for this low level stuff but it definitely interests me, especially when I'm tasked with having to improve the performance for something today.
It should run fine... I run VS off of SQL Servers and other development servers that are running on a Hyper-V or VMWare install... it is pretty resource intensive, so don't skimp on the RAM/vCPU allocation.
Cool, thanks for the responses. I am still trying to decide on a front end framework to try and learn, might just try and set up a basic web API and experiment to see which I like best.
I pretty much run VS 2017 on a Win10 pro machine on virtualbox on linux with 8 gigs ram for the virtual machine and It works ok. I haven't gotten into anything like the emulators for hololense or phones yet. The one and only issue I have come up against was windows 10's fault. It would not stop sucking up all the hard drives bandwidth.
Oh boy, just seen they have a Mono version for Unreal Engine in the works. I wanted to ask a question but I don't know who the speaker is.
I’ll add to the voices saying it should be fine. I run Windows in a VM on my MacBook (which is pretty much Linux), no issues with either VS 2015 or 2017. I’m a college tutor, so the stuff I do is pretty basic college-level stuff. It’s probably a bit slower to start up and to compile than it would be on a native PC, but everything works absolutely fine.
Thank-you for the reply theFlyingCode, I had tried using string.join but I'm also trying to avoid performing lots of conversions :) Thanks, Elliot
Interesting... Thank-you for the reply Cyberworm! I will look into this further... [Edit] Works perfectly, 10 points to you sir!
Indeed, its a pretty ambiguous code snippet. Thank-you for your comment FizixMan :)
It's an ongoing problem with any messaging/signaling system. If you look at ObserverBase in RX you'll see that there's no built in error handling. So one answer could be: "Errors are not trapped so they can easily be debugged." Which is totally good. It just feels a bit incomplete to me that you could have 100 subscribers and one can mess up the whole thing. Which again, may be intentional as you would then each observer.OnNext() needs to have good error handling.
Yep. My "work from home" rig is a Windows 10 VM hosted by Linux Mint. I give it 8 GB of RAM (more would be better, VS/Chrome love RAM), and it works well. I'm using Visual Studio 2017 and the latest release of SQL Server.
That may have been true when win 10 was introduced, but they've got it straightened out now.
Maybe assume that these are just test controls, not actual controls. Which they are test ones, never was going to be real ones.
&gt; +1 comment on Reddit &gt;where you know, you can vote.
[ASPX vs MVC](http://lmgtfy.com/?q=aspx+vs+mvc)
Using .NET Standard you can create libraries that could be used from both .NET Core AND .NET Framework. If you write your financial code in a .NET Standard library you could reference that from both your COM interop .NET Framework project, and from whatever .NET Core stuff you want to build in the future.
If you write C# web apps, you probably deal with alot of javascript. Usually you have some element's events being reacted to by modifying other elements. Often times these interactions depend on the elements being in a certain hiearchy. I.e. you might have a cell in a row and clicking the trash icon in a cell causes you to reference the $(this).closest('.itemRow').data('itemId') to spawn a delete dialog or request for that item. The problem here is you have a data model that's represented in HTML, and if you move the HTML around to change the layout, you have to contend with alot of javascript that will break. Angular separates client side data modeling from the HTML layout, resolving the above problem. Additionally, it works great with MVC because you can easily retrieve HTML fragments from Controller Actions that return partials. It seems like Angular, being an MVC framework, is mutually exclusive to ASP.NET MVC, but they serve completely separate roles. One helps keep the server side organized, and the other improves client side. https://stackoverflow.com/questions/36319880/what-does-angularjs-has-to-offer-to-an-asp-net-mvc-project/36320388#36320388
I like EPPlus alot and have used it quite a bit, but note it is simply a file format reader/writer. It does not have an Excel engine, meaning calculations won't refresh until you open the Excel file up in Excel. It is also not for building Excel add-ins.
There's not really much benefit to using .NET Core for your use case in my opinion anyhow. If you intend for it to only run on Windows, then just use .NET Frameowk. While .NET Core is newer, it is not better nor worse. It is stripped down compared to .NET Framework removing Windows specific features. It is much better organized for cross platform development, OWIN support paired with ASP.NET Core, and is required for certain architectures such as certain Azure roles. That's certainly not an exhaustive list of decision points, but I don't see that it offers your use case anything. .NET Framework is not going away anytime soon.
MVC is glorious. Web forms' code-behind is a nightmare.
Aside from my low disk space with virtualized windows (only have a 500GB) at work, 8GB for the VM (10 Pro, VS Pro 2017), 16GB total, and a dual-core i5, all is working fine for me (Gentoo Linux - 4.13.2)
Serves me right for stopping my reading at excel :) 
There are two types of web developers: Those who use the MVC frameworks provided by their platform of choice, and those who are wrong. Seriously, anything but MVC these days, and you’re already 10 years behind the game, and your app will already be legacy code. Razor is great as well because the syntax (use the @ sign, then write your code) is very easy to use, and to read, and to maintain. The whole postback model of WebForms is antiquated and bloated, and just doesn’t fit in well with HTTP as a protocol. Just take the MVC plunge, as that is where MSFT is sinking virtually ally of their resources and R&amp;D budget as well...WebForms is all but dead.
Isn't the Unreal Engine already cross-platform, including Linux?
I did that as well, thank you very mucho.
[openxml, microsoft's low level libraries](https://msdn.microsoft.com/en-us/library/office/bb448854.aspx) [closedxml, built on top of openxml making it easier to use](https://github.com/ClosedXML/ClosedXML)
Thank you very much!
Yeah, but it doesn't support C#
&gt;Many of the features that make ReSharper great are now included in VS 2017. It was the first sentence of his comment. You seem really hell bent on not using 2017, and nobody is forcing you to use it. But to be completely honest, you're doing yourself and anyone you work with a big disservice by intentionally using outdated tools. My old boss refused to upgrade anything for our department unless it was absolutely necessary and it's why I ended up leaving that job, and he ended up getting replaced by someone half his age. No developer with any resemblance of a marketable skill wants to work in VS2012, especially younger ones. Any downside to you using 2017 will be far outweighed by the benefits. Don't hamstring yourself by intentionally choosing to use inferior tools. 
If you're struggling with this you should probably take an intro to using computers course before you jump into software development...
Thanks for your advice guys, it's appreciated. I've implemented both a single context passed to methods, as well as context invoked with using statements within each method individually. I have scheduled both versions to run on different nights and will utilise telemetry to ascertain which is technically faster. Being faster isn't obviously the only piece of the puzzle though, so I'll be doing a refactoring pass over the code to ensure thread safety (or as much as possible). In closing, I wanted to iterate that this solution is only for the web job in particular. The actual web app and api are running through repository and unit of work implementations which are obviously handling context lifecycle. In saying that, I've struggled getting the repo implementation to play nicely with the web job and gave up favouring the above described context solutions. I've gotta ask thought, **would I be better off spending the time getting the repo and unit of work implementations working correctly within the web job instead of the context approach**?
As long as nothing is running on your linux desktop, and you have enough resources (multicore and 4GB RAM) you should be fine. Take half of your available cores for the VM, and use 100% utilisation.
I use Fedora 26 with virtualbox for windows 7 &amp; 10 vm's. Just put the virtual disk on an SSD (50Gb per instance should be enough), give it 2 cores and 4GB ram and you won't feel a speed difference or any lagging. Obviously gaming in the vm is not really feasible. Build a gaming rig for that and install windows natively. If you don't like/want virtualbox, try vmware player. It is free for non-commercial uses and is supposedly better than virtualbox. Fedora is rock solid as a daily driver and have been using it for about a year now. I avoid ubuntu because it always manages to break itself with updates after about a month. Fedora just works. If you have money to burn, buy 2 Intel NUC machines and install Windows 10 and Fedora on each, that way you get 2 native OS's with the same hardware. The Intel NUC is more than enough for 90% of developers and we are replacing all of our towers at work with these. Buy a third that acts only as a server (maybe install debian on it?) if you have even more coins laying around.
If you have a large code base of ASP, then there's no advantage large enough that you should wholesale convert to MVC. However, MVC is nice to write with, so if you can develop a single signon method to move users between one and the other, it may be worth it to you to put up two servers and move users back and forth, so you can develop *new* features in MVC and leave the old code intact until you need to redo it. A more gentle migration strategy. A few years ago Microsoft said they would be dropping ASP and to move to MVC, so my employers all started making that move. Then I think MS softened their stance and said ASP will be staying around. I developed a common schema that could be used in either, so you could write once and use on either server. This allowed us to transition more gracefully.
I didn't say you can't; I said it's unlikely.
[Here](https://channel9.msdn.com/Events/dotnetConf/2017) is a link to the actual event.
I thought they did support it with some kind of plugin?
This will be the second time they announced it. They did it around 2015/2016 and it faded into nothing.
There is a thing, but it's never up to date with the lastest version of Unreal or something.
Oh :c
ahh cheers. This is good news then. :D
What advantages would UE have over Unity if you used C# for both? Is UE more powerful?
I'm no expert, and I'm not updated on the current situation, but last I heard it seemed generally accepted that UE was indeed THE performance engine, while Unity was simpler to use. Also, for my personal reasons, a 3D animator friend of mine and some of his friends want to make a game, and they only swear by UE.
What is the green book?
Excellent idea for a blog but my question is that why are you targeting SQLite? 
2005? It's 2017. MVC is not a schema? The fuck? You need to read up on these because you clearly don't know any of it.
Nuget would, at least, decouple your solution from whatever you may have installed on your machine, which seems like it would simplify picking the solution up elsewhere.
It's why I do almost all of my context (email, github, web, documents, research) in the host OS (macOS) and only use Win10 for running VS / SMSS / GitKraken. 
Not to mention the new Tag Helpers make the razor code so much cleaner and it's pure joy.
Yeah, there are times when MVC makes sense and times when WebAPI (with fat-clients like Angular, Vue, React) makes more sense. We're starting to use more Angular/Vue in our projects (too much feature requirements that AJAX/jQuery can't handle).
you are 100% correct.... I know code.. just not good structure. I have been stuck in a company that is using ASP classic... since 2001... I need to learn new technologies NOW.. I am reading what i can. 
Using nuget is most correct for portability I believe.
This is an awful response to a question from someone who is specifically looking for advice/tips. Please don't comment on people looking for help, or stick to questions you have some respect for.
T R I G G E R E D
curious, what is the original code/stack? C++ and VB? Are these client-server or web apps? As others have mentioned, def push for MVC. 
NuGet is the more modern approach.
Troll.
Perhaps you should stop enabling and excusing OP's behaviour and allowing them to shitpost without any effort.
It's difficult to put into a Reddit comment. I'd advise to find an MVC training somewhere and go through a basic project from start to finish. I think you'll find you love it in comparison.
My team looked into both ClosedXML and SpreadsheetLight. They are similar, but for most use cases we preferred SpreadsheetLight. To read very large spreadsheets, we wrote a simple streaming reader based on OpenXML. Here's SpreadsheetLight: http://spreadsheetlight.com/download/ https://www.nuget.org/packages/SpreadsheetLight/ 
ASP CLASSIC! Please stop laughing.... I do not want you to burst a blood vessel an I be responsible..
Thanks. all I am looking for is advice. Captian obvious called me out on not knowing anything about it. Which is true.. I am stuck in a company that is 20 years in the past and I want to move them to the future. But it ain't happening without me getting better informed on new technologies, and having the ability to sit down and say "This is what we are going to do, this is how we will do it" and I just need advice. I am taking only trainings now with pluralsite. thanks for backing me up. :)
Just include in project and change output to if newer 
Have a look at EPPlus. I've used it countless times with great success. https://github.com/JanKallman/EPPlus/blob/master/README.md 
I would suggest the website Udemy. Lots of Free/Inexpensive ($5-$10) classes with video tutorials and tests. This one is pretty good and goes up in difficulty. https://www.udemy.com/csharp-tutorial-for-beginners/ 
Just to clarify - the reason I am asking is because VS suggest adding a dll via quick fixes. The tooling pushes people in the other direction.
probably because you can store everything in a single file and for portability. I mean if you do not have millions of records, sqlite is small and light, perfect for the job.
I wrote this kata a few years ago and keep improving it. I hope it's helpful in learning to deal effectively with legacy code.
You're experiencing the move towards micro services for better or worse. The idea, in an enterprise environment, is that you can update a single table and version it's associated service without affecting the rest of the services. Then only the apps that use that specific service have to be updated. If you have a monolithic service used by 20 apps, updating one table or service call could mean versioning the service and updating all 20 apps. It with micro services, if only 3 of those apps use the specific function you updated, you only have to update and redeploy those 3 apps. This only works if the data behind each service is fairly self contained, not tightly coupled to other services. If service 1 depends too much on services 2&amp;3, which in turn depend on services 4&amp;1, it gets to be as bad or worse than the usage and maintenance nightmare that you were trying to avoid. 
The instances of VS is the most important context that I lose. Windows 10 is bad enough, MacOS is definitely not for me. Yesterday I was with my boss and I asked him if he had a mouse for the Apple laptop and he brought one. Its not really a mouse, its a touch pad on a string :P
So far, for me, EPPlus works great.
In that case the DLL is probably part of the SDK and it doesn't need to be referenced via the NuGet package.
The path is extremely weird - Program Files\dotnet\sdk\NuGetFallbackFolder 
That makes some sense, and was a benefit I did not really notice, but can you tell me if that's the correct route if all of those tables are for this specific application (Most of it being HR related) So while sure, we may make something else to use the info but it will be few and far between... I mean the only stuff I think is really usable is also available in Active Directory... (Again, I'm the novice here, so I also assume I could be wrong in this) Secondly, The models for these applications are setup on a NuGet, so should my tables change After updating the single big api, a simple update of the packages should resolve any issues in separate applications. (Unless they did specific calculations on a field that changed of course.) Right? I have done my best to follow the SOLID principals when designing these api's and because of that, Short of completely altering what something does in general, (In which case I could just leave that alone and create a new thing.) I am failing to see the benefit of micro services for what we are working on. Plus, (In my novice opinion) instead of separating these things out by table, We could separate it out by job, Like... All training information for employee's is on a single controller. All standards on another. Doing it this way we would have ~10 controllers (Is that too big?), instead of ~10 Api's
To me the name implies that it will pull dlls from there if you haven't indicated that you want them from a specific NuGet package+version. So referencing the package will be more explicit about which version you want.
I have not needed to do this type of filtering in a WPF app myself however based on a quick scan [of this MSDN article](https://docs.microsoft.com/en-us/dotnet/framework/wpf/controls/how-to-group-sort-and-filter-data-in-the-datagrid-control) which I think you used (or the companion article mentioned). It looks like what you need is a kind of "empty" filter that does no filtering. You can then apply that just like you apply other data filters. This would likely be the easiest way as you don't need to un-hook the filter on the list nor would you need to re-load any data. 
The official 70-483 prep book by Microsoft
A better option might be to run Linux as a VM inside a Windows host.
Your team is not well-versed in this. I read the comment by \u\MrSpiffenhimer, and I don't agree with his comment. I think the issues he's discussing would only result from the poorest of planning. Creating a different API for a different table is not a good strategy. It's a terrible use of system resources, development time and maintenance time.
If you have a variable of the DateTime type, it has a Month property that returns the numeric month (1 to 12).
You can use the .Month property of the DateTime.
Its probably still better than writing PHP :)
MVC was very hyped at the beginning even though it wasn't really that good. There have been a lot of improvements over the years. A lot of people had a bad time with WebForms, its not as bad as a lot people say (I saw people do horrible things and then blame WebForms ). I think the current MVC framework has surpassed WebForms and should be the default choice going forward. The Razor syntax is a much nicer syntax for intermingling HTML and code.
If you have access to the date as DateTimes i would sugets something like this. var monthCount = new Dictionary&lt;int, int&gt;(); foreach (var dateTime in dates) { if (monthCount.ContainsKey(dateTime.Month)) { monthCount[dateTime.Month]++; } else { monthCount.Add(dateTime.Month,1); } } This is also applicable if you either go trough the list and parse the dates into DateTimes or if you do some super funky string comparison. I guess you can use this for Days and years as well if you want to.
Seems like a classic case of over-engineering to me. 
I personally don't agree with micro services, and in your case of a single app using the entire DB, I would think it would be smarter and easier to just have a single larger service. If you update the mono service or a micro service for the hr app, you'll have to redeploy the app anyway. Why add the complexity. Someone (architect?) on the team should be able to give a rational explanation for why they're taking this new (unnecessary?) approach (you're not making a new Netflix so don't invoke Netflix). If they can't give a good explanation without invoking Netflix or startups, the I would start questioning the overall architecture. When people started talking about them at my work, it was like they just got a shinny new hammer and wanted to try it out on all of the screws. That's died down since, because no one can give a real use case in our environment. 
That's the conclusion I started to draw after I made my fifth one... And I probably won't say anything but I needed to know because I am attempting to rework the entire application using one api with an attempt at an angular front end. It's an absolute wreck right now and hard to read, but what it does seems fairly straightforward. There is gonna be a new position opening up in a month, I feel like if I dedicate my life to revamping the whole thing I may get myself a 30% raise by doing in a month what took a team of three almost a year. And even if not I want the angular xp. (Even though so far I've only completed the tour of heros tutorial with slight modifications)
Shouldn’t you be asking these from whoever is in charge of the project/architecture/team ?
The TypeScript/C# connection is probably the biggest reason. Also, the data binding features of Angular reminds me a lot of Knockout.js (with is also a MS backed lib). Also from my (rather limited) experience Angular, it has that "corporate" feel to it (well documented, well supported, gives the impression of being rather all encompassing, but comes with a steep learning curve).
Is this something that has different parts that will need to scale independently? Is the data behind each of the services completely independent of the data behind each of the other services (including no foreign keys to tables behind other apis, etc.)? Is the intention to replace the single SQL server with multiple separate stores (be they SQL servers or other persistent data stores) in the future? If and only if all three of these answers are yes does this approach make sense.
Don't get me wrong, I can see how they would be useful, Especially in our environment... I am just not seeing it for this particular project where all the data is HR related so Its not going to be used anywhere else. The current "architect" for this project was just attempting to clean up the mess of a project left to them (it broke regularly and nobody knew how to fix it), and now they are leaving as well. I have a faint hope, that I could wrangle all this together for when they leave and make the application easier to develop and maintain. Since asking in depth questions would appear like I was calling their baby ugly. I wanted Reddit's opinion on the situation. 
Sounds like someone at your company watched a 30 minute seminar on "Microservices" and decided to implement... that. Because buzzwords. Sorry, man. I feel for you. It could be worse. I've worked on the opposite kind of system... the UBERMEGAMONOLITH. That's right. Not only do we have a monolith, but we're going to put all of our business logic in stored procedures, and we're going to put all of our data in one table! And we're going to freak the fuck out when we discover that SQL Server had a column limit of 1024! *shudder*
C# is easy to reverse engineer and requires the target computer to have the .NET framework installed which causes it not to be a common choice in the realm of hacking.
Yeah, running with the next big thing seems to be Management's new deal... And they go to conferences a lot... But that's ok, I don't mind new stuff as long as we do it correctly.
Yeah there's nothing wrong with Microservices... they're a fantastic idea. If done right. Most places don't need them though. It's mostly for scalability on Google/Facebook/Netflix scales.
Depends on what you mean by "hacking".
* you can use .NET Core and pack it together with exe so you dont need .NET framework installed * from C# you can call C/C++ functions, so everything you can do in C/C++ you can do with C#, so are able to hack programs on Windows/Linux/Mac (.NET Core is multiplatform)
Asking the real questions.
I have a feeling they're trying to get set up for a day when they split their tables into multiple databases (instead of multiple tables in one DB) and when when they split the API into separate web servers handling only part of the API. Each service can point to a specific set of tables and you can version that part of the API independently. It's going to be a nightmare trying to keep up with the right version of specific API endpoints. I don't see a good reason not to use one API that gets versioned as a whole. If they really want to, they can have specific endpoints hit different databases/tables. There are other ways to reduce database load without creating a messy API layer.
You only ever get to work on 2 types of code: legacy code, and future legacy code. 😀
I seem to be the only one here who thinks that the multiple APIs is the way to go. An API should handle a single responsibility similar to services I don't agree that there is some huge performance overhead. You could literally say the same thing about creating classes. It takes more work up front but better off in the end. I don't think the author was referring to separate websites and is referring to having a large group of API controllers which is perfectly fine / correct in my eyes especially if doing REST. I can't understand why everyone is encouraging him to build a single huge controller 
Looks like you have made some sort of jagged list of lists, or lists and arrays; I don't like the syntax but it's not important. Are you trying to store humidity, location and temperature each in their own list; housed by another list? Don't do that. It's hard to read. Create a class that has humidity, location and temperature properties, then create a list of that class. Add an instance of the class to the list to store a set of values. list[0] is a list. That line sets the text property to the name of the list, which is its type, which is a generic list; or some sort of jagged abomination. You wanted to set the Text property to list[0][0], which is the string you added to the zeroth list. If you follow my suggestion from paragraph 2, you code will become easier to follow and easier for you to understand. 
This is how i would go about it: Forget the tables/databases/controllers. Think on the perspective of the api user and the context of usages. Does it make sense to have a separate api for each resource? Or will it make it easier for the user if the resources are mutually inclusive and would benefit from being on one api. When i talk about the user, i don't mean a web interface. It has to fit a more generic audience. You don't want to bottleneck your design to just one medium. 
Thanks! Your comment fixed the problem right up but more importantly thanks for helping me with the structure and syntax. The idea is to have a label for several variables like location, temperature, etc, and have the labels reflect values stored in the database. My next step once I build a class, is to use WHERE to display values above a certain thereshold only but I think that shouldn't be a problem. Thanks again for the help!
Removed: Rule 2.
Sorry I may not have made it clear, I am referring to multiple sites, just splitting all of them into multiple controllers on one site is what I felt was the correct answer.
Awesome thanks!
Thank you :)
The purpose of the assignment is probably to demonstrate that a simple seeming algorithm can be impractical or impossible to implement formally. You can implement spaghetti sort, but only for a constrained set of lists, and even then it's impractical. I just went ahead and did it as an exercise though, and I guess I can drop some pointers. My implementation was a function that took a List of items, and a function for mapping those item to (positive) integral lengths. I then found the greatest such length. I made a "fist" containing collections for each possible length, then walked though the list and put each item at it's associated length. I then walked though the first by order of length, and as such produced a sorted collection. EDIT: Ignore this, it's a shit implementation. This has the obvious flaw that it requires a finite (and, for practical reasons, small) number of possible lengths. But, as far as I can tell, this limitation is unavoidable on any digital computer.
I don't see enough information here to make that determination. If it is HR data, there may be legal reasons to split the APIs, especially if they will be consumed by different groups. It may also make sense to split the APIs apart if they are in production and breaking often as a way to stop the hemorrhaging. In general though, it makes more sense to keep them all together in one site so that shared operations can be reused when appropriate and to avoid having so many build and deployment operations.
I still don't know what a "kata" is despite clicking on various links in your article.
Would you mind posting your final solution? Thanks 
The metaphor is a martial arts kata or form. Martial artists practice and REPEAT a precise set of steps until they perfect it to to train their muscle memory and react at speed with the same behavior when sparring or in an actual fight. With a code kata, we practice and repeat a precise set of coding steps to perfect a coding skill and make it second nature when we run across a scenario for it in the wilds of actual development. A little on the fly because I'm at Pluralsight Live tonight, but I hope it answers the question.
Lots of things used to be: install the SDK/libraries on your machine, they are registered with GAC, so VS knows about them and you can easily add a reference. However, this will be confusing when pulling the solution onto a new machine. There's no cue that tells you what SDK/Installer that broken reference comes from. You know the assembly name, but it might have been part of another SDK that is not easily found under that name. It can also be difficult to tell which version of the installer/SDK cvorresponds to the specific version of the assembly needed. So even if you find the installer, it's a guessing game. It might be EF 1.3 installer, but the broken assembly reference was some Microsoft.SQL.Data assembly version 4.5, because dependencies could be a different version. NuGet solves all that by ensuring a nuget reference is specific to a package version, and the solution knows where/how to retrieve it when restored on a new machine. You still have to deal with oddities such as multiproject solutions where you aren't referencing the same nuget package version in all projects, and similar things. But it at least eliminates the most common problems. 
Never heard of it before. Ok, makes sense. 
Ah ok understood. I guess that seemed too far fetched to be real so I couldn't imagine. 
Expressions
This is what I got from a quick google: https://github.com/dotnet/roslyn/wiki/Scripting-API-Samples 
If you look for things related to injection, you'll find things trying to modify compiled applications for which you do not have the source. This will be much more complicated than what you are asking about. Since you clearly want to make this a feature of a program you own the source code to, then you have several options. An older way is using Emit: http://www.brainbell.com/tutors/C_Sharp/Creating_and_Executing_Code_at_Run_Time.htm A newer way is using Roslyn: http://www.tugberkugurlu.com/archive/compiling-c-sharp-code-into-memory-and-executing-it-with-roslyn Here's some Google fu: https://www.google.com/search?q=c%23+running+code+at+runtime+dynamic
Why not use an ORM like EF or nhibernate? Will make your life infinitely easier. 
Thanks for the link! I'll check it out.
Thanks for all the info and multiple links! You are very helpful :)
Sure don't mind at all!
I have no idea what that is truthfully. Thanks for the tip, I'll look into this!
Sometimes people want to do thing's because they're new or cool, not because they're the best or most elegant solution for a particular problem. This appears to be one of those cases. Hopefully it doesn't end up as a maintenance nightmare in a few months. Also remember, that everyone's baby is ugly except for your own. But your's will get pretty damn ugly too 6 months after you stop working on it. It's just a fact of life for computer programmers. One day you'll look at some atrocious code, start cursing the original coder, look at the BLAME file, and see it was you. The real test is how you react when you realize that you wrote shit code not too long ago. 
You can detect backspace like any other key. Here is a stackoverflow answer with example https://stackoverflow.com/a/19274284
So... the answer is yes. You can do this. This is a snidbit from a closed sourced project I'm working on doing just what you asked. I'm sure formatting will be terrible but just copy it into visual studio and use auto formatting. public static Func&lt;Single, Single&gt; CreateFunction(string function, out String err) { string code = @" using System; namespace InLineNameSpace { public class InLineClass { public static Single Function(Single f) { function_here_replace } } } "; string finalCode = code.Replace("function_here_replace", function); CSharpCodeProvider provider = new CSharpCodeProvider(); CompilerResults results = provider.CompileAssemblyFromSource(new CompilerParameters(), finalCode); if (results.Errors.HasErrors) { StringBuilder sb = new StringBuilder(); foreach (CompilerError error in results.Errors) { sb.AppendLine(String.Format("Error ({0}): {1}", error.ErrorNumber, error.ErrorText)); } err = sb.ToString(); return null; } Type binaryFunction = results.CompiledAssembly.GetType("InLineNameSpace.InLineClass"); var mi = binaryFunction.GetMethod("Function"); err = null; return (Func&lt;Single, Single&gt;)Delegate.CreateDelegate(typeof(Func&lt;Single, Single&gt;), mi); }
Holy smokes the formatting looks amazing! Look at you reddit!
I would say that this typically isn't a good practice, and especially so for the example you've provided. What exactly are you trying to achieve? Is there something you wish to work around? 
May I suggest using string interpolation: $@"preamble stuff {function} postamble" Much better than the replace which does a search through your string. And easier to build. You need to use {{ and }} for your braces instead of { and }. Thats what I use in a closed source project. 
On the long run you have to start learning Entity Framework and Linq for manipulating databases. I think the last time I've put SQL in my code like this was back in 2008. 
If you go the Emit route, check out [Sigil](https://www.nuget.org/packages/Sigil/). `System.Reflection.Emit`is an ugly namespace that offers little help in debugging/validating IL, so you may need something like Sigil.
I’d agree that you should do this eventually - but I’d also suggest learning the basics first, before using tools that do some of the basics for you. Keep doing things this way (but as noted in another comment, using a class to hold your data, not an array of lists). Only when you’re totally happy with how that works should you look into Entity Frameworks instead.
You would make sure the length of the string being inputted is &gt;= 1 if the let being pressed is backspace. This page has exactly what you are looking to do in regards to that. https://msdn.microsoft.com/en-us/library/system.consolekeyinfo.keychar.aspx &gt;And also I sometimes get some strange garabage in the input, ideas? Prob a CTRL+ key or an ALT + Key combo. 
Agreed. The only issue I could see if you have more than 1 user who is actively using it, then SQLite could cause an issue.
Yes i was thinking about extension methods too. 
Unreal is c++ and therefore the most powerfull. c# has automatic garbage collection and can never be as fast(although sometimes can be about as fast). But there's no point in writing a game in c++ if it has medium or low resource use. 
https://github.com/pardeike/Harmony I haven't dug deep into the source yet, but this library essentially let's you turn C# into an aspect oriented language via method replacement.
I really liked the side-by-side visualization. If you find a place for it in your series, a scenario I find interesting is what happens when a collection expands its capacity. Most of the BCL collections will create a new array double in size, copy values from the old to the new, and then remove the reference from the old allowing it to be GC'd. What this means if you are reading a large file into a MemoryStream, and need the entire file in memory, when you add additional elements to a 256 MB collection, then you end up consuming 768MB(256+512) while the copying is occurring, even though you are only potentially trying to store only 257MB, almost a triple memory requirement at growth. This initially leads some people to think, I only need 257 MB, why am I getting out of memory exceptions when I still have well more than that free? Even if you have enough free, fragmentation can often prevent the allocation of a contiguous block. The large object heap does not get compacted. The take away is: - Be aware of things like MemoryStreams that expand in this way. Often a .Capacity property is a dead give away or a constructor that allows an initial size to be defined. - Avoid scenarios where a collection may grow to be very large. - If you know the final size a collection will grow to, such as in the above case we would know how large the MemoryStream needs to be based on the filesize we plan to read, then specify the capacity during construction. In the above case if we specify the 257M capacity then we would avoid a couple dozen of these growths/juggling and our peak contiguous memory requirement would be 257MB instead of 768MB.
React has really terrible and anti open source licenses. This has maybe not been spoken about, but it will and it should. Based on that no one should really use React. Use Vue instead.
As someone else lower down said, it's a bit thin on information to give proper advice, but it does sound a bit hokey. There are some basic rules that seem to be violated, but again, it depends on the structure of the data and what the "architect" has planned as the big picture. One of those rules is leverage the strengths of the technologies you use. In this case, a relational database is good at doing ACID stuff with relational data. If you're going to be using the apis to query individual tables and then the consumer will have to assemble them into meaningful entities, you're wasting one of SQL's party tricks which is querying related data. My main concern here is who is going to be using the API endpoints? If it's your team's published endpoint to its data, available to everyone in the organisation, you're going to suffer a death by a thousand cuts. SQL is not designed to be massively scaleable (It is scaleable, but not massively, trivially or cost effectively) so you're going to be fire fighting the first time someone decides they want to poll all your data every 30 seconds to see if anything changes (for example). It doesn't sound like it will mitigate versioning issues anyway. There are no good "technical only" versioning strategies. You always need a schedule, forewarning and other acknowledgements that the endpoints are consumed by software *written by people*
From the sound of it, it seems OP is just experimenting with different things. Seeing what's possible etc.
It can be quite helpful to offer a scripting console for some types of applications. Though of course you have to be careful to not create a macro virus route like Microsoft Word did.
**Using Enums To Index Arrays** This is ok, but I generally wouldn't do it. Sometimes you want to code against fixed sized arrays and don't want to use 'magic' number indexers. That said, if the enum gives you pause, it is also fine to just use constant integers. An enum just ensures that you understand all of the constants are part of a set. Generally I would only ever use something like this inside of a class to manage data, and expose the elements from a contained array in simple properties, if possible. **Making the last enum NUM_ITEMS** I haven't seen that convention before and I'm not sure I like it. It would be nice to have an array size defined somewhere in a constant to handle initializing your arrays, but normally I would just make it a constant in the class that manages the array's data. Putting it into the enum no longer allows you to treat the enum values as part of a set. Instead it is treating it like a class with constants, which isn't why enums exist. It **is** hard to argue with the convenience though: var newThing = new [Thing.Size]; newThing[Thing.Name] = "Some Name"; If you are trying to strongly name each element in a fixed array though, you should probably just use a normal class: var newThing = new Thing { Name = "Some Name" }; The performance will likely be better or the same (unless you are doing unsafe stack allocated arrays or other optimizations) and it will be much easier to use and pass around in code. So...I guess I would agree with you OP. This pattern you found is kind of odd and it doesn't look like paradigm specific C#. It looks more like code translated from another language.
I've never seen this. It feels more in the spirit of a dictionary to me where the enum is the key.
I could see using it in a situation where I have data in an array that I need to assign to variables. So, rather than doing var name = myArray[1]; var email = myArray[7]; You can do var name = myArray[(int)MyArrayIndices.Name]; var email = myArray[(int)MyArrayIndices.Email]; Of course, in this scenario it's probably better to simply use a helper class with public constants instead, but it is a possible scenario. Also remember that while enums are implicitly numbered by order, there's nothing stopping you from giving them whatever (integer) value you'd like, and that two enum values can represent the same integer value. While not recommended, enum Foo { Bar = 7, Baz = 1, Quuz = 1, } Is perfectly valid code, and Foo.Baz and Foo.Quuz will both represent 1 (and Foo.Baz == Foo.Quuz will return true)
I've run into a scenario where having a limited set of constants in an enum, and then using those values to index an array, was exactly what I needed. Two things to remove some of the code smell there are: 1. As /u/essohbee mentioned [here](https://www.reddit.com/r/csharp/comments/71ivuh/using_enums_to_index_arrays/dnb4ls5/), you can explicitly number your enum members to enforce their values. I would however definitely try to keep them sequential and unique unless there's a reeeeally compelling reason to do otherwise. 2. The NUM_ITEMS member isn't necessary. While it's admittedly a little wordy, you can use Enum.GetValues(typeof(YourEnum)).Length instead. ~~If you're doing this at compile time, then the enum values are fixed and I *think* that should get optimized out to a constant, but I can't confirm that right now.~~ Edit: I guess I should clarify, this is not likely to be the right solution in a vacuum if you're starting from scratch, but it also bears stating that if you do need to do something like this, OP's original concerns (enum reordering/modification and the NUM_ITEMS member) can both be dealt with safely. Edit 2: Stopped being lazy in thread below. At least VS2015E doesn't seem to optimize any of the enum length check. Cache as necessary. ;)
I've never seen this, it seems like code smell to me.
Getting data in poor structures is an unfortunate reality, please don't be the one who puts things in an array like that. The need to cast to int is part of the code smell that tells me that using an enum for this is wrong. A constants class is better, it won't need the cast and it doesn't imply anything.
It has a nicer interface than the interactive window, I can save full code snippets with different libraries/nuget packages (fortunately my company has a license), and most importantly it's 1000x more reliable than SSMS for me. It's more lightweight, supports either SQL or C#, doesn't randomly barf, and isn't a memory hog. I do think the pricing is way too high now that C# interactive and RosylnPad are out there, which offer autocomplete and the basic features for free. But if you regularly work with databases and need to write queries in both LINQ and c# it's awesome. 
Please don't use an enum for that, use a class with some constants.
In the scenario I dealt with, the enum was pre-existing and having the type constraint of an enum rather than a collection of constants was a requirement.
:( :)
Enums are just groups of (numerical) constants, that's what they're there for.
I agree with /u/darchangel - a Dictionary would be much better to get data with enums. While this is valid it looks horrible and just a huge pit of possible bugs waiting to be unleashed.
To: MrTammy - Seems like you need to create a Microsoft Account and sign in with that account in Visual Studio. I think it's this way since VS 2015 or VS 2017.
I did this in one of my game projects where I stored all equipped equipment in an array of objects and referenced them via enum (byte). I did this because when I did my networking layer I just had to send the enums byte value to the server vs a string. Probably pre optimization, but saved some bytes ;p
What possibility of bugs? Enums are literally stored as integers (or bytes depending on if you're using a byte enum) you get enum to integer/byte conversion for basically free.
&gt; you can use Enum.GetValues(typeof(YourEnum)).Length instead This will only work properly with sequential, unique enum values. A safer general purpose approach would be something like ((YourEnum[])Enum.GetValues(typeof(YourEnum)).Max(); &gt;I think that should get optimized out to a constant Doubtful, it's better to cache it in a static variable.
As /u/essohbee in the enum two enums can contain the same value - while I can imagine a scenario where it is needed, I can imagine more scenarios where two different enum returns the same value and it will be very frustrating to track down. And as it is super-rarely used technique it will make the code harder to read which again can and will cause other problems. I know they are integers, and I wrote that "this is valid" because it isn't a problem for the compiler. It is a problem for the developer.
&gt; This will only work properly with sequential, unique enum values. Yep, but it replaces the NUM_ITEMS enum member, which was OP's concern. If the enum values aren't sequential, I'd say that's another strike against the idea of using the enum as an array index in the first place. &gt;&gt; I think that should get optimized out to a constant &gt;Doubtful, it's better to cache it in a static variable. That made me curious enough to check. Sadly, at least on the version in front of me right now (VS2015 Enterprise, optimizations enabled) it does not optimize out, and worse, the typeof() call is resolved at runtime too. So yeah, cache it if needed. Or even better, maybe come up with another way of doing this entirely. ;)
Use Dictionary&lt;K,T&gt; where K is your enum.
It's basically a `Dictionary&lt;Items, T&gt;` if you do this. Pros: fast, memory efficient. Cons: a little ugly, somewhat brittle, and it doesn't interface well with other code that expects `Dictionary`s. It's a totally fine optimization, but it probably shouldn't be your first attempt for any enum -&gt; T mapping.
Dictionary is slower though of course. 
The last time I saw either of the bolded practices was in old skool C code. Well, technically it was in C++, but it was using C coding conventions.
Two enum constants with the same value would be just as problematic with a dictionary, though. There is literally no way to tell them apart, no matter what you do with them. 
Ok cool, I'll get these functions working the current way I'm going and then look into these tools to handle it.
Performance wise it is better to use an array than a dictionary. I do this all the time when manually working with CSV files or IDataReader. (Thankfully I don't do this manually very much any more.)
&gt; &gt; &gt; Making the last enum NUM_ITEMS &gt; I haven't seen that convention before and I'm not sure I like it. I have and I hate it because that value changes over time.
As a default sure, but there are times where the array's performance is important.
If the number of options is small [FindKey(TKey)](https://referencesource.microsoft.com/#mscorlib/system/collections/generic/dictionary.cs,bcd13bb775d408f1) is going to complete quickly. There's a cost, but unless the work you are doing is just spinning on doing dictionary lookups... probably not of concern.
I am just experimenting with stuff. If you really wanna know, I was watching a speedrun of Super Mario World where they use code injection in-game to make Flappy Bird and then I thought about if it could be done in C#.
The values are being accessed as if they are properties (i.e. named indexes.) If that's the case, myItemArray should be rewritten as a class.
Wow, that's fancy. Could you please explain how exactly it works? 
You still have a modulus operation and a equality check that could be skipped. A realize this is probably a micro-optimization, but it is a technique that the compiler can't do for us.
[You're not wrong.](http://strangelights.com/blog/archive/2011/08/24/modulus-amp-integer-division-are-ldquoslowrdquo.aspx) But I will say if you are caring about the CPU execution time of individual operators, you probably shouldn't be writing in C# in the first place. Also keep in mind that spinning on just modulo is going to be much worse because it's going to overwhelm that part of the pipeline. Assuming you have a more reasonable distribution of operations the CPU will be able to schedule your modulo operation to complete faster.
That a rather defeatist attitude. C# doesn't have to be slow if you take reasonable care with memory allocations and tight loops.
It's a matter of scale though. Caring that modulo is slow is vastly different than caring that new is slow. C# provides many abstractions in a very efficient manner. Managing those abstractions, primarily around memory as you say, and the algorithm selection is the key to writing performant C# code. However the abstractions you use do put an upper (lower? I dunno. Performance can only get so good.) bound on where you can expect C# performance to end up. That bound is somewhere before caring about the performance of % and / vs *, + and friends. If you have a tight loop that needs to run ungodly fast there are tools for that. Fighting the abstractions, that are very good and very strong, in C# to squeak out half nano seconds probably isn't a quality use of your time.
I've not seen this before, however; UWP gives you the opportunity to target Xbox, HoloLens and Windows Phone, which Avalonia doesn't list. UWP takes advantage of a newer compiler, which makes it execute code faster; it offers more touch-friendly controls, and the newer Windows 10 APIs.
Dictionary key lookups are O(1) though, you're probably saving a couple milliseconds (at most) by using an array instead of a Dictionary. Plus if you're using a enum with non-sequential values it won't make sense to store the values in an array. Edit - Dictionary key lookups [approach O(1)](https://msdn.microsoft.com/en-us/library/kw5aaea4.aspx#Anchor_2)
O(1) just means the lookup time is (mostly) independent of population. Accessing an array at a known location is also constant, and it's pretty much the smallest constant possible since it's just accessing a memory location. With a Dictionary, with every access you have to: 1. Calculate the hash of the value. 2. Use that to calculate the bucket that it's in (a modulus operation usually) 3. Traverse the linked list at that location in the array, comparing the hash value of each element to the calculated value. 4. Use the Equals function to really make sure that the hash match isn't a collision. 5. Return the value. For searching an array, dictionary wins in performance fairly quickly. (A quick search shows that peoples tests usually end up crossing somewhere between 3 and 30 elements depending on the exact nature of the tests.) But for accessing a known location? Not close.
Big-O notation doesn't tell you how fast or slow something is for a given N. It just says how bad your life is going to suck as N increases. &gt; probably saving a couple milliseconds (at most) That statement is based on nothing. The time savings could be nanoseconds or hours depending on how often the operation is performed. What we should be asking is what is the relative cost of the two operations. * array index Vs * modulo * array index * hash code comparison * equality comparison You might have to consider cpu caching as well, as an array is more compact. 
[Not by any meaningful measure](https://msdn.microsoft.com/en-us/library/kw5aaea4.aspx#Anchor_2) *in this case*. edit: thanks u/nemec for providing [empirical evidence](https://www.reddit.com/r/csharp/comments/71ivuh/using_enums_to_index_arrays/dncc20a/).
Are you referring to where it says O(1)? That just means it takes the same amount of time every time, however large the dictionary, not that it takes the same amount of time as an array access. Every call that involves a key calls GetHashCode() on the key. For an array it literally just adds two numbers together. Plus the fact that using contiguous memory, as you would if you used an array, can give huge performance increases at the CPU level depending on the task. 
Clarity and thus good practice is solidly in favor of using a dictionary. I see some other answers deal with the difference in performance... Let's first make it clear that obsessing about performance at this level is insanity, unless it's already shown to be a problem. A quick experiment I did shows that it's *very* slightly slower: Cast method: Ran 100000000 times in 364,1171ms averaging 3,641171ns per run. Dict method: Ran 100000000 times in 1,5202415s averaging 15,202415ns per run. For reference, you'll have to run it (unoptimized!) 34.6 million times before the combined time saved is up to a literal blink of the eye. You'll save one second for roughly every 86.5 million. Go with the dictionary.
You should try hitting up your local library and look for programming related books that you find interesting. Also the [Microsoft Virtual Academy](https://mva.microsoft.com/en-us/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC_2706218949) has a lot of free training videos.
Thanks for the in-depth explanation!
Look at the side bar on the right, plenty of link and resources to learn C# :)
Once you take GC out of the equation, the next limitation is the JIT compiler. Replace that with C#'s native compiler and you'll get the same optimizations that we see in C++. &gt; .NET Native uses the same back end as the C++ compiler, which is optimized for static precompilation scenarios.
That looked like a lot of work and hopefully you will save someone some time. Ill stick with visual studio code for the angular project and 2017 community edition for the core api. Personally I like simple vanilla stuff. I am even a bit nervous about using the 2017 built in angular / api project template.
While that is true about some uses of the C# implementation of enums, it is way off when you are talking about the design construct of an enumerated type. Other languages have much more robust enums that are therefore much safer, notably Java. C# also has other uses of enums as flag fields, so it allows values in an enum field or variable that have no named constant associated. 
This guy is the best: https://www.youtube.com/user/kudvenkat Watch his c# for beginners tutorial. He should be side-barred.
&gt; closed source If this isn't your personal project, you might want to take this down before you or OP gets sued by your employer...
It can't optimize it out. There are lots of different ways enums can be used and it can't necessarily see all the possible uses. 
I realise, but I would discourage it in the future, depending how far OP goes with C#/.NET.
Codegasm on youtube. Dude was a programmer for microsoft before they laid everyone off. The way he teaches is amazing.
One of the articles from this link really helped clarify for me how arrays work, I was working on something that involved information like this but didn't realize I was infact rewriting the method table pointer lol. Very obscure and complicated information here but I'm sure some find it useful and interesting!
I'm just starting out myself, and thus far I've found dotnetacademy to be a good primer, if nothing else.
What he's talking about is moving toward a microservices architecture and his comment is spot on. You don't create a new API for each table though. You try to figure out what "service" that is being provided and if it can be segmented out on its own. What this lets you do is use any technology stack you want. So for one set of services, you might use Mongo. For another, SqlServer, etc. You can make one little update to a service that doesn't cripple other services, and can be deployed quickly. I worked at an enterprise shop and having to deal with the monolithic code base with all the legacy bits included was a nightmare. And now working on a very clean and nimble microservices architecture has really opened my eyes on the benefits. There are some drawbacks, but on the whole, microservices are a nice step up from monolithic beasts. 
I have never seen this; I am not sure I would want to.
&gt; Sometimes you want to code against fixed sized arrays and don't want to use 'magic' number indexers. Just use a class. Arrays accessed with enums smells awful.
**edit: [Jkotas](https://github.com/jkotas), a Microsoft .NET Runtime developer, [correctly points out that the array hacking will cause crashes](https://github.com/HelloKitty/Reinterpret.Net/issues/1) even where I didn't expect them to. Therefore that feature is being removed.** Hi guys. Not sure if this is a place to post stuff like this but I just released a library on NuGet for this and wanted to share and would love feedback! The past few days I attempted to write high performance generic extension methods for reinterpreting bytes and primitives in .NET. I wanted to bring the performance and semantics of reinterpret_cast from C++ to .NET Core and &gt;=.NETFramework2.0. It has some performance infographics comparing against the old and new versions of .NET. Interesting note is that BitConverter is much faster nowadays than it used to be, I must say! Check out the MS Corefx library to see why and compare it to the .NETFramework's old reference sources. One oddity I found is that Encoding.Unicode.GetString seems to scale very poorly for larger strings in newer versions of .NETFramework. This is why it looks so terrible in the .NET Core infographic but not so bad in the .NETFramework2.0-3.5 infographic. Who knew!
The big difference here is the runtime sandbox and that may or may not matter depending on what you want. UWP apps live in a virtual app space during runtime similar to how browser scripts are sandboxed but with additional features an installed app would need. Based on my reading of the Avalonia project's main github page it appears to be a framework centered around launching applications in user-mode (like a traditional application) this would mean that the target operating system will not need UWP components to run you just bring it all with you in the installer. Further UWP is limited to Microsoft OS platforms at the moment (this may change in the future). Avalonia appears to support MacOS and Linux runtime similar to .NET core or Mono. This is actually a good thing because if you want to write a proper cross-platform .NET client app you are stuck with GDK# which while pretty good is a far cry away from the power and overall ease of UI development with WPF (you can do MVVM in GDK# you just need to roll it yourself).
Material Design WPF
Presumably, there is a plan in place and you're only seeing the beginning. Since companies should rarely ever rewrite code from scratch, this may be the way your company is moving toward microservices. Someone who is at an architecture level of proficiently should be able to explain the goal to you. But with microservices, you don't arbitrarily create a new API for just a few sets of tables. You try to find related bits that can be segmented out and stand alone as a service. You partition by purpose. Once the API is in place, teams could start removing dependencies or even implement another technology stack that suits the service better. Maybe Mongo is a better DB for a particular service and SqlServer some others, for example. With microservices, you can do this. Now you could argue that maybe creating the services separately and pulling in code from the "legacy" base might make more sense, but by doing it this way, they can start the UI or whatever layer above is calling the microservices much sooner. The database part can be optimized once the services are segmented. Having worked on a humongous enterprise app and now a microservices architecture, I see the value for enterprises to make this move. You rarely ever want to write code from scratch, so hopefully this is just your company transitioning into the microservices architecture. With microservices, you can quickly deploy just the services that changed/were fixed. You can scale the services horizontally to meet demand. One bug won't cripple your release. Etc.
Is it possible to run the cli commands while starting up the debugging from Visual Studio, without using terminals?
Honestly if cross platform is what you want, you'd be better off with Electron. It has some flaws but the positives of using countless well supported JavaScript Frameworks and a HTML front end outweigh the negatives. But this is /r/csharp so fuck it, Avalonia all the way.
 String error; var compiled_function = CreateFunction("return f * Math.Abs(f);", out error); if (error != null) { Console.WriteLine(error); } else { Console.WriteLine(compiled_function(3)); // Returns 9 Console.WriteLine(compiled_function(-3)); // Returns -9 Console.WriteLine(compiled_function(1)); // Returns 1 } It's designed specifically for functions the take in a single float and return a single float, however changing that would not be difficult!
I am not one to judge the solution choice here unless the poster asks. Business requirements can be fucking stupid. 
If the derived class wants to make the return value of a method or property more specific. For example, if I have abstract Customer and CustomerAddress classes, and derived Organisation and OrganisationAddress classes, then I might want to define a "new" Address property on Organisation with the type OrganisationAddress - so I can use myOrganisation.Address.OrganisationStuff without having to cast to OrganisationAddress or add a (less discoverable) property with the right type but under a different name. It's important to note that for this to not be horrible, both Address properties should return the same object.
I'm pretty sure that C#'s dictionary doesn't use a linked list. 
I'm currently taking C# courses I found on Udemy for $10/ea. Pretty good if you have the option to purchase them, it's 3 courses (beginner, intermediate &amp; advanced).. Mosh, the teacher, is pretty good and explains well. https://www.udemy.com/csharp-tutorial-for-beginners/ Edit: He has a 1 hour free beginner course on Youtube you can check first: https://www.youtube.com/watch?v=gfkTfcpWqAY
Run it against optimized. Micro-optimizations like this are very sensitive to debugging information.
Rewriting object headers to reinterpret array values seems like an incredibly bad idea. When would you actually want to use that instead of just using `unsafe` pointer casts?
This is exactly the kind of thing Dictionaries/Maps were created for. This won't translate nicely to other languages without either creating the enum yourself (or extension methods or fields for one) or creating a Dictionary/Map/Lookup table anyway to find a predermined integer value. This may also run into problems where you're using flag enums (where the integer values are assigned 1, 2, 4, 8, 16, etc.) or other enums with differently valued members. val MyItemArray = new Dictionary&lt;Item, String&gt;; // populate MyItemArray val GottenValue = MyItemArray[Item.Item2]; The only advantage it may offer is in optimisation where using the enum member's integer value as an array index doesn't involve a lookup. But I don't imagine it would be very much of an optimisation, and probably isn't worth making your code more fragile or less portable like that.
The best way to learn to program is to program things you personally need. Notwithstanding the excellent resources on the sidebar and anything in this thread, solve a problem you care about using code. Are you a board gamer? Build an objectmodel for your favorite boardgame. When you have that, build methods that change the model the way various moves would in the game. Build test methods as you go. Test-driven design can be overdone, but you really have to work hard to achieve that. And hey; you're learning to code while writing your tests. Over-document everything. People will tell you bullshit about how too many comments is a form of "code smell," but documentation is *the best* habit you can form. Period. It will help you think in code. It will help you know wtf you were thinking 6 months from now when you are cringing at how bad your code was, and that helps you learn. Learn git. Right now. Every atomic change you make should be a commit. That is, you should learn to, and continue to, pick one unit of work that you want to do, do it, and commit it. Wash, rinse, repeat. *Make every commit message be fucking poetry.* I mean that seriously; if you absolutely cannot write meaningful commit messages (your own poetry,) then dammit go find a haiku or Bible verse or *something* to stick in there. Every time you want to put some bullshit comment like, "Did some work," you should imagine that I am stabbing your eyes out with a rusty icepick. Seriously though, try very hard to make your commit comments describe the change precisely and concisely, but if not, find something unique and interesting to put in place of that. Nothing is more frustrating than trying to find a commit when the committer is lazy about comments.
I can't think of a case where this is good design.
It yields an incredibly high performance result. Can you provide an example of an unsafe pointer cast? I know of none that fit these requirements. You can't just cast afaik either otherwise reflection and length information for the array will be invalid. Struct unions won't work either because you still need to modify the array header too. Manual pointer casts for individual elements will require allocation too and is O(n). If you can produce a no allocation, high performance O(1) pointer cast that has a resulting array with correct Type information when reflection/typeintrospection is used on it and correct length that preforms better than the solution in this library I'll be happy to accept a pull request!
I mean something like var x = new int[] { Int32.MaxValue }; unsafe { fixed (int* xi = x) { byte* xb = (byte*)xi; } } This also let's you (temporarily) reinterpret structs/arrays without additional conversions or allocations, without having to corrupt the state of CLR objects. 
Firstly, it's not corruption. Secondly you aren't converting an array to another array. You're converting an array to a pointer. You can't go back efficiently from the byte*. You could Marshal.Copy but that requires allocation. You'd have to do the same thing and rewrite the array object header. You're not going to find a higher performance, no allocation and constant time way to go from one array time to another array type other than what is here. Unless you maybe hand clean up some of the IL instructions involved. There are only afew of them though. I do see some potential improvements already just from looking at the IL, but I have not found a better way than this. The relevant IL: https://pastebin.com/T4RUURG3 These few methods convert an array from one type to another. It's only a handful of rather fast instructions. That's why the performance is several orders of magnitude faster than [BlockCopy](https://github.com/dotnet/coreclr/blob/master/src/mscorlib/src/System/Buffer.cs#L35), which is itself very fast and competitive because it uses [memmove](http://www.cplusplus.com/reference/cstring/memmove/), if you go the dangerous route. It's instant by comparison to anything else.
Make sure to use MVVM in the process.
My latest program just uses chromium.
I say to do that further down in my comment. About the only time I could see doing this is for performance reasons where you are avoiding creating object references by stack allocating arrays and treating them like classes. Even then, that sounds like a huge headache for little gain.
Doesn't the `System.Runtime.CompilerServices.Unsafe` class already provide APIs for this? e.g. // Does not throw exception string s = Unsafe.As&lt;string&gt;(new object());
That's what a bucket is.... 
Yes! In fact this library makes use of the ```System.Runtime.CompilerServices.Unsafe``` but ```System.Runtime.CompilerServices.Unsafe``` doesn't support older versions of the .NETFramework so I backported a small subsection of it and it's ILRepacked into the library for older versions. Supporting older versions of Unity3D, which rely on .NET3.5, so that's always a concern in my mind when creating a library. Since I also consume the stuff I make. Also I've never tried to use it on reference types, and there wasn't a goal to support it. So not the safest thing to expose to typical users. The main issue is alone Unsafe.As does NOT easily and cleanly reinterpret things. The API provided in this library is better and on top of that Unsafe.As cannot reinterpret arrays. Which is one of the most performance problematic things in cases like serialization/deserialization. If you try to do Unsafe.As&lt;byte[], int[]&gt;(...) the result will be invalid because if you reflect on the Type you'll see it's still the old type and length will be invalid. This is solved in the library by rewriting the array's type and length header.
Thanks a lot! I'll try it :)
&gt; If you try to do Unsafe.As&lt;byte[], int[]&gt;(...) the result will be invalid because if you reflect on the Type you'll see it's still the old type and length will be invalid. This is solved in the library by rewriting the array's type and length header. Why would you want to do that instead of using `fixed` to get a `byte*` pointing to the array, and then casting it to an `int*`?
Because very few .NET APIs consume pointers. Very few libraries consume pointers. Having a pointer to something isn't helpful to most people or usecases. Having a reinterpreted array is.
From a pragmatic point of view: if you're using a dictionary with enum keys, the size is going to be very small and so the internal machinery will be quite fast. Going further, since we're talking about C# here we're implicitly talking about running JIT code in a VM (obvious, I know) and that provides additional overhead that diminishes the value of such optimizations, such that the differing performance profiles here are not significant. Now also consider the readability/maintainability and self-documenting code that comes about by using something like a IDictionary&lt;TEnum, TWhatever&gt; compared to an array with a unconstrained enum index ("ok team, everyone please use this enum when accessing this block of memory!"), it would seem to me that there is no meaningful gain by taking this approach. At least, not in the real world with exception to very esoteric scenarios where this might lay in a critical hot path and native code isn't an option for whatever reason. A bit hyperbolic but it's like removing seatbelts to make your car lighter and therefore faster. 
I use Mahapps http://mahapps.com/ and you can also use Material Design http://materialdesigninxaml.net/ that works with Mahapps.
If you're using winforms, Bunifu Ui is pretty good and cheap. They have a lot of tutorials too. 
&gt;Firstly, it's not corruption. It's not corruption as long as nothing goes wrong. &gt;you aren't converting an array to another array. You're converting an array to a pointer Of course not, but for the purpose of reinterpreting the values it does the same job. I just can't imagine a lot of scenarios where you simultaneously 1. absolutely need an array to store it/pass to somewhere 2. do this in such large volumes that extremely hacky performance optimizations are required 3. don't need the the source array anymore 4. can't create the array with the target type in the first place A typical use case for stuff like this is binary IO or deserialization, where bytes need to be converted with high throughput. But in those cases you'd want to be able to keep reusing your source buffer, and you couldn't necessarily rely on always having exactly sized buffers without offsets.
I don't hate this, but I feel like if I did it, I'd wrap all that stuff in a larger class. enum Pet { Dog = 0, Cat = 1, Octopus = 2, } class PetCounts { private int[] Counts { get; } = new int[Enum.GetValues(typeof(Pets)).Length]; public int this[Pet pet] { get =&gt; Counts[(int)pet]; set =&gt; Counts[(int)pet] = value; } } That way there's an abstraction between how you're using the data (accessing a collection with an enum value as a key) and how it's actually stored (those enum values translate to array indices). Would allow malleability down the road (maybe you want to switch from an array to something else, or maybe you could take advantage of a switch and have counts stored in multiple different sub collections, who knows?), allow custom mapping from enum to index if need be, and open the opportunity for better testing and more descriptive error messages. enum Pet { Dog, Cat, Octopus, Snail, } class PetCounts { private int[] MammalCounts { get; } = new int[2]; public int TotalMammals =&gt; MammalCounts.Sum(); private int[] MolluskCounts { get; } = new int[2]; public int TotalMollusks =&gt; MammalCounts.Sum(); public int this[Pet pet] { get { switch (pet) { case Pet.Dog: return MammalCounts[0]; case Pet.Cat: return MammalCounts[1]; case Pet.Octopus: return MolluskCounts[0]; case Pet.Snail: return MolluskCounts[1]; default: throw new ArgumentException(nameof(pet), $"Unrecognized pet {pet}!"); } } } } Definitely wouldn't rely on everyone fully understanding the whole "you need to access this array by casting values from this specific enum to ints", though. Not super complicated in a vacuum but it's pretty nonstandard and another layer of stuff to remember that could trip people up.
There are numerous ways to implement the buckets. Linked lists are one option, another is just using an array. In the latter case, if there is a hash collision then the object is inserted into the next available slot. This is often preferable because it reduces the number of objects being allocated and improves memory locality. Check out ReferenceSource to see how C# does it.
I think the new `Span&lt;T&gt;` type is going to be good for this perf sensitive stuff but that isn't going to help older libraries either. https://github.com/dotnet/coreclr/blob/master/src/mscorlib/shared/System/Span.cs I think you should be able to have a `byte[]` and call: ref int i = new Span&lt;byte&gt;(bytes).NonPortableCast&lt;byte,int&gt;()[0];
It needs to be `ORDER BY`. Make sure your column names are correct... you could try maybe making it all on one line, perhaps the text wrapping is causing issues? As for the SQL itself, it's correct: http://sqlfiddle.com/#!9/121f90/3
It's unsafe, so things can go wrong but things can always go wrong with anything. That's why you verify your applications usually. You seem to think that the only value in reinterpreting is accessing the values. However I would wager in many cases most people are utilizing Framework libraries or 3rd party libraries and must fit the constraints of those existing APIs. Most do not provide overloads accepting pointers for their array arguments. Most people do not have source access to the libraries they depend on so passing around an int* isn't really viable. The usecase that I personally wrote this library for, a serializer similar to Protobuf-Net, wouldn't really function if I could only efficiently deserialize bytes to int pointers. I can't think of many APIs I depend on that will access pointers and arrays. As for relying on a source buffer, that's fine too. Reinterpret.NET offers an allocation based reinterpret which will copy the array first. I'm working on improving that particular feature's performance even more too. So if you aren't allowed to destroy the source buffer that's fine too. It's still higher performance. An allocation has to happen if you want to protect the source buffer AND end up with an array even if you grab the pointer and reinterpret the values per element that way. That's unavoidable if you have those requirements. Unless you control absolutely every piece of your application, API and dependencies. Then you can support pointers with all sorts of ugly C++ pointer + length overloads. I'll go work on improving the performance of that usecase though even more right now!
Why not make the build task depend on the flag setting task directly?
You mean to say "array wins", correct? Due to the overhead cost of dictionary lookups?
There are multiple build tasks in a tree AND there are multiple flag setting tasks. Setting flags before I enter the tree is enough, regardless of where I enter, but there are still multiple entry points.
I still don't see the appeal. It's still a waste of system resources, running several IIS worker processes, or whatever web server you're going to use. Using different database engines again will require more resources. It's another SSL certificate to sort out. It's another URL to remember. It's another hassle. I don't see why you can't update a web service without breaking parts of it. Can you give an example?
I'm not sure what the issue is here. Are you asking how can you do this: ThreadLocal&lt;Int32&gt; nextPrice = new ThreadLocal&lt;Int32&gt;(); myClass.nextPrice = 5; Yeah, can't quite do that. But you can wrap it with a property: private ThreadLocal&lt;Int32&gt; nextPrice = new ThreadLocal&lt;Int32&gt;(); public int NextPrice { get { return nextPrice.Value; } set { nextPrice.Value = value; } } myClass.NextPrice = 5;
Interesting! I don't know much about Span but I'll look into it. Is it in the current .net core 2.0 mscorlib? Is NonPortableCast that something they're already supporting? That's interesting, I'll need to look into that too. I'd be surprised if it somehow had less overhead. Either way it's nice to see MS address the issue of working with a pointer. The main issue is their current ToArray seems to allocate instead of reinterpret for Spans.
`Value` is a property, you read and set it like any other property. Not sure what exactly your question is?
So using it there is an actual performance increase? I've never really used interpolation before.
While this is pretty neat, it isn't exactly injection. Codedom will generate a library in memory and your code executes it through reflection. However, I'm not sure if OP was referring to "dynamically executing code" or actual code injection via thread creation or other means.
There's nothing specifically wrong with it, it actually makes sense in a lot of cases.... ...BUT..... If you have a known-length array of items, where each element is a known, specific, purpose and a known data-type (which this process implies) , then you are REALLY describing an object, and should probably REALLY be creating a class for that array. It's amazing the amount of nasty hacky workarounds using generics and arrays or dictionaries (and then realising that they need an Add , Find , Filter or Sort method that's now almost impossible) that people will find instead of creating a simple class.
Put simply, yes. In your example, the order would be Default -&gt; B -&gt; A (Default is dependent on A which is dependent on B)
&gt; what are some legitimate, won't-cause-frown use cases for hiding members in subclasses like that? I'm not entirely sure there are any. I can think of situations that might *require* that sort of workaround, like if the parent class isn't really in your control and the method isn't virtual, but it's always going to be a hacky way to get around a lack of extensibility in your object's parent. u/Huffers' example is one that rings a bell, but I'm having some trouble remembering where I've seen it. Might be something to do with crufty interfaces from the bad old days of .Net 2.0 or something, though.
in case you're curious here is the course i am taking: https://channel9.msdn.com/Series/C-Sharp-Fundamentals-Development-for-Absolute-Beginners
&gt; There are numerous ways to implement the buckets. Linked lists are one option, another is just using an array. True, it's not a "LinkedList" as in the class implementation. However, you still have to traverse through all the different elements in that particular bucket serially, so it is another form of linked list, just with the array indices acting as the next pointer instead of a reference. I think it's a semantic argument though. if (buckets != null) { int hashCode = comparer.GetHashCode(key) &amp; 0x7FFFFFFF; for (int i = buckets[hashCode % buckets.Length]; i &gt;= 0;** i = entries[i].next**) { if (entries[i].hashCode == hashCode &amp;&amp; comparer.Equals(entries[i].key, key)) return i; } }
No, I was saying the time when dictionaries win, which is in a search for a particular key value. In random access to a known location though, you really can't compete with an array.
This is exactly what I was looking for, thank you so much!
What about them is throwing you for a loop? A method is a set of instructions/lines-of-code that execute when you call the method (and you call using parenthesis usually). Method overloading lets you declare multiple methods that have the same name but different parameter inputs. public static class MyClass { public static void SomeMethod(int someIntegerInput) { Console.WriteLine("SomeMethod with int input!"); } public static void SomeMethod(string someStringInput) { Console.WriteLine("SomeMethod with string input!"); } } //calling the integer overload version MyClass.SomeMethod(9); //calling the string overload version MyClass.SomeMethod("Hello world!");
I think I've had a similar situation where essentially you have many tasks all dependent on one task, but it's a lot of boilerplate to write out these dependencies. When I originally came across the issue I couldn't see a way around it. I would be interested to know if there is. 
Is that a behaviour you can depend on though. Doesn't the example given express that Default is dependent on A **AND** B and **NOT** that &gt; Default is dependent on A which is dependent on B I personally assume that A and B may run in parallel and you can't rely on a dependency being resolved without specifying it explicitly. 
If the derived class wants to override the implementation of an interface function the base class implements, it can also declare the interface then implement the function using 'new' to hide the base class version.
I'm solving it by having a bunch of "internal" tasks, while the "external" tasks are just strings of dependencies, since it apparently *is* ordinal. And it matters that they're dependencies and not calls to `RunTask`, because there are a few that would otherwise be called multiple times.
`packages.config` is the file that lists NuGet package dependencies. It's used by NuGet to restore packages. `app.config` is the application config file. When you build your application it will actually get copied to the output directory and renamed [YourExe].exe.config. Sometimes NuGet package authors will include a script in their package that modifies the `app.config` file. In your case it sounds like the author of the NuGet package added an assembly redirect binding, which basically just tells the runtime to always use the latest version of the assembly even if an assembly references an older version.
&gt; I still don't see the appeal. &gt; I don't see why you can't update a web service without breaking parts of it. Can you give an example? - Distinct Partner APIs versus Customer Front-End APIs: You can upgrade either side without disrupting the other. Downtimes are easier to coordinate and much more localized. - Above, but Internal APIs instead of Partner APIs. Classic example is if I want to be able to upgrade how certain data is migrated between systems without disrupting customer access to that data. - Simplifying your bugfix/change workflow: If you are having to deal with one or both of the above (or, possibly worse, multiple discreet jobs/services on top of the above,) deploying a change can result in a cascade of deployments across the board, guaranteeing a very coordinated downtime. - Ability to scale out versus up. If I ever get to where certain parts of the application are under heavy utilization/load I can have those portions on their own server. &gt; It's still a waste of system resources, running several IIS worker processes, or whatever web server you're going to use. There are plenty of ways to implement microservices without additional web server processes. Akka.NET does straight TCP or SSL (Shared cert across all services) and I will say it's cheaper on memory than an IIS ASP.NET process. RabbitMQ can have some resource usage (it can be tuned, but I'm more considering behavior out of the box) but for what it offers (option of guaranteed delivery, heterogeneous architecture for message processing) that might be a fair tradeoff. &gt; It's another URL to remember. It's another hassle. If you're having to remember the URL, whoever did your microservice implementation was lazy. A thorough implementation should give any consumers a library that can be easily imported into their project to allow communication back and forth. Is it more work up front? *Yes*. Is it easier to deal with when you have a huge codebase? *Actually yes*. /u/BinaryHelix has it on point with &gt;&gt; And now working on a very clean and nimble microservices architecture has really opened my eyes on the benefits. There are some drawbacks, but on the whole, microservices are a nice step up from monolithic beasts. And until you've seen a *decently* designed microservice implementation it doesn't make a whole lot of sense. It doesn't help that many of the ones I have seen aren't that well done, but OTOH I've seen just as many coding horrors where a business app's 'MVC' 'N-Tier' Architecture was a CodeProject tutorial taken to it's illogical conclusion. Bonus points for whenever they used strictly a 'generic repository pattern' across the entire DAL.
Would setup/tear down or task setup/tear down fill the gap? It feels like cheating, but it could be a practical solution. https://www.cakebuild.net/docs/fundamentals/setup-and-teardown
Enterprise ASP.NET application used by Fortune 100 clients with millions of lines of code which has legacy (VB, WebForms) as well as WebApi/MVC controllers doing everything from handling Office uploads, output, PDF conversion, pretty graphs, diverse metric handling, background computation, users, timesheets, projects, etc. all running atop thousands of stored procedures and Service Broker. A one line change can break the app that is shipped, and we were lucky if we found it before our customers. A one line bug that might be easy to find and fix in a small microservice, but nearly impossible to find due to the ungodly dependencies without running an entire suite of tests (automated and manual) that takes several teams a whole day. So there were a lot of needless tests for the smallest changes, and these still never caught all the bugs before a release which necessitated several weeks of critical bug fixes and point releases. A nightmare.
Ok, I think that's the key. The author of the package has the ability to update the app.config, which is why some packages do it and others do not. It really depends on what the package author decides. I think it seems a little strange to override if a project references a specific version, but at least I know where it's coming from now.
Adding onto this, it must be the same approach with .csproj files as well? I've had a couple packages that would add EnsureNugetPackageBuildImports targets, and add specific &lt;import Project="..."&gt; etc rather than just a &lt;Reference&gt; and calling it a day.
Umm, I don't see any whitespace between your query text. When you put that string together (at least in the syntax provided,) you get SELECT CurrentHumidityFROM test_panelWHERE CurrentHumidity &gt; 50ORDERBY Timestamp ASC ; try adding spaces between your queries? or better yet, try: @"SELECT CurrentHumidity FROM test_panel WHERE CurrentHumidity &gt; 50 ORDER BY Timestamp asc;" the @ symbol tells the compiler to treat it as a multi-line string till the end quote.
No, I would agree this meets the definition of a linked list.
Gotcha that makes sense, thanks
Get some expressions up in there! private ThreadLocal&lt;Int32&gt; nextPrice = new ThreadLocal&lt;Int32&gt;(); public int NextPrice { get =&gt; nextPrice.Value; set =&gt; nextPrice.Value = value; }
Cake doesn't run steps in parallel, so you can be safely assured that A will run before B. I personally prefer to make my "release" step (which is empty) dependent on only the things I explicitly care about (starting from a clean slate, testing, and then packing). Each of those steps is dependent on things, some of which are the same (for instance, testing also requires a clean slate). Cake will figure out an order to run each of the steps in such that they run exactly once when they need to. So far, it's worked well for me even with a dozen or so steps.
Yeah `ToArray()` allocates... the idea is to keep it in a `Span&lt;T&gt;` for the duration of the call stack where it is being used. Spans can be `Slice()`-ed and copied (values in one range copied to values in another) and `ref` types can be pulled from them. You can think of a span as a pointer to some array segment, reinterpreted as whatever structure you desire. I think there is a nuget you can use to play with the prototype [here](https://www.nuget.org/packages/System.Memory). There will probably be some language support in C#7.2 for these types because you can get bad things to happen if you let `Span&lt;T&gt;` objects get in the heap since they have a pointer stored in a field. https://github.com/dotnet/roslyn/blob/master/docs/Language%20Feature%20Status.md#c-72 https://github.com/dotnet/csharplang/blob/master/proposals/csharp-7.2/span-safety.md
Considering the question, I didn't want to over complicate matters. But yup, can definitely use expressions for this! 
I see what you're complaining about, but I think it's an issue of poor organization. Each controller would be independent. I don't see why altering your PDF conversion code would break office uploads, for instance. If your upload makes a call to a PDF conversion controller, then altering the PDF conversion code should not alter the way the method is used; else you create a new method.
Interpolation is the same as `string.Format(...)`, just a different syntax and it has the same perf characteristics (unless you are storing it in a `FormattableString`). The fastest way to write this code would be something like this: public static Func&lt;Single, Single&gt; CreateFunction(string function, out String err) { string finalCode = string.Concat(prefix, function, suffix); ... } const string prefix = @" using System; namespace InLineNameSpace { public class InLineClass { public static Single Function(Single f) { "; const string suffix = " } } }"; Certainly though the string stuff here is such a small part of the profile here you could write it any way you want and would see it run 0.001% of the total profile or less.
If you're developing services for different audiences, then fair enough - in your first bullet point, your customer does not use your partner API and they do different things. I think everything you're saying makes sense. I don't have issue with making different web services for completely different purposes. It sounds like your microservices will all be on the same domain. It's worth noting that not everybody consumes a web service within their own project. With remembering URLs, I was thinking of accessing it through the web. Most web services are probably consumed by a website or other application.
I'm new to C#, can someone ELI5
https://www.nuget.org/packages/Microsoft.CodeAnalysis/
[This link](https://docs.microsoft.com/en-us/dotnet/core/tools/project-json-to-csproj#scripts) should help. Essentially, you run it the way we've done post build scripts in C# forever. &lt;Target&gt;&lt;Exec/&gt;&lt;/Target&gt;
You can do this without any third party libraries. You'll want to use [`System.Drawing.Graphics.CopyFromScreen()`](https://msdn.microsoft.com/en-us/library/system.drawing.graphics.copyfromscreen\(v=vs.110\).aspx) and the [`System.Windows.Forms.Screen`](https://msdn.microsoft.com/en-us/library/system.windows.forms.screen\(v=vs.110\).aspx) class. Example: var bounds = Screen.PrimaryScreen.Bounds; var screenshot = new Bitmap( bounds.Width, bounds.Height ); using( var graphics = Graphics.FromImage( screenshot ) ) graphics.CopyFromScreen( bounds.Location, Point.Empty, bounds.Size ); // do something with screenshot
 public class A { public string Method() =&gt; "A"; } public class B : A { new public string Method() =&gt; "B"; } var a = new A(); var b = new B(); Console.WriteLine(a.Method()); // writes A Console.WriteLine(b.Method()); // writes B Console.WriteLine(((A) b).Method()); // writes A Because the method isn't virtual, you can't override it, and casting the child object to the parent type will treat it as an object of the parent type.
I was being an idiot and forgetting how literally every modern object oriented programming language works.
[ScreenShot](https://imgur.com/a/My5VA) of it running...
Well, this is clearly a homework problem, but I'll try to point you in the right direction. A setter is used to SET a value. Why would you want to ever set yearly salary when you can just GET it by multiplying monthly salary by 12? One thing to keep in mind is that getters and setters are just methods that wrap accessing/mutating an object's fields. Another thing to keep in mind is that it's usually not a good idea to store duplicate data. For instance, suppose you also had a property, FullName, which should display the employee's first name, a space, and then their last name. Sure, you could set this property in the constructor, but FirstName and LastName have public setters. That means every time FirstName or LastName is changed, you have to remember to update FullName, as well. Ah crap, though, you can't do that in a property setter. Well, now you ditch the property setters for FirstName and LastName and replace them with methods SetFirstName and SetLastName, because in those methods, there's nothing to stop you from updating LastName, as well! Things are even worse if you (for some unknown reason) want to be able to publicly set FullName. This can quickly get you into a very bad spot where you're massively over complicating things. A better option is to make FullName get-only and return $"{FirstName} {LastName}";.
Spend 25% of your study month brushing up on fundamentals. Data structures, algorithms.. Practice writing Dijkstra and other technical interview favorites even though you won't be doing pathfinding in your new job they love asking you to solve those kinds of puzzles from memory. Spend the rest building some small focused projects (more than one) that you can put on github and show your interviewers. Learn and impliment a Web app on a popular framework. Bonus points for something you can show off on your phone.
Well, it is, but the instructor isn't being particularly helpful with answers like "Just figure it out. Do some research". Well, I don't understand where I need to put the math. How does EmployeeTest know where to look for the new salary with the 10% raise? I thought it would go the same way with the name, but it didn't work. I thought I could just use monthlySalary to compute yearlySalary and then use yearlySalary to compute the newSalary, but it didn't work. Is this what you mean by duplicate data? I guess we haven't read far enough into the book to see how we could use monthlySalary to just display both yearly- and newSalary. THis...is not going well. 
Sometimes it's helpful to remember that ideally, object oriented programming is meant to model real life objects. If you were to give an employee a raise in real life, what would happen? One thing is that their monthly salary would have to be adjusted to reflect that. It's not a matter of reading the book to figure out how to use monthly salary to display yearly salary. You have the formula, it's just monthly salary * 12. newSalary is unnecessary.
&gt; It's worth noting that not everybody consumes a web service within their own project. With remembering URLs, I was thinking of accessing it through the web. Most web services are probably consumed by a website or other application. True, you can mitigate around those hazards though. *Public* URLs shouldn't change, and public API contracts shouldn't change without consideration. As for whether it's worth providing access to said API's via nuget package, Swagger, or another thing entirely is up to you. Most (not all) of my experience has been coding to partners standards rather than creating APIs for others to consume, so YMMV. I'll admit, sometimes *that* part (the public API) is where it can start to feel like you're doing a little bit of meaningless passthrough code/duplication if your internal API is the same as your public API. That's part of why microservices can sense when thinking about abstraction; if everything always does the same thing and your server is fine with the load, staying with a more monolithic architecture is probably fine.
So can multiply that and show it at the same time? Or do you have to use two different statements for it to multiply AND THEN display? I think that's where I'm getting caught up now. If you tell it to do both in one, how does it know what product? Wouldn't it need to store it somewhere so it can remember what the yearly salary is supposed to be? edit: ok, I think I'm going to go back and just start over. Thanks
Okay, I think I understand your confusion a little better now. Get and Set are actually methods. C# auto-generates them for you. You could write a method like so: public decimal GetYearlySalary() { return salary*12; } This is something you can do in a getter, as well. You don't need or want to store yearly salary because then you run into a scenario like I described with FullName in my first reply. You may, however, want a get-only property that applies a transform to data you're already storing and then returns it.
When you can't control the base class because it s in a different solution.
DotNetRocks. I listen to them in class lol
Some tips, try to cut down on the amount of static methods you are calling in test, it's making it harder to read, especially when GetNewSalary 1 &amp; 2 do exactly the same thing. Now, first up, an "Annual" salary _is_ a yearly salary. the names are super confusing. Math tells us there is 12 months in a year, but salarys are usually recorded as yearly/hourly based, because of varying days in a month/year. So my advice would be to make your backing numbers the yearly/annual salary (unless your assignment says otherwise, it's heavily implied in your current code (by the constructor) that it's probably monthly based with year being the calculated value). then you need to create a getter for the monthly salary, but since you don't want to duplicate and keep the same value around (the salary) in different formats, you want to keep it's setter private (it's never going to have a real backing value) or do math when set in order to create a yearly salary and update that. on monthly get, you can simply calculate it right there and then from the yearly salary. All this can be reversed if you want monthly salary to be the real backing value. As for the 'add 10%' that's some pretty simple math. Salary = Salary + Salary*0.10 Hope this helps without giving it away too much.
It would be great to see these articles/tutorials/courses for ONCE without .Net Core and utilize the full .Net Framework and standard libraries with MVC 5 etc. Most companies cannot switch to Core, its relatively new and unproven and most see it as a risk still. Angular is being adopted in the front-end quite quickly however, so there is a disconnect with many of these tutorials in recent times focusing strictly on the Core version of.NET. Edit: Really? Downvoted for this? Go fuck yourself...
Oh. wow, ok this is different coming from Java.
And it will call the new version, even if the type is of the interface? but not if the type is of the parent class?
Yes, they want us to make up a monthly salary and then display the yearly salary and then give them a 10% raise and then display the new yearly salary. So, what was happening is I kept thinking that each time I had a new number, I needed it to be stored somewhere which meant a new variable. And it sort of snowballed out of control. I followed the way the book said to do the name part, and then it just left us to our own devices. So I thought the numbers could be done in a similar way, but this is only chapter 4. I really hate this book with a passion. It doesn't explain or define things very well. Now, I've started over and I'm trying to make sure I keep it more simple. I don't have to display the monthly salary or ask for the raise amount and maybe that's what began this muck. Thanks for the reply. I'm really trying, here.
It's slower, but negligibly slower. In 1 million inserts the difference is about 10ms. https://gist.github.com/nemec/e79d2e50867337634b78afcbe19fd123
Ok, so if get and set are methods and I only need monthlySalary, I can set the monthly salary like it tells me to, and then use set and/or get methods to multiply and redisplay it. Now, for example your GetYearlySalary from above: in the EmployeeTest I would still call it with GetYearlySalary(employee1)? ... So what's the difference between get and Get? Also, when I did the construct under Employee, why do I need to say First = firstName? I think those are the examples the book gives us, but it just feels like that's not necessary. Does that make sense? It's late and I feel like I'm speaking gibberish now...
There has been a number of attempts to get a Qt C# including Qyote and Qt#. Sadly, the complexities of Qt's precompiler (`moc`) makes things really difficult to make into C#. Most of the efforts go for a number of months and then stall.
My point with GetYearlySalary was just to show what you can do in a property getter. When I said Get and Set I actually meant the get and set as in: SomeProperty { get; set; } You can do something like: public String FullName { get { return $"{First} {Last}"; } } That creates a property that will return what you tell it to, but cannot be set. This is what you want for yearly salary. You want it to be a property of the Employee class, not a method in your test program. I believe your instructor is essentially interested in making sure that when you apply a raise to the monthly salary, that raise is reflected in the yearly salary. When you set First = firstName in the constructor, you're doing so because otherwise, First has a default value of null. Well, to be more precise, Name's BACKING FIELD has a value of null. In C#, when you do this: public String First { get; set; } what C# actually creates behind the scenes is something like the following: private String _first; public String GetFirst() { return _first; } public void SetFirst(String newFirst) { _first = newFirst; } So basically, it creates a private backing field, _first, and then creates two methods, one to return the value of the field and another to update the value of the field. These methods correspond to get and set of the First property. If you were to create a new Employee, e, and then do the following: Console.WriteLine(e.First); you're calling the getter. When you do e.First = "John"; you're calling the setter. So, to get back to the point, the reason you have to set these properties in the constructor is because their backing fields are null otherwise (or their default value for non-nullable types). For instance, if you gave Employee a parameterless constructor, like so, public Employee() { } and then did Employee e = new Employee(); Console.WriteLine(e.First); you'll see that First is null.
I know this place is not for homework review, but i'm learning as well, and looking through your code was a pretty good exercise for me, so here's my input. Ideally i'd say your setter for yearlySalary would just set MonthlySalary = value/12, if you even ever want to use a "set" for yearly salary, not sure there is a case for that. the "get" for yearlySalary would then "return monthlySalary*12". the setter you have for YearlySalary right now is pretty useless since it takes no inputs anyway, meaning your yearlySalary is only updated when you try to set it, but never to any value you supply. Further more, you could change Salary, call yearlySalary and not get the changed value as long as those are not tied by change-event or yearlySalary changed when Salary is changed. (alternatively, work on YearlySalary as the main, and MonthlySalary as the derived value, but choose one, or things get unnecessarily complicated.) I don't know if you're using VS2015 or older, but if you are, the code snippet "propfull" will autogenerate you a property, complete with private property. you seem to have a lot of repeat variables, like FirstName, firstName and First. you only need FirstName and its' private counterpart _firstName. You've also got a math problem with Annual, as far as i can tell. if YearlySalary is set to Salary*12. and annual is set to yearlySalary*12, Annual is going to return salary for twelve years (12 months times 12), that can hardly be the intended feature? also, like with yearlySalary, Annual is not actually set to a value until you do a "AnnualSalary = 120000" or something, however no matter what you input, the setter will disregard this and do "annual = yearlySalary * 12", so if yearlySalary is not set either at this point, you'll be dividing with null ;) You do not need a separate method for GetYearlySalary for employee 1 and 2, just a single method that you input first one employee into, then the other, no need for a separate method for each, when the methods do the same thing with the object they are presented with. Lastly, you prompt for raise percent for the employees, but in the method for applying the raise, you add raiseAmouny to Salary as a number. instead you should "Salary = Salary+(Salary*((100m+raiseAmount)/100)". this way, if you set 10 as your raise percentage, you're going to end up with "Salary = Salary + (Salary * 1,1)" which will result in a 10% raise.
&gt;you're probably saving a couple milliseconds (at most) A couple milliseconds is a HUGE amount of time in many usage scenarios, especially servers and games. If it's something that has to happen within a short update timeframe, then it's definitely worth going the most optimal route even if it is a bit more convoluted.
Just a few things, since you said you're learning, and hopefully OP sees this, too. Using propfull generates a property with a public getter, public setter, and a private backing FIELD, not property (pedantic, I know, but just to avoid confusion). Using the syntax to create an auto-implemented property: public String FirstName { get; set; } does the same thing as propfull under the hood, but with less clutter within the source code of the class, so it's preferable to explicitly declaring a backing field and manually implementing the getter and setter. This way, you don't actually need FirstName and its private counterpart, _firstName, you only need FirstName.
C++ is the problem in the first place, only C++ can talk to C++, because there's shitload of implementation that goes on top of C++. It load the stack differently from C, it mangled up the names of symbols, it have libunwind that you have to worry about unwinding the stack whenever exception happens, and so many other things. C++ is easily the shittest language out there and for good reason.
Url should be https://channel9.msdn.com/Events/dotnetConf/2017
Avalonia is a new upcoming gui framework that runs on .net core. It's pretty neat.
So just like your standard, everyday "find" tool? Maybe if you do some inheriting you can handle it in the onpaint override. But idk tbh
You need to use the rich text box control.
Honestly avalonia is still pretty immature for use (when compared to uwp). But I'd still go with Avalonia if nothing else than to support it.
Cool stuff! Out of curiosity: why's the PointerHelper type/size rewrite code written in IL as opposed to unsafe managed code?
If you have it as a reference to the interface it calls the new version. If not - try it and find out.
Im using tileview control to make a tiles Can rich text box control do something like that?
What are the issues you're running into? I'm sorry for the late response, just happened on this thread by chance again.
https://github.com/aelij/RoslynPad Includes a WPF editor with auto complete, auto-indentation etc.
I've not encountered any issues (yet), but that's something I'm trying to prevent before it happens as this is a production app. What I'm concerned about is database DTU and thread safety for relatively long running processes.
In that case, use the SQLCOMMAND syntax, and ideally a stored procedure, for the process. It alleviates/eliminates those concerns. https://stackoverflow.com/questions/7316304/is-sqlconnection-sqlcommand-thread-safe
It should be fairly easy to make Avalonia work on top of UWP: our Direct2D backend is targeting netstandard (so it will just work) and we already have TopLevel implementation for integration with WPF (which can be copy-pasted). It's just something that nobody actually needed yet. And it will also make the project impossible to build on Win7/8.1, which is still used by a lot of developers.
as i remember, i had some issues modifying the get and set og the "prop" versus the "propfull" since i don't know what the backing field is called, so i can't assign to it. that's why i use "propfull" instead. and yes, of course they're called fields, not properties, still working on using the correct syntax when talking about it. you have no idea how many times i went back and changed "function" to "method" in that post ;)
You can pinvoke c++ no problem. I've written c++ wrappers before. It has been used for decades, it's not shit. It's just a lower level language.
C++ interop was one of the founding pillars of C#, because Java couldn't do it.
Algorithms are pointless for most programming. I did algorithm work because I did a Master's degree in Physics, and Physics is all about problem solving. In my experience, most programming doesn't need any of it. I disagree with wasting time on algorithms, unless that's the sort of work you want to do. If you want to be a good programmer, then learn to program. Make something you want to make, and you will learn from it.
Yes, methods in Java are virtual unless specified otherwise. In C#, class methods are final unless they're abstract, virtual, or an override (but you can declare an override as sealed, and it will behave like it's not virtual for that class's descendants). Methods from interfaces behave as virtual methods when called from a reference typed as the interface, and as however they're declared when called from a reference typed with the class. *And* you can implement interfaces explicitly, which only exposes the interface methods when the reference is the interface type. Also: `new` is optional when shadowing an inherited method or property, but omitting it when you do that will generate a warning during the build. The access modifiers are different, too, but much simpler.
Thank you
You are thinking about it as a set of orders for you to perform, not as a description of a situation. This is not a problem of books and teachers, but a problem of wrong mindset. Now throw all C# and programming away for a moment and imagine a boss giving his employee a 10% raise. You had a guy with a monthly salary X and a yearly salary 12*X. Now you have a guy with monthly salary 1.1*X and yearly salary 12*(1.1*X). What changed about that guys paycheck? Only the salary. He does not see any new number that was not there before, just a different value. If he tells his friend he earned X one month and he got 10% raise, his friend will know what was his old yearly salary and what is his new yearly salary. Try to translate this situation into code.
It's a little convoluted for the TileView, but here's the basic steps: 1. Create a RepositoryItemButtonEdit as the in-place editor for your TileView column that requires the formatting 2. Set the following properties of the RepsoitoryItemButtonEdit: * AllowHtmlText = DefaultBoolean.True * TextEditStyle = TextEditStyles.DisableTextEditor 3. Assign the RepositoryItemButtonEdit to the TileView columns using their ColumnEdit property 4. Handle the RepositoryItemButtonEdit's CustomDisplayText event and use the built-in DevExpress-supported [HTML formatting](https://documentation.devexpress.com/WindowsForms/4874/Common-Features/HTML-Text-Formatting) to mark up your text parts as required. private RepositoryItemButtonEdit textEdit = new RepositoryItemButtonEdit(); textEdit.AllowHtmlDraw = DevExpress.Utils.DefaultBoolean.True; textEdit.CustomDisplayText += TextEdit_CustomDisplayText; textEdit.TextEditStyle = DevExpress.XtraEditors.Controls.TextEditStyles.DisableTextEditor; tileView1.Columns["FieldName"].ColumnEdit = textEdit; A sample event handler for the RepositoryItemButtonEdit: private void TextEdit_CustomDisplayText(object sender, DevExpress.XtraEditors.Controls.CustomDisplayTextEventArgs e) { string part1 = e.DisplayText.Substring(0, 2); string part2 = e.DisplayText.Substring(2, e.DisplayText.Length - 2); e.DisplayText = $"&lt;b&gt;{part1}&lt;/b&gt;{part2}"; } 
Ah interesting question! The reason is because it does things that aren't possible in C#. It uses ```fixed``` to grab a pointer to generic types. Pointers to a generic type aren't possible in C# since there is no way for the compiler to ensure/determine they won't be used for managed types. But it is possible in IL! Here is what the IL would look like in C# if it was possible to implement in C#. internal static class PointerHelper { [MethodImpl(256)] public static UIntPtr GetTypeHeaderValue&lt;T&gt;() { unsafe { fixed (IntPtr* intPtrPointer = &amp;(new T[1])[0]) { return (*(intPtrPointer - sizeof(PointerHelper.ArrayHeader))).type; } } } [MethodImpl(256)] public static void SetTypeAndSize&lt;T&gt;(T[] values, UIntPtr type, UIntPtr size) { unsafe { fixed (IntPtr* intPtrPointer = &amp;values[0]) { fixed (IntPtr* intPtrPointer1 = intPtrPointer - sizeof(PointerHelper.ArrayHeader)) { (*intPtrPointer1).type = type; (*intPtrPointer1).length = size; } } } } } edit: It may be possible to do with TypedReference, I didn't look too much into that though because I couldn't support NETStandard1.1 if I used TypedReference afaik.
Any exceptional ones people would recommend? I caught about 15 mins of the one on security seemed quite good. Also I wanted to watch the one about kubernetes.
Well yeah, you're absolutely right. A couple of milliseconds CAN be a huge amount of time, but I took from OP's example that the problem most likely IO bound, and the dictionary lookup is inconsequential.
Thanks for correcting 
I was thinking about the same things actually. It would be a lot more helpful to show how this is done with the full .NET framework rather than with .NET Core.
Consider finding and contributing to an open source project that either uses or is your preferred frameworks.
Review your latests jobs. Every project you intent to do something in a better way than before... but during development time you end it up using the easiest solution 'cause its faster.... i bet w/y that every project you worked on will find something to improve... doubt that?! Besides MVC, do you applied any other design pattern? Are you using parallelism? Threads? ...and so on... in fact... i keep a notebook with everything in every project that i already know that could be done in another way. (Ie: gonna use a DAO class for db crud here cause its faster.. but... i wrote down: "would have been better to use entity framework? How can i implement it faster? Can i use it in any situation? Can i implement it faster than a DAO class? ... it works for me.... every job, first i dont make the same mistakes made in the past and finally keeps pushing me always try to find the best solution for that problem... 
Removed: Rule 4. Feel free to repost, but please include the code you're trying to use. Also please mark it as NSFW. Also, maybe this is an issue with how you have the console configured. I'm assuming you're using a console application? If so, by default the Windows console is 80 characters wide, but you can change it to be longer: https://stackoverflow.com/questions/319305/why-is-the-windows-cmd-exe-limited-to-80-characters-wide
I do this between projects too. What I tend to do is look at where I feel I am the weakest and/or where I want to improve more. Then research that particular aspect. For me, I wanted to learn and understand more deeply C# events and delegates so I started watching a video on that on www.pluralsight.com. it's a great help to me.
bump
With or without a job every real programmer does the same thing. 1) identify a weak area 2) some form of learning in that area 3) realize full understanding requires a good knowledge of 5 other areas 4) take 1 topic from step 3 and go back to step 2 with it.. repeat forever .. and love it 
hilfen? anybody?
&gt;C# does not allow for strings longer than a line? Do you mean that the console window doesn't allow for a long string on a single line?
Pick one thing to focus on. Go deeper instead of wider.
but... with .Net core 2 you can just do `dotnet new angular` and it will set up the entire project structure for you... and you don't have to serve the angular when you do dotnet watch run, dotnet watch run will monitor all files for recompile, not just the .net side, you should never need to call ng serve
Removed: Rule 4. This is a really open ended question and probably no real way to answer it. You would also want to clarify if it's most commonly used directly by developers or more commonly invoked by the CLR via abstraction.
Removed: Rule 4. Again, no marking of it as NSFW, and no commentary about updating the console window as I suggested. Also, please ensure your code is indented/formatted for display on Reddit. If you don't want to mark it as NSFW, then you can probably skip the "naked ladies" part and just make it about outputting a long line in general.
The base class is out of my control or I just don't have time to refactor the base class properly.
Seems like this would be better solved with generics
You should in general consider using `AsyncLocal&lt;T&gt;` instead of ThreadLocal, as well.
In my opinion, pretty much never. For some bizarre reason the `new` keyword isn’t required and not having it only generates a warning. 
Assembly versions and NuGet versions are not (necessarily) the same. App.config redirects apply to the former. Those are generated automatically by msbuild if needed (ever since Microsoft admitted that their assembly versioning system was never going to work and effectively dismantled it).
Cool! Are you the maintainer of this project? If so, it looks like there's some code there (in RoslynPad.Roslyn) that's copied from src/Editor features/CSharp in the Roslyn repo. How much did you have to have to adapt it to work for your editor?
Yes, I am already aware of Roslyn as I mentioned in the description. What I was asking for was any existing code I could use for editor features like brace completion/Intellisense/etc, which Roslyn doesn't directly offer APIs for.
I was always curious about that. It's interesting that, when reflecting upon an object with members declared as `new` members, it still has the original members. Say you have this: public class Bar { public object A; } public class Foo : Bar { new public object A; } And then you try this: PropertyInfo property = typeof(Bar).GetProperty(nameof(A)); You'll get an `AmbigiousMatchException`. If you use `GetProperties`, you'll see both `A` properties are present.
Diversify. Right now i'm into diversifying my skills, but that's only because diversifying got me my current job prospects. Get into something that is *related* to what you're currently skilled at... something that will compliment what you can do now. You said you're interested in mobile development. Maybe you could spend the next month hashing out a mobile app good enough to serve as a presentation of serious skill to potential employers. That way at the end of the 30-45 days you can move on from that project with more skills and without the need to go back to finish it later. I hate unfinished projects.
As he posted RoslynPad, which I found uses what I was going to suggest as well, I'm going to go to the source that actually gives you the tools: https://github.com/icsharpcode/AvalonEdit used it multiple times to great success.
If you need multimonitor support for some reason, you'll want to do this per Screen in Screen.AllScreens. That would give you one bitmap per screen; stitching them together is left as an exercise for the reader.
Find a niche, enterprise level product that gets lots of reqs in your area and learn it. Obv go for something based on .NET so you can learn it faster. Once done (usually 3-6 weeks) you can now do jobs for higher rates due to the niche and the process of learning the software will teach you multiple new things that are useful even outside the product. Some products have boot camps and certifications that are not too expensive or hard to get. 
Is it possible to create a new array header to point to the same array body instead of overwriting the existing array header?
Hmmm I'm not sure. The pointer hack accesses the [array object's header](https://blogs.msdn.microsoft.com/seteplia/2017/09/12/managed-object-internals-part-3-the-layout-of-a-managed-array-3/) to rewrite some stuff so the runtime sees it as the type and length you want. I'm not sure you can properly construct a new array object header without constructing an array, I never tried. If you could I think you'd encounter the issue that alerting the GC to this new reference, if even possible, would be more experience and that the new header/reference might not be considered a real reference and wouldn't keep the GC from clearing up the array. You'd need to do a lot more than just that I think to create a managed reference object, I wouldn't even know the process! I don't really know though, this project pushed far beyond my own limits already. I'd have to experiment and research to know if what you're asking about is possible or viable. Someone way more knowledgeable can chime in though!
I'm in your situation, except I'm unemployed, so I don't have a defined time interval. If you haven't done it already, create a project and put it on git. It could just be what you know already -- done well! Or you could pick up something new. Core ASP.NET is a huge topic. I don't know if it's much of a credential in the job market.
Jesus These answers are so contradictory.
.LearnRecursively();
This is just a guess -- but I'd consider getting into WPF. It will let you explore amazing UI stuff, if that interests you. I nominate it because I know a big-brain intellectual developer who gets fascinating WPF gigs at research organizations and medical device companies.
Sorry I appreciate the response, but that's really just learning MVVM pattern, probably PRISM or other framework and then you're just doing MVC applications :( This isn't salary related or full job related,, but more about making myself feel like a much smarter developer...hard to explain because obviously top C# gurus are indeed genius level but I feel like the knowledge I currently have wouldn't get me a job at Amazon for example. I know I said its not job related, but it serves as a reference point ! 
Maybe you could allocate a zero length array of the target type, rewrite it to point to the other array's body and give it the correct length. Then you could rewrite the original to point to the zero length body and give it a zero length. You'd still be modifying the original, but at least any code accessing the original array would type safe, they'd just get index out of bounds exceptions.
 public partial class CustomControl1 : Control { public string Text = string.Empty; public string Hightlight = string.Empty; public CustomControl1() { InitializeComponent(); } public int GetWidth(string text, Font font, Graphics g) { if (string.IsNullOrEmpty(text)) return 0; StringFormat format = new StringFormat(); RectangleF rect = new RectangleF(0, 0, 1000, 1000); CharacterRange[] ranges = new[] { new CharacterRange(0, text.Length) }; Region[] regions = new Region[1]; format.SetMeasurableCharacterRanges(ranges); regions = g.MeasureCharacterRanges(text, font, rect, format); rect = regions[0].GetBounds(g); return (int)(rect.Right); } protected override void OnPaint(PaintEventArgs pe) { base.OnPaint(pe); if (string.IsNullOrEmpty(Text)) return; var index = string.IsNullOrEmpty(Hightlight) ? -1 : Text.IndexOf(Hightlight); if(index == -1) { pe.Graphics.DrawString(Text, new Font(new FontFamily("Calibri"), 16, FontStyle.Regular), Brushes.Black, new Point(0, 0)); } else { var t1 = Text.Substring(0, index); var sz1 = GetWidth(t1, new Font(new FontFamily("Calibri"), 16, FontStyle.Regular), pe.Graphics); pe.Graphics.DrawString(t1, new Font(new FontFamily("Calibri"), 16, FontStyle.Regular), Brushes.Black, new Point(0, 0)); var sz2 = GetWidth(Hightlight, new Font(new FontFamily("Calibri"), 16, FontStyle.Regular), pe.Graphics); pe.Graphics.DrawString(Hightlight, new Font(new FontFamily("Calibri"), 16, FontStyle.Regular), Brushes.Red, new Point((int)sz1, 0)); var t3 = Text.Substring(index + Hightlight.Length); pe.Graphics.DrawString(t3, new Font(new FontFamily("Calibri"), 16, FontStyle.Regular), Brushes.Black, new Point((int)(sz1 + sz2), 0)); } } } Create a custom control and draw text in paint event Long time since I used Forms.. I don't know why measure-text thing is so complex in 2017 :P Measure text code from here - https://www.codeproject.com/Articles/2118/Bypass-Graphics-MeasureString-limitations 
Get drunk all the time and wing it. That’s the only sensible answer. 
 As Captain Jack Sparrow said, you've obviously never ~~been to Singapore~~ done WPF programming. It is a completely different paradigm from web development. More importantly, people who are building WPF apps instead of web apps are doing so because they need a rich interface that's hard-to-impossible to deliver on the web. Formulating a theory on one friend's experience is bad science, but he keeps getting really cool projects. It's his opinion that WPF pays better than web development, too. Every kid coming out of college has web skills. Demand for WPF is a *fraction* of the demand for web developers -- but the *supply* of WPF developers is even smaller relative to demand. "get me a job at Amazon"... Wow, that's a whole different thing than what you were originally asking, I think. Good luck. I've talked myself into hitting the WPF learning curve again. I find it challenging -- and I've done about 20 years of desktop app development with other technologies (PowerBuilder, WinForms).
maybe regex is what you want: https://www.google.com/search?q=regex+match+case+insensitive
Hmmmmm maybe, I'll have to tinker around with that.
You can call `ToLowerInvariant()` on your strings before comparing them to "normalize" their cases.
WPF is pretty easy lol. 
Have you considered just using regex pattern matching for this?
To the Edit, ya, how dare people disagree with your opinion. Who do they think they are?!?!?!
Using new is probably not a great idea. If you marked your properties with virtual you might be able to get the effect you desire. This MIGHT be a good use of an Interface (Where both classes implement the same interface that has the shared properties) depending on why you are trying to keep the serialized variant separate. 
Makes sense! Here's a non-IL-based implementation. Output: 1920275964 1 &lt;- Dummy TOut[1] = uint[1] type and length 1920287816 8 &lt;- Dummy TIn[] = byte[8] type and length 30201000 7060504 &lt;- Reinterpreted bytes due to endianness and no left-padding Doesn't use native ints, though IIRC IntPtr would work as a stand-in replacement? Also, I love how `(TOut[])(object)input` actually works :P unsafe class Program { [StructLayout(LayoutKind.Sequential, Pack = 1, Size = 8)] public struct ArrayHeader { public uint Type; public uint Length; } static void Main(string[] args) { var bytes = new byte[] { 0, 1, 2, 3, 4, 5, 6, 7 }; var result = ReinterpretArray&lt;byte, int&gt;(bytes); Console.WriteLine($"{result[0]:X} {result[1]:X}"); } static TOut[] ReinterpretArray&lt;TIn, TOut&gt;(TIn[] input) where TIn : struct where TOut : struct { var dummy = new TOut[1]; var pDummyArrayHeader = (ArrayHeader*)GetAddr(ref dummy[0]) - 1; var pInputArrayHeader = (ArrayHeader*)GetAddr(ref input[0]) - 1; Console.WriteLine(pDummyArrayHeader-&gt;Type + " " + pDummyArrayHeader-&gt;Length); Console.WriteLine(pInputArrayHeader-&gt;Type + " " + pInputArrayHeader-&gt;Length); pInputArrayHeader-&gt;Type = pDummyArrayHeader-&gt;Type; var sizeofTIn = (ulong)Marshal.SizeOf(default(TIn)); var sizeofTOut = (ulong)Marshal.SizeOf(default(TOut)); pInputArrayHeader-&gt;Length = (uint)(pInputArrayHeader-&gt;Length * sizeofTIn / sizeofTOut); return (TOut[])(object)input; } [MethodImpl(MethodImplOptions.AggressiveInlining)] public static IntPtr GetAddr&lt;T&gt;(ref T t) { TypedReference reference = __makeref(t); return *(IntPtr*)(&amp;reference); } }
Vaguely curious if there's GC Gen Numbers around both of those. I'd still use Dictionary in almost every case due to readability, but I could imagine some lower level libraries doing enum based access if it's a crazy hot path.
I would create a matching model to serialise. Then either use something like AutoMapper to map one to the other. Or just pass it in the constructor and set the properties.
Step 2: Add link to git on your resume. 
Dunno. Running these through my half-assed "benchmark" was about as far as I was willing to go, since there's only one in about a gazillion cases that will ever have this become an issue. If you want to profile it in detail, feel free. :p
Exactly! Thank you sir!
I'd try to focus on and finish one of my 37 half-baked personal projects that touch on some of those areas. What would actually happen is I'd bounce around between all of them making no progress.
No I'm not the maintainer, sorry :)
Get a job at a temp agency, preferably one that involves manual labor. Physical exercise will improve your health and add clarity to your mind. I know it sounds counter-productive, but sometimes the best way to improve at something is to take a break from it. When you return to programming you'll be amazed at how much faster you pick things up. Plus you get some extra beer money. *** If cash isn't a problem, you can take up a hobby or sport. Just as long as it involves actually moving around and not just playing video games.
https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/generics/generic-methods
I suspect this is a case of not studying up on [Generics](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/generics/generic-methods). You basically already found the answer but just don't know it. :) public class Program { private static int x = 1 ; private static int y = 3 ; public static void Main (string[] args) { //Your code goes here Console.WriteLine ("Hello, world!") ; Swap (ref x, ref y) ; Console.WriteLine (x.ToString() + "should be 3.") ; // Swapped from 1 to 3. Console.WriteLine (y.ToString() + "Should be 1.") ; // Swapped from 3 to 1. } public static void Swap&lt;T&gt; (ref T x, ref T y) { T i = x ; x = y ; y = i ; } }
Thank you. I hadn't read about Generics yet.
Yeah, a case of having not read about them yet. Thanks.
No problem. 
Careful with that unbounded loop.
( ͡° ͜ʖ ͡°)
Nice. Does AvalonEdit use Roslyn or a different C# code model? Also, does it have a dependency on Windows Forms or WPF?
I made an extension method for you: public static string[] SplitIgnoreCase(this string str, char[] separators) { var splits = new List&lt;string&gt;(); var lastIndex = 0; for (int i = 0; i &lt; str.Length; i++) { if (separators.Any(c =&gt; char.ToLowerInvariant(c) == char.ToLowerInvariant(str[i]))) { splits.Add(str.Substring(lastIndex, i - lastIndex)); lastIndex = i + 1; } else if (i == str.Length - 1) { splits.Add(str.Substring(lastIndex)); } } return splits.ToArray(); } In action/demo: http://rextester.com/HNKH45219 https://pastebin.com/w5Yh5D88 EDIT: just realized you were asking for strings, check my other reply
 public static string FindFirstNeedle(this string str, string[] needles, StringComparison comparison) { foreach (var needle in needles) { var i = str.IndexOf(needle, comparison); if (i &gt;= 0) return needle; } return null; } public static string[] SplitIgnoreCase(this string str, string[] separators) { var splits = new List&lt;string&gt;(); var needle = str.FindFirstNeedle(separators, StringComparison.OrdinalIgnoreCase); while (needle != null) { var i = str.IndexOf(needle, StringComparison.OrdinalIgnoreCase); splits.Add(str.Substring(0, i)); str = str.Substring(i + needle.Length); needle = str.FindFirstNeedle(separators, StringComparison.OrdinalIgnoreCase); } if (str.Length &gt; 0) { splits.Add(str); } return splits.ToArray(); } http://rextester.com/HNKH45219 https://pastebin.com/irtnPf6H You can optimize this, but I'm too lazy to do it.
"Alright let's see what it takes to add user authentication functionality via Azure AD in this app." An hour of googling later... "Time to get the beer cause it's gonna be a long night of trial and error"
&gt; Most companies cannot switch to Core Most companies cannot switch from old version of windows. Heck we still use Kaspersky 6.
problem with reddit system is that your opinion when downvoted appears as written by an idiot and people will not read it, or will read it with the bias that is wrong, which will get more downvotes.
Edit: Whoops, misunderstood your post. Yeah, if you're modifying the getter and setter, you need a backing field. In the case of FirstName, all OP needed was an auto-implemented property, though, which was why I pointed out what I did. I also thought you were under the incorrect assumption that you had to implement a property manually, but I was mistaken. Generally, you want to avoid modifying the backing field directly, you want to go through the setter unless there's a really compelling reason not to do so. These situations arise (very rarely) from time to time, and then yeah, it's best to implement the property and backing field yourself. And haha, yeah, I slip up with methods vs. functions and properties vs. fields pretty regularly, I just figured for the sake of clarity it was best to point it out in this case due to the nature of the post. People who get all bothered by incorrect terminology even when the intent is understood are annoying.
&gt;Heck we still use Kaspersky 6. My deepest sympathies friend.
Companies aren't perfect, and even when using agile methodologies (or sometimes because of), when it's all about adding new features, you can build up a lot of technical debt. In the PDF controller case, you'll likely add database support to save/load older copies, so some dependencies there in the DB/stored procedures, also with the vendor who also gets chances to screw up with new releases. So lots of places for things to potentially go wrong as more and more features are added with every release.
That definitely seems a lot easier than crafting some IL. I'm curious if it performs better. But I cannot possibly know how safe this is. Can the object not move after ```return *(IntPtr*)(&amp;reference);``` or does makeref do something to ensure it never moves? Also the dummy header you're using appears to be used in essentially the same way I use it, to get a reference to the array Type's table/type/info. So very similar except for the use of TypedReference, which honestly makes me weary because I don't know enough about it and whether it's safe to pass a pointer to where it points to around without fixing it somehow, I know you can't return any pointers from a fixed context because sometimes it moves... It rarely comes up so it's difficult to debug and cover because it seems like it'll work. I would need to read a lot more about TypedRerefence and __makeref before I used it. Somehow it feels even more dangerous than the rest of the hacking going on lol.
When serializing using the build in MS serializer you can use overrides. See https://stackoverflow.com/questions/602384/can-i-add-attributes-to-an-object-property-at-runtime
Sounds like you want to do something more computer science-y. Maybe find a good machine learning MOOC?
It’s not guaranteed, but one often-good indicator of the corporate style is to hang out near the office around finishing time. If almost everyone comes out bang on closing time, that might be worth thinking about (although isn’t a red flag alone) If people appear half an hour before and slowly appear over the next hour, that’s probably a good sign. Why? Because it shows the company isn’t the type to stick to an overly rigid structure just for the sake of it. That can matter for your personal work life balance, but in my own experience it also seems to strongly correlate with how management deal with technical issues too
If you're dealing with newer projects created using VS2017, NUGet references [may have moved to the .csproj file instead](https://docs.microsoft.com/en-us/nuget/consume-packages/package-references-in-project-files).
The TPL does not start a new thread for every call to `Task.Run`. It has a pool of threads that it wants to reuse. Clients are expected to run for a short time and then return control so that other code can use that thread. There are situations where it will increase the number of threads, but that is not something you should depend on. Threads are expensive. You should use as few as possible. In this code you can use `async`/`await` and `Task.Delay` to get the effect you want without blocking the threads. for (int i = 1; i &lt;= 20; i++) { int captured = i; Task.Run(async () =&gt; { while (true) { Console.Write(captured); await Task.Delay(TimeSpan.FromMilliseconds(100)); } }); } 
You're totally right and your modification does indeed produce the results I asked for. Thanks! But I think I oversimplified my original question. I boiled down my problem to that small code snippet but maybe I boiled it too much. Instead of Thread.Sleep(), my real code has some relatively expensive computation (not I/O - I know thats a different story). So I dont think async/await applies to my case. Is it simply a matter of "threadpool knows best" and I should allow it to do what it thinks is more efficient? I would prefer if all threads would run more or less simultaneously, because I would like the quickest calculation to finish first, not just the one that I started first. Edit: Just found out about ThreadPool.SetMinThreads. This seems to do exactly what I need if I set the minimum number of threads to 20. But I cant help feeling that its a bad idea to mess with the threadpool like that. I guess I need to read more.
It’s worth considering whether you really want all 20 tasks to run simultaneously. Unless you’re running on a machine with 20 cores you’re not really saving any time by doing that. In fact, the context switches actually make it slower. It’s better to let the scheduler do its job instead of trying to make it “fair”. Usually the scheduled is right, and you should trust it. If for some reason you really need it to behave this way then another option is to use the `TaskCreationOptions.LongRunning` flag, which is a hint to the scheduler that this task will run for a long time so maybe it should dedicate a thread to it. You can replace `Task.Run` with `Task.StartNew` and use `TaskCreationOptions.LongRunning` as the second argument. 
There are only so many threads that can be run at the same time. Typically, that's the number of CPU cores. Although there are valid reasons for setting the minimum number of thread pool threads higher, it won't make things run faster. You might get a more even scheduler distribution, but it's going to make the overall process longer as you context switch more frequently. I think your comment about reading more is definitely a good idea. There are strategies for dealing with highly-concurrent workloads, and depending on your problem, you might find a solution that works better than a naïve "run these all together" approach. I strongly suggest "Concurrency in C# Cookbook", which is written by Stephen Cleary. Even if you think you know everything there is to know about concurrency in C#, Stephen can teach you something.
You blocks thread for 100ms and becouse of that your for loop cant spawn new tasks. Just make your task lambda async and intead of Thread.Sleep(100) use await Task.Delay(100) Here [fixed version](https://gist.github.com/ADworld-AleD/ba5d268deae6adb1f0031e44a6c73f75) of your code.
You can try to make your computation function async and call Task.Yield periodically. Switches between tasks in same thread is a lighter that thread switching.
You could use attribute [ThreadStatic] like this : Class Test { [ThreadStatic] int NextPrice; } So every thread will has its own NextPrice variable.
Finally, a voice of reason!
How did you conclude that you have 4 threads off the bat? And do you mean main+3? But anyhow... I did not look at the .net source code, but the number of threads in a thread pool implementations is higher than the number of cores. One other MS implementation I saw sources for uses cores*4. This is because: * one expects some i/o in threaded work, in which case threads execute while others are waiting for the i/o * having more threads helps spreading work through OS scheduling and achieving "fairness" at the expense of more context switches I see that else-thread, you say that your actual work is CPU-bound. If that's the case, then having more threads than cores is harmful due to context switching. If so, suggest to read the [number of processors](https://stackoverflow.com/questions/1542213/how-to-find-the-number-of-cpu-cores-via-net-c) and only use that many. But! * ***measure*** * if you still want to go faster, you will need to look at doing less work, and smarter (number of allocations, data locality, [CPU-level data parallelism etc.](https://cppandbeyond.wordpress.com/2012/07/26/new-session-writing-fast-code-i-and-ii/))
That's what stack overflow is for
To add to the other 2 good replies here: If you have CPU-bound work then async isn't really the right solution. If the problem looks very similar to your example, consider using [Parallel.For](https://msdn.microsoft.com/en-us/library/system.threading.tasks.parallel.for.aspx), (or ForEach if you need it). This will automatically distribute the work across an appropriate number of threads.
And soon Java can do it just as well, and even has interop with even more languages natively. Interesting how these two languages constantly push another forward.
To correctly format code in Reddit: - Have an empty line between text and your code. - Indent every line with 4 spaces. If you want it to use a new delay every time, simply move the declaration of `delay` inside the `for`-loop. Then it will be executing `ran.Next` at every loop iteration and always creating a new `delay`-value. And currently you're not even using `delay`. You likely want to replace the `50` with it.
You should just use Thread.Sleep(ran.Next(20,82));
yeah, hehe ^^; mistyped some of my comment. Also, I tried that earlier and got an error, but it seems to be working now, strange... Thanks for the help!
Perhaps not reading more, but thinking more. 20 threads on 4 cores is one thing, but what about if you had 200? 2000? 2,000,000? I’m reading between the lines here that your “expensive” computations might take a short time, or a very long time. (Because you say you want the quickest to finish first) Stats and math might be boring but here’s where it matters. If your computation takes 100ms-1000ms *of CPU time* then knowing the number of threads and cores you can calculate how quickly you will be done. Do the math to work out if doing 20 threads simultaneously (slower overall) or 4 threads, then 4 more, then 4 more etc is quicker. 
You're doing "kernel call" (Console.Write here) in your execution. This will *always* fuck up any and all performance/priority measuring you're doing. The "kernel call" is anything that gives control from your thread/process back to kernel (when asking it to do stuff). So any kind of IO, exceptions, many memory manipulations. At that point the processor that is running your code switches to kernel mode and the kernel does what it needs to do. *BUT* your code doesn't go back to be the one that's executed, it's put back into the "waiting" queue and kernel will decide what other thread can be scheduled back to run.
We have tail recursion, its OK. And we don't need an explicit termination clause, our hypervisor eventually shuts us down though not always gracefully.
&gt; "Alright let's see what it takes to add user authentication functionality via Azure AD in this app." An hour of googling later... If it can be added in a new project then create a new project with it. It helps put the documentation in context and can save hours. This is how I learned the differences in adding Azure AD from asp.net core 1.0 to 2.0, and how I learned the way to do asp.net core configuration in general. There are a lot of things they put in the new project templates that don't even make it in documentation, sadly.
What areas do you feel weak in? How many years of experience do you have in C# and web technologies? I have found that the best way to learn is to "always be reading". New articles, books, blog posts, etc...and to be part of a team that pushes you. If you have worked on larger or enterprise teams, you often get pigeonholed into a narrow focus. What has your enterprise vs small team / small company ratio looked like?
You know what, you’re absolutely right. I’ve just recently been working on one of those scenarios you describe. There was a lot of code using dictionaries, but worse, there was lots of LINQ `.Join()` calls on these dictionaries. Thing is, if you join two dictionaries on their keys using LINQ, you don’t get any of the O(1) performance because the first thing it does is turn it into an IEnumerable of KeyValuePair objects and the everything is just serial search. And all of a sudden we had a situation where this code needed to be called tens of millions of times instead of once. I moved everything into arrays and took out the joins, and made the code go from ten hours to under a second. Fun, but in 99% of situations it’s not going to matter, as you say.
Keep in mind that Parallel.For &amp; Parallel.Foreach are not thread safe so only use if each iteration of the loop is independent.
If you love C#, you can still write low latency and high throughput code. Read up on object and array pooling, System.Numerics (SSE/AVX extensions), GPU code libraries for .NET and other high performance C# conventions (e.g. you can stack allocate an array in unsafe C# code). We need more high performance C# libraries. The downside here is that C# vectorization is explicit (no auto vectorization) and you'll have to treat the GC like an angry child sometimes. I don't think GO would give you the kind of change you expect. When people call GO a systems language, they mean more than you can build systems out of it, and they don't mean kernels or OS code, they mostly mean services that work together in the cloud world (more like microservices). Based on your description, Rust is probably your best bet. It lets you manage ownership / memory in a more modern way with more safety and still enables high performance code. That said, the largest pile of knowledge on performance code and systems level programming is going to be in C/C++ for the foreseeable future. Those will look good on your CV as well...I just know that I don't have any interest to touch those in a mid or large project myself. Reading C or C++ makes me want to pull out my teeth. 
&gt; However, if you created a .NET Core class library that targeted the .NET Standard platform, you would be able to use it within all projects that target a platform which complies with .NET Standard. You're creating a .NET Standard class library, not a .NET Core class library. The list of missing features is very short and does not cover nearly enough. There's so much more important features missing (e.g. AppDomains, WCF server).
Good spot - thanks! 
Sorry not sure why formatting isn't working, im trying to indent 4 spaces... Still new to reddit
Indentation didn't work because you used 3 spaces for the first block. Also, both "random" code blocks look identical to me. Did you accidentally paste the same block twice? int a = new int(); Doesn't really do anything, basically the same as `int a = 0;` or `int a = default(int);` The existence constructors is useful though when used with generics and the [`new` constraint](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/new-constraint).
Sorry, updated
In the second example you haven't assigned an object to rnd. You can't call a method in rnd if it doesn't refer to anything.
 Random rnd; is just a placeholder for a random Object, you haven't created one yet, it still remains unassigned. However once you do: Random rnd = new Random(); It is created and assigned to your placeholder, hence why you can use it now. Regarding data types, for primitives it doesn't really make much sense, it just assigns their default value :) You should only use them for classes or custom defined value types (structs).
C# has rules whereby it can enforce that any variable is assigned something before being accessed. In this case, you can't use `rnd` because you haven't assigned anything to it yet. You could write `Random rnd = null;` and then it would compile (though you would get a `NullReferencdException` when you try to use it at runtime.) Maybe in the context of the question you're asking why you don't have to do this with value/struct types? Well, you do if these were local variables. If they were class _fields_, C# has rules where reference/class (and nullable structs) types are initialized to `null` and non-nullable value types are initialized to their "zero" value. Not sure if this answers your question or not. I'm not quite getting exactly what you're asking about, sorry.
Answered it perfectly- thanks!
Yeah automatically adding with a new project is best. Unfortunately I had to rig it into an existing WPF/WCF project
Give each letter a rough x,y coordinate as it’s laid out on a qwerty keyboard. When going from letter n to n+1, calculate the Cartesian distance between the two key coordinates, and use that number to calculate your delay. Simulates someone hunt and peck typing. 
I more meant adding a new project shows you which classes to use, how to configure them and where to set it up in the 'pipeline' so that you can figure out where to put it in your existing project. That said, is there even a template for AD Authentication for WPF projects?
I feel like I would have saved me a bunch of time had I thought of this rather obvious approach. I found no such template and the official docs are severely lacking
Sadly I'm currently unable to wrap my head around it. All the code I have is working perfectly. I just don't know how to proceed from here. Bascically I don't know how I should actually validate the user and then return something like an authentication token.
Understanding C#'s 2 categorization of objects, either Value Types or Reference Types, is crucial in grasping the fundamentals of the language. Here's a long StackOverflow post on the topic: https://stackoverflow.com/questions/5057267/what-is-the-difference-between-a-reference-type-and-value-type-in-c
Look at DSO using JWT
If you really need perpetually (or at least long) running threads, just create your own `new Thread()`. They'll start immediately and won't be subject to the thread-pool's scaling algorithm. This still doesn't guarantee perfectly even distribution (depending on the OS scheduler, other CPU load, etc.), but it'll be much closer. If the actual work performed in place of the `Thread.Sleep` also consists of smaller discrete steps in a loop, you could use some sort of queue. Start a number of worker threads independent of the number of work items, and have each thread repeatedly pick the next item from the queue. You may also be able to use `Parallel` for this, depending on what the actual code looks like. In general I wouldn't advise messing with the thread pool config, if you run into those limits it's *usually* a sign that you're using the thread pool wrong/for the wrong things (though I'm sure there are exceptions).
I have not yet used Identity in Asp.Net Core 2. I hear there are some big underlying changes. Try issuing a POST request to /token. The body should be: username={username}&amp;password={password}&amp;grant_type=password You should get back a JSON object containing an authentication token, among other things. This token is a bearer token. With each request, send it using the Authorization header. Set this header to "Bearer {token}". I recommend testing this with Fiddler. Note: {} denotes variables.
Sorry for the informative reply just now. I meant, a lot of complicated things in traditional asp.net are much simplified. Have you done setting up dependency injections? In asp.net core, everything need to be configured for dependency injection in startup method, and you need to enable them to use most of the features. eg. app.UseMvc() UseStaticFiles() UseAuthentication(). Once the object are registered just put in controller constructor to use them.
I wonder when we will ever see the end of the "introduction to .net core" posts. It's been a couple of years now.
Alex.. The code really works.. Thanks atleast know i get the idea, so it means i'll just have to try to to understand your code and put it in a completely different way as we were told not to plagiarize. 
I did something like this years ago to help a friend make a short movie, and wound up going a different route. The goal was to show someone typing a story, without having to actually type it in real time. If you want a truly realistic effect, you could build a table of delay values with characters on each axis, a 2d array. First index is current character, second index is next character, value is the typical delay between the current and next character. Include punctuation. Make a quick program to seed that array by typing a bunch of paragraphs into it, and now you have a very realistic way to delay between letters. In your typing function, just lookup the delay between the current and next character and delay that amount. You can add a few milliseconds of random dither each time to make it less deterministic. It actually comes out looking very realistic, since it allows combinations like "we" a much shorter time than "gn". Not much extra work, either.
And praise Anders that we have them, because not every language does.
&gt; the TaskCreationOptions.LongRunning flag, which is a hint to the scheduler that this task will run for a long time so maybe it should dedicate a thread to it Which indeed it does (in the current and, AFAIK, all previous implementations). Using that flag, the task basically becomes `new Thread(...).Start()`.
This doesn’t have anything to do with winforms, by the way. 
Sounds like someone coming from JavaScript or Python. Most statically typed languages have value and reference types. Value types are literally just a pointer to memory on the stack that can be manipulated freely. C++ allows non-referenced objects (MyObject X; is a legal declaration in C++) which I think live on the stack as well, but don't quote me on that. Reference types are pointers to objects in memory. You get a pointer that lives on the stack instead of the object itself. It's faster for passing around and all that jazz. When you say MyObject X = new MyObject() you're creating an object on the heap and a pointer is returned. So when the processor runs X.MyField, it goes out to the heap, gets the memory location of MyField and returns the value there. Tl;dr:. Values live on the stack, references live on the heap. Edit: removed a pointless statement. 
Great explanation, I appreciate it! Yea python was my first language..
&gt; Start a number of worker threads independent of the number of work items, and have each thread repeatedly pick the next item from the queue. You may also be able to use `Parallel` for this, depending on what the actual code looks like. There's a few good ways to do it in .NET, [Threading in C#](http://www.albahari.com/threading/) may be good reading for OP in considering solutions. IMHO you could use a shared `ConcurrentQueue&lt;T&gt;` or similar to push items onto, and the worker threads could then go ahead and pull off in a loop. &gt; In general I wouldn't advise messing with the thread pool config, if you run into those limits it's usually a sign that you're using the thread pool wrong/for the wrong things (though I'm sure there are exceptions). I've been guilty of messing with thread pool settings. Typically, this has been code where there is a lot of 'bursty' use of the thread pool and response time is more important than other efficiencies. Things like PLINQ `.WithDegreeOfParallelism(n).ForAll(func)` for me are signs I should probably just hint to the thread pool that I'd like N threads ready to go.
Do you need to pull in some authentication middleware for it to handle the /token endpoint? Or is that what's added for you when you add in Identity? (I've recently inherited a project that uses the exact pattern and it has some authentication middleware registered in the AppStart, but points to a custom provider class that does the database querying to get the user details out the DB then compare them to what the user's passed in).
I believe it should work out of the box.
Just set delay exactly as you have but inside the loop. Or am I missing something? Edit: a word
Not KISS. The pauses between keys is far greater than the distance a finger needs to travel affects the typing pace. Don't forget to add random typos with backspaces.
Lul.
There will never be an end. Why would there be? All relevant languages and frameworks gets plenty of new tutorials covering the same topics over and over again because people like writing/talking about it. I wouldn't look at this as a bad thing. As a beginner it is very good to have several different resources that explain in the same thing in different ways. There are still a lot of people that haven't even looked at .NET Core yet. From what I've heard version 2.0 is what many of them have been waiting for.
Beyond being a value type, int is also a primitive value, different from other structs.
I'm working on my first solo angular 2+ project here, and after a lot of screwing around trying to figure out how to best organize an angular/.net api project, this is the approach I prefer as well. Besides any views or static pages you might be serving up, your angular stuff is going to go through several major transformations. With Node serving those files on demand during development, you simply don't need everything smushed into one visual studio project, especially the thousands of files that come with an angular project that aren't even necessary once you produce an AOT build. 
It's the same as shown in the [docs](https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity?tabs=visual-studio%2Caspnetcore2x) * You set up Identity and Cookie auth in ASP Core * You're then given SignInManager and UserManager classes, within the DI framework, and you create controller endpoints which handle sign in using those classes. * Finally to authenticate requests, you just add the `AuthorizeAttribute` to each controller class which you want to protect. There are some little changes you have to research around redirections. By default a failed request will be rewritten by MVC to return a redirect to the login page, but for an SPA that's not valid and needs changing to just return a 401.
Hey, opportunistic question as we're doing beginner stuff. Where is .NET Core at with config files? At launch it used its own format, then there was talk of migrating everything to .csproj compatible files and then talk of it being a hybrid. After that I lost touch. Thanks :)
There will always be beginners and beginner bloggers. I've dabbled in it since the earliest working code but don't use it for anything. All my work is old fashioned .net. So I'm sure they will be of interest to me eventually :)
Try Taking a look at identityserver 4. They have some really great examples of implementation and it's built for .net core 
So... You will need to take a look at the various Middleware that are available and find something that does what you'd like. JWT bearer is pretty standard for the token format but and cookies are still popular. You will need some Middleware that you can connect to your DB and define user tables, permissions, etc. We are using an IDP so it's a little different that what I'm familiar with, but you should be able to do some Google-fu and find what your are looking for with terms like "net core database authentication middleware" 
I find the exercise interesting. Finding the algorithm that produces the most realistic typing speed... sadly, it'll probably be more of a "try and retry" than a "think and make".
You can start [here](https://social.technet.microsoft.com/wiki/contents/articles/36804.asp-net-core-mvc-authentication-and-role-based-authorization-with-asp-net-core-identity.aspx) and [here](http://https://digitalmccullough.com/posts/aspnetcore-auth-system-demystified.html). User Veranova points you to the correct way. Mechanics for auth in ASP.NET and aspnetcore are diferent so don't loose your time trying to get work ASP.NET samples on aspnetcore.
Buddy of mine is using OpenIddict in his project. .Net Core Web API on the backend, React up front. https://github.com/openiddict Check out this writeup on how to implement a basic setup. http://kevinchalet.com/2017/01/30/implementing-simple-token-authentication-in-aspnet-core-with-openiddict/ Just ran through this guy's Pluralsight course on OAuth 2 and OpenId implemented with Identity Server 4, and his stuff has been great to learn how to get started with authorization and authentication.
No, you have to set this all up in .net core. In mvc 5, it was provided.
I don't think IS4 supports .net core 2.0 yet.
I think learning OOP is a very good idea. There are tons of books on the subject but I would recommend these 2: Uncle Bob's [Agile Principles, Patterns, and Practices in C#](https://www.amazon.com/Agile-Principles-Patterns-Practices-C/dp/0131857258/) This book will teach you not only about good OOP principles (SOLID principles) but a also a lot about other programming practices such as testing and refactoring. Sandy Metz's [Practical Object-Oriented Design in Ruby: An Agile Primer](https://www.amazon.com/Practical-Object-Oriented-Design-Ruby-Addison-Wesley/dp/0321721330) Don't worry about being a Ruby book, you should be able to understand the concepts (and learn some Ruby). Sandy ha a very good way of teaching how to think about OOP. Hope it helps. PS: I'm curious: what exactly did you struggle with? What made you think you should learn OOP?
*proj files. (csproj/fsproj/vbproj etc) They use an updated MSBuild format.
This what I did in a recent project. SigninManager coordinates your authentication middleware. You setup that middleware in your startup. I even wrote an authentication middleware by implementing a few methods. There are precious few articles right now around .NET core 2.0. I had to learn a lot about core 1.0 first, then I could better digest the 2.0 documentation, and the template projects.
Yup, it even replaces `packages.config` by having `&lt;PackageReference&gt;`s right in the *proj file instead.
Here's some ASP.NET Core 2.0 specific information, that includes JWT migration from 1.0: https://docs.microsoft.com/en-us/aspnet/core/migration/1x-to-2x/identity-2x So look at how it was done in ASP.NET Core, then make the changes above: https://blogs.msdn.microsoft.com/webdev/2017/04/06/jwt-validation-and-authorization-in-asp-net-core/ You should test, but I think all actions will be protected by default unless AllowAnonymousAttribute is used. It used to be you would use a JwtAuthenticationAttribute on actions, but I don't see this in any ASP.NET Core examples. The fact they are applying AllowAnonymous in some places tells me authentication is required by default if you follow their setup, so no attributes needed to protect methods. Of course test this. Edit: Would love to hear what key pieces you ended up with if you get it working. Obviously I've not tinkered with 2.0 yet.
Shouldn't really matter though since you can host IS separate from your project.
`new`, in this context, allocates storage for the new object and runs the appropriate initializer to create the object in the allocated space. Certain types have some built-in language support to allow them to be represented as constants--just numbers, strings, bools, and characters, really. `new`ing up an object does not necessarily allocate the value on the heap or stack, but value types (generally) live on the stack, and reference types (generally) live on the heap. Note that all variables have to be initialized before use, however, so the major difference is that declaration does not automatically initialize the variable.
That's also available in the older format
Yep that's what I'd did too! I read a bunch of 1.0 instructions and then checked the docs for those APIs to see the lists of breaking changes I needed to alter. MS have done a really great job of writing migration guides this time.
This video series on WPF is very good [WPF UI Programming (C#)](https://www.youtube.com/playlist?list=PLrW43fNmjaQVYF4zgsD0oL9Iv6u23PI6M) Goes from basics to advanced and gradually builds up a chat application while covering lots of different topics.
I've never used it myself but you could look into Microsoft Patterns and Practices. For example this link: https://msdn.microsoft.com/en-us/library/windows/apps/xx130643.aspx I would say though that it's a good idea to separate your learning of concepts and patterns (I.e. OO, MVC, etc) from learning language specific implementations.
Read up on application structure (classes, namespaces, assemblies etc) start small and gradually add more features keeping the structure nice and clean.
It matters when you are verifying the token on your api.
Subtitle Edit is written in C# and also some OCR (you can ignore it for now). It'll give you a good understanding of how a big project is structured and written https://github.com/SubtitleEdit/subtitleedit There are many more you can find on github, give it a try
Thanks :)
This YouTube playlist by Tim Corey should be pretty much exactly what you're looking for: http://www.youtube.com/playlist?list=PLLWMQd6PeGY3t63w-8MMIjIyYS7MsFcCi
Epplus, htmlAgilityPack
Without knowing what is driving you to learn, Pluralsight.com is a great tool but it's not free. Their video tutorials usually do a great job going end to end. But even then things like images, hosting (in the case of web applications), proper source control usage, etc. are separate videos. So I guess it depends on your definition of complete.
Pretty much all non-weird modern languages do. 
Take a look at closedXML. https://github.com/ClosedXML/ClosedXML It's a nice wrapper for openxml, it let's you create/modify Excel files.
"Random" is class, in C# whenever you want to work with classes you going to declare Constructor for that class, so in this case "new Random()" is declaring Constructor to object(to "rnd" in this case). Imagine Constructor working like this : If you want to build house you need foundation ( Foundation would be Random rnd), After making foundation you going to build whole house ( new Random() ). Tried to make it simpleish as i can!
In my opinion, it's the best library to do this. Super easy to use
 string xml = File.ReadAllText(FSEA.FullPath); int xindex = 0; IEnumerable&lt;string&gt; opens = xml.Split('&gt;'); var TagLayout = from forme in opens where forme != string.Empty select new { start = forme.Split(' ')[0].Replace("\r\n", "").Replace("\t", ""), close = forme.Split(' ')[0].Replace("\r\n", "").Replace("\t", "").Replace("&lt;", "&lt;/") + "&gt;" }; var TagInfo = from feature in TagLayout let iclose = xml.IndexOf(feature.close,xindex) let istart = xml.IndexOf(feature.start,xindex) let xlen = iclose &lt; istart ? -1 : istart &gt; 0 ? iclose - istart : -1 let index = xlen &gt; 0 &amp;&amp; xlen &lt; 1000 ? xindex += xlen : xindex += 0 let xstr = xlen != -1 ? xml.Substring(istart, iclose - istart) : "" where iclose != -1 &amp; xstr != string.Empty &amp; xlen &lt; 200 &amp;&amp; xlen &gt; 0 select new { Start = istart, Value = xstr, TotalLen = xlen + feature.close.Length }; foreach (var x in TagInfo) { Console.WriteLine(x); } Updated
Thanks for the book recommendation. I notice Stephen Cleary appears very frequently on stack overflow, responding to threading questions and he seems to know his stuff.
I know what you are saying but you (and most others) are (understandably) making an incorrect assumption. I'm not interested in having the overall program finish as quickly as possible. Whats more important is that each thread starts at approximately the same time, and gets an approximately equal amount of CPU time. I understand that context switching etc will cause the overall program to be slower but I dont care about that.
You're right. And I knew that too. I think I messed up when I simplified my code to post it here. The real code does some expensive math, not console.writeline() or sleep()
From the output, I can see that numbers 1, 2, 3, 4 are printed many times before I see a 5. To me that seems like there are 4 threads running for a while before the 5th one fires up. Is this reasoning incorrect? 
Could be correct, or it could be that others aren't scheduled (but I admit, that is unbelievably improbable). What about the main thread? Point being: you expect there to be as many threads as there are CPUs, but there's a main thread, too. So shouldn't the pool do 3+1? Also, for all we know, it's possible that all threads are running on one CPU, or whatever. I am trying to say no more than: the only "correct" way to reason about this is to read the implementation sources.
I have been writing a book aimed at people with some programming knowledge who want to learn C# by programming a project, namely an implementation of chess. The book is unfinished, but complete enough to take you through implementing a console version of chess. If you're interested, I'd be happy to comp you a copy in exchange for some brief thoughts and feedback. Link: https://leanpub.com/checkmate-csharp/
If you are doing a small app for a phone, web, or even a full 3D game the unity3D website has a lot of good tutorials (unity uses c#). https://unity3d.com/ For general program design and organization (not C# specific) this book is basically required reading: https://en.m.wikipedia.org/wiki/Design_Patterns
Been waiting for a thread like this. Thanks.
Agree. Just used it on a project. 
I'll 2nd pluralsight they show a lot of modern dumbed down examples of how code should be organized and separated in a more professional environment. also they offer a subset free if you can get a dreamspark account.
The one I personally use is NPOI. It's a port of a Java library, but it works quite well both for .xls and .xlsx .
ASP.NET Core is what you're looking for.
Wow, you need to do some serious reading...
No, ASP.NET Core can not run on Mono. But it can run on .NET Core, which runs on many Linux platforms.
Core is used in-place of Mono. You will use the .NET Core runtime rather than the Mono runtime. Also, ASP is very old and is different from ASP.NET. We do not use ASP these days. It sounds to me that you are not familiar with these technologies. ASP.NET Core projects are typically hosted on Kestrel behind IIS, but you can host them on Linux. 
Google it....
Not exactly. Asp.net core can run on any .net standard 1.5+ compliant platform. .Net Core is the main .net standard, but not the only one. Mono, Xamarin, and .Net Framework are all .net standard compliant, but their compatibility depends on their version. You can find the full compatability list [here](https://docs.microsoft.com/en-us/dotnet/standard/net-standard).
I can write my website once and next I can host that same code on linux or windows. Doesn't get more cross platform than that. It isn't Xamarin where you still need to do some platform specific programming. Net core is the continuation of what Mono set out to do. Creating a project to run in Mono right now is, imho, creating a legacy project.
https://imgur.com/DD3STvD
Mono and .Net Core won't merge. Mono is a legacy platform. Moving to .NET Core will bring large performance improvements and compatibility with the latest features.
Create a list from the enum values, then move every selected item into the players list.
Enum isn't the right way to store cards I think. Why not a list of card objects? When a card is randomly selected it is removed from the list and added to the users hand etc.
What do you mean by duplicates? Duplicates in the UI? Or the same card being selected multiple times? If you want to have each card selected only once, you should keep all cards in the deck in a collection (or array) and remove a random card every time (similar to dealing IRL). Or create a shuffle method and store the cards in a stack. 
So on button click the same values cannot appear in another textbox :)
Probably best. I have taken this route and it's come back to haunt me I think! Thank-you for the suggestion Versk!
I agree. An enumeration for the suit would be fine but the cards should just be numbered 1-13 (or 0-12). public struct Card { public SuitType Suit; public int Value; } public enum SuitType { Hearts = 0, // etc... }
Ahhh good idea PunchFu - I'll try implementing this now. Thank-you for the comment
Why don't you just remove the card from the deck after dealing it?
Okay. The **last** major version can run on Mono, the **current** major version will be able to run on a future version of Mono (5.4).
That sounds like a brilliant idea, only, I don't know how this could be done with distinct types. Thanks for the suggestion HeySeussCristo 
I'm currently reading C# and .Net Core: Modern Cross-Platform Development - it's really good! 
I wouldn't think so. C# runs in the server, text overflow is a browser problem, impacted by things like user font size, scaling, installed fonts etc. You would need the browser to report to the server about overflow, and this is back to Javascript again. Think about the behaviour you want when overflow occurs, and see if there are css/Javascript solutions that run in the user's browser. 
Record types seem like yet more syntax for such little gain; or is it just me?
This is a client side issue. The server should have no part in it. Use a client-side language such as JavaScript to accomplish this. That said, I'm not sure what exactly you're trying to achieve. Perhaps don't let it overflow in the first place?
Non nullable types are great in Kotlin and Swift, I'm excited to see them in C#.
I’ve used EPPlus for years, great package. 
Here's a significantly less scary example, since you seem new to programming: public class SimpleDealer { private readonly ICollection&lt;Card&gt; _availableCards; private readonly Random _random; public SimpleDealer() { _availableCards = CreateCards(); _random = new Random(); } public Card DealCard() { // Should check if any cards exist. I didn't write that part in this example. var cardIndex = _random.Next(0, _availableCards.Count); var card = _availableCards.ElementAt(cardIndex); _availableCards.Remove(card); return card; } private ICollection&lt;Card&gt; CreateCards() { var cards = new List&lt;Card&gt;(); for (int i = 1; i &lt;= 13; i++) { cards.Add(new Card(SuitType.Hearts, i)); cards.Add(new Card(SuitType.Clubs, i)); cards.Add(new Card(SuitType.Diamonds, i)); cards.Add(new Card(SuitType.Spades, i)); } return cards; } } public struct Card { public readonly SuitType Suit; public readonly int Value; public Card(SuitType suit, int value) { Suit = suit; Value = value; } public string DisplayValue() { // TODO Handle Ace, K, Q, J return $"{Suit.ToString()} {Value}"; } } public enum SuitType { Hearts = 0, Clubs = 1, Diamonds = 2, Spades = 3 }
Record types will make it much easier and more succinct to create immutable types, with compiler-generated "With" methods, equality. etc.
Really hyped about interfaces being able to provide a default implementation, should cut down on copy-paste code in certain scenarios where implementing classes don’t share a common parent.
So that's a WinForms control that is rendered via GDI. I believe you can just include that cs file in your project and it will be displayed as a control in the toolbox. https://docs.microsoft.com/en-us/dotnet/framework/winforms/controls/developing-custom-windows-forms-controls Maybey you should read this first.
Net standard 2.0 was *literally* finalized the same day as the latest Mono version release (Aug. 14), so there was no way they could include it. That was also only a little over a month ago, meaning very few projects are using 2.0 yet. Most .net standard libraries are still written for 1.3-1.6, including the entirety of Asp.net. Calling the next planned release of Mono a "future version" is a little disingenuous to say the least. You make it sound like Mono is way behind in support for net standard and aren't planning on supporting it for a long time.
In the mean time you can use extension methods of course!
What's with the Java style open braces { } on the same line? Is using C# style braces that wasteful of vertical space?
Can’t override those of course. 
Hey. This pattern is something I have come across at work, although the implementation we have at work is slightly different as it leverages other code infrastructure we are using. However I tried my best to keep my description quite neutral. Since I did not see a description of this pattern anywhere online, I thought I'd write a small blog post about it and see what others gave to say about it :)
Device apps (phone, tablet etc) , desktop apps, facebook bots, console/headless apps, there are a lot of things that aren't on the web. (yes, I know, those things CAN have browser support)
Thanks, definitely feel like I'm on the right track after that
This is the feature I'm most interested in in this release.
&gt; Whats more important is that each thread starts at approximately the same time, and gets an approximately equal amount of CPU time. So it is intriguing to me that you care when the threads start, but not when they finish. That's why i was suggesting you think about what you really want from the program. I can certainly imagine a situation where having all of them start, and waste a lot of time on context switches might be valuable - like a brute force search where one solution will be almost instantly found to be correct, and the others will only slowly be shown to be incorrect. As soon as you find the "correct" option, you can abort and ignore all other threads. However, the important thing I was suggesting you think about is knowing how long each process takes, and what you want to do with the results. Think statistically. Once your thread count vastly exceeds the number of cores, the percentage of time you waste on context switches can (and will) actually dwarf the amount of time you spend running your own code. It's entirely possible to get the CPU doing almost nothing but switching, and get no progress on your tasks at all. Therefore if it's really important *all* tasks start at the same time your best bet is to add cores - AWS and Azure sell them by the bundle.
C# can be, and is, used to develop all sorts of apps. Phone/mobile, industry, business, any sorts. The software I develop is an Enterprise-grade application that formulates food for cows. C# works brilliantly for just about everything. Edit: spaces.
Sure you can so long as you understand the pattern. For example, the `.Count` extension method can be overridden by implementing the `ICollection&lt;T&gt;` interface.
&gt; with compiler-generated "With" methods, equality. etc. That's the real winner. Immutable classes by themselves are easy to write, but tedious when you start adding that kind of feature.
Although I know the majority of the C# world uses braces-on-newlines, I personally prefer Java style. I feel it connects a function's scope to its definition better and yeah, lets you fit more on 1 screen. Not gonna get super worked up about it though.
I agree. I didn't realise this was also part of the feature; I like it more now. Resharper already takes away a lot of the pain for equality etc but I still find myself writing "With" functions a lot.
Correct me if I'm wrong but you'll only get the overidden behaviour when using a variable of the derived type using this pattern, correct? I.e. if you pass your variable as an IEnumerable somewhere it'll drop back to the extension method. It's basically just name hiding, not true polymorphism...
Correct me if I'm wrong but record types don't seem to be on [their roadmap](https://github.com/dotnet/roslyn/blob/master/docs/Language%20Feature%20Status.md) at all. 
Putting braces on the same line is [objectively wrong](https://vimeo.com/97329157).
Spreadsheetlight
What about Azure careers? Are they necessarily using C# or is that more general .NET knowledge?
That's not what objective means, it's just an argument for new line bracing. I personally prefer seeing more code on my screen over a momentary improvement to at-a-glance structural clarity, especially when we have syntax highlighting anyway. Like I said before, not worth getting too worked up over as both styles get used and both have valid arguments. Same as tabs/spaces.
Can someone elaborate what a 'with' method is?
BackgroundWorker isn't really appropriate... the only way I can think to do it would be using Thread.Sleep inside a loop (in the DoWork) so you can sort of clumsily use the BackgroundWorker as a timer. You should have a play and see what methods on BackgroundWorker can be used for your purposes... I.e. ReportProgress might be suitable for changing the image and Cancel might let you stop it.
https://www.dotnetperls.com/backgroundworker The background worker has methods that you can assign to do work and what to do when the work finishes. I'm in Mobile, so forgive the formatting. Var bw = new... Bw.DoWork += method to do work Bw.OnCompleted += UpdateUi Be.Start() If you pres tabtab on the plus equals, visual studio will create a method with the right signature for you. Edit. Not sure why he wants a background worker for this. If you use a media element, you can set the payback speed. I'd start with that.
Hahahahaha, I was going to link him to the same exact presentation. Kevlin (what the hell kind of name is that?) is awesome!
Resharper generates them for you, but it doesn't keep them up to date, this is substantially better.
It's a pity it's only a warning. Though I understand it, for legacy code. Hopefully, over time, they'll be able to transition it to an error. Everyone just ignores warnings. 
Implementing warning as error has fixed that for us. On new projects only and fixing old stuff as we go though, so yeah.
Also a good point!
We did that. The dev's complained that we were slowing them down. Management agreed. SIGH. 
Yeah I am not too sure either, he doesn't make sense most of the time so I am completely confused on this. Everything that I have seen and read shows that this wouldn't be the best option for this type of project. Thank you for the advice, the more I have stared at this over the weekend, the worse my irritation has gotten lol. 
Enumerable.Count() contains this code: ICollection collection = source as ICollection; if (collection != null) return collection.Count;
tabs/spaces Who still uses tabs!? 
Very basic concepts that you can find in a interview question review for c#. I'm really bad at concepts. Most of the time I just google and piece together code to achieve my goals. I'm trying to improve and learn the fundamentals. That's for the recommendations. I will definitely check them out.
Thank you so much. I dont know why he wants a bgw either but hes very specific on that and very harsh on grading. Which makes things more frustrating when he doesn't give any kind of direction or discussion on the topic. Its going to be a long semester lol 
Well true, Count is a bad example specifically. But in general, it's still true I believe.
`var thing2 = thing1 with { SomeProperty = value };`
Is the assignment in written form? While obviously we don't want to do it for you, maybe if you can post the exact requirements someone here can make sense of it.
Composition helps. Also abstract base classes which, in practice, default implementation for interfaces is. In a way C# is getting multiple inheritance, something present in certain other languages since the dawn of time. IOW... it's existing and minor stuff, one has to be young or otherwise not aware of what is going on to be "really hyped".
It's automatic generation of operator== and I hope IsEqual, which isn't necessarily trivial nd is a PITA.
Doesn't change anything. Let people do it their way. 😀
Record types are very situational, but it's a situation that a lot if C# developers find themselves in. You have to write and maintain a huge amount of boilerplate code to generate and maintain those things so syntactic sugar here is really great.
I have an IDE extension that shrinks the size of lines containing only curly brackets. It saves space while maintaining the structural clarity you mention.
&gt;Everyone just ignores warnings. [citation needed]
Don't forget that you should override GetHashCode if you're overriding .Equals and == I'm pretty sure the record types handle this too.
Warnings as warnings in Debug builds, Warnings as errors in Release build. Facilitate merge requests and CI.
"Default Interface Implementations". This seems like it could produce a lot of potential for the same headaches that would have come with multiple class inheritance. =(
They are right. Warnings as errors is a huge annoyance when developing. Comment our an assignment to test something? ERROR UNUSED FIELD. Stuff like that. 
The following are some alternatives, I ordered them by their "difficulty": - The native .NET Framework solution by using System.IO.Packaging (or some other zipper/unzipper) and System.Xml. The XLSX files are just zipped XML and non-XML files and you can manipulate with them as such, for example see: https://www.codeproject.com/Articles/208075/How-to-read-and-write-xlsx-Excel-file-Part-I https://www.codeproject.com/Articles/15593/Read-and-write-Open-XML-files-MS-Office - Using Microsoft's OpenXML SDK, this is in essence the first solution + a strongly typed classes. Note that both this and the first one do require some knowledge of the XLSX format itself: https://msdn.microsoft.com/en-us/library/office/cc861607.aspx - Using GemBox.Spreadsheet library, it provides content model classes that abstract the spreadsheet format: https://www.gemboxsoftware.com/spreadsheet/examples/c-sharp-vb-net-excel-library/601 Note that this one has a Free and a Pro version, but for your task you would need just the free one, for example see how to update an invoice: https://www.gemboxsoftware.com/spreadsheet/examples/excel-template-use/403
True, but abstract classes, like all other cases of inheritance, are limited to a single parent, as you correctly imply. Getting excited about reducing redundancy can hardly qualify one as being “young or otherwise not aware”. Calling default implementation a type of multi-parent inheritance however, is to overlook all but the most simple cases, which would imply the speaker is new to OOD/OOP.
Those are Java style? I thought that was default C style.
I hope they add default auto-property values as well
The [OTB](https://en.wikipedia.org/wiki/Indent_style#Variant:_1TBS_.28OTBS.29) style what I use and have for over 20 years (back to my C pup days). I find the other way quite wasteful and visually annoying. If you swap a lot between C# and JavaScript it's actually better since newline braces are a problem in JavaScript. It's a ~~source of religious wars~~ matter of personal taste, however.
What is the problem exactly? BTW, many of your usings are not necessary (i think of Threading, Linq and Generics)
Go devs
 This is the constructor You don't need to explain language features to your readers. Talk about your custom logic in your comments, not how C# works. Also put your code in a github Gist - it is easier to read that way. Also your post is really low effort, which is why it's being downvoted. Put yourself in the shoes of someone who might help you - are you being considerate and making it easy for them?
int.TryParse is safer than Convert.ToInt32
Try this c# 6.0Nd the. NET framework, Andrew Troelsen and Philip Japikse
Hi Makte, There are a lot of things that you can do with C#. I would suggest that you can start learning about WebApi and look into how to use angular as frontend (any frontend technology will do) and WebApi as backend. You can find tutorials at: https://www.asp.net/web-api and here's a tutorial to start creating your first webapi: https://docs.microsoft.com/en-us/aspnet/web-api/overview/getting-started-with-aspnet-web-api/tutorial-your-first-web-api If you want to do C# tutorials you can easily find on Microsoft's Channel9 website: https://channel9.msdn.com/Search?term=c%23#ch9Search&amp;lang-en=en&amp;pubDate=year There are some videos showing the latest features of C# and even on how to create bots using Microsoft's Bot Framework in C#: https://mva.microsoft.com/en-US/training-courses/17590?term=c%23 You can also checkout Xamarin to start doing C# applications for Android and iOS, there are tutorials on MVA (Microsoft's Virtual Academy): https://mva.microsoft.com/en-us/training-courses/xamarin-for-absolute-beginners-16182?l=fPHWqptJC_5705846048 Goodluck for your C# future! :)
I don't see what the default interface implementation can achieve, that can't be achieved with one of single/multiple inheritance, without a presence of the concept of interfaces, care to give an example?
I'm thinking about that from the moment I read that they are thinking about including that. I'm scared.
Yep, and in a better way than one can do in 3min :-), e.g. by composing hashes. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3980.html
You’re misunderstanding. Default interface implementations means that interfaces can now provide a default way of implementing a given interface method. It does not add any functionality, but if you for example have four implementors of an interface, three of which implement it identically, you can now place this code as the default implementation, rather than have it be copy-pasted in three of the four implementing classes, which reduces code redundancy, thereby increasing code readability and reducing the chance of forgetting to change one of the implementations, if all three are to be changed.
Removed: Rule 4. Please include a clear question/request, include only the relevant portions of code, and make sure your code is properly formatted for display on Reddit.
Yeah this is best of both worlds.
You can do that already like: int A {get;set;} = 5
I'm sorry, but the title is misleading. These are "Proposed C# 8 Features"
Cleanup using statements. If it's not needed, less wasted lines are more useful lines. It helps us clearly read the meaningful content, without distraction. Namespaces should be top-level groupings and system ideas. Such as, geometry would be a math concept that has several smaller concepts that belong to it. Like Cubes, Pramids, and Cylinders. Shapes have Surface Areas, Volume, coordinates, color, density, etc... A good NS encapsulates these ideas, so it's clear what belongs inside of it. It's not a general convention to see a name with "_new" in it. Namespaces usually do Pascal case, like... Namespace MathLibrary Class names are usually representing the objects name. Similar to a noun, like cube, shape, math... it should try to be specific enough that simply reading 'new cube' allows any developer to have a good idea of what it will/should be doing in the code. Comments should try to help developers, future maintainers by making effective notes about it's conceptual design, purpose, or problems. Anything that can't be easily grasped by simply reading the code briefly. Otherwise, it's like re-reading the same thing in different words. But, it can be useful for learning, and understanding personal projects, tutorials, and advanced code samples. Use good judgement, and most won't mind. You have a typo in the summary comment. Breadth is written as breath. Also think this fails to add value for programmers reading this. CalculateArea gets confusing with face abcd, efgh. We only have 3 values to our cuboid, where does this alphabet come from and why was it needed? The final return math was just 2 (L*W + W*H + H*L). There's no abcdefgh necessary... just 6 squares, representing each side possible. Variable name cuboidObj works, but in an OOP language it's not helping anyone to call it an object. It's just a cube. I wouldn't suggest long method names, if you can avoid them. Instead of CalculateArea... getArea is less verbose. WriteLine can be formatted a few ways. Concatenation is common early on, but error prone. Double check your spaces, such as WL ("Volume is" + volume + "."); Would say "Volume is100. Neglecting a vital space before our number. WriteLine("Volume is {0}.", Volume); Allows us to see most of the string, without all the syntax breaking up our intended point. Alternatively, WriteLine ($"Volume is {volume}."); is even clearer.
Default interface implementation would streamline or automate most of the patterns for delegating those details to a composed class or extension method. It may also provide binary compatability for updating interfaces with new methods (with default implementations) without having to update the code that consumes/implements the bulk of the interface type.
I meant in interfaces. The syntax you mentioned is not currently allowed in interfaces. Anyway it looks like they will add what I want
IME "correct" and "Use `Scan()`" are mutually exclusive (and that's ignoring the superlative use of "the correct way" when you should use "a way") Instead I find it more manageable to use direct references and to call `AddRegistry` for each registry. This usually manifests in a triangular architecture like: A / \ B --&gt; C Where project `A` houses the configuration(s) and bootstrap for my system/app and nothing else, `B` my domain stuff, and `C` the implementation of a specific infrastructure thing (e.g. database or other I/O). `C` will reference `B` in order to implement the interfaces `B` needs fulfilling. e.g. `B` could have: public interface IRepositoryOfThings { // snip ... } public class SomeDomainThing { private IRepositoryOfThings repo; public SomeDomainThing(IRepositoryOfThings repo) { this.repo = repo; } // snip ... } and `C` then has something that implements that like: public class EntityFrameworkRepositoryOfThings : B.IRepositoryOfThings { // snip ... } public class EntityFrameworkRegistry : StructureMap.Registry { public EntityFrameworkRegistry() { For&lt;B.IRepositoryOfThings&gt;().Use&lt;EntityFrameworkRepositoryOfThings&gt;(); } } so `A` can configure with: public static class ConfigureIoC { public static void ConfigureSystem(this IContainer container) { // snip ... container.Configure(cfg =&gt; cfg.AddRegistry&lt;C.EntityFrameworkRegistry&gt;()); // snip ... } } (FQNs used for illustration purposes, normally I would use `using` statements). This way my domain (project `B`) contains zero knowledge of my choice of infrastructure (project `C`) and my bootstrap project (`A`) has the responsibility of putting the pieces of the puzzle together (and nothing else!)
Years of experience has taught me that the majority of developers ignores warnings or suppresses them. Last time I turned on warnings as errors, the next developer turned it off.
Might as well make the ranks an Enum too; Rank.Jack is clearer than 11
So basically Electron but probably worse
You can look at Xamarin to start building C# applications for Android and iOS, there are tutorials on MVA (Microsoft's Virtual Academy): https://mva.microsoft.com/en-us/training-courses/xamarin-for-absolute-beginners-16182?l=fPHWqptJC_5705846048
It shows up on their [milestone](https://github.com/dotnet/csharplang/milestone/8), but I don't know if that's all the stuff that's proposed, or what.
The issue is multiple iterations of the `IEnumerable&lt;T&gt;`, causing the multiple calls to `InitializeChildViewModel` (which apparently does some DI stuff). Don't iterate multiple times. To expand, these lines are the problematic ones: var childrenViewModels = model .Select(InitializeChildViewModel) .OrderByDescending(x =&gt; x); if (childrenViewModels.Any()) { observableCollection = new ObservableCollection&lt;ChildViewModel&gt;(childrenViewModels); } `IEnumerable&lt;T&gt;` is has something called deferred execution. That means the `InitializeChildViewModel` is not immediately called, it will be called when iterating the enumeration. When he now calls `childrenViewModels.Any()` it will start iterating the enumerable and call the `InitializeChildViewModel` method. Then, after the `Any()` call, he passes the enumerable to the `ObservableCollection&lt;T&gt;` constructor, **which will again iterate the enumeration**, causing the `InitializeChildViewModel` to be called **again**. A simple solution: Add a `.ToList()`, to enumerate the `IEnumerable&lt;T&gt;` directly and get a `List&lt;T&gt;` out of it, which can safely be enumerate multiple times.
Resharper finds these for you a lot of the time. Usually there's no side effect to multiple iterations (because you're just applying a value or something), but then there's this case... 
How is it a bad example? You can do that with any extension method you create. 
Moments convenience for huge PITA in near future. Management material there.
Easily fixed with a Debug-NoWarnings build mode.
I wonder if you change "childrenViewModels.Any()" to "childrenViewModels.Count() &gt; 0" if it would fix the issue. The Any gets the enumerator. The count should already know if there are any in the collection.
No, it will not change anything. `Count()` needs to get the enumerator and iterate the enumeration too. There are some optimizations in the implementation of `Count()` that you probably mean. If the actual type is a collection, then it will cast and access the `Count` property instead of iterating the enumeration. But since he's using `.Select(..).OrderByDescending(..)` he does not has a collection yet.
Creating .xlsx files using raw XML? I'd rather poke a stick in my eye. 
I would say that the JVM pushed the CLR forward for performance and C# pushed Java forward for language features. I don't think C# has taken much from Java as a language since .NET Framework 3.0 came out.
C# has taken a lot of stdlib stuff from Java, but little language features.
C#'s original conceptual notion of classes, inheritance, interfaces, memory safety, automatic memory handling, exception handling (outside of checked exceptions) generics, namespacing, and many other language features were almost directly lifted from Java, though the implementation details often differed (e.g. GC and generics runtime). It wasn't until .NET Framework 3.0 that we saw a clear break away from a Java lineage.
Yes, of course. I mean, in modern C# they copy more of Java's new libraries than of Java's new language functions.
Eh, yes, that exact same thing is achieved with a base class and multiple inheritance (e.g. in C++). That's something C# doesn't have, but there's languages that do. That's why I wrote "In a way C# is getting multiple inheritance..."
Personally, I go with a MVVM type architecture. Use your models to populate a ViewModel that the controller gives to the view. Here's a general overview: https://stackoverflow.com/a/3742950
If it isn't already referenced, you need to add a reference to the assembly that contains System.Data.SqlClient - which is System.Data.dll.
How would I do that? I've tried all normal avenues for adding the reference, and it doesn't list System.Data.dll as an option to include (in fact, it allows me to add nothing, and lists nothing as being available to reference)
Sounds to me like he wants the background worker to do the animation while the main thread modifies the logic of the animator to allow for speedup/slowdown etc. You'll need to create a backgroundworker, Implement the background workers "DoWork" delegate then use some state variables to communicate between the worker and the main UI. Implement the background workers DoWork, WorkCompleted, and ReportProgress delegates. 
I guess they're doing it for compatibility with Java (Xamarin)
Shouldn't you be passing the subreddit object as a parameter to your Upload method?
Which tab are you looking at in the Reference Manager? It may have defaulted to "Recent", which could indeed be blank if you haven't recently referenced any assemblies. In that case, expand the "Assemblies" tab and choose "Framework" to see the standard .NET Framework assemblies, including System.Data.
Probably is both...
I probably should've included this in my original post, but does it matter if I'm using Asp.net Core? It was using .Net 4.6. Right now, I'm trying to repair the installation again. This is baffling me, as everything I've read or tried online points to this should be working.
You need to post your full code and explain yourself better. I think your problem is scope and you want use the contents of your Subreddit class in your Upload method but I can't tell that for sure. If that's the case you could have another argument after clip of type Subreddit (i.e. Upload(Config.Clip clip, Subreddit subreddit) If you just want to have a completely different variable of the same name you need to declare it in Upload. var subreddit = new string[]; Although it looks like you want to assign the contents of subreddit to the Tags property of video.Snippets class. Which would mean that Tags is of type Subreddit which doesn't really make sense.
It does depend on the scale of the solution as to how to tackle an MVC site. For Landing, I'd simply use the HomeController for this. I personally would have a Model per View to ensure that the data you retrieve from the database is only the data you need and nothing more. Sometimes the mistake is made where Data Access is too generic and data is filtered in memory rather than in the data access - and this can lead to performance issues in the long run. I'm not going to tell you how you structure your application in detail as it is your school project and it should challenge how you think, but I'd suggest you base your controllers on what you want them to do. If you are interacting with your application in a specific way, ie. Venues and you can interact with venues in multiple ways (add, delete, etc), then to me you would have a VenueController. This can help with routing and the way your url looks to the end user, however routing can also be handled in any way you want it to be handled in the RouteConfig. Edit: it may also be worth mentioning that EF is very handy in web applications. You can extend your solution beyond MVC in to a three tier architecture to separate data access from the view with business logic being performed in between.
It may in fact matter. Take a look at the solution from this similar question: https://stackoverflow.com/questions/35444487/how-to-use-sqlclient-in-asp-net-core
I mean I can’t tell without all of the code but it isn’t immediately obvious in your code that the subreddit variable exists in the context of your upload task. Are you trying to invoke the task inline? It still wouldn’t have context for the subreddit variable in that case. 
i got it guys, all i had to do is pass subredditname to uploadclips and then to upload as string subredditname thx for the help
The power of .ToList(). It's essential to understand what it does, when to use it, and what kind of object you're working with before calling it.
i understand why im having this problem (I think) , but not how to solve it. the var "subreddit" doesnt exist down in the upload part when i want to use it for the tags. all i want to do is reuse that. adding something like: global string subreddit1 = subreddit up top where subreddit does exist, so i can call subreddit1 later would work, but i cant figure out how to set a string that can be called from anywhere the Subreddit class thing actually goes and checks if that subreddit exists, but i dont really care about that, all i want to do is take the word stored in the subreddit var and then insert it as a tag later
more general. Unfortunately that information is easy to come by and only needed occasionally. for example, setting up a web server and sql server happens once per project and takes a few minutes. occasionally i may bump up the power of a server or something, but nothing that qualifies as full time. I am not sure how many companies need that kind of constant monitoring. If you are wondering what career is most lucrative, go for coding. There is an increasing need in an already strained market. (translation: cha-chiiing)
warning: many people are learning that xamarin is great for the standard stuff, but for complex issues you probably want to develop native apps (swift for ios, java for android)
Easiest way would be to pass subreddit to your UploadClips method then pass subreddit to Upload, not the cleanest way but it will work. You can refactor later on if you want.
Should learn type systems instead. It uncouples inheritance hierachies and allows structures to be controlled by what they do then what they are. Lisp or golang
it doesnt (i think) and thats the problem... how do i get a previously defined var "out" so i can use it before the it changes with the next foreach loop? if i could add a line right below where subreddit is defined that does something like this: set public string subreddit2 = subreddit or set global string subreddit2 = subreddit so i can call subreddit2 from anywhere, that would solve my problem, im sure there are better ways, but thats the simplest way i can think of, but i cant get the syntax right to do something like that
Saved the day... I feel like an idiot for not figuring that out on my own, but thank you for that link!!
But you have subreddit as type Subreddit, does this class only have one property? You can declare a private variable just under your class declaration and the scope would be the whole class but I find it bad practice to do this. I think it's better to pass that value to the methods that need it. Class level variables are better left to error logging and database objects. Basically things you need throughout your class for different purposes.
im pretty new to c#, how exactly do i do this? i really dont care if its not clean, it just has to work, but i really need someone to spell it out for me step by step, cause im having trouble with even the basics
MVC vs MVVM is a confusing topic that is probably too nuanced to be helpful for someone learning MVC. I actually disagree with that stack overflow answer... the next highest ranked answer is better IMO. MVVM does away with a controller and instead uses a VM to handle events between the view and model (see [wikipedia](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93viewmodel)). Mapping models to view models (models just used for presenting) but still using views and controllers is just an ideal implementation of MVC.
No worries, I wouldn't have realized that myself.
You should almost never use global variables. I maintain about 2 million lines of code across about 50 projects, and I still have yet to use a single global, mutable variable. Pass it as a parameter.
sry im pretty new to c#, how exactly do i pass subreddit to upload? and how exactly do i then use the passed subreddit to insert it as string? thanks for your help
You have a class, each class has members and methods. Some members are static (shared between all instances) and some are instance (only applies to a specific instance of the class). //Declare a class. You can't access any of this //b/c none of it is static, but it's a template for what will //be available if you have a reference public class Foo{ int SomeInt; public Foo(int i) { SomeInt=i; } } //Create a storage location that will contain a "pointer" to the classes instance data //f will be null because there is no instance data to point to Foo f; //Create a new instance of the Foo object and record it's location in the variable f f=new Foo(3); //Create a second instance of the Foo object and records It's location in the variable foo2 var foo2=new Foo(5); //Write the value of the SomeInt variable associated with instance of Foo stored at the location //pointed to by the reference to the Foo class stored in the variable f Console.Writeline(f.SomeInt);
maybe? probably? im new to c# how exactly do i pass subreddit to my upload method and then insert it as a string?
the problem im having i that i dont know how to do either. both will work fine, this is a simple program that wont change much, but im having a hard time actually implementing this change either way... this all sounds great, but if nobody gives me some code examples i probably will struggle to implement it myself 
 foreach (var subredditname in mSettings.subredditList) here it sets subredditname to the exact string i want to later insert as a tag. how do i pass subredditname or subreddit or just that simple string to the upload part later in my code, specifcally this line: video.Snippet.Tags = subredditname; from what i understand here i probably have to modify this part to pass it: private async Task Upload(Config.Clip clip) but what exactly do i have add there to get that string into upload?
What are you using to render the images?
You're on the right track! You'll want the following controllers: StateController, CityController, VenueController, EventController, and HomeController. Here's where I think you're getting confused: Data for an event can be used in any controller that it's needed in. For instance, your home/index needs to get the top 5 events -- you don't need to call the event CONTROLLER, you need to call the events context (or however you're getting event data). The home controller will have a view model that contains a collection of events, cities, states, and venues. You'll need to fill that model with the top 5 events, cities, states, and venues from the database. For the events pages, /events/index should just return a collection of all the events. When you click on an individual event, call /events/details/{id}. That action will get the model from the DB by ID and return just that single object to the view. That's the high level architecture, at least. If you want something more comprehensive, check out this [tutorial for EF and MVC](https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/getting-started-with-ef-using-mvc/creating-an-entity-framework-data-model-for-an-asp-net-mvc-application). Good luck! Edit to remove an example of code so OP has to figure that part out :p 
Change the method signatures to: private void UploadClips(List&lt;Config.Clip&gt; clips, Subreddit subreddit) private async Task Upload(Config.Clip clip, Subreddit subreddit) Then change the calling/invoking of those methods to pass `subreddit` through: UploadClips(clipQueue, subreddit); Upload(clip, subreddit).Wait();
expose a parameter in your method, called "string subreddit" then, when you call your method, pass in both the clip and the subreddit string. I think something you are misunderstanding about c# is [Block Scoping](https://stackoverflow.com/questions/2693138/variable-scope-in-statement-blocks). When you see `{}` curly braces, you should be aware that you are entering a new scope, and depending on that scope, 'local variables' used in other scopes may not be visible to that new scope. [There are a number of scopes.](https://msdn.microsoft.com/en-us/library/ms973875.aspx) You have the Public scope, Private, Internal, (protected...) and local scopes. Having a good understanding of these scopes will help you understand what you can and cant' do with your design patterns. The error your compiler was giving you was telling you that the subreddit variable wasn't in scope to your local Upload method. You can fix that by passing in the parameter (as suggested). This makes the parameter local to the method's block scope. You could also expose the Subreddit to the public, internal, or private scopes, which would allow you to retrieve the value publically, internally, or privately, too. (Passing it in as a param is probably best, since you're within a loop). 
To pass an argument you first have to modify the method to accept it. So the first step is to modify you UploadClips and Upload method to allow a Subreddit to be passed in: private void UploadClips(List&lt;Config.Clip&gt; clips, Subreddit subreddit) and private async Task Upload(Config.Clip clip, Subreddit subreddit) Next step is to change the line of code calling those methods to pass in the new argument: UploadClips(clipQueue, subreddit); and Upload(clip, subreddit).Wait(); Now your Upload method has access to the subreddit object. I didn't see this class in your code so hopefully it contains the string you need in Upload. Make sense? 
Actually quite nice. Responsive and easy to add features, but all the fun quirks that is CSS. Utilizing a lot of graphs and dynamic data, it seemed (and still does) like a decent choice. Install size is of course a bit higher, but that's acceptable.
You’ve had a couple of good answers suggesting a model specifically for the home controller, containing collections of the top 5 pieces of data from each of the business domains. Here’s the opposing view: you could use partial views to allow for re-use. The State controller, for example, could have an action called TopFiveStates, which would generate the relevant model, and pass it to an appropriate partial view. Then, the Home/Index view could invoke each of the partial views it needs. The advantage of this is that you can then use the same partial views in other places. Are these partial views likely to ever be needed in other places? I don’t know. But that will answer the question of whether to use this method. If they’re likely to be reused, this is the way to go. If reuse is unlikely, then the model specifically for the Home page is easier.
It's possible there's a difference in formatting after the decimal. Some location devices return degree minutes and seconds, and other formats prefer decimal degrees. Confusingly, some devices will return degree minutes and seconds as decimals, so you really need to check what format any given data is intended to be interpreted as. http://www.rapidtables.com/convert/number/degrees-to-degrees-minutes-seconds.htm
I almost got it now... but im not sure if Subreddit subreddit contains what i need: right now with your changes im getting this error: Der Typ "RedditSharp.Things.Subreddit" kann nicht implizit in "System.Collections.Generic.IList&lt;string&gt;" konvertiert werden. Es ist bereits eine explizite Konvertierung vorhanden (möglicherweise fehlt eine Umwandlung). which translates to: the type "RedditSharp.Things.Subreddit" can not be implicitly? converted to "System.Collections.Generic.IList&lt;string&gt;". There is already an explicit conversion present (perhaps a conversion is missing) what exactly does that mean and how can i fix it... in the main worker of the prog first this happens /// &lt;summary&gt; /// Main worker /// &lt;/summary&gt; private void MBackgroundWork_DoWork(object sender, DoWorkEventArgs e) { while (!mBackgroundWork.CancellationPending) { List&lt;Config.Clip&gt; clipQueue = new List&lt;Config.Clip&gt;(); foreach (var subredditname in mSettings.subredditList) { Subreddit subreddit = TryGetSubreddit(subredditname); if (subreddit == null) continue; it uses the settings list and the Subreddit function to set the current subreddit and check if it exists heres the Subreddit function part of the code /// &lt;summary&gt; /// Try to get subreddit by name /// &lt;/summary&gt; /// &lt;param name="name"&gt;Name of subreddit&lt;/param&gt; /// &lt;returns&gt;Returns null if failed, else Subreddit&lt;/returns&gt; private Subreddit TryGetSubreddit(string name) { Subreddit subreddit = null; for (int i = 0; i &lt; 5; i++) { try { /*Try to get the sub-reddit which we will retreive posts from*/ subreddit = mReddit.GetSubreddit(name); if (subreddit != null) break; } catch (Exception ex) { mLogError.Write(Log.LogLevel.Error, $"Error getting /r/{name}\n{ex.Message}"); Thread.Sleep(5000); } } return subreddit; } and then heres the final upload code: UploadClips(clipQueue, subreddit); SaveAllCheckedPosts(); And /// &lt;summary&gt; /// Uploads a video to youtube /// &lt;/summary&gt; /// &lt;param name="clip"&gt;Clip class containing file information&lt;/param&gt; /// &lt;returns&gt;Returns task&lt;/returns&gt; private async Task Upload(Config.Clip clip, Subreddit subreddit) { var video = new Video(); video.Snippet = new VideoSnippet(); video.Snippet.Title = clip.post.Title; video.Snippet.Tags = subreddit; is it possible to use subredditname from the main worker as the tag during the upload? cause i want the tags to sync up with the main worker 
You can compose in C# fine: public struct HashCode { private readonly int _hashCode; [MethodImpl(MethodImplOptions.AggressiveInlining)] public HashCode(int hashCode) { _hashCode = hashCode; } public static HashCode Start { [MethodImpl(MethodImplOptions.AggressiveInlining)] get; } = new HashCode(486187739); [MethodImpl(MethodImplOptions.AggressiveInlining)] public static implicit operator int(HashCode hashCode) =&gt; hashCode._hashCode; [MethodImpl(MethodImplOptions.AggressiveInlining)] public HashCode Hash(object obj) { var h = obj?.GetHashCode() ?? 0; unchecked { h = (_hashCode ^ h) * 16777619; } return new HashCode(h); } [MethodImpl(MethodImplOptions.AggressiveInlining)] public HashCode Hash&lt;T&gt;(T obj) where T : struct { var h = obj.GetHashCode(); unchecked { h = (_hashCode ^ h) * 16777619; } return new HashCode(h); } [MethodImpl(MethodImplOptions.AggressiveInlining)] public override int GetHashCode() =&gt; _hashCode; } using it is as simple as: public override int GetHashCode() =&gt; HashCode.Start.Hash(_field1).Hash(_field2).Hash(_field3);
im almost got it, but now im getting cant convert to string errors. how can i expose the subredditname var from the main worker to be used by the upload function thanks for the links btw
&gt; in the main worker of the prog first this happens &gt; &gt; &gt; &gt; /// &lt;summary&gt; &gt; &gt; /// Main worker &gt; &gt; /// &lt;/summary&gt; &gt; &gt; private void MBackgroundWork_DoWork(object sender, DoWorkEventArgs e) &gt; &gt; { &gt; &gt; while (!mBackgroundWork.CancellationPending) &gt; &gt; { &gt; &gt; List&lt;Config.Clip&gt; clipQueue = new List&lt;Config.Clip&gt;(); &gt; &gt; foreach (var subredditname in mSettings.subredditList) &gt; &gt; { &gt; &gt; Subreddit subreddit = TryGetSubreddit(subredditname); &gt; &gt; &gt; &gt; if (subreddit == null) &gt; &gt; continue; &gt; &gt; &gt; &gt; it uses the settings list and the Subreddit function to set the current subreddit and check if it exists &gt; &gt; &gt; &gt; heres the Subreddit function part of the code &gt; &gt; &gt; &gt; /// &lt;summary&gt; &gt; &gt; /// Try to get subreddit by name &gt; &gt; /// &lt;/summary&gt; &gt; &gt; /// &lt;param name="name"&gt;Name of subreddit&lt;/param&gt; &gt; &gt; /// &lt;returns&gt;Returns null if failed, else Subreddit&lt;/returns&gt; &gt; &gt; private Subreddit TryGetSubreddit(string name) &gt; &gt; { &gt; &gt; Subreddit subreddit = null; &gt; &gt; for (int i = 0; i &lt; 5; i++) &gt; &gt; { &gt; &gt; try &gt; &gt; { &gt; &gt; /*Try to get the sub-reddit which we will retreive posts from*/ &gt; &gt; subreddit = mReddit.GetSubreddit(name); &gt; &gt; if (subreddit != null) &gt; &gt; break; &gt; &gt; } &gt; &gt; catch (Exception ex) &gt; &gt; { &gt; &gt; mLogError.Write(Log.LogLevel.Error, $"Error getting /r/{name}\n{ex.Message}"); &gt; &gt; Thread.Sleep(5000); &gt; &gt; } &gt; &gt; } &gt; &gt; &gt; &gt; return subreddit; &gt; &gt; } &gt; &gt; &gt; &gt; and then heres the final upload code: &gt; &gt; &gt; &gt; UploadClips(clipQueue, subreddit); &gt; &gt; SaveAllCheckedPosts(); &gt; &gt; &gt; &gt; And &gt; &gt; &gt; &gt; /// &lt;summary&gt; &gt; &gt; /// Uploads a video to youtube &gt; &gt; /// &lt;/summary&gt; &gt; &gt; /// &lt;param name="clip"&gt;Clip class containing file information&lt;/param&gt; &gt; &gt; /// &lt;returns&gt;Returns task&lt;/returns&gt; &gt; &gt; private async Task Upload(Config.Clip clip, Subreddit subreddit) &gt; &gt; { &gt; &gt; &gt; &gt; var video = new Video(); &gt; &gt; video.Snippet = new VideoSnippet(); &gt; &gt; video.Snippet.Title = clip.post.Title; &gt; &gt; &gt; &gt; video.Snippet.Tags = new string[] { subreddit }; &gt; &gt; &gt; &gt; is it possible to use subredditname from the main worker as the tag during the upload? cause i want the tags to sync up with the main worker 
First, lets examine the relevant parts of your code. In MBackgroundWork_DoWork(), you build a temporary list of `Config.Clip` objects called `clipQueue`. Once you have that queue filled, you call `UploadClips(clipQueue)`. In turn, `UploadClips()` iterates over each clip in your list of clips, and calls `Upload(clip)`. `Upload()` is where you want to inject the subreddit as a tag. private void MBackgroundWork_DoWork(object sender, DoWorkEventArgs e) { // ... while (!mBackgroundWork.CancellationPending) { // ... List&lt;Config.Clip&gt; clipQueue = new List&lt;Config.Clip&gt;(); foreach (var subredditname in mSettings.subredditList) { // ... foreach (var post in posts) { // ... clipQueue.Add(new Config.Clip() { post = post, clipUrl = regMatch.Value }); // ... } // ... UploadClips(clipQueue); SaveAllCheckedPosts(); } } } private void UploadClips(List&lt;Config.Clip&gt; clips) { // ... foreach (var clip in clips) { // ... Upload(clip).Wait(); } } private async Task Upload(Config.Clip clip) { // ... video.Snippet.Tags = subreddit; // does not compile because `subreddit` isn't a variable here. // ... } Now that we've got a good overview of the important parts of your code, it's easy to see that `UploadClips()` is called once per subreddit, which means we can just modify its parameters to take in the subreddit: private void MBackgroundWork_DoWork(object sender, DoWorkEventArgs e) { // ... while (!mBackgroundWork.CancellationPending) { // ... List&lt;Config.Clip&gt; clipQueue = new List&lt;Config.Clip&gt;(); foreach (var subredditname in mSettings.subredditList) { // ... foreach (var post in posts) { // ... clipQueue.Add(new Config.Clip() { post = post, clipUrl = regMatch.Value }); // ... } // ... UploadClips(clipQueue, subredditname); SaveAllCheckedPosts(); } } } private void UploadClips(List&lt;Config.Clip&gt; clips, string subreddit) { // ... foreach (var clip in clips) { // ... Upload(clip, subreddit).Wait(); } } private async Task Upload(Config.Clip clip, string subreddit) { // ... video.Snippet.Tags = subreddit; // ... } Viola, problem solved.
I'm assuming Subreddit is a class you created. The Tags property on video.Snippets must be of type IList&lt;string&gt; or a type that implements IList. So when you assign a property it must be the same type. subreddit is of type Subreddit which is not the same as IList. What does you Subreddit class look like? Does it have a collection of strings are a property? If so you'd have to do something like: video.Snippet.Tags = subreddit.Tags (assuming Tags is a list of strings)
Count is actually worse - .Any() can stop after just one result because it knows. Count has to go through every single item in the enumerable to count them before it can do the comparison. 
that's a type error from the compiler. It's telling you that the type of the thing you are trying to pass into your method doesn't match what your method parameter expects: a string. What type is the thing you are trying to use? Is your 'Subreddit' not a string? is it a complex type? Then maybe there's a property on the type, like subreddit.Url, and that's what you should be passing into the method. 
Well maybe it's just my bias because CSS is a nightmare to me compared to WPF/Avalonia or even WinForms. But you've got a point right there.
Rule of the thumb: A variable defined in a pair out curley brackets {} (if, for, methods, classes,...) will stay in them. So just define it outside of it. 
it works! thanks. i actually managed to do it with just subredditname how i wanted by passing just that to uploadclips and then from going from there with string subredditname. works like a charm 
On Azure you can use much more things than a web server or sql server. You can check about: - IOTHub which stores IOT device registrations - Logic Apps which are used to connect different services to each other - Function Apps where you can create API methods directly on Azure - Service Fabric to use microservices - Event Hub to process messages and alerts raised by other service And much more :) 
Thank you so much for your reply. This definitely gave me a clearer view on how to organize the project. I haven't used EF yet, but I might just also put it on my to-do list. Thank you for the suggestion!
Thank you for going into further detail! This really helped a lot. I will check out the tutorial, seems to be what I am looking for.
That is what I was thinking about and how to go about it. Thank you for the explanation! That makes a lot more sense to me now!
Thank you for the link/suggestion. I haven't heard about using MVVM in ASP.NET MVC, so I will check it out. (Also thank you /u/DevyMcDevface for your thoughts on this)
Which is better for "instantiating" IEnumerables? ToList() or ToArray()? I use ToArray() because arrays are (I think) more lightweight, but I could be mistaken...
In visual studios, you can create a new user control. This creates a new class which inherites from UserControl. Without any further implementation the base usercontrol acts similiar to a "Panel" control. Developers can override the OnPaint method utilized by the usercontrol. By overriding the OnPaint menthod you are able to obtain a graphics object from the control and execute arbitrary Graphics commands (Draw points/lines/circles/etc). You can create a custom winform control that draws in anyway you want using this method. In this case, the developer has created a custom control and based at least some of the rendering on the value of a property "Speed". Once the control is defined, you can drag and drop your custom control onto winforms and manipulate it very much like you could any other winforms control (Textbox, label, etc.) 
A couple methods First method: Put each distinct enum value into list one time. Randomize the list and sequentially pull cards out of the list from top to bottom. Second method: As each card is pulled add it to a list of "Pulled" cards. When a card is pulled check that it does not already exist in the pulled cards list... if it does, pick a new card.
closedxml 
Not in the above example as they are not looking for a particular item with the Any. See the fiddle I created: https://dotnetfiddle.net/DP3UoB 
 Pretty sure if you curse more you'll get to your answer
As others have said, this is a client-side problem. The only way to do this via server side would be to post-back to the server after every keypress, and that's clearly a pretty silly proposition. So, you need to define clearly what you mean by "overflow". Most text entry mechanisms will allow you to put a size limit on them as a basic property. But that may not help you with a visual overflow problem, and that's a much trickier beast to solve... does your control use a browser or user defined font? If so you'll need to account for things very dynamically such as checking for whether or not the control is currently scrollable? Or you could force a mono-spaced font, and just know how many characters fit, and then via an on-keypress type event, ignore any key presses (that aren't backspace or delete, etc) if the current text size is at the limit. But frankly, you just want to use a control that lets you set the max input size.
Your example isn't using Any and Count from IEnumerable, you're using the ones on List. https://github.com/Microsoft/referencesource/blob/master/System.Core/System/Linq/Enumerable.cs#L1191 has the source code for the Count() extension method for IEnumerable&lt;T&gt; It has special cases for ICollection (which List also implements) to speed up processing of Count but purely IEnumerable has to iterate - shown in line 1198. 
While `List&lt;T&gt;` is (for most purposes minimally) less performant than arrays, `ToList()` is often faster than `ToArray()`. The reason for this is that `ToArray()` needs to allocate an array fitting the exact number of items in the `IEnumerable`. If the number of items is not known before enumerating (e.g. `Where(...).ToArray()`), it usually needs to perform an additional allocation+copy from a temporary buffer to the final array. `ToList()` doesn't have this problem because the `Count` property of the list can be smaller the underlying storage array, so it doesn't have to do that final copy (but might waste some memory).
Generally, yes. In this particular case it's less relevant, because for the `OrderBy` he needs to completely iterate anyway.
Moving the OrderBy to inside the if solves that problem. ```if (childrenViewModels.Any()) observableCollection = new ObservableCollection&lt;ChildViewModel&gt;(childrenViewModels.OrderByDescending(x =&gt; x))``` It's also worth noting that .Any() expresses the intent much better which allows further optimizations inside IQueryable implementations.
This is almost exactly it. I talked to some other students today and we were able to get a bit more clarification from him! Now to just figure out how to do this LOL. I have office hours with him again in the morning but unsure if that will help at all. 
Would a link to the requirement, like on google drive be ok? Ive had to back everything up on there because my harddrive is going so its there :D 
Thank-you very much for the suggestion HeySeussCristo - as it happens I am a developer and have been writing in C# for about 2-3 years - sometimes I can get hung up on simple things like this though. Thanks again for clearing this up
Or spice it up with some LINQ sugar! void Main() { var tasks = Enumerable.Range(1, 20).Select(async (int i) =&gt; { while (true) { Console.Write($"{i} "); await Task.Delay(100); } }); Task.WaitAll(tasks.ToArray()); Console.WriteLine(); } 
Background workers can be utilized in informed like a contrl... you can drag and drop them into a form then use the properties-&gt;events tab to associate an event handler to the appropriate fields. Alternatively you can treat it as a normal variable and declare it in your form.cs file and in the load event use the events += syntax to attach your handler... Backgroundworker wkr=new backgroundworker Wkr.dowork+= new iforgetthetype (myeventhandler) Wkr.reportsstatus=true Wkr.reportstatus+= new iforgetthetype (myreprtstatushanfler) . . . Wkr.start () You can just press tab twice after the += to auto generate both the remaining line of code and a default implementation of the handler... Sry for formatting should have waited for computer but I was bored on phone. As far as "state" variables... they are just normal variables that both threads have access to but you as a developer choose to utilize only for describing the workthread state. They would be scoped to the form most likely. F1 = https://msdn.microsoft.com/en-us/library/system.componentmodel.backgroundworker(v=vs.110).aspx
&gt; I personally prefer seeing more code on my screen over a momentary improvement to at-a-glance structural clarity Get a better monitor.
No problem. Only said the new to programming part because I had originally responded with some code that used factories and interfaces to create decks, dealers, etc. Which seemed a bit like overkill. Wasn't trying to be pretentious. Good luck.
This is a great explanation, thank you! Yall have been amazing, I was quite nervous about asking any questions because, well, Reddit LOL. 
Understand the [fundamental principles of OOP](http://www.introprogramming.info/english-intro-csharp-book/read-online/chapter-20-object-oriented-programming-principles/#_Toc362296565) and why they're important. I ask interviewers to describe each of the four, but I don't necessarily put much weight in whether they can recite the concepts from memory, as much as I want to see if they demonstrate them in practice. But if they CAN describe them, it's a good sign. There's a natural progression for how people learn to write programs: * Write an exe with a Main method that's big and complicated and does all the things you need. * Write a class within your app that has big complicated methods that do all the things you need, and call that class from your Main. * Write a class within your app that has small, easily understandable, easily testable methods called in combination to form layers of functionality, which can be called from your main. * Write a library outside of your app, which can be referenced and used from your app, web applications, power-shell modules, or wherever. There's a perfectly good place for each of those types in software and understanding the appropriate level of design necessary for the scale of the problem you're attempting to solve is something I try to look for in an interview. 
Because the pattern you're describing requires essentially replacing the vtable with a bunch of type checks in the extension method. Not only is it impractical, it's often impossible as you can't know every possible derived type that may override your behaviour from within the extension method. `Count`'s implementation is more of a performance improvement to be honest, as both the linq version and the ICollection version are expected to return the same result, it's just that more derived specializations can provide better performance than simply iterating until the end is reached.
Don't be stupid. My monitor is 1440p btw, and I have two of them.
Turn them vertical.
I don't want to. Either way it's irrelevant: It's my personal preference- I'm not the one saying one way is *objectively* wrong. ;)
&gt; Not only is it impractical, it's often impossible as you can't know every possible derived type that may override your behaviour from within the extension method. WTF are you talking about? You only need to know one type, the interface that matches the extension method. If you extension method is `.GoJumpInALate` just create a matching interface `ILakeJumper`. This isn't a hard pattern to understand. 
Separate your concerns of "Showing" the bets and "Ordering" the bets: public static List&lt;Bet&gt; OrderBetsByDate(List&lt;Bet&gt; bets) { return bets.OrderBy(bet =&gt; bet.Date).ToList(); } This becomes a fairly easy method to test. Toss a bunch of unordered bets in, assert that they're in order. (Also toss in a bunch of pre-ordered bets and ensure they maintain their order!) Then make a method that formats a bet for printing: public static string GetBetStringOutput(Bet bet) { return @$"Course: {bet.Course} Date: {bet.Date} Amount: {bet.Amount} Was it a win?: {bet.Won} "; } I removed the anonymous type since it was pretty superfluous. Also tweaked the output string for better readability (but feel free to revert any of these tweaks if you needed them included for the assignment.) This also becomes an easy method for you to test: toss a bet in, assert that it matches your pre-formatted string. Then the full program/output can stand on its own: public static void ShowInOrderOfDate(List&lt;Bet&gt; bets) { var orderedBets = OrderBetsByDate(bets); if (orderedBets.Any()) { Console.WriteLine("The bets in order are: "); foreach (var bet in orderedBets) Console.WriteLine(GetBetStringOutput(bet)); } else { Console.WriteLine("You haven't submitted any bets to be analyzed!"); } } If you like, you can take it a step further and abstract the output lines indicating if there are bets or no bets, but I'm not sure it that's useful. For example, you can create your own wrapper class/method around `Console.WriteLine` and assert that all the lines were written to the console that you expected. Or you can make a small wrapper class that contains all the lines/messages intended to be outputted. If this is sufficient, then great. If you need to add tests _even for this_, maybe try making those wrappers I mentioned and give it a shot.
This is brilliant, thank you so so so so much! You're a superstar! I'm feeling a little dim now as it was pointless creating anonymous types for this. For instances when I do need anonymous types (eg. I've a few group by and sums in my the rest of the method), what should I do then? 
One of the major goals of .NET Core was to slim down the .NET install size, so they moved a lot of components previously shipped as part of .NET out to NuGet packages.
Here is some free advice. Go do your own homework.
If it's within a method, and you just need some temporary grouping of properties, then they're useful. Once you feel like you have to pass around the anonymous type to other methods or as part of the `return`, then you'll need to consider promoting the anonymous type to a full blown `class` instead.
There is an xml serialization attribute that allows you to collect all the "left over" xml tag attributes. https://msdn.microsoft.com/en-us/library/system.xml.serialization.xmlattributes.xmlanyelements(v=vs.110).aspx
Jesus h, how did I not know about flagging threads? Baller.
Removed: Rule 1, Rule 4.
MSMQ fits the bill with those requirements, you can set it for durable messages. RabbitMQ is probably more popular and has features that MSMQ doesn’t, like in-order message delivery - and is fully supported for .net HTH
It's best to add breakpoints and step through the code line-by-line. Brute forcing things usually isn't the best strategy. 
Not sure if I'll need in-order messages, but it's good to hear it's an option.
+1 for RabbitMQ. It's cross-platform as well. I've been toying with for a few years, and I've always found it fairly straightforward (this after coming from Service Broker, which is anything but).
Yeah it was just an example. RabbitMQ also has clustering that’s easy to set up so if one fails it has the message on another node. Fault tolerance and scalability is always my #1 requirement and MSMQ doesn’t exactly handle that well.
Of course, C# is a programming language after all. My point is: people don't know how to compose hashing and will do silly stuff, e.g. xor parts like MSDN does. And to be frank, your solution is not very advanced either :-). 
OP sounds like an aussie (source: am aussie &amp; curse more than OP)
If this is a .net core application you’ll see these issues. In order to provide a light weight framework all the fluff has been removed. In order to get this reference you’ll need to use nuget package manager and add the correct reference. 
Thanks mate! I'm at the fourth progression at this point. Definitely gonna sit down and read that link.
Ok. First, +1 for FizixMan, for getting rid of anonymous type. It doesn't help. Also for separating the ordering concern. My approach would be this: I would try to remove the direct usage of Console.Writeline. Abstracting it into a collaborator class (named ConsoleWriter, maybe?) and extract that into its own interface, then inject that dependency via constructor (DI). The point of unit testing (at least, the point for me), is to assert the behaviour of the System Under Test (ShowInOrderOfDate). The hard part is that since this method is void, you cannot "check its results". Not directly, at least. But, if writing into console was a dependency, you could mock it and check the arguments of the different calls. There are lots of arguments here, of course, and lots of ways to test. However, A void method with no dependencies, it's jolly hard to unit test. Well it has a dependency, the Console. But that's not injected. So how are you checking what is being written there?
Tweq is correct. But most of the time it doesn't matter. When it does matter, profile your code to figure out what's best for your situation.
I also recommend RabbitMQ. It scales crazily well or works great even for small setups with say one pc/server using it. Supports dead letter, routing, exchanges, pun sub, topics, timeouts, clustering. All that is optional and configurable. I've used it in a high load enterprise type scenario and I've used it installed on my raspberry pi for the hub of a home made IOT type setup. It runs on everything pretty much.
Yes, obviously you can compose, C# is a programming language after all :-). Still, I believe that the above is definitely not something to be done in 3 min (or perhaps it is if you already know this particular hash), and isn't the best hashing ever either. To be honest, my gripe is with the bloody MSDN... when GetHashCode pops up, does an xor, which is God damn awful, it's the kind of thing the professor tells the students not to do when teaching hashing :-).
Disgusting spam. You need to "Complete an offer below to continue." to even download. And this does not look very legal.
What is your goal? If you just want to see use up cpu cycles while the service is running, there's [tons](https://blogs.msdn.microsoft.com/vijaysk/2012/10/26/tools-to-simulate-cpu-memory-disk-load/) of tools out there to spin cycles. If you want to make one yourself (not a trivial task), use SpinWaits instead of thread sleeps. It's a pain. Use a tool. If you want to load test a service, you need to create a load test client to load test it. Send test requests that are like what you would expect in production. Then look at response times or the test client experiencing problems. The absolute number of threads on the service doesn't matter too much, if the thread count is stable and response times are acceptable. You should really read the threading chapter in CLR via C#. 
Removed: Spam.
Agree, another option could be [Rebus](https://github.com/rebus-org/Rebus) as a layer above MSMQ/RabbitMQ.
Does it have rate limiting? Now I'm being asked to not saturate our network connection .
You could try this: https://github.com/Fody/PropertyChanged It adds property changed calls at compile time if your class implements IObservable.
Not bad. I wonder if I could implement something similar with attributes?
If you are not using AsNoTracking your context's ChangeTracker.Entries() give you access to EntityState in DbEntityEntry's State property. myCtx.ChangeTracker.Entries().Where(e =&gt; e.State == EntityState.Modified);
You could try implementing your own in a class that would keep track of the state of the individual values of each record, and then possibly another class that would track the record as a whole. See example of the individual value class. You would also follow this sort of pattern for the record as a whole, possibly with a List&lt;ValueItem&gt; and the IsDirty property would be Items.Any(item =&gt; item.IsDirty)). abstract class ValueItem&lt;T&gt; : Prism.Mvvm.BindableBase { T _value; protected ValueItem(T value) { _value = value; CommitValue = value; } protected T CommitValue { get; set; } public T Value { get { return _value; } set { if (SetProperty(ref _value, value)) { OnPropertyChanged(nameof(IsDirty)); } } } public virtual bool IsDirty { get { return Comparable.NullCompare(Value, CommitValue) != 0 || !(Value?.Equals(CommitValue) ?? false) } } public virtual void Commit() { CommitValue = Value; } }
I use Anchor to add change tracking to my models. https://docevaad.github.io/Anchor/ChangeTracking.htm Using it, your properties look like this: public int HitPoints { get { return Get&lt;int&gt;(); } set { Set(value); } } A little tedious compared to straight properties, but overall not too bad. https://docevaad.github.io/Anchor/PropertyChangeNotification.htm https://docevaad.github.io/Anchor/ChangeTracking.htm 
You, sir, may be the winner.
Ah, nevermind. We're pulling the entity out into a list, MAYBE doing some changes, then handing it back to the context to save it. We need to track the changes before handing it back.
If you are putting entites into a list without using AsNoTracking they are still being tracked by the ChangeTracker. Calling SaveChanges will save any modified object. Objects in the list are the same references as the ChangeTracker objects.
Ah, so they continue to be tracked by EF, and it basically "auto-ignores" any "updates" to unchanged objects? Basically, am I looking for an efficiency that is unnecessary?
Probably. Efficiency comes from AsNoTracking, usually, but that opens up another can of worms. When you ask for an object from EF the ChangeTracker adds a reference. If you ask for the same object again, EF will check the ChangeTracker first and give you that object reference instead of going back to the database.
Gotcha. Thanks!
[EF Core will ONLY save modified/added entities](https://github.com/aspnet/EntityFrameworkCore/blob/dev/src/EFCore/ChangeTracking/Internal/StateManager.cs#L793). I imagine EF 6 does this too. You shouldn't have to do this.
Backpedaling a little here: this is true within the context using body. Are you using this list after using(myCtx) ?
Ah, no. :/ 
Apparently this only applies within the same using block. We preload our objects, and a different class/context entirely does the saves.
How many messages are you talking about here? I think you'd need in the millions per second before you saturate a pipe...
Then you're good.
Sorry, I meant no, we're not within the same using statement. We "preload" all of the data we may modify into a list, maybe, maybe don't do some modification to it, and send it to another class to transactionally batch our changes with others. We currently track an "EntitiesCreated / EntitiesUpdated / EntitiesDeleted" list, and append our objects to those as we muck with them, but there's a possibility that those in the "updated" list may have been "updated" to the same value they previously had. That's the optimization I'm trying to figure out.
Good stuff, though the gifs drive me crazy while trying to read the text!
Then you should be using AsNoTracking during the "preload" to avoid unnecessary caching.
Good to know, thanks!
As for checking if something has hasn't really changed by changing to original value - is this for your own logic's sake or EF optimization? Would it really bring much optimization? Because it sounds to me like you're trying to solve a problem EF has already solved via ChangeTracker as the DbEntityEntry has a OriginalValues property. By going disconnected you should assume the object is changed either way and explicitly save the ones you have in your updated list, even if they contain original values.
Strictly for the sake of optimization. Our database gets hammered, and I'm trying to clean up old codebase and find out where changes can be made. (For instance, preloading the entities in batches instead of allowing event processors to hit for each event saw a massive savings.)
Can't you call attach to reattach them? Or does this brake the change tracking Edit: it does brake the change tracking never mind
Is there an actual need to be disconnected (ie working outside the using block)? There are many reasons to do so, so it's not like that's wrong, but if you actually don't have to it would help you a lot. Any event trying to get an object would just go straight to the ChangeTracker and get the reference without going to the database.
Like others have said, you didn't instantiate the `Random` object in the second example -- instead, you created a placeholder variable. Doing this should illustrate the concept: Random r; //pretty much the same thing as Random r = null; var result = -1; if (GetRandomNumber) { r = new Random(); result = rnd.Next(1, 100); } return result; //returns -1 if GetRandomNumber is false. Two placeholder variables are declared. There are many reasons to declare placeholders, but you generally only declare placeholders if you need it to exist across scopes. Like this: public int GetRandomNumber(int? seed) { Random r = null; if (seed.HasValue) { r = new Random(seed.Value); } else { r = new Random(); } return r.Next(1, 100); //doesn't care how Random was instantiated, only that it was instantiated }
Yeah, the existing code base has multiple processors, all of which hand off everything they're doing to one giant transaction tracker. This allows us to do "batches" of transactions in... well, a transaction. So the "gets" and "sets" are quite separated.
Can't you maintain the db context until you are done with it? It's not designed to work like this unfortunately. Could you keep a list of the ones you changed? e.g. add them to a List when you modify them then just attach as modified, not pretty though. Edit: or you could implement property notify and create a ChangeTracker class that subscribes to the event and stores a list of the senders.
I don't know yet. One of the things I may be doing is chopping up large files into a series of messages so that if the connection drops I don't have to restart from the beginning. It's ship to shore for the Navy so the network pipe isn't going to be particularly large. We're possibly talking 90's era dial-up modem speeds on the bad days.
You're certain this transaction class isn't what is causing the hammer on your database? Each time any object is queried in any way it *always* goes to the database, even when you already have the object in memory. It's the downside of disconnected EF which should really only be used if the data is actually sent somewhere else, like web clients. If this is a local CRUD application you'd be better off letting the context share its lifetime with the transaction class. It's a common mistake: just like people create repository classes everywhere without realizing each DbSet *is* a repository, a transaction class is created even though the DbContext *is* a transaction class. If the transaction class isn't wrapping the context(s), it should. If the transaction class has knowledge of the context(s), stop preloading and get rid of the using block on context(s) and implement IDisposable on the transaction class instead, where you dispose your contexts. Or if the transaction class has knowledge of each DbSet in the context(s), create a Repository&lt;TEntity&gt; wrapper class, where the repository has knowledge of the context and shares its lifetime.
So you are loading all your objects in one EF context. Manipulating them. Then saving them in a different EF context?
I believe this is accurate. EntityType listOfEntities; using (var context = new MehContext) { listOfEntities = context.Foo.Where(blah).ToList(); } * Do stuffs. * Hand changes back to another context to save into DB. 
It's very much a separate distributed system. The "changes" get handed off to a bus, the bus hands them off to a handler, etc. before they get written to a database.
I agree the msdn documentation should remove the xor example (as should the shift and wrap method). The only ones that should be there IMO are the basic int one and Tuple one: public override int GetHashCode() { return Tuple.Create(x, y).GetHashCode(); } Which could be made better by using ValueTuple on the elements to prevent an allocation: public override int GetHashCode() { return ValueTuple.Create(x, y).GetHashCode(); } Which I would expect can be done in 3 minutes and works rather well for hashing things. If for some reason you need something more ideal than the built in or than the FNV algorithm I posted above (and messed up copying from memory instead of from the source code where it has sat for years) you could use a crypto algorithm like so: public class HashCode { public static int Create(params int[] values) { var bytearray = new byte[values.Length * sizeof(int)]; var bytes = bytearray.Length; Buffer.BlockCopy(values, 0, bytearray, 0, bytes); var result = HashAlgorithm.Create(nameof(HashAlgorithmName.SHA1)) .ComputeHash(bytearray); // cutting the sha hash here is fine (no additional value would be // obtained by xoring the whole result together) return BitConverter.ToInt32(result, 0); } } But that is significantly more expensive (and thus a bad idea for the purpose of GetHashCode in .NET)...
The changes get handed off, but until then the context might as well be alive, with access to the ChangeTracker. By sent somewhere else I meant the instant the entity is retrieved.
If this happens in one execution context. Is there a reason you can't maintain the same DbContext?
It might be overkill for your project but change tracking is one of the features of the CSLA framework, including supporting change tracking in disconnected n-tier environments (where the EF change tracker would not work at all). http://cslanet.com/
I know some of the guys at work use ZMQ, but they use it for Delphi (that project is supported in like 10-15 different languages it seems) and they seem really happy with it's performance. Wish they had an embedded version for what my coworker and I are working on.
You could use the [Memento](http://www.dofactory.com/net/memento-design-pattern) pattern.
Oh, I see. That makes a lot more sense, then. A few concerns that come to mind are: do you know how you'd be rebuilding the files on the receiving side? that's ordinarily not a use for messaging, as far as I'm aware (but I'd be curious to see/research the use case). It'd be worth checking the max / suggested message size for rabbit and other brokers. If you need ordered delivery, AFAIK rabbit doesn't support this but other products like kafka do. Hope it helps.
You could use Fody or PostSharp to do it with attributes - you could use dynamic proxies of entities to add change tracking, that might all work. Ultimately, it's probably not a great thing to be doing - it's a concurrency nightmare - much rather have your cached object, and at the point of manipulation, refetch and modify in the scope of a single context / operation, and update your out of date cached version.
+1 for code weaving. I believe PostSharp also has a solution for this as well
Is it necessary to keep this structure? Usually, you make your changes to the object, then hand it back to the same context to save it. If this is a web application, you really should be using a "context per request" type of approach. Most dependency injection containers offer this functionality. Even if this isn't a web app (meaning the whole "context per request" thing doesn't exist) I would look into using some sort of DI (ex: Unity) to help you manage the scope of your context.
Just linking to Microsoft's reference source browser in case anyone wants to poke around further. [Enumerable.cs - Line 1191](https://referencesource.microsoft.com/#System.Core/System/Linq/Enumerable.cs,1191)
Do you really need anonymous types for the groups? Dictionary&lt;DateTime, List&lt;Bet&gt;&gt; groupedBets = bets.GroupBy(b =&gt; b.Date).ToDictionary(grp =&gt; grp.Key, grp =&gt; grp.ToList());
Attributes could help in this scenario if you are making the data object available via a proxy. The thing is you would want to be careful to not set properties directly maybe by taking away the setters. Essentially you are saying built in EF change tracking workflow is insufficient. Unless there is a doc somewhere showing you how/where you can shortcut EF and do some work you want then you will need to track changes manually. At that point how obtain and use your models will be the most critical. Chances are you will need some kind of property changed or observer type pattern if you want to avoid the evils of inheritance by using a base class.
&gt; A few concerns that come to mind are: do you know how you'd be rebuilding the files on the receiving side? Not yet. Worst case I'll send a message with the expected number of parts, then once I get the last part I'll merge parts back into the file in C# code. This is very much a research project at this stage to see what's even possible. &gt; If you need ordered delivery, AFAIK rabbit doesn't support this Elsewhere in this thread someone said it does. Not sure if I'll need it though. For files I can just include header information and fix the order on the receiving side.
As an addendum to what others are suggesting, you could author a convenient utility class to do things like this. CommonFunctions.cs: public static class CommonFunctions { public static void Swap&lt;T&gt;(ref T obj1, ref T obj2) { var temp1 = obj2; obj2 = obj1; obj1 = temp1; } } Usage: class Program { static void Main(string[] args) { var x = 3; var y = 7; Console.WriteLine("Before:"); Console.WriteLine(" X = {0}", x); Console.WriteLine(" Y = {0}", y); CommonFunctions.Swap(ref x, ref y); Console.WriteLine("After:"); Console.WriteLine(" X = {0}", x); Console.WriteLine(" Y = {0}", y); Console.ReadLine(); } } Output: Before: X = 3 Y = 7 After: X = 7 Y = 3 Now you can import and reference `CommonFunctions` to use `CommonFunctions.Swap` wherever you want.
I'm sorry, but what is this? You name it "The Conditional Operator", **but you're not even using the conditional operator!** The conditional operator is this one: `?:` - often also called the ternary operator. (https://msdn.microsoft.com/en-us/library/e4213hs1.aspx) What you're doing is simply the conditional compilation with preprocessor directives. (https://msdn.microsoft.com/en-us/library/windows/apps/jj714084(v=vs.105).aspx) And using the conditional attribute. (https://msdn.microsoft.com/en-us/library/aa664622(v=vs.71).aspx) But nowhere are you using the operator you have in your title.
Could be a bit of an overkill but have you considered BizTalk?
I will never consider BizTalk again. Too many bad memories. True story. I work for a magazine and I was interviewing a couple of people who wrote books on BizTalk. Neither could answer the simple question, "What would you use BizTalk for?". 
What's wrong with using XOR?
See answer of [yakk here](https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes).
That makes sense. Thanks.
I solved this my self. Sorry for the waste. If anyone is struggling with this type of thing, and wont lose anything by getting rid of the grid, you can use a dock panel. Dock both the label and the other control to the left. That doesn't mean I'm not interested in an answer here though. Please address the issue if you can. I really feel let down by this, and as if this should have been possible. Please tell me if it's not.
From http://www.rabbitmq.com/semantics.html , it looks like it's only in one very specific kind of setup, but maybe the other poster knows something I don't. &gt; Message ordering guarantees &gt; Section 4.7 of the AMQP 0-9-1 core specification explains the conditions under which ordering is guaranteed: messages published in one channel, passing through one exchange and one queue and one outgoing channel will be received in the same order that they were sent. RabbitMQ offers stronger guarantees since release 2.7.0. 
How should it behave if the hard drive fails? Do you need redundancy of any kind? Perhaps an Active/Passive or Active/Active scenario?
If my client isn't willing to pay for RAID, I'm not going to warranty my application against hard drive crashes. As for clustering, not sure yet. 
Also avoid using Conditional attributes and other [preprocessing](https://qualitycoding.org/preprocessor/) directives. When different build flavors have different code paths, you'll end up with those nasty bugs that repros only in release builds and never in debug builds.
Thanks. Ideally I'm going to just sit down and spend a week or two studying the docs. Message queue systems are easy to get started with, but there are always lots of edge cases that we as developers really need to know about. 
Nifty, thanks!
Unfortunately, yes. Very large, very old project, and I'm the new guy.
Good that you renamed it: https://www.reddit.com/r/csharp/comments/72lctt/things_i_didnt_know_about_c_part_4_the/ - But in your video you still wrongly call it the conditional operator. But otherwise I'd agree with /u/ggreer. Really avoid these features, they're rarely useful.
It is a bit of a nieche product and I don’t think many technical people use it out of choice. I’ve used it in the last couple of years for a large university integration project and a project for a police force.
Agreed. I'd be curious to hear updates as you progress. Good luck!
Aye, conditional attributes and preprocessing directives were really handy in the c/c++ days and still in embedded systems where memory and processing is limited, but for 99% of c# development they're just going to add hard to track down bugs.
+1 more for RabbitMQ. Used it at my last job for 3+ years, contributed a bug fix (related to redelivery of un-acked messages after auto-reconnect) to the .NET client.
Removed: Spam. Also, don't use `throw e;`. That resets the stack trace (unless you really want that). If you want to rethrow/bubble up an exception, just use `throw;` See: https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/throw#re-throwing-an-exception
My goal is basically the load test scenario. I have a service that is multi-threaded, and I want to confirm how quickly it can handle 100, 1000, 10000 simultaneous requests. I disagree that the absolute number of threads doesn't matter. 4 threads can't possibly simulate 100 simultaneous requests, It can only simulate 4 requests. I understand that to truly simulate 100 requests I would probably need 100 processors. But I would settle with 100 actual threads that are hammering the service **more or less** simultaneously. 
What's wrong with try { // code } catch { } /s
Depends. They are still relevant when writing portable code across multiple .NET implementations and types of hardware.
One must be 100% sure that such code is independent, otherwise refrain from using it. A cool use for Conditional is profiling. You can add profiling scope calls to your code which won't have any impact in the final code if they only compile with the profiling flags, without cluttering your code with ugly preprocessor directives.
Post your csproj file.
[Here](https://pastebin.com/12ibsZpz) is the .csproj file. I've tried adding the `System.Text.Encoding, Version=4.3.0` before, but the error didn't change, so I've removed it.
I'm ok with preprocessing directives when used for multi-targeting (e.g. .NET and .NET Core). What I don't accept is using them for Debug vs Release.
If you wanted to do this the fun, complicated way: build a markov model of typing. Have someone type into a text editor that you're monitoring every keystroke. For every keystroke, record three values: the previous keystroke, the current keystroke, the delay. From that data, you can calculate the average delay from any two characters, as well as the standard deviation. Then when typing from one character to the next, take that delay and randomize it according to the standard deviation. Some keystrokes will be wrong, and this is where the markov model comes in. From your keystroke data, you can determine the probability that after keystroke X, the user will type backspace, and you could determine the probability of which character they typed wrong. Maybe, 10% of the time when I type "Hello world", I actually type it like "Helo\^Hlo world" (\^H here means backspace). So you would have a model that says 10% of the time, after typing 'l', insert an error, then a backspace, then the right character. This is the crazy super complicated way to do it, and definitely is not KISS. But it might be fun, depending on what you want to do with this project.
Removed: Rule 4.
Xamarin forms is tricky for complex stuff, not xamarin android and xamarin ios.
I also have the code in a .net fiddle if that makes it easier for anyone and I can provide example images if necessary. https://dotnetfiddle.net/pHN16s I'm also open to changing to a different drawing library if SkiaSharp is not the way to go
Sorry, I didn't understand what you meant before; I see what you're describing now. It's a good pattern. My bad.
I use preprocessor directives to compile a single project for several different versions of Unity, similar to your .NET situation. I'm really not sure any other way it could even be done that wouldn't be worse. The author of the article in the parent comment mentions the drawback that "the code you see is not the code you compile" but for me that's entirely the point. The code *can't* and *shouldn't* compile except in the version of Unity it was written for. The only alternative I can think of is completely separate project and maintaining branching in version control but I can't really see any way that that is better. It just seems like it would be even more time consuming and error prone.
Why oh why is this a video?
Based on the [Microsoft documentation](https://docs.microsoft.com/en-us/sql/t-sql/functions/encryptbypassphrase-transact-sql), I'm going to say no it's not possible. Doesn't look like they provide a library with equivalent functionality either. If you need encryption all the way to the application and have access to the connection string and SQL server instance, you can set up an SSL certificate on the SQL server to encrypt the traffic between the server and client (read up on that, because starting in .NET 4.5 there were changes to requirements for the certificate CN). It does generate one additional round trip per connection to the SQL server.
Post the code? Minimal example? https://github.com/dotnet/corefx/blob/master/src/System.Runtime/ref/System.Runtime.cs it does seem to contain an Encoding class for some reason. Where you call Encoding, can't you just call it explicitly with Text.Encoding?
No problem.
&gt;"Default Interface Implementations". This seems like it could produce a lot of potential for the same headaches that would have come with multiple class inheritance. =( I'm optimistic about it. The diamond problem in particular won't be a problem here, because the default-implemented interface method won't be a member of the class (it would be like every implementer implemented the method explicitly, with that exact implementation). You will only see the default implementations when you use the interface type. Do you have other examples of things you're worried about?
[Here](https://pastebin.com/8Yf9b2e7) is a code example where the error is thrown. I've tried removing the using and specifying the full name (System.Text.Encoding), error is the same. It's strange that the project compiles on Windows just fine, but on fresh install of Ubuntu inside of virtual machine it fails. I've also tried reinstalling the Ubuntu as well as .Net Core - same error.
 I tried on a new install of ubuntu and mine works fine, are you sure you're on 2.0 base and not a preview? when you do `dotnet --info` it returns just Version 2.0.0?
Is this winforms or WPF? On mobile right now so can't form a proper code example, but you shouldn't be creating your views by code. Going to use this post as a placeholder to remind myself to respond properly. I will say this. If it's WPF, which I think it is from your code, you should be using the MVVM pattern and using bindings from the view to the view model. Edit: Here's a solution I would use: Use the MVVM pattern and create a CharacterViewModel, which would contain the items specific to the character. Then another view model which is the window/control/page view model, WindowViewModel. This would contain an ObservableCollection&lt;CharacterViewModel&gt; Characters. Using the MVVM pattern, your view would be bound to this list and generate the necessary items. In your view, you would create a listview, whose view property is a gridview. // Character public sealed class CharacterViewModel { public CharacterViewModel(string name, string speech) { Name = name; Speech = speech; } public string Name { get; } public string Speech { get; } } // window view model public sealed class WindowViewModel { public WindowViewModel(IEnumerable&lt;CharacterViewModel&gt; characters) { Characters = new ObservableCollection&lt;CharacterViewModel&gt;(characters); } public ObservableCollection&lt;CharacterViewModel&gt; Characters { get; } } &lt;ListView ItemsSource="{Binding Characters}"&gt; &lt;ListView.View&gt; &lt;GridView&gt; &lt;GridViewColumn Header="Name" DisplayMemberBinding="{Binding Name}" /&gt; &lt;GridViewColumn Header="Speech" DisplayMemberBinding="{Binding Speech}" /&gt; &lt;/GridView&gt; &lt;/ListView.View&gt; &lt;/ListView&gt; 
[Yep](https://i.imgur.com/cB4B66a.png), it's version 2.0.0 - `dotnet --version` returns the same.
Lot of people saying they should be avoided, but what about performance reasons? In my game engine I had some DEBUG conditional function calls that added a lot of tracing. In debug builds it allowed me to track down bugs, but in release mode the tracing calls were not even compiled (meaning they had no impact on framerate).
Never seen this. Doesn't make sense a model is just a class there is no discovery on startup of models like there is for controllers I've been using mvc / core for many years and never once had this happened. Is this model even setup in a controller for use in data binding ? 
I do a lot of azure specific stuff, (event hubs, service bus, blob storage, stream analytics, data warehousing/BI/dimensional reporting, batch apps, data factory, document db, redis, schedulers, app service, setting up monitoring dashboards for all of the above, etc.), and still most of my time is spent writing C# code or debugging it. 
Are you asking us to come up with project ideas for you? I just don't understand the question in relation to WinForms.
Damn, I ran into this issue just last Friday and I'm trying to remember what I did to fix it. Are you even using System.Runtime at all? If you're not, then remove it from your `app.config` and `packages.config` files. Also remove it from your `.csproj`.
Your Subreddit object needs a .ToString() method. internal class Subreddit { string Name; public string ToString() { return Name; } } Now you can call: Subreddit sub = new Subreddit(); sub.Name = "CSharp"; string subName = sub.ToString(); // sets subName to "CSharp";
This is an issue with your environment, not any of the tools or architecture which you're using. Try a clean reinstall.
You always seem to be pumping out great projects! Thanks for your hard work
Sorry I was unclear! I want to create a winform that will track a GPS receiver with updates every second or so. I have coordinates coming in, I just don't know what to do with them besides to plug them into Google maps in a web control.
Well, you've got the coordinates coming in successfully so you can do whatever you want with them. Maybe you could plug the coordinates into a graph and draw lines between them over time? So if I walk in the shape of a circle, it will draw a circle on the program. If I walk in the shape of a triangle, then it will draw a triangle. That would be neat, right? Have it draw a dot every second on a graph wherever the coordinates are located.
I build enterprise and retail grade desktop applications using C# and .NET Core so it can be cross platform. You can do anything you want in C#, be it web or mobile or terminal based.
Reddit is much more friendly in these small, topic-specific subs. We all love C# here and most of us also love to help. Life is already difficult enough as a junior developer, so you don't need to worry about people calling you stupid for asking normal questions. It wasn't that long ago that I was also bashing my head against the table trying to figure out how BackgroundWorker works. :)
Just to clarify, the point of moving work into a BackgroundWorker is so that the UI layer isn't interrupted by other logic. If you do everything all on the same thread/layer then you run the risk of the animation looking jittery while competing for CPU time. Typically you do the animating/UI on the top layer, and put the logic into background workers. This way none of the logic will interrupt the top-most UI layer. I think it's a bit silly that he demands you use BackgroundWorker *specifically*, because there are lots of other ways to do this. That said, learning it is still a good idea.
Are you okay with Debug assertions and the like?
I do the same thing in game- and graphics-related code. There is no reasonable alternative, and this is a perfect use of conditional compilation, IMO.
Yeah that's a great idea! So now my question is that since the coordinates from the GPS are based on a spherical object, how do I project those on a flat plane?
Nope. I've never seen an assert that shouldn't have been an exception.
In my experience, having Haskell show up somewhere on the resume has opened up some interesting conversations in interviews. In the interview I had at my current position (a large bank) having Haskell on my resume as "non-work experience" opened up a conversation about the benefits/downsides of purity/immutability/laziness. I think it helped me land this job. So please don't discount Haskell out of hand just because not many places are looking for people to be able to code professionally in it.
Try disabling Application Insights, google will turn up how. It can improve performance quite alot and resolve freezing issues.
You can totally make 100 simultaneous requests with less than 100 threads if you use async IO. Service side, it all depends if it is CPU or IO bound. But hey, I've been only testing this shit for like 10 years so what do I know. :)
This post made my night :)
Thanks, yeah exactly that's I'm doing.
Thank you for that. I debated for a while before posting because the world of reddit can be a bit hostile sometimes. Now that I know I can ask questions and get guidance, Im much happier. I just wish my professor would help more than he does. One day in the middle of class he started talking about this auction he went to that he ended up bidding on something accidentally and how he got rid of them. Its very hard to learn in these classes, so I will probably be back for more questions and guidance :D 
The EncryptByPassphrase is a method for encrypting data at rest. It only works in the DB, you can’t encrypt it on the DB server and decrypt it elsewhere (or the other way around), because the method behind it is native to SQL. The benefit is that you can decrypt and query the data from within SQL. But if someone walks off with a backup, or a drive from the server, the data is encrypted and basically worthless. Your next option is to encrypt the data on the web sever, and storing that already encrypted data in the DB. You lose the ability to query the data directly on the SQL server, but gain protection for transport between the web server and DB server. I’m not sure of a solution to encrypt and decrypt data from a webform, since that’s client side and inherently insecure. You could encrypt it with a public key in the webform before sending it to the server. You then would decrypt the data to process it on the server, and then re-encrypt it for transport to the DB. However the return trip with that data would be less than useful, you’d read and decrypt the data from the DB, then re-encrypt it using a public key, pass it to the client to be decrypted with the private key you had to send it in the same session. Anyone listening to that session would already get the private decryption key to decrypt the data, so passing it to them encrypted is a waste of time. Instead, you can mitigate eavesdropping with an HTTPS connection. That will handle client to web server connection encryption, giving you encryption in-flight with the client. Then you can decide if you want to encrypt the data on the web server or the DB. There are protocols that allow secure communication between the DB and the web server, so using those will allow in-flight encryption between the servers. That allows for using the at-rest encryption of EncryptByPassphrase. 
I appreciate you lending your experience :) Not trying to argue, just trying to learn. I'm using the term "service" in the general sense. Its just some code that does some hefty calculations. Its not a web-service and its not I/O. The service is actually currently in the same process as the test threads so its definitely not I/O. I dont think async will help here. 
Yes, you need to convert the lat/lon to plain X/Y coordinate before plotting in the map. However, the complexity of the conversion depends on your actual moving distance, if they're short (eg. &lt;100km) you can use the local flat earth approximation which is simpler and faster. Otherwise you may need to use the Great Circle Formula which is slower. This may or may not cause you a problem if you're working in a computer. You may have a look on this wonderful page about the detail: http://www.edwilliams.org/avform.htm 
Sure but what's your title though? Is this role part of DevOps or Development? I personally would like to jump into a role that involves Azure but won't do it if it involves being re-classified as DevOps. 
Ah, I see! :) Your service is totally CPU bound. But your example is IO bound by Thread.Sleep and Console.WriteLine. In this case, the thread pool create more threads because the threads it has aren't doing any CPU work. If you don't do any blocking IO on working pool threads and there's enough work to do and everything is perfect, the threadpool will max out your CPU and won't create a ton of threads.
There is a lot of work available in the physical security software space. Most Enterprise level access control systems, video management systems, visitor management etc have a Windows-based back end, and C# is a common language here. The industry is also continuously growing double digits. I'm about to transition from a long career in software support to a developer role where my job will be writing integrations between different products, specialty tools to fulfill specific customer requests, and automation tools to make life easier for various departments within the organization.
This is the most "real" post I've read here, thanks OP!
How does it compare to JSON.NET?
https://github.com/neuecc/Utf8Json/blob/master/README.md
Yes, show both. I’d want to see we’ll structured code and exploration of different techniques and patterns. This can be shown through both console and web apps. I can teach a junior to do web programming if they already have a good foundation. That’s what you want to demonstrate: knowledge of the basics and a thirst for learning and improving. 
This confuses me a little. You say that Task.Run does not start a new thread. But doesn't Task.Run always start work on a different thread? That's why you avoid it in ASP.NET -- you're unexpectedly taking a thread away from the scheduler.
The Task Parallel Library has a pool of threads and a shared queue of work to do. Each thread pulls something off the queue, executes it, and then repeats. `Task.Run` basically just puts something on the queue. The number of threads in the pool is usually based on the number of CPU cores there are, but sometimes it will add threads to the pool or spin off a thread just for one thing. The instructions I gave earlier are one way of triggering that. 
Ok, so maybe put another way, Task.Run always offloads work to a thread in the thread pool (whereas async/await can potentially run synchronously if the work completes before even needing to be awaited and thus no context switch is needed).
Basically. If you want to get technical, async/await doesn’t do anything thread-related. It’s just syntactic sugar for making continuation callbacks look nicer. You can still use async/await even for async things that run on a single thread. For instance, if you’re on the UI thread doing async things your function could be broken into pieces that get run all on the UI thread. Just because something is async doesn’t mean there has to be another thread somewhere. 
There's a few things very wrong with you project file. 1. Remove the PackageReference to System.Threading, it's not needed (and likely causes the issue). You're targeting a netcoreapp2.0, this already includes a lot of stuff (like threading). 2. The same counts for the PackageReference to System.Threading.Thread. 3. Fix the "OpenSslCore" and "TinyMapCore" references. You never ever reference from the "bin\Debug\" folder. **Never!** Instead you should add a **project reference** to those projects.
What about newtonsoft?
[JSON.NET is a Newtonsoft project](https://www.newtonsoft.com/json).
Did not know that
How does it compare to ServiceStack.Text?
There is another approach. Creating interfaces for platform specific implementations, with the respective implementations in separate Assemblies, explicitly loaded at application startup instead of being directly referenced. Or having multiple startup projects as well, if you want to avoid the explicitly loading part. However this extra effort is only worthwhile if there is a big codebase with lots of #ifdefs. 
1. Removing the System.Threading doesn't seem to affect anything. 1. Removing the System.Threading.Thread indeed solves the error, but I am using the Thread class and it is not found in the SDK version of the library, hence I've included the latest version. 1. The references aren't a problem, they are included correctly and working as intended. I am not referencing them from `\bin\Debug`, but rather `..\..\opensslcore\OpenSslCore\bin\Debug\netcoreapp2.0\OpenSslCore.dll` and `..\..\tinymapcore\TinyMapCore\bin\Debug\netcoreapp2.0\TinyMapCore.dll` as they are standalone libraries and not a part of this solution. Edit: I just checked the corefx repository and there is the [Thread](https://github.com/dotnet/corefx/blob/master/src/System.Threading.Thread/src/System/Threading/Thread.cs) class that I'm looking for. But when I remove the package reference, I get `error CS0246: The type or namespace name 'Thread' could not be found (are you missing a using directive or an assembly reference?)`. I am running on .NetCore version 2.0.0, as I've posted below.
There is no `app.config` or `packages.config` file. The project is using the new `.csproj` file structure, where everything is specified in the `.csproj` file itself (afaik).
What I look for is somebody who goes home and wants to code still because it is a hobby also .. I've come across 3 types of people. 1) love to code and started doing it in teen/pre teens usually they see they overestimated how good other programmers are and never apply for a junior position again and don't stay long but can still bring value and are worth the chance. 2) (majority I see apply for jr) parents boot them off to college and they heard there was some money in it. These people are fresh out of college and couldn't write an empty class on paper. They are never worth the chance. 3) same as 2 but these kids show glimmers of hope and usually naturally smart but never exposed at a young age like the people in 1. These guys are tough to judge because they have ability but you don't know about the passion. That said I have no idea which one you are but the expectations for junior from an average small to mid size company are usually fairly low. Get some small stuff together that shows you understand writing in C# does not make your code OOP and you understand a pattern or two. Edit: if you do end up posting code I personally can't stand to look at a person's "work" and it is 1 commit.. I want to see the work.. the refactoring .. the scope creep ... not something you just followed a blog post or YouTube video on and uploaded your final cleaned up code. 
I don't think that is possible, how would CustomBusinessAssociateRelation be casted to BusinessAssociateRelation in the first place? If you have: public class BusinessAssociateRelation { public string Relations { get; set; } } public class CustomBusinessAssociateRelation : BusinessAssociateRelation { public Guid LegacyId { get; set; } } then, var a = new BusinessAssociateRelation() { Relations = "Hello" }; var b = a as CustomBusinessAssociateRelation; // &lt;--- this will be null You could approach it by for instance instead having: public class Item { public Guid LegacyId { get; set; } public BusinessAssociateRelation Property { get; set; } } and creating a list of items to be used as a DataSource, the Item.Property would then be a reference to the original object.
Like many other features, they have their uses. I think that people sying that they should be avoided are mostly thinking about the serious pittfalls represented. So, use conditional compilation if absolutely neccesary, otherwise don't. Did you ever try to measure whether having the tracing calls in release had any significant impact on performance?
Have you checked the links in the sidebar yet?
How does it compare to JSON.DoYourOwnDamnComparisonsItsAFreeOSLibrary? /S for snark
Removed: Rule 4. Plenty of learning resources in the sidebar and at /r/learnprogramming. Other resources on google, plenty of online courses/tutorials, many books. Dive in, have fun!
Try using [`CollectionAssert.AreEquivalent`](https://msdn.microsoft.com/en-us/library/ms243779.aspx). Using dictionaries, and in particular how you're tossing them in by splitting by grade, means that order isn't preserved. This method checks that the collections contain the same values, but not necessarily in the same order.
Take off the training wheels and just use the functional style.
You seem upset about something
Not at all, I just found it funny that there were 2-3 "how does it compare to..." queries almost immediately. If it were my library I'd be eager to test against a bunch of different libraries, but that stuff takes time. It's free so one could test on their own.
You haven't ordered the names hence why the test is failing, you can either implement some form of sorting algorithm or use the linq extension method `OrderBy`to order the names. Example var names = new List&lt;string&gt; { "Rob", "Bob", "Dave", "Alice" }; var alphabeticalNames = names.OrderBy(x =&gt; x); foreach (var alphabeticalName in alphabeticalNames) { Console.WriteLine(alphabeticalName); } The output is Alice, Bob, Dave, Rob. 
I would configure your constructor to receive an int and based on that int, initialize the enemy with certain values. You can use a few if/else statements or use a switch statement. Otherwise, this might be an opportunity to use interfaces or inheritance to make sub classes of your enemy class. If you're going to do more enemy specific logic later, that might be more interesting. Let me know if you need help figuring any of this out.
My guess is that its better for self-promotion
Alright, ty! I'll take and see what i can come up with! ty ^^
Thanks for the help on this one guys. You saved me a good 4+ hours of google`ing. 
Right, OK. And so the reason Task.Run never really makes any sense in ASP.NET is because it's just a pool of threads, they are all the same. Calling Task.Run just frees up your current thread and puts it on another thread, which just offloads the work elsewhere and doesn't really solve a problem. Though it can make sense in WinForms or the like, where a UI thread exists where you want to offload it to not lock up the UI. Is all of that true?
Are you auto-generating your columns or did you explicitly define them?
&gt;Do you guys see any error in my code or the way I'm trying to solve this problem? It could be possible that the way I found is due to inconsistent use/simplified code and not related to the problem. (`this.myLookUpRowHandle` is never used) I see that you are using three different handles: &gt; [line 3] e.RowHandle &gt; [line 5] this.myLookUpRowHandle &gt; [line 9] GetRowLevel(e.RowHandle) Is this the actual behaviour you want or is there something different than you wanted it to be? 
Oh yeah sorry, should have clarified that. myLookUpRowHandle is a global variable. The thing with the handles is the following: e.RowHandle returns some kind of handle for the group of a value, as stated above myLookUpRowHandle is a global variable and GetRowLevel(e.RowHandle) returns the exact index of the clicked datarow in its datatable.
I don’t know anything about ASP. NET, but I would think `Task.Run` would still make sense if you wanted to do some work in the background while also doing some more work on the original thread. 
First of all, regex can also (and has a sufficient method to) split a string Furthermore this can be done either using the WindowsAPI or using one of the list of examples found through you preferred search engine (Bing prefers C# results as it's from Microsoft so it possibly lists better results)
I looked through some options (didn't realize RegEx could do it itself) but couldn't find anything that would manage escaped characters. Any ideas there?
You should use an enum rather than an int. An enum can be used as a number that has a name. It's more readable.
What do you mean? Never heard of an enum before :p
I just had a thought. Is there any way i can store all my "enemies" as objects in an array, and then change "enumVal" to the index number instead to call all the info from the array?
For a moment there I thought you were trolling.
Nope, just ignorant 😁
I once found a script which splits the command line using linq
If you have a collection of enemy objects and index into one, you'll get that object and it's associated details. I'm not sure if that's going to match the functionality you have planned for enumVal.
 var text = "This is \"a big\" test."; var pattern = @"(?&lt;=(\s|\b)\"")[^""]+(?=(\s|\b)\"")|(?&lt;=\s|\b)[^""\s]+?(?=\s|\b)"; var result = Regex.Matches(text, pattern).Cast&lt;Match&gt;().Select(x =&gt; x.ToString()).ToArray(); // tested -- result should be ["This", "is", "a big", "test"] Detecting boundaries to Regex.Split() seems a little more complicated.
Ok, I'm pretty sure it doesn't, at least from a couple posts I've read. Notably https://stackoverflow.com/questions/33764366/is-task-run-considered-bad-practice-in-an-asp-net-mvc-web-application. Since all threads are equal, there's no sense in switching. It's just unnecessary offloading / context switching.
FYI you can make this bit of code neater: Enemy crow = new Enemy(); crow.enemVal = 1; crow.name = "Crow"; crow.maxHpVal = 5; crow.hpVal = 5; crow.xpVal = crow.maxHpVal; by writing it like this: Enemy crow = new Enemy { enemVal = 1, name = "Crow", maxHpVal = 5, hpVal = 5, xpVal = crow.maxHpVal };
https://www.dotnetperls.com/enum
Awesome! What if someone has this, though: "This is \"a \\\"big\\\" test." *Edit: There should be triple slashes in there, but reddit edited them out.*
Probably doesn't do whatever you're after, but I'm not sure what that's supposed to *be*. Is that supposed to be a string constant containing `This is "a \"big\" test.`? What are you wanting to get out of it? ETA: at some point, it's going to easier to manage this by parsing it a character at a time and building the result with a StringBuilder, FWIW. Regexes are really neat, but they get pretty esoteric pretty fast.
You might consider the factory pattern and create a class called EnemyFactory with method called GetEnemy(...) Your GetEnemy method could then take an enum parameter like EnemyType.Crow. Your enum would be defined like... public enum EnemyType { Crow, Snake, Dragon } That way you don't have "magic numbers" in your code and you rely on named parameters (Google magic strings and magic numbers if you're unfamiliar with why they are discouraged). In your GetEnemy (...) method you would have a switch block covering all your possible enemy types and you would "new them up" there, setting their parameters appropriately for the supplied EnemyType. This makes your calling code look cleaner... var enemy = EnemyFactory.GetEnemy(EnemyType.Crow); And you can even randomize the spawned enemy by pulling the enum values into an array, then using Random to select an enum value from the array for spawning.
Yes, that. So basically if a user types this in to my commandline: command.say "This is a test of a \"quoted\" line." color:red Then it could parse the command line correctly into the command and two arguments, showing this in red: This is a test of a "quoted" line.
You would generally use a return, unless the method needs to return multiple results... short of using a tuple you can do this: public static string SerializeErrorMessage(int ErrorCode, string ErrorMessage, out byte[] Buffer) { object ErrorJson = new { ErrorCode, ErrorMessage }; string Serialized = JsonConvert.SerializeObject(ErrorJson); Buffer = Encoding.UTF8.GetBytes(Serialized); return "you can consume this and still get the out value"; } Basically if the signature is void and it has an out then change to a return. Microsoft evem has a codesmell test for this (eg don't use out if youdon't have a very good reason... eg the try/catch model of Int.tryParse): https://msdn.microsoft.com/en-us/library/ms182131.aspx 
1. Doesn't change it, but is the right thing. 2. You don't need to reference the `System.Threadng.Thread` package to use the `Thread` class. It's part of the netcoreapp2.0 target. Do you have your Visual Studio 2017 fully updated? 3. You **are** referencing it from **a** `\bin\Debug` folder. That is a **bad** thing and should not be done. Either wrap that stuff up in a NuGet package, or add a project reference. As it is, your current project will not compile unless you compiled the other project first, which is not even part of your solution. That's just plain nasty. When you create a simple empty console project you will have this `csproj` file: &lt;Project Sdk="Microsoft.NET.Sdk"&gt; &lt;PropertyGroup&gt; &lt;OutputType&gt;Exe&lt;/OutputType&gt; &lt;TargetFramework&gt;netcoreapp2.0&lt;/TargetFramework&gt; &lt;/PropertyGroup&gt; &lt;/Project&gt; Within this created project you can immediately use the type you desire: new System.Threading.Thread(() =&gt; { }); That is because of the `Sdk` property and the configured `TargetFramework`. This will cause basic libraries like this to be referenced already. When you now add a reference to the **old** NuGet package `System.Threading`, then this will introduce a transitive dependency on the **old** `System.Runtime` package and you end up with the error you have: `Encoding` exists twice, once in the .NET Core 2.0 SDK, and once in the referenced `System.Runtime` package. If you can't reference `System.Threading.Thread`, then you should try updating your Visual Studio 2017 installation.
Quick and easy hack for this would be replacing \" with a placeholder character (perhaps a non visable character that would otherwise never show up in your string like 0x1A then do your split, then replace 0x1A with ".
unsubscribe
Hungarian notation is only useful in certain environments. In most environments, it reduces the readability of the code by increasing unnecessary clutter. The notation would be useful or even considered best-practice in environments where some sort of intellisense isn't available or if you are working with a dynamic-typing language like JavaScript where type mismatches aren't caught during compilation time and are instead caught during runtime. It is also the case that Microsoft considers it convention to prefix the variable names of UI controls to indicate what type of control they are so you end up with something like txtUserName (textbox) or gbxUserInput (groupbox) or pnlLeftFrame (panel). This prevents naming conflicts (UserName property that is bound to the textbox UserName, for example), so prefixing UI controls is an exception to the intellisense argument. You also benefit from auto-completion if your IDE supports it. Ultimately, if hungarian notation was the only thing I *could* complain about, or one of the only things, I wouldn't complain about it. However, coupled with all of the other things on my list, it makes the code base a virtual nightmare.
Yeah, that's basically what I'm doing now with the whole quoted string.
Not that it will help, but do you mean "roster" which is a list or schedule of people, rather than "rooster" which is a male chicken? Readability matters.
That might be the point where a finite state machine is easier to deal with than a regex. The FSM would be more verbose, but wouldn't require a deep dive into regex grouping and lookbehind and lookahead etc esoterica to build and maintain.
Its really personal preference. I honestly hate using out most of the time and often only end up using it because its a simple scenario and my other options I hate more for the simple cases (Tuples or Custom/Dynamic type). I tend to feel that if your method needs to return 2 or more disparate data items that your function may be responsible for too much. 
True that. Could even be faster considering how specific I'm trying to be... Might just go ahead and do that.
The only time I use out is if I'm writing a function similar to TryParse, where the return value indicates success, and only on a return of true is the out parameter accessed.