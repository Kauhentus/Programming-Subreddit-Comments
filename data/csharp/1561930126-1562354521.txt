So how does that change my code then?
Electron if it has to be an installable app.
Is this your first time doing any sort of UI programming? Do you know other languages besides C#? I find WPF to be a little underrated. It has a pretty steep learning curve at the beginning, and unless you've seen many (older) UI toolkits, it's difficult to see what problems it is solving. If your goal is to be productive quickly and learn useful things for your career, maybe learn HTML/JS/CSS and some related UI frameworks, which you can then use for web development but also offline using Electron and whatnot. I hardly know anything about that world but sometimes I wish I did. If you really like C# (it's definitely my favorite), you could of course go for some solution that uses it for the back-end (as another commenter pointed out). It is pretty good for windows apps though, and the most popular patterns and libraries commonly used with it will teach you some good practices from the beginning, so you don't have to spend a decade writing shitty unmaintainable code. What's usually part of the WPF "package": 1. MVVM - stands for Model-View-ViewModel. It's a way of separating your UI code into layers. Model: the part of your application that doesn't need to know it's part of a GUI application. View: the part of your application that is all about how to display things to the user and how they interact with them, without really knowing anything about the model. ViewModel: The part that gives the view something to present, basically glueing the view and model together without exposing them to each other, plus some view-dependent logic. 2. Dependency injection - One of the most important design principles in programming. Usually when I make some architectural mistake, I realize it would have been 100x easier to fix if I hadn't skipped a step related to proper DI. It's really important in order to make MVVM useful, otherwise you don't really need it, and then WPF in general will be quite a drag. 3. Prism - a library that will help you implement MVVM and DI effectively. Just to be warned though... tutorials around WPF/MVVM/Prism aren't very up-to-date, even though it's all being actively developed.
Yeah I don't know if I agree fully, but the part I do agree with is "understanding a XAML framework and the concepts of MVVM with data binding is really valuable". I think a lot of other frameworks also run with that theme. One day, MS will settle on their GUI strategy, and then all of that knowledge can be applied.
Either: - Check if that library provides an overload that lets you specify the type, so you don't have to deal with `object`. - Check if that library can return you a string, so you can deserialize yourself. - Get a better library. - Be dumb and use reflection.
Stick with WPF, MVVM is hard to get your head around once you have gone into Winforms
Learning WPF was a pain for me, because like you, I found there wasn't a really tutorial, and it is very different from Winforms. WPF is amazing, but is limited in some ways such as poor high speed rendering performance, and binding debugging. UWP is like WPF, but much better, but also something I will never ever use because it requires the latest versions of Windows 10 different functions. If you can't confirm that other people are using a specific build of W10 or higher, you can't use features - Plus it makes it insanely hard to open files on your machine from code. Avalonia UI is perfect, and undocumented entirely.
There is absolutely nothing inherent about WPF and MVVM. When I say "treat it like winforms" I kinda mean "don't do mvvm" because I don't want beginners to get the impression that they have no choice if they pick WPF, which means they pick winforms and then don't do mvvm anyway. &amp;#x200B; So many people are surprsingly unaware that you can treat wpf as winforms. Drag-drop is there, property view is there, double-click a button to generate and hook-up an eventhandler in the code-behind. There's no reason to pick winforms.
Removed: Rule 1.
Where have you guys been given the impression that MVVM is implicit in WPF? There's nothing about the Framework that directs you down that path, you'd have to read about it from external sources. While I'm a fan of MVVM, I'm not a fan of scaring away beginners. They can do WPF without MVVM and it won't be worse than if they picked winforms.
Terrific attitude: ambitious, realistic, honest.
No, I totally understood that. What I was saying is that I think MVVM is a better pattern (in most instances) and definitely worth learning.
I think there's really no point introducing design patterns to beginners until they have a firm grasp of delegates, events and eventhandlers. Basic code-behind is perfect for this. Once that's in place introducing MVVM will make a lot more sense to them.
You might be right.
The repository is a layer between the data source specifics, SQL Server, Oracle, Kafka, and as such is very specific in generalising the things those systems understand. It's specifically CRUD oriented. We also have the repository pattern that extends the CRUD model to business specifics. This is a perfectly legitimate leap of faith, but not what the repository pattern attempted to encompass. If you have a method "DoubleStaffBonus", this will be turned into a CRUD operation by the layer above the repository. It's a really hard one to communicate for me, and I don't really know why. I guess it's how often it is misrepresented, and the places where it is legitimately re-purposed, but without adequate explanation. Sorry for being snappy, I've had a shit day. It's not your fault obviously, but I shouldn't have been snappy.
Be aware that the InMemory database can behave very much differently from a real database. It does not replace proper integration tests.
True that
this many upvotes in 13 hours for a fairly average blog post with comments calling out errors. I smell a hidden ad or some other form of vote manipulation going on.
what stops a dev from doing this public class MyController: Controller { private IProductsService productsService; public MyController(MyContext context) { } } I mean, a dev following standards would do it. But EF is not really protected because of the dependency injection. Isn't this what they call leaky abstraction?
1. Client makes a POsT request with username password and 2FA. 2. The server issues a refresh token and access token. 3. Access token expires every 30-60 minutes, at which point the client takes the LAST refresh token, and we go back to step 2. For additional security you can have cert pinned pkcs7/cms encryption INSIDE SSL, which will protect your users in corporate environments (zscaler) or from MiTM attacks.
And no MacOS. rip
I started with C++, where i learned some basic things (a bit of algorithms and efficiency, classes, namespaces, pointers, dinamic memory, a small bit of async programming, etc), got my hands on a bit of html+js too (not a big fan of webdev) and some hardware programming using arduino and some mcus (also not a big fan). Right now i'm kind of looking to try all things out before i go to university, to see what i like the most and what to focus later on. Maybe in the near future, i'll also try unity. Now i want to get the basics of windows apps.
&gt;can I make calls to the API from the WinForms app to check the user's login credentials at startup, then allow any further calls while the app is still open because the current user is authenticated? Or should I try to implement some kind of token-based authentication in the API itself? Without a token, how do you tell apart calls from the authenticated user/app and calls from unauthenticated ones?
That's true, completely forgot about that part
It's a netcore program inside a docker container. I don't see the problem.
I would very much recommend taking further advice of his with a grain of salt. Speaking in absolutes in regards to languages he isn’t familiar with really just makes him look like an idiot.
This kind of implementation certainly comes from Spring/ Spring boot programming, and it makes sense in Java and Spring Data JPA apps. In C# it makes no sense and it is utterly unproductive. DbSets are repositories already, and LINQ is a thing in C#. The DB context and DBSets (even the IQueryables) can be extended to fit your business domain into the same LINQ chains and make compositions of queries in order to reuse data access metaphors(and create much more efficient queries to the database). The same metaphor for getting X or Y records can be used for Counts or for aggregates. This kind of repositories is a mitigation of the complexity of connecting your apps to databases in the Java world.
So while I was writing this program, I did discover over this class and have been using it to get the process by using Process.GetProcessbyName(process), and using a name for the process inside the parenthesis. That worked.
Indeed rip macos
It absolutely makes sense in c#. If you reuse complex LINQ queries, then it’s good to have all of that in one place
I've been able to get it working to the point where it gets the process and is also able to output the runtime by using [DateTime.Now](https://DateTime.Now) and using Process\[0\].ExitTime to find the runtime for example for notepad, but the application will only run for one instance so it only records time for the application for only one time and the program needs to be rerun in order to get a second value for its runtime if "notepad" has been opened once again.
&gt; encapsulate domain queries into specially names classes You mean like a repo pattern?
No, like IGetAllProducts or IGetFruitProducts or whatever. The repository pattern keeps the rest of your domain language in the tech world (db language) instead of expressing what you want to do. Those classes *could* call a repository though.
That’s still not quite right. Delegate handles the multicast stuff, because that’s just part of what delegates do. All delegates have the ability to multicast because the “delegate” keyword is a reference to the MultiCastDelegate class The event modifier just prevents clients from replacing the delegate object because that would remove other client subscriptions. The default version also adds thread “locking” to enable concurrent updates
To me, that just sounds like a poorly planned repo pattern. I’d much rather have a fully built, fully planned Product repo instead of scattered classes that do the same thing while pretending to be something different. Something like Products.GetAll() or Products.Fruits.GetAll() seems much more maintainable to me But maybe I’m misunderstand the repo pattern entirely
So this is true but I do run into issues. The in memory provider doesn't support transactions. You have to tell it to ignore the error. It's ok, but in the end you still need to do integration tests to get better tests
It should work on mac os as well, but I do not have a mac to test
Fair enough. I don't understand it very well yet. I feel like the point of the ORM is to make it easy to interact with the database within one line or so which in my experience is what the repository pattern is meant to do. If you just use the ORM around your domain you'll definitely end up with duplication which kind of sucks. However, hopefully this allows you to be more expressive with your class names and move away from working with data and towards working with domain language. I also think the size and scope of the project have a huge impact on how I would approach this but that's another discussion.
The sample isn't clear. The assumption is that you're loading the data in two steps. For example, you might load a list of items from json and then convert to the structure that xUnit expects. I'll update the article.
Use real os maybe?
A heavy ORM like EF makes databases approachable for application developers. It moves DB logic into C#. That means that well defined Sprocs now turn into LINQ, which is then “compiled” to SQL. The old way had a very clear separation of concerns. The sproc existed on the DB, then a repo served as a wrapper to prevent unnecessary duplication Now, all of that is moved into the application. Without a repo on top of EF, you’ll be repeating important queries all over the application
 You could use Jetbrains Ryder if that is still free to use.
If you can get by with it running periodically, I’d just write the console app to do batch processing and use Task Scheduler to run it as often as necessary. Also makes it inherently cross platform since other OSes have their own built in job runners (cron, AppleScript, etc).
VS 2019, but wish I could use Jetbrains' Rider.
Rider is it.
I would really suggest to do planing before you start programming. You will catch a lot of errors before which would spare you long hours of rewriting bad architecture. 1. Think about the base outline. Which kind of functions, features should the app / program have. What kind of technology do you want to use 2. Architecture of program. Maybe you can even use an UML designer (unified modeling language). To shape out your necessary classes, functions, etc 3. Implementation of above mentioned things. So write the actual code with the chosen technology I know that at the beginning of a process planning is boring and you think you don't need it you just want to start programming already. Trust me don't. I would use Google to find software dev process, software architecture If you have any other question feel free to ask me or again this post. Cheers, Max
I volunteer as tribute. Hit me up if you need a tester
Removed: Spam, plagiarism.
Alternatively use JetBrains Rider.
So you swapped one issue with another, without even addressing the new issues that result of this.
Just learn blazor, react or angular, no sense in learning old tech as young as you are.
Lots of the new C#7 and 8 features are trying to bridge that gap to reduce allocations. Writing that level micro optimisation is going to be difficult in any language
I'm not really sure what he is talking about there either. It is possible that he is talking about some esoteric bug that has been fixed in the 8 years since that article was written
I like to use a [domain-driven design](https://en.wikipedia.org/wiki/Domain-driven_design) approach and I often think about it in terms of an onion architecture, start at the centre and then move outwards. The centre domain objects are the 'things' of the system, they provide the language that the next layer will use to express what they are trying to do but (for me at least) don't often do that much themselves. The next layer, domain services, are then the layer that take that language a do something with it. Both of these layers should be independent of all other concerns, i.e. you still aren't thinking about how you might be reading or saving data to a database. Finally the outer layers are then taking those services and connecting (composing) them with external resources, triggering them to run etc. Take a practical example of Netflix, there is a language that you would use to describe their business: Accounts, Users, Films, Shows, Series, Episodes. There are then services that operate on those objects, a recommendations service for example that would take a user's viewing history and some big old correlation matrix and spit out the recommendations. The next level up would take that service, and then something else that can get that users history and the other data needed to generate them Design is one of the most difficult problems there is and everyone is going to have their own process that works for them. The way to find yours is to read as much as you can, practice, and then when you eventually hit something that doesn't work try and analyse why it happened and what process you can use to prevent it happening next time
I've made a little DiscordBot that will play a TextAdventure game with the user. [https://github.com/RMSteenwijk/StoryDiscordBot](https://github.com/RMSteenwijk/StoryDiscordBot) The story is very short but all the functionality is there. I'm hoping for some feedback on my code or somebody with actual writing experience to maybe produce a story.
The Soap operations can be wrapped in a service. All the Soap-specifics will be handled in this service and your app only need to worry about "GetSomething". ```cs public class SoapService : ISoapService { private bool _isConnected = false; private bool Connect() { //Connect var connectRequest = new ConnectRequest //Initialise Connect Request { ID = AppSettings.Id, Token = AppSettings.Token, Username = "Username", Password = "Password" }; var connectResponse = _soapClient.Connect(connectRequest); //Get Connect Response if (connectResponse.ErrorCode &gt; 0) //Check for errors { _logger.Log(connectResponse.Exception); throw new ConnectException(connectResponse.ErrorDescription); } _isConnected = true; return true; } public string GetSomething(int id) { if (!_isConnected) { Connect(); } var getSomethingRequest = new GetSomethingRequest { ID = AppSettings.Id, Token = AppSettings.Token, SomethingId = id }; var getSomethingResponse = _soapClient.GetSomething(getSomethingRequest); if (getSomethingResponse.ErrorCode &gt; 0) //Check for errors { _logger.Log(getSomethingResponse.Exception); throw new GetSomethingException(getSomethingResponse.ErrorDescription); } return getSomethingResponse.Data; } ``` You would need try/catch around GetSomething to handle errors. It can be as simple as ```cs try { var text = _soapService.GetSomething(3); } catch { Alert("We're sorry, but something went wrong."); // Don't need to handle error details here because the error has already been logged. } ```
What are the arguments for that?
It actually exists, unlike "Ryder".
No, i got the Joke. I mean why is it better then VS.
I didn't say it's better.
I just discussed this with a colleague. In .Net core Asp.Net behaves the same as Console in regards to SynchronizationContext. They both have the default one- meaning they run on a Thread Pool.
That's not the only advantage. It also allows non js devs to build web apps without learning new skills / using libraries they're already familiar with.
I love your comment thank you stranger
I love you both
If it's your machine, I'd recommend putting windows on it. You're developer experience will be much less frustrating if you use Visual Studio. That said, if your willing to be frustrated and insist on staying in Linux, you can use Visual Studio Code.
Hopefully this will change with span.
Because the tech is brand new? IIRC blazor is around one year old, and it has still to hit release version. Doing a video game takes quite some time (or at least in my small experience), and I would guess a video decoder isn't the first thing you think about when trying a new tech. WASM is obviously older, but I don't know what has been done with it.
Creating extension methods for DbSets and IQueryables that encapsulate complex linq chains are a good place for this. The advantage of creating them as extension of the chains is that you can make composition of compositions. A repository pattern makes imposible further composition. Repositories might be useful when you want to create a demarcation in your app to disallow further extensions. But but extension methods and controlling accessibility of method can give you miles before having to resort to yet another data access metaphor on top.
[https://www.amazon.com/HTTP-Programming-Recipes-C-Bots/dp/0977320677](https://www.amazon.com/HTTP-Programming-Recipes-C-Bots/dp/0977320677) This book is old (and I think it may be available in a PDF version), but the information is still current :D. It may be a good place to start for your specific project. &amp;#x200B; You can use C# for anything you can think of that will run on Windows. To put it a different way, C# is an excellent choice for nearly anything that can be done on the Windows platform (and some stuff on other platforms); and the few things you don't want to do in C# you want to do in C++, which can interop with C#. &amp;#x200B; The .NET ecosystem (which C# is a part of) is rich, and general purpose. Have no fear, jump right in. It's quite a journey.
Thanks for the code, but if I'm reading your response correctly, I think I failed to explain my problem correctly. I think you have solved the issue of optimising calling the same method multiple times. If I had to call Connect from 100 different places in my code then this would save me lots of effort. The problem I actually have is that I have 100 different methods that all require the same fields - ID and Token and all return an Error ID and Description, but all have other, different, fields that are required as well. I thought about using interfaces but as far as I can tell I'd have to write an interface for every method - which wouldn't save me time in the end. I'm actually thinking now I'm getting too caught up in *this* problem, which isn't the actual problem I need to solve - in the end writing out the save variables 100 times is painful but not problematic.
You do realise making a game takes longer than Blazor has actually existed right? Plus it isnt even in release yet so a lot of developers wont even touch it for production use.
I get your point, its just that I got frustrated looking for ways to decode RTSP stream inside the browser. And with all the hype around it, there ought to be something created using it which actually showcases its usability.
You could try [Unity 3D](https://blogs.unity3d.com/2018/08/15/webassembly-is-here/) which will compile c# into wasm
&gt;The whole point of client side c#, c++ was to get better performance. This premise is flawed in many ways, including: * C++ existed before JS * C# is a significantly different language than C++ If you're saying that the point of C# and C++ _on top of WASM_ was better performance, that makes more historic sense, but I'd still contest it. I would also contest the implication that JS performance in the browser is poor. By JIT standards, JS is actually fairly optimized these days. &gt; Has Blazor managed to achieve that? No. Blazor is currently interpreted. That makes it _very_ slow compared to JS. It will at some point be AOT, which should yield a massive performance boost, but we're not there yet. And performance isn't the point of Blazor. Having an SPA framework that uses C# instead of JS is. You can use (much of) your existing .NET code, and that of others, through NuGet dependencies, code snippets, etc. &gt;Why don't we see games/ video decoders written in wasm yet? Because WASM is really new, lacks tons of crucial features (any threading at all is _barely_ there at this point), and isn't necessarily faster than JS.
&gt;IIRC blazor is around one year old, and it has still to hit release version. Doing a video game takes quite some time (or at least in my small experience), and I would guess a video decoder isn't the first thing you think about when trying a new tech. Blazor also doesn't make sense as a basis for a video game. You want to use the lower-end Mono/WASM code directly.
Well, don't hesitate making one :)
Thanks, this is the answer I was looking for.
Great job! Any reason you chose UWP over WPF? And if you need help for translation to other languages ping me!
/u/FizixMan please ban this spam-bot.
This looks great!!
Looks great!
You should check out [Notepad2](http://www.flos-freeware.ch/notepad2.html) it's a direct replacement for Notepad but hasn't been updated in years. One nice feature is that the UI can be customized so that it looks exactly like Notepad or you can optionally turn on more advanced UI elements. For me it's the standard that any other Notepad replacement would be competing against.
Have you chosen Xamarin because you have the most experience with C# or because you want to focus/show that you can build a multiplatform application? :) Could you try to explain what you have worked with before? I would also point out that this could be done with a web-app and that a lot of people are moving towards web development instead of application development right now.
C# is the language I'm trying to stick too, as I have a habit of constantly changing and not fully getting used to one language :) I have knowledge of alot of C# language itself, but not much when it comes to database stuff or anything like that. If you think a web app would be easier to do, then is there any advice on where to start with that? As This project is just getting used to the language more than proving I can make a certain type of application :)
If it were, then I would make .Net Core ASP.NET MVC project with EF to either a MySQL or MSSQL for database. And then a simple CRUD setup (being able to Create, Update, Delete and Update) the collection of coins. Here is an example of a project that could is similar: https://docs.microsoft.com/en-us/aspnet/core/data/ef-mvc/intro?view=aspnetcore-2.2
Because Rider actually runs on Ubuntu...
Thanks for your help and the link, I'm new to all this so had no idea where to start :)
This ^^
Also... why not Xamarin? Could have had iPad, Android, and Mac support, and I don't see anything here particularly platform-specific (but also I'm not a Xamarin guy so please don't roast me if the answer is obvious!)
The get-request from memory (untested): // GET: Categories/Edit/5 [Authorized] [HttpGet] public async Task&lt;IActionResult&gt; Edit(int id) { // check if the requested category exists var category = _context.Categories.FirstOrDefault(c =&gt; c.Id == id); if (category == null) { return NotFound(); } // check if the user is the owner of the category var applicationUserId = userManager.GetUserId(User); if (category.ApplicationUserId != applicationUserId) { return Forbidden(); } return View(category); }
Oh, look at Mr. Wishes-They-Were-Still-A-Mod over here. You had your shot. You can't tell me what to do! (I'll get to it in a bit, don't have access to a real computer at the moment. I really despise these useless bots.)
Yup, i mean C# can perform almost as well (if not as good) as C++ in many use cases now. I believe you can build C# straight to a specific target's assembler now (can't remember), if so, maybe that does help performance, but certainly not portability.
It's beautiful!
What about my situation? Every user is registered under some location or set of locations (closed registration). When querying for data sets, we always want to filter the results down to the set of locations relevant to the user. Basically every piece of data is tied to some location. Writing this from scratch, our approach has been to implement a generic repository that implements CRUD and pagination. This repository also has a hook that you can override to specify how a resource is connected to the locations. Then when a service calls the repository, the location-based filtering is automatically applied. The alternative would be every service method having to apply this logic, and even if you had it in a common method/extension, it would still prone to being omitted by accident. Is this a reasonable use case of a generic repository? Or is there an alternative that ends up being equally as convenient that I just haven't seen yet?
Thanks for the detailed response! Do you have any read recommendations, building DDD apps using .net core?
I've been putting a bunch of time into my CSV parser [Cursively](https://airbreather.github.io/Cursively) ([GitHub link](https://github.com/airbreather/Cursively)). It's on version 1.1.0 now, and I'm planning a 1.2.0 release sometime soon that makes it easier to use with various different input sources. It works directly off of the input bytes, assuming UTF-8 or other strict supersets of ASCII, and I've designed it so that it looks at one chunk of the input at a time, feeding slices of the input directly to an instance of a visitor, which can then implement whatever processing it needs. This design allows it to scan through `worldcitiespop.csv` (a popular benchmark for CSV files) with [over 15x the throughput](https://airbreather.github.io/Cursively/benchmark-1.1.0.html) of Josh Close's popular CsvHelper library on .NET Core 2.2, and it also gives the caller a straightforward way to defend against malicious attacks that might try to upload a stream of just a billion 'a' characters to try to run the application server out of memory, or else a billion fields on a single line, or something like that. So far, this has been a really fun exercise in spans and micro-optimizations that actually have a measurable impact on throughput. I've also learned a lot more about text processing... way more than where I was before I started on this journey, which I would classify as just the contents of [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses), and it made me even more of a proponent of [UTF-8 Everywhere](http://utf8everywhere.org) than I was before (I have no affiliation with the owners of that website).
this looks great wd. shame i'm still running 8.1
That sounds like a good approach. Your ApiHelper class can handle the code for building and sending the request with an HttpClient or RestSharp, and the logic classes can handle input validation and any other logic before/after the API call. Inject those classes into the controller, and define the api urls in appsettings.json.
How much longer the app starts now ? +5 or +10 seconds, UWP/WPF same story, bloated and slow Design itself looks good, some UX/Readability issues, but it is getting there
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/unity3d] [I'm having trouble matching scrolling speed of environment to match my character (Infinite runner game)](https://www.reddit.com/r/Unity3D/comments/c7tkko/im_having_trouble_matching_scrolling_speed_of/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Look up the "Unity", it's a cross-platform video game engine.
I'm not sure that last version of .net core has option to build desktop apps for the macOS. But you able to creating web application with .net client and server side.
Neat library. I have a few more or less biased suggestions: - I'd place the assembly-attribute in a dedicated file, instead of a "seemingly random" file. A `AssemblyInfo.cs` file is common for this. - Your formatting is... Bad. :-P Very biased, but why not stick to the formatting that almost all C# projects use? - None of your types and methods have XML documentation. While it may be obvious for most cases, it's still nice to have. - You don't validate any of your input. It's nice to have the arguments validate, and crash early and hard (throw an `ArgumentException`). - `SpanReader.memory` and `SpanWriter.memory` can be made `readonly`. - In your `SpanReader` and the second `SpanWriter` constructor you use `this`. You don't do this anywhere else. Keep it aligned. :-) - Three-letter acronyms are usually written in camelCase or PascalCase, not all upper case, so prefer `Utf` instead of `UTF`. same wit `Ascii`. This is part of the official Microsoft naming guidelines. https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/capitalization-conventions#capitalization-rules-for-identifiers - Why not make `SpanWriter` and `SpanReader` structs? Then you can store and operate directly on the `Span&lt;byte&gt;`, instead of having to create an entire copy of it.
Please use Pluralsight! I've used it solely for this reason and it's perfect if you already have code experience. The lessons are actually built so you can skip the junk you already know (but make sure to read the lesson plans bc C# is more intricate than js). My other advice to everyone who asks me, is to come up with an actual project - Mine was a mobile app with Xamarin (oof), but Unity sounds fun or just whatever interests you the most. Learning code can be boring, but building your own project as you go gives you the motivation to research outside of what's being 'taught.' Gl. Hope your journey goes well.
For example, code that mutates a shared non-thread-safe object such as a list from two different async methods at the same time will work fine in GUI and ASP.NET applications, but may fail randomly in console applications. private static List&lt;int&gt; values = new List&lt;int&gt;(); static async Task Main() { Console.WriteLine("Started"); var task1 = ReadValues(); var task2 = WriteValues(); await task1; await task2; } static async Task WriteValues() { for (int i = 0; i &lt; 1000; i++) { for (int k = 0; k &lt; 1000; k++) values.Add(k); await WriteLogMessage($"Values #{i} written"); } } static async Task ReadValues() { for (int i = 0; i &lt; 1000; i++) { int sum = 0; foreach (var value in values) sum += value; await WriteLogMessage($"Sum = {sum}"); } } static async Task WriteLogMessage(string message) { await Task.Delay(1); // pretend we're writing it asynchronously to a file or smth Debug.Print(message); } &gt;My another surprise was AspNetSynchronizationContext: it awfully acts like default context (for example like Console). -could anyone explain what's the practical difference? The (pre-Core) ASP.NET sync contexts use random threads from the thread pool and multiple threads may be involved in processing a single request, but the sync context ensures that there's never two threads working on the same request *simultaneously*.
Is it possible that execution is finishing extremely quickly and it just seems to not be finishing? Whatever you’re trying to do, it doesn’t seem like the spawned threads are doing any work.
If I'd be a mod again, I would definitely clean up and keep order. There mus be order!
Thanks for clarification, much appreciated! 🙂
Thank you for the reaction, how can I fix this?
Starting a new project in a new technology is always pretty hard. It's easier if you've already completed the application in another technology first, that way you don't have to do both design work AND learning what's realistic in your framework at the same time. What *have* you used before? Windows Forms? WPF? Why are you concerned about "the database part"? Is that a new frontier too? I ask those questions because developing for a mobile device is frustrating. The build/deploy times stink, the Android emulators stink, the iOS simulator requires a Mac, deployment is a process, iOS requires an annual fee to keep the app alive, etc. If you are used to working on a Windows machine, it's a lot easier to work with a Windows application or a web application. And Xamarin is a lot easier to explain if you've already cut your teeth on some other GUI framework. I'm similarly concerned about the suggestions to write it as an ASP .NET Core app. That'll mean you need to look into some hosting solution for the website, don't discount that complexity. So let's step back and ask about the real requirements. Does the family member use a laptop already? Would the app work just as good there? If not, then we've got a strong case for web/mobile. If so, you'll probably get it done faster for them if you don't start with the Xamarin version. (This is also anecdotal experience. When I was big into Magic: the Gathering, I had tools on both iOS and Mac to help me with the collection. Since I was sitting at a big table surrounded by cards when organizing, it was easier to use a laptop than the iOS version. The only time I preferred the mobile version was when I was at a tournament and needed to answer quick questions like, "Do you have any copies of this card?")
This is really weird, why are you mixing TPL and invoking threads manually? This is going to give you problems. Is there a reason that you can not just use the TPL interface?
https://i.imgur.com/WGv9Tvd.png
yeah so do a if or check statement or task it to monitor the application for its exit, so you have it able to capture the opening of the application, great that part is done, it writes that down and then you need the next process to monitor the application for exit which you can have it check for every few ms or so until it sees the application exit. and then records that. &amp;#x200B; use use the AppDomain.ProcessExit event. though if your monitoring the applications for a unhanded exception then you would need ***AppDomain.UnhandledException*** Event.
I've worked with windows forms before, not too much but enough that I could justify using that. As for where they would use it, mobile would probably be where they would use it, as not often do they sit down and use the laptop. He would probably want it with him so he can check coins on the go. I've worked with databases before but not combined with C# (I used PHP as part of a university project) so wouldn't be sure how I would go about that, unless not using a database at all and finding another way to store the information? The Magic: The Gathering tools you talk about sounds similar to what I am looking at, just with coins instead of cards. What did you use to develop that?
What exactly are you trying to do?
Please reach out if you have any questions. I've made a couple of projects by the same fomula and also have experience with posting files(or more specific, images) when you come to that.
Xamarin.Mac allows you to build GUI apps for OSX, and .NET Core Console apps will run on OSX. https://docs.microsoft.com/en-us/xamarin/mac/
If you're using HttpClient, then using IHttpClientFactory is a good way to go. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/http-requests
You are on the right track with reflection. These are properties which are only common in name, not symbolically, so it has to be reflection. How about something like this: var SC = new SoapClient(); var commonValues = new CommonValues("someId", "someToken"); var connectRequest = new ConnectRequest { Username = "Username", Password = "Password" }; var connectResponse = SC.Connect(commonValues.Set(connectRequest)); CommonValues.ThrowIfError(connectResponse); CommonValues.ThrowIfError(SC.Disconnect(commonValues.Set(new DisconnectRequest()))); public class CommonValues { private readonly string mId; private readonly string mToken; public CommonValues(string id, string token) { mId = id; mToken = token; } public T Set&lt;T&gt;(T request) { typeof(T).GetProperty("ID")?.SetValue(request, mId); typeof(T).GetProperty("Token")?.SetValue(request, mToken); return request; } public static void ThrowIfError&lt;T&gt;(T response) { var errorCode = typeof(T).GetProperty("ErrorCode")?.GetValue(response) as int?; if (errorCode &gt; 0) { throw new InvalidOperationException($"Error {errorCode}"); } } }
Thanks for your feedback! Can I ask some follow-up questions? &gt; Your formatting is... Bad. :-P Very biased, but why not stick to the formatting that almost all C# projects use? What do you mean by that, exactly? &gt; Three-letter acronyms are usually written in camelCase or PascalCase, not all upper case, so prefer Utf instead of UTF. same wit Ascii. This is part of the official Microsoft naming guidelines Yeah, I bounced backwards and forwards on that. I ended up going upper case to match System.Encoding.ASCII/System.Encoding.UTF8.. MS should follow their own guidelines The rest of your feedback is very interesting, I think on it some more and might incorporate it!
&gt; What do you mean by that, exactly? Mostly the Egyptian braces. &gt; Yeah, I bounced backwards and forwards on that. I ended up going upper case to match System.Encoding.ASCII/System.Encoding.UTF8.. MS should follow their own guidelines Backwards compatibility. The types predate the guidelines.
I am new to C# and trying different threading methods, this one is the fastest but it crashes. TPL?
+1 for Rider by JetBrains, it's OS agnostic and haven't found a reason to go back to VS in the year or so of using it.
Hi, I am new to C# and I am trying different threading methods right now. In "Worker" I wrote these line: console.writeline("test"); tested++;
This work for me thanks &amp;#x200B; // GET: Categories/Edit/5 public async Task&lt;IActionResult&gt; Edit(int? id) { // Fail early here, no reason to check the DB if // the user doesn't include the right information if (id == null) { return NotFound(); } var currentUser = await _userManager.GetUserAsync(HttpContext.User); // First, look up the category the user is attempting to access var category = await _context.Categories.FindAsync(id); // Check that the category the user is accessing belongs to them if (category.ApplicationUserId != currentUser.Id) { return RedirectToAction(nameof(Index)); } return View(category); }
Using DDD to design an application should be (programming) language agnostic. A better way to phrase that question would be: "Do you have an read recommendations for designing applications using DDD?"
I'd say your best starting point is: http://dddcommunity.org/
You create a task, that task starts threads, then the task is done. The task will not wait for the threads to finish working.
Shame I can only upvote this once.
&gt; It also allows non js devs to build web apps ~~without learning new skills /~~ using libraries they're already familiar with. Fixed that for you. JavaScript may be scary to statically typed language fans, but the real learning curve is the insane HTML/CSS model.
You have to try it before making that conclusion. It starts immediately with no delay or loading screen except for the very first time. The store version is in review and will be available pretty soon.
If you're using Dapper, you should only create classes that express the outputs (and probably inputs) of your DB calls. So if you're calling a stored procedure, then you'll want a class that mirrors the columns returned. If you're calling a SELECT col1, col2 col3... Then you want a class with just those columns.
Presumably because UWP makes more compatible with .Net Core. WPF and WinForms won't be supported on core until 3.0
+1 for Rider, with VS Code a close second.
Because EF allows far greater developer productivity, compile time checking for database interactions, find all references benefits, much easier \`IN\` clauses when necessary without security concerns, and allows huge flexibility in composing multiple \`Where\` clauses without having to do manual text manipulation.
If you want to do GUI apps for a mac you can use xamarin. Command line programs or if you want to do your own gui from scratch using opengl or whatever, then yes with dotnet core you can do that.
&gt; Mostly the Egyptian braces. They're hideous. Hahaha, I actually far prefer them. IMHO, as long as the code is readable, it's not a big deal. &gt; Backwards compatibility. The types predate the guidelines. Fair play; I'll standardise these
OK, it sounds like you have a good reason to write a mobile app, which makes Xamarin a good choice. RE: the database, I'm not the best for advice. But I do know you'll be limited either to a local SQLite or "access a hosted something else via a web API". Local SQLite works offline, but if you want to sync between many devices you have to write it. Remote "whatever else" gives you options and syncs, but you have to deal with hosting a DB and an API somewhere (and will probably end up implementing offline support at some point.) Past this I'm not a good source of advice. People tend to want to use an ORM these days but I haven't shopped for one of those on Xamarin in a while. Your needs sound pretty simple so I'd be willing to bet local SQLite with even a bad ORM is sufficient. (If you're unfamiliar with what ORM means: it's a tool that abstracts some of the DB work away from you. It lets you say "save this object" instead of "execute SQL that updates this row". EF was really popular, I believe ASP .NET Core is moving away from EF, I don't know what the cool kids are using right now. For complex reasons, I had to write my own SQL the past few times.) For Xamarin itself, just start following tutorials and writing apps. Read about MVVM. Ask questions about MVVM. People get really hung up on it, and I get it. It's super easy. It took me more than a year to "get" it. I can't figure out why. But I see a lot of people struggle the same way I did, so it's probably the biggest hangup. I'll end *this* post here, and reply to it with a short MVVM tutorial because I feel compelled. I wish I could point you at a "good" jump-in Xamarin tutorial, but I don't feel like Xamarin's quite mature enough to work on newbie docs yet. They're still iterating and producing new features, so what we have is sort of initial tutorials they wrote, then broke, then rewrote, then broke again, then gave up because it's moving too fast. :/ The MtG tools weren't written by me, I bought them. But they do sound similar!
wasnt there some sort of default new windows 10 app for code writing that was like basically an improved Notepad? I think it was called like "Code Writer" but IM not finding it on my machine anymore
# Quick MVVM The best way I can describe it in short is in terms of WinForms. In WinForms, you (tend to) put controls on a Form, handle their events, and generally when a button or some other "finished" thingy is clicked, you gather all the data from all the controls then work on it. Everything is in your `WhateverForm.cs` file. That's actually *really bad* as apps get bigger and most people never graduate past it, partially because WinForms has no widespread tools to help you do things differently. So how's it work in MVVM? The 'View' is a XAML file that has the controls on it. Controls that represent data like text boxes "bind" their properties to another property on an object the View doesn't know about other than "it has a property with this name". Controls that represent actions (like buttons) have a `Command` property that binds to a property that implements a "command", which is just an object with an Execute() method on it. (So "commands" are just how MVVM does events, this is only because binding is important to MVVM but only works with properties.) That "object the View doesn't know about" is the ViewModel. It has properties the UI is expecting to bind to and usually implements `INotifyPropertyChanged`. The properties for the data controls raise the event if they change. There are properties for the action controls that present Commands to do stuff. But outside of "I need these properties", the ViewModel doesn't directly reference that XAML view or any of its controls. So how's that work? In WinForms, you *had* to have a control reference to update a TextBox. How's a ViewModel get a value from the XAML if it doesn't know about that XAML's controls? How's the XAML get the values from the object if all it has is a property name and not a referende, that's Data Binding, the silent DB in "MVVM". XAML Views have a special property named `BindingContext` (`DataContext` in some frameworks). It is of type `object`, and that's what holds a reference to the ViewModel. Since it's `object`, it can be *any* object, even one without the right properties. That's not an error. Binding just won't work if you do it. The TextBox of XAML is named Entry. When you say, "Bind your Text property to FirstName", there's a lot of invisible WPF/Xamarin code that does this: * When the BindingContext property changes: * Check if it has a 'FirstName' property. * If it does: * Set the Entry's Text value to the current value of that property. * When the Entry's Text value is updated by the user, set the BindingContext's FirstName property to its new value. * If it does, AND implements INotifyPropertyChanged: * Handle its property change event so when its 'FirstName' property changes, this Entry is updated with the value. That's the magic. There's an invisible layer of code in Xamarin that connects the two. If you've ever seen the MVC pattern, it's sort of like MVVM writes the Controllers for you. In theory, since the ViewModel doesn't reference any XAML types, you should be able to write unit tests against it. So you can test, "If FirstName is blank, and I execute SubmitCommand, the Error property should be set to this value", and such. There's another 'M' there, the "Model". I find in smaller projects you might skip this step. "Model" types are data types that don't work well as ViewModels. Maybe they don't implement INotifyPropertyChanged, maybe they don't work via properties. But sometimes you have to implement them because some library you're using needs them. When these exist, part of the job ViewModels have to do is adapt their not-friendly API to something the UI can bind to. In really pure MVVM implementations, you ALWAYS have pairs of Models and ViewModels, even if the VM just wraps the Model. I find in most simple projects that kind of guideline feels stuffy. I'm oversimplifying a lot, and hiding some places where it doesn't work so well. But if you know nothing else, it breaks down like this: * The View == the XAML file, which is basically the .Designer.cs file from WinForms. You don't write code here, you describe UI, where it gets its values, and what commands it invokes when user actions happen. * The ViewModel == something that implements INotifyPropertyChanged for binding. In WinForms, this is like "everything you would've put in event handlers". It does work to keep the properties coherent/validated, and also responds to commands the View will execute. * The Model == something that was designed for your domain rather than to be a ViewModel. There's no rules here. * Data Binding == the thing that magicaly connects a View's bindings to a ViewModel's properties.
They are however making plans to include AOT. This will allow you to compile performance critical code straight to wasm rather than having it interpreted by the mono wasm. Not sure when this is coming, or how perfomant it will be, but in one presentation I saw, the release build of the wasm c# assembly closely matched the debug build of a native c# assembly. So not perfect performance, but I think faster than JS. The reason we don't see much in Blazor is that it is really new and just only went into preview. It needs some time to mature.
* There isn't any, your best bet is just use a C++ tutorial and translate as you go. * yes it is possible to create a slider in oepngl * consider using monogame, it may suit your needs, be more flexible, easier, and there are tutorials available
So firstly, I would not pick UWP if you ask me "now" instead of a month ago but at the time when I started, I was thinking about these: 1. I have not done anything with UWP yet so I just want to give it a try. 2. Easier to implement/tweak UI that feels Windows 10 comparing to Win32/WPF. 3. Easier to push it to Microsoft Store. 4. .NET core 3 and xaml islands are coming pretty soon and I can reuse what I have and migrate it to Win32/WPF with UI remains the same in the near future. 5. I did some experiment before I started and UWP app can launch instantly without splash scree. (If it takes time to start/launch, I will definitely go Win32/WinForms/WPF instead) 6. You can easily do theme based UI customization in UWP comparing to WinForms/WPF. 7. Better DPI support and pen support. (Yes, my app supports pen input and I can add ink type of note easily)
Ah sorry another question I had: what were you referring to when you were talking about guarding against arguments? I'm on mobile now but I can't remember anything which really needed to be guarded against; apart from maybe a negative cursor value?
No, that is thrid-party app.
&gt; JavaScript may be scary to statically typed language fans, but the real learning curve is the insane HTML/CSS model. bruh
Be an /r/pcj mod instead 🤗🤗🤗
The CLR hasn't changed significantly since. Net 2.0 was released. So while I haven't read that particular book I see no reason why it wouldn't still be just as relevant as it was when it was first written
Great job, looks cool. Does it handle big files well?
No, not for now. The app is intended to to lightweight editing anyway. I will investigate big file support later this year after I finish my planned features.
I found this article: [https://stackify.com/creating-net-core-windows-services/](https://stackify.com/creating-net-core-windows-services/) However, it mentions that a "Windows service" uses a lot of "windows" proprietary libraries and such. The method described in that article will produce a .net core service, but I don't think it would be Cross-Platform. &amp;#x200B; You might have luck creating a single command line application that is cross platform compatible, then creating a windows service using .net framework and using the .net framework windows service to execute the commandline argument in windows and maybe a chron job in linux... basically, just the part that automatically starts the application would have to be platform specific.
AJAX = Asynchronous JavaScript And XML Which is a misnomer as JSON is used *so much now*. When AJAX was introduced, XML was used almost all of the time for structured data.
Looking at the first ~100 lines of the 1GB+ file is a valid usecase for a lightweight editor for me personally - I often need to understand the data format in some CSV or NDJSON file. I guess I'll try to implement something like that myself ;)
Dependency injection is key to being able to unit test easily. Start there.
TPL: Task Parallel Library. All of the things that have to do with 'Task'.
Do you have a list of bots that use your nuget/code for their bot?
This is absolutely beautiful and needs more than just a couple hundred upvotes
Unless you're writing a library, you shouldn't use System.Threading directly at all. System.Threading.Tasks is intended for efficient asynchonous and parallel execution without having to deal with the overhead of managing threads directly. &gt;this one is the fastest but it crashes. What other ways did you try?
For existing code you can write tests that verify the current functionality. If you have products that are working, but are legacy, then a key goal in refactoring them is to not break the currently working features. For new features, I recommend looking into [Test Driven Development](https://technologyconversations.com/2013/12/20/test-driven-development-tdd-example-walkthrough/) if you aren't familiar with it. I use NUnit for testing and keep my test suite as a separate project in the solution. From there I test only the code that is intended to be public and I do my damn best to follow [Uncle Bob's rules of TDD](https://blog.cleancoder.com/uncle-bob/2014/12/17/TheCyclesOfTDD.html). The reason for only targeting my public functions is because, theoretically, I shouldn't have any code scoped protected/private that won't get called by the public methods if I'm designing my code correctly. Another thing that I find helps when working with interfaces is to create abstract classes to serve as my text fixtures that test the _specific behavior_ of the interface. Once I've defined the behavior properly then I can create child classes that extend the abstract class and instantiate the appropriate concrete class. Helpful in cases where you know the implementation for an interface will be (or will have the potential to be) swapped.
FYI: Text sharing tools like [PasteBin](https://pastebin.com/) are usually preferred to screenshots.
&gt;tested++; This isn't thread-safe. Reading the value of tested and incrementing it are done as separate operations, and a thread can be context switched out between the read and write, so you can end up with behavior like: Thread 1 reads tested as 0 Thread 1 writes tested as 1 Thread 2 reads tested as 1 Thread 3 reads tested as 1 Thread 3 writes tested as 2 Thread 2 writes tested as 2 Use Interlocked.Increment(ref tested) instead, which increments tested and returns the result as an atomic operation (one unit of CPU work that can't have a context switch happen in the middle of the operation).
There are some good courses on Pluralsight around this topic, including some older ones by K Scott Allen on TDD (or as it was titled Test First Development). The concept of TDD (Test Driven Development) is that you start off with the tests before you write your code and refactor to get a working test. It's an interesting concept that I'm still trying to get my head around properly, with advocates on both side of the fence, some saying it's a waste of time and others (like Robert Martin) going as far as saying if you're not doing TDD then you're not a [professional developer](https://www.infoq.com/interviews/coplien-martin-tdd/)
Overall still very relevant. Some minor details here and there are no longer true but if you're trying to step up your game from junior to intermediate CLR via C# is still a good place to start.
Thank you for your advice and the explanation, SQLite sounds like it may be a good choice for this task and will look into that for the database side :) and the MVVM I will definitely try to follow :)
Thank you!
Its crashing becuase you are not following the intended use case. Tpl should be used above threading manually. Look at Task parallel library. Its the task object you are using. Spawn a task per unit of work. The scheduler will take care of managing the thread pool. The default scheduler does a pretty good job of balancing context switches vs. Performance. You should be correct before being fast. Otherwise you'll waste time chasing optimization of the wrong solution.
I think your point makes perfect sense. I will do it this week or next week to have something like showing first 500kb or 1MB and make it read-only if you are opening with large files.
What do you need core and infrastructure for? Web API is your infrastructure. Embrace it.
Not an easy topic to answer as there are many facets to this seemingly simple question. The biggest hurdle will be changing the culture and mindset of any developers that work on that code base. &amp;#x200B; Obviously the developers don't unit test, and almost assuredly the code is tightly coupled. This means not only do you have to convince them to write unit tests, but to also write code to be unit testable. It can be hard to do. To make matters worse, you have a code base of n-number lines of code that would need to be addressed as well. &amp;#x200B; I think the size, age, complexity, and architecture will almost certainly dictate which direction you go. I'll give you a quick summary on how I solved this issue. &amp;#x200B; The code base I am responsible for is a line-of-business app that predates even .Net. It was "converted" to .Net 1.0 in 2002 from VB6, and since then has been upgraded with every traditional version of .Net. It has about 110 projects in one solution that encompasses 2.5 million lines of code, and is pretty tightly coupled. &amp;#x200B; I decided the best path was not a one-size-fits-all but rather a hybrid approach: 1) If code is completely new, then this is best case scenario as you can just simply write your code to be unit testable and loosely coupled from the very beginning. I also put in place coding standards that makes immutable method parameters a default. (There is no auto enforcement of this rule though). In the event your method does make a change to the parameters, the type and scope of changes needed to be documented in the "remarks" tag of the method comment. What this basically means is that you pass in only what your method needs and it returns whatever it was asked to do as a new object/value. Since that's not always feasible some allowance is made to modify values in a collection. (My system does very heavy financial calculations and involves many hundreds or thousands of values). &amp;#x200B; 2) It was decided to not test the actual data layer since it comprises of either [ado.net](https://ado.net) or various versions of EF. The testing of "persisting to data store" is done with automated integration testing. &amp;#x200B; 3) Changes to legacy code has two approaches, depending on scope. If "a lot" of new functionality is to be added, a new "companion project" is created and written in the manner of #1 above, and the legacy code can just call it by adding a "driver method" in the original code. This is needed because in our case, the architecture of the legacy code depends on having "all data available at any point." It's one of those "what happens when you write procedural code in an object oriented language?" examples. What I mean is that you end up with a class that is 35,000 lines long with properties that serve as "global variables" from days of yore. &amp;#x200B; The second approach is if little changes are needed to legacy code, refactor those methods to look like #1, and when you have deep call stacks and cannot refactor all of them, use a mock framework (Moq in my case). &amp;#x200B; Other thoughts: If you need a database connection to unit test, you're almost certainly doing it wrong. Write unit tests even for cases you think "can't happen." For instance, if you are passing in a decimal, write unit tests for when that value is negative, zero, and positive. If it's nullable, add that one too, even if you think there is no way the method could receive a negative value (for instance). &amp;#x200B; Add the running of unit tests to your build, or you will almost assuredly find that the tests slowly start to fail and no one ever fixes them, plus, what good do you do if you write unit tests but never run them. (I've seen it happen!) &amp;#x200B; Know that adding effective unit tests will dictate in some manner how your code is architected. For example if you have a super small api surface because everything is private, well that's not super effective way to try and unit test. If you have to do a lot of mocking, you will have trouble with static structures.
use at least Dapper for data access, it is an ORM-light. You still write your own SQL, but it can help map SQL results into models easily.
&gt;Task task = Task.Factory.StartNew(delegate() { for (int i = 0; i &lt; Variables.threads; i++) { new Thread(delegate() { ThreadManager.Worker(); }).Start(); } }); Sir, thank you for your clear reaction, I understand what you mean! I fixed it with ref tested and it works smooth! Is my threading also great? &amp;#x200B; for (int i = 0; i &lt; 1000; i++) { new Thread(delegate () { ThreadManager.Worker(); }).Start(); }
Get the book *Working Effectively with Legacy Code* by Michael Feathers. The book defines "legacy code" as "code that is not tested". It covers theory and refactorings for how you can safely make seams and pull units out so you can test them and turn the legacy code in to testable code. It's going to take some time, though. I feel like a big part of testable design is having a lot of experience with what *doesn't* work, so the things that *do* work stick out better.
- Negative cursor value. - Out of bounds cursor value. - `null` reference for `string`. - `null` reference for `Memory&lt;byte&gt;`. These are the obvious once at a quick glance.
I want to have a separation of concerns. I could , indeed, use one Project Web API and separate models, controllers, data ... with folders . I know myself and I will loose the track when the project will become larger. And I want to test my layers, it’s clearer in my head this way. That’s why I thought about Clean Architecture Do you see what I mean ? May be you have a good counter example for me ;)
Ah ok thanks. Do you know of any other frameworks / libraries that are similar to OpengGL apart from MonoGame? &amp;#x200B; Also, do you how I would go about making a slider? Are there any libraries / packages I need to download?
I take it, it will be cleaner . Thanks!
Fair play, thanks! I'll go over it with a more careful eye
why is wordwrap in the context menu? theres nothing contextual about it in the text area. Perhaps the context menu on the tab, alongside "close others" ?
The simple but true answer. I also ended up in a team that wrote... Let's call it old school code. A mantra was repeated often in this team: "We want to test, but most of our code is either repositories, gateways or mapping of models to other models". So there were no tests. But that wasn't the only smell. The solutions had no inversion of control, everything was newed up whereever it was needed. Code was simple to read and understand, but every refactor was a nightmare. You couldn't change one thing without changing 10 classes depending on the thing. We introduced dependency injection using an IoC container, and slowly began to inverse control. We also began introducing interfaces where needed so that we could have multiple implementations for stuff. Slowly but surely, magic happened. Once in a while we'd be able to test something we hadn't before. Then another thing. And another. It turned out the problem with unit testing wasn't due to the nature of the code, whether it was a repository, a gateway or something else. The problem was that there was nowhere in our code-base that we could break in and unit test. Since everything was hardwired to a specific database or a specific endpoint, we couldn't test anything without messing up our environment. When we inversed control and were able to abstract dependencies away, that went away. That said, the solutions are big, and even today we don't have the test coverage we should. But you have to start somewhere to get in the right direction.
It is a button for quick text wrapping change for the selected file. Your point makes sense tho. I do have plan to create a right context menu on the tab. Maybe I should move it there once I have that. I will think about it.
The example project you linked isn't using Unity. The functionality is probably different between the two.
Yeah I'm aware of that, his is a console project. But they are both Visual Studio C# projects behind the scenes. Do you know of any specific differences?
No prob, just trying to help keep your app as usable and within the UI guidelines as possible! https://en.wikipedia.org/wiki/Context_menu#Usability https://docs.microsoft.com/en-us/windows/desktop/uxguide/cmd-menus
Doesn't look fat to me.
This is the code from which it was decompiled from. So here.
&gt;they should be small, as they will consume memory since they get copied all over You assume that they get copied multiple times, but that's not the case. The state machine is passed by reference or boxed.
Also the code in a struct is usually not copied around either, just once instance of methods.
WPF doesn't have this sweet acrylic efect
My concerns of struct design are the following (from MSDN considerations of class vs struct): **✓ CONSIDER** defining a struct instead of a class if instances of the type are small and commonly short-lived or are commonly embedded in other objects. **X AVOID** defining a struct unless the type has all of the following characteristics: * It logically represents a single value, similar to primitive types (int , double , etc.). * It has an instance size under 16 bytes. * It is immutable. * It will not have to be boxed frequently. In all other cases, you should define your types as classes. &amp;#x200B; Size seems bigger than 16 bytes, especially since you refer to other instance from the struct! I tried making a little test with: var before = GC.GetTotalMemory(true); var machine = new DemoStateMachine() { ch = 'a', stack = new object(), text = "Hi" }; var after = GC.GetTotalMemory(true); var diff = after - before; Console.WriteLine($"DemoStateMachine size (bytes): {diff}"); and it outputs 24
This is how ours is broken down: ActionFilters Const Controllers Interfaces Logic Modes Properties &amp;#x200B; We currently use EF and the whole layer is in a NuGet package. But, if it were me, I'd use either Dapper or PetaPoco and store my parametized SQL strings as consts. That way, I would only have to change them in one place.
http://letmegooglethat.com/?q=C%23+return
Its almost as if I already did that before posting on here.... weird....
Well, the first link got a perfekt example for you. https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/return
That's what I'm looking for. Thank you.
monogame isn’t too removed from opengl, it uses opengl as the backend on some platforms. otherwise no, opentk is the thing to use. making a slider with opengl is a rather big question if you want to do it from scratch. are you doing this to learn? you might look at “dear imgui” which is a gui library that has sliders and can work with opengl.
&gt; Structs should be plain and dumb Where did you get that idea? The look limitation is based on size, not complexity. And methods do not count towards the size. &gt; they will consume memory since they get copied all ovethey will consume memory since they get copied all over No, that's kinda the point. They don't consume heap space no matter how many times they are copied. The concern is the time it takes to make the copy, and even that is often exaggerated.
That's not how you calculate the size of an object, struct or otherwise. 1. The space for local struct doesn't even go into the heap. 2. There are other things going on in the background that you cannot see. 3. You allocated a new object on line 5. That's where your 24 bytes are probably coming from.
The clients should maintain backwards compatibility with old API versions
Thank you for clarification and clearing my misconception on structs. The size on thst on is probably bigger than 16 bytes, but it's not that it matters since it doesn't get moved around that much!
So far I've read the first two chapters and this is awesome, there is much more than thread safety, a complete guide about multithreading in C#. Very helpful.
Agreed. Also considered just versioning in general, but I feel like there's a lot of overhead to versioning an API. On the other hand, it might be good to force it, because then you can start deprecating features. I think there's a ton of code that should've been killed off but hasn't, because there's no plan for killing old endpoints. It would definitely make it easier to release independently though, and has been the number one considered option.
I too have experienced problems with Nugget hierarchies. Creating a chain of dependencies guarantees a lot of confusion and deployment headaches. I found it is better to consolidate code into fewer packages.
That's excellent, thank you - this looks like a really good starting point. I was a bit scared of using reflection but this looks a lot less prone to error than what I was thinking.
Yes, Unity projects are not really “just Visual Studio C# projects behind the scenes”, the C# projects generated are only used to provide a working dev environment with autocomplete, debugging etc. The actual code is not built using Visual Studio (although nowadays it does use a Roslyn-based compiler). Since most of the Unity API does roundtrips to native code, Unity stuff really does not work outside the Unity scripting runtime, and that includes the interactive window (other than very simple code) and partly the immediate window. Partly, because when you are using the VSTU Unity Debugger, the immediate window works when you are stopped at an appropriate context during a debug session. Not all features you expect from the .Net debugger work, as it is simply not the .Net debugger.
Thanks for clarification. I've come across a Unity plugin called "immediate window". It's not as good, but it lets me fairly quickly test methods in isolation. Just a shame it doesn't have autocomplete.
&gt; And I don’t want to use Entity Framework, only sql requests Someone likes security holes. Don't write direct queries, even if you do parameterize them.
Java and C# are very similar. If your target platform is Android it might be easier to pick up Java and write native Android code in Android studio rather than trying to fight with some of the oddities of things like Xamarin. If you can read C# you can pretty much read Java straight up.
You can do this. Just localize to one language - yours.
&gt; UWP makes more compatible with .Net Core Qué?
Best practice is to keep those api client packages as light as possible. Baring that, binding redirects in your config file will help most times. Newtonsoft. Json and protobuf are particular pains in my ass though
Building up some libraries to make distributed code significantly easier. Primarily aimed at game style workloads. Lots of interacting state. Some state is constantly changing but small, while other state is large but slowly changing. Im extending the idea of Software Transactional Memory (though I just looked around, and apparently thats a common idea, so Ill definitely be looking around at them). Ive found that distributed systems seem to solve quick updates, or slow updates, not a mix of both.
Also, my variable "selection" isnt recognized in the main method either.
I'm building an app that will be used to help predict whether TV shows will be renewed or canceled, based on a variety of factors. The prediction model for each network is determined with a neural network, which is trained by a genetic algorithm, using data from the last several years of TV as a basis. Results of these predictions will be posted on Facebook.com/TVPredictions. This is a hobby I've been doing for a few years now and every year I've been trying to find ways to get even more accurate at predicting them, so I thought a neural network was a cool way to achieve that. I'm also taking this opportunity to learn UWP. While the app will only be used by me, I may later make a version for other people to download, simply to view the predictions. Might try doing cross platform for that though so it wouldn't be limited to the Windows Store.
It's not that it isn't defined, it's that not all paths set the variable's value. Make sure that the value is set before being returned.
Because the string needs to be assigned to in all cases. Otherwise, what does the method return? Also look into enums.
I just realized the one else if statement in the travelOpts method was missing. But otherwise, how woul I do this?
Enums are the next lesson. Any idea how to accomplish this
It’s declared, not defined
And how would I define it then
My recommendation is to use a switch. The default case will force the assignment to be exhaustive. You should write some tests though, your cases likely aren’t behaving as you expect.
In certain situations, like yours where the value returned is based off some logic you’ve written, upon definition you need to declare it E.G. string temp = “”; Someone else will be sure to elaborate as to why that’s necessary I’m sure
I'd rather not rewrite the entire assignment.
Sorry, new person here. What is the "obvious" reason not to choose Electron? To my understanding, VS Code was built on Electron and it's by far my favorite editor so I'm curious why not Electron. A
You can assign a value while declaring, e.g. string travel = "unknown", or string travel = null. Also, check your logic, because (numParticipants &lt;= 5 &amp;&amp; numParticipants &gt;= 10) will always be false.
What’s happened is your if else if statements don’t have an else, so what the issue with the code is, is that if none of your conditions are met, what exactly is the method returning, nothing! To resolve this set a value in the definition as I mentioned previously, or in your series of else ifs end it with an else and in that else assign a value. Long story short the method is worried it can be returning a variable with a value that’s not been assigned
The best strategy from my experience is to eliminate using internal nuget packages wherever possible. Duplicate your contracts in both code bases and make your API updates backward compatible. API versioning sucks and your team is trading easily duplicated code for dependency and versioning hell. It starts out seeming like a good idea but it gets out of hand really quickly and then you spend more effort dealing with the boat than actually doing important feature work.
Rewriting 6 if/else clauses to 2 switch/cases shouldn’t take a lot of time. I don’t know what to tell you, the code won’t work as it is, you gotta do something :\ If you do want to stick with if/else though I still strongly recommend you write some test cases. You will be surprised by what inputs are returning.
Interesting
 Good catch on the logic. The other part just doesnt make sense, I feel like I'm doing exactly what you're saying already.
Acttype have a else sentence, the travel string is not asigned because you only have else if, add a else to your conditions. Sorry my english
It’s good practice to have a default initialization on all class variables (like strings). Instead of string travel; use this string travel = string.empty; Now you have your string class initialized to a value and the error will go away.
This, or just call Stored Procedures and pass in the parameters needed
https://www.pluralsight.com/courses/asp-dotnet-core-api-building-first
* Make your WebAPI controllers simple wrapper classes around your 'real' API classes. This allows you to test your real implementations individually. * Make sure you use verbs properly and also return the appropriate status codes. Nothing is worse than using a REST api that only responds with 200 and 500. * Inject your real API classes as dependencies to the WebApi contollers, make them implement an interface so you can substitute them later, for example if you ever need to move to make use of microservices, i.e a "IProductsAPI" interface could have a "ProductsApiSqlDataAccess" and "ProductsApiHttpDataAccess" implementation - each testable individually. * Don't write a million different endpoints for different operations, for example you don't want a different PUT for changing quantity, price, title etc - you just want one PUT "api/products" where you receive a "product" model and pass it straight down to your Api class UpdateProduct method. * Use attribute routing, you don't want to use the controller/action mapping, it's inflexible and leads to some pretty terrible interfaces. * Don't go nuts with composition for your models, instead give your models ID references to other entities and have different endpoints for those operations - this will help you avoid side-effects.
&gt; Doesn't look fat to me. It's like 48 bytes + overhead on x64.. not huge I suppose, but definitely not small.
&gt; Where did you get that idea? Probably a poor regurgitation of the idea that structs are generally a poor fit for types that do not have value-like semantics, like the struct in the OP.
&gt; X AVOID These rules have been broken here for performance reasons - specifically, as /u/tweq said, to avoid allocations.
If you have to update more than one web service when your contract changes, they already fucked up. The purpose of package dependencies are to *increase separation* and simplify dependency management. If the services and clients are so interdependent, then they should just be built out of the same repo, reference the same class library projects directly, and be deployed at the same time.
 Two pointers, 8 bytes each on x64, plus a char for 2 bytes. That is only 20 and there is no overhead for unboxed structs.
Yep, this is THE intermediate text for dotnet as far as I’m concerned. The amount of concepts that you’ll learn about the underlying system you utilize is incredible.
Do you work for NVR? Lol.
Companies have made billions with games written in C#.
Sounds like our old architect. Jesus. Also sounds like Service Stack BS. That shit is repugnant, over engineered BS. Its json for gods sake, not sand script. Just document the apis and be done with it. Theres some weird hangup about re-writing code, when in fact POCOs are not code. So stop treating them that way...
You said it, man.
Nuget packages should be thought of as products. Each package should be testable in isolation, and should have releases. Like any product, you do not want to making breaking changes that affect your users -- they should be backward-compatible, and older versions shouldn't be made unusable just because a new version was released. It sounds like you've got a monolithic project that is masquerading as something more agile than it really is. Consider what a single project would look like, or maybe take a look at something in-between such as git submodules, as a good replacement. Also consider that you've only been there for three months. An outsider's perspective is very useful, but can also be uninformed. Ask unbiased questions about why things are the way they are -- they may have tried alternatives and found this ultimately has fewer drawbacks.
The issue is that the travel variable is undeclared, for a string its a weird error as that should be null, but here its asking you to specifically specify the initial value.
This worked, you are an absolute life saver! Thank you, thank you, thank you!
I’m actually in the sMe boat with you. Every time i look this up it seems really interesting and something i should implement in a dozen different ways. And then it falls apart and never works out...
Or simply don’t use the resource manager. There are ways of reading images/text etc without directly using the wrapper. You need to load it from resource stream. Bitmap bmp = new Bitmap( System.Reflection.Assembly.GetEntryAssembly(). GetManifestResourceStream("MyProject.Resources.myimage.png")); If you want to know all resource names in your assembly, go with: string[] all = System.Reflection.Assembly.GetEntryAssembly(). GetManifestResourceNames(); foreach (string one in all) { MessageBox.Show(one); }
&gt; Two pointers, 8 bytes each on x64, plus a char for 2 bytes I don't think we're looking at the same code.. OP: https://i.redd.it/1aabrkqx7r731.png private struct DemoStateMachine : IAsyncStateMachine { public int state; public IEnumerator&lt;char&gt; iterator; public AsyncTaskMethodBuilder&lt;int&gt; builder; public object stack; public TaskAwaiter taskAwaiter; public YieldAwaitable.YieldAwaiter yieldAwaiter; public char ch; public int total; public int unicode; public IEnumerable&lt;char&gt; text; void IAsyncStateMachine.MoveNext() { //... } } That's: 3 int's - 12 bytes 3 references (object, IEnumerable, IEnumerator) - 24 bytes AsyncTaskMethodBuilder is a struct with a Task - 1 more reference, 8 bytes Both of the Awaiter's are structs with a boolean - 2 bytes And a char - 2 bytes
You answered your question already, if you like what VS Code offers and you are good with its launch speed, you should use it as your daily driver. I use it everyday as well but the launch time is not ideal for making it as a turn-around editor for senecio like quick editing a config file on the fly or for quick notes. Besides, electron uses too much memory.
Hmm, I've never thought about POCOs not being "code". Wouldn't it still be easier to just keep all the POCOs in one place though? Not necessarily to just not rewrite code, but also because if the POCOs change, they can all be changed in one place.
Oh, I'm sure! One of my favorites is written in Unity and I've made several games with C# using XNA and silverlight. It's just not the BEST language for games. For games that require cutting edge optimization, you're going to see performance suffer if you take C# over C/C++. If you look at a game like Kerbal Space Program, you can see the suffering.
The principle of "every web service must supply it's own nuget package" is where you are going wrong. You're trying to avoid code duplication, but it's actually causing you all of these problems. It's a false economy. You don't need the nuget packages, they are actually causing the coupling problems and the dependency problems. The solution? Get rid of the nuget packages and have each app implement separately. Version your api semantically (either URL or headers) so that you know if there's a breaking change. That will solve your problem.
What they are trying to do is make consuming the api easier. What it sounds like is that it actually makes maintaining any consumer much harder. The pattern of releasing a package for consuming the api is pretty common, especially with third party service providers, who want to make it easy for you to use their services. This type of pattern, in my opinion, is actually great, because I can automate tests against one of these api clients and ensure it and my service are working as I expected. Limiting code duplication shouldn’t really be the focus, rather making something that increases productivity should be. I’d recommend coming up with some ways to fix the process and propose them to your lead. A few things that I’d recommend: - most nuget servers allow you to store not just production packages but prerelease as well. Take a look at its ability to store any semantically versioned package. Your dev build should publish a prerelease version - stop having interdependent service contracts and move all ownership of pocos to the service. Having duplicate pocos in different services is not the same as having duplicate business logic.
If your family member is using Android, take a look at the app called Coin Collection : https://play.google.com/store/apps/details?id=com.akhaj.coincollectionmanager If you still want to roll your own, get in touch. I have a few Xamarin apps under my belt.
Thanks I'll check it out
you should also minimize versioning by planning ahead and using dynamic objects and/or JSON for the variable portion of your contracts. this gives you a lot of flexibility for 'new versions' to work with old data as long as possible until updated downstream. &gt; because there's no plan for killing old endpoints put in auditing to catch when an endpoint is run in production (just log timestamp and endpoint name to DB). write a script that groups by endpoints against a master list of logged ones to see if any approach 0 usage and deal with them accordingly.
Only a sith deals in absolutes. Those are guidelines, no strict rules.
I have never used Firebase, so I don't know if you can change that output, but they assume you are going to iterate through the json like it was java. JObject's and such. Otherwise, it would have something like this: C# Class public class Status { public string u { get; set; } public string c { get; set; } public int h { get; set; } public int b { get; set; } public int a { get; set; } } public class BirdieData { public string birdieID { get; set; } public Status Status { get; set; } } JSON Output { "birdieID":"103168348456653782090", "Status":{ "u":"lukegamitchell", "c":"#4565E6", "h":4, "b":27, "a":1 } } And you just request the birdieid, and the result you `JsonConvert.DeserializeObject&lt;BirdieData&gt;(results);`
Nice! Where could I see how much memory each type takes?
Well yes, but they are there for a reason and I just had a hard time realising the reason of a choice of class vs struct. Now I do know the reason- no heap involved
Ok, that makes more sense.
This really sounds like a recipe for disaster! &amp;#x200B; This approach introduces a lot of dependencies between different packages and the API consuming clients. Even worse, these dependencies might be explicit or implicit. I think this architecture is build on a misbelief that just depending on versions of packages will solve your issues. It does not! (read this post of John Skeet: [https://codeblog.jonskeet.uk/2019/06/30/versioning-limitations-in-net/](https://codeblog.jonskeet.uk/2019/06/30/versioning-limitations-in-net/)) Also trying to prevent code duplication at the cost of everything else introduces a dependency hell. This is the main reason that there are domains and subdomains in DDD. Sandi Metz has a nice article about the problems with preventing code duplication ( [https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction](https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction) ) &amp;#x200B; You should look at your problem like this: The API represents a mechanism to decouple two different parts of the system as much as possible. This means that there should be as less as possible dependencies between the parts. Sharing nuget packages just adds dependencies and thus using those shared packages deminishes the advantages of using the API. You are effectively making a distributed monolith application. &amp;#x200B; You talk about the redundant fields in your contract. That's also a symptom of the same 'naive' vision on the system's architecture. Trying to not look at the bigger picture ends up in having each API needing to be able to do anything and probably also in such a way that the whole system must be in a concistent state. &amp;#x200B; How to solve this: * Remove the dependencies on the packages and introduce your own DTO layer. * Use something like Swagger to detect API changes * Use Swagger, integration testing and devops techniques to detect version conflicts in stead of trying to find them at compile time. * After the services are decoupled a lot better you can look into introducing better separation of concerns on the APIs. Maybe even introducing eventual consistency to improve on agility and system's performance
I would say (Maintenance - Performance) *Security
Requirements come in two flavours: functional (what a system does) and [non-functional](https://en.m.wikipedia.org/wiki/Non-functional_requirement) (how a system does it). The architecture is driven by the non-functional requirements, which varying depending on the stakeholders and their needs.
Requirements come in two flavours: [functional](https://en.m.wikipedia.org/wiki/Functional_requirement) (what a system does) and [non-functional](https://en.m.wikipedia.org/wiki/Non-functional_requirement) (how a system does it). [System architecture](https://en.m.wikipedia.org/wiki/Systems_architecture) is driven by the non-functional requirements, which varying depending on the stakeholders and their needs. [Here’s a list of potential NFRs](https://en.m.wikipedia.org/wiki/Non-functional_requirement#Examples) that may be applicable. Tldr; first identify the NFRs, then design an architecture that fulfills them.
Desktop links: https://en.wikipedia.org/wiki/Functional_requirement https://en.wikipedia.org/wiki/Non-functional_requirement https://en.wikipedia.org/wiki/Systems_architecture https://en.wikipedia.org/wiki/Non-functional_requirement#Examples *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^264928. [^^Found ^^a ^^bug?](https://reddit.com/message/compose/?to=swim1929&amp;subject=Bug&amp;message=https://reddit.com/r/csharp/comments/c85kv4/what_criteria_should_drive_an_architecture/esk2cx4/)
Hi I shouldve noted that we use New Relic, but it's not implemented in the systems I work on. I have pushed changes to enable it exactly so I can see which endpoints get used. So thank you, it's a great idea!
&gt; if I updated the NuGet package at the top, I would have to manually update every single project that depended on it to the newest version What. Why? &gt; Let me give a nasty example. System A releases a package with its contracts. System B releases its own contracts too, but its contracts package depends on A’s packages for some reason. Now I want to install the new package in system C OK, I have a question. How many engineers are involved in this? Because if it’s less than a handful, that’s just overengineering. But if we’re talking big teams, it may just be hard to coördinate otherwise.
&gt; It sounds like you’ve got a monolithic project that is masquerading as something more agile than it really is. We have a winner.
The thought has occurred to me, but isn't this the same problem that microservices have? They must all be aware of each other, but this is a way to build independently scalable software based on a specific responsibility areas (such as shop, order etc.)?
I mean isn't there still something to be said for the contracts if you can do it in a way, where there isnt such a high level of interdependency? I figure it would be easier to work with, if there was a hierarchy to the web services of some sort, so only certain services can talk to each other
&gt;Any idea how to accomplish this It's easy, learn the lesson and do it yourself. [https://www.tutorialsteacher.com/csharp/csharp-enum](https://www.tutorialsteacher.com/csharp/csharp-enum)
This is an excellent source. Thank you for the citation, I will dive in tomorrow after work.
It sounds to me like you have multiple solutions. I would be asking "why do we have multiple solutions?" In each of my employers we had one solution and things worked okay. In the last one they hired a new manager who was an "expert" on Visual Studio and he forced us to split it into 3 solutions, and suddenly we were in NuGet hell and spent literally half our programming time fighting with problems like you describe. If it's all in one solution, you implement these rules: * You're not allowed to ever deploy anything that isn't checked in. * You're not allowed to ever check in until you check out, recompile, and iron out all the bugs. * Everything gets updated all at once. No piecemeal deployments. This eliminates version conflicts. If you have client software distributed to remote customers, you must either make it auto-update or keep the old versions of the web services up for a while for them to use, and make additional web services that use the new contracts.
&gt;Ask unbiased questions about why things are the way they are -- they may have tried alternatives and found this ultimately has fewer drawbacks. Or, as has happened in my employers, somebody incompetent ordered them to do it this way because they once read (and probably misunderstood) a white paper saying it's better, and everyone else is suffering the consequences.
Like Windows, riiight?
Although there might be a lot of answers that have a technical explaination of what should be done I would say that the answer lies in a more non technical approach to this question. &amp;#x200B; Im my opion architectural work is work that one does to ensure that the system under development will be able to achieve the business goals that it needs to achieve. Both for the short term but also for the long term. This means that architectural work is both on the pragmatic side of things (get it done as soon as possible) but also on the strategic side (if we do it like this, then will we still be able to do something else in the future?) &amp;#x200B; Starting from this approach there is not really a one size fits all answer to your question. Start with an architectural vision statement for your system and from there determine the importance of the functional and non functional requirements.
Unity has its own C# engine doesn't it? Maybe it just doesn't support immediate execution.
This code will crash with a NullReferenceException if the category is not found.
Let’s hope he does’t have 100 resources. Ready to click “ok”!
Your error is different than you think. You are not assigning the string in the empty if case.
Heap might get involved, yes, but it’s kept under control.
Linux, windows, write your own. Just not contribute to supporting terrible client treatment by using apple.
For me one of the biggest factors is discoverability. Often Architects love generic abstractions that you absolutely cannot understand anymore without reading a five pages document that doesn't even exist. Plus ofterntimes it doesn't add any benefit. New developers will just be lost in the code. Personally, I would recommend orienting on your requirements. Keep it as simple as possible. Do not add complexity where the underlying problem is not complex. Add abstraction to make complex things easier to grasp, not to make a simple problem harder to understand because some book said abstraction is always a good thing. Then it is beneficial to not mix different layers of abstraction. What I mean is that I would try to make the code readable even for a non developer on the highest abstraction (like describing the process) and then dive down to the lowest levels where you might find your bitshifts and stuff like that. Stumbling over these nitty gritty details really increases the cognitive load when the developer has to understand the code of someone else for a bugfix, so it is a good idea to have your code structured so that he can read it and understand the process going on withuot having to understand every detail. And don't jump on any hypetrain because it sounds cool. If it violates anything above be at least sceptical if that tool/framework is right for your project. Usually these tools or frameworks are hyped because they make a certain kind of problem very easy to solve and behave natural in these environments.
I wish I did. But the closest thing I have to that would be this: https://github.com/sirkris/Reddit.NET/network/dependents I have a few bots of my own using the library, as well, though none of them are open source at this time.
Aww maaan... Can't install the beta package on my work laptop, I only get: &gt;The package or bundle is not digitally signed or its signature is corrupted. And I can't build the sources, cause we're still on Win10 Build 16299... Guess I'll have to try it out when I'm back home.
Ah shit, here we go again. What you describe is a really bad implementation of a mono-repo. It's bad because you are intertwining three incompatible versioning systems: On the bottom layer is a normal VCS, in the middle is Nuget and on top is "hope and prayer". How to simplify this? Just put everything in a single Git repository, throw away Nuget and stop wasting brain time for unnecessary dependency fighting. Have a build server that builds everything from source, from the same commit. The master branch is always green. If not, revert to the last known green.
Sorry, it only runs on windows 10 1809 and higher for now.
So I've done something kind of similar, but got there via wpf. First, I think look at [INotifyPropertyChanged](https://docs.microsoft.com/en-us/dotnet/api/system.componentmodel.inotifypropertychanged?view=netframework-4.8), it is basically the interface you are thinking about, which allows you to subscribe to an event that will fire when some property on the object changes but you need to fire the event with the args when you update it. My version (which I found the basis of somewhere but can't remember so can't credit :( ) takes the same idea but used Rx so you can observe any property that supports it There is a reasonable amount of code to make it work, so I'll only post a subset ```csharp public abstract class Notifier&lt;TImpl&gt; where TImpl : Notifier&lt;TImpl&gt; { private readonly Dictionary&lt;MemberInfo, Subject&lt;TImpl&gt;&gt; cache = new Dictionary&lt;MemberInfo, Subject&lt;TImpl&gt;&gt;(); public IObservable&lt;TProperty&gt; Observe&lt;TProperty&gt;(Expression&lt;Func&lt;TImpl, TProperty&gt;&gt; propertySelector) { if (!(propertySelector.Body is MemberExpression memberExpression)) throw new InvalidOperationException("Property selector expression is not a valid MemberExpression"); var member = memberExpression.Member; var accessor = propertySelector.Compile(); if (!(cache.TryGetValue(member, out var line)) cache[member] = line = new Subject&lt;TImpl&gt;(); return line.Select(accessor); } protected void SetProperty&lt;TProperty&gt;(ref TProperty store, TProperty value, Expression&lt;Func&lt;TImpl, TProperty&gt;&gt; propertySelector) { if (!(propertySelector.Body is MemberExpression memberExpression)) throw new InvalidOperationException("Property selector expression is not a valid MemberExpression"); var source = (TImpl) this; store = value; cache.TryGetValue(memberExpression.Member, out var observer); observer?.OnNext(source) } } ``` You would then implement your temperature service using Notifier ```csharp public class TemperatureService { private double temp; pub } ```
What's the reasoning behind using SetProperty(... , Expression&lt;Func&lt;TImpl, TProperty&gt;&gt; propertySelector) instead of just doing this, which allows to automatically grab the member-name if it was a Property/Method SetProperty(... , [CallerMemberName]propertyName = null)
Could do that, but then would have to either reconstruct the Func&lt;TImpl, TProperty&gt; from the name as the selector on [line.Select](https://line.Select)(accessor), or store Subject&lt;TProperty&gt; in the cache and store them as Dictionary&lt;string, object&gt; and cast to Subject&lt;TProperty&gt;. Just feels a little cleaner It would be cool if there was a \[CallerMemberExpression\], but that might be a little too much to hope for
If you were a box of crayons, you'd be the big industrial name-brand one with a built-in sharpener :)
Actually he created at least 2 references, by doint `new object()` and `text = "Hi"` even though the string is constant, a reference to the interned value is stored in text
Not just built-in but self sharpening
I'd rather construct the `Func&lt;&gt;` on the first observe and store it in a cache (yea.. casting is not great, but also not ridiculously expensive), than to have the additional `s =&gt; s.Property` for every single property that does change notification, but ymmv
`File.WriteAllText("resources.txt", string.Join("\n", all))` \-&gt; There you go! :D
The most compelling reason in my code is probably to use the observable attribute to guard against a mixed properties ``` ... var observable = member.GetCustomAttribute&lt;ObservableAttribute&gt;()?.IsObservable if (IsObservable.HasValue || !IsObservable.Value) throw new InvalidOperationExpression(...); ``` and ``` pub
just for clarification: mixed properties are properties that invoke other properties that might invoke the starting property and create loops?
Yeah, I didn't define it well. Mixed as in observable and non-observable properties, ie. setters that call SetProperty vs setters that don't
A programming language is a software development tool. That video you're watching is trying to teach you how to use this specific software development tool. Before writing something as complex as a game, first learn how to put a basic application together and understand the concepts of C#. Understanding the tool helps you solve problems by using it correctly to create software applications or tools that serve one or more needs. Physics is something else entirely, not specifically related to software, but if you understand how to use C# and the fundamentals of physics, then you can start simulating physics in C#. Graphics development could have a strong matrix algebra element to it as well. But, baby steps! You're not going to learn it all in week/month/year. Be patient and stay curious. A good idea would be to get the source code of someone that has previously developed a game, and spend some time studying it. I've learnt most of what I know by looking at how other people solve problems.
so you only allow to observe on properties that "SetProperty"? What's with properties like double Progress =&gt; /* some very light calculation*/ where the code never updates it manually, but the value still might change? using `INotifyPropertyChanged`, i would do `RaisePropertyChanged(nameof(Progress))` in code, when i know that my work modified the progress (or status value) typically i use this kind of code when i have many calculations and want to throttle the refresh on the window, so i do (overly simplified example) if (i % 10 == 0) { RaisePropertyChanged(nameof(Progress)); }
I do it in the setup of the Impl In Notifier: ``` private readonly Dictionary&lt;MemberInfo, List&lt;MemberInfo&gt;&gt; dependentProperties; public void SetDependency&lt;TSource, TTarget&gt;(Expression&lt;Func&lt;TImpl, TSource&gt;&gt; sourcePropertySelector, Expression&lt;Func&lt;TImpl, TTarget&gt;&gt; targetPropertySelector) ... ``` The SetProperty func also iterates over the dependents and OnNext's those as well ``` class Service { private double prop1; public Service() { SetDependency(s =&gt; s.Prop1, s =&gt; s.Prop2); } public double Prop1 { get =&gt; prop1; set =&gt; SetProperty(...); } public double Prop2 =&gt; Prop1 * 1000; } My full implementation also does INotifyPropertyChanged as well, use it in wpf
sounds a little complicated, but i can see it's use case in a more mature application &amp;#x200B; nitpick: shouldn't it be called `SetDependant(...)`, because target is dependent on source-value? Also you could (if you don't already have) add public void SetDependants&lt;TSource, TTarget&gt;( Expression&lt;Func&lt;TImpl, TSource&gt;&gt; sourcePropertySelector, params Expression&lt;Func&lt;TImpl, TTarget&gt;&gt;[] dependantSelectors) { foreach (var dependant in dependantSelectors) { // ... } } // SetDependants(s =&gt; s.Age, // s =&gt; s.IsAdult, // s =&gt; s.HasSoonBirthday, // s =&gt; s.IsAgeDiscountApplicable // );
"Readability, Testability" etc are not arhitectures , they are goals. Arhitecture usually refers to deciding if the app is a monolith, ntier, microservies etc.
Mistype, it is SetDependency in my code Yeah, it is mostly just some syntatic sugar and a way to not use events because they annoy me. Using it in a data analytics app I've been working on for about half a year, so depends on your definition of mature I hadn't thought about the multiples one, probably because I haven't had a place I would have used it. Also, it isn't often I want veriadic generics but that would be one
I don't think so. Maybe if there was a simple else case you would be right, but there is nothing but one if and few "else if".
oh boy, i totally missed that we don't have variadic generics :D this would make the code a little ugly i suppose `Func&lt;TInstance, object&gt;` scrap that idea ^^'
I don't think I've ever heard of a way to achieve this. The only option is to use a better library.
Yeah, it would work but doesn't pass the 'is it pretty enough' test
So you should contribute to the extensive spying on customers that Microsoft is doing?
No company is perfect. I honestly believe that Apply is the worst though. Buying their products destroys market. They spy on you as well and do whatever they can to close you in their system. Their hardware price is 50% worth and 50% hype. I honestly don't want to go in details, but if you really get to it Apply is just the worst. I'm not defending Microsoft. Just saying there is bad and there is apple.
&gt; What criteria should drive an architecture? The ones you care about. &gt;And yes I'm focused only on C# developers because of C# itself. The language makes no difference. The first thing to keep in mind is that engineering will always be about tradeoffs. You can make a highly testable, maintainable, performant system, but it will cost you in time and money. By the time you ship, your opportunity to bring it to market may have passed, or you may have gone bankrupt. That's one extreme. Conversely, you can figure it out as you go, and that may help you find the right moment to launch the product, but cost you in the long run (as technical debt). Any of these are great. Of course you want your code to be readable, testable, maintainable, documented, performant. But in reality, you have to figure out a particular level you're comfortable with. For example, IMHO, some level of testability is great; optimizing for code coverage is, in my opinion, a fool's errand that gives an incompetent manager a worthless metric to compare their employees. I'd favor code reviews over some metric as code coverage, cyclomatic complexity, etc.: have someone else take a look at your code, and they'll find all the things that either seem obvious to you but aren't to a third party, or seem unavoidable but can actually be done better (which portions of the code should receive a comment? Which ones are a WTF? Which aren't necessary at all? Which can be done in a more elegant or performant manner?). That's costly, and may often seem like a pointless exercise, but can surprise you in its effectiveness — and leads to maintainability in the process. (It's also great for getting new team members on board.) There is no right answer here.
Dynanic UI components where their state is shared with other components. Chat messages for example. SignalR client is receiving messages from the server hub and stores at local state of application. You should notify UI about new message for rendering on screen. Or render method will read shared state for N mesaages. And other example is Unity where each gameobject has independent logic, but you probably want to implement "isGamePaused". Each component can read shared global state of scene or will be notified when it could be paused
Apple is very privacy oriented company. They use differential privacy and unlike Microsoft, they do not know what YOU personally use your machine for. They merely know that for example people generally use Mac for doing A and B, whereas Microsoft knows that this one guy that lives in address X uses his windows machine to do C. And when it comes to the price: yes it's expensive from hardware perspective, but the os is the selling point. It is a good exercise for you to think just why so many programmers do use Apple. It will give you some perspective. Apple is not a bad company like you seem to think.
And why wouldn't you use it now?
Awareness of the GDPR (e.g. no IP address in generally accessible logs). And a way for the user to let them delete their data.
Some of these projects are pretty big. Wouldnt it take forever for a build, if we piled them all together?
Simplicity. Always.
Idk if I understood correctly your question but it seems that you are trying to disambiguate several methods with the same name in different classes I think what you want is not possible (someone correct me if I'm wrong) but you can use aliases. Take a look here https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-directive You can do something like using alias = Tweetinvi; Then use it alias.method(params);
Take a look at aspnetzero for some ideas
Sexy videos of my mom.
I wrote a library in .NET standard to work around this. The only thing that needs to be shared is the model. The client serliazes expression trees into query strings and the API rebuilds and executes the expressions against the model server side.
We do something similar to this but it doesn't receive the vitriol these comments have produced because we adhere to versioning standards between our microservices. You can only get away with mismatching versions of nuget packages if you version your RESTful endpoints correctly. For instance, if an endpoint changes previous functionality, the version of that endpoint must change. You can do this through path, headers, or parameters (Design decision). That way the new functionality doesn't break old code. Through telemetry, you can then analyze what services are using the old version and plan on how to upgrade those. You don't always need to upgrade all services that depend on a newer version. If all you're doing is adding a new field to be returned, this doesn't break most serializers so your updated (but not up-versioned) endpoint api shouldn't mess with your older nugets. If you would like to enforce nuget versions across projects, there's a library for that: [https://github.com/Microsoft/MSBuildSdks/tree/master/src/CentralPackageVersions](https://github.com/Microsoft/MSBuildSdks/tree/master/src/CentralPackageVersions)
It seems like the concept of API versioning is completely missing. Core has good versioning support and each of your micro services should be targeting an specific API version so if you increase a version number everything still works if you haven’t upgraded it. Secondly your main API project should have a contracts assembly that is referenced as a project, not as a Nuget package. The contracts assembly can be published as part of the devops pipeline to a private Nuget feed if you want, but that’s for your consuming services to use. Personally I prefer generating clients from Swagger json rather than referencing a contracts Nuget package but that’s just my preference and I use Nswag Studio to do that.
still doesn't work.
I think you missed the word 'Criteria' in the post.
The only thing I need is not to see Tweetinvi in suggestions anywhere except single project where it's directly included.
Something that never crossed my mind as I am so far from the EU. Do I have to comply if there is even the slightest chance that an EU citizen will use the application?
Can't believe I haven't seen this before. Thank you!
I'm not sure if she would like that - but hey whatever floats your boat.
 return NotFound();
My experience is anecdotal. I know organizations that do this and they have their reasons. Like some others have said though, why use separate web services if they are so interdependent? A simpler option is putting them in the same repository and deploy them together. There may well be a good reason not to do this but we are still in the era of microservice envy where I've seen teams overly separate their processes for no real gain.
&gt; Do I have to comply if there is even the slightest chance that an EU citizen will use the application? Yes, unless you're purely dealing with an intranet application for companies.
`OutOfMemoryException` - mother too fat.
I'd launch PowerShell.exe using the System.Diagnostics Process class and feed it your script Via command line arguments.
&gt; When it comes on Invoke() then it waits for 3-4 seconds but it does not prompt for login. You're not in an interactive session, how would it prompt for login? Check if there's another way to pass credentials directly.
Time to do some research - thank you /u/AngularBeginner
This isn't accurate. OP, read up on your GDPR obligations and get familiar yourself - [https://gdpr.eu/companies-outside-of-europe/](https://gdpr.eu/companies-outside-of-europe/)
Well, it was definitely simplified, and he surely must get himself familiar with it. But logging and traffic monitoring usually involves the IP address, which is relevant: &gt; If your organization uses web tools that allow you to track cookies or the IP addresses of people who visit your website from EU countries, then you fall under the scope of the GDPR.
So, you have several projects in one solution? For that, you can take a look here https://docs.microsoft.com/en-us/visualstudio/ide/how-to-create-and-remove-project-dependencies?view=vs-2019 for how to create project dependencies. The other projects in the same solution won't be able to access the dependencies of the first project
Thing is VS hooks into Unity and supports full debugging sessions, breakpoints, variable watching, editing etc. So it would be normal to presume that immediate mode would work, especially when there's a plugin for Unity that does this.
&gt; Well, it was definitely simplified And wrong. I appreciate that you're just trying to help, but when it comes to GDPR it's best to point people in the right direction and let them draw their own conclusions. The advice to consider including GDPR was enough.
I would probably use the FileSystemWatcher in. Net, does exactly as you describe!
Great answer
This was enlightening. If I were to pick just one of those NFR examples, I'd pick ["Integrability"](https://en.wikipedia.org/wiki/System_integration)
Why? POCOs are cheap. Domains can map external dependencies into the POCOs that make sense for them making their implementation easier while creating additional decoupling.
We’re gonna need a bigger camera.
I'm just curious, which company is this? Because this situation is very similiar that I had at my previous work. I hope you are not the one who follows me ontl that project :D
There's a million applications for this - think of a scenario where something can be produced at a different rate to how it can be consumed - pub/sub helps to decouple the creation of a thing from the consumption of a thing; which can help with dealing with surges, can palm off intensive operations to a background thread etc. Concrete example - logging. A web server will produce more logs in bursts when traffic is high, but writing those logs out might take longer than you would like. So, you write your logs to an in-memory queue, and read off that to persist them to disk (or wherever). Really you don't need System.Threading.Channels for this (IMO), you could use something a lot more simple like a BlockingCollection for most use cases.
Connect-AzureRmAccount has a [`Credential`](https://docs.microsoft.com/en-us/dotnet/api/system.management.automation.pscredential?view=pscore-6.2.0) parameter, which takes a [`PSCredential`](https://docs.microsoft.com/en-us/dotnet/api/system.management.automation.pscredential?view=pscore-6.2.0) object. PSCredential has a (String, SecureString) constructor, for parsing the username and password, respectively. You can create the PSCredential object in PowerShell in a quick one-liner: `$credentials = New-Object pscredential($usernameVariable, $passwordVariable | ConvertTo-SecureString -AsPlainText -Force)`
&gt;sand script Is that a scripting language I'm not aware of or did you mean Sanskrit?
Readability and testability are goals that can help you choose what architecture you use, which is the point of the question.
Have you had any luck with solutions that include both an ANC project and a WebForms project? We don't enforce a single solution, but there is a powershell script at the root of our repository that performs a global build (a server does so automatically on every push) and runs some limited tests. Our "rules" are 1. never break json serialization in any form in any api or data persisting medium (if something potentially serializes to some json object, it must always be able to deserialize from that form forever) 2. never change endpoint routes or bindings 3. never add validation requirements to existing endpoints or objects 4. don't break build.ps1 5. all nuget/npm packages must come from the in-house registries 6. all nuget/npm packages in the in-house registries must be approved by legal team and security team Any nuget/npm packages that depend on each other are produced by a registry script off a forked version to remove diamond dependency hell. For example both Nodatime (2.4.6) and Newtonsoft.Json (12.0.2) are in our repository and the bridge dependency NodaTime.Serialization.JsonNet (2.2.1-inhouse) is a source fork updated to depend on the current version of both package references.
1. Testability - I haven’t even gotten around to adding tests to my project but just by making sure it is testable has forced me to conform to an architecture. I inherited the project from someone else and it was a total mess when I got it. I’ve slowly been imposing a cleaner architecture since beginning to work on it. 2. Maintainability - I think this just follows from testability. Once you have things split up into a few different layers it becomes almost mechanical to place a new class to do something. You don’t have to think about where it needs to go or what to call it. I’ve stumbled upon a scheme that has been working brilliantly so far, I doubt I’m the originator but it’s one of those things where I hadn’t seen anyone spell it out explicitly. I have a Repository, Core, and Web layer (there’s also a Test and Facade layer but those are secondary). The repo layer contains the dB contexts and communicate with the database. They also inherit from a IRepository class in the Core layer. The Core layer contains all of my business logic and interfaces that all the other projects are depending on. So I maintain the dependency hierarchy by having core at the center or top. My Web layer is using DI and newing up classes that are in my Core layer to get the business logic I need for my views. Each time I create a new page I basically add a new controller with an index view and maybe a few partial views. I then create a sister class in the appropriate folder in my Core project where all of the business logic for that view will live. This makes the controllers extremely thin as far as number of lines goes. Rinse and repeat.
The method to calculate mother's fat mass caused a stack overflow
When choosing an architecture I always prioritize readability. This is because readable code is simplier code that is easier to understand. Easier to understand code is easier to maintain and change. If someone cannot understand the code they are going to be hesitant to make changes because they won't understand what the change will do. So instead of making a proper change, they will look to change the least amount of code possible. This often results in nests of if-else statements, unnecessary duplication, and more complicated harder to understand code. Part of readability, in my opinion, is following tried and true practices that most developers will be familiar with or will be able to find plenty of resources for. This reduces the cognitive load that a new developer will need as they will be working within a framework that they either already understand or can easily learn about. You always have to remember the code you write is not for the computer, it is for a person. So our priority should be on making sure a person can reasonable consume the code first before we worry about anything else.
Hey man. Thanks again for your feedback, it was super helpful. I've gone through your comments and made a bunch of changes: * Added XML documentation for types/methods (excluding the straight read/write methods). * Refactored SpanReader/SpanWriter as ref structs, which let me use the Span directly - also added implicit constructors while I was at it, so they can be created in the same way as Span's etc. * Renamed ASCII -&gt; Ascii, UTF8 -&gt; Utf8. * Added a bunch of parameter validation. For straight read/writes, I didn't go as far as testing if the cursor would be in bounds, as the underlying method (.Slice) doesn't do this either; but for the TryXX methods I did; so that they would fail rather than throw. * Added AssemblyInfo.cs - I wasn't really sure about the conventions for this with .NET Standard, but seems OK.
A surprisingly large number of self-professed “architects” are completely unaware of the concept of functional vs non-nonfunctional requirements.
A reference takes up no more space than the null it replaces. So if the string was pre-allocated then it doesn't count against the total.
TopShelf can make console applications runs as a service. We use it in our .net core apps all the time. The startup code is minimal, and it turns a console app into a console app that can install itself as a service or just run the program once without installing itself.
Muchas gracias
A lot of orgs do build their microservices in a monorepo. Even then, your clients should not need to be updated unless they need to take advantage of new features in the services. If you're constantly breaking your clients, then you have a design problem, not just a dependency management problem.
1) Maintainability 2) Performance 3) Extensibility So why? Maintainability is the __most__ important criteria. If you cannot hire people that can maintain your application, your application will die. That means using sane architectures that are easy to be understood by mid-level developers without very little help (usually just the standard getting your feet we stuff). I never use junior developers as a target because you never, ever know what you have with a Junior until he's been there long enough to slap the mid-level tag on him. So, what architectures for Maintainability? The first one I always think of is the MVC architecture. No, not ASP.Net MVC, but a real [MVC architecture](https://github.com/gatewayprogrammingschool/simplemvc). If you are unfamiliar with MVC here's an [article I wrote](https://www.codeproject.com/Articles/1197973/Demystifying-and-Simplifying-MVC-Frameworks) that I hope helps you out.
&gt; Sounds like our old architect. Jesus. Never hire a simple carpenter to be an architect, I guess.
You said it, man.
Can that be scheduled in something like hangfire
Sure, the FSW will hold its own thread so its does not really need anything to help keep the app running as TSR though it looks like hangfire does give you some nice trimmings that would be more work otherwise.
Thank you, now I can learn two languages at one time :D
If you’re exchanging json the parser shouldn’t care if you get extra elements. You’re code most likely wont care about extra elements and if you’re modifying your code to support the new elements you’ll be modifying the POCO classes anyway.
If you want to prompt for credentials, you'll have to do it explicitly within your console application, your PowerShell runspace isn't interactive so it can't prompt. The way I've done this in the past is build the credential object in the runspace and using Set-Variable to store it for use with other cmdlets. Also, honestly think if you need this to be run from C#. PowerShell is not bad on it's own, but it is absolute hell to work with in this manner. I've built enterprise level applications like this and honestly I wouldn't wish this upon anyone. Just write a PowerShell script and just run that if you have the option
I'll be honest, I've never worked directly with the Thread class. The entire point of Tasks is avoiding the pain of dealing with Thread.
I have to be honest, I'm possibly a bit early out in my criticism. I'm sure I could say more, once I dig a bit deeper into some of these projects. The monorepo thing sounds fantastic to me, but after hearing podcasts such as the ones on Software Engineering Daily about Google's Mono repo, it sounds like you need a lot of internal tooling to get it to work probably. For example, if we slap everything into the same repo, we could probably just reference .dll's in other solutions relatively, but how do we handle that the whole solution needs to build with every change? I know that Visual Studio and even ReSharper's build system can cache and check if a solution needs to be rebuilt, but I can just imagine that it would be hard to manage all solutions in one repo. It seems to be the common sentiment here though.
I imagined that the reson to have separate web services would be that they can each scale independently, but I'm not sure that it's a good argument in our case. Load is not really out biggest problem; moving slowly is. Can I ask though, what is the argument against these contracts packages versus something like the client Google exposes for their Content Shopping API? [https://developers.google.com/api-client-library/dotnet/get\_started](https://developers.google.com/api-client-library/dotnet/get_started)
Get more RAM or modify your algorithm to use less memory. If you are working with a recursive algorithm, consider rewriting to use a loop, instead.
You are thinking about it the wrong way. Memory is automatically cleared when *no longer in use*. You are creating objects and holding references to them, probably longer than necessary. Figure out where.
Man, I know this way to solve my problem but I don't have more RAM and any way to make my algorithm to use less memory. Anyway Thank You :)
Without knowing the algorithm we can't tell you how to improve it.
Other projects do see that dependency and all than dependency classes get into intellisense.
&gt; For example, if we slap everything into the same repo, we could probably just reference .dll's in other solutions relatively, but how do we handle that the whole solution needs to build with every change? Just how big *is* the organization and how many projects are there? You put them all in a git repo with a policy that the only way to get changes into master is via Pull Requests that have at least 1 non-author reviewer sign-off and passed buddy build. The cloud build service does a rolling build every 5 minutes if there is at least one checkin to master. You can manually request a buddy build off a branch at any time. Azure DevOps can handle this. Pretty sure GitHub can. Setting up your own CI system is something lots of companies have done, but is a significant undertaking that may be outside the human/political capabilities of an organization with the problem you're facing.
Hmmmmm, I'm not very familiar with the relationship between machine memory and C# programming. I know that I should find the short way always , and this is what I have made in this algorithm I suppose. Can you find me any post that would help me to learn a bit about the relationship between machine memory and C# programming?
Removed: Rule 4. Without code or context, it's not possible to help beyond generalities. If you're being hit by out of memory due to temporary spikes, you could force a call to [`GC.Collect`](https://docs.microsoft.com/en-us/dotnet/api/system.gc.collect). Another possibility is that you might have some infinite loops incorrectly blowing up your memory usage. But it's impossible to tell without code. If possible, please try to [create a minimum, reproducible example](https://stackoverflow.com/help/minimal-reproducible-example) that we can review and reproduce your issue.
using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; &amp;#x200B; namespace sumOfEanAlgorithm { class Program { static void Main(string\[\] args) { string\[,\] ean = new string\[,\]{ { "a","2" }, { "b", "5" }, { "c", "3" }, { "d", "2" } }; List&lt;string&gt; allEan = new List&lt;string&gt;(); List&lt;string&gt; combination = new List&lt;string&gt;(); List&lt;string&gt; final = new List&lt;string&gt;(); &amp;#x200B; &amp;#x200B; // Preapre ean list for (int i = 0; i &lt; ean.Length / 2; i++) { for (int j = 0; j &lt; Convert.ToInt32(ean\[i, 1\]); j++) { allEan.Add(ean\[i, 0\]); } } &amp;#x200B; &amp;#x200B; &amp;#x200B; combinations(allEan, combination); &amp;#x200B; foreach (string comb in combination) { if (final.Count &gt; 0) { //var aSet = new HashSet&lt;char&gt;(comb); int combCount = final.Count; bool find = false; for (int i = 0; i &lt; combCount; i++) { //bool abSame = aSet.SetEquals(final\[i\]); if (final\[i\] == comb) { find = true; break; } } if (find == false) { final.Add(comb); } } else if (final.Count == 0) { final.Add(comb); } } &amp;#x200B; foreach (string result in final) { if(result\[0\] == 'd') { Console.ForegroundColor = [ConsoleColor.Blue](https://ConsoleColor.Blue); Console.WriteLine(result); } if (result\[0\] == 'c') { Console.ForegroundColor = [ConsoleColor.Green](https://ConsoleColor.Green); Console.WriteLine(result); } if (result\[0\] == 'b') { Console.ForegroundColor = [ConsoleColor.Red](https://ConsoleColor.Red); Console.WriteLine(result); } if (result\[0\] == 'a') { Console.ForegroundColor = ConsoleColor.Cyan; Console.WriteLine(result); } &amp;#x200B; } &amp;#x200B; Console.WriteLine(); Console.ForegroundColor = [ConsoleColor.Green](https://ConsoleColor.Green); Console.WriteLine("All Combination: " + combination.Count); &amp;#x200B; Console.ForegroundColor = ConsoleColor.Yellow; Console.WriteLine("Final Combinations: " + final.Count); &amp;#x200B; Console.ReadKey(); } &amp;#x200B; static void combinations(List&lt;string&gt; list, List&lt;string&gt; fin) { double count = Math.Pow(2, list.Count); for (int i = 1; i &lt;= count - 1; i++) { string str = Convert.ToString(i, 2).PadLeft(list.Count, '0'); [//Console.WriteLine](//Console.WriteLine)(str); string comb = ""; for (int j = 0; j &lt; str.Length; j++) { if (str\[j\] == '1') { comb = comb + list\[j\] + "||"; } } [//Console.WriteLine](//Console.WriteLine)(comb); fin.Add(comb); } } &amp;#x200B; } &amp;#x200B; }
This is not in a readable format.
Can you try this? In Solution Explorer, select a project. On the Project menu, choose Project Dependencies. The Project Dependencies dialog box opens. On the Dependencies tab, select a project from the Project drop-down menu. In the Depends on field, clear the check boxes beside any other projects that are no longer dependencies of this project. I think you have it set as dependencies for more than one project
Can you try this? In Solution Explorer, select a project. On the Project menu, choose Project Dependencies. The Project Dependencies dialog box opens. On the Dependencies tab, select a project from the Project drop-down menu. In the Depends on field, clear the check boxes beside any other projects that are no longer dependencies of this project. I think you have it set as dependencies for more than one project
Tweetinvi is referenced only in one project. That project is used by the main project.
Google does what they do because their API is public. They provide SDKs for ease of use and version their APIs. They do this to make integration with their services as easy and seamless as possible. What's hidden is the vast infrastructure they have behind the scenes to make this all work. When they upgrade their API, they also have to update their SDKs, test everything, deploy it all, etc. They probably have a large pipeline, extensive automated tests, and a team of engineers to handle it. There are tradeoffs. When building internal APIs, we use simple architectures. We aim for monoliths until something hurts; figure out the pain points (deployments, scalability, whatever) and then adjust. We also avoid cross-repository code reuse / dependencies as much as possible. This makes updates easier, makes deployments easier, and requires less institutional knowledge.
&gt;Do I have to comply if there is even the slightest chance that an EU citizen will use the application? Not even just citizen; they could also merely be a EU _resident_.
http://www.ben-morris.com/memory-leaks-in-net-applications-yes-they-happen-all-the-time/
&gt;And wrong. You haven't actually specified what AngularBeginner is wrong about.
I believe the nugets are available to any project that references the one with the nuget reference.
They told OP they need to comply with GDPR "Unless you're purely dealing with an intranet application for companies." This is wrong on both counts. There's situations and factors outside of it being an intranet app where GDPR doesn't apply. Conversely, there's intranet situations and factors where GDPR does apply.
For scheduling, have a look at [Coravel](https://github.com/jamesmh/coravel)? It's pretty simple to get started with.
What’s your updated code?
It sounds like you're trying to nitpick. AngularBeginner's main assertion was that OP _has_ to comply with GDPR, which in 99% of cases is accurate. Your link doesn't disagree with that.
Thank you :)
Not trying to nitpick at all. They shouldn't have given advice for "99% of cases" like it applies to all. There are exceptions to GDPR which they didn't bother to explain. OP could also have easily taken the advice as "great well this is an intranet so I'll be fine!" And that isn't true either.
 Writing one method that does everything is definitely simpler than splitting out methods. Simpler, always, isn't good advice. Keep it simple, but don't forfeit other designs to do it.
I think this is the best mindset to have. The challenge then becomes "what is the most readable architecture for my application?" I like the concepts of screaming architecture and things like feature folders. The folder and file structure clearly communicates what an app can do. But then that may obscure the details of monolith/onion/microservices. It's interesting how this question spreads very deep and wide as you dig into it. I'm planning to write some kind of guide that addresses this fully.
more like you don't because IUserRepository is abstracted away by the interface it defines. the implementation is specific to EF..
&gt; They shouldn't have given advice for "99% of cases" like it applies to all. We take this shortcut all the time in software engineering. Taking all edge cases into account is cost-prohibitive. For legal matters, that becomes problematic. &gt; There are exceptions to GDPR which they didn't bother to explain. OP could also have easily taken the advice as "great well this is an intranet so I'll be fine!" I don't think AngularBeginner was trying to provide legal advice here, just some general guidance, but you're of course correct that edge cases are legally relevant.
&gt; Declaration Expressions Oh. My. God. Can it be real? Is it real? Has hell actually frozen over?
people are confusing themselves. you don't create an IRepository&lt;T&gt; or IRepository with Get&lt;T&gt; methods etc. you create IUserRepository with contracts specific to that entity... the implementation of that interface would be specific to entity framework, or dapper, or nhibernate. the interface already provides that abstraction. the pro of using a Generic Repository is it's much most easily mocked for unit tests, and you can easily switch ORMs via DI registrations for your whole application, certain repos, etc. you can't do that if your ORM is used in your ORM specific implementation of IUserRepository
Try [this](https://docs.microsoft.com/en-us/windows/desktop/search/windows-search).
 [Maintainabilit](https://en.m.wikipedia.org/wiki/Maintainability) and [Testability](https://en.m.wikipedia.org/wiki/Software_testability) You'll thank me in some years.
It's a great way for separation of concerns when having an event based architecture.
I understand when people tell me C# isn't their favorite language. I understand why people tell me C# isn't good. After C# 8, I won't be able to do either.
&gt; The language isn't complete until the compiler cannot distinguish between a programmer and a cat walking across the keyboard.
`var sum = (var p = GetPoint(); p.X + p.Y);` I quite like this. I understand that people tend to be skeptical of new syntax, especially if it seems to be niche. But I actually think stuff like this can make code more concise, which in turn makes it easier to read. For example, the consutruction above makes it immediately obvious that we're only using `p` so we can sum `p.X` and `p.Y`. This allows the reader of the code to understand straight away that `p`, `p.X` and `p.Y` are temporary variables and that the only value we're really interested in is the `sum`.
probably one of the only things i like about go is the syntax similar to this. if blah := getSomeData(); blah.Property != nil { doSomething(blah.Property) }
Have you installed 4.7.2 targeting pack? That’s different from the framework itself. If VS 2017 or 2019 go to Visual Studio Installer and add 4.7.2
Good bot
I'm interested in other's answer to that question. Couple of years ago, we had to install Visual Studio on the faulty computer and run in debug mode to find the problem, which was related to some third-party not coping well with a weird Windows regional settings.
I believe that these syntax changes make c# a write-only language.
I work mostly with Unity, and we have [UniRX](https://github.com/neuecc/UniRx/) as a platform-specific reimplementation of Reactive Extensions on that environment. As a disclaimer, this means it's not entirely compatible with standard Rx because it has to deal with things like AOT platforms and minimizing allocations for game engine performance. I've also neither done anything like this nor claim to have enough understanding of all the nuances and requirements of doing so. It has a [ReactiveProperty](https://github.com/neuecc/UniRx/blob/master/Assets/Plugins/UniRx/Scripts/UnityEngineBridge/ReactiveProperty.cs) which kind of acts like a Subject (you can push values onto the stream using `reactiveProperty.Value = someValue;`) but is in fact just a hot `IObservable&lt;T&gt;` with an accessor for the current value and a lot of handling logic beneath it. I'd probably do something like this just because I'm used to it, and while I'm sure it's neither ideal nor good practice, it allows me to weave in and out of the monad more easily, which is needed sometimes. I can expose the property stream as an `IObservable&lt;T&gt;`, bind properties together, or just expose values like a regular old property that happens to notify subscribers, but without subscribing to anything: ``` private readonly ReactiveProperty&lt;int&gt; counterProperty = new ReactiveProperty&lt;int&gt;(); // Access the property as a stream of values public IObservable&lt;int&gt; CounterStream =&gt; counterProperty.AsObservable(); // Access the property as a value public int CounterValue { get =&gt; counterProperty.Value; set =&gt; counterProperty.Value = value; } // Turn any stream into a read-only reactive property var stream = Observable.Range(1, 10).ToReadOnlyReactiveProperty(); Debug.Log(stream.Value); ```
So I completed the project for this person only for him to run off without paying me - as you can see his account was deleted. Now, I'm not upset or anything. Maybe he didn't scam me and there was a legitimate reason this all happened. Regardless, I just want to say that if you see this, it was probably better it happened to me than anyone else. It didn't cost me much and I have a job so $50 lost isn't too big a deal. We've all done bad things and make mistakes in the past, myself included. I just hope that you become a better person if you did intentionally scam me. Because after all, I still have faith in humanity. ;)
C++17 also has this: https://en.cppreference.com/w/cpp/language/if
Thanks i am trying that right now and i will let you know if it works!
Look up Angelsix on YouTube and view his WPF application playlist. It is by far the best online guide for WPF and MVVM that I've seen. Do yourself and favor and watch in order and don't skip around. Even watch the videos that don't seem like they might apply directly to what you're doing, because every video he's showing an essential step to building a functional application. Outside of that, check out the book WPF Unleashed. It's probably the best book on WPF out there, and includes tons of examples and pictures. I know you're looking for quick primers but unfortunately there aren't any, really. You can't really explain WPF quickly. It's... Immense.
Silly &amp; embarrassing side question: how does one install a specific version of C# as opposed to .NET? With the advancements in the syntax making news, this feels as if MS has broken out the C# installation from the .NET installation. I'd like to be able to support the latest syntax on my build server, but not sure how to accomplish this.
You can set the compiler level in the project properties, build tab, advanced button.
Cool cats make cool programmers 😎
We've been able to do something similar to that since C# 7, just FWIW: if (GetSomeData() is var blah &amp;&amp; !(blah.Property is null)) { DoSomething(blah.Property); } Although we have an arguably more concise (and, I think, more obscure) option, too: if (GetSomeData().Property is PropType blah) { DoSomething(blah); } because `expr is Type identifier` is false if *expr* is null, but `expr is var identifier` is always true. I like the ability to do this for things that aren't branches, though.
Write it to a CSV and import it to Excel instead of working directly with the excel namespace. Excel can open CSV files and they are also usable pretty much everywhere.
Thanks alot! It worked well!
 Visualization product Engineer position available with Esri in Redlands, CA. **Company:** [Esri](https://www.esri.com/) **Type:** Full time **Description:** Do you have a passion for data visualization in 2D and 3D? Do you want to eat, sleep, and breathe bits and pixels? The Graphics Team in Product Development is looking for new recruits to help them bring the next generation of ArcGIS to life! Product engineers are involved in every step of the software development life cycle. They are the digital shepherds who guide new features, functions, and critical bug fixes home to our users. In this position, you’ll work with developers and other product engineers to evaluate functionality, triage and investigate customer issues, tweak automated tests in various harnesses, and even code new test fixtures to help us build a better ArcGIS. **General Requirements:** · Experience with C++, C#, Java, or another object oriented language · Ability to work well in a highly collaborative environment · Knowledge of software development processes · 1+ years of experience using an application development language (such as C++, Java, or C#) · Strong analytical problem-solving abilities · Excellent written and verbal communication skills · Bachelor’s in computer science, computer engineering, or a related field, depending on position level **Bonus points for experience with:** · Working knowledge of graphics interchange file formats such as PDF, JPEF, and PNG · Working knowledge of computer graphics APIs such as DirectX and OpenGL · Familiarity with Esri ArcGIS products and online services or other GIS products **Location:** Redlands, CA – Relocation assistance provided for qualified candidates **Remote:** No **Visa Sponsorship:** Yes **Technologies:** · C#, C++ · VisualStudio · Git, Github · Jenkins · Bash, Python3 · OpenGL, OpenGLES, DirectX11, Metal · Both Esri and open source GIS technologies and standards **Contact:** [www.esri.com/careers](https://www.esri.com/careers) is the best route. Some questions can be answered in the thread. **Apply Directly:** [https://www.esri.com/en-us/about/careers/job-detail?req=7782&amp;title=Visualization%20Product%20Engineer](https://www.esri.com/en-us/about/careers/job-detail?req=7782&amp;title=Visualization%20Product%20Engineer)
if you love video games or making videos, do it as a hobby. otherwise you're going to hate what you love.
Great to hear! VS isn’t very obvious about this, I also had issues in the beginning trying to figure out how to do this and it just linked to web etc which didn’t help at all.
&gt; which in turn makes it easier to read. i agree. its adding the x and y coordinates of a point object in one line!
First off, I will say don't let it bother you. You probably didn't want that job anyway and are lucky you didn't get it because it would have been terrible! That's what my wife always told me after a failed interview. And although it was just meant to try to raise my spirits, I think there was probably some truth to it. The best job I ever had was one I wasn't really excited about and took only because I wasn't picked for another job I was looking forward to accepting. Things sometimes have a way of working out like that. Keep your chin up and don't let a failed interview get you down. In most cases, it's their loss, not yours. :-)
I rattle on about this all the time. The persistence thing is not really an issue as there's no infrastructure between the event raised and the event consumed, there's no network to go down or RabbitMQ server that can be taken offline. You do have to be slightly careful because you can , optionally, use fire and forget and concurrency, but these are concepts which we have to deal with in "normal" code anyway. Where to use it? Everywhere! UI's use it a lot as a way to separate components and still allow them to communicate. On the server side it solves similar problems. If you've ever seen code where 10 dependencies are injected into a service because it needs to coordinate things, you can skip the injection and raise events/listen for events instead. The nice thing here is, it makes testing really simple. The simplicity is you call the method you want to check the result of, and if it raises the correct event you're golden. It can make debugging more complicated in that one event may be subscribed to by a billion things, but this is more of a learning thing and it becomes obvious after a bit of time. Generally you're not interested in the billion, just the one that's on the path to failure. It's difficult to provide specific examples of where to use it. Cases where you have to do n things every time are a good candidate. Imagine having a service which generates a dataset. Once it is complete you want to: * Send an email saying it is complete * Save a detailed version to a file * Send a summarised version via RabbitMQ to other interested parties. &amp;#x200B; Traditionally you'd have a class into which we'd inject the email service, the file writing service and the rabbitMQ service. Now we don't. Three separate services listen for the dataset complete event and each handles their only little job. If later you also want to transform the data on completion into something else, generate a png of it and send it to a URL, you just hook up a new event listener which does this. &amp;#x200B; Does that make sense?
I'd rather just add an extension method or local function.
It's bullshit boilerplate which is sufficiently vague that you can't cause trouble legally. Technically the feedback could be "Too white, looking for more diversity". You could immediately cause merry hell. So they don't say these types of things. Even with technical feedback, sometimes you get something useful, but generally it's too much of a risk, so you either get nothing or some vague crap like the above. &amp;#x200B; Anyway,. don't worry. I don't know the details of the role, so it's hard to even try and unpick what they said. &amp;#x200B; Interviews are weird. Don't take it personally, do try and learn from them. If they ask you 10 questions and you can't answer 1, when you get home, google it and learn (Same for if you get 10 wrong ;) )
&gt; how does one install a specific version of C# https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/configure-language-version &gt; I'd like to be able to support the latest syntax on my build server, but not sure how to accomplish this. Install the latest build tools.
Awesome, thanks!
yeah, i think this way is just easier to parse and doesn't make me need to understand what `is` is doing in that context. also, why `!(blah.Property is null)` over `blah.Property != null` or i suppose `blah?.Property != null` to be extra safe?
How about visual studio? Thinking about it for myself but not too sure what would be the best approach as I’ve only ever made really basic apps during school.
Learn Unity and make a game.
The problem with != null is that == is an operator that can be overridden. is cannot.
Don't do it by hand. Look for a Nuget package to handle all the nastiness for you. I've used this and it works well. [https://www.nuget.org/packages/ClosedXML/](https://www.nuget.org/packages/ClosedXML/) &amp;#x200B; Also consider using an in-memory dataset (less mucking about with columns, formatting), then using a utility to dump it en masse. [https://stackoverflow.com/questions/5790431/export-data-from-dataset-to-excel](https://stackoverflow.com/questions/5790431/export-data-from-dataset-to-excel)
Bah. You can already be as concise as an obfuscated Perl programmer if you want. Semicolons are line terminators. var sum = () =&gt; { var p = GetPoint(); return p.X + p.Y }; The extra symbols are there to help you realize what you're doing is borderline evil. Maybe it can only be the rhs, but I'm thinking you're going to find more of this in the wild: if ((var p = GetPoint(); var q = Normalize(p); var m = CauseSideEffect(p); var l = PointsNear(p)).Any()) I don't likes it. I've never understood the fetish for "How can I do more than one thing on a single line?"
Haha, I didn't want to say that, but you're right! I'd bet it's a completely unprofessional, unethical reason in many cases why someone doesn't get hired. Not much you can do about that.
I'd say we have about 40-50 engineers(but also 3 different consultancies), and the oldest legacy is about 15 years old. It's not an overwhelming amount of code, but some of these projects are big by themselves. I'd say there are about 50 different repos in our ADO. Some are one-off projects, others are long lived ones, others are websites that sit as a shell on our infrastructure, but the company has really written a ton of products to get a high marketshare, and is now in the process of consolidating/dealing with the technical debt. We use Azure DevOps, and have it set up to build both our develop branch and feature branches.
I wouldn't want to add an extension method for every little thing; but a local function I can kind-of get with. Still, I'm in the habit of declaring all local functions at the bottom of the enclosing/parent function; which means I'd have to navigate down to that local function to see what it was doing (unless it was well-named and/or obvious, I guess). Do you declare local funcs "in-line" alongside their usage?
This has always struck me as an overstated issue. I've been writing C# for over a decade and never had this problem. I've heard that it's abused in Unity (the game engine, not the DI framework) but that's Unity for you ¯\\_(ツ)_/¯
&gt; I've never understood the fetish for "How can I do more than one thing on a single line?" It's not about that for me, it's about removing as much useless boilerplate as possible in order to make the intention of the code stand out. It's definitely possible to go "too terse" or "too clever" but generally I feel that the language should just give us the tools and it's up to use whether we abuse them or not. On its own something like `var sum = (var p = GetPoint(); p.X + p.Y);` still looks easier to digest to me than the alternative; but I accept it can be subjective.
Right. I’ve never (knowingly?) run into this either. But this is why is null was introduced as a syntax — it’s a safer alternative.
Even with a local debugger installed and symbols, just slowing the process down with the debugger will \*probably\* keep it from happening. Memory Dumps and WinDBG are probably your friend here. &amp;#x200B; If you have another release coming up, consider logging the hell out of everything (using a .config to turn it on/off when you're done). Log4Net or similar if you can manage it.
:) It's not all evil, when you date you are going to reject and be rejected based on trivial concerns, but rarely anyone says "Yeah, I don't like your nose".
I'm sure there are good lessons, etc, which I'm sure others will help with links. One thing I would suggest, is in between lessons, try to write little programs using the material learned. Just small little ideas of your own. This will help solidify what you have learned and get your brain thinking on how to combine the skills you have gone over. Putting the pieces together.
Thank you.
I don't like your first one and I like and use the second example.
I feel like we already have a lot of options to do it concisely here. The most basic tool we have to remove boilerplate is a method. * `var sum = GetPoint().Sum(); // Extension method or implemented on the type` * `var sum = Sum(GetPoint()); // "Actually I don't want to promote the scope of Sum" * `var sum = GetDefaultSum(); // "I noticed this isn't a unique point instance" This just feels like procrastination. It's what a junior dev implements if their real job is "Record Types", but that's hard and the spec problems are unresolved, so they reckon if they grab a lot of other backlog items nobody will notice the giant 500 user point task they're assigned isn't moving.
Do **not** use FileSystemWatcher if you need to **reliably** detect changes.
Well, the first step is to get versioning under control. Why are the clients breaking when the service contract is updated? If you can fix that, then clients only need the updated nugets when they need to the new features, and you no longer have cascading NuGet dependency hell.
&gt; I need to check for a file every few minutes in a folder &gt; This might be triggered or managed through an ASP.NET MVC solution, but I might also just need it to run standalone. It's not terribly clear how you intend to run this.. But you probably want to utilize Hangfire or Quartz.Net for recurring scheduling. Then you can register the job in an ASP app. You can also write a Console app that runs the check as a one-off. If you need to run the check persistently with a recurring schedule outside of an ASP app, I would implement a Windows Service that registers the Hangfire or Quartz.Net job. If you didn't need to run persistently in an ASP app, then a plain console app running the check as a one-off could be scheduled with Windows Task Scheduler. It's a bit simpler than a Win Service with Hangfire or Quartz, but also offers less functionality.
Write Pong. https://tinodidriksen.com/2003/05/but-can-you-make-pong/
Ah now that's a capital idea! I had debated about the idea of making Space Invaders.
That's for adding indexing capabilities (such as being able to search within files of your own file format). I don't believe there's an API for what OP is asking for: &gt;doing simple calculations right inside the search bar (just like google's search engine) or typing in custom commands.
Potentially sidesteps overloads of ==/!=, but really just to show off the newer syntax for anyone that hadn't seen it. I wish they'd included some sort of not pattern to make negation less clunky, personally.
All those methods have their own implications though. * you habe to write the methods: boilerplate * if only used at for this special use case, they convolute the namespace * have a bigger performance impact Especially the first two points are important in a clean code base and for readability. But I agree with you in the sense that all those features can be easily misused, and it's important that the programmer keeps an eye on where to use what
The windows search bar already does operation. https://i.imgur.com/y1aimlr.png
Make a Magic the Gathering card database contact manager app simple game like pong
Sadly it’s not real, as there’s no source and Microsoft hasn’t said anything about that feature at all
That looks to me like Bing is doing it.
I know, you need Cortana enabled I think. But it was just an example ;)
I usually declare local functions at the top of the function.
The point isn't to do as much as possible, the point is to do one thing in one line. The point of this code is to sum the x and y of the result of getpoint. Syntax means that previously we had to separate getting the point and summing the point into two statements. The new syntax means we can actually write the code in a way that matches what it actually does.
How is that a problem?
Thanks for clearing that up.
Because some libraries make the operator do crazy stuff. (Unity, supposedly?) `is` guarantees a certain behavior.
If you are using PackageReference in your csproj you can set PrivateAssets="all" on the reference to avoid it being transitively added to other projects
I don't buy it. If your library is really that bad, null checks are the least of your problem.
If a single service is running and doing this, a simple [Task.Run](https://Task.Run) with an infinite loop inside that checks then await Task.Delays X minutes is fine. If distributed, hangfire is the way to go. Although if this is the only thing your service is doing, implement the loop directly in your Main.
Cortana can sorta do what you want. https://docs.microsoft.com/en-us/cortana/skills/overview
Have you ruled out any external factors first? Can the client reproduce the issue or is it intermittent? Does the issue still happen with antivirus disabled or excluded? Does it just happen on one computer or multiple computers? The client may have something specific to their machine builds causing the problem. Are they able to loan you one of the PCs having issues?
Can hang fire resubmit a job, or schedule the next day's pick up? Can hole at regular intervals and then shut itself off. Stop resubmitting itself? Forgive my ignorance I've never used it
Operator overloading is a language feature. To indicate no one uses it and any library that does is bad seems very arrogant. He answered your question.
I think a common confusion with Hangfire is that it can schedule applications to run. If you use hangfire, you must keep your application running 24/7 so that it can use hangfire to check when to run a function. Hangfire just lets a running program know when to a call a function, it doesn't actually control when the program itself is up or is launched.
That cause errors in runtime file not found for that package when calling methods of project referencing that package.
Probably just need to ensure the assembly in question (from the package) is explicitly copied so it's there on disk at runtime.
Yeah, because PrivateAsetts dlls are not included into build of parent projects.
The point of the tools we have is to talk about the "what", not the "why". Or at least, that's the point in high-level languages. I don't "put leaves in water and heat it", I "make tea". I don't "apply current to a strong resistor and wait until the voltage reading on a thermistor reaches a threshold", I "preheat the oven to 400. I don't want to "sum the X and Y coordinates of some default thing", I have a higher purpose and that context isn't present in our one-line summary. But you'll be hard-pressed to find software engineering literature that touts the values of "how" instead of "what".
I find the third questionable, the first laughable, and the second answered by either good SOLID practices (when your units are small there is no namespace to pollute) or local methods.
I find the declaration expression syntax really ugly, and have always wished that C# never supported it from the beginning. This line, for example, has the assignment in the middle of one of the comparison checks, making it look like the first or'd expression has nothing to do with the others. while ((ch = GetNextChar()) == 'a' || ch == 'b' || ch == 'c') I'd much rather go with putting the check in the middle of the loop. This way, it's clear that two different operations are being performed, first the call to `GetNextChar`, then the comparison. while (true) { char ch = GetNextChar(); if (ch != 'a' &amp;&amp; ch != 'b' &amp;&amp; ch != 'c') break; I'm not sure how I feel about the whole sum thing, maybe if it looked more like a mini-method. For example, I can write the following code in JavaScript (and I think it might even work in C# too after replacing let with var, but probably wouldn't be optimal). let sum = (() =&gt; { let p = GetPoint(); return p.X + p.Y; })(); It might even make more sense (and definitely be shorter) to declare a lambda to preform the summing operation. let sum = (p =&gt; p.X + p.Y)(GetPoint()); Overall, I just want to say that I'm not a fan of the latest trend in programming of cramming as much as possible on one line.
https://en.wikipedia.org/wiki/LOLCODE
What do you mean by the logic of coding? Do you mean building a complex app that benefits from design patterns?
That and a very limited cookie policy (i.e. only strictly necessary cookies, additional ones need to be opt-in with consent).
But this is why? var p = GetPoint(). Why do I have a p here? What's it for? Is it used anywhere else? Did someone use it somewhere else since I wrote this? The answer is who the fuck knows. You can use tooling to find out, but it isn't immediately obvious. With this syntax these questions have answers. P is to get the x an y of the result of getpoint(which should have a better name). It's not (and cannot be used) anywhere else, and no one has done anything stupid with it since I last looked. I then know that I can change things about P and the scope is distinct. Now yes, you could extract this into a function, but single use two line functions are bad design. You could create an anonymous function like you did, but there's a lot of overhead in anonymous functions. If you could do this, which couples two activities (getting the point and performing the sum) into one. This literally is "make tea".
That's the piece i was missing. I've never done any kind of non web work except for simple console utilities.
Yeah. I guess I have a grasp of the tools but I'm struggling to put them in a coherent design, or being able to deploy them at their full potential. Should I use an if statement or a switch?
It doesn't matter if anyone uses it. It only matters if they are using it so badly that `== null` is broken.
If SOLID is the foundation of your argument then you're building on sand.
 while (GetNextChar() is var ch &amp;&amp; (ch == 'a' || ch == 'b' || ch == 'c')) is possibly right now and probably clearer than the proposal for this sort of thing. Something more LINQ-like would probably be better for the extended declaration expression the article is described: var sum = let p = GetPoint() select p.X + p.Y; but that implies that something like this might be licit var sum = let p = GetPoint() where p.X &gt; 0 &amp;&amp; p.Y &gt; 0 select p.X + p.Y; which invites complications about the type and value of the result (is it nullable?), suggests further compounding and complication (which *definitely* makes it less readable!), and replaces existing constructs with branches and pattern matching and assignments, like the switch expression they are *finally* adding. Something like var sum = let p = GetPoint() in p.X + p.Y; might be the way to go.
You’ll need to build an application to get experience deciding which design to use. You’ll learn after a while that you run into the same problems over and over. It’s like any other skill, you need to practice and get a feel for the best option. The if/switch question is a good example. In my opinion a switch should be used sparingly, and mostly just in factories. A factory is a method or class whose responsibility it is to create another object. You shouldn’t just put a switch randomly in the middle of a method with other logic. But sometimes you might need to turn an if into a switch if the requirements of a product expand. It’s up to you to figure out if it’s worth the effort to refactor the code.
I am practicing on a regular basis but on your own you just have questions. Thank you.
I think first focus on your SQL learning. I've used Strata Scratch to prepare for my SQL interviews. Other platforms like HackerRank and DataCamp are pretty good too. Youtube videos like this one https://youtu.be/n6gM265zG68 are useful if you're trying to learn how to approach interviews.
C# 8 has so many features, but it feels like it will never be released
Check the installed .net framework.It is possible to not have the right version installed. This could lead to unexpected behavior. But a faulty machine is also possible. If the machine is overheating and throttling like crazy, it could lead to high cpu usage. WPF uses the GPU, does their machine even have a GPU? not having one could lead to problems. I known, that's pretty rare these days, but you never know.
&gt; After C# 8, I won’t be able to do either. Some people will like it less after C# 8, which I can also understand; it’s getting to be a very complex and syntactically overloaded language.
Microsoft's official introduction to C#: https://docs.microsoft.com/en-us/dotnet/csharp/tutorials/intro-to-csharp/index
Thankyou!
I say force yourself through Tod Vachev's C# course on udemy. Cost about 10 bucks. I kind of suck and get a little stuck when they start talking about methods, OOP, etc, but I was able to take what I learned and make some really cool programs for myself with the web scraper and what not which he teaches you to use. So thats the goal, the first time I kind of just listened through and got a general overview of the course. Then on the second push I started doing all the exercises until I mastered each section. I'm still working on it all but I have permanently learned a lot of the basics this way.
Of course, but I meant with the code above :)
Just make something, anything and use Google a lot, even experienced programmers Google a ton of things so don't feel ashamed that you have to google a few things
You should go to the doctor. Get your arm fixed.
I'm not understanding what you are trying to do. You can use the AWSSDK.ECS NuGet package to launch, inspect and terminate FARGATE tasks which are a collection of docker images. When the container is launched in Fargate the `AWS_REGION` environment variable will be set to the region the container is running in. I'm confused what you are trying to do with logs though. Not sure if this will help but here is some sample code to inspect a cluster and find all of the log groups for the tasks running in the cluster. ```csharp using System; using System.Collections.Generic; using Amazon; using Amazon.ECS; using Amazon.ECS.Model; namespace ConsoleApp58 { class Program { static async System.Threading.Tasks.Task Main(string[] args) { string cluster = "WebTest"; using(var client = new AmazonECSClient(RegionEndpoint.USWest2)) { var listClusterRequest = new ListTasksRequest { Cluster = cluster }; var taskArns = (await client.ListTasksAsync(listClusterRequest)).TaskArns; var describeTaskRequest = new DescribeTasksRequest { Cluster = cluster, Tasks = new List&lt;string&gt;(taskArns) }; var tasks = (await client.DescribeTasksAsync(describeTaskRequest)).Tasks; // There can be multiple tasks launched with the same task definition. Cache the task definition // that have already been processed by similar tasks already processed. var processedTaskDefinitions = new HashSet&lt;string&gt;(); foreach(var task in tasks) { if(!processedTaskDefinitions.Contains(task.TaskDefinitionArn)) { var describeTaskDefinitionRequest = new DescribeTaskDefinitionRequest { TaskDefinition = task.TaskDefinitionArn }; var taskDefinition = (await client.DescribeTaskDefinitionAsync(describeTaskDefinitionRequest)).TaskDefinition; foreach(var containerDefinition in taskDefinition.ContainerDefinitions) { if(containerDefinition.LogConfiguration.LogDriver == LogDriver.Awslogs) { Console.WriteLine($"{taskDefinition.Family}:{taskDefinition.Revision} / {containerDefinition.Name}"); foreach (var kvp in containerDefinition.LogConfiguration.Options) { Console.WriteLine($"\t{kvp.Key}: {kvp.Value}"); } } } processedTaskDefinitions.Add(task.TaskDefinitionArn); } } } } } } ```
I suggest CodeWars. Its a website that offers a well delimited challenge, you solve it and submit your code, they'll run some tests on it to see if it works and you can also see what other users submitted. As you progress you level up and the challenges become more complex, but the first levels are basically programming 101 and the solution usually only takes one method. So I think it's a great way to practice a new language. I suggest always trying to solve the problem yourself first and then comparing your code with what other users submitted. This won't teach you how to write full applications though. For this you probably should begin learning about object oriented design principles and common patterns.
Yeap, if you use database, then it will be very costly. From your budget above, it is quite hard to find VPS, if you only spend around EUR 60/year, then you can just go with shared hosting. Anyway, just take a look at [hostforlife.eu](https://hostforlife.eu). They are European based provider that support .net core. I have few clients using their service.
Avoiding extra declarations for one-time stuff is exactly why this syntax is interesting.
I finally got a Linux VPS in OHV for 30€/year plus domain which works perfectly, took me a day to install everything I needed but I found it very nice to do as I've never did it before. thanks.
You don't have to cram it. You could indent using the parentheses for example to reflect the scope better.
&gt; Can someone re-program this tool so the bottom left window is for inserting words Do it yourself? Or pay someone to do it.
What?
OVH server is not so good, right? I have tried to register with them around 2 years ago, the server very slow and they took a long time to setup 1 server, I forgot, but it seems around 4-5 days. Anyway, good luck for you.
Ohhhhh, thx
what I got is an "empty" Linux server, so I installed centOS myself and everything into it; I have to say that I don't have any complaint with them. in addition it seems good enough 2gb ram, 2 processors (don't remember the ghz) unlimited traffic it was a good deal as atm is just "testing" website.
I'm sorry but this goes beyond the scope of asking for help. It's too much effort to clone the repo, changing the code, debugging, testing, documenting, pull request, etc. If you have no idea how to do this yourself, ask the author of that program to implement the changes for you, though I wouldn't get my hopes up without being ready to pay him to do it.
Game development is typically one of the more difficult aspects of programming (no matter the language). I would suggest to get a good handle on the basics before jumping straight at trying to make a full game, as you may get frustrated and turned off to it. That said, even just fiddling around trying to make a game is a great learning experience, I simply mean don't think it is going to turn out great on your first or second try, view it as a learning experience and practice. There are some tools like [Unity](https://unity.com/) that game make development pretty simple for beginners, but the trade-off is a rigid framework and performance (which is very important with gaming). This is very dependent on the type of game you plan to create, the quality of your code, and a hundred other factors, so only take this at face value. If you want to go the more direct route to use a graphics library directly, OpenGL (suggested for cross-platform support) is a good start, but be warned, it requires knowing a huge API that has a rather steep learning-curve to the uninitiated. Would suggest save learning the use of graphics libraries directly until after you feel confident in the language and the traditional concepts of game development.
Well.... That's good then... Hopefully no problem with their service.
Your exception happens in the `ardPort.ReadLine();` call. So it seems to be related to that library you use (or is the .NET `SerialPort`?).
I have no idea what the error is about.
Perhaps you want to learn the basics of C# first, before dealing with more advanced subjects like serial communication. Also, you wrote that the data sent is: "xPosition|yPosition|REDbtnValue|YELLOWbtnValue" - Does this include a newline character at the end? `ReadLine()` tries to read a line, and a line is received once you got a newline character, or if the end of the data is reached (which does not happen unless you disconnect).
Make sure you follow the rules. They are a picky bunch. lol
Stackoverflow is an error you cannot handle in any way other than fixing the bug in your code. Try ReadExisting instead.
&gt; They are a picky bunch. Violation of rule 5 detected.
dang, you're right, totally forgot that a ***nullreference*** is a real ***reference.***
Yeah i see that
while that's generally a good place to look at, Unity3D scene recommends many so called anti-patterns (for desktop and web-app developers) which are **totally fine** in game development (e.g. fields over properties, singletons, don't do interface inside hot-paths/rendering, no proper IoC, no modular architecture (compared to things like Plugins, IoC Containers))
I rewrote the code in a c# console application and now it works for some reason.
Removed: Rule 3.
Maybe [this](https://stackoverflow.com/questions/25523212/memory-leak-issue-in-wpf-datagrid) &amp;#x200B; Answer just copied. :) &amp;#x200B; Memory leaks are a hazard when working with context menus -- especially when attaching them to grids (I have had a similar issue in the past). In the comments you mentioned that you isolated the problem to the DataGridRow Style: &lt;Setter Property="ContextMenu" Value="{StaticResource DataGridColumnHeaderContextMenu}" /&gt; I don't know exactly why the above causes a memory leak, but it does look like a risky thing to do. You're attaching the static object ("DataGridColumnHeaderContextMenu") -- meaning it cannot be disposed -- to every row in the Grid. All it takes for that to leak is for the context menu to hold a reference to the row, and for the row to be recycled. Anyway, what I think you should do in this case (and in this kind of scenario in general) is to use events to attach the context menu when the row loads, and detach it when it unloads. For DataGrid rows, this means you should attach the context menu in the [DataGrid.LoadingRow](http://msdn.microsoft.com/en-us/library/system.windows.controls.datagrid.loadingrow(v=vs.110).aspx) event, and remove it in the [UnloadingRow](http://msdn.microsoft.com/en-us/library/system.windows.controls.datagrid.unloadingrow(v=vs.110).aspx) event. This should ensure that no menu leak will occur.
Tried it. I removed the menu but it didn't have any effect.
Rn can't look into that more, still in work, maybe later. Wish you luck with debugging/solving problem
Thanks, appreciate the help!
I just wanted to add that in the Immediate window I get these messages way too many times, I don't know if there is any correlation. [System.Windows.Data](https://System.Windows.Data) Error: 4 : Cannot find source for binding with reference 'RelativeSource FindAncestor, AncestorType='System.Windows.FrameworkElement', AncestorLevel='1''. BindingExpression:Path=(0); DataItem=null; target element is 'AudioButton' (Name=''); target property is 'Foreground' (type 'Brush')
I'm not sure which of these will actually be in the 8.0 release. Declaration expressions don't seem very far along in development, and it wouldn't surprise me if it was put off to an 8.x or later version.
I've been trying to look around, what does OpenAPI exactly do? Is it a tool to quickly generate a back-end API?
There is an empty (else) if case, which is the problem.
No, there is a missing else, not en empty one. There is an "else if" which is empty though, but that is not the problem
Thanks for letting me know!
Really the names should describe what they do. 'Service' is another common one...it usually describes an intermediary class which does data access / some file operation etc. However I'd tend to avoid things like 'Manager'...as it's one of the places you dump stuff you can't find another place for. Handlers in the web world 'handle' a request...or in desktop / backend may handle a specific event (why you seen 'EventHandler' a lot) Helpers is a bit nebulous; in the Web world they usually provide some service to Views... &amp;#x200B; THe .NET Framework guidelines are really useful here [https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/names-of-classes-structs-and-interfaces](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/names-of-classes-structs-and-interfaces)
Some may consider it bad form and would typically be for web projects. I suffix my view models with 'ViewModel"
Does the lot: OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and configuration automatically given an OpenAPI Spec (v2, v3)
An OpenAPI/Swagger document describes an API, like so: https://petstore.swagger.io/v2/swagger.json This is useful because with tools like the one in this post, your API documentation can be automatically generated and used to create end user documents, imported into Postman, etc. Swashbuckle is a popular add-on for .NET as it will auto generate a swagger file based on controller method attributes and xml documentation. What's _really_ great is that if you have a swagger file, you can use swagger UI: https://petstore.swagger.io/ (Swashbuckle adds this too!).
It is going to depend on your design. This may help though https://docs.microsoft.com/en-us/ef/core/modeling/relationships
Thanks!
Thanks!
Personally, I’d use Entity Framework to do this. EF has three different strategies for how to deal with inherited class. [This 3-part blog](https://weblogs.asp.net/manavi/inheritance-mapping-strategies-with-entity-framework-code-first-ctp5-part-1-table-per-hierarchy-tph) describes them all in detail, I’d recommend reading all 3 parts. Even if you decide not to use EF, you can still mimic its strategies manually, and the blog is still a valuable resource.
I don't like conclusions that don't come with arguments. All I hear is "believe me when I say" and "everyone's talking about" etc. But whatever, go ahead and defend writing half your program on one line because "functions are hard".
I can't see the whole of your program, but I suspect that you're calling Form1 repeatedly to check the mouse, which means your program never unwinds and just keeps calling Form1s until it overflows the stack. (I'm just guessing at this based on your Ex info screenshot which shows you call mouse() from Form1, which must mean you're calling it repeatedly to check right?) Meanwhile your console version doesn't do that, it probably just loops, so it works fine. For your Form app what you want to do is call the Form1 **once** and then create a timer that will go off every N milliseconds and call your mouse() checking function. That way you won't just keep loading infinite forms until it overflows. Create a timer on your Form1 and then call the mouse() functions from the timer instead, so it gets called every n seconds. Your console app calls it once, whereas your Forms app is calling it and calling it and calling it until it runs out of stack.
The architecture of Entity Framework already covers this use case very extensively, with multiple approaches. 1. Table per hierarchy - This is where you have a single table for all types that inherit from a common base class, with a set of columns that's a union of all all classes. E.g. AbstractUser has Id and UserName. Employee and Customer inherit from AbstractUser. Employee has a property called Designation. Customer has a property called PaymentMode. Your table has the columns Id, UserName, Designation, PaymentMode and Type. Type contains the record type (Employee or Customer). This makes your table wider, with null values in columns which are not applicable to a given record. 2. Table per type - This splits your data across multiple tables. Assuming the same example as shown above, you will have a table called AbstractUser with columns Id and UserName. Then you will have a table each for Employee and Customer with a foreign key to the primary key in AbstractUser. They both also contain columns appropriate for their respective types, i.e. Designation for the Employee table and PaymentMode for Customer. 3. Table per concrete type - Your data is split across two tables in this design - one for Employee and one for Customer. Each table contains the common properties shared by each type, plus columns for their own specific needs. Employee has Id, UserName and Designation, and Customer has Id, UserName and PaymentMode. If you're using EF, which your question does seem to hint at, then there are configuration options which let you select the strategy you wish to use. The default technique is table per hierarchy.
*A simple application that ships with Windows 10 has been rewritten in C# and ported to WebAssembly* would be a bit more accurate. I was a bit underwhelmed, as I half expected them to announce some kind of virtualization in a web browser of part of the OS itself.
Thank you for the replies. &amp;#x200B; Sorry. I really have no clue of programming so i wanted to know if it is difficult or not. I allready asked the programmer if it is possible (couple of months ago) but i didnt get a reply. I would pay him. I hope this doesn't come across as a cheap shortcut for not paying someone to do it. I wouldn't have used the program for comercial benefits. Thank you
This
Me neither, I thought I was just tired :p
How Hungarian of you.
There are many trains of thought in relation to class naming, but here are the ones I typically use. &amp;#x200B; * Entity - e.g. 'Customer' - A state bag that represents the state of the entity at that point in time. Unlike traditional OOP, it doesn't own the methods that perform complex operations on itself. * EntityService - e.g. 'CustomerService' - An API within the system for interacting with customer data. This wraps up CRUD operations and high level domain operations on Customers. CRUD operations exposed here should only be used when a user of your system is directly modifying fields on a customer, for anything more complex there should be a top level method (that is, using the CRUD operations outside of the CustomerService would allow you to model complex related or macro operations on Customers, but that should be inside of the CustomerService, not outside of it). * EntityRepository - e.g. 'CustomerRepository' - If I not using an ORM, then I'll usually abstract the data access using the repository pattern (I do even sometimes when I am using an ORM, but that is more controversial). The repository is injected into the customer service so that the customer service doesn't have to know about query handling or the database details. The customer service should know about a unit of work or transaction context (though that is a more complicated discussion). * EntityChangeTracker or EntityTrackingService - e.g. 'CustomerChangeTracker' - If you kick off user events from changes in data, then you might want your customer repository or service to have a tracker than can publish out events whenever a customer entity changes. This works especially well combined with in-memory entity caching in cases where your app will always run in one server, but that approach has many caveats. I usually have a signalR publishing class that gets injected a relevant entity tracker and can listen for changes then send them on in the right shape to the relevant users. * JobNameJob - e.g. 'CustomerInvoiceJob' or 'CustomerInvoiceGenerationJob' (depending on how long the name needs to be to make it clear what it does) - If you have jobs that are long running in the background and pull work from queues, databases, or files, then it helps to give them a common naming scheme and I would suggest finding a way to make them start and stoppable at runtime. &amp;#x200B; You can get a lot more complicated with it. I will usually branch off an EntityVerb class whenever I have an action I am doing in a service that has dependencies that are specific to that action. For example, if I am working on a CustomerService and there is a method that I need to add to convert to a certain standard format, I might make a method to do it. I might take some dependencies on in the CustomerService to parse or write that type of format. It might make more sense to make a CustomerWhateverFormatter class, have it own those dependencies, and then inject it into my CustomerService class instead. &amp;#x200B; Other EntityName patterns I have used before are: EntityBatchLoader (usually used in background jobs if I'm loading batches of an Entity from some source). EntityServiceOptions - A special state bag that holds configuration for a service, usually when the configuration comes from an external source like a config file, a database, or some other [ASP.NET](https://ASP.NET) Core configuration pattern. &amp;#x200B; You'll have to build your style over time, and you'll have to learn to dynamically work with the style of the code bases you help maintain and of the developers you work with. Most senior devs don't get it right most of the time. I'm constantly wishing I had used different names for old classes all of the time, and I've been doing this for almost 15 years.
Hi 'ng', im DAD.
Thank you to everyone for the tips, I did not know that EF could do that (hopefully core is up to par with this too).
It is.
I've seen a number of vb null object pattern things where `SomeType.NullObject == null` and yet `object.ReferenceEquals(null, SomeType.NullObject) == false`. I've long argued that there is an underlying bug whenever something like that is possible, but have been told that the behavior couldn't be changed because of compatibility concerns.
Use the VS debugger and create two memory snapshots a little bit apart. Then you can see which object types keep growing over time. You can then also drill down and see what references them and keeps them from getting garbage collected.
I thought the calculator was written in c# already.
`internal void combinations(List&lt;string&gt; list, List&lt;string&gt; fin)` `{` `IEnumerable&lt;string&gt; myEn = (IEnumerable&lt;string&gt;)list;` `double count = Math.Pow(2, list.Count);` `for (int i = 1; i &lt;= count - 1; i++)` `{` `string str = Convert.ToString(i, 2).PadLeft(list.Count, '0');` `Console.WriteLine(str);` `string comb = "";` `for (int j = 0; j &lt; str.Length; j++)` `{` `if (str[j] == '1')` `{` `comb = comb + list[j] + "||";` `}` `}` [`//Console.WriteLine`](//Console.WriteLine)`(comb);` `fin.Add(comb);` `}` `}`
To be fair, so did I, but they made a specific point of saying they ported it to C#, so I took a look and sure enough it's C++.
Wow this article/blog is a really good read.
keep it cool cowboy, he didn't say `CValuesViewModel`
Don't worry, this is a pretty well put together question in no danger of violating rule 4.
Those are simply too many values. You need to adjust your algorithm to deal with the values incrementally. Look up IEnumerable and deferred execution. Divide and conquer is important when dealing with such immense large data sets.
I did mention in my post that I used JetBrains dotMemory to get the snapshots but I'm inexperienced in using it
The link you shared seems to be more inline with DB relationships between tables (PK, FK, 1-m, 1-1, m-m) and how you would configure those in code (FluentAPI, Attributes, Shadow properties) [https://docs.microsoft.com/en-us/ef/core/modeling/inheritance](https://docs.microsoft.com/en-us/ef/core/modeling/inheritance) shows how you can use FluentAPI to map class relationships but is not as in-depth as the link posted by /u/LondonPilot .
So this will affect on the speed of my execution or in the memory exception?
Depending on how good the compilers analysis is, an else clause may not be needed in general. But yes, here it would be.
Say hi to Rob for me! I graduated CS from Hull in 2007...
Both.
Bold of you to assume that anything Windows isn't running on decades old legacy code.
Thank you for all your explanation :) and sorry for my bad English :(
I got you fam, first... Create a class called Student &amp;#x200B; then two appropriate variables for age and name &amp;#x200B; after that a constant field named MIN\_AGE equal to 18 anf constant field named MAX\_AGE equal to 99 &amp;#x200B; a full property named Age (validate for minimum input MIN\_AGE and maximum input MAX\_AGE) &amp;#x200B; a nullable automatic property named Mark &amp;#x200B; Then a constructor with age and name parameters &amp;#x200B; once u finish that a readonly dynamic property named Info, combining name and age in one string &amp;#x200B; then you just have to read Age and Name from the console that you named earlier. &amp;#x200B; There you go bud all done, good luck.
Which item are you stuck in? The first onwards? The second? Do you know how to write a basic class in C#?
yeah Ik that
The instructions are pretty straightforward. This is basically a really simple jigsaw puzzle that you Google-fu to help you. If you got no experience coding, I have a painful method of doing assignments I know nothing about the details. It's called googling. And I'll tell you that you learn next to nothing if you don't ponder why the steps you took work. When you learn this way, you have to retain what you learned as tools to solve the assignment. Hence it's like a puzzle. I use a site like tutorialspoint for my programming language syntax and features reference. It's a foundation. So I see a word "Class" called Student. I literally google things like 'tutorialspoint class' or 'c# how to write a class'. Two fields? I search "C# what are fields" and "tutorialspoint c# fields" or "c# fields examples". Reading and Writing from/to console? I scan tutorialspoint c# for the closest thing to that. Luckily it was hidden under Hello World for write info. Read info requires you to recognize it's an input method and then google fu.
I got some questions regarding some of the things you mentioned, I'll need examples for constant field, full property, nullable automatic property, I know how to make a constructor so that's fine but then you got me in the dark with the rest
Quick read, but decent summary of how to get started (I assume). Looking forward to the rest of the posts in the series, as well as trying Blazor out myself at some point.
https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/constants Google is your friend. Make an attempt on your homework, post ur code where ur stuck, then maybe someone can help.
it's true that I have no experience but I still know some things and I thought that maybe I get some info on how I could do it without a general answer for my homework like when you make something in math let's say a math problem: whats 10+10? what I wanna know is the formula that maybe I'm thinking of but I'm not sure so it'll be number + number.
AFAIK the calcular app is a new UWP app. It's def not running on legacy code.
There UI isn't, the calculation engine is (per the linked blog post).
With that poor pseudo-code it's impossible to say what you're doing wrong, besides: You're doing it wrong. Provide a proper example.
At places I’ve worked, business logic classes are usually suffixed with “Service” or “Logic”. For example UserService or UserLogic.
Decades ago people very smart people knew how to write quality code that does arithmetic. Rewriting code because it's "old" is a funny concept.
But this one is not. Windows Calculator has been rewritten from scratch in Windows 10 as an UWP app. I don't understand why they picked what looks like WinRT for this project though. The app ought to be light enough that it wouldn't matter if it was written with often terser C#. I'm saying "ought to be" because when I look at the Github project it looks super big for being a calculator: https://github.com/microsoft/calculator
Thank you! Im not experienced using nuget packages, I will have to do some research.
There are code files in the calculator source dated back to 1995. It's unclear how much had been rewritten in that time (probably a lot) but they didn't start from scratch.
Don't ask others to solve your homework, otherwise you won't learn anything at all. [What are fields](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/fields) [What are constants](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/constants) [Properties](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/properties) [Automatic properties](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/auto-implemented-properties ) [Nullable types](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/nullable-types/) [Constructors](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/constructors) [Readonly keyword](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/readonly) [dynamic](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/types/using-type-dynamic) [List&lt;T&gt;](https://docs.microsoft.com/de-de/dotnet/api/system.collections.generic.list-1?view=netframework-4.8) [Console.ReadLine](https://docs.microsoft.com/de-de/dotnet/api/system.console.readline?view=netframework-4.8) [Console.WriteLine](https://docs.microsoft.com/de-de/dotnet/api/system.console.writeline?view=netframework-4.8) [Foreach Loop](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/foreach-in) [int.Parse](https://docs.microsoft.com/de-de/dotnet/api/system.int32.parse?view=netframework-4.8)
Oh, I see now... I didn't expect their CalcManager tree to be of a very different, and older, origin than the rest.
That's some rose colored glasses you seem to be wearing if you think Windows didn't have bugs decades ago. In fact some [quick googling](https://www.askvg.com/finally-classic-square-root-bug-fixed-in-calculator-in-windows-10/) shows at least one big they fixed during the Win 10 update to calculator.
And you're wearing rose colored glasses if you think people don't introduce new bugs when they rewrite code. Especially people who think they must be better engineers than everyone was 20 years ago. Legacy vs modern is a mostly orthogonal problem to quality.
I never mentioned quality when I was talking about legacy code, you're the one saying legacy code was a higher quality. They're both buggy, because that's software. It's neither good nor bad because it's legacy.
Try looking at the trace captured with PerfView in Windows Performance Analyzer (available with the Windows SDK or on the Windows Store); it's got a much more intuitive UI making it much easier to pull insights out of.
That's an argument I can agree with.
Think of a game or program you’d like to write, that’s kinda small. And just make it, google what you need to create each part and learn what the code from google actually does. After this you’ll slowly get better and better if you keep making harder and harder programs.
This are all post 8.0 features.
I will repeat that quality and legacy are mostly orthogonal.
I'm only caring to comment because I wasted my time on others who had no idea how to use learning. Your analogy about math made little sense to me. This place isn't for doing your homework for you. A math test problem like "Solve this 2nd order ode" can't be solved with real skill when you're asking the instructor for all the steps to solve it during the exam. In fact I failed a test because I couldn't recall the steps. The goal is to UNDERSTAND the steps, then memorize the steps and finally apply it generally over and over. If you want a code review, post your code. No one writes code for this.
I found [The C# Player's Guide (3rd Ed.)](https://www.amazon.com/C-Players-Guide-3rd/dp/0985580135) to be pretty solid at teaching the basics of the C# language. I particularly liked how they diagrammed the various data types. [Head First C# (3rd Ed.)](https://www.amazon.com/Head-First-Learners-Real-World-Programming/dp/1449343503/ref=sr_1_1?keywords=head+first+C%23&amp;qid=1562168582&amp;s=books&amp;sr=1-1) was also good, but it's pretty out of date at this point. If you can use Visual Studio 2015 or earlier, you should still be able to follow along without too much trouble. After that, the templates they use for doing UI are no longer available, so you'd have to do some extra work there. That said, Head First C# includes a lot more general Computer Science information the Player's Guide, and includes UI design and implementation. I think one issue with hard copy books is that C# and .NET are evolving really really fast currently, which makes it hard to keep up to date. As far as projects go, I totally know how difficult it can be to think of something when you're specifically trying to. Several projects I've made ended up being due to some need. For example, I have a project idea I really need to get started at some point for a recipe book for Breath of the Wild. I want something light weight that I can use to record the recipes I find in game, as well as being able to store additional useful information (such as places where ingredients drop or can be purchased, purchase prices, etc). Another project idea that I've played with a bit here and there is a basic character stat generator for an RPG. This is something that can be super simple, but can also be expanded a great deal into a complex program.
C/C++ was historically hard to write because of unmanaged memory. .NET and other modern languages take that burden off the programmer. Memory management leads to a literal shitton of bugs while managed Languages mostly consist of Logic Bugs, so I would consider new code to definetly have advantages...
"besides: your doing it wrong" What is being done wrong, aside from the lack of code?
&gt; good SOLID practices (when your units are small there is no namespace to pollute) …I’m sorry, what? Doesn’t smaller units imply *more* pollution?
What you're doing wrong is hiding in the code, and it's not possible to tell without it. It won't make a difference if you assign a property in the constructor or in the object initializer. Both will run to completion before anyone else gets access to the object.
&gt;a nullable automatic property named Mark I honestly thought all students had an instance of a Student named Mark.
&gt; I’ve seen a number of vb null object pattern things VB doesn’t have `null`, and it’s similar `Nothing` is not exactly the same as C# null. (For example, `Dim i as Integer = Nothing` is valid. `int i = null` is not. `Nothing` can mean `default` in C# lingo.)
Yes, but “API developers shouldn’t have done this crap five years ago” isn’t a helpful argument for the compiler team, who need to look backwards as well as forwards.
&gt; What am I missing? I don’t know what *you’re* missing, but *your post* is missing a ton of context for us to help.
If you absolutely need to bypass operator overloads you can always use `((object)x) == null` or `Object.ReferenceEquals(x, null)`. I would argue that `x is null` is broken if it doesn't return the same result as `x == null`, but it's too late to fix it now.
Removed: Rule 4.
&gt;at least one big There's a big in your comment
I use the vm variable to set the property in the vm `vm.prop = prop`
SRP means * one line per method * one method per class * one class per namespace * one namespace per library (I've heard all of these at one time or another, though not necessarily all from the same person.)
Damn you Gboard!
And that's it. The code execution leaves the scope, the vm variable is not referenced anymore, and it will be garbage collected. Seriously, this is getting ridiculous. Share some real code. Currently you're violating a subreddit rule (request for help should be made with effort). Until you show a minimum amount of effort I'm done with this thread.
Still relevant and much better than many others
I know, I was calling libraries written in VB and full of VBisms from C#. For example most of the time those `NullObject` static properties were properties, but one or two of them were methods with no parameters. The vb documentation didn't care but Visual Studio .NET sure did. I certainly don't miss the days before Resharper. IIRC `Nothing` is the same as `default(T)` except if you are doing string equality comparisons where `Nothing` is either `null` or `String.Empty`.
Create a custom DataGrid (like your AudioButton and ImageButton) and then register dependency properties. &amp;#x200B; Next you will need to create another class (let's call it DataGridPropertyProviderBase.cs) so you can bind the CustomDataGrid in XAML to a property in your code behind or another view model. &amp;#x200B; Fill DataGridPropertyProviderBase.cs with the bind-able properties that are also registered as dependency properties in CustomDataGrid.cs and then you can control what happens and how this custom datagrid behaves outside of the XAML. &amp;#x200B; I would assign all the visual attributes in the XAML instead of trying to manually assign the look and feel of the buttons in C#. Set an instance of DataGridPropertyProviderBase to the FancyNewDataGrid property and your audio or image collection to the Items property and let WPF handle the rest. public class CustomDataGrid : DataGrid { public static readonly DependencyProperty RightClickCommandProperty = DependencyProperty.Register("RightClickCommand", typeof(ICommand), typeof(CustomDataGrid); public CustomDataGrid() { this.MouseRightButtonUp += this.CustomDataGrid_MouseRightButtonUp; } public ICommand RightClickCommand { get { return (ICommand)this.GetValue(RightClickCommandProperty); } set { this.SetValue(RightClickCommandProperty, value); } } private void CustomDataGrid_MouseRightButtonUp(object sender, MouseButtonEventArgs e) { this.RightClickCommand?.Execute(null); } } public class DataGridPropertyProviderBase { public IEnumerable&lt;Button&gt; Items { get; set; } public ICommand RightClickCommand { get; set; } } ...in a file.xaml far, far away.... &lt;local:CustomDataGrid DataContext="{Binding FancyDataGrid}" ItemsSource="{Binding Items}" RightClickCommand="{Binding RightClickCommand}" /&gt; I haven't noticed any memory leaks with this implementation. FYI, most of my knowledge and experience is working with MVVM. But this can all be accomplished in the code behind as well if need be.
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/sizeof
Doesn't work with structs (at least says to enable unsafe code)
If you can't get started from there, which literally has a table showing the sizes of all the aliased value types in c#, I'm not going to sit here and spoon feed you dude.
imma look into it thanks
Not if you're doing it right. The point of smaller units is so that I go from this WinForms mentality: &gt; "When I click the 'Get Data' button, open a connection to the database and execute this SQL query. For each row in the result set, get a Point object, sum its coordinates, then add the result to this list. After that, for each item in the list, create a new ListViewItem with the value and add it to the ListView." To this mentality: &gt; "When I click the 'Get Data' button, execute the GetDataCommand." No need for utility methods there. So what's the command do? &gt; "I have a reference to a PointRepository, call GetSumsAsync() and, when it finishes, add the results to the `Sums` property. The UI's bound to that property, when `Sums` updates it'll update its ListView. No imports for the sum method needed. What's `PointRepository.GetSumsAsync()` do? &gt; "I have a reference to some utility that fetches Points from the database. I'll use `Select()` to apply my `Sum()` method to each point and return the sums." That's where the helper method exists. We don't have to dive deeper, because the layer beneath has no knowledge, its only job is "get Points from the data store". SRP isn't about making a million classes. It's about organizing your code the same way we organize other complex systems. The human body would be impossible to describe if we had one flat hierarchy including every organelle. Instead we divide the body into systems, and systems into organs, and organs into cells, and cells into organelles. We pick which layer of abstraction we want to discuss, like "the nervous system" or "the sciatic nerve" or "a neuron", and we don't talk about the layers above or below it, only how this particular thing receives inputs and creates outputs.
A lot of the calculator is handling localization. It's really not so big. The Ratpack calculator was the same as it was since Windows 95 and is super small.
did they actually "port it"? Sounds like they kept the C++ as C++ considering they had to P/Invoke.
&gt; And you're wearing rose colored glasses if you think people don't introduce new bugs when they rewrite code. Its not guaranteed though, especially if you identify core issues with the old that you solve with new. As much as I hate to rewrite code I often encounter a fear and pushback over changes that **need** to happen to promote development volition in favour of keeping things old and skanky. Old and nice, sure its not a problem but people use these arguments to defend old and skanky too.
the problem is that gesellschaft is abstract and the json parser cant create an abstract class as it doesnt know if it means LGesellschaft or SGesellschaft PS: keep the code in english
It would be useful if you also post how you send the data to the controller.
I am not asking for spoonfeeding 🙂 This wasn't even my question. I was wondering if there was an easy way to calculate it, as it seems as basics maths really, so I see no reason why wouldn't reflection or the like help. Thanks for pointing me there at least.
I disagree. Performance and optimization should always be the end goal of a project, so there’s no reason why you’d port over a working C/C++ app to something like C#. You gain nothing. People use languages like Java and C# because they allow for faster development, but for an already existing app, faster development is rather irrelevant.
Bugs can be fixed. Rewrite an app, and you have entirely new bugs.
For your average modern software developer, I’d agree. But Microsoft has had the pick of the litter when recruiting for decades, and back then was the time where memory management was one of the largest and most covered subjects.
To be fair, for something like the calculator anything short of a huge rewrite wouldn't have fixed "bugs" like working on high DPI monitors, resizing properly, Windows theming... Probably why they gutted the UI in the first place.
Remote Desktop or buy a usb keyboard. If you have an iPhone, there is a C# editor app you can download but it’s very shitty and uses an online compiler.
I agree but that's all true about new and skanky code too.
Wrong. Most of the code is decades old. Which is fine, calculator logic doesn’t change.
I just used their words.
I think i dont even have usb ports available on it anymore, i was already using one for an extra monitor(because the display is also almost dead) and another for a mouse.
Then buy a Bluetooth keyboard.
&gt; Memory management leads to a literal shitton of bugs Only when not done correctly. Writing correct programs is hard in any language. The skill and diligence of the programmer is usually a bigger factor in code quality than the language. C# brings it's own set of problems, not the least of which is over confidence of programmers who think they can ignore lifetime issues because GC is magic. You can also refactor legacy C++ to use unique_ptr to avoid the vast majority of memory management issues. This should usually be much simpler, and less error prone, than porting everything to another language.
You can just buy a hub for the port you're using for mouse so now you can use it for both mouse and keyboard
React.NET is a good starter. The docs are halfway decent. I just use create-react-app and then create my production build, link it to the index of whatever I’m serving. Doing it this way prevents having js package clutter in my .net core project directories. It’s much cleaner this way in my opinion. Unless you want to do live transpiling (which is a cluster of a mess), that’s the way I would do it.
They kept the underlying calculation engine which is written in C++ as I understand it, the presentation code was originally in C++/CX which was then ported to C#
It's still risky, as some tend to include that POCO nuget in other nugets and there you are again. Plus, consider that you want those API/services to be language agnostic.
Great summary. I internalize this a little more every time I read about it. Thanks for writing it up. Regarding #2, table per type, wondering if you can confirm that the relations between AbstractUser and Employee and AbstractUser and Customer will be 1-0..1 (one to zero or one)? And also does dbcontext surface collections of Employees and Customers for direct querying, in addition to AbstractUsers?
Sorry for being late to the party. I've worked on such a system myself, so I understand the frustration. I agree with a good part of the other comments, and I would just let consumers map the response to their own DTOs.
&gt; Rob for me! I graduated CS from Hull in 2007... Miles? He left just before i started i belive, 3 years ago ish
Where do you live? If it's business critical and you absolutely need it, I can ship you my old Asus transformer if you live in North America.
Im not from NA.
Oh no, I think my keyboard just died too.
&gt;The human body would be impossible to describe if we had one flat hierarchy including every organelle. Instead we divide the body into systems, and systems into organs, and organs into cells, and cells into organelles. We pick which layer of abstraction we want to discuss, like "the nervous system" or "the sciatic nerve" or "a neuron", and we don't talk about the layers above or below it, only how this particular thing receives inputs and creates outputs. Exactly. Systems. We don't have a _nose repository_ and a _get food in mouth repository_.
Then buy a Bluetooth keyboard. :P
But it’s super business critical though, this porn isn’t going to watch itself.
Removed: Rule 1, Rule 4.
Removed: Rule 3, Rule 4. /r/learnprogramming has a good FAQ with some project ideas: https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_where_can_i_find_practice_exercises_and_project_ideas.3F
Can you describe your layers?
Wow, thanks! That has given me plenty to think about it's actually my first MVVM project and it was a real headache and an eye opener at the same time, every other time it was Forms or Asp.Net Core mostly.
wonder if they will bother continuing or just put a pure redirect to the official in browser .NET playground - https://try.dot.net/ i guess you cant share code/samples since its not like a fiddler like site
Making the transition from WinForms to WPF has a STEEP learning curve! I'd recommend getting a copy of WPF textbook. The one I use is a little dated, but it really demystified a lot of things I wouldn't have even been able to attempt without it. WPF4 Unleashed is the book's name. To me, MVVM wasn't the hardest aspect to get the hang of; always felt like MVC and MVP. Best of luck and happy coding!
Do your schedules actually have different behaviours, or are they basically just the same Schedule with a different timescale property?
I could agree on mvvm having a learning curve. But why aren't so many wpf/c# enterprise applications not built in c++ then? Try reading about the following * Event aggregator &amp; passing events around, pub sub. * Patterns that go along with c#/xaml/mvvm like dependency inject, unity, prism, modular structure etc
I don't think those attributes are in the preview yet.
You bring up a really good point about changing Skillsets, i would guess a lot of companies try to stay ahead in terms of using new Technologies so they dont end up like NASA having to pay a COBOL dev a lot of money because they are so damn rare. Doesnt really apply too much to C++ specifically though because the language spec gets regular revisions, but it still is a valid point.
I'll have to go back and look in the newer releases. I want table per concrete type, which it couldn't do previously. At least not automatically.
I don't think they published anywhere, you can paste [the declarations](https://github.com/dotnet/csharplang/wiki/Nullable-Reference-Types-Preview#annotation-attributes) in your own project and the compiler will recognize them as long as they have the right namespace and name. [Seems like they're being replaced with new variants in an upcoming version, though.](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.codeanalysis.notnullwhenattribute?view=netcore-3.0)
And yet Microsoft is still, after all those years, fixing dozents of memory management issues every 2 weeks... You can't make a secure Programm unless you spent an ungodly amount of money on it, and even then, it probably still isnt free of bugs. But you can atleast reduce the errorprofile by using modern technologies that reduce attack surface.
The second link here is the correct set of attributes. They're in the latest corefx previews, but the support isn't in a publicly-released compiler yet. They should be fully supported by preview 8.
the name of the class should be what it does: User, IUserRepository, UserRepository, IUserService, UserService, IMessageHandler, MessageHandler. Notice how some of these follow a pattern, these are some common conventions to interfaces and certain patterns/architectures. you should read about design patterns (and anti patterns) and things like SOLID principles, DRY principle, etc. look at existing code in github of a proper project. look at the .net framework classes- how they are named, the names of properties, methods, results, etc. these mostly following convention that MS and the community have set. btw having Helper classes is usually a red flag, unless it really is a useful helper method that can be called in multiple places (classes, etc)... we usually create these as Extension methods in .NET.
As for declaration expressions, they really are no more complex that the ability to introduce variables in the middle of an expression with the existing *is* operator. If it does make it into the language, use at your own discretion, obviously. After all, I did follow up the whole proposal with these words: *If you need to.*
i don't think you can configure intellisense like that
The older ones are actually supported in current Roslyn versions, as far as I can tell. Not sure about the exact range of versions.
Yeah, there was some support for it, but that's been ripped out at this point and the new attributes are mostly implemented.
C and C++ is modern. You clearly don’t know what you’re talking about.
OAG FlightView. Costs $$ though.
Few things - 1. Don't expose dbcontext in controller. Create a repository layer that works with the dbcontext. Then create a service layer that works with the repo layer. Then... expose the service layer to the controller. 2. [HttpGet("{email}&amp;{password}", Name = "Login")]... You cannot use a GET request here, it needs to be a POST request. Your method shouldbe the following: [AllowAnonymous] [HttpPost("login")] public async Task&lt;IActionResult&gt; Login([FromBody]LoginVM vm) { if (ModelState.IsValid) { if (vm.GrantType == "password") { var user = await _userManager.FindByEmailAsync(vm.Email); if (user != null) { var result = await _signInManager.CheckPasswordSignInAsync(user, vm.Password, true); if (result.Succeeded) { var tokenResponse = await _tokenService.GetTokensAsync(user, vm.ClientId, vm.Scope, vm.RememberMe); if (tokenResponse != null) { return Ok(tokenResponse); } } } } } // don't want to throw a badrequest error on failure return Ok(new { invalid = true }); } and your LoginVM will be: public class LoginVM { [Required] [EmailAddress] public string Email { get; set; } [Required] public string Password { get; set; } [Required] public int ClientId { get; set; } [Required] public string GrantType { get; set; } public string Scope { get; set; } public bool RememberMe { get; set; } public LoginVM() { } } Hope this helps.
Your last sentence sounds like a comment out of /r/itsaunixsystem
&gt; if you think Windows didn't have bugs decades ago I don't think that's what he/she was implying. I understand the debate between legacy and modern systems and the arguments for both. If a legacy system does not compromise or add unnecessary complication to implementation, you'd need a compelling case to rewrite it, especially if it is in fact good, well-tested, bug-free (lol) code written in a time when every CPU cycle was very valuable and thus well-optimized. Sure, you could say that because modern hardware is much faster and more efficient than back then that minute optimization does not matter, but, again, rewriting perfectly good code just to say it's no longer "legacy" is pretty silly.
You need to explicitly send the desired type in the request. See https://stackoverflow.com/a/23999085/1600 for instance.
&gt; PS: keep the code in english For general code, sure. For domain code, that‘s tricky (good luck doing support calls when the customer uses completely different words than your code) and sometimes downright impossible (e.g., country-specific legal terms). But yeah, you (probably) shouldn’t have a HoleDaten method instead of GetData. For better or worse, C# keywords are in English, and most of your dependencies will be as well.
The end goal of a project is to meet the needs of the customer(s). It doesn't matter how optimized for performance your application is if it's useless to them.
Joel Spolsky's ["Things you should never do Part I"](https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/) comes to mind: &gt;There’s a subtle reason that programmers always want to throw away the code and start over. The reason is that they think the old code is a mess. And here is the interesting observation: they are probably wrong. The reason that they think the old code is a mess is because of a cardinal, fundamental law of programming: It’s harder to read code than to write it.
I'd learn react without worrying about ASP.Net core, as the latter is mainly there to provide back end APIS and the templates tend to lock you in to a certain rendition of how to buold react apps - good for simple stuff but there are often better ways to buold and host react apps separately from your. Net Api apps. Therefore there'll be many good resources out there specifically about react and the APIs they call are separate (although could be hosted under the same domain/host name but in a different server app and resource path to avoid worrying about CORS) Here's some background: Setting aside server side pre rendering which you can live without for all but the most high performance sites (and even then...), the relationship between react and .Net core is very loose in that react as a client side framework will typically make calls to one or more APIs that can be hosted in any one of a number of server side technologies (NodeJS, Asp.net core or framework and a plethora of others). The react app's static files (as they usually are static files after going through some kind if buold pipeline) aelre usually best served from a plain Web server (such as nginx or even IIS ) though you may end up needing functionality in that Web server that could need the asp.net core runtime (but serving out static resources really ought not involve asp.net).
This is one of the nice aspects of expression-oriented languages - any piece of code can be nested in any other piece, since everything is an expression. For example, in F#: let sum = let p = GetPoint() p.X + p.Y I'm not so sure that trying to shoehorn these concepts into a statement-oriented language is going to work.
It depends, there are patterns and designs that are clearly superior to others in given use-cases. Just because the developers made mistakes in their designs (that hey, maybe weren't mistakes then) back then shouldn't mean we're forced to forever live with them.
That’s just wrong. Making basic functionality your end goal is moronic.
Why wouldn’t you throw a bad request on invalid model state? You should be returning the correct http status codes for each different piece of validation.
Because it’s a login form. I don’t want to give any information on if the request went wrong or not to malicious attempts.
I agree, there is some information you want to hide, like not revealing if a user exists or not. I still think that you should return a 400 if the model is invalid. If the user doesn’t exist or the password is incorrect, then I would return either a 401 or 403.
The line of thinking is that bots will hammer a login form until it gets a 200. The user doesn’t care about these codes, so if you throw a 200 on a malicious attempt, it confuses a bot j to thinking it logged in but it really didn’t so it stops attempts. It’s not much of a security feature, but it’s just another thing added on top of all the other protocols.
Ok, interesting. I haven’t heard this before.
Great blog post, and a very interesting approach. An alternative answer to the maintainability headache (where refactoring a whole stack with unit tests can take a long long time) is Behavioural Driven Development (BDD) - what are your thoughts on that?
&gt; It’s harder to read code than to write it. In general, I would tend to agree; however, it is sometimes possible to write readable code, and it's up to the current developer(s) to make the decision to do so. Arrogance may also be a factor: "He's shit, his code is shit, it's all shit. I'm gonna rebuild this from the ground up and it's gonna be gold"
I'd put money on the cause of your problem being that in the control initialized event you are appending items to wordlist, but you don't appear at any point to be removing items from that list (you haven't included the code that instantiates the list, so correct me if I'm wrong). It looks to me like you're just creating a list that is ever growing. Now, unless wordlist is an ObservableCollection, you may not see that in your UI. I suspect the binding might be happening as the control is constructed (so your UI always shows only the initial state of wordlist) but the initialized event firing multiple times. If wordlist is a simple List&lt;T&gt;, you could get a quick insight into whether that is the issue by changing it to ObservableCollection&lt;T&gt; - you should see the UI data grid getting bigger at each reload.
I agree with you except for the 401/403 part. For the auth systems I've implemented, any invalid request is just a 400 request. Bad modelstate is a 400 with modelstate errors. Anything else is a 400 error with a generic "could not log you in" type message with no additional information. Those 400 entries can also be pushed to Application Insights if you want to analyze them later, or trigger an SMS/email alert if the failure rate exceeds a certain high amount.
Your projects should be separated so it shouldn’t matter what your backend is. Check out Stephen Grider’s courses on Udemy.
They have different properties. Weekly is different because it contains a list of enum values for each day of the week the schedule would run Monthly has a complex object that holds two properties the week in the month and the day (first Tuesday, third Wednesday, etc) Yearly and daily use the same properties.
&gt; they're unifying everything under one umbrella That already happened years ago. &gt; In ASP.NET Core 3, how does webapi fit within MVC and Razor pages? The same way it does in ASP.Net Core v2, or ASP.Net Core v1 - MVC is middleware added to the ASP.Net Core request pipeline. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/?view=aspnetcore-3.0 (notice there's no difference between this and `?view=aspnetcore-1.0`) Some more general ASP.Net pipeline info: https://msdn.microsoft.com/en-us/magazine/mt833464.aspx
Cliffs notes: Author doesnt realise treat test code like production code and writes lots of badily written tests with unnecessary duplication. Author then finds magic new way to solve writing duplicate code in tests. &amp;#x200B; Author\_Also\_Needs\_To\_Stop\_Using\_Naming\_Construct\_That\_Encourages\_Testing\_Methods\_Instead\_Of\_Business\_Requirements
create react app I think is one of the best boilerplates to start a react project.
Maybe you need to add a ref to the file which contains this name space or provide the actual code for it.
The problem could be any number of things... Could you please tell us: * What you're trying to do * what that error is * What Dispenser is * What you've already tried looking up in your search engine of choice.
It doesn't say all code is hard to read. It says it's harder to read code than it is to write it. Heck, you've kind of provided evidence yourself here- That's why there are approaches to *writing* readable code, and not techniques for reading code.
Explained in an ultra simplified way, it's all just layers on top of plain controllers. I think it's been unified as far back as full framework MVC 5. That's when I remember them trying to get devs to let go of the differentiation. Web API is plain controllers that return status codes and optional data. MVC sticks an additional html view + model binding layer on top of that so entire HTML pages are returned. Razor pages abstracts MVC even further to glue a page view and a controller for that page together, almost like WebForms codebehind.
@realjoeydood @Octopork First of all thank you for taking the time to reply. Secondly, I am making a program for a dispenser machine, the error is that "The type or namespace 'Dispenser' could not be found", Dispenser is a new namespace from what I can tell hence I need to make a new 'using' called 'Dispenser' in order to use it, and finally I have been looking into creating a new namespace or reference which can be used as using in another project in Visual Studio 2019. &amp;#x200B; @realjoeydood that's why I need to make a new 'using' namespace however I was unable to understand after searching on Google hence I'm here.
@realjoeydood that's why I need to make a new 'using' namespace however I was unable to understand after searching on Google hence I'm here
@Octopork I am making a program for a dispenser machine, the error is that "The type or namespace 'Dispenser' could not be found", Dispenser is a new namespace from what I can tell hence I need to make a new 'using' called 'Dispenser' in order to use it, and finally I have been looking into creating a new namespace or reference which can be used as using in another project in Visual Studio 2019
if this is for something non-commercial just scrape someone else's service
It strikes me as very unwise to ignore legitimate bug reports just because of *who* reported it.
If you need to create the name space from scratch, right click your project in solution explorer and select add | add class. If you need to add an existing name space which is in a file, right click your project and add a reference, navigate to the source file (possibly a dll). If you have the actual class code as a file, right click your project and add class and point to the file. I will try to help you if that does not work. Hard to do this using posts to communicate.
@realjoeydood Thank you so much I know it's difficult, If possible I do not mind using a more comfortable platform for communication. And as for the issue I am trying to create 'using [Dispenser.Properties](https://Dispenser.Properties)' which I do not know how, however I do have it's coding. &lt;blockquote class="imgur-embed-pub" lang="en" data-id="a/dFin04B" data-context="false" &gt;&lt;a href="[//imgur.com/a/dFin04B](//imgur.com/a/dFin04B)"&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;script async src="[//s.imgur.com/min/embed.js](//s.imgur.com/min/embed.js)" charset="utf-8"&gt;&lt;/script&gt;
Then first, right click your project in solution explorer and select add | add class. Save the new class' file. It will then appear in vs. Change the name space to Dispenser. Create a public void Properties() { Code goes here... }
No Problem. I am able to create '[Dispenser.Properties](https://Dispenser.Properties)' now which solves the first problem. I posted an Imgur picture link if you notice their is no use of the usual namespace as it is really different, so my question is, Do I have a wrong file? Plus on the left tab you can see that the dispenser properties only has 'Settings' and 'Resources'.
Hard to tell, I'm on mobile. If the name space appears, whether usual or strange, you likely have done it right.
@realjoeydood I have a couple of hours before I solve this issue, most probably 3\~3.5hrs roughly so I can wait for you until you reach your PC and can comfortably see the picture and reply.
Okie.
A using just implies that a class namespace is being referenced in the current file. Soo, if you are working in a c# console app, and make a new folder and a new clasS, that class’ namespace will be technically different from the first file, and if you want to reference it in the first you would pull it in via a using statement. Sooo... you don’t really create usings, you create classes and it’s just a reference to a class in another directory
This is the best way to describe it. Controller for example is used in MVC while ControllerBase is used in the traditional Web Api RESTful requests.
So can you use Dispenser.Properties.Settings and Dispenser.Properties.Resources properly?
Unable to, really need those two in order to be able to calculate certain quantities and to continue programming. If u want I will send u the file itself making it easier for you to look at it.
If you've used it, can you give an estimate?
i wouldn't be able to help any further until tomorrow sometime. it is late here and i need to rest because i was dreaming about coding all night and waking up to figure out stuff and then had to actually do the work today. running on empty!
No Worries then, Rain check for today it is.
&gt; Testing_Methods_Instead_Of_Business_Requirements Business requirements mostly cover the scope of multiple units and are out of scope of unit testing.
What do you define as a unit? I've always had issues with this because everyone assumes a single class, but if you do TDD properly, you'd start from bad code (make it green), then refactor it. Therefore, it's likely that you'll split a class only after the tests are created, so you'd be covering witha test more than a single unit if we use a class as the unit. I personally edge closer to a unit being a small cluster of classes. Thoughts?
So let me understand you right, you'd rather give your customer a fast thing they don't need than a slightly slower thing they do?
What constitutes a unit can vary, but a class is a common case. &gt; if you do TDD properly, you'd start from bad code (make it green), then refactor it. If you do TDD properly, you start from nothing. Then you write the failing test, then you write code to make the test pass with the "least" amount of effort, then you refactor. Repeat. If you start with bad code already, then you're not doing TDD.
Of course not. But stopping just once you have functionality is terrible practice.
Sorry I misspoke. I meant that an intermediate step is "bad code", aka least amount of effort. The point I was trying to make was that after you have "least amount of effort" code, it's likely you'll split and simplify it, without modifying the test, as that's how you guarantee it is not coupled to implementation, so in many cases your tests will cover multiple classes.
MVC controller and WebAPI controller are one and the same, if you return a view it serves like MVC controller of the old and if you return some other result like json it serves as web api controller.
A unit doesn't has to be only one class, yes. But a single purpose. For example serialization, validation, storage. A business requirements usually covers all three of these examples.
Agreed, those would be separate tests as they are separate concerns 👍
It is a requirement that an order line have a quantity of 1 or more. OrderLineZeroQuantiyErrors or SaveOrderAsync\_QuantityOfZero\_ThrowsException &amp;#x200B; IMHO the premise is broken. Testing methods is not the right way to think about TDD or even it's poor brother unit testing.
You have to put the namespace keyword around your class namespace Dispenser.Properties { class yourClass {} }
How does this compare to Cake build?
I wasn't a party to the negotiation, and couldn't guess at what other arrangements might be on the table, but we made an agreement to pay a percentage of our sales on the product that uses their data and that fee amounts to several thousand dollars per month.
I'm missing something here. It's quite possible it's because I don't understand some of the libraries, but take this one as an example [Theory, UnitTest] public void DoAThing_WhenCalled_ExampleWithSetup( [Frozen] IDependency1 dep1, AwesomeClass sut) { // Arrange var withThis = "&lt;SomeUserInputThatWillLookLikeThis&gt;"; var withThat = 3; // Also a specific case // Setup the interface to respond with the value expected from that // interface when calling it. A.CallTo(() =&gt; dep1.Result(withThis)).Returns(5); // Act var result = sut.DoAThing(withThis, withThat); // Assert result.Should().Be("8"); } you configure dep1.Result with parameter withThis to return 5. From there dep1 is never used. Is dep1 used somewhere and I just don't understand?
You need Visual Studio 2019. Not VScode
Can you see winforms if you just enter "dotnet new"?
Post the output of dotnet --version. You need to be running on a 3.0 version.
If you look at the implementation of AwesomeClass (the sut) you will see this: ```cs public class AwesomeClass : IAwesomeClass { private readonly IDependency1 _dep1; private readonly IDependency2 _dep2; private readonly IDependency3 _dep3; private readonly IDependency4 _dep4; public AwesomeClass(IDependency1 dep1, IDependency2 dep2, IDependency3 dep3, IDependency4 dep4) { _dep1 = dep1; _dep2 = dep2; _dep3 = dep3; _dep4 = dep4; } public string DoAThing(string withThis, int withThat) { var someResult = _dep1.Result(withThis); someResult += withThat; return someResult.ToString(); } public string DoAnotherThing(string withThis, int withThat) { var someResult = _dep2.Result(withThis); someResult += withThat; return someResult.ToString(); } // And many more thing to come } ``` You can see that dependency one is being used in the "DoAThing" method. This was the method being tested in the referenced unit test. By "preloading" the value 5 in dependency 1 I can predict what the outcome of the test will be.
No its not listed.
how do you get a 3.0 version?
Oh, sad. Is there a way to make a program with a window without using Visual Studio 2019?
Do you have the 3.0 preview installed? If not, download it [here](https://dotnet.microsoft.com/download/dotnet-core/3.0) and try again.
Hi, In my post I was exaggerating somewhat in my example unit tests, but having written loads of unit tests in my career, I know that unit tests eventually become cluttered like that. As for my naming constructs, I'm just following Microsoft best practices. [https://docs.microsoft.com/en-us/dotnet/core/testing/unit-testing-best-practices](https://docs.microsoft.com/en-us/dotnet/core/testing/unit-testing-best-practices)
It says I need Visual Studio 2019, but I don't have that.
Got it. I didn't realise the dep1 was being injected into sut. Thanks
You can download a free community version [here](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community&amp;rel=16).
&gt; I’ve always had issues with this because everyone assumes a single class, but if you do TDD properly, you’d start from bad code (make it green), then refactor it. &gt; &gt; Therefore, it’s likely that you’ll split a class only after the tests are created, so you’d be covering witha test more than a single unit if we use a class as the unit. That’s a case where you’re *retroactively* introducing TDD. If you start out with TDD, you start with the tests (against unimplemented methods / stubs), which will then obviously fail, then start implementing. Refactoring isn’t part of that process. Unit tests (*regardless* of TDD) help protect against regressions, giving you more confidence when refactoring.
This. A business requirement tends to span units and is more properly tested in a system test or integration test.
I already tried that before, but it wants me to purchase it, complaining that my free trial has expired.
There is a big difference between Test-Driven Development, which is what I'm talking about here and Behavioural Driven Development and their way of testing. I'm personally a big fan of TDD, but it's more like a personal flavour. I don't think there is anything wrong with both the methodologies. I have not done much BDD yet, but I'm going to take a look at it soon, and I understand your concerns in the naming of my tests but for the sake of the exercise here I don't think it matters that much. I believe these principles still can be used even in BDD but don't pin me on that as I have too little experience in BDD.
I will look into BDD soon, it looks promising, but I have no experience with it yet.
Then you probably downloaded the Pro/Enterprise version. You need the community version, which has no trial and is free for personal use.
You download it from the Microsoft website.
someone else already beat you to it. they even provided a link.
I downloaded it from the link you provided and it yielded the same result.
Yes. Winforms is just a wrapper over GDI+, which is a Windows API that you can access yourself with [Extern], or MFC, both of which are of course unmanaged code. You'd probably be better off using C++ instead, if you're unwilling to use the Winforms IDE. I assume you know that Visual Studio 2019 (actually all versions) are free for personal use, yes?
It sounds like you are not signed into Visual Studio. You need to sign in using your Microsoft account to further use the Community edition. But the prompt should have told you that already.
Full disclousure I am the author of FlubuCore. I recommend you to go through [Github readme](https://github.com/dotnetcore/FlubuCore) and [build script fundamentals](https://flubucore.dotnetcore.xyz/buildscript-fundamentals/) If u are familiar with cake you will be able to make comparision by yourself and create your own opinion. But as you asked me...couple of main adventages that I see are: * The \*.cake files aren't valid C# files. That means that cake runner must interpret them, dynamically compile them, and then execute them. When you do this, you loose support for the standard toolchain (dotnet), and built in IDE support. FlubuCore integrates as normal C# project, meaning all the basic IDE features like auto-completion, navigation, debugging and refactorings are available out of the box. * In my opinion better designed API with more features. * Auto generated API(from official documentation) for some third party command-line tools like docker. * [Parameter injection, which supports command-line arguments, json configuration files, and environment variables](https://flubucore.dotnetcore.xyz/buildscript-fundamentals/#pass-command-line-arguments-settings-from-json-configuration-file-or-environment-variables-to-your-build-script-properties) * [Posibility to execute scripts remotely via the FlubuCore Web API. Useful for executing deployment scripts.](https://flubucore.dotnetcore.xyz/WebApi/getting-started/) * [Interactive mode which offers target tab completition, options tab completition, toogle targets and options, executed commands history and more.](https://flubucore.dotnetcore.xyz/build-script-runner-interactive/) * [Ability to override existing options or add additional options to tasks through console](https://flubucore.dotnetcore.xyz/override-add-options/)
Is it free to make an account? I always thought the account was how they confirmed you actually bought it.
C++ is significantly more difficult than C#, though. Not something I could manage. Already tried that once and was more stress than it was worth. (I'm particularly unintelligent and only do this as a hobby.)
A Microsoft account is free, you also get lots of extras with it like Office for Android, an email account and free access to MS's source control.
You don't speak like a particularly unintelligent person speaks, lol. But I get your point. Anyway, I think I was wrong, apparently the core team did all the things: https://github.com/dotnet/winforms Not sure if you get any kind of designer like you would in VS, but you don't really need it. Forms are just classes like anything else.
Thanks for the response, I've ordered the Players Guide now :) One of my friends has advised I just start trying to use what I know in Unity, since I'd like to make a simple game at some point for a project. The recipe book stuff sounds kinda fun, using arrays in arrays?
&gt; Performance and optimization should always be the end goal of a project No, it is not. If performance and optimization were considered as the **end goal**, we would have written everything in Assembly, or go for machine code. There're things called maintainability and scalability. C++ is one of the most respected languages out there, largest and most complex systems are built with it, but if anyone messes up a huge C++ codebase, it turns out to be the most **dangerous** thing to maintain and scale. You'll be lost in its code maze and discover that this monstrous thing is unmaintainable, unscalable, and too complex to work with. Performance and optimization matter, but these aren't the end goal. End goal is the satisfaction of end-users and developers so that both of them can be functional. C# and Java are slower than C++, but provides more maintainable and scalable codebases, in general. *It's not the fault of C++ language itself, rather the shortage of talents in this area.* Grey-haired developers rule here, and we respect that, but it also indicates that a good number of young talents aren't coming to this field. Companies are rewriting their apps or specific portions of the back-ends in either C# or Java as these languages offer more maintainability and scalability, a pool of young talents, a reasonable performance (devices these days are capable enough to overcome the performance issues anyway).
I actually found that in my research, but didn't know what to do with it. (still don't)
Wait, what the fuck am I saying, I have two Microsoft accounts ffs. The lack of sleep is killing me, lol.
Everytime I work with Identity I want to throw it away and write my own auth layer Of course I didn't read manual on it, but it does so much things by default
You'd download the assemblies, start a new executable project, add a reference to those downloaded assemblies (or at least the primary form library), and then define a class that inherits from Form, and then instantiate it in Program.cs -&gt; Main() and call the .Show() method. As for customizing the form with controls, there is an incredible amount of documentation on the internet. Winforms has been around for almost 20 years now. Practically everything has detailed examples available. Let me know how it goes.
Be aware that 3.0 is a preview version.
I think they mean for .NET core. I have 4.5 .Net normally
I haven't had enough sleep to begin to understand what you said, but I'll give it a try sometime and get back to you.
Yes, the "dotnet" CLI tool is part of .NET Core, and .NET Core 3.0 is in a preview version. Running `dotnet new winforms` will likely create a .NET Core 3.0 project, not a .NET 4.5 project.
Oh, okay.
I actually think the other reply might be the better route, downloading that preview version of 3.0, especially if you are just experimenting. I'd try that first.
Okay! Once I get some sleep I'll try to wrap my head around that.
Hmm I thought .NET Fiddle was abandoned project but I'm happy to see I was wrong.
Web sites would be easier to change, and can be altered to make APIs from which to connected to, if you need a mobile app later. So stabalise with your website and then expand to an app later if the customer base grows.
How does it compare to nuke.Build?
Design it like you would design a database. At the end of the day that is what your dealing with, when you forget that you end up in all sorts of pain. Without knowing the full business requirements its a bit hard to judge how you should model it.
I see, thank you.
Thanks that helps a lot except that I’m actively trying to avoid using a repo model.
So test seperate concerns not methods?
The catch with naming tests like that the focus turns to testing your code instead of testing the problem. But kudos for not dismissing the advice out of hand. On a side topic BDD could be viewed as TDD on steriods. But you start to need in memory databases or you end up mocking/stubbing the living shit out of everything. But I guess thats what your article is about huh?
Focus less on the concept of a 'unit' even the guys who write the books struggle with that. Focus more on solving the problem.
Step 5... https://en.m.wikipedia.org/wiki/Test-driven_development
Thank you very much! I will look for the setting you mentioned. As for using english or german in my business logic: I thought about that very thoroughly (for a decade or so) and came to the conclusion that a mixture of english and german (but nothing else) is exactly right for my purposes. It feels the best. Having everything artificially in one language or the other makes the code feel alien. I convinced my team to do the same and we are all happy with it ;-) I did figure though, that it was a bit strange to have german code fragments in an english language forum...
IMHO Microsoft misses the point with testing. But damn man, your right they do become cluttered, hard to refactor and brittle.
Yes, I've tried installing NuGet packages through visual studio. Ultimately what happened is that I add the following through the NuGet packages manager: MySQL.data.nupkg MySQL.data.entity.nupkg Entityframework.nupkg I have tried each of the following versions: - 6.2.0 - 6.10.7 - 6.10.8 - Current versions I then install MySQL for visual studio (1.2.7||1.2.8) and the MySQL connectors for .NET (6.10.7||current version) I have tried several combinations of the different versions of the frameworks, NuGet packages and connectors, I've tried VS 2017 and VS 2019. I have tried installing them through the VS NuGet package manager, I've also tried adding them manually. I've tried downloading it from the official sources as well as from archive websites for old versions. I have tried several iterations of everything listed above, after dozens of triesni just started randomly picking versions with no rhyme or reason and hoping for the best (obviously with no success). After that is all installed, when I attempt to import the data source, I create the connection string with the wizard and it brings me to a step where it shows my schema and allows me to select which tables to import as my data source. At this point, I've tried: - Selecting all - Selecting just the important tables - Selecting all except for the triggers and stored functions And even - Selecting JUST my 'dbase' table (1 of ~45 tables) And I get a slew of errors while Visual Studio attempts to add the data source. Someone had suggested that it is likely that I'm using the wrong versions of the data and entity packages and/or the connector which is why I've tried so many versions and iterations/combinations of every variable. I tried to uninstall everything and re-install it all using legacy versions (My database is MariaDB 5.7 so I searched for which versions of the respective packages and frameworks are compatible). I have found the same problem on stack overflow BUT anyone that has had this issue and posted on StackOverflow has found very basic and easy solutions (usually just 'uninstall your connector and reinstall version 1.2.7 instead of 1.2.8) So when I post about this on StackOverflow, it gets flagged as a duplicate question. When I commented on the duplicate 'solved' questions to share my issues but the threads seem to be more or less dead and haven't gotten any response. I'm so aggervated with this whole MySQL connection problem, I've invested weeks (almost 2 months) into this problem and made NO progress at all. It's soul crushing. I really must be missing something, probably some simple prerequisite or something.
How would you describe the difference between WPF and WinForms from a beginner developer's POV? I'm interested in any observations such as 'you can't just double-click on a button to redirect yourself 2 the applications code for a button click event which is autogenerated' (I have no idea if that is an actual difference, I just made that up) as an example. I really need to make a website to replace my placeholder website which is currently built in squarespace. I'm considering asp.net. would you still recommend WPF over an asp.net website for learning purposes?
This guy TDDs. Going to give it a crack. A unit is the smallest, simplest bit of logic that is a segment of a user story become green. For example, a user can only login to a system with the right username and password. Some 'units' would be. What happens with a null password? What happens with a null username? Invalid username? deactivated account? Etc... Persknally K think the term 'unit' is crap and tends to throw newbies. It should never have become a discussion point.
I understand and I couldn't agree more even with his little experience that I currently have. I get the feeling right now that my lack of understanding with class libraries and integrating libraries or frameworks that aren't standard And the .NET framework is a huge mental block for me and I don't know where to go to learn how to manage dependencies and libraries. It is a strange in-between level in The learning curve where beginner tutorials don't cover it but advanced tutorials take for granted that you understand it. I can't find any intermediate training materials that clearly teach this information.
I have to admit I never see any value in these C# based build systems, such as Cake. Seems to be pointless layers on top of just `dotnet` and a CI.
Ok that makes sense, I have a file in my decompiler whose codes I want to use in a new class however the codes used in that file makes less sense to me as a newbie. Kindly can you elaborate how I can use the .Settings and .Resources from decompiler to make new class. [https://imgur.com/iIAyEhj](https://imgur.com/iIAyEhj) (This is an image of the decompiler showing the programming)
yes wouldn't that mean that I have to create a new class as @druhlemann suggested as well as @realjoeydood.
👏
&gt; But the Extensions in Main Menus extension has been downloaded only 800 times in around 3 months. It means only a tiny subset of VS extension users are aware of it and are actually using it. What a jump to conclusions. It could also mean that the majority of users simply doesn't bother about such a triviality.
This might be true for simple projects. But when you have more complex build script and deploy script they are very good as you familiar in C# and is much simple for developer to write scripts in C# atleast in my opinion. &amp;#x200B; 2 examples of more complex build and deploy script from real projects. Quite simple to make with Flubu. It would be alot harder to do with I don't know let's say msbuild. &amp;#x200B; [https://github.com/dotnetcore/FlubuCore/blob/master/src/BuildScript/BuildScript.cs](https://github.com/dotnetcore/FlubuCore/blob/master/src/BuildScript/BuildScript.cs) &amp;#x200B; [https://github.com/dotnetcore/FlubuCore.Examples/blob/master/MVC\_NET4.61/BuildScripts/DeployScriptComplexFromRealProjectExample.cs](https://github.com/dotnetcore/FlubuCore.Examples/blob/master/MVC_NET4.61/BuildScripts/DeployScriptComplexFromRealProjectExample.cs)
My answer would be the same as for cake but take out 1, 3 and 4 point.
The problem is I'm trying to persist a model that I dont have control over. I need users to be able to save the object state until they are ready to submit to a third party. Someone outside of Reddit suggested to I treat it like a save state and just serialize it to json and save the json. Idk how I feel about that but it would be an easy solution.
Same issue over here ... already tested different libraries too but no one seems to have a working solution. Workarounds didn't worked for me yet, maybe I find something soon. &amp;#x200B; I'll Keep you updated!
Read the comments here, https://developercommunity.visualstudio.com/idea/435711/get-rid-of-new-extensions-menu.html?childToView=466563 a lot of users are not considering this as a triviality at all, are you using some VS extensions to judge? The question is: for each vote and complain, how many non-complaining users are hindered daily by this forced UI change?
For each who complains, how many are there that not bothered at all? The people that have something to complain are always the loudest one.
I would consider try dot dot dot net a different use case.
I found the problem! Every time I loaded the UserControl it created a new instance but the old ViewModel was still on memory. What I did was this: public RelayCommand SetMainViewCommand { get; private set; } public MainViewModel() : base() { SetMainViewCommand = new RelayCommand(SetMainView); } public void SetMainView(object o) { SetView("Main"); } private object _selectedViewModel; public object SelectedViewModel { get { return _selectedViewModel; } set { _selectedViewModel = value; NotifyPropertyChanged(); } } private void SetView() { SelectedViewModel = new MainData() { DataContext = new MainDataViewModel() }; } And in my MainWindow.xaml &lt;Grid Margin="0,32,0,22"&gt; &lt;ContentControl Content="{Binding SelectedViewModel}" /&gt; &lt;/Grid&gt; In the unload method I cleared everything from the DataGrid and it worked but what I don't understand was why after changing the SelectedViewModel the "old" one didn't get destroyed? &amp;#x200B; PS - I ordered WPF 4.5 Unleashed from amazon today I really like the "unleashed" series my very first was Visual Basic .Net 2010
Try and see what happens. Run it on your pc and make sure you can’t access the library. Best advice for you now, is not the answer, but try to replicate the same behavior and see what happens :-)
I have control of the server so i can do it however i want. The basic requirement is this: 1. Between 6 and 11:40 PM each day, poll a folder on the server looking for two files that are supposed to be dropped there. 2 If they're found, run a program to bcp import them into a database and kick off an import process (not sure how to implement that, but a console app might work.) 3. At 11:45, connect to a database and create a csv file. SFTP the file to another server. 4. The next morning, around 7AM, zip up the text files from step 1. Repeat steps 1..4 each day.
in general libraries can be statically linked (part of your program) or dynamically linked (loaded at runtime). Statically linked libraries are the norm in csharp, so packages you get from nuget will generally work when your program is run elsewhere, unless they in turn depend on a dynamically linked library (like say, an sdl2 wrapper). however with csharp the machine running your program will need the correct version of the .net runtime installed, unless you do an installer that includes it.
Ok, so I’m not sure what program you’re using for looking at that .dlls contents, but if you want to use that in your app, you need to have it as an available reference to your solution. The first image looked like visual studio, so in that case you need to right click the references folder in the solution explorer window and there should be an option to add a reference, then you’ll have to browse for that dll you were decompiling. Visual studio only implicitly knows what’s in your machines global assembly cache. If you’re sharing the code with someone and that dll is unique, you’ll likely want to add a library folder to your code solution and put it there, so it is carried with the codebase.
"a lot of users" &gt; there's 255 upvotes. Sure, there's definitely more who haven't voted that are bothered by this. But there's a magnitude more who haven't said a word because they just don't care.
This is good information about the difference between statically and dynamically linked libraries, but I think csharp uses dynamic linking instead of static. You will need the DLLs you reference to be available somewhere the runtime can find.
This post is all over the place. &gt; This change impacts millions of extensions users &gt; [..] &gt; I guess this major (and blunt) change was provoked initially by the VS2019 compact menu look, but I am not sure: even on a 1920 pixel wide monitor (DPI 100%) there is still plenty of width space to show extension menus. That's besides the point. The chrome of IDEs tends to be really cluttered, and extra menus added by extensions don't help. Just because space is there doesn't mean it should be filled. &gt;Personally I still have hope Microsoft will reconsider this move and will embed a similar option in a future VS version to let the users chose which features (out-of-the-box VS feature or extension feature) deserves a no-brainer/main bar access or not. Perhaps. &gt;They pointed us to this documentation and kindly offered quite a few custom advices: Per-Monitor Awareness support for Visual Studio extenders &gt; &gt;Actually this change is pretty deep for (the tons of) WPF and Winforms controls rendered in the Visual studio UI. This took us time but we just released on July 3rd 2019 NDepend v2019.2.5 with full support for this Optimize rendering for screens with different pixel densities option. This required quite tricky fixes and we’d wish we have had a few months to adapt to this major breaking changes as we had for deferred loading explained above. I do wonder how many more years Microsoft will need to get their DPI act together. Feels like every other Windows 10 and/or .NET Framework release has a mention of "we've made further fixes / we've added yet another new API for handling DPI". &gt;Visual Studio 2019 is still running in a 32 bits process upon the .NET Fx 4 CLR with a massive WPF based UI and some COM usage. &gt; &gt;Can we expect VS2019 to run on .NET 5 sometime in 2021? or in a later version? or never? That seems quite optimistic. It took them three years after the release of WPF to move VS itself to WPF. They've been moving more and more stuff into separate processes — currently, they're doing so with the WPF designer. This lets them work around the legacy and/or 32-bit weirdness, but also creates an architecture that's complicated and probably has overhead in terms of RAM usage and performance. Still, they've clearly determined that moving `devenv` itself to a more modern architecture is either a very long gradual process, or will basically never happen. As for .NET 5, we'll see how well .NET Core 3 _actually_ works for migrating desktop apps.
Thanks for the info. I did read the readme on GitHub but I'm not really familiar with Cake yet. For some of my projects I'll need to make some big changes to the build system in the future, and using c# instead of msbuild scripts seems to make things easier. So the list you gave is a good starting point for me when I need to rework our build systems.
I think the biggest difference in the design phase is the xaml. It looks a bit like xml but essentially is how the UI gets its look. It’s also one of the strong points of wpf. To take full advantage of it you’ll want to use bindings, behaviors, styles and setters, etc. I think this is where beginners get a bit lost, there’s just so much you CAN do but don’t necessarily HAVE to do in order to make an app functional. For your second question, have you looked into MVC? Asp.net is still pretty relevant too. WPF is more for desktop applications as opposed to websites.
&gt; The chrome of IDEs tends to be really cluttered, and extra menus added by extensions don't help. Just because space is there doesn't mean it should be filled. Absolutely! But why not let the user decide what amount of clutter is acceptable or not if she's clicking a hundred time a day in some extension menus? &gt; I do wonder how many more years Microsoft will need to get their DPI act together. My guess is that we reached a final point now. Maybe the urge to implement that in VS2019 and .NET 4.8 came from the fact that they decided that .NET 4.8 won't evolve anymore except security patches, so they needed to get this multi monitors DPI things right. Just a guess
The main difference would be that the variable outside of the loop would still be accessible afterwards, whereas the one inside the loop wouldn't. That's to do with a concept called scope, if you need a keyword to research.
1. Why? 2. This really doesn't have anything to do with C#: algorithms are pretty much language neutral.
The number of up-vote stopped when the *Extension in main menu* extension got released. Certainly many users don't care but obviously some others actually do care. A single design cannot satisfy everybody, this is why VS has tons of options ... except for this point.
Thanks, I know about scope! I'm wondering about performance.
&gt; My guess is that we reached a final point now. Maybe the urge to implement that in VS2019 and .NET 4.8 came from the fact that they decided that .NET 4.8 won't evolve anymore except security patches, so they needed to get this multi monitors DPI things right. Just a guess Maybe. [4.5.2](https://devblogs.microsoft.com/dotnet/announcing-the-net-framework-4-5-2/): "High DPI Improvements is an opt-in feature to enable resizing according to the system DPI settings" [4.6](https://devblogs.microsoft.com/dotnet/announcing-net-framework-4-6/): "High DPI support in WPF is now better." [4.6.2](https://devblogs.microsoft.com/dotnet/announcing-the-net-framework-4-6-2-preview/): "Prior to 4.6.2, additional native code was required to enable per-monitor DPI awareness in WPF applications." [4.7](https://docs.microsoft.com/en-us/dotnet/framework/whats-new/index#v47): "In .NET Framework 4.8, WPF adds support for Per-Monitor V2 DPI Awareness and Mixed-Mode DPI scaling." [4.8](https://github.com/microsoft/dotnet/blob/master/releases/net48/README.md): _a ton of mentions of DPI_ It doesn't really sound like have an actual roadmap here of "we have to accomplish these steps before we get it right", but rather like they're stumbling onto one issue after another.
I learned from the article about the use of $type in the Json and got the request to work. Thank you very much!
None. Compiler optimizes most of these things, including property access.
If it’s not used after the loop these should be identical in the end. And as you noticed the IL even is the same. I can’t come up with any case where there would be any difference, unless there’s some very weird situation where the compiler/JITter can’t figure out that it’s not used afterwards. Scope was already mentioned and is pretty much the only reason to do things one way or another.
C# does not do static linking. It is almost exclusively dynamic linking. You must bundle your libraries with your application, or (not recommended) ensure that they're available in the GAC.
and [try.dot.net](https://try.dot.net) uses web assembly to run everything in your browser that limits possible use cases
The fact that the il is the same is likely because the compiler hoisted the variable for you. Google variable hoisting. It is common and very performance relevant in languages closer to the metal.
Ah cool cool. No other difference that I'm aware of otherwise then.
&gt; I would always recommend you write code for readability before performance Yeah, I only focus on performance in context (such as cryptography) that sacrificing a little bit of readability is acceptable if the performance gain is good enough.
Yeah, I got to solve nearly this a while ago, its a lot of fun. For the one I solved, it had the mirror values. It was unique orders only. Havent seen the no-mirror case. That would half the cases. What I would do is write out the 4 and 5 value cases and track the skipped values and such. I bet theres a pattern you can exploit.
So then 255 upvotes + 800 downloads. It's a small percentage of the number of users of Vishal studio. You say it has options except for this point, yet there's an option to achieve exactly what you need in the extension. I don't get it, some people just want to complain for the sake of complaining.
**Why make another HTML parser when HtmlAgilityPack and AngleSharp are out there?** HtmlAgilityPack is a rather old library with (in my opinion) dated API. For my use cases it was a bit clunky to use and lacked support for CSS selectors which I prefer to XPath. AngleSharp is a massive framework which lets you do so much more stuff than just parse or traverse HTML. Unfortunately, for my use cases I didn't leverage most of what it can do, so instead I had to spend more time figuring out the API which was overflowing with complexity I wasn't particularly interested in. Neither of the frameworks support .NET Standard below 1.3 which was also bad for me because one of my projects targets .NET Standard 1.1. Basically, my main motivation was to produce a viable and extremely lightweight alternative to HtmlAgilityPack and AngleSharp for read-only HTML parsing and data extraction. Also, since the library is pretty simple, it's arguably a good place to learn how parsers are made (LtGt uses monadic parser combinators via Sprache for both HTML parser and CSS selector parser). So hopefully this can be a useful resource for beginners. :)
Thanks for this historic, this is quite interesting, not sure if/how they will handle future DPI problems with *frozen* .NET fx 4.8
Input: [1, 2, 3] Output: [1, 2, 3], [1, 3, 2], [2, 1, 3] Input: [1, 2, 3, 4] Output: [1, 2, 3, 4], [1, 2, 4, 3], [1, 3, 2, 4], [1, 3, 4, 2], [1, 4, 2, 3], [1, 4, 3, 2], [2, 1, 3, 4], [2, 1, 4, 3], [2, 3, 1, 4], ~~[2, 3, 4, 1]~~, [2, 4, 1, 3], ~~[2, 4, 3, 1]~~, [3, 1, 2, 4], ~~[3, 1, 4, 2]~~, [3, 2, 1, 4], ~~[3, 2, 4, 1]~~, ~~[3, 4, 1, 2]~~, ~~[3, 4, 2, 1]~~, ~~[4, 1, 2, 3]~~, ~~[4, 1, 3, 2]~~, ~~[4, 2, 1, 3]~~, ~~[4, 2, 3, 1]~~, ~~[4, 3, 1, 2]~~, ~~[4, 3, 2, 1]~~ Without formalizing a proof or anything, I notice from the second example that after I take the permutation starting with 1, that cancels out all permutations ending with 1. Same with 2 and 3. So my strategy is to reorganize it in this way: [1, 3, 4, 2], [1, 4, 3, 2], [1, 2, 4, 3], [1, 4, 2, 3], [1, 2, 3, 4], [1, 3, 2, 4] ~~[2, 3, 4, 1]~~, ~~[2, 4, 3, 1]~~, [2, 1, 4, 3], [2, 4, 1, 3], [2, 1, 3, 4], [2, 3, 1, 4] ~~[3, 2, 4, 1]~~, ~~[3, 4, 2, 1]~~, ~~[3, 1, 4, 2]~~, ~~[3, 4, 1, 2]~~, [3, 1, 2, 4], [3, 2, 1, 4] ~~[4, 2, 3, 1]~~, ~~[4, 3, 2, 1]~~, ~~[4, 1, 3, 2]~~, ~~[4, 3, 1, 2]~~, ~~[4, 1, 2, 3]~~, ~~[4, 2, 1, 3]~~ The difference here is that I pick the first number, then the last number and permutate everything in between. So I go (1,2), (1,3), (1,4); (2,1), (2,3), (2,4); (3, 1), (3,2), (3,4); (4,1), (4,2), (4,3) But we can eliminate any pair where the second number is a number we've already iterated over: (1,2), (1,3), (1,4); (2,3), (2,4); (3,4). So let's abstract this: Given a set [n_0, n_1, ..., n_m], the unique, non-reversable permutation can be found with this algorithm: iterate each number from 0-m =&gt; i iterate each number from i+1-m =&gt; j permutate the set [n_0...n_(i-1), n_(i+1)...n_(j-1), j_(j+1)...j_m] =&gt; perm insert n_i at perm[0] add n_j at end of perm Hopefully my assumptions hold for all cases of n. It seems right, but I did not formally prove it
If you're using .Net Core, you can create [self-contained deployment](https://docs.microsoft.com/en-us/dotnet/core/deploying/#self-contained-deployments-scd), which is basically a folder that contains all the files necessary to run the application, including any libraries and .Net Core itself.
5 upvotes + 800 downloads + all the guys that missed both the post and the extension
Probably a couple of billion who haven't come forward as also disappointed by this change right?
&gt; Semicolons are line terminators. Have you seen the for loop?
Property access can't be optimized, because the properties behavior can change. It can even have side-effects.
Yes. Do you have a point? You didn't make it.
A long time ago this mattered for performance because we didn't have the luxury or sophistication for compilers to notice and optimize this. Now the C# compiler is very good at optimizing this case. I'm pretty sure within the last couple of weeks someone did a comparison down to IL of exactly this case and determined it doesn't matter.
They call this 'hoisting' if I'm not mistaken. You usually could tell if it matters or not. In your sample code it wouldn't make much difference. But if it's another class where there are behind-the-scenes logic in the constructor and you're much better instantiating it outside the loop and just adjusting the properties at the loop.
Looks awesome. I recently started a project using HTMLAgilityPack but this looks awesome - I am going to try it out!
Huh. Array indexing then? Something about creating a separate variable like int x = arr[0]; for(int i = 0; i &lt; x; i++){ } The x assignment being unnecessary. I could swear there was a benchmarking post on this subreddit about this.
That will be optimized in release mode.
One consideration is that not everybody who may dislike the change has even used VS 2019 yet, so they might not even be looking for the extensions. Another possibility is users that saw the extensions menu, saw no obvious way of changing it, and decided that was enough to immediately switch back to what they were using before. That said, it actually seems entirely sensible. One thing that actually kind of pissed me off - going back to at least VB6- is that add-ons and extensions would seemingly always add their own top-level menu. I recall a year or so ago I evaluated a few control libraries and it made my top-level menu in VS an absolute mess- I had like 3 or 4 added menus. Ended up that I decided against any of them not because of the lack of features or capabilities of the software, or the price tag/licensing- but entirely because it would mean those menus are going to be a permanent fixture of our VS installs. as a result I opted to instead write an in-house DataGrid instead.
It's been a couple of years, but probably still relevant.. I ran into an issue that took me a couple days to debug an application that used libraries. It compiled and would run just fine on my own machine, but when destributed it would error out because the libraries didn't go with it. There's a setting to change this, it was a little checkbox in the properties or something, I believe it was "Copy local files" or something along those lines, definately had the word local in it. Like I said, it's been a few years since I ran into the situation, but definately remember it gave me hell all over one little checkbox.
Why is that?
&gt; Hahaha, I actually far prefer them. I'm sorry, but it's just wrong. It's against nature.
&gt; Added AssemblyInfo.cs - I wasn't really sure about the conventions for this with .NET Standard, but seems OK. There are no convention for .NET Core and .NET Standard projects, so I just think it makes sense to keep it from .NET projects.
I think more specific functionality such as this is more appropriate in a service whereas a repo should be more generic (unless I've got it mixed up). I could do with a service but I don't understand the need to abstract the DbContext away from the controller.
How do i fix if anyone nows bc it wont let me sign in
Removed: Rule 3, Rule 4.
No offense, but I’m just going to drop a truth bomb here. Don’t take it the wrong way, because I want you to continue learning. Having said that, you are going to need a lot more experience and knowledge about all this stuff before you start making rash decisions about stuff you don’t fully understand. Repo’s suck when people don’t do them correctly, so I’ll agree with that. But what you don’t understand is that by going down your current path, you’re going to jack up your request pipeline (all the way to the db and for dependency injection/garbage collection) and it’s going to be a massive mess of spaghetti code. So 2 things: 1. Look into ONION architecture 2. Your controller should have the least amount of code as possible. All your business logic should be offloaded to the service layer, which calls the repo to work with the dbcontext/database. Hope this helps.
Removed: Rule 3. Maybe try reinstalling Visual Studio. Or try /r/dotnet or /r/visualstudio.
Depends if you deploy with symbols. Very Sleepy [http://www.codersnotes.com/sleepy/](http://www.codersnotes.com/sleepy/) is a simple, reliable way to do some performance tracing.
Awesome, would love your feedback
&gt; clicking a hundred time a day in some extension menus Sounds like you have a bigger workflow issue than an additional level of menu nesting.
As a rule, places don't teach it. Mentors can do or working on a bigger team can show patterns that either work or suck, beyond that its feeling your way through. How do I manage a multi-application solution with an api and multiple clients? Like, is it bad to have a library called "interfaces" with just interfaces or is that a "code smell?", is it bad to have everything in one project, when is that bad, why is that bad, is it ever okay? Funnily enough the answers to those sorts of questions as well as those that answer questions of composition and architecture are so damn nuanced that every answer can be correct in a given situation. Books like Pragmatic Programmer or Code Complete attempt to answer aspects of such questions (specifically I adore the "its just a view" chapter of pragmatic programmer) but they aren't comprehensive solutions. Understanding programming patterns helps understand which solutions can be more optimal but then there are some patterns that just suck (Singleton) or can be sub-optimal at times (Visitor) and sometimes even the State pattern can be better served by just outputting a simple switch (because its less code and is clearer). This is why I recommend ensuring that bigger projects you embark on are not mission critical so you can make wrong turnings and don't lose much.
Think of the code as being compiled twice. Once at compiletime, once at runtime. If they result in the same code compiletime, then to the runtime, it's the exact same code. But then the JIT compiler will do optimizations on top of the compiletime optimizations. &amp;#x200B; A good general guideline is to shoot for clarity, and the runtime is optimized to make clear code perform well. Don't do stuff just because you think it'll perform better. If you're doing crypto code, most everything has already been written, so unless you're doing it for personal study, don't re-implement it. &amp;#x200B; If you're looking for how to manipulate large objects quickly, the big thing to consider using Span&lt;&gt; and Vector&lt;&gt;. Those let you do many of the key primitives quickly.
The converse is that it's inflexible - so that even if you have a consistent concept of equality and manage to correctly keep the 42 different apis you need to implement to do that in sync, you now have yet another source of unavoidable inconsistency. &amp;#x200B; Customizable pattern matches and/or inline deconstructions would be a \*huge\* boon.
&gt; inline deconstructions if (foo is { bool b, int i }) Like that?
There is a plenty of online tutorials available on the internet by I have come across a useful online tutorial website called onlinetutorials today. There you can get an online tutorial for all programming languages. [https://onlinetutorials.today/](https://onlinetutorials.today/)
That's fine for as far as it goes, but it's pretty limited. In particular, it requires a boolean expression, so if you're just trying to pipe one complex expression into the next, or introduce a temporary or whatever, you need to artificially embed it in a boolean expression. Who hasn't used pattern matching on expressions they know to be true solely for the purpose of extracting subexpressions? The story on customizable pattern matches is actually a little better; the try-parse pattern is ok there. But it's not ideal; the definite assignment checker can't tell whether you're doing something stupid in statements like `!int.TryParse(s, out var i) ? ...use i here... : ...`.
&gt; Who hasn’t used pattern matching on expressions they know to be true solely for the purpose of extracting subexpressions? I would wager most C# devs haven’t yet used pattern matching *at all*. ;) I’m actually not sure what you’re looking for. Frankly, I find some of the pattern matching hard to read already. Switch expressions get hideous rather fast, for example (and don’t feel like idiomatic C#).
Could be something as simple as the sum of both elements of a tuple. Or in a conditional, where the first element is less than the second one. As is now, you need to place those in a variable, but the downside there is that the scope is typically fairly large (and inflexible). You can't so something like `var onDiagonal = GetPosition() as (x,y): x == y;` or whatever. The declaration expressions look like they'd fit the bill, even if they're not too pretty. Still, bet I'd use those a lot.
 [https://www.codecademy.com/learn/learn-c-sharp](https://www.codecademy.com/learn/learn-c-sharp)
[removed]
You seem to have this black and white idea of what is right and wrong. Making basic functionality the end goal isn't moronic, neither is stopping when you have functionality. The question you have to ask is "is it appropriate to the situation". Not being open to the possibility that something is a good idea in the right situation is frankly moronic. What you have said might apply sometimes, other times not. Stop looking at things in a blinkered way.
Well, I have two semicolons. :)
disagree. let a hundred flowers bloom, giving us a choice
Did you try ScrapySharp?
I'm kinda through most of that homework, I'm stuck on that nullable type, I have tried multiple things also how do I show you my code, do I just paste it here ?
I admire your reaction, I really do!
Dont save json to a database. I did it once (when my boss insisted). We caught bugs only when exporting (catching bugs early is good). It was a pain to change the structure as we lost all the built in tooling and there was no way to query the data.
Nice work! I've been looking for such a parser in the new PowerShell core, which doesn't come with IE HTML engine for its IWR parsing. You may want to preface the question with the letter "Q:" or the qualifier "common question:" so that people can easily know that you're not the one asking this question.
You're welcome. ;-)
Thanks! And yeah, good point, edited.
When it is clear a bug is legitimate, it is fixed no matter who raised it
&gt; 1 - Can gRPC in Visual Studio completely replace WCF? No. WCF does everything and you probably don't need everything. If the question was "Can gRPC in Visual Studio completely replace WCF for me?" then I would say yes given what you've described so far. &gt; Will WCF be usable in the coming years? Maybe. It may die as an open source project or it may take off and get some much-needed love. https://www.infoq.com/news/2019/06/WCF-Decision/
&gt;1 - Can gRPC in Visual Studio completely replace WCF? &gt; &gt;No. WCF does everything and you probably don't need everything. &gt; &gt;If the question was "Can gRPC in Visual Studio completely replace WCF for me?" then I would say yes given what you've described so far. &gt; &gt;Will WCF be usable in the coming years? &gt; &gt;Maybe. It may die as an open source project or it may take off and get some much-needed love. &gt; &gt;https://www.infoq.com/news/2019/06/WCF-Decision/ Thanks!
Yes, in fact the first sentence of my comment *said I agree*. It is not, however, a universal justification for rewriting legacy code.
Sure, but adding options never hurts anyone.
How does that work if you automatically close their issue?
WCF is embedded across many industires and applications so it won't be going anywhere anytime soon even if no new updates on Framework will occur. Note that there is a WCF client library for Core and an OSS project rebuilding portions of the WCF server framework for Core as well. It will not be 100% compatible but should provide a landing point for many teams in the future.
Removed: Rule 2, Rule 3, Rule 4.
I have been trying and failing to get a fairly complex use-case where I need a server giving access to a fairly complex UI with some heavy back end libraries. I’ve purchased some fairly expensive front-end libraries to help make this reality and I don’t know if it’s my lack of experience or what, but it’s been a lot of fail. Also, there’s so many ways to do something on the web that the documentation is not really great. In fact, just getting a single button to trigger something meaningful on the backend without JavaScript has been a problem for me. Fast forward to when I installed server-side Blazor and a whole lot of things worked very intuitively, and I was able to do some fairly meaningful things quite easily. Now, I am very glad I’ve skipped on JavaScript since now it seems I have exactly the tools I need to make some fairly in depth Web apps without learning too much weird new stuff.
there are a lot of things the .NET Core client doesn't support, outside of the fancy stuff it doesnt even let you have configs in a config file, making it unusable for enterprise applications where WCF is most used. If you want to be able to configure endpoints, bindings or whatever you actually have to roll your own ServiceModel configs.
Just like the days before WCF was supported in the IDE, its like a time machine of hate.
He said property accesses can be inlined which is mostly true - virtual properties are a challenge, but clever JITs can handle even those to a degree (don't think RyuJit is up for those optimisations though, but Hotspot can). If there are side effects you can't hoist the code out of the loop obviously. And if you can't prove that called coffee won't
Joisting means taking some computations inside a loop and proving that they're constant across the loop and therefore only have to be computed once. It's irrelevant where you declare your local variables for modern compilers. They all convert the input into a form of SSA where the lifetime of variables is decided based on where they're used.
The JITer can probably inline it. The C# compiler can not inline it.
You can read up on SSA (which is what basically all modern optimising compilers use to represent your code at least at some stages) to understand why to the compiler these two things are the same thing. Scope is for humans, the compiler just cares about the actual lifetime of the variables (in C++ scope influences behaviour so there's some things to consider). One classic example: If you have `int a,b;` as local variables, but those two variables aren't used at the same time the compiler will only allocate a single spot for both on the stack.
It does. Every option has to be maintained and supported for a long time. And at some point you get overcrowded with options.
Yeah, front-end is over-engineered IMHO. WebAssembly is renovating it. Blazor makes things much easier by reducing complexities. I'd be happy to replace JavaScript with C# in every single day of the week. Waiting for the client-side Blazor to arrive.
Point taken. I think I might have used the term wrongly. But you're telling me that this: using (var c = new ServiceClient() { for (int i = 100; i &lt;= 500; i++) { c.DoSomethingOnline(i); c.DoSomething(); } } ... would end up being the same as this performance-wise? Because it's sort of the jist of what I'm trying to say: for (int i = 100; i &lt;= 500; i++) { using (var c = new ServiceClient() { c.DoSomethingOnline(i); c.DoSomething(); } }
if you switch to markdown when answering, you can format code by having 4 spaces in the beginning. But I can just explain nullable types a Little. value types cannot be null, so the following is invalid: int a = null; Because you sometimes do want null with this basic types, theres a generic Type NULLABLE&lt;T&gt; that helps you with that, so the following is valid: Nullable&lt;int&gt; a = null; Because that's quite a long type and used fairly often, Microsoft created some syntactic sugar to make it easier. The following line is semantically the same as the previous code line: int? a = null; Now when you have a nullable type, you have basically two methods, HasValue that returns true if the value is not null an null otherwise and Value that returns the value if it is not null and throws an exception otherwise. int? a = 7; int b = a.Value; //no exception, since a is not null int? c = null; int d = c.Value; //exception, since c has no value that is an int if (a.HasValue) //if you don't know if a has a value, just check it b = a.Value; if (c.HasValue) //now you get no exception with d because you first check it d = c.Value; There's some other syntactic sugar that is nice with nullable types, like the null-coalescing operator (??) that Returns the right hand side if the left hand side is null. int a = null; int b = a ?? 0; //a has type int?, but c# gets that this cannot result in null, so you assign that.
You're running into the issue of passing by reference vs passing by value here. Try changing static public void math(int counter) to static public void math(ref int counter) then switch math(count); with math(ref count);
You need to either pass `counter` as a reference or return once you increment it. What you ultimately use will boil down whether you give `counter` a value before passing it along or not. &amp;#x200B; static void Main(string[] args) { //need to assign value before passing reference int count = 0; Console.ReadLine(); math(ref count); Console.ReadLine(); math(ref count); Console.ReadLine(); } static public void math(ref int counter) { counter += 1; if (counter == 1) { Console.WriteLine('1'); } if (counter == 2) { Console.WriteLine('2'); } } Or returning the value and assigning it to counter: static void Main(string[] args) { //no need to assign value int count; Console.ReadLine(); count = math(0); Console.ReadLine(); count = math(count); Console.ReadLine(); } public static int math(int counter) { counter++; if (counter == 1) { Console.WriteLine('1'); } if (counter == 2) { Console.WriteLine('2'); } return counter; }
Math(count); is only running the method and not saving the output of the method to the main method. Assign each of the math(count); methods a variable like so... int first one = math(count);
This here is one way to make the program behave as expected. What I'm going to say next is a bit difficult to explain the 'why' to someone new. If you at any point need to use `ref`, there is probably a better way to accomplish things. In your specific scenario, I would rewrite the program so that your `math`function doesn't try to change `counter`. Before calling `math`, you alter the `count` variable instead. Programming like this (one function does one thing) is going to help you in the long run.
Why you don't just contribute to AngleSharp? Also you can use html part without other part of big framework. Don't you think that fact is why we still have no good library that to cover all scenarios?
Thank you, that issue bothered me. I'll have to read up on that.
Thank you.
Read only refs and out params are very useful though. It’s not critique on your answer but an important side note to the family of types.
I just tried it. So I made a method that alters the variable count. So I call that method first and then the method `math`. and it works. Is that what you meant?
If the program still works as expected then yes! With this change (if I understand it correctly), you can now change the logic independently, what alters the variable is not tied to the outcome. Maybe you want to do something like this: public int EvaluateInput() { ConsoleKeyInfo keyInfo = Console.ReadKey(); if(keyInfo.Key == System.ConsoleKey.Enter) { return 1; } else { return 0; } } and with this in main perhaps: int count = 0; count += EvaluateInput(); math(count); count += EvaluateInput(); math(count); Now it would only increment when using enter, but not when using any other key
Also, in programming you dont want your code to have hard coded output. So try changing Console.WriteLine(‘1’) to Console.WriteLine(counter.ToString()) This should give u same result as it will read the value of the counter and then convert it to string as your output
There is no chance that a single library will cover all scenarios. There is a need for a lightweight product. Make a PR to AngleSharp if you feel it lacks something.
No, I haven't
Seeing as my problems were with the design of the library, rather the (lack of) individual features, I don't really see how I could have contributed to AngleSharp. Like I said, that library had everything I needed (except .NET Standard 1.1 target, which the author understandably wants to avoid). I just wanted something simpler that gets the job done without the extra complexity.
Good read.
Saved for future projects.
You misunderstood my comment that you're replying to, but thank you :)
So... you've read the entire thing in 4 minutes? Uh huh.
I've read on GitHub few days ago. Uh huh.
While they can be useful ive always understood they should be used sparingly and generally if you need to use them your method is doing to much. OP should read about reference types, value types and scope
automatically closing an issue usually only happens when the raiser of an issue both is not a patron and has not put in adequate effort into the issue. The issue template states: \&gt; This process will depend on the issue quality, your circumstances, and the impact on the larger user base. [https://github.com/Fody/.github/blob/master/.github/ISSUE\_TEMPLATE/bug\_report.md](https://github.com/Fody/.github/blob/master/.github/ISSUE_TEMPLATE/bug_report.md)
functional programming in a object oriented language is going to be the future. neither one can solve the problems on its own in a clean way.
*Whew*, that actually gives me quite a bit of piece of mind.
Visual studio is the IDE you need to use for that.
Also, why are they going .net to java? .net core would be a more scalable and platform agnostic tool. Going to java just seems unusual nowadays.
Well, in these cases, inside the for loop, the ServiceClient instance would be created for every loop iteration (401 times in the example). If declared outside the for loop, it would be instantiated only once. So, unless there's a reason why the ServiceClient instance can only be used once, it doesn't make sense to declare and instantiate it inside the for loop. Instance creation and disposal overheads would be very relevant (memory allocation, resource disposal, GC pressure, etc).
yep, i did and thank you for the lib - there are things pissing me off in HAP
Its en nternship so you know
Right, neither paradigm is the universal tool. Btw, F# has an excellent support of OOP, so you can dive into your future right now!
Can i see the plages in it like chrome ?
This article triggered our webfilter's "news" recognition so it wanted to make me unclock and read it on my own time, because it had recognized the word "terror" 14 times lol. Webfilter now has an exception for guthub.
&gt;Those problems weren't challenging, just a tedious routine: making sure you didn't miss anything stupid and obvious. Instead of doing this routine on a daily basis I became obsessed with seeking solution: some development approach or code convention or whatever that will help me to design a project in a way that will prevent those problems from happening, so I can focus on interesting stuff. [You don't say](https://imgflip.com/i/34zlf0)...
How much do you know about development in general? The answer would help tailor the amount of details you require.
[ASP.NET](https://ASP.NET) Is a (Web-)Server-Framework that allows you to host arbitrary endpoints on a PC. if you run your [ASP.NET](https://ASP.NET) Application in Visual Studio, it should open up the website inside your default webbrowser (unless somebody modified the project files to explicitly don't)
Most likely not, unless you add the certificate to your trusted roots.
Thanks. So probably I have to purchase the certificate, from the looks of it Comodo is the way to go due to their cheapest prices. Do you know whether I have to sign both, .msi and .exe files? I developed a winform application, there's .msi installer that installs the software including the .exe file, so what is the best practice here? And would I have to pay for both of them or one 1 certificate will suffice?
Note that you may still get the Microsoft SmartScreen warning dialog, even if you purchase a valid recognized certificate. First enough users have to accept your program afterwards for the tool to be recognized. "Application reputation" is the keyword.
i'm good in C++/C#/PHP
So does C# has functional-looking features with LINQ.
We’ve been using cake because we are quite large and have a variety of CI tools with their own way of doing things. However they can pretty much all run a script of some sort. Cake gives us portability, especially for the more complex tasks beyond simply running tests or publishing an app.
You did not say whether the project was ASP.NET WebForms or ASP.NET MVC, but if it is the former, then yes, you can preview *.aspx files in the page editor.
But no union types, which results in unnecessary workarounds and added complexity. :-( Like what the ASP.NET Core Team did to support `ActionResult&lt;T&gt;`.
How can I know which one ?
There's a lot of files of type Page server
If you have assemblies with names ending in "Mvc", it's likely to be an MVC project. If you have pairs of files with the extensions .aspx and .aspx.cs, then it is a WebForms.
Its webforms then thank you so much
No problem. But really you should be able to load the *.sln file and Visual Studio will detect the type of project.
I'm not using Visual studio, but once i'm home I will install it and try. Thanks again !
Hey thanks! I finished my dissertation now and just didn’t include this part. Might try and fix it now anyway.
Well, C# does have _some_ functional features, but still doing functional programming in it is painful and doesn't make any practical sense. It's like saying "hey, we have objects in our language, so you can do OOP" when there's no inheritance, encapsulation or polymorphism. If you believe that C# has a good enough set of functional features, I encourage you to try F# or Haskell or Rust to see the difference.
If you would or would not share the sourcecode, I am particularly curious if it works with Mono + libgdiplus + Winforms under Mac/Linux. Because that would definitely be something I would be interesting in. The barrier to entry with Windows.Forms is so low compared to (most) other solutions for cross platform game dev that I would think it's a good entry into making 2D games with dotnet + c#/f#.
The certificate represents you, not the software (in this case). All binaries should be signed so yes both .msi and .exe (along with any .dll's you may have that are not third party).
Thanks. And would I have to pay for both of them or one 1 certificate will suffice?
I already contributing to AngleSharp, and using it. And I feel that coverage of all scenarios is possible when you speaking about html and xml
You get a cert and sign whatever you like.
That sounds like a fun place to work.
the good thing is that they are slowly adding FP features to C#. e.g. pattern matching has improved quite a bit recently. they even say that they are using F# as a testbed and let the features trickle down to C#.
I think you’ll find a lot of people are *not* happy with the Xamarin integration, actually.
To expand on your point on the painfulness, you *can* do anything in C# that you could in F#. They run on the same CLR, and the CLR is still *mostly* &amp;#x200B; You *can* implement sum types through the Visitor pattern. You *can* define your own Result types using said visitors. You won't have a pleasant time, and especially won't have a fun time if your coding style forces multiple, trivial visitable implementations of a sum-type-as-visitor to be in their own file, each being maybe a 5-line class to declare a constructor expression body and an expression body \`Accept\` implementation. You'll also probably run into collisions with other ad-hoc implementations of things like \`Result\` across different libraries. &amp;#x200B; Or you can just write it in F#, and write the same logic in less LoC and significantly fewer files, in a more compact fashion. The ML syntax works wonders for this kind of expression. &amp;#x200B; We could use some syntactic sugars for these, and some C#-focused BCL additions to extend this, sure, but it may be just best to use a different dialect of the same runtime to fit your expression needs here.
Ok I know it's an internship but that's what an internship is for don't they have someone to point you in the right direction and show you the basic tools that you will have to use? (like visual studio). Also my opinion is to avoid work projects at home unless you are paid more but even then. If you can and want stay more at the office in order to study and catch up. That's my go to rule for keeping a work/life balance or at least trying to.
'Using' is primarily used with things that implements IDisposable, which indicates that there's is an action that has to be done to cleanup the object - the Dispose() method. Using block automatically invokes this method once you go out of scope, i.e. when the code goes after the curly brace in the using statement. For example when SqlConnection is usually wrapped in using block if you happen to use ADO.NET, as it closes the connection in it's dispose method. Otherwise you'd have to remember to call Close().
Thanks. It's my first internship and I'm still discovering things.
It is once you know your way around
In our field of work it's pretty easy to get shucked up because we mostly like what we do! Even if is maintaining a tedious 10 or more year old codebase. Because we like to code!
Well, do you need ftpclient after whatever it is you are doing in your example? If not, then that's completely fine. Although I would implement the class that's executing that code from IDisposable and dispose ftpClient in it's own Dispose() method.
You inject ftpClient, the instance in the using block is the stream created by ftpClient, which is totally different object. Using keyword automatically cleans up via call to Dispose() on IDisposable when you go out of scope. Dependency injection has nothing to do with cleanup - it is only concerned with object graph creation. The code looks OK to me, only thing that might be off is constructing new objects each iteration, but unless you feel like your code is slow, I wouldn't worry about it.
I really hope you arent employed as a programmer and do it as a hobby, because this is almost a criminal tier offense of mis/un-education about the basics of C#
If we equate FP's destruction with the ubiquity of garbage collection we might see a totality functional equivalent to state.
&gt; I'm doing the dependency injection on the ftpClient Ask yourself, Do I really need to swap out implementations of FTP Client? Generally speaking it is better to fully encapsulate classes like this instead of messing around with dependency injection. With DI you add uncomfortable questions about object ownership and lifetime. And thus you make the code that calls it more complex than it needs to be.
Just imagine all the other things you don't understand yet.
Didn't know this. Am employed as programmer.
Did you have anyone to teach you? Are you just an IT guy that is doing side projects in C#? This is some basic like first or second week learning thing.
I work for an organization that handles lottery software. I don't clock in or out, but the company computer comes installed with software that warns you when you're navigating to a site that may violate company policies. When I navigate to our demo systems, it always gets flagged for "gambling." It gets me every time.
Another reason I like python.
This article is to complex to read.
What do you mean "fields store references" I'm just starting out &amp; when we have discussed references it has been in the context of pass by value &amp; pass by reference. Is this in any way related to what you are saying?
How can people know about interfaces and not about value / reference?
I'm not happy with xamarin. I don't think Microsoft is responsible for that. The entire concept is rotten to the core. To many layers of stuff plus they can't be blamed for an ecosystem that is built around enforcing stupid rules: can't build without an iPhone, can't run anything native besides jvm or apple-approved swift. I guarantee you .net would wipe the floor with ionic and the like if they'd be able to pinvoke some .so and dlls and run otherwise native.
Look at that guy's username and then learn not to engage with troll accounts.
Company spam.
&gt; The certificate represents you, not the software
It's not entirely correct. In C# structs are value types, and classes are reference types. If a field is of a struct type, it means the field holds the entire data of the struct. If it's of a class type, it only holds a reference to data that resides elsewhere. Pass by value/pass by reference can apply to all types (both classes and structs). It just means whether the original field/variable will change after the method execution. If it's a struct type, "the original will change" means that the actual data will change. If it's a class type "the original will change" means that it will just reference a different object (because it just holds a reference to data, and not the data itself) I'm sorry if it's confusing, the terminology makes more sense if you come from a language such as C or C++ which has pointers as its bread and butter.
ah fuck i thought it was OP
&gt; can't run anything native besides jvm or apple-approved swift You can run C, C++, etc. on iOS just fine. What you _cannot_ do is ship your own JIT. That's why Xamarin has to do AOT on iOS, which has some positive and negative (e.g. hard to do Reflection) effects.
Yup. It still has to be approved by Apple (the dll stuff was in reference to Android). Also mac-only builds is enough of a hassle already. Microsoft learned from that mistake which is why you can build net framework on Linux with the latest sdks. The general Dev experience of xamarin on iOS is so subpar to everything we've got, average Joe windows shops will never bother to do anything besides maybe PWAs in the future.
Lol damn, Florida by any chance?
Remember, though. The field stores the VALUE of the reference which is copied in certain cases (like function calls). So you can change the reference in the new scope and leave the original unchanged unless you actually pass by 'ref'. First couple Google hits -&gt; https://www.quora.com/Is-C-pass-by-value-or-pass-by-reference https://stackoverflow.com/questions/436986/c-sharp-pass-by-value-ref
It's abstracted away. Just like you probably don't know how the IL which your C# program compiles to interacts with the JIT Compiler and how that Native Code is interacted with at the OS level and machine level. These are just things that people learn as they code more.
&gt; Microsoft learned from that mistake which is why you can build net framework on Linux with the latest sdks. You can build Mono and .NET Core. .NET Framework doesn't really exist on Linux, nor do Windows Forms and WPF. Also, Microsoft didn't "learn from a mistake"; they were forced to adapt their business model because Windows license revenues have been in decline. Apple's hardware+platform business continues to do fine. &gt;The general Dev experience of xamarin on iOS is so subpar to everything we've got, average Joe windows shops will never bother to do anything besides maybe PWAs in the future. We may end up in a bizarre world where it's easier to use [Blazor with a Xamarin wrapper](https://github.com/Daddoon/BlazorMobile) than to write a Xamarin app.
Nope, entirely self taught. Was hired initially as just the SQL guy but then started building websites for the company and now build (fairly simple) integration plugin things. This is my main weakness, I have nobody to go to with questions etc. Applied for my first purely programming job this week. Now doubting I'm ready haha. Still, I read the description and understood it once I did.
I can't be the only who works in c# and never fills out surveys
good luck, hope your email isnt as cringe as your username lmao so not BASED
&gt;With DI you add uncomfortable questions about object ownership and lifetime. That is correct, but do keep in mind that some disposable objects have an intended lifecycle that is the same as the application. \`HttpClient\` is a great example of that - spinning up and disposing multiple \`HttpClient\`s to do similar HTTP requests will thrash your internet sockets for no reason. I would imagine that an \`FtpClient\` would have a similar lifecycle requirement, although I haven't used the library in question. &amp;#x200B; It may be an uncomfortable question for you, but you need to ask it anyways.
Haha cheers man. BASED JOB APPLICATION