There's already an enum called in c# that does this. https://msdn.microsoft.com/en-us/library/system.dayofweek(v=vs.110).aspx
So .net 461 project -&gt; .net Standard project -&gt; .net core web? (The 4.6.1 project has reference to nuget Azure Elastic ClientLibrary)
I agree. I spent a few years solely as a DBA (MSSQL/Oracle) and that was more to better understand the internals after working in Btrieve, dBase and Foxpro. On another hand it sucks as I look on in horror whenever I run a trace on EF code.
&gt; A dedicated DBA though can help with storage management, replication, import/exports, monitor run-away queries and processes, manage proper filegroup organization, and help with additional performance tweaks that may be too obscure for a developer to know but is super useful to implement. I have done all of these things as a developer except filegroup organization. We have 17 IT members and no DBA. I'm not sure if I should be happy about accumulating skills or cry about the time I have lost on development.
I sort of disagree. Eating tide pods is becoming more and more common. That doesn't make it a reasonable idea. Less cynically: Did you like Clippy? Because this is Clippy without the paperclip winking at you. It is difficult and frustrating for all the reasons people wanted Clippy gone. It is faster and efficient to deal with checkboxes and other UI widgets than it is to type out full sentences. It is *nice* to start with a typed question like, "I'm having trouble with my network." I don't want to have to type "Yes" to "Have you tried unplugging the cable and plugging it back in?" I want to click a button. Some people are frothing at the mouth, excited because, "What if Cortana/Siri/Alexa/Google could read these UIs to you?" Congratulations, you're developing a phone tree. That's everyone's favorite thing, right? It's going to be really popular and widespread, right up until someone "discovers" they can make their product more efficient and intuitive if they replace their assistant dialogue tree (with an average problem resolution time of 15 minutes) with a wizard (average resolution time of 3 minutes.) What was will be.
My users connect a variety of different instruments and sometimes the com ports aren't the ones they need to be assigned to use their programs. As a tech support I normally have to go back, figure out what instruments they need connected, open device manager and swap the ports to the numbers they need for their programs. Im just trying to recreate the events of swapping the numbers in device manager in a more user friendly program that they can operate without getting confused since they're not tech oriented.
I remember coming across LinqFaster when I was trying to find open source libraries that were using the System.Numerics namespace. It was hard to find documentation on useful ways to vectorize methods in C# in any meaningful way.
We're all soldiers now
A developer alone cannot be a good DBA. They have to want to know and understand the database in order to fill that role. Some devs don't have, or want, to spend their time doing that or gaining that knowledge. In that sense not all devs are suited to be DBAs. A DBA that does not understand what the application is doing, how it's structured, and the usage patterns beyond it is more of a liability than an asset. Without that knowledge DBAs tend to say no to everything and perform backups. Unfortunately that is far more of the kind of DBAs you'll find then the ones who can open up SQL Profiler, read execution plans, and tune your database. If i was in your shoes and the need for managing databases is growing, i would do everything i could to find (or promote internally) a developer who has a strong aptitude for databases. I also would not isolate them in this new role, but ensure collaboration with the rest of the dev team to manage the db in a proactive manner. In that sense knowledge of how ORMs work is should be an important skill as well. Make sure they've got the chops to do more than just db admin tasks, but know how to run a trace, analyze an execution plan, and build indexes. 
**If I were**
Yeah and Oracle is pitching their new auto-tuning stuff heavily. As this stuff gets better and better you are going to see the DB's be able to automatically cache, materialize, index, etc based on observed access patterns. Nevermind that RDBs in general are on their decline as a technology- one of the main features of the DBMS systems of the past was to put multiple layers of smart caching on top of extremely slow disk accesses. Now that RAM and SSDs are f cheaper more and more use cases can just load the whole dataset in memory and go from there. 
Its not really a pity unless you have to deal with a context where the distinction matters.
&gt; The new *.csproj format (from MSBuild 15, VS 2017) doesn't require *.cs files to be listed anymore, and it works with most legacy project types, being completely separated from .NET or C# versions. Do you mean this syntax? &lt;ItemGroup&gt; &lt;Compile Include="**\*.cs" /&gt; &lt;/ItemGroup&gt; Maybe I am just blind, but I have not seen this feature referenced anywhere in Visual Studio. I had to find it on StackOverflow once I got tired of manually adding and removing files. &gt; There aren't that much implicit conversions around, and most of them are around number types (at least the ones I know of) and are pretty handy. Type inference (with var) is your friend here, because it will always infer the correct type in the end, disregarding any misconceptions/imprecisions you have (here of anywhere else by the way, you should really use it 95% of the time if you aren't already) I know that implicit conversions can be handy, for example I am using them to convert double to Complex, which makes perfect sense. However the main problem is precisely that their invisible nature can give rise to subtle unexpected behaviors. This bit my ass a few times in C++. Maybe with var the situation is different, but I much prefer static typing in most cases. &gt; Hiding isn't the really the default, since you can't hide a method by mistake because it raises a warning asking you to prefix with new. Unless you totally disregard whatever warnings the compiler throws at you of course, but I don't think you do. I think non-virtual as default and explicit override is better, even though it limits extensibility, but that's more an opinion that a hard fact. Mocking is better done with interfaces anyway. Frankly hiding should be forbidden. Either override or a compilation error. Having two methods with the same signature is confusing, and behavior can vary depending on how you access the object. I am sure it is a violation of the Liskov Substitution Principle or something similar. Yes, this bit my ass as well. I am not familiar with C# enough to say, but some Java libraries rely on methods being virtual by default. Mockito for mocking, Weld / CDI for dependency injection, cglib for various proxy purposes, Spring for AOP and possibly dependency injection. Testing of legacy code is also much easier when you can mock collaborators. Having non-virtual methods by default is a huge handicap. &gt; Elevating visibility in an overridden method seems to me like an anti-pattern and something I shouldn't be allowed to do (even if I admit it can be useful), but I guess this is my opinion too. Nothing prevents me from exposing the same method by a different name, so this restriction does not really make sense. And yeah, it can be definitely useful when working with WinForms. Yes, this bit my ass as well. &gt; Tuple return values and destructuring are there since C# 7. I was unaware of this feature, thank you! &gt; Switching on "type patterns" with "when" clauses is also a new feature on C# 7. It could be better and is probably better done in Kotlin but it's just the start. I do not mean pattern matching. I mean handling cases with lambdas and blocks with their own scope, instead of legacy case..break statements with a common scope and the risk of fall-through. when (x) { 1 -&gt; print("One") 2 -&gt; print("Two") 3 -&gt; { var str = "Three"; print(str); } else -&gt; { var str = "What"; print(str) } } &gt; Nullable types are designed for value types, there's little use for them as a null guard mechanism for regular nullable reference types. C# 8 should bring non-nullable references by default with optional nullability, with standard null checks being able to work as non null assertions. All of this will be hidden behind an assembly level flag and will only raise warnings, but that's something still. Last time I checked they were arguing about adding a ! modifier to signal non nullability. Having non-nullability by default is definitely a step into the ideal direction, even if they have to take baby steps to maintain compatibility. &gt; I wonder why you would call Linq verbose and compare it to Java streams, aside from naming it works exactly the same as it does in Javascript. Javascript syntax is pretty much ideal. It has no initialization calls like Java's .stream() or .parallelStream(), or collection calls such as .toList(), .toArray(), or much worse, .collect(Collectors::toList). I am aware that these calls and the underlying representations are necessary to optimize queries, but I would benefit better from less verbosity and optimization overhead. &gt; Naming conventions are totally fine by me and my favorite amongst all the languages I used, but again this is really subjective I guess. My biggest beef is the newlines around brackets. They are completely unnecessary, they waste precious vertical space, and they come from legacy codebases, no actual thought went into them. My second biggest beef is parenthesis spacing, if( condition ){...} is much more legible than if (condition) {...}, but this is something that all languages screw up. Thankfully I can change formatting to my own liking in my codebase. &gt; And I'm not sure which version of Visual Studio you are using, because most of the points you cite were greatly improved in 2015 and even more so in 2017. Resharper is far less mandatory than what it was before and it the number 1 reason why people find VS slow as hell. I think I was using Visual Studio 2017 Community Edition. It was not Speedy Gonzales to begin with, but Resharper and Format On Save made it borderline unusable. Rider however is completely fine with the exact same features. Eclipse is not a problem either after being stripped down. When I tried the same with VS, it wanted to uninstall the entire C# feature. Disclaimer, I have an old computer. 
A lot of professional workstation motherboards still provide an internal COM port. For instance my company uses HP Z440 which still provides an internal one, which is useful for us. 
Ah, that makes sense. They just don't bother putting a port on the back of the mobo since it'll likely never get used by your average PC person. Thanks.
When I add nuggets package to .netcore20 web app ... Won’t I get the following warning ... [NU1701 warning ](https://stackoverflow.com/questions/45738982/how-to-hide-net-core-compatibility-warnings-when-referencing-net-4-6-nuget-pac) Can suppress the warning (and run the portability tool as suggested in post) 
That DBA is going to love your EF code-first approach. &gt; so that we could remain focused on innovation. 'innovation'. And really manage your database how exactly? What is your concern here?
Nothing wrong with self-promotion if: * The person is sticking around to answer questions and discuss (not just using the sub as an exposure tool) * The product is worthwhile or unique * It's not being spammed
I appreciate the advice but never unplugging the devices is impossible for our field. To specify, we calibrate several dozens of different instruments, probes, and antennas a week. Usually stuff works out but very often do I have to go back and reconfigure the devices, hence why I am designing this simple program so they can change the settings without getting lost in device manager
No doubt I'm not the only developer in a small company who begrudgingly has to do DBA work because the company refuses to hire a person who's sole responsibility is the database. Can I do DBA work? Yes. Do I enjoy DBA work? No.
Depending on the mock engine you can make it expect an employee item. With a stub you simple check to see that the item was added at the end. // Do Test Stuff... Assert.IsTrue(repositoryStub.Employees.Contains(item)); n.b. This is the most simple solution and I don't think is a popular one. Most people seem to prefer mocks over stubs and generic repositories over concrete interfaces.
the warning is there because you're doing something that should be temporary. there's no guarantee that all of the code in the .net 4.6.1 library will be able to run on top of .net core 2.0. they just allowed people to do it because of a couple of reasons: 1. it makes porting things over to .net core easier. 2. some legacy libraries may never get upgraded even if all of the code is supported. so they didn't want this situation to prevent people from writing .net core apps. so the warning exists to make sure that you know what you're doing. any problems won't show up as compilation errors but as run-time errors. so, you need to make sure you have a lot of tests.
Fantastic explanation ... thanks for your help! Heading to Microsoft for a Hackathon next week - then kicking off an product rewrite. Good to be armed with info going in
I will agree with you on that. Luckily the technical directory is also a dev, he *treis* to set clear boundaries on what he want the DBA to do. He can provide input on schemas and such, but, ultimately that is up to devs as that is just part of the actual dev work. Also our DBA position seems to be the one with the most turnover, usually because of reasons not related to being a DBA though- which we all (her at our office) find odd.
I too have learned many of those things too. It gets in the way of dev work. I mean i do too much tech support as it is (small startup, but hiring to expand our support options so devs do not have to go through this). Even with some DBA experience, I am still kinda slow at it, not my expertise, and I HATE DOING IT.
So... in a c# subreddit filled with developers you all have concluded that no one needs a dba huh? Shocking... Large applications, or anything beyond toy level typically could benefit from an experienced dba. This includes all of the cloud stuff. The world Is indeed moving away from on premise dba and "operational dba" needs of backups, file systems, patches, etc. The real need these days are development dbas, which tend to know your business domain, your application, and focus more on data, sql, tuning, and I know all the devs will cry, but structure of tables. The latter part being that once you have large scale data, structure matters from a performance perspective of the context of how data will be retrieved. I speak this from 15 years of watching only a small select few developers be remotely good and capable of not needing a dba, and tons and tons of other developers thinking they don't but running on way too much hardware for how little their application is actually doing simply due to bad design or inefficiency. We are all dbas, so long as we are all OK running 3x more hardware than we need to and spending the dba salary on said hardware instead. (Or renting it in aws, or azure...)
My company has one dedicated DBA, but then again we have like 30 SQL databases, and a few oracle ones. Our volume is a bit low tho, since most is internal tools that other workers use in their workflow. I kinda agree with the other dev, like if you just have one database and it isnt having shit tons of records being altered every day (like a moderately sized start up getting lots of registrations per day), then yeah, a dedicated DBA would kinda be a waste
shit runaway bot
I agree with your friend in principle, and disagree with him, without agreeing with you... ? I don't think you should have a DBA. I think that, if you do have a DBA, you WILL all become DBAs. Right now, you're not thinking about how your storage works. Right now, it's all code first, and it's all clean. Right now, it's working fine, and you don't have performance issues. Let's say you do have some performance issues in the future. You, for one reason or another, can't address this with a better api/code tier caching/access strategy (generally some transactional/write issue). The only way you can solve this is to go data-first (it's probably not). You get a guy in there. He's going to fix that problem with an optimized query plan in a stored procedure. Oh, well, that's all done. No, it's not. Now all your code pivots around this. Your deployment plan pivots around it. Stuff doesn't sync. Prod is busted. No, you've fixed all that now. I guess he's done with his job and is off to greener (although probably not greenfield) pastures, right? No. You need more optimization. Now, you're developing two models, or you're data-first and suddenly your code is a slave to the intricacies of the storage technology. Development slows down, as there are new layers of testing, review and approval (or new levels of broken if you'd rather forgo that). I'm saying this as somebody who could be a DBA. I have 20 years of experience with storage. I love SQL. I'd love to optimize every query. And I know that it's poison. Premature optimization is the devil! Optimization when it's necessary is a deal with the devil. A codebase should be clean, concise, and maintainable. And that, after it's in-fucking-use. If you need to be optimizing your DB in dev, with dev levels of use, your app will never work so just kill it. If you need to optimize your DB because you've got fucktons of users, then you've got the good problems, son.
I have used SWIG in the past and it was ok, but CppSharp lets you create your bindings using C# code and idioms. AFAIK there's no language or tooling support for the SWIG language.
There are a few key SIMD instructions missing from the API that make it very limiting, it hurts because you can get so close to doing a lot of amazing stuff but run into a missing instruction that ruins it. They are working on that though. 
All developers should have a good understanding of Databases, how to write queries, design tables, run/execute stored procedures... etc. However, there comes a point where your database issues are every bit as intricate and complex as the rest of the code... that's where a DBA comes in... I think a good DBA should have a good understanding of Code as well. Kind of like an athlete... someone good at football can be expected to do reasonably well in baseball, but the DBA is more specialized to deal with issues relating to the database. No one can know everything about everything... but it's nice to have at least one person that knows "Everything" about databases. 
It's both true, in that developers working on top of a database tend to wind up doing some amount of database design and administration, and not true, in that partitions and indexes and patches and backups and so forth probably aren't your responsibilities. You're busy building data models, not administrating the database. The big problem, though, is that the work you're wanting to farm out is (mostly) data modeling and query design stuff, and that touches so heavily on business and system requirements that it's typically difficult to separate it out to a different task. It's also very possible that you just don't have enough of that sort of work, right now, to keep a single person busy on a full time basis. I would say that it probably ought to be *somebody's* explicit responsibility, even if all they do with it, in practice, is review the rest of the team's proposals and issue a yea or nay. At some employers, that responsibility may have an actual name, while other places may just say "Yeah, Bob's the database guy, why don't you run it past him?" It may even just be an implicit responsibility of your team's tech lead or manager. But, I think it should be *somebody*, and everybody on the team should know who. If nothing else, you need somebody able to take a look at, say, a nullable bit field and say "What the hell is this?!" or to enforce conventions regarding names, data types, and so forth. ETA: this is probably a good question for a more general sub. It's not a topic specific to C# or .NET.
Microsoft has been beating this drum for 20 years. ["One major enhancement to SQL Server 7.0 is that the database engine has become largely self-configuring, self-tuning, and self-managing."](https://msdn.microsoft.com/en-us/library/aa226166.aspx). I still wouldn't want to run any application with lots of data under heavy load without a DBA my side, and I say this with a team of developers who are really excellent SQL developers.
The OP and most of the comments are pro DBA. You can stop pitchforking your straw man.
This should be the top
Yes, that was exactly my experience with it. I was able to make a few methods that were faster using SIMD instructions, but it required making pretty extensive changes to my code structure to get it to work.
That kind of shit is why we have NoSQL databases. When people say "schemaless" many of them really mean "no dumbass DBA preventing me from updating the schema".
We are all DBAs. But some are better than others. Experienced DBAs who know their shit are way better than full stack devs who google every otger thing. Honestly, if you have a production app, then there should be a dedicated DBA. 
This code was taken directly from Microsoft's website https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/hello-world-your-first-program
I second this. Also, It’s not only a matter of design. The data has to be nurtured for decades in many business domain, like finance. 
I agree. In shops I've worked with a well designed DB, the devs had strong DB design skills. There was alot to the design process as well that gave the small team opportunities to understand how new additions or changes were married with the evolving app design, and it the combined evaluation of the design allowed for some insightful tweaks before anyone started writing code against that design. We always talked through how the application would interact with new tables in detail, sometimes drafting out query criteria so we are clear on what the app would be bringing back and hash out edge cases. We did have a DBA, and they were excellent, but generally weren't involved in deployments. Instead they handled backups, tested recoveries(verifying your recovery process is equally important as backups), handled manual modifications of data for business requests where we had no UI for certain admin/config features), monitored, looked for hotspots, managed the various files and monitored sizes, acquired disk space as needed. Sometimes they would look at needed indexes, but that was rare because every new table we created already had a set of query scenarios in mind based on application behavior, and so we knew exactly what we'd be throwing at it and create appropriate indexes in advance. I'm sure there's alot more important stuff they did that I'm forgetting because they did it so well. When things are quiet, things are good. Other places with hokey DBAs were relying on heavy handed third party software to do backups, and alot of times they were doing stuff like full backups and truncating logs where they had no point-in-time-recovery because they thought a proper backup was too slow and taxed the DB. I've had to hold DBA's hand as a lead dev through SQL Server migrations when they required an intermediate version in the migration plan. In one case we layed out a detailed implementation plan and were migrating the staging DB to exercise the production plan, and I made it really clear that I expected the plan to be followed as if we were in production maintenance window, in order to verify the plan. Very simple concept. Instead they took shortcuts that wouldn't be possible for the production migration.
Agree 100 percent. I think that once a db and app platform grows seriously large, enough to need ops staff, having a dba to ensure healthy operational use (maintenance, backups, failover, etc) is a great asset. Letting them dictate schema is not an operational positions responsibility unless he alerts you to underlying issues in db design from poor planning or design from the developers that is leading to awful performance or size issues.
*raises hand* ..... But when i told my project manager that it was a time sink but a needed task, we were assigned time with an in house dba and he did it better, quicker, and with more confidence than my efforts. Plus, now if the db hits the fan, i wont have an overwhelming sense of guilt. 😊
We are all DBAs to a degree. However, dedicated DBAs bring analysis and tuning skills that developers do not possess. A developer is often asked to wear many hats, but sometime you require those specialized roles. It depends on the project and its requirements.
I work for the largest ATM operator in the world. Trust me when I say you need DBAs.
We have DBAs. We also have 30,000 databases, including one massive 7.5 tb database. They mostly do backups, occasional troubleshooting, and consults for things we realize will be tricky. Sql performance is mostly on dev. We monitor it with timings in New Relic and dig into performance specifics with Solar Winds. If we find a specific query that suddenly got a bad plan we get the dba team to recompile it. If we had access wet could do that, but it's the last thing that hasn't fallen to dev ops. Developers suck at database backups / restores in my experience. You don't want to be googling "how do I replay the tranlog" when you're restoring. Some people mentioned auto indexing above - I'd be careful. Index Update on data change can slow you down. Not every query needs to be covered by an index. It's a balance. Good DBAs can help with that. Most importantly - move to ssd if performance is an issue, it's such a difference.
Most (not all) DBAs are system administrators, not application developers. The trouble comes when your application architect thinks "databases = magic" and starts passing design decisions over to the guy who is primarily there to do backups and apply security patches.
I see the potential here but the analysis in your sample screenshot doesn't seem to get the proper sentiment from the tweets.. most are listed as negative but there are some positive tweets aligned with negative.
I am a DBA and a Developer, wearing two hats at my company. I can assure you, those roads only cross paths every now and then. There's a lot more to databases than "keeping them clean" and EF just like there's a lot more to development than using Git. You guys will want someone with DBA experience for proper security, proper server configuration when the database grows especially. Back ups are more than just "making a backup" if you want to ensure you never lose data ever. When you find that one day performance seems shit on the database and you guys all swear it was working fine in the code, you're going to want someone who knows all about how to dive into it. And sometimes, want to hear it or not, code first even with EF produces shit relationships. It takes someone with DBA experience to see that. That all said, it does depend on scale. If you're talking about a little sqlite db, then why even try. But if you're looking at PostgreSQL, Oracle, MSSQL, Maria or MySQ, get someone with experience with THAT database engine.
Agreed. This was more of an exercise to see if this task was possible and to explore the libraries (if any) that were out there. Although I haven't measured actual accuracy of the model, just by looking at it, it does not seem to classify tweets correctly as you pointed out. This I assume may be caused by tweets not being clean enough for processing by the sentiment analysis library. I think an easier and more accurate (although not free) way to go about it would be to use the Azure APIs.
Ah, still, I must iterate that I'm impressed with your post, while the sample results may not show proper sentiment there is a great deal of potential here. I'm definitely going to be working with some of these libraries you pointed out.
Checks out
I had no idea this was a request feature. It's uses are not immediately obvious to me so maybe I just understand it wrong? Is it basically just a way to pass a read-only variable to a function or am I missing the bigger picture here?
There's a few others. SharpGenTools (which I maintain) is the code generator for SharpDX. It's focused on mapping COM libraries accurately with a lot of allowed customization.
Yeah, from what I understand it's a performance feature, but my made-up estimate is that 99% of C# developers will have zero need for this. 
I think the other half of the issue is places that are big enough that they need a DBA, but there isn't enough actual system administration work so the DBA has to wear multiple hats.
A significant number of USB accessories use USB to work. Bear in mind, when we talk about a COM (or serial) port... it's the Universal *Serial* Bus all our devices talk over. ;) Most GPS receivers show as COM ports. Any sort of microcontroller projects like Arduinos and the like are connected to over COM. My home automation system is talked to via COM, and another one I'm about to add support for does as well.
I can almost see you ducking as your hand slowly raises.
I hate by reference because side effects so if I can look at the argument list and know a function won't change it, that's a very good feature. 
That's a much more concise explanation than what I had. Nice one! :)
About the new csproj format : https://blogs.msdn.microsoft.com/dotnet/2016/10/19/net-core-tooling-in-visual-studio-15/ (the article mentions .net core a lot because it is what carried the new tooling, but they describe it as unified across all .net flavors) About non nullable references, they aren't gonna add a "!" modifier, I think it wasn't part of any proposal past maybe the original one. It was dropped quickly because it's not a good solution. ".ToList()" or ".ToArray()" are definitely not just about optimisation, and it's not fair to compare that a a language that has simply one array type. Even the distinction between "IEnumerable" and "ICollection" is massive. Calling "ToList" is far from systematic, sometimes you need to execute the query right away and sometimes you need to defer it, and this is especially true when your Lina queries work against a database. Javascript can't do any of this with its basic arrays types, and it's definitely not just optimisation.
It's a cost/benefit-thing. How much extra database power can you get for the price of your first DBA + manually writing trivial CRUD stuff + manually handling migrations and schema changes? My estimate is a lot. Where I'm located, you can get an Azure SQL database P11 for substantially less than the cost of an experienced DBA. That's a lot of power. And here we're not even considering the cost of complicating the devs work.
But wouldn't that be a really easy optimisation for the compiler to make anyway? If the variable's not assigned to, treat it as read-only.
Passing by reference is the optimization, not the read-only behavior. `in` being read-only is simply intended to make it safer to take advantage of this optimization.
Yes indeed, that would work too. I like my solution better because it forces him to use a static enum method, to look for solution that are already implemented. 
`ref` is a performance feature, `in` is a contractual feature - you're saying to the users of your function(s) that you will not modify what is being passed in. To say that 99% of C# have zero need for contractual-type programming is pretty ignorant.
No, I meant, couldn't it just do the same optimisations that `in` does anyway if the the same requirements of using `in` are met?
Can someone offer a simple example of where this would be useful?
We should all have knowledge of the database systems we are writing for, but in terms of Administrating the DB? That stuff takes time, and effort, and probably not cost effective for a developer to do the day to day work a DBA must do. Not withstanding the nuances of being a full DBA which would be completely lost to a developer. As developers we suffer from a huge amount of hubris, in regards to network administration, database administration and security administration, which just opens up the business to all manner of risk. 
&gt; ref is a performance feature, in is a contractual feature I think most people would understand what I wrote without having to spell out that distinction. Nonetheless, you did succinctly clarify the difference. well done. That said, your last sentence was condescending and abrasive - the worst side of programmer culture.
I think he ment was 99% of programmers shouldnt use it.
C'mon, "99%" is over-generalizing it :) That said, it has been difficult to find a competent C# developer in my area - as you say, *many* just write CRUD/Web apps and are a C# developer - but there's so much more out there! 
I think at least in EF you should try to avoid implementing repositories since it's generally in place in EF from the start. You can, however, use services or whatever to produce an abstraction on top of that. Also I don't think you should test EF. You should test your own code instead. The following code uses IQueryable (DbSet implements it) of Customers, and LinqToObject to test the queries rather than testing directly against the DbContext. public static class CustomerMapExpressions { public static readonly Expression&lt;Func&lt;Customer, CustomerDto&gt;&gt; CustomerToCustomerDto = c =&gt; new CustomerDto(c.Id, c.Name); } public static class CustomerQueryExtensions { [CanBeNull] public static T Get&lt;T&gt;([NotNull] IQueryable&lt;Customer&gt; query, Guid id, [NotNull]Expression&lt;Func&lt;Customer, T&gt;&gt; map) =&gt; query.Where(c =&gt; c.Id == id).Select(map).SingleOrDefault(); } using static CustomerMapExpressions; public class CustomerController { private readonly IQueryable&lt;Customer&gt; customerQuery; public CustomerController([NotNull] IQueryable&lt;Customer&gt; customerQuery) { this.customerQuery = customerQuery; } public IActionResult Get(Guid id) { var customer = customerQuery.Get(id, CustomerToCustomerDto); if(customer == null) { return NotFound(); } return Json(customer); } } [TestFixture] public class CustomerQueryExtensionsTests { [Test] public void Get_WithId_ReturnsCustomer() { // Arrange var id = Guid.NewGuid(); var customer = new Customer { Id = id }; // Act var result = new [] { customer }.AsQueryable().Get(id, x =&gt; x); // Assert Assert.That(result, Is.Not.Null); Assert.That(result.Id, Is.SameAs(customer)); } } Note that I'm not saying this is the exact way you should do things, but perhaps it brings some inspiration. Avoid sending the enteties around in the application unless it makes sense because it causes quite a bit of overhead. If you can just map to a DTO using a query that means that EF will act mostly as a glorified mapper, and in *most* situations that's exactly what you want.
Not when you're calling native code because the runtime can't know. Today you specify this with `InAttribute`. `in` applies this automatically.
 public struct TransactionData { public Guid Id; public int Revision; public DateTimeOffset Created; public Guid? Parent; public decimal Value; } public delegate void TransactionMutateDelegate(in TransactionData data); public sealed class Transaction { private readonly TransactionData data; public Transaction(in TransactionData initialData) { this.data = initialData; } public Transaction With(TransactionMutateDelegate alter) { var data = this.data; ++data.revision; alter(data); return new Transaction(data); } public Guid Id =&gt; data.Id; // etc. }
Yeah sorry - sarcasm is lost on the internet (was trying to be funny). The second paragraph was my real advice. I am on my PC now - I will lookup what I was referring to and get back to you.
Every feature that enables the remaining 1% to keep using safe C#, instead of being forced to write unsafe blocks or switch to C++, is a welcomed improvement.
I welcome every C++ performance feature that allows me to write everything in 100% C#. Who knows, maybe some day, C# alongside .NET Native could be used to write the next generation of DirectX, given enough safe performance features.
We have been just fine without a DBA on the team for 15 years. Dev team size is a little over 20 right now. I think people here would revolt if we were told we had to let someone else do the db side for all of our work, and management would never allow it because it would slow development down too much and probably create an us-vs-them situation. With that being said, I agree with everyone else here saying that administration is not the same as development. I personally think that having someone to turn to for optimization, tuning, backup, and replication would provide a lot of value. An operations generalist just doesn't cut it for many DBA tasks.
This sub could really use a wiki.
Yes i very much need some help Thanks!, Im not sure if i translated my assignment perfectly but here is literally what it says (Translated) "You must create a program for storing personal data in a text file (StreamWriter). When the program is started, the program will load all people (StreamReader) so that they are in some form of list in the program. After the loading is complete, the user must be allowed to create a new person or list all persons in the registry. Choosing the user to create a new person may fill this in First Name, Surname and Email of the Person. In addition to being added to the list in the program, the person will be added to the file that stores people when the program is not running. If the user chooses to list all persons, all persons should be listed in the console with their tasks and then the user must choose what to do, create new or list. Your program should handle exceptions that may occur in connection with file management and in the program, people should be handled as their own data type, ie you should create a personal class." So anything that isnt specified i guess we can chose ourselves how to do. Like your question "the user list shown and options has to be graphically managed or just console level stuff" He doesnt address that so i guess we could do it either way. Now i havent actually written much of the code, Because while i do know somewhat about what commands to use (as stated in my post) I still dont know totally how to code. Im working on the code ATM so this is what i have so far.. where im kinda stuck In my class: class Kona { public string firstname; public string surname; public string email; } } In Program: namespace Inläminig { class Program { static void Main(string[] args) { bool running; running = true; do { Console.WriteLine("Create user or list existing users?="); Console.ReadLine() } while(running); } } } So: I know i need some variables (is the command literally "Variable"?) i'll need some "if" commands for the possible choices, and i dont know how to to that really.. im trying to find out thru the powerpoints with no luck so far.
Hmm.. Reddit formating kinda messed some of that. i'll get a link with some images instead.. But im making some progress so i'll do it soon.
My dev lead is a substantially better dba than any other dba in the company. Having a broad and deep end-to-end understanding will help improve the system overall
Unfortunately I have heard this statement before. Developers especially young developers seem to think there couldn't possibly be gotcha they aren't aware of. EF is not infallible it does not write efficient sql queries many times this isn't a problem many times for small companies but it is when your user base starts to scale. This can be avoided by have a good dba that uses tools to profile queries and find problem queries. furthermore things like Indexing and Clustering for high availability are not things your C# developers will be efficient at. Finally BI tools and things like data cubes and MDX can make reporting and front-end data use vastless less resources per request and removes the need for things like building denormalized data tables. The first time you temp tables start consuming all you storage on your database lets see if he's still saying that.
See https://martinfowler.com/articles/mocksArentStubs.html#ClassicalAndMockistTesting Basically, you can either Mock your data access (EF) or Stub it. Usually, you want to test your Business Logic / Business Rules and not worry about the data access. In this case, as mentioned in other comments, you would have Repository interfaces that are used as the types your business objects are "fetching" data from. In your tests, you would create a stub or mock of your Repository interfaces and pass those into your business objects / business layer. If you want to actually test your EF queries... You would have to connect to a database to run these tests (obviously). You would test your concrete Repositories - which are in their own "data access" project. Write tests specifically for that project in this case. Make sure you separate your business objects from your data access objects (by putting them into different projects). EF models should stay in their own project and your repositories should be return different types of objects (that come from your business layer). Otherwise, your data access is married to your data layer and you can't really test it properly (or it gets really messy) Business Layer (Fetches data Via repo interfaces) -&gt; Data Access (EF wrapped into Repository classes which implement the repo interfaces and returns objects from the business layer) Does that make sense? 
The task is only considered unhandled when the task object is finalized. You won't see that happen here because you're keeping a reference to the task in `t3` (at least in debug mode) and there is no GC pressure.
You created a Universal Windows Platform project ("Windows Store" app), but the tutorial is for a "Console" application. When making the project, choose "Visual C# -&gt; Windows Classic Desktop -&gt; Console App (.NET Framework)" https://i.imgur.com/F5Tdo0V.jpg
If your team has the budget sure why not! But with modern databases and cloud options, a lot of the skills of the DBA are being managed by the increasingly self managing software. Azure SQL Databases eliminated all our database issues from 5 years back. It’s much smoother sailing now!
I do believe that this is the correct answer. Note the filename ends with .xaml.cs, not just .cs. That's an indicator for you, /u/ddalcanto.
Also, he needs to make sure `using System;` is at the top (it should be by default if he follows your directions). I say this in the event that he may do something funky and end up back here saying "Console still doesn't work".
Thanks, it works now!
It's also worth noting that many of the complaints are already a few years old. I've been using the SerialPort class in .NET 4.6.2 and 4.7 and haven't experienced any weird issues (however, I don't use the DataReceived event). If I unplug a USB/RS-232 adapter while the port is open (as mentioned in [the top comment in the thread you linked](https://www.reddit.com/r/programming/comments/24yq5w/net_serialport_class_library_is_horrendous/chc3xen/)), I get a System.IO.IOException. It's [easy to handle](https://imgur.com/P2x1Qzk) and does not force my program to end.
`in` combined with `readonly struct` is a performance feature also. The code that will get the most performance improvements from it are likely to be games that happen to rely on large structs being passed around. This sort of thing works nicely with `Span&lt;T&gt;` segments over memory being managed outside of GC. You can have a `Span&lt;MyStruct&gt;` that holds a single instance of a non-readonly struct, reinterpret it as a readonly struct with the same layout and then call methods with `in` parameters without making a single copy of the underlying data (obviously not thread safe).
good to know! I simply haven't looked back since switching to Zylsoft. 
Maybe so, but one of the instructions listed, when making a new project, is making sure you created a "Console Application" - as stated in other responses, you made a Universal Windows Platform project which may not have access to the Console object by default.
We do this a lot at out current org. Most of our apps have a "web" project and an "api" project. The "api" project is usually a WebAPI application. The "web" application is an MVC/Razor app, but only to deliver an index page to run an angular app (plus we get things like bundling of scripts and CSS using an MVC app) - so usually it has one controller and one controller action to deliver the index page. Angular partials and and an angular module runs the rest of the front-end.
Yep, you got it - MVC for serving "empty" pages, webapi for data, front-end framework like angularJS to tie it all together. Simples. The only thing you'll need to look out for is passing the XSS token into the angular app...if that's something you're worried about.
Do you have enough work to keep a dedicated DBA busy full time? If the answer is no, you're probably a lot better off hiring someone whose primary job will be DBA, with a skillset focused on that, and secondary will be helping out on the dev side... writing, improving, and troubleshooting SQL or other db related code.
Thanks! 
Where does this "Razor is outdated" idea come from? If your app is simple, Razor with a bit of jQuery should be more than sufficient. If your entire app consists of logging in and writing something to a database, there should be zero JavaScript required to accomplish that. KISS. Great advice, hurts my feelings every time. 
You might also want to encrypt/decrypt the data in the text file considering this is for cyber security lol. Googling "simple string encryption/decryption C#" will yield a lot of useful results.
It's 2018, we don't use the "J" word anymore.
Roles are bullshit. But a person dedicated to a single role may actually become surprisingly proficient. I don't advise anyone to go down the path of picking out just a single role and then gluing themselves to it (self-limiting and all that). I'll say this: A dedicated DBA is a nice-to-have, and not a "must". You are all DBAs if you want to be. If you don't want to be: Hire someone to do it for you. 
The attribute can't access the private members. It's only fed a parameter argument. The _expression_ though, `ConstantControllerString` from `stringParam: ConstantControllerString` is in scope of the `MyController` class. No different than: public static void Main() { var controller = new MyController(); var foo = new Foo(); controller.AccessMyPrivateMember(foo); } public class Foo { public void PrintMessage(string message) { Console.WriteLine(message); } } public class MyController { private string ConstantControllerString = "foo"; public void AccessMyPrivateMember(Foo foo) { foo.PrintMessage(ConstantControllerString); } } https://dotnetfiddle.net/qXPuS9
Here is something I discovered recently but makes sense after you think about it: public class FooBar { private void DoStuff () { ... } private class Nested { public Nested (FooBar fb) { fb.DoStuff(); //private member accessible in nested types } } } `Nested` objects can see `DoStuff()` on `FooBar` even though the method is private :-D.
Right, I understand that private members can technically be made publicly available through other means. I was more surprised that attributes have implicit compile time access to the scope of the class that they decorate. I usually see a class "scope" as everything that appears within its curly braces, and this breaks that understanding, might be what was most tripping me up.
 If you're only serving it as an index page, there's no reason to server a .net core spa application. That's opening another port with just an additional layer on stop of a regular angular project.
I actually handle these matters for my company. But hey. If you think it's hard don't let me tell you otherwise.
Yes, while in C++ friend classes can play with your private parts, in C# your children can.
That's what he's saying, it doesn't have access. The class has access to the attribute's constructor, the attribute doesn't have access to the class. Try implementing some attributes yourself, and then accessing the decorated class's members inside the body of the attribute constructor- you can't. What you're seeing here is the class feeding the attribute constructor a value, not the attribute accessing the private member.
So i've made a lot of progress and with my code, I made some images you can review. All the code except for the Class: https://imgur.com/a/dvChy The class: https://imgur.com/a/gtG4W
we havent went over anything about encrypt/decrypt in C#, unless you mean using "Private" instead of "Public" but i've written all the code around public so im not sure if i can do private now without changing too much of the code.
I'm having a bit of trouble understanding what you're asking, but I think you're trying to profile your code. If you google "c# code profiler" you should find lots of useful information and tools.
The attribute is, from the compiler's perspective, part of the class definition itself. (An aspect or quality of the type definition.) This is by design. I get that it can come across as strange when you look at the C# representation but consider the IL code: ``` .class public auto ansi beforefieldinit ConsoleApp1.MyController extends [mscorlib]System.Object { // note that the value being passed to the ctor is the bytes for "foo" as a string .custom instance void ConsoleApp1.DemonstrationAttribute::.ctor(string) = (01 00 03 66 6f 6f 00 00) // Fields .field private static literal string ConstantControllerString = "foo" ``` The attribute is part of the class despite the fact that we write the attribute "on top" of the class in C#/VB.NET.
The program has specific ports requires with no way of changing them? seems like a questionable design choice...
Here's a link to odata syntax: https://msdn.microsoft.com/en-us/library/gg309461(v=crm.7).aspx Here's some tutorials on using odata: https://docs.microsoft.com/en-us/aspnet/web-api/overview/odata-support-in-aspnet-web-api/odata-v4/create-an-odata-v4-endpoint
Those links are doing what I'm doing now. I'm trying to avoid loading all records into memory before filtering
check your types. If you are using IQueryable, then it won't be loading all results into memory. Did you do any checks to verify that all records are being loaded into memory or is this more of an assumption? It's hard to tell without seeing any code.
Well if anyone sees this wanting to load only the filtered into memory so they can do something to the models before returning then here is how I ended up doing it var s = new EnableQueryAttribute(); var g = s.ApplyQuery(context.Model, options);
JQuery is evil now? Well damn, that is the only thing I ever actually *enjoyed* using on the frontend. Why must frontend development be an entirely different reality than backend.
&gt; JQuery is evil now? It ends up in a bunch of spaghetti code. Everyone knows that. 
what, jquery? it's 2018, some of us have work to do instead of fucking around changing libraries every 10 minutes
It’s JavaScript. There has to be thousands of libraries that all do the same thing. We know libraries, in fact, we have the best libraries. Our libraries are huuuge, and sometimes we include pictures of Guy Fieri in them.
absolutely. Also MVC and Jquery/Ajax is a great combination and a fraction of the footprint of something like angular. Recommend it. 
&gt;I wouldn't even consider myself to be a junior DBA I've met plenty of DBAs with years of experience who wouldn't know how to do any of those things.
I always prefer UNC. Server names rarely change and if they do, unless the user's mapped drives are set up by a centrally-managed script, those are going to break too. Network admins are reluctant to change server names since they know how many users are going to complain when they do. You can never safely rely on drive letter mappings staying the same. And if they change, you can never really know what drive S: used to be. But with a UNC path, you can usually deduce where it used to be by the server name. Even if it has changed, hopefully there's documentation of the server name change.
Couldn't you get the IP address? Then you should never have to worry about either of the problems (disconnecting / or upgrading) public string GetIPAddress() { IPHostEntry ipHostInfo = Dns.GetHostEntry(Dns.GetHostName()); IPAddress ipAddress = ipHostInfo.AddressList[0]; return ipAddress.ToString(); } Do something with your returned value.
$$$
Ewww
Always UNC. I can’t count how many issues users have from developers using mapped drives. Plus our VPN forces people to manually run a batch script.
&gt; Razor with a bit of jQuery &gt; there should be zero JavaScript Ummm....
&gt; If your entire app consists of logging in and writing something to a database I would have expected a person commenting in a C# thread to understand conditional statements better than most. Surprising.
Context matters in English. An application that consists of two tasks, logging in and writing something to a database, IS a simple application. I read that as you saying Razor w/ some jQuery was enough to accomplish that ask and should require zero JavaScript. 
Of course you are completely right that it would be impossible. It was probably copied over from list&lt;&gt;. Report it over at the corefx github 
The proper way ? The correct answers are all of: both, the former and the latter. It's a question that requires knowing which goes wrong more often now **and in the future**. Allow both and be ready to support failures stemming from both.
Trivial and not specific to tests.
All I was doing so far was backend services and probably some simple forms GUIs. Web is a whole other beast, that's why I ask what the best way is to approach it.
&gt; The attribute is part of the class despite the fact that we write the attribute “on top” of the class in C#/VB.NET. Well, the attribute *instance* is part of the class. And in IL we write “.custom” short for “custom attribute”.
Not evil, but frameworks are better for organizing large codebase, and vanilla isn't horrible for tiny scripts. In-between jq is a good choice.
Another possible option is storing the root path in another table and associating each entry with that. All paths stored in the main table would be relative to this so changes to a UNC or mapped drive would only require a single entry to be change Vs all of them. It would be a trade-off depending on how likely you think paths will change.
In your situation UNC sounds the way to go. There are situations where I'd use the drive mapping (e.g. in a large organization drives could be mapped to local servers and that might be what you're looking to reference, rather than a specific UNC). I would recommend storing the path in a config though (e.g. App.Config) and reference that, then if you need to change it in the future it's a one line change.
I have definitely used this approach and it worked well over time.
I always use a UNC path and add the server root path in my appsettings.json, add documentation about the app that specifies if the server is changed that they need to update the config as well. 
As others have said, _SimpleNetNLP_ does not seem to give good results for tweets. Consider using [VaderSharp](https://github.com/codingupastorm/vadersharp) instead.
Don't do the math on the output line. Assign it to a var. Then print the var. That might help you see the brackets dont match. And you need to concatenate the strings. I.e ("average is"+result).
Looks like line 28 is missing a ) after 3.
 Console.WriteLine("The average is: " + ((num01 + num02 + num03) / 3)); 
I recommend using string interpolation, but your output line is missing an end parenthesis and is not concatenating the string and the calculated average value.
You're missing a + between the " and the parenthesis, your average calculation line should be something like this: Console.WriteLine("The average is " + (num1 + num2 + num3)/3);
Dude you need to covert the numbers to text before adding it to a string. Set it to a variable and in your console.writeline do "Scores are:" + averageNumbers.ToString() Or wrap the whole equation in brackets and do .ToString() on it in line
Also, your code is fragile because you are using int.Parse instead of int.TryParse. Please research these different methods. What happens if you parse "abc" into an int? How are you handling an error?
Your last Console.WriteLine which displays the answer is missing a closing bracket, and you have to concatenate that literal string with the result of the equation. var average = (num01 + num02 + num03) / 3; Console.WriteLine("The average is: " + average); 
Nope
Console.WriteLine(“The average is :” + ((num01 + num02 + num03) / 3)); Should do it.
 Console.WriteLine($"The average is: {(num01 + num02 + num03) / 3}");
Thank you. That helps.
Yes. I don't believe I've ever put a calculation in one before, but if that's legal then this is what it would look like. As this is a school assignment, I was hoping the OP would do his own research, as he would like remember it better ... but maybe not, and maybe that was presumptuous of me.
That’s definitely an option and in fact it was the first one I tried when doing this. Unfortunately, results were not great either. This is not a knock on either of the packages, I happen to think it’s an issue that has more to do with how clean the tweets are prior to processing rather than the libraries themselves
It is nice to have functioning code to work off of. Stylistically, I wouldn't really prefer putting a calculation in the interpolation as it muddies what's going on. But that's just a personal preference.
Others have already answered your question, but in future paste your code rather than a screen shot. It makes it easier to help. Also indent it 4 spaces in the post so it looks like this
Since the values are all Int32's, you'll need to change the `/ 3` portion to `/ 3.0` in order to get a double result. With `/ 3`, it will perform integer division, which truncates the result to an integer and then assigns the integer to a double variable. For example: double avg1 = (1 + 2 + 4) / 3; // avg1 will equal 2 double avg2 = (1 + 2 + 4) / 3.0; // avg2 will equal 2.3333... 
dunno if this is the same as a c union, but that would be achievable using the structlayout and fieldoffset attributes
&gt; Why would I, as a consumer of System.Collections.Generic, care about this implementation detail in the first place? So you can avoid situations like doing a binary search on a linked list ...
this is not a static member, its a const, which is basically a named literal
It's often called a Sum Type. Here's a nice site about F# which covers Discriminated Unions: https://fsharpforfunandprofit.com/posts/discriminated-unions/
even if this kinda defeats the purpose, but a general sum type could be implemented using the DynamicObject. member access on such objects is redirected to a method, so that could be used to check for type safety. sadly this is only evaluated at runtime, so probably not what we need. other alternative would be to generate classes with T4 with a growing list of generic parameters to ensure type safety
No such think in C#, but they are mostly syntactic sugar and a nice alternative implementation can be done on case by case basis. 
There's a language issue and it seems to be getting positive feedback, but at best it's still a long way off. https://github.com/dotnet/csharplang/issues/399 
I'd like a better way to do this too. A parent class can sort of be used as the disjoint union of its subclasses. C# 7 allows you to pattern match on the subclass in switch statements.
I actually tried implementing this in the form of the [Either monad](https://mikhail.io/2016/01/validation-with-either-data-type-in-csharp/) this week, which worked really well with implicit casts and no properties (so developers don't get any crazy ideas)--right up until another developer suggested just using abstract classes instead. I like the pattern, I just need to figure out where to use it and when not to.
There are a handful of different ways to cobble together a simple, generic union type for type-safety purposes, but they won't have the memory advantages of a manually-laid-out struct.
The closest you'll get to the sort-of F# style is to create an empty interface that you attach to each of the possible types of the union and using pattern matching a la void DoStuff(IDiscriminatedUnion obj) { if(obj is PossibleState1 x){ /*do stuff*/} if(obj is PossibleState2 y){ /*do other stuff*/} }
Thank you for this resource. I will check it out.
Everything is mostly syntactic sugar, by that measure. It’s not easy to implement these yourself, especially not if you want value type semantics. 
Check out this library: https://www.nuget.org/packages/DiscU/ We provide fast and simple Discriminated Unions, with robust and type-safe matching and switching capabilities, that work well with the C# type system. The library automatically converts any of it's union elements into the union when passed to a method, constructor, function, or any similar context in which type coercion is allowed. I recommend you try it out. I'm currently working on a patch that upgrades it in-place to a struct, so that the condition of null is not allowed, and instead defaults to a None sentinel value. Also in the works is moving it to its own github/nuget organization so it's not just tied to me - I expect to get to these by the end of the summer.
This is pretty cool, great work!
You could also use an abstract class to avoid type casting: public abstract class Either&lt;T1, T2&gt; { public enum Tag { Type1, Type2 } public Tag TaggedType { get; } private Either(Type tag) =&gt; TaggedType = tag; public sealed class Type1 : Either&lt;T1, T2&gt; { public T1 Value { get; } public Type1(T1 x) : base(Tag.Type1) =&gt; Value = x; public implicit operator Type1(T1 x) =&gt; new Type1(x); } public sealed class Type2 : Either&lt;T1, T2&gt; { public T2 Value { get; } public Type2(T2 x) : base(Tag.Type2) =&gt; Value = x; public implicit operator Type1(T1 x) =&gt; new Type1(x); } public TResult Match&lt;TResult&gt;( Func&lt;T1, TResult&gt; f, Func&lt;T2, TResult&gt; g ) { switch (this) { case Type1 x: return f(x.Value); case Type2 x: return g(x.Value); default: // practically unreachable throw new ArgumentOutOfRangeException(); } } } There's a handful of ways to skin this particular cat. I think I'd prefer a struct to the abstract class approach above (for a union of 2-3 types, a tagged struct with separate fields for each type might be *slightly* more efficient than the abstract class, above, without incurring typecasts; for more than that, you could fall back to typecasting). I would probably also recommend using a template to generate these as needed, rather than using a parameterized type, just to get more useful names on things.
I don't think I'm following you. Binary search on a linked list is inefficient because linked lists are O(n) for random access. Any reasonably CopyTo() implementation is going to be sequential access. My point -- and let's just say it's with respect to List&lt;T&gt;.CopyTo() -- is that it shouldn't matter to me whether they internally implemented it with Array.Copy() or by rolling their own for loop; it's got nothing to do with me. So why are they telling me? I feel like I'm missing some implication about Array.Copy() that would make this a relevant detail.
I'm not sure of the full details but you do need Visual Studio Pro or higher. I found this page which seems helpful: https://developer.xamarin.com/guides/ios/getting_started/installation/windows/connecting-to-mac/
Thanks!
&gt; other alternative would be to generate classes with T4 with a growing list of generic parameters to ensure type safety [Someone has already taken care of that](https://github.com/mcintyre321/OneOf).
You can assign a variable in your if statement like so if ((variable = function ()) != null)
Side note: I would recommend renaming your method to GetTeleportCard, as the current name implies that a Boolean will be returned.
The best way would be to change your method to have an out parameter. For example: bool TryGetTeleportCard(out Card target) { ... } Then you can do: if (TryGetTeleportCard(out target)) { ... }
In C#7, you could do this either with pattern matching or with inline `out` variables. Since you're using Unity you're unfortunately still limited to C#6, I believe. Otherwise, you can't declare a variable in the if condition, but you can assign a value to an already declared variable: Card card; if ((card = CheckIfIHaveTeleportCard(target)) != null) { DoSomething(card); }
Another way(only for educational) Var list =iEnumerable&lt;int&gt;(); list.add(num1); list.add(num2); list.add(num3); Console.writeLine(list.Average()); 
Don't over think this -- just assign the result of that function call to a variable.
I like this solution the most. It follows keeps the assignment inline, removes the ambiguity of a null value and conforms to established C#/.NET conventions.
Not in this specific case, but usually you need details about internal implementation to write efficient code. I was mentioning that because once I saw somebody using a binary search on a class that implemented an interface similar to IList without being aware that inside data was stored in a structure similar to a linked list.
Game engine...
FWIW, here's my take: var card = GetTeleportCard(target); ValidMove = card != null; if(ValidMove) { ListOfCardsUsedThisTurn.Add(card); } I renamed the CheckIfIHaveTeleportCard method because, to me, "Check" implies that it returns a bool.
Might as well just move the assignment up and get clearer code (plus can use var) at that point. 
 But please don’t use anything like that in actual code :p
That doesn't work as well if you have a series of `else if` statements as the OP mentions. In that case you'd need to either forgo lazy evaluation or complicate your control flow instead.
Just create the variable outside of the if statement, and then assign it inside.
Out. Look at dictionary's TryGetValue, copy that.
Not sure why youre being downvoted, this is the way I would do it too. Out parameters and assignment in conditionals make stuff harder to understand imo.
I feel like there is something illogical about checking if you have a card, and then adding it. Most card games simply add a card, and then checks if it's valid to use.
Nice - curious, why not use BenchmarkDotNet
It hasn't. I took it in late December.
Right. I do put assignments in conditions myself sometimes, but I prefer not to. 
That is nice too. Personally I would not use any of these variants, I would simply structure the code so this will not be needed since I find it a waste of time ...
&gt; Not sure why youre being downvoted It looks like I was voted back up, but honestly I deserved the downvotes for being lazy and overlooking this part of OP's question: &gt; Because I'm using a series of else if statements I would prefer not to simply use a local variable to run the function beforehand and then compare the results.
Fair enough, seems like you’re doing well
For what you're trying to do, you could extend the List&lt;&gt; class. Something like below. Might be a bit over engineered most of the time, but still fun. class Program { static void Main(string[] args) { var myList = new List&lt;Example&gt;(); myList.AddIf(CreateNullObj(), a =&gt; a != null); myList.AddIf(CreateObj(), a =&gt; a != null); // list only has one entry. } public static Example CreateNullObj() { return null; } public static Example CreateObj() { return new Example(); } } public class Example { public int SomeProperty {get;set;} } public static class ListExtension { public static void AddIf&lt;T&gt;(this List&lt;T&gt; theList, T toAdd, Func&lt;T, bool&gt; add) { if (add(toAdd)) { theList.Add(toAdd); } } }
Most virtualization software not built on hyperv will crash or cause system falts when it's enabled... It's due to how windows functions when hyperv is enabled. Virtual box for example will bsod when hyperv is enabled.
It would seem really silly for a human to do the same thing twice - however for a computer program less so, especially if there is little cost in running the function twice and it makes the code more readable than anything "clever". If you are not careful you can spend more time worrying about getting best for computer than the computer will spend running the less than optimised code. Rather than worrying about the calling method twice - you may want to look at all those else ifs and see if there is a neater way of doing them
That emulator is no longer maintained, and is stuck with marshmallow unfortunately. It seems that Xamarin is pushing to use the Google emulator nowadays, even though that means disabling hyper-v.
Oh, don't let me start on this. Anyway an option is to run the android emulator in hyper -v guest and use either SSH tunnel or xamarin live player. Haven't tested these but I'll have to eventually. 
Wouldn’t it be easier to move the function invocation out of the if statement and assign the result to a variable instead?
Microsoft’s MSDN C# reference site is a good one. It has all of the language features documented. https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/index
I would do something `LINQ` related, cause i friggin' love it so much &lt;3
Use MEmu and you will thank me later
If they weren't reliable they'd be called UdpListener and UdpClient. 
Unity forces me to only use c#v6
So you attach to this from Visual Studio?
https://imgur.com/gallery/xgz9nkR
I laughed for a good 5 minutes. Thanks haha.
On my phone; bear with me. Is this what you're looking for? int addOne(int x) =&gt; x + 1; void Main(...) { if (addOne(5) is int myInt &amp;&amp; myInt == 6) { Console.Write("It works!"); } }
If you are sending over TCP (create a socket connection) you can create whatever messages you want in a byte array. If your message has simple types, you can serialize/deserialize an object to a byte array for sending. One thing to be aware of is MTU (maximum transmission unit), which was a typically 1500 bytes. TCP header is 60bytes, 4 bytes for from IP address, 4 bytes for to IP address. The rest you can use for your message/data.
You could use SkiaSharp in a Xamarin Forms app with a NavigationPage. https://developer.xamarin.com/guides/xamarin-forms/advanced/skiasharp/
The closest you can get would be: object obj = null; //dunno what type your method is returning so replace object with that type if ((obj = CheckIfIHaveTeleportCard(target)) != null) { ... ; ListOfCardsUsedThisTurn.add(obj); } But, I wouldn't recommend doing this -- you are sacrificing readability for something that doesn't buy you much. It would be better to use /u/MakesGamesForFun's suggestion.
These are just helper-classes, pretty much wrappers for tcpconfigured sockets. Most of their methods results in calls to the underlying socket anyway, so it's just a way to keep things simpler.
If you want to something performance related, have a look what was done for a The Disruptor project (java). They got phenomenal performance on commodity hardware having really good engineers really focusing how java byte code behaves on physical cpu. They came up with a lock free architecture, ring buffers, etc. Disruptor has been ported to .net but the performance is not the same as jvm and clr are different and optimisations are different. The cool research is the causes of differences and what needs to be true to get similar performance on .net and java between the two implementations
Why not use the single folder deployment available in .NET Core? You wouldn't need to install a .NET runtime or SDK on the machine you deploy it to. Anyway, CoreRT isn't in a very usable state (assuming you want the AOT compiled stuff).
Will vmware have issues?
Thanks for the link, I already watched that video tutorial. I was interested in a library with a higher-level API, something more like UIKit and CoreAnimation on iOS, with things like buttons, labels, containers, layouts, transition, etc. but using SkiaSharp for the rendering engine.
Enabling hyperv in windows 10 makes the os run on top of the hyperv subsystem as a virtual machine. This causes any application in said is that wants to use the virtualization instructions crash unless they hook into hyperv. VMWare will have issues with this as well.
Not that I'm aware of. But perhaps if people want it, we can do a monthly job posting/looking for work thread, not unlike the current "side projects" post.
What you are supposed to do is pay for an advertisement. It supports Reddit and demonstrates that you are serious about hiring. 
*rimshot*
Can you? Sure. Should you? Absolutelyfuckingnot. This would be a ridiculous stupid idea. Just target the framework you want minimal supported: it's that easy.
Thanks for your comment. The loop is more of a convince right now as I usually set a break point on, check that the first document is mine and then step through until I see it compile and then stop the execution. But I should really change it to make it more clear. But I think you're right about that it must be something with immutability. With this code I'm hoping to get the latest "copy" of the project and later compile it: var newDocument = document.WithSyntaxRoot(root); var compilation = newDocument.Project.GetCompilationAsync().Result; I also know that I have to save the project reference from "newDocument" if I want to keep building on it but right now it doesn't event work the first time which made me skip it for now. I just find it strange that that if I inspect the syntax tree on this row: var sementaticModel = compilation.GetSemanticModel(newDocument.GetSyntaxTreeAsync().Result); It contains all the changes and I can see it in clear text if I do a ToString(). But then I emit the compilation on the row below and I still get the old code without changes. It just feels like such a simple case which makes me a bit annoyed.
Seems to work fine. I used System.Net.Sockets stuff to implement an RTSP server a couple jobs ago.
Maybe. Depends on the classes and method calls used in the application. If the app uses anything new to 4.6.2, then it’ll fail to execute (the image loader would fail to load imports for the address of the required method calls). Even worse; if the method used rely on updated code for methods and classes that previously existed, you’ll probably get an exception (if the executable even loads). The is precisely the reason the manifest lists a minimum framework version.
Yeah I was thinking about the AOT compiled stuff. Did not know about single folder deployment. Thanks
I wrote this post to expand my knowledge on how .NET loads code and I thought it might be interesting to others as well. I agree with you that you should not do this (as stated in the conclusion in the article).
I find your comment interesting. Or rather the concept of making a comment stating the exact same thing that the article does. Did you read the article or did you just check the title? :) No offense intended, just interested.
Yeah... Less size and much much faster booting and running time 
No. But I have training in reverse engineering, which requires more than a bit of knowledge in the PE and .Net structures.
They execute sequentially; serialized by the await. However they also return Tasks (like Promise in JS) so you can capture the return prior the the await in a local; to get them to run concurrently; then await the variables.
`dotnet publish --self-contained -r win-x64` and `dotnet publish --self-contained -r linux-x64` is probably all you need.
Adding the following line to the code fixed it for me: rdpClient.AdvancedSettings8.EnableCredSspSupport
You don't need to worry about dealing with dropped or out-of-order packets - TCP deals with that for you and provides a reliable end-to-end stream. TCP provides a checksum on each packet so that corrupt packets can be detected and automatically resent (again, this is completely transparent and you don't need to worry about it). However, that does not guard against intentional tampering so if you want to ensure the authenticity of the data you will need to use TLS (wrap System.Net.Security.SslStream around your underlying TCP stream) or something similar.
I think the only wrinkle here is that they're using Unity, which probably doesn't have C# 7 support, yet.
No. While the exam has changed according to colleagues of mine who took it before that date, .NET Core and .NET Standard are definitely not in the exam. I took the exam on the 10th of January.
Nice. Good to know
Forgot to mention -- you don't *have* to use the proper types in an interface. In fact, I never do. You could have used `string` instead.
Where are you located dude?
Thanks a bunch! It was way simpler than I expected, thank you for the explanation. It makes a lot of sense now. As for your last point, I'm aware that an interface can be implemented by one or more classes (well, to be honest, I learned that just yesterday haha). I blame my poor English for the unclear description. Thanks again!
Thanks, it makes a lot of sense now!
I like the idea of them. But, so far, every time I have used them, I ended up using a custom class in the end.
This dude coming in with the assist. Nice looking out, my man 
Removed: Rule 3, Rule 6.
You might check out the websockets ASP.NET Core middleware instead if you want a persistent binary connection, but don't want to spend as much time mucking about with networking code (unless that is your thing).
I have submitted a pull request for this: https://github.com/dotnet/docs/pull/4169
&gt; the attribute *instance* is part of the class Correct. My wording was sloppy. 🙁
In reference to my particular case, the application is a Windows Forms app and only used within the network so it'll use AD authentication. 
Would you possibly be able to provide an example of using the App.Config? I see for instance, the database string in there but I'm not sure how I would add an UNC? 
Thank you everyone for the valuable input. I'm going to go with UNC as I originally suspected as being the better route! 
Awesome! Thank you for the help! 
No problem
It's a feature with a niche. In many places, they're a good prototype placeholder until you can be bothered to go make a real class, and the var keyword helps. You can also never use them and prefer a more formal class in all cases. So far I'm using them more as return values from private methods in prototyping. As my APIs gel I almost always end up making real types. Something about returning a tuple at a public API level feels off to me. But it's nice, when in the midst of proof-of-concept, to not have to stop the workflow to go deal with the steps of adding a new file and filling in the class boilerplate.
Ehhh... I think we’re just low traffic enough that crappy job postings would swamp everything else. Personally, if I’m hiring, I’ve got better options for spending my budget than paying to post something on Reddit. That’s no offense to Reddit or this community, but I want as many eyes as possible and specifically eyes that are looking for a job. 
Thanks. I went in circles for a while on Friday trying to figure out which entity was responsible for maintaining the .NET API reference, and then a whole lot of IRL crap hit me, and I never got back to it.
It sounds like the text block might be on top of the buttons
It's only a proof of concept thus far, but check out "Skixam". https://github.com/adamped/Skixam
There’s no visual overlap, and when the user clicks the button, the dialog window closes, it just never calls the handler that I’ve set up.
While it doesn't matter, from a functional perspective, which you use, there is one edge case where [Microsoft's suggested naming conventions](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/general-naming-conventions#avoiding-language-specific-names) (for whatever they're worth) prefer one over the other: &gt; ✓ DO use a generic CLR type name, rather than a language-specific name, in the rare cases when an identifier has no semantic meaning beyond its type. &gt; For example, a method converting to Int64 should be named ToInt64, not ToLong (because Int64 is a CLR name for the C#-specific alias long). The other case I can think of is if you're writing library code intended for use in multiple .NET languages. In that case, using the CLR types in your public declarations might make it easier to generate language-agnostic documentation/API references. You can find a list of the C# built-in type alias keywords and their corresponding CLR types [here](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/built-in-types-table).
It's updated for C# 7, I think that's the biggest change. So they will ask you about pattern matching. Not the whole exam obviously but a couple of questions. Aside from that the first couple of questions were structured very differently from the others. Quite difficult and more a test of programming skill than learning the C# specifics / libraries by heart, which is what the rest of the exam comprises of. All in all its very doable but the update for C# 7 surprised me. I didn't practice it, only knew the syntax from what I had read in blogs. The book you are using btw, is still the most important thing you need. Don't forget all those 'extra information online' things in the book though, use msdn as well.
Thanks for your help
I've only used value tuples in palette handling code as helper functions to split a color into individual color channels. It's not something I'd want to do in the caller code because of handling many different color formats.
Yes, it's to reduce allocation. It might seem crazy, but every little helps, especially in framework code 
My guess would be to save having an unnecessary object allocated. I can't see it being problem really unless you are in a super limited memory environment. If you had lots of collection it would be a waste of memory. So if you can use lazy loading to avoid it you may as well. 
This software BSOD on machines that have Hyper-V installed btw
Disable Hyper-V, problem solved
did you not read my question? I cannot disable Hyper-V... sigh
Fair enough. I guess it's not like most code uses SyncRoot anyway. It feels like kind of a kludge to me.
24 bytes I think. Must depend on the app but I bet there are many collection instances in something like a large WPF app.
The size itself should be negligible, 8 or 16 bytes (32/64bit) for the object header and method table pointer. But it is additional work for the GC to track and clean up. `SyncRoot` is effectively a legacy feature. It wasn't included in the generic `ICollection&lt;T&gt;` interface and most collections implement it explicitly, so you'd commonly have to cast to `ICollection` to even use it. I bet most devs don't even know it exists let alone what it does.
I think if you wrote it yourself it would be considered premature optimisation. But as this is in the main assemblies it needs to be as optimised as possible. 
Even more, SyncRoot is considered an anti-pattern now, since it weakens control over your locking domain.
I don't consider it a premature optimization, but rather a Standard Design Pattern. Developers would do much better if they got into the habit of writing code that is memory efficient from the start. If you know that 99.9% of the time you aren't going to use something, don't allocate it. Or better yet, see if you can live without it entirely. The real world cost of following this pattern is trivial compared to the cost of trying to detect and fix performance problems caused by inefficient memory usage.
As in SyncRoot is accessible to anyone who can access that collection, similar to locking on the Type itself?
Yep. It means they can unlock it while you're locking it, causing you to corrupt your internal state; they can lock it while you're trying to lock it to serve some blocking request to that same consumer, causing a deadlock.
I was being facetious which was totally missed, and as previously mentioned I did misread your question, and as also mentioned I've left my reply in case it helps someone else
Right, was just confirming that was what you meant.
No worries man, on a side note that emulator looks pretty sweet
I completely agree with you. Just because you way more memory than you need there's no need to waste it. But for the majority of cases it wouldn't be noticeable.
Thank you so much, this is only my second week in the course so I needed those hints to get me there! Here is a link to the new code which seems to work great! https://gist.github.com/kindawg98/170c7665089704e433c13c40e8c4bc62
I think you left a default value attached to your form: &lt;div class="form-group"&gt; &lt;h3&gt;Where are you from?&lt;/h3&gt; &lt;label for="country"&gt;Country&lt;/label&gt; &lt;input type="text" name="country" class="form-control" value="Czech Republic"/&gt; &lt;/div&gt;
Just food for thought. What happens if you have two numbers which are equal to each other? ;) 
This is my second week in the course... On line 40 I believe I put in an error just in case that happens. Any recommendations? 
Just return one or the second Also are you sure your teacher specified int's as the only input? Ie if I enter 3, then 3.14, an exception (or the suggested 3 below) will be returned Check for a `float` or `double` requirement in your assignment eg if (one == two) { return one; }
Hiring manager should have their senior programmers/developers write some questions IMO, not pull from a pool.
Probably done on purpose...just to test your debugging skills. You have just passed phase 1 of the interview! 
Your answer was really helpful! The book we have did not go to in depth... and our professor is a tad absent/all over the place (that was his whole description of the project in the original post...). Anyways, I believe ask and give an answer 10 times rather than the same answer 10 times. 
I changed it to use float... When I change the code and add the if (one == two) { return one; } it gives me error CS0161... not sure what I am doing wrong yet.
I second that idea. Senior devs may not want to be bothered by it but they should definitely look at what is being asked. This allows them to choose better questions that are more suited to the work you will be doing. 
This will be very helpful!
It really depends on the individual interviewer. I work predominately in C# and all four of my interviewers asked at least one algorithm question. There were also architecture and deep knowledge questions as well. As an interviewer now, I personally like to ask fewer algorithm questions and focus more on problem solving and ability to learn on the fly. That being said, plenty of my fellow interviewers ask algorithm questions in troves. The real key is to talk through the problem from start to finish. The interviewer wants to hear your thought process. Don't be afraid to ask questions. Best of luck in your future interviews!
The best questions I’ve been asked are about attitude and experience. Coding puzzles are for children.
When you do ask algorithm questions which type of questions do you like to ask? Thx for your reply!
When I'm conducting technical interviews I give the candidate a page of code (loaded with code smells) and ask them to refactor it. Good programmers love to point out whats wrong with code!
My first question when conducting interviews is always: "On a scale of 1-to-10 how would you rank your C# skills?" Candidates tend to be pretty honest as they know my next questions will be verifying their claims.
Dotnet core and it is free but doesn't fully cover everything from dotnet yet but it is getting there. Check it out. 
Hangfire is you friend. 
If you're Linux I'd probably just write a simple console app that is invoked by chron
I have in the past asked algorithm type of questions. I normally don't. When I am trying to judge a someone's skill level I may ask one or 2 questions just to find out if you know about the subject. (e.g. name and rank a few sorting methods) Every so often we get a intern or someone who is still in school and that I'd normally when I would break out more of those type of questions. They just had the class and they just didn't have the c# yet. Honesty, now that I think about it. The the only time I was a dick about it was a guy who's resume was covered in buzzwords and how he saved so much time in something by switching sorting algorithms. It was all he could tall about in the interview. We had him handwriting quicksort on the whiteboard. (badly) And for me, partial credit matters a lot. So if you don't know something. Talk out loud what you do know about it. And if it's something that you are missing say how you would find out more information about it.
The code on top lazily creates the object only once it's accessed. It's actually slower than the code on the bottom, and could even result in creating multiple objects in rare circumstances (but any beyond the first one would be thrown away). The key difference is that the code on top only creates it once somebody actually needs it. 99% of the time that property won't be used, so just creating the object immediately in the constructor is a waste. Heap allocations (that is, creating new instances of a class rather than struct) are expensive, you want to minimize them when possible. So in this case the allocation only occurs once it's needed, which it very rarely is.
Yup all still there!
Why don't you want Mono? It's fine.
Personally, I don't like the classics you would find in "cracking the coding interview." The last classic I remember asking was reversing the words in a string. Otherwise I like to get creative with my questions.
Unless the compiler is doing something fancy underneath to lazily evaluate the argument (which is very unlikely due to performance implications), it can create multiple instances because the check above isn't thread safe and it passes in a newly allocated object as a parameter. Meaning that a new object is created and then passed in to CompareExchange (but only in the rare event of a race condition in the above check). That object is then discarded because the field isn't null and so CompareExchange doesn't assign it the new value, but the object was still created. It's not a big deal here because creating and throwing away an object in rare events isn't a big deal, but if it was something that had actual side effects in its constructor, then it would be.
You never want to compare floats for equality. This gets more complicated and may come up later in your course, but floats are... imprecise. Along with issues like NaN and infinities, it's possible for a &gt; b, a &lt; b, and a == b to all be false. Because of this, it's possible for all of your if checks to fail, at which point you haven't returned a value from your function so the compiler gives you an error. I would have left the last check as just an else rather than an else if.
Sounds like .net core can do it. Most linux services are console apps so you can build it as that. Then make systemd or init run it. If you want to make a combo windows service/console app you can do that too there are examples on the internet.
Every company is different, but I think algorithm questions are very common. Certainly at any of the big software companies they are pretty much guaranteed. Personally I rather detest whiteboard coding to solve algorithm questions. Some of the best developers I know do terrible at them, mainly the ones who are self taught veterans; kids fresh out of college do better because that's pretty much what they've studied for 3 or 4 years doing a comp sci degree. I.conduct dozens of interviews per year and still ask candidates to code something up on the whiteboard because the alternatives are not great. Also you can still learn a lot about their approach to solving problems as they walk through their thought process...and I care little about syntactic correctness for the most part. But I try to ask more open ended problem solving questions that have lots of different solutions rather than a standard "find the optimal solution to discover the point where two linked lists intersect" kind of thing. But you will definitely encounter those kinds of questions a lot at many companies.
Sounds more like a console app than a service tbh. Unless you want to manage frequency within the service via service calls, then yeah it will need to be a service. Linux currently supports .Net Core 2, and you could create a console app using that. Creating a service, listening on a port for commands may be a bit more complex as the WCF libraries are not yet available for Core. However, you could run a ASP.net core Web API application which could service requests, but it wouldn't be able to run code periodically, as it would need to be instantiated by a web request. You could also use Mono, which is a community driven representation of the .Net framework, which offers a lot of the current capabilities of .Net 4. Personally, I'd go for a .net core application, which is triggered by a CRON job, and uploads to a shared space once the scraping is complete. Here are a few links I found which could help; [Microsoft .net core](https://docs.microsoft.com/en-us/dotnet/core/get-started) [REST client .net Core](https://docs.microsoft.com/en-us/dotnet/csharp/tutorials/console-webapiclient) [HttpClient](https://www.codeproject.com/Articles/1204494/Consuming-ASP-NET-Core-Web-API-using-HttpClient) [Azure storage](https://docs.microsoft.com/en-gb/azure/visual-studio/vs-storage-aspnet5-getting-started-blobs) [CRON](https://www.raspberrypi.org/documentation/linux/usage/cron.md) 
I sometimes ask about big o just while talking about data structures in general. It's useful to understand the broad characteristics of data structures. I tie it into atomicity, thread safety, etc. All those topics bite developers if they don't know how they work. I ask a lot of questions, so if you didn't know about big o it wouldn't necessarily mean you were unhirable. Oh, something I wish people understood in interviews: I've got maybe an hour to interview you, so I can't spend that hour teaching you all the bits you don't know. If you didn't know Big O I might try and coerce some recollection, but quite often I'll just move on because there's a lot to cover. As for white boards. Personally I hate them. I can't write code on a white board, there's no copy paste and I don't necessarily write code in a linear fashion. You also can't unit test a white board. It's quite an old fashioned style of interview really which possibly indicates the interviewer hasn't stayed current and that can be a problem. As always though. Shouting and whining about it isn't going to help. You're better off gritting your teeth and fighting through. The interviewer might not even be part of the team, or just not good at interviewing. It's not like anyone is ever taught how to interview really. I've interviewed a lot of people and I have a pretty broad set of things I ask which at the same time reflects the things I see people get wrong, and the things I want people to do right. A general tip is, if you go to an interview, make a note as soon as you leave of anything you couldn't answer and look it up. It doesn't matter if it's relevant to you, it will take you five minutes and might tip you over the edge at the next interview.
Removed: Rule 4. Please include the platform you're using, and ideally, make an attempt. Best I can offer based on the vagueness is that since Page 2 has the results, it must have been fed the query. Pass that query back to Page 1 and implement its initialization/load methods to bind against the properties in the query (if it exists) or initialize to blank/zero values if it's the first time loading (no query).
To reduce allocation since ICollection is essentially deprecated and use of syncroot as well.
What about lazy loading navigation properties?
platform: windows server 2012. Language:C# I created two pages(Page1.aspx and page2.aspx). On Page1, user can select any value on each controller then click "Search" button. the search button redirects to Page2 for the search results. On Page 2, There is a refine search button that can go back Page 1 with the previous selected and entered data. But, The refine is not working. I used page go back for the refine search. After branding site, the page go back initialize the previous selected values on page1. 
`SyncRoot`isn't used 99% of the time so why allocate it? The remaining 1% of the time it shouldn't be used.
I agree that overriding the `System` namespace in .NET is a silly example that would likely never be done in a real-world application. The Xamarin.Forms template uses `global::` to ensure there’s no conflicts from any community generated libraries: `global::Xamarin.Forms.Forms.Init(); `
I get that /u/vijayankit but you should really really change the example that you use.... Use one of the standard 3rd party libraries that we use like linq etc etc 
As someone else mentioned .net (core ) and Hangfire for scheduling/managing your jobs. Less coding and rock solid.
I knew I should have clarified in my original post, but was lazy on mobile. It's subtle and something that's super easy to overlook since it's not what you would expect from looking at the intention of the code. I'd add a comment personally saying the issue and that it'd fine in this case, because if someone went later and changed that to something other than an object, it could cause issues.
Nah, you were clear. I just straight up wasn't thinking. I even pointed out that two threads could fall through to the CompareExchange block. I just somehow forgot that arguments have to be evaluated. Obviously "new Object()" happens regardless of whether the exchange occurs, since that's one half of what's being compared.
I would say the main argument against calling the method directly from the constructor is the danger of exceptions. If new Foo(params) doesn't cause the object to create for any reason, then it will return a null object, and the MyMethod() call will crash because it will be null.MyMethod() (which is bad). If you do it as two distinct calls (and also check the object has been created) it narrows down the potential for null object issues.
&gt; new Foo(params) doesn't cause the object to create for any reason, then it will return a null object &gt; ... &gt; (and also check the object has been created) I don't think that's even possible. It could throw an exception (thus skip the method call entirely), but otherwise calling a constructor will never return a `null` reference.
The point I am making /u/vijayankit is that you are teaching bad practices. If a newer / younger developer doesn't understand the implications of overriding a System namespace then it will cause more and more headaches. I appreciate your tutorials and blog posts, but have some humility and take the criticism, and refactor the blog post to override a 3rd party library 
I don't know if there's specific guidance on this. I would say it's not "wrong", but it can be obtuse depending on usage. If this ought to exist as a static method, then you could refactor it as such. Otherwise you could also be looking at your own duplication by creating `CallingMyMethod(params)` which just wraps the underlying object instance method. What might really get you going is skipping the assignment of result altogether: new Foo(params).MyMethod(); That's weird too. Not necessarily wrong depending on what `Foo` is doing. Also considering your preference of using a local variable `var myObj = new Foo(params);` This scenario creates a `myObj` variable which, depending on its context, could be "polluting" the scope of the method. Perhaps you don't want a `myObj` floating around that doesn't need to be managed/interacted with, or perhaps should absolutely _not_ be accessed again (for example, perhaps calling `MyMethod()` twice is a _bad thing_).
/u/dylz_dad I also like to have my superiority verified by random 3rd parties, but I think that it is a scenario where it depends on the context of the application / system that is being developed..... But then people hate 1 line if(statements) return; 
I don't believe that either is different or better, especially if your Foo object goes out of scope and is not used any where else (which it sounds like is the case). Personally I like your CallingMyMethod method better as it's is better encapsulated, but even better would be to have all your dependencies either injected or at the very least listed at the top of the class as variables/private fields. So from a SOLID principals stand point, you're both wrong...
You should really be using a ConcurrentDictionary data structure here, keyed by the computer name. This let's you insert from multiple threads, and you have O(1) access to check if a computer exists in your collection.
woke
&gt; //var result = new Foo(params).MyMethod(); Smells like trouble Why are you even creating instances when you only make one call on the object. Maybe you should consider a static method
Yes, this. Lists aren't thread safe, sooner or later you will run into errors when trying to access it the same time. And ConcurrentDictionary is really easy to use and will handle everything that you need. In case you don't want to use the Dictionary for some reason, here are the others: https://msdn.microsoft.com/en-us/library/system.collections.concurrent(v=vs.110).aspx
You can just embed the file with a link
This is so weird. Why not just have an extension method with `params KeyValuePair&lt;TKey, TValue&gt;[]`?
I do it all the time with the builder pattern. But, most of my use is in unit tests to make data easier so I don’t care about the debugging issues. 
Most of the time I think I would need an object only for one call, I end up needing it for at least one more some time later...
first off, use tapped events not click ones, click events are kinda kept for legacy support. Prism imho is not a nessesity, just import your own observable items, xamarin has a nice observable item and observablelist. if the textbox is covering the button, use the canvas.z index to put it on top. 
Is it the Exam Ref by Wouter de Kort that you are using? Hoping to take this exam in the next few months...
[You can](https://docs.microsoft.com/en-us/dotnet/visual-basic/programming-guide/language-features/collection-initializers/how-to-create-an-add-extension-method-used-by-a-collection-initializer), although I don't like that either for collection of collections.
That is my thought as well. Feels like we are just constructing an object for fun.
&gt; Regarding stepping during debugging, when you break on that line, you can right-click and IIRC choose "debugging -&gt; Step Into Specific" and choose the method. That will let you skip stepping through the constructor. Now I just need a way to not muscle memory step into it...
Depends on the method I guess, but never call a virtual method in a constructor, because the subclass that may have overridden the method has not been initialized yet. 
I'd say you should look into using Concurrent Collections. Your design is flawed as you would need to somehow split the list of computers before passing to the UpdateServiceDataList, otherwise each task would be pinged all computers. Using multiple threads (not tasks) and several ConcurrentBags would be my choice. Fill a bag with all computers. Several threads each take a computer out of this bag, ping it, then add the computer to a 2nd bag. When the 1st bag is empty, you know they've all been pinged. You should check that your threads have all agreed it is empty then make a new list of all online computers and pass it to the ServiceChecking threads. You can now swap the 1st and 2nd bags around and start the pinging again. Handling the services would be done similarly with two more bags, except you don't swap bags if there is a new List of online computers. I would also put some time stamps in here. There is probably no point pinging a computer every minute. Perhaps some logic that increases the time between pings depending on the previous ping. A computer that has been offline for 10 pings, each time having to timeout, could have its period increased to 5 or 10 mins between pings. Similarly, if a computer successfully reports services but there is nothing new, don't check it again for 5 mins. If it fails, mark it for pinging etc..
Where is ‘here’? :-). It largely depends on the country and industry. I work in South Arica and quality of the skills is shockingly bad. In my company we ask candidates a simple snippet of code to swap the content of two variables. It is not even funny how many times we had someone failing this after having so many years of J2EE or similar on their CVs. I thing it largely depends on what the position is expected to produce. If the person is to produce a low latency high throughput service and probably involving complex algorithms, in memory processing, etc you want to test the reasoning about not how to build something that will get the job done but also how much cpu will it take and how long it will run. And you want people who can think in terms of algorithmic performance and modelling but also estimations (e.g. how many tube drivers are employed in London). If you need someone to churn day in day out typical web app using a standard and established framework and application you probably do not to need to test them on Knuth’s the Art of computer programming :-) 
`var result = new Foo(params).MyMethod();` could this be something like `var result = Foo.GetMyMethod(params)` and returns a new instace with your params
But how would that apply to an extension method on a dictionary using the `params` keyword? Also, how would this apply to adding new entries to an _existing_ dictionary?
I'd imagine it's fine. The blogpost isn't meant to provide ready-to-go code to stick into your application, but just to demonstrate the feature, and everybody of all skill levels is familiar with `System` and immediately know "hey this is going to conflict with another library" even if they don't know any libraries.
In my opinion his is much cleaner. It's less code overall and one less variable to muddy the waters. Creating a new method for those lines would muddy the waters *even further*. 
WCF is dead for new development. Mono is old stuff and .net core is the new shiny nice thing. I am rather excited by shininess of the 2.0 and 2.0 standard.
Are you new to networking or so? Some reading up on the basics of networking (TCP and UDP etc) would be beneficial to you
Microsoft still do that (or at least did 4 years ago), I had to write algorithms, implement trees and search algorithms etc. Did NOT do well. Not only does the lack of a computer access/google search set up you for an unrealistic scenario, I had to write on a whiteboard, a skill I had not learned yet, being left handed made it worse. So from college level programming to: WRITE EFFICIENT DFS ALGORITHMS ON A WHITEBOARD FROM MEMORY. I left that interview honestly worried I had made a mistake in my future career. Now, owning a small business I know better. They are looking for a certain kind of programmer. One I sure as hell was not. 
What's the benefit of the extension methods over just having the methods declared on `AddRangeTo`?
If only one method is being used it would be better as a static method like `object result = MyObject.MyMethod()`. Chaining calls together is convenient, sure, but it always affects readability negatively. This doesn't mean you shouldn't chain calls but rather you should balance readability with convenience. With that said, I never instantiate an object and then immediately make a call to one of its members on the same line. To me, object instantiation should be more pronounced and if you nest it with a bunch of member calls it becomes more "hidden" while reading. The only somewhat related exception to this rule is when I do something like this: var manager = new LogManager(new FileLogger(path)); But that is because *I* never need to actually use the file logger so I don't need to hold a reference to it. Even still, if I find myself creating more than 2 or 3 objects within the constructor of another object, I'll normally break it apart for readability. Code should, for the most part, should read almost like your natural spoken language. When it can't read like a spoken language, that's when you add inline comments. Your example, to me, and I would assume most programmers, will be the most readable. However, don't over-declare things like this: public Person GetMax() { string name = "Max"; int age = 2; int weight = 30; return new Person(name, age, weight); } In the above example, you might as well have just hard-code the values in the constructor directly like this: return new Person("Max", 2, 30); Really, though, it obviously boils down to what is more readable and unfortunately there aren't very many absolute rules and there are many subjective rules. I'd find your co-worker's code strange but if the calls were always "short and sweet" I probably wouldn't care to mention it.
Different assembly. The second one cannot be declared on the type anyway because `TKey` is not `TValue`. The extension methods were just an example though. The type should still be a readonly struct.
hey i recently just solved this!
Assuming everything in this class is a string constant and you can use reflection: public static class MyStaticFooBarClass { public const string BarAction = "B8EC848D-B4AF-4FBD-BF69-61F2931831F5"; public const string FooAction = "726D61F0-D902-4FC4-B86E-2C00B053573B"; // ... public static Dictionary&lt;string, string&gt; Values =&gt; ReflectionCache.Value; private static readonly Lazy&lt;Dictionary&lt;string, string&gt;&gt; ReflectionCache; static MyStaticFooBarClass() { ReflectionCache = new Lazy&lt;Dictionary&lt;string, string&gt;&gt;(Initialize); } private static Dictionary&lt;string, string&gt; Initialize() =&gt; typeof(MyStaticFooBarClass) .GetFields(BindingFlags.Static | BindingFlags.Public) .Where(f =&gt; f.IsLiteral &amp;&amp; !f.IsInitOnly &amp;&amp; f.FieldType == typeof(string)) .ToDictionary(info =&gt; info.Name, info =&gt; (string) info.GetRawConstantValue()); }
That was sarcasm on my part. I obviously know that constructing objects takes resources. 
`new whatever(params)` can't possibly return null. This either runs to completion and returns a non-null reference (on which `.method(params)` can ve called) or an exception is thrown and `.method...` is not reached.
Completely and utterly irrelevant on its own. One criteria to decide, for or against, should be the line length. Long lines are harder to read.
google (and similar dream-it job) interviewers tend to ask such things. but it tends to be a side question, as they are realizing this is a bad way to judge someone's skills. same with all these riddle-type questions. it's more and more so you are given these inputs and need to generate these outputs type of questions, and how can you improve your design etc etc. from personal experience on interviewing all level candidates (as from what i think i am a mid-level developer), you'd be surprised at how often people fail at pretty simple design whiteboard questions about object oriented design, type safety, stuff like that. the interview doesn't even get to big-O notation..not that we plan to ask such things.
You are right, it doesn't. I forgot the original point.
They're both right. That wikipedia page talks about the different possible implementations and how negative values are managed. In particular, for programming languages, it may even be a case of performance optimization and/or calling specific CPU instructions. Ultimately, you need to check your programming language documentation to know what modulo you're gonna get. Take a look at the side of that Wikipedia page too; all the different environments and languages and the different results you get.
% isn't a canonical modulus operator. It is a remainder operator. I read a good MSDN article about this a while ago. Try searching "modulo vs mod"
On google: (-10) modulo (3) = 2 (10) modulo (-3) = -2 (10) modulo (3) = 1 Wolfram Alpha: (-10) mod (3) = 2 (-10) mod (-3) = -1 (10) mod (3) = 1 https://imgflip.com/s/meme/Jackie-Chan-WTF.jpg I'm sure there's a perfectly reasonable explanation for this.
What does the result of (-10) % 3 give in .NET?
Here's a related article by Eric Lippert: https://blogs.msdn.microsoft.com/ericlippert/2011/12/05/whats-the-difference-remainder-vs-modulus/ &gt; Today, another episode of my ongoing series "What's the difference?" Today, what's the difference between a remainder and a modulus, and which, if either, does the % operator represent in C#?
Yes, that's the one. 
Technically, both answers are correct, they're just slightly different implementations of modulo. -10 % 3 = -1 when using truncated division -&gt; the result is the same sign as the dividend. -10 % 3 = 2 when using floored division -&gt; the result is the same sign as the divisor. You can further demonstrate this in Google by searching "10 modulo (-3)", which gets a negative result. 2 is a more correct answer, mathematically speaking. The Euclidean definition of Modulo says that the remainder should always be nonnegative. There's more details about this in the Wikipedia article you linked.
It's complicated. Mathematics doesn't define a simple modulus operator - you usually state concurrence relations modulus some value, eg, ` 2 === 5 mod 3`. However, there is an object that comes close to the set you're thinking of: *least residue system, modulo x*, for instance, the least residue system, modulo 4, would be `{0,1,2,3}`. So the least residue of `2 mod 4` would be 2; the least residue of `5 mod 4` would be 1, the least residue of `-1 mod 4` would be 3. See this wikipedia article for more information: https://en.wikipedia.org/wiki/Modular_arithmetic ... On to programming languages. Every language defines the modulus operator differently, and thankfully there's a whole wikipedia page for that: https://en.wikipedia.org/wiki/Modulo_operation And in C#'s case, the dividend's sign is used for the modulus. 
-10 (mod 3) is not the same thing as -10 % 3. This StackExchange answer explains it better than I probably could: https://math.stackexchange.com/a/1100797
https://stackoverflow.com/questions/11720656/modulo-operation-with-negative-numbers &gt; Modulo and remainder operators differ with respect to negative values. &gt;With a remainder operator, the sign of the result is the same as the sign of the dividend while with a modulo operator the sign of the result is the same as the divisor. So it looks like C# works like C in that the % is a remainder not a modulo. Interesting.
&gt; (10) mod (-3) = 2 Yup - That on Wolfram Alpha gives -2
&gt; (-10) % 3 -1
What about you actually read the wikipedia page you linked? It explains it.
Cool, how you finding it? 
lol sorry I'm taken &lt;3
Curious -- why use parallel bags instead of parallel `ConcurrentQueues`?
&gt; https://en.wikipedia.org/wiki/Modulo_operation#Notation Sorry for looking for an implementation of the mod function...
Well, it actually reads quite well. There is also [this video](https://mva.microsoft.com/en-us/training-courses/programming-in-c-jump-start-14254?l=Jg8SC1SfB_000115888) that might be easier to digest. Didn't watch it yet and I will have time only for some of the topics.
the modulo operation cannot return negative values. Google calculates it correctly. In C# the % is the "remainder" operator
This is a great answer 
&gt; And, last I checked &gt; &gt; -1 != 2 Actually, `-1 ≡ 2 (mod 3)`: -1 - 2 = -3 -3 is an integer multiple of 3: 3 * -1 = -3 therefore -1 ≡ 2 (mod 3) https://en.wikipedia.org/wiki/Modular_arithmetic 
Really wish C# did modulo instead of remainder, in the last 10-15 years I've yet to need the remainder instead of the modulo. Life's hard!
&gt; love to point This is awesome, I plan to do the same thing. But guess what. I never had the time to compose dummy non-NDA code. I have all the code smells in my head but putting them to presentable form is a not-enough-time challenge. And I assume I am not the only one, for that reason I want to provide such materials to people online. It will be another section that will be published soon, I call it internally "crap-code gallery".
Could you give me some examples, please?
You mean: return something;
Mate, senior developers are busy building complex things, waiting for new members to be added to the team so they wouldn't be that overloaded :). Obviously developers are able to create thousands of questions, but in reality, which questions are the best to identify the right candidate? You are usually limited by time. I am doing technical interviews myself and I am always trying to improve the experience for the candidate being interviewed - as such, I am always looking for inspiration.
Just nit-pick, I am super ashamed of that form, it's that ugly, anti-UX, killing conversions. But it's just PoC, I am improving things on a day to day basis and the fact that people are willing to comment such bad code is motivational, so thank you!
Btw, you can get to the questions by using the menu or direct link http://www.bettercoder.io/JobInterviewQuestions
Read the FAQ over at /r/cscareerquestions , then make a post over there if you don't feel like your questions are answered in their wiki or FAQ. Mind you, they have a LOT of questions asked from people without a degree in computer science
Awesome, didn't know that sub existed.
You need to use .config files, not put them in some class
The remainder is the most intuitive to me, not sure what I would use the other method for, but im sure it has some use.
I meant im not sure what I would use the modulus method where -10 mod 3 = 2 for. The "remainder" modulus that C# uses I am intimately familiar with.
Services in linux are just regular executables so you just need to make a regular console application :) If your linux distro uses SystemD, you just need to write a service file and a timer file (just a plain text file that gets loaded by systemd and tells it how and when to run your app). If not, you'll either need to configure crontab or init.d (I don't have much experience with those, sorry). As for mono, yes you will need it because csharp is compiled to bytecode and you need a virtual machine that will convert that code to something the CPU understands. You could also use .net core and in that case, you wont need mono. Here is a simple service file: [Unit] Description=Web scrapper 9000 [Service] ExecStart=/usr/bin/mono /home/path/to/your/app.exe And here is the corresponding timer file: [Unit] Description=Web Scrapper 9000 daily scheduler [Timer] OnCalendar=daily [Install] WantedBy=timers.target Hope it helps :) P.S. Using C#, you can compile your code on windows and run on linux :) No need to compile on Linux unless you want to of course :)
How so? Mostly one deals with positive numbers anyway and there it makes no difference. When negative numbers are involved (I've never had that case), I'd imagine you are doing actual remainder calculations. When I use the operator, it's almost always an offset calculation modulo some size and in most languages there are no negative indices. I know Python, for example, has them but then again, if I was to calculate some index from a negative value modulo the array size, I sure want it to stay negative (to keep the counting direction the same).
It's wrong IMO. There is no need to instantiate an object and throw it away immediately . Just cut your runtime overhead and use a static method.
I'm curious if someone could give an example of a use case where you would want the canonical modulus operator as defined by Wolfram, rather than the C# remainder? As others have pointed out, there's plenty of use cases where C# remainder is desired. I.e. what would be a practical real world case where you'd want (-10) mod 3 = 2? When I encounter these kinds of nuances, there's usually not a best way, but instead an appropriate use case for each, and understanding where each is applicable is a great place to refine your skills.
You're welcome! I think this project is great and you're clearly on the right track. PoCs are just a fact of life. :)
For example say you want to have a clock with values (for simplicity) 0, 1, 2, ..., 11. You want to implement moving the hands forward by *n* hours (or backwards by using a negative value). You can implement that with a mod easily, the result is just (before + n) mod 12 The mod operation is useful when dealing with anything cyclical of which you know the length. I have actually not needed the remainder operation yet, can you show me something where it is more *useful* than mod? I am genuinely interested.
That depends on the language. In C# it is the result of the remainder function, see OP's comment. In other languages it could be something else. This is not something that is influenced by the .NET libraries.
Can you please show me what you would use the negative values of the remainder for? I always found mod more useful. I am genuinely interested.
&gt; This is not something that is influenced by the .NET libraries. Just curious, is there any .NET language where % is not defined as the remainder?
The only example which I can think of is IronPython, that is if % works the same as in Python (I've never tried it).
^ also useful for keeping rotational values in an interval to not run into floating point precision issues
Should be able to set the foreground property ResultBox.Foreground = new SolidColorBrush(Colors.Green); ResultBox.Text = "Success"; 
The only reasonable argument for not inlining this is related to debugging. It gives you and easy way to have a look at myObj if you need to, possibly before having called your method. From a performance perspective, it doesn't meaningfully matter. From a coding style perspective, it's subjective preference.
This is just an example app to get my feet wet. 
For readability and maintainability, it helps to encapsulate the instantiation logic in a static method when doing stuff like this. 
What type of variable is studentType? Is it a char or an int or something else?
The data types are different: '1' is a char type 1 is an int type "1" is a string type The value for '1' is the ASCII value and is not equal to 1, the ascii value for '1' is 0x31 in hexadecimal, or 49 in base 10 math 
based off the studentType, the user has to enter 1-4, so the 1-4 could be counting as a char somewhere. That would make sense and is the best explanation i've heard so far! 
anyway, I don' t think we have enough code to see what you had in both cases. We're missing the code to read and define the studentType variable, and it's possible that what you had and replaced before is different somehow than you remember. If you can post two complete exact examples of works versus not works... someone can answer 
I think the weird thing is that inside the first switch you are trying to change studentType from an int to a char. I wouldn't even think the studentType='1'; statement would compile. Maybe create a different variable to store the char? Or help me understand how static typing gets thrown out the window here. 
Could char maybe be implicitly converted to int? Then you reassign `studentType` to the specific char which you use in the second switch. To fix this, you should just remove those unnecessary assignments `studentType = …` from within the first switch and change the second switch case back to the "real" numbers
lol, thats why I'm confused here. I'm pretty new to C#, but something about it doesn't seem right why it works in 1 and not the other. Regardless, as it is written above the code works exactly how its supposed to when I run it. 
I'm hesitant to change things if its working correctly for what the assignment is requiring. I posted the full code in the OP which might help explain something I'm not seeing. 
See [this](https://pastebin.com/mVVsEWjF "pastebin.com/mVVsEWjF) //7 switch (studentType) { case 1: studentType = '1'; // omitted could be written as //7 switch (studentType) { case 1: char charType = '1'; int intType = (int) charType; studentType = intType; // omitted and to make it even more clear //7 switch (studentType) { case 1: studentType = 49; // omitted Therefore, your `studentType` assignments are just causing bugs due to implicit conversion (char to int). (Which you certainly don't want) If you want to, you can leave it like that but you should atleast understand what is actually happening here.
As someone pretty new to C#, I don't really understand what your saying, I'm sorry. I feel even more confused now. I have no idea what 49 is referring to. In both your examples case still does not have single quotes. 
Not sure if you checked back here after you didn't get an answer, but just in case, here's a typical example: Lets say you have an array [0,1,2,3,4,5]. Now, you need to move forward or backwards in the array based on some condition. So, lets say you start on 2, and you need to move forward 10 steps. 2, 3, 4, 5, 0, 1...5, 0. Generically, this is '(starting index + number of steps) % length of array'. But, what if we want to move backwards? We can't have a negative index, so we always want to have an index somewhere between 0 and length-1. If we use normal 'remainder' math with the above formula, we get (2 - 10) % 6 == -8 % 6 == -2. That's a no-no, and doesn't really make sense in the case of a circular object of whatever kind. So in that case, it would definitely be more handy to have the canonical modulus operator. You can get around it by just adding 'length' back to the answer you get from the remainder modulus operator, though. So in the 'start at index 2, traverse backwards 10 steps' example, (2-10)%6 == -2 + 6 = 4, which would be the correct index to stop at.
There's no need for our particular use case. Normally I would agree and I understand why you'd look at this question and think "shouldn't those GUIDs be in config somewhere?", but it's not needed. Those values have no need to be configurable.
While I do love me some dirty reflection every now and then, it's not really an option. Still a nice solution though, thank-you!
What would have solved my problem perfectly would be the possibility to implement a string indexer on a static class, but unfortunately this is impossible because the indexer method requires access to `this`. What I decided to do was simply store the constant *key* in the constants class, and put the auto-initialised dictionary in the class that needs to do the checking. This is for an extra layer of protection for controlling access to MVC actions where the request source is restricted to local (in our case a PDF generation tool). The dictionary is held in an action filter which checks the `IsLocal` property of the request, and also checks that the request has been made with the correct query string (one of those GUIDs) that matches the action we're trying to complete, eg. EmbedImage. Probably slightly over-engineered, but it didn't sit right with me just checking the request origin.
I agree to a point, but a lot of "its not ready to go code" is used by Junior / Amateur developers as "ready to go" I agree with most developers should know, but not all do, and those that don't are the ones that I am talking about. As /u/throwaway_lunchtime mentions below maybe use 2 3rd party libraries that both use Utilities or whatever, just keep away from the System namespace But as is always the case with online boards it is an opinion 
[msdn documentation should help](http://lmgtfy.com/?q=package+program+into+msi)
I'll leave the in-depth stuff to you, but You might want to look into ClickOnce https://docs.microsoft.com/en-us/visualstudio/deployment/clickonce-security-and-deployment#what-is-a-clickonce-application https://docs.microsoft.com/en-us/visualstudio/deployment/how-to-publish-a-clickonce-application-using-the-publish-wizard Alternatively there are installer projects https://marketplace.visualstudio.com/items?itemName=VisualStudioProductTeam.MicrosoftVisualStudio2017InstallerProjects Which can run the install through a wizard-type series of questions. The downside is that you'll have to handle the update check and update process on your own. 
You could use a [Token Bucket](https://en.m.wikipedia.org/wiki/Token_bucket).
Non-Mobile link: https://en.wikipedia.org/wiki/Token_bucket *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^141158
ClickOnce is a great tool for easy and rapid update of an app, but keep in mind it has big limitations. If you want to use continuous integration / delivery (and I strongly suggest to), click once just can't work properly in that context. The reason is that ClickOnce will always rebuild your app when deploying. That mean that if you deploy your app on 3 different environment, you will rebuild your app 3 times. There is absolutely no guarantee that everything will be exactly the same between these 3 build. But if your app is quite small or you don't want to use CI (but you should, really), ClickOnce is very easy to setup.
I've done simpler but similar things on a gateway with iptables (on linux). Of course, in this case the filters will not be in your library.
If you build/deploy against the same changeset number for 3 environments then why wouldn't everything be exactly the same?
Compiler optimisations, conditional compilation
Removed: Rule 4.
Nice try Verizon and Comcast....
Nope I meant exactly what I wrote, otherwise I would of wrote return something;
&gt; Filtering the Output Windows messages Thanks!
Nice post, really useful. I would just add the VSColorOutput (http://mike-ward.net/vscoloroutput/) it is basically showing the build modules in green, errors in red which I find pretty useful when you want to catch the first error during the build. Also, makes warnings more visible too.
Removed: Rule 7.
That's a shame. I get it violates the rule but people were just starting to get into some good discussions I was going to find relevant. 
Hmm, the example you gave just felt like a Q would be more appropriate but after re-reading what you said I agree with your decision -- order wouldn't matter here. I am not too familiar with bags so I have some learnin to do myself ;). Thanks for your reply.
Removed: Rule 4. The question you've posted is too vague. What is the question you're asking? If you're looking for JSON usage tutorials/documentation, there are a plethora of resources available by searching. The problem you state: &gt; have all manually put JSON input into their program and I can't find anything on parsing an actual JSON file What does this mean? You want to read the JSON from a file on your harddrive rather than a hard-coded string literal? If so, then use the convenience methods like `System.IO.File.ReadAllText` to read the text as a string, then send it to the JSON parser. If you wish, you can repost the question, but please include more clear details about what you're trying to do, what you've tried, what tutorials you looked at specifically (include examples, not state "countless Youtube videos", that doesn't help us help you), and why they didn't help.
Anywhere where you need "circular" (modular) arithmetic. The very simplest example in (classical) cryptography is rot-X (caesar cipher). With (the once reddit-favorite) rot-13 as the most famous example. string alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"; int alphabetLength = alphabet.Length; string message = "IREL FRPERG ZRFFNTR"; int x = -13; string result = String.Empty; for (int i = 0; i &lt; message.Length; i++) { char c = message[i]; int index = alphabet.IndexOf(c); // Find shifted character unless message character isn't actually in alphabet - then we just pass it through result += index &gt;= 0 ? (alphabet[(index + x) % alphabetLength]) : c; } This allows decryption by simply using negative `x` (well, in the case of x = 13 and the classic 26 letter alphabet, it's an involution). But to use negative `x` you need modulo, not remainder. Although of course it's trivial to "fix" the modulo operation. As others have mentioned, plenty of modern cryptography algorithms hinge on modulo too (and XOR, which is itself bit addition modulo 2). Although you'd be hard pressed to find a cryptographic primitive that involves signed integers, modular addition with modular subtraction as inverse isn't entirely uncommon (although then it's *often* mod 2^32 to take advantage of integer overflow, meaning no actual modulo operation is required in most languages).
It is a poor practice, but sometimes we just have to let stuff go. \#region is a great way to hide code smell
This is mostly (no time based limits) built into WCF. For example I can specify that I can only receive a maximum number of current calls. Ex: &lt;serviceThrottling maxConcurrentCalls="2" /&gt; I can also throttle the maximum number of request per outbound connection to a specific address. The default is two, in our application we upped it to 20: &lt;system.net&gt; &lt;connectionManagement&gt; &lt;!-- Allow more outbound connections to the same URL --&gt; &lt;add address="*" maxconnection="20" /&gt; &lt;/connectionManagement&gt; &lt;/system.net&gt; You can do even more refined controls such as forcing services to operate in one thread or have it operate in multiple threads, but don't create new instances of the service upon subsequent calls. However, it sounds more like you have an unpaid license to an endpoint and you are only allowed a maximum number of calls to it. I don't know of any out of the box code that does this, but you can just put a lock around the code and then tell the thread to sleep for X seconds before the next try.
&gt; Thank you /jdotlo. &gt; &gt; I got the follow compiler message. &gt; &gt; Compiler Error Message: CS1061: 'System.Web.UI.WebControls.TextBox' does not contain a definition for 'Foreground' and no extension method 'Foreground' accepting a first argument of type 'System.Web.UI.WebControls.TextBox' could be found (are you missing a using directive or an assembly reference?) Thank you /jdotlo. I got the follow compiler message. Compiler Error Message: CS1061: 'System.Web.UI.WebControls.TextBox' does not contain a definition for 'Foreground' and no extension method 'Foreground' accepting a first argument of type 'System.Web.UI.WebControls.TextBox' could be found (are you missing a using directive or an assembly reference?)
You could do the "IT Crowd" chat-bot: User: help Bot: Have you tried turning it off and on again? 
Great post, this will make debug less of a chore!!
Copy/pasted from production code: if (DateTime.Now &gt; new DateTime(2018, 7, 1)) { System.Windows.MessageBox.Show("This release is no longer licensed."); Environment.Exit(-10); } http://i0.kym-cdn.com/entries/icons/facebook/000/022/266/brain.jpg
This is where I draw a line in my knowledge. I don't know what either of those are. guess I'll have to look stuff up. 
I did think of WCF, and even though they are including it in .net Standard, I really don’t want to take that path. But I will check it out more closely. 
I know it's a joke but that would require a separate build for each user since each license will expire at different times.
I once saw one in (written in VB.Net) that used datetime tostring and datetime parse together with a date saved as a string. The guy who made it got pretty upset about me de-compiling it and explaining to him that it didn't work in non-US cultures :P
Makes a lot of sense, thanks for the explanation!
Can't speak to how good/bad/outdated this is, but I found this: https://stackoverflow.com/questions/14306048/controling-volume-mixer
We use a simple custom solution. - In the registry, save the expiry date, encrypted. - To set the expiry date, users need to enter a valid authentification code (12 digits) from our website or our customer service, which includes the expiry date and other options. - Each time the software is started, the date is logged, encrypted, in the registry. - At startup, we validate the expiry date and the last date the software was started to prevent the user from changing the system date.
Removed: Rule 4. You already have a duplicate post here: https://www.reddit.com/r/csharp/comments/7sihaa/need_some_result_font_color_help/
Is there anything that is blue? If not, could I make the green items blue? I'm slightly colorblind so unless the greens and reds are vibrant and next to each other I might mistake the two
woop, if using System.Web.UI.WebControls.TextBox, then the property is called 'ForeColor'. See here for how to use it: https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.webcontrol.forecolor(v=vs.110).aspx
woop, if using System.Web.UI.WebControls.TextBox, then the property is called 'ForeColor'. See here for how to use it: https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.webcontrol.forecolor(v=vs.110).aspx
On the linked page, it looks like you can change the colours under 'Tools|Options|VSColorOutput' I haven't used it myself, but I hope this helps
What's preventing the deletion of the start date entry, and rolling back the date?
Yeah, I get the quandary that puts you in. Thanks. 
I guess the thing is most people are not going to go to those lengths. Depends on the type of software you are selling. If it is a game it would be cracked in 10 mins. 
Make the expiration DDMMYY for US release and MMDDYY otherwise and they will never figure it out
I've done something similar to what you're aiming for, and the API /u/FizixMan linked does the job. I found it a bit tricky to get working right though. If no one else has posted anything helpful by the time I get home tonight I'll look at posting a bit of code that will help to get started.
Software works only with a valid encrypted string that hides the expiry date. Deleting it will ask the key again. Trying to change it is not that easy. It is calculated from the windows installation guide and other values. That is more than enough for our customer type. Less than 1% knows what is the Windows registry. We don't sell games to poor kids, we sell statistical health tools to professionals.
This should offer a jumping off point for the CoreAudio API https://blog.sverrirs.com/2016/02/windows-coreaudio-api-in-c.html
Actually, according to [MSDN](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/operator-overloads), the operators that define op_Modulus in each language all compile down to a call to op_Modulus. That's % in C# and \ in VB. But any syntactic sugar that compiles to op_Modulus will have the same remainder-because-it's-marginally-more-efficient-than-math-purist-modulo implementation.
Perhaps something is blocking your shutdown routine or you are only shutting down a thread
Apart from just giving me a snappy reply, why? What benefit does this confer?
Your program can't run code after exiting, so what's happening is probably that you're running two programs at a time. Until the second instance has started the first can't close. I'd suggest looking at how other programs that need to close first has solved it, like programs that self update. You might also be able to call a CMD command that sleeps and then calls your program, then terminate instance 1 while the command is sleeping, but imo that's not a good solution as it feels way too "hacky".
In my wpf app, when it starts and checks for other instances, I delay complaining. If another instance is running I check again every second for a few seconds in case it's still closing. If it's still there after 7 then I notify the user. If there is no other instances I don't delay so the start isn't 7 seconds each time.
Thanks I will try using this 
Thankyou it looks like it will help
Use code first. Its better. var from u in context.User Join ul in context.UserLog on u.UserId equals ul.UserId group g by new { Name = u.Name, UserId = u.UserId} into g select new { Name = g.Key.Name, UserId = u.Key.UserId, Count = ul.Count() } ; That was off the top of my head so their might be a syntax issue or 2. Google linq group by sum if it doesnt work
If you use openxml to load your document in C# you can look over the word elements and filter on tables. Then you can access further information to parse the table and look for a certain word in certain columns. I can't give you docs for the moment but if you are interested by it. Ask I'll give you it later. But some Google research on what I pointed out could help you
&gt; Doesn't have anything to do with code smell - it's not even code. That's not really true. Often `#region` is used in response to the nagging feeling of "this class is a bit too big and lacks a bit of organization/cohesion." The "correct" solution is to break a class down into multiple sub-classes. Sometimes people will instead reach for `#region` to solve this. Therefore, it's an indication (definition of 'code smell') that a class probably could be broken down better. I used to think the same way as you until I inherited a project where `#region` was used extensively to "help organize" several 15 thousand line classes. And now I believe it to be Satan masquerading as a language feature.
I tried using FileInfo in order to access a certain file at a certain location. I can try with openxml, but how exactly do I filter on tables at least? I have been googling for the past 2 days, believe me, but nothing that I can understand completely.
Thanks!
You should try to use Environnement.FailFast for better and faster results :3
I would consider using JavaScript to aggregate saves. Your current solution is difficult to support due to the reliance on constant server client communication for potentially small amount of changes. You can also use JavaScript to do more complicated change detection before initiating to make your saves more thread efficient and for aggregate writes to db. Ie -&gt; pass array of queued ids and values for save after 3 seconds since last save
We use http://benalman.com/projects/jquery-throttle-debounce-plugin/ (doesn't actually need jquery) and save the entire form no more often than every 10 seconds.
thank you led the right path. this worked. ResultBox.ForeColor = System.Drawing.Color.Green;
I was thinking of doing that with another save on the leave event. I may go that route but was hoping to repair my existing code if possible rather than rewrite how the save happens.
Hmm.. I could combine that with the suggestion from /u/BezierPatch. Add changes to a "queue" array and periodically send those changes to the server and clear the queue. The weird thing is my current solution works 100% for me, I cannot duplicate what the user is experiencing. I think I might go watch over his shoulder to see what he does.
Don't procrastinate too much? ;-) I've never done this but let me look for you.
I kind of done it. I encountered some other issues, but I found some help somewhere else :D Thanks anyway
objDoc.Tables[4] ?
We use the Windows installation GUID to get a part of the user provided code. We provide the user with a valid key that will only work on his computer. The key itself holds a checksum of another part of the key and the date is included in the key. So the entered key must match the local GUID and have a valid checksum. Regarding encryption, in the registry key, we don't just save the key as it is: we apply an AES encryption when accessing the registry.
oh really? Awesome. You should update your post at the top and add something like: "edit: I found some help. Thanks anyway". If you do need anything though let me know.
The problem with this approach is that it can fail on the client side, so you need a way to retry the operation or like other suggested batch them up. It might even be an issue with too many async calls for all I know. For now i would suggest the user have the debug console open while they use the application as soon as they notice the issue walk over and inspect the console. I guarantee it will show something red with the exception. Assuming the user is using Chrome.
To get the size of a class it must have [StructLayout(LayoutKind.Sequential)] or [StructLayout(LayoutKind.Explicit)] Otherwise C# doesn't guarantee a particular size or alignment
Hang on, why would it spam saves anyway, if you only save on changed value + blur, tab tab tab shouldn't do anything.
It's not easy. You can ask the GC for total memory used before and after you create one. You can serialise it which will give an approximate size if you exclude the type information that's included. There are no guarantees.
Two things: - I would queue the "pending changes" and process them as a batch every X seconds. Going to the server every time a cell changes is unnecessary. Also, you may be doing this already, but make sure your "pending changes" are actually changes - you don't want to submit stuff to the server when someone just tabs through cells. - You said you've got logging, but can't find the error? Something is off then - you're either swallowing the exception or not catching it. Regardless, in addition to logging, you should be returning some sort of an error to the browser when a call fails. You said it doesn't currently return anything to the browser, so you could probably just rely on treating 200 responses as "success" and other responses as "error."
If you allocate a large enough number of objects and do a garbage collection before and after, that should give you a decent enough idea. Serialization for size estimation is completely pointless, that would completely depend on the serialization format and have no relation to the CLR object size. You'd be better off just manually adding together the sizes of each field in the object.
Serialisation to a memorystream using the standard serialiser will result in a pretty clean representation. It does include some additional type information but it's not the worst way of getting a vague idea. I'm not suggesting using XML or json or something like that :)
Unless those cells have large amount of data, i'd try communicate through an websocket connection using SignalR and see if that helps.
If by standard serializer you mean `BinaryFormatter`, that produces gigantic output. The string containing the assembly qualified type name alone is going to be larger than most CLR objects.
Would this work out? public class Config : IDictionary&lt;string, string&gt; { public static readonly string FooAction = "B8EC848D-B4AF-4FBD-BF69-61F2931831F5"; public static readonly string BarAction = "726D61F0-D902-4FC4-B86E-2C00B053573B"; public static Config Actions { get; } private static Dictionary&lt;string, string&gt; actions; private static Config instance = new Config(); static Config() { Actions = new Config(); actions = new Dictionary&lt;string, string&gt;() { { nameof(FooAction), FooAction }, { nameof(BarAction), BarAction } }; } private Config() { } // In VS, right-click IDictionary&lt;string, string&gt;, // select Quick Actions and Refactoring, // then select Implement interface through 'actions'. } 
I believe one of the creators of C#'s async/await actually did call it "viral".
I've used that before and Unsafe.SizeOf&lt;T&gt; but it will always equal IntPtr.Size. That is, 4 or 8 which is the size of the pointer.
Are you primarily developing console applications? Otherwise, the `async`-`await` "infection" only affects a single controller action/event handler/whatever, which shouldn't be that bad.
It's rude to mock.
This may be a really dumb question, but do you mean as in to joke about someone? I'm not an English speaker, so I may be missing the elephant in the room here! Anyways, if that was the case it was a good one haha
Yes, this is a pun in English and not a real response.
Why not just create a keybind (ie CTRL+S) or a save button that saves all changes to your database? Probably not the request of the user, but perhaps you are bending too far for their will...
Thanks for clarifying that!
I would say a unit test is not the best way for you to test this interaction. Unit tests are really just for testing small bits of code and what you are wanting to do here is really more of a smoke test/interface test. Beyond that, there are several different things you are testing here. &gt; _account.BuildLoginViewModelAsync(model); &gt; _interaction.IsValidReturnUrl(model.ReturnUrl) &gt; _actions.AuthenticateAsync(model, HttpContext) Really, the unit test should be on those methods instead. If you still want to test the endpoint, I would recommend looking at something like Selenium tests. It will allow you to build a test that actually navigates through your site (so no need for faking the httpcontext). That said, you mentioned this is your first full unit test project, so I'll give you this advice: You don't have to unit test everything. Focus on the business logic of your application and cover the important parts, rather than generate tests just to reach 100% coverage. 
Yes, that's what I meant by type information. There's no good solution , the GC approach is probably closest if you know what you're doing. Serialisation can work to give an approximate size. Theoretically you can iterate through the class members and recursively dip into reference types then add up everything, but this is fraught with difficultly. If you want to know more, take a look at [Advanced .net debugging](https://www.amazon.co.uk/Advanced-Debugging-Addison-Wesley-Microsoft-Technology/dp/0321578899) which is old but goes into a lot of the internals and describes ways of inspecting and dumping .net objects. [This](https://www.amazon.co.uk/Internals-Debugging-Techniques-Addison-Wesley-Technology/dp/0321934717) is the updated version that I don't have and may no longer exist. And [This](https://www.pluralsight.com/courses/dotnet-internals-adv-debug) is a pluralsight course on the same. Possible some context of what OP intends to do with the object sizes would help. Another option I just thought of is to use DotMemory with the DotMemory unit test extensions. This gives you the ability to build a unit test that measures memory usage, allocations, basically everything that DotMemory can show you in its profiler, but in a unit test. It's pretty simple to use (Was pretty simple to use, I haven't used it in 18 months). I don't remember if you need to own DotMemory to use it, it's a nuget package, so give it a go. 
ayo hold up one of our old WinForms apps has a dbconfig string thats pretty much global (base namespace, `public static string`), which is a string representation of a database.table.field of our database, to read a field that has the same dbconfig string wew
You have a methhod; what are you testing?
First of all, I'm not certain I follow what you mean when you're asking how to/if you should/ "mock" the HttpContext. read this https://en.wikipedia.org/wiki/Mock_object and then let's continue. &gt;"Mock objects have the same interface as the real objects they mimic, allowing a client object to remain unaware of whether it is using a real object or a mock object." So if you want to be able to test your class while simulating a HttpContext, you would mock it. Is this what you're asking how to do? 
In any case the research in Google was : C# reading word document openxml Then I found this : https://stackoverflow.com/questions/45466325/how-to-read-values-from-a-table-in-a-word-doc-using-c-sharp Feels like a good example I think.
Thanks. That's an interesting point. Mind you, I'm a _complete_ beginner when it comes to Unit Testing. I do have some Selenium knowledge, I did some Python + Selenium scripting in the past. I think I can adapt that to C# without too much hassle. This is something I should tell the Devs, however, I'm concerned that my lack of experience won't help me to present a strong case. Thanks a bunch!
Let me rephrase: I was tasked to write Unit Test for this project, which I'm not really familiar with (I haven't written a single line of code of it). The told me to start with the _AccoutController_ class, which has 4 methods that returns a view. That class has a constructor with a crap ton of parameters, which are used in the methods that are inside the class methods (if that makes any sense). So my problem is, that I need some way to mock those dependencies. In the particular case of the method I posted, is `HttpContext`. Does it make any sense? I'm fairly new to all of this, so please forgive me if all I just wrote sounds like gibberish. Feel free to ask me whatever you need to know as many times you want.
&gt; therefore, you should be mocking out whatever _actions is as well as whatever _interaction and _account are. That is _exactly_ what I don't know/understand how to do. I have mocked some of the objects needed on the class' constructor but is how far my knowledge goes. I'm currently doing the _Moq .NET Core Unit Tests_ course on Pluralsight, hope it helps me!
That was his original request but I don't think you can override shortcuts that the browser uses.
https://stackoverflow.com/questions/93695/best-cross-browser-method-to-capture-ctrls-with-jquery I'm pretty sure JIRA (my issue tracker for work) overrides browser ones IDK if this is good tho, perhaps it will help
The following article has a good approach that has worked for me in the past. [JohnnyReilly](https://gist.github.com/johnnyreilly/4959924) 
hopefully those things are implementations of interfaces. hopefully your controller has a constructor that takes in instances of those implementations and stores them as private read-only fields. this is the common way of doing dependency injection and the way asp.net core is set up to do it by default really. if that's the case, your test might look something like this (syntax may be incorrect, doing this from memory). the creation of the mocks and the service under test usually happens in some test setup method (constructor of the test class if using xUnit, for example) and are stored as fields in your test class. // create your mocks var accountMock = new Mock&lt;IAccountService&gt;(); var actionsMock = new Mock&lt;IActionService&gt;(); var interactionMock = new Mock&lt;IInteractionService&gt;(); // create the instance of your controller under test using your mocks var controller = new Controller(accountMock.Object, actionMock.Object, interactionMock.Object); // set your mocks up to expect and return proper values so your test does what it should do. // alternatively, if you don't care, set the method up to expect any instance of the parameter var loginModel = new LoginInputModel(); var authResult = new Users(); actionsMock.Setup(a =&gt; a.AuthenticateAsync(loginModel, It.IsAny&lt;HttpContext&gt;())).ReturnsAsync(authResult); // perform your test actionMock var result = await controller.Login(loginModel); // assert that your results are as expected and that things were called correctly Assert.NotNull(result); actionsMock.Verify(a =&gt; a.AuthenticateAsync(loginModel, It.IsAny&lt;HttpContext&gt;()), Times.Once()); 
We all gotta start somewhere. Honestly, my company paid for formal training and we started building the unit tests but it still took 6 months or so before we were comfortable with them. We brought the same trainer back a year later and he was like, "This is good. You are doing the tests, but you are still thinking too big. I bet you have found your tests to be brittle. A small change cascades failures throughout the tests, right?" He was right. A single change in the right spot could fail multiple tests, sometimes requiring the tests to be rewritten. Then he gave us similar advice to what I gave you. If your test hits multiple classes, or runs through multiple paths, you are probably building the test too broadly, and that will lead to test failure pains down the road. 
I feel terrible at the moment, I feel I'm failing big time. I've read that writing good Unit Tests is not easy but is not how the guys see it around the office (over here, writing Unit Tests is a _meh_ task, for juniors mostly). I do find comfort in your words! Thanks for that! I will keep learning, it is my intention to do it right! It may take me a lot of time, but I rather do it right and learn good practices, and do it quick to be over with it and pay for it in the future. Thanks!
Look into the owin test server. You can test an in memory version of your full API using an instance if HttpClient provided by the test framework. It's a game changer. 
Yes, it was a joke, which apparently r/csharp is not a fan of :D
Oh right, sorry. The latter. I'd be doing quality assurance.
Oh right, sorry. The latter. I'd be doing quality assurance.
You might be running into the browser's XHR count limitation. The number of current requests is limited, which can be exacerbated if, say, the user's connection is more latent.
&gt; so, your unit tests shouldn't be testing any of the controller's dependencies (that would be more in-line with integration testing). Depends on how you define "integration testing". I for one define that as "testing two or more things, at least one of which isn't under my control". And the database is always under my control. Integration testing is "UI + Services" or "Services + 3rd party services". Not "Services and the database it is tightly coupled to". That's just normal functional testing. *** But regardless of what you call it, testing a controller without it dependencies is a waste of time. Controllers are stupidly simple and every method should look damn near identical to every other method. 
Start learning to think like this: https://twitter.com/sempf/status/514473420277694465?lang=en
Don't even bother for a Login method. There is no way you can mock the HttpContext exactly the same way as it will be in production. That is way too dependent on factors that you don't have a clue about. This is a method that you're going to need to test by hand using a browser.
/u/xour you should definitely check this out. It's the link I was going to post as well. Since HttpContext doesn't implement an interface, it's tricky to mock in the traditional sense. But you CAN mock the handler it uses to get control over the types of responses you get from it, which serves essentially the same purpose.
I dislike doing both. It makes your code much more complex just for the sake that someone isn't using async when they should be. if you know you are doing io, don't block the thread. simple as that. it is the 21st century and almost no computers only have 1 core. use them and don't waste them. did you look at what happens when you return Task.CompletedTask or Task.FromResult?
Task.Run doesn't even do anything in this instance. you still block that thread. but I guess you don't block the UI thread.
I have to do my own QA and UAT at my job, and I usually go about it a couple of ways. The first thing I do is go talk to the users about how they plan to do use the code. Make a mental or an actual note of everything they do, including how they move their mouse around. You'd be surprised how differently people interpret "Click this button." For example, at my work we have a woman we call Linda the Clicker because she double or triple clicks anything. If it doesn't work in a New York Second, she starts rapid fire clicking on it until it starts working. Believe it or not, we've actually found bugs by acting like her. After I've talked to the end users and seen how they use the part of the program, I test that along with the opposite of what they did. The second thing I do is to talk out how the code work with someone who has no idea what the code is supposed to do. They'll usually come up with some kind of functionality that I'd never even thought of. Worse come to worst, just get real drunk and try to use the program. :)
This is what I use on my unit tests. Hope it helps, I use MOQ public class MockHelper { public string Url { get; set; } public HttpCookieCollection CookieCollection { get; set; } public Mock&lt;UrlHelper&gt; UrlHelper { get; set; } public Mock&lt;IIdentity&gt; Identity { get; set; } public Mock&lt;IPrincipal&gt; User { get; set; } public Mock&lt;HttpServerUtilityBase&gt; Server { get; set; } public Mock&lt;HttpSessionStateBase&gt; Session { get; set; } public Mock&lt;HttpResponseBase&gt; Response { get; set; } public Mock&lt;HttpRequestBase&gt; Request { get; set; } private Mock&lt;HttpContextBase&gt; Context { get; set; } public MockHelper() { CookieCollection = new HttpCookieCollection(); Context = new Mock&lt;HttpContextBase&gt;(); Request = new Mock&lt;HttpRequestBase&gt;(); Response = new Mock&lt;HttpResponseBase&gt;(); Session = new Mock&lt;HttpSessionStateBase&gt;(); Server = new Mock&lt;HttpServerUtilityBase&gt;(); User = new Mock&lt;IPrincipal&gt;(); Identity = new Mock&lt;IIdentity&gt;(); UrlHelper = new Mock&lt;UrlHelper&gt;(); Url = "http://localhost/"; } public Mock&lt;HttpContextBase&gt; MakeFakeContext() { Context.Setup(c =&gt; c.Request).Returns(Request.Object); Context.Setup(c =&gt; c.Response).Returns(Response.Object); Context.Setup(c =&gt; c.Session).Returns(Session.Object); Context.Setup(c =&gt; c.Server).Returns(Server.Object); Context.Setup(c =&gt; c.User).Returns(User.Object); Response.SetupGet(r =&gt; r.Cookies).Returns(CookieCollection); User.Setup(c =&gt; c.Identity).Returns(Identity.Object); Identity.Setup(i =&gt; i.IsAuthenticated).Returns(true); Identity.Setup(i =&gt; i.Name).Returns("CurrentUser"); UrlHelper.Setup(x =&gt; x.IsLocalUrl(It.IsAny&lt;string&gt;())).Returns(true); UrlHelper.Setup(x =&gt; x.RouteUrl(It.IsAny&lt;string&gt;(), It.IsAny&lt;object&gt;())).Returns(Url); return Context; } public T MakeFakeContext&lt;T&gt;(T controller, string url = "http://localhost/") where T : System.Web.Mvc.Controller { var context = MakeFakeContext(); controller.ControllerContext = new ControllerContext(context.Object, new RouteData(), controller); controller.Url = UrlHelper.Object; return controller; } } [TestMethod] [Description("user has permission to view acquisition")] public void user_has_permision_to_view() { // Arrange var helper = new MockHelper(); var context = helper.MakeFakeContext(); var controller = new Controllers.HomeController(); controller.ControllerContext = new ControllerContext(context.Object, new RouteData(), controller); // Act var result = controller.Index() as RedirectToRouteResult; // Assert Assert.AreEqual("", result.RouteValues["Category"]); Assert.AreEqual("", result.RouteValues["action"]); Assert.AreEqual("", result.RouteValues["controller"]); }
Act as if you're a user who doesn't understand the system, and don't use it correctly. See what breaks.
integration testing is pretty nebulous in nature as you are integrating multiple modules together and testing that they work appropriately with each other. about the only requirement is that it's a form of white-box testing (you have visibility into the code). i'm talking about integrating units of code. you're talking about integrating larger systems. also, there was no mention of a database, and we really have no clue whether those dependencies are first-party. testing "services and the database it is tightly coupled to" is not functional testing. functional testing is black-box (no knowledge of the code itself) and usually done by qa. it comes after integration testing. --- the controller method shown has logic in it that determines what result is returned. if you're not mocking out the dependencies and you run into a bug, you have no clue if the bug exists in the controller method logic or in one of the dependencies. you may think that's fine and that writing actual unit tests for your controller is a waste of time, but i guess we will just have to disagree on that. it sounds like you really just don't find any value in actual unit tests. it really doesn't matter how simple a unit of code is, i still find value in ensuring that unit does what it's expected to do.
It could be triggering DDoS prevention stuff if you start spamming a server like that. locally you would be fine. I would probably batch them up and have a setInterval call or something that pushes all changes every 2 seconds but only if there are changes. May need to catch the closing event to prevent data loss. you can catch ctrl s keys with jQuery for cross browser support if he is ok with that. 
Then what do you call it when you are actually integrating components created by different teams, possibly in different locations? Actual integration testing is a completely different experience than just testing two pieces that you probably wrote at the same time. It requires quite a bit of cross-team or even cross-company coordination. It's like the difference between running to the kitchen for a snack and running a marathon. In one sense they are both "running", but that doesn't really convey the true meaning.
 &gt; it sounds like you really just don't find any value in actual unit tests. I find a lot of value in "actual" unit tests. What I usually don't find valuable is mock tests. There is a world of difference between the two, starting with how the code is written.
&gt; if you're not mocking out the dependencies and you run into a bug, you have no clue if the bug exists in the controller method logic or in one of the dependencies. Then you are incompetent. Stop what you are doing, right now, and find a tutorial on how debuggers work.
Wow, that is a lot of code to prove nothing. What's the point in creating a bunch of empty objects that merely have the same shape as the real ones? He's not trying to test if the compiler works. At the very least you need to populate them like they would look in a real setting.
if dependencies are being used in the unit, and you're not mocking out those dependencies, then it's not a unit test, at least not by the standard industry definition: it's an integration test.
It's also an integration test. I don't care who's involved. 
you're a god amongst programmers and i'm vastly inferior and tremble before you. also, your penis is gigantic. can we move past the personal insults now? the point is not that you can't debug and find where the problem is, the point is that it's not immediately apparent. meaning your test cases have some ambiguity to them. if your test fails during continuous integration, you now have to reproduce the problem, parse console logs, download and load a dump, or whatever to figure out where the problem is. it's a huge amount of wasted time. if those tests were meant to be regression tests, you have no clue if you actually regressed based on the test result alone. say you had something stupidly simple like someone originally shipped `user == null` rather than `user != null` and you wrote a regression test for that. you have no clue if someone mistakenly changed the operator back or if some bug was introduced in `AuthenticateAsync` that's causing it to return a null value now. if you had written an actual unit test and mocked out _actions and specified a defined return value, you would know immediately that the Login method is what changed and could immediately go there and fix the problem.
You were getting downvoted because it does nothing to answer the question. 
HttpContext != HttpClient. Please learn to read.
Take a look at the MvcContrib project. They have a TestControllerBuilder that may help here. The project itself is old but still has its uses.
Oh, I'm so sorry, you honorable master of grammar and correctness. I do hope my extremely minor typo that, within context, does almost nothing to detract from the point of my statement, didn't offend your obviously extremely sensitive mind. Ass.
It's not just a minor grammatical error, dickhead. Your entire post and the sub-thread it is contained in is wrong because of it. The OP doesn't want to mock an HttpClient, nor does he want to mock a response from it. He wants to mock an HttpContext within a Controller's Action method.
I wouldn't look down on testing. Like all things related to coding, the better you are at it, the better you are at testing. At my place of employment, QA is actually closer to management, and I'm going to guess your employers think it's a good way to introduce you to the code base, not that testing is inherently beneath engineers.
Yes. I wasn't asked about run time complexity directly, but when asked to solve a problem in the most efficient way possible, it was a veiled question.
The Tables interface from Microsoft.Office.Interop.Word inherits from IEnumerable so you can't index it. The MSDN article states that there is also a method named Tables that takes an index and returns a table: https://msdn.microsoft.com/en-us/library/microsoft.office.interop.word.tables(v=office.14).aspx Seems like you could do objDoc.Tables(4). This might throw an exception depending on how many tables you have though. An easier way might be to use the IEnumerable and Linq to guard against exceptions. var fifthTable = objDoc.Tables.Skip(4).FirstOrDefault(); will result in null or a Table object depending on if one exists at index 5.
FYI depending on your use case, you may be able to use VS 2017 Community, which is a free version of Pro that you can even use commercially with some restrictions, and for .net core apps, you can also use VS Code (probably). 
Regarding development on Windows and running under Ubuntu, you can always make a Docker Ubuntu container on top of Windows.
&gt; can we move past the personal insults now? Not until you stop repeating the myth that its impossible to discover the cause of an integration test failure without herculean efforts. "if your test fails during continuous integration, you now have to reproduce the problem" ? Really? Seriously? The whole point of an automated test, integration or otherwise, is that you have something that is reproducible. 
This is a very interesting change. Thanks for the video.
google, we all live and die by google. 20+ years and I have to remind myself of simple stuff at least once a week. Before google indexed everything I has a stack of "cookbooks"; check out publishers like APress and ORiley
Check it TryParse instead of ToInt as it's safer if you cannot guarantee input values. For example: bool result = Int32.TryParse(value, out number); Then check the result to see if it was successful. If so, the value is in number.
[C# Pocket Reference](https://www.amazon.com.au/7-0-Pocket-Reference-Joseph-Albahari/dp/1491988533/ref=sr_1_1?ie=UTF8&amp;qid=1516937804&amp;sr=8-1&amp;keywords=c%23+pocket+reference) is exactly what you need. It is basically full of all the syntax examples with brief explanations for everything. A paper copy on your desk would be better than a digital copy, so you can quickly flick through it. You can get an older edition much cheaper if you shop around (you really don't need the most up-to-date edition for C#7).
Yes! This is exactly what I was talking about. Thank you so much!
 otherScript.myList = new string[] { "str1", " str2", "etc" } That *should* work. I can't verify at the moment because I'm not at a computer but I think it will.
Any chance you'd be willing to fill us in on your master plan? It's rare that you actually need something like this, it'd possible there's no answer to your question as asked, but we would still like to help you solve your ultimate problem.
If you need a list: otherScript.myList = new List&lt;string&gt;{"Hello", "Random", "Do i have enough strings?"}; If an Array or IEnumerable will work otherScript.myList = new []{"Hello", "Random", "Do i have enough strings?"};
*Testing Computer Software* by Cem Kaner, et al. is a great place to start. Do not let the publication date get in the way as the material is still relevant. If the organization does not yet make use of automation, definitely look into [Selenium](http://docs.seleniumhq.org/). Test automation could provide huge value for the team and provide you with more opportunity to practice your coding skills professionally.
Also not on a computer, you can even do it shorter OtherScript.myList = new [] {"foo", "bar", "wee"};
We use USB dongles so the license is bound to a dongle. Software doesnt work without the dongle :)
Syncfusion has a number of free books. Try c# suscintly https://www.syncfusion.com/ebooks/csharp
Backend dev here. A key tool in your toolbelt is regression analysis. To do regression analysis, you make a checklist of all the app features. Each version, go through the checklist and validate each app feature. Regression testers are worth their weight in gold, because us devs tend to get tunnel vision pretty bad when working on architecture.
Not at all, it depends on how many threads are on the Task pool and the current scheduler policy assigned to the pool. Besides, I can always make use of *TaskCreationOptions.LongRunning* as a way to try to force new threads to be launched. When everything fails, one can just launch a plain old thread.
Write a Roslyn analyzer or Fody weaver to autogenerate the IEquatable&lt;T&gt; definition for you.
Not at the moment, except you can find tools to create them for you (ReSharper, Rider, ...). Some languages (e.g. Swift) have compiler-synthesized implementations as a relatively new feature, which is pretty neat.
Just some things from looking at the code * Why is there a secondary interface IBlock, which has just one implementation (Block)? * Don't use DateTime, use DateTimeOffset * "data is **to** short" - also, this is somewhat misleading, as data is also checked for null * "data.Length &lt; 1" - Length has exactly one possible value smaller than 1, use == 0 * Why use two extension classes for the classes that you've created, instead of just adding those methods to the classes themselves? 
As the question was already answered, I want to add some nitpicking: - You should really make your structs immutable, that means making all fields read-only and only provide values via the constructor. It's best practice and prevents you from accidentally and unintentionally modifying a copy. - Making your struct immutable is a requirement for it to work properly as a key in dictionaries. You may don't need it now, but maybe in the future? And if you forgot by then that it's mutable.. You're up to nasty difficult to find bugs. - Your `GetHashCode` does note check all fields. Your hash code should be made up by all values relevant in your struct. - Keep an eye on https://github.com/dotnet/corefx/issues/26412 for a ready-to-use NuGet package to calculate hash codes for your structures.
The result of this modulo operation is a number of ℤ3 = {0,1,2} where -1 is equivalent to 2(-4 is also equivalant to 2, and 2+2 = 1) because they belong to the same residue class ring. In the first implementation the transformation step into ℤ3 is missing.
Silly question, is that not the same as my response but i used an anonymous type and linq query while you used a concrete class and lambda? If so yours is simpler i think. 
&gt; namespace ConsoleApp5
I actually do know several tools to generate it for you, even then it seems very bloated. It seems the comparisons could be reduced by a mixture of .net/c# features and built in tools to the IDE, but that maybe is just me being nit picky. 
So?
That did it. Thanks :D
I did it. Sorry. Didn't know :D
Keep an eye out for [records](https://github.com/dotnet/csharplang/blob/master/proposals/records.md), which are [currently](https://github.com/dotnet/csharplang/milestone/8) candidates for C# 8.0. It won't help if you want to implement a type that's more than just a bunch of members glued together that should all contribute to the identity of an instance if `Equals` / `GetHashCode` are called, but it looks like that's what you'd probably need here. That said, a suggestion: public bool Equals(SpellInfo other) =&gt; (name, rank, icon, castingTime, minRange, maxRange, spellID).Equals((other.name, other.rank, other.icon, other.castingTime, other.minRange, other.maxRange, other.spellID)); public override int GetHashCode() =&gt; (name, rank, icon, castingTime, minRange, maxRange, spellID).GetHashCode();
What do u use to read the docx?
&gt; Making your struct immutable is a requirement for it to work properly as a key in dictionaries. Since `Dictionary&lt;TKey, TValue&gt;` does not offer a way to get a `ref` to the actual slot in the underlying array, I don't see `Dictionary&lt;TKey, TValue&gt;` being a reason to make the struct immutable. e.g., this would be harmless (though perhaps confusing): var dict = new Dictionary&lt;SpellInfo, string&gt;(); var spell = new SpellInfo { spellID = 4 }; dict[spell] = "A spell of 4"; spell.spellID = 5; foreach (var key in dict.Keys) { // key.spellID is 4 here } That said, I appreciate the "immutable everything by default" stance. &gt; Your `GetHashCode` does note check all fields. Your hash code should be made up by all values relevant in your struct. Assuming that the `base.GetHashCode()` part in OP's code was a mistake and they meant some field instead, it's absolutely fine (and often beneficial) to omit some fields from a hash code calculation sometimes, depending on what you know about the way it's used. e.g., in this case, if `name`, `rank`, and `icon` are always set to the same values together (that is, if you never have two spells with the same `spellID` and `rank` with a different `name` and/or a different `icon`), then there's no point mixing in all three; it just wastes time in what can turn into the most performance-sensitive method in your code.
Dictionary is internally using buckets to store the items. The bucket is chosen based on the hashcode. If his struct is mutable, the hash code will change, but the dictionary won't be aware of that.
 string appPath = Path.GetDirectoryName(System.Reflection.Assembly.GetExecutingAssembly().Location); string wordFile = appPath + "\\document.docx";
Structs are passed by value, so unless you can somehow get a `ref` to the underlying slot in the dictionary's underlying array, you won't be able to mess up the dictionary by mutating any instance of the key you can get your hands on. [Try it out for yourself](https://sharplab.io/#v2:EYLgtghgzgLgpgJwDQxAgrgOwD4AEAMABLgIwDcAsAFAHEkAslV1pAbMQEx0Ds1A3tUJDCsDAGMYhALLoYEYABs4AaTgBPQiEIBJAKIBHdBDmK4AHhkmlqtQD5BwgVWEviAZkIBLTJM8ATJldhXA9SIkwIMDgmByCQwgB7ADdEBH84QmAEhIVCAyMFKAAKBOAAKzgJRPKASkIAXltqsq8oaVl5a3VEmAALREIAMkHCPs8oADp8iEKSvsQawKD3TOzc6dnLTpVuhPmEOsbR3vGJ/wb6nv6EM78hkbHJiKiLq8QJ5+jqWNd45NT0l4fIQAOJwGAACWgvQAwgk/HAiocmo9bjFnMs/ikEGkEXQiAAVBIAZRgaUwAHMkQ0mgASABEW1MNgA2udLnxUf4AL5IQifBqETknJ6RODcgC69KWQm5Px+bGI9DoAA4kT8nMtCEkIAhCABrbqXTBwADu7SsOw0fC8d0uJD5Asu9Js/LFdxI9MI3Jlrh1er8niqxrNhAAIkGYJ4EhEEGoLB1meo+WF7BigpqtcIWYa1BLBfSAGozdAZABmCT1ucIps8fVthE9SB+Lh9LeE7aE/sSaQp3hmrsuud9Llzt0FbhHwjHTsILu6nzubmlnboAE4igzc1o+LnufTFqvSBuGYGJBM4T4IN4oDYirmajuzzALzG5De7w/94fmOnfiQT3pStPD7CIFBsHdgNAgd1G/KchGPTd6WfV8rw/dQSl7ftwPUR8hRQy930wW8MKg7CbBqODVwrBA4AgMRekIIpu31JIAAcgUIZ8alXTMggASEQrdujLBAEjALjIx3Vi2ImGwqL/VsfjlKhuSAA=).
I work on VS2017 enterprise on windows at my work, but on mac at home I use VSCode, i tried normal VS for mac, but didnt see the benefit.
I've never had to perform an Application.Restart. What is the reason that you are doing this in your application? 
Always loved that joke. 
* Upcoming records would do this for you (I know that is no help now) * you could define them all as ValueTuple, which would have the same effect, but be a bit bulky to implement * you could use an F# library and just fill it with record types, then reference that library from your C# code. This would have the same effect as the first point, but is doable today Maybe this will help you, maybe not: I usually just XOR (^ operator) relevant field hashes together when overriding GetHashCode. Remember that the hash code doesn't need to be 100% unique, just a decent check that the objects *could* be equal
ConsoleApp5
I think you're probably getting tripped up on the initializer syntax. The form you're using works for arrays, and only as part of a declaration where the variable or fields type is explicit. That is, it would work here string[] foo = {"foo", "bar"}; but not here var foo = {"foo", "bar"}; // implicit variable type or here List&lt;string&gt; foo = {"foo", "bar"}; // not an array or here foo = {"foo", "bar"}; // not a declaration I'd have to do some digging, but I think the problem is that this syntax is too similar to the syntax for creating an anonymous object, so the compiler can't be certain about what you're up to without the extra information. Even then, I think it's probably a special case that's detected and handled, which is why it only works for declarations. What you can do, instead, is make it clear that the right-hand-side of your assignment contains an array // the type of the elements in the array is inferred to be string, so it doesn't have to be mentioned foo = new [] {"foo", "bar"};
Fody is the best tool for this. https://github.com/Fody One of their tools can do this for you: https://github.com/Fody/Equals
https://docs.oracle.com/javase/7/docs/api/java/lang/System.html#arraycopy(java.lang.Object,%20int,%20java.lang.Object,%20int,%20int)
thank you a lot, it's a very good point. I'll think about it
&gt; Remember that the hash code doesn't need to be 100% unique, just a decent check that the objects could be equal Not that I disagree with this but.... struct Foo { public int A; public int B; public override int GetHashCode() =&gt; A ^ B; } var a = new Foo { A = 1, B = 2 }; var b = new Foo { A = 2, B = 1 }; // Eek! Same hash code! 
I hate having an Excel spreadsheet as part of my solution. Even if it's set as shared I still get errors that it's in use. I have to poll the file every x seconds to check for changes because FileSystemWatcher doesn't work for Office files; Excel updates the timestamp as soon as you open the file triggering the FileSystemWatcher. I still can't find a good reason why async controller actions would be of benefit. I have a way to check for changes, it's similar to what you have but I record the value when I enter a box then compare it to the new value when I leave. This way if someone deletes a character and then puts it back it doesn't record as a change.
I run internal with few users so I doubt it's DDoS. I'm waiting to spend some time with the guy so I can figure out exactly how the data loss is happening.
Our network here isn't the best so it's possible.
Assuming you want exactly the same size as normal GUIDs, storage doesn't get any more efficient. 16 bytes are 16 bytes (no padding). The performance completely depends on your implementation of those methods, which we know anything about.
That's good to know, I didn't think you could override browser shortcuts. I'm not sure if I could implement this now that I'm saving on blur and the user is spoiled by that lol. I might try to change the colour of the textbox if it doesn't save, just have to figure out how to detect that.
Wrong subreddit for that one
Have you tried searching stack overflow? I would suggest you take a look into HashSet. Example below HashSet&lt;string&gt; names = new HashSet&lt;string&gt;(); for (int row = 3; row &lt;= 8; row++) { string name = author.Cell(row, 1).Range.Text; if (!names.Contains(name)) { names.Add(name); Console.WriteLine(name); } }
Removed: Rule 4.
F# is not supported in some platforms like the UWP. If you want your code to work everywhere you have to use C#.
I recently started with jet brains Rider IDE and have been impressed so far 
or is it? ok, yeah. 
1 is abusing LINQ. ^^^^^^^^^^. ^^^^^^^^^^. ^^^^^^^^^^. ^^^^^^^^^^. ^^^^^^^^^^. ;-)
I'm not sure I understand your proposal, what is the list supposed to be doing?
ConsoleApp6
So what would the process look like to read the data in a block? You have to know *what* data you are storing so you know how to read it right? I am not very knowledgeable about blockchains but it has always interested me.
* resharper: has code generation for equality members (among many more: formatting members (ToString), etc). * fody: weaves it for you on compilation.
to to nitpick, but its not very professional for one. its also not a good thing to seen by possibly future employers looking at your github in the future, which is more and more common.
It's your foot https://stackoverflow.com/a/8414869
There are plenty of answers if you open google.com with the very sentence you put in the title. To not be completely useless, https://stackoverflow.com/questions/13658555/need-to-execute-exe-in-server-from-asp-net
thank you, I guess, I can not get it any faster, unfortunately(
Could be IIS setting that iisexpress doesn't have.
minor critique: &gt; throw new ArgumentException("block is null", "block"); should do something like ` throw new ArgumentNullException (nameof(block));`
Dot Com bubble 2.0 (~20 years later than OG one)
Honestly, get used to googling and using (usually) the stackoverflow and MSDN websites. If you cant remember a keyword, you just need to know what you are trying to do. For your convert example you gave someone else in this post, you could have googled any of the following: how to turn a string into an integer C# how to convert a string to an integer C# string to integer C# how to turn user input string into integer C# etc. You'll always want to prefix or suffix your query with C# if you want the C# "version" for your answer. Otherwise, you'll get results for other languages as well like Java, Python, etc.
I'm waiting for them to just reboot the series and call the next one "ConsoleAppOne".
Removed: Rule 4.
I mean do you even bother to read the API? and yeah its pretty technical since you are new, but its your only hope. you've asked a lot of homework related questions here. https://msdn.microsoft.com/en-us/library/microsoft.office.interop.word.document.aspx https://msdn.microsoft.com/en-us/library/microsoft.office.interop.word.aspx
It isn't so much an obsession with the *currencies* but rather the obsession with *block chain technology*. It has many, many applications that can have far reaching implications not only in the financial industry but other industries as well. Because of the fascination around the technology itself, that fascination "bleeds" into the crypto-currency hype because that is the (current) most widely used implementation of the block chain. Sticking with crypto currency, think of it this way -- I can put $200 of a crypto currency on a USB flashdrive and that very flashdrive is, for all intents and purposes, actually $200 (barring fluctuations of the value of the crypto currency). This is different from a debit card. A debit card is an interface *to your banking account* -- the flash drive **is an account**. You can read the amount on the flash drive but you can't manipulate the amount -- doing so changes the hash and invalidates your currency, rendering it unusable (and you just lost $200). Someone with access to your bank's account database could change a few numbers, make themself a prince and someone else a popper, and the general ledger could still balance out (assuming the amount taken and deposited was the same between the two accounts and those accounts were in the same GL account). You'd only catch this maliciousness *after* it happened and probably only during an audit. Blockchain *prevents* this altogether. So, everyone can *read* from a blockchain but can't modify a block once it is created -- they are immutable and modifying one renders your copy of the block useless. You can still encrypt the data itself so sensitive information is protected, but anyone processing blocks (like in bitcoin farms) can still see the encrypted data. I am not an expert on block chain and I may have gotten a few things wrong but there'ya go. Block chains aren't without its own issues, though. For example, as time goes on, the "difficulty" of processing the entire chain increases since the whole chain is required in order to validate blocks and perform opertations -- this is how mining came about. As incentives for helping process blocks, you may be rewarded some amount of a crypto currency.
You can create an extension of object class to make a pseudo generic implementation. If passed object is the same type, get typedescriptor, then get property descriptors iterate over property descriptors, get values for both and compare. If the value is not string or not valuetype then recursively compare those two objects got from property also it is possible to implement inheritance checking. Also muh performance hit Could provide the actual implementation, but typing from phone at the moment. Also this can be abused to avoid encapsulation by gaining access to restricted members. But as you come from c++ you already know how "friend" evil is
I don't think the loop in the MineHash function that compares the first n bytes of the hash against the difficulty is ever guaranteed to exit.
This example is not about crypto currencies
Correct. This is a flaw that needs fixture. 
I tried to recreate in UAT as well with no luck.
Bit shifting. https://en.wikipedia.org/wiki/Bitwise_operation
Good idea. I was just thinking about doing the same thing my self. 
Name it'll just be called ConsoleApp
I prefer VS code for dotnet core. Dotnet framework I would use the full IDE though (which would be windows anyways, doesn't apply to your situation) VS Code is useful for more than just C# though which makes it easier to switch between projects.
It seems to be reversing the but order of a byte[4] array and returning that as an int32.
`|` is bit-wise 'or'. `2 | 1` would be 3. you take each bit of 0b10 (2) and 'or' it with each bit of 0b01 (1), which gives you 0b11 (3). `&lt;&lt;` shifts bits left and fills in the gap with 0s. `1 &lt;&lt; 2` would give you `4`. you shift all bits in 0b1 (1) left 2 times and fill in 2 0s giving you 0b100 (4). you can also think of it as multiplying the left-side by 2^right-side. `2 &lt;&lt; 1` is the equivalent of `2 * 2`.
From the size of your struct I'd say use a class, but in any case a struct has a built in "Equals" implementation for all properties / fields 
You could try messing with [Vector&lt;&gt;](https://msdn.microsoft.com/en-us/library/dn858385(v=vs.111).aspx) in System.Numerics. It would theoretically allow for certain operations to be faster (eg. comparisons) because it can utilize SIMD operations. That would mainly be beneficial for floating point operations which take several cycles so I'm pretty sure it could be slower. There is a limited amount of bytes that can be stored (iirc it was 4x 32 bit types last I checked) and that is probably processor dependent. Also the hardware acceleration only happens on ryujit but I think that has been deployed in the newer versions of .Net.
The block chain is simply the technology that they use. It has wide variety of uses.
Thank you! This has been driving me crazy. 
I just use FALSE (and remember never to define FALSE) [Conditional("FALSE")] public Ctor() { // Whatever }
System.Numerics.Vector only works with managed arrays.
It also checks the wrong variable.
This is driving me crazy.
I use the `ObsoleteAttribute` when I want to tag a view ctor for design-purposes only. Example: public partial class MyForm : Form { [Obsolete("For designer use only.", true)] public MyForm() { InitializeComponents(); //do stuff } } The `true` argument for the attribute will cause a compiler error if it is called directly. This will prevent future devs from calling it directly but the empty ctor can still get used with reflection if someone *really* wants to use that ctor.
I'm guessing this is faster than calling htonl/ntohl ?? (those are old-school socket calls to turn a Long into a network-order byte array) 
VS just greys it out/wants to simplify it.
That's the weird part; it says Actual &lt;1&gt;, but under Autos/hovering over the property, it says 2. However, I just noticed that stepping through it works, so it might be a wait issue. Just weird that the property has the correct amount but the Actual shows an incorrect amount.
This shouldn't be needed.
You can add a method for testing your property.
Well do you have more than 1 thread??
Right, but the property is returning 2, as the screenshot shows in the Autos window/hover over the property. The assert Actual reads 1, though, which doesn't make sense
Nope
Having some QB45 flashbacks. Neat
I've created this namespace so many times.
Pumped this got merged. Nice job, Ben. And excellent write up
&gt; QB45 Miguel gave us the midgnight commander, so I guess he had a thing for console UI all along.
This function interprets a sequence of four bytes as a number in big-endian order (which simply means that the most significant byte come first). Big endian is also the "network byte order", and is used by convention by most (all?) standard network protocols. Since the most common processors nowadays use little-endian, you cannot just point the processor at the sequence of bytes and tell it to read it as a 32-bit number, you have to explicitly "rebuild" the number by shifting (&lt;&lt;) and combining (|) these four bytes at the correct position. 
Some open questions regarding the lazy initialization: - Should it be thread safe? - If it is thread safe, is only the assignment/return of the field synchronized or the value creation as well (`Lazy&lt;T&gt;` `ExecutionAndPublication` vs `PublicationOnly`)? - Is this something that the user can specify? If so, what's the syntax syntax? - (How) does it work for value types which can't be `null`? Will the compiler add additional fields to track initialization status? I don't really understand the examples in the initialization part: &gt;By default, properties and their backing fields share auto-initialized values. [...] Is there a non-default option where they don't share the same value? How does that work? &gt; Property = backingField; &gt;[...] &gt; public SomeType Property { get; set; } = backingField; Why are the properties assigned the value of the backing fields? What would that even do? ---- To be honest, other than the lazy initialization I don't really see any significant gain relative to auto properties or manually implemented expression bodied properties. Not big enough that I would expect it to pass the generally high bar for language changes, at least. 
I have a small "database" of information thats 80 lines long. I just stuff it as a static instance member of the application lol If you really want you can do something with SQLite3 Sounds like you want maybe a history or circular queue that flushes every 20 calls or whatever https://en.wikipedia.org/wiki/Circular_buffer I've used something like this months ago to continuously cycle the last 10 images uploaded to one of my sites 
This is fantastic! Question about the design, it seems the problem was in C# compiler, however it has now been fixed in the core clr? Does this have any ramifications for other .net languages? 
What is the type of FlowchartTab? Maybe the class is doing something screwy.
Thanks, definitely makes sense.
I'm so excited for this. The stack traces were driving me insane.
I like C#, but man do other languages start to annoy you with things like this after you've used D. It's a dangerous language to try. 😛
A database would be overkill. I would think about using a purpose built class for storing this data, and put your logic within that class for controlling how long information is retained. Then add persistence by writing the current list of API call history items to a CSV file. On startup, read the CSV file back into memory to initialize things after a restart. The persistence doesn't need to be CSV either, could be XML, JSON or a SQLite database.
Biggest barrier to entry for async is now solved, hooray
Why do you need to be live-monitoring the Excel spreasheet? Why can't they just upload it when they're done editing it? If it needs to be live, is it possible to use a Google Sheet or Excel cloud and use that API instead? or maybe use an off the shelf grid tool? Can you upload your code to github? Can probably help with the save issue.
It depends what you're needs are in terms of a) durability, e.g how much do you care if you lose the data and b) does the web server need to scale out or will there only ever be one instance? Assuming a small chance of data loss is ok and you will only have one we've server running, I would look at an embedded database like https://github.com/mbdavid/LiteDB or sqllite
I wrote up a more technical description of Veldrid's implementation details, with some information about how each of the backends (OpenGL, Direct3D, Vulkan, Metal) is implemented. I figured this could help shed some light on how Veldrid works for those who are familiar with one graphics API or another.
&gt; The given key '0' was not present in th Guy needs to work on wordwrapping on his blog :p
If your json includes values as keys, a) your json is fucked up, and b) I think you're out of luck.
You can append a string to the JSON key before sending it to C# so page_373775 and then when you need to send that data structure back to JSON/Javascript you can remove page_ from the key again
It's from wikipedia https://en.wikipedia.org/w/api.php?format=json&amp;action=query&amp;prop=extracts&amp;exintro=&amp;explaintext=&amp;titles=comb
So some regex pattern to identify number keys and append? Sounds complicated, as using regex to begin with.
The \[code\] stuff won’t work on reddit. Just indent each line by 4 spaces instead. 
Thank you all for your time and info. This was supposed to be an exercise in data deserialization, but I'll find a better source of json or strat with xml. Thanks again guys.
When writing a hash code method, a desirable property to have is that collisions should only happen rarely. Simple XOR on members that are around the same magnitude is going to create all kinds of interference and almost certainly way more collisions than you probably want. The best scheme is always going to depend on what data you're typically going to hold (it's a real art), but if you're looking for a generic mixer that doesn't suck, I like to seed with 17, then multiply each round by 31 and add the next member's hash code (wrap on overflow) ([not my idea](https://stackoverflow.com/a/5450717/1083771)).
This is normal JSON. The ```"373775": { ... }``` part can be parsed into a `Dictionary&lt;int, whatever&gt;` or `Dictionary&lt;string, whatever&gt;`. 1) Change: public class 373775 { public int pageid { get; set; } public int ns { get; set; } public string title { get; set; } public string extract { get; set; } } To: public class PageData { public int pageid { get; set; } public int ns { get; set; } public string title { get; set; } public string extract { get; set; } } 2) Delete ```public class Pages { ... }``` 3) Change: public class Query { public IList&lt;Normalized&gt; normalized { get; set; } public Pages pages { get; set; } } To: public class Query { public IList&lt;Normalized&gt; normalized { get; set; } public Dictionary&lt;int, PageData&gt; pages { get; set; } // Dictionary&lt;string, PageData&gt; should work too } 4) Use [Json.NET](https://www.newtonsoft.com/json) like this: string myJsonString = ... // pull the json into the string var myExampleObject = JsonConvert.DeserializeObject&lt;Example&gt;(myJsonString); 
FYI, hash code collision math aside, I [recommend against](https://docs.microsoft.com/en-us/visualstudio/profiling/da0010-expensive-gethashcode) allocating in a `GetHashCode` method. I count on the order of 10 allocations or so in your snippet. The framework calls this method assuming it's extremely cheap to do so. These days, you can just make a tuple literal with all the fields and call `GetHashCode` on it; it'll do an adequate job.
Why not just hardcode your user account and replace you DB functionality with a Shim/Mock?
Reminds me of my old Clipper days. Neat idea but can I ask when you’d use this nowadays?
Does [`DesignOnlyAttribute`](https://docs.microsoft.com/en-us/dotnet/api/system.componentmodel.designonlyattribute?view=netframework-4.7.1) work here? I've never used it before, so I don't know.
Oh, well I didn't know that. (Personally never used it, I only used `Unsafe` for stuff like `AddOffset`) Then I guess there's nothing you can do. Perhaps you could write your own `SizeOf` using reflection, simply get the object's type, then iterate through all its fields and sum up their size (perhaps even call this reflective SizeOf recursively).
When talking about. NET inline means something very specific. This is not that case. It refers to how IL should be compiled/generated for called methods. Inlining meaning to copy the IL of a referenced method and "pasting" it in the callee.
If someone wants some extra credit, I guess... why **not** this? object System.Collections.ICollection.SyncRoot =&gt; this; Even the [docs for `ICollection.SyncRoot`](https://docs.microsoft.com/en-us/dotnet/api/system.collections.icollection.syncroot?view=netframework-4.7.1#System_Collections_ICollection_SyncRoot) say that: &gt; For collections whose underlying store is not publicly available, the expected implementation is to return the current instance. I can't think of a situation where it would be wrong for someone's `lock (theList)` to block entry while someone else's `lock (((System.Collections.ICollection)theList).SyncRoot)` is still live, and it seems like there could be plenty of cases where this is actually the wrong thing to do. Surely somebody thought of this before the answer became what it is today: "because it's been that way for over a decade now, so it would be a breaking change to do anything else"?
Just a little tip on terminology - if you're writing c# code, its not conventional to call everything a script. Classes and structs define your types. They have methods, variables, properties etc. An object is a particular instance of a class and contains real state/values. At runtime, you create instances of your classes and pass them around to other instances of classes, etc.
This is actually Unity's fault. They call any piece of code a "Script". Want to create a new C# file? The menu item will be called "New Script" or the likes. The reason it's like that is because they support multiple languages, including JavaScript and (I think) Boo, so they collectively call everything a script.
+1 for Json.Net ASP.NET WebApi uses it when serializing too. It's a great library, very flexible and extensible.
I haven't tried this docker approach but with a Ruby app SQLite is not permitted to use on Heroku.
Well damn. Hard to avoid using a database then.
Ah, that makes sense.
niiiice, wanted to make such a thing myself at some point but quickly lost interest. looks neat. does it work crossplatform?
So which platforms does this support?
Update: I talk to the devs, and showed this thread. They gave me green light to (for now) put the Unit Tests for the Controller class away and start on the methods that are called within the Controller class (as you suggested). I will still have to mock several things (including the HttpContext for what I just saw), but I guess it will be easier. Thanks!
Your post makes me realize just how bad I am with terminology. I have to store canWalk and canBuild, since canWalk is used for pathfinding and canBuild is used to check when the player is building. I might be able to compute canBuild, but I'd be going out of my way. For example, let's say there are dozens or hundreds of trees/rocks that stop you from building in certain locations. I could in theory have all those locations in a seperate array and when the player tries to build something, it checks the array to see if it's not on a location it can't build. I was going to compute canSpawn based from canWalk and canBuild. As for storing, I currently have a Node class with something like this: public class NodePF { public bool canBuild; public bool canWalk; public int gridX; public int gridY; } it has more stuff in it for pathfinding, but I have a Grid class that creates 100x100 instances of Node in my grid[x,y] instance, and base everything off that. A node can currently be occupied more than once, so I don't store where mobs are or worry about them overlapping yet. I am still deciding if I want to allow that or not. For now I use a List to store all my buildings, and the canBuild and canWalk in my Node class to check if the location allows movement or to be built upon. I'm sorry but even after looking it up I don't know what you mean by your last paragraph. The way it currently works though is: BuildManager requires 2 methods to modify the Grid instance. A `SetNodeProperties(int x, int y, bool walkable, bool buildable)` -- so that it can update a Node's canWalk and canBuild state. I also have a `IsBuildable` method that returns the bool for grid[x,y].canBuild, which is a simple check before allowing the player to build at that location. I am using A* pathfinding and it relies heavily on my Grid instance to calculate a path from a starting location to an ending location. As for the random spawner, it will need access to the grid simply to check if a Node at a certain location is completely empty, most likely by checking the canWalk and canBuild properties, and that is all it will need. I understand preoptimization is the root of all evil, but I am mainly trying to understand how to better structure my code and to have a better understanding how objects are used and linked together and how they are used in memory or allocated to the GC etc. The main question I have is, since the grid is quite big from having 10,000 Node instances in it, is it a bad idea to link the entire Grid instance to the BuildManager and RandomSpawner? The BuildManager only requires access to 2 methods, while RandomSpawner probably only requires access to 1. But what I am curious about is, when these access the Grid instance even for that single method, does it have to load the entire Grid instance in cache/memory/whatever, including the 10,000 Node instances to call a simple method? I apologize if my question is weird or doesn't make much sense. I hope I've been using the right terminology to explain all of this. Thank you for reading and for trying to help. 
And apparently Heroku doesn't let you write to the file system. Guess he has to go with what they offer for persistent storage.
Try http://redditlint.com for formatting your code when posting here
I found this website the other day while looking for cookbooks and whatnot. This might be what you're looking for http://goalkicker.com/ Here's the book for C#: http://goalkicker.com/CSharpBook/
Images are really nothing but an array of bytes. So look into a way to read and write an array of byte to a file. 
Nice. The old Borland "Turbo" products would have a drop-shadow on the frames. 
Good question. Multiple GL contexts could help with some types of resource creation, which would allow me to initialize things like buffers and textures when they are first created rather than lazily on the worker thread. Unfortunately, it doesn't work for a lot of other types of resources, so I think I would still be left with the full complexity of the current implementation, plus additional complexity from multiple GL contexts for some resources. This would likely involve additional worker threads that are looping over submitted work items, so it would have some extra overhead. A lot depends on how well drivers handle this, but it could end up being slower than having a single dedicated thread. I'd have to do some experimentation to see. This is all assuming that that sharing GL contexts actually works correctly on different platforms, which I've heard mixed things about, and which raises some skepticism from me, since it's relatively obscure. OpenGL drivers tend to do worse on features that less people use, unfortunately...
An aws S3 bucket is a good cheap option for persistence 
I've really enjoyed firebase for storing small amounts of data.
is this an explicit excercise in working with bytes or why are you trying to reinvent the wheel? you could just save the avatar as a bitmap with a unique name and save that name with the score. If you are hellbent on doing the legwork yourself then you could sequentially write bytes of 0-255 r - g - b byte values and if you know the pixel size of the image you can read it back.
[quicktype.io](https://app.quicktype.io/#l=cs) can help.
The blogs ads make this unreadable on mobile view.
Sorry, i read that page with adblock and forget to check the advertising. 
I tried out Rider and it did seem really good. It's pretty expensive though when there are numerous free alternatives (VS and VS Code i guess being the main two). 
I didn’t know VS was on Mac. For Linux the jet brains products are the best
&gt; A database would be overkill.... ... &gt; add persistence by writing the current list of API call history items to a CSV file. A CSV file *is* a database. It's just not a very good one :P
Yes, that is factually correct. Well done!
&gt; values as keys Where are you seeing this?
Have you tried stepping your code? If not, this is a good time to learn how to use the debugger. Does the server crash or the client? What error message do you receive? 
You provide a link to a repo, a vague non-technical comment on what is occurring and you expect us to solve the problem for You? Are you getting literal segfaults or sigsegv in the .NET Runtime? If not then you can probably provide significantly more context to the issue by providing the exception information and stack trace. You could probably even figure the problem out yourself if you had these things. If you don't have these things then that is the first major problem with what you're developing. Get them. Then you'll figure out the rest quick.
Ok, I'll try to send specifics, as for the repo the code was way to long to paste and had several files due to the winforms
Jason.net newton soft Also, I think there is a special "paste from json" command under edit in visual studios that will paste a json serialization/deserialization class from json text in your clipboard... you can do the same thing with xml.
This targeting core would be hilarious and awesome. 
Hilarious?
Json.NET definitely is the way to go. Its on NuGet, and you can use attributes(?) like @StuffHere to change the default behavior. Documentation is awesome too.
I started to learn .NET/C# a little over a year ago on with VS2017. Altho the full IDE features are nice I often didn't fully understood what VS2017 was doing for me under the hood and often was lost figuring stuff out I didn't fully understand. Only once I switched to vs code where you have to do a lot more yourself manually/barebone and with commands/terminals/certain use of files I truly started to understand how things worked. Might be a little harder to getting into but if you ask me vs code is better for overal understanding on the long run. My 2 cents from a fellow newbie.
It doesn’t seem like you understand the way the current auto properties via get; set; functions First, it already creates a private backing field, so half your examples aren’t or don’t seem relevant. Second if your using auto properties and want differs behavior you can easily do it now, by not using auto properties. The current methodology is clear and easily traceable, your examples are neither of those. 
This part: "pages":{"373775":{"pageid":373775 373775 is the key for the page object that contains a pageid field, whose value is also 373775. No? 
I think this is where VS Code really shines. You get can full intellisense for c# *and* HTML/CSS/JavaScript.
oh dear
I actually know her very well. We've been friends since the fourth grade and her mom was my first grade teacher.
Heroku supports Redis
Life is short, so go for it. Just be a gentleman and take her answer in stride.
I would assume they just release updates for both at the same time. I mean the updater is an application so it's obviously going to need new features added and bugs fixed same as every other application.
Its not an explicit exercise but if i can implement the users avatar in the leaderboard page i will get extra marks.
Yeah but it's EVERY VS update that needs the installer to update lol.
What does it matter? It's tiny.
I just hope she doesn't choose an unfortunate player name. Also is it supposed to work at all? I tried it out in VS2017CE and got: &gt; The program '[5160] dotnet.exe' has exited with code -2147450751 (0x80008081). Then again I'm a dunce, so there's that. Best of British luck to you Matey!
Like I said they likely release the updates together. It doesn't mean that the new update requires a new updater. It could purely be bug fixes. But it's also likely as they extend what the updates can do that the updater needs changing. It's like amazon patching their apps before a sale.
I am surprised too. Frequently changing installer is a bit worrying. It means that code is not very stable and if bug gets in and it screws some serious stuff up then the only fix could be OS re-install. 
It's mainly annoying as it's extra steps that seems so unnecessary.
It's mainly annoying as it's extra steps that seems so unnecessary.
AFAIK, the installer app is a Wix Burn bootstrapper application. That means that the information about the packages to be installed (including the versions and hashes of the packages) is embedded into the installer. Thus, to update the list of packages, the bootstrapper has to be updated.
I'm not on the installer team, I'm in docs, but AFAIK, all of C&amp;E (content and engineering - Scott Gu's org) is on 3 week sprints. 
Isn’t your JavaScript example synchronous? If it was asynchronous, there’s a foo has no data when you log it.
Game was made in VS2015CE, so... sorry about that... Never seen that error before, try looking it up but it will most likely be because it was made in an older engine.
So. How it went?
No worries. I assumed I don’t have a library loaded or something.
Are you limited to using CEFSHARP or can you use another library such as Selenium WebDriver? I can probably provide the Selenium code that will work. 
yes
So why are you comparing synchronous JavaScript to asynchronous C# in a question about async methods, using the synchronous code as an example? You even said you’re an “async JavaScript programmer” right before providing a synchronous code example. 
Everyone else in this thread knew exactly what I was doing and why. Try figuring it out.
Prom is months away, I'm gonna let her play once the game is finished.
or: var testVar = new[] {"test", "blah", "blah"}; shorter.
You will have to install the following packages: &lt;package id="Selenium.Chrome.WebDriver" version="2.35" targetFramework="net461" /&gt; &lt;package id="Selenium.Support" version="3.8.0" targetFramework="net461" /&gt; &lt;package id="Selenium.WebDriver" version="3.8.0" targetFramework="net461" /&gt; Try this: using OpenQA.Selenium; using OpenQA.Selenium.Chrome; using OpenQA.Selenium.Support.UI; using System; namespace ConsoleApp3 { internal class Program { private static void Main(string[] args) { var chromeOptions = new ChromeOptions { BinaryLocation = @"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe", }; IWebDriver driver = new ChromeDriver(chromeOptions); driver.Navigate().GoToUrl("http://www.raiplay.it/dirette/rainews24"); WebDriverWait wait = new WebDriverWait(driver, TimeSpan.FromSeconds(20)); wait.Until(ExpectedConditions.ElementToBeClickable(By.Id("mep_0"))); wait.Until(ExpectedConditions.ElementToBeClickable(By.CssSelector(".mejs-fullscreen-button &gt; button"))); driver.FindElement(By.CssSelector(".mejs-fullscreen-button &gt; button")).Click(); } } } If this project is going to grow into something bigger going forward or you want to make it more maintainable in the long run I would strongly suggest investigating the [Page Object Model](https://www.swtestacademy.com/page-object-model-c/) pattern.
Code looks like java/javascript...
What would solve this is if we could just have an installer app for the installer app.
Thank you very much for the fast reply! I'm not able to make "ExpectedConditions" to work, I tried many examples but is not working (the name "ExpectedConditions" does not exists in the current context). What can it be? [I've installed everything you said](https://i.imgur.com/hyS8YlE.png). I've another question, what does that &gt; means here? driver.FindElement(By.CssSelector(".mejs-fullscreen-button &gt; button")).Click(); like: fine this `.mejs-fullscree-button` and go to the child called `button`? Sorry if it is a stupid question, will look into your link, maybe the answer is there. I would like to being able to use wait.Until(ExpectedCondition), much smoother than the loop I've done. I was able to have it to work, just before you posted the solution, in a WinForm (stupid choice, sorry) but used a form because every example with `ExpectedCondition` didn't work :( public partial class Form1 : Form { IWebDriver wBrowser; public Form1() { InitializeComponent(); wBrowser = new FirefoxDriver(); wBrowser.Url = @"http://www.raiplay.it/dirette/rainews24"; isFullscreenButtonThere(); } private async void goFullScreen() { wBrowser.Manage().Window.FullScreen(); wBrowser.FindElement(By.XPath("//button[@title='Fullscreen']")).Click(); } private async void isFullscreenButtonThere() { bool isFullscreenButton = false; while (!isFullscreenButton) { await Task.Delay(500); try { IWebElement fullScreenButton = wBrowser.FindElement(By.XPath("//button[@title='Fullscreen']")); if(fullScreenButton.Enabled &amp;&amp; fullScreenButton.Displayed) { isFullscreenButton = true; goFullScreen(); } } catch { } } } private void Form1_FormClosing(object sender, FormClosingEventArgs e) { wBrowser.Dispose(); } } **Thank you so much for pointing me in the right direction!!!**
Hi again! Hmmm that is interesting that you get that error when you have the `using OpenQA.Selenium.Support.UI;` include... what options do you get if you `Alt` + `Enter` on it? Maybe reinstall the `Selenium.Support` package (uninstall then reinstall). Yes that is using the CSS Child selector, saying that it is the direct child of the first element. More information [here](https://developer.mozilla.org/en-US/docs/Web/CSS/Child_selectors). If you have a Stack Overflow account with more than 20 rep can you post it here so that we can chat, otherwise [discord](https://discord.gg/cR3q5f) could work for quicker communications. 
Soooooo... Is it that bad to use Linq this way?
Agreed, I just prefer to use explicit types in strongly typed languages.
Haha nice! I'm still available on discord if you want to talk about the rest of your code, I can see some improvements and suggestions. :-) Mostly around not using `XPath` because it is terrible. I would use By.CssSelector("button[title='Fullscreen']") Instead of XPath.
No problem man, best of luck with the learning. Yeah I wasn't sure how much web knowledge you had but you nailed it CssSelector is basically the jQuery selector, so you can test things out in the dev tools pane using jQuery then copy the same selector over into your C# code.
So this a mistake you *haven't made yet*. Just ask her out man, this is way over the top, and a bit creepy.
Lol
&gt; it's a node app Now I'm sad. How stupid is it that it doesn't just download a separate manifest?
&gt;I'm sad [Here's a picture/gif of a cat,](http://random.cat/i/ew6kA.jpg) hopefully it'll cheer you up :). ___ I am a bot. use !unsubscribetosadcat for me to ignore you.
Bad bot. !unsubscribetosadcat
Thank you MisterTheCookiePear for voting on ThisCatMightCheerYou. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
That did cheer me up, actually. 
Not exactly arrays of bytes, but byte ranges and positions for specific pieces of image data.
I don't get why they just don't use winforms or wpf, whatever. I don't care. Why node? VS is not a cross-platform... 
Program it for yourself. You are unlikely to find something so specific.
Are you asking about using MVC with no ORM at all?
I like EF for its convenience, but it's certainly not required, and there are many alternatives. Dapper is a lightweight and popular ORM that will have less features built-in than EF, but will also typically have faster read/write times.
Do we work together? Haha
Not stupid. With decent interfaces, your front end should neither know nor care how data gets pulled from the database. You should be able to replace EF with any other database connection framework (or none at all).
For OP's use-case, treating it as one long array will get them what they need. 
Originally that's what I meant. So what's your thoughts on using no ORM?
There is no reason to use EF if you want to use another ORM. As for no ORM, i would not recommend doing that you want loose coupling between your data store and your tooling. 
Docs as in developer documentation? If so, I love you.
SuperConsoleAppDxRgAndKnucklesAndKnuckles64
I once created a `SafeDictionary` class that wouldn't throw exceptions (instead returning null) when getting a nonexistent element, and you could also add items using the indexer syntax `dict["bob"] = 42` instead of `.Add` without an exception being thrown... not sure if brilliant or crazy!
Yes, that's me, and we love you too! 😍
We don't use any orm. Just sprocs or parameterized queries. Your view doesn't care, it just takes a Model
What are you trying to do? You could always use SSRS to email the report out; just have to write something to pull the data from the API and dump it into a table that SSRS can read.
Yeah, came here to say NHibernate still exists and is good. The sql generated tends to be nicer, too, in my opinion. EF is subquery happy. Probably doesn't matter for most things, but just something to note.
I don't see how interfaces are related to my question - it was pointed more towards reflection.
use flurl
Nothing wrong with it at all. Personally I'm a bigger fan of not using any ORMs and just writing out the SQL for more complex stuff (not straight up crud). Way more control for me, the downside is most on my team can really only handle basic SQL. 
I'm not sure what you mean. Interfaces wouldn't help me see the exact parameters of a method of a given type unless the parameters of the method would be the same for every class method. I could use an array of objects using params, but it's nice to know the exact parameters of the method. 
I absolutely despise Entity and have switched over to Dapper. In all my tests it was easier to manage and the performance was exponentially better compared to Entity, and it gives you the power and control you lose out on when dealing with Entity’s idioms.
Mix of WF and ado.net at work, but lately using dapper at home .... very hassle-free and if you're decent with sql I think it's a good fit. 
Generic contraint can ensure some method only with interfaces.
Yes, it wouldn't be a perfect way to make sure the class has a named method. 
It definitely seems strange how it's setup.
Same here, but writing all of that SQL can be annoying for the trivial cases so I created this: https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper
EF Core seems to be better about not generating too many subqueries or joins. On the other hand, it gets easily confused and is more than happy to suck down the entire table to process it client-side. 
If you want loose coupling, use stored procedures. Then the application doesn't even have to know what the actual tables are. I worked at a company that was nearly 100% stored procs. It was great. I could completely refactor tables to my hearts content so long as I didn't break the API exposed by the stored procs. 
Hi there, My company makes ReportMagic, a commercial package that does exactly this. It is free to use (advanced features cost, but you probably won't need them), so just register at https://reportmagic.net/ In order to work, however, you will need to let us know which REST API you are working with. We will then add the required macros. To do this, just use the Feedback button (speech bubble in the top left of the UI). Best wishes, David
We tend to use EF for writes and dapper for reads, exposing the DB reads via views instead of SPs. IMHO, its a good approach. It really separates concerns from a CQRS perspective. 
Ah, okay. I haven't gotten a chance to play around with EF core, but good to know. Thanks!
Another fun bug is when you remove a child object from it's parent. Instead of deleting it, it tries to set the non-nullable FK to null. SO I end up having to always remove it from both the parent object and the context's table collection. I hate EF Core so fucking much. (Not that I ever liked EF, but at least it worked.)
Are you Azure hosted? We use App Insights for stuff like this if you are. https://azure.microsoft.com/en-us/services/application-insights/ 
What? You don’t like NHibernate? Ok, I’ve also used dapper for small projects. Even wrote my own adodb wrapper to make it fluent (ish). Not every project needs all the bells and whistles.
I'm not using one, I'm comfortable in SQL, I start my projects from the ground up with utility procedures for making changes, deserializing to an object is already easy. Maybe i'm missing something, but I see little point in further abstraction when the fundamentals aren't difficult to begin with.
That's a good point that I often forget: once you have stored procs you can freely mix Java, C#, Node, etc. in the middle tier.
I was like that until relatively recently, then i got a case that involved writing some procedures to do a sortable, filterable and pageable search over a large database. It took me days to pull it off, but it was probably the most rewarding task ever had to do to in terms of upping my skills.
When it's going to be serialized immediately to JSON type safety doesn't matter.
An under-appreciated advantage of that is you can easily bake in things that a normal ORM doesn't support like soft-deletes, audit columns, etc. Stuff that tends to be application specific, but is really important to get right.
Don't always blindly return interfaces instead of concrete types. Understand the difference and the implications, then choose depending on your requirements.
Larry? Is that you?
for the trivial cases we are using FastCRUD dapper extensions
I'm about it make the change as well. Entity gave me a lot of speed in getting POC up and running, als I do like to the code first way of working. But performance is becoming a thing now. If you're scalable rest api, I would suggest to leave Entity out of it.
Good to hear, it amazes me that databases are a huge thing but with ORMs some people are missing out on a huge skillset. Glad you dived in head first. You can do some really neat stuff with a proper understanding of SQL.
And they can't create a simple web service to download the hashes and versions? -_-
&gt; VS is not a cross-platform There is [Visual Studio for Mac](https://www.visualstudio.com/vs/visual-studio-mac/).
Most of our applications use either ADO.NET directly or Dapper. Which in hindsight was a very good decision, given how they broke EF compatibility with EF6 on .NET Core.
I've just been through this process (in the last 5 months at least) and we had to resort to a completely custom built reporting solution due to the amount of products on the market that ended up being completely unsuitable. Waiting for final implementation and sign off right now actually. This is one of those rare times in programming where it does appear to be necessary to reinvent the wheel...
&gt; I worked at a company that was nearly 100% stored procs. It was great. I could completely refactor tables to my hearts content so long as I didn't break the API exposed by the stored procs. My main worry would be that unit testing stored procedures is difficult. Unless someone has come up with a good way to do that since I last worked with stored procedures 10 years ago.
My take from your comment is that it really depends on the situation, yes? I think I tend to try and do too many abstractions and go crazy with inheritance, so maybe I'll try a slightly more concrete way and see if I'm actually working less efficient by trying to be too abstract.
Yes
You use App Insights for report generation? What about report persistence, running on demand, emailing? I understand using it as a dashboard, but in my experience Insights are way too heavy for anything like report generation.
1. Using a factory for your services is fine, however don't cast down to the service type, you should only ever be referencing an interface that the service implements. You should also consider creating factories separated by component/use case, rather than a single factory for every service for boundary purposes. 2. Read up on the Interface Segregation Principle. You should consider creating interfaces (composed of smaller interfaces if needed) that only implement the methods that you require, and no more.
Do you have some kind of alert set up to push Chain as soon as Dapper is mentioned?!
For 2. Identify the commonality between the two services and bundle them up into a single abstract base class. Extract an interface from that class and name it in generic terms. Then further more specific interfaces can use that single 'base interface'. That way you have a single implementation of the common aspects of your services, which branch out to specific services. This will satisfy DRY principle since you have consolidated similar functions under one base umbrella. If you implement an interface all of it's members should have an implementation, if not, they belong somewhere else.
How do you know someone uses Dapper?
This applies to both Java and C#. Always return defensive copies of objects that aren't immutable if you don't intend for the user of your API to make changes to them. In C#, `struct`s are a value type so you don't need to make a defensive copy of them. In Java and C#, you need to make clones and/or copy constructors of classes to make defensive copies. However, collections in particular have a bunch of special methods to handle it: * In C# * `Array.AsReadOnly(T[])` is a static method that will return a`ReadOnlyCollection&lt;T&gt;` that is a wrapper around the array * `List&lt;T&gt;` has `.AsReadOnly()` to wrap it in a `ReadOnlyCollection&lt;T&gt;` * For Dictionaries, you can instantiate `ReadOnlyDictionary&lt;TKey, TValue&gt;` directly; its constructor takes an `IDictionary&lt;TKey, TValue&gt;` * In Java * `Arrays.asList(T...)` is a static method that will return a `List&lt;T&gt;` that is a wrapper around the array * The `java.util.Collections` class has static methods to return unmodifiable copies of the various collection types, such as [`Collections.unmodifiableList`](https://docs.oracle.com/javase/9/docs/api/java/util/Collections.html#unmodifiableList-java.util.List-) * ...and [`Collections.unmodifiableMap`](https://docs.oracle.com/javase/9/docs/api/java/util/Collections.html#unmodifiableMap-java.util.Map-) 
Hang on, so you wrote your own orm?
The 1990s just called... it wants its design pattern back.
Imagine? I know them!
Testing the controllers always hurt my brain. Your not supposed to put business logic in them so whats left to test?
Except you might break other stored procs snd not find out until runtime.
&gt;Another fun bug is when you remove a child object from it's parent. Instead of deleting it, it tries to set the non-nullable FK to null. SO I end up having to always remove it from both the parent object and the context's table collection Does the EF6 fix of making the child's key a compound key consisting of the parent and child work?
Your contract; input checking, return codes etc etc
We use ASP.NET MVC and our own home grown data layer. It’s neither crazy nor stupid to do so. The only disadvantage is with libraries like Owin and the ASP.NET Identity Framework, as the assumption is that you’re using Entity Framework. 
Your good example is the perfect case of an awful example. I've seen way too often `IEnumerable&lt;T&gt;` returned, when in the context of the application the only usage ever is as lists. So many unnecessary `ToList()` calls. Also `IList&lt;T&gt;` instead of just `List&lt;T&gt;`, which immediately gets rid of optimizations, virtual calls instead of static calls, and garbage through the enumerator instead of the `List&lt;T&gt;` struct enumerator. And when you define a return type of `IList&lt;T&gt;` you should not ever return an instance of `ReadOnlyCollection&lt;T&gt;` just because it (stupidly) implements the interface. `IList&lt;T&gt;` is explicitly mutable, it has `Add` and `Clear` methods. So suddenly you might get runtime exceptions instead of compile time errors. 
Your question is really open ended. Some stripped down code to show where you're having a problem would help. I think you've got a few different concepts mixed up. In example 1 it sounds like you want an IoC container, not the factory pattern. Have you googled around for that? In example 2 it sounds like you've got a messy object model. Your interfaces don't have to be large. You can make them very granular. E.g. if you have an ICustomerService having to deal with Users, Admins and Roles and who knows what else, it might be better realised as 3 or 4 separate interfaces. If that is made impractical by other problems, you can still have ICustomerService implement IUserService, IAdminService, etc, and the client side can reference those more granular interfaces instead of ICustomerService. Move step by step in the direction of tighter encapsulation. &gt;go crazy with inheritance Don't over do it. Usually, make abstractions only when you spot a practical advantage, rather than when you spot the pattern. There are patterns everywhere, but it's not always adding clarity to abstract, nor will it always save time down the road.
Not so hard to do. I've written a few over the years. http://persism.sourceforge.net/main.php I never got around to finishing my C# version though. 
Out of all the people in the world that require reports.... reinventing the wheel just seems stupid. 
Thanks. I’ll take a peak. 
&gt; I've seen way too often IEnumerable&lt;T&gt; returned, when in the context of the application the only usage ever is as lists. So many unnecessary ToList() calls. This itself a design flaw. `IEnumerable&lt;T&gt;` should only ever be used if the **only** valid thing to do with what you returned is to iterate over it. &gt; And when you define a return type of IList&lt;T&gt; you should not ever return an instance of ReadOnlyCollection&lt;T&gt; just because it (stupidly) implements the interface. IList&lt;T&gt; is explicitly mutable, it has Add and Clear methods. So suddenly you might get runtime exceptions instead of compile time errors. You're aware that `ReadOnlyCollection&lt;T&gt;` was only an example, right? I could have just as easily said single dimension generic array, which for some strange reason **also** [implements `IList&lt;T&gt;`](https://docs.microsoft.com/en-us/dotnet/api/system.array?view=netframework-4.7#Remarks). The point is for an API, if you specify `List&lt;T&gt;` as the return type, you're locked into that decision for all eternity unless you want to break the code of other people using your API. That could be your coworkers or, if it's a public project, anyone.
"Haha, that pattern is old!" "What's wrong with it, though?" "It's...OLD, you oldie!" "..."
This is an amazing API. Thank you for your effort! 
Can't believe no one has mentioned [JSON2CSharp](http://json2csharp.com/), just paste sample JSON into the box and click "Generate"
This is an amazing API. Thank you for your efforts!
You can share a single factory for multiple interfaces, but that's starting to break the Single Responsibility Principle. If those interfaces don't really have anything to do with each other, they should have their own factories (or at least _appear_ to have their own factories if each factory implementation is shared for caching or something like that). You also shouldn't need to do any casting once you request something from a factory. If you feel you need to do that, you're probably doing it wrong. It should be as simple as `ITypeIWant x = myFactory.GetITypeIWant();`
I could've gone the upload route but I originally thought I could use the FileSystemWatcher to track it and use SignalR to push the update out to users. I built the whole thing that way and when I found out that Excel triggers the FileSystemWatcher on open I decided to switch to polling instead of re-writing everything. I did this as a temporary measure, once I freed up some time I was going to build a nice UI for it. When I built this UI it was really nice, you clicked on text and a textbox would appear that you could edit with a save and cancel button. I thought it looked nice but the users said it was more difficult to use than Excel. I guess I could have said too bad this is what you get but I tried to appease them with textboxes that saved on blur rather than having to click to edit and click to save. All my testing indicated this worked well, only weeks after release did the user come back and say that some textboxes didn't save. My company is super cheap and won't pay for any third party grid tool. I also I re-use the code that displays the read-only version with the input version. 
No. This is Patrick.
Sounds to me like you're already on the right path. I would suggest contributing to open source projects. This opens your code up to scrutiny from others. While books are a good resource, programming is such a vast area that you can't really just say "I want to learn programming" and start learning. Having a goal is usually a more tangible path, allowing you to learn along the way.
Please include your code. You probably have an infinite loop running on the main UI thread.
https://stackoverflow.com/questions/39572985/displaying-base64-string-in-asp-net-gridview
I've definitely heard this mentioned before. I'll add it to the cart!
You won't regret it
Have you considered an IoC container like `Unity`? You can do things like this: public class MyConsumer { public MyConsumer(IDependency1 d1, IDependency2 d2, IDependency3 d3) { ... } } .... //during app startup var container = new UnityContainer(); //map interfaces to concrete types container.Register&lt;IDependency1, ConcreteDependency1&gt;(); container.Register&lt;IDependency2, ConcreteDependency2&gt;(); container.Register&lt;IDependency3, ConcreteDependency3&gt;(); .... //later on, when an instance of MyConsumer is needed MyConsumer consumer = container.Resolve&lt;MyConsumer&gt;(); The container automatically resolves the `MyConsumer` type with the required dependencies. You can also register specific instances like this: var d1 = new ConcreteDependency1(); container.RegisterInstance(d1); That way, anything that needs `IDependency1` will receive the **same** instance of `ConcreteDependency1`. You can also create child containers so each container has a "parent" collection of registrations to use as well as registrations unique to the container: var container = new UnityContainer(); container.Register&lt;IDependency1, ConcreteDependency1&gt;(); container.Register&lt;IDependency2, ConcreteDependency2&gt;(); IUnityContainer child1 = container.CreateChildContainer(); IUnityContainer child2 = container.CreateChildContainer(); child1.Register&lt;IDependency3, ConcreteDependency3&gt;(); child.Register&lt;IDependency3, OtherDependency3&gt;(); MyConsumer consumer1 = child1.Resolve&lt;MyConsumer&gt;(); //creates the object with the first two dependencies from the parent container and the ConcreteDependency3 object MyConsumer consumer2 = child2.Resolve&lt;MyConsumer&gt;(); //same as above except it uses OtherDependency3 instead. I may habe gotten some of the methods on the container wrong since I am doing this from memory. Hope any of this helps.
While this is a good idea, I do actually have a peer at work with a bit more experience than myself. We both contribute to a library that is used for a large number of company applications. 
Gotta post your code, hombre. Also, post *screenshots* instead of taking a picture with your phone (unless, for some reason, this app is screwing up your computer such that a screenshot is impossible). Off the cuff: * Make sure the constructor for your form has a call to `InitializeComponents();` * Add break points to your code and "trace" the program execution. Once it starts to do something you didn't expect, you'll know where the problem is. * Down on the bottom of VS there is an "Output" tab (I see it in the screenshot). Expand it and see if there is any informatiom there that may be able to help you or us figure out the problem. Again, post your code. There is 30 billion ways to make a UI form behave that way so we can't really tell you what the problem is without showing code. Your post is analogous to someone saying "Something is wrong with my computer, how to fix?" with a picture of their monitor and PC turned off.
Google these (I am on my phone so I am being lazy): * S.O.L.I.D Programming Principles (most important on this list) * D.R.Y Principle * C# Code Style and Naming Conventions * [Design Patterns](http://www.dofactory.com/net/design-patterns) (ok I am not *completely* lazy) As my personal general rule, if I look back on code I've written 6 months ago and I am not *disgusted* then I know I haven't been learning.
public class __invalid_type__373775 { public int pageid { get; set; } public int ns { get; set; } public string title { get; set; } public string extract { get; set; } } public class Pages { public __invalid_type__373775 __invalid_name__373775 { get; set; } } 
THAT WORKED! For those keeping track at home, you pipe in a &lt;img src...&gt; html tag into a BountField (not Image Field) and then set HtmlEncode="false" in the aspx. Thanks again!
I have found that sometimes focusing on just a language doesn't show me the big picture. Meaning that if I get the idea in my head of how I should tackle the problem I can then find the appropriate way to do it in the language of choice. Below are some books that i have read that really helped me move forward in IT. My back ground is computer science, so some topics maybe easier or harder to follow depending on yours. Patterns of Enterprise Application Architecture (Addison-Wesley Signature Series (Fowler)) Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems Writing High-Performance .NET Code - Ben Watson SOA in Practice: The Art of Distributed System Design The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win Technical Impact: Making Your Information Technology Effective, and Keeping It That Way 
Is there something missing from Visual Studio that you're expecting? You can create Calc very easily with a WPF project in VS (you'll want at least Community edition, Visual Studio Code doesn't have project templates to my knowledge); Paint takes a little more knowledge of the presentation engine but the starting point is the same. As for "best", the discussion is purely subjective. Visual Studio is certainly the most fully-featured IDE for C# on Windows, but you can full-well write any of these apps with Notepad &amp; csc.exe.
it all depends on what you want to do. Visual studio is the primary development tool for most windows dev, especially with a UI, but there are other options. If you want WPF/XAML/UWP, then I'd go Visual Studio. If you are making console programs, you can use Rider or VS. 
Sorry, I'm already using an IoC container. In your example you're using something like a delegate factory for every service, yes? I use those for classes that are one-of, but I was speaking more using an IFactory that would be in charge of creating new instances of similar classes. I just wasn't the exact time I should switch from a delegate factory to an IFactory. Well, besides when they share an interface.
I'd recommend looking into WPF (Windows Presentation Forms), it uses a language called XAML (eXtensible Application Markup Language) to build a user interface for programs with C# back-end. It's all built-in to Visual Studio and there's tons of tutorials online for everything involved so it's a good place to start.
I'm looking to create programs that contain alot of graphical stuff that the user sees or can create themselves.
FYI this is built into Visual Studio now, "Paste Special | JSON as Class" http://visuallylocated.com/post/2015/10/05/Creating-C-classes-from-JSON-%28or-XML%29-in-Visual-Studio-2015.aspx
There's also winforms. Much quicker to get going with, but it's a pain in the arse if you want to really change the look of the application from a standard windows fare.
You haven't answered my question there, which is why would you choose one and not the other. Since you decided not to answer it and just give an unhelpful reply, I thought about it a bit more and worked out the answer. For anyone reading this in the future, the reason is because if `something` is equal to true, then you want to return true. But if `something` is equal to false, you might well want to do something else before you return from the method. So you might have if(x &gt; 5) { return true; } // x wasn't &gt; 5, try something else if(y &gt; 5) { return true; } // neither x nor y were &gt; 5, so return false return false; 
The short answer is: no, they can't. The long answer is: they can't because it's not up to them. The bundle description is compiled into the bootstrapper by Wix Burn, and there's no way to swap it out programmatically (as far as I know). Besides, the bootstrapper probably also contains a lot of code that helps with the detection of existing components and the planning of the installation. Wix Burn has its own self-update procedure. It can query an RSS feed, download the new bootstrapper and launch it. That's probably exactly what the VS installer does.
Crusty Crab?
Hey thanks for your reaction, I don't completely understand what you mean by: &gt;If you want WPF/XAML/UWP, then I'd go Visual Studio. I'm mainly looking to create programs that contain alot of graphical stuff that the user sees or can create themselves. 
No, but I do know my target audience.
Honestly, I usually don't beyond making sure Swagger doesn't get confused. Ideally every one of my controller methods looks identical. All they do is extract the information I need from HttpContext and pass it along to the service class. Well, really there are three patterns: normal, file upload, and file download. Once you have a pattern that works, its really hard to screw up and I never see bugs there. 
Telerik Reporting FTW
Don't know, but that's worth trying. What I want to know is why it happens in the first place. Code that works fine for weeks all of a sudden starts exhibiting this behavior even though it hasn't been changed. 
Return codes are handled by throwing exceptions, which are converted by filters. This is far less error prone because you only have to do it once. Input checking I handle in the service class. My service classes are not tied to ASP.NET and often end up being repurposed in other things such as Windows Services running in the background. 
So you’re saying you have no clue what you’re talking about... Your questions seem to confuse technologies (WPF, etc.) from tools used to develop them (Visual Studio). I humbly suggest you do some Googling to distinguish the two before you try to do anything. 
I took some C# courses on edx that have been helpful — on mobile so I’ll post links later. Dev204.1 - Introduction to C# Dev204.2 - Object Oriented Programming in C# Dev204.3 - Algorithms and Data Structures in C# Dev258x - Data Access in C# and .NET Core Dev235x - Asynchronous Programming in C# and .NET Core Dev256x - Developing Data Client Applications and Services Dev250x - MVC Application Design using .NET CORE Dev247x - Build Web APIs using ASP.NET Goes from the basics to ASP.NET, ADO.NET and Entity Framework Core + MySQL. It’s a lot of time, but seems pretty close to what a standard web dev curriculum might look like from what I can tell. I’m still working through these (currently on Dev258x and Dev235x) but I’ve learned a lot!
As long as the graphics are 2D I found WinForms to be a lot easier, since you work with bitmaps (for image processing) I tried WPF years ago and ran into some issues. maybe I was just a WPF/XAML noob back then and didtn get the MVVM right
I’m sorry, am I confusing you? I must not know what I’m talking about, so I’ll stop now! 😫
I was just trying to inquire what the program is built on so he learns the right things. Fuck me right? I couldnt tell if he was trolling me, so he said he was gonna ask another friend who is in his first year of CS vs a multi year professional like me lmfao
That sounds like a nightmare of a request, probably gonna have to do COM interop maybe something like this? https://www.codeproject.com/Articles/15760/How-to-Integrate-Excel-in-a-Windows-Form-Applicati or this maybe? https://marketplace.visualstudio.com/items?itemName=VadimTagil.WinFormsExcelLibrary
Could you not launch a sort of bootstrapping app that would either open your app or message it if it is already open?
&gt;I thought about having the hyperlink launch the app and using command line arguments but I don't think that is the way I would like to go for security reasons as well as it would launch a new instance of the app every time. That's the way you would typically do this. Register a protocol handler with a custom scheme, your app will be launched when the user clicks a link, and then you can use IPC to inform an already running instance of your application to switch views or whatever. 
C# 5 Unleashed by Bart De Smet (2013). I spent some years as a consulting architect. Generally my job was to "fix" an existing architect's system. Of course, any change to an existing system is going to cause an argument with the architect that designed it. I kept this and a few other books in my car to use as a legitimizing aid to convince the architect I was assisting that X is a better way than Y. At every company I have used this book, I've lent it out, and most of the people who've looked at it ended up buying their own copy. It is exhaustive, and reading it cover to cover will give you both a solid fundamental understanding of how .net works, and a lot of advanced understanding as well (that you may or may not get a chance to use). It is not a recipe book; it is a book that explains what's going on. The author of the book is a brilliant programmer at Microsoft, and there is a lot of love evident in its pages.
I didn't hear about Jetbrains creating Rider recently, thanks for mentioning it. Seems interesting. 
I’d use Visual Studio 2017 Community to make Console Applications first.
And who, exactly, is forcing them to use that tech stack? Using Wix Burn cannot be a hard requirement, and if it is, then the requirements need to be changed. This is a solved problem in several other programs, and going "Update me!" "Update me first! BUT CLOSE THAT GUY!" is just plain user hostile.
It's frustrating when I don't know the correct tool for the job and hack something together. It's very rewarding to me when I find a much more elegant and simple solution using something I found googling or SOing. 
I wrote a cloud based licenser in Azure for floating license checkouts - Allowing clients to manage installs from a pool. It manages multi-client multi-app scenarios. In settings, it allows clients to go over the contracted number of seats, whereupon our contract stipulates any seats over the limit, they pay full retail for. I've been thinking to market it.
I really people would keep saying this. WPF is not harder then Winforms, it was 15 years ago, but these days the XAML editor is fine, and you can use just like Winforms with Event handlers. if you are starting today, use WPF. Don't bother with MVVM when you start, but start with WPF so you get a feeling of XAML (even if you are using the designer).
&gt; Also, you are being an armchair general over something that's very insignificant, yet hard to change. What if someone asked you "And you can't do blah blah blah? -_-" lol? are you serious?
any idea how long it will take for google search results to rank up the new docs instead of the old?
just a bit of feedback - PlayerInput = Console.ReadLine(); do `PlayerInput = Console.ReadLine().ToLower().Trim();` that way every input is lowercase and spaces (whitespace, enter, space, tab) are trimmed off
Oh im not questioning how hard it is :)
We do what we need to. Reporting is one of those business functions that every business needs, however the companies supplying reporting frameworks just haven't cracked the problem of one reporting system for every business. Power BI was the closest we got, but even that wasn't suitable for our problem domain, ergo we had to create ours from scratch.
&gt; And who, exactly, is forcing them to use that tech stack? Have you ever had the misfortune of installing Visual Studio 2015 or older? They use Wix Burn because *it works*. &gt;This is a solved problem in several other programs, and going "Update me!" "Update me first! BUT CLOSE THAT GUY!" is just plain user hostile. What problem? This is a mild inconvenience at worst. This is the *installer* we are talking about. Something that you don't see or use very often.
Infinte or recursive loop in main most likely. need code, FEED ME CODE!!!
Yes... Visual Studio is likely the best IDE to use when writing C# code for windows. You can write Console apps, winforms, WPF applications, services, asp sites, web-services... 
😂😂
&gt;&gt; And who, exactly, is forcing them to use that tech stack? &gt; Have you ever had the misfortune of installing Visual Studio 2015 or older? I have, several times. It wasn't as horrible as you seem to install. Your average windows installer. &gt; They use Wix Burn because *it works*. Except for the whole, it not actually being fit for the task part, you mean. &gt;&gt;This is a solved problem in several other programs, and going "Update me!" "Update me first! BUT CLOSE THAT GUY!" is just plain user hostile. &gt; What problem? This is a mild inconvenience at worst. And yet, the very topic of this thread. &gt; This is the *installer* we are talking about. Something that you don't see or use very often. I see it far more often than should be necessary. Updating Visual Studio should not include two separate programs that both need to download several hundred megabytes and update, when it can be solved using a single background operation and a restart of VS. This is simply bad design.
I'm afraid he is. Changing difficult things is sorta in the job description of a software developer. Not to mention one working at one of the largest software companies in the world.
Straight old ADO.NET and parameterized queries or stored procs work fine, you just have to hydrate your objects yourself. In other words, MVC isn't depended on any ORM or type of persistence layer.
Sigh way to miss the point. The class is just a stub to help you test httpcontext in your code. I'm not proving that it does anything, just a setup. You are reading way to hard into it. But to each his own. Have a good day. 
Check out SQLite - https://system.data.sqlite.org/index.html/doc/trunk/www/index.wiki then try to google some tutorials that use this C# wrapper over the SQLite api
Minor correction, but WPF stands for Windows Presentation Foundation.
Yep I'm always worried that my implementation is inefficient or straight up bad practices. Makes me wonder how do people learn this stuff Pre SO days.
It does indeed and now I feel like a fool ._. Corrected the comment, cheers.
Learned something new, thanks!
I also failed to mention VS Code which is similar in scope to Rider.
Interesting. If you can share, put it up online somewhere and I'll a look.
VS Code is pretty nice, it's come a long way development wise too. I use it a lot. 
You must be delusional to think that there isn't anything more important to do than shaving 10 seconds off your update procedure.
&gt; I have, several times. It wasn't as horrible as you seem to install. Your average windows installer. Except it was a major source of pain for Microsoft's customers, hence the rewrite of the installer. &gt;Except for the whole, it not actually being fit for the task part, you mean. It installs, updates and removes Visual Studio much better than the old installer. How is it not fit for the task? &gt;And yet, the very topic of this thread. A mild inconvenience is not a problem. There are hundreds of issues with Visual Studio and still many issues with the installer, some of which may cause irreversible damage to the operating system. And as far as inconveniences go, this is a very small one in comparison to some of the UI issues with VS itself. Visual Studio isn't a compact portable Electron application. It can't be installed with a single msi. It includes hundreds of SDKs and other components which have to be installed system-wide. If you could point me in the direction of an alternative to Wix, I would be very grateful because that means I would be able to abandon my custom bootstrapper. &gt; I see it far more often than should be necessary. Updating Visual Studio should not include two separate programs that both need to download several hundred megabytes and update, when it can be solved using a single background operation and a restart of VS. &gt; This is simply bad design. Why not? The average customer will spend at most 5 minutes updating the installer during the whole product lifetime. Do you know how much it would cost to make it do restart-less updates?
Thanks!
I think VS itself is wpf, but the services handling extensions, updates etc. are done in node.
At which point did I claim that?
Sounds good to me! Should post it on bitbucket. And make a ConcurrentSafeDictionary 
&gt; If this project is going to grow into something bigger going forward or you want to make it more maintainable in the long run I would strongly suggest investigating the Page Object Model pattern. Nice suggestion, took me a little to get around it. Thanks for the suggestion :)
Line 107, replace "VOWELS" with "VERBS". Line 111, replace "NOWNS" with "NOUNS".
godly immortal brain: &gt; if (character.Equals(' ') != true)
I've heard something about XAML being close related to XML but I've never heard about the other two. Going to look up what everything means tomorrow when I've more time. 
Thanks for your reaction, tomorrow I'm going to look it up.
Thank you. It hurts my brain how I didn't see that mistake before.
Tomorrow I'm going to look up all these terms since I have no clue what you're talking about to be honest. I've only heard something about XAML before. The only thing I know now is that I'm interested in making programs that will contain alot of graphical stuff (2D). 
save it as a bitmap and render it as a bitmap? https://msdn.microsoft.com/en-us/library/system.drawing.bitmap(v=vs.110).aspx i mean you can always set up the file to not be binary at all, and make it like a `.ini` or config file looks like you are using winforms so you can look into this as well: to save the user's choice of an avatar and have it persist across launches of your quiz program - https://docs.microsoft.com/en-us/dotnet/framework/winforms/advanced/how-to-write-user-settings-at-run-time-with-csharp
&gt; Is there a reason your're recommending VS17 instead of an older version of VS? No, but there isn't any reason that I am aware of why one shouldn't use the latest VS. It comes with the latest .NET framework and other nifty tools that may or may not be available to older studios.
Good for you! Server side paging/sorting and filtering is a great example of where ORMs won't work well. Keep it up! SQL will serve you well!
&gt; armchair general Never heard that term before, but I love it! Also, that's not what I'm doing. I'm 100% confident that just about everyone on the VS team is a much better developer than I am. I'm just trying to understand the logic. &gt; how inconvenient Wix Burn's API is Is it that good that it's worth using even if it is that much of a hassle?
DB2 installer. Oracle installer. Jeeeezus help us :)
The fundamental problem is this. Your business logic ends up being split between the database and your application layer. You also end up with complex relationships between stored procedures, views and god forbid triggers. Your application is then fragile as you loose some of your strong typing. And the real kicker is that it is near impossible to refactor out the stored procedures as your business logic as previously mentioned ends up all over the place and you will end up having to create duplicates of existing sub sections in order to refactor out the store procedures which will then get out of sync and create all sorts of interesting bugs. Attempting to isolate these sub-sections and refactor them is also near impossibly due to the cyclic dependencies hidden away in the views and store procedures... While you might argue if you keep it simple and use a REST like approach to your store procedures... Congratulations, you have great intentions! The next developer won't understand the complexity and will start throwing everything bar the kitchen sink in where ever is easiest for them. Ask me how I know :)
I wish this functionality was built in VS2017
Learning how to search for answers to problems is a [really valuable skill](http://www.lmgtfy.com/?q=c+sharp+string+format+specifiers).
lowercase hex vs uppercase hex
thanks for nothing
thank you
Question: How long have you been using C#? It seems like you're need a bit more practice before delving into stuff like JSON.
Woah, that's pretty cool. I'll have to keep that in mind, I also can't believe I never knew about that.
I highly recommend that you make your service classes stateless and thread-safe. For most applications, I only have one instance of any given service class. 
Don't be so entitles. No-one owes you anything. It's not nothing - I demonstrated that forming a **relevant** search query is a useful skill that can often lead you directly to an answer. 
[Brackey's](https://www.youtube.com/watch?v=pSiIHe2uZ2w)
It is nothing. Do you think I have not already done that? Read the post jack ass.
Insults? OK you entitled shit head. The first result leads to the page that show you exactly what %x an %X specifiers do with examples. If you're too dumb to understand the page then you should just give up on the course and programming, its obviously not for you. 
no response? YEAH THATS WHAT I THOUGHT. if you do not have any helpful information do not comment. thanks
For free, you can try Microsoft's MVA and Channel 9 or go with Pluralsight, with courses by Scott Allen (C# &amp; Asp.Net), Shawn Wildermuth (Asp.Net Core), Julie Lerman (Entity Framework) and, last but not least, Jon Skeet.
Yeah this isn't so much marking the answer (per the OP) as it is marking the ability to find it, which is far more important.
So I searched what is the difference between %x and %X format specifiers essentially. and two that website definitely does NOT have the answer so screw you too 
What were the **exact** search terms you used? And his link will, after the automated Google search completed, have "Standard Numeric Format Strings | Microsoft Docs" at least on the first page. And that page does have the answer to your question. &gt; so screw you too Please grow up. People are trying to help you, and you're being rude to them, just because they don't present the answer to your question on a silver plate.
Looks like someone isn't getting help then. Well done. :)
Asp.net is a framework for doing things. C# is a language of building things. One supersedes the other. 
Серега, дай ключик бесплатно
Oh fudge, I didn't realize! 
First off all, switching to C# from C++ can be quite easy. Most of the resources you’ll need can be found on MSDN, that is one thing I love in C# - Microsoft did a very well job in documenting! Also, consider using a book, because C# 7 evolved to a incredible powerful, but extensive language. You really need some overview to really be able to fully arbitrage C# 7. Maybe you want to rewrite one of your C++ projects, to get to know C# basics and then you can progressively implement C# specific patterns. Some online resources: [C# for C++ programmers - by MSDN, 2005](https://www.microsoft.com/en-us/download/details.aspx?id=55984) - you probably found that one already, and yes the language has drastically improven since 2005 (was C# 2, now we are at C# 7), but its still a good comparison to start off with. Just keep in mind, that many things, where C++ outbid C# back in 2005 are now resolved. [C# for C++ programmers - by MSDN, 2008](https://msdn.microsoft.com/en-us/library/yyaad03b.aspx) - quite the same, just compring with C# 3 now. [Unsafe Code and Pointers - by MSDN, 2015](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/unsafe-code-pointers/index) - coming from C++, this is probably very important to know. [MicroSoft Developer Network](https://msdn.microsoft.com/en-us) - that is really all you need. Look up things here, its a very good way to start off in C#.
I wrote a library https://github.com/mcintyre321/OneOf (it's on Nuget too) which does a pretty nice job retrofitting them.
FWIW DiscU is a fork from my project [OneOf](https://github.com/mcintyre321/OneOf) which adds some options for defaulting when a value isn't met e.g. `.Else(somevalue)` and uses fluent methods for doing Match (rather than parameter increases). I'm not a fan of those changes - they mean that code which consume the OneOf's won't always raise a compile error when an additional Type is added to the union, which for me is they key strength.
Have your even bothered to search? https://www.pluralsight.com/blog/it-ops/learning-path-web-application-development-with-asp-net-mvc5
Should be required reading for all new C# developers
Yes. I despair a little every time I see someone generalise a solution by putting code into configuration. There are cases where it's really useful but so many risks for the inexperienced :) 
Thought I'd put the answer here for anyone else that comes across it. I got this working after a *lot* of Googling and experimenting! Step 1 - create a new class, I called it `UserValidatorDeDup`. It inherits from the `UserValidator` class, and overrides the `ValidateAsync` method. You can see the code [here](https://pastebin.com/8xWTPUy6) - it's based on Microsoft's code, which you can see [here](https://raw.githubusercontent.com/aspnet/Identity/dev/src/Core/UserValidator.cs). Step 2 - in the `App_Start` folder, in the `IdentityConfig.cs` file, modify the `ApplicationUserManager` class's `Create()` method as follows (I've left the old code here, commented out, so you can see where the new code goes): // Configure validation logic for usernames //manager.UserValidator = new UserValidator&lt;ApplicationUser&gt;(manager) //{ // AllowOnlyAlphanumericUserNames = false, // RequireUniqueEmail = true //}; manager.UserValidator = new UserValidatorDeDup(manager); And then it should work!
Good point, although it doesn't actually address the problem. I've actually got it working the way I want now - see my other post for the solution.
I don't know where this could be useful. I use F3 to select the next thing searched, and there are other shortcuts to do more or less the same thing. Maybe i'm missing something? 
Having gone through the exercise of parsing strings into expressions, I really appreciate the simplicity of this technique. 
You can compare strings using the supplied `Equals` method.
No errors yet, thanks a lot :D Now I have to come up with something in order to select one particularly file.
You can just write/paste the code, then highlight it and press the code button. Reddit uses a fairly common form of Markdown.
Please don't create interfaces for every type. The code base will become very hard to navigate. Also it becomes hard to refactor as the interface types become entrenched seams which you can't use things like 'inline method' against.
Oh god, this decade started in 2010...
 I'd just build an external DSL (with syntax and semantics specifically designed for any domain expert to understand) and parse it with some parser combinator or PEG.
There's a code button?? Do tell :) 
Any time i see Mark's book, i upvote. Regardless of it's coverage of dependency injection (which is phenomenal), the book is a really good survey of object oriented design and SOLID principles. Worth the read even if your not interested in DI.
Get your hands on a copy of C# in a Nutshell, it's an excellent reference book. Also look into interfaces, LINQ, and attributes to get started. As you probably learned with C++, the best way to learn is to do, so maybe try rebuilding some of your existing projects in C#.
Wouldn't [Dynamic LINQ](https://weblogs.asp.net/scottgu/dynamic-linq-part-1-using-the-linq-dynamic-query-library) be a better choice here?
Can you please elaborate on some advantages of that over Roslyn? From my perspective, I appreciate that Roslyn lets me write true C# that, AFAIK, gets the same optimizations (within reason) that I would get if I wrote the expression in my own app code (less one-time parsing cost that both solutions share, of course).
&gt; it's several orders of magnitude more work Yes, I agree it's more work, however: * You can have full control over the syntax and semantics * You can evolve the language to meet new requirements * You can provide insightful error messages (this is f*cking valuable because non-programmers will use your language) I had the oportunity to build an external DSL in the previous company I worked for. Business managers and accountants would use this language so it had to have easy syntax and to provide really insightful error messages. I created a fully declarative language which is parsed with a LL parser and interpreted with interpreter pattern (the GoF one). I'm myself proud of the result and I think our customers are happy with it. That said, I understand that sometimes it may not be the best solution, but I'd be reluctant to not construct my own language if I ever face this problem again.
And introducing a potential attack vector to execute code
It's been awhile since I've done anything in ASP.NET MVC (like 7 years ago), although I *am* reading up on it again, so I thought I'd dive in again... ;) Sorry I wasn't more helpful. Anyway, yeah, your solution reminds me of one that I had to come up with then to override an existing `OnActionExecuted` method in order to build a dynamic menu system based on the type and permissions the user had. It was actually pretty slick. But yeah: `inheritance`, FTW! 
Update: after tinkering around, and finding SharpGenTools quite nice, one thing prevents me from using it: The ability to retain per-method comments from the original source, and then re-output them when writing out the C# classes. It appears that CastXML does support a pre-processor step that retains comments via -fcomment-block-commands=&lt;arg&gt; but those comments don't aren't emitted in the XML output. I think it would be possible to write a quick parser against the pre-process CastXML output, but for now I'll need to keep what I've got.
Short answer: client-side (javascript?). Long answer (at least on your part :) ) - do read up on [lifecycle of an ASP.NET page](https://msdn.microsoft.com/en-us/library/ms178472.aspx?f=255&amp;MSPPError=-2147217396), you seem to have completely confused how this works (not criticizing, stating a fact).
1. It's a much simpler language. I think especially the chance it will get abused is much smaller than full C#. 2. I think Dynamic LINQ uses Expression Trees, so there should be no issues with insufficiently optimized code. 3. The one-time parsing cost of Roslyn is high. I think that this would make Dynamic LINQ significantly faster.
All conditional expressions must evaluate/resolve to a boolean value. However, in VB.NET, you can turn off some settings (Option Strict, I think?) and certain things can evaluate to a boolean implicitly (this pisses me off to no end, btw). But that is VB, not C#! Anyway, you just need to "translate" what you want to do into a boolean expression. You can do that many ways with strings: if (myPath == @"C\path\to\file1.docx") { //you now know the path is pointing to file1.docx } else { //other path, assuming there are only two possible paths } or... bool usingFirstPath = (myPath == @"C:\path\to\file1.docx"); if (usingFirstPath) { //do stuff for first file } else { //do stuff for second file } I usually prefer the former but the latter is useful when there might be multiple if-blocks that need to know the result of the same condition.
Or...you know....don't introduce a bunch of bad design into your application. Really the actual solution is to throw all your data access behind a repository interface so you can have this internal debate about stored procs vs ORMs all day long, but as long as your repository is returning model objects the right way, no view will give a shit.
One use case is tenant in subdomain, you can see example here https://github.com/mariuszkerl/AspNetCoreSubdomain/wiki/Multitenancy-in-subdomain
What if someone creates `Process.Start("deltree /y c:\");` as an "expression"? Wouldn't you need to run these scripts in an AppDomain?
I'm pretty sure it does catch that case. Can you create a reprocess of such a case so we can fix it?
&gt; I'm just trying to understand the logic. That's great! However, I think you should be a little bit more careful with wording your questions, because they can be misinterpreted as you being an arm-chair general. &gt; Is it that good that it's worth using even if it is that much of a hassle? Unfortunately, there's no better alternative that I know of. So it's either Wix or something worse. There's InstallShield, but I'm not familiar with it (it's way too expensive) and I am not sure how customisable it is. Also, Microsoft probably wants to dogfood.
Removed: Rule 4. If you want it to be cross-platform and run on both Windows desktop and Android, maybe check out Unity3D.
Thanks for trying it out! I’ll put being able to pull comments from the original source on the backlog! If you were interested, you could develop a doc provider to pull docs from the source and plug it into the build in the meantime (the built in MsdnProvider hooks in to pull docs from the MSDN service instead of source). I’m working on documentation now so I don’t think that feature will make it into 1.0.0.
You're basically done already with the small snippet you wrote. Something like: bool canAdd = true; foreach (Zebra z in zebras) { if (z.id == ???) { canAdd = false; break; } } if (canAdd) { // Code to add zebra to list } This seems like the best way that I know of, however I'm not the most experienced programmer in the world so there could be a better method.
I recommend C# in a nutshell (anything past C#5 is fine if you want to save money) There are only like 2 or 3 chapters on "coding in C#", rest is what is IN the .NET Framework that you can leverage. another thing is just develop some WinForm or WPF apps and use tutorials and the likes to learn. or ASP MVC 5+ apps for web development if you wanna learn that. start small, like simple apps like a pizza store, a NFL team database, etc
Different names +1
why not just make a predicate and use that instead??? something like this private static Predicate&lt;Food&gt; ActiveFilter { get { return f =&gt; f.IsFresh &amp;&amp; f.ShelfDate&lt; DateTime.Now; } } usage return foodDB.Where(f =&gt; ActiveFilter(f));
If you want to handle checking if it exists in the add method, you can do something like this: public class ZebraCollection { private Dictionary&lt;int, Zebra&gt; Zebras { get; set; } = new Dictionary&lt;int, Zebra&gt;(); //example of an indexer -- you don't really //need this to accomplish what you need public Zebra this[int key] { get { return (Zebras.ContainsKey(key)) ?? Zebras[key] : null; } set { Zebras[key] = value; //or... //If (Zebras.ContainsKey(key)) //{ // throw new Exception($"The key '{key}' already exists in the collection"); //cant remember the name of the dictionary exception for duplicate keys but you should use that instead of Exception //} //else //{ // Zebras.Add(key, value); //} } } public void Add(int key, Zebra zebra) { if (Zebras.ContainsKey(key)) { //handle this how you want } else { this[key] = zebra; //or... //Zebras.Add(key, zebra); } } } Usage: var zebras = new ZebraCollection(); zebras[7] = new Zebra(); zebras.Add(8, new Zebra()); //etc. The indexer isn't required for this. The takeaway is to create a class that encapsulates a `Dictionary&lt;int, Zebra&gt;` and exposes an `Add` method that uses the `ContainsKey` method to check if the zebra object already exists. I added the indexer for funsies. Peace.
Thanks for sharing your knowledge.
put an if statement in your second foreach also consider just flattening the directory, then set a whitelist of files to keep (which is what you are trying to do) https://msdn.microsoft.com/en-us/library/ms143314(v=vs.110).aspx