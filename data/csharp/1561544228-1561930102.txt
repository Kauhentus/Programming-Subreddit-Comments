The machine isn't object oriented, it's just one of all the abstractions invented to make program code more organized in the mind of humans. It has fallen out of favor in later years and many languages use multiple abstractions anyway. Don't fall into the trap of the course literature on OOD. It's mostly useless. Look at real world frameworks and get a feel for what things go in a class. And as others say, don't be afraid to break principles (when learning). Everyone does.
Thanks, I'll try it now :)
Thank you for the response! I will try out dabcabc's suggestion first, using SkiaSharp. If it doesn't work, I'll try out Sharp Vectors.
This is the major cause of headaches with INotify.. If you aren't stringent about subscribing/unsubscribing you end up with dead objects notifying/being notified and possibly mem leaks.
INPC spaghetti is real.
You should consider using [`Input.GetAxis`](https://docs.unity3d.com/ScriptReference/Input.GetAxis.html) if applicable.
I'm not sure if you are joking, or just don't know, but you can use it anyway: [https://stackoverflow.com/questions/51498896/use-httpclientfactory-from-net-4-6-2](https://stackoverflow.com/questions/51498896/use-httpclientfactory-from-net-4-6-2)
There's nothing inherently different between a DLL you've referenced at compile time, and a DLL that you've chucked in alongside your application after it was compiled, or even pulled from a Stream (eg as mentioned - from a database or other network location). Reflection is really a way of allowing code to inspect itself or other code - like using a mirror to brush your hair or see something on your forehead. You don't (strictly speaking) need Reflection, but it makes things easier when dealing with .NET assemblies. For instance, if you have a photo library application and you want to include support for viewing photos of different filetypes, you could implement an interface that defines that functionality - say IImageDecoder. You ship your application with a bunch of classes which implement IImageDecoder - say for JPEG and PNG. - all good. But then someone wants the application to have an image decoder for, say Photoshop files. That's fine, but you don't want to write it - instead, you tell them to just implement the IImageDecoder interface and drop the compiled assembly and all it's dependencies in the 'plugins' directory. You would then modify your application to look for .dll's in the plugins directory, load them using Assembly, scan them for any type that was implementing IImageDecoder and instantiate those classes. From that point on, as far as your application is concerned - there's no difference between the code you wrote, and the code that someone else added later. This post is already long enough, but if you want a short example of what I mean by all this, let me know.
I def got the idea through this post. But yeah, I wouldn't say no to an example.
On a side note I am super annoyed that [DoesNotReturnWhenNull(nameof(parameter))] is now "open question".
Come on mate you should be able to tell from the content of this post that this is all new for me
Removed: Rule 4. Please include the relevant code you have, and the exact error message and line/location it's being reported on.
This is absolutely not the right way to ask for help. You need to describe what the problem is and where in your code you're getting this particular error. Paste in some code to show what you've written, and maybe what you've tried to do to debug the error. "Parameter not valid" is so generic it's useless without context. We aren't here to solve your problems for you, especially if you haven't shown any effort in a) showing some code that will help give people an idea of what you're trying to do and why your code is broken and b) writing a good question.
Sorry, didn't realize this
If I had to guess, the path to the bitmap isn't where you think it is. First, [use the debugger](https://docs.microsoft.com/en-us/visualstudio/debugger/using-breakpoints?view=vs-2019) or log out the value of `@"..\..\" + dr["Student_image"].ToString()`. Perhaps it's not the value you expect it to be. If it is the correct path, then perhaps your assumption about the relative paths are incorrect. If I recall correctly, the default folder path will be your compiled exe's location (which might be something like "C:\blah\blah\blah\YOUR_PROJECT_DIRECTORY\bin\x64\Debug\YOUR_PROJECT.exe" So, you'll have to correct your relative paths for that, or provide an absolute path, or something else to fix your paths.
Ok, so I haven't compiled this to ensure it actually works but it should be pretty close. Also, to be clear - this is far from good code - I threw it together in a few minutes, it doesn't handle exceptions or any number of other issues. If you wanted to do this for real - there's a whole Addin and Extensibility model that's supported in .NET, and many IOC frameworks will do this for you too. Anyhow, you've been warned... Lets assume you have two projects - ImageViewer.Plugins, which is a class library, and ImageViewer which contains your application code, etc. Here's the two interfaces you'd need in your ImageViewer.Plugins library public interface IImageDecoder { bool IsFiletypeSupported(string filename); IDecodedImage OpenImage(string filename, Stream imageStream); } public interface IDecodedImage { // placeholder interface, for completeness sake } and then the code for your main project public class JpegImageDecoder : IImageDecoder { bool IsFiletypeSupported(string filename) { return Path.GetExtension(filename).Equals("jpg", StringComparison.InvariantCultureIgnoreCase); } IDecodedImage OpenImage(string filename, Stream imageStream) { // do whatever is necessary to open the file and return a type that implements IDecodedImage } } public class ImageDecodeManager { List&lt;IImageDecoders&gt; _decoders = new List&lt;IImageDecoders&gt;(); public ImageViewer() { // load up the decoders we ship with _decoders.Add(new JpegImageDecoder()); } public IImageDecoder FindImageDecoderForFile(string filename) { foreach(var decoder in _decoders) { if (decoder.IsFiletypeSupported(filename)) { return decoder; } } // Unable to find a decoder for the given file return null; } public void LoadPluginsFromPath(string pluginPath) { // find any .dll's and try and load them var pluginDirectory = new DirectoryInfo(pluginPath); var dlls = pluginDirectory.GetFiles("*.dll"); // Load each one. foreach(var dll in dlls) { var assembly = Assembly.LoadFile(dll.FullName); LoadDecoders(assembly); } } public void LoadDecoders(Assembly assembly) { // find all the types in the assembly that implement IImageDecoder var types = assembly .SelectMany(a=&gt;a.GetTypes()) .Where(t=&gt; typeof(IImageDeocder).IsAssignableFrom(t) &amp;&amp; !t.IsInterface &amp;&amp; !t.IsAbstract) .ToList(); // construct each of them foreach(var type in types) { var ctor = type.GetConstructor(BindingFlags.Instance | BindingFlags.Public, null, CallingConventions.HasThis, null, null); if (ctor == null) { // Has no public default constructor continue; } // Construct the actual class IImageDecoder instance = (IImageDecoder)ctor.Invoke(null); _decoders.Add(instance); } } } Now, your application would load up the ImageDecodeManager and tell it where the plugin path is, and you can then start decoding images... var decodeManager = new ImageDecodeManager(); decodeManager.LoadPluginsFromPath(@"c:\imageviewer\plugins\"); var jpgDecoder = decodeManager.FindImageDecoderForFile(@"c:\temp\foo.jpg"); var psdDecoder = decodeManager.FindImageDecoderForFile(@"c:\temp\foo.psd"); // returns null if there's no PSD decoder registered. As you can see, to the code at the end, it's no different to dealing with already existing code. Infact, to be clear - the JpgDecoder class could be in it's own seperate assembly too - this would let someone swap out a better JpegDecoder (maybe a bug fix, or faster, or whatever) This is just showing you loading plugins and calling code from .NET assemblies. There's no reason you can't call code written in other languages, too - it's just a bit more difficult and involves a whole lot more code.
Do a sanity check on the path. Ditch building the bitmap path and put a full hardcoded path to the image file. For example @"C:\path\to\image.jpg". Try running again and see if it works. If it doesn't, try running the program in administration mode/privileges. If it does work, then you know you have to fix the way you construct your paths or deploy your images with your program. If it doesn't work, try making a simple program without the datagrid that just displays the image. Get that working then see if you can apply it to this datagrid.
I have Tried the Above but it is compulsory for me to use Bitmap
Did the above work, though? &amp;#x200B; You need to take small steps to figure out where you went wrong. &amp;#x200B; I would try using the Path.GetFullPath() method to get an absolute path to the image based on your string above, then I might pass that path into the File.Exists() method to ensure that the file is there before I try to load it into the Bitmap class.
Other compiled assemblies (DLLs) that were not present when your own program was compiled can be loaded at runtime (Assembly.Load). Reflections is how your program can discover the compiled types and methods in those assemblies. The type information was not available at the time you compiled your program yet your program can still “new” an class discovered using reflections and your program can “dynamically invoke” the methods from that class that were also discovered using reflections. Realistically, you should try to avoid using reflections if you can use interfaces in a shared assembly instead. It’s much less likely to go wrong and much easier to debug. To answer your second question, it is even possible to generate new code at runtime. System.Reflections.Emit can build new code at runtime. Code has to be written directly as MSIL, not C#. Alternatively, you can emit C# using code dom, compile it at runtime, and then load the result using Assembly.Load. There is also the new C# script option (CSX) made possible by the new Roslyn compiler. If you host a CSX interpreter in your program you could, in effect, dynamically run C# code directly at runtime. There are lots of options to dynamically add “new code” to an already running application. You’re right - the code has to be compiled to run. In some cases that all happens under the hood hidden away from you. That’s how CSX works.
Are you returning one row and one column in your query, or is it one row with multiple columns? Execute Scalar is expecting something like a row count, a literal single value.
You can do a lot with Unity without relying on the visual representation, particularly now that Unity is developing an [entity component system](https://docs.unity3d.com/Packages/com.unity.entities@0.0/manual/index.html). It's quite interesting, very useful in game development, and highly performant. Not convinced the paradigm is SOLID though.
It seems to me that it would have just made things so much simpler if they implemented non-nullable reference types. String! foo; Then added a compiler switch to bring its syntax inline with nullable and non-nullable value types, by switching `String` to `String!` and `String?` to `String`. That would have meant existing parameters and return types would already be appropriately marked, and we wouldn't have nullables being such a softly enforced thing.
The purpose of the interface is to define that the type has a certain interface. So if your circle and square are each an IDrawable with an Draw method, you could keep a list of them and call Draw on each in a loop. That said, I don't really get why it would be the responsibility of a square to draw something.
Did you check if the exception has an InnerException?
The idea isn't to save you from declaring the methods in each individual class. It's to allow your program to have loosely coupled code (code where one class isn't reliant on another class). An ideal solution would be that the class that calls the Draw() or Erase() method doesnt know what shape class is being used. Making it far easier to upgrade your program with new shapes like a triangle class. That make sense?
maybe it's a poor example, I'm struggling with this concept. In python, I can have multiple inheritances and even then with a single inheritance I can simply overwrite a method if I need to change something for a specific class.
Interfaces are really useful for programming to an abstraction. By that I mean that you program your code in a way that's least-specific as possible. So say you have a method that takes in a shape object, such as: public void Draw(Square square) { } This method will only ever work with a square. But say you want to also draw a circle, you would need to create an overloaded method, such as: public void Draw(Circle circle) { } However, if both your classes implement the IShape interface (i.e. **public class Square : IShape** and **public class Circle : IShape**) then you can have a single method like so: public void Draw(IShape shape) { } You can now pass in any class that implements IShape and it's easily extensible because if you want to draw more shapes (like triangle, rectangle, etc) then those classes simply need to implement IShape and your Draw method will accept them without any changes to existing code.
"allow your program to have loosely coupled code" so it isn't reliant on another class... If you declare the method in each individual class, it accomplishes the same thing. I realize my example is prob a poor one. OOP was difficult to grasp at first but the more I coded, the more it made sense. Inheritance makes sense. Interfaces don't. I don't know if it will click suddenly... but the videos I've watched all have the same glaring issue in their explanations. Interfaces are there to allow each class to have their own methods that aren't dependent on other classes. That's great. But you accomplish the same thing by making the method native to that individual class and thanks to namespaces you can have a draw method in two different classes. Like I said, just having serious trouble wrapping my head around why this is a thing? where would you use it? What's the benefit over say declaring and implementing the methods to each class?
I... very much like that idea. Find your way out of a spooky mine or cave, with no light, relying on sound cues.
One good example, let's say we have two shapes (square and circle), both have the Draw method. And we will have the IDrawable interface, that will tell, that any instance which implements that interface will have an implementation for Draw. interface IDrawable { void Draw(Canvas canvas) } class Square : IDrawable { //Maybe other properties too public void Draw(Canvas canvas) { //implementation for drawing the square on canvas } } class Circle : IDrawable { //Maybe other properties too public void Draw(Canvas canvas) { //implementation for drawing the circle on canvas } } Now, let's imagine you will have a method that will prepare the canvas and everything, and all that needs is the shape that will be drawn. You can overload the method with each parameter of the shapes you need, or you can expect just an object (a shape) that will have the Draw method, something like this. &amp;#x200B; public void DrawShape(IDrawable shape) { var canvas = new Canvas(); shape.Draw(canvas); } public void Main() { var shape1 = new Square(); var shape2 = new Circle(); DrawShape(shape1); DrawShape(shape2); } This is an example which takes advantage of interfaces into polymorphism. &amp;#x200B; However, as **Mr\_Cochese** said, the shape shouldn't implement IDrawable interface, it's not the responsibility of the shape to draw itself.
That makes perfect sense. However, when you declare it in the interface you have IShape interface public void Draw(IShape shape){} then in the square class you have public void Draw(square square) { drawing code } and in the circle class you have public void Draw(circle circle) { draw code } That's basically every example I've seen. It just seems horribly redundant without any benefits. According to docs.microsoft.com - "Any class or struct that implements the" IShape "interface must contain a definition for a" draw "method that matches the signature that the interface specifies. As a result you can count on a class that implements" IShape "to contain a" draw " method with which an instance of the class can determine whether it's equal to another instance of the same class." it goes on to talk about the properties of interfaces and how to put them into code. That part I understand. I can type the syntax. I can use it as it is exampled on the page and in my text book. I don't have the foggiest when to implement it or what good it does. Right now it feels like it's the most cumbersome and clunky thing that doesn't have a use.
For small scale stuff it doesn't make sense to use Interfaces. It's more for large scale products where it is expected to be updates / upgrades to the system after it's gone live. It was described to me as Interface is like a Manager. They don't care on the specifics, they just know only to tell 'something' to Draw(). Again, using interfaces small scale doesn't matter much, but large scale with numerous devs working on it. It makes upgrades far easier to implement.
I may have used a poor example. I was just trying to show how an interface (IShape) can be passed as a parameter instead of concrete types (Square, Circle, Rectangle, Triangle, etc). That allows you to write more loosely-coupled code which will save you down the line. Also, C# doesn't allow you to inherit from multiple classes, whereas you can implement multiple interfaces. So if you have a class such as Cellphone, you could inherit from class Device and pass around Device as a parameter like with IShape. However, if you want your class to inherit properties/methods from multiple classes you would need to use interfaces.
I very much prefer the term "contract" to "blueprint". Think of it this way, we have an interface name "IShape", and that interface defines two methods that you are contractually obligated to implement. Which is "Draw" and "Erase". If you don't implement these methods you break the contract and the application won't compile. So when you create the "Circle" class and implement the IShape interface, you have to implement those two methods. That concrete implementation will be specific to the "Circle" class and may differ from the implementation in the "Square" class. And the reason we have that IShape interface is so that when you have a method to handle shapes, you don't have to worry about the kind of shape you're working with. Whether it's a circle or a square. You just know that it's a shape and it implements the IShape interface. Which means you know that it can draw and erase and you can call those methods and that they'll work for whatever type of shape is passed in.
Check out the Pluralsight course C# Interfaces. It will explain everything you need to know.
When you get to advanced programming, you find yourself using them everywhere. Just a really quick example, a data store. `public interface IWidgetStore` `{` `void StoreWidget(Widget widget);` `Widget GetWidgetById(int widgetId);` `}` Now I might have some code that works with widgets. It needs a place to store these widgets. It doesn't care where - could be a database, could be the file system, whatever. All it cares about is that you give it something that can get and store widgets. That's it. `public class WidgetWorker` `{` `private IWidgetStore widgetStore;` `public WidgetWorker(IWidgetStore widgetStore)` `{` `this.widgetStore = widgetStore;` `}` `public DoSomethingWithAWidget(int widgetId)` `{` `var widget = this.widgetStore.GetWidgetById(widgetId);` `// [Do something with the widget]` `this.widgetSotre.StoreWidget()widget;` `}` `}` I can then create multiple things that implement IWidgetStore. In my Live environment, this might be a database. But when I'm running tests, I might just store them in memory. I can just switch out implementations without ever having to touch the code. It makes the calling code as independent from the implementation as possible. It doesn't depend on any particular widget store. It doesn't care what the widget store is doing or how. The only things it needs are the Get and Store methods.
I'm wonder if it's the static typing that is throwing you. In Python you use dynamic/duck typing. You can pass any object into any function/method and so long as it has the attributes and methods required it will work. If it doesn't you will get an error. The classic duck typing example is; class duck: def speak(): print("quack") class dog: def speak(): print("woof") def talk(animal): animal.speak() C# requires that you declare the type of all variables, including method arguments. This lets you know ahead of time that you won't get any errors from properties/methods not existing. In C#, these two methods are different due to the differences in their signatures; public void talk(Dog animal) { return animal.speak(); } public void talk(Duck animal) { return animal.speak(); } We generally want to avoid having to write all of these explicitly. Instead we want to work out groupings of classes that we can treat interchangeable within certain situations. In this case we can define an interface that requires a class implement a `speak` method like so; interface ITalker() { void speak(); } And re-write the `talk` methods to a single version; public void talk(ITalker animal) { return animal.speak(); } Now any class that implements the `ITalker` interface (by having a `speak` method and explicitly stating it implements it) can be used within this function. This is an obviously trivial example. This gets much more powerful in complex systems.
Wouldn't that be late binding, not reflection?
As far as I know entity validation is when you try and add or update an entity. So like if a required property isn't set. And I would assume the anti forgery one is invalid anti forgery token on a request. It might just be that the new server reports them and the old one didn't.
This is really not a good demonstration of the utility of interfaces. It demonstrates the utility of abstraction, though.
Add some controller vibration when you collide with a wall, or maybe even a "ugh!" from the character, add some voice lines to help navigating ("I think I've been to this place before", "this sound, is that a river?") &amp;#x200B; Man, I am all worked up to cook something like this one day!
&gt; Another question is what happens when the type is nullable (int?) but the null check is desired. If supported, this may result in an contradiction in the signature (void Insert(int?! i)). Why would you accept a nullable value if the first thing you do is validate it's not null? I don't understand this use case.
They are coded outside of start() and update() actually. Yeah, those codes are for moving a ping pong pad. using System.Collections; using System.Collections.Generic; using UnityEngine; //I edited ping pong game from https://www.awesomeincu.com/tutorials/unity-pong/ public class PlayerControls : MonoBehaviour { public KeyCode moveUp = KeyCode.UpArrow; public KeyCode moveDown = KeyCode.DownArrow; public float speed = 10.0f; public float boundY = 2.25f; private Rigidbody2D rb2d; // Use this for initialization void Start() { rb2d = GetComponent&lt;Rigidbody2D&gt;(); } // Update is called once per frame void Update() { var vel = rb2d.velocity; if (Input.GetKey(KeyCode.UpArrow)) { vel.y = speed*3; } else if (Input.GetKey(KeyCode.DownArrow)) { vel.y = -speed*3; } else if (!Input.anyKey) { vel.y = 0; } rb2d.velocity = vel; var pos = transform.position; if (pos.y &gt; boundY) { pos.y = boundY; } else if (pos.y &lt; -boundY) { pos.y = -boundY; } transform.position = pos; } }
Are you talking about structured logging because Microsoft.Extensions.Logging does support structured logging and passing properties. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/?view=aspnetcore-2.2#log-message-template These properties are then pulled out by serilog to form serilog's context. https://github.com/serilog/serilog-extensions-logging/blob/29bdf6ca8654412f4e820203426045f397461c5c/src/Serilog.Extensions.Logging/Extensions/Logging/SerilogLogger.cs#L63
An interface is essentially a contract - it forces classes that implement it to declare and implement those methods. To expand upon the Shapes example: sure, you could have an abstract Draw method in the base Shape class. But what if you introduce bitmaps? They're not a shape, but you should be able to draw them as well. Instead of further abstracting Shape to support something that shares very little in common, we can just use an IDraw interface and now everything that drew shapes can draw bitmaps without a code change.
How to stop them, because these warnings are creating an issue with users to use the application.
Another aspect of Interface is to allow you to maintain Type Safety. You should know that in C# you can't have a list of many different types. You can't have a list of int and string together. This means you can't accidentally call wrong methods on objects of the wrong type. Here is where the interface comes into play. If you have a list of things you want to draw but they are a different type, then you can use the interface , say ``` IShape ``` and have a ``` List&lt;IShape&gt; ``` . Remember because and thanks to type safety, you can only call the draw method on an object of that IShape interface. What you did here is impose a restriction on your objects to ensure they behave properly. You made a list with circles and squares but didn't get a runtime error because of different types. Thats why interfaces exist
The point is you know if that class implements that Interface you know it will have a Draw method you can call. It helps you maintain consistency and avoid errors when writing larger programs.
It only seems like extra work because in these simple examples you can keep the entire program in your head.
You should have AMA! I for one am really interested how blind coders code. When I get real deep I have all flat surfaces and screen covered with numbers, notes, stack traces and open files. Cannot imagine how would I do that non-visually. On the other hand understanding how blind coders work may help me cleanup my own messes I hope..
https://docs.unity3d.com/ScriptReference/Input.GetAxis.html I don't understand those codes enough to modify them to fit my game.
Basically you need to find out where they're coming from. Chances are there's a bug in your application somewhere.
I'm kinda bad at trying to get my point across ;D
I tried to debug the code but this issue did not caused a break while debugging.
The best example that helped me understand and made it click is with logging: https://www.tutorialsteacher.com/csharp/csharp-interface
That was the original plan. But then they decided that the vast majority of variables/parameters were intended to be non-nullable so they wanted that to be the default. Also, non-nullable is the default for value types. They didn't want `A a` to be nullable and `B b` to be non-nullable based on whether or not it was a class or value type.
Subclasses. Maybe `ICollection&lt;T&gt;.Add(T value)` accepts nulls, but your list that implements this interface does not.
anything from the stackoverflow gang (ncraver, mgavell, etc). the new m$ repos are really clean, too.
P.S. This isn't complete. You probably want to check the status of the cached task and if it's an error, discard it. And if it is complete, replace the cached task with the result so you save a little memory.
Thanks.
We should have just broke compatibility and used ? exactly as with structs. Then publish a tool to convert existing code, which is just adding ?. This mass butchering of C# to try and avoid breaking backwards compatibility will only cause a mountain of issues the sum of which are far, FAR, worse than the obvious fix would have ever been. I'm deeply disappointed in the C# team on this one.
/u/psychicash this is the answer you want. I specifically want to highlight this: &gt;C# requires that you declare the type of all **variables** You may be used to languages where a variable can hold whatever, and when the runtime needs to, it'll check whether whatever the variable is referring to has the field we're attempting to use. But C# insists on knowing the types for variables- not just values- and that complicates any attempt to have a variable like myCircleOrSquare. In the case that you need to operate on both circles and squares, there needs to be a type for those variables that could hold either circles or squares. And interfaces can provide that.
Part of the reason you are having trouble is that you are looking at a fake example. What you should be looking at is something we really use. For example, the collection series: * IEnumerable&lt;T&gt; * IReadOnlyCollection&lt;T&gt; * IReadOnlyList&lt;T&gt; * ICollection&lt;T&gt; * IList&lt;T&gt; * INotifyCollectionChanged And the collections: * List&lt;T&gt; * Collection&lt;T&gt; * ObservableCollection&lt;T&gt; * ReadOnlyCollection&lt;T&gt; * ImmutableList&lt;T&gt;
Interfaces are really just a specialized form of abstract class that you inherit from, specifically designed to specify behaviors. Since you brought up shapes earlier, a proper Shape interface would look something like this: public interface IShape { public void Draw(); } and a proper Circle and Rectangle implementation would look something like this public class Circle : IShape { public Point Origin { get; private set; } public int Radius { get; private set; } public Circle(Point origin, int radius) { this.Origin = origin; this.Radius = radius; } public void Draw() { // Draw something use the origin and radius } } public class Rectangle : IShape { public Point Origin { get; private set; } public int Width { get; private set; } public int Height { get; private set; } public Rectangle(Point origin, int width, int height) { this.Origin = origin; this.Width = width; this.Height = height; } public void Draw() { // Draw something use the origin, width, and height } } Now, you might ask what the point in all this is. Well, the key point of interfaces is what happens when you call this: // Get a shape from some data store public IShape GetShape(int index); You don't know what type of `IShape` you just got back... but that doesn't stop you from calling `.Draw()` on it, which will cause it to (presumably) draw correctly.
Have you ever used a foreach block? That works because of IEnumerable. The foreach loop doesn’t care what implementation you give it. It just knows it will be IEnumerable. Foreach has decoupled its implementation from the implementation of the collection it enumerates. If you don’t know how useful that is, it’s okay. I’d urge you to look at the strategy pattern, factory pattern, dependency injection, mock testing to start seeing Interfaces used in patterns. I really liked thinking about this question. I’m glad you asked it. Good luck and keep being curious.
No, it's using reflection to load inspect the types and classes in a compiled .Net Assembly
Really? We still say M$?
Building on your example, suppose you have a map class that puts shapes on a screen. You set the class to take an IShape and you can pass either a square or a circle. The map class will know what it can call (thanks to the interface) and then you can add new shapes that implement IShape (Pentagon, etc) And the map clad won't need any additional code because it knows what to do with any shape that implements IShape
Can't really help you there mate. Just have to track it down. Does it give you a stack trace?
There’s no stack trace along with the error log entry?
It gives a stack trace and I have tried putting the break point on that function itself, but still no success.
There is one.
I know i just answered but i have another example: In a personal project i have a class Template, and an interface ISubstantive, with methods Generate(), Describe(), Place(), GetVolumeDescription() and GetMassDescription(). Substantive means "person, place, or thing". I define an Item class as implementing ISubstantive. Later i draw a huge long list of substantives to the screen in a single for loop, using a method that takes a ISubstantive. I know that regardless of whether i am drawing a person, place, or thing, I'm going to need to call these methods, so i can define these methods in am interface and use them elsewhere. Later i can add a new implementation, say Creature, which is an ISubstantive, and only need to add new code in one place: the new class. My draw method already knows how to use something that implements the interface
 [https://www.youtube.com/watch?v=v9ejT8FO-7I&amp;list=PLrhzvIcii6GNjpARdnO4ueTUAVR9eMBpc&amp;index=1](https://www.youtube.com/watch?v=v9ejT8FO-7I&amp;list=PLrhzvIcii6GNjpARdnO4ueTUAVR9eMBpc&amp;index=1) strategy pattern. You make a class that implements behaviors, with each behavior having as many methods as you'd like, so then when you create the class, you can set which methods the behaviors use, and then if you want to adjust a method, you can do so through the behavior... I think
It likely doesn't happen every time. You need to look through that function and see if there's anyway that error could happen. Until you can reproduce the issue consistently you can't solve it.
Okay. Let me try it again. Don't know if this an upgrade issue or issue with my code.
No it's impossible to say. It could be the old server just didn't report them or the bug could be caused by changes in the new one. You basically need to go through all possibilities and eliminate them one by one.
&gt;RTFM I know, I know. Well, have you? What is your current understanding of what `async`/`await` does and is used for?
Okay, will do that. Thanks for the help. Also one more thing in web.config there are 2 entries for production one more old servers and one for new , could that be an issue?
Ok I ve had a tough time processing all this info but the one clarifying line from me I just read here: [https://docs.microsoft.com/en-us/windows/uwp/debug-test-perf/keep-the-ui-thread-responsive](https://docs.microsoft.com/en-us/windows/uwp/debug-test-perf/keep-the-ui-thread-responsive) It says "// The await causes the handler to return immediately. " When you say "await" it tells the thread to go do something else and I guess it circles back to the awaited line based on some compiler magic. And so far as I can tell "async" means that this function might have some await stuff in it so don't expect a return value right away. So the signature for the Task.Delay method will have 'async' if I look in the Threading library code. I think I get it now, but just asking the question out loud helped.
No problem. As long as they have different names and it's using the right one shouldn't be an issue. It may be worth sticking logging in the functions that are causing the issue so you can compare logs to when it happened.
When you call an `async` function, everything before the first `await` is done on the original thread. If you are in a GUI context (WinForms, WPF, ASP.NET non-Core) then everything after the `await` call is also on that thread. This allows you to interact with UI elements. Which means the only line that could potentially be on a different thread is this: await Task.Delay(1000); But that doesn't require a thread at all, so no second thread there.
&gt; If you are in a GUI context (WinForms, WPF, ASP.NET non-Core) then everything after the await call is also on that thread. This allows you to interact with UI elements. P.S. If you are on a non-GUI context, or use `.ConfigureAwait(false)`, then it can resume on a generic background thread. Do NOT use `.ConfigureAwait(false)` directly in your GUI's event handler code. That will put you on the wrong thread and bad things will happen if you touch a UI element.
One thing I've found useful is to think of interfaces as -ables. They imbue an ability to do something. 'Erasable', 'printable', 'shareable'. In your example, it seems like you're blending the role of the interface with the role of the parent class.
No you don't. You can point your domain or subdomain to the azure url using a CNAME. I've done it for a few of my projects.
How wouls that work. You can't execute server side code from github or gitpages?
Azure is the way to go. The free tier should fit your needs. You can also set it up to run serverless for real cheap. You can configure uptime and put a cap on how much you want ro spend. I run a few websites with databases and it costs about $4 mo.
I saw these warning about ConfigureAwait in Stephen Cleary's blog. Is that you? Thanks for the info! This async stuff seems super high level. The UI doesn't get locked up because somehow the compiled code goes and does other stuff when it sees an await, right? And we don't have to worry about telling the code to come back when the awaited stuff is done, the compiler takes care of that for us? I feel like the overhead for this stuff must be huge.
If you want to have more than one "order", you'd want to find a way to make an order a complete, independent object rather than a collection of variables in your code. This can be accomplished multiple ways, but in C# you will most often do it by making a class. If you create a class to hold all the order data, you can then have more than one order with its own custom information. This is one of the places where object oriented programming really shines. Looking up more info on that will likely help you out.
&gt; That's basically every example I've seen. It just seems horribly redundant without any benefits. Inheritance shares implementation, but interfaces only share the contract. You're stuck on your own use cases where you *do* want to share the implementation. In that cases, you'd probably use a base class. If that base class can't stand completely on its own because it's incomplete, but you want to share that implementation of Erase() among all shapes, then you'd make it an `abstract` class. Now consider a case where you absolutely positively do not want to share the actual implementation details -- `IComparable`. `IComparable` gives you everything you need to sort a collection of such objects, whether they were dogs, sprockets, game rules, etc. The rules for sorting all of those things are completely different, but you can write a sorting algorithm that can sort *anything someone else might write*, as long as they implement the `IComparable` interface. Now, eventually you learn that sharing the implementation details of long chains of inheritance hierarchies becomes very cumbersome. You want to make a change in the Grandpa class, but someone on another team wrote a GreatGreatGreatGrandchild class that is breaking due to your change! Oh, bother. You'll find it's often better to rely on composition, rather than inheritance, and programming to interfaces rather than implementations means you're much more free to mix and match implementations as you see fit, rather than being a slave to somebody else's inheritance hierarchy.
You should read about the scope of variables in C#. In general, every variable has a scope it's declared in. For example, if you have the following code: int MyFunction(){ string s = DoSomething(); // some other stuff } then every time you call this method, a new variable named s is create that only exists during this method call. If you wanted to persist anything you create in this method, you either need to assign it to something that is in a "bigger" scope (i.e. if this is a class method, then assign to a field of the class), or return it from the method. If I do something like this: class MyClass{ string s; int MyFunction(){ s = DoSomething(); // some other stuff } } then when the call to MyFunction finishes, the string variable still has its value. At least without seeing your code, I assume this is your problem. If your problem is not scope, but your problem is that you don't know how to save multiple values, look into Collections in C# (like List&lt;T&gt;). That way, you can have a List of strings, and you can add a new string to it every time you call that method.
using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; namespace DofeProjectOne { class Program { static void Main(string[] args) { int quant; start: Console.ForegroundColor = ConsoleColor.Green; Console.WriteLine("Welcome to the store"); Console.ForegroundColor = ConsoleColor.White; Console.WriteLine(""); Console.WriteLine("Prices:"); Console.WriteLine("Red £40"); Console.WriteLine("Blue £37"); Console.WriteLine("White £45"); Console.WriteLine("Black £43"); Console.WriteLine("Green £39"); Console.WriteLine("Yellow £41"); Console.WriteLine(""); Console.WriteLine("PLease enter your name:"); string ordername = Console.ReadLine(); Console.Clear(); Console.ForegroundColor = ConsoleColor.Green; Console.WriteLine("Welcome to the store"); Console.ForegroundColor = ConsoleColor.White; Console.WriteLine(""); Console.WriteLine("Prices:"); Console.WriteLine("Red £40"); Console.WriteLine("Blue £37"); Console.WriteLine("White £45"); Console.WriteLine("Black £43"); Console.WriteLine("Green £39"); Console.WriteLine("Yellow £41"); Console.WriteLine(""); Console.WriteLine("Please enter wanted colour:"); string colour = Console.ReadLine(); Console.Clear(); Console.ForegroundColor = ConsoleColor.Green; Console.WriteLine("Welcome to the store"); Console.ForegroundColor = ConsoleColor.White; Console.WriteLine(""); Console.WriteLine("Prices:"); Console.WriteLine("Red £40"); Console.WriteLine("Blue £37"); Console.WriteLine("White £45"); Console.WriteLine("Black £43"); Console.WriteLine("Green £39"); Console.WriteLine("Yellow £41"); Console.WriteLine(""); Console.WriteLine("Please enter wanted quantity:"); string quantity = Console.ReadLine(); Console.Clear(); if (colour.Equals("Red", StringComparison.InvariantCultureIgnoreCase)) { quant = Convert.ToInt16(quantity); int total; total = 40 * quant; Console.WriteLine("Thankyou for your order, " + ordername); Console.WriteLine(""); Console.WriteLine("Order:"); Console.WriteLine(colour + " x" + quantity); Console.WriteLine(""); Console.WriteLine("Your total is: £" + total); goto neworder; } else if (colour.Equals("Blue", StringComparison.InvariantCultureIgnoreCase)) { quant = Convert.ToInt16(quantity); int total; total = 37 * quant; Console.WriteLine("Thankyou for your order, " + ordername); Console.WriteLine(""); Console.WriteLine("Order:"); Console.WriteLine(colour + " x" + quantity); Console.WriteLine(""); Console.WriteLine("Your total is: £" + total); goto neworder; } else if (colour.Equals("White", StringComparison.InvariantCultureIgnoreCase)) { quant = Convert.ToInt16(quantity); int total; total = 45 * quant; Console.WriteLine("Thankyou for your order, " + ordername); Console.WriteLine(""); Console.WriteLine("Order:"); Console.WriteLine(colour + " x" + quantity); Console.WriteLine(""); Console.WriteLine("Your total is: £" + total); goto neworder; } else if (colour.Equals("Black", StringComparison.InvariantCultureIgnoreCase)) { quant = Convert.ToInt16(quantity); int total; total = 43 * quant; Console.WriteLine("Thankyou for your order, " + ordername); Console.WriteLine(""); Console.WriteLine("Order:"); Console.WriteLine(colour + " x" + quantity); Console.WriteLine(""); Console.WriteLine("Your total is: £" + total); goto neworder; } else if (colour.Equals("green", StringComparison.InvariantCultureIgnoreCase)) { quant = Convert.ToInt16(quantity); int total; total = 39 * quant; Console.WriteLine("Thankyou for your order, " + ordername); Console.WriteLine(""); Console.WriteLine("Order:"); Console.WriteLine(colour + " x" + quantity); Console.WriteLine(""); Console.WriteLine("Your total is: £" + total); goto neworder; } else if (colour.Equals("Yellow", StringComparison.InvariantCultureIgnoreCase)) { quant = Convert.ToInt16(quantity); int total; total = 41 * quant; Console.WriteLine("Thankyou for your order, " + ordername); Console.WriteLine(""); Console.WriteLine("Order:"); Console.WriteLine(colour + " x" + quantity); Console.WriteLine(""); Console.WriteLine("Your total is: £" + total); goto neworder; } neworder: Console.WriteLine(" "); Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine("Would you like to order again?"); Console.WriteLine("Please enter 'Y' for yes or 'N' for no"); string ordernew = Console.ReadLine(); if (ordernew.Equals("y", StringComparison.InvariantCultureIgnoreCase)) { Console.Clear(); goto start; } else if(ordernew.Equals("n", StringComparison.InvariantCultureIgnoreCase)) { goto ordercomplete; } else if (ordernew == "Admin") { goto Admin; } ordercomplete: Console.Clear(); Console.WriteLine("Order Complete"); Console.ReadKey(); Admin: if (ordernew == "Admin") { Console.Clear(); Console.WriteLine("Enter Password"); string attpass = Console.ReadLine(); if (attpass == "Charlie") { Console.Clear(); Console.ForegroundColor = ConsoleColor.Green; Console.WriteLine("Login Successful"); Console.WriteLine(" "); Console.WriteLine("Orders:"); Console.WriteLine(); Console.WriteLine(ordername); Console.WriteLine(colour + " x" + quantity); Console.ReadKey(); } else if (attpass != "Charlie") { Console.Clear(); Console.ForegroundColor = ConsoleColor.Green; Console.WriteLine("Login failed"); Console.ReadKey();
Not sure if its any help but i have commented the code.
&gt; The UI doesn't get locked up because somehow the compiled code goes and does other stuff when it sees an await, right? Correct. &gt; And we don't have to worry about telling the code to come back when the awaited stuff is done, the compiler takes care of that for us? Close. It's really the Task Parallel Library that handles all that. The compiler just makes it easier to use TPL correctly. Before we could do the same thing by calling Task.Continue
Get yourself a disassembler (DotPeek, Reflector, etc.) and take a look at what the compiler does to your code.
I won't be answering your question but I find it interesting how everyone have failed at making this concept click for you. I recall I had the same problem like you and was wondering why do we bother using interfaces? I would advise you just give up on this and move to other things. I might be wrong but I think it's one of those things that may only get understood with experience and whose benefits only show up on non trivial apps. I also suggest you have a look at SOLID principles. They might guide you to the right track.
If I may take this further: One of the most useful real life cases for interfaces is in unit testing. Let's say you have a class that performs a calculation and stores the result in a DB using a method `Save(MyData data)`. To test your class, you'd like to avoid needing a real DB, or in fact any DB logic, so you place `Save(MyData data)` in another class, and for the test pass a mock implementation instead of the real thing. &amp;#x200B; But static typing! How does your class know that there's in fact a `Save(MyData data)` method? The answer is an Interface. An "I can do this thing". &amp;#x200B; In bigger code bases-especially where multiple teams may not have access to each others' code, the usefulness of interfaces grows well beyond just testing, but even for small-mid size projects this is useful.
People use "contract" to describe what an Interface means, in terms of writing code. In terms of functionality, an Interface is very literally that - an interface with the rest of the code. A real-world example of an interface would be the fuel port on your car. Every internal combustion car implements are real-world version of "IReceiveFuel". They all have different implementations, but it's the same "interface" - a section of pipe of a certain diameter and depth that can receive the fuel nozzle. A class method's signature, like "public decimal CalculateSalesTax(decimal taxPct)" is, in code terms, the same thing - a set of specifications: this class has a method named CalculateSalesTax, and it takes exactly one input - a decimal sales tax percentage. Having your class implement an Interface is just to let other code know that the class has that particular method, and it conforms to the standard laid out. In the case of Square and Circle - both of them can be drawn, and the "Drawer" needs to be able call the "Draw" method on both classes. And, in general, all classes sent to the "Drawer" need to implement IDraw { DrawMe() }. Using the interface, you can easily know at design/compile time if you are a) not implementing IDraw according to the specification, or b) trying to ask to Drawer to draw something that doesn't implement IDraw. That eliminates the possibility of a large number of common bugs, even if it means a few extra lines of code.
Doesn't this violate LSP?
That's messy. What exactly do you get when you ask for a `ICollection&lt;string?&gt;`? At runtime, that type doesn't exist. You only have `ICollection&lt;string&gt;`. *** Also depends on the definition of `ICollection&lt;T&gt;.Add(T value)`. The contract could be specified in the documentation as "Will add the value or throw an ArgumentException", implying that null is not the only check that it may perform.
Options: * Rewrite everything to use REST calls. (Ugly I know, but the web monkeys swear its the one true way.) * Wait for server-side to be completed. https://www.infoq.com/news/2019/06/WCF-Decision/ * Try out gRPC https://docs.microsoft.com/en-us/aspnet/core/tutorials/grpc/grpc-start?view=aspnetcore-3.0&amp;tabs=visual-studio
I guess things would be easier if it were possible to specify a generic constraint for nullables rather than a check on default (T) = null at runtime. I prefer as much type safety baked into the contract as possible.
+1 for grpc
+1 for grpc
gRPC sounds [exactly](https://grpc.io/docs/quickstart/csharp/) like what I need! &gt; In gRPC a client application can directly call methods on a server application on a different machine as if it was a local object, making it easier for you to create distributed applications and services. I'll also keep an eye out on WCF, thank you!
I haven't used it myself, so I am interested in hearing how it works out for you.
P.S. If you go the WCF route, and care about performance, use the TCP bindings. WCF with TCP is nearly as fast as gRPC and other binary protocols. WCF with HTTP is as fast as REST, or in other words, slow.
It's not really "overhead", it's syntactic sugar. The compiler just rewrites async/await to output the same boilerplate you would have written to accomplish the same thing with the "Task" library. Certainly, i = i + 1 is going to execute faster than i = await new Task&lt;int&gt;(() =&gt; {return i + 1;}); because, obviously, more instructions are executed. But, in the case of I/O operations (the reason for 90% of await usage), the operation itself is at best orders of magnitude longer than a thread context switch or a few CPU instructions. int i = 0; i = await Task(() =&gt; return i + 1); Console.Log(i); is just interpreted by the compiler as int i = 0; Task(() =&gt; return i + 1).ContinueWith(() =&gt; { Console.Log(i); }); They do the same thing, essentially, but async/await syntax is far easier to understand than a chain of nested ContinueWith(() =&gt; {}) statements.
\&gt; Smells like multithreading to me! You know you could print the ID of the current thread instead of trying to guess. It´s also possible to see all threads in the built in VS-debugger if all threads are paused.
Disable the button at start and re-enable at end. Will all run on the UI thread, but it can be clicked again while its awaiting for the await to complete and not doing anything (so your UI remains responsive)
it would never have server side. basically youd create dummy static data and use that
It sounds like you need an Order object, along with a list of all current orders. Set the fields in the order object, finish it, and add it to the list. Then each new Order will just create a new object.
If we use the classic example the *IDrawable* interface would have a bunch more information stored in it. Coordinates, anchor point, size%/pixel, layer priority, etc. all of which would be passed into the Draw() function in order to actually draw the shape. So let's say I'm going to implement that. i create the standard Circle &amp; Square classes, fill them with everything the IDrawable interface requires. A user has created a logo using squares and circles and we're going to recreate it using their saved file. I load up the file and my program loops through a list of squares and circles ordered by their layer priority and draws each shape. Instead of having a switch statement to determine which class method I should be calling (and having to update that every time a new shape is added), I can just have a function that pulls in the IDrawable and calls the Draw() method of whatever shape it is. Now if we get a new shape the only thing I have to do is to add a new IDrawable class and not touch any of my main code.
diidnt know that, thanks for the idea.
\&gt;but it can typo? but it CAN'T? I set IsEnabled=false before my for loop and IsEnabled=true after the for loop. As I would expect, the button cant be clicked while the await stuff happens. Other parts of my app remain active, however, as expected.
It can if you don't disable it :)
Oh yea youre right!
I've used gRPC extensively and it's fantastic. Don't bother with WCF, even if it gets ported to net Core, it's EOL. gRPC is the RPC of the future for dot net Core.
&gt; `[DoesNotReturnWhenNull]` Is this a testing thing?
It's definitely not EOL, but it does serve a different goal. WCF is for situations where you need flexibility in wire formats, security protocols, etc. If you have some clients that need REST and some that need WS/SOAP and some that need a proprietary wire protocol and security scheme, WCF allows you to support all of them with minimal overhead. If you are just talking about point-to-point communication where you own both sides, gRPC starts to sound more interesting.
I was pretty sure microsoft wouldn't be doing any more work on it though. It's not like it's going away, but I wouldn't expect any new features.
Not multithreading. Asynchronous does NOT mean multithreading. At no point is any of that code executing simultaneously. Your output there should pretty definitively show you there the exact order things are executing, but in case it is not obvious: 1. UI Thread sees a button click event from the operating system. 2. The FIRST part of `DoSomething\_Click` executes. From the start of the function until the `await`. `startCount` and `clickCount` are set to 1 and this outputs: Call #1 saw 1 many total button clicks 3. The await causes the UI thread to be freed to look for more messages from the OS. 4. UI Thread sees another button click event from the operating system. 5. The FIRST part of `DoSomething\_Click` executes again. From the start of the function until the `await`. `startCount` and `clickCount` are set to 2 and this outputs: Call #2 saw 2 many total button clicks 6. The await causes the UI thread to be freed to look for more messages from the OS again. 7. The delay being awaiting the first button press is finally up; the SECOND part of `DoSomething\_Click` executes. From the previous `await` to the next `await`. `startCount` is retained from the original call and is still 1 while `clickCount` is global and is still 2. This outputs: Call #1 saw 2 many total button clicks 8. A second await causes the UI thread to be freed to look for more messages from the OS. 9. The delay being awaiting the second button press is soon up; the SECOND part of `DoSomething\_Click` executes. From the previous `await` to the next `await`. `startCount` is retained from the original call and is still 2 while `clickCount` is global and is still 2. This outputs: Call #2 saw 2 many total button clicks 10. A second await causes the UI thread to be freed to look for more messages from the OS. 11. The delay being awaiting the first button press is finally up; the THIRD part of `DoSomething\_Click` executes. Which does nothing. 12. Event is done so the UI thread to be freed to look for more messages from the OS. 13. The delay being awaiting the second button press is soon up; the THIRD part of `DoSomething\_Click` executes. Which does nothing. 14. Event is done so the UI thread to be freed to look for more messages from the OS. Nothing more to do after that.
Check out the `is` and `as` operators, and the pattern matching features added to `switch` blocks in C# 7.
I still can't fathom the reasons why WCF was ever relegated to second place after REST. Sure it is complicated, but that is because it does complicated things.
I'm actually hopeful for the reverse. Now that Microsoft has given up control we may see them actually start making progress on it. At the very least there should be WCF bindings for all of the popular message queue servers out there. As well as any binary formats such as gRPC. But when the source code was locked down, no one had the examples to teach themselves how to create plugins.
No it is for methods like ThrowSomeExceptionIfNull(someObject). For example I throw HttpExceptions with 404 status when my database returns null for an object with the specified id.
Gotcha. I do the same and I have middleware catch it and return something useful to the caller. Id have to see a code sample I guess to see how this fits into that usecase.
I really don't see why they need this. I mean in the rare cases when you really need it the good old if check is still there
I am afraid I don't understand. What they are going to do is break backward compatibility and use ? the same as with structs.
1. Web programmers are very, very vocal. So they get far more attention than the rest of us. 2. Web programmers desperately want to kill WCF. As far as they are concerned REST is good enough for everything. They don't even have the faintest concept of things like non-HTTP transport, distributed transactions, or the many other things WCF offers. 2. WCF has really bad documentation for users. It's hard to even understand what it can do. 4. WCF has really bad documentation for library authors. On day one they should have released "how to write your own binding library" so we can build non-SOAP plugins.
Yes I have middlewhere too. They used to have HttpResponseException in the framework but they removed it with Core. I wrote my own to put it back in. What I do in my controllers is something like this Product product = await ProductService.GetAsync(id); ThrowNotFoundIfNull(product); //Do something with product, convert to DTO in case of web api I can think of other examples that can be used elsewhere when null represents some state that must be converted in an exception like missing credentials being converted to some form of permissions exception, or lack of something in the database becomes some form of business exception.
Tutorials on xamarin are already scarce and one which teach the basics as well might be very hard to find. Just start with C# tutorials
&gt; Like I said, just having serious trouble wrapping my head around why this is a thing? where would you use it? What's the benefit over say declaring and implementing the methods to each class? You could have a list of shapes: List&lt;IShape&gt; Shapes; Then you can iterate through them and call the draw method on each one: foreach(var shape in Shapes) shape.Draw(); This is not possible if your classes don't implement the same interface. The interface allows you to store these objects in the same collection, and it also garuntees that each of these objects has a method names Draw. Very useful.
I completely agree with (3), as someone who had to implement SAML 2.0 in .NET before Windows Identity was a thing. At the same workplace, we had over 500 POS terminals sending transactions to an ESB server over WCF; I would not want to do that over REST. I agree with (4) too. It took me a while to understand WCF, especially the configuration part, but once you get ABC, it suddenly all makes sense.
/u/The_Binding_Of_Data &amp; /u/yawnston gave some great advice that should help you out. Start by creating a [class](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/classes) in a seperate file to represent the order information. And store all completed orders in a collection like List&lt;T&gt; (which would become List&lt;Order&gt; once you've implemented the class). So: -Create a class called "Order" to represent all order data. -Create a variable of List&lt;Order&gt; to hold all complete orders. -You can search this List to return any completed order.
Yes structured logging. Im talking about adding extra properties to the log event that aren't part of the log message.
&gt; lare the method in each individual class, it accomplishes the same thing. &gt; &gt; I realize my example is prob a poor one. OOP was difficult to grasp at first but the more I coded, the more it made sense. Inheritance makes sense. Interfaces don't. I don't know if it will click suddenly... but the videos I've watched all have the same glaring issue in their explanations. Interfaces are there to allow each class to have their own methods that aren't dependent on other classes. That's great. But you accomplish the same thing by making the method native to that individual class and thanks to namespaces you can have a draw method in two different classes. &gt; &gt; Like I said, just having serious trouble wrapping my head around why this is a thing? where would you use it? What's the benefit over say declaring and implementing the methods to each class? What if you have a list of shapes and you don't know what shape is in each position of the list? Let's say you wanted to get the area of each shape or draw each shape. With an interface it doesn't matter which shape you come across as you iterate, you can call the method because the interface guarantees that it has been implemented on the class.
agreed. I write extension methods on int types to make it iterable like Ruby's 2.times. It works perfectly, and as you said I can always fallback to using the original/default way if there is method name collision with another library.
&gt; What they are going to do is break backward compatibility They could’ve done so at a runtime level and shied away from it. Given that I still mainly use NetFx, I benefit from that choice, but it’s a shame in the long run.
My general attitude is "fuck the configuration". For the vast majority of us, hard-coding everything except the connection string is the right answer. XML config was always an advanced technique for COTS products that need flexibility (e.g. SharePoint) that was improperly promoted as the default.
Simplest possible explanation: Without the interface, you have no way to know it can draw/erase.
dotnet publish cp dotnet &lt;path-to.dll&gt;
Gprc for the win
&gt; XML config was always an advanced technique for COTS products that need flexibility (e.g. SharePoint) that was improperly promoted as the default. I agree. A lot of XML could have been eliminated if convention-over-configuration was a thing back then. Given that WCF was the first to introduce self-hosting in .NET (at least to me), it would have been way simpler that it turned out to be. Ironically, we have all this convention-over-configuration now in ASP.NET Core, plus self-hosting as a default, yet WCF is neglected.
Tasks oversimplify a lot, and I think people take that for granted. The way tasks behave is completely different for "I/O bound" and "compute bound" operations. I/O operations don't tend to use extra threads. Compute bound operations have to use a new thread. So "`async void` doesn't use a new thread" is completely false, and you really shouldn't use `async void`. It only exists because it was easier to let it exist than change the syntax for event handlers. "I/O bound" tends to mean something like a disk or the network is involved. Those are basically independent machines, from your computer's perspective. They're also very slow machines, from your computer's perspective. It might take a whole 200ms for the network to make a connection. That's enough time for your CPU to do several billion operations. So it'd be stupid if the whole machine stopped to wait for the disk. Instead, logically speaking, when the computer writes to disk, it puts a sticky note on the line of code it wants to come back to and writes a number on that sticky note. It includes that number when it tells the disk what data to write and where. Then the computer goes back to doing other things. When the disk finishes, it whistles and shouts the number. The CPU finishes what it's working on, then finds the sticky note with that number on it and starts on that work again. That's a dirty secret of multitasking, even in this age of multiple cores. The CPU can do so many billions of things per second, it shares every second between every program. Slack gets this many cycles, Firefox that many, Outlook that many, and it all happens so fast you don't even notice they're all sharing the same core and technically can't do anything in parallel. Threads are just a formal way the CPU organizes how it plans to spend its time. It's like a little storage locker of state for each program's work. Every time the CPU moves from one thread to the next, it has to lock up the old thread's locker, then open the new thread's locker, then rearrange some things so they look like they did when the new thread was last running. It takes a little time just to switch, which is why we like to minimize our thread use. That's time our CPU isn't working for us! "Compute bound" is just plain old code. It's not going to happen on a disk or over the network. It has to execute somewhere on the CPU. That means it's got to happen on a thread. You don't want it happening on *this* thread or you wouldn't bother with a task. So some other thread has to exist to do it. When we use Tasks, we can make suggestions as to whether we think a new thread should be created or if the thread pool should be used. But we're just making suggestions. Now let me circle back to that I/O bound example. You know how I said the OS sends data to the disk, notes where it was in the current thread, then goes to do other things until the disk says it's finished? That's basically what `await` does. You're on a thread, you want that thread to be able to do something else while another thing happens, and you want to come back to this thread when that thing is finished. It only does *exactly that* in a UI framework like WinForms or WPF, but you can use `await` anywhere. It doesn't really matter if you're calling an I/O bound or compute bound operation. `await` will tell whatever it is to do its thing, and it's not going to come back to the rest of the method until that finishes. So that's why `Task.Delay()` didn't stop you from registering two button clicks. You didn't tell the program it should ignore clicks until the loop is finished. Let's say you click 2 times so fast that the 2nd click got into the event queue before the event handler even executed. Here's how it would work. * (Windows OS thread) - A click happened, I'm stuffing it in this application's message queue. * (Windows OS thread) - A click happened again? Same. * (UI thread) - Is there anything to do? Oh! 2 things. First one: call this event handler. * (UI thread) - `clickCount++` * (UI thread) - `var startCount...` * (UI thread) - `for loop...` * (UI thread) - `Debug.WriteLine(...` * (UI thread) - Whoa. `await`? OK. I'll call `Task.Delay()`, and when it finishes come back. * (Windows OS) - "Got it. I'll tell you when 1000 milliseconds have elapsed." * (UI thread) - Anyway... next thing: I'll call the event handler! * (blah blah) * (Windows OS) - "Hey the timer finished. But your busy. Of course. I'll stick that in your event queue." * (UI thread) - Another `await`? Handle it for me, Windows. * (Windows OS) - "Gotcha." * (UI thread) - Can I rest yet? Oh, no, you finished that last `await`. I'll handle that. * (UI thread) - &lt;next loop iteration&gt; If you really wanted the code to do two button clicks in serial, you'd have to do something way more complicated to make sure the two different executions have different copies of the data. Or you'd have to do work to make the 2nd execution wait until the first finishes. `await` doesn't accomplish either of those, because its *job* is to make sure the UI thread is free while the `Task.Delay()` executes. `async` and `await` feel sort of like voodoo until you have a very firm grasp on how Tasks work. I feel like older asynchronous patterns were easier to grok, even if the code was more tedious to write. I don't think people should start with `async` and `await`, I think they are shortcuts to be used by people that understand how they'd write code without them. Even then, there are pitfalls.
Huh, I never looked at it that way. But you're right.
That would have been a complete disaster worse than the Python 2 vs Python 3 level 8 disaster. Instantly making all existing libraries unusable + breaking compatibility of all .NET languages (other than C# and VB.NET) would be the death of either .NET or that specific version of .NET
Eh, this is kind of an ugly want. I'll *assume* your context is OK, but generally if you think a thing is a particular type it should be in a variable that lets it be that type. I think something like this would be OK, maybe not the most elegant but it's a start: (bool, int) TryCompare(object left, object right) { if (left is DateTime leftDt &amp;&amp; right is DateTime rightDt) { return (true, DateTime.Compare(left, right)); } else if (left is decimal leftDec &amp;&amp; right is decimal rightDec) { return (true, Decimal.Compare(left, right); } else { return (false, 0); } } So it returns true in the first value if it made an actual comparison and false if it didn't know how to compare. The `int` part follows the contract of .NET compare methods: `&lt; 0` if less, `= 0` if equal, `&gt; 0` if greater. You could add more to indicate what the types were, but at some point it's easier to not be using `object` than writing this kind of code. Maybe you could compress this with a new `switch` statement but I think that's just lipstick on a pig ;)
But in this example what is the difference between using a base class ClsShape and using an Interface?🤔 I mean writing this and reading your last I kind get that it takes less code to draw each shape but you could achieve the same with a base class or am I wrong?
I understood why to even use interfaces at all when looked up how IEnumerable worked. I had a Map class with a list&lt;Cell&gt; and i wanted to write something like &amp;#x200B; foreach(Cell cell in map) &amp;#x200B; It didn't work at fist. I had to implement the IEnumerator interface, maybe I can't remember now. Then the code compiled and I could use it that way. It is a neat way to add the same funcionality to classes that don't really have anything in common. That said I have never created my own interfaces in personal projects. I only have implemented others interfaces on my classes. Is too time consumeing and modularity is not my concern. I can understand why to use on bussines enviroments. &amp;#x200B; A c# noob.
https://docs.microsoft.com/en-us/dotnet/api/system.drawing.texturebrush?view=netframework-4.8
https://www.newtonsoft.com/json You can get it through nuget.
You could technically do a base class in my example but if we make the assumption that each shape needs it's own draw method would you save any time? What would the base class method look like? What if I inherit the base class by a new shape and forget to override the method? Interfaces also tend to be cleaner in c# because you can make them more granular (see the I in SOLID). A class can have only one base but as many interfaces as you want!
All take a look thanks.
As a side note, for your own collection to work with foreach, you don't have to implement IEnumertor (though it's a good thing to do so), you only need GetEnumerator() method that returns an object that has a MoveNext() method and a Current property.
.net core 3 supports a built in json parser. So nothing beyond the .net components needed to parse a json string. See https://docs.microsoft.com/en-us/dotnet/api/system.text.json?view=netcore-3.0
Thanks. All look into it
&gt; Interfaces are there to allow each class to have their own methods that aren't dependent on other classes. This isn't about polymorphism, as you note: &gt; But you accomplish the same thing by making the method native to that individual class and thanks to namespaces you can have a draw method in two different classes. This is about test-ability. Interfaces make unit-testing far easier. Unit testing is about making sure the individual pieces are all functioning as expected. If you have an object w/ a lot of dependencies, then if any of those dependencies are broken, then that object is broken too. But if you're doing testing, you want to know that the dependency is broken, not some other object. If you have each object just be an interface, then rely on that interface in some other object, then in your tests you can create a fake to return/function in a pre-defined way. That way your test is only testing one thing. Hope that's clear...
Search for Deserialize JSON and you should get many examples on how to do it
Yes!! I knew I was forgeting something. Interfaces clicked with me when reasearching this but I implemented the enumeratot thing like you said. Thanks!
In case of String? to String scenario: what should be default values in array of String -&gt;var a = new String[10]; ?
Are nullable types coming to the desktop framework? The BCL is almost certainly not going to be annotated.
Source? I'm pretty sure I've read that the BCL will be annotated.
I am not sure but you are maybe looking for this: `[assembly: AssemblyVersion("1.0.*")]`
Install required dependencies (sdk, runtime), build, run. You can also setup a dockerfile and run it in a container. This is easier when you upgrade to newer versions. Then just proxy your nginx.
Nothing is stopping you at all. But what if we want to have a Canvas class that you’d want to draw or erase multiple shapes on? If you’re just using disjointed classes with the same functionality and no shared contract (the interface), you’d end up doing something like this (pseudo code below as I’m on my phone): class Canvas { void draw(Object o) { if (o.getType() == “Circle”) { ((Circle)o).draw(); } } } Or, you could make separate methods, one for each type. Either way, your Canvas *cares about the implementation.* Does our Canvas need to know that it’s a circle or a square? Nope. Anyways, now, you manually have to check what it is some way or some how. Maybe you’re like, this isn’t a big deal, but say you have 5 shapes. 10. 100. Think of all the code necessary to maintain that. You don’t wanna do that, I don’t wanna do that, let’s see how interfaces can make our lives easier. So now let’s have these shapes all implement the IShape interface. Our Canvas class *doesn’t need to care about the implementations*, just the contract. It says, okay, cool, I’m getting some object that allows me to draw and erase, and that’s all that’s important to me. Updated class: class Canvas { void draw(IShape shape) { shape.draw(); } } And this class works for *all* objects which implement that interface. How it is used: var canvas = new Canvas(); canvas.draw(new Circle()); canvas.draw(new Square()); What if we have a collection of shapes? var shapes = new List&lt;IShape&gt;() { new Circle(), new Square() }; foreach(var shape in shapes) { canvas.draw(shape); }
You can look at gitversion if that's your thing
I would update it to directly do "leftDt &lt; rightDt" and "leftDec &lt; rightDec" since they are the correct types.
First thing, install .net core on the sever. While, not required...it makes it much easier. Then, install kestrel. Kestrel is the same server .net core uses and works on Linux. Configure kestrel to pass it from Port 80 to 3000. Do a publish of the project and copy the files up to the server. You can test it by running "dotnet &lt;name of dll&gt;". You'll then want to create a linux service that simply runs the dotnet command in the background. All of the steps have tons of walk through that are finda le on Google.
This is something fundamental to strongly typed languages. I definitely wouldn't be advising OP to give up on this now. It might take some grokking but there's some great advice in this thread and some good examples, too. Definitely don't give up.
I added an article to my previous post, that I read a while back on this topic, if you are interested. I'm learning C# as well and for me it's always easier to understand some things about it when I look at what my code really compiles to.
or [https://docs.microsoft.com/en-us/dotnet/api/system.windows.media.imagebrush?view=netframework-4.8](https://docs.microsoft.com/en-us/dotnet/api/system.windows.media.imagebrush?view=netframework-4.8) should be able to go directly in the fill prop of a rectangle.
As /u/Vaguely_accurate mentioned, I think you are getting stuck on the mechanics of what is going on and missing the major differences between static typing and duck typing. Python's type system is optimistic. You can call draw() on any object you want and Python will try. If it fails, you'll find out at runtime. Open you code base, add a draw method to that class (or one of it's parents) and away you go. The point is that you find out when you run your code. C# assumes that runtime is too late to find this stuff out. An Interface guarantees behavior to the compiler. If your Draw method takes an argument of IShape, you are telling the compiler: I don't care about the specific object type that gets passed in, but I need you to *guarantee* it will have the behavior in this interface **before** I get to runtime. An interface is a quick way to guarantee the behavior we want, have it checked at compile time, and since C# only has single inheritance, interfaces are also a way to guarantee behavior without requiring other classes to have a specific hierarchy.
The only thing I read that suggested that it would was a post by /u/grauenwolf on InfoQ. The documentation all says it requires the .net core 3 sdk and while it seems to work for .net standard, the desktop framework dlls aren't.
Here’s my dumb real-life example of interfaces. We’re throwing a party in a month . We send invitations to friends at work, some old friends who live out of town, and a couple of neighbors. Think of us as the calling program and the guests as different implementations of the IPeople interface. We’re invoking a method on this interface named ComeToThisAddressAtThisTime(string address, DateTime dt). As the caller, we don’t care how this function is implemented. Our neighbors are going to walk down the street. Our work friends may drive or take a bus- some might even drive together. Our out of town friends will take a plane, then a Uber. All different implementations, but all accomplish the job of coming to our address at a certain time.
Nerdbank
&gt;Are nullable types coming to the desktop framework? Yes, as long as your project uses the Sdk-style. The old project system may never get them. &gt;The BCL is almost certainly not going to be annotated. The .NET Core BCL is being annotated as we speak; I'm guessing the Framework one won't be.
&gt; The documentation all says it requires the .net core 3 sdk Yes, because it contains the C# 8 compiler (VS itself currently _does not_). C# 8 will (partially) work on .NET Framework, too.
Yeah, possibly. But ultimately, this does mean that e.g. Swift's nullable notion will always be "cleaner" than C#'s.
Depends on the level of precision you need. I'd probably poll over HTTP but a couple of options you haven't listed are message queues and named pipes. Why are you focused on the bindings? You have control over the clients and the server, right? You don't have to update ONLY the server and leave the clients? That'd be horrid. Assuming you don't list out all the MarshalByRef inheritors and replace them using any technology that currently exists. Is the API extensive? Also, why would anyone want to port this to .NET Core? It will continue to work perfectly well in old .NET, so just leave it there. What will running on a Linux box buy you here? Not sure why people on this thread are lamenting the loss of .NET Remoting, it was a hunk of cack couldn't scale for shit outside of single-instance (at which point you might as well just have a stateless API).
Even if it was true when I said it, MS has been changing their minds a lot lately so it may not be true come RTM.
Or SignalR
It's easier to imagine with less concrete ideas than this. Take for example I want some datetimes to use in my app, I'll have an `IDateTimeService` field in my class. Then I write all my code to use this interface's `GetStart/EndDate,` `SetStart/EndDate` properties and `Save()` method Now I can set this field to hold a class that goes and stores the user-selected datetimes on a server somewhere, or maybe a different class that saves it as xml format in the documents folder. Without having to change the code using the interface - I just give a different class that implements IDateTimeService &amp;#x200B; How is this useful? Well, as opposed to python, the interface is a contract *telling you* what you need to implement, not from a comment somewhere that might become outdated, but from the compiler itself. That way you eliminate a lot of what would otherwise be minutes or even hours of testing code for runtime errors.
What makes gRPC the popular thing and what makes WFC/Remoting obsolete?
use docker, fastest and easier, and you would just need to forward the port to your Nginx or expose the docker port directly to host ip
What makes gRPC the popular thing and what makes WFC/Remoting obsolete? Isn't this literally an example of re-inventing the wheel?
Remoting has all kinds of problems ranging from secuity flaws to implementation flaws. That is why WCF was created to replace it. WCF is fine, but it mostly only works within C#. I say "mostly" because there are some things you can do with SOAP that will allow you to use it in other contexts, but it's not going to be simple. The advantage of gRPC is that it allows for RPC between multiple languages such as C#, C++, Python, Go, Ruby, and Java. If your application has the need to be able to communicate between different languages, gRPC is your answer. Even if you're doing C# to C#, gRPC is strictly faster and better performing. Additionally, it has better connection logic to handle retries and smooth over any potential intermitant network issues. My favorite feature is that it's designed from the ground up to use and take advantage of async/await. All of the generated server stub methods are async Task and all of the generated client methods have both sync and async methods.
All the answers above are to some degree correct. Unless you have some kind of unique requirement transport is probably not your biggest worry. The key to your success or failure is how well you encapsulate your business logic in a well defined service layer i.e. some plain old .dll's. If you get that right it's usually pretty simple to wrap your service layer in a WCF service, a REST controller, something else, or all of them. In fact if you want to expose your API via http AND use it in-process (like for a desktop WPF app) you can use a small library like [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient) that makes that a simple task. BTW WCF is still a great choice especially if your app is in-house.
Yeah, the OP will think this C# stuff is a bunch of bullshit until he sees the power of things like AutoFixture, Hedgehog and FsCheck for supercharged unit testing/property-based testing.
The problem with structs is that they may not be initialized at all. For instance when creating an array. What would you do with classes without a parameter less constructor?
Not only does C# require that you declare the type of all variables, it requires that you declare the type of all parameters. This is incredibly powerful way of inductive reasoning about a program, and creates modularity in unexpected ways: Consider AutoFixture, a tool for eliminating constructor calls in the Arrange phase of a unit test. How can AutoFixture configure automatically a giant graph of objects for you (such as a database object model)? It can because it knows how to construct each component of the graph, independently, thanks to seeing the interface/type required. You can independently break down problems now in much simpler ways than Python will ever allow you to do. Hope this helps.
You just pointed out exactly why I have the stereotypical IShape example. It would be just as easily implemented with inheritance. The point of interfaces is to allow two completely unrelated objects to pretend to be of the same type. An interface defines what the objects need to implement in order to pretend to be that type. It is like a class putting on a costum. Yeah I am a human, but I implement IVampire so now I'm a vampire sucking your blood. I also implement IBee, so now I'm a sexy bee stinging you with my stinger, but wait I also implement IPlanet, so now I am Planet X with massive gravity knocking other planets out of their orbits.
Sounds like a simple project with well defined requirements. I wouldnt worry about frameworks or patterns, your approach sounds rational given the scope.
You would not need a Song property in your Reaction class. The SongID does stay though as a foreign key.
Yeah. Use an image brush.
Oh you mean the full framework BCL will not be annotated but the .NET Core BCL will be?
The 20 years worth of ecosystem is much more valuable than that. Again look at the Python 2 vs Python 3 disaster.
One piece that I haven't seen brought up so far, is the concept of polymorphism. Interfaces allow you to treat very different objects the same way as long as they implement the same interface. For example, think of an IPayee interface. It defines an entity which can be paid something. This entity could be a business, a user, a website, a bank, whatever. Those are all very different things, but if they all implement the IPayee interface, then your payment processing code can handle all of them and not care about the properties and methods which are different between them. This is hugely powerful for code reuse when done properly.
I prefer to keep the Song property and fluently define the relationship in the modelbuilder. But there are a couple of ways to achieve the same result. Give me an hour and I’ll post an example.
I don't know if it's "correct" but it's how I do it :)
Possibly unpopular opinion in this space, bit if your can't swap out your transport mechanism with relative ease, your way too tightly bound. Obviously if this is the case for you, my comment is unhelpful as a lot of work may be required. Perhaps separation of concerns may help mitigate your problems.
As others have said in various ways, spend some time learning the difference between strong and dynamic typing. There are concepts that are quite different as far compilers and runtimes are concerned. A solid Pluralsight or similar course would be worth a few hours of your time. If you've been programming in a duck-typed world, grab an O'Reilly book or any programming channel online that demonstrates differences between static type definition versus dynamic, or learn how to implement dynamic typing in general - in this use case it isn't needed but knowing the possibility may help you rethink classing strategies. I don't work for Pluralsight, but this is a great primer: "Dynamic C# Fundamentals" https://app.pluralsight.com/library/courses/f1c3cd06-1d41-403d-ab6f-4b8b71798c70
A better way to think of interfaces is that they are "contracts" In your example you have public interface IShape { public void Draw(); public void Erase(); } public class Circle : IShape { public void Draw() { //draw a circle } public void Erase() { //erase a circle } } public class Square : IShape { public void Draw() { //draw a square } public void Erase() { //erase a square } } Now let's say you have a client (piece of code that consumes the above) public class Canvas { private IShape _shape; public Canvas(IShape shape) { _shape=shape; } void Run() { _shape.Draw(); // do other stuff _shape.Erase(); } } Canvas no longer cares about the *implementation* of your shapes. It only cares that the your shape classes have fulfilled their contract by implementing all methods, otherwise you can't compile. I'm still learning about this stuff, but I believe this is called inversion of control. Now if your shapes didn't implement IShape then Canvas couldn't use both or it would have to handle each class separately. IShape abstracts away the behavior of your shape classes so that whatever classes use it don't have to worry about every single implementation of IShape.
This is nice to know and all, but recommending a complete beginner use pre-release software seems needlessly complicated. Someone who doesn’t know how to deserialize JSON also probably won’t be familiar with the ramifications of using a preview SDK and/or preview version of VS, and they’ll likely just get hung up, not understanding why all of the answers on google look nothing like what they’re doing.
Don't give up, it do some reading on interfaces in C#, as well as contracts as a software engineering principle. If your background is scripting, any language you have availability to classing and inheritance within will be beholden to the constructs of your framework and associated compilers most likely. Take the time to learn and simplistically implement what you don't know about unfamiliar concepts in personal project code. Learn what works, and when you're stuck, figure it out or employ Google fu (or just search StackOverflow)
The other answers are better than mine, but just for another approach. I generally prefer well defined messages over things that look like function calls but are actually network messages. I like retrys, timeouts, responses, etc explicit and easy to use. It also mixes well with things like ZeroMQ and such. Theres ways to do this via a function style interface of course, Ive just found the explicit message based one generally easier.
It's also so crazy overengineered. "You thought SOAP was a _lot_? We can do worse than that!" Web API (REST / JSON over HTTP) is such a breath of fresh air compared to that. A goddamn simple text format that uses simple HTTP verbs like GET and POST and that is fucking _it_. Yes, it lacks stuff like code gen, and is generally not as nicely integrated as SOAP was in the VS 2005 days. But it's so… simple. Look at it in your browser's Web Inspector. Or Fiddler. Or heck, Wireshark. It's right there.
&gt; Possibly unpopular opinion in this space, bit if your can't swap out your transport mechanism with relative ease, you're way too tightly bound. Conversely, if you _do_ make your transport mechanism swappable with relative ease, you've engineered towards a use case that will likely never happen.
All an interface does is require the class to have that method/property. How it's implemented is irrelevant. The fact that a Square and Circle both share the same interface means nothing as far as how each class implements the interface and they could have nothing in common with each other. The whole point is that if I need an "IShape", the class behind that IShape is irrelevant to me as long as it has that interface.
Oh. Right. Duh. It's been that kind of day. I'm going to go edit it because I feel dumb.
&gt;I don't really get why it would be the responsibility of a square to draw something. The point is that the drawing logic is defined by the shape. A rectangle will know how to draw a rectangle, a circle how to draw a circle, etc. Then you can tell each shape to draw itself on a canvas: public interface IShape { void Draw(Canvas canvas); void Erase(Canvas canvas); }
Removed: Rule 4.
The thing is, you can implement a WCF server in fewer lines of code than a comparable Web API server. But the fucking documentation doesn't show you that. The examples pile on all this extra crap that you usually don't need.
If you are using razor pages then you shouldn't separate 'view' from 'controller'. A project, at its root location, should have a 'Pages' folder and inside it all of the razor pages. Every razor page has a '.cshtml' file which is the 'view' and optionally a '.cshtml.cs' which is both a controller and a kind of model to the view, some call it a viewmodel. The structure of the razor pages files in the 'Pages' folder will specify the routes, unless explicitly defined differently inside the '.cshtml'. Your problem can probably be solved by these things, if not then show us your authentication and authorization setup?
&gt; The advantage of gRPC is that it allows for RPC between multiple languages such as C#, C++, Python, Go, Ruby, and Java. That was the promise of WS-* and SOAP. (Too bad the standard is so complicated that no two vendors implement it exactly the same way.) Also, in theory WCF can use whatever wire format is native to those languages just be swapping in the right binding. (Too bad MS never delivered on that promise.) &gt; Even if you're doing C# to C#, gRPC is strictly faster and better performing. By a tiny amount. Like micro-seconds per message when compared to WCF with TCP bindings. And in some benchmarks, WCF needs less memory. But as I've said before, I'm eager to see where the open source version goes. It could be just a bandaid, a port for those stuck with legacy code. Or they could make it into the generic communication framework we were promised. Time will tell.
Remoting is obsolete because... I don't remember because it's been obsolete since WCF and seen as suspect before then. WCF is obsolete because Microsoft refused to bring it fully into .NET Core or even tell us their plans regarding it. gRPC is winning mainly because WCF left the stage and REST... well we all know what a kludge that is.
Well that's the theory behind WCF, but you pay in terms of performance and complexity.
What's the background on the reqs? Anything you're forced to use for the UI? Or is this signed, sealed, delivered with event listeners POSTing proper data?
Yes it's easy to over-engineer things but I can think of at least one very common use case where you actually do want to be transport independent. Say you have a desktop application that is used internally in your company. The vast majority of users have LAN connectivity so your app talks directly to your database using an in-process client. This is great because it is very fast. However you have a small number of field personnel who need to use the app remotely. They want to be able to connect without a VPN. In this case your app needs some kind of api perhaps REST, WCF, etc. I've consulted for a lot of different companies and this setup in some form is very common. What you don't want to do is write your app against the least common denominator (your remote api). If you do that than you have the bulk of your users talking to your db over http which is a tenth the speed of an in-process client. In a perfect world your local users will just need Services.dll while your remote users will access some api host which will wrap and call the exact same .dll. You don't want to have multiple versions of your service layer.
Yes, the full framework BCL (the dlls in `%SystemRoot%\Microsoft.NET`).
I'm sure there's some fantastic explanations below but I haven't bothered to read them before typing this... Anyways, you can think of an interface like a "contract" instead of a "blueprint". By defining an interface, you are guaranteeing that anything which implements that interface will have that interface's methods and properties. For example, let's compare an interface to an electrical outlet on the wall. The wall doesn't care what you plug into it, and it doesn't care what's on the other end of the cord. All the outlet cares about is that whatever you're trying to plug in is the correct *shape*. So what does this mean in terms of an interface? For an interface to work, every implementation of that interface must implement each method defined in the interface. For example, let's pretend that we create an interface called `IMammal` with 2 methods and a property: `public interface IMammal {` `void Breathe();` `void Heartbeat();` void Eat(); `double BodyTemperature();` `}` Then let's create two classes which `implement` IMammal: `public class Person : IMammal {` `public void Breathe() { }` `public void Heartbeat() { }` `public void Eat() { }` `double BodyTemperature { get; set; }` `}` &amp;#x200B; `public class Dog : IMammal {` `public void Breathe() { }` `public void Heartbeat() { }` `public void Eat() { }` `double BodyTemperature { get; set; }` `}` Then let's create another class, maybe we can call it Hospital, and give it a private field of type `IMammal` (remember, this is our interface). We will also require that we pass in an `IMammal` to its constructor, but `Hospital()` doesn't care *what kind* of `IMammal` we pass to it, as long as it implements `IMammal:` `public class Hospital {` `private IMammal _mammal;` `public Hospital(IMammal input) {` `_mammal = input;` `}` `}` Since we assigned the value of `input` to the `_mammal` private variable, we can use that anywhere within the class and use the methods and properties defined in the interface: `Breathe()`, `Heartbeat()`, and `BodyTemperature`. We can also define any other methods we want on the implementation classes - a dog, for example, might `Scamper()` or `WagTail()` or `GrowFur()` (yes, some `Human`s can even do that too but we'll leave it specific to `Dog`). Likewise, a `Human` can `WalkOnTwoLegs()`, `CombHair()`, `GetDressed()`, and some other `Human` specific stuff. The great thing about interfaces is that *they don't care about the class-specific stuff.* Your `Dog` can still `GrowFur()` and your `Human` can still `CombHair()`, but you cannot tell them to do that from the interface because the interface doesn't know about those details. &amp;#x200B; Back to the `Hospital` example, we passed in an `IMammal` to its constructor and assigned it to a private field called `_mammal`. Now anywhere in the class, we can access `_mammal` and call the methods on the implementing class - if we gave the `Hospital` a `Human`, we can call `Breathe()` on the `Human`. Likewise, if we gave `Hospital` a `Dog`, we can call `Breathe()` on the `Dog` \- this is because `Breathe()` is defined in the interface. The code doesn't care *what* kind of `IMammal` you give it, all the code cares about is that it has an `IMammal` with a `Breathe()` function so that the code can use it, regardless of the type of `IMammal` passed into it. &amp;#x200B; I really hope this example makes sense, it was the first thing that came to mind when I started thinking of an example.
How are you building? If locally on your computer, I can't help you, but if you are building on Azure DevOps I might be able to. I made a build task that stamps automatically-incrementing version numbers as part of an Azure DevOps build. It's private right now, but I could clean it up a little and make it public if there's interest.
I'm not doubting that it might work with .net 4.8 assembly projects. Only that the 4.8 dlls in your windows directory are not going to be updated to have nullable annotations and that this would negate most of the potential benefit of using it on said projects. The .net standard 3.0 dlls will have the annotations. Perhaps the reference dlls for previous versions will be improved with them as well so you might get the benefits in a .net standard 2.0 project.
Looks good to me. I personally like to fluently define the relationship in the modelbuilder as well &amp;#x200B; [https://www.learnentityframeworkcore.com/configuration/one-to-many-relationship-configuration](https://www.learnentityframeworkcore.com/configuration/one-to-many-relationship-configuration)
&gt; Say you have a desktop application that is used internally in your company. The vast majority of users have LAN connectivity so your app talks directly to your database using an in-process client. This is great because it is very fast. However you have a small number of field personnel who need to use the app remotely. They want to be able to connect without a VPN. In this case your app needs some kind of api perhaps REST, WCF, etc. I’ve consulted for a lot of different companies and this setup in some form is very common. Yes, been there. (I would caution against direct database connections, though. An API makes for more robust authentication, caching, etc.) I was more speaking in terms of replacing one API transport with another.
Not famliar with Kestrel or NET Core yet, but unless it acts as a request proxy for the service inherently in a container this seems wearisome on the same machine in principle. Is net core that bad/good out of the box to be trusted to handle memory protection between host VMs? Never read any posts on it in particular, curious to learn from anyone who's had to handle it
Right. The usual 2000s-era Microsoft thing of a framework that is *versatile*, but comes with poor defaults and little guidance, and thus scares off would-be users.
I really hope you are wrong. I've got too much invested in non-portable code.
I think rather than try and drill down to what you should be doing, I will try explain the why, because I was like you too, until I spent a few years dealing in production and suddenly 'clicked' as to why Interfaces are so frigging important. The reason interfaces are used is primarily to reduce coupling. If you are unaware, coupling is considered a symptom of bad software design, where your classes become interdependent on the actual implementation of other classes in your project. A classic 'bad code smell' (yes that's a thing) is a project that doesn't implement or use interfaces, and there are solid reasons for this inside of OOP design. The main reason is simple, whenever you have a function with a signature like public void DoSomething(SomeClass object) You're explicitly saying 'SomeClass is the only object I can ever, and will ever, need to call DoSomething() with'. The problem is that while this was probably true when you wrote it, it won't be true in six months, when your customer comes and tells you that they've added a requirement and want to be able to DoSomething() on 'SomeOtherClass'. If instead we had public void DoSomething(IDoable object) Then instead we can simply roll up 'SomeOtherClass' implement this interface, and know that anywhere that IDoable is referenced, this code can be used. The best way to think of an interface, is that it's saying that your code and *do* something, if you look at most MS interface names, they often end in -able: IEnumerable IQueryable IDrawable IDisposable This is because most of the time, we're using an interface to declare that a class is capable of a specific set of actions, and by defining these well, we can speed up development, as not only do we always know that any piece of code using these Interfaces will work with the code expecting it, but we also have a template of sorts in terms of expected core functionality of any class implementing one of these interfaces. The final note, the other big, big, big useful scenario and reason you want to use interfaces everywhere, is that it means you can write tests, use IOC and many other incredibly helpful tools when your code is loosely coupled. If, for example, I have a service that takes in IDatabase, I can test the output of my service by swapping IDatabase from it's live version to a 'dummy' implementation of IDatabase that uses hard-coded values and write unit tests that can check that my service is always outputting the expected values. Finally, as to 'why not just use abstract classes', the simple reason is that Interfaces are more universal, I might have 20 different objects in my project with IDisposable on them, but outside of that they are unrelated, using an abstract class would make my code less understandable, and box me out from being able to use inheritance in my class design. Hopefully this helped, my pms are open if you'd like to see some code examples, or if you want to send me a little snippet of something you've worked on i'd be happy to show you where/how to add some interfaces. There's a lot to get your head around but once you're into it it'll be second nature.
There are different types of page transitions available documented [here](https://docs.microsoft.com/en-us/windows/uwp/design/motion/page-transitions). Take a look.
So if I understand correctly, if a class inherits a class, it will have all methods of the parent class, but isn't considered the same type as the parent class, i.e. if a function asks for a parameter of type Shape, you can't fill it with a Circle, even if Circle inherits from Shape. OTOH if Circle implements IShape interface, it can be used in any function which accepts IShapes as a parameter? That is where the key difference is?
Should you always have functions with object parameters use interfaces instead of classes, or do you only build the interface once you actually have a second object type you may want the function to accept?
It looks ok to me. My only critique would be to have a base class that all of your entities will inherit from. Put the common attributes in it. Examples: Id, CreatedOn, UpdatedOn, etc. Using the CreatedOn, UpdatedOn timestamps on all your persisted entity data comes in handy when debugging data issues in the future.
If this is the implicit frame navigation, then you will need to add SuppressNavigationTransitionInfo in place of NavigationTransitionInfo in the .Navigate function: [https://docs.microsoft.com/en-us/windows/uwp/design/motion/page-transitions#suppress](https://docs.microsoft.com/en-us/windows/uwp/design/motion/page-transitions#suppress) private void HyperlinkButton\_Click(object sender, RoutedEventArgs e) { Frame.Navigate(typeof(Page2), null, new SuppressNavigationTransitionInfo); }
More importantly, when you add new shapes later (Triangle, Octagon, etc) you do not have to recompile your drawing application. The shapes themselves "own" the logic of how they are drawn, the application only needs to know that it can always call "Draw". This "inverts" the dependency and makes the "Application" not depend on the shapes, so you're free to introduce any such shape later as a plugin / add-on. Without interfaces the application would "depend" on the shapes and have to be recompiled every time someone wanted to add a new shape. :(
Programming with mosh has some decent starter videos on xamarin basics. It touches on bindings as well which I feel is an important piece to it all. Xamarin also has its own forum that has a bunch of posts with relevant questions imo. I’m by no means an expert but would be happy to try and help with any questions you might have.
I appreciate that. What is Mosh?
Using kestrel as a reverse proxy between the internet and the code is the recommended configuration on Linux. If you look at the default debug server within VS, you'll see that it uses kestrel by default. VS used to use IIS express, however they finally admitted that kestrel was a better solution and switched. Kestrel is also extremely configurable. It can also be configured as a load balancer too.
It is a website. Just go to programmingwithmost.com he’s an instructor and has courses on c# and xamarin. Although they do cost money but honestly if you are just starting out it is worth it
Agree - an API such as REST is much more available. I suggest a bit more consideration before ruling out things like direct database connections. For one thing in-process connections are extremely fast versus an http call. But...................................... much more importantly................................, doing things like substituting transports or database platforms should not require a logical leap. Its not a far-out idea nor is it rocket science. Think about it - if you have embraced SOLID design principals you have already embraced and perhaps implemented patterns that make features like this possible and even simple to create. Doing something like writing your service layer to to talk to both WCF and SQL client is a quintessential example of why we use IoC/DI. In the case of the LAN app I described in my comment above: public class InProcess.OrdersService : IOrdersService { public Order GetOrder(int id) { return "SELECT * FROM Orders..."; } } public class WebAPI.OrdersService : IOrdersService { public Order GetOrder(int id) { return httpClient.GetAsync("http://yada...").Deserialize&lt;Order&gt;(); } } public class OrderViewModel { public OrderViewModel(IOrdersService ordersService) { Order order = ordersService.GetOrder(10); // Don't know or care if we call SQL server or WebAPI // Display the order... } } The above code is as routine as it gets. Relies on principals we use everywhere in our apps. BTW I wanted to say this in my first reply but I couldn't quite verbalize it. I went out for a run and it finally came to me :).
you can set it using the &lt;AssemblyVersion&gt; field in the csproj, you can build in autonumbering using [macros](https://docs.microsoft.com/en-us/cpp/build/reference/common-macros-for-build-commands-and-properties?view=vs-2019). that being said, I'm pretty sure that they now recommend doing [deterministic builds](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-options/deterministic-compiler-option) which I think don't allow for classic autonumbering (e.g. based on date)
Will SignalR give you what you need? It's cross platform, and gives you the RPC type functionality you're looking for.
netstandard and netcore use the new csproj format which uses &lt;AssemblyVersion&gt; field, the properties files that use the older format are deprecated.
I'm hopeful like you are, but I don't think the community can do miracle because of all the legacy stuff such as SOAP.
What does that do that [assembly: AssemblyVersion("1.0.*")] doesn't?
To give an example of why the tiny amount of extra code is worth it.. I have an application which runs in prem, and also in the cloud. On prem can't access the internet, so it sends emails by SMTP via a local mail server. When it is on the cloud it doesn't have access to an SMTP service and actually we want all the benefits of SendGrid - a REST API service for sending emails. Because all of our code only relied upon an IEmailService, rather than the SmtpEmailService, it was super easy to create SendGridEmailService and inject that in startup instead of the SMTP service. My MVC controllers don't care how the email is sent - they just want it sent, so they have the IEmailService contract. In startup, based on an environment variable, we decide which email service should be registered and made available every time IEmailService is requested (via dependency injection). I always find these shapes etc examples a bit abstract - it is nice to understand the theory of how something works but not so good at demonstrating why something is useful.
Yeah, I was also going to suggest SignalR
Let me preface this post by saying get your C# basics down first, otherwise you'll be in for a rough go with Xamarin. It's already been mentioned, but if you're looking for a good quality course, check out mosh's xamarin.forms course on udemy. It's low cost, and covers the very basic stuff that you need to get started. ## Udemy Link https://www.udemy.com/xamarin-forms-course/ Check out the Xamarin slack channel as well. It's actually quite active, and you can *usually* get an answer to your questions. ## Slack Signup (https://xamarinchat.herokuapp.com/) Microsoft guys that are in the Xamarin orbit: ## Twitter Links * James Montemagno: https://twitter.com/JamesMontemagno * David Ortinau: https://twitter.com/davidortinau * James Clancey: https://twitter.com/jtclancey Follow these guys, as they often post updates, and some do live Xamarin development streams on twitch. There's more folks I'm missing as well. James Montemagno and Frank Kreuger do a podcast called Merge Conflict (https://www.mergeconflict.fm/) and they'll occasionally go over things Xamarin-related. Microsoft shut down Xamarin University and published all materials from Xamarin University on Microsoft Learn for free. This is an invaluable resource for new Xamarin devs. ## Microsoft Learn Link https://dotnet.microsoft.com/learn/mobile Forget about the Xamarin subreddit, that place is deserted.
My code is from core 2.1 but should be similar. The docs [for this feature are here](https://docs.microsoft.com/en-us/aspnet/core/security/authorization/razor-pages-authorization?view=aspnetcore-2.2) but they assume that you have Authentication and Authorization already setup\` In startup in ConfigureServices() you need to setup Identity and you need to AddAuthentication() and AddAuthorization() services.AddIdentity&lt;IdentityUser, IdentityRole&gt;() .AddDefaultTokenProviders() .AddDefaultUI() .AddEntityFrameworkStores&lt;ApplicationDbContext&gt;(); services.AddMvc() .AddRazorPagesOptions(options =&gt; { //options.Conventions.AuthorizePage("/SecurePage"); options.Conventions.AuthorizeFolder("/Admin"); //options.Conventions.AuthorizeFolder("/AgeGated", "Over21Policy"); }) .SetCompatibilityVersion(CompatibilityVersion.Version_2_1); services.AddAuthentication(); services.AddAuthorization(); In Configure() you need to call use UseAuthentication() app.UseAuthentication(); // I think before Mvc as you want to auth before processing the request app.UseMvc(); Then you can add the attribute to your pagemodels [Microsoft.AspNetCore.Authorization.Authorize(Roles = "Administrator")] public class EditModel : PageModel { This is just a rough overview and you will have to do more to get logins working.
Heres a simple RPC project I worked on for a few months now, its stable, works on many protocols, bust the one that works better I believe is websockets. You have do call remote methods as Expressions, tho, but its really simple, like: &amp;#x200B; client.Execute&lt;List&lt;int&gt;, List&lt;int&gt;&gt;(new List&lt;int&gt;(), y =&gt; y); client.Execute&lt;List&lt;int&gt;&gt;(y =&gt; y.Add(80)); client.Execute&lt;List&lt;int&gt;, int&gt;(y =&gt; y\[0\]); var r1 = client.Execute&lt;List&lt;int&gt;, IEnumerable&lt;int&gt;&gt;(y =&gt; y.ToArray()); &amp;#x200B; In this case y is a "Remote Variable" that is created and initialized on the first line, execute remote methods on the second and third, and get a value back on the last line. You can call any class that exist on the remote server. This is very simple and clean code, well tested. &amp;#x200B; Here are some samples: &amp;#x200B; [https://github.com/okhosting/OKHOSTING.RPC/blob/master/test/OKHOSTING.RPC.Test.UI.ConsoleClient/WebSocketTest.cs](https://github.com/okhosting/OKHOSTING.RPC/blob/master/test/OKHOSTING.RPC.Test.UI.ConsoleClient/WebSocketTest.cs)
Why not just host the scheduler on a separate thread inside the same process?
Dear OP. Only one very small tip. A strong proposal is to install Visual Studio and to learn C# there. Studio will help you very much and will answer you to most your questions: it show you errors at the moment while you types, it offer you how to fix errors, it will show you recommendations etc: it's the best tutor. You should not read a ton of books with some nuances: Studio will say you: "you should do this and that, you can not do this" etc. Try it.
What is the value of dr[“Student_image”] ? Can you assign that value to a random variable, like just above your bitmap line put var a= dr[“Student_image”].tostring() and put a breakpoint on it. What does that variable end up being?
I began working on a project called **Slyk Sync** that I have uploaded on GitHub. I'm using Microsoft's UWP development tools to create a GUI based Syncronizing application. &amp;#x200B; My reason for creating this application, is part UI/UX desires and irritation of using Qsync to sync projectsLibrary folder between desktop, NAS, and laptop. &amp;#x200B; What I want to accomplish is a Sleek(Slyk) UI/UX design with simple high-performance file synchronizing. &amp;#x200B; So far my issue has been decreasing the width of the drag bar so I can use a settings button near the top that is displayed left of the minus, expand, and exit buttons.
Another protocol which is cross platform/cross language is [WAMP (the Web Application Messaging Protocol)](https://wamp-proto.org). It supports WebSockets and has implementations in various languages including JavaScript, Python, Java, C#, Go, Ruby and others. I'm the author of the C# implementation of WAMP, which is called [WampSharp](https://github.com/Code-Sharp/WampSharp).
gRPC uses Protocol Buffers. Why'd you drop your objection to that?
Awesome thank you for the info
I had a similar requirement not too long ago. The idea was to use async/awIt as a js promise. Multiple requests within a specified time frame should get the same answer, and avoid multiple database calls. The solution was to build a cache layer that managed fetching the data as needed. The GetAnsyc method internally has a backing dictionary of string, Tasks GetAnsyc checks to see if a Key exists and if so returns the same Task if its still pending or will trash it and create a new one if it’s expired. This solved my issue, but had a downside that you hVe to somehow manage expired Tasks. Theres some optimizations dealing with those expired tasks that I meed to revisit, but it served my needs.
&gt; Not yet discussed is using an attribute ([NotNull]) instead of custom syntax. While more verbose, it would set a precedent for other forms of declarative parameter checking. Not only is this not yet discussed, it will not be discussed. The version that is being implemented is `string foo!`.
The attribute you want there is `NotNull`, applied to the parameter that you care about.
\`\`\`type like this for code blocks```
Build interfaces early, the longer you leave it the more technical debt you're creating. The key idea is if you're handing a class in to just do stuff to it (as in call functions) then an interface is ideal, as you're instead saying "as long as the thing handed to the function can do xyz I can use it" as opposed to "you have to be object type x ". The times you want to use an explicit class type should be because you want to access properties on the thing being called (eg database saves), however even then, things like IComparable show the uses of abstracting some property access behind interfaces. If you're just getting your head around it, try thinking of interfaces as abstract classes, but only for functions (although new C# kinda supports properties too)
Thanks for the hint.
I suggest you read the original discussion on that point, if not already. It is not as simple as you think.
Structs are always zero-initialized, i.e. all fields have default values. There is not such thing as an uninitialized struct.
Thanks!
`$Project = YourProjectName` `$currentDate = get-date -format yyMMddHHmm;` `$pattern = '(.*&lt;Version&gt;\d+\.\d+)(\.\d+)(&lt;/Version&gt;.*)'` `(Get-Content ".\$Project.csproj") -replace $pattern, "\`$1.$currentDate\`$3" | Set-Content ".\$Project.csproj"` You'd set the first 2 numbers manually in the csproj file, and this will set the last number to the current date-time when the script runs. You could also do a similar thing by looking at the current build number segment and incrementing it. One thing you can do is run a powershell script like above as part of your deployment routine. Or, with MSBuild I know there's a way to run the powershell as part of the routine build process, but I haven't checked to see if that option's available as part of the dotnet build command.
I'm not crazy about the examples in this thread because imo they don't demonstrate the value of interfaces in a real world scenario. I had the same issue understanding interfaces when I first started learning OOP and the Shape example didn't help me either. Suppose you have an application with 3 services all instantiated in your main method (what these services do is irrelevant for the example): public class Application { public static void Main(string[] args) { var serviceA = new ServiceA(); var serviceB = new ServiceB(); var serviceC = new ServiceC(); serviceA.Run(); serviceB.Run(); serviceC.Run(); } } All is good and your app runs well. However, One day your boss tells you that there's a new requirement to add email notifications to the application. So you add a new class and pass it to your 3 services because each service needs to be able to send email notifications: public class SmtpEmailSender { public void Send(string to, string subject, string message) { // https://docs.microsoft.com/en-us/dotnet/api/system.net.mail.smtpclient?view=netcore-3.0 var smtpClient = new SmtpClient(); smtpClient.Send(...); } } public class Application { public static void Main(string[] args) { SmtpEmailSender smtpEmailSender = new SmtpEmailSender(); var serviceA = new ServiceA(smtpEmailSender); var serviceB = new ServiceB(smtpEmailSender); var serviceC = new ServiceC(smtpEmailSender); serviceA.Run(); serviceB.Run(); serviceC.Run(); } } Each of the servives constructors now accept an argument of type SmtpEmailSender. All is good and the new changes to the app successfully send out email notifications. However, one day your boss comes to you and says, /u/psychicash we're moving to the cloud and we want to use AWS SES to send our emails because it has good monitoring features. So you add a class for this new email sender implementation (which at the end of the day, does the exact same thing as the SmtpEmailSender class, it sends an email): public class AwsSesEmailSender { public void Send(string to, string subject, string message) { // https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-using-sdk-net.html var awsSesClient = new AmazonSimpleEmailServiceClient(); awsSesClient.Send(...); } } public class Application { public static void Main(string[] args) { AwsSesEmailSender awsSesEmailSender = new AwsSesEmailSender(); var serviceA = new ServiceA(awsSesEmailSender); var serviceB = new ServiceB(awsSesEmailSender); var serviceC = new ServiceC(awsSesEmailSender); serviceA.Run(); serviceB.Run(); serviceC.Run(); } } Because the 3 services constructors were previously accepting a SmtpEmailSender type, they had to be refactored to accept the new AwsSesEmailSender type. The other option was to create new services that are duplicates of the existing ones but with the constructors accepting the AwsSesEmailSender type. We obviously don't want this option. Instead let's create an interface and implement it in the 2 implementations: public interface IEmailSender { void Send(string to, string subject, string message); } public class SmtpEmailSender : IEmailSender { public void Send(string to, string subject, string message) { // https://docs.microsoft.com/en-us/dotnet/api/system.net.mail.smtpclient?view=netcore-3.0 var smtpClient = new SmtpClient(); smtpClient.Send(...); } } public class AwsSesEmailSender : IEmailSender { public void Send(string to, string subject, string message) { // https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-using-sdk-net.html var awsSesClient = new AmazonSimpleEmailServiceClient(); awsSesClient.Send(...); } } Now if instead of having the concrete class (SmtpEmailSender or AwsSesEmailSender) throughout the application (like in the examples above), you had the interface type propagated throughout your app, then the only piece of code you need to change when switching between the implementations is the instantiation of the object: public class Application { public static void Main(string[] args) { IEmailSender emailSender = new SmtpEmailSender(); // Or IEmailSender emailSender = new AwsSesEmailSender(); var serviceA = new ServiceA(emailSender); var serviceB = new ServiceB(emailSender); var serviceC = new ServiceC(emailSender); serviceA.Run(); serviceB.Run(); serviceC.Run(); } } The value of interfaces comes from not having to change dependent code when you need a new implementation and as such, they promote code reuse of the existing dependent code. This is of course assuming that all the implementations of your interface abide by the spec of that interface i.e. same input (validated by the compiler), same behavior and same output (validated by the compiler). Others in this thread have mentioned the benefit of interfaces being testability but that is only a side effect of the real benefit, being able to reuse code. For example being able to reuse the code in ServiceA to test with a mock IEmailSender or in your production system using a real implementation such as AwsSesEmailSender. So to answer your last question, you can absolutely have your 2 separate classes without an interface but it makes the code dependent on these classes harder to maintain and reuse.
The framework (as in 4.8 and below) will not be annotated. Core 3 and 5 will be annotated.
Currently released versions of VS 2019 contain a preview version of the C# 8 compiler.
&gt; Yes, as long as your project uses the Sdk-style. No. They are not coming to the framework, regardless of what project style you use. The are coming to Core and 5.0.
Because I'm now writing raw protobuf code, this encapsulates it nicely.
I am using mvc
Why are you using razorPagesOptions then?
I am using an mvc project with individual users authorization.
Because I'm not using the library manually, it's just an implementation detail of grpc
It's an older project that I only need to port some part of over as a new project. I could spend a few days designing and implementing the API. But the old remoting code was literally 4locs
Have a look at ServiceWire. (It's my personal project but it might fill the bill for you.) https://github.com/tylerjensen/ServiceWire
I assure you I have here a bunch of Framework projects where nullable reference types work. The BCL may never get updated accordingly, but that doesn’t mean you don’t still benefit in your own classes.
I tought it was the same sorry. I am using \[Authorize\] on controller. Is there a way to do this on the startup class so I don't have to add authorize and the import of aspnetcore.authorization in every controller method I want to do this?
Yes, that is true. I only mean that the framework APIs themselves will not be updated.
This is will produce a warning from the compiler: [https://github.com/dotnet/csharplang/blob/master/proposals/null-arg-checking.md#intersection-with-nullable-reference-types](https://github.com/dotnet/csharplang/blob/master/proposals/null-arg-checking.md#intersection-with-nullable-reference-types)
This isn't and won't be rare. You should still code defensively. You can't count on your consumers having turned on the nullability feature, either because they are still on an old version of the compiler or because they simply haven't upgraded the part of the project yet that calls you.
I hate to disappoint you, but they are not wrong. Previous versions of the framework are not being annotated.
I publish a couple of NuGet packages and I use CircleCI to do it. You just drop a yaml file into the repo. Here's how I did it: https://github.com/jamietwells/rigid-fluency/blob/master/.circleci/config.yml
Are the dash placements consistent? Is it always the same length? Assuming both of those things are true, and only the actual hex values are changing then this quick and dirty match should work. `RunspaceId=[0-9a-f]{8}(-[0-9a-f]{4}){3}-[0-9a-f]{12}`
Ah that whole crusade against null is such a hassle. The cure is worse than the disease. Why they feel need to bloat the fairly old language with this? Create a new language and experiment however you want.
To clarify, what doesn’t currently work in them is the project-level setting.
They are indeed consistent, I'll give this a shot, thanks!
That looks like C#. It also looks like it's always a GUID. It also looks like it's part of an object definition, which tells me you've gone about this in a really really weird way to get here, but... I'm almost positive you don't want to use a RegEx here. It's not appropriate. var runspaceId = Output.Substring(Output.IndexOf("="), 36) Not vetted for syntactic accuracy btw.
Source?
That doesn't answer his question. Consider this line: var x = new Foo[20]; Where `Foo` is a class without a parameterless constructor and `x` is an array that cannot contain nulls. How would the compiler treat this line?
By "initialized" he means "the constructor was called" in lieu of just zeroing the fields. This actually matters now because parameterless constructors are going to be allowed on structs. (CLR already supports it, but C# does not.)
I don't think that's true. When I did a case study on converting a small, but fairly complex library to use nullable reference types I found that it wasn't difficult at all.
[removed]
Probably better as `Guid.Parse(str.Split('=')[1]);` or similar.
Use `Guid.Parse` instead. You're parsing a GUID.
There's also where WCF isn't using new .net core primitives like `Span&lt;T&gt;` yet or other possible optimizations made possible over the years so there's definitely room for improvement.
nosql?
There's nothing wrong with a table referencing itself as long as your careful. Just give it a parent department id foreign key that points to the same table.
If you're new to programming then you need to learn a language first. Xamarin.Forms is for people who already know C# and XAML and want to reuse their skills for a new platform. If you're target is to learn mobile development, then why Xamarin in the first place? Android and iOS each have their own ecosystem and for cross-platform frameworks also checkout React Native and Flutter. If you want to find a job, you should also check the job market first to make a better choice. For example in my country I see more React Native jobs than Android (Java/Kotlin) and iOS (Swift) and very few Xamarin and Flutter. So my advise is to invest you time and energy wisely.
That does something else, it tells the compiler to accept null when the type says it does not.
I'm talking about the case with nullable value types which need checks. These certainly will be rare especially since you have runtime representation of non-nullable value types that can't be sidestepped.
ah ok? I did not follow that parameterless constructor were going to be allowed on struct. While I don't think it matters a lot for structs, I can see how it is a problem for a class without a parameterless constructor.
Partly depends on how you deploy. If it's classic IIS web deploy you can still set up config transforms and apply them per environment at deploy time. If you're using docker, environment variables are best practice, using appsettings.json for invariant config. As your secure production config settings should not really be in source control anyway (application code and config are separate concerns really), both AWS and Azure have parameter stores that you could use to pull in config at deploy or application startup time.
Holy goto, Batman! :p
Thanks!
I was thinking in sort of the same lines but I didnt get around to playing with it. Thanks
Thank you for your thoughtful answer.
There aren't any user credential in the config files so it doesn't seem a problem to store them in source control. Access is controlled via the AD account the service or IIS application pool is running as.
&gt; While I think I generally agree with this, extensions still have a use with &gt; interfaces &gt; you own. I do this all of the time; it’s the best way we have right now to containerize methods that have a single implementation that should be available to any implementer of an interface. Thank you for your answer, I imagine this part can be very useful when dealing with stucts!
Thanks!
Thanks!
what are the things to be careful about? because if i can do this, it sounds to me to be the best option
i have thought about that. but i have no experience with noSql, so i would rather avoid it ;)
NO! &amp;#x200B; This is very much a relational data model. If you try to shove some no-sql garbage in this use case, you'll be screwing yourself six ways to sunday. &amp;#x200B; This is a simple use case, just create a Departments table, with an optional foreign key, pointing to its' own primary key, as the Id of the department's optional "parent" department.
How does it split the monolith?
Using [coding and algorithms](https://www.reddit.com/r/ProgrammerHumor/comments/5ylndv/so_thats_how_they_did_it_its_brilliant/)
I am looking for a serious answer.
Me too, that's why I tried to trigger a smartass :(.
Basically just need to make sure you keep on top of it. If you get any wrong it can get confusing real fast haha
By reweaving the single binary into multiple binaries and creating a proxy interface that pipes into icp for rcp calls, basically it recompiles your binary into microservices.
Removed: Spam, plagiarism.
hum. Better try sites like [codingame.com](https://codingame.com), [codechef.com](https://codechef.com), [topcoder.com](https://topcoder.com)
https://practity.com/csharp/
&gt;So in constructing a database structure for this, i can't just create a company table, then have a one to many departments and then have one to many more apartments. because that would be a loop. Doesn't matter. Joining a table onto itself is no problem. You can even do recursive queries with stuff like CTEs. So, something like these tables: Department ---------- DepartmentID Name And: DepartmentTree -------------- NodeID ParentID And then a query like: SELECT CurrentDepartment.Name, ParentDepartment.Name, Current2Parent.* FROM Department CurrentDepartment, Department ParentDepartment, Current2Parent WHERE Current2Parent.NodeID = CurrentDepartment.DepartmentID AND Current2Parent.ParentID = ParentDepartment.DepartmentID So, an `n:m` table schema with the A table schema Node2Pare
I’ve had to do this very thing in the past actually. How I did it was to implement a hierarchical table. So essentially each of your rows in the table has a column for a start and end value. Let’s say you have companyA and it contains departmentA, departmentB, and departmentC. CompanyA would have a start value of 1 and a end value of 8. DepartmentA would be start=2 end=3, departmentB start=4 end=5 departmentC start=6 end=7. So at any given time if you wanted to know all of the departments that belong to that company you just Select * from table where start &gt; 1 and end &lt; 8. Sorry I’m on mobile so it’s kinda tough to explain all this but, let’s just say at some point departmentA gets a sub-department names departmentA’. Now that your dB table is set this way all you do is get the end value for departmentA, 3, set the start of the sub department equal to that and the end equal to that plus one then increase the start and end values of everything else to fit it in so you would end up with CompanyA, 1, ,10 DepartmentA 2,5 DepartmentA’ 3,4 DepartmentB 6,7 DepartmentC 8,9 This type of structure prevents you from having to implant recursion in order to find all the children of a specific node. You just use one statement and pull back everything in between start and end
Sometimes, when you're stuck on something it's better to forget about if for a while and come back to it later. For people learning OOP, there are more important things to understand than interfaces. You can perfectly create good small apps without using them. They're not a critical path in learning OOP. That's what I meant by "give up"
NDepend is great. Some of the documentation is lacking which makes using the LINQ query language more of an uphill struggle than it should be, but the package is great.
How are you modelling it in your code? It sounds like a JSON document...
Thank you! Was facing the same issue as OP but I now understand it much better!
First glance I thought you were asking for something like Hypercard... :)
Why wouldn't you want to do that over rest?
No, if Circle inherits from Shape, then you can treat Circle as a Shape. That is what I meant by, "It would be just as easily implemented with inheritance." When it comes to passing around objects both inheritance and interfaces work the same way. The difference is in how the details get implemented. Through inheritance the details are already implemented in the base class, so the inheriting class doesn't have to implement anything. With an interface nothing is implemented so the class has to implement everything itself.
Showing the same thing
Showing the same thing
codewars.com
[https://exercism.io/](https://exercism.io/my/tracks) Not quite sure if it is the same
The way you’d measure time complexity in any language. Or if you want another way, convert your c# code to pseudocode and calculate the time complexity using your (assumed) knowledge of computer science. If you don’t know what time complexity is, well, I remember seeing some nice courses on udemy (maybe) explaining it very roughly, but enough so you’d get an idea.
What is driving the requirements for change? Are there portability and scalability requirements? Where do you perceive the added benefit of docker being?
I take umbrage with the title; you can't deploy \_my\_ C# monolith; you code for Icos using its framework and then let it perform the split along lines you define. The title (and tag line on the repo) suggests that it's generic, it's not. The approach itself is interesting, I prefer to ensure that my microservices are cut along distinct DDD aggregate boundaries and doing that all in one DLL is unwise because it's harder for devs to ensure that the aggregates are distinct. You get a lot of protection by splitting them up into separate DLLs.
Removed: Rule 4.
Icos does split them in to there own DLLs they are not in the same DLL, every microservice gets its own DLL and Docker container, and if you dont like the title and tag would you be so kind as to recommend a more accurate one ?
Besides that approach sounding like magic and an absolute maintenance hell, it won't be enough to create proper scalable microservices.
Why would it not be enough to be scalible ? and how is it a maintenance hell ?
Yes, but your supposition is that the code \_begins in a single DLL\_ and is then split. However, I believe that if you're going to do microservices, you're better off splitting each service \_when you are coding\_ to help protect your Devs from mistakingly crossing an aggregate boundary. &amp;#x200B; I would say: "A framework for building microservices within a single DLL"
Probably should have clairfied, I'm more interested in doing freelance work atm or putting applications out on market places because I'm in high school, so I can't quite get a job at a company yet. I do want to learn mobile development. Are you suggesting I learn something other than Xamarin? I'll take a look at what you suggested.
&gt; and how is it a maintenance hell ? Try debugging this **as a user** (not the maintainer of that tool) when something breaks or doesn't work. &gt; Why would it not be enough to be scalable ? Context dependent meaningful retryability? Context dependent meaningful fallback behavior? Configurable load balancing per context? Lots of shit. It's more than just splitting up your app in chunks and host them distributed in multiple instances. That is actually the least of all issues.
Glad I was able to hello!
I disagree with you, doing it manually add alot of over head, it also adds room for errors when the developer does not update the Internal communication protocol when making changes to services, as for crossing boundaries, the lines are very clear drawn icos lets you define boundaries using interface.
```csharp [IcosCfg(Cfg.ServiceType, ServiceType.Stateless)] [IcosCfg(Cfg.LoadBalanceStrategy, LoadBalanceStrategy.RoundRobin)] [IcosCfg(Cfg.Protocol, Protocol.Icp)] ``` as you can see icos does let you set theses things, and there is alot of room to expand things to facilitate more advance cfg and runtime behaviors, and as for debugging im have already started working on a debugger that allows you to debug code with icos in real time over multiple servers, the same also holds a lot of potential for expansion in debugging when it comes to logs, tracing etc, and not only that existing debuggers like in vs will work perfectly if you attach onto a remote host.
That debugger won't help you much if the weaving is fucked already. Sure, it **may** support it... But overall this sounds like just way too much magic. Using something like this in a productive setting is just irresponsible. Do it properly and do it clean instead of hacking your way together with tools that promise too much.
There is more overhead with doing it manually and that is the balance you have between magic performed in a framework and developer speed. When it comes to separation, you're talking about logical separation, which is soft. I'm talking about hard separation because mistakes can't be accidental. I want my developers to think about the effects they will have when they change an API/port/adapter because in micro services you have multiple consumers for a service. Another facet I don't like is that one benefit of using micro services is that larger teams can work independently of each other. If a single DLL is the best way to develop, perhaps a monolith is actually the best solution.
Thank you, this is exactly what I meant and needed!
Yup. I would recommend that OP read up on tight coupling.
You too, many thanks. This was the 'problem'. I do not yet know if I want that transition in my app, but I want to make the decision myself, not some default behaviour.
Speed. Transactions. Type safety. ESB integration.
This is the best addition to C# since C# 2's generics. Super excited about the "crusade"
Not exactly the same, but similar. I've been following the F# track there and its been extremely helpful and I've gotten some solid advice from the mentors there.
Try to install AccessDatabaseEngine.exe. Google will help you find the version you need.
So, I am not at my computer right now, but looking at the Dao page (https://docs.microsoft.com/en-us/office/client-developer/access/desktop-database-reference/dbengine-object-dao) I can see that you use DbEngine.CreateDatabase. Try that instead of trying to instantiate a new instance of the DbEngine class. Hope that helps.
Should be perfectly possible with OleDb using the Microsoft.ACE.OLEDB.12.0 As u/quebecbassman said you might need to install it if it doesn't appear in this list: `Get-OdbcDriver | Out-GridView` Preferably both 32-bit and 64-bit MS Office has a habit of stopping this install so run the .exe from PowerShell as admin like so: `AccessDatabaseEngine.exe /quiet`
C# does have Hypercard, it's called WinForms. heyo!
Same thing as in same error? If that’s the case then I would try to see what the value of dr is and what it contains. What do you get if you do dr[0] ?
foreach uses duck typing and doesn't actually need IEnumerables
Whoops. Thanks for the correction. Maybe I should have used IComparable and Sort as an example instead.
Me. I'm a member of the Roslyn compiler team.
&gt;There is more overhead with doing it manually and that is the balance you have between magic performed in a framework and developer speed. Honestly, I'm more worried about the long term impact on the developers. Magic may safe in the beginning, but in the long term it will always have an increased cost. I much rather spend more time and write more code in the beginning if this means everything is clear and maintainable. No magic.
Removed: Rule 6.
It allows for more elaborate versioning schemes, in particular if the project is being packaged as a NuGet package. For example, it could have something like `1.0.0-beta01`, and the next build would automatically increment to `1.0.0-beta02`, etc. If all you want is the 4-part version number that auto-increments based on current date/time, then stick with `[assembly: AssemblyVersion("1.0.*")]`.
Not quite. You're thinking of `AllowNull`. There are 4 attributes. `AllowNull` and `DisallowNull` affect the input to a function. `NotNull` and `MaybeNull` affect the state after a function has been called. So for a method defined like this: `void ThrowIfNull([NotNull] object? arg)`, the thing you pass to `arg` will be considered not null. Here's an example of the attributes being added to corefx: https://github.com/dotnet/corefx/pull/38732/files
Ah. I thought you meant the feature as a whole. Yeah, this specific scenario will be a warning.
Ditto. I'm loving SignalR. But gRPC looks pretty awesome at first glance. I think in core 3.0 signalR is built on top of gRPC? I've got some reading to do tomorrow I think. :)
Step zero: make sure you don’t have a manager who just loves to [optimize towards a shitty metric](https://en.m.wikipedia.org/wiki/Goodhart's_law). &gt;While it may be enough for you an your buddy who is next to you analysing the same code, it is not enough for professional communication. Sure it is. WTFs per line of code tells me far more about quality (and clues as to what led there, such as unrealistic deadines, poorly communicated technical goals, etc ) than a horseshit metric like “code coverage”. There’s some vaguely useful metrics here like cyclomatic complexity, but even those serve as little more than an indicator of a low-hanging fruit. They’re not an actionable item, don’t reflect on quality, and unlike what an incompetent manager might think say little about an engineer’s competence. You can write bad code with excellent coverage and low cyclomatic complexity. And you’ll probably have someone screaming WTF over it.
Desktop link: https://en.wikipedia.org/wiki/Goodhart's_law *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^263785. [^^Found ^^a ^^bug?](https://reddit.com/message/compose/?to=swim1929&amp;subject=Bug&amp;message=https://reddit.com/r/csharp/comments/c62dfk/how_to_quickly_analyse_a_net_project/es6h83e/)
With OleDb I was able to get all of the primary keys from the database, but was unable to get the [field properties listed in Access.](https://imgur.com/a/pXCLB9e) Here's my code using that method: OleDbConnection cnn = new OleDbConnection(); cnn.ConnectionString = @"Provider=Microsoft.Jet.OLEDB.4.0;" + @"Data source=C:\DB_Location;" + @"Jet OLEDB:Database Password=SomeDBPassword"; DataTable userTables = null; string[] restrictions = new string[4]; restrictions[3] = "Table"; try { cnn.Open(); MessageBox.Show("Connection Open!"); userTables = cnn.GetSchema("Tables", restrictions); } catch (Exception exception) { MessageBox.Show("Connection Failed."); System.Console.WriteLine(exception); System.Environment.Exit(1); } List&lt;string&gt; tablenames = new List&lt;string&gt;(); for (int i = 0; i &lt; userTables.Rows.Count; i++) tablenames.Add(userTables.Rows[i][2].ToString()); foreach (string table in tablenames) { System.Console.WriteLine("*****" + table + "*****"); DataTable schemaTable = (cnn as OleDbConnection).GetOleDbSchemaTable(OleDbSchemaGuid.Primary_Keys, new Object[] { null, null, table}); int columnOrdinalForName = schemaTable.Columns["COLUMN_NAME"].Ordinal; foreach (DataRow r in schemaTable.Rows) { string keyName = r.ItemArray[columnOrdinalForName].ToString(); System.Console.WriteLine("\t" + keyName); foreach (DataColumn myProperty in mySchema.Columns) { Console.WriteLine(myProperty.ColumnName + " = " + r[myProperty].ToString()); } Console.WriteLine(); } } This is the info I get with this code instead: *****TABLE_NAME***** PRIMARY_KEY_NAME TABLE_CATALOG = TABLE_SCHEMA = TABLE_NAME = TABLE_NAME COLUMN_NAME = PRIMARY_KEY_NAME COLUMN_GUID = COLUMN_PROPID = ORDINAL = 2 PK_NAME = PrimaryKey
Doesn't gitversion do that?
Looks like it (though I've never used it). It was not available for me to use when I needed it a few years ago, so I wrote my own. gitversion (or something like it) sounds like a smarter choice, though. :)
All abstractions are magic! I only know of a few people who write C++ port/stream listeners; most of us accept frameworks with .NET/node/etc and they are magic. You can't really see the TCP/IP interaction. So, that's kind of magic. For me, this is magic too far.
I believe it has its own msbuild task too now.
Interfaces are forcing you to obey a contract. If a class implements an interface you must have those methods and properties in that class.
Abstractions and existing implementations are not magic. But a tool that will take your compiled application, and invasively modifies and changes it.. That is magic.
There is no better proof than that. Thank you.
Ah yes, that could be interesting. I wonder how much would have to be applied directly and how much they would get just by picking up the newer versions of the XML parser and data contract serializer.
They keep going back and forth on whether or not to allow parameterless constructors on structs. I don't recall what the current opinion is.
This works because there is output (i.e. ref). Now it may work with non-ref arguments but I haven't seen it mentioned anywhere.
I'm on the fence about the feature as a whole. I think I will not use it but library authors may need it. However the int?! is quite absurd syntax and the case is rare with easy workaround so they should disallow the feature in this case.
Note that my example did not have a ref in it. It does not have to be on a ref parameter.
Well, it would be `int? param!`, not `int?! param`
It is not exactly an effortless tool. You have to code for this framework. I have a hard time deciding if it is any good or just another problem source.
The example in your GitHub link is ref. Do you have info that your code will work the same way? public static void Resize&lt;T&gt;([System.Diagnostics.CodeAnalysis.NotNullAttribute] ref T[]? array, int newSize) { }
Well even then...
I am a member of C# compiler team. It works this way.
If I understand you correctly, you don't want to use Windows and whatever DNS caching it has in place. Rather, you want to always go directly to the DNS server. If so, look at something like this: http://dnsclient.michaco.net/
I would really appreciate it if your try it out, and give me some feedback.
I see. Then I guess you are right, I don't need the other attribute
Don't know if it will help, but this is what I'm using... https://github.com/docevaad/Chain/blob/Version-2.2/Tortuga.Chain/Tortuga.Chain.Access.source/shared/Access/AccessMetadataCache.cs
Are you using the right CPU platform setting? If you have 64-bit Access installed I think you need to run your application as 64-bit. Likewise, if you are using a 32-bit version of Access you need to set the platform to 32 bit.
Thanks. Pro tip - auto format your code you copy paste from somewhere by CTRL+A, then press tab for four spaces in Notepad++ or some other editor then when you paste it in it will be formatted
You can use environent variables which you would then set to change in your deployment pipeline (if using automated deployment). See here for a better explanation. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/environments
Oh didn't know about Hypercard!
Have you tried flushing your local DNS cache? It sounds like your update is being pushed out through the domain to the DNS server on your network, but your local cache isn't updating. Without flushing your cache, local DNS will keep the last known host name of the device until something with a new host name shows up on that address (most of the time) `IPCONFIG /FLUSHDNS`
haha! Just in case I inadvertently led you on a wild goose chase - I was joking, Hypercard was a Mac app waaaaay back in the 80s/early 90s, one of the first to do the whole "designer view" and "code view" splits. I was just making a dig at WinForms :)
That's because you're using the JET driver instead of the ACE driver like I said.
Are you saying you have a class with 70 properties?
You're not necessarily doing anything wrong. A C# file is just a C# file. You can write one with 0 `using` statements at the top. The files a project starts with are determined by the project templates installed with Visual Studio. What they include can change over time. For example, if you choose the "Windows Forms" application template, and you add a new "Windows Form" to the project, your C# file is going to be a class that includes namespaces like `System.Windows.Forms` and inherits from `Form`. But if you choose a "Console Application" and choose the "New Class" template, it's not going to include that namespace. The "it doesn't even recognize the 'using System'" part is concerning, though. I don't know what that means. So try creating a new solution, choose "Console application", and without changing any of the code try to run it. If it runs, then everything is fine, these templates just aren't the ones you're used to. If it doesn't run, what are the errors?
That's the thing, I open a project, without changing anything and I mean anything like I don't type any letter, the "System" is highlighted red and theres like 20 errors telling me it cannot find system.object/string/void. I'm really confused. I might try reinstalling see if that helps.
Well that's fair enough (returning to it later) - I would *strongly* recommend to prioritise it over most things, though; certainly if OP is planning to spend a load of time within the .Net infrastructure :)
It sounds like you did t install everything correctly. I would run the VS Installer again and make sure you check all of the desktop dev stuff to ensure that the framework is setup.
I'm reinstalling it now so we will see if it's going to work now
If that's the case it sounds suspiciously like a botched install, and a reinstall might cure what ails you. Pay attention to the screen where you choose components. I find it really easy to *think* I'm installing Windows Forms and WPF and instead be installing UWP. It's like they named UWP "Windows Applications" and they named WinForms/WPF "Install Oracle JDK and IE browser toolbars" or something, I can't remember the exact wording.
Reinstalled it now and it doesn't work, it did say "setup completed with warnings" tho, I looked at the log and it says " Package 'sqlsysclrtypes,version=16.0.61904.23160,chip=x64,language=en-US' failed to install. Details MSI: E:\\VS cache\\sqlsysclrtypes,version=16.0.61904.23160,chip=x64,language=en-US\\SQLSysClrTypes.msi, Properties: REBOOT=ReallySuppress MSIFASTINSTALL="7" SKIPPENDINGREBOOTCHECK="1" Return code: 1603 Return code details: Fatal error during installation. Message Id: 1714 Message Details: The older version of Microsoft System CLR Types for SQL Server 2019 CTP2.2 cannot be removed. Contact your technical support group. Log C:\\Users\\NAMELOLOLOL\\AppData\\Local\\Temp\\dd\_setup\_20190627212113\_174\_sqlsysclrtypes.log Impacted workloads .NET desktop development (Microsoft.VisualStudio.Workload.ManagedDesktop,version=16.1.28811.260) [ASP.NET](https://ASP.NET) and web development (Microsoft.VisualStudio.Workload.NetWeb,version=16.1.28811.260) Python development (Microsoft.VisualStudio.Workload.Python,version=16.0.28621.142) Universal Windows Platform development (Microsoft.VisualStudio.Workload.Universal,version=16.1.28811.260) Impacted components .NET Core 2.1 development tools (Microsoft.NetCore.ComponentGroup.Web.2.1,version=16.0.28621.142) .NET desktop development tools (Microsoft.VisualStudio.Component.ManagedDesktop.Prerequisites,version=16.0.28621.142) [ASP.NET](https://ASP.NET) and web development (Microsoft.VisualStudio.ComponentGroup.WebToolsExtensions,version=16.0.28621.142) [ASP.NET](https://ASP.NET) and web development tools (Microsoft.VisualStudio.Component.Web,version=16.0.28517.75) [ASP.NET](https://ASP.NET) and web development tools prerequisites (Microsoft.VisualStudio.ComponentGroup.Web,version=16.1.28812.146) Azure WebJobs Tools (Component.Microsoft.VisualStudio.Web.AzureFunctions,version=16.0.28714.129) Azure WebJobs Tools (Microsoft.VisualStudio.ComponentGroup.AzureFunctions,version=16.0.28621.142) Cloud Explorer (Microsoft.VisualStudio.Component.CloudExplorer,version=16.0.28625.61) Cloud tools for web development (Microsoft.VisualStudio.ComponentGroup.Web.CloudTools,version=16.0.28621.142) CLR data types for SQL Server (Microsoft.VisualStudio.Component.SQL.CLR,version=16.0.28315.86) Connectivity and publishing tools ([Microsoft.VisualStudio.Component.Common.Azure.Tools](https://Microsoft.VisualStudio.Component.Common.Azure.Tools),version=16.0.28315.86) Container development tools (Microsoft.VisualStudio.Component.DockerTools,version=16.0.28625.61) Data sources for SQL Server support (Microsoft.VisualStudio.Component.SQL.DataSources,version=16.0.28315.86) Developer Analytics tools ([Microsoft.VisualStudio.Component.AppInsights.Tools](https://Microsoft.VisualStudio.Component.AppInsights.Tools),version=16.1.28917.181) JavaScript and TypeScript language support (Microsoft.VisualStudio.Component.JavaScript.TypeScript,version=16.1.28811.260) Library Manager (Component.Microsoft.Web.LibraryManager,version=16.0.28315.86) Managed Desktop Workload Core (Microsoft.VisualStudio.Component.ManagedDesktop.Core,version=16.0.28621.142) Python web support (Microsoft.Component.PythonTools.Web,version=16.0.28517.75) SQL Server Data Tools (Microsoft.VisualStudio.Component.SQL.SSDT,version=16.1.28811.260) Universal Windows Platform tools ([Microsoft.VisualStudio.ComponentGroup.UWP.Support](https://Microsoft.VisualStudio.ComponentGroup.UWP.Support),version=16.1.28811.260) Universal Windows Platform tools for Xamarin (Microsoft.VisualStudio.ComponentGroup.UWP.Xamarin,version=16.0.28621.142)"
Do you have Office 365? If you do, it has Flow and this might be easier to wrap around the process. https://docs.microsoft.com/en-us/flow/modern-approvals
Thanks for the reply. Sorry for not being clear — I currently have it stored in a list. I’m not that crazy yet. What I’d like is for the elements in the list to be stored in the database as one column for each bool. I know that I could store as a bitfield but I’m wondering if there’s something else I can do.
Still getting Parameter is not valid
Student\_image is the folder name where the image is getting saved. I tried putting var the same error is coming
I'm not familiar with EF Core, but can you store that as one JSON blob?
if you want to do some stuff with databases sql than take a look at the entityframework from microsoft for parsing of JSON and XML you can use newtonsoft json its the best framework for it and is in the nuget package explorer like the entityframework &amp;#x200B; (sry for my english)
Are you able to set a break point on that for each and determine what the value of dr is?
Dr represents the datarow
Oh man, congrats on fighting tooth and nail to get this thing done. First things first, pluralsight. Great tutorials and straight to the point. Go through the beginner tutorials, then I would watch a series on SOLID development to learn some good behaviors and class abstractions (saying the phrase "The app has about 3,000 lines of code (as in the form 1 and form 2 back-end code, not the other less accessable and auto-generated code.)" makes me physically hurt). From here look into EntityFramework for wiring upto MySql. Newtonsoft.Json for Json serialization and deserialization (super simple stuff).
Yeah, I’ve seen examples of storing it in JSON but I’m wondering if there is a way to store it with one bool per column
If you want to do web development you need to know javascript. If you want to be a very employable full stack web dev you'll know html, CSS, sql and nosql databases (at least a little) , javascript, a backend language like c# or python or node, be very familiar with source control, have at least a basic understand of CI/CD, and then just for icing on the cake you can learn a front end framework like react or Vue.
This x10
I'd recommend doing some practise projects with WPF, it's a bit harder to learn than winforms, but it's so much more rewarding and powerful, you can do a lot more with it. A great series i used to learn the basics was [this](https://youtu.be/gSfMNjWNoX0) which was really thorough and taught some really good practises.
Under the assumption that you know SQL, you could turn all those columns into a computed column ([https://docs.microsoft.com/en-us/ef/core/modeling/value-conversions](https://docs.microsoft.com/en-us/ef/core/modeling/value-conversions)) and add a `NotMapped` property which converts the resulting string to a `List&lt;bool&gt;`. Of course I'll give you the obligatory "bit field would be better". I see no reason why these books should be stored as individual columns. It's really not a great idea to have so many columns in a single table.
Udemy is running a sale right now on just about all of their courses right now. Sale ends tomorrow, but they've got plenty of C# content.
In my opinion in this order: SQL, HTML and JS and then whatever JS frameworks interest you like React or Angular. Razor is pretty much just HTML with its own extra syntax candy and Blazor is pretty new, so much so I wouldn’t recommend spending time on it as a new dev trying to get a job. With just C# and SQL you can get a lot of backend or legacy app jobs and then add the web tier and you can look at web dev. Also, if you have time look into some NoSQL too cause it’s pretty common in the ecosystem.
For English is perfectly good. I have played around with the entity framework and with Newtonsoft also but something in my mind just isn't clicking or I am not installing the nuget packages correctly. But you are correct, those are two major things I need to learn. I bought a book specifically dedicated to learning the entity framework, just haven't gotten around to it yet. thank you for confirming my suspicions that those are two very important fundamentals I should be focusing on.
Hey, thanks for the advice. I think I’ll just go with the bitfield route. That way I won’t have to deal with the issues with naming each of those fields.
I knew that I was going to hurt some people when I mentioned that lying about having 3,000 lines of code, and I left it in there anyways because I felt that it would really reinforce exactly what the problems are that I'm having, or roadblocks for lack of another term. Is pluralsight anything like SkillShare or Coursera? Or is it more of a developer resource like stack overflow? I understand that I can look this up with a single Google search but I am on mobile at the moment, I am working and I just want to get an idea of what type of resource it is because it sounds incredibly familiar. I actually posted on upwork offering $100 to someone who could do a remote session with me and teach me how to link a locally hosted MySQL database to a WinForms application And literally did not get a single bite on that, I imagine that is because it is a strange request for a freelancer website. I'm pretty sure that something mentally is not clicking as far as packet installation or at the very least, version compatibility issues as far as MySQL 5.7 is concerned. I had a ton of help from stack overflow. All of my questions were downloaded into Oblivion, no matter how hard I tried to format them in an easy to digest way and get straight to the point, it really is like people hate on you there hard if you aren't a seasoned developer. I wish that the stack overflow community was a little bit more accepting of newbies. And thank you, your response is very reassuring.
You can use reflection to do a pivot on a list of items, but it's complicated and I don't think worth it for such a simple use case. I think the best options in terms of simplicity are: 1. have a model that has 70 bool properties, and the front end uses those as-is with 70 different fields 2. have three tables, one for the form metadata (id, user, etc), one for the checkbox definitions (label, name, etc), and one to associate the form and the checkbox definitions (i.e. the boxes the user checked) Neither option is particularly great but it is much simpler to use the same data structure across the board from the UI to the EF model. Part of that depends on what you are using for the UI, but a checkbox does not necessarily have to represent a boolean value.
Tim Corey is the man. If I didn't have a business to run that takes up 70 hours a week, I would treat his YouTube videos as if they were several semesters of a computer science course built specifically on top of .NET. He is such a great teacher and so unbelievably good at what he does. I really want to learn WPF and I will, I just don't think that is my next step. I think that ASP.NET is probably the next type of project I'm going to take on. Do you think that WPF is a better 'in between' point? As in in between WinForms and and ASP.NET?
[MySQL docs on EntityFramework 6 integration](https://dev.mysql.com/doc/connector-net/en/connector-net-entityframework60.html)
I'd say it is an improvement on winforms as a desktop development platform. ASP.NET is different entirely really.
A good thing about Udemy's sales is that they're never over. If you pay full price for a course from them you simply weren't patient enough.
I don't think I've ever seen Udemy courses not on sale. I thought that was the Gimmick of Udemy. I've had some bad experiences with Udemy whereas I've had great experiences with SkillShare and Coursera. If someone recommends a specific Udemy course, I'd go for it but the last one I purchased ended up to be a VB.NET developer passing his project off as a C# project but when you look at the 'using' statements at the top and see that they are 'imports' statements instead. Then proceeded to show where you find everything in visual studio and how he likes to set up his work space. There was no coding taught at all but it was marketed as a full C# course. It really just felt to me like they have no real content moderation If that was able to slip through and if that man was able to take my money under false pretenses.
Awesome, that sounds like exactly what I need
I've never actually had that problem and I'm sorry you did. They do have a 30 day money back policy now, though I'm not sure how it works personally. I've had fairly decent luck with udemy, sadly I can't really provide you much direction which course would suit you best.
- Entity Framework - Data First Migrations - LINQ (In that order) All of those will help you to interface with and manipulate your MySQL database. As others have mentioned, get some theory under your belt too. You need to be concerned with security and encryption side it sounds like you're dealing with people's financials. Pluralsight to learn those things is invaluable. It's what the industry often provides their employees for on job training.
If you're not familiar with databases then that's a good point to start studying next. Especially with entity framework making it a breeze
I understand that, but is it actually getting populated? If you break on it is there anything in there? Do the keys match up with the key you are looking for?
All the things the other people said, specifically doing some properly decent db stuff and maybe a HTTP Web API would be good. One point I'd like to labour is to ensure when you build a big thing that spans multiple forms, dbs, apis, apps, etc _don't_ make it mission critical. You need to get your second system syndrome out of you. I'm pretty sure while writing this app you've thought of "better" ways of writing code and structuring your objects. If not, you'll start to. You need to write a non-critical system that tests all these "brilliant" ideas so when they're found to be terrible you don't lose anything. You may have a few of these systems, I built at least two and thankfully as they were tawdry they're not millstones around my neck.
try something like this: for ( int i =0; i &lt; dt.Rows.Count; i++) { Bitmap img = new Bitmap(@"..\\..\\" + dt.Rows\[i\]\["Student\_image"\].tostring(); ... &amp;#x200B; }
WPF using MVVM is a significant difficulty jump from WinForms. It is well worth the effort, but it can be an uphill climb. Check out Laurent Bugnion's MVVM Light Toolkit, it is a great starting point. [http://www.mvvmlight.net/](http://www.mvvmlight.net/)
Yes. A history window function that logs data
To add to this, ASP.NET brings with it it's own unique flavor of challenges and opportunities: do I build a user interface, or do I serve data to a single page application? where do I put my logic? Are there any best practices regarding logging? How do I test it? What about hosting and publishing?
https://www.codeproject.com/Articles/14122/Passing-Data-Between-Forms
Just a small note on the "link to mysql" piece. That may sound trivial when phrased that way, but such an undertaking is likely not. It depends on what your app would use a database for, but either way you have to establish the connection and write the code that maps your application's state to the database in some way. Anybody that could do so in an hour for a non trivial application I would be skeptical of personally.
Regarding &gt; I am proficient in MySQL but I could not link my MySQL database to my project. I was able to link an MSSQL Express DB which was pretty easy but the problem is that my company LIVES and operates on MySQL databases. &gt; I use an older version (MariaDB 5.7) and I'm having a hell of a time getting it to link without errors. I imagine that learning the entity framework and how to link my DBs will be difficult. I would not use Entity Framework in your case. EF doesn't necessarily simplify things. EF can, in the end, save you time and reduce boilerplate. However, and this goes for a lot of libraries/tooling, it's not a bad idea to have actually experienced the problem that EF solves before assuming you need it. It is important that developers understand connection, command, parameters, data readers, and other classes like those listed [here, on the MySQL .NET library](https://dev.mysql.com/doc/connector-net/en/connector-net-programming.html). These classes are similar to the MSSQL classes and likely other libraries are idiomatically similar. Also just a note, you said MariaDB and I linked MySQL, according to [this](https://mariadb.com/kb/en/library/other-net-connectors/) they are generally compatible. That might sound like a lot, but here are two examples that cover a significant portion of database operations. var connectionString = ""; using (var connection = new MySqlConnection(connectionString)) { // Example 1 connection.Open(); // or await OpenAsync... using (var command = connection.CreateCommand()) { command.CommandText = "Some query like an update that does not return data"; command.ExecuteNonQuery(); } // Example 2 using (var command = connection.CreateCommand()) { command.CommandText = "SELECT * from information_schema.TABLES WHERE TABLE_CATALOG = @mosquito"; command.Parameters.Add(new MySqlParameter("mosquito", "def")); // mosquito is name of param with value def using (var reader = command.ExecuteReader()) { while (reader.Read()) { var thingIWantedFromDatabase = (string)reader["TABLE_CATALOG"]; } } } }
I second the WPF MVVM approach. As stated it can be a difficult concept to understand but the code speaks for itself at the end of it all. Definitely worth learning
Something I haven't seen listed here yet is maybe look at Dapper for database access. Entity is fine, and good for beginners but I've seen many people run into issues down the line (probably not an issue at scale you'd be using it at). If you're not using identity to authenticate to the app I definitely recommend this route. Dapper will keep you closer to the raw SQL you already know. Just pair it with FluentMigrator and you'll be off. I also haven't seen anyone mention cloud databases. Instead of worrying about connecting to local DB, a cloud DB will not only protect data incase of future disasters but you don't have to worry about local networking. A mariadb instance on azure is pretty cheap (was ~$17 a month last time I set one up) and mariadb is a fork of MySQL so all the same packages work with it. One last thing to mention is, you said you have ~3k loc in 2 code behinds, that's a lot. Maybe look into design patterns and do some refactoring. I'm assuming you can probably get something much more maintainable with a couple services.
I recommend ASP MVC 5. It has great documentation, been around stable for 4-5 years, if you want to make a web app. You'll learn SQL and C#, razor syntax used in modern ASP web app frameworks I jsut did a small shitty ASP MVC Core 3.0 web app and I would recommend to avoid. https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/introduction/getting-started I also recently found this channel might be of use: https://www.youtube.com/user/kudvenkat/videos
I usually start with three layers * Models * DAL * UI (including web services) The divisions are based on testing strategy. Models have all of the pure code that can be unit tested. DAL requires integration tests (or lame ass mock tests). UI is manually tested and thus kept as thin as possible.
Can you use VS community for a business?
Yes, as long as you’re not an enterprise. I believe they classify that as 1MM in revenue and or 250 employees. Other than that, you can have 5 devs using VS.
&gt; so instead it exports a .rtf file which 'form 2' imports and parses there is an embedded database called [LiteDB](https://www.litedb.org/) . i recommend it for storing the local data. it's as easy as this: &amp;#x200B; // open or create a new database file using(var db = new LiteDatabase(@"just_one_file.db")) { // collection is like a table in SQL; you don't create structure in advance in LiteDB var memes = db.GetCollection&lt;Meme&gt;("memes"); // store in DB memes.Insert(meme); // query DB var mem01 = collection.FindOne(Query.EQ("Source", "Reddit")); // change something and update record in DB mem01.age++; memes.Update(mem01); } (just wanted to tell you about this DB, because of its simplicity and how little you need to get it added into your project. however, since c# and oop have better ways to pass data between objects (like forms), please don't take my recommendation in a wrong way :))
Agreed, but it looks like OP tied themself to strings, even though we're using guids :(
For what its worth try uninstalling it, then install Visual Studio 2017 instead. https://visualstudio.microsoft.com/vs/older-downloads/ Visual studio 2019 has some nice new things but VS 2017 is still awesome
I know you said you wanted each to be a separate column, but that seems rather in efficient. Have you looked into flags and bitmasking? You can store up to 32 values as a single entry in the database. https://www.google.com/amp/s/csharp.2000things.com/2013/11/26/982-an-enum-type-can-store-a-maximum-of-32-flags/amp/
I'm not sure I'd characterize it that way. You write .proto files to generate all your objects. ServiceStack is another interesting option. It really does abstract away the transport layer: https://docs.servicestack.net/architecture-overview - to the point it works fine with protobuf messages. They're both message based, contract first. gRpc is a lot bigger
Thanks for the advice. Another poster suggested using bitfields, so I’ll try to figure out my best option from there. I don’t have much of a background in databases outside of one college course so it was a good experience to learn from everyone’s responses.
Your doing something wrong. Forms are just normal classes. Constructors work as usual. The info we really need is the error.
That's the problem, it just says the build failed and there isn't a message. [Here's](https://imgur.com/gallery/pInES1q) a screen cap of what I'm getting. FWIW, the constructor I'm attempting to create is at the bottom on the left.
You can use whichever is to your linking, C# is the most popular choice. VB is really just there for those who have history and experience in VB and want to stick with that. C# is a much better language IMO. F# is a functional language, if that is your thing. If you aren’t sure just go with C#.
I know a bit of Javascript, but I've been working through CS50 and learning C so I thought C# might be interesting since building websites isn't really interesting to me. I'm curious about Blazor though
C# Vb and F# are just the languages that implement the .net standard. You can use any of them to get the same end result. My preference is C#. JavaScript is just used on the front end so unless you’re developing a website of some kind you want need it.
.NET includes a CLR (common language runtime) which is virtual machine that executes an intermediate language (rather than the raw assembly that C compiles to). C#, VB, and F# all compile into the same intermediate language, so you can use any of them. Most people use C#. F# uses the functional programming paradigm. VB has been around for a while so it still has legs but I don't think anyone in their right mind would choose to use it on a new project.
Microsoft’s “.Net environment” consists their implementation of the Common Language Runtime (CLR), plus languages and development tools that target it. The CLR is a public standard that includes specifications of the Common Intermediate Language (CIL, a byte-code format) and the Common Language Runtime (CLR, a virtual machine that executes CIL code). - The “.Net Framework” is the general name for Microsoft’s proprietary implementation of the CLR. It’s purpose is to execute CIL code. “Mono” and “.Net Core” are open-source alternatives. - C#, F#, and VB.Net are programming languages. They were designed to be compiled into CIL code to be run on a CLR implementation like the .Net Framework or Mono. They are public specifications that anybody can implement a development environment / tool chain for. - “Visual Studio” is Microsoft’s proprietary development environment and tool chain for programming in those languages and compiling programs into CIL code. “.Net” is also a marketing term so Microsoft plays pretty loose with it; it can be used to refer to the entire ecosystem of tools that Microsoft sells for the Common Language Infrastructure, not just their implementation of the CLR.
&gt; SQL, HTML and JS and then whatever JS frameworks interest you like React or Angular. Razor is pretty much just HTML with its own extra syntax candy and Blazor is pretty new, so much so I wouldn’t recommend spending time on it Spot on. &gt; Also, if you have time look into some NoSQL too cause it’s pretty common in the ecosystem. I'd guess you meant more along the lines of Document DB's, but I might suggest Redis specifically.
Yeah Redis is a great one to point out. Key Value systems are really simple but powerful systems that can introduce new ways of communicating. I use Redis heavily for pub subs and a little bit for caching.
I Can vouch for [Mark Seeman's 'SOLID and Encapsulation'](https://www.pluralsight.com/courses/encapsulation-solid). Really great tutorial that also goes through how the principles interact which IMO is a thousand times more useful than being able to parrot "A class should have only one reason to change"
What's CI/CD?
Continuous Integration and Continuous Deployment
Please let us know at support@ndepend.com which content you'd like to see. By now you have the doc here: https://www.ndepend.com/docs/cqlinq-syntax https://www.ndepend.com/docs/cqlinq-features https://www.ndepend.com/docs/cqlinq-performance-in-visual-studio 300+ queries and rules OSS based on CQLinq https://www.ndepend.com/default-rules/NDepend-Rules-Explorer.html and a rich code search which is actually a query generator https://www.ndepend.com/docs/code-search
&gt;You can write bad code with excellent coverage and low cyclomatic complexity. This is why technical-debt exists. It aggregates all sorts of code smells (OOP misuse, dead code, API breaking changes, bad structure, lack of test...) into one simple metric: effort to fix (in man-time or in money)
Someone's already given you the straightforward expansion. To expand on that, it's the process that automatically takes the latest version of your code from source control, builds it, runs your tests and then, if they pass, deploys it to its destination (potentially running further tests at that point to confirm success). Some companies make it part of a developer's role; others, it's part of DevOps or Release Management.
yes, i've thought about saving it as json too. but i'm not sure if that is as robust as saving it in db (unless i can just save the json in a way that makes sense in order to also read it and update it later)
.net core is the clear future for .net, at this point learning outdated frameworks for new applications isn't recommended. Can I ask what issues you had with .net core mvc (that weren't related to the fact you were using a non production ready version)
Nice, have you updated it? I swear I couldn't find half of that stuff before :)
Flushing doesn't help. Considering DNS returns a FQDN for remote machines, but not for local, I don't think it's even checking local DNS cache, but something else local.
Yes, this works. Quite a lot in that package over what I need... I could probably parse through it to see how he is querying DNS directly and cut it down significantly for my needs, but certainly it's nice. Definitely prefer native code, but I wonder the overhead of this versus NSLOOKUP, also considering the dll/xlm that is installed with the package. &amp;#x200B; I find it strange that the built-in DNS.GetHostName doesn't appear to have an option to bypass cache/local considering it must do so for all remote devices. &amp;#x200B; Anyway, thanks for the pointer!
This is the path I took: HTML &gt; CSS &gt; JS (these are musts for any web developer) &gt; jQuery C# &gt; ASP.NET Core &gt; EF Core &gt; SQL Server Once you know these you can expand your skills by learning a SPA which is necessary today, I chose Angular, it's great. React is also very popular and you can build native mobile apps with it too (React Native). Blazor is still young and in my opinion investing your time for a JS framework is a better option for now because they have better job market. Once you learn one SPA framework you can quickly learn another.
Take a look at the System.Diagnostics.Process class. There's a property on the class called StartTime that may be helpful to you: https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.process.starttime
Drive your architecture from what makes sense in practice for your project. Will you benefit from separation into different layers and assemblies? Then separate. Otherwise don't.
I bet the built in class is just a thin wrapper around an OS call. Check Reference Source to see if it lists the source code.
Isn't it better to make the song property virtual?
Okay, but what’s the difference to just using making a Shape class and letting the others inherit from it?
No, I'm not taking it the wrong way at all. I actually really appreciate you bringing this to my attention. Is there a using statement I need to add in order to use liteDB?
why does it look like only setting up 2 vars to you?
Finally solved it few days ago
I'm also the owner of a collection agency and this app that I created isn't something that I intend to sell, is being used internally to make my employees lives just a little bit easier. I'm not in the business of software development and this is more of a personal tool which I'm sharing with my staff. Essentially, imagine that you worked for a bank doing data entry. You found that something they were doing was very inefficient and you threw together some quick software which happened to be in accordance with the data compliance standards and allowed your fellow co-workers to input data more efficiently. If you were sharing the tool with them and not selling it, I can't imagine that Microsoft would force you to purchase Enterprise license.
My business does about $700,000 a year and has under 10 employees, none of which do any sort of development besides myself as a hobby.
Thank you! I got recommended this book by a senior colleague as well: [https://www.amazon.com/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164](https://www.amazon.com/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164) &amp;#x200B; Think I'm gonna give that a read as well!
I do use a clogged database which is hosted on Azure, but I use a third party company that hosts my server for me and provides all of the services. I would like to eventually take everything over but they also host the software that I use. I back my database up locally on a regular basis so that I can play with it on my PC locally instead of experimenting straight onto the cloud where I could potentially require myself to roll back a full day's worth of work if I push through a sloppy update query. so for practice and testing purposes, I want to connect to a local database but then for deployment purposes after it's been developed, that is when I need the connection string to reach out to the cloud with an IP address, username and password. My code is highly reusable but I have dozens of methods and many of the methods are only used once or twice. I think I did a very good job at preventing duplicate code from being written but because I don't understand class libraries yet, I had to pack quite a bit of code into each form. As a matter of fact, both of the forms that I created actually would serve as excellent class libraries on their own because they have so much custom code that is highly formatted to my industry and that could be reused and dozens of projects moving forward if I learn how to save it as a class.
I am really excited to try this. Thank you so much for your insight, it makes a lot of sense and I want to learn the basic background before I start working with frameworks as often as possible. For that reason I was considering learning c++ before c# but a lot of people told me that it was more likely that I would get discouraged quickly if I started with c++ instead but the concept is sound and I appreciate that you are confirming that I should reinforce the basics before using frameworks and libraries.
I just need the proper dependencies added to my app and I need to create a connection string or a form that generates a connection string. I have numerous apps that I need to create and the coming once and they all use the same database. The same MariaDB 5.7 database with the same layout and schema. How big of a job is it to create a basic outline that connects a single database to a WinForms app? I understand that actually mapping, querying and manipulating the data is a larger job.
Thank you for this information, this will be very helpful for me
See if NAudio will work for you.
As opposed to what ? What are your other options? What made you say "I need c# for this" ?
No, it would make no sense. Use Python to execute Python scripts.
Sounds like you are in the clear, but just so you know for the future, it doesn't matter if you intend to sell the application or not. If you are using it at your business and you have more than x developers or make more than y dollars you need a paid license. It doesn't have to be Enterprise, but it can't be community. [This link has some information about that. ](https://www.google.com/url?q=https://visualstudio.microsoft.com/wp-content/uploads/2017/11/Visual-Studio-2018-Licensing-Whitepaper-November-2017.pdf&amp;sa=U&amp;ved=2ahUKEwj3k6zvg4zjAhXZKM0KHSZBB3QQFjAAegQICxAB&amp;usg=AOvVaw30aNarB2-jjwObvsKLKE2-)
You can already do that with IronPython which is a .NET implementation of Python.
Depends on whether you want the property lazy loaded or not.
Why not? If there is a valid reason...
WHY NOT? If you want to encapsulate the execution of the script with some logic and you want to do that in .NET I dont see any problem.
well if you already have pulled the data, and it shows what you need, it seems to me is that you need to have it keep doing checks put results to array, break array up and have it update the portion of the array with a task to update again and only update the portion of the array for time. then do a a streamwriter outputFile.WriteLine(line) with path.combine.
Try looking into this repo https://github.com/dotnet-architecture/eShopOnContainers It also comes with books and articles. It may be bit overwhelming from beginning because it's discusses lots of topics on one place but it can give a nice understanding on how build large scale enterprise applications.
I'm sorry but you are wrong. He wants to use .NET to control the script execution. The script will run in a Python environment but the .NET application will control the process execution.
Then I'd still just invoke python.
Believe me or not - but couple of weeks ago I was implementing exactly this at work. The reason was: we already have Python scripts that do that we want, and rewriting this code in c# would take forever for us (10 scripts with hundreds of functions). So we decided to launch it from c# code. Yep, from architect perspective looks somewhat ugly. But currently it is the best solution for us. One caveat here: when you will run Python script from c# (I guess this will be via ProcessStartInfo) don't forget to set Working Directory to the folder where a script file is.
Why add extra dependencies? Just use python.
Have you installed NuGet packages before? Right click on a project -&gt; Add NuGet Package. Search for MySql.Data (search can be finnicky btw). Installing that will allow you to use the code I was talking about in my other comment. If you prefer commandline, cd to your project, NuGet Install MySql.Data.
Removed: Rule 3. Maybe give /r/cscareerquestions a shot.
No problem, glad it makes sense. I wouldn't worry about C++ skills if you're writing C# applications. By basics, I meant there is a library (EntityFramework) that allows you to write different code to interact with the database. In some cases, it's the right decision and saves time / maintenance / complexity. However, I argue that it isn't right for your current program.
That's a weird one, and the weird part to me is where "a tuple of enums for key". That's .. odd. JSON keys are always strings, so clearly the `.ToString()` method on your tuple did a decent job and produced the string `(Young, Light, Nice)`. And then the deserialiser doesn't know how to convert that back. So your options are to provide some custom code that can parse that string into a tuple, or to rework the data stringcture bing serialised so that the keys are simpler, .e.g. ``` "young: { "light": { "nice" : { ... data ... }, etc } } ```
The answer is in the error, create a TypeConverter for the deserialization process to use so it knows how to generate the key.
I've done this when I needed to use python-only libraries in tandem with .Net libraries (screw you arcgis). It wasn't pretty but it worked.
isnt python part of the dlr?
Using .net framework to do orchestration of py? I'm not bothered by this lol but I'm not sure I see a use-case where this would be the "best" solution. HOWEVER. SCCM is technically a dotnet application and it sure as hell can orchestrate py. Ahhhhhhhh yeah if you're a totally free-to-play shop and you're running all centos on hyper-V but you're also a crazy person who replaces bash with python as your default shell... You could then use your motherfucking hypervisors as "serverless" orchestration infrastructure, platformed on a heckin custom dotnet framework. What in the hell is wrong with you? How can I be a part of this project? It sounds great.
I mean if you already have python script that does some job/task, it does make sense. What wouldn't make sense is rewriting python script to .NET language, just so you don't run script from .NET app.
 using LiteDB;
It sounds like a dotnet dev who is memed into "devops" and he just inherited a whole bunch of python for server controls.
One of the main difference is that you can only inherit from one parent class but you can implement multiple interfaces. Also, let's look at my example a bit more closely. And let's examine the naming. "IShape". There's nothing in the interface that actually pertains to shapes so maybe the naming can be better. Let's go with "IDrawable" instead. That way we distance it a bit more from the implementation and concrete classes. With "IDrawable" it seems that it can be used for anything you'd like to draw on the screen. Whether it's a shape, ascii art, or any image. Let's look at some other interfaces that already exist in c#. Like "IDisposable" or "IComparable". These are named in such a way that you know what functionality you gain by implementing them. Rather than just inheriting from a parent class.
Yeah, but what made him think he'd need C# to run those ?
Because he knows how to write C#, right? I mean, you can see it... Unix admins have tons of py scripts out there for their various tasks. None of it is really stringed together, instead they're just executing by bash script. Our boy the OP wants to put a nice front end on all that stuff.
Here is a link to to a tut : [https://ourcodeworld.com/articles/read/702/how-to-record-the-audio-from-the-sound-card-system-audio-with-c-using-naudio-in-winforms](https://ourcodeworld.com/articles/read/702/how-to-record-the-audio-from-the-sound-card-system-audio-with-c-using-naudio-in-winforms)
Or just Python...
I can't believe it's that easy. Is that the same thing as SQLite? Or is that different?
Because OP wants to give future devs a mind fuck who have to maintain his Frankenstein creation.
I guess if you had certain scripts you needed to kick off then that would be ok.
What are you trying to achieve exactly?
A valid reason is that the code base for your framework is C# and you want the flexibility of executing data analytics, deep learning or machine vision algorithms without recompiling... Have the client download the script update into a directory and restart the software. And C# script using Rosyln now requires something like 20+ nuget packages.
This is how azure functions work. The runtime is c#/.net core but can trigger python (and other) scripts
Right, I agree. But for all of my future apps, I need to make them database focused. My next application is essentially just an SQL code snippet runner which will have very specific 'SELECT' and 'UPDATE' statements that will generate (sort of how snippets work in MySQL workbench but HIGHLY customized to a very specific database with very specific needs). I'd imagine I will need the entity framework for that.
I've implemented something similar recently at work. It's not viable to have python installed on each user's pc so I wrote a c# application that has a python environment embedded in it that can call set scripts against the embedded environment. Works quite well
I am calling python scripts to work with FreeCAD from C#
vs 2019 is still pretty new. I wouldn't try using it just yet. I didn't fully switch to vs 2017 until 2018, IIRC.
Not 100% CPython compatible.
Lots of databases support json natively if persistence is what you are worried about. Also, the Newtonsoft.Json library has great support for traversing the JSON tree, such has finding children, parents, parents of parents, etc. It honestly sounds like you are going to hurt yourself if you take a graph and try to normalize it into a table structure, then try to hydrate your object from the tables again. If you need hierarchy, IMO json is the perfect structure for representing that kind of relationship.
Not really. IronPython does not support lots of libraries.
A better solution is probably a client/server model using a local server in Flask or something like that to expose the endpoints. That way you can maintain some abstraction from those scripts if they need to change.
I didn’t need CS front end to get junior devs to run my python script to do all the C compilation python scripting on the back end but piping those results to a GUI was a lot easier for them to grok and only took me a couple hours to write.. probably saved me 80+ hours of headache. Many (not all) of the kids don’t know a ton about python/c/Linux. We had a deadline and it just made sense at the time. The ones that did understand it, had no problem with, but when introducing inexperienced people to embedded development it can make click and read error messages a lot easier.
Y'all guyz are crazy. OP isn't asking "is it technically feasible", he's asking "would it make sense". The answer to that is [here](https://xkcd.com/1205/). Sure, you can do it. But I doubt it's a good plan. If you're working with people so tech-illiterate they can't run a python script (which is totally okay), they should probably NOT run that script. Give them a tool to do it anyway seems a dangerous idea. The thing is, that question can't be answered without knowing what the script do and why you want to run them, hence my first reaction.
You compile C with python and you display it via a c# app ? Dafuq are you working on ?
On mobile. .NET Core supports environment based transforms of the appsettings.json. Check out this doc https://docs.microsoft.com/en-us/aspnet/core/fundamentals/environments?view=aspnetcore-2.2#configuration-by-environment Basically have common settings in appsettings.json, then create a appsettings.Production.json, appsettings.Staging.json, and a appsettings.Development.json to set overrides based on the env being deployed to. Then in the Startup.cs, configure the JSON Config provider to refer to the base config first, then an interpolated env config to override it. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/index?view=aspnetcore-2.2#json-configuration-provider
Embedded lighting controls where the interns and junior devs regularly have to test new hardware in-house. It was just easier, I wrote the compilation script in python because that’s what it is best leveraged for and I don’t trust the kiddos or want to get pulled out of what I’m doing because they don’t have the experience to find the firmware images/bootloaders or even initiate the script properly.
At my current work place, the software that analyst use to extract data is going away. What we have left is a database. The problem is that the analyst do not know SQL. I myself is not a programmer, but do know how to program. &amp;#x200B; I was thinking to create a .NET application that I can deploy on their computers as a user interface, since we all run on windows and execute python scripts on the server. The reason for me to use python is because it so much easier to write quick scripts and return something, via excel, csv to a specific folder. &amp;#x200B; I am trying to find a solution, and time is ticking...they are counting on my to come up with a why for the analyst to access and retrieve data.... &amp;#x200B; Let know if you have questions.
That depends on the type of data you're storing in the fields. If it's data you don't want shown in the UI but be persistent then hidden fields is one way. You could store the data in Session or ViewState (if using WebForms) variables.
Do you want to use MVC, web forms or client side js with a web API backend? Or something else...?
~~Your analyst don't know sql.~~ Wait, so you don't have currently scripts in python ? You plan to write those, to retrieve data in a SQL db ? But you will use .Net to write the front end ? Just use .Net to retrieve the data's. Why include python... ok yeah, it's supposedly easier but if your app is in .net, you'll have an extra overhead in dev and maintenance.
Exactly. I'd say the problem is that JSON doesn't support OP's data model. OP, rather than there being any problem with the (de)serializer, it's doing better than I'd expect.
This is almost the same path I took except it was pre-core. However looking bad I would recommend learning SQL before learning entity, entity is a great tool but it's not perfect and if you don't understand the SQL it's generating it can be hard to optimize
Use React/Vue/Angular and communicate with the backend using api calls.
&gt; JSON doesn't support OP's data model. Well put. But how well does C#? Technically it does, as shown above, but if I saw that in C# code, I'd be frowning, and asking "what are you trying to ultimately achieve and is this really the best way to do it?" I'm also suspicious of "unnamed" types such as tuples or `new { }` expressions being part of the app's core data model. If it's an important and widely used type to you, give it a name: You're coding in an OO language after all. Declaring named class and struct types is a core activity.
Depend when is before :-) Yes we relentlessly improve NDepend for more than a decade: https://www.ndepend.com/whatsnew
JSON doesn't support just *any* object graph. When it looks at a property, it has to decide how to serialize its value. The things it knows how to serialize are: * strings * numbers * arrays * JavaScript objects A "JavaScript object" is probably best explained as, specifically, a set of key-value pairs. The key *has to be* a string, the value can be a string, number, array, or another JavaScript object. That's it. JSON doesn't know what a Tuple is, or even an Enum. But the Newtonsoft library comes with a lot of magic you don't usually have to think about. It tries its best to handle some really common data types, but if you've got something it doesn't know what to do with, things can get strange. The default settings are very friendly and try not to throw exceptions unless they absolutely can't proceed. For serialization, that tends to mean if it can't figure out how to serialize something, it calls `.ToString()`. For parsing, that tends to mean if it can't figure out what to do it will throw an exception. That's where you are. A `Dictionary&lt;TKey, TValue&gt;` can be represented in JSON, but we have to be careful. If `TKey` is `string`, we can probably pretend the dictionary is a JavaScript object. Even if `TKey` is a numeric type, we can serialize it as a string so we're still good. But if `TKey` is not a string or number, the built-in Newtonsoft stuff won't be able to deserialize what it serializes. It's probably just going to call .ToString(). You need to do some more work to make this happen. But that's OK. Newtonsoft saw this coming so they have types that help you tell it how to serialize and parse things that it didn't forsee. You asked for a nudge, not a tutorial, so I'll hold back and give you some hints. To pull this off: * You'll need to derive a new type from `JsonConverter` that can convert the tuple to JSON constructs and back. * You need to create a `JsonSerializationSettings` object that includes that converter. * You need to pass those settings to any call to `Serialize()` or `Deserialize()`. Alternately, you could put a layer between your types and JSON. In the past when I had a type that didn't play well with JSON but didn't really know about `JsonConverter`, I'd make a "JSON Model" type that I could map a thing to and extension methods for `ToJsonModel()` and `FromJsonModel()`.
off topic, but for those who may not know, any type can participate in the var (x, y) = EXPRESSION kind of syntax, as long as the type expression evaluates to has an appropriate Deconstruct() method. It's another one of c#'s magic methods like add or getenumerator.
&gt; things it knows how to serialize are Also `true`, `false` and `null`.
He said he doesn't have much time. Rewriting the scripts could take a lot of time he doesn't have. A temporary solution is to call the scripts and use that data, and then later on write the real .NET application :)?
The suggestion that people are not mentioning is to use a . Net framework front end to call a rest service written in python that executes the data extract scripts. It won’t take much longer and you don’t need to worry about calling python from .net. It also gives you the ability to tightly control access through a user management scheme on the api if you need to. Controlling access through permissions on api endpoints in python is easy as there are several libraries that already do it.
We use AddJson file to include multiple config files. Environment.MachineName allows us to have the config for our dev machines in source control WebHost.CreateDefaultBuilder(args) .ConfigureAppConfiguration((hostingContext, config) =&gt; { config.AddEnvironmentVariables(); var env = hostingContext.HostingEnvironment; config.AddJsonFile("appsettings.json"); config.AddJsonFile($"appsettings.{env.EnvironmentName}.json", optional: true); config.AddJsonFile($"appsettings.{Environment.MachineName}.json", optional: true); }) .UseIISIntegration() ...
SOAP to the rescue!
Dunno if it's a good idea giving people advice about something you've never used 🤷‍♂️ I presume when you say '.net framework' you mean WinForms as WPF is also part of the .net framework. BTW, WPF has a drag and drop designer and property grid like WinForms, not sure why people think it's complicated (it can be but doesn't have to be)
If you're looking for an abstraction for your end users to running scripts on servers, go look at RunDeck. It's easy to use and I think will accomplish what you want without having to write anything new.
Reverse polish notation isn't an algorithm, it's a second form or writing expressions. You use the Shunting yard algorithm to convert In-fix notation to RPN. It is much easier to write a expression processor for RPN.
 I can get why you wouldn't want to build geocities or wordpress crap, but front end nowadays is pretty cool. Don't knock it til you've tried it.
Right! Good catch.
There's no script. He wants to use python because writing script in python could be faster
So what’s the point of wrapping the python in C# in the first place? Why not just run the python.
Are you able to pass arguments via RedDeck to set a value in a script?
Declaring named types is unrelated to OOP. &gt;You're coding in an OO language after all: declaring named class and struct types is a core activity.
The [System.Action](https://docs.microsoft.com/en-us/dotnet/api/system.action-1?view=netframework-4.8) class inherits the [System.Delegate](https://docs.microsoft.com/en-us/dotnet/api/system.delegate?view=netframework-4.8) class. Delegates are immutable which means once they are created they cannot be modified. Using the += operator on a delegate actually returns a new delegate which is a combination of two other delegates. &amp;#x200B; Consider the following code block: &amp;#x200B; Action a = () =&gt; UnityEngine.Debug.Log("A"); Action b = () =&gt; UnityEngine.Debug.Log("B"); &amp;#x200B; Action c = null; c += a; &amp;#x200B; UnityEngine.Debug.Log("About to invoke delegate 'c'"); c.Invoke(); // Invokes a &amp;#x200B; Action d = c; // d is a direct reference to c (they are the same object in memory) &amp;#x200B; UnityEngine.Debug.Log(ReferenceEquals(c, d)); // Logs True &amp;#x200B; UnityEngine.Debug.Log("About to invoke delegate 'd'"); d.Invoke(); // Invokes a .. same as calling c.Invoke(); &amp;#x200B; d += b; // Adding a new delegate to d's invocation list causes it to become a new delegate entirely &amp;#x200B; UnityEngine.Debug.Log(ReferenceEquals(c, d)); // Logs False, d is no longer the same object in memory as c &amp;#x200B; UnityEngine.Debug.Log("About to invoke delegate 'c'"); c.Invoke(); // Still only invokes a &amp;#x200B; UnityEngine.Debug.Log("About to invoke delegate 'd'"); d.Invoke(); // Invokes a, then invokes b &amp;#x200B; &amp;#x200B; To fix your issue, you will need to update the dictionary at the specified key with the new combined delegate (after calling the += operator in AddListener)
Eh.... "weird" is hard to agree with, there's some history. "Just use React/Vue/Angular" is sort of along the right path but I think it's best to know *why* people use those rather than just think gods dictate we have to use frameworks to do things. When HTML is your only tool, there's only two ways to communicate with the server. * If the user clicks a link, a GET request for the resource is made. * If the user submits a form (generally by clicking a button), the form's fields are serialized and sent to the server using GET or POST as specified by the form's `action` attribute. If HTML is your only tool, the only way to submit a form is to click a button. If you expand the world to include JS, you can obtain a refrence to the form's DOM object and call the `submit()` function to submit it without a button. For a long time, this was it. You had to submit a form to GET or POST to the server. If you wanted to PUT or DELETE you were out of luck. So yes, classically speaking, if you wanted to make a request to the server you *had* to have a form and if you didn't really want the form's UI you needed to hide it. And there's not a good way to submit forms without doing a page reload in response. Eventually, JS got a cool new feature that allowed it to make arbitrary HTTP requests. Even better, you could make these requests without having to reload the page. These kinds of requests became known as AJAX, and I used to know what that stood for but now I don't. Having AJAX changed the internet, and nothing made that more apparent than GMail. Every webmail client up to that point had to reload the page every time you clicked on something. They could use framesets or iframes to make it a little more pleasant, but it was always clear you were using a web page. GMail used AJAX heavily and is sort of the first Single-Page-Application (SPA) most people saw. So in that kind of application, you can load a really bare-bones HTML with a fairly large JS framework. When the document is finished, your JS makes some requests to get data from an API. Then it parses the data and generates the correct HTML DOM. You don't have to reload a page in these kinds of applications: your JS can throw away the current DOM and replace it with a different one. That means URLs and browser history get weird, but you can do things about that in JS. So that's what the answers re: "Just use React/Vue/Angular" are pointing at. Those frameworks were designed for pages that want to dynamically load content, and in particular they excel at single-page applications. So in short: * You don't have to use hidden forms to communicate with a server, you can use JS to make REST calls. * If you do that, things get very complicated very fast, and most people prefer to use some kind of framework designed for it today. * It's a big topic and the rabbit hole gets deep.
Oops! You're right u/dArcMadder , i agree with the person above. Its not too difficult
Robert C. Martin? He's a hack. He sprinkles words like 'clean' and 'solid' over his writing to disguise the fact that what he's saying doesn't hold up to critical thinking. Unfortunately far too many people in this industry treat his garbage as a religion. *** These are the books I would recommend: https://www.amazon.com/Framework-Design-Guidelines-Conventions-Libraries/dp/0321545613/ref=sr_1_3?crid=3J8NX6WRHSPF0&amp;keywords=framework+design+guidelines&amp;qid=1561736811&amp;s=books&amp;sprefix=framework+des%2Cstripbooks%2C915&amp;sr=1-3 https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670/ref=sr_1_2?crid=9ZYFF94DDUKL&amp;keywords=code+complete+2&amp;qid=1561736850&amp;s=books&amp;sprefix=Code+Complete%2Cstripbooks%2C357&amp;sr=1-2
It makes literally no sense. OP has no existing Python or .Net code. "I can write Python scripts faster" is no reason to greenfield a project with two languages + interop. Either write the control script in Python or write the entire thing in .NET (.NET can do databases too!?!?)
Just take this example: You have a service to rent instagram bots where you have 1 instance of the bot for each client and the bot script is written is python and the service with web api in .NET. Are you telling me that will write everything in .NET or Python instead of the two languages??
Oh I would never have guessed it by myself hahaha. I really appreciate your answer and I will fix it ASAP. Thank you!!
You would this to save data between posts. The controls (listboxes,etc) will keep their contents, bit if you had auxiliary data to preserve, stashing it in a hidden control is one way to do it. You can also put it in the HTTP cache, or in session. Or just not save it and reload it every time. The tradeoff here being bandwidth &amp; browser memory against database/storage hits.
Yes. I have setup many jobs where you pass params via list boxes, dropdowns and also dependent dropdowns (they call them cascading remote options). We also populate dropdowns via json files which are generated from other jobs.
This makes me sort of cringe, but /u/nandos13's answer is correct and I'm not taking away from it. Actions are not Events. Don't start interchanging them. Actions are a type that represents a void-returning function as a delegate. You use Actions to assist with using delegates, which are used for a lot of things. Events are older, and represented by a delegate type called `EventHandler` and, later, `EventHandler&lt;T&gt;`. There is syntax sugar for events that irons over the fact that they are "multicast delegates", which are special kinds of delegates that can have multiple targets. Every event handler takes one `object` paramter and one parameter that must derive from `EventArgs`. The reason I'm being pedantic here is because "an action" can take just about any number of parameters. You can use `Action` or `Action&lt;T&gt;` or what-have-you to represent "something like events with them. But when a .NET developer hears "event", they should think of one, and only one, method signature: public void EventHandler(object sender, EventArgs e) This enables a lot of patterns but is also a convention that is nearly 2 decades old now. I am being pedantic here because on a previous project, I feuded with the team for a long time over defining events like: public event Action&lt;StupidIdeaArgs&gt; OnStupidIdeaArgs = (e) =&gt; { }; Their argument: "Hey, now I don't have to worry about it being null! Then, one day, we wanted to unit test events. Our mocking framework had methods for mocking events. Great! But when it said "event", it meant "Something that matches the `EventHandler&lt;T&gt; delegate`. Our events did not. So we couldn't use the mocking framework to mock our events being raised, and if I recall that we had used the `event` keyword when defining them *also* meant we couldn't just be smart-aleck and call the method. Words matter. If you're using actions *like* events that's fine. But don't call them events if they aren't `EventHandler&lt;T&gt;`.
c17r has the right answer, but I’d seriously look at the design. Just create a class to wrap those 3 properties. Simple, less code and more readable.
http://pythonnet.github.io/ Look at the examples for embedding python. It works like embedding CPython in a C/C++ environment.
Cool! I will definitely check this out. I love reddit!
I would move the app to MVC and do away with the ludicrous ViewState and/or Session stuff.
Joe’s stuff is great - not to mention he’s the creator of LINQPad!
For a very simple deployment, you need to use the [`dotnet publish`](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish) command, install .NET Core Runtime for the version your app uses on the server and copy over the publish output folder to the server and execute `dotnet &lt;YourApp&gt;.dll` to get the server running. And then you'll need to set up your MySQL server, etc. However this deployment method is far from ideal - Docker is the best deployment method for most scenarios right now
Yeah I knew they were different but I've seen the two words used as synonyms and I mixed them up. Thank you for the explanation, really appreciated!
To be fair, if you know you're just going to be doing Windows and you need to get stuff done then IMO WinForms is better. WPF is too slow to just make stuff quickly with.
My point is that naming often-used types in c# code is a good idea, and goes with the grain of the language. Your is what?
Quite true, I just wanted to point out that there is already a .NET python implementation (and btw there are others such as Python.Net).
My point is that it's nothing specifically in OOP.
was doing a small web app for learning the .Include EF core syntax was correct but kept getting weird errors that and constant visual studio problems with scaffolding things or other small related things that were just annoying that worked before in ASP MVC 5 and Visual Studio 2017
I prefer vs code.
For ASP.NET Core projects stick with VS Code. With a few extensions installed you can have a very comfy C# experience with it. I'd recommend staying away from VS for Mac unless you are working on Xamarin apps specifically. It's been getting better lately, but I've always preferred to use VS Code on Mac.
Maybe it's a web application, on remote server and you need to start this script when do something on site, so you just call start this script in c#
Alternatively, you could request parallels or VMware fusion and spin up and windows VM with VS 19 Community on it. When life gives you a Mac, make it an expensive windows machine.
I feel like for ASP .NET Core I'd recommend VS Code on Mac. I do more Xamarin Forms, and it feels like VS is more set up for that. Something about when I've worked with ASP .NET Core makes me like VS Code overall better. I can't explain it. The only time I evaluated JetBrains Rider, it had a major glitch that made it incompatible with Xamarin Forms, and they didn't fix it for the entirety of my trial. It was really nice for general .NET Development, but I can't tell my company to spend money on a product that's fine with being broken for that long.
Thank you. That contributed nothing.
Working with ADO.NET will almost always be fastest. The benefit with something like Dapper (or an ORM) is that you will have less code to maintain. Since you are already using stored procedures, I would stay away from an ORM unless you are starting to feel that you are writing a lot of boilerplate code. Dapper is nice for materializing queries into entities, but you won't get too much from it with the way you are currently coding.
+1 for dapper if you want to write the sql queries yourself. You will know if you need to use ADO.NET, until then go for EF, Dapper, NHibernate or any other ORM out there
ORMs don't generally construct more efficient queries than by hand and with proper indexing / strategy the difference is typically minimal. Once you begin using LINQ to objects more you will *want* to use an ORM just for the sake of consistency -- trust me it is nice being able to deal with tables as if they were just collections. At the end of the day this all depends on your application requirements and design principles, but at least learning how to use an ORM and what it is for doesn't hurt.
I would learn to use Business Object before ORM.
VS Code for Front End (JS, TypeScript) or quicker edits. Rider for SQL or C# - I find it easier for debugging and anything that may take me more than 5 minutes.
First of all, you mentioned Dapper as being an ORM. It is true it calles itself a micro ORM. The fact that the term ORM is in their description does not make Dapper the same as an ORM. &amp;#x200B; Dapper does not abstract you away from your database implementation because it still requires you to specify the SQL that needs to be executed. Without any extensions Dapper only helps you serialize and deserialize your data from and into your objects. Dapper will remove a lot of boilerplate code that you otherwise have to write by hand. I cannot imagine any application size or type where you will not benefit from including Dapper. Probably this answers your question already. &amp;#x200B; There are pros and cons by using a full featured ORM. &amp;#x200B; Some of the cons that will apply to your situation (such as you describe it) are: * An extra layer of complexity * There are more things that you need to configure/code. * More maintenance on your code * Additional complexity in debugging your application * Less flexibility in where you place your business logic - Complex business logic that you now have programmed in your stored procedures might not fit when you use a ORM * Generating reports where you get your data through your ORM might be slow. &amp;#x200B; The pros of using an ORM are obvious when your application grows in size. I guess you concider your application small but the fact that you are calling it an ERP makes me think that you underestimate the size of your application. Any application that has more than say three different business entities gets complex very quickly. This means that you need to look into code reuse and separation of concerns (layering). When you try to do that you will quickly find out that having any kind of business logic in your database will make your application hard to develop and even harder to maintain / extend. &amp;#x200B; Architecturally speaking having an ORM mitigates a lot of risks that otherwise will reduce the lifetime of your application. Especially in an application that has a lot of dependencies between the business entities. &amp;#x200B; So I guess that my answer is Yes to your question.
Vee es code
I do, but I need it as a part within a bigger project so I have to create it with Visual Studio, which is what the other parts will be written in.
thanks so much.. I believe I have it down. However I wonder if there's a simpler way.. So right now, I have created 2 forms.. both have 2 buttons on top. The first form as an approve button and a close button... When the approve button is clicked, it opens the second form which is the exact same thing except, it has an Unapprove button and a close button.. And same thing, which Unapprove button is click it opens up the first form. This will make it look like it's the same document but the button switches... The reason I did this is so that when I have the button clicked, it will change my boolean in my sql database table. And vice versa with the unapprove button. &amp;#x200B; Is there an easier way?
&gt; The fact that the term ORM is in their description does not make Dapper the same as an ORM. I prefer the term "object graph style ORM" to describe EF and NHibernate. Dapper is barely more an object-result set mapper, the bare minimum for the definition, but there is a lot in between these extremes. The first micro-ORM, literally called MicroORM, was even more simple. It only supported strored procs (ie no online SQL) and dynamic objects and could be implement in about 160 lines of code. Though really just a demo, there are production based ORMs likewise built around dynamic typing. Off to the side there are things like my ORM, Tortuga Chain, which is built on database reflection rather than statically defined mappings. Not really a micro ORM, but not a object graph style ORM either. In short, there is a lot of room under the ORM umbrella.
I have to use Telerik Winform C# to create this. &amp;#x200B; So right now, I have created 2 forms.. both have 2 buttons on top. The first form as an approve button and a close button... When the approve button is clicked, it opens the second form which is the exact same thing except, it has an Unapprove button and a close button.. And same thing, which Unapprove button is click it opens up the first form. This will make it look like it's the same document but the button switches... The reason I did this is so that when I have the button clicked, it will change my boolean in my sql database table. And vice versa with the unapprove button. Any easier suggestions?
Here is what I'm doing in my codes for approval page pretty much the same vice versa: private void approvalButton_MouseClick(object sender, MouseEventArgs e) { //TODO - Form UnApproval Page will pop up, this will close this.Hide(); DocumentUnapprovePage formDocUnapp = new DocumentUnapprovePage(); formDocUnapp.ShowDialog(); this.Close(); //TODO - change data in table to true based on parameter in report reader } private void closeButton_Click(object sender, EventArgs e) { this.Close(); }
 Create an event listener on the Approve button, when it's clicked change the button's HTML text. When the text is Unapprove and clicked, a separate event listener should change it back. In a typical MVC framework you would toggle classes based on the event
No, you don't need any library to do SQL other than what .NET already comes with. I would recommend however that you do consider a simple library like Dapper, just because it'll make it simpler to write correct and easy to maintain code. As an aside, you should really be using `using` statements around your SqlConnection code (and other `IDisposable`s )
Something like: `while (`[`string.Compare`](https://string.Compare)`(Console.ReadLine(), "quit", true) != 0) { }` You'll have to set up any events or threads for doing your work before this.
Having been on quite a few projects, some that do use an ORM, some that don't, I've come to the conclusion that using one is more trouble than it is worth. Dapper however, is such a lite weight ORM it is fine. You still write SQL, it just makes it easier to get the data into classes with good performance. That's fine, dapper is good stuff.
Watch out what these people are recommending. Adding a whole bunch of frameworks to your issue isn't the way to go. Keep everything as lean as possible. You don't need an ORM like Entity Framework, you don't need WPF (you aren't doing anything intensive) w/ MVVM, and don't confuse yourself too much on the 'SOLID' principles. Focus on your main problem right now: software architecture. 3000 lines of code in two win forms is not great. Pick up a book on "Clean Code" and "Implementing Domain Driven Design". Once you get the ball rolling then learn how to Unit Test properly. Avoid these 100's of frameworks like the plague..you DON'T need them and they'll just hinder you from actually learning how to code. These frameworks include: WPF, MVVM libraries, Dependency Injection libraries, Entity Framework and other ORM's.
I really like linq2db it seems to be the fatest ORM that uses linq so you get all the nice strong compile time checking.
VSMac needs a lot of work, but it recently got a lot better with the [new C# editor](https://docs.microsoft.com/en-us/visualstudio/releasenotes/vs2019-mac-relnotes#---new-c-editor) (which is now basically on par / mostly the same codebase as the Windows one). That said, I look at VSMac and VSCode now and then, but ultimately keep going back to the imperfect (slow) but powerful VSWin.
I'd suggest you not to separate your code horizontally into technological layers, but to cut the system vertically, based on the domain functionalities, instead. Here's a post with some interesting arguments, better detailed than what I could be able to do. It mentions Java, but the argument is actually very language independent: http://www.javapractices.com/topic/TopicAction.do?Id=205
ORMs aren't going to make your program more efficient. They'll make writing your program easier and faster. There will always be some sort of performance hit but it's often not an amount that will make much of a difference. If having the absolute fastest code isn't a requirement for you, I don't see much reason to not use an ORM. It'll make your code easier to write.
&gt;The fact that the term ORM is in their description does not make Dapper the same as an ORM &gt;Without any extensions Dapper only helps you serialize and deserialize your data from and into your objects That's what the definition of an ORM is...
I did this some years ago. We had several printing, folding and inspection machines, all reporting speed, material usage etc... Each screen would have a different layout, and could change dependent on the job so I had it intepret python scripts to draw the screen etc... The other advantage was that if something new was being implemented, I could simply amend a script on the fly.
It's a false dichotomy. Even if you are splitting your code by domain, within each domain there is an advantage to sub dividing by testing strategy.
Nope. An ORM is a part of software that helps bridge the object relational impedance mismatch. https://en.m.wikipedia.org/wiki/Object-relational_impedance_mismatch This involves more than just mapping a row of a result set to an object instance.
Desktop link: https://en.wikipedia.org/wiki/Object-relational_impedance_mismatch *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^264071. [^^Found ^^a ^^bug?](https://reddit.com/message/compose/?to=swim1929&amp;subject=Bug&amp;message=https://reddit.com/r/csharp/comments/c6nvjq/should_i_be_using_an_orm/esaijiy/)
How does dapper not help bridge the object relational impedance mismatch?
It's less about mapping and more about writing. With a full-fledged ORM like EF you actually write your business logic in managed code. With dapper you keep on writing stored procs.
But that's not what makes an ORM an ORM... There's no question that Dapper doesn't have as many features as other ORMs.
http://www.catb.org/esr/faqs/smart-questions.html
It’s good to know an ORM as well as understand the fundamentals. From a practical perspective you will probably use the ORM as much as possible and write your own custom stuff when you need to fix a performance bug or break the rules. Dapper is great at filling the cracks in a more full featured ORM.
Apps written in .Net core can be published with all their necessary dependencies, and can be built for any platform.
Even faster - a contiguous struct of arrays...
First learn what a **using** statement is
Are you sure it's happening on that string?
1) This is hex, not C# code. 2) The '' is a null character, it's not a character there, you are correct, because it is not a character. 3) What are you trying to do that relates to C#? Are you trying to reverse engineer a binary by using a Hex viewer to disassemble? A game perhaps? The other commenter's link is a good bit of info. If you want help, please explain in detail what you're trying to do and why you're sharing this and not C# code... As it is now, this isn't a C# question, AFAICT.
I cannot help, sorry, but there are services online where u can buy code reviews. Maybe you take a look, i hope it helps.
Ok ok I got you. Is the sqlconnection object one of those "idisposeables" that should *always* be in a using?
Just use .NET core
the only way to do this properly is include the runtime you need with your program in the installer.
two things you probably want to look in to are the [Haversine Formula](https://en.wikipedia.org/wiki/Haversine_formula) or possibly a database that supports geolocation queries, which will probably have the haversine distance built in. There are also likely some data structures you could use that would be very efficient at finding "nearest neighbors" but since you're talking about thousands of store locations you probably want to go with a database based solution that will already use efficient data structures automatically.
You are right let's not debate semantics. As long as that we can agree that there are multiple aspects of getting data stored in an object graph in and out of a relational database then we can call all these types of software ORM's. But it's important in my answer to the OP to make a distinction between Dapper and things like EF or NHibernate.
Exactly, it is a web app
And I think they do a great job of making that distinction by calling it a "micro ORM". Trying to redefine what an ORM is to make a distinction that already exists is just confusing.
I've found myself utilizing these lightweight micro ORMs for the very reason I tend to hoist IL assembly of entity concretions to the run-time inside their own application domains. This may get supplanted with containerization in the model but that still lends itself toward purpose specific meta programming all of which can be stored and used to stand up your environment with minimal flat-file style configurations. I figure if I am going to complect my application to the database I might as well go all the way and define the entire dynamic environment inside that database. Micro ORM's help tremendously in these use cases.
At least modern ORMs are not CPU bound. I've seen far too many that spent 50 to 99% (yes, 100x slower than direct dB calls) on doing internal bookkeeping rather than waiting on the database.
The performance hit isn't seen in the individual database calls. Rather, it happens because of your access patterns. ORMs tend to encourage doing more work client side when it should have been done in the database. The net result is more round trips and more strain on the database and network.
Yep. Always check the docs to see if the class implements IDisposable.
I have used Hibernate in the past for some Spring Boot work and i have to say, after using Dapper on some of my most recent projects. It's very very nice and easy to use. Also, if you are willing to write some pretty simple wrapping code you can use it seamlessly in your service layers and i actually find it more convenient to work with than EF or \*Hibernate. I like to eliminate "magic shit" from my codebase whenever i can
Yeah we have written a wrapper utility around dapper at work, and we use that utility to make sure when we call IRepository.Update(obj) that it's wrapped with some default using, logging and error handling. It's really nice.
If your forms share common fields, you might want to read up on databinding. You'd have a model class 'Form' with common fields (I'd, Name, Author, CreatedDate etc). You'd inherit from this model and add form specific fields in the derived classes such as MySalesForm or MyExpenseForm You'd then create a proxy class that has get and set accessors for each property. When it sets the property it should raise an INotifyPropertyChanged event. This is where the magic of Wpf starts to become apparent. Now if the property changes, you can do things like enable the approve button only if certain fields have a value etc. (Rather than using a click event on the button you use the command property) You would create a ViewModel called I dunno, 'FormViewer' It would have two ICommands Approve and Reject which. Theese bind to your buttons and only become enabled when your validation passes. Search MVVM if I'm not making sense. If you want a few things to read up on, a typical WPF app for me includes the following: MVVM, SOLID, TPL, IOC, RX, REST, Fody, Expressions, reflection, Linq to name a few
You should always close a database connection at some point in your application's code. Disposing the connection also closes it. The using statement just makes it easy at the code level but it is not a requirement. You could make a class that is disposable itself and close the connection in the dispose method. Or you can close the connection in the finally block of a try catch. As long as you close the database connection at some point.
give this man a medal
async await took care a lot of those woes.
Nice! Dapper is great for that kind of work. I like NHibernate when things like caching and changetracking become important. Also the composability of Hibernate's queryover can have some nice benefits which will be difficult to implement using Dapper. So depending on the requirements of the application I make different choices.
Ohh I didn't know, thank you! I'll look into it.
I didn't say it was. The overhead is caused by a few different things, those sort of access patterns being one.
You can download the runtime installer when needed as to not bloat the application installer.
Ok lets agree to disagree. The point Totalmace was making (with my apologies) is that "...Dapper does not abstract you away from your database implementation" which is correct.
I can help with the c# code and EF Core.
Even for synchronous calls, EF Core is easily 3 to 5 times faster than EF 6. In RawBencher it is nearly indistinguishable from raw ADO.NET calls.
If you want a good path for learning here's what I found Does your app get hard to maintain as it starts to evolve? Do you need more flexibility and reusability? Learn MVVM Is your app running slow despite your 8 core i9? Learn about dispatchers the taskpool and TPL library in general. Want to swap out a major feature of your app but don't want to spend ages rewriting and rewirting it? Learn about dependency injection and how architecting for an IOC could benefit you. Did the learning about TPL get you into a multihreaded headache? Has handling all theese ui events in a multihreaded context got you sweating at night? Learn about Rx Writing the same code over and over, learn about IL weaving.
And that's a totally valid statement that I never took issue with.
can you explain a bit more about this wrapper? I really like the idea of Dapper but my colleagues dont want to lose some of the features of EntityFramework that we currently use. Looking for ways to ease the pain if we ever switch.
Yeah they must have had some funk overhead going on, maybe reflection and lack of build caching and use of expression trees for get/set ops? Be interesting to see where their inefficiencies actually sat.
I use visual studio 2019 on parallels, and fall back to visual studio on mac when I need to.
I'd say 4.6.whatever 4.6.2 was released like 3 years ago so that should be stable enough. Otherwise, Id stick with 4.5 https://en.wikipedia.org/wiki/.NET_Framework
So, first off, yes - SignalR will allow you to do real-time notifications. But there are complexities here that may bog you down. Why do you think you need real-time notifications? What problem does that solve? Isn't this something that can instead be solved with a non real-time report? Or are you trying to solve the problem of limited resources (e.g. ticket sales and limited quantities of things)? There are other patterns besides real-time that could be easier to implement and/or work just as well for your use-case.
Identify your actual requirements. Why do you need real time updates? What is the desired workflow? You can likely address your needs without it being ‘real time’.
You don't use ORMs to make the program more efficient. You use ORMs to make the programmer more efficient. For small apps, I use dapper. For larger apps I use EF Core and [EF Power Tools](https://marketplace.visualstudio.com/items?itemName=ErikEJ.EFCorePowerTools)
That’s an interesting topic, not true in all circumstances, and this approach happens to be one where it’s not so clear which is better. For any given tree node you need 3 out of 4 of these features and decision trees tend to jump around in memory, only 5 of the average 50 nodes in a tree are touched for a random sample, so spreading out the values across memory pages doesn’t really improve spatial locality. It’s not clear if it’s a negative either however, in our experiments we didn’t see much improvement using a strict of arrays with this approach but we also didn’t put much effort into once we realized the fundamental issues with this.
I just thought if I did real time updates that would be a plus for my product. For example, I don't want the user to refresh manually to see in the dashboard what others users in the same store have sold. Is it overkill?
The string has the text representation of ASCII hex codes in it and at index 2 is the space character between the 46 and the 69, which is not alpha numeric. Are you trying to convert the string to an integer or bytes? You'll probably need to split it into individual parts first and convert each one separately.
Honestly as someone with a *very* strong SQL background I very rarely see the point in using an ORM. I almost feel like most of the people claiming they speed up work are just slow at writing proper SQL. There's definitely some cases where they're helpful, but I feel like they're really overused by people who hate the database end of things.
Maybe this [doc](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.2) will help. Looks like you would want to inject the ILogger into your controllers' constructor and access it that way.
Removed: Rule 4.
EF 6 is incredibly subquery happy; nearly anything that involves a join will generate a correlated subquery. It's easy to get subqueries nested 4-5 levels deep if you're not actively trying to avoid this. I'd be curious to find out if the reason for this is that using subqueries all over the place is probably the simplest way to support the OData spec. I would guess the poor performance is a combination of deeply nested subqueries and too much bloat (although I will say MS code, at least from what I've read through, tends to be pretty good with caching the getters/setters built through reflection and so forth, so I dunno if the bloat comes from that). EF Core doesn't generate nearly as many subqueries. It also breaks large queries with multiple to-many joins up into multiple smaller queries to avoid monolithic result sets.
Something. Even my simple reflection based version was kicking their ass. Now I have to use runtime code generation to get close.
I did something similar to this on a website I made recently. I had some Javascript with google api getting the users location and saving to a hidden field control value. Then in the code I use the GeoCoordinate class. You can create coordinates and in the constructor add the latitude and longitude. And to get the distance use GetDistanceTo method. More details found here on the GeoCoordinate class https://stackoverflow.com/questions/6366408/calculating-distance-between-two-latitude-and-longitude-geocoordinates And in terms of the Javascript for getting the users location you’ll find a tonne of info if you search
Sounds like a good way to blow out the cache if you need to access more than one field / property during a single processing cycle.
It certainly feels like it makes things faster at first, but as a project gets bigger and more complex it will tend to get in your way. Some people manage to master all the workarounds for those issues, but perhaps that same cognitive load is better spent just writing the sql.
Rider is the best IDE on all OSes
If your audience is on Windows 10, windows update will keep the latest version of the framework installed. If they are not all Windows users, then use dotnet core, since it's cross platform. If they're on Windows 7 or earlier... what are you doing with your life?
I'd take a look if you need some eyes on it. I'd be a lot more useful on the backend side and some of the deployment stuff than the Angular.
I think it's overkill. I would suggest pushing for solid POS functionality over unique features. Managers are used to pulling sales reports. Sales people don't care unless there's a contest or unless it relates to tips (US). Worry about system speed, taxes (different taxes in different cities, counties) and reporting that they want: net sales, per cashier, system, and over time. If you do food service, can you handle different taxes for eat-in vs eat out taxes? Alcohol- different taxes. Different taxes for mixed items on a bill is a thing. Different tax precision (US east coast has some 4-digit precision). Split receipts. Quantities. Partial quantities. Have you solved printing receipts? Super long receipts? Receipt reprints. How about credit card sales and cash? Do you need to worry about PCI? If you have multiple "registers", do you need an offline mode? What happens if the "cloud" is unavailable (hint - it should still work)? What about returns/refunds? Price adjustments? Discounts? This is basic functionality in many POSs. Don't solve these all at once. Do the functionality your current customers want now. Enhance when you have a customer that needs it. I've done POS before - this is just the start...
Framework 4.8 is supported back to Win7 SP1 but might not be installed on a user's machine. Framework 4.6 was the version that came with the original version of Win10 and us supported back to Vista SP2 If you want to support XP you have to use Framework 4.0
One of the YouTube channels that I watches always reinforces 'learn on a need to nerd basis' And I really like that. I really want to learn the fundamentals because a house that is built on a cracked foundation is not going to be structurally sound. I guess what I am struggling with is figuring out which technologies or frameworks I need for the next few projects I plan on working on which are going to be heavily databased intensive. I have a very large database with hundreds of thousands of rows across dozens of tables with a very complex schema but I know the database inside and out and I could dozens of custom queries for it daily. My next project is going to be essentially a snippet app where people who do not know SQL could select options on a WinForms app and the query will write itself and process while exporting the results to a data grid. this will allow my administrative assistant to run complex SQL queries which only I am currently capable of doing because he has not learned a language and has no intention to learn SQL. For a project like that, don't you think it would make sense to use the entity framework? I I'm using MariaDB 5.7 And I am having an incredibly difficult time mapping data from the database into visual studio. If I'm not mistaken, isn't this a major used case for the entity framework?
Thank you! I ended up figuring it out! Appreciate the time you took to reply though 😊
I would use a data access layer to return data. You don't need all that dataset and adapter stuff. I would wrap your db connection in a "using". Here's a quick Dapper implementation. //////////////////// using Dapper; using System.Data; using System.Data.SqlClient; using System.Linq; namespace ConsoleApp1 { internal class Program { private static void Main(string[] args) { //you may want to inject a data access service instead of instantiating var da = new DataAccess(); //get data var customers = da.GetCustomerList(); //fill ListBox using customers here } } public class DataAccess { //maybe store this connstring in config private string _connString = "Server=yourserver;Database=yourdb;Trusted_Connection=True;"; public string[] GetCustomerList() { string[] customers = null; using (var conn = new SqlConnection(_connString)) { customers = conn.Query&lt;string&gt;("dbo.TEST_GET_LIST", commandType: CommandType.StoredProcedure).ToArray(); } return customers; } } }
I'm not a SQL pro, but as someone who is comfortable with it, when I first tried EF, attached a logger to it, and saw the queries it ran, I was appalled by the incredible overhead it introduces just to get some data. I rather write my SQL myself thank you very much. Like others said: Dapper is cool though - once you run your query, it saves you the need to manually build your objects from the results.
If you don't want to use Dapper, you'll need to write more code: public string[] GetCustomerList() { string[] customers = null; using (var conn = new SqlConnection(_connString)) using (var cmd = new SqlCommand("dbo.TEST_GET_LIST", conn)) { //customers = conn.Query&lt;string&gt;("dbo.TEST_GET_LIST", commandType: CommandType.StoredProcedure).ToArray(); cmd.CommandType = CommandType.StoredProcedure; conn.Open(); using (var reader = cmd.ExecuteReader(CommandBehavior.CloseConnection)) { var tmpList = new List&lt;string&gt;(); //using System.Collections.Generic; while (reader.Read()) { tmpList.Add(reader.GetString(reader.GetOrdinal("APP_ID"))); } customers = tmpList.ToArray(); } } return customers; }
I sometimes feel like I'm starting to get a decent grasp on C# after having been writing it professionally for four years, then I read comments like this and am reminded of just how little I actually know.
Because OP sets 2 values at one place and reads 3 values in another from the same array. It's just a bit weird. Do check the portions of code I have extracted from OP's question for further reference.
I would recommend parallels over fusion as it has WAY more integrations between macOS and Windows that makes it 10x more productive to use vs fusion
I thank you for this knowledge I hope I never have to use.
Jetbrains Rider
What time zone are you in? Anything specifically you want reviewed, or just general review? Happy to have a look.
Ahhh... like Stack Overflow. I’ll remember that.
Utc+12 Nothing specific, but I'm most concerned about security I guess. Generally just need to raise my confidence level or identify areas that can be improved.
Thanks, I'll let you know
Got a public repo to share, or keen to do it in person? I am utc+10, so that's not too rough
Take some time to update your post. 1) So you don't waste people's time who do respond trying to help. 2) So you can help others who come across the same issue.
If you're wanting to get events when processes start and stop, you need to use WMI. In c# you can use ManagementEventWatcher. I've used it before to watch for processes starting/exiting [here](https://github.com/sbarrac1/Inputshare/blob/master/InputshareService/SpMonitor.cs) . It should be fairly simple to adapt that to what you're wanting to do.
Unfortunately not very well supported by C# at present.
Entity framework with linq is super simple and easy to use (for the basic stuff) If peak performance is not your concern it’s the best option.
Cool article, I had no idea struct alignment worked in c#!
ADO is faster in theory than something built on it; in practice it's usually (slightly) slower. The API is quite impractical, and that means you'll often use less than optimal patterns to remain at least a little practical. In any case the difference is fairly minor. If you *really* care about perf make sure you're not using anything that uses ADO.NET: the library itself (at the very least all implementations I know of) is very slow, and implies a lot of unnecessary virtual method dispatch, boxing, and generally chattiness. On real world queries I often measure more CPU time clientside (even when the client simply dumps the results immediately) than in the db server, and if you test the perf of something like SQLitePCL.raw vs. system.data.sqlite (which is in-process so you can't as trivially separate server from client), throughput for trivial queries can be an order of magnitude faster; it's really not a small difference at all. Most of the DB stuff I work with can stay in memory; so CPU and memory overhead matters more that disk (because you're not hitting that anyhow). Obviously once you touch the disk none of this matters anymore, usually even if it's a very fast disk like optane. In any case: coming from an sql background, dapper is a good place to start. It's simple; usually fast enough, and anything faster is going to be much more special case and usually more complex.
I'd like to point out one more downside to EF (a full-fat ORM), and likely all full-fat ORMs: They aren't really abstractions, they're utility belts. The implementation details leak through in all kinds of places; you *cannot* use EF well (and most certainly not efficiently!) without understanding both EF, and how it maps to SQL, *and* your db server. That doesn't mean you can't get a lot of value or shouldn't use them - you should! But it does take considerably more expertise to do so well, and if you have a bunch of people without that expertise just hack away at it: you're much more likely to have an incomprehensible mess than you would with raw sql when it comes to figuring out why some specific execution is slow or deadlocking or whatever. The laziness, the navigation properties, the rarely but occasionally bad sql, the implicit query tracking, query compilation, implicit client-side query complilation, and let me emphasize laziness again: they make it really easy to have spagetti. Hiding a shared resource use (a connection) behind a lazily enumerated api is not the best of ideas. And while I was totally gung-ho about LINQ when it was released, retrospect I think it's unfortunate that LINQ has largely the *same* syntax as C#, because ORMs cannot honor that, so there's an eternal pitfall as to what is executed where, if something can execute at all (quick, which overloads of Substring are client side and which server side?). It's not just perf too, semantics of EF ORM LINQ are subtly different from the directly executed C# equivalent, which can cause bugs. None of that is a good reason not to use EF; it's just much more complicated and a much longer learning curve.
You’re wrong about a few things. Primarily the use of EventHandler. This is simply a shortcut tool. You can use any delegate for an event. You do not need to use EventHandler
A struct with arrays inside it instead of a struct with an array of other structs... Pass by ref to prevent stack copying as well.
No idea, we just moved into 4.7.1 back in January for new projects.
No idea, we just moved into 4.7.1 back in January for new projects.
Purely anecdotal, but all the servers and clients I work on have at least 4.5.1. &amp;#x200B; That was the default install for Windows 8.1 and Windows Server 2012 R2. For prior machines (Windows 7/8 or Windows Server 2008 R2+) it's highly likely that some other bit of software has required 4.5.1+ to be installed anyway. It's incredibly rare to find a machine that doesn't have 4.5.1 installed these days, so I target that. &amp;#x200B; This may be useful: [https://blogs.msdn.microsoft.com/astebner/2007/03/14/mailbag-what-version-of-the-net-framework-is-included-in-what-version-of-the-os/](https://blogs.msdn.microsoft.com/astebner/2007/03/14/mailbag-what-version-of-the-net-framework-is-included-in-what-version-of-the-os/)
As [this SO post shows](https://stackoverflow.com/q/262280/4255824), you can get a reference to a process by its name: Process[] pname = Process.GetProcessesByName("notepad"); if(pname.Length == 0) Console.WriteLine("nothing"); else Console.WriteLine("run");
ADO.net is CPU bound on the client side, and EF is considerably slower. To pick an extreme and not entirely fair example: EF on sqlite probably is around 100x slower than sqlitepcl.raw for the simplest plausibly real-world queries. And if you're not precompiling everything, then perhaps more complex queries too.
If I'm not mistaken, it might also be useful to be able to use the "is" keyword to check whether an object has implemented a given Interface, such as: if (object is IShape) { // do Shape stuff }
.NET core rather than .net framework.
Yes you should be using one. Its a hell of a lot better than the other options. People talk about performance. Write readable code, write performant code when you need to.
You should *always* be ``using`` an IDisposable unless you have very compelling reasons not to do so. The only counter example would be HttpClient, and I consider the fact that ``using`` it can cause problems a massive design flaw.
Agreed. Performance comparable or better than Dapper, with LINQ and support for more intermediate SQL e.g. CTE, window functions, etc. I refactored the query side of my CQRS system to Linq2Db and I'm very happy with it.
I don’t know if this is applicable for your situation, but you can do multitargeting. eg. I package some libraries on NuGet with support for both .net framework 4.5.2 and .net standard 2.0 in a single package to get maximum coverage. (In my case I get away with exactly the same source for both, so it’s just a few lines in the csproj, YMMV)
I find it really depends on the project and what your role/scope is within a given project. ORMs can save huge amounts of time beyond initial application development. Being able to automatically generate scripts to manage database up and downgrading across a variety of target database platforms is a huge feature that developers aren't always positioned to care about. I love the database end of things, but there comes a point where I feel my SQL knowledge is wasted on writing business logic queries and scripts. I tend to avoid SQL until reporting, at which point the report is usually going to be bespoke enough that I can tune it to the target platform.
I assume you are working on web forms given how you call it an asp field and have a code behind(asp:textbox for example) so I'll make a few comments based on that. One thing that someone needs to get their mind around coming to web development is that it is stateless. This is a different paradigm for sure and it seems Microsoft created webforms as a way for desktop devs to more easily switch over to web development. Unfortunately there is a lot of bad things that were done(viewstate, drag and drop elements, update panels, etc). More so the viewstate as that was a big attempt to create a state in a stateless environment. Anyway, if you are using webforms please switch over to mvc and at least use razor views/templates for the UI. Microsoft stopped supporting this9webforms) a long time ago and even the developers of webforms said they made mistakes. If you are new to web development, i'd suggest holding off on learning a whole new tooling with other frameworks or libraries(angular or react). Hidden fields have their place, but avoid doing something because you have noticed a lot of developers have been doing it and continue to. That doesn't mean its right, more than likely all it means is they saw someone else do it and just did it(or it was the easier way or maybe they just don't have the skills yet to think differently). I suppose this is another discussion, but my 2 cents on it. You only know what you know right? I'd suggest starting a free trial with pluralsight and knock out a bunch of the [asp.net](https://asp.net) stuff. If you are excited about that i'd shift over to the .net core courses as that is the next framework step Microsoft has been taking.
Several thousand locations really isn't very many when we're talking about point-set data. Because the data set is store locations I assume the data set also pretty much never changes, so it's a good candidate for caching. The fastest thing is to just keep it resident in memory. There are lots of efficient data structures for point-based queries, and they all fall under the umbrella of a [Spatial Index](https://en.wikipedia.org/wiki/Spatial_database#Spatial_index), you'd have to choose whichever one meets your specific needs. Personally, I think for a data set this small it's not worth adding the complexity. Just keep the point set cached in contiguous memory and do a simple linear search using a Geo location distance metric. Should be blazing fast. The HTTP overhead is likely to dominate on total request time compared to finding the N closest points.
.Net has a GeoCoordinate class. https://docs.microsoft.com/en-us/dotnet/api/system.device.location.geocoordinate?view=netframework-4.8 You can pop the user's lat/long in, then loop through the lat/long data for the stores to build a second GeoCoordinate class to then use the .GetDistanceTo() method to help find the 10 closest stores. How you go about implementing that I'll leave to you.
Dapper is an ORM. It maps relational database models to objects.
Use an ORM. They handle the crappy bits around errors better than you will, they manage relations better than you will. &amp;#x200B; Also, don't use an ORM unless you've benchmarked it against your current code and understand the performance change. Sometimes easily readable code i s better, sometimes you have to slap the metal. &amp;#x200B; I'd say there are also some issues with your code. The connection is only closed if the entire method completes without exceptions. I can't remember what the impact of this is these days, but it used to screw stuff up.
I am a Mac user at home and I would still recommend using a VM. VS for Windows is much better than VS for Mac.
Ahh gotcha. I use Angular regularly and we have some better MVC applications. I mostly run into this with our huge and outdated legacy applications, but I see it happen in some new ones too. That's where I was a little thrown off.
Is it only me who is having issues with Rider and installing nugets? It doesn't seem to support to run powershell scripts or run config transforms. Am I doing something wrong?
Thanks for the detailed explanation! It's good to hear the history. I think I was in the web world for some of it, but I wasn't doing that kind of work yet.
Not to be snark but perhaps the company should rethink if they should just use an OpenSource ERP [https://opensource.com/tools/enterprise-resource-planning](https://opensource.com/tools/enterprise-resource-planning)
I honestly hate using entity framework - most popular c# orm. It's not only over 10 times slower than Dapper, but the extra layer of complexity makes it really hard to debug if the application grows. That's the case in my company actually. We are rewiring everything. Switching from Entity Framework to Dapper. And that would be my recommendation. If you work with SQL, Dapper would fill quite natural to learn. It's also fast.
Yeah, but it makes the EXE size very large. You're basically installing a sizeable portion of the .NET core framework.
See here: https://blogs.msdn.microsoft.com/astebner/2007/03/14/mailbag-what-version-of-the-net-framework-is-included-in-what-version-of-the-os/ Looks like Windows 7 came with .NET 3.5.1, while Windows 10 comes with 4.6 and includes 3.5.1, but (strangely) 3.5.1 is *not* installed by default. Not sure what to tell you.
Here is why you use an ORM: * You can write code that is much more reusable than stored procs. * You can write statically typed code. * You can write code that is much more expressive. Writing SQL is like trying to write a novel in a language with 200 words. You can do it but it's difficult. * The development and debugging experience is far easier. Make sure you use an ORM for the right purpose: ORM's are for line of business apps not ETL apps or some other specialized use. If you used an ORM like EF and you did not realize these benefits than you probably used it incorrectly or used it for the wrong purpose.
Thank you. That example makes a lot more sense. When I wrote this post, I understood and do understand how to make one. I just didn't get the why. This makes far more sense in a real world application. :D Thank you so much for explaining that.
I am using visual studio. The main problem with my understanding is that I come from Python. As a hobby, I have been following a C++ tutorial online. I enrolled in college and after signing up for everything, my adviser called me. He said I needed to take more class and gave me 3 options. I chose "Intro to software development." It was not intro to software development. It is an MTA course. That's fine and all but I'm feeling very out of my depth with C# as it is extremely different from Python and I see almost no similarities to c++. Not that I would expect to, I didn't get far in the tutorial. I kind of abandoned it for the time being while I focus on school. I don't know how much I will have to learn but interfaces are on the test and the written material is about 2 pages and contains no good information except the how to implement them so code runs. There's no why or when you should use them. Visual studio is pretty cool for c# though. I don't care for it for c++ or python but it's like it was made for c#, probably was.
yeah I got the how. The why was super fuzzy. That example and the example someone else gave was super helpful, being a real world example. For some reason it was easier to follow the why in that. I appreciate it. :D
One piece of hard-won advice: never add extra functionality that is not part of the spec. What seems like a simple feature to add will usually multiply many times in terms of your effort due to unforseen complications, bugs or user change requests. Your goal should always be to constrain the scope of the deliverable as much as possible - not to arbitrarily add to it.
Python has interfaces too. In Python 2 you declare some class with abstract methods and you can use it as interface: class IFile: def open(self, name, mode): raise NotImplementedError def close(self): … … class CADFile(IFile): … class WordFile(IFile): … etc. In Python 3 you can: class IFile(ABC): @abstractmethod def open(self, name, mode): pass # … and so on... Actually something like interfaces exist even in Haskell: with typeclasses. IDea is super-simple: you define some API or contract as set of methods. These methods are declared by their names and arity (number or arguments) in Python 2, or with names and signatures in C# (arity and types of arguments), etc - mostly you can find interfaces in most modern languages. So, those interfaces methods are only declaration (arity/signature, but no body - each implementing class will have own body for them). Then you declare that some class implements interface: by defining the methods of the interface, but now you write the body. So now you have class which has the same set of interface's methods, with the same arity and signature (if language supports static types, like C#). That's all. Why do you need them? Because you can implement the same interface in different classes. And each of them can be easy replacable with each other - you will use it's functionality through common interface. This is intuitively understandable if you will try to find analogues in the real life. For example, each smartphone has a lot of interfaces, but some of them are common for all smartphones. And if you will try to use my one (it's different from yours) you will understand how to use it because you will use the same interface, without to know how "methods" "bodies" are different. If you call `IFile` interface method `open` you are not interesting about the body, knowledge of interface is enough to use it. That's all.
That's not just rider, nuget is dropping support for running powershell scripts and content transforms in newer versions.
Do you have any benchmarks or are you just making stuff up?
Eh?
Oh I had no idea. I've had the issue since I started using Rider about a year ago. But it always worked fine in visual studio. Do you have any link were I can read more? I tried googling but didn't find any relevant information.
https://devblogs.microsoft.com/nuget/nuget-now-fully-integrated-into-msbuild/ Read the heading "Will existing NuGet packages work if I am using PackageReference for WPF, Windows Forms or ASP.NET projects?" "Some examples of scenarios that will not be supported include **content folders** (we have introduced ContentFiles), **XDT transforms**, **PowerShell scripts i.e. install.ps1 and uninstall.ps1** (only init.ps1 is supported) ." I would guess init.ps1 will also go away in the future.
I ran exploratory benchmarks a while back of dapper vs. sqlitepclraw, and am extrapolating from that. I'll see if I can dig em up; but if you're honestly interested, I'd advise you run your own benchmarks. Details matter hugely in setups like this.
Understand that if you build the application with .NET Core, you can still reference packages and libraries that require .NET framework. This is both a pro and a con. If you're looking to run this program in non-windows environments, meaning environments that do not support .NET framework, make sure to look for packages and libraries that do not have such dependency.
I’d look into Azure functions too, instead of having a full fledged web app. Serverless is quite nice and I’ve been using it a ton lately.
don't feel bad, that's some /r/iamverysmart material above
&gt; (strangely) 3.5.1 is not installed by default It uses v2 of the runtime and .Net Framework versions that use the v2 runtime have largely fallen out of use, whereas .Net Framework v4+ all use the v4 runtime.
I've used geodesy for a similar problem, it was easy to configure and use. It relied on using a third party Api to geocode a street address for lat/lon coordinates. As you already have the users coordinates it should be trivial to implement.
Thank you! I did!
Take a look at the micro orm space because they generally provide you with the ability to do everything by hand as well as provide some abstractions to make some basic querying and mapping easier. Some have been mentioned by many here: * Dapper * OrmLite which contains dapper * NPoco Are some of the ones I've used, being the most familiar with OrmLite which allows you to write pure sql with the ability to map the result into classes.
Public repo?
Maybe it makes you feel better to tell other people they don't understand things, but you'd be a more likable person if you explained what you thought instead of including the condescension. Like I actually don't know why the reference source has a Delegate.cs that [throws if you try to multicast](https://github.com/microsoft/referencesource/blob/e0bf122d0e52a42688b92bb4be2cfd66ca3c2f07/mscorlib/system/delegate.cs#L325) and a separate MulticastDelegate.cs that doesn't. My guess is it swaps between them internally and single-cast is more efficient. You didn't include that, just the gut punch. You didn't answer any questions. Delegates and events are the same thing. But if you hear the word "event" as a .NET developer, I think you should expect the `event` keyword and the `EventHandler` signature. Moq agrees. The Reactive Extensions agree. Visual Studio agrees. Framework Design Guidelines agree. It's sort of just you and my old team out there saying it doesn't matter.
I think you have to be sure your Process(Putty) is started Maximized. To ensure this you can use `ProcessStartInfo` class' WindowStyle property. See second example's OpenWithStartInfo() method: https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.process?view=netcore-2.2
Have you considered using built-in Windows 10 ssh instead of putty? (I assume thats why you try to use putty)
Unfortunately, we have to use Putty since it's part of our job.
Thank you for the suggestion. I already tried that but Putty just refuses to open normally. It's just weird since I am able to run my application on my Computer with no issues, but it refuses to work on a different one.
I have no solution but what I can say is that I have noticed a very similar phenomenon but with completely unrelated apps. I have been using computers running Windows continuously since Windows 3.11 and in all that time on two occasions I’ve had two apps that did not ever show a window (it was impossible to maximise them). One occasion was was on Windows 8, the other Windows 10. My conclusion was that it was an OS-level bug. i.e. UI code that worked on previous Windows had a bug introduced in Windows 8. So not your fault.
Garbage.
I would suggest the issues were due to it being in preview (as I've never heard of anyone else getting weird unexplainable errors with EF core). Did you try using a supported version? That's generally recommended especially if you care about tooling issues.
ngl it’s quite bad, also there are already hundreds of tutorials that cover these subjects..
Thank you so much for letting me know about this. I am currently looking at ways to essentially "force" the window to maximize. So far, all I got were a few "No access" messages from windows.
Just because you have to use Putty for your typical workflow why does that mean your app also has to use Putty?
https://www.humblebundle.com/books/programming-packt-books Direct link not needlessly pointing to twitter (and likely a referral link).
You apparently did not notice the first line of the Delegate class - it’s abstract. The MultiCastDelegate inherits from Delegate, and is the only concrete implementation. When you use the “delegate” keyword, you are referring to MultiCastDelegate The fact that you keep having this argument could indicate that you are incorrect.
&gt; ADO.net is CPU bound on the client side That doesn't sound right. I'd assume if I used the sqlclient the request would be sent to the sql server instance where the work would happen.
Include the free MS SQL Server Developer edition. It's the full SQL Server version. localdb is a poor comparison.
Oh, I thought you actually have to pay to create apps lol /sarcasm
Depends on how you configure the database, not the ORM. EF specifically delegates work to the database engine, that's the entire point of it. Unless the devs use it wrong, of course, in which case the churning happens client-side.
I recently wrote an app to send the same command to multiple switches using SSH.NET. It manages the connections, all I have to do is set them up. There are also libraries for telnet or pretty much any other communications protocols you would want to do.
Yes yes yes.... I edited my sentence to not annoy people ;-) But to explain again. Dapper (without any extensions) only helps you with reducing boilerplate code. Both on assigning parameters to your query and deserializing a row of data in the result set to an object. This is only a small set of work that has to be done in deserializing all data of a complete object graph. Thus it does not completely help you bridge the object relational impedance mismatch which is the original goal of an ORM.
This might sound stupid, but have you considered reinstalling putty?
Do these books go over a lot of the same stuff or is there decent value in each one individually?
Might sound as a dumb question, but does either of you use multiple monitors setup? I happened to run into a similar issue and having the additional screens unplugged and plugged back in helped me resolve that. Also - don't be so focused on putty - that's just middleware. Just because you were using it when working manually doesn't mean you have to automate the process using it. Unless there really is a thing you cannot due outside of PuTTY, give it a chance.
the twitter link (and all humble bundle links by that twitterer) are referral linked to support purplehub as the humble partner. OP does not have any obvious relation to the twitterer.
https://docs.microsoft.com/en-us/dotnet/api/system.array.binarysearch?view=netframework-4.8
there are only 3 C# specific books in the bundle. If you want to learn Java, it looks like a great deal. As with all programming books, they can become dated quickly, but if that format works best for you, it's a great deal.
:) Annoy everyone is my motto ;p &amp;#x200B; I always look at it as a discussion about the CQRS pattern. It's absurdly simple but then people start adding DDD, as if CQRS doesn't work without it and the bloat continues. "CQRS doesn't work without Event Sourcing!" and so on. All of a sudden you've got a stupidly simple pattern that people think requires a year of study to understand :) &amp;#x200B; I get what you're saying though. We expect a lot from ORM's, but it doesn't have to be "feature complete" to qualify. I pick some silly arguments sometimes ;)
Actual URL: https://www.humblebundle.com/books/programming-packt-books PSA: This user is a lousy, low rent Humble Bundle "partner" spammer. Report this user and, if you've got the time, report them at Humble Bundle as well at the following URL (the partner here is "purplehub"): https://support.humblebundle.com/hc/en-us/requests/new
Have you tried something like: var sortedLoggar = loggar.Sort(); ? you could even do loggar = loggar.Sort(); although some people prefer keeping the original and the affected lists separate. With the second option, you wouldn't have to replace "loggar" with "sortedLoggar" anywhere. Anyway, I believe you're sorting the loggar and then just dumping the result and never using it right now.
1. Don't use Putty since you don't have to. 2. The "works on my computer, but not in others" problem - use an installer when deploying on other computers, don't just copy the files. Create a new folder and install it there. 3. If you are set on Putty, how exactly are you automating its usage? Are you using UI Automation?
This is probably an [XY problem](http://xyproblem.info/), what exactly is it that you are trying to achieve? Do you really need to use putty to solve your problem? If so why are you not using the command line arguments?
i think the struct needs to be marked public or it defaults to internal.
Thanks! That fixed it
Is it all books? I'm getting decent at programming, but also want to learn a little more theory.
Consider LibLog, which is the only truly generic solution (popular one as well). It lives directly in your namespace as a single hidden file and it automatically binds to major loggers. It's especially useful for libraries where your choice of logger affects your users, but it's of course equally useful for your reasons.
Learn something new every day- I'd always thought the two were separate myself- but looking into it, when you do public event EventHandler&lt;SomeEventArgs&gt; ImportantThing; It's basically like an "auto-event" analogous to an auto-prop. I didn't even realize that there was a "full version" where add and remove are defined similar to set and get and using the above is shorthand for a compiler-generated version. And that is where the special event handling for subscriptions happens- I'd always figured it was somehow in EventHandler and EventHandler&lt;T&gt;, but those are merely delegate declarations- the "magic" for handling the multicast stuff happens in the generated code.
Look up gamedev.tvon udemy. They make very good quality courses covering unity as well. Thats where i learned from.
Learning C#, you should perhaps look into using classes and object orientation. C# is an OO language after all :). Instead of keeping a List of string arrays, look into turning that string array into a LogEntry class. If you then want to be able to sort those log entries, look into making that class implement the IComparable interface. I have modifed your code below to show how this is done, but I'd recommend you have a go at doing this yourself first :). I wish you all the best with your studies. using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; namespace Logg { internal class LogEntry : IComparable { public string Title { get; set; } public string Value { get; set; } public DateTime TimeStamp { get; set; } public int CompareTo(object obj) { return String.Compare(this.Title, ((LogEntry)obj).Title); } public override string ToString() { return $" Title: {this.Title}; Message: {this.Value}; Timestamp {this.TimeStamp.ToLongDateString()}"; } } class Program { static DateTime time = DateTime.Now; static List&lt;LogEntry&gt; loggar = new List&lt;LogEntry&gt;(); static void DisplayMenu() { Console.WriteLine("[1]Create log"); Console.WriteLine("[2]Display log"); Console.WriteLine("[3]Sort log"); Console.WriteLine("[4]Search log"); Console.WriteLine("[5]Delete logs"); Console.WriteLine("[6]Quit"); } static void DeleteLogg() { Console.WriteLine("Which post do you want to remove? Use 0 to remove the first item in the list"); string delete = Console.ReadLine(); bool toInt = int.TryParse(delete, out int result); try { for (int i = 0; i &lt; loggar.Count; i++) { loggar.RemoveAt(result); } } catch (Exception) { } } static void CreateLogg() { var entry = new LogEntry(); Console.Write("Title: "); entry.Title = Console.ReadLine(); Console.Write("Write your message: "); entry.Value = Console.ReadLine(); entry.TimeStamp = DateTime.Now; loggar.Add(entry); } static void Search() { Console.WriteLine("What do you want to search for "); string input = Console.ReadLine(); for (int i = 0; i &lt; loggar.Count; i++) { if (loggar[i].Title.ToLower().Contains(input.ToLower())) { Console.WriteLine($" Title: {loggar[i].Title} Message: {loggar[i].Value} "); } } } static void SortList() { loggar.Sort(); foreach (var sorted in loggar) { Console.WriteLine($"{sorted}"); } } static void AskingForLoggs() { string input = ""; do { CreateLogg(); Console.WriteLine("Do you want to add another logg? (type 'yes' to do so)"); input = Console.ReadLine(); } while (input.ToLower() == "yes"); } static void PrintLoggs() { try { foreach (var item in loggar) { Console.WriteLine(item.ToString()); } } catch (NullReferenceException) { Console.WriteLine("There was nothing to be found"); } catch (Exception e) { Console.WriteLine("Errormessage", e); } } static void Main(string[] args) { bool keepGoing = true; string menu = ""; do { DisplayMenu(); menu = Console.ReadLine(); switch (menu) { case "1": AskingForLoggs(); break; case "2": PrintLoggs(); break; case "3": SortList(); break; case "4": Search(); break; case "5": DeleteLogg(); break; case "6": keepGoing = false; break; default: Console.WriteLine("Use menu choice 1-7"); break; } } while (keepGoing); Console.ReadLine(); } } }
Tim Corey on YouTube. His courses are awesome and gives you weekly challenges. Oh....and it's all free!
That's definitely going to be something that's specifically involved with game development, as you don't worry about bullet trajectory when learning business applications. But, you need that base of all around C# knowledge in order to know how to implement such things.
You need to learn C# with Unity. It's the Unity engine that has the APIs for a 3D namespace like you are wanting. Getting the basics is a good start, you should learn how to organize your code somewhat sensibly, it will help as your game grows in complexity.
Is there a 'start minimised' setting in putty? Correction - googled that exact phrase and there is a start in tray option. Turn it of on the client and it should work - but long term I advise you to see above suggestions and not shell out so that you can ensure control.
The best analogy is that learning C# doesn't *directly* teach you game design or the implementation details of particular game algorithms. It gives you the tools that allow you to do so. Similar to how you need to know how to speak and write a language to write a book, but no matter how much you learn a language's syntax and grammar, it won't teach you how to write a good story.
Check out Brackeys channel on YouTube for excellent examples of using C# in video games with Unity. A lot of the core constructs you mention are covered and are demonstrated fantastically.
At bottom of everything there is only machine code. No matter which language you use, results are (mostly) the same. Of course you can write physics engine in c# and later use it to calculate player movement or bullet drop. Unity is just an engine as your hypothetical physics engine, bunch of tools and pre-made code (framework) to do stuff faster, without the need to write camera, texturing, physics for yourself. Some tools are better than others and that's only reason why to choose one engine over other or write everything from scratch all by yourself. Learn one general purpose language (c#, cpp, java...) and then start with game engine like Unity. It will be much easier.
I’m going to go very specific In response to coding physics: What is “velocity” in the real world? It’s just a direction and a speed. What is speed? It’s just changing position x amount over a given time. Imagine you’re running a loop that lasts 1 second. In the loop, if you update your “position” value to be yourlastposition + yourspeed, you will have your new position! So if you “redraw” your object every time the loop repeats, you’ll effectively be moving in your game. So... the question kind of confuses me, because the ideas I’m talking about has nothing to do with a coding language, it’s a very conceptual layer of programming that you will definitely need before you can really get efficient with your game coding. That being said, I am 100% positive if you google and copy the right things to your game that you could stand something up without even really knowing what you’re doing.
Unity uses C# as a scripting language, it sits on top of the engine. Personally I don't feel Unity is a good way to learn C# but knowing C# helps with development in Unity. &amp;#x200B; For things like movement and collision, you set most of that up in Unity and use C# as the glue that makes it work (trigger things on collisions, health and so on) &amp;#x200B; For the short term you I would suggest you keep up with your beginner videos and add in some Unity beginner videos. The C# videos will teach you how to be a better coder, and the tricks that can make coding easier and more efficient. The Unity videos teach you about the engine and where your code will go.
You can use command line version of Putty called Plink for automation. plink, just like putty doesn't need installation, so you don't need administrator rights to use it.
You don't do temp tables or complex queries in EF. You could with inline SQL, but people don't.
Learning a programming language, any of the dozens out there to be exact, **won't teach you "x"**. &amp;#x200B; You can learn a programming language, but you won't necessarily have learned **logic**. And even logic can be broken down to simplify processes like shooting a gun. &amp;#x200B; a) Do i have a gun? Ammo? Pull Trigger -&gt; Shoot -&gt; Hit. &amp;#x200B; b) Are there guns? Can i pick it up? Does it have Ammo? Where to get Ammo? Load Gun? Clip Size? Cock the gun? Safety? Ammo Powder Charge amount? Bullet Weight? Barrel Friction? Spin? Initial Velocity? Wind Resistance? Gravity? Manufacturing Quality of Barrel/Bullet? Humidity? &amp;#x200B; Logic makes a programming language become magic basicly. You know the words, once learned, but do you know how to speak or are you barely able to form a setence? &amp;#x200B; Anything you've asked would be dead simple with beginner knowledge to do in a WPF environment, you just have to write the logic up to the detail amount you want and reflect it with \*something\* without bothering with graphics at all. The Detail of realism etc. is up to you, you just have to update something to reflect the change made by that logic. GFX is a whole 'nother matter but the logic beneath it remains, all you need to understand (next to the programming language and logic) is how to translate it to the engine in methods and values it expects to get.
This guys stuff is pretty good: https://www.udemy.com/csharp-tutorial-for-beginners/#instructor-1 He has a presence on Udemy and Youtube and probably a bazillion other resources. He's clear and succinct and has his material worked out before hand.
Arrays are heap allocated though, no? You need to use `unsafe` and `fixed`, but then you're restricted to basic value types in the arrays. Or can you just assume good data locality if you instantiate the arrays sequentially?
Whitaker's C# tutorials are where I started. http://rbwhitaker.wikidot.com/c-sharp-tutorials
Toturialspoint is my goto. The quick guide for languages are time savers.
Jon Skeet's c# course in Pluralsight, he's the best!!!!
Pluralsight
\&gt; But take for example coding something like player movement, or collision, or physics, or bullet trajectory. Will I learn how to do this if I thoroughly learn C#? Or will I specifically have to learn C# for video game development/unity on top of learning traditional C#? &amp;#x200B; Once you get pretty comfortable with C# you can probably figure out ways to do most of those things, and run into problems, and then you can look up how game programmers have solved those problems. So a little of both. Programming is a huge domain, if you wanted to write code for spaceships you'll need to learn some spaceship stuff, to make websites, some website stuff, to make games, some game stuff.
No, you will learn the how to communicate with a computer and instruct it to do what you want. However, there is no magic "goHereAndDoThis()". You have to define the logic that makes this possible, you don't need a lot of deeo maths knowledge but it helps as that is essentially what you will doing. For example, you may need to learn how to take vector input (from say a joystick) and give out a quaternion that you can use to change the rotation of a character should you do a top down game.
Mosh is awesome, but I'd reccomend going to his website and paying the $15/mo sub to get a huge chunk of his courses. https://codewithmosh.com/
Thanks! I do the Udemy stuff because i always seem to find $11.95 discounts!
To use an analogy, all you need to write a novel is a decent knowledge of your native language, but there are hundreds of courses on how to write a novel. I encourage you to look for books, videos, and courses on game development in Unity, depending on how you prefer learning.
Oh, no doubt but there are three in the c# fundamentals course (though the last one is just 20 minute lectures), so it would come out cheaper methinks
I would do 10 days trail with Pluralsight and do beginner course from [https://www.pluralsight.com/paths/csharp](https://www.pluralsight.com/paths/csharp) . &amp;#x200B; There is 2 reason I recommand plurasight 1) The content seems to be really good 2) When you pay for something you are more committed &amp;#x200B; You may end up paying $100 or something for 3 months but if you spend 2 hours everyday 90 x 2 = 180 hours. You can learn lot of stuff: I would say following 1) Learn fundamental 2) Do TDD/Unit Testing course
Basically, the language doesn't matter that much, it's your way to communicate to the computer what you want to compute, the thing is *what* do you want to compute? You have to come up with a method, an algorithm if you like, that is able to calculate the data you desire, then you implement that design of that algorithm in the language you prefer the most and that allows you to do such things. The language doesn't work for you, you work for you, the language helps you get there just a bit.
Removed: Rule 6, spam.
There is something called remote debugging. Have you try using remote debugging? I would step through code and see what's difference between running locally (your machine) and target machine ( someone else's machine). You can also use [ProcMon](https://docs.microsoft.com/en-us/sysinternals/downloads/procmon) to see details of all calls. I would also run ProcMon locally and remotely and compare what's the difference. ProcMon in most case is over kill but if you have tried everything and nothing works it will help you. &amp;#x200B; I would also strip down application to do something minimal; where you launch putty and do some basic stuff.
You need to learn the game engine (in this case Unity) as a sort of 'layer' on top of the language. I would recommend that once you have a decent grasp of C# fundamentals, start doing some Unity tutorials. I have written some up at http://unity.grogansoft.com for beginners (for the beginner tutorials you don't really need to know any C#). In Unity, physics and movement use Unity's Monobehaviour class, which you can think of as a sort of add-on to C#. For example: transform.position = new Vector2(100,50); That code will place an object at a particular position on the screen (well, in 'world space'), and it is C#, but it wouldn't be anything you'd find in a C# tutorial or book because 'transform' and 'Vector2' are Unity-specific. Unity's engine runs in the background doing its thing (e.g. applying gravity to objects with physical 'rigidbodies', ticking through frames, drawing the screen, and so on), and your C# code interacts with the engine as needed, e.g. telling an object to move or changing the status of a door from locked to unlocked. Try out my Pong tutotial at the link above to learn all the ore Unity concepts, and keep learning C#. Most Unity resources tend to shy away from the more advanced C# concepts, but they can be quite useful in structuring your game code.
I'm in UTC-6, are you willing to share a private repo?
To really understand this, you'll first need to know how APIs work. So C#, at its core, is nothing but a way for a computer to convert a line-by-line text file into instructions for itself. For just about everything you're doing in code, you're going to use libraries, also known as APIs. An API is a set of prewritten code that acts as a set of tools for whatever project you're working on. In 'traditional' C#, whether you're referring to the creation of a console program or Forms application, you're typically using Microsoft's prewritten API that they give to you by default. For example: when writing the line... Console.Write("Hello World!"); you are referring to an object called 'Console', which is found in the 'System' API. This is why most of your C# class files will have the following line towards the top of the file: using System; APIs are written for a few reasons, one being to make programming a hell of a lot easier for the programmer. Without Microsoft's API, we'd have to figure out a way to print text to the console ourselves. Another reason is for convenience, because it can consolidate tens or hundreds of lines of code into one little line. When writing code for use in a Unity game, you'll be using Unity's prewritten API. You'll be pleased by how many tools Unity has created to make game programming a breeze. For example, if you wanted to rotate an object 45° along its Y-axis, instead of having to go under the hood and figure it all out yourself, you can add the following line to a class attached to the object: transform.Rotate(0, 45, 0); with the 0's representing the desired change in the X and Z axises, respectably. I understand this is a ton of information, and I know I'm not the only one who wrote a book here, but once you really understand C#, programming, and how APIs work, it'll get really easy to get the hang of Unity. And it'll be a hell of a lot of fun too, if you're like me and always thought game development was magic witchcraft before realizing magic wands are free and they're called Visual Studio 2019
Thing is, everything in game is a problem to solve. For example movement, you probably want to register key button presses, then make your player move along the axis, maybe read speed variable and velocity while pressing it etc. And you solve all those with the tools you have. The main tools are all those fundememtals you learn. There will be certain libraries that are build in Unity (like collision system physics) etc. But you will use it the same as any other tools. Of course, after you set up your character running around you think "so what's next?" and what's next is some technical layers - you need to learn how to use singletons, serialization if you wanna make something bigger. But then learning almost never ends, afterwards you generally need to learn about game design, what makes it fun, SOLID principles, how to keep your code clean and efficient etc. Now, I am still a beginner in terms of my skills. But take this from my own experience, I went though C# fundementals, then I was exciteed to jump to Unity and did bunch of small projects. I learned quite a lot what generally goes into making a game in Unity and have done some very small gamea but realized I don't have good problem solving skills with code and often just kinda stich things up. So now I went back to absolute fundememtals and trying to do as much code challenges that I can, as well as learn good code practise.
The DeleteLogg method didn't need a for loop, didn't think of that :P But when I try to change the SortList method to var sorteLoggar I get an error saying "Cannot assign void to an implicity typed variable".
I asked the teacher about using OO and that was ok, but I was to use a string array for the list, I couldn't use objects.
I’ve been using a mac for over a year now, and while I do have parallels for legacy projects, most of my work day is spent in VS code.
I do, for work. But in my experience there's no difference in benchmarks like this; the overhead is largely client-side, not server side (just run the benchmark for longer and look at task manager!). In fact, in most workloads, there appears to be no difference between any of the editions - it's just more or less features; so unless you hit some memory limit, or use some fancy query feature not available in cheaper editions localdb, express, standard, enterprise, developer - it appears not to matter. (There may be exceptions to the rule, but in any case given a simple query the most likely outcome to expect should you measure is identical perf across edititions). In fact, even across older versions like 2012r2/2017 etc most simple queries appear to perform identically, at least in my experience (but then, that might be because in simple cases the ado.net derived clients are the bottleneck, not the server.)
 class Entry { public string u { get; set; } public string c { get; set; } public int? h { get; set; } public int? b { get; set; } public int? a { get; set; } } Dictionary&lt;string, Entry&gt;
Should that do it? :O I'll have to try it in the morning unfortunately but I'll get back to you.
I'm not sure why you need the window to have focus, but I'd try changing the standard input the output streams. I feel that's more likely to succeed than anything window and focus related.
https://dotnetfiddle.net/De5Dgm
Learning how to do this was so much fun in JavaScript. Sorry to raid r/csharp, but I want a taste of everything, so I roam everywhere.
Oh, I apologize then. I thought Sort returned the ordered list. I usually use OrderBy, honestly. For example: var sortedLoggar = loggar.OrderBy(x =&gt; x);
I tryed to use a LINQ and it did the trick, though we have never used it in the course so I'm not sure it's allowed to use. Last assignment we used Bubble Sort,which I'm not really sure how to implament here.
https://studyblazor.com for beginners
I see. Well, it looks like the issue with sort is that it's expecting you to pass a method into it that does the comparison. https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1.sort?view=netframework-4.8 Ctrl+F for "CompareDinosByLength" That is the method that was written for the later use of Sort() if you scroll down a touch. dinosaurs.Sort(CompareDinosByLength); I don't know if your homework is going to accept you doing that. If not, you could also look into SortedList https://docs.microsoft.com/en-us/dotnet/api/system.collections.sortedlist?redirectedfrom=MSDN&amp;view=netframework-4.8
Keep practicing!
Will try all of your suggestions! Thank you!
Sorry for the late reply. So normally .net framework 4.5 projects puts their nuget dependencies in a “packages” folder next to the solution file. What I then do from my nuget project/solution is to set my output dir to the dependent solution’s packages folder, essentially overwriting the nuget/dll that is there. Visual studio picks this up immediately, so the development loop is still very fast/tight. When it’s time for deploy, I’ll publish the nuget as normal, then when I deploy my .net framework project, it downloads said published nuget before building and releasing.
&gt;Imagine you’re running a ”game loop” that lasts 1 second. (This is how nearly every game works) Wouldn't most game loops run several times per second? They would either run once per graphical frame (possibly using delta time for consistency) or on a separate update cycle several times per second?
This. Also, it would help to nail down a few programming principles. Having neat and maintainable code will help when flushing out bugs
You can get 1 month trial for pluralsight if you sign up for [Visual Studio Dev Essentials](https://visualstudio.microsoft.com/dev-essentials/).
Drawing happens after the update in a game loop.
Damn that second paragraph is neat
Entity Frameworks is implementation of repository pattern. If you are using repository pattern with EF you have repository pattern packed into repository pattern. It's funny, but in many systems it makes sense.
A lot of errors mate. The first "awesome" graph shows a completely different pattern to the one you're writing about. &amp;#x200B; If you're going to describe a pattern, please don't require a nuget package. Patterns are never that complicated.
Can I ask how it shows something different? It has a repository taking a business entity and saving it. What's incorrect? Am I missing something?
It separates query with command, so it shows CQRS, or CQS, it's not a great diagram. &amp;#x200B; The data source changes so rarely it really doesn't matter. Trust me when I say that if it happens you will have bigger problems to deal with. Repo doesn't understand caching or real time, both of which are staples of modern dev. &amp;#x200B; Everyone does this once, I did it (once, many years ago) and it's a nightmare to manage while giving no actual benefits. &amp;#x200B; And you may always ask. I'm not always be correct, I am opinionated, but the skill is in learning how to tell if I'm right or my opinions are valid :):
I'm really inexperienced in this area. How does a pattern understand caching or real time
I have never understood UnitOfWork. What does that ACTUALLY DO? Whats wrong with: using(DbContext context = new DbContext()) { context.Customers.Add(customer); } is it just too easy?
It doesn't. That's why I said " repo doesn't understand caching or real time" ;) &amp;#x200B; The important thing to take away is that you don't often change back end storage, so it's not a good reason to spend weeks supporting that proposition. &amp;#x200B; Second, things like EF are implementations of the repo/UoW pattern, so people spend weeks wrapping a repo in a repo. It's a horrible idea especially once you need transactions. Repo is an abstraction over CRUD, and I think this was missed in the article. It didn't describe the pattern properly and didn't give an accurate description of how it would work. As mentioned in my original response, the fact you need a nuget package means you are not describing the pattern.
Couldn't agree with this more man, I've seen so many:
It used to be 6 months than 3 months now 1 month :). I asked my boss to try it once and we purchase yearly subscription now :).
I know you don't always swap an entire data source out, however I have previously swapped out certain specific methods and repository implementations to talk to different data sources i.e. change this from entity Framework to raw SQL for performance etc. I can't do that without my business logic having 0 idea how I implement persistence. This doesn't just mean databases, it means your business logic having 0 idea if something is coming from an API, a file, a database etc. That part is what is more used and more useful. I have several apps developed in a DDD way which access different types of data sources. This is hidden behind interfaces and the interfaces implemented by repositories. That way I can decide if I want to use the CachedUserRepository or the UserRepository or if I want to use an APIUserRepository which talks to a centralised Auth website... and my business logic does not care in the slightest. It just cares that I have an IUserRepository and it can check the users password is correct, regardless of where it is getting the data from.
Yes a game with updates every second would look like mr game n watch. The frame rate is essentially the game loop in a practical sense. I was just trying to keep it super simple for the already kinda confusing example.
Yea that’s true
That's using EF which implements Unit of Work. What you did there would persist that object to the in-memory context but will not save it to the database, unless you call SaveChanges. The purpose is so you can build object graphs and save them all at once, and more importantly, roll them all back at once. Imagine saving a transaction record, with transaction line items that have a FK to a SKU in a Products table. In between your order being submitted by the user, and saving it to the database, another process has deleted the SKU of one of the line items. If you saved transaction and line items separately, you would now have a transaction but the line item would violate the FK constraint, and would not save. Then you would have to manually roll back this error. The problem is that despite crossing tables this is really one record from a domain perspective and it doesn't make sense to have just the transactions without the line items. EF will allow you to roll back the entire commit as a transaction. If you were using something like Dapper and needed to handle multiple inserts you would have to build your own transaction model.
Don't forget to call Save. :D Kidding aside, your code example is a unit of work, albeit a barebones one with just one business object update. If you added multiple customers or created an order for that customer or something along those lines, all within the same DbContext, you'd have a more traditional example of UoW with EF. Wrap it in a transaction and you'd have a straight up classic example. OP's article (and the entire idea of a self-implemented repository pattern) is over-complicated and totally unnecessary. I speak from experience, having done it myself years ago. I ended up ripping it out later down the road. There's no need to hide DbContext or abstract it away. It's already an abstraction and it's already a repository. DbContext is meant to be light-weight, used briefly, and thrown away as soon as possible. It doesn't need an additional layer thrown on top of it. Anyway, when it comes to this stuff, I say it's always a good idea to see what Fowler says about it. Here's what he says about unit of work: https://martinfowler.com/eaaCatalog/unitOfWork.html
How do posts like this get upvotes?
For .net use HtmlAgilityPack library. Python or Node do not 'support' html scraping out of the box either. You must use a library or make one.
Thanks for the explanation. I typically create my dbcontext "per-request" so I haven't encountered this.
Yes repository-over-repository is a common detour on the path to enlightenment. I will mention however, that exposing dbcontext directly to upper app layers can be harmful (as generic repo pattern often does). For example you don't want anyone and everyone writing rows to a table unless they are first validated. I use a service layer that hides DbContext for this reason.
 **Invisible Character Visualizer** [https://marketplace.visualstudio.com/items?itemName=ShaneRay.InvisibleCharacterVisualizer](https://marketplace.visualstudio.com/items?itemName=ShaneRay.InvisibleCharacterVisualizer) Its a visual studio extension that adds visibility to invisible unicode characters that may slip into your code. I recently added visual studio 2019 support and looking into adding additional features and customization options.
Hey fren hope you are having a wonderful day, i like your comment made my smile : )
I mean, technically you can generate native executables and [write operating systems](https://www.gocosmos.org/) in .NET, but generally .NET is a general-purpose application platform. It's not limited to one specific use case. Your friend is wrong.
You can use C# to write almost any type of application. The language is not very limiting in itself and there is a vast array of third party library’s. I have used C# to write web applications, Web API(rest), scheduled batch-jobs, console applications and games in unity. I have also written a web scraper for a company using c# and agility pack as described in the comment above, worked like expected. It’s hard to go wrong with C# if you don’t need bare metal coding and I can definitely recommend it. A lot of companies are using .net core now, might be worth looking at since it’s the way forward when it comes to .Net.
Idiomatically, you write as much of the view in XAML as possible, and everything else (models, repositories, commands, whathaveyou) in C#. In practice, there’s stuff that’s clumsy to express in XAML, so you find yourself using C# for more complex portions of the view as well.
there is no limitation, to very close approximation.
Unfortunately these are few and far between. It's hard not to make this an opinionated rant. When MS released WPF, they pitched it as the newest, best thing to happen to Windows and insinuated they wanted everyone using it ASAP. It brought in a lot of stuff that people had wanted in WinForms for years. Adoption was slow because devs are usually skeptical of new things. Instead of supporting it for a long time and phasing out WinForms (which would've hastened adoption), MS released Silverlight. It was a pared-down version of WPF that ran in web browsers, apparently to challenge Flash. Except MS rapidly increased its capabilities to run Desktop Applications too. Now WPF devs were confused: do I keep going with WPF, or use Silverlight Desktop applications? It felt like Silverlight was getting more features, so everybody who was doing WPF started moving that way. Then MS discontinued Silverlight and said we should all be writing HTML5 applications. That lasted 3 months before they decided to abandon it in the face of rioting devs and instead say, "Well, we meant the thing we used to call Metro but is now Modern Windows Applications". These only ran on Windows 8, and there weren't many compelling Win8 devices to exploit them. It became UWP, which only runs on Windows 10 and still lacks a plethora of compelling devices. And it's even hard to say MS is betting on UWP because there's also Blazor, which runs C# applications in the browser with Razor Pages for GUI, and also MS is investing in Chromium so it seems like they want that to be a viable path. This looks like a competitor to Electron, which is what Discord and Slack use. Even MS uses Electron for Skype and Teams because UWP can't support Mac/Linux and they've not been able to deliver a Xamarin solution for 3 years after promising "any day now". Before that line between Silverlight and Modern Windows Applications, there was a really excited WPF community. The "WPF Gurus" were an unofficial group of some of the best blog-writers and tutorial-creators I'd ever seen. When MS abandoned Silverlight, a lot of them became Ruby or Objective-C developers. One of them's been writing a really good Swift blog recently. But that means somewhere around 2011 or so, everyone quit writing tutorial content for WPF. Even on Pluralsight, most courses are obscenely dated. Not a lot has changed since then, mostly because there's not a lot of "for fun" work around WPF these days. People who do it "for work" don't tend to blog about it, either due to lack of time or worries about showing off stuff their company might consider private. I think Xamarin has the most coherent resources around designing MVVM-aware applications right now, but even that's lacking a really good newbie path in my opinion. You do *have* to be using MVVM to use WPF properly. So the right path might be to go write some Angular/React/Vue applications for a little while, or alternately dabble in Electron. Yes, that's JavaScript. No, it won't kill you. If you're really bothered, write some ASP .NET Core applications. When you write a web application, you have *no choice* but to separate your UI from your logic and use an MVC pattern that is *very similar* to MVVM. Once you're very proficient with that, I think WPF will seem pretty dang easy to you. From there, it's just understanding the nuts and bolts. Charles Petzold had a good initial book about them, but there are a handful of things that arrived later like "attached behaviors" that as far as I know never got a good tutorial. Every blog I've ever seen about them assumes you know what they are and is about showing off cool tricks with them.
Maybe people upvote without reading it? I've seen the repo on top of EF so many times in my career though. A lot of people think this is a good idea. I think it's a huge mistake.
How do I repeat myself writing the same linq queries all the time? For example, a _GetAllProducts()_ query. My repo has this so I only have to change a query in one place in my application. Without a repo, how do I avoid having to rewrite a query in multiple places in the app?
Agree with you. But the repo on top of EF here is worse than just a repo on top of EF. This repo severely denies most of the power of EF to the consuming code. It only allows simple CRUD operations on one kind of POCO. It's like wrapping a Ferrari inside a bicycle.
Instead of a repo pattern, I would make specially named interfaces and classes that encapsulate the domain queries you want to make. The only time imo that the repository pattern is useful with a strong ORM is really when you're making a library around your database that will be used in multiple projects and you want to abstract the ORM away from consumers of the library.
First thing, GetAllProducts is never going to scale right? To your question, instead of calling GetAllProducts, can't you just inject the DbContext into your code and call _dbContext.MyPocos.ToListAsync() or whatever?
I wasn't recommending that and I fully agree. My remark was in reference to creating another repo layer to hide dbcontext.
You could write a generic extension method on DbSet&lt;T&gt;
Are you really hiding it though? EF at least gets instantiated by the top most application. Lets say API Layer on application startup. Nothing stops a dev from injecting dbcontext into their api layer and make calls to the repo from there. This is just an architectural decision that doesn't quite make sense. If EF inherently implements a unit of work, why wrap it around another Unit of Work layer that does similar things that EF provides, just in case we might replace it. It's like re-inventing the wheel. Databases don't really change much and a switch from EF to NHibernate or Dapper or whatevers is going to require for you to change the unit of work anyways to accommodate for the way those other models work. At least that has been my experience.
&gt; Adoption was slow because devs are usually skeptical of new things. Not mention because there was almost zero dogfooding.
I always say that too. Don't build a repository on top of a repository. EF is a repo.
The only reason I used to could a repo on top of EF was purely for theoretical concerns. Namely.. You might change your database. Great. EF will be fine worth more than MS sql. And guess what? If you are using EF, you have a sql db. So fuck that noise
This is the same question I have. We looked at switching from nhibernate with a repository pattern to EF but finding a good way to architect it seemed... Well, it did t fit with what we currently do. For us, our repos are in a separate domain project that we use across projects in our solution, and keeping it separate and in a repository allows us to not have to rewrite db access code between projects. So, I genuinely wonder what a better method would be to allow reuse across projects without writing the same code over and over again.
I’m just starting to learn wpf and feel the same way as you. Just give me a definitive list of properties I can use on each object! Instead I have to randomly google search for every little thing I want to do! And some properties work on some objects but not others..
I use vscode over vs even on windows, the git integration is just much better (gitlens)
Yes, but the domain layer repository is not what you're talking about here. The basic repository pattern is a CRUD template. This is the thing. Using a "repository" does not mean you're implementing the repository pattern.
The actual post doesn't mention EF. Or am I tripping balls?
Nice analogy...i will use it some day.
&gt; Maybe people upvote without reading it? wait... you guys are voting *after* reading more than the title?
How do you write tests without abstract repostitory?
I don't understand. You should have intellisense for available properties, and you can F12 to the class definition. And if you're a beginner you should learn to use the property view like you would in winforms, instead of writing xaml directly.
Here's my rant on the matter, posted this before: I wish WPF just presented itself as more approachable for beginners. Tiny changes they could make, like hiding the XAML by default. The initial impressions people get when opening a project matters so much, so when Winforms only presents the user with a designer, toolbox and a property view and the assumption of drag-and-drop, then they're happy to start trying things out. Could you imagine how daunting it would be if the default window setup showed all the code-behind being generated, next to the designer? ​ So when WPF shows this big box of XML underneath the designer, that's scary. Already lots of text that you apparently should understand. It's a whole new world people aren't prepared for, and simple decisions like ignoring it entirely in favor of the basic drag-and-drop experience feels like a huge decisions for beginners. They never get to the point of realizing they *can indeed* just drag-and-drop and input stuff in the property view, just like in winforms, it's not given the chance. ​ Personally I had the opposite impression; I thought it was really cool to have a window that showed me what happened "behind the scenes" of what I made in the designer, but I can understand why people think it's more confusing than helpful. Also because of the lack of adoption of XAML the tooling goes under the radar. How many are aware that 'Visual Studio Blend', an XAML designer tool is installed alongside Visual Studio?
Still is. *Apparently* there are a few UWP/Xamarin apps out there in the wild, but MS seems equally invested in every framework, not focused on their own.
People are suggesting Html Agility Pack which I would've agreed with in the past but can I suggest you look at AngleSharp instead (I think it's better tbh)
Use a bar to wash out your mouth after saying that dirty word! 😄
Made a server control panel for my game on Unity, with some server/database related functions, to make it easier to add items/release content updates and manage database tables conveniently. It also has maintenance mode to fix and debug server related issues. This was a project i started months ago, but decided to update it again
So, what else do you recommand for making windows apps? Sticking to winforms? I got my hands on js already, can't say it kills me, however web developement doesn't appeal me that much; right now i want to experience making windows apps.
I’m mostly referring to editing the xaml, which you kinda need to do after you do the general placement, no? Is there a property view similar to winforms? Where’s that? I’ve seen the document outline view, which does show each object, but I would think I could right click each item and see a property list, but it doesn’t seem to work that way.
EF dotnet core has an in memory db option. Just configure that and inject it into your test code. If you have functions on the DbContext to call stored procedures you can extend your DbContext and use a combination of in memory and mocked functions. public class MockJfccDbContext : JfccDbContext { public Mock&lt;JfccDbContext&gt; MockDbContext { get; private set; } public MockJfccDbContext(DbContextOptions&lt;JfccDbContext&gt; options) : base(options) { var optionsBuilder = new DbContextOptionsBuilder&lt;JfccDbContext&gt;(); optionsBuilder.UseInMemoryDatabase(Guid.NewGuid().ToString()); MockDbContext = new Mock&lt;JfccDbContext&gt;(options); } public static MockJfccDbContext CreateDbContext() { var optionsBuilder = new DbContextOptionsBuilder&lt;JfccDbContext&gt;(); optionsBuilder.UseInMemoryDatabase(Guid.NewGuid().ToString()); return new MockJfccDbContex(optionsBuilder.Options); } // Function executing stored procedure.. test code will Setup the function public override IQueryable&lt;ReturnParserXml_Result&gt; ExecReturnParserXml(Guid webServiceId) { return MockDbContext.Object.ExecReturnParserXml(webServiceId); } }
Select a element and press F4 to get the property view. Then place it how you like it in Visual Studio
lol
Don't know why you're getting downvoted without explanation but you're exactly right. I have yet to work on a project where we had to change out the entire persistence layer, which is the argument against your suggestion. I HAVE had to work on tons of projects where making a change to the product catalog maintenance interface impacted the shopping cart because they both relied on the same GetAllProducts method when they're completely separate features intended for completely separate sets of users.
Agree with you. When I've seen this implemented, the consuming code is denied access to the underlying EF DbContext.
I usually just do \`yield return HelperToTurnArgumentsIntoObjectArray( string arg1, int arg2 )\`. Seems more intuitive to me than populating multiple collections.
Most of us are agile/clean coders right? So we don't solve problems until they present themselves? To me this is a bad trade off: write a ton of extra code and severely curtail the ability of consuming devs to write efficient LINQ to protect against this future event that almost never happens.
Your buddy is right and wrong. It isn't limited in what you can do, however there is an argument to be made for it being the right tool for the job. You can put in a screw with a hammer but a screwdriver is better. Just because c# can do it doesn't always mean it is the best tool. Personally I don't see why a web scraper can't be done in c# but many would say use Python as it is simple enough to do. It's all about the task at hand and using the right tool.
Moving from monoliths to microservices. It's easy to swap how a repo gets it's data (from a database to an api). It's a lot more difficult to do the switch when you ignore persistence ignorance and have your ORM infesting your application layer, presentation layer, domain layer etc. Separation of concerns isn't just some fancy buzz words. They have a meaning and a purpose. It's also helpful when you're preparing to make the transition to microservices - if an application doesn't use repo's - refactor to use repo's while still using the database, make it stable, and then make the switch to using APIs
&gt; Separation of concerns isn't just some fancy buzz words Right. My features are nicely separated so that if I DO want to convert one to a microservice I don't have to untangle it from the generic repository. How can you have separation of concerns if all the concerns rely on the same repository?
Generally microservices are broken up by bounded contexts or aggregate roots, and following DDD/eric evans, you should have one repository per aggregate root. When you break up into microservices, you shouldn't have to untangle it from any repo
I think it's more complicated than just implements repository and unit of work to create abstraction where all possible calls to db will be stored. This approach is easy to use, especially if you have a lot of tests.
I don't think you've read the article and the entire thread. It's about the generic repository pattern specifically, not "repositories" (aka DAOs) in general. Nobody is advocating for mixing data access and mutation. Nobody (at least not me) is advocating for exposing DbContexts. We're simply saying the generic repository pattern offers no concrete advantage. If you can provide a specific, concrete example where having a generic repository was beneficial I'll be happy to show you how it actually wasn't.
A better approach is writing services that get the DbContext injected into them and return DTOs using AutoMapper or something like that. The consuming code (like controllers or business code) uses the service and doesn't know about or have a reference to the EF model. This is microservice/CQRS friendly and does allow for SoC.
And it's a good idea to hide all possible usage of ef inside small repository. Because, you control you code and shrink all posbilitties only to needed and required. For example, when new developer will check what you repository can do he/she will see only one logic of adding entity. But with while ef core you can do it more than one way and it's confusing and can lead to errors.
I didn't read the article and entire thread. I'm sorry.
I like severely curtailing the ability of consuming devs to write terribly inefficient db queries.
Architecture is all about trade offs. I don't think this is more complicated than mocking a home-rolled repo on top of a repo, but assuming that it is, it's worth it. You are adding test setup complexity to gain very large performance and productivity benefits by allowing devs to use the full power of the ORM.
Why should your application layer know, or care about how you store or retrieve data?
&gt;And it's a good idea to hide all possible usage of ef inside small repository. This will not be a small repository. Your other concerns can be mitigated by using services and writing a base service class for the simple cases. Having good test coverage and requiring that new code also has good coverage will help. Assuming that the devs are dumb doesn't benefit the code or the dev.
What are you defining as the application layer? Where does your repo on top of EF live?
There are better ways to prevent this than assuming that devs can't learn to write efficient LINQ queries.
Buzzwords
I don't agree. The code we wrote is a service for others. In my opinion we should focus on creating tools from code for others coders to use for specific project. Ef core is too broad.
The repo's live in the infrastructure layer. The application layer services get called via the presentation layer. The application layer gets repo's injected into it. The repo's return domain models from your domain layer. The application creates new domain models, or gets pre-existing domain models from the repo. You call methods on your domain models. Domain models contain only business logic. You save domain model through repo's. Application layer services are just orchestrators. They manage the interaction between the presentation layer, the domain model, and repo for said domain model
The services that I'm talking about would also live in the infrastructure layer. Application layer services can consume infrastructure services, get DTOs back. They don't know about EF or the generated entities.
Not an online resource, but I bought a copy of [Programming WPF](https://books.google.co.uk/books?id=558i6t1dKEAC&amp;pg=PR17&amp;dq=programming+wpf&amp;hl=nl&amp;sa=X&amp;ved=0ahUKEwjSn93l15HjAhVxTxUIHbK-BdMQ6AEIKTAA#v=onepage&amp;q=programming%20wpf&amp;f=false) ages ago, and still find it to be one of the better sources that explains WPF from start to end. Sometimes the history in the first few chapters is a bit over the top, but further in they thoroughly cover the basics and layer it nicely as you progress. Some chapters are useless by todays standards like an almost complete chapter dedicated to XPS (which no one used since ... Win XP?) as well as a few other niche ones later in the book. But most of the starting chapters are very solid, and full of clear examples (IMO obv.). I like it so much that I recommended the book at work, since we have very few WPF programmers, so other C# devs have to dabble in WPF from time to time. And I feel this book provides an adequate foundation for WPF. Don't worry too much about MVVM, you need to learn to walk first, before you can run. Focus on the basics first. For that this playlist on Youtube is worth a watch: https://www.youtube.com/playlist?list=PLrW43fNmjaQVYF4zgsD0oL9Iv6u23PI6M But it's not very noob friendly, so I would only try watching it after you have a decent WPF foundation to build it on. But he covers the very simple to some of the very hard parts of making an app.
If it works for your team and product, that's cool. I've never seen it done where some or all of the following things happen: * The repo is later abandoned * The code in the repo constantly grows to try to encompass more EF functionality or handle special cases * Devs do inefficient things in memory because the repo limits them from writing LINQ that would do it in SQL
You don’t need to dispose the db context in .net core. It’s handled automatically with your startup settings.
I wonder if you're using the term infrastructure service the same way I'm using repo. They sound like the same thing after googling. I'm pretty sure eric evans uses the term repository, which is why i'm calling them repos. Am I wrong and they have different use cases?
Yes you are really hiding it. &gt; EF at least gets instantiated by the top most application No! That should never happen. In a perfect world you want to put your DbContext in it's own project (assembly) and mark it as internal: internal class MyContext: DbContext { } Your services might look like this: public class ProductsService : IProductsService { private MyContext context; public ProductsService(MyContext context) { this.context = context; } public void SaveProduct(Product product) { if(ValidateProduct(product)) { // save to db } } private bool ValidateProduct(Product product) {...} } public class MyController: Controller { private IProductsService productsService; public MyContext(IProductsService productsService) { // MyContext is not available here. // Anyone who writes to Products table must call // SaveProduct and validation will be enforced. this.productsService = productsService; } }
I tested the last link and the second solution, it gave me an error saying "At least one object must implament IComparable". What's the object since I don't use objects in this application? The error occured on this line: `if (`[`comparer.Compare`](https://comparer.Compare)`(x, y) &gt; 0)`
You have way too many choices for Windows applications, and everything has downsides. **WinForms** is the oldest, most well-understood GUI Framework for .NET. It will be part of .NET Core in 3.0, but that doesn't make it work on Mac/Linux. It *is* important though because if MS didn't port WinForms to .NET Core I would say "it's probably not going to exist in 5 years or so" because .NET Core is the future. So you can find a lot of tutorials for WinForms of every possible quality. The downside? Most devs today agree you should separate UI and logic, but WinForms almost encourages you to mash them together. Almost zero tutorial code exists for teaching you to use some kind of Presentation Model pattern. Short blurb for WinForms: Easy to learn but doesn't even point in the direction of "good" practices. It's the VB6 of 2019. (Mad respect for VB6, though, and a ton of VB people would murder me for suggesting .NET is anything like it.) **WPF** I've already been through so just the short blurb. It's more future-proof and looks a lot more like modern development, but people quit writing tutorials because MS had an identity crisis, made it seem unsupported, and never really recovered their fumble. It's only going to make Windows applications. **UWP** is like WPF. It only works on Windows 10 and is *really* designed to take advantage of tablets/phones. This means some desktop ideas like "multiple windows" or "tool windows" don't exist, you're expected to make single-window applications, interact with touch, etc. MS tried to pay people to port UWP apps and got no takers, so there's not an awful lot of content about doing things more exciting than "what MS ships with UWP" like Calculator. There are a handful of .NET-compatible-but-not-MS frameworks like GTK# or Avalonia. They're all either "in early prerelease" or "not very well documented" so while I have to acknowledge they exist, WinForms/WPF are the front-runners. That's really it if you want to stick to C#/MS options. They are all Windows-only. If you want to write an iOS, Android, Mac, or Linux app you have to either look to Xamarin (which is like "UWP for not-Windows"), one of the HTML/JS frameworks, or Java/Obj-C/Swift. MS has no cross-platform offering, only undelivered promises.
&gt; And it's a good idea to hide all possible usage of ef inside small repository. Then why use EF at all?
C# is incredibly versatile and is growing in versatility every day with .Net Core enabling cross platform development on Linux and Xamarin for Android/iOS apps. A couple of examples of applications I've built with C# * IT ticketing platform with email capability. * Network inventory tool (PCs, Servers, printers, network switches etc.) * Network Switch interface manager. * High speed file transfer system. * Magic the Gathering card text reader via OCR. * Web Scraper for harvesting Keno numbers using the WinForms Web Browser control, REGEX and text filtering.
I think the goal or function of what I'm calling an infrastructure service and your repo are the same. But what I'm thinking of is a service layer that would often be extended by devs. Something like: public class ProductsService { public ProductsService(DbContext dbContext) { ... } public virtual List&lt;ProductDto&gt; Get() {...} ... and so on } When I've seen the repo on repo used, it usually denies devs access the DbContext.
&gt;Why would the application layer service get DTOs from the infrastructure layer? You gotta draw the line somewhere to keep the model from leaking into other layers right?
Yeah, we're basically saying the same thing, except you maybe don't use a domain model, so you return DTOs
&gt;Why would the infrastructure layer be calling business logic, it's concern is only how to save and retrieve domain models (not ONLY, but in terms of persistence) I would not have the infrastructure layer implement or depend on business logic. It's not required by what I'm describing is it?
I'm thinking of DTOs as being a lazy alternative to domain model but basically achieving the same thing right? A set of objects for the application layer and so on to operate on and prevent the persistence model from leaking.
Kind of, but without a rich domain model, you have an anemic design, which is less intuitive and maintainable
Well, I could start you down the path of interfaces and how to use IComparable, but I really get the feeling that if you can't use Linq in your homework, using IComparable might be a problem too. Would you be able to give more info on your BubbleSort exercise prior to this one? Everything else you need to do in this homework seems so straight forward until the requirements of the sorting, that I kinda get this feeling that you're supposed to be using the BubbleSort you already used. (ie there's an advanced piece, but we covered it in class so just re-use it).
Oh yeah I think that's awesome... most people don't take the time to set that up.
Well, they eventually shipped a WPF-based VS, but that was *three years* after WPF. And that’s roughly it. (Some stuff like portions of the discontinued Expression suite, I suppose.)
Yeah, generally that line is the application layer. Repo returns domain models, which are DTOs but with all the business logic associated with it. For instance your product service. Do all products have to have a price greater than 0? Business logic in the domain layer. Do products have to have skus? Business logic. Do they have to have a description? Business logic. Or maybe they are being used for purchasing, do they have to have a quantity greater than 0? Business logic.
This is the explanation that I found missing in the article
Since he mentions DbContext in a few places it appears that he is using EF for the example code. I think Dapper would've been a better example.
Are you on LinkedIn? I'm Matthew Morgan in SLC
I use C# to do a ton of web scraping, works totally fine!
ProModel?
Please see [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient) for a small library that will help you build a service layer that is transport/platform agnostic.
Yeah
I kind of use it as resume...
Thank you guys so much! Pluralsight seems to be a good start. I'm writing down all your recommendations.
I use it at work because we have a multi purpose automation tool that can use almost any function in a Windows desktop that a human can, I also write games for unity and godot with it, I also wrote a pixel art editor and my current personal project is a procedural music generator, which is a basically a synth, wrote without any libraries outside the .net environment. It is a REALLY general purpose language.
I don't mean to be like "Here let me do my homework for you", but I realized I may have been complicating things more than helping. So I got vs community on my machine and built this damn app. I'm gonna post the code at the end, but we don't need to get too involved in IComparer, no worries. Until I got to running the app and testing it, I didn't realize that a large part of the problem was that Sort needs to sort string arrays ( I assume by their first value). As such, I created this code. class Program { static DateTime time = DateTime.Now; static List&lt;string[]&gt; loggar = new List&lt;string[]&gt;(); static void DisplayMenu() { Console.WriteLine("[1]Create log"); Console.WriteLine("[2]Display log"); Console.WriteLine("[3]Sort log"); Console.WriteLine("[4]Search log"); Console.WriteLine("[5]Delete logs"); Console.WriteLine("[6]Quit"); } static void DeleteLogg() { Console.WriteLine("Which post do you want to remove? Use 0 to remove the first item in the list"); string delete = Console.ReadLine(); bool toInt = int.TryParse(delete, out int result); try { if (toInt) loggar.RemoveAt(result); } catch (Exception) { } } static void CreateLogg() { string[] logg = new string[3]; Console.Write("Title: "); logg[0] = Console.ReadLine(); Console.Write("Write your message: "); logg[1] = Console.ReadLine(); time = DateTime.Now; string justNowTime = Convert.ToString(time); logg[2] = justNowTime; loggar.Add(logg); } static void Search() { Console.WriteLine("What do you want to search for "); string input = Console.ReadLine(); for (int i = 0; i &lt; loggar.Count; i++) { if (loggar[i].First().ToLower().Contains(input.ToLower())) { Console.WriteLine($" Title: {loggar[i].First()} Message: {loggar[i][1]} "); } } } static void SortList() { loggar.Sort(CompareLoggars); PrintLoggs(); } static void AskingForLoggs() { string input = ""; do { CreateLogg(); Console.WriteLine("Do you want to add another logg? (type 'yes' to do so)"); input = Console.ReadLine(); } while (input.ToLower() == "yes"); } static void PrintLoggs() { try { foreach (var item in loggar) { Console.WriteLine($"Title: {item[0]} Message: {item[1]} Tid {item[2]} "); } } catch (NullReferenceException) { Console.WriteLine("There was nothing to be found"); } catch (Exception e) { Console.WriteLine("Errormessage", e); } } static void Main(string[] args) { bool keepGoing = true; string menuInput = ""; do { DisplayMenu(); menuInput = Console.ReadLine(); switch (menuInput) { case "1": AskingForLoggs(); break; case "2": PrintLoggs(); break; case "3": SortList(); break; case "4": Search(); break; case "5": DeleteLogg(); break; case "6": keepGoing = false; break; default: Console.WriteLine("Use menu choice 1-7"); break; } } while (keepGoing); Console.ReadLine(); } private static int CompareLoggars(string[] firstLoggar, string[] secondLoggar) { if (firstLoggar == null || secondLoggar == null) { Console.WriteLine("Failed to sort, one of the arguments was null"); } string firstLoggarValue = firstLoggar.First(); string secondLoggarValue = secondLoggar.First(); if (firstLoggarValue == null) { if (secondLoggarValue == null) { return 0; } else { return -1; } } else { if (secondLoggarValue == null) { return 1; } else { int retval = firstLoggarValue.CompareTo(secondLoggarValue); return retval; } } } }
It's still not working. :( New code: [Serializable] public class Entry { public string u { get; set; } public string c { get; set; } public int? h { get; set; } public int? b { get; set; } public int? a { get; set; } public Entry() { } } internal static void GetBirdieData() { List&lt;string&gt; birdieIds = new List&lt;string&gt; { "103168348456653782090", "g17467760575980388556", "g06544397889293102354" }; HttpsCallableReference getBirdieData = FirebaseFunctions.DefaultInstance.GetHttpsCallable("getBirdieData"); getBirdieData.CallAsync(birdieIds).ContinueWithOnMainThread((task) =&gt; { if (task.IsFaulted) { Debug.LogError("GetBirdieData task.IsFaulted: " + task.Exception); return; } if (task.Result == null) { Debug.LogError("GetBirdieData task.Result == null"); return; } if (task.Result.Data == null) { Debug.LogError("GetBirdieData task.Result.Data == null"); return; } try { Debug.Log("GetBirdieData Result.Data: " + task.Result.Data.ToString()); Debug.Log("GetBirdieData Result.Data casted: " + (Dictionary&lt;string, Entry&gt;)task.Result.Data); Debug.Log("GetBirdieData Result.Data as: " + (task.Result.Data as Dictionary&lt;string, Entry&gt;).ToString()); } catch (Exception e) { Debug.LogError("GetBirdieData EXCEPTION e: " + e.ToString()); } }); } Output: 06-30 11:26:54.011 13974 14009 I Unity : GetBirdieData Result.Data: System.Collections.Generic.Dictionary`2[System.Object,System.Object] 06-30 11:26:54.028 13974 14009 E Unity : GetBirdieData EXCEPTION e: System.InvalidCastException: Unable to cast object of type 'Dictionary`2' to type 'Dictionary`2'. And then it stops. If I remove that cast line, there's an error on the "as" cast as well.
C# is suboptimal for gaming. It CAN be used to make games, but it has a bit too much overhead for real high-end games. You can write all manner of desktop applications with C#. It's faster than both Python and Javascript, and since it doesn't care about white space and is type safe, it's easier to write quality code with it.
Upvote for AngleSharp. Another tip as more things move to JS + API, you can use the dev tools to find the API URL. Then you can skip the HTML altogether. One possible complication is if the API requires an access token that generally gets stored in a cookie. You can use Selenium to browse to the URL that sets the cookie, and then copy that cookie over to your HttpClient. They usually expire, so just handle results that return unauthorized by fetching a new auth cookie.
No, stick to WPF. Just treat it as if you were making a Winforms app, you don't have to write the xaml by hand. Close the XAML window.
Expression still exists, they just dropped the name. If you have Visual Studio installed then you have Blend installed.
What is your buddy’s background? I’ve made several web scrapers with c#.
I just loaded up JetBrains Rider 2018 and pasted your code. I did not get this error. Sounds like an issue with 2019.
I can build that without a plugin thanks.
[AngelSix - WPF UI Programming (C#)](https://www.youtube.com/playlist?list=PLrW43fNmjaQVYF4zgsD0oL9Iv6u23PI6M)
It is fine for the game logic layer of a game. However, the lower level stuff (graphics, compositions, basic game engine) is best provided by highly-optimized "close-to-the-metal" language/compiler. Example, you can use C# with Unity quite well, and performs well, but Unity is doing the low-level heavy lifting.
I'm using htmlagilitypack in a project right now, what benefits does anglesharp offer?
The repository pattern is just abstracting persistence away from the business logic of an application as far as I know (and according to a few different articles a quick Google). Is there a more authoritative source on what it actually is if that's not correct? PWhat do you mean by a crud template? Obviously a repository is a way of doing CRUD... Those are the 4 components of persistence so of course a repository is just a CRUD implementation.
He’s a Java type of guy with some python. Mostly does python these days though
I'd argue that the real problem in this whole model is that `TestData` and `Test1` have no type-system relation. It's trivial to have type mismatches... and I've seen em several times, including causing bugs (because unlike a plain call, not all type mismatches are cause for a crash, sometimes xUnit decides to be "helpful" and e.g. replace `null` by 0 or whatever). Frankly, tests-as-methods isn't a great model to start with.
You can't cast a `Dictionary&lt;string, object&gt;` to a `Dctionary&lt;string, Whatever&gt;`. It makes no sense. My code was to parse the JSON to the specific structure, but that is **completely** unrelated here. You're not dealing with any JSON. You're dealing with whatever that crappy FirebaseFunctions method returns you.
AngleSharp is spec compliant and includes stuff like QuerySelector(All) without extra libraries. If you're used to js dom apis they should be available in AngleSharp. I swapped out HAP for AS in a project the other day and it worked well. Below is from their GitHub repo: Standardized HTML5 parsing model Much better error correction / handling Also parses SVG / MathML elements correctly Can handle CSS (selectors, rules, …) Better performance
Event better. Loaded Visual Studio 2017 and you know what? Error...
Blend does. The entire rest of the suite was killed or sold off. And as for Blend, I haven’t seen it mentioned in the VS release notes in a long time.
I'd say his buddy is wrong by thinking it's for games. He sounds like his only experience with C# is in Unity. That's like saying hammers are only good for making the bell ring at the county fair. Or that screw drivers are only good for prying thing. I don't want to confuse OP in thinking his friend has any credibility here.
No offense but it sounds like he has no experience if he only knows of C# in Unity. Tell him Java is only good for making Android games and watch his head spin. That's literally the exact same thing he's trying to say.
Isn't the word 'Caching'? Bummer.
I'll def check it out. I use it with ebooks and those documents end up having a ton of elements to parse so any performance increase would be awesome.
It's returning that exact object I showed you. Remember that JSON.Stringify output?
Did you read the post? &gt; the above code doesn’t even compile: I did some further testing on Rider 2018. Setting the C# Language version is set to 7.3 or higher. I did some research, C# 7.3 improved overloads for methods. Specifically generics. &gt; When a method group contains some generic methods whose type arguments do not satisfy their constraints, these members are removed from the candidate set. C# 7.3: https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-7-3 So it should work, on the right version of C#. Right click your project, go to properties. There should be a selection for "C# Language Version". Select 7.3 or higher, or latest major and you should be good.
Not at all. https://whatis.techtarget.com/definition/caching
Even in that link it say's Caching.
LOL
Oh It's a spelling mistake, I though you are talking about Cache &amp; Caching. I'm really sorry. Let me repost
I was talking about Cache and Caching.
Hey, the typo is gone, lol.
I'm trying to wrap my head around all this. Should I create classes mirroring all my db tables as classes and all the columns as members of the appropriate data type with a get;set?
Wrapping an abstraction layer with an unnecessary abstraction layer. What could go wrong? I just started at a company that standardized this type of thing and it does not scale well. Huge, vague, repositories, leaky abstractions and the inability to fully utilize the tooling that you've selected. All for that sake of "testability" and being able to swap out the data store, which rarely, if ever, happens.
Note: I haven't read it wholly, but most likely you should wrap your whole game code with loop ("Until exit is requested"), then at the beginning of this loop add: arr = { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' }; So each time you start the game, you'll start with a fresh board.
Thank you! :D You are right!
Thanks for answering! When I do this I can't even change the numbers for "X" or "O" anymore, they are always numbers
Then you already have an object, and you don't have to parse anything anymore. The library did that for you
Maybe you'll have to reset flag variable as well. This code is a good start, but requires a bit of work to be readable. In the meantime, try using debugger - and familiarize yourself with it. It will be invaluable further down the road. https://www.google.com/search?client=firefox-b-d&amp;channel=trow&amp;q=debugging++visual+studio
Yellowbook, Pluralsight. Lack of resources isn't a problem if you're willing to learn.
You keep saying what I just said, I don't think we're getting anywhere. Can we try again tomorrow? I genuinely would like to explain this better, but tonight is not a good night for me.
TY very much, reseting flag was my problem: while (match_counter &lt; match_numbers) { arr = new char[10] { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' }; flag = 0; do ___rest of the code___
I just wanted to know what you deem as a repository pattern. You seemed to disagree with the image in the original article which showed the repository as a layer between business logic and a data source. You said it shows CQS, which is true, but CQS/CQRS and a repository pattern are not mutually exclusive. You then stated that just because I was using repositories, that doesn't mean I was using a repository pattern. I think all of this would be cleared up if you told me what your definition of the repository pattern is, as that's what the root issue here is.
I honestly wouldn’t recommend that. MVVM is probably harder to get your head around when you already know the win forms method. And it then ports over to Xamarin too.
You don’t ... that’s the beauty of repository pattern (wrapper or not)
Is there a reason you duplicate names. Eg. In the ICustomerRepository you have GetCustomer. Why not just Get. It’s pretty lexical we working with Customers. +1 for using Visual Studio compliant convention. I don’t like people using framework conventions like EFCore and underscores everywhere for no reason, especially in a bounded, well defined context.
Generic Repository Pattern confuses a lot devs. I love it but I find 9/10 devs don’t understand it and start doing weird things with it. Yea... how right. Not sure how or why it just happens.
+1 - no high-schooler should be learning WPF. I’d go so far as saying nobody under 40 should be learning it. MVVM is useful, as is the concept of 2-way binding, but most everything else is proprietary and somewhat arcane.