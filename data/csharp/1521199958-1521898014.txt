Can anyone tell me why I'm receiving downvotes on this post? I'm not asking for anyone to do any code for me, more so help on my understanding on the matter. I'd just like to clarify so I don't do the same thing again, resulting in another down-voted post... 
Agree. Interesting, but there's no way I'd ever make use of it. This is funny. He has reversed his meanings. Normally, false is zero, and true is not-zero (implementations could have it be 1, or even -1) public static bool operator true(TrueFalseOperator value) { Console.WriteLine("true"); return value.Value == 0; } 
Yep, better docs are coming. I'm all for adding more high-level constructs. 
In retrospect, maybe posting your own resume might not be a great idea, just for doxxing reasons. If you do decide publicly post it, be sure to remove any personally identifying information. Any other questions, comments, issues, discussion, feel free to comment or reply to this message.
What? You don't want a set of 30 random titles under your name in your work emails?
Oh, I get it now. Yeah, rolling back forward again after rolling back...I could see how that could require some manual intervention.
What would be the difference between that and this: public static implicit operator bool(TrueFalseOperator t) =&gt; t.Value == 0;
just learn MVC
Change Value to value and use this.value instead. 
ü§¢
If I understand correctly, Unity uses this to have JavaScript-like check for non null values in the form of `if (obj)`. Still sounds like a hack to me, but it's there.
Oh well, horses for courses then. 
What if I look back on code I wrote a day ago and am completely disgusted by it?
Cool. For example, I totally understand not having a Cgte when Clt + brfalse are a thing, but that shouldn't be something a dev needs to deal with, especially when the code you're passing in is gonna get jitted anyway.
I'm actually in the process of doing that now. Everything writing to a memory mapped file, and the file regularly dumping to the harddrive. Since this happens hundreds of times per second, it's a lot of "noise". At the least, hopefully this will tell me if my theory is correct.
No jobs to offer but this is a cool idea, I like it üëç
... or you are an AI with machine learning &lt;*eyes you suspiciously*&gt;.
Why should he go against the code convention just to make the code more unnecessarily verbose?
I've tried Rider. My work require Winform app but unfortunately it does not support drag n drop GUI design
You could make a dump(e.g. using debugdiag) and then check the stacktaces(e.g. using windbg). That could help pinpointing where the waits are.
If you are only interested in simple primitives, then an [obj file](https://en.wikipedia.org/wiki/Wavefront_.obj_file) could suffice. Visual Studio is also able to natively open and render them. Their format is trivial to understand and easy to emit. Another text-based format to look into would be [glTF](https://www.khronos.org/gltf/). It is a json-based format which could be fairly easy to emit. But it is probably far more complicated than you need for simple primitives. I've never heard of URDF or X3D, so I can't recommend those.
Yeah, somewhat. The problem is that you cannot negate the condition. Then the cast to bool _might be_ reasonable.
&gt;However, the language now provides built-in support for nullable value types, and whenever possible you should use those instead of overloading the true and false operators. To me, this makes it seem obsolete.
^ | | | This. Don't even need windbg. VS debugger reads dumps sufficiently for this.
[removed]
I want to hire people but I have to convince the money people to give me money to hire people with. When-the-heck-that-happens-if-ever I hope we are still doing this.
In the MS documentation, they call them the "Definitely-true" operator and the "Definitely-false" operator. This makes sense, as they were originally (pre-C# 2.0) intended to allow developers to implement their own ternary logic. This was to emulate t-SQL behaviour involving NULL's in WHERE and JOIN clauses. I think it's frickin' cool, and interesting, to boot. However, in their example, MS overloaded *every* logical operator, as well. This means utilizing this overload basically requires you to overload five or seven *more* operators to use effectively. There's probably some cool cases where this is useful (someone said something about Unity earlier.) Also, interesting historically, to me at least.
Just as for good practice, when you overload operators like `true` or `==`, use negation in the opposite. So your class would look like this: public class TrueFalseOperator { public TrueFalseOperator(int value) { Value = value; } public int Value { get; set; } private bool IsTrue(){ return Value == 0; } public static bool operator true(TrueFalseOperator v) { return v.IsTrue(); } public static bool operator false(TrueFalseOperator v) { return !v.IsTrue(); } }
I am not a fan of it. I think if we want mixins we should create a new type category for it: * Struct * Class * Interface * Enum * Mixin ... or whatever.
Give this a shot, class Program { public static void Main(String[] args) { int a = 5; int b = 6; multiplyThis(a, b); //Holder your window open so you can see your results Console.ReadLine(); } public static void multiplyThis(int a, int b) { Console.WriteLine(a * b); } }
Give this a shot, class Program { public static void Main(String[] args) { int a = 5; int b = 6; multiplyThis(a, b); Console.ReadLine(); } public static void multiplyThis(int a, int b) { Console.WriteLine(a * b); } }
It's been discussed, here, at least a [couple](https://www.reddit.com/r/csharp/comments/60alwo/a_tour_of_default_interface_methods_for_c/) [times](https://www.reddit.com/r/csharp/comments/75pqva/c_80_method_implementation_in_interface/). It's got some good and bad, from what I recall, but it would definitely make for cleaner ways to handle implementing, say, IDisposable.
I accidentally put my java code in as the example(just edited it above). I did what you did, and it worked(switching it to Console.WriteLine) . Is it bad practice to try to return your values like that in C#? It doesn't seem to do anything. 
Not at all. In fact I would say you almost always want your methods to return something. That way you can reuse code, simplify error handlinf, etc. Returning it and writing it to the console from your main method is just fine in this situation. 
At first I didn't like the idea, but it solves a problem with evolving interfaces that have a lot of implementations.
I think C# needs *some* kind of traits. Classical single-inheritance is fast becoming outmoded and this is one area where C#, a language that is usually ahead-of-the-curve for a mainstream lang, is actually lagging behind. Don't believe me? All these languages support traits or mixins: * [Swift](https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Protocols.html#//apple_ref/doc/uid/TP40014097-CH25-ID267) * [Rust](https://rustbyexample.com/trait.html) * [Java](https://opencredo.com/traits-java-8-default-methods/) * [Python](https://ahal.ca/blog/2014/when-would-you-use-python-mixin/) * [Scala](http://www.scala-lang.org/old/node/117) * [C++](http://www.drdobbs.com/cpp/mixin-based-programming-in-c/184404445) ---- For me the question really lies in whether default interface methods is the right implementation. I've seen some good arguments for and against that, so I'll abdicate from that one. But on whether C# should support traits or something similar, I'm 100% for it.
I typically always return; I was just getting weird errors, so I wanted to ensure. One more quick question - when I run this: using System; class MainClass { public static void Main (string[] args) { int a = 5; int b = 6; multiplyThis(a,b); } public static int multiplyThis(int a, int b){ return a * b; } } I get nothing to return. I don't get an error. It just seems to return nothing.
Gotcha, try this instead, class Program { public static void Main(String[] args) { int a = 5; int b = 6; var result = multiplyThis(a, b); Console.WriteLine(result); Console.ReadLine(); } public static int multiplyThis(int a, int b) { return(a * b); } }
That worked and did what I wanted it to... Thank you! I think I understand how to do all this now.
Awesome! Feel free to pm me with any other questions you've got and I will happily assist. I come from a python background myself, so I feel pretty comfortable helping people overcome some of the nuances of C#
Not very different. Useful in the rare case where `true` and `false` aren't always opposites. NullableBool b = new NullableBool(null); if (b) { } if (!b) { } Neither branch is taken.
Thanks, I appreciate it a lot. I imagine I will be doing that. I've got a lot to learn before May(being of internship), so I imagine I will be running into a few more issues.
That's nothing compared to a junior developer's salary. As a student, you can get a license for free.
Use [Postsharp deadlock detection](http://doc.postsharp.net/deadlock-detection). I've used it to detect a deadlock and it was fantastic. From [their](http://www.postsharp.net/blog/post/Deadlock-Detection-using-PostSharp-Threading-Toolkit) article a while back In order to detect deadlocks we have to track all blocking instructions used in user code and build threads dependency graph from them. When deadlock is suspected all we have to do is check if there is a cycle in the graph. It sounds simpler than it really is. Tracking all locking instructions using hand-written C# code would be very tedious. Normally one would write a wrapper for all synchronization primitives such as Monitor and use these wrappers instead of standard sync objects. This generates a couple of problems: a need to change existing code, introduction of boilerplate code and clutter to your codebase. Moreover, there are some synchronization primitives, such as semaphore or barrier, which are hard to track because they can be signaled from any thread.
I think the interfaces would lose their meaning with "default implementations". Since the interfaces are made to only define the behavior and characteristics that must have the objects that implement them. 
&gt; And there 0 means success Yep. I somethings think of it as "no problem, mon."
I'm not against them, but I'd prefer them to focus on the shapes proposal instead. I get that it's a much more complicated feature, but it should be able to accomplish roughly the same things, and much more. If they end up implementing shapes they'll end up making default interface methods obsolete in just a few years time.
[*Shapes*](https://github.com/dotnet/csharplang/issues/164) is a proposal from Mads Torgersen proposing something resembling typeclasses/traits. It has existed for over a year, but unfortunately it hasn't seen much progress since then.
What computer science background do you have? You might get more from learning some fundamentals, perhaps in another language to broaden your horizons. Something like C++ or Rust if you are interested in low level code and performance, or maybe something like F# or Haskell if you are interested in higher level ideas, or function programming (Rust gets you a bit of both actually) Unless you have a very specific subset of the industry you want to get better at, mastering the fundamentals of programming is the most valuable things you can do. There are innumerable courses out there, codingame.com can be a fun way to learn about data structures and algorithms and you can do them in many different languages (including c#). I have an ongoing series where I teach programming starting from the basics up to pretty advanced stuff in Golang, with game related projects. But there are important comp sci fundamentals in each project too, like recursion, trees, graphs, and so on: https://gameswithgo.org/ 
I say WPF. Unity has quirks, and isn't quite up to date on the latest C# features/versions. You'll probably also find lots of tutorials or examples just plain using _bad_ coding practices. I find lots of Unity stuff involves people getting something to just "work" then move on. MVC means you have to work within the bounds of the whole site-page-request model. Might make for experimenting with advanced C# features (say, async-await) more cumbersome. Plus you'll have whatever else HTML/razor, MVC, page handling stuff to deal with. Going WPF you can use as little or as much XAML as you want. But it should also give you flexibility to go deep on whatever C# language feature or .NET framework feature you want. Should be easier to debug, and easier to learn some other things, like unit testing, multi-threading, I/O, pinvokes, you name it. Plus it seems like you're enticed by it ("just seems cool") which is important to keep you enjoying the experience. Once you feel like you got a good handle on writing "good" code in C#, you can easily branch out and learn Unity or MVC (or whatever platform).
Part-Time, Ongoing, Remote C# freelance gig available for developer with Azure experience that likes to work the whole stack. Rate: $45-$60/hr + equity options on product launches. Hours: 20-40 hours per week. Apply here -&gt; https://i.codefor.cash/gig?req=222408
I have been doing front end development with a little backend, but doing a lot of old practice with front end at my current company. Jquery and such, not super heavy applications. I would say I am a good scripter, but OOP has never been needed with such short projects with low interactivity. Lacking on OOP practice (I know the concepts though), and doing anything at all related to algorithms. I do tend to sell myself short often, but I would say 4-5 out of 10 on programming skills. I am definitely conncerned with becoming a good programmer, but I am trying to find a path that I won't get bored and quit halfway through, which I am usually pretty okay at, but the tutorials I have been following in pluralsight were console related and... well it was making me very unwilling to move forward. Would you recommend another way for me to master the fundamentals with c# that I didn't list? The more the interactive of a application I am making the better for my own sanity. 
 I'm assuming inner xml returns a string. Can't you just do the replace then write it to file like a normal string?
Followed you on twitch, I will definitely tune in! I did a quick edit to my post above about considering Xamarin also, what do you think of that? 
I haven't used Xamarin since its infancy (when it was "Mono for Android"). My understanding is, again, you might have to deal with quirks and also learn all the platform concepts/quirks of developing for Android. Plus whatever slower compile/deploy/test cycles running it in the emulator or device. Plus whatever issues with using the debugger. Xamarin is fine, but you're learning that much more at the same time. If your primary goal is to learn C# and good programming practices, I say you should try to eliminate other platform-related stuff or complexities that can make that task more difficult. Once you're comfortable/fluent in C#, then learning those platforms is easier because you focus your mental energies on understanding the platforms rather than also fighting with writing C# code.
That is completely fair, I definitely may just continue that then, and just push through the pain haha
If you are interested in making apps that will run on Android and IOS (and/or PC/Mac/Linux)with a single codebase, Xarmarin is a decent way to do that. Its still just C# programming, with an API to make windows and buttons and so on that is cross platform. There is also monogame which lets you do 3D or 2D graphics cross platform as well. Again, its just programming, with libraries for graphics and vector math and fonts and found and input and so on. 
Jeez, what's the line count in your multi-gig project? And is it all in one solution? Sorry I'm not adding much to this discussion, just curious.
I've never needed to actually revert a deployment in my 10+ years of development, if something happens (which is rare if you have good automated testing practices) it's a quick hotfix/patch and rolling forward instead. I've never been on projects with more frequent than monthly releases to production though (but several per hour to Dev/staging), I could see the ability to roll back DB changes being more important if you're doing more or less continuous deploy to production. But TBH there could be just as many problems with integration between services; changed message contracts causing messages to go to DLQ etc.
`true` and `false` versus `implicit operator bool` actually have fairly different semantics. `true` and `false` can't be used with operators. `if( b )` is valid but `!b` isn't. Nor are `b || c`, `b &amp;&amp; c`, or `b == true`. Which means really all you can do with it is `if( b )`, `while( b)` etc. If you want your type to actually behave like a bool you need `implicit operator bool`. Also the CLR will prefer the implicit overload over `true`/`false` for all purposes if all three are defined.
mfw php is further ahead in the game than c#
That's pretty cool. Didn't know about not being able to use with operators. I don't really see much utility to these operators really.
The only reason I see for this is compatibility with Java (via Xamarin). Other than that I see no point, it's too messy.
So how is it submitted?
They give us a DLL that has all the submit / response / etc. methods to us to call, and it handles all the communication inside it (black box to us). We just call their submit function and pass it as a parameter.
i've found this post here; https://github.com/dotnet/corefx/issues/11292
Of course I like it, much better than trying to rely on extension methods. Not sure why you'd bring up multiple inheritance since this has none of the issues associated with that.
One of the things that worry me is that the implementation called will depend on the boxed type. I don't know how this is implemented with traits.
I don't think that really changes, but even if it did, so what? It's a very dogmatic approach to development concepts.
Pretty clever use of IDisposable with Twenty. Can't say I'd ever use this but it looks very functional and was probably lots of fun to make. Cool stuff! Were your benchmarks using runtime compiled razor views? That would cause lots of performance loss - I would expect precompiled razor views to be much closer to your results.
Ah bummer. Maybe ask them if they know? They must test it somehow, so that may be your best bet. See if you can talk to one of their developers.
Yeah, all the developers are allowed to say is "Submit and XMLDocument type to us" and "We don't accept named html entities, only character references". It's up to us to figure everything else out (helpful, right?). I did ask if they would accept the text inside a CDATA block as that would be cake, just plain text with no references. They're going to test next week and let me know. While I understand it, it's kind of surprising that there's not a way to use an XMLDocument data type and prevent it from converting to named entity references.
Will doing this still "block" appropriately?
I couldn't begin to tell you. There's 10 different code bases we work from, each code base has an installer solution (which can have hundreds of files) and then is broken into the solutions that contain all the event processors, command handlers, web services, windows services, etc. So no, LOTS of different solutions for the code base.
Thanks! I'll look into this!
I'm going to hate it until I figure out the circumstances in which it helps me. Before I get there, I'll use it in more than a dozen ways that hurts me.
Does the Core version of the class support the SetSocketOption method? You might need to add some parameters to make it work. I had trouble seeing any good socket examples for Core with a quick google. The ones I found use websockets or tcp listener.
Yes. The issue with using async/await incorrectly is that the context switching with the Wait()/.Result causes the deadlocks
&gt; To me it seems like sneaking in multiple inheritance. Is that a crime?
"Multiple Inheritance Is Bad" is one of those things that Everybody Knows.
Generally speaking, it's Pascal for classes, methods, public properties, and camel for private fields. 
Perfect, thanks. 
I've had a Google and it looks like that is just how the xmldocument is designed and there doesn't seem to be anyway to change it. If that's the case then I don't know what they are doing with it. Sorry I couldn't help bro, good luck with it. Let me know if you find a way.
Use XDocument instead and enjoy the linq enabled API.
Could you give an example of what you mean?
What convention?
Indeed. Not to say there are no *legitimate* criticisms of multiple inheritance or the problems that can come with it, but the reaction is sort of like what happens when one mentions `goto`: Everybody Knows that "Goto Is Considered Harmful"; far fewer understand *why* `goto` was harmful or, therefore, how it's still useful.
The standard is old and very widespread with excellent tooling, most providers assume you have someone who knows how to handle it. Seriously, its would be like asking someone if they know how to use bash.
Parameter names are lower camel case, see ```void Main(string[] args)``` if you create a console application and every other .Net class
I'm lost. That was the reason for my original comment: OP used an upper case letter, Value.
Ahh, I see. Then it is against the convention that public properties (like Value) are upper case. Btw, private shouls start with underscore, lower case is more or less exclusive for inline variables and parameters
... I just had my Jimmy Stewart in Mr. Smith Goes to Washington moment, and then you're like yelling "Also Hitler did nothing wrong!" from the gallery.
Yes, in c# variables start with lower case , methods with upper. Generally. That's why I suggested changing Value to this.value. 
An absolute clusterfuck. There is nothing good about it.
‚úìDO use PascalCasing for all public member, type, and namespace names consisting of multiple words. ‚úì DO use camelCasing for parameter names. ^^[source](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/capitalization-conventions) It is a public member so the guide suggests Value. The one time the variable should be lower case is at ```var value```, and there it is lowercase
Have you considered following along with a course specifically focused on MVC, such as [ASP.NET MVC 5](https://www.pluralsight.com/paths/mvc5) over at Pluralsight? MVC is a pretty basic concept but it was difficult as hell for me to wrap my head around as a junior. The best advice I can give is to start building MVC applications and fail at it a few times until you work out your misunderstandings. It's okay if you don't understand everything right away. For the longest time I didn't quite get the difference between the Model and the Controller, but at least I understood the View and the Model. Some is better than none when it comes to design patterns.
Just curious since I‚Äôm relatively new here: Are there typically entry level positions available?
100% for them. I understand the arguments against them, but extension methods provide a lot of the same functionality without the benefits: polymorphism being the big one, but it's also always seemed a hack to define an interface and then another static class in (if following the "proper" procedure) another file to define the methods in. The line is already been blurred, and by adding polymorphism, I feel like it actually brings interfaces back closer to the open ended code contracts people see them as. It's also kind of nice that interfaces already have a solution built in for the diamond problem, so I'd imagine that will end up feeling natural once default methods get implemented. Only thing I'd say is that default interface implementations should always be virtual, for the aforementioned reason.
Well, I guess that proves my point? C# has `goto` and it still has a couple, very niche uses. It's also pretty constrained in C#. I'm not saying you should use it instead of something more appropriate, but you simply can't jump into a completely different scope. The language does not allow it.
Could you just databind the checkboxes to your viewmodel and see which values are observed?
In addition to what /u/Liam2349 said, some people use `_camelCaseWithAnUnderscore` for private fields. It's contentious however, and others are strongly against that convention.
If you have questions, just ask. I cleaned up your code an threw away a lot of stuff that wasn't used. The student class had some _Name-Fields that weren't accessed. Next step was separating out the parts of the code that generate the students and to push the data into data files. You should get in the habbit of pushing code into multiple classes. This will enable reuse and will make your code a lot easier to test. Last but not least I threw away your sorting code and replaced the ListView with a DataGrid. To leave in some code I implemented the filtering in the StudentSearchViewModel. I'm sure someone with a propper background in WPF could provide a *better* solution via a CollectionView. But I felt the solution was "good enough"(TM).
This sounds really interesting. I was trying to build a library like this for some time, but never got around it. Are you using it anywhere in production already? 
Hello, just wanted to stop by and let you know that you can PM me as well if you are ever stuck. You should also consider trying out a free trial of Pluralsight, or getting [3 months of it free](https://help.pluralsight.com/help/im-a-visual-studio-dev-essentials-user-what-can-i-get-on-pluralsight-how-do-i-redeem-it) by signing up for a Visual Studio Dev Essentials account. Good luck!
I literally just encountered this a few minutes ago as I work through an intro lesson online where the guy uses an underscore for a private variable. Mapping out public classes vs public variables and private and all that hierarchy stuff is complicated right now. Future problem. 
Why everyone hates goto but is okay with exception handling that is basically a goto but without requiring explicitly stating where it's going to is beyond me. 
Hey thanks, I appreciate it a lot!
Yeah how is this different from multiple inheritance? Why did they choose to do this compared to multiple inheritance?
I might have to look into this. I have asked them if enclosing the text in a cdata block would work, that way I can just pass it as plain text without needing to escape the special characters. They didn't know so they're going to test and get back to me next week.
I had the same issue with a textbox inside a popup, never did figure it out. I'd love an answer. I ended up having to switch to a Window, used as a dialog, to get it too work.
You know, at this point I don't think anyone is going to use goto "the wrong way". It's a weird anachronistic complaint, because it's not obvious it's even there any more. Nobody learns to use "goto" and then has to unlearn it.
After doing some research before I started my new job position I came across Pluralsight, reviews were positive regards to their c# tutorials. I will be defiantly getting subscription on it as soon as I get paid, still have one months worth Lynda.com subscription, not sure if any of their available courses is something that I should try and do. When I began to learn c#, I started of by working with console applications within the Visual Studio IDE, it was fun and I was enjoying it and I felt like I was learning at the same time, but later on I had to change the project type and work with Web Api using MVC, since the start it was really confusing and felt like I am stuck on trying to understand basic concept of it, as you have mentioned models and controllers did play big part on confusing me, still is...-.- Appreciate your response, I was feeling very anxious by posting this, I always overthink how people are going to judge me, its great to know that there is someone who was in a similar situation and understands how I feel, I will defiantly join the discord also contact you for advice not to the point where I would start annoying you with bombarding questions.
Why not just omit the MVC controller and use the API controller for everything? What benefit do you get from "wrapping" the API controller with the MVC controller? Controllers should also never reference other controllers. This screams violations of SRP. If you have two controllers that need to do the same thing, then make a third class do it, and call it instead of tightly-coupling your dependencies between controllers.
Do you have a sample of what they consider to be valid request data? Do they have a DTD at all? Its not about the API you use to generate the XML its about the document output. XDoc has a more fluent way of describing your document where the code looks kinda like the resulting XML. It also has better namespace control and defaults to no namespace.
Yes it does! That is very strange.
That's not their role unless they do training, at best you get a spec and some samples, maybe an actual API ref. At some point you have to draw a line where your docs and support are going to stop, at one point XML was considered so standard everyone learned it right along with whatever language. Its a bit cumbersome for simple use so it has been supplanted in a lot of places though it still cannot be paralleled in some use cases, team that support it have likely had that line forever from a time where nearly any given developer could read and write basic XML. What you do with your docs for others is of course entirely up to you, if you want to walk people from how to click the start button to opening the browser that's what you can do. If you want to try and push some sort of standards of documentation on the software dev world, I wish you the best of luck. Most hate writing docs, and most companies hate paying to have any docs written. Its also a pretty thankless task professionally. 
It's always called in the constructor of a form.
I do this, I can see why it's contentious. Some of the Google maps libs (JavaScript of course) use an underscore after the var name - still getting used to that one. this.div_ 
InitializeComponent should only be called once in the constructor. It builds the whole form, don't call it yourself.
Sounds great to me. Make an interface, have it automatically implemented somewhere (at your option, of course.) Anything to save me from writing more boilerplate. It's what I like about Scala. Cuts down on boilerplate code.
Exactly. There's no practical difference between an interface with default implementations and an abstract class... other than you're allowed to implement multiple interfaces and not inherit from multiple classes.
Yah, so having switched to core I ran into the exact same error message... now that being said the library itself hasn't been updated to Core specifically but what I learned is that the core runtime has the same issue as the mono 4.8 runtime... I've been googling and can't seem to find any way to overload that param. I understand it's purpose, or at least why the author used it but it is really a pointless param. 
ValueTuple and tuple syntax aren't an advanced topic IMO
&gt;also contact you for advice not to the point where I would start annoying you with bombarding questions. Any time, it's really no trouble. Good luck out there! :)
&gt;But it's a bit like tabs vs spaces or bracing style, it's not something I get too hung up on. Whoa, if you want to fight, let's fight!
I reference this. http://www.dofactory.com/reference/csharp-coding-standards
Tabs and egyptian style ;)
Interesting, I've never seen SendKeys before ... I bet that would work. My personal theory about the Popup class is that it overrides the functionality of certain keys (Backspace, Enter, Escape, etc.). If i was able to force the Popup to 'tab', meaning move to the next element (the textbox) that might/should pull focus to the appropriate element.
I'd say it'd be cool to teach them like after you have made a few programs and find out a legit way thats better than a POCO or struct or something
Try u/TheManFromOregon solution and report back. My code is so dramatically different now that I can't go back to what it was.
Wow. Thank you! I really appreciate you putting that much time and effort in to helping me.
Not a problem. I just installed Rider on my new laptop and wanted to take it for a little spin. So a little refactoring project was just about the right thing to try. If I can help someone getting started to improve along the way - even better. But seriously if you have questions just ask :)
This needs more upvotes!
If this was on stach overflow it would be marked as the answer.
Haha I feel like we are all working on TextBox projects
Camel for parameters too 
Very useful article! Been playing around with this myself as an alternative to cake. It‚Äôs nice to have some proper integration into the actual project. 
Can't we already basically do that with extension methods?
Elabstops. *** ^(Bleep-bloop, I'm a bot. This )^[portmanteau](https://en.wikipedia.org/wiki/Portmanteau) ^( was created from the phrase 'Elastic tabstops'. To learn more about me, check out this )^[FAQ](https://www.reddit.com/78ilq0).
Good shout. There are probably more I forgot too.
I'm with you until the last one. Suffix of Enum makes it so you can tell so much easier when you need to pass it in a function 
It's an an attempt to resolve an implement issue which occurs because C# doesn't have multiple inheritance that can be implemented without major changes to the runtime or introducing too many problems. It's not by any means the best possible way to solve this problem, but it solves a real problem in a way that's simple to implement. 
They chose to do this because it can be implemented without major runtime changes. There are at least a dozen ways to do this, most of which are probably better or at least cleaner, but they're all much harder.
 private void Form1_Load(object sender, EventArgs e) { textBox1.KeyDown += TextBox1_KeyDown; textBox1.PreviewKeyDown += TextBox1_PreviewKeyDown; } private void TextBox1_PreviewKeyDown(object sender, PreviewKeyDownEventArgs e) { Console.WriteLine("TextBox1_PreviewKeyDown " + e.KeyCode.ToString()); } private void TextBox1_KeyDown(object sender, KeyEventArgs e) { Console.WriteLine("TextBox1_KeyDown " + e.KeyCode.ToString()); } 
Works for me. Maybe I don't understand. How are you adding the event? textBox1.KeyDown += TextBox1_KeyDown; textBox1.PreviewKeyDown += TextBox1_PreviewKeyDown; then: private void TextBox1_PreviewKeyDown(object sender, PreviewKeyDownEventArgs e) { Console.WriteLine("TextBox1_PreviewKeyDown " + e.KeyCode.ToString()); } private void TextBox1_KeyDown(object sender, KeyEventArgs e) { Console.WriteLine("TextBox1_KeyDown " + e.KeyCode.ToString()); } 
For individual licenses: It's $139.00/1st year $ 111.00/2nd year $ 83.00/3rd yr onwards
Personally, that is one of the few Javascript features I wish C# had built in. Although, ?. takes care of most cases where this is useful.
I tried Resharper once, and it made Visual Studio unusable.
I'd also like to point out private fields are *technically supposed to use `_camelCase` with a beginning `_`. Strict `camelCase
The question would have already been closed for not showing code samples....
C++ had pretty much the same thing for many years. I have seen it being used quite infrequently but it is very useful sometimes. I like it. I have a feeling that these default implementations are more like macros than actual virtual functions. So no sneaky multiple inheritance here. Just a pinch of syntactic sugar. 
Agreed. I wonder what the use case was that supported this feature or why they chose to pursue this. Feels completely contradictory to the use of an interface, which is abstraction without implementation. 
The strange thing is that I don't have any controls in front of the textbox, no labels or anything. It's just a basic winforms textbox and it's inside the main form, not inside of any popups. I think the Delete key should work by default. As Nunto pointed out, if I click outside of the textbox and back in then the delete key works as normal, even without any event handlers. I only tried using the KeyDown event to see if I could get some sort of response from the key but it does not work, though every other key seems to work. The textbox is not a custom control but I did try shifting the focus in various ways in the main form's constructor to no avail.
I wonder, isn't the event caught higher up the component hierarchy, and handeled, so it does not reach the TextBox? Can you check the same events you tried but on the parent? Doesn't one of the classes that the parent of the TextBox inherit from have some functionality on 'delete' which causes this? Can't really think of anything else.
I usually find that `PreviewKeyDown` solves my weird problems.
I don't see how this can be done without runtime changes.
While I think a prefix for private fields is cleaner, there is no standard for it.
&gt; public RolesApi2Controller(ApplicationDbContext context) That's a problem. `ApplicationDbContext` is an `IDisosable` object, but `RolesApi2Controller` is not disposable. A non-disposable class should never, ever have fields that are disposable. That causes all kinds of life-time issues. Furthermore, you are potentially hogging a database connection for the lifetime of the request. (I say potentially because EF is weird about this.) Database connections should be released as soon as they are no longer needed. What you should do is inject a connection string which will allow you to create the `DBContext` when needed and dispose it as soon as you are done with it. That's why we have the `using` statement.
&gt; _rolesApi = new RolesApi2Controller(context); You are calling it a `Controller`, but you are treating it as a `Service` class. What's the difference? *** A `Service` class is where you put the bulk of code, including everything that's reusable. A `Service` class should be thoroughly tested, preferably with automated tests that hit live dependencies like databases. (Some argue that you can just use mocks for testing. They are wrong. You can use mocks plus live dependencies when needed, but that's different than only mocks.) *** A `Controller` has one job: tell ASP.NET how to convert the incoming HTML request into a function call. As such it should almost always look like this: [HttpXXX("route")] public async Task&lt;Result&gt; MethodName(parameters...) { return await _service.MethodAsync(parameters); } Unless you are doing something tricky like accepting a file, that's literally all I want to see in a `Controller` method. It should be so small that there is no reason to test it independently from the UI. 
&gt; public async Task&lt;IActionResult&gt; GetApplicationRole() I'm going to take a lot of flak for this, but I hate `IActionResult`. It throws away all type information so things like Swagger don't work. (Unless you add the type information back in later using extra attributes. But those are impossible to check at compile time.) If you can use `IActionResult&lt;T&gt;` I guess it's ok. Otherwise just use the real type. **** What about HTTP status codes like BadRequest and NotFound? That's what exceptions are for. Throw an exception, probably from the `Service` class, and use an exception filter to convert it into the appropriate HTTP error code. There's no reason why you should be directly dealing with HTTP error codes. That's a infrastructure concern that shouldn't be leaking into the application code. *** Again, this is an area where intelligent people are going to disagree with me.
&gt; return View(okObject.Value as IEnumerable&lt;ApplicationRole&gt;); No. Do not ever use an `as` cast without immediately following it with a null check. I know `return View( (IEnumerable&lt;ApplicationRole&gt;)okObject.Value);` isn't as pretty, but it is the correct thing to write. What you wrote says "If okObject.Value is an IEnumerable&lt;ApplicationRole&gt; then use it, otherwise pretend it is null so that I get an unexpected NullReferenceException later that no one can explain." Don't do that to your fellow programmers; it isn't nice. 
Why? It's not like the compiled IL code has interfaces anymore. The compiler has to change, but probably not the runtime. Also note I said major runtime changes. Compared to something like mixins or traits or shapes or full support for multiple inheritance this is a simple change. It feels dirty and like a hack, and it is, but better solutions are much more complicated.
See [my other comment](https://www.reddit.com/r/csharp/comments/84wrvl/whats_your_opinion_on_default_interface_methods/dvt3jle/) in this thread.
&gt; It's not like the compiled IL code has interfaces anymore. Yea it does. When you call a method through a variable declared as an interface type, it uses that interface's vtable rather than the class's normal vtable. And if you add a new default method to an interface, without recompiling the class that implements the interface, it has to work. Which means the runtime needs to look up the default implementation, as the compiler isn't in the picture. Likewise this has to work with all .NET languages, not just C#, at runtime.
My head is spinning. Do the installer solutions do all the package management if you update one solution that is referenced a lot?
Yes, it uses the interface version, but that's not the same as actually being an interface. IL code is a lot lower level.
I‚Äôm guessing he might mean that if you have 3 interfaces that all have the same method signature (perhaps they all ultimately derive from a single base) and it‚Äôs implemented by default there might not be a method signature collision when an object implements all of them (without explicitly implementing the defaulted methods). As such depending on whether the object is cast as type a, b or c it will behave differently. 
I prefer pascal case with prefix system for variables. mField cConst lLocalVar aMethodParameter 
&gt; A non-disposable class should never, ever have fields that are disposable. That causes all kinds of life-time issues. Unless of course you have an IoC container that handles it for you. Even without it, as long as you have some other component that handles the lifetime for you, it‚Äôs not at all horrible for a non-disposable class to have a reference to a disposable one. &gt; Furthermore, you are potentially hogging a database connection for the lifetime of the request. (I say potentially because EF is weird about this.) Database connections should be released as soon as they are no longer needed. Unless your system is under _really_ high load, this is not really an issue. Requests generally don‚Äôt take that long. &gt; What you should do is inject a connection string which will allow you to create the `DBContext` when needed and dispose it as soon as you are done with it. Holy shit, no. Now you‚Äôve coupled the controller to the database _and_ to the specific implementation of the data layer. Good luck testing that controller. You _should_ be injecting an abstraction of your data operations into the controller, whose implementation can do whatever you like. 
Yeesh... 
Forgot about iVar: foreach(var iSomething in IEnumerable). Now you can throw up. Anyway I found it very useful. You can see on first sigth what is purpose of variable and since our senior accept it as standard, I have to use it.
Everything is bad if [poor use]. So there's that :-).
Major differences are that exceptions transport arbitrary error information from the throw site to the catch site and that they are not function-local. So basically very different in my opinion.
Last I know, interface can't contain fields. If so, the default implementation is equivalent to a static function call. So the ~~gain~~trade-off is: in lieu of making that static function and calling it from a desired implementation, I get it in every implementation by doing nothing. The rest is hand-waving.
If it works for you then go for it! It looks like a form of Hungarian Notation which for most is not used today. However based on the Stack Overflow answer here, you may be using Hungarian Notation the right way: https://stackoverflow.com/questions/111933/why-shouldnt-i-use-hungarian-notation
bad bot
ReSharper for visual studio does a good job of letting you know the proper conventions, among other things
Extension method is not virtual, whereas the whole purpose is to get polymorphism.
That‚Äôs just one convention. Doesn‚Äôt matter, since private fields are not part of the API. 
Well, it works fine in other languages such as Swift. 
&gt; Only thing I'd say is that default interface implementations should always be virtual, for the aforementioned reasons. I know there are (slight) performance considerations for choosing between sealed and virtual methods, but the implementer of an interface should still maintain full control over how the methods are defined, so we don't sacrifice any ability to change behavior. From what I understand, if an implementing class decides not to implement an interface method that has a default implementation, then the default implementation only shows up when you do a virtual dispatch via the interface itself. e.g.: interface IHaveDefault { void Dewit() =&gt; WriteLine("Default"); } class EmptyBoi : IHaveDefault { } class ConcreteBoi : IHaveDefault { public void Dewit() =&gt; WriteLine("Concrete"); } class ExplicitBoi : IHaveDefault { void IHaveDefault.Dewit() =&gt; WriteLine("Explicit"); } class SwitchyBoi : IHaveDefault { public void Dewit() =&gt; WriteLine("Switchy A"); void IHaveDefault.Dewit() =&gt; WriteLine("Switchy B"); } class Program { static void Main() { var a = new EmptyBoi(); //// a.Dewit(); // won't compile ((IHaveDefault)a).Dewit(); // Default var b = new ConcreteBoi(); b.Dewit(); // Concrete ((IHaveDefault)b).Dewit() // Concrete var c = new ExplicitBoi(); //// c.Dewit(); // won't compile ((IHaveDefault)c).Dewit(); // Explicit var d = new SwitchyBoi(); d.Dewit(); // Switchy A ((IHaveDefault)d).Dewit(); // Switchy B } } In the above example, the only "new" thing is that you can write things that, to consumers, look exactly like `ExplicitBoi` without actually having to write the guts of `IHaveDefault.Dewit` everywhere. So unless I'm mistaken, it's going to have all the performance characteristics of "virtual" methods, because it's impossible to invoke these non-virtually (maybe the JIT could eagerly try to special-case devirtualize if default implementations turn out to be the 99% case, but I doubt it), and you're also able to provide your own implementation just like other "virtual" methods. Edit: it looks like they've expanded the proposal more since last I looked (or I never looked that deep into it) to allow interfaces to have more stuff in them like `private` / `protected` things and even override things in the base... if that's the case, then cool, but what I described above seems to cover the core of the feature as I recall Mads describing it.
Maybe like they always do, by using lots of attributes and having the compiler synthesize the implementation as if you had written it. I haven‚Äôt studied this particular proposal in detail, though. 
IL code isn‚Äôt actually all that low level when it comes to the object model. IL knows about virtual calls.
It‚Äôs very useful to be able to make larger interfaces which are still easy to implement because most of the methods have defaults. It‚Äôs used a lot like that in Swift. 
I haven't used any of both, which would you recommend to use if I have to decide?
Well, you have here multiple options: * Setting IsEnabled to false * Setting Visibility to Hidden * Setting Visibility to Collapsed Ok, so the answer here isn't straightforward as it really depends on what you want to do and it depends on personal preference obviously. That being said though, I would usually use the IsEnabled property in more work-oriented programs in situations where the user can get access to the control if he does X. For example I have a button "Remove entry" which is disabled when I don't have any item selected in ListBox Y, but is enabled when I select one. But if you don't want the user something at all then use Visibility.Collapsed or Visibility.Hidden (NOTE: This will only hide these controls for the user, but you should also secure your logic regardless) And finally let me explain how you COULD solve this programatically. Let's say you have an enum like this: enum UserType { User, Staff, Admin } ...and in some ViewModel you have a property public UserType UserType {...} Then you want to bind the property to your control and attach a **IValueConverter** to it, which will either convert the UserType to a bool (for IsEnabled) or to Visibility. This would look this: &lt;Button IsEnabled={Binding Path=UserType, Converter={StaticRessource UserTypeToBoolConverter}, ConverterParameter=SomeParameter/&gt; OR &lt;Button Visibility={Binding Path=UserType, Converter={StaticRessource UserTypeToVisibilityConverter}, ConverterParameter=SomeParameter/&gt; Check this out on how to implement converters: https://wpftutorial.net/ValueConverters.html EDIT: typos
You should definitely write that library! I‚Äôd be keen to see what decisions you end up making differently to me.
Did I say multiple inheritance was one of the better ways?
Without member fields, what implementation is possible? Empty, which is easy anyhow and some work on inputs and global state only, which is a static function. You call this "very useful", fine. I would call it "mildly, if at all".
Would be easier to write _value tho. But rules are rules.
ü§¢
There's a big use case for this that I don't think I've seen many people on Reddit bring up, and that's the effect that this has on the story of updating interfaces across versions. Consider that you've delivered a library that contains an interface that looks like this: public interface IDatabaseStuffDoer { int GetRowCount(string tableName); // other stuff... } And in the next version of your library, you want to add TAP support to make it look like this: public interface IDatabaseStuffDoer { int GetRowCount(string tableName); Task&lt;int&gt; GetRowCountAsync(string tableName, CancellationToken cancellationToken = default); // other stuff... } The status quo is that if you want to do this, then anybody downstream who already implements that interface will fail to compile, even if we think that it would be better to just have a default that `Task.Run`s the synchronous version than to break downstream code. This, I presume, is why Microsoft themselves strongly favors "interfaces" that actually get delivered as abstract classes: they can always add new virtual methods whose base behavior just depends on already-existing abstract members (a really great example of this being that if you had a `System.IO.Stream` subclass circa .NET 3.5 that used the Begin/End methods for the APM async pattern, you will automatically get a "true async" implementation of the TAP pattern that uses those, even if I imagine most new subclasses will prefer to just go straight to overriding the TAP methods). But once default interface implementations come into the picture, you can get the same benefits of being able to upgrade your interface to add composite methods without breaking downstream: public interface IDatabaseStuffDoer { int GetRowCount(string tableName); Task&lt;int&gt; GetRowCountAsync(string tableName, CancellationToken cancellationToken = default) { if (cancellationToken.IsCancellationRequested) { return Task.FromCanceled&lt;int&gt;(cancellationToken); } // still pass the token just in case it gets canceled before our task is scheduled. return Task.Run(() =&gt; this.GetRowCount(tableName), cancellationToken); } // other stuff... } This lets anybody with an `IDatabaseStuffDoer` still use an async method on something they got from a pre-existing implementation from downstream with the new async method (legacy implementation *might* have to be recompiled, though, I'm not 100% sure on that one). It's almost certainly not the optimal way to make an async database request, but it's still a major improvement: if the base is "good enough", then the implementer never has to specialize; otherwise, they can do so at their own pace within their own normal development cycle.
Sorta. The real added value here is that the implementation of the interface can choose to replace the default with something more targeted. To go back to the example I've used in the past when I've discussed the problem that this now looks to solve, I like to think of `Task.Run` as something you'd do in a default interface implementation of an async method, with the implementation being free to override that with a more specialized version that uses async support that's built into the API of the underlying provider. (edit: a word, "To to back to" --&gt; "To go back to")
Sorta. The real added value here is that the implementation of the interface can choose to replace the default with something more targeted. To go back to the example I've used in the past when I've discussed the problem that this now looks to solve, I like to think of `Task.Run` as something you'd do in a default interface implementation of an async method, with the implementation being free to override that with a more specialized version that uses async support that's built into the API of the underlying provider. (edit: a word, "To to back to" --&gt; "To go back to")
If php does something, that's usually a good excuse to think twice about implementing it.
&gt; Without member fields, what implementation is possible? interface IStreamlike { int Read(byte[] buffer, int index, int count); byte[] Read(int count) { byte[] result = new byte[count]; int prevRead = -1; while (count != 0 &amp;&amp; prevRead != 0) { prevRead = this.Read(result, readSoFar, count); readSoFar += prevRead; count -= prevRead; } if (count != 0) { throw new EndOfStreamException(); } return result; } byte ReadByte() =&gt; this.Read(1)[0]; sbyte ReadSByte() =&gt; (sbyte)this.ReadByte(); int ReadInt32() =&gt; BitConverter.ToInt32(this.Read(4), 0); uint ReadUInt32() =&gt; (uint)this.ReadInt32(); long ReadInt64() =&gt; BitConverter.ToInt64(this.Read(8), 0); ulong ReadUInt64() =&gt; (ulong)this.ReadInt64(); float ReadSingle() =&gt; BitConverter.ToSingle(this.Read(4), 0); double ReadDouble() =&gt; BitConverter.ToDouble(this.Read(8), 0); } Implementation is only **required** to implement `int Read(byte[] buffer, int index, int count)` but is **permitted** to implement / override (whatever you want to call it) the other methods if it has a way to do them without allocating, or if it has a way to do a buffer pool that consumers know how to deal with, or if it can't stand `BitConverter`'s hatred of unaligned reads, or whatever.
The purpose is to get a default implementation for interface methods. So far this has been achieved by using extension methods (cf. the entire Linq implementation), but default interface methods would be a lot cleaner.
Which is all this is.
From the proposal: &gt; The syntax for an interface is relaxed to permit modifiers on its members. The following are permitted: private, protected, internal, public, virtual, abstract, override, sealed, static, extern. &gt; &gt; &gt; TODO: check what other modifiers exist. &gt; &gt; An interface member whose declaration includes a body is a virtual member unless the sealed or private modifier is used. The virtual modifier may be used on a function member that would otherwise be implicitly virtual. Similarly, although abstract is the default on interface members without bodies, that modifier may be given explicitly. A non-virtual member may be declared using the sealed keyword. Unless I'm mistaken, the proposal very explicitly involves adding protected, virtual members.
*What exactly* are you passing as a parameter? An `XmlDocument` instance, or a string or something? The encoding isn't handled by the `XmlDocument`, but by an `XmlWriter`. The document's text nodes just store the raw strings, nothing you do to it will affect how entities are encoded. Writing text nodes is handled by [`XmlTextWriter.WriteString`](https://referencesource.microsoft.com/#System.Xml/System/Xml/Core/XmlTextWriter.cs,5a67fa73534f66c3), which then calls [`XmlTextEncoder.Write`](https://referencesource.microsoft.com/#System.Xml/System/Xml/Core/XmlTextEncoder.cs,8d5d0988ec1ef9ec) which does hard-coded entity encoding. You can override `XmlTextWriter.WriteString`, but the entire `XmlTextEncoder` implementation is internal so you'd have to fully duplicate it if you wanted custom XML encoding. If you're passing an `XmlDocument` to the third party library and have no control over how its encoded, I don't think there is anything you can do (without modifying or replacing the library). Also, the `&amp;amp;` entity is a required part of the XML standard, if they don't support it then their implementation is non-compliant. I realize that doesn't help you when you have no control over what they do, but unfortunately it means that finding solution or work-around may be difficult because it's just not a problem that should exist. CDATA might be an option, but if they're using some kind of half-assed XML parser that doesn't even support basic predefined entities I'd frankly be surprised if they supported that.
I personally don't think it is a good idea. The only difference compared to an extension method is the ability to change the implementation if you want to, but you can open up a big can of worms. What happens when a class implements 2 interfaces with the same method and both have different default implementations? What if the default code ends up calling something required to do and then someone overrides it and doesnt call it? There are so many bad scenarios that could happen and you wouldn't even know unless you had very good tests in place.
Try writing out some sentences in noun-verb-noun format that describe the process and see where you get. Customer calls Staff Staff takes Order Staff collects Ingredients 
Ah! You mean finding my entities by writing out my different use cases? good tip!
You can also do some research by ordering a pizza for pickup instead of delivery and watch them work while you wait. 
I‚Äôd expect they‚Äôd keep it consistent with the way they handle it when you hide an inherited member instead of overriding it, which is to say when it‚Äôs cast to the implementing object it uses its implementation, which would mean it would use the one on the interface.
I just wish I had an XP bar that made it easier to show progress. "I'll join the meeting in a minute, guys... I gotta grind on making some KillBoarViewModels to get to the next level."
&gt;At this point I'm defining the main entities and I'm at the first stage Don't mean to be gate keeping, but that's not really what DDD is about. You don't start a DDD project by creating the entities. You start by defining the ubiquitous language that will drive the system and use what you gather from defining that language to determine the bounded context that language is relevant for. A change in the language typically denotes a change in the bounded context. From there you can begin mapping out domains and sub-domains based on requirements and functionality within the system. As domains need functionality from other domains you can map the connections and begin defining interfaces for that communication. One thing that is important in DDD is to not allow the concerns of one domain "leak" into another just because those concerns center around the same topic. To take an example from your post, what does an order mean in different to different parts of the pizza delivery business? Does the cook care about the address the pizza is going to? Probably not. Does the guy delivering the pizza care that the customer requested light sauce on the pizza? Probably not. Does the person taking the order need to know how to get to the address? Probably not. My point is that an in DDD, the concept of an order might actually be split up and look different between which domain it operates in. You also might find that what you thought was an order the cooks actually call a ticket because an order to them is something that they place with a supplier to get more flour, cheese, and other ingredients. While DDD has some architectural considerations that are associated with it, it's ultimately about understanding the business, and having the software follow that business much more closely than if a developer just sat back and came up with an entity model. So my advice to you if you want to use DDD for a project like this is to think like the business owner and think from the role of a subject matter expert rather than a programmer. Think about what drives different parts of the domain. Yes, at a high level it's delivering pizza, but once you get closer to the actual operations that the software has to support, you'll find that there's different things that drive different parts of the business, and capturing those elegantly with the software's design is what DDD is about.
Thank you , great advice, it makes sense defining my bound contexts first. I would say my bound contexts are ordering, delivering, cooking, billing. Yes it makes more sense now. I will define entities further, no need now.
&gt; Needs a bit of compiler magic though (to fill in the missing pieces at class compilation time). I think it was decided that this one would need runtime support.
I think there are proposals in the pipe for both of those.
Why a pizza delivery system? It should be a burger delivery system because of your name haha. I‚Äôm working with DDD as well. Keep us posted about any relevant questions or progress in your project.
Haha, good point, I'll make it a burger delivery system then :) I might write the project in english and share it on github, I'll let you know if I do..
Yes, I'm doing the project in another language than English and payments is the word I'm using (after being translated), thank you so much, I'm trying not to think as a developer at this stage.
In web application we don't even add the buttons to the UI if they don't have permission based off their role. So if you have a roles based system dynamically add the UI elements at runtime to reduce your attack surface.
Just a quick note, I would also recommend not just hiding the controls in the UI, but also checking for role permissions in your business logic as well (aka in the button event handlers, don't execute any logic until you verify that the user has permission to do so). This is because an attacker can modify your program and add buttons to trigger events if they wish.
If you get ReSharper, it will suggest all the best practices stuff. Learned a shitton of stuff just by keeping an eye out for anything ReSharper flagged. Students can get it for free, but you need an eMail address from your school to complete registration.
&gt; ordering, delivering, cooking, billing as with most applications, its the detail side things that catch you * stocking * cleaning * equipment and building maintenance * back office (payables/receivables) Of course for the purposes of most systems you draw a line somewhere and stop. Just be sure to spend some time thinking about what you might need in the dark, quiet corners of the system.
The idea is that initially the MVC views will handle the presentation, to get things working. There is a subset of the required functionality that must be accessed by other services, but the management part, could just be handled in the app itself. So I could split it up and do everything through API from the start, but the configuration/management doesn't yet have a consumer. So I was thinking I'd just put it in as MVC contorllers/views.
Thanks, I'll look into this.
You beat me to this one. Thanks for the good response. The code I pasted was just the boiler plate code. But in general it is how I model my code. I've done some reading on dotnet core IOC, but wouldn't call myself an expert. And I know that not all template code is best practice, but MS seems to be getting a lot better at it.
Take a look here: https://github.com/topics/csharp
I agree with you quite a bit. Most of what I read says that throwing the exceptions for flow is bad. But personally, I don't see much difference in throw new BadRequest vs return BadRequest(xxx) in the middle of a function. With return types and exceptions, I feel like the type safety is a big plus, and as I mentioned. I think throwing an execption mid call to be much more clear than returning some different type mid call. I've heard the argument, that this isn't exceptional behavior and therefore shouldn't be used, but I don't agree. Having something that usually returns IEnumerable&lt;Foo&gt; but may return BadRequest to be way more confusing. https://imgflip.com/i/26l26j edit: IActionResult&lt;T&gt; doesn't work, because by it's nature, IActionResult must be able to return multiple wrapped types. Maybe the next addition to C# will be union types, and we'll be able to say IActionResult&lt;IEnumerable&lt;Foo&gt;|BadRequest|BadResponse&gt; and the world will make sense again.
Actually return View( (IEnumerable&lt;ApplicationRole&gt;)okObject.Value); will throw InvalidCastException: if the type is not correct. I prefer to use as/is and deal with the null rather than a try/catch for invalid casts.
&gt; Unless of course you have an IoC container that handles it for you Don't use your IoC container as an excuse to write bad code. It's not like you are gaining anything by violating the .NET Framework Design Guidelines on this point. All you are making it harder to reason about and reuse the code in other situations. &gt; Holy shit, no. Now you‚Äôve coupled the controller to the database and to the specific implementation of the data layer. Good luck testing that controller. If you want mock testing, mock the `Service` class and ignore the connection string parameter. 
If you want to see good code from Microsoft, ignore MSDN and instead read the **.NET Framework Design Guidelines, 2nd edition**. 
&gt; Most of what I read says that throwing the exceptions for flow is bad. It is bad for "normal" control flow, but it is also badly explained. (And for good reason, as it's really hard to explain.) The best explanation I've seen is that you should expect to see 10 `using` or `try-finally` blocks for every one `try-catch` block. Throwing exceptions is ok, catching them is where you run into trouble. This advice came from the lead designer of C# itself in an interview.
Yep, that sounds like a perfect fit for reusable `Service` classes that are shared across controllers. 
&gt; Yes and stylecop won't let you have it, I believe StyleCop can be configured. But to be honestly, I've always hated that tool. Everything it does is also done by FXCop or the auto-formatter. 
https://docs.microsoft.com/en-us/dotnet/api/system.net.dns.gethostaddresses?view=netframework-4.7.1
That pattern exists to deal with subclasses of disposable classes, not just unmanaged resources.
I haven't really looked into DDD yet (if you have good sources to learn about it feel free to share :)) but would that mean, technical, that you have multiple Order classes based on context? If so, do they have their own DAL or do they get mapped differently? Thats the stuff that always confused me, because I haven't found a "from 0 to done" example yet
Have you actually looked at IL code? It's all about working with interfaces. When you disassemble it you'll actually see things like `callvirt instance System.IDisposable::Dispose()`.
If you add a new default method to an interface, without recompiling the class that implements the interface, it has to work. Which means the runtime needs to look up the default implementation, as the compiler isn't in the picture. 
Should they need know that they can't do something? For some applications, I leave the button there, disabled, with a note indicating which permission they need to activate it. That gives them a clue on who to ask. But I do admit that it is rare. Usually I just hide or collapse the button (as appropriate for the UI layout).
For things like cache pollution, it really doesn‚Äôt matter who disposes of the context and how long it is held open. The cache lives longer than any single context. That‚Äôs the whole point. 
&gt;would that mean, technical, that you have multiple Order classes based on context? Yes. Generally you have a "source" domain where the order originates and the order in other domains generally build their order off of the original order one form the "source" domain. &gt;If so, do they have their own DAL or do they get mapped differently? Similar to microservices, its recommended that each domain has it's own persistence mechanism. If you've got really big contexts, especially if they have multiple Order types, then you're probably doing it wrong. The ultimate idea is that an Order in each domain is allowed to evolve independently from any other domain. &gt;I haven't found a "from 0 to done" example yet From my experience that's kinda hard, just because there's a lot that exists outside the code with DDD. You need to have the documentation and knowledge from the subject matter expert to really understand why certain things are structured the way they are and why certain terms might be used over others. As far as resources go, the obvious answer is to go directly to [Eric Evan's book](https://www.amazon.com/dp/B00794TAUG), but I also feel that's a lot to chew and digest if you're just getting into the topic. My recommendation is to actually start with Vaughn Vernon's [Domain Driven Design Distilled](https://www.amazon.com/dp/0134434420), as it gives a higher level overview and description of the concepts of DDD rather than diving into the deep end like Eric's book. From there, I'd either go to Eric's book or to Vaughn's other book, [Implementing DDD](https://www.amazon.com/dp/0321834577). Once you get a lot of the concepts, I've found that [Patterns, Principles, and Practices of DDD](https://www.amazon.com/dp/1118714709/) is a good book to get a handle on the code, architecture, and infrastructure implications of DDD.
The DBContext has its own internal cache. You should know this by now, as it's vital for understanding how it works. Especially when mixing in stored proc calls.
&gt; All you are making it harder to reason about and reuse the code in other situations. It is stupidly easy to reason about. The controller or service or whatever takes something that is disposable as its constructor arguments, and then doesn‚Äôt dispose it. Disposal is handled by the IoC container. This is so common that even Microsoft‚Äôs implementations do it. &gt; If you want mock testing, mock the `Service` class and ignore the connection string parameter. What if you want to test the implementation of `Service`? Also, having a dependency on the context class instead of a connection strong means you can subclass it and override its behavior - without having to change the service class. 
Thanks! I'll do it then.
Thanks for the comprehensive answer :)
Lets say you have classes A and B, with a FK relationship between them. If you load B for any reason, then later load A, then A.B will be populated. When means you will be returning B along with A to the client even if you don't mean to. And this can cascade, dragging along very large object graphs when you only expected to return a single object. This is easy to account for when you can see the whole lifetime of the DBContext. But if you are doing a bunch of operations in other methods before your final read &amp; return, its often really hard to know exactly what it being dragged along. This can be mitigated by carefully mapping all of the entities into separate DTOs before returning them. But that defeats the purpose of using an ORM, since the whole point was to avoid having to write mapping code. P.S. Yes, it is a cache with all of the problems that entails. You really do need to pay attention to it or you'll get surprising results.
&gt; What if you want to test the implementation of Service? Then test it. If the purpose of the service class is to talk to dependencies, then you damn well better test it against those dependencies. 
Solutions shared by other members are great, assuming you know the hostname of the server you're looking for. If not, show the criteria on which you'd be searching for a server with (i.e. an open port, etc.).
Thankyou 
Thankyou 
Yeah I am not a fan either. Using statements *within* the namespace declaration? wtf.
lol kebab case -- I've never heard of that before haha.
Personally, I would recommend disabling rather than hiding controls. Previous job experience has taught me that a missing button is more likely to generate a support call about them not being able to find it, use it, etc. Whereas a disabled button at least makes them think a bit about why it's not enabled. Even if they still did call in with a disabled button it's easier to handle it (one less thing to troubleshoot). With a hidden button you would have to check both if the user has access or they simply cannot navigate your UI.
You can back properties with other properties although I have not thought if I want to do that.
thanks for the headsup, a lot of rubbish on udemy went for this https://www.udemy.com/csharp-tutorial-for-beginners/ good reviews though ill probably learn a lot of this on pluralsight
I use pluralsight and it's excellent but I don't pay, my employer does so I probably wouldn't use it if it wasn't free. Good luck with your learning and if you have any questions about C# or .NET feel free to pm me.
it is open source: https://github.com/dotnet 
That's the .NET framework, not the language, C#. 
Why does it matter? Why does everything have to be open source?
The compiler is open source in there, the .NET runtime is open source in there, the core libs are open source in there, discussion about the design is open source in there (https://github.com/dotnet/csharplang) What thing needs to be open source for the language to also be open source? 
The language is an ECMA standard. You can choose from mono and .Net Core as fully open source runtimes. It is by any means open source. 
Another tip: If you get a Microsoft Account and sign up to Microsoft Essentials you can get 3 months of Pluralsight for free (or at list this was the case ~6 months ago)
Why doesn't it matter? Anyway, sometimes I like looking at what's actually happening at a lower level.
Well that was dishonest.
Can you explain exactly what you mean? 
Can't you just resolve the server ip from its name?
Bad bot
The latest and greatest runtime stuff is all in .net core so you can look at that there. The compiler is open source so you can look at that too. The core libs are open source. What did you need to see? 
Might be a really naive but pragmatic solution for a home project. If you have some webhost, let the service post it‚Äôs ip to some endpoint there and retrieve it with your client. I used that as a fast solution for a home project.
Which is very different from the ability of the abstract class to define its own state.
If all you're trying to parse is POPUP and MENUITEM then this can be done pretty simply. Push the text from POPUP into a list. When you encounter the } then pop a value off the list. When you encounter MENUITEM you join all of the items in the list with | as the delimiter and add the value from MENUITEM to the end. Level of indentation would be equivalent to the position in the list. It's not going to be the most fancy solution but it's simple. Unless there is more complex syntax you need to parse then something like that should probably work. 
The C# language, compiler, development experience, framework and runtime are all open source. - Compiler + VS IDE: https://github.com/dotnet/roslyn - Language: https://github.com/dotnet/csharplang - Framework: https://github.com/dotnet/corefx - Runtime: https://github.com/dotnet/coreclr Source: I'm the C# compiler lead. 
THIS has been so helpful, yet I can't seem to keep my original code from sh****ng the bed. These migrations all want to add about fifteen lines of stuff I don't think I need... Any thoughts?
No apologies necessary. This back and forth is one of the most integral parts of keeping me on task. I've managed to get the user signup and login to work by itself in a new application. I wasn't able to add it to my existing project, but someone else in my group has managed to add an older project into a new user login/signup, so that's what I've been working with. It's coming apart at the seams, but it's getting better, one step at a time. If I'm not mistaken, that's just how this kind of thing works. This will work. I will make it work.
Clean Architecture Clean Code Robert c. Martin Amazon
There is a metric fuck-tonne of projects on Code Project: https://www.codeproject.com/KB/cs/ You have to register an account before downloading, but it's free. There's a lot of bad code out there (even for projects with high ratings), however, you can still learn from them. 
It's been a while since I've set up a new codebase with identity. What is being added? If it's the DbSet classes, leave them in place until you're sure whether you need them. 
OK, I see where you were going.
If I'm reading this right, am I to presume it also allows inheritance of static methods? Yes please. The feature in general stands to simplify designs and cut out middlemen, making it easier the implement if done well, while still keeping things flexible.
Why don't you just set a static IP for your server?
Standard is just that... a standard. It‚Äôs just a definition that Core implements. Basically not much more than a list of APIs.
What if you're developing software that will be installed on multiple machines? Static IPs will not work for that.
You lack imagination. It's not hard to toss in a `ConditionalWeakTable` so that the default interface can have its own state. Hell, even extension methods can do that today with very little effort.
It's that simple, with an unknown number of levels. 
Determination! :)
I added ": IdentityUser" to every single class, because I got overzealous and didn't read the damn documentation, BEFORE just typing away. AND I didn't realize that "// Add profile data for application users by adding properties to the ApplicationUser class" was telling me what they already did for me and not 'add more info here' At least it's mostly working, now... AND without all the extra info in my generated tables.
I often just call ipecho.net/plain. Returns plaintext IP address from HTTP GET
Winforms, Angular, and webapi projects. https://github.com/bluesektor/TreeMon
If you can use DNS for this, please do. But if you need to discover the server regardless of the name or IP, probably best to use upnp/sdp. There are projects out there to simplify this for C# on GitHub though I haven't gotten around to using any.
Because a proprietary language cannot be supported once its owner abandons it. Because refactoring is a hideously expensive endeavor. A company that may plan to use its contracted application for another twenty years is not beholden to either the original developer, or to a software company that may abandon support of its language product after a few years. 
[removed]
&gt;Source: I'm the C# compiler lead. I'm curious - how did you learn to do anything involved with this? Where did you start? It's all just so incredible to me. 
Thank you i'm looking into it and I was using HSB. :) 
You can decompile exe and dll files using NET Reflector. It has a 15-day trial version, so before installing it I would go through the Nuget gallery and pick the projects I want to check out. NET Reflector shows the decompiled code in its own code explorer, you need to add the FileGenerator plugin to write the source to file.
But that doesn't use ssr. I am trying to do this on the server, so when the page loads, it loads with data
I've been building a simple n-tier CRUD program as a project to learn c# and SQL. It was recommended to me as a good starter project that you could keep scaling up as you learn new things. I'm having fun reading up on it and trying to understand all the parts involved. 
Is there a pattern or file flattening method you know of, or just read a line and check the row?
What do you alread know? Data types, arrays, if statments, cycles. How much do you know about object programming? 
Not a ton. I did a 101 with Python on codecademy about two years ago... so I remember, in principle or theory, the basics of declaring a variable, if else statements, what a function is, a for loop, a while loop and a class. Oh, and a dict and a tuple (one you can edit, one you can't I suppose) But I didn't do anything with it, and all I did with it was write simple scripts that the crappy program walked me through. I'm enjoying playing in visual studio more because it's more...well, visual. I can learn syntax and logic while also building a gui-centric piece of something. Easier to kind of peg what's happening. 
I don't have career aspiritions with this right now - it's mostly a hobby to see how into it I get. If I were to persue this as a career, the most immediate option is to migrate from my current role and into one of the dev teams in my company. In terms if "if I could wave a wand and poof, I'm a dev somewhere, what would I want to do with it?" I have no idea. There's too much out there that I simply don't know exists because I'm NOT a developer. I've heard of things like SDET, devops, front-end, back-end, desktop applications, web-apps, games, whatever. All sorts of stuff. I'm not looking at the finish line, I'm just trying to make sure I keep running the race once I start it. 
This "system" will be used on a closed network, no DNS, no Gateway. I will need to boot from PXE and run my app over WinPE. Due that I need to create the WinPE image each time that any update is added and I have different locations where I will run this, the IP of the servers will be different and also the App conf. Knowing the IP of the server I can put all the config in the server and my app can download it without problem. I don't want to have many config files to maintain, I just want to create the App, encapsulate it on a WinPE image and let the App to find the server and download the proper config dynamically.
Thats enough. Maybe try to look up inheritance and interfaces and play a little with them. Also crud operations are gonna be something youll eventualy need.
Then why use angular at all, wouldn‚Äôt a typical MVC page be easier to deal with? The fact that the ssr requires a nodejs instance to perform the rendering should speak volumes. If you used an MVC page then you wouldn‚Äôt have these concerns your dealing with, the data could easily be passed to the view. The other option would be to simply create an api end point for the specified data. 
Exactly, we handle it at the rendering stage. And we double check on the backend. Hiding the fields is simply a mind field, and assumes any abuser would be stupid not to look at the html before attempting to build a fake payload. 
If you're learning I'd suggest sticking with v2.
I would stick with 2.0 if you're trying to learn. 1.1 won't offer you any benefits, and downgrading will probably cause other dependency issues in your project.
So, what should I do to fix this issue and proceed further to the course?
So, what should I do to fix this issue and proceed further to the course?
How it compares to squirrel? 
I've had this problem when the nuget packages for asp.net core were newer than the dotnet runtime I had installed. I know this is pretty strange but try downgrading the minor version number on your main dependency to asp.net core.
Just follow the basic tutorials here: https://docs.microsoft.com/en-us/aspnet/core/tutorials/ If you don't quite get what to do just from the tutorials and would like to use a course I'm sure there is another one on Lynda that is 2.0 based. I would highly suggest not following a 1.0 based course, **especially** if it's using the project.json based project format.
Honestly, I would contact the course author and ask for assistance. They might have upgraded exercises or content.
It actually works completely differently from Squirrel, but the main points are: - Squirrel uses a launcher which decides which version to execute -- new updates are downloaded and installed side-by-side. Onova simply overwrites old files with the new files instead, no launcher is required. - Squirrel requires an additional deployment step to pack the binaries, create an installer, publish it all, etc. With Onova, if you're already distributing your project in a zip archive, for example, you don't need to do anything. - Squirrel also forces you to use its installer for the initial install. With Onova you can use any installer. - Squirrel has support for delta packages, Onova does not (yet?). - Onova is easier to extend with custom update providers and comes with a few more by default.
Particularly, as TheManFromOregon, I'm impressed that you used the correct spelling of 'tonne' given the fact that it's a **metric** fuck-tonne.
Those answers on Stackoverflow are useless. This is how I fixed it by specifying the **full path of dotnet.exe** in `Web.config` like this. &lt;aspNetCore processPath="C:\Program Files\dotnet\dotnet.exe" /&gt;
Particularly, as TheManFromOregon, I'm impressed that you used the correct spelling of 'tonne' given the fact that it's a **metric** fuck-tonne.
Thanks, will have a look through these
Auto- update can be the worst. Re:neo4j.
Do you have any logger enabled like nlog in your project? Set to go to the windows event log? Have you tried compiling it on a Linux machine before deploy?
Nice. Maybe include this in readme. I assume that more people know squirrel. I've recently used squirrel successfully in production and I see some missing parts in docs: - how exactly it works? Where it downloads update, zip extractor removes old content? - are there some logs if update failed - real world full sample for newbie for all integrated providers with all steps with explanation :-) (I know that there is not much rocket science but updater integration is one of the latest thing to do with limited time - so better examples will help you get users) - maybe some FAQ or best practices for creating update strategies - nice for newcomers The only problem I've encountered with squirrel is lack of force update when hash is different with the one on server (but version is the same) - I'd like to use this to update internal builds. Semantic versioning omits pre-release. To sum up squirrel looks more complete for my use cases (out of the box installer) but I keep my fingers crossed for this project :-) 
FYI if you deploy to Azure and get this, don't deploy web.config and see if the generated one makes your site work.
Good idea, I will add some more tutorials. :) Thanks for the great feedback.
How would it work sith an ASP.NET/MVC web application?
That's an interesting question. What would be the use case for something like this?
Hah! No worries. Any suggestions for getting the current, logged in user? &gt;ApplicationUser user = context.Users.Single(u =&gt; u.Id == id.ToString()); isn't working because there isn't anything IN ApplicationUser to reference. GetUserId and FindById don't seem to work either...
You seem to be offended?
The best? I think you can implement MVVM in your application. You need a class for permissions: public class Permissions { public bool CanDoSomething { get; } public bool CanDoSomethingElse { get;} // a property for each permission } In your ViewModel you can pass an object with the current user permissions, for example: public class SomeViewModel : INotifyPropertyChanged { private readonly Permissions permissions; // pass permissions in the constructor public SomeViewModel(Permissions permissions) { this.permissions = permissions; // create the command, and assign the permission for enabled this.ActionWithPermissionsCommand = new RelayCommand(SomeMethod, d=&gt; permissions.CanDoSomething); } // this property will be binded to the button that requires permission public ICommand ActionWithPermissionsCommand { get;} } And in the view just bind the ActionWithPermissionsCommand command to the button that requires to be disabled if user has not permission.
Not OP, but I found the MSDN series very helpful. 
&gt; DO NOT use underscores, hyphens, or any other nonalphanumeric characters https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/general-naming-conventions
ApplicationUser has no properties or fields?
+1 for the real world full sample, so many projects lack this and it's one of the primary considerations I make when choosing which tools to use on my own projects.
I would guess that the typeloader will be unable to resolve this correctly. Have you tried making the CrashingStruct a class? That might solve this, because of the way generics are handled.
https://github.com/dotnet/coreclr/issues/4049 https://stackoverflow.com/a/36337761/1156423 Appears to be a known deficiency in the (Core)CLR implementations.
Just admiring the dichotomy.
Go to school. Learn, practice, be tenacious, and work your ass off.
Beat me to it. Just switched from my mobile phone to my laptop to search for that stackoverflow answer by Eric Lippert you posted. I remembered reading this a good while back. I think there was a joke that went something like: "If Jon Skeet asks a question on SO, the compiler team appologizes." And in a number of cases Eric Lippert was the one to answer. Quite enjoyable and detailed posts! By the way: I tested my idea that this should work if you don't use structs - and it does. Might not be a solution depending on the problem - but a struct holding a static field of a wrapper of itself seems kind of strange... I know this is a formulaic stack overflow answer: but could you elaborate on what you were going for with this design? I'm really curious!
Have you tried running VSCode as Administrator? That is, if you are running on windows.
I'd guess a locally-run web app?
Saw that so many time, always wondering why devs would waste their time in such bullshit. It is not like finding another job is difficult for devs. (as long as you are willing to move)
Thank you! This is exactly it, and lots of discussion about it. Too bad that this bug has been open for almost two years.
Yes, it works if I use a class. I actually hit this bug when switching from class to struct. I could have mentioned this. :) I am just experimenting a bit with something and I hope to have it on github this week if it becomes remotely usable. I haven't created structs much before so I don't quite remember what is allowed or not. It's not a secret, and not something fantastic, just want to see how far I can get myself on this small thing before asking for feedback. One reason for trying out using a struct instead of a class is that you can design it so that default(T) is a valid value, allowing you to safely skip null checks when using values of the type. I will still need to decide if I think it is a good idea to do that.
As mentioned by /u/tweq it seems to be a bug in the CoreCLR implementation (though perhaps not all of them). Making it a class makes it not crash, as you suggest, but I wanted to see if I could do this with a struct, since it has some different properties.
Yup. I'd say the only reason to learn the non-core version is if you have to maintain an existing project that uses it.
I agree, Core is the way to go. It's much more flexible in that it can run on both Windows and Linux, and can even be containerized. I'd definitely recommend starting any new .NET projects in core if possible. 
If you want to get a job as a developer, MVC 5, not core, is what you'll want to learn first. It's likely that as a junior, you'll be maintaining other work and the vast majority of that will be legacy code. There's nothing wrong with learning both, but learning MVC 5, or ASP.NET MVC, will be more valuable in the immediate. 
Or you could also look at forward facing and modern jobs, not all junior jobs have to be maintaining legacy crap.
That would be ideal, but I think whether or not you're seeking 'forward facing and modern jobs' they'll have a large legacy codebase and will more than likely start a junior there. Like I said, nothing wrong with learning both, but a junior will most likely be working on the older stuff first. 
I would go with .NET Core since it is the future. Besides it is a derived from previous versions on .NET MVC and Web Api so if you learn one you will also be comfortable in another. You are making it sound like these are two drastically different choices but one is just a next iteration of the other. 
Bit of an assumption, 7 months out of uni and I work on the front end of a WPF mvvm application, never touched legacy code. Go with the new tech if you're doing it in your own time and learn the legacy when you need it.
Wpf is effectively legacy code. Also, we'll see what your next position is. I can say that after three years, I've worked on web forms, .net core and .net "legacy" and the vast amount of code bases have not been in core. Not to mention, core is in version 2. I don't think even c# had wide adoption at that point in its history. You can think about legacy code as nasty as much as you want, but the business wants results and rarely cares about developer experience. I like learning new stuff as much as the next person but we need to be pragmatic when starting out and be idealistic after work. This was the same argument made with swift vs obj-c. Sure,earn swift if you have the time but there will be a plethora of obj-c for the foreseeable future and you're only hurting yourself by ignoring it. 
in the first code snippet you have to do something like this int a = Int.Parse(Textbox1.Text); int b = Int.Parse(Textbox2.Text) int c = a+b; Reason as Textbox only stores values as string you have to first figure out what is the integer value of the text stored in the textbox 
Or if your aim is to get a job in the mid-to-near term future. Cores adoption is still very low, except for in brand new projects. standard isn't going anywhere for a long time. A lot of larger projects don't even have formalised road maps for moving to core yet, never mind working implementations. 
Seems basically everyone in this thread except you and I have overlooked this fact. OP is asking about getting a job. Not starting a new personal project. 
You can very easily use what you have learned with core to switch to the old stuff in MVC though. 
Tell junior developer to always stay relevant. Tell junior developer to learn the old stuff so they could do the boring maintenance work. One of these statements above is what I want in a junior developer when I interview them. Take a guess at which one it is.
I wouldn't call it a 'replacement' per se, but I would argue that UWP is taking over in the same way that core is taking over the .net of the last 10 years. These technologies will still exist for the foreseeable future as the business is unlikely to see the point in rewriting a working application because it makes developer experience any better.
Are you saying that MVC 5, which came out in like 2014-2015 isn't relevant anymore? If you want to stay relevant, screw the framework of the week and learn data structures, algorithms, and design patterns. I don't know where you work, but everywhere I've worked and my friends have worked have had an 'old' project that was very valuable and unlikely to go away in the next year because of some new hotness. I never said to only learn 'the old stuff.' What I said was to learn that stuff first so you can get a job and then focus on the new stuff in your free time.
What exactly is the difference?
I am not a beginner in programming. Basically, I am an EEE graduate. During my graduation, I was taught only C programming language. However, I learnt the basics of C#, C++, Java and Python through online courses, specifically Lynda. So, I am comfortable with dealing intermediate level of coding. I think that I should learn ASP.NET Core MVC first, as it is very likely going to be future. Then I will move on ASP.NET MVC 5. And yes, you are right. I should learn them both. A lot of freelance C# developer jobs on Upwork require ASP.NET MVC 5. But there are only a few jobs for ASP.NET Core MVC. However, I expect the number of jobs to be increased for the newer framework in the coming days. My plan is to do some freelancing jobs and use them as references to the overseas enterprise clients. My main target is to get a job as a .NET developer in USA or Canada or Singapore. 
I'm not sure about those "advantages". File overwriting doesn't seem logical, as it requires application to shut down. Squirel can update in the background and then just restart for new version. The separate package build allows for package consistency checks. And Squirel using custom installer is not a problem, as majority of the installation is specific for Squirel-enabled application.
Nobody hiring for a job is going to say "oh sorry we are looking for someone who knows a difference version of ASP.NET MVC than you" 
Consider using the NumericUpDown control for this type of entry. Sterilizing user input can be a chore for a new developer. 
It really depends on your area. The best thing you can do is to go on a couple of job sites like dice, indeed, etc. and look around at the positions that are open. Look for trends of what technologies are most used in your area. I'm in the midwest and we have a ton of C# positions, but your area might have more PHP or Java. It's very location-dependent. Also, whichever one you decide to learn, focus on learning the fundamental concepts of what is happening. Too many people focus strictly on learning the syntax and have trouble translating that knowledge into a new language. If you really understand what's happening in the code, moving to a different framework becomes easier.
They aren't all that different, but the future will skew towards dotnet core. If you are looking soon I'd say learn MVC. I'm actually branching out an away from dotnet right now as a senior developer to see what the development experience is like in other languages and there's quite a few really good ones. Don't tie your boat to one dock once you get some experience.
If you go in and you're experience is solely in something they aren't using and someone else has experience in what they are using, that's a card stacked against you. Of course hiring isn't as simple as that and things like personality, willingness to learn, as well as other experience with things like version control are just as important. Either way, knowing how to use what was popular a few years ago is likely going to be more important that knowing what came out last year. Even more important is knowing concepts over syntax, but this whole thread is apparently framework obsessed.
I never really said those were the advantages in general, but they can be for some use cases. For example, updating portable applications.
OK. By the way, which is better for getting jobs now and in the future, .NET Core, Spring and other Java frameworks, or Django?
It seems like it allows the definition of static methods on interface types. I doubt that this allows you to define abstract or virtual static methods as part of the interface contract, if that's what you're thinking.
Decide what area you want to live in, find a company you want to work for. Learn what they use.
Based on [the proposal](https://github.com/dotnet/csharplang/blob/master/proposals/default-interface-methods.md), they're expecting to need runtime changes (unless I'm misunderstanding something): &gt; (Based on the likely implementation technique) this feature requires corresponding support in the CLI/CLR. Programs that take advantage of this feature cannot run on earlier versions of the platform.
From [the proposal](https://github.com/dotnet/csharplang/blob/master/proposals/default-interface-methods.md): &gt; This proposal requires a coordinated update to the CLR specification (to support concrete methods in interfaces and method resolution). It is therefore fairly "expensive" and it may be worth doing in combination with other features that we also anticipate would require CLR changes.
I would personally say that Java is on the decline, dotnet core is going to grow in popularity no matter what. I'm unfamiliar with Django but I do not see it regularly mentioned as much as it used to.
You can run plain .NET just fine on other platforms. And not everyone has the .NET Core runtime installed.
Not sure where the epiphany came from but I used LINQ... for (int i = 0; i &lt;= 8; i++) { Console.WriteLine("&lt;div class=\"row\""); Console.WriteLine($"&lt;div class=\"col-md-12\"&gt;"); foreach (var slot in _timeslots.Skip(i * 12).Take(12)) { Console.WriteLine(slot.Value); } Console.WriteLine("&lt;/div&gt;&lt;/div&gt;"); } 
Not everyone has an up-to-date .NET Framework installation either. Besides, you can bundle the .NET Core runtime with your application (`dotnet publish -r win10-x64`) if for some reason it's unfathomable to install .NET Core on the system.
Which is why you just do a [self contained deployment](https://docs.microsoft.com/en-us/dotnet/core/deploying/).
Okay, so you solved that problem by bloating the hell out of your application, and making it so that the user could end up with two or more copies of the runtime bundled with other software. Now what GUI framework do you intend to deliver to your users?
The subject is ASP.NET, you don't need a GUI framework.
The OC said ".NET Core is going to be the future of .NET", implying that the plain .NET framework will be deprecated in its favor. 
Yes, everything is "Nuget'd". We have a Nuget server running internally, so everything gets built as a Nuget package, and updated through our gated build. Then at night, the latest build gets "pushed" with all the changes. LOOOOTS of unit tests too, to try and mitigate the major problems.
Learn how to use **Git version control** to version your software. You can use Github or Bitbucket as remote repositories for your code. After that, you can clone code repositories from Github straight to your PC. This is the conventional way to "download code" and you'll learn the role of version control while you are at it.
Anything that'll run in a browser.
It's clear MS is heavily investing in .Net Core. Multi-platform and containerization are the present and foreseeable future. Market forces (where apps need to run, the types of apps that need to run, and the collective attention of the overall development community) are all pushing MS away from native Windows application development.
Yeah ffs tons of business apps are still continuing development in VB/C# Webforms. I get interview requests every week. You manage one legacy project and everyone jumps on you like a hawk.
That's a fair point, however as an employer id rather you had development experience in the outgoing technology. There's a lot to .Net that you only pick up when developing with it, but is required for ongoing practical maintenance. Junior devs are typically going to spend their first year or so working primarily on maintenance, and the stuff they'll be maintaining is necessarily going to be classic Net code. If I had two otherwise identical candidates in front of me, but one had net core and the other had classic net, id go with the classic net applicant, as you can definitely teach them net core on the job, while they're still immediately fully useful on existing software. I expect that'll be the case for a few years at least, as the major platforms still use classic, some even use VB. That's all anecdotal for a mature business though. Really you need to look at the companies in your region and see what they're using and how quickly they're moving to Core. 
Purely for the sake of getting hired, use .NET Core as a buzzword, it's very well possible that the actual job opening will still be in regular ASP.NET MVC over Core. Recruiters love to lure you in with "the latest technologies"
I hope the webdev meme dies soon. Computers are becoming more and more powerful, and instead of using that compute power to do useful things locally, we're using it to run slow, sloppy, single-threaded JavaShit apps contained in a browser. And in doing so we're turning the greatest information system to ever exist into an ephemeral, unsaveable, unbookmarkable mess that a select few corporations have almost absolute control over. And developers are forced to use a mess of markup, JavaShit and stylesheets riddled with float hacks instead of a clean, efficient GUI framework.
I work for an enterprise that still has legacy code written in COBOL on a mainframe. So I wouldn‚Äôt lecture me on keeping up on old projects and only following the framework of the week. My point still 100% stands. I want my developers to stay relevant and if they can learn .net core then they can easily figure out MVC5 later. The framework isn‚Äôt going to stop a junior dev from getting a job and implying that it is like you‚Äôre doing is just straight up ridiculous.
Ah I see. Okay, so, you're looking at two different concepts, essentially. AspNetUser is part of ASP.NET's session and Principal management, while Identity is .NET's Principal management, and IdentityFramework is the storage and wrappers for those concepts. Look up Authentication, and Authorization for more info; these concepts are language-agnostic. With all that said, ApplicationUser needs to know at least the ID of the AdpNetUser. I _think_ this is already supported, but I don't recall how to get it working. Failing that, you can add an integer ID property to ApplicationUser.
I‚Äôd go with the candidate who shows the most potential in not only their development knowledge but also how they work with others. To make a decision based on what .net framework they know over another one is just straight up short sighted.
You'll likely never have much trouble finding a c#/.net job in a medium to large metro area.
not an official one, but this project seems to be going along at a pretty steady clip: https://github.com/AvaloniaUI/Avalonia
Short answer: machine.config. Long answer: https://msdn.microsoft.com/en-us/library/ms178685.aspx
Having written apps in Silverlight and WPF, I would like to hear more of this clean, efficient GUI framework whose styling isn't a mess.
Have you opened up Task Manager to see if the file is open? Maybe there's a left-over from previous debugging attempts? Just a quick guess.
Change your code to this and it should work.. FileStream fs = File.Create(path); TextWriter tw = new StreamWriter(fs); If you look at File.Create(path); it actually opens a stream, but then your next line of code attempts to open another stream on the same file, hence the exception.
IIRC, StreamWriter will automatically create a new file if it doesn't already exist anyway. (The error you're encountering is that you've opened up a new file for writing, locking it in the process, and then StreamWriter has tried to access the file which is currently open and locked). So rewrite this: if (!File.Exists(path)) { File.Create(path); TextWriter tw = new StreamWriter(path); // System.IO Exception tw.WriteLine($"Hello, {customName}. How is your day?"); tw.Close(); } To this: //let StreamWriter handle File IO (Create and Close) using(StreamWriter tw = File.AppendText(path)) { tw.WriteLine($"Hello, {customName}. How is your day?"); }
Ok, it makes sense. I tracked it down in the .NET framework folder but all the settings in their seem high level and generic for all applications. I have a setting in my web.config called "NumberOfRecordsToRetrieve" and it's an integer and is set to 20. When I copied my app to prod I forgot to put that setting into my web.config but somehow it still only retrieves 20 records. Now I put the setting into my web.config and changed it to 50. When I run my code it still returns 20 records. I didn't see any specific settings in the machine.config that would tell my code to only retrieve 20 records so I have no clue why it didn't throw an error or why it returns 20 records. Now I want it to return 50 records but my change didn't work.
Good to know that it exists.... But why?
Depends on your definition of beginner. Beginner Scenario 1 - Recent grad still living at home with parents, they're glad to have me back in the house and I'm looking for my first job. If this is the case then learn Asp.Net Core MVC and look for jobs using it. Beginner Scenario 2 - Living at home with parents but Dad glares at me every time I reach for the refrigerator door handle. Learn Asp.Net MVC. Beginner Scenario 3 - Living on my own and I got bills to pay and need to get a job quick! Learn Asp.Net MVC Good luck!
How else are you suppose to access global variables within a native library? If you try to dynamically load the library and grab the pointer to the variable, you'll see an inconsistent behavior in Dotnet Core vs Mono and Microsoft CLR, because Dotnet Core would've end up with a duplicate instance of the same library. This project basically solves that by making sure there's only one instance of the native library and everything can be accessed by symbol.
For some libraries, it's not possible to use DllImport in a way that works on all .NET platforms. Mono has a custom feature called "DllMap" that allows them to arbitrarily redirect native function calls from one name to another name. This allows you to write a DllImport against "vulkan-1.dll", and have it automatically redirected to "libvulkan.so" on Linux or Android. No other .NET runtimes support this feature (.NET Core, .NET Framework, .NET Native, etc.), so it can't be used in a portable library if you intend to run on all of those platforms. This library instead uses the lower-level module and function loading calls of the operating system to do this mapping manually. These are the same functions that are used internally by .NET Runtimes to implement DllImport/PInvoke. Additionally (and I think this is the main value-add here), it adds a higher-level abstraction on top of this low-level loading by allowing you to define an interface that will be used to determine which functions get loaded (their names and signatures, etc.). I have a similar library [here](https://github.com/mellinoe/nativelibraryloader) which just wraps the low-level module and function loading -- no higher level abstractions.
I'm glad my employer agrees with you, because I only had experience in .NET Core when they hired me...
np w wir
Dotnet Core create a new instance of a native library if you use DllImport. The original purpose of this project is to reduce amount of boilerplate codes of writing a delegate based approach for loading functions instead of DllImport just to enable support on getting library global variables and the functions within the same library, the Dllmap and other features came later. It caused me some headache that Mono would've loaded only once when you use dlopen the library along with Microsoft CLR that would've loaded only once as well, Dotnet Core is the only one that doesn't behaves the same as the rest of them.
I've never heard of that behavior, and the information I'm finding on the web seems to agree with what I wrote above. Do you have a bug report or some other information about it?
You should really be using transformations so this doesn't happen. You should be free to overwrite everything in production with only changing the build.
Yeah, I'm too worried I'll forget the change the profile when publishing and will accidentally publish to prod. When I release a new version I take a back-up of the entire prod folder so I can revert to the last version very quickly.
This is nice but with a GPL license I won't be able to use it here at work. Which is unfortunate could really use this to make some of interfaces with managed dlls work better.
I did a writeup on some of these issues here: http://sharkman.asuscomm.com/blog/the-curious-case-of-the-function-that-shouldnt-exist/
We offer custom licensing for companies and individuals. Drop me an email at jarl.gullberg@gmail.com and I'm sure we can work something out :D
Thanks for the link. Was a bug ever filed for this? I'm assuming not -- I used to work on tangentially-related things and haven't heard of it. I can't say whether it's intentional or not, but it's at least interesting in that it behaves differently from mono. I think the runtime team would be interested in investigating such differences. However, mono has a lot of buggy behavior that isn't correct (at least not objectively), so it isn't necessarily the model to match here. Looking into it further online, it seems like `dlopen` will return different handles if the path given to it is different, even if the file is ultimately the same. That might be the behavior observed in that example.
I've checked for that one as well by ensuring the dlopen is specified with an absolute path and having no other library being around for it.
I see. Have you traced to see what the runtime is passing in to `dlopen`? If it's using the same path and you're still seeing different handles, then that doesn't make much sense to me based on what I'm reading online (which could certainly be wrong :) ).
In my situation everything else about my job is great. I work 100% remote on problems I like with a team I get along and great pay. It would be hard to find a better situation. I don't think I could ever commute or work in an office again.
Yes, I do accept remote applicants.
Seems the behavior changed with the latest version of Dotnet Core, so it doesn't seem to produce the same behavior anymore as last seen. (The code I've used and demonstrated on is on November last year.)
without seeing any code it's hard to say why that's happening. The machine.config wouldn't know anything about specific settings and make some guesses about them. So my psychic debugging skills tell me that the deploy went screwy. IIS is perhaps pointed to a path than you think it should be. That would explain why it was still pulling 20 and why changing the value would keep it at 20. The only other guess I have is that whatever code you think is pulling the value isn't.
File.ReadAllText()? Or File.WriteAllText()? Have you even looked at the API?
&gt;UWP is the future right? Just like WinRT before it.
Select the course, as you have done, and then run linq on the grades field of the returned course ?
I ran into this problem a few weeks ago. A couple guys on the engineering team looked at it and said "fuck it, we're not using arrays in the JSON", and that was that. I know it's not helpful, but I found it funny. 
Let me throw something together. BTW [You may prefer method syntax for linq](http://www.tutorialsteacher.com/linq/linq-method-syntax)
 string jsonData = @"{""Info"" : [ { ""course"" : ""Norsk"", ""grades"" : [2, 6, 8, 3, 6, 1] }, { ""course"" : ""IT 2"", ""grades"" : [5, 6, 2, 3, 6, 1] }] }"; JObject data = JObject.Parse(jsonData); var iGrades = data["Info"].Select(x =&gt; x["grades"]).Select(x =&gt; x.Select(y =&gt; y.ToObject&lt;int&gt;())).ToArray(); --- Gives an array containing two arrays of ints. It's a bit complex, but it helps to remember that you are dealing with JTokens. The "var igrades = " line says: For each element in the Info structure select the grades element (returns an array) and for element in the grade array select convert the element to an int (using the JToken.ToObject() Method), and return the whole thing as an array 
Instead of trying to map the json yourself, you should consider having it map to a type via the `JsonConvert` methods available in Json.Net. Here's an example: //Define some classes that match your json public class Root { public List&lt;CourseData&gt; Info { get; set; } } public class CourseData { public string Course { get; set; } public List&lt;int&gt; Grades { get; set; } } //Elsewhere... var parsed = JsonConvert.DeserializeObject&lt;Root&gt;(jsonContent); This will provide you a properly typed object model from which you can base the rest of your code.
Use a razor template and real view models
Thank you! But this returns all grades for all courses right? Would it be possible for me to access just one course at a time? Maybe something like: var iGrades = data["Info"].Select(x =&gt; x[str].Select(x =&gt; x["grades"]).Select(x =&gt; x.Select(y =&gt; y.ToObject&lt;int&gt;())).ToArray(); where str is a condition in a foreach or something along those lines? I don't have a windows machine in front of me so I can't test it out. 
I agree, and it's kind of silly because it shouldn't be difficult. I think the most popular library (JSON.NET) suffers from being too powerful. You can do so much with it, but the documentation is geared towards people who already understand the nuances of parsing. I wrote up a working example of how to parse the JSON you have in your original post. It's not exactly pretty, but it should help you figure out how you can best optimize it for your own needs after seeing how to access those values. [You can find it here](https://gist.github.com/AlexanderJ-ULabs/db72a8c9faaa413204cb079c19fbd8b3)
Here you go: https://www.reddit.com/r/csharp/comments/85atir/braindump_forming_a_list_of_appropriately_scaling/
Thank you. I'm sorry, I haven't quite learned C# yet, but how would this be different than my current situation? Wouldn't I still have to go through the same process to link List&lt;int&gt; Grades to the arrays as I have to now?
No - in this case, Json.Net will map the object as fully as it can, including nested properties. It will create an instance of the Root type, and automatically create instances of `CourseData` to map to the inner json objects (and thus, the `List&lt;int&gt;`). This will differ depending on what your json looks like, of course - some data is too complex to map this way, in which case you'll need to implement a more complex solution as described in other posts of this thread - but from what you've shown so far, it should work fine.
OP -&gt; This is the cleanest and simplest way for processing your data. 
I did say major runtime changes, and we're comparing it to other solutions. Traits and mixins are much more expensive.
 //Elsewhere... var parsed = JsonConvert.DeserializeObject&lt;Root&gt;(jsonContent); In this case ```parsed``` is a Root object, so you can access the grades list like this var grades = parsed.Info.Select(inf =&gt; inf.Grades); Where grades is a ```IEnumerable``` of ```List&lt;int&gt;```
ooh somebody posted their email on reddit :o
&gt; One reason for trying out using a struct instead of a class is that you can design it so that default(T) is a valid value, allowing you to safely skip null checks when using values of the type. I will still need to decide if I think it is a good idea to do that. I'd be curious as to your use case for such a thing. Keep in mind: - Structs Holding Reference Types is generally considered a Bad Thing. - Structs get worse than classes (as far as copying/passing) when they become larger than ~16 bytes. - You may be able to get similar behaviors with some cleverly done extension methods on an interface, depending on what must be done. But it's still very use case specific, as typically substituting a 'default' value for run-time is a bad idea because it's masking a behavior problem in the application. Example of one way to do such (Not tested, but should be pretty close if not a working example): public static T DefaultInstance&lt;T&gt;(this T mayOrMayNotBeNull) where T: new() { if (mayOrMayNotBeNull == default(T)) { return new T(); } return mayOrMayNotBeNull; } This is arguably worse on a struct because we are creating 2 extra structs for that case (one for the default(), one for the return anyway). You can get around this to an extent by having two separate methods `where T:Class` and `where T:struct`and having the struct method just return right away (IFF you want uniformity between the two in your code.) I'd still just check for null, personally.
Thats what I‚Äôm using.
https://deck.net/0b76f8f76ae6e4c499060c7477c457c0 Just wanted to see this sample running.
Google "57 programming challenges" it's a pretty good book, using it myself 
Yea for a second I didn't make the connection, because I use the nuget version.
Well, 'tis for a good cause.
OP doesn't have a DNS to query.
If you're an intermediate, I would suggest building a full project from scratch. My go-to suggestion is a character creator for role playing games (e.g. D&amp;D, Savage Words, Traveller). They are complicated enough to be interesting with lots of edge cases just like real-world projects.
PMs exist for a reason
By custom you mean paid right? Fair if that's the case, but good to know up front.
Yeah, no. Json and csharp mix just fine. Best is to do what's noted above: deserialize from the json into an object in csharp. Then you can manipulate the data as though it's a native class in your project.
I could write a litany about Json.NET and how it's the best worst parsing library out there. It's super powerful. And it's great for general purpose use. But... That means that everyone winds up using it. And over time the likelyhood of running into some sort of dependency trap gets closer and closer to 1. Yes, perfect shops don't get stuck on dependency versions; No, you probably don't work at a perfect shop where %architecture_critical_library% got upgraded so that you can go past version 6 or 8 of Json.NET. That in and of itself isn't Json.NET's fault; the strong versioning IS meaningful (in that yes, there *is* a breaking change somewhere in the library, just not a part you were aware of,) and while I am amused that the fix I had to hotwire into a messaging bus different but semantically the same, but at the same time I have to question why they're so happy to throw around breaking changes like that [while sitting on thread safety bug fixes](https://github.com/JamesNK/Newtonsoft.Json/pull/1393/files). SimpleJson works for most sane cases of Json, and has the advantage of being a single-file drop-in that doesn't have any real version dependency. Yes, this could make bugfixes annoying, but the less stupid you get with your objects the less likely you'll ever have to deal with such things. I'd argue that if your requirements are outside of the capabilities of that library, Json may not be the best tool for the job.
In my experience when the IT were full hitler in the company, the whole company followed the same path. Glad it is not the case for you!
Does this handle const strings (eg. LPCTSTR)? It's not clear from the docs/source whether it does.
I started as basically and entry level developer on the VB compiler 12 years ago. Worked there for a while. Then worked on the language debugger, IDE and then back to the compiler layer and migrating to C#. Been there in some capacity since. I don‚Äôt really have any specific background in compilers. Actually avoided them in college because i thought they were boring. Most of what I‚Äôve learned have come from working on them, reading about languages (Work and for fun) and just experimenting around. 
Please make a thorough example. I remember trying to get Squirrel to work and failed because there were none of it.
The tide is already turning on server-side rendered views with an MVC pattern though, if you're only concern is staying ahead of the curve i'd look into MVVM (SPAs with a REST API) instead. If MVC falls out of favor for new projects then expect knowledge in designing/implementing RESTful services and SPAs to be where the value is. If you really want to get ahead of the curve try a project like [Blazor](https://github.com/aspnet/Blazor) (C# Views/ViewModels compiled to WASM, running .NET in the browser) or another language that can compile WASM (C, Rust, Haxe etc), and apply it with an MVVM pattern.
I'm on it
Seconded. I was intrigued, but once I saw the license I quickly lost interest as I couldn't use it in any of my projects. I think GPL is way too restrictive, especially for libraries.
I am learning ASP.NET Core through this free Udemy course: https://www.udemy.com/quick-introduction-to-aspnet-mvc-core-20/learn/v4/overview It's an amazing framework. I also learnt Django. But I have fallen in love with the Core within a very short time. ;)
Boss specifically mandated aspx web forms. He even made me rewrite the mvc system I did he‚Äôs that adamant about not deviating from this. 
Does it support binding when declaring the forms in XAML?
Too late, I already signed them up for cat facts.
Guess I didn't expect anybody to ask me if I drive a car lol 
You may be interested in that one also: https://github.com/aspnet/Blazor Thera are suggestions to run blazor SPAs in electron which is great.
System.Drawing in a working enough structure to create bitmap and other images....so I can finally build my ZPLII image generator in .net core, without depending on third party projects that focus more on photo manipulating.
1. This sub is for C# which is a different language than TypeScript. Try /r/typescript. 2. This error indicates that you are attempted to invoke a function call on an object (in this case an object of type '{}') that is not necessarily a function. Your project may still work, because TypeScript trans-piles to JavaScript which is dynamically-typed. 3. There is little more we can do to help you fix the errors unless we have access to the code generating the errors.
Do you have a public repo containing your efforts in regards to C#+LLVM? That does seem very interesting. Wouldn't it be possible to also compile to native assemblies using that approach?
+1 for being able to resize a damn jpeg on a website.
There is a .net extension pack for .Net Core for Windows which let's you access System.Drawing today. Not sure what OS you're writing for.
A UI framework would be nice.
[Coming soon](https://github.com/dotnet/corefx/issues/24909).
Thank you, I got most of it working, but it's not reading the whole JSON array, only 5 out of 6 entries. Do you know why? And it only reads 1 course, but I suspect that's a typo I have somewhere.
Xaml Core!
Well then you have to do that interesting trade-off between server CPU cycles and bandwidth. What is on sale today? Best to do the resize once and store on the filesystem.
Actually, it would be nice to be able to validate that what the user uploaded was, in fact, a JPEG.
I know c# is 0-indexed, the for loop looks like, for (int i = 0; i &lt; getGrades(course).Length; i++) { // Stuff } I'm trying to achieve a chart view of all courses and their grades side by sides. Right now it only shows 0, 1, 2, 3 and 4 of the first course, in their correct places, the 5th index and the other courses just don't show up.
I'm soon moving into the high-traffic territory, but at the moment it's still a pretty low average request rate (with random peaks into the 10-30 req/s here and here). I actually moved all my assets off to a static nginx instance to prevent kestrel from having to handle static traffic Anyhow, I completely believe you, I've run into dotnet core issues as well after porting from .net core framework (with sql server). While I can't really offer help - I know .net core 2.1 greatly improves on the performance of socket IO and kestrel in general, so it might be worth a look to see if that perhaps fixes it. If anything, write a quick stresser for it to test it out?
Well, there's plenty of articles out there going over it. Here's one by Jon Skeet: http://csharpindepth.com/Articles/General/FloatingPoint.aspx The basic gist is that a `float` will have only 32 bits of precision (64 for `double`), and you can only represent so many numbers that way. So instead it stores the number as a mathematical formula which can be used to pretty well to describe a large range of numbers (+/- 3.402823E+38) and with a lot of decimal places, but it trades 100% precision. In particular, its representation doesn't do a perfect job of translating base 10 decimal points into an equivalent binary format. So when you write `double b = 0.94`, the `0.94` actually cannot be represented in this formula 100% accurately. The default `.ToString` representation usually does a good job of rounding the output to an expected number, but if you use the "R" round-trip formatting specifier, you can see the _actual_ stored number: double b = 0.94f; Console.WriteLine(b.ToString()) //0.94 Console.WriteLine(b.ToString("R")) //0.93999999761581421
Why?
Good point, and that can certainly be done. "WIP". Validating file formats doesn't tie you in any way to GDI or an OS, so that will be implemented.
So based on that issue you linked it's not aspnet core. It's those common pitfalls of using task.result and not increasing the tcp connection limit. 
lightsabers.
Do you happen to have fallbacks for the values in your code? Something where if the app setting is null, NumberOfRecordsToRetrieve gets set to 20, or some other value?
Excellent answer
It depends - I'm open to free licensing for established open-source libraries. As for knowing up front, it's right there in the readme. 
I've been doing this for 20 years and just yesterday I created a function on a class and didn't know whether it made more sense as a read-only property. Sometimes it doesn't actually matter. Though if anyone has some reasoning behind why it does I'd love to be reminded.
Isn‚Äôt it obvious? So OP can learn something... about cats. And the internet.
My reasoning behind GPL comes from a strong belief in copyleft and open-source - any lesser license would be pointless, since custom licensing is an option. I've put a lot of work into this library, and much of it stems from existing work in the open-source sphere. GPL is, to me, a way to get something out of that work that isn't straight money (which is also an option, hence custom licensing).
Or some other graphics and image manipulation library good enough for server side image processing.
My apologies, here is the code in question (names have been changed) var items = _dataService.GetTopItems(Properties.Settings.Default.NumberOfItemsToRetrieve); As you can see I call a data layer to retrieve records and pass a parameter for the number of records I want to retrieve. In my data layer I query the database using lambda and do a .Take() with the parameter I passed in. public List&lt;Item&gt; GetTopItems(int count) { using(var db = new DatabaseContext()) { return db.Items.OrderByDescending(s =&gt; s.CreateDate).Take(count).ToList(); } } I did some more testing and think I might have figured it out. To see what would happen if my program ran without a setting I commented out the above setting in my web.config (it was set to 40) when my code ran it had a value of 20. So I checked my web.config and when it built it must have un-commented that setting and reverted it to 20 or maybe it detected that a setting was missing and filled it in from the project settings (Settings.settings). This raised more questions since if there's a Settings.settings then is that stored on compilation? So I checked my project's DLL file and found those settings towards the bottom. So I guess when you compile it stores a copy of the settings in the DLL. So I think that's where my phantom values are coming from. I have no idea how to fix this without a redeploy though.
Never before I've seen the "R" format specifier, TIL!
I was just responding based on the link you sent. If that's the issue you're having then it's most likely not kestrel. Try run your service on windows and replace usekestrel with usehttpsys. If you can repro then it's definitely not kestrel. I've seen the behavior you describe. A while back I wrote a large file uploader to upload 100GB + files to azure blob storage. What it would do is break the file up into 4MB blocks and try upload them as fast as possible. I used TPL to parallelize my tasks. Anyway, I wasn't aware if the connection limit at the time and was very confused by why my process semmed to do nothing for a few seconds with no CPU usage. I haven't personally experienced issues around task.result and the others because I try to avoid synchronus calls whenever possible and use getawaiter.getresult when it isn't.
Depends on what you wanna improve. Language skills? Framework skills or things like "build an n-tier application"? If you wanna have some fun with coding challenges, try https://www.codingame.com Really fun and entertaining.
first class AOT compiler for all platforms
I'd really love some more complex Math &amp; Geometry library. I know that `System.Drawing` has Rectangle, Point, and Size, but that's not enough. I'm looking for things such as Line/LineSegment, Circle, Polygon. Ability to bisect a polygon with a line, etc. I feel as if I'm not the only one who's had to write they own Math/Geometry library.
.NET Native is in making right ? What is the status on that project ? Does anyone know when and if it will be usable ?
Thank you for the advice. &gt;Or do you want many copies of it each time you assign it to another object of the same type (such as in a foreach loop) Do you have an example of this I can look at to understand better?
A version EF that is equivalent to EF6
My first .net core API was running initially in a Windows Server, 4 machines handling something like 100k reqs/min. Not bad. So I had to move it to a Linux server, just added the kestrel and my headache started. The solution was what I said before, spawning multiple processes and multiple servers to guarantee that the kestrel will receive it slow. I was using .net core 1.0 at the time, and I'been upgrading it every time a new LTS is released. The issue is the same. New APIs: same issues and different approaches to handle high traffic since every new project uses a different set of libraries. One project the solution was simple: I have to limit the traffic with nginx based on req/sec. The connected service could handle this and retry later. The other one? Enqueue the request directly with nginx to a queue service. Moved from kestrel to start listening the queue direcly, I even bother to control my thread pool, it worked at the first try. This API don't have a output then switch to this approach was easy. Other project spawn multiple processes was a issue due the high memory consumption, so I had to spawn dozens of machines (micro) with a single process on it. Developing in .net core and hosting it on kestrel is a rollercoaster. Fortunately I like puzzles.
Hi! Enums are not like a struct or class, think of them like a reverse array. You input a word, and the output is it's position like 0, 1, 2... Helpful when you want to "name" settings that you pass around but don't want to remember that 0=tacos and 1=burritos, you can just say myEnum.tacos. Structs are by value types while objects/classes are reference types, that's the biggest difference. For me I rarely use structs unless I just need to make 1 of something, and usually just make them to quickly and easily store similar data. Classes are much more detailed than structs, effectively a class is a complex data type. I think where this gets confusing is that C# allows structs to have methods, which isn't something I've seen in other languages. In Java I'm pretty sure structs may have a constructor and that's it. So really you could use structs for all kinds of things in C# that you should be using a class for if you really wanted to, but constantly passing value types may greatly increase the memory usage of an application as depending on how you use them. Really I wouldn't use structs for anything where you need a lot of copies. If I'm going to make 2000 of something, it's going to be a class that I'm instantiating into objects. 
About access modifiers Public and Private: When inside a non-static class for example, would you want instances of the class (objects) to expose that variable to the rest of the program (public) or just use that variable internally to the object (private)? A case where I would use public is when I want to store data that I want to reference later like car.color, or car.horsePower. A case where I would keep a property private would be one that I use in a calculation that wouldn't me one o plan to expose. An example might me car.currentEngineTemp. Maybe I don't expose the temp so keep it private so anyone else using the class isn't messing with it, but I use it to lower the car.horsePower if currentEngineTemp is too high. (weird example I know lol)
That's a good start. Look, my issues was just doing some APIs and the issues are related to libs used and operations. Maybe you won't have the same issue at all while running your application and scale it based on CPU usage it's simple like it should be. Even facing issues I'm still using the framework because I don't want to handle http requests myself and create more bugs in the process. Write lots of code to just have a simple application supporting a higher req/sec rate? I rather test it out and discover where the boundaries is then figure out how to contour it.
I've added an additional license file which clarifies the option of a custom license: https://github.com/Firwood-Software/AdvanceDLSupport/blob/master/LICENSE-NOT-GPL.md
SDK for ARM. We have the runtime on ARM, so I can write a .NET Core program and run it on a Raspberry Pi, but I cannot compile directly on the Pi.
Lazy Loading in EF Core. It is scheduled for 2.1, though, I think.
I personally recommend .NET Core. 
95% of the time most of this stuff doesn't actually matter, it's just what style you or your team prefers.
Yeah it seems that everyone is saying I would only really use classes outside specific situations, the text I got given made this seem seriously important to be able to tell when to use each thing and that you can't move on to the next section if you don't understand :/
Yeah, it's pretty much AOT compilation without needing to specify an AOT compilation approach. The project stem from the following ideas: 1. Transpiling C/C++ Headers so it could be used by C# with LLVM JIT on the fly, but not necessarily be included as a final code in C# compilation. 2. LLVM JIT would enable supports for emitting new code during runtime, but it would also be optional. 3. Having C# become a system programming language which then can be linked up with C/C++ object files and be used in official development projects like Linux Kernel. 4. Adaptive Reprogramming (An idea that I wanted to experiment that basically push the decision of optimization to the JIT to make a determination to rewrite codes that are single threaded and assesses the workload to parallelize the code or to make it singlethreaded depending on the threshold for net performance gain.) 5. Reflection support is a big one, but that is something that I'm still trying to solve. So this project that I've been doing is pretty much called the Kinos and Pineapple Projects. Kinos for C# + LLVM Runtime Project and Pineapple for Parser Generator that simplify transpilation and other features when writing the languages with a custom Backus-Naur Form grammar. This is pretty much why I gave up ownership of Advanced Delegate Support project to Jax so I can focus on working on this project and Jax can continue to maintain the project. Jax is doing a pretty fantastic job on it as you could see in the commits.
wpf
&gt; I think where this gets confusing is that C# allows structs to have methods, which isn't something I've seen in other languages. C doesn't support methods for structs, but it doesn't support them for anything else either because it's not an object-oriented language. C++ has both `class` and `struct` keywords, and they are mostly the same thing. It definitely allows declaring methods for them. Swift has both `class` and `struct` and they work identically to C#. I'm not aware of any other languages with the struct/class dichotomy, so I have no idea what you're referring to. &gt;In Java I'm pretty sure structs may have a constructor and that's it. Java doesn't have structs or anything directly comparable. &gt;but constantly passing value types may greatly increase the memory usage of an application as depending on how you use them This is false. Value types are allocated on the stack (or embedded directly into heap allocated objects), so they don't consume any more memory than class instances - as a matter of fact, they typically consume _less_ memory. For example an array of objects takes about `n * 8 + n * sizeof(type)` bytes of memory on a 64-bit system (because you need `n` pointers), whereas an array of structs takes just `n * sizeof(type)` bytes. It also has significantly better cache locality, since the structs are stored in a linear chunk of memory. Unlike objects, structs don't cause any GC pressure. The only case where reference types are more efficient memory-wise is when have a list containing lots of duplicates. Instead of duplicating the data you can just store multiple pointers to the same object. The trade-off you make value types is that unless you use `ref` and/or `in` you will have to copy the struct on every function call and assignment. If the struct is bigger than a pointer (8 bytes on a 64-bit system), this tends to be slower than passing a reference to an object. The copy doesn't increase memory usage as you claim, but it adds unnecessary work for the CPU. This can be avoided with the aforementioned keywords and careful design. &gt; Really I wouldn't use structs for anything where you need a lot of copies. If I'm going to make 2000 of something, it's going to be a class that I'm instantiating into objects. This is literally the opposite of the right answer.
Why not LGPL? Stops creation of closed source versions of your library, but still allows closed source software to use it.
Do you have to run it on the Pi to test what you did or is there some sort of emulator you can use on your dev machine? That would be annoying if there wasn't :-/
LGPL severely limits my opportunities to commercialize the library. There's just not enough difference between using a free LGPL library and having a commercial version. 
For class vs struct, the general best practice is to use a struct for immutable data i.e read-only. Many structs don't follow this best practice (even many Microsoft structs). Basically, once you've instantiated a struct, it's values are permanent. It's properties should be read-only. Use classes for nearly everything else (assuming you don't need an interface or enum). &amp;nbsp; Enums are just nifty lists of items that provide type safety and allows you to avoid what we call magical strings. Instead of this: public void WriteDay(string day) { switch (day) { case "Monday": //do stuff break; //etc } } You can use an enum like 'Day' to specify the exact days. That incoming string could be literally any type of string. With an enum, you ensure type safety. There is one issue with enums and that is the fact that you can cast relevant numerical values to the enum that don't exist. For example: public enum Day { Sunday, Monday, //etc } Day myDay = (Day) 42; //this doesn't map to any of the 7 members of the enum but this cast is valid and no compiler errors will be emitted &amp;nbsp; Public vs. private members concerns the concept of encapsulation. **Only expose needed functionality and the class should be able to maintain its own state**. As a general rule, assume that everything in your class or struct should be private until you know that some other type will need to use the member. If they need to only *read* it, make it read-only. If they need to be able to write to it, then allow that as well. This information may not help you, but you should look up **encapsulation** as well as the **S.O.L.I.D Programming Principles.** &amp;nbsp; Hope this helps. 
There is a version of the sdk out. https://mobile.twitter.com/PeterMarcu/status/974412390937780224
* Machine learning libraries comparable to Python. There are some libraries (and tools/sdks on Azure), but they are not nearly enough today. * A sane project template for long running stateful services (preferably one that IIS/Azure won't decide to unload every 20 minutes) and that doesn't require some kind of service orchestration to run (e.g. Service Fabric or Kubernates). No status that I know of. * A production equivalent to project Blazor. Probably a couple years (or more) away. * Rosyln based autovectorization (System.Numerics requires too many concessions to use explicitly). I'm not even sure if this is theoretically possible. 
&gt; Dot net core sdk for raspberry pi - it's incoming. There's a candidate build that works. I'd like just being able to run .NET Core apps on it too, following the poorly constructed official docs leads to various DLL errors.
Some parts are cross-platform, but not all.
&gt; It would help everyone to have Xaml processing out in the open, but MS is not interested. They're probably still sore that XAML never managed to beat out PDF as a read-only file format. Hell, I bet most people don't even remember they tried that.
EF Core still can't match the basic functionality of EF 6. It's shameful that they released it in the state it's in.
https://blogs.msdn.microsoft.com/david/2017/07/20/setting_up_raspian_and_dotnet_core_2_0_on_a_raspberry_pi/ Also there's a certain parameter you have to specify when you compile to target ARM.
As far as I know there isn't an emulator. I develop and test things on my PC and then I publish out on the pi. So far, I haven't run into any issue moving from x86 to ARM, though I'm not doing anything too intense, just a basic webservice with some image manipulation.
&gt;Enums are just a concretely defined categories, basically. If you're passing around a string that could be "Red", "Blue", or "Yellow", chances are you could defined an enum to represent those options instead. Color.Red, Color.Blue, or Color.Yellow. Otherwise, you'd have to make sure that string is one of your given options. So would it be good to use in switch/case situations?
I most certainly had to.
This may be a bit dated https://github.com/picoe/Eto/wiki/Data-Binding 
I wanna see an official build option for FreeBSD
This might help: http://www.mono-project.com/docs/tools+libraries/libraries/monocurses/ 
I don't think monocurses is noob friendly lol
It sounds pretty easy to do but I don't know what you mean by dynamic. You can do everything you said with Console.WriteLine() and Console.Read()
It literally doesn't matter. Just name it that way and if someone one day says you should change it for something clearer then do.
priceText
Re-read it. Then delete your comment accordingly. :-)
Are you talking about the old [Lotus 123 menus](https://regmedia.co.uk/2013/01/28/123_release_1.png)? That's a cool idea! There might even be an object or library for it, but I've never run into it before.
Maybe not in the lib itself but I got used to Visual Stuido‚Äôs handy functions a lot and I really miss dotnet commands there in some menu or shortcut like dotnet ef migrations add or dotnet ef database update.
With no further look than the readme, looks pretty cool! I'll check it out later :)
Thanks a lot 
Something like Flutter for C# with Razor with hot-reloading would be amazing.
Something like Flutter for C# with Razor with hot-reloading would be amazing.
Thank you! So I guess I'll leave it at that :)
I've taken to naming string representations of variables that I'm going to parse as "fooAsString", but maybe that's just me.
Jsonml
... In what way? 
I'm assuming you enjoy it now after learning so much about it? This has happened to me more than a few times. Not in just coding, but lots of different things in life that I swore I'd never enjoy. 
You can still web form tools for this. It looks like something like a Repeater could work for you.
If you need a regular HTTP proxy, you can configure it in your app.config or web.config. This will only affect that one binary, everything else will work as normal. See https://docs.microsoft.com/en-us/dotnet/framework/configure-apps/file-schema/network/defaultproxy-element-network-settings
https://stackoverflow.com/questions/13122369/use-webclient-with-socks-proxy
I made something for this situation a while ago: https://github.com/alsiola/DeclarativeConsoleMenu
Didn't know what [Flutter](https://flutter.io/) was so I Google'd it. That sounds pretty awesome.
Try Avalonia. It's awesome.
Side note, does it actually need to be `IList`? Prefer `ICollection` over that, but does it need to support adding and removing or will you simply be newing up a list and then iterating it later? `IEnumerable`. I use `IEnumerable` for pretty much everything, and only go to "higher level" interfaces when I actually need the functionality they provide.
The best source, sadly, is to finish projects and ask people questions when you get stuck. There's a lot of ancestral knowledge and not all of it gets codified. Books I found useful include *CLR via C#*, *C# in Depth*, and more general texts like *Clean Code* and *Code Complete*. *Framework Design Guidelines* was also useful, but it's really an annotated copy of [the MS documentation](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/). For specific things you pointed out: * The answer to "Should I use a class or a struct?" is "a class". MS's guidelines say as much. There are very specific, narrow circumstances where you should use a struct. There are even more specific, narrow circumstances where it makes an observable difference on your program's performance. It is far, far too early for you to worry about this. Many professional C# developers never write a struct. * Enums have a more narrow, even more specific use case than classes or structs. They represent "a set of values". They aren't relevant to that conversation. * To decide if you should make a property public or private is an art. For new people, we tend to say "start with private, make it public if something else needs to see it." As I've developed, I find I don't make properties if they aren't public: they're overhead on top of fields and I never make fields public. Discussing why I adopted this practice gets pretty deep. (This is basically the "when to use get/set vs. manually assigning. Personally I hate properties in .NET and I think they created a lot of confusion.) All of this makes a lot more sense if you read many, many more books and at the same time write many, many programs. You'll read things, think they sound stupid, then try them and find out if they are. Sometimes they are stupid. Sometimes they aren't. Sometimes things are only stupid in small projects. Other times they're only stupid in big projects. How do you find out? By doing. We write books to list the practices that have worked. Good books try to point out *when* they worked. But it's up to us to give them a whirl in our projects and get a feel.
I'm waiting for a grid control. Though I don't need everything from the WPF grid, that's a must-have for the kinds of projects I do.
Official build support for WebAssembly.
Seems like this is more or less logically equivalent to [MediatR](https://github.com/jbogard/MediatR/wiki): MediatR requests are equivalent to LogicMine baskets MediatR handlers are equivalent to LogicMine terminators MediatR pipeline behaviors are equivalent to LogicMine stations What advantages are there in using LogicMine over MediatR?
 &gt; dotnet publish -r linux-arm Is the command, then you copy over the whole publish directory to your pi. That's right, the whole folder, baby. Then you run &gt; dotnet &lt;your_dll&gt;.dll If that doesn't do it for you, then I can't help you anymore.
:: slow clap :: (i actually upvoted you)
Somebody gets me. 
&gt; I haven't thought of it as bad as long as you are careful with the implementation. Could you elaborate on why it is generally a bad thing? Much of it boils down to the 'as long as you are careful with the implementation' part of it. And whether you can be sure *consumers* of your class/library will understand that just because the array itself is immutable, that doesn't mean the actual contents are. Personally, I haven't seen Immutable*&lt;T&gt; outside of Library code and the outermost edges of it (where the only params allowed in are primitives or effectively immutable anyway). &gt; I don't think anyone thinks these types having valid/usable default values is masking behaviour problems in the application, or at least having structs with this property should be no worse. Masking is often a bit strong. But consider: public void LazyExample() { //I spent all day de-duping code, I apologize for nothing WRT method/variable names. var myReturnValue = myDataThing.GetterFromWherever(); var soonToFail = myReturnValue ?? default(MyClass); //Or whatever technique you use. DoSomethingWith(soonToFail.Property); } Now, in this most basic example, my failiure is going to be just one line lower in the stack trace. But I'm not debugging in production, and in most production code `myReturnValue` is something I grabbed from another function. It will likely take me longer to figure out where/when the null value came from. Which may also make it more difficult to understand what precisely resulted in me getting a null. This is something I haven't appreciated the value of until more recently (i.e. Earlier null checking) but once you encounter a sufficiently layered and complex code-base the value becomes more apparent. &gt; when you have a value of that type, you know that it can be used without any validation. That said, the qualifier there is a good exception to the rule; If it is a type that you know will always have 'safe' defaults, you're probably OK. That's not the typical case, but it certainly happens.
A SOCKS5 proxy is a service that runs on a server and handles all the traffic sent to it by the client. In Windows &amp; Linux, the application has a configuration option for which destination IP addresses are sent through the proxy and which aren't. This is typically done in the browser settings, but other apps may have the option also. In this case, only applications that are configured to use the proxy will use it. Some OSs also have a proxy option in the Network Settings and will allow setting a system-wide proxy for particular protocols, for example HTTP/HTTPS. If you want your C# program to use a proxy and not tough the system settings, you can use [System.Net.WebProxy](https://docs.microsoft.com/en-us/dotnet/framework/network-programming/how-to-override-a-global-proxy-selection) 
Publish feature that does not create 100 megabytes and 400 files. Would love to be able to publish hello world executable that is smaller than average movie TV series episode.
For Polymorphic Seralization, Protobuf or Hyperion are my tools of choice, depending on need. Protobuf is very standard but requires Attributes on your Objects. Hyperion will take just about any concrete type you can throw at it and generate a fairly compact format that can be read on the other end right out. Biggest drawbacks are the concrete type issue, and possibly polymorphic security concerns; anything using that should be properly locked down lest someone use one of the more nefarious types in .NET to do bad things when the type gets disposed.
I think that conveys intent more clearly. "discount" or "discountString" may get confused with a discount code rather than discount value than "discountAsString". 
Why not have the parameterd of type decimal?
There are similarities, however there are also many differences. I'd say the 2 main differences are: 1. LogicMine is geared around writing entire applications (I don't think MediatR is). Mines can be built vertically (shafts AKA pipelines) and/or horizontally (layers). A layer contains a related set of stations/terminals, e.g. a data access layer, and the can be shared with many mines. This means for your run of the mill data types you likely don't have to create any form of custom pipeline, you can just use a mine which is built from your standard set of layers. * LogicMine is designed for compile time safety (a LOT of effort went into this). MediatR works out many things at run time (which obviously means potential runtime errors). 
Have you tried the ML in accord.net? Whats missing?
Fair call on the use of "widget"! To be honest I debated with myself for a while about whether to call it a data structure or not. In the end I went with "data structure" because: * I think it meets this definition: "More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data" Wegner, Peter; Reilly, Edwin D. Encyclopedia of Computer Science. Chichester, UK: John Wiley and Sons Ltd. pp. 507‚Äì512. ISBN 0470864125. * Something like a DHT would always be called a data structure (in my experience) but they are very often used for purposes other than just storing data.
Oh, the method is just an example, but somewhere down (or up in this case) the chain would have to parse the values and it would run into the same naming problem.
Why not ImageSharp or SkiaSharp? GDI+ is a really old library, and there's a lot of newer, better stuff out there nowadays. If you're building something new (sounds like you are), then you shouldn't use GDI+/System.Drawing.
How does this look? https://github.com/SixLabors/Shapes
Why not use smth like Orleans?
GoT, Season 7, Episode, the Hound says, "Everything before the "but" is horsesh!t.
This stuff is strange. Redis/memcached; hash source ip + body of the request - store in cache with sliding expiration of whatever; if found, log and don‚Äôt process....
That's some bad advice. 
I tried ImageSharp, but the issue is I need to specifically be able to create a 2byte black and white bitmap, where I couldn't get ImageSharp to do anything like that. But I didn't try SkiaSharp. I'll give that a look over. Thanks!
Which is a huge shame, it keeps us from porting many projects over to core. No, rewriting from scratch to rest isn't an option. That involves rewriting the consumers of the service to the new format too. If core is aimed at reducing server side cost, not allowing server side wcf compatibility is foolish
Yeah... Though this would probably be the only standard library feature that doesn't "just work" eg due to numerical robustness issues. Would be curious to know how java standardizes it... 
I would use a VM. There are just so many more tools to work with VM's than dual booting, along with the added flexibility of having tools from both operating systems available.
Jesus, I'm rustier than I thought. I'll do some research on those points.
One question on the very last point, if you need to instantiate a large number of a very similar pattern, you would use a struct instead of a class? Why is this? Typically if I needed to make say 2000 of the same thing, say car, I'd just spin up a pile of POCOs and stuff them into an ArrayList&lt;car&gt; (or other appropriate container). What would be the reasoning for using structs here instead? 
Are you using WPF or Winforms? 
Cross-platform is one (highly promoted) benfit of using .Net Core. Though in reality, I don't think many companies have a business need for that use case. There are other benefits to using .Net Core on a Windows stack. Faster web routing, Improved MVC in ASP .Net Core classes, better dependency handling. Just to name a few.
It's not Microsoft's problem but still waiting for Oracle support!
I'm pretty sure it's WinForms.
My experience in 6 years of making WinForms controls is that you *never* derive from one of Microsoft's controls. There are bits and pieces of Button logic that affect painting through every event. Just derive from Control. You've already done most of the work if you've already overridden OnPaint. Control doesn't have any fancy hidden built-in paint logic to tangle with.
Docker A basic docker-compose.yml file version: "3" services: borkbot: restart: always image: microsoft/dotnet volumes: - /home/&lt;yourname&gt;/&lt;appname&gt;/app:/app command: ["dotnet", "/app/&lt;appname&gt;.dll"] Then just docker-compose up -d
I don't think .net core was designed to reduce server cost. It was designed to be cross platform and (for now) they didn't think wcf server support was important enough to port.
Are you using HttpClient?
what about wcf behaviors?
Whatever you do... just ensure you triple / the top of the function so that it builds that auto documentation. On the variable in question go into detail WTF is going on. Remarks could be used to go in depth as to why.
can't argue with that have an upvote
I think the first question I would ask is... What do you want it to output? Then we can make the function to do that. As a side note In C# a List&lt;T&gt; is a wrapper around an Array List which is a wrapper around an Array. It adds the ability to add, remove, insert, and more. Arrays are immutable so once they are made they can't be resized which is why these wrappers exist to make life easy. Once we have the desired output we can figure out how to serialize the data into what you want. You could serialize to a comma separated string, a json string, or what ever types you are familiar with that can work accross the boundaries of the languages. You could call string.Join(",", x.ToArray()) to get a comma separated string of thoes ints. You could create a function that has a for each loop that just concatenates your list into a string in what ever manner you want. You could get the Newtonsoft JSON NuGet package and serialize the the list as JSON so that it is standardized.
 Great! :) I'm glad you were able to get it working. 
 If you go with Ubuntu, go with a slighter older version (16.04 for example). 17.* have had a lot of issues with graphical drivers and not loading.
I set up a VM using virtual box and loaded Ubuntu 16.04 LTS. As mentioned above, that is likely your path of least resistance. I set mineup for python and Django development and to learn Linux a bit more. Also set up a copy of SQL server to play with and will get to .net core next! Good luck!
A sort of Anti-Pattern I've seen involves using `IList` instead of `IEnumerable` to enforce query execution. Since `IQueryable` inherits from `IEnumerable`, it can be passed out without evaluating against a DB; you have to do the `.ToList()` to get an `IList`. (Not saying this is a great thing...)
This is implemented by the DWM, the display window manager. You would need to import the public API of it using p/invoke. Note that most of it's functionality is NOT exposed as part of a stable API, so you would need to rely on internal functions that aren't really meant for third party programmers to use and might change with each windows update. I am not sure if the color query is public, I worked with it back in the windows 7 days, where I had to use undocumented API endpoints to control the aero glass colors.
Something to note about Hungarian notation, as in the real Hungarian notation, is that it's purpose was to add more information. For example, let's say you needed the length and width of something. Easy right, call it `float length` and `float width`. Oh wait, is that in meters? Feet? Inches? With Hungarian notation you would name your variables `ft_length` and `ft_inches` to make it clear. In .NET we prefer longer names and no underscores, so instead we would probably use `lengthFeet` and `widthFeet`. *** In your case, calling it `priceSting` to distinguish it from `price` is not really Hungarian notation because you already knew it was a string. But I would still use those names because what else would you call it. 
Not bad IMO. Looks like it can be used for comp-geo stuff.
Well a definition of duplicate request is ‚Äòsame payload, same ip, same cred‚Äô. And then lock or no lock, it has to run for a set period of time. What you are doing is unsetting it when stuff like talking to externals is done... I don‚Äôt know of any cloud provider that offers managed ignite, whereas redis and memcached are available
I am using WinForms.
Whatever you choose, just be consistent. 
I do agree with going with LTS builds, but that statement isn't actually true. Most arnt dealing with graphics issues, especially not in virtual machines. And even there, you just change your desktop environments. That being said, for easy up and go, Ubuntu, Devian or CentOS for the enterprise feel, all nearly the same dotnet core experience.
I've made a `BlockingDetector` package to output warnings to the logs when code blocks: https://github.com/benaadams/Ben.BlockingDetector
Beta is available http://www.oracle.com/technetwork/topics/dotnet/downloads/odpnetcorebeta-4077982.html
Gm has a batch command that allows you to start a process once for the lifetime of the application and drive it over stdin. It feels clunky, but it‚Äôs fast as hell, and you can hide most of it behind nice abstractions. 
Yes, thanks, but it's a beta, and they are "planning" on launching in Q3. Sigh. Only alternative is expensive third party drivers. 
If he's asking to dual boot, I assume it's his computer, not a company. Even though I agree, build servers, etc, wouldn't have graphics drivers in the first place, most home computers do, and if it's Nvidia, 17.10 is garbage ATM for them
As Slypenslyde suggested, derive from Control and override OnPaint and all the other events that you need to override depending on the control you want to make such as hovering, clicking, etc. You're going to have to make flags for hovering and custom paint functions for all of the overridden events, but at least it won't conflict with the base Button's events.
We are using centOS 7 in our 23 servers to deploy our API‚Äôs and man.. it‚Äôs a breeze. We also have a linux agent on our Teamcity CI. 
You can use WSL
I see. Licensing it is fully your choice and I respect that, but from my perspective, it makes me lose the interest in the library altogether and the custom licensing option doesn't really help. Licensing can bring a lot of hurdles, so I prefer libraries with more permissive licenses (such as MIT), because I can start playing with them, without the worry that I won't be able to put them into my projects if they're good. Having to make a custom inquiry for a separate license, figure out what that entails and even pay for its use is something I'd do only if there was absolutely no better alternative, but most of the times I just go away and find something else or write my own solution.
I've derived for Control and it's working just fine now. Thank you so much for your help!
There's nothing *wrong* with using class instances in that case, but creating 2000 instances causes 2000 separate allocations, which can harmful to performance. If the objects are _long-lived_ (in other words, they will exist for more than a second) it's not so bad, but if you allocate and throw away these lists all the time, it causes unnecessary work for the garbage collector to clean everything up. If you have an array containing 2000 structs instead, it's just one big allocation. If the list contains 2000 instances of a reference type it will actually contain 2000 pointers to 2000 separate memory locations. The objects are not stored linearly in memory, so looping through the list (and accessing each item) will not take advantage of the [CPU cache](https://en.wikipedia.org/wiki/CPU_cache). Of course, these are just best practises for consistent performance. Unless you're working on games, mobile apps, high-end UI applications, server frameworks or other real-time things, these don't matter that much. Structs are practically always superior performance-wise, but the benefits are relatively small for small data sets and typical applications. Working with structs can be unwieldy, because most of the standard library doesn't support `in/ref` yet. And they don't support inheritance, which can be an issue.
What do you mean when you sa flags? Could you give an example?
Docker
Here's where I found them most useful. An int is 32-bits. You need some data structure that requires 4 numbers, but you don't need the range of an int. You can use bitwise operations to treat the 32-bit int as 4 8-bit variables: the first 8-bits could be used for one thing, the next 8-bits could be used for another thing, etc. That way, you can have 4 different variables packed into the space of a single int, without having to use 4 32-bit ints. 32-bits vs 128-bits (4 bytes vs 16 bytes) doesn't sound like a lot, but you can cram more of them into cache. If you need thousands of them, it starts to add up. This helps a lot when iterating over an array, because value types are all packed together in memory, which makes the CPU's job of pre-fetching and caching much easier. However, doing bitwise operations is kinda clunky. Not only that, but the variables aren't named. You start introducing magic numbers, or what would look like magic numbers to other people. Instead, you could simply define a struct. The struct could have 4 bytes (the byte data type) in it, and therefore would be 32-bits, the same size as an int. However, you can name the bytes, and you can perform regular operations with them. Structs are a much easier way to pack data, primarily because you don't have any overhead like classes. However, the catch is that you distribute copies of them, which can introduce bugs if you aren't careful.
Have you defined the types of current, second, charArray1 and charArray2?
Removed: Rule 4. Please provide a description of the desired behaviour and the currently observed behaviour.
I think we are in agreement on most points. Thought I have worked with code with pervasive use of Immutable*&lt;T&gt; values and it gives you some peace of mind when passing around things between threads in a highly concurrent application, something I don't think IEnumerable and the other base data structures give you. The problem with understanding how immutable collections work is much harder and I don't know how to solve that ‚Äì I have had misconceptions about some other features and it is very hard to fix if you don't think you have any misconceptions. I think experimenting, reading (especially documentation) and trying to learn more can help here. I agree that your example just hides a problem and that it is a bad solution. And thanks, it is nice to hear someone else's opinions about such matters.
Why not use a format like json to pass data between two API's?
There's nothing preventing you from trying the library out and seeing if it fits your use case. As it is, ADL is the only complete solution for the problems it solves. 
Calling .ToList gives you a List&lt;T&gt;.
My guess would be that the value is stored somewhere in the registry. Once you find the key look at the following SO answer to see how to retrieve the value in your code: https://stackoverflow.com/a/18234755/1801219 
&gt; I believe you mean PublicOrProtectedProperty because public fields are a big no-no. No they aren't. In particular, public readonly fields are fine, and in some cases regular fields are fine as well. It depends.
Doesn't work in C#
The convention we‚Äôve been using is: - use a method when further processing is required to return the result - use a read-only property to return a value which was already processed An exception to this rule is lazy-loading for properties.
That's actually what I settled on in this case as well. Thanks!
Noted, thanks again. Maybe I'm old fashioned (or the stack allocates more memory than I thought) but if I'm spinning up a large and non-predetermined number of structs isn't there an overflow risk? Very curious about this topic as a whole, I've always had that idea the heap is the place for large/unpredictable/mutable data and the stack was more for control variables or frequently accessed and predictable things. Stack is no doubt faster, just tiny (I thought). Going to play with that a it and see if I can figure out exactly how much stack memory gets alotted to a thread, I've got a few places I can probably leverage the stack a bit better if I've got enough.
Sorry everyone, after I left work I neglected the thread. I am but a lowly undergraduate researcher. Thank you everyone for the replies! I am now trying those solutions suggested below, specifically serializing the C# output as a JSON object!
No, it does not have to be IList, to be honest, I wanted a python type list (i.e. x = []) while using my C/C++ knowledge of constructors and building a vector/array/list with predefined elements, and that's what google yielded. Thank you for the information!
Going to try this! 
Absolutely, great idea. As I reported to /u/am385 reported above, I am going to try this! Thank you!
I wasn't able to get a working Orleans clster going last time I tried - you need various datastores etc. to be set up correctly.
This. My first project in my first job as a developer was to add some features to an API written in PHP. My first day on the job was the first time I had ever seen PHP. Remembering that I was once told, ‚ÄúIt‚Äôs not what you know and it‚Äôs not what you don‚Äôt know, it‚Äôs what you know how to find out,‚Äù so I set to the Googler. It all worked out. I think a book can help to get the basic gist of a language, it‚Äôs conventions, syntax, best practices, etc but at some point you just gotta get on the bike and ride.
Yep agree with this too... it's a much clearer at-a-glance statement of both the type and the intent
As long as the list can be observed without causing a shuffle, I don't see an issue with it. If the list does get shuffled by accessing its members, that seems like a recipe for mayhem (even without IList)
It is just an example :), but he breaks all the expectations, that every sane person might have. So list[i] == list[i] could return false. But even in your version I do not see the advantage, just the danger that someone will use ShufflingList by mistake and will kill me afterwards... 
[From the MSDN description](https://msdn.microsoft.com/en-us/library/5y536ey6(v=vs.110).aspx) &gt; Represents a collection of objects that can be individually accessed by index. I think the critical part is that you can have the add method going around shuffling things or removing items doing the same. If you get an IList in a method, and that IList is a shuffling list, you expect things to be in order - because that's how an IList works. If you want a ShufflingList, I'd recommend just using IEnumerable. If that doesn't work for you (because there's additional methods you want to implement with a ShufflingList that exist in IList but not IEnumerable), then extend IEnumerable.
Does the indexer getter cause a shuffle? That's really weird no matter what.
&gt; than "discountAsString" Is that the discount value or discount code? It's just as confusing. If you want to remove confusions like these you should create wrapper types. public struct DiscountCode : IEquatable&lt;DiscountCode&gt; { private readonly string value; // Lots and lots of boilerplate here // Should be massively improved by record types } public Item PriceDiscount(Item itemToDiscount, DiscountCode discount); public Item PriceDiscount(Item itemToDiscount, decimal discountAmount);
Thank you, the hunt begins
&gt; So list[i] == list[i] could return false. If that is true, then it is absolutely wrong to implement IList - because it breaks the contract that IList represents.
What I really want to know, what is the use case for this sort of class?
I don't think it said that at first 
I would name it according to the purpose e.g., if the string representation is there because it's been formatted according to locale rules and ready to be printed, I would call it `displayPrice` or `formattedPrice`. I don't think including the type information is intrinsically useful when you can reasonably expect that an editor will lookup and provide that information, and warn you if there is a mismatch.
A good and consistent naming scheme is very importantif your code needs to be shared with and understood by others.
The problem is he is incredibly smart and his code works everytime at 100% ... He wouldn't break the LSP or your IDog/ICat problem... There is nothing wrong with his code, you can point out. IList interface doesn't specify, that indexer works in that "normal" way... Everyone expects it, except him... Debugging his code is a living hell :)
&gt; you expect things to be in order - because that's how an IList works. I don't think that's implied in its definition. It's however implied that accessing by index will be stable, at least as long as you don't do any other modifications.
A ShufflingList sounds like bad news to begin with. Are you controlling the enumeration process? Because I foresee one day, when enumerating one of those, that it decides to swap two elements and break the program. Pretty nasty to mess with. Your list should be separate from your shuffling algorithm. You could have the ShufflingList&lt;T&gt; hold onto a List&lt;T&gt;, and do the shuffling. Whenever you want to use the list, you have some accessor like getList or something, which *copies* the list (use toList or something, make sure to lock access to the internal list to prevent shuffling while this is happening) into a new one and then returns it. Is there a strong reason the list should be shuffling itself?
Liskov Substitution Principle: &gt; "objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program" so no. bad design.
Yeah I agree with you at 110 %, but where is that contract specified? It just in our heads, I can't find any line in the documentation (english is not my native language, but...), which he breaks. It's just an example, most of the time it's more subtle... Our documentation looks more like mathematical theorems and proofs because of him... I guess it's just our incompatibility... I am glad that everyone sees it in the same way :) ... In the end it might help me to be more precise... 
In principle, I don't think there'd be an issue if e.g. adding an item to the list causes to to be entered at a random spot (or shuffles the whole list again), even if that overrides the exisitng IList methods. Lists are supposed to work regardless of the order of their elements.
To continue off of this. If the indexer property always returns the same value when called multiple times with the same index, then yes. Otherwise no. if(list[0] != list[0]) then don't do it. var timestampItem1 = list[0]; list.shuffle(); var timestampItem2 = list[0]; this explicit action in between means that the values do not have to be the same. 
Fundamentally, the indexer "[]" is defined by "get;" and "set;" methods. It's absolutely bad practice to cause mutation as a result of calling a "get;" accessor. It should be side-effect (at least in terms of meaningful state) free. That's a fundamental of software design, and not something you would specify in the definition of a given interface.
You may or may not know this, but there's a fairly solid convention on what you call different kinds of collections/enumerables based on what they do. I mention this because this, to me, sounds more like a Bag than a List - if you look around you will find that term used for a collection where the count of each element is preserved, but the order isn't. A list, like an array has a stable order and quantity. A set preserves neither the amount or ordering.
Authentication on that site is handled by some kind of Microsoft-based telemetry system I don't recognize, so the prime suspect would be any adblocker you're running. If you see any scripts or cookies on the on the www.codehunt.com or *.microsoft.com domains, try whitelisting them and see if that changes anything.
A good replacement for Bower as the default package manager. Now that projects like Bootstrap are moving away from Bower, it's being a lot more complicated working with them. Just read [this thread](https://www.reddit.com/r/csharp/comments/815qqi/how_to_add_bootstrap_4_to_aspnet_core_project/) on how much of a shitshow it can be now.
Imagine that someone from C# team changes implementation of List&lt;T&gt; to randomly shuffle, when removing and adding items. Would all your programs really work fine afterwards?
No. Why is that relevant?
I expect that if I call list.Add(obj), I can then call list[list.Count - 1] and get the object I just added back.
&gt; he is incredibly smart &gt; Debugging his code is a living hell Writing complicated code does not make someone smart. If it's a living hell because it's so difficult to read or because of unintended consequences, then it's bad code. A big factor in code quality is maintainability. And it sounds like this person does not write maintainable code. If you can solve complex problems with simple and easy to understand code, then you're smart.
If you use IList&lt;T&gt; and follow LSP, they should work
Because that's exactly what happens :) My method expects IList&lt;T&gt; and from definition of LSP it shouldn't matter, if you give me List&lt;T&gt; or ShufflingList&lt;T&gt; ... 
Maybe a card game of some sort?
Wouldn't it just be more advisable to create a wrapper for a list?
I knew a kid in college who was incredibly smart, but generally bad at writing SOLID, readable code. He would come up with really clever, performant solutions to complex graphics &amp; physics problems. He also had Tourretes, which led to variables being named... creatively.
My only guess, but even still your data structures should be storing things deterministically, and you should shuffle as a well-defined operation. Something as bad as `list[i] == list[i] // might be false` makes no sense.
Enums are usually meta representations of "stuff". You use them when it makes sense to list all the members of a category of object. In the wild that'll usually be something you abstracted away and don't want to access by say a public property. You might enumerate all your primary ViewModels in an Mvvm app. You might enumerate all the monster types in your cashgrab monstersummon app. You might enumerate anything finite that'd be copy and pasted over and over and instead call it via a factory(enum.specific) or IValueConverter(enum.specific). Enums are seldomly used alone. They are just a handy contract for meta references to objects. An abstract reference doesn't do you any good unless you also implement stuff that can handle them :)
Agreed.
Don't confuse how you calculate a value with what it is used for. If I rewrite C# so every assigned int value is going to be randomized, many programs will obviously break. But that doesn't mean that YOUR application isn't allowed to randomize an int when you need a randomized value. LSP dictates that a derived class shouldn't rely on _not allowing_ using a method that is otherwise usable in the base class. If it works in the base class, it should work in the derived class. So if BaseClass has an IntProp, so sjould DerivedClass. But LSP doesn't prohibit changing how the int prop is calculated. If Employee has a Wage, then Manager : Employee should have a wage too. But an employees wage might be calculated differently (hours worked * minimum wage) from a Manager (fixed monthly wage). The same is true of your IList and IShuffledList. As long as they expose the same properties and methods, _even though their value may be calculated differently_ , is a valid inheritance as far as LSP is concerned. But that is not the issue here. Your shuffled list is still just a list. Whether the items are still in the same order as before or not is irrelevant. However, if accessing a list member reshuffles the list, while you're still adhering to the interface of an IList, the **behavior** is going to be erratic, **regardless** of whether it violates SRP or not.
The name is fine, but might be unnecessary. Are the prices being stored as strings or is that just from data input? It's usually a better idea to normalize the data to a number right away. Also, use TryParse instead because you're going to crash if you try to parse on a bad number. 
Before "add" and after "delete" I swap some random items. It really doesn't matter (just an example), but my point is : "Behavior is different so I shouldn't implement IList, because I could break your code (as you said i would)"
Of course, but it shouldn't stop you from writing code. Beginners should focus on writing functioning code more than respecting all the guidelines.
That‚Äôs probably not a good expectation. Think about a priority list, or any other list type where insertion doesn‚Äôt necessarily happen at the end. 
I am not going to change C# implementation obviously :) I was just trying to show you, that you have probably some "hidden" expectation in your code how IList works :) ... you probably expect standard List&lt;T&gt; implementation ("without some crazy shuffling"), if I give you ShufflingList&lt;T&gt;, your code breaks.... So I shouldn't be allowed to give you my ShufflingList&lt;T&gt;, so therefore I shouldn't implement IList&lt;T&gt;
You can get around the problem by converting the numbers to integers before doing operations on it. int aInt = (int)(a*100); int bInt = (int)(b*100); int cInt = aInt - bInt; double c = cInt/100; But obviously this won't be suitable for heavy mathematics such graphics. This is one reason I like to store prices as integers instead of decimals. 
There is a difference between `float` and `decimal` numbers. The former is a base-2 representation and the latter is a base-10. The latter generally only has issues with irrational numbers.
I'm following /u/xxpx's SO link with your key but that key is null `Registry.LocalMachine.OpenSubKey(@"HKEY_CURRENT_USER\Software\Microsoft\Windows\DWM\ColorPrevalence")` This stuff is all new to me
Well, if you need the list to retain the order of its elements, then you should not use IList in my opinion, because that interface does not make that guarantee. You can however depend on List to have this behavior, because that is how the implementation works. So if you modified the behavior of List, then that would be a breaking change obviously. But if your custom (and valid) implementation of IList breaks a method, then that method has an assumption on the behavior of IList, that IList does not guarantee, and that is a different matter.
I think the argument works just as well if you use `.Insert(0, arg)` instead, which *is* part of the contract.
&gt; list[i] == list[i] could return false. &gt; but where is that contract specified? It just in our heads If he cannot understand that intuitively (which, I'm going to bet he does) he shouldn't be writing any more code for your code base. He's a liability. Nobody DOCUMENTED that because it's OBVIOUS. They didn't document that the methods shouldn't throw exceptions upon success, but I COULD do that. He should be implementing ICollection, not IList.
 Yeah, it was a quick and dirty example. I used Parse just for brevity.
You can't use a Span&lt;int&gt; to call that method. IMO, there's never a reason to declare a PInvoke with an array in the signature. Using a by-ref parameter (`ref int`) is always better, because it's more flexible. You can simply pass in a reference to the first array element, so it's usable in the same places (and more).
`Span&lt;T&gt;` has a `DangerousGetPinnableReference` method which can be used to obtain a pointer -- you don't need this `MemoryMarshal` type for that. Declaring a PInvoke like this: `public static extern int Sum(in int buffer, UIntPtr size);` might look safe (and not require the `unsafe` keyword), but it's not. Interop is unsafe by its nature, and your native code can still corrupt any data that it wants to -- using a pointer or a manged reference doesn't really make any difference. The runtime still needs to pass down a raw pointer to the PInvoke.
1. Server class should have a data member "App", which is a instance of application class since as you described: "There will only be one application per server.". 2. if your application class is using a Singleton design pattern which means you can create only one instance of each application. Having a server property in the application class is fine. But if not, you would better find a way to generate a unique signature for each instance of application to identify one instance from another. 
Your logic is a bit squiffy. Take a standard List. It's not thread safe which means that its behaviour is only "guaranteed" for a single thread. There's nothing in IList or its implemented interfaces (IEnumerable, ICollection) that say anything about guarantees of the sort you're talking about. I get what you're saying about Liskovs, that's a different discussion really. 
Have you tried reaching out to SciChart? This is not specific to a language, but more implementation issue. For example I can create the same type of chart to handle 1 million points, but my implementation will draw dots on an image and the display will be an image and not many controls drawn on the screen.
I can't resort to a image because they are real time charts. I think the issue was actually not disposing of a signalRProxy correctly. 
I could be wrong, but I think in OP's case the "shuffling" only happens during an Add(); operation.
 public int PopFirst(IList&lt;int&gt; list) { int firts = list[0]; list.RemoveAt(0); return first; } PopFirst(new List() {1,2,3,4}) // returns 1 PopFirst(new ThreadSafe() {1,2,3,4}) // return 1 PopFirst(new MyCrazyShufflingList() {1,2,3,4}) // returns 3
As far as I can see, InsertAt() is the only part of the IList contract that could potentially break with OP's ShufflingList. However, I think this is only the case depending on the *implementation*. The description is given as follows: &gt; Imagine a class ShufflingList&lt;T&gt;, which is basically just List&lt;T&gt;, that sometimes (nondeterministically = "with some probability") swaps two elements. To me, the issue of whether it breaks IList or not is down to *when* that "nondeterministic" swap happens. If it can happen during any kind of read operation then all bets are off - it's not in any way immutable and stuff will break. That's bad practice right there regardless of IList or not. However, if it only occurs during an operation that mutates the list in some way (i.e. Add()) then that's pretty reasonable. We all seem to be imagining that this is some kind of data model of a deck of cards and I think the analogy fits. Based on that, I would imagine that the shuffling will only happen during an Add() call. I would **not** expect any kind of shuffling to occour during an Insert() call. In this analogy, Add(), to me is akin to adding a card to a random part of the deck. Insert() is more akin to inserting a card into a specific part of the deck (i.e. 5th card down), no shuffling. Now, I'm not saying that this is the best way to make some kind of shuffled deck, but I can see where it would be possible to do while implementing IList in a way that isn't going to break anything.
At no point in any documentation does it ever claim that IList is an *ordered* list. Only that you can access the elements by an index. Add(T) adds an item to* the underlying collection*, not the list. There's nothing to suggest that calling Add(T) won't change the ordering or sorting of the list.
A list is supposed to behave like a list. The idea that it shuffles makes it NOT a list anymore. Arbitrary reordering of the whole collection should NOT be a side effect of the Add method, even if Add assigns a random index. Why isn't this implemented as an IDictionary&lt;int, Card&gt;, but you just get random shit, and the key is meaningless? The different collection types have specific meanings, and this is a betrayal of that meaning. You could make: IRandomizableList&lt;T&gt; : IList&lt;T&gt; { void Randomize(); } And suddenly it's not a stupid idea requiring pedantic justification, and infuriating other maintainers of the codebase.
Most companies hit having to require a degree due to H-1B problems. Just as an fyi if you see it other places. 
Leave it to [Jon Skeet](https://stackoverflow.com/questions/1790245/in-what-order-does-a-c-sharp-for-each-loop-iterate-over-a-listt/1790318#1790318) to provide a technically-correct-is-the-best-kind-of-correct answer. It's not guaranteed, either formally (by code) or informally (by the developers of the .Net FX). But the implementation of List&lt;T&gt; uses an array as the backing store, and that gets read sequentially according to the C# specification. And it would be insane for them to change that. But, strictly, no, IList&lt;T&gt; (and even List&lt;T&gt;) do not *guarantee* the indexing order. In that spirit, as long as the concrete class (e.g. ShufflingList&lt;T&gt;) implements IList&lt;T&gt; in a way that doesn't break at runtime, it should be fine. IList&lt;T&gt; should be able to be implemented as an array-backed list, a linked list, a doubly-linked list, or a reference table lookup (hashed or unhashed). Those all work very differently under-the-hood, and can (and do) reorder their elements. And in every instance, IList&lt;T&gt; should work the same. As for your question, "would all your programs using IList really work fine afterwards?" The answer is: yeah, probably. I can't think of a single one that expected any sorting or ordering. If you want sorting, use a DataView.
Thanks for the answers. I found a work-around for this. If you start the game (Codehunt.com --&gt; Play --&gt; Select Level), once you have entered a challenge, in the top left corner there are small errors pointing to left and right. You can click them to skip a level. It's not as fast as going directly to a specific level, but a lot faster than re-solving every challenge.
https://docs.microsoft.com/en-us/aspnet/core/security/authorization/secure-data maybe something like this. I haven't tried it myself but authorisation in core is quite new 
&gt; Why isn't this implemented as an IDictionary&lt;int, Card&gt;, but you just get random shit, and the key is meaningless? Maybe I'm missing some sarcasm here, but wouldn't that be *just as bad* and break the expectation of a Dictionary &gt; Arbitrary reordering of the whole collection should NOT be a side effect of the Add method I'm curious as to what your opinion of [SortedList](https://msdn.microsoft.com/en-us/library/system.collections.sortedlist\(v=vs.110\).aspx) is? By definition, it's a list that can be reordered when you add something to it. 
I think that third line shouldn't compile :) ... Basically if you're too "creative" with your class, do not implement IList :)
And there's nothing saying that it won't also delete all the other entries. Would that be a good implementation?
By definition, it's an IDictionary. The Key is a meaningful way to access a given item.
Sure it's based on IDictionary, but it's literally called Sorted**List**.
If you had a use-case for that behaviour, then sure why not. It still doesn't break any contract defined by IList. 
&gt; Leave it to Jon Skeet to provide a technically-correct-is-the-best-kind-of-correct answer. I'm confused. The answer you linked to wasn't by Grand Master Jon 'Skeet Skeet' Skeet. Too bad, he's the best.
Or you could create IList implementation based on astrology, that is adding duplicate value only when Venus conjuct Mars... 
Might be worth checking out the algorithm used by MimeKit to scan for the end of a line and see if it can be optimized to include \r and \r\n as well as \n. With a 64-bit machine you should be able to compare 8 bytes at a time instead of 1 byte like you are doing. https://jeffreystedfast.blogspot.com/2013/09/optimization-tips-tricks-used-by.html
I don't believe, that you didn't save some index value and used it multiple times to index this list... May I ask you for your github profile? :D
Yes it does, but it also forces an enumeration. In the case of db queries the query is deferred until the list is enumerated. So by calling ToList() you are forcing an active call to the database to happen and return that data and store it in memory. 
`Enumerable.LongCount` can be used to avoid the exception. Your numbers indicate to me, that the loop could maybe benefit from loop unrolling. Have you tried benchmarking it against a plain `wc -l`? Or together with `parallel`? http://www.rankfocus.com/use-cpu-cores-linux-commands/
Good job, but it doesn't matter; You can write something much better and much more useful. I challenge you. 
You're trying to do way too much in one line of code. That never goes well. It also makes debugging really hard. Try something like this: string line = Console.ReadLine(); then process the string variable "line" further: convert it to lower, convert it to a char array, take the first character (all in separate steps instead of in one line). You might also want to look into the StartsWith method. It's a lot simpler than what you're doing.
I love that stuff like this gets repeated: &gt; Carriage Return (\r) used in Macintosh Uh, yeah, in OS 9. Macs use LF. 
I have tried doing exactly that and the string will always return null and there is no prompt to enter input. i.e. Console.WriteLine("Enter input: "); string s = Console.ReadLine(); // This is seemingly skipped over s = s.ToLower(); // System.NullReferenceException thrown 
Why did he specify which HDD he had, but not CPU and RAM? I assume those would play a big role as well.
Using `Console.ReadKey().KeyChar` seems much more efficient here.
Well that's just weird. Make sure you have the project set as a Console Application. And make sure you only have "using System;" at the top. I can't think of any other libraries that have a Console object but if there is one and it also has a ReadLine() function that might explain it. I mean, what you have here is pretty much identical to the sample code here - https://www.dotnetperls.com/console-readline 
Yeah I'm at a complete loss. How do you check if it is set as a Console Application? When I created this project I swore I chose C# Console Application, but maybe I didn't?
Given that `File.ReadLines().LongCount()` seems to be within ~10% performance of the lovingly handcrafted character state machine, I'd probably just use the simple one, unless the whole value proposition of my business was to count lines in text files efficiently.
A guess would be that throughput time through the CPU and RAM are negligible to the access time on the HDD. 
Maybe, I'm no expert. But a low end Celeron CPU differs a lot in computational power compared to a high end one, like an i7 8700K. I remember having a laptop that would max out the CPU just by opening Notepad++. Anyway, just found it interesting.
it's a good expectation if `list.GetType().GetGenericTypeDefinition() == typeof(System.Collections.Generic.List&lt;&gt;)`. IMO it's a reasonnable expectation for any IList - you'll notice [SortedList](https://msdn.microsoft.com/en-us/library/system.collections.sortedlist\(v=vs.110\).aspx) does NOT implement `IList`, and a priority list should probably not implement it either.
what about a class named `NotAList` ? should it behave like a list ? the name does contain `List` :)
Oh, you!
Okay one more time :) ... Are you saying that this https://gist.github.com/PetrChudoba/145442ef450f9c4008758dcb2e23b0f9 is legit implementation of IList and your code would work with it without any problems? I would love to see :)
The problem with that sample is that the authorization is "locally" managed and there is no reference to ActiveDirectory/ADFS/LDAP/Azure. I found a sample on github that does authentication, but no authorization. https://github.com/microsoftgraph/aspnetcore-connect-sample
Seems like it would have been easier to read the docs and discover `LongCount()`
Clean your directory and do a COMPLETE rebuild of the solution. Place a breakpoint on every line.
Fair, but I've certainly saw a lot of "yay we can run our servers on Linux and remove windows licensing cost". As someone who is also responsible for our large IT budget, I'd be lying if I didn't say that's the most intriguing part of core to me. Otherwise core feels a lot like .net 2.0 days where lots of features are missing
Totally agree. Although I will posit that the skill of knowing before hand (that there are no further high-payoff optimizations to be made) _is_ _a_ _tricky_ _one_ _to_ _refine_.
The difference is in GC count. The effect of that won't show up in a simple benchmark, but could be important in a real application.
&gt; a simple summing up of the numbers shows us that the switch version executes 15% fewer statements than the if version. So there we go, we know which version to pick. You really don't. The number of statements executed has almost nothing to do with actual performance.
A very interesting article albeit he's only handling `LF`s and yes my implementation can surely benefit from unrolling. I may just try it for the pure fun of it. Thanks :-)
Correct. This task is a lot more I/O intensive than it is CPU intensive. Both techniques that he used only run at O(n) computational complexity, not counting garbage collection.
He did reference that in the article. 
He is referring to the number of atomic instructions that the compiler transforms each version into. For these simple conditional statements this is a pretty sure bet.
Ah. Glanced over that. 
Especially for conditional statements, it's not, since branch prediction can affect performance a lot.
&gt; How do you check if it is set as a Console Application? In VS, Project -&gt; Properties -&gt; Application, [look at "Output Type."](https://imgur.com/a/XiFzw)
Run it manually from a command prompt. If it works, the issue is likely with Visual Studio's launching of cmd.
Where exactly does the stack trace say it is throwing the exception from? Also, long shot, but do you have multiple threads running by chance? Maybe a different thread is throwing it?
&gt; I remember having a laptop that would max out the CPU just by opening Notepad++. The thing to keep an eye on is your current memory usage when you execute a task *and* where your swapfiles are located. With the kind of machine that has a Celeron, you're usually going to have less RAM and cheaper hard drives. So if your box has 2GB and is running at 1.8GB with your average loadout, then opening an app that pushes past the RAM limit is going to kick into swapping. ...and if you're swapping to a 5400rpm hard drive that's fragmented to hell, your box will slow to a crawl. 
Once you've detected if there's an LF using the fast method, then you can check if the previous byte is a CR. 
Windows Subsystem For Linux exists if you're on Windows 10 and up to date. I believe it mimics or exists as Ubuntu.
What code and input is before this? The input stream could be processing a previous new line that you entered likely from a Console.Read(). Keep in mind that Console.Read() and Console.ReadLine() are going to read from that stream - not necessarily from what happens after the call.
A line is an instance of the String class. The string class, internally, is a number (length) followed by the actual characters in the string. The ReadLines method goes through the file and creates these string objects itself, returning them to you. These string objects are allocated on the heap, which must be cleaned by the GC, taking up time. So creating these strings requires going through the each character anyway,but includes the addition work of copying them into these String objects and then throwing them away with the GC, and that work is considerable.
I think SIMD be used to achieve a similar optimisation without unsafe. Haven't ever used it though, so not sure how. 
But you could say that of any implementation of anything. I don‚Äôt think the interface concept covers this, and the discussion should revolve more around side-effects, especially if they are crazy and/or illogical.
Should IList refer to a contract where placement on Add is preserved? I‚Äôm not sure this should be so, but I could be wrong. 
Basically this is the 3 solution everyone should think about on the first place. And everyone would come out with that after coding in c# for several months. Would like to see some more clever stuff tbh.
I figured it out it had something to do with Visual Studios for Mac so it might have been the same issue. I switched to my Bootcamp partition and it worked normally. I still can't get it to work in the Mac IDE but in Windows everything works as expected.
You're right, I just didn't know that existed. I'm pretty fresh to C# since this for a class that teaches how to do the basics of the language.
&gt;Not only we improved the overall execution time but also we managed to be nice to the GC by not causing any collections. What is the GC improvement? I ask because overall execution time is ~5% drawn from exploding 4 lines of clean, elegant, framework code public long CountLinesReader(FileInfo file) { var lineCounter = 0L; using (var reader = new StreamReader(file.FullName)) while (reader.ReadLine() != null) lineCounter++; return lineCounter; } to a convoluted procedural loop-in-a-loop
The call to Console.Readline() should have the program wait for user input and the enter key to be pressed, but in my case it's not doing that. I tried it in a loop where it would print a prompt, call Console.Readline(), and then print what was entered and it would just print the prompts and without waiting for input. 
It looks like it was something like that. When running in Visual Studios for Mac it would bring up a console that was part of the IDE instead of a terminal window, where as when I run it in Visual Studios for Windows I actually get a separate cmd window.
Well I am now üòÖ
I get it. Thank you.
I've never used C# on a Mac, but [this StackOverflow post](https://stackoverflow.com/questions/40690871/visual-studio-mac-console-application?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa) has some information about settings for making the console work on a Mac which might be helpful...?
That code will allocate a string for each line. Depending on how long the lines are, it will likely also allocate additional char arrays to store characters in while building up these strings.
Efficient? It‚Äôs a different behavior! Read key will not wait for return to be typed. 
In general, I‚Äôd stick to ReadLine, for least surprising behavior for users. 
Does anyone actually use old macs now? I say just count the \n and there you go.
I think I've found a two example from Microsoft that should help your argument against this awful behaviour: Take a look at the [SortedList](https://msdn.microsoft.com/en-us/library/system.collections.sortedlist\(v=vs.110\).aspx) class in the .NET Framework. It's basically a list keeps itself sorted and the order of items changes when you add things to it. Did Microsoft allow accessing items based on an positional index? No, which is why they didn't implement IList. Similar case with [LinkedList](https://msdn.microsoft.com/en-us/library/he2s3bh7\(v=vs.110\).aspx). By adding an item you change the position of everything behind it. Did Microsoft implement IList? No. So at least Microsoft agrees that if the index changes when values of a collection are added or modified it's not an IList anymore. Furthermore, if a method does change the index it's explicitely mentioned and also describes how it should be modified, for example in [ICollection.Remove](https://msdn.microsoft.com/en-us/library/bye7h94w\(v=vs.110\).aspx) it's specifically stated that upon removing an item from a list, all following items must be moved up. So while it's never explicitely said that modifying or adding an item shouldn't change the index of existing items, it's more or less implied because: 1. Microsoft doesn't implement IList if their Lists break that convention. 2. Microsoft explicitely mentions if and how indexes are modified by methods. 3. Common sense. Even if that implementation would be technically correct it violates the rule to avoid side effects whenever possible.
But what about the common case of individual CR's in OS 9!?
Thank you, your answer is actually very helpful, and I will try to use your arguments :) ... But I am still baffled, I was obviously exaggerating, I come up with the craziest and most useless implementation I could imagine and top voted answer is "I don't see an issue with it" ... I don't know if they are just trolling or not ... 
It can be faster all it wants, it's still garbage (WCF, that is).
Its been some time since I did any WFC, is net-tcp with binary still a thing? I was always using http, but I recall claims that net-tcp binary was faster.
Bad bot
I'm working on a WCF project now; what's so bad about it?
Probably tons of work to get it right but would be huge for .NET. Third-party ones are alright, but official one would be something else.
Wow, thanks, I had no idea that a Linux system would have a server version
So why shouldn't the classes of the .NET framework also be open source? For what reason should I not what them to be open source? Or are you just parroting the same bullshit everybody else here is saying.
Quick question to help frame the troubleshooting: Does this only not work with your client's code, or has it ever worked correctly for you?
Are the other fields getting set properly? At first glance, the case of your xml elements don't match the case of the method parameters.
I believe you need a [message formatter](https://stackoverflow.com/questions/18511147/change-default-date-serialization-in-wcf). Or you could make that type a string and use datetime to parse it on the other side.
I still wish I knew wtf MS was thinking when designing that abomination. I just about lost my mind the first time I had to write a factory factory just to make a simple customization to how our communications worked. My life has never been better since deciding to never touch WCF ever again.
I would test with a svcutil generated client
It's still there, but of course that's not a very fair comparison.
Why don't you think its fair?
https://mva.microsoft.com. Microsoft Virtual Academy is an online resource created by Microsoft. I would start there (I wish I had) 
Because HTTP comes with an unavoidable overhead that you won't have with plain TCP sockets. And named pipes even eliminate the socket overhead.
I have a book called ‚Äúlearning c# programming with unity 3D‚Äù by Alex okita which is pretty good but it‚Äôs more of a focus on 3D. Not exactly what you want but it may help :/
Something this article doesn't bring up is how difficult it is to integrate a WCF service with .NET core. Was just trying to do this the other day and all I could get was a 404 from the WCF endpoint. No matter what I tried, always got a 404. Spun up the connection on an MVC 4 server, instantly worked. WCF is very difficult to use if you want to integrate with more modern frameworks.
I think its a feature that is worth including in a performance comparison. 
&gt; I may be wrong here, but I am thinking that simply dividing a number by 100 wouldn't raise any precision errors. It ultimately depends on the precision of the floating-point type you convert to. * If you convert to `float`, you will get a lot of mismatches (`2,071,986,175 mismatches` for 0..MaxValue, and `4,236,248 mismatches` for 0..21474836). * If you convert to `double`, you will get no mismatches for `int`, but a number of them for `long` Using `int` also restricts you to numbers which are less than `21,474,836`, or the multiply by 100 will cause you to lose information. 
This is very much true. I tried to include ASP.NET Core running on .NET Core, but WCF was of course impossible. And there were issues with BenchmarkDotNet when I tried to do that.
&gt; Configuration is overly complex, Very common anti-pattern in the Enterprise Software world. It's basically a Cthulu-worshipping death cult. "Writing code is so hard, so our product simplifies your life by being able to do anything and everything simply by changing the configuration!!!!!" And then the configuration becomes a Turing-complete meta-language all of its own and you're writing bad scripting code in config files instead of your favorite compiled language.
It's not impossible, you just have to use some sort of 3rd party connector and manually configure the whole thing. You can't rely on Visual Studio's code generation because it just doesn't work... I think the problem with ours was the WCF service was on an https endpoint. When we ran it locally it worked great, but then trying to connect to the dev environment always failed with a 404...
It's basically the definition of "enterprise-grade".
Debatable. Reading from disk is going to be slower than counting the bytes on a single core. You‚Äôd need some pretty amazing IO to be faster than the counting operation. 
&gt;Using int also restricts you to numbers which are less than 21,474,836, or the multiply by 100 will cause you to lose information. Often not really a problem if you're just doing math for most pricing on items though. But you make some good points. Thanks.
According to https://en.wikipedia.org/wiki/Solid-state_drive ssd could transfer at 6GB/sec. so the 37GB file can be read in under 7 seconds. there's not much parallelism overhead as counting new lines in each chunk is independent work. I'd think it will be close to linear speed up depending on # of cores. 
it is actually simple. Would I ever logically use data binding? -&gt; property.
Ah sweet. But you can already get code coverage for .NET Standard/.NET Core stuff with dotCover (though it costs money).
Gigabit. 6 Gigabit. It‚Äôs 600MB/s for most sequential on SATA. M.2 and SAS can go higher but those disks go up to 2GB/s. 
It‚Äôs such an overengineered _mess_. I made the mistake in 2011 to think, hey, .NET 2.0‚Äòs SOAP (`System.Web.Services`, Web Service Enhancements, etc.) is getting really old; let‚Äôs move to the newer Microsoft stack of WCF! Never again. Turns out instead of resolving some of the weird complexity of SOAP, they made it far worse by introducing lots of what-ifs you don‚Äôt need in real-world use. Briefly went with ServiceStack. Now Web API. I miss the easy ways SOAP generated type-safe (with quite a few asterisks) client code, and even allowed debugging (again, with asterisks), but I don‚Äôt miss WCF.
True 
Effectively WCF is used with NetTcpBinding and binary serialization in production, it's unfair to HTTP but closer to real world.
OpenCover is free and works with .NET Core as long as you're building on Windows, although it takes [a little setup](https://github.com/CreateAndFake/CreateAndFake/blob/master/build/testCoverage.cmd) and needs ReportGenerator so you can actually read it. A quick peak at Coverlet looks *a lot* easier to use, and even outputs to OpenCover format, so I know I can use it with my code coverage service. I might switch sometime as it matures. It still needs features like merging outputs and such, but I like what I see so far with a quick glance.
I think WCF can be as complex or as simple as you require, thats the beauty of it. I think a lot of people drank the JsonREST cool web dev koolaid and threw WCF out as overly complex. I've spun up basic HTTP comms with a few lines, as well as message-level and transport security without too many problems. SOAP is a good set of standards and is meant to leverage XML to promote platform agnostic communications. I'm watching the WCF Core project with interest. 
It's a good fun isn't it! Couple of points to remember though: * I am trying to avoid unsafe however by using unsafe you are essentially eliminating array bound checking which is a huge perf gain. * I am checking for `\r\n`, `\r` and `\n` My implementation can surely benefit from eliminating bound checking as well as unrolling the for loop. I will update the article with those improvements.
ASP.NET -- Very legacy. Basically web-forms. ASP.NET MVC -- Mainstream. ASP.NET Core -- What a lot of people are moving to because of it's cross-platform and Docker support 
not my preferred method either but when you have a deadline and it works for some reason.
i sure am left wonder that, after reading your 3 paragraph rant about how people without degrees are always good and people with degrees cant solve fizzbuzz, if you have a degree or not ...
It has a steep learning curve. If you need all you need is a is a simple end point avoid WCF at all cost. If you need lots of flexibility and control down forcing operations to run on single threads, support both rest and soap on a single end point, if you don't want to spin up an asp.net site, but want it to be with in a service. WCF's flexibility is endless with goes hand in hand with it's complicity.
Can I get a link to the input data? I'd love to have a go.
https://github.com/SteveGilham/altcover is a thing too, and has been for a while. Works on the same principle.
You're going to end up learning basically all of them, but I'd go with MVC and Core, with heavier focus on MVC since it's already mainstream.
Good points. I can confirm the dictionary doesn't have any null fields in it. I am using mostly synchronous functions. A thread pool is also ensuring that there aren't any other tasks trying to enter function in the `Manager`class out of order, and I checked my threads window just in case.
MVC is just a framework available in numerous ASP.NET versions. From a usage standpoint ASP.NET Core (sometimes written AspNetCore to avoid confusion as you can run AspNetCore _not_ using .NET Core) is similar, just a newer version. However it was rebuilt from the ground up targeting .NET Core, can run cross platform, and is a good bit more efficient. What you learn doesn't really matter as they're all fairly similar. I'd definitely learn using Visual Studio though and it's still much more common than VS Code.
That isn't valid code?
Asp.Net is just the term for the kind of technology this is for. Unlike what xampl9 said, asp.net != asp.net webforms, the words don't mean the same thing. WebForms is WebForms. Anyway, Asp.Net is C#s system for developing websites. It has had many flavors over the year. - WebForms: Legacy, do not use. It was a way of making "desktop" application developers into web developers. - MVC: Model, View, Controller. It is a newer methodology that allows you to separate concerns. You write normal HTML, CSS, Typescript, whatever as your front end, while your backend handles the data. This is preferred, it gives you a separation of concerns. - Asp.Net Core is the newest version of Asp.Net. By default (and recommended), it is to be used with .Net Core, microsofts open-source, performant, new .Net Framework. (even though it can be used with the .Net Framework). MVC is not specific to Asp.Net, it's just an ideology that is a template for Asp.Net. It can be used in both Asp.Net Core or Asp.Net. With Asp.Net Core, you get the options of blank, mvc, or webapi. MVC is going to create view for you. This is a part of your application. If you want to take it a step farther in terms of separation of concerns, you can use just webapi. This is basically just the MC part of MVC. Views are controlled by an outer application such as an angular, or vue app. Then you can have a UI team, and a backend team, that don't have to mesh together and constantly break eachother and helps alleviate monolothic applications. So, tldr; Asp.Net Core is new - this is where the jobs will be going. Asp.Net (Framework Version) - this is where the current jobs are. MVC - Ideology, can be used in either. Suggested: Learn Asp.Net Core using either MVC (if you're just starting web dev) or webapi and build a front-end separate from the backend.
Have you tried putting a break point in the lambda (either right-click the `existing.Value.Connected == true` expression -&gt; Breakpoint -&gt; Insert Breakpoint, or turn it into a multi-line lambda and add a breakpoint normally) and validated that the `existing` (and `existing.Value` and `existing.Value.Connected`) entries are what you expected?
Have you tried putting a break point in the lambda (either right-click the `existing.Value.Connected == true` expression -&gt; Breakpoint -&gt; Insert Breakpoint, or turn it into a multi-line lambda and add a breakpoint normally) and validated that the `existing` (and `existing.Value` and `existing.Value.Connected`) entries are what you expected?
I assume they're talking about the code you had before your edit where you had something like: `=&gt; bool userAlreadyConnected = this._sessions.Any(.......);` before you changed it to a `return`. Even now, `private bool UserAlreadyConnected() =&gt; return this._sessions.Any(......);` is invalid code. The `return` use here is incorrect for lambda method syntax. Perhaps you should post the _actual_ method code as you have it?
 This is very hard to answer, as it depends on the resource. For most things, you can do policies: https://docs.microsoft.com/en-us/aspnet/core/security/authorization/policies But in your scenario, assuming you should only be able to edit yourself, yes, you would want to do this as a claim, 
Check gamekedo / youtube / code your 1st game on udemy (its free btw) It might help you out Cheers
When it breaks on `existing.Value.Connected == true`, you should be able to inspect the value of `.Connected` in the debugger without entering the `Value` property. I don't even think you can "enter" the `Value` property since it would be in the `KeyValuePair&lt;TKey, TValue&gt;` type.
I feel that the mistake here is using hand written xml instead of a WCF client. If you have clients who for some reason must do this, you should insist that they validate issues with a WCF client. 
Yes it is in the `KeyValuePair&lt;Tkey, TValue&gt;` type, though I have it explicitly cast to `Details` as a custom type on the `TValue`. The custom type contains a bool and two strings as fields, namely `.Connected` being the bool. You can see here how it's populated as well during the break point: [screenshot](https://i.imgur.com/zLtPSVe.png)
&gt; Include a user id in the JWT payload and check for it before allowing to execute requests like this on the server? That's what I do. Maybe there's a better way, but this seemed like the most obvious way.
Is it too much over head try private bool UserAlreadyConnected() =&gt; this._sessions.Values.ToList().Any(...) 
Aha... found it. Once I broke the method out into multi-line statements, it became apparent that my debugging symbols aren't matching up with the actual assemblies. Thanks so much. 
Good idea, that's not too much overhead for me. I managed to sort it out though, thank you. :)
There is bounds checking in that the buffer size is 1byte larger so it is terminated with a LF byte. Whats so bad about unsafe? :D
lol, or json for that matter fml
This is added to a library package which can be used anywhere and in different contexts including inside _SQLServer_ or anywhere with a _CLR_ host, some of those hosts have strict rules when it comes to executing _unsafe_ code. But even that aside unsafe in general: * Avoids type checking * Bypasses security as strict object access rules are not followed * Increases the dev's responsibility to check for security issues I am not saying _unsafe_ should never be used but it's definitely not my first pick unless absolutely necessary.
I got ya one better, I had an RFID reader send me hexadecmial data as a string. This was not my misunderstanding of sockets, this was after a month of WTF and a conference call with their eng team. I still feel dirty having written the conversion class.
At work.
This is probably the most correct answer. You can set up your Authentication layer (i.e. middleware) to not just inspect the JWT for validity, but read values from it to determine who the user is and set it as the current user on the http context. You can do similar for roles that are set up in the JWT. If you want to get fancy you can do 'Claims'. Here's a not-terrible example I found with some searching: https://andrewlock.net/introduction-to-authentication-with-asp-net-core/ You can then use the Current User via the static User.Identity in a controller; This will have properties like claims/roles and username you can use before proceeding with an action.
Dude. Do some research. https://www.reddit.com/r/csharp/comments/8566w9/i_love_c_but_how_do_you_tolerate_that_its_not/dvv7gks/ The *.NET Compiler Lead* showed you every part that you're complaining about (As far as the source to .NET itself.) If you're ever curious enough about Someone Else's Library, there are always tools like Telerik JustDecompile and Jetbrains DotPeek (Both free) that can disassemble the compiled language back into C#.
 They have a GUI folder, so I would look there. What specifically are you asking? They used Windows Forms, so it's kind of old. You could learn WPF, or just modify what they already have. If you learn WPF (and MVVM), you could just take the logic out and apply it to the new UI.
I didn't need to do anything extra to the authentication middleware to get this working. I just set up an extension method that I can use like `User.Identity.GetId()`.
My goal is to have a program with a similar design to the windows 10 task manager/performance tab using HWMonitor to gather the hardware performance data. Specifically I'm having trouble modifying/working with an existing program and can not seem to find any help in this area.
Well this was a fun exercise...I've never used unsafe or pointers in c# before, but I like to see how fast things can be! I'll be very curious to see what speed improvements you can find with loop unrolling and still maintaining CLR safeties.
Okay, I got to this thread way too late, but.. https://github.com/bmbsqd/jil-mediaformatter is an example of how to do it. You'll want to read the JIL documentation on how to Configure it to handle things like nulls and dates formats. Also, while others screech "Premature optimization!" I agree but also disagree; changing out a JSON formatter can be very hazardous to any consumers of your API. Json.NET actually has an advantage in this regard; it is usually far less picky about certain things like nonuniform enum/datetime use by consumers. But that means if you switch later you wind up breaking consumers. Choosing up front means no surprises down the road. Also, in the case of JIL much of the speed increase is by lowering allocation (i.e. less GC Pressure). Less GC is good for the *every* request the Web API is processing, not just the one being serviced. So on one hand it can be premature, on the other hand if done early it is a cheap optimization that can be done in almost no time.
What you want to do is create a new form instead of a message box and then change the values in the UI thread from another thread by invoking. The message box is simply not designed to be used in this way and is thread locking.
Removed: Rule 4. I do not believe you can do that with the built in `MessageBox`. You'll have to create your own Window/Form and controls. If you create a custom form to house it in, the code to show the form in a non-blocking fashion is simply: MyForm f= new MyForm f.Show();
I've done this. I can't figure out how to transfer values between Form1 and Form2
Create a `public` (or `internal`) method on your `MyForm` class then call it. MyForm f = new MyForm(); f.Show(); f.UpdateText("Your Time Is: " + "\n" + label7.Text + label8.Text + label1.Text + label2.Text + label9.Text + label3.Text + label4.Text + label10.Text + label5.Text + label6.Text + "\n");
Not really. The whole point is to have a platform agnostic runtime. VS is on Windows and Mac OS and VSCode is on even more. It was never tied to VS. you could get msbuild.exe and do C# with a basic text editor. This all said. I love VS and VS Code. Maybe a bit biased.
I am a software engineer at Citrix Cloud, we build the tools, automation and platform which enables cloud.com. We are looking for c# developers with an interest in automation, or even better a background in devops, to join our team building tools &amp; platforms with technologies stacks like Kubernetes and Service Fabric. As long as you want to automate all the things prior cloud/devops experience is not necessary. Competitive salary, great benefits and relocation offered. If the brief introduction above sounds interesting PM me a resume and we can setup a time to jump on zoom and have a chat, feel free to PM me with any questions. We are looking to turn around candidates very quickly so it will be zoom screen right to on-site and an offer. Locations would be Boston/Fort Lauderdale/Raleigh/possibly remote.
thanks
Good summary, but I warn against learning Learn Asp.Net Core first. The documentation sucks right now.
https://docs.microsoft.com/en-us/dotnet/csharp/quick-starts/
go to youtube, google "Mike Acton" and watch everything. That will give you some good base knowledge about memory. Then you can go learn more about garbage collection. 
Fair, I don't use razor so I can't speak for it. Haven't used it in years since old asp.net
Thank you for reply! Do we need to make an object pool myself or c# already has a class that we can use? Is it a collection like list and array or a static class with methods controlling the array or something else? Thank you :)
Thank you!
It depends on what you mean by big and it depends on what you mean by a lot. A single float takes up 4 bytes of memory so you could fit about 1 billion of them in 4 gigabytes of memory. So if each of array had 1 million floats, a decent modern PC would start running out of memory when you had somewhere between 1000 and 4000 of those arrays allocated depending on how much RAM you have and what other applications are competing for your system memory at the time. Now at that point windows will start paging some of your RAM out to a swap file on your hard drive so your program will keep working but your performance will nosedive. Eventually your program will just crash as you run our of memory. Now lets say you are allocating the array in the function new each time. When the function ends that array is no longer needed so the C# interpreter will try to reclaim that memory and reuse it the next time the program asks for a similar sized chunk of memory. In your particular use case where you are allocating the same size chunk every time that will probably work pretty well. Where you can run into issues is if you are allocating lots of pieces of memory of different sizes and you get what is referred to as memory fragmentation. With regards to the specifics of how good C# is at dealing with that, I really don't know. I suspect that if your memory usage pattern is stable enough it will work just fine for a long time (weeks or months) though you would probably see the overall application memory footprint gradually climb over time as the memory became more fragmented (again I don't know the specifics of how C#'s memory manager works but it seems likely). As for performance, using lots of memory generally doesn't slow down your program (of course, if you are using a lot of memory it probably means you are doing a complex task which will be slower by it's very nature anyway). There are some issues you can run into but memory access is pretty fast and consistent and not a problem unless you are really digging into some very serious optimisation.
I'm using it for toy projects and the random changes between it and the classic version are a pain in the ass. Thankfully I don't have to deal with it professionally. I stopped doing UI work when Silverlight died.
No, but you don't really need much. Create a static variable that holds a `ConcurrentQueue&lt;T&gt;`. It's thread safe so you'll never accidentally pull the same object twice. Just be really careful that you don't put something into the pool until you are 100% sure you aren't using it anymore.
seems like you did ok. companies test a lot of things at once. dont stress and overthink. 
Dont worry about the time aspect. At this point in your career (the very beginning of it), how long it takes to figure out how to do something and complete the task is the very bottom of priorities. Here's how this will work in the real world. You'll go into an interview, and they'll ask you one of these questions, like convert a number into Roman numerals. You won't do this in an IDE or VS. You won't even have a computer. You will need to do this on a white board. They likely won't care about the language. They want to know if you can figure things out. Basic algorythmic structure. Problem solving. Testing. What happens if the number is negative? What about if it's a float instead of an integer? What about if it's really really big? What the interviewer does NOT want, is for you to silently struggle at the whiteboard and start writing. What they DO want is you to engage. Ask questions. Gather requirements. Write pseudocode if you need to. Languages are easy. Programming is hard. They don't expect your code on a whiteboard to compile. Who cares. They expect you to be able to take a problem, figure it out as best you can, translate the solution to that problem into some sort of code, and defend it if necessary. If you're not asking questions, you failed. If you're not gathering requirements, you failed. However, if you ask questions, engage the interviewer, gather requirements, fully understand the problem, come up with some sort of solution, and able to represent that on a whiteboard, then you probably passed. There's a famous question something along the lines of "If you were to stack quarters, how much money would you need to reach the top of the Empire State building?" No one expects a correct answer. What they do expect is things like asking if the quarters are stacked on their ends or their faces. If the answer is faces, then you can assume a roll of quarters is like 3" long. A roll is $10. 4 rolls in a foot. 10 feet in a floor. The building is 100 floors tall, so the answer is 100*10*4*10, so $40,000. Is it right? Nope. But it's a hell of a lot closer than throwing your hands in the air and saying I dunno. In the real world, you are going to have problems to solve. Sometimes really hard ones. Your interviewer wants to find out if you can figure out a path to the answer. You don't necessarily need the answer, but you gotta know how to get there. Hope this helps.
Have you tried Visual Studio Code? 
VS Code is acceptable.
This is an excellent comment
Thank you so much for ur comment, kind sir! You all made my bad day a tad better to say the least :) I will keep on pursuing my game, and if new challenging projects arrive I'll try to embrace them with all I have. The only thing id ask for in return would be patience. Putting someone on a pedestal is not the way to go. At least for me it doesnt look like it. Also, a big thumbs up to this subreddit. I came in here thinking people would say I was not the brightest but you all made me cheer up with such positive comments and tips, so from the bottom of my heart, I thank you kindly!! &lt;3
&gt;The program will trigger this action several times in a frame Are you using this in a game context (Unity)? It does require fewer resources to re-use the array, but I would first check if the code is currently causing performance issues. There is no point changing your code to improve performance if the code isn't currently causing performance issues. I'm not sure, but I think you might create garbage when you create a new array and stop using it, so you may get less garbage collection if you re-use. If you are making a game, garbage collection avoidance can really improve performance.
1) Use a site like Pastebin for pasting code, not Imgur 2) Null Reference exceptions mean that you've written something like `Object.Property`, and the `Object` is null 3) Which line is the error on? On that line, can you see anything that matches the pattern I described above? If so, look at the item to the left of the "dot", and check that you've assigned it a value 4) Learn to use the Visual Studio debugging tools! I'm not familiar with Unity, but I imagine it works the same way as other C# projects, which means that when the exception occurs, you can actually hover the mouse over each item to see its current value. That will immediately show you which item is null 
Yes I have, but couldn't get it to work properly, may be that I'm a noob. Is the csharp plugin enough?
If you want more practice 'programming under pressure' look into TopCoder.com: https://www.topcoder.com/community/competitive-programming/
Line 24 has: public Text questionText; You never assign this variable in code, so presumably it is meant to be assigned in the Unity Inspector. Have you checked that this is being done?
You‚Äôll need the csharp plugin and create launch.json and task.json files (vs code should prompt you to create these). Have look at the extension‚Äôs project on github, they have a guide for setting up the debugger - https://github.com/OmniSharp/omnisharp-vscode/blob/master/debugger.md
okay so yeah i see now that Question text is null but im not quite sure how to give it a workable blank value.. normaly for strings or ints i set = ""; or =0; but im not sure what to do with that variable.
&gt; the error is apparently on line 34 but i feel like its linked to line 24 as well Yes, you've got it. On line 24, you've declared the `questionText` variable to be of type `Text`. I'm not sure what that data type is (is it a Unity thing? I said I don't know Unity), but like all objects where the type is a class, you need to initialise it before you use it. You would do that by writing, on line 24, something like: public Text questionText = new Text(); However (and again, I may be wrong on this, it may be a Unity thing I don't know about), another option might be to declare it a `string` rather than `Text`. In that case, you can assign it the value on line 34 without having to initialise it first, because the assignment would actually be initialising the variable. That's because if it was a `string`, you'd be assigning to the variable itself, rather than to a property of the variable such as `.questionText`. Hope that helps - hopefully someone else can chime in with some Unity-specific advice too.
Text is a Unity component. So you need to have a GameObject with a text component, and assign questionText to it. You can do create all this in code, but what you probably want to do is make the visual side of it in the editor, then just drag the Text component where you want the question to appear into the questionText property of the TriviaGameLoop component (ie your script).
Would be interested to see that compared to this and https://github.com/lucaslorentz/minicover as well 
You have to make sure that you know what you're doing though. Cause by putting your objects into this "pool" you're preventing the garbage collector from taking your objects. So you have to make sure you don't enqueue too much, and don't have more enqueuing than dequeuing, otherwise you'll run out of memory at some point
As a c# developer since .net 1.0, who has also interviewed potential hires before, I‚Äôd rather ask a developer with 1 year experience to write in pseudo code rather than something that compiles. I‚Äôd rather see how your brain works at problem solving than technical skills. It‚Äôs the lack of problem solving vs technical skills that cause the most delays (in my experience). Unfortunately some companies and managers use tests like these to weed out true-non programmers when they get a lot of resumes submitted. I‚Äôd say keep it up. You‚Äôll do fine. Always go for new experience, even if it‚Äôs not on the job. code code code in your spare time. Do some code kata a few times a week. Think of a small task, like those in the test, and just do it. You‚Äôve got the right mindset to be a coder so far. Keep at it. 
Very insightful, thank you
Ahoy Burger! Thanks for sharing ur opinion with me, mate! If you dont mind, since ur a senior at this I would like to ask you something. Right now Im still studying and working on my own 3D fps game in unity from scratch. Ive been applying to job offers as they come but sadly 80% of them come from shitty consulting teams. Since the worthy ones arent even looking for Junior progammers. Ive always been a dedicated and passionate guy but as of right now I feel kind of lost because going towards my favourite area is not worth it cause the opportunities are too few and in terms of general software engineering I already had to decline a few offers that came from consulting companies because they were that bad. I still dream that one day I'll find a friendly company with great fellas and a great working environment where theyll actually take the time to explain how their software's structure works and guide you towards being a computer enginneer and not just a progammer, I look at my friends and most of them work on a pedestal where no design/analysis patterns are followed and theyd rather have something developed fast other than building a well structured software. 
It seems like this test was deliberately designed to test your ability to come up with algorithmic solutions to problems than it was to test your knowledge of any particular language/library features. I expect you'd take similar amounts of time to solve the problems in any language you knew the basics of. Perhaps this is something to work on?
Well who would knew.. they probably used codility idk. I did the whole thing on a platform called hirevue tho.
Just curious, what's wrong with using divide and modulus? They seem like the right tools for the job.
yes but i would stay away from using static unless you know what you are doing and the consequences of doing that.
Oh they are!! I just might have some inner temptations to used other tools to iterate big numbers digit by digit over using div and mod to get the left and right operands. :/ idk how you would pass the number 3244 to Roman for example but in my case I would iterate the digits as a string char by char and check if it belongs to the thousands/hundred/etc category. Since they have that 9xx, 5xx, 4xx rule Id do a switch case for those (and concatenate their keys using a dictionary with all their translations) and as default (8,7,6,3,2,1) i would use div 5 to see if I had to add its 5xx translation and then add the 1xx translation x times until it reaches the digit. This is probably a bad manner to achieve the goal but was the one that came up to my mind the quickest :/
What a time to be alive! When it's harder to find well written tutorials - yes, yes there are plenty of topical blogs - than video tutorials :) I assume a book is out of the question for the same reason as videos, but what about buying a good book as pdf on your prefered topic? I got plenty of downloadable [results](https://www.google.com/search?q=c%23+tutorial+pdf) from "c# tutorial pdf", but personally I would prefer to pay for a quality book.
This right here. A lot of people downplay whiteboard interviews. It I think it is because the expectations are wrong. I want to see how do you handle getting a little stuck. Do you ask questions and talk through solutions. I‚Äôve don‚Äôt a lot of interviews and the thing that will sway me the most is if the person gets excited. I like to ask them about something they‚Äôve been working on, school/personal/whatever. If they become excited and animated what it shows me is that they can become passionate about a problem and for me, those are the best developers to work with. 
There is no need to setup de debugger, just enable code lens and click on ‚Äúdebug this test‚Äù (or something like that) above the test function. And to debug usually if you press ‚Äúf5‚Äù or ‚Äústart/play‚Äù with C# extensions installed VS Code do the work of finding a good launch.json and starts debugging almost like magic.
I've not heard of that one, but it sounds like a similar principle. There's also https://www.hackerrank.com/ that provides similar stuff. As a junior then the thing to remember is, even if you don't get through an interview, then you will learn something from it. If this one doesn't work out, then practice some of these online tests to make sure you're better prepared next time.
Converting to Roman numerals is also a really hard problem to solve because of all the special rules involved. Best solution: code runs a Google search and scrapes the answer from the results 
Removed: Spam.
Or you can have the best of both worlds by utilizing React where needed. Example of this is Facebook; they use react on specific components like Comments.
He assigns it in the constructor.
Absolutely despise interviews where syntax or API matters. I've been a developer since .NET 1.1 days and I often still find myself typing stupid shit in the IDE and relying on the IDE to tell me what I did wrong. It's especially difficult because I'm a jack-of-all-trades and master of none developer.
I have the same issue with coding interviews. The time limit and using one of those browser coding windows always screws me up. That being said, I think the time they gave you was pretty decent compared to one of the interviews I‚Äôve done in the past. The last interview I had was 10-15 min per question. The questions were of similar difficulty. I failed miserably as you can probably guess. I‚Äôve got about the same amt of experience as you.
I actually got a job offer more or less entirely from being excited about a project. The interviewer even said, "I want to find the project in my company that makes you feel that way, because I know you'll work hard on it and do a great job." I sometimes wish I had taken that job, that manager seemed awesome. Everything else about the job seemed miserable though. Defense contractor :/
&gt; So at least Microsoft agrees that if the index changes when values of a collection are added or modified it's not an IList anymore. I don't think this is the reason why LinkedList&lt;T&gt; doesn't have an indexer. LinkedList&lt;T&gt; is not backed by an array, but by node objects pointing to the next node in the list - well, a linked list. This means the performance of reading from an index in that list is not O(1) but rather O(n). If your argument were to be true, then there should not be an Insert-Method on List&lt;T&gt;, or it should not implement IList&lt;T&gt;.
Compared to MVC API, it requires a lot of configuration. HTTPS vs HTTP. Hell just basic setup requires an entry in the web.confg. 
Scroll up. It seems I linked to a named anchor farther down the page.
Removed: Rule 4.
Does it need to have a "database"-proper, that is, something like MySQL or MSSQL? Or just a "database" in-memory, basically a `List&lt;Artist&gt;`, `List&lt;Song&gt;`, and whatnot, perhaps stored/populated via an XML or JSON file? Regardless, create a service layer (basically just a class or classes), whose only job is to get or set that data for each requirement. For example: public List&lt;Artist&gt; FindArtistByName(string name) { //magic } public void RateSong(Song song, int numberOfStars) { //magic } public void PlaySong(Song song) { //magic } With a clearly defined service layer, you can divide up the work between your GUI and your database/storage stuff. Hopefully that can help you maintain your head and avoid [spaghetti code](https://en.wikipedia.org/wiki/Spaghetti_code).
Yeah I‚Äôm technically still a junior but I absolutely bombed a interview for dream company. It is more about thinking out loud and attempting. You can teach anyone syntax it is hard to teach people to think logically.
This comment is linked to the comment of /u/LondonPilot He says to create a new Text object. You probably don't want to do this. I think want you want to do is drag a Text object from your gameobject hierarchy into the script's Text property :) This will create a new instance at runtime for you. LondonPilot is right about it being null though! You havent given the script an object to work with, you do this (mostly) by using `GetComponent()` or by dragging stuff into the script in the Unity Designer when you are trying to work with Unity objects. I hope you understand what I mean! If not, ask away
Sounds like you are perfectly normal. Under pressure, in a dev environment different than you are used to, you did fine. With more experience you will get better. 
I feel ya. I‚Äôd been doing .Net for about a year when I interviewed for a startup. They loved my personality but I honestly left there feeling like I couldn‚Äôt code my way out of a paper bag. It was souls crushing. Every tech interview since I‚Äôve just left feeling sooo dumb. One interviewer asked me ‚ÄúHow do you set an image as a background image on a web page‚Äù ¬Ø\_(„ÉÑ)_/¬Ø idk man.. I‚Äôd have to google it as I have to google most everything. He was like ‚Äúthis is a really easy question‚Äù.... Ok, well I spent my evening reviewing sorting algorithms and sql queries because I thought this was going to be a technical interview a coding job and not front end 101. The problem is, there‚Äôs sooooo much to learn and every employer wants something very specific. I‚Äôm just trying to get as good as I can at the most basic stuff and during my next interview I‚Äôll just try to highlight not what I know, but how easily I learn. 
First off, you're used to using an IDE where you're giving a LOT of help. Visual Studio checks synax, autocompletes statements, and has boatloads of handy shortcuts to make your life easier. I doubt I could just hop into a programming question for C# and knock it out immediately if I wasn't able to automatically import a library when I reference something from it. Second, if you were able to get the gist of the problem solved, I think that's what matters. These problems were likely designed to be tricky to complete without any help. They wanted to see your thought process, and with the allotted amount of time, they probably weren't all that surprised you took that long. Third, you're way too harsh on yourself. You're a recent grad, you only have a year of C# experience, and that year of C# experience probably isn't professional work experience (as in that's what you were doing for 40-45 hours every week). Along with being too harsh is your self-deprecating speech. If you were talking like this about yourself in an interview that'd be an immediate flag for me that you lack self-confidence in your skills. Humility is a good thing, perhaps a great thing when it comes to the workplace, you're likely going to work with people who are way more experienced than you are, but that doesn't mean you should put yourself down for not being an expert the first day on the job. Hiring a junior developer means that you expect to need to train them a bit.
The first 0.1.0 release of blazor is out.
May I ask in which country you live/applied for the job? 
I don‚Äôt know if it would be an overkill, but maybe you can use Entity Framework to create and connect to your DB and to create your entities?
Well, you have a broader experience than I. I'm curious how much actual programming they have one do in Computer Engineering. I'm an engineer myself, and, in hindsight, it's shocking how little they taught us to use technology. The programming course we took in first year might as well have been titled *Introduction To C++: Why You Want Nothing To Do With Computer Engineering*.
That's a great approach. I know there is an Mvc tutorial on Microsoft pages that will guide through this process.
Great comment!
It's considered an easy recursion problem, because there are actually very few special rules. It all works the same way, given a symbol with a value H: IH, H, HI, HII, HIII Then the next value. The trickiest part is that "IH", but by treated it as it's own symbol, you can create a very simple dictionary containing each symbol and it's value sorted high to low, and just recurse subtracting the value if possible and replacing it with the symbol.
The best way to find out if you have low IQ is to take an IQ test.
I'd agree with that. Almost literally every sentence of that post I had to restrain myself from posting a whole bunch of caveats so definitely there is a lot of subtlety and nuance missing.
It's a little more than that, as XL, XC, CD, and CM are all legal. The thing about representing each as its own symbol is spot on though.
Live in portugal. Apllied to work in France.
Thanks for the kind words :') how friendlier could this sub really be?
[Not really](https://dotnetfiddle.net/1uuoo3)
You solved the problems. You are not an idiot. Plus you finished a degree common give your self a break. The only way to get faster is to solve more problems, write more code. Your Speed increases exponentially. Then you need to learn design patterns. Look at GoF design patterns because once you become quick you need to be quick in justifying your decisions. Doing great pal ! Keep going 
This should get yo at least part of the way there. https://docs.microsoft.com/en-us/aspnet/mvc/overview/older-versions/mvc-music-store/mvc-music-store-part-1 It is an older version of MVC but it should all still work the same. 
I really liked Mosh Hamedani's Advanced C# course. He has a three part C# series and I think that's the one it's in. I still rewatch it occasionally as a refresher.
Consider JSON as a format. It's common, fairly human-readable, and easy to use. Serializing a Dictionary: https://www.newtonsoft.com/json/help/html/SerializeDictionary.htm Deserializing a Dictionary: https://www.newtonsoft.com/json/help/html/DeserializeDictionary.htm You can then write/read that data from a simple file.
You can't use the generic xml serialiser to serialise or deserialise dictionaries, what I usually do if I have to use a dictionary is to write a `node` class of sorts like this: public class Node { public MyKeyClass MyKey { get; set; } public MyClass MyObject { get; set; } } Create a generic xml serialiser: public static void Serialize&lt;T&gt;(T obj, string path) { var sw = new StreamWriter(path, false); var ser = new XmlSerializer(typeof(T)); ser.Serialize(sw, obj); sw.Close(); } Convert your dictionary into a `new List&lt;Node&gt; list;` and serialise the list by using the generic xml serialiser like this: Serialize(MyListOfNodes, "C:\my\path\file.dic"); You could then create a generic deserialiser as follows: public static T Deserialize&lt;T&gt;(string path) { var sr = new StreamReader(path); var ser = new XmlSerializer(typeof(T)); var output = (T) ser.Deserialize(sr); sr.Close(); return output; } Then deserialise your file back to a `List&lt;Node&gt;` and turn it back into a dictionary. To be quite honest, unless I am processing a very large set of data, I don't bother with dictionaries. If I were you, then I would ask myself whether I need to use a dictionary or not.
Wow, I feel dumb I couldn't find that. That would be perfect. Thank you. On the side, is my approach to the problem fairly efficient? This is a pretty small project so probably wouldn't matter much. This isn't my normal job description, but I would like to get into good habits/thought processes.
John Skeets C# in depth have a very good walkthrough of this topic and how it has evolved through the .net versions. The 
Thnx!
http://www.r-5.org/files/books/computers/overviews/cs-tools/Brian_Hogan-Exercises_for_Programmers-EN.pdf These kinds of problems may be exactly what you're looking for to practice your logic and problem solving skills.
I've been coding for 20 years at various levels, and do the hiring for my company. As most of the comments here say, these tests are just to see how your logic works, don't worry about timing and if the code works perfectly. For juniors, the real selection process starts after this, with a face to face interview, to see how they will fit into my team, programming techniques can be taught, personality can't. Hope this helps...good luck.
Thanks for your insight. I think personality can be molded as well dont you think? For example, cant you make a shy guy feel more confortable with the working environment?
Eh. For a small project it's probably fine, As long as you are consistent/considerate with how you read and write files. For instance, with all the requirements given, I'd suggest using `File.ReadAllText` and `File.WriteAllText` for your reads/writes. They take care of stream opening/closing for you, so you won't have to worry as much about things. From a more robust standpoint, you could consider using a SQL Database, but if it's literally one app to do one thing, it's probably overkill. For an app that runs every 5 minutes, I wouldn't worry about going any crazier than SQLite, which is very low on resources but still gets your toes wet in how to deal with RDBMs concepts. Efficiency is relative, especially if this is something you do for work. I.E. Taking the time to set up a full-blown SQL DB (i.e. Sql Server, Postgres, Oracle, etc.) for an app this won't impress anyone if it doesn't provide actual value.
Well that was a giant waste of time. The whole intro was about how you can have this cool data backend that your apps can connect to directly, but as soon as the guy asks about how it works with users/permissions/etc, there is no answer.
In regards to your edit. The a and b attributes of my class are both strings. If I do: newDictionary["Key"].b = oldDictionary["Key"].b Isn't that just seeing if the string of each b attribute is the same? That was my goal.
I would ask permission before using EF. If this is a DB class, it's dangerously close to cheating IMO. In my experience, classes/professors had rules on what libraries we could use. That said, I used EF for a DB class (very similar project, just movies instead of music). I went DB first and I still felt like it was cheating but hey no one said anything.
I should read better. Yeah that will work fine.
Could you? Yes. Should you? Not likely. This could cause some very nasty and hard to find bugs, and gain you very insignificant performance gains at best. Depending upon your algorithm, you might not need an array at all! If you loop through once, say like add them all together or something, you can do something like: public IEnumerable&lt;float&gt; GetCurrentFloats() { for(int i = 0; i &lt; size; i++) { yield return GetNextFloat(); } } Still, I very, very much recommend to not try to maximize performance over design without actually knowing you have a problem to begin with. You are probably better off generating a new array each time.
I'm using a very small amount of data. It will only be 15-20 entries per dictionary. I just couldn't figure out a better way to "lookup" the values between the last pull and new pull.
Well, wont you get me a spot there, fella? Haha 
That's really too vague for me to give you any further advice, post your entire code, I don't know why you need a dictionary since lookups on both dictionaries and lists are O(1) and lists have less overhead. Anyway, a general rule of thumb on using list vs dictionaries is when you have a sparse index or some sort of unique key system going on which requires lots of element insertions and deletions. What are you using as keys for your current dictionary? If you are scraping a set number of strings from the same website over and over again, then there's really no reason to use dictionaries since they offer no advantages for you to do so.
Haha...where are you based?
I feel like this is an addition to the OP's answer, but I wanna share something I learned about yesterday (I never used JSON before in a C# project, as an FYI). With the Newtonsoft JSON library, you serialize and deserialize JSON data (json -&gt; object, object -&gt; json). If you make a class that embodies the nature of your JSON data, you can simply do "JsonConvert.Deserialize&lt;MyClass&gt;("source.json");" and it returns an object of type "MyClass" populated with all the data from your JSON file. It's pretty amazing, it works a lot like Entity Framework in that regard where you build your model class, use the library, and you get your data with relatively little effort. Just note that the class and variable names must match with the JSON data. Just thought I'd share that in case it wasn't as obvious as it was to me the first time around :)
Portugal. But I want to work outside my country. I apllied for 2 or 3 companies in Germany, Belgium and France
I'm still surprised Json parsing is not native to the System assemblies. XML serialization has been in there forever.
[BinaryFormatter](https://msdn.microsoft.com/en-us/library/system.runtime.serialization.formatters.binary.binaryformatter%28v=vs.110%29.aspx) is your friend. Be sure to flush the I/O stream when you're done writing it out to a file or you may not be able to deserialize from the file properly. Dictionaries (and generics) seem to be a bit touchy in that regard, but most other serializers will refuse to touch a generic or a dictionary (one or both, depending on the serializer). The best part about BinaryFormatter, though, is that you never have to fiddle around with hacks to make the serialization/deserialization behave and properly re-hydrate your objects. JSON and XML serializers have all kinds of type-dependent issues where they just break for no good reason. BinaryFormatter doesn't. (Its limitations are more related to data portability across versions, platforms, or even hardware, none of which seem to be a concern in your situation.)
When I used to give hiring challenges we would make them so you couldn't finish them or not easily. Part of it was to see how people responded to time constraints, how they reacted to deadlines, if they could prioritize etc... but we told people ahead that it was unlikely to generate a full solution in the time provided and we didn't expect them to finish, but make sure what they did get down was representative of their skill level. We also provided VS or whatever IDE was applicable. We also usually gave some sort class or app skeleton as I don't want knowledge of the IDE to skew things or to make decision based on how fast they type boiler plate code.
Thats a good one. I also spent time doing things that the interviewer could very well leave there already defined to save time for more important things..
It depends on what you're tasked to do, I've asked people to draw out how they'd structure data or something or to demonstrate an idea not put into words well, but when they ask you to write code or develop and algorithm on a white board it makes no sense. I can't write for anything anymore since its mostly relegated to a check I have to still write every other month. I can a bang out a view model or web page or java class with my eyes closed in four IDEs.
Look for MVC music store, it's a classic tutorial on ASP.NET MVC. 
&gt; Then the last exercise was a cashier simulator, you had a bunch of bills and pennies with all the different values and you would have to give to the user the exchange in the wisest way possible (more bigger bills/pennies, less smaller ones).I completed this one within 50-55 minutes (so within time) using a dictionary, 2 vectors, a few cycles and the DIV and MOD operands along with the sort method just to sort currencies out alphabetically. This seems kind of over the top... When I've given this out, I basically expect the simplest possible solution in a procedural style code. A loop with a list more or less. So let's say you have to give $55.50 in change. I have a list of values I can give out (So coin types). I then just loop through the list of values I can give out, minus it from the total I still need to return, and then start again. I'm not sure how vectors would come into this. MOD is probably good and makes sense, but I wouldn't really expect it. I think the worst thing you can do is overengineer the solution. In my interviews for senior engineers, I simply asked them to tell me whether a string is a palindrome (Reads the same backwards as it does forwards). The solution should realistically be something like : for i=0; i &lt; myString.length /2; i++ { if(mystring[i] != mystring[mystring.length - 1 - i]) return false; } return true; OR you can simply use Linq and reverse it. That's fine too. And honestly, I saw some crazy crazy coding. People would do things like put the string into a stack object, then read out the stack into a string (So it's essentially reversed the string), and then compare the two. It's pretty "smart" I'll give you that. But the first thing I think when I see this is am I going to have to tell this person constantly "Can you please just do it in a nice simple readable way". 
Which company did you do this for? I completed the same test for a French consulting firm a while back. I thought that it took a lot longer to complete the tasks than expected as well. I did pass the test though.
People are used to do thing at their own way, if they're used to draw Apples and you tell them to draw an Orange they'll probably draw an apple when it was not the intented result. This doesn't mean that they can't comprehend other interpretations and evaluate them. I have a friend that likes doing things his own way, one day his chief told him "I like your approach but I'd like you to follow this pattern from now on cause it's better performance-wise" and so he did. We tend to get stuck in our own ways of doing things and forget there are many other (and probably better) approaches of doing things. Regarding the cashier simulator. The wanted you to implement a sort of dictionary like this: Dictionary&lt;double, string&gt; dict_coins = new Dictionary&lt;double, string&gt;(); dict_coins.Add(0.01, "PENNY"); dict_coins.Add(0.05, "NICKEL"); dict_coins.Add(0.10, "DIME"); dict_coins.Add(0.25, "QUARTER"); dict_coins.Add(0.50, "HALF OF DOLLAR"); dict_coins.Add(1.00, "ONE"); dict_coins.Add(2.00, "TWO"); dict_coins.Add(5.00, "FIVE"); dict_coins.Add(10.00, "TEN"); dict_coins.Add(20.00, "TWENTY"); dict_coins.Add(50.00, "FIFTY"); dict_coins.Add(100.00, "ONE HUNDRED"); Then you'd have to make the exchange between 2 different amounts and Print the bills/pennies sorted alphabetically. The input would be something like "29.75;34.08" and you then would treat the string (splits and stuff) and then print the bills/coins necessary. Two vectores were probably? not necessary but I treated it in 2 different Ifs/functions. 1 For decimal values (how many coins) and one for integer values (how many bills) using DIVs and MODs This was probably not the wisest approach but at least I reached the result I guess? idk I would rate a good justification over a good implementation though, I think that way you can see how open-minded that person is
Read a book called 'C# in a nutshell ' prefer the more modern edition 
Akka Technologies
That's great :) That approad would probably be fastter idk
Yes, good answer. To further iterate, here's an example of how Google handle the scenario of making you answer questions without a computer. [How to: Work at Google ‚Äî Example Coding/Engineering Interview - ...](https://m.youtube.com/watch?v=XKu_SEDAykw)
Yep, that's the same company. Good luck with the final stage if you haven't already done it.
And whats that?
I had a three stage process. 1. Video Interview with recruiter. 2. Technical test (same as this one) 3. Video interview with business manager. I was offered a role but declined it mainly due to the salary so I can't comment any further than that.
On the other side life costs arent as high but still .
I never had to do any programming challenges as part of an interview until I interviewed for the job that I know have. They gave me a problem and told me to write out a solution on paper. I started doing a bunch of best practices like sanitizing inputs and what not when the interviewer told me to chill and that these puzzles weren't trick questions. He told me not to worry about syntax stuff and just to write the solution in pseudocode. One problem involved some basic algebra and the second was a sorting algorithm. I knocked out both with little difficulty because, as it turns out, I knew exactly what was needed I just didn't know how to turn off my bullshit interpreter and just hammer out a solution. Like my mechanical engineer father always says "KISS. Keep It Simple Stupid"
OK sure. Just don't use double for money values :) Use decimal. 
Hey, to each their own. I respect your right to F### that noise. 
Hi /u/jheizer! Feel free to shoot me an email! We can dive deep into incorporating users &amp; permissions with Cosmos! Brandon.Minnick@Microsoft.com
Noted :)
I wrote (and have been actively maintaining) my own music player for over ten years, so I know a bit about this. Because your list of requirements includes being able to play songs, your first decision needs to be your UI. Do you want a web based solution, a client server based solution or an entirely client based solution? You can then ask here for the easiest to learn UI, persistence and plumbing libraries/frameworks. The other thing I'd say is to make sure how strict the definition of "Adding" is, because in the real world, people have collections of music (in the form of MP3s) that already have the information. So adding the information usually means pointing at a directory of MP3s and writing code to extract that information yourself from ID3 tags. Anyone writing code will tell you that the gift of free data is a blessing from a testing perspective.
Basic question time... do each of your REST services have access to the same data source? If so don't send all the data just references, ids or parameters to search, to each api. Alternatively consider creating amalgamated reference tables to common queries to which you can add primary key references to so you can then query them when required from any of your API services. Let the DB handle your data and your services present it in the format you require.
Haha! I've witnessed this, but with dependency injection. I like DI, I think it's great. But some "senior" developer had decided that "jobs" for want of a better word that would be run by a scheduler should in fact be totally defined in the form of fucking *Unity Container XML configuration*. Yes, that is right. Unity (a pretty legacy container even a couple of years ago when this happened) has support for composing dependencies via XML (talk about Java cargo cult-ing). It was so fucking retarded I can't give the explanation justice. The whole application was now inexplicably tied to not only one DI container (already an anti-pattern, that's what DI is supposed to let you avoid among other things), but now it was all tied up to a extremely brittle XML file that had lots and lots and lots of boiler plate in it. *You even had to manually setup, for example, how and where to load System.Collections.List&lt;T&gt; from to make it all work*. Absolute cancer.
Unless I'm misunderstanding your description, then this is pretty much exactly the same as the Roman Numeral problem.
Its quite similar to be honest. They didnt diversify things that much
I will surely do so :) thanks for being so open minded ;)
For Dictionary&lt;key,val&gt; pairs you can use DataContractSerializer if you want to avoid list conversion or other non built in tools. public static void SaveDCS_XML&lt;T&gt;(ref T tClass, string path) { DataContractSerializer serializer = new DataContractSerializer(path.GetType()); XmlTextWriter writer = new XmlTextWriter(new StreamWriter(path, false)) { Formatting = Formatting.Indented }; serializer.WriteObject(writer, tClass); writer.Close(); } public static T OpenDCS_XML&lt;T&gt;(string path) { DataContractSerializer serializer = new DataContractSerializer(typeof(T)); using (FileStream fs = new FileStream(path, FileMode.Open)) { return (T)serializer.ReadObject(fs); } } In your class. using System.Runtime.Serialization; class x { [DataMember] public Dictionary&lt;key, val&gt; dict; } 
I usually use constructors for properties that are required for the given class to function properly. ex) A Sql connection would not function if you didn't have a connection string provided, so new SqlConnection(string) is required or a Open(string) is required, but you usually don't want people reusing the same connection variables for different connections so the 2nd option is usually never seen. You can mix constructors and initializers, by doing something like this. This is how I usually populate optional properties, or by requiring an options class in a constructor as nullable. new Consumer("John","Doe") { PhoneNumber = "123-4567" }; Framework(FrameworkOptions options = null) Usually the options variables contain info for configuration that will be defaulted otherwise. And it is usually more readable to have 20 properties on a object than to have 20 parameters in a constructor, mainly because you can tell what each is mapped to rather than having a huge list of variables and having to place them together, especially if they don't use the parameter:value pattern.
If a dependency is needed for the class to function, it should be required in the constructor. If your constructor takes way too many parameters you may want to consider if you should be refactoring your code. Your class may be doing too many things, or maybe some of your inputs can be grouped into a class. Object initializes are good for calling a lot of setters, but that shouldn't affect whether or not you are requiring a dependency as a precondition for creating the object itself. 
I've been using Msgpack for several years now. My favorite cross language serializer. 
I use dependency injection pretty heavily and found that constructor injection works out the best for me. I don't mind having extra values, that is what default parameters are good for managing.
Constructors are great for requiring certain fields be filled out by the caller at initialization time. If your class can‚Äôt function without a certain property being populated, it makes no sense to allow it to be created without that value. Also, if you want to implement an immutable class, which for me happens quite often, there is no way to do that but use a constructor, and not exposing any setters at all on your fields / properties. I write very strict constructors for 90% of the classes I write. In a team setting, it saves a ton of time to write classes that other people consume that fail as early as possible (at construction time), and are guaranteed to never fail after they‚Äôve been instantiated (because you‚Äôve guaranteed the class can never enter an unpredictable or invalid state with a combination of constructor and immutability).
Seriously thanks. I messed up I didn't know what I was talking about.
[This](https://github.com/filipw/dotnet-script) might work for you.
Honestly? Instead of using C#, I'd really recommend Powershell. It's a first-class .NET citizen, just like C#, and is specifically designed for scripting and interactive use. It'll be a lot friendlier than C# will.
Powershell is the correct answer. Anything that Powershell can't do natively you can just load up .net classes directly and get all the behavior that you need.
Can‚Äôt you also use c# in Poweshell?
Yes, but you can‚Äôt use powershell on non-windows systems.
C# isn‚Äôt just for Windows anymore. 
Isn‚Äôt that what Powershell core is for?
It's not particularly painful, it's just not exactly the same syntax.
Jeremy Clark's videos are good: https://www.youtube.com/user/jeremybytes/playlists
Neither is PowerShell
Have you investigated ScriptCs? http://scriptcs.net/
I must have been looking at old examples where you script c# as a string variable. I thought I‚Äôd read somewhere that they made it easier but I couldn‚Äôt find examples while on my phone.
im not sure how to use +=. How does that sum the 50 results i have?
If you are allowed to use linq then you can do the following decimal[] numbers; decimal average = numbers.Average(); If you must do the sum and division manually you can do the following decimal average = 0; foreach(var number in numbers){ //This is a shorthand for average = average + number average += number; } //This is a shorthand for average = average / numbers.Length average /= numbers.Length; Here's a fiddle with both cases https://dotnetfiddle.net/UBC5QF
You can use anything in C# in powershell, you can even JIT compile sections of it, rather than interpreting it so long as you're using pure .NET in that section. There's just some syntax differences in how namespacing and a few other things work.
Id have to type my array in to use this would I? I thought i would be able to read from the file again or the console. the .Dump comes up with an error on visual basic anyway. thanks for your help though. 
Will check it out
Not exactly what you might be looking for, but I want to throw [LinqPad](https://www.linqpad.net/) out there.
Something like this. var constantToAdd = 5M; var myArray = ReadFromFile(); var average = 0; for (int i = 0; i &lt; myArray.Length; i++) { myArray[i] += constantToAdd; average += myArray[i]; } average = average / myArray.Length; WriteToFile(myArray);
That's a commonly used operator. I suggest reading up on it. I think you'll find the answer to your most recent question will be answered by the documentation.
Ugh. I would prefer C# syntax over PowerShell. Why couldn't they have used proper logical operators? -gt and -eq and -lt... are you fucking serious?
+1 For a quality book. I'm all for the portability of a PDF or eReader format, but when you want to flip to a specific section quickly, nothing beats a book.
Also use constructors for any read-only properties, naturally. Also, in general, non-readonly properties are a code smell. Not inherently bad, but many people leave mutable state as get/set properties, which is bad habit for any interdependent state.
So, there are a few paths to enlightenment here. 1. Powershell, as has been mentioned. 2. Either [LinqPad](https://www.linqpad.net/) or [RoslynPad](https://roslynpad.net/). LinqPad has a cleaner interface, but RoslynPad is pretty badass in other ways. One of those ways is the ability to spit out a binary exe of your script. 3. C# Interactive (csi.exe). It ships with Visual Studio &gt; 2015 Update 1. This is a [REPL.](https://www.youtube.com/watch?v=2xilWlL7X5A) You can also run .cs scripts from the commandline using csi.exe. I forget exactly where the exe is located, but obviously it's in the Visual Studio tree somewhere. You'll probably want to add it to your path. The syntax changes for using this are basically the same as RoslynPad or ScriptCS. 4. [DotNet Core](https://www.microsoft.com/net/learn/get-started/windows). A developer would have to be brain-damaged not to have at least played with this before now if they come from the .Net ecosphere. It's pretty much the present and future of .Net. In essence, this makes it possible to compile binaries for Mac, Windows, or Linux. With some caveats, true enough, but not as many as you'd expect. *This* is what you're asking for, really. DotNet Core originally shipped with REPL capabilities, too; you can see it in action in some of the earlier videos where but the dotnet core team removed it for some sort of super-secret-squirrel reasons. Ostensibly so they could package it separately, but that plan seems to have vaporized immediately after removing the already-working repl functionality, so I can only assume there was something else going on. There's several ways of skinning the cat, and each one has its benefits. I feel like I've missed some. But those should get you where you want to be.
yea i see how it works now and ill use it. My problem is i dont really know where to put these lines exactly. if i put it higher in my code i get different answers. But i managed to get it working now. thanks again for you help.
I assume that's because it also has to work as a shell where symbols like `&gt;` have other conventions, although one could certainly question the value of preserving some of those conventions forever.
With .NET Core you can use C# to code cross platform. https://msdn.microsoft.com/en-gb/magazine/dn913184.aspx You could do it before .NET Core with Mono but it‚Äôs more mainstream now.
With .NET Core you can use C#/.NET pretty much anywhere. https://opensource.com/article/17/5/cross-platform-console-apps You could before with Mono but it‚Äôs more mainstream now.
Really? Never heard people say that peyote. What if you need to change the value of a property? For example you had a user class with an updated date against it. This would be changed whenever the user is updated. Would you spin up a new version of the class to update this (by re retrieving it from the DB or something similar), or would updated date be an exception to this statement? Same with username, first name etc. If you update these properties would you go and get the user from the dB again after updating to create a new user object? Thanks for any insight :) 
That one looks really interesting thanks. It's allways good to know a good place to start instead of learning some bad practices and this site seems pretty good.
#2 : I wish Linqpad was free. I would love to use especially the autocompletion but I am hobbyist so not sure if its worth the money for it.
I have no idea what you are actually asking but it all sounds like the classic Inheritance problem to which the answer usually is: Composition and dependancy injection. This talk is not about c# but since your post is more about core OO concepts it might help you out: https://www.youtube.com/watch?v=OMPfEXIlTVE it's a great talk.
To be honest I'm not entirely unconvinced this isn't a thinly veiled troll, this whole wall of text for example: &gt; All "Person" follow the same template despite being different. Should interface be "IMale, IFemale" or "IGender"? What about other genders not M/F? Also, Male and Female are each a Gender, so they would need to descend from IGender. They have different actions associated with them. For example a male has the ability to take a piss standing up, and a female above a certain age has to bleed every 30 days or so. What if we add gender as a property to Person? Well, if the gender is male, we expect person to implement the IMale interface and allow certain actions to take place. However, we cannot conditionally assign interfaces. Well why not have Person implement both IMale and IFemale? Well, if the person is male, he cannot bleed every 30 days as this code would suggest. They are mutually exclusive. You can be one, but not the other. In addition, what about any other genders? We should not need to implement 50 different interfaces for a Person who only is one of the above (aka Male). In addition, they need the ability to change their gender (or occupation, etc... since this is possible in real life). I mean, really? Couldn't make it more obvious you was trolling, or baiting.
It's a good question actually. We purchase data from a lot of sources, and I've only been involved with parts of it. There's also the differences between what we call "raw" data, which is the purchased data, for example all properties, property type and usage etc., and then there's "transformed" data, which is basically raw data turned into a more practical format using our own internal keys and indexing and what not. It's also a bit scattered over different servers and databases. We're in the middle of moving and refactoring a lot for security reasons, but eventually, we're actually aiming at having a "data bank", where it's all collected and available for all services. There are some restrictions through VLANs right now. I was actually originally against the idea of letting multiple services have access to the same data, but I see that it's not a practical distinction to make. Rather, it's more become something like a database for each customer project. A customer project acts more like a shell around the "core", which are the services that have access to the data sources, and then the customer projects stores the data relevant for the customer, and presents it as such. Do you know where I can find an example of using amalgamated reference tables? It sounds a little bit like those transformed tables I described, but not fully. Also, originally I considered something like sharing NuGet packages that contain DAOs or repositories or something like it that can help with the data access. It seems to me that a lot of time is wasted rewriting the same database queries over and over again in different pieces of software, but it seems ugly somehow to share data access in NuGet packages. It's here I'd kind of hoped to instead have REST services responsible for performing lookups. Is any of this making sense?
or the alternative http://www.csscript.net/
[C# yellow book sounds close enough](http://www.robmiles.com/c-yellow-book/)
The needs of the application drive the model. Keep it simple but leave room for expansion if you sense ambiguity. I personally prefer data modeling to OO because it is simpler and reflects what will likely be the persistent means of storage anyway.
Trevor, great writeup. I'm new to using Xamarin with Visual Studio 17 (it's been just a month). I have been trying off and on to get everything working but have had numerous problems setting everything up. By my understanding there are currently a number of bugs that can stop things from working with the latest version of Visual Studio so I guess I picked the wrong time to start! I see you mentioned in another article a write up you did on overcoming various install issues, any chance of a link? I couldn't find it anywhere. Cheers and keep up the good work!
You could expose methods to make those changes to private fields instead. Or treat objects as immutable