In Columbus OH there's at least one shop I know of that's moved over to Elixir from Ruby. They've been the hot place to work for a few years now, so I suspect others will start following their lead.
Exactly my thoughts!
You don't want to work for them. They're running terrible infrastructure behind Elixir, and they won't change it, so you'll likely be learning exactly how not to do things... Also they got bought out by a huge corporation which is slowly killing the startup culture that made them appealing to begin with
While the number of open jobs for Elixir isn't huge, we're at a particularly interesting part of the adoption curve, IMHO. We saw a very similar kind of growth happen with Rails in the late 2000's. What I see going on right now are a lot of "infection vectors" by which Elixir is introduced into larger companies: * Startups that use Elixir are getting acquired, introducing Elixir into the larger organization. * One-off projects to test viability of Elixir within an organization are turning into multiple projects * More startups are looking first to BEAM where they would have prototyped using Rails or Django or something like that previously. * A lot of side projects are growing up and turning into startups in their own right—which may eventually get acquired. This stage is interesting to me because its represents an inflection point in the growth curve. Its what I think of as the third stage of adoption, after pioneers (1st stage) and tinkerers/very-early-adopters (2nd stage) have pushed it far enough along that the new platform achieves critical mass. Ultimately, this leads to orders of magnitude more jobs, assuming the growth of the community doesn't falter and/or level off. While I don't think any new platform is going to own mindshare as completely as Rails did there for awhile, I think Elixir is going to share a large stage with some other very respectable contenders. Now is a good time to become active in the Elixir community, because when that happens you'll be well-positioned in terms of experience at a time when experience on the BEAM will be at a premium in the market.
I work for a company doing elixir development in Chicago. There are a decent number of elixir shops, depending on where you live or how interested you are in remote work. The elixir job board is probably the best place to start. I believe Chicago has 3-4 that are actively recruiting (including mine!)
I've had a job where I maintained two Elixir projects. The company used to have more, but the guy evangelizing Elixir fucked up and introduced it faster than he himself could keep up, so they were sunsetting most of their Elixir projects because they blamed the language/platform for the failure of those projects. In brighter news, I see new startups post listings for Elixir devs once in a while so maybe now is exactly the time to learn it to be slightly ahead of the curve.
I wrote an [ANSI to HTML](https://hex.pm/packages/athena) package based on something I had to deal with at work, formatting Cucumber output. I also created a new application at work that takes in last weeks user agent data(about 350k rows) from the production database, translates it, and inserts it into my Phoenix application. This application then serves up Javascript graphs based on different queries of that data so that we know what to OS/Browser combinations people are adopting and where to focus our testing efforts. It helps with seeing trends. I am unsure why we aren't using Google Analytics or the like. But still a fun project. 
This sounds really interesting! You got a link?!
It's really helpful for both inspecting data, and flipping args around if they aren't in the correct order. Glad I could help with that dumb little joke. 
Thanks for showing interest, helps with motivation :-) I don't have a link yet, but I can let you know when it is up. I expect to open source it soon™.
very very very few
https://github.com/stepnivlk/pushex Pusher websockets client. Slowly getting somewhere, appreciate any feedback.
Do you mind PMing me the name?
Another more explicit way would be to define a custom type similar to the plug.conn struct. This han be accomplished with the defstruct keyword
Hmmm interesting- you’d still have to handle atom conversion thought right? What would be the major benefit ?
Yes that is true. I'd say the main benefit is that you'll end up with a defined struct where you can use enforced keys and therefore end up with a more reliable struct rather than a regular map Here is a hastily written example of how it could be done defmodule Pagination do @enforce_keys ~w(something)a defstruct page: 0, page_size: 30, something: nil def from_params(pagination, map) when is_map(map) do pagination |&gt; Map.from_struct |&gt; Enum.map(fn {key, value} -&gt; {key, Map.get(map, to_string(key), value)} end) |&gt; Enum.reduce(pagination, fn {key, value}, acc -&gt; Map.put(acc, key, value) end) end end params = %{"page" =&gt; 4, "non_existing_key": 100} pagination = Pagination.from_params(%Pagination{something: false}, params) IO.inspect pagination #=&gt; %Pagination{page: 4, page_size: 30, something: false} 
I like this approach. Define a module and struct with a `new` function which will cast and validate the string-keyed map, returning `{:ok, %SomeStruct{}}` or `{:error, reason}`. It allows you to clearly communicate throughout the codebase where you expect to be receiving validated struct data vs untrusted string maps.
Also particularly non-web/phoenix jobs would be interesting - Elixir/OTP only.
There aren't many, especially when compared to other technologies. My city (Melbourne, Australia) has roughly a handful (maybe a bit more now, since when I was applying was over ~8 months ago) of companies that I'm aware of that advertise elixir positions. I did happen to find through my job search quite a few companies with people on staff who either were interested in elixir or were already using it for some personal projects. However the amount of developers that already know elixir is also quite small, so even with those few companies they've even said they've had a hard time finding applicants. Another thing to note is many of those positions are requiring applicants to know whatever other stack of their's they used (or are migrating from). As there's even fewer companies that started with it or have completely replaced all their old tooling with it. This is to be expected though, as the language is still quite new (like Rust) and lacks the backing of some massive company (like Go with Google). So adoption will take time, as long as we keep getting success stories both with companies who've used it and developers themselves enjoying the language then that will change overtime. I think it would be interesting to see what portion of the community currently are just interested in it (haven't taken the plunge to learn it just yet), use it for personal projects, or use it at work. 
I'm im_bot-hi_bot
I may be a bot, but bots are made by humans &lt;3
I really don't see that this approach is solving any problems. `cast/4` already does this (in fairness, noted in the article), and if you want something that operates on other schemas its trivial to define a function that pattern matches on schema type or accepts a schema module to operate on. I'm also a fan of /u/mintcore's suggestion of a custom struct to handle the data. I would personally go towards an Ecto embedded schema, which again allows the use of `cast` to whitelist your parameters.
It depends on how large your project is. The one I was working on had about 20 controllers and changing web.ex would recompile almost everything (this was Phoenix 1.2 days, pre-Context) so it would be 2 minutes to recompile every controller, view, router, and schema every time you modified web.ex. This is why the `xgraph` command was added to mix. Debugging long compile times is important in large projects. If you isolate your stuff that you put into web.ex by using imports/aliases/etc in web.ex, changes in those shared behaviors can reduce compile times to between 5-80%, depending on how your project is structured.
I see! Thanks for the example! That makes sense, it is definitely an interesting approach. Do you mind if I update the example in the article to also include it? Since more people also seem to approve it. For me personally, I believe it is good to have a flexible map. The problem is only partially get rid of bad input, but also helping clean up your contexts. I can think of a couple times where it would be useful to add more things to that map later on, so I wouldn’t particularly be interested in enforcing only certain keys after params leaves the controller level.
[No, never did and probably never will](https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags#answer-1732454) :) 
CSS Selectors might not allow you to select nodes based on text, but XPath will. iex&gt; html = """ ...&gt; &lt;div&gt;abc123&lt;/div&gt; ...&gt; &lt;div&gt;&lt;span&gt;./---DeFfff/&lt;/span&gt;&lt;/div&gt; ...&gt; """ iex&gt; import Meeseeks.XPath Meeseeks.XPath iex&gt; Meeseeks.all(html, xpath("//*[text()[contains(., 'abc')]]")) [#Meeseeks.Result&lt;{ &lt;div&gt;abc123&lt;/div&gt; }&gt;] That's still not as flexible as allowing a regex though. [Meeseeks](https://github.com/mischov/meeseeks) tries to make defining custom selectors easy, so how might a custom selector mimicking the one in the post look? iex&gt; defmodule ElementTextSelector do ...&gt; use Meeseeks.Selector ...&gt; ...&gt; alias Meeseeks.Document ...&gt; ...&gt; defstruct value: nil ...&gt; ...&gt; def match(selector, %Document.Element{} = node, document, _) do ...&gt; children = Document.children(document, node.id) ...&gt; child_nodes = Document.get_nodes(document, children) ...&gt; ...&gt; Enum.any?(child_nodes, &amp;text_node_contains?(&amp;1, selector.value)) ...&gt; end ...&gt; ...&gt; def match(_, _, _, _), do: false ...&gt; ...&gt; defp text_node_contains?(%Document.Text{} = node, value) do ...&gt; node.content =~ value ...&gt; end ...&gt; ...&gt; defp text_node_contains?(_, _), do: false ...&gt; end {:module, ElementTextSelector, iex&gt; sel = %ElementTextSelector{value: ~r/abc|def/i} %ElementTextSelector{value: ~r/abc|def/i} Meeseeks.all(html, sel) [#Meeseeks.Result&lt;{ &lt;div&gt;abc123&lt;/div&gt; }&gt;, #Meeseeks.Result&lt;{ &lt;span&gt;./---DeFfff/&lt;/span&gt; }&gt;] A little involved, but no having to rely on implementation details to make it work. :)
I'm currently using `Meeseeks` as well for its support to XPath queries. I had to modify an already running project and frankly removing `Floki` just for XPath was not worth it. It took a few minutes to understand how it worked and having both html5ever as a parsing engine doesn't even make a lot of difference in practice. It's usually a good exercise to read other people's code and try to understand it to get better and better with the language. Actually what I did it's not even relying on an implementation detail, the implementation of `Floki.find(html, selector)` does not make assumptions on the type of the `selector`, it makes assumptions on whether or not HTML is a string or a parsed tree and then forwards the call to Finder which accepts a `%Selector{}` as input def find(html_tree, selector = %Selector{}) do find_selectors(html_tree, [selector]) end BTW I think that [lack of XPpath support in Floki is by design](https://github.com/philss/floki/issues/94), Floki aims to be minimal, not a feature packed parsing and querying library.
The particular implementation detail to which I was referring is `fl-contain`'s use of `=~`- it could just as easily use `String.contains?/2` and then that trick wouldn't work. 
You're right! And thanks 
Yeah, if you're not using Ecto at all I can see a need for something else to sanitize parameters with. I'm still sort of unconvinced a reimplementation of strong_params (which I never really liked in Rails, tbh) is the way to go over a controller- or use-case-specific sanitizing function. (Though having started out more than one project that bypassed Ecto only to reinvent it, poorly—you'd have to work pretty hard to convince me that not using it is better than using it!)
Can somebody explain why I would want to run Erlang/Elixir apps inside a container?
London, UK is thriving with Elixir opportunities.
You could have multiple apps run on the same VM with different versions of erlang or elixir. Not really specific to elixir but dependency management seems to be one of the biggest reasons for using containers.
😂😂 Thanks for your comment- I think you’re very right to ponder if something like this should be implemented or not. To be fair, I also ponder a lot.
Because if you're on a cloud provider, like googles, and you're using kubernetes it trivializes deployment. Only time it might throw a wrench is if you're running an app that has clients with long lasting/persistent connections. But even then, it's usually find to just delete the old containers and let kubernetes redeploy them with the new image, then the clients just reconnect.
Does doing it this way detract from using BEAM languages? 
I think you avoid some benefits like hot code reloading, but I don't personally miss that for my development work. For me, the real beauty of the BEAM lies in the process and concurrency model.
Yeah, don't get me wrong—while I question the utility of it in most circumstances, its a nice piece of work. :) Kudos on putting it out there.
I am sure he is talking about the built in global registry.
Submitted my abstract for ElixirConf, would be nice to expand on my lightning talk. Going to start building out the API for the weather station, and maybe start the elm front end.
I took some time away from my project but I'm back to working on my Sci-fi real-time MMO with a Unity front-end.
For OTP 21, they are rewriting many of the file APIs to use dirty NIFs so there is a chance this is fixed. I recommend you to try out Erlang/OTP master and report a bug in case sockets are not yet supported on sendfile.
I think the course is going to be basic for you. Dave doesn't spend much time on data structures, standard libraries etc. because he assumes you're a programmer that I personally liked. Instead he takes an introductory approach how to structure your modules and applications (components/modules), which I found very valuable. For example if you need a chat GenServer you split that into three modules: chat.ex # API chat ├── impl.ex # Business logic └── server.ex # GenServer This makes it easy to make changes to the business logic since you know exactly what is where. This is not very Elixir specific but I like that Dave teaches good programming practices even in his introductory course. It also makes testing easier since you can test the implementation without thinking about a GenServer. This chat module might even be its own application so that it could be reused in multiple projects instead of it being a module tied only to a Phoenix application. Some discussions [here](https://elixirforum.com/t/single-responsibility-principle-what-does-it-mean-to-you-and-your-elixir-apps/8704/5), [here](https://elixirforum.com/t/applications-are-components-aka-microservices-in-elixir/6884/10) and [here](https://elixirforum.com/t/discussion-dont-add-a-database-layer-to-your-phoenix-application/8623). While nice with a quick introduction to Phoenix (both request/response and web sockets) there are no videos on Ecto. You will definitely need another resource for learning Phoenix which was expected. Personally I still have trouble understanding OTP; especially supervisors but also GenServers, Tasks, Agents etc. That is why I bought Elixir in Action to hopefully get a much better understanding of OTP, which is what I think really sets Erlang/Elixir apart from other languages/platforms and what I am mostly interested in learning. TL;DR: you will know how to write and structure Elixir code into modules and applications but you will only touch lightly on how OTP with GenServers, Tasks, Agents, Supervisors etc work which is fair.
Good idea. I would suggest to follow along the lines of 4clojure. This is a good starting point imo. Here'source code : https://github.com/4clojure/4clojure . 
The original idea is on the elixirforum
https://elixirforum.com/t/a-free-and-open-source-online-elixir-and-phoenix-bootcamp/13032
The last suggestion was to use Elm instead of Vue. Let me know if anybody is interested.
I'm not aware of there being any safe/sandboxed evaluation environments for elixir, so you wouldn't be able to execute the code on the server. Two possibilities might be to grab the AST and write your own evaluator or walk over the AST and remove any illegal expressions before compiling and running. Although looking at the original elixirforum topic, it looks like you want to make Phoenix challenges. Which would just complicate things further. One alternative (but won't be able to be contained entirely within the browser) would be to get the user to add a hex package to their project for the challenge. That package could then setup the challenge environment (could even present it as a web page or do whatever really), and all code would then be executed on the user's local machine so there wouldn't be the same concerns like before. 
And it’s available now?
exercism.io may be a good place to investigate. They have an elixir course
Not quite a boot camp, but open sourced - [exorcism.io ](exorcism.io).
*exercism.io
That will allow them to run any code (even if you don't call any functions of the module explicitly, cause you have to remember elixir can have code outside of functions that gets run during the compilation stage). Which is a really bad idea given just how much functionality is self contained inside Erlang itself (and that's assuming you've sandboxed the entire VM and protected your server). They could run code to establish their own SSH connection directly to the VM, or they could grab all of your secret keys, or they could interact directly with your DB, or they could change the content being served to users, etc. 
You can use `Code.string_to_quoted` to convert elixir code into an AST. That's the easy part however, either evaluating it yourself (without relying on compiling and executing it) would take a lot of work. I wouldn't actually recommend it beyond the trivial stuff. Or doing the same and walking over the AST and filtering out any illegal operations. I feel like that's the more sane approach you could take. Given that all illegal operations will be from calling functions in certain modules, you could make a whitelist of modules that are allowed to be accessed. Then just walk over the AST looking for any function calls and seeing which module is being used. It would of course have to be a little bit more complicated than that seeing as they could make it a dynamic call (passing the module name to a variable and ten using that to call), or use imports, requires, aliases, etc. But if you also prevent them from using the Code module, don't allow them to use quotes, basically just block any way they could provide a string or AST with illegal code then it shouldn't be too complicated. 
How far will ExUnit take me in eval?
I seem to have found a sandbox. It's based on try elixir. 
ITT OP is dick
Cool. I did a quick search and there seems to be another [Exbox](https://github.com/christhekeele/exbox). It does say it's no longer maintained though, but it may have some other useful information for you. 
Thanks you for the thorough explanation! 
Hmm, wonder what they teach there...
&gt;The most obvious option for rest APIs in Django is DRF, which is an external package that acts as a framework on top the framework. Some people love this approach, some people hate it. You can build a restful API without the need for any extra package in Phoenix. As someone who has used both languages/frameworks, that's just unfair. You can build a rest api without DRF, it's just a matter of "why would I do that when I have DRF?"
I haven't tried this or anything but have you tried just doing: render("footer.html") 
For somebody unfamiliar with Django and DRF, what does DRF bring that Phoenix doesn't have?
It's great to see Phoenix contrasted to frameworks other than rails. I see the 'you don't need an external job queue' advice quite often, but rarely are the trade-offs discussed. Simply spawning processes to perform async work gives you at-most-once processing semantics. This is almost never what you want for a business application. If you don't want a dependency on redis/rabbitmq, then the safest place to put your async jobs is in the SQL DB you are already using. The backy and ecto_job packages make it pretty easy to setup on postgres.
idk much about the differences, maybe this might be useful https://elixirforum.com/t/comparison-to-django-django-rest-framework/8075
Haha. Exorcism. Did that but we need something for beginners.
At exercism, you solve challenges. Urdu for people who have basic knowledge of programming and have read official docs or have completed a bootcamp.
[Eh, Tobias... :D](https://i.imgur.com/8wkOGK2.png)
It can be very confusing to see Foxy talk about bunnies. I blame the others ;) 
Yup, the underlying PubSub functionality exports a direct_broadcast function: https://hexdocs.pm/phoenix_pubsub/Phoenix.PubSub.html#direct_broadcast/4 Here is how absinthe uses it: https://github.com/absinthe-graphql/absinthe_phoenix/blob/master/lib/absinthe/phoenix/endpoint.ex
For now bunny still works a lot like benchee. 
We will use this to convert the given command-line arguments into a structured form and validate them. 
 The key idea is to take the samples that make the overall shape of your data as similar to the original one as possible.
Through our investment in collaboration and innovation 💡 we ensure the excellence of our product.
Yes, I know, I was talking about the typo. 
So what do you think: full stacks cert elm/Vue ( nyd ) + elixir phoenix
I liked how taskrabbit was the ad that was placed for me. 
Correct
Yes. 
I'm particularly fond of Tesla
Almost as if someone just wrote a thin wrapper around benchee as an excuse to post lots of pictures of their rabbits ``` () () (* *) o( 0 ) ```
Ok thanks for indulging me, if anyone ends up here out of context - this was an Aprils' fools joke. However, don't worry bunny is just a thin wrapper around benchee. It will remain usable if you want to have that bunnytastic benchmarking experience. Look forward to benchee 0.13 with memory measurements at your doorstop soon-ish (stilla blocker remaining).
However it is rather wrapper on other libraries, to provide easier interface, rather than JTTP library on it’s own. 
As is HTTPoison, as is HTTPotion....
+1 for Tesla, my client of choice for all my projects
Just about all of the HTTP client libraries in Elixir are wrappers around Erlang implementations: HTTPoison wraps Hackney, HTTPotion wraps ibrowse, Tesla and [Maxwell](https://github.com/zhongwencool/maxwell) have default adapters for Hackney, ibrowse, and httpc, so it's important consider the underlying Erlang libraries when figuring out which Elixir library to use. A simple rule for beginners to follow is: use something that wraps Hackney, because [Hackney handles HTTPS more safely by default than the others do](https://blog.voltone.net/post/7). Similarly, *don't use httpc*, it can be quite buggy- I am currently flummoxed by an issue regarding malformed gzipped body content of synchronous (but not streaming) responses.
[Heads up if you're using hackney](https://github.com/benoitc/hackney/issues/462)
This is particularly interesting to me. I have a Davis weather station on my roof, and right now get data out of it and online using WeeWX. Its not terrible, pretty good actually, but I've been meaning to get around to writing an elixir interface.
Hackney. Why bother with a wrapper for it when it already is extremely easy to use.
what's the downside of using a wrapper?
Not sure if this will help or not: https://joearms.github.io/published/2016-03-13-Calling-Elixir-From_Erlang.html
I haven't tried this plugin, but it's mentioned in the Rebar3 documentation: https://github.com/barrel-db/rebar3_elixir_compile
Unfortunately it runs into versioning issues when used alongside an application that also uses the Cowboy webserver (which is the default for Phoenix).
that's sad given it's been developed by cowboy authors. gonna check it, I'm using gun in a lib (without cowboy dependency) without any problems.
Apparently they just figured it out and pushed a fix for it. Spurred on by your comment maybe? 
For one, it’s a little bit extra overhead, but that’s generally negligible. The other issue - a common one for wrappers around erlang libraries, is that you potentially have to debug two layers of issues. “Is my problem how httpoison wraps hackney, or is the problem in hackney itself?” Both are pretty stable libraries, so I generally lean towards using the wrapper. Hackney may be simple, but HTTPoison feels just a little more comfortable. 
You are correct in your assessment. Generally speaking, use the simplest abstraction to solve the problem at hand. In terms of complexity, function clauses are simpler than behaviours, behaviours are simpler than protocols. Both function clauses and protocols provide polymorphism based on the data. I.e. they allow you to control the branch to invoke based on the data. Function clauses are more general but they are also "closed". Once you define the function clauses for a given module, you can't change them. Protocols are open and can be defined and implemented at any time. Behaviours bring you polymorphism based on the module name/function dispatch. They exist for documentation and they provide warnings and some static checking when using dialyzer. Protocols are internally implemented with behaviours plus a dispatch logic based on the data type implemented with function clauses. So it is implemented on top of the two other mechanisms.
I’d say it entirely depends on their perspective. Elixir solves a lot of problems that other languages struggle with and some problems that other languages don’t even know they struggle with. Aim your speech at the audience. Talk to them or think about it on your own and find the thing Elixir solves that they are (or don’t know they are) having issues with. 
On mobile sorry but there are a few Erlang/Elixir bitcoin packages on hex.pm and github so check there.
I guess you didn’t read the blog post? :)
Total beginner. New to programming though we might have something for experienced devs too..
This will be interesting because I don't think there have been really many Elixir/Phoenix resources aimed at a total beginner. Almost all material I've seen assumes you've seen something else (typically Ruby). You should, of course, really think of what you mean by a total beginner. A beginning 7 year old is not a beginning 20 year old. I'm sure I could read any intro material you have, and point out something that you're assuming a beginner knows.
Yeah. I'm thinking of writing a lot analogies. Aimed at a 5-yo. 
Lol nope my bad 🤗 
In reality, Mesos, for example, would do the hot switch of your app to a newer version bootstrapping the new image in parallel with the current, and switch the traffic once the new one is healthchecked. On practice, the downtime was not really visible. Beside of that I would add that code hot reloading is quite a complex topic, and I find it quite easy to really mess up things here (but it's my personal experience with it, and I accept that more experienced... I would say more lucky people, had a better experience with it :) )
Isn't there a conflict between Docker containers being disposable and the focus on statefulness common to BEAM systems?
Agreed :)
While there are lots of things to love about elixir (the community, mix, hex, pattern matching, macros, ...) the unique feature is the concurrency model on the BEAM VM. Isolated processes communicating by immutable message passing, with a scheduler that allows thousands to run smoothly on a single core, automatically scaling up to use multiple cores, and a path to scale out to multiple nodes. Other languages can run on BEAM, but elixir has Ecto, Phoenix and other libraries that make Elixir the best for new projects. 
I guess I am just a little confused on the use for this library. For example in the github readme...is this not just as easy and more forward about what is happening: # def index(%{assigns: %{current_user: %{admin: true}}} = conn, _params) do # your normal function logic end def index(conn, _params) do # unauth end
Cool! One thing that confused me about GenServers is how they save state over long periods of time - if someone pulls the plug on all the VMs at once, how do you hold on to the data?
We're indeed not storing any data persistently right now, but since all Players' connections are through Websockets, they'll simply continue to try to reconnect in the front-end until the servers are back up. So if the servers for example take a brief nap for 10 seconds, the users in the front-end shouldn't really notice anything, other than some lag if they attempt to interact with one another during those 10 seconds.
Pretty neat. In other words, any important state that is lost during downtime is regained when players are able to reconnect. I wonder how this performs compared to periodically caching data on the disk and reading it back into memory when the servers restart. 
Indeed - this should perform rather well, but it's due to the nature of the service being realtime, such that it doesn't really make sense to store anything since we require that the user be present. As such, the 'persistency' just comes from them leaving the site open and thus keeping the websocket alive.
Glad you think so! We've tried to keep it that way indeed! There's not too many using it right now, as it only comes in bursts when we post it on league subreddit, so I can see how you could miss that :D 
Awesome! 10k Phoenix channels open I assume? What’s the specs on the server and what’s the CPU and memory load with 10k?
Yes - 10k websockets/channels. The server used for testing was [Digital Oceans 5$](https://www.digitalocean.com/pricing/) server, which has 1GB of Ram and 1vCPU. And it was basically a 'worst case' load, in which all Players matched with around 50% of other players, which in practise would be a bit much. I believe we hit around 500mb of ram usage, and actually hit a File Descriptor wall, which we stilll need to fix, rather than a memory wall.
Awesome, this might give me a reason to actually implement my shareplaywith.me for PS4. 
Nice project. Have you thought about moving the riot API app into its own hex package?
Not a terrible idea - will defintely consider it, although right now it is still somewhat tailored to our specific use-case rather than a more broad API integration. 
What are your pain points with php? 
how about submitting files to json api?
That's definitely tutorial worthy material. But to give you an answer, there is two ways to go about it: 1. If you want to remain a JSON purist, you can Base64 encode the file (at 33.3% more file size [https://stackoverflow.com/questions/4715415/base64-what-is-the-worst-possible-increase-in-space-usage]). Then simply send it as a string. 2. Have an endpoiint that accepts mixed content (application/json and multipart/form-data). I usually go with number 2 unless expected files are very small... still prefer number 2 though.
I saw you didn't find a good development API client, have you tried https://insomnia.rest/ ?
I want to register interest in a version with JWT auth as well. I'm a little surprised that you didn't use any of the Auth libraries from https://github.com/h4cc/awesome-elixir#authentication Any reason for that?
visual studio code and a command line lol.
The Elixir core team is working on a pure Elixir http client. So don’t write everything off just yet
Hey! How's your elixir learning going?!
I created a simple web app to extract text found in images. Feedback welcomed. https://image-to-text.edgardev.com
The goal of our http client is to be extensible, support HTTP 1 and HTTP 2 and be safe. It likely won't support pools by default, which makes it most likely not useful out of the box for applications talking to APIs, but it should be fine for one off requests. We want to make it extensible so we can write pools, GenStage pipelines and others on top of it. The master thesis /u/mischov shared below does seem to cover this aspect well - which is one of our main design principles.
This thesisys looks great! All in all, the article mostly cover “what to do today”. I’ll be happy to get one main way to make http communications in Elixir, and hope to make contributions to make this come true.
This thesisys looks great! All in all, the article mostly cover “what to do today”. I’ll be happy to get one main way to make http communications in Elixir, and hope to make contributions to make this come true.
Good to hear. Hit me up whenever =D
Hi there, I just pushed (meh) new version of pushest. My approach to a pusher client. It's getting more stable so feel free to check it (and the docs https://hexdocs.pm/pushest/Pushest.html).
Why would anyone use pusher with Elixir other than migrating off of it? What's the point of paying for infrastructure that the language can do?
Interoperability with apps written in other languages?
https://github.com/phoenixframework/phoenix/blob/master/mix.exs#L57 In master of phoenix it's fixed
Are you using Pusher as a message queue then? Why not use a proper message queueing service then?
I think providing a digestible chunk of a design pattern like this is naturally going to lead to that. Especially a design pattern focused around eliminating boilerplate by absorbing the boilerplate behind macro calls. This pattern very much emulates Plug, which is already a well respected pipeline based way to architect a web server. So I don't think the examples being a lot of code is necessarily an important factor in evaluating the pattern.
Plug was written to be initialized at compile-time. It makes sense, because you don't want to process options and initialize plugs on every request. That's mostly why the Plug pipeline exists. And even if you remove that, you could implement the Plug pipeline like this: with %{halted: false} = conn &lt;- plug1(conn), %{halted: false} = conn &lt;- plug2(conn), ... do conn end For your custom business logic, you could standardize on `{:ok, val}` and `{:error, reason}` tuples and that's it. There is no reason to hide your code, your logic and your conditionals under tons of macro code. The previous post from the same series mentioned Ecto and Ecto doesn't use any meta-programming when working with changesets. You will actually find that most Elixir code doesn't use macros for flow control and there is no reason why we should be promoting it here (unless you are doing some compile-time preprocessing, such as plug, which is rare).
Yeah, even though I defended the article I feel the same. I just didn't want the verbosity of it to be the only criticism, as its not really the reason that I think the design pattern has issues. I'd much rather see central_state_object |&gt; do_thing1 |&gt; do_thing2 |&gt; do_thing3 Or with {:ok, res1} &lt;- do_thing1, {:ok, res2} &lt;- do_thing2, {:ok, res3} &lt;- do_thing3 I've seen a few articles on design similar to this and for some reason I always go in w/ my hopes up that they've some how cleanly wrapped or solved for complex control flow. But so far none of them has :D
Not trolling. :) I have been following the series, thank you for writing it. However, I feel like this article missed the nuance that Plug uses meta-programming mostly because it wants to initialize plugs at compile-time. It is not about flow control. The blog post is very didactic but I wouldn't ever use this solution in practice without further considerations - which were not mentioned, such as compile-time initialization. See my other replies on this thread. 
I have not, thx. But I see it's a desktop app, I was looking for an in-browser solution.
Hmm I wasn't aware of that resource. And it surely is a BIG list... which one would you pick? As I said I'm just starting with Phoenix / Elixir and wanted to have a look at what was needed for building a simple authentication from scratch. I was happy that I didn't need that much! :) I'm a Rails developer and you also don't need much when rolling your own Auth, and there is little margin for error with libraries like Bcrypt. So, unless I have specific needs (like multiple login strategies [google, facebook, github, etc]) I usually prefer to roll my own and fully control my stack. 
I look forward to reading them :)
You didn't mention phoenix, we'll have to know if that's part of the plan. I tasked myself with learning elixir as quickly as possible to evaluate it for a project and I found that learning it broke up into 4 groups. 1. elixir: which is a pretty simple language because its so well thought out. So you'll get that out of the way quickly. 2. OTP, which you have to learn a fair amount of or you'll feel like an idiot because knowing just elixir gets you almost nowhere. 3. Phoenix: you might need to tackle this, and its more complicated than "minimalist frameworks", and you'll have to figure out contexts, a recent pattern that seems designed to confuse newbies. 4. ecto: you'll get nowhere in phoenix without this, and its not at all trivial. 
I would be working on some API services, so I would assume Phoenix will be involved, but am not 100% certain. My previous (year-old) experience includes Phoenix 1.2.5 (and Ecto), so I'll have to learn about contexts. I don't have much experience with OTP. Maybe I'll make a web app to re-familiarize myself with the syntax and the new Phoenix, then get back to learning more about OTP...
Phoenix |&gt; Ecto |&gt; Making a REST API with Phoenix |&gt; Deploying Phoenix But I'm also an amateur elixir enthusiast. 
^The linked tweet was tweeted by [@ElixirConf](https://twitter.com/ElixirConf) on Apr 11, 2018 01:54:40 UTC (6 Retweets | 10 Favorites) ------------------------------------------------- Release the hounds! Registration for ElixirConf US 2018 is NOW OPEN!! [https://ElixirConf.com/#registration](https://ElixirConf.com/#registration) [Attached photo](https://pbs.twimg.com/media/Dad3AdqU0AA7UQP.jpg:orig) ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Seems you have good advice already for what to learn so I'll just mention; it seems to me there is no cause for panic. They hired you knowing they hadn't tested your full Elixir aptitude and knowing it's a newer tech, and like any dev job there will be some fast pragmatic learning required but don't be fooled into thinking everyone else knows everything about what they are doing. If the company is smart they hired you based on their way of judging conscientiousness, which since your asking your questions here I'm guessing you are strong. So good luck and feel free to message me if you have more to ask. I develop professionally (mainly with other languages but some elixir &amp; erlang). 
Thank you so much. What a relief this thread has been. This must be what imposter syndrome feels like. I might take you up on the offer to message you. I'm not hired yet, but if I get the next interview, I'm sure I'll have some questions :)
I'll echo others and say understanding OTP is probably on the top of the list. It's a fundamental part of how most Elixir projects are structured. If you don't already have it, I'd get Dave Thomas's [Programming Elixir](https://pragprog.com/book/elixir/programming-elixir) book. Helped me pick up the language fairly quickly when I first started.
Out of curiosity, what language is that service written in?
I need realtime messaging, I mentioned rabbitmq just b/c some of its features overlap a bit and I can see it being useful in my scenario at some point in future. I just wanted to say, it allows you to communicate with other apps while being quite a cheap.
It looks like you're using still using global under the hood. I may be missing something but because its still based on global if there is a partition in your cluster then you can end up in a split brain scenario where there are 2 versions of your singleton process. That may be fine for your use case but it would be good to document that somewhere in order to not mislead any potential users. I also may be missing something here so please correct me if I'm wrong.
That's probably true if you want to do server to server communication or have special needs with big loads because of lots of users signing in. In my case I'll be using my API for web clients, so I'm fine with http_only and secure cookies. I'll leave these here: * http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/ * http://cryto.net/~joepie91/blog/2016/06/19/stop-using-jwt-for-sessions-part-2-why-your-solution-doesnt-work/ I'll change my approach to JWTs when I think I really need them, otherwise cookies is the way to go for me now.
A thought: if they're purely an API it's possible it's just Plug and not phoenix. Plug is a pretty simple little framework! So don't fear, you could learn a lot about it in no time at all :)
Absolutely. I came from a small town to the city for these kinds of jobs and remember very well how it seemed at the time. Good luck, talk to you soon
Danke schön!
Yep, you've hot it right. I've added some commentaries to README on Github. Thank you! If you have any ideas about resolvig split brain - welocome with PRs
Our company recently put together a list of resources for our rails team to help them learn elixir. It might be useful to you as well: https://letoteteam.github.io/how_the_fulfillment_team_works/resources
No, I'm struggling with the same problem. Right now, the only option is to access it via REST using OAuth. See: https://firebase.google.com/docs/firestore/use-rest-api https://developers.google.com/identity/protocols/OAuth2ServiceAccount The underlying issue is that there's no solid gRPC support in Elixir, which is how other libs (Node, etc.) are using Firebase services. There's https://github.com/tony612/grpc-elixir but it's quite new, and probably because of that, no one has built on it yet. There's also some other stuff to read: https://medium.com/@KevinHoffman/mutual-tls-over-grpc-with-elixir-a071d514deb3 https://speakerdeck.com/tony612/the-way-to-grpc-elixir https://www.reddit.com/r/elixir/comments/4qrv6a/any_implementations_of_grpc_in_elixirerlang/ But for now, I'm planning on just using it via REST and revisiting the problem later.
While I like Elixir, I just imagine how this might be written in, say, C, and I feel that it would be shorter to write in C. Admittedly, that's because most of the article is not just about getting the task done, but other stuff are things we *ought* to be doing (creating a unit test, making a mix project, etc, etc).
&gt; Flapping tests are usually an indication of a race condition that is happening between the test suite and the browser under test. Many times, they occur because some asynchronous code is running and does not return before the test suite makes an assertion. This is super helpful. Thanks for writing the post!
You are definitely right that the goal here is not to find a simple solution but to explore tooling with a simple task. This code can definitely be written more condensed with Elixir. For example inline like this: ``` echo -e "ice cream\npizza\ncats" | elixir -e 'IO.stream(:stdio, :line) |&gt; Enum.map(&amp;("I like " &lt;&gt; &amp;1)) |&gt; IO.puts' ``` But then you are better off doing it in shell directly: ``` echo -e "ice cream\npizza\ncats" | sed 's/^/I like /' ```
I have found this article that goes with JWT for a REST API: http://blog.nathansplace.co.uk/2018/ueberauth-and-guardian Hopefully you'll find it useful.
Yes, this post is definitely not an introduction to all mentioned concepts (testing, repl, property tests, docs, ...). It is rather targeted at people that are already familiar with programming techniques and search for a quick example how to do things in Elixir. There is definitely room for another post explaining those concepts and when you would want to use them =)
If I were you I would maybe do a really quick refresher for Phoenix, like generate a 1.2 app and a 1.3 app with a JSON resource for each one and just take a quick look through each of them to see the differences. This will basically get you up to speed with contexts in like 15-20 minutes I think. One thing I would probably invest some time in if this were me is looking at Ecto queries in a little more depth. I don't use Elixir professionally, but I do use it regularly for a side project (as in, I probably hack on code a couple nights a week) and one thing that has never felt natural to me for whatever reason is Ecto. Not like you need to know every function for an interview or anything, but just in case they ask about repos and changesets or the two styles of making queries.. just to make sure you're familiar enough that you can talk about these things. Another thing I think I'd spend some time on understanding (again, if this were me) is applications. Very often when I add a hex package then I have to go and add it to my list of applications to start, but other than that I don't have much in-depth experience with them and I suspect that I should. I feel like if someone asked me to explain all about applications I'd just have a totally hand-wavy explanation, so if I were going into an interview this is something I might want to read up on again. If I were in a position to be hiring an Elixir dev to work on my project I think I'd want to ask them to explain how GenServers work. There's a lot more to OTP of course but I feel like if someone can explain to me what's going on inside a GenServer then they'll be able to learn and understand almost anything else. If you don't know how GenServers really work I'd recommend looking at Elixir in Action. There's a chapter in there that explains it very well in my opinion.
Nice post! Would love to see some throughput stats that we're captured or stats about the metrics system.
Thank you! I’ll keep that in mind for the next blog post
Wrong subreddit. Our Elixir is "... a functional, concurrent, general-purpose programming language that runs on the Erlang virtual machine". 
Isn't awesome elixir already like this, or the elixir forum? Anyway look's like a cool project. I'll definitely try and contribute once I'm done with uni. Good luck. 
In a way it is, but this is focused on projects only. Each project includes a description, author, title, website url, and source code url. I want to make it easier to find and feature Elixir projects. 
Built with Elixir and the Phoenix Framework: https://elixirfiddle.com/ Not open source yet
Awesome, it doesn’t have to be open source. I will post it on the site. Thanks!!!
Elixir and Erlang have binary pattern matching for this purposes. Try to read this article, there should be answers to all your questions: http://www.zohaib.me/binary-pattern-matching-in-elixir/ Here is the binary pattern matching doc: https://hexdocs.pm/elixir/Kernel.SpecialForms.html#%3C%3C%3E%3E/1 TL;DR: You can take `a[i]` using something like `&lt;&lt;_::integer-size(i), variable :: integer, _::binary&gt;&gt;` 
You could fetch individual bytes out of the string like this but it's probably not the ideal way to sum the bytes in the line. A more Elixir-style way to do this might be to write a recursive function: defmodule LineSummer do def sum_line(sum, &lt;&lt;h, t::binary&gt;&gt;) do case t do "\n" -&gt; sum + h _ -&gt; sum_line(sum + h, t) end end end Then you can do: File.stream!("foo.txt") |&gt; Enum.each(&amp;IO.puts(LineSummer.sum_line(0, &amp;1))) This treats the binary a lot more like a list, with a head and tail. It's like instead of having `["a", "s", "d", "f", "\n"]` you have `&lt;&lt;97, 115, 100, 102, 10&gt;&gt;`. With a list you would pattern match it as `[h|t] = list` and then `h` would be set to `"a"`, but in this case we're doing `&lt;&lt;h, t::binary&gt;&gt; = line`.
I am working on a terminal animation haha maybe I will add it over here. I was also considering making an MMO as ascii terminal game before I asked myself WTF
Type safety, help avoid SQL injection, query composition, automatically casting/loading/dumping from the DB types to Elixir types, etc.
Thanks for the quick response. I agree with all of the above. I think what I meant by raw queries was using a specific dB driver for elixir. https://github.com/elixir-ecto/postgrex/ Just like one has node-mysql in node which allows to have control over the query and still provide (most) benefits you mentioned. I am not adamant about not using ecto. Was just curious what opinions some of you have. 
google 'why should I use an ORM'
Well thanks for the reply. Afaik, it is not really an ORM. Although it is close to one. Ecto is a domain specific language for writing queries and interacting with databases in Elixir. It is something similar to ORM (Object relational mapper) but the fact that there are no objects in Elixir makes this statement invalid. Anyways, sorry for the noise. This thread is relevant to this discussion. https://elixirforum.com/t/is-orm-the-only-way-or-the-right-way-to-design-and-deal-with-data/6562 
OmiseGO stack is mostly Elixir. SDK is already published. Blockchain part is in progress (previous iteration is at github.com/omisego/honted)
Ecto can be used as little more than a connection pool, just sending string queries to the Repo. From there you can use schema-less queries to compose larger queries from smaller pieces. Add Schemas and you can describe types and relationships. So on the Query side, Ecto gracefully scales from a minimal library to a clever DSL. Then there's Changesets and Multi for updates. Changesets are an alternative to the change detection mechanisms in traditional ORMs, since Elixir data is immutable. Multi composes many Changesets into a single transaction. Once you grok Changesets and Multi, they can be used to structure code into a more pure functional style, separating the construction of the update commands from actually submitting those commands to the database. Then there's validations, migrations, test sandbox, logging, ... Lots of great features that you can opt into as you need. The only reason I wouldn't use Ecto is it doesn't support joins between tables in different PostgreSQL schemas, which might be problematic when working with an existing DB that makes heavy use of schemas for logical namespacing.
Thank you for such a detailed response. Appreciated. :)
I t is not an ORM because Elixir doesn't have "objects" per se but it is still a relational mapper. The What's new in Ecto ebook talks about this too: http://pages.plataformatec.com.br/ebook-whats-new-in-ecto-2-0
I really enjoyed this, thank you for sharing!
I still think you shouldn't encourage its use in new tutorials like these, and should point to headless chrome instead, at least so the tutorial stays relevant a little longer :) 
My advice is to write it without Ecto once. Then rewrite it with Ecto and take note of how much of Ecto's featureset you implemented (probably with a less-than-ideal API). I had a couple of projects where I objected to Ecto's perceived bloat and balked at learning the full API "when i just needed to do a quick update." My experience was that I ended up implementing a less-flexible API than what Ecto gave me, doing a lot more work to shepherd my data elsewhere in my app. It only took me a week or two of experimenting with a low-level API before I tossed it and just used Ecto schemas when I needed the database, and embedded schemas when I didn't. Ecto really doesn't cost much to provide you with a great deal of functionality you should really be using anyway (if you care about your app at all, that is...)
Thanks for the write up. This is an interesting way to solve the problem. We solve it slightly different in Wallaby. In wallaby you use declarative queries that describe how the DOM \_should\_ look and then Wallaby handles and the retry logic and blocking until that query either returns successfully or times out.
The [most recent Achemist Camp episode](https://youtu.be/m2NGQ9qnYsc) is on exactly this topic and covers a few different ways of doing it.
 I don't know... [Alchemist Camp](https://alchemist.camp) has over 50 free elixir learning screencast on the site and over 70 on YouTube. AFIK, that's far more than any other resource but awesome elixir still doesn't list it, but they do discontinued series, paid only screencast and in some cases ones that are badly out of date. It seems like it's a bit of an insider's club.
This talk was presented at ElixirSydney, to an audience of... tens of people. :D 
Thanks for the link. I don't agree with their sentiment exactly, but I can see why it's viewed as a valid stance.
1) Your player needs a real volume control, not just mute 2) Links to items from the podcast should open in a new tab (I lost my place more than once trying to follow along -.-) 3) I'm brand new to elixir and I have no idea who you two are, and it seems like you're not just two randoms in the community.. maybe an introduction would be a good idea? Other than that, it seems like you've done a good first episode.
Cool project - keep up the good work. Feel free to add https://elixircasts.io
Will definitely do, thank you!!!!
I just added more projects, thanks to everyone who submitted them. More features coming soon. 
Thanks for listening! Just wanted to address your comments: 1. We don't control the player. Its provided by [fireside.fm](https://fireside.fm) the service we use to host the podcast. I'll mention it to them though. We've been accepted to itunes \(and the google play store and spotify I think\) so you'll probably have a better time using an off the shelf podcast app or player. 2. Basically the same thing. We just submit markdown. I'll see if we can use an alternate syntax for links so they open in a new tab. 3. We'll try to do a better intro. We really want it to be very conversational which is why we didn't do anything this first time. We just started recording as soon as we opened zoom. We're not far away from rando's anyway. Just rando's who have been around the community for a while.
People choose it because it scales really well so if you had a project where you solved solutions around scaling you should highlight it. Numbers of concurrent users, how many nodes, what you did to distribute. Totally made up paragraph: "I wrote an online voting system that was required to handle north of 200.000 votes per seconds. I've built performance tests to prove it would hold up under load and figured out how to best spread the load over different nodes. The system performed fast and flawless with a peak of 850.000 concurrent voters over 4 nodes, backed by a single machine running a GenServer".
Why not make your resume in Elixir/Phoenix!
If I were evaluating someone's experience in Elixir I'd want to know in what capacity they used it and where they are in terms of understanding. Was it full-time? Do you understand OTP? What kind of scale did you work with? Did you have a hand in deployment and machine configuration? Was it a single node or multi-node setup? Do you have any open source contributions? How comfortable are you with the Erlang ecosystem? Elixir is still pretty new and finding people with experience is tough. If you have experience though, it's good to surface how deep that experience is (e.g. are you a beginner, intermediate, or expert?)
Full disclosure: I'm a technical cofounder at a startup currently, I designed and built our entire backend platform in Elixir with Phoenix, and have been an engineer and hiring manager at various points in my career. My 2¢ is that I would avoid characterizing yourself as a "StackX developer". To me, this raises a red flag every time I see it. If you're experienced and capable, I would suggest characterizing yourself as a "software engineer" or, if you want a narrower focus, a "distributed systems engineer". I see that you asked, "What skills...", so I think you're already probably thinking in this direction, but I just wanted to call it out specifically because I feel it's really that important. The kind of person a company is looking for varies pretty widely, but my own tendency is toward people with a variety of language experience and solid fundamentals. I would highlight your understanding of distributed systems, functional programming, databases, and cloud architecture over any specific focus on a particular language (i.e., "I know Elixir, Phoenix, Ecto, and ExUnit", or whatever). To me, when I see "Node developer", "Rails developer", etc., it gets translated in my mind to, "I don't have depth or breadth, but I make up for it by being able to recite trivia about this language, and it's the (only) one I know how to get things done in, or am willing to work with". This is admittedly not very fair, but it is an interpretation based on many years' experience working with people who identified themselves in this way. Another way to frame it might be to echo what others have said—do you understand OTP? Processes, Supervisors, and GenServer? I would argue that if you do, you're a capable distributed systems engineer in general, because these principles are the same whether they're at the architecture level (e.g., Kubernetes, etc.) or the application level, as is the case with Erlang &amp; Elixir, so calling out Elixir specifically doesn't really add a lot in my opinion. Ultimately, my point is that from a hiring perspective, I'd prefer a resume that highlights an in-depth understanding of fundamental distributed systems design (concurrency, streaming patterns, queuing patterns, etc.), functional programming, database design, and modern cloud architecture (containers, container orchestration, etc.) in *any* language over a resume that highlights that a person "knows Elixir". If you have the skills I called out, learning Elixir won't be an obstacle to you, but if you don't, knowing Elixir won't help you. 
JavaScript.
Here's to the randos! :)
This is a really cool project to see and makes me want to open source the next Alchemist Camp side project!
Knowledge of Erlang syntax &amp; NIF implementation is helpfull too
did you just spin up 200k processes?)
Thanks
Welcome!
Yeah, that would be great. I'm not sure how to do that with the CodeMirror (the JS code editor). It does do syntax highlighting and a bunch of features but I'm not sure how to work the autocompletion for Elixir. Any thoughts on how to do it with [CodeMirror AddOns](https://codemirror.net/doc/manual.html#addons)?
I would love some input of my situation. I am an "iOS Developer." Self taught, never taken a CS college course, and never coded outside of Apple's IDE, XCode. I would like to break out of mobile/frontend development and move towards backend development, and of course have considered Elixir/Phoenix. I'm currently a lead dev at a large, Fortune 500 company. Is Elixir an appropriate path for my first experience in backend development? Or is it too much to take in at once? Ideally, I would build Elixir projects on the side until I can find a opportunity that would pay comparable as my current role. It may take a couple years of personal project, but I'm okay with that. I guess I wondering if I will understand the void that Elixir fills without ever understanding the problems with more traditional backend languages and frameworks. How can I make the best of this situation and be an attractive candidate to someone in your position? Thanks!
thank you, I'm glad you like it. I will continue to add features. 
This is a thought-provoking question with many layers that strikes a chord with me on a personal level. I wish more than anything that I could give you a Medium-like "5 Ways to Achieve Your Dreams in Tech", but life is often about nuance, subtlety, and resilience and rarely about n-point plans. You usually end up having to do a kind of controlled slide gradually toward your goal, trying to figure out how to turn things outside your control to your advantage by adapting to _yourself_ to _them_, rather than fixing a point on the horizon, forming a checklist, putting your head down, and marching to the end, blasting through every obstacle. That being said, I'll do my best to share my perspective here and I hope it helps you! First, and this is just a subjective opinion, I'm not sure Elixir fills any void, really. I _love_ Elixir, and have enjoyed working with Erlang, too, in the past, but the problems that they solve also have other solutions nowadays, like Kubernetes, which is effectively the same kinds of things the BEAM and OTP were designed to do applied to cloud infrastructure and containerized applications, and serverless computing, which takes a different approach, but still solves many of the same problems. I suppose if Elixir could be said to fill a void, what it really provides is a) an on-ramp for developers with experience using modern languages like Python or Ruby to build web applications into the world (and mindset!) of building distributed systems in general, and b) language-level (rather than infrastructure-level) primitives and libraries for designing and crafting modern distributed systems. That being said, I don't think Elixir is too much, no. If anything, I think in many ways, Elixir makes learning these concepts a lot easier by bringing them all together and approaching them as core, fundamental building blocks. You _can_ build a fault-tolerant, scalable distributed system in Python or Ruby, but you'll lean hard on tools and techniques _outside_ the language to do so, whereas with Elixir, most of those are built right in. You can get _incredibly_ far with just OTP and EC2 instances running Elixir and nothing else! In any case, if you had to learn every technology that ever was just to understand the ones we use today, well, I think we'd all be in a lot of trouble! 😆You're also not trying to master every detail—you're trying to acquire the capability to land that first opportunity. After that, you can continue to build on your understanding. Being self-taught myself, one of the most important things I've discovered (which you probably know, as well) is that if you find something you _do_ know and are able to connect it in some way to something you _don't_, it makes learning new things much faster and helps the concepts stick with you longer. So, being an iOS developer, I would recommend starting with processes, threads, and dispatch (https://developer.apple.com/documentation/DISPATCH) within iOS/Swift, then move toward functional programming and try to apply the principles of functional programming in your current work. From there, you have a solid general conceptual framework to hang _new_ concepts off of, and can jump over into distributed systems, since you would be doing fairly similar things at a small, app-level scale to what a distributed system does at a large, cloud-level scale. You get the added benefit using your existing work to prepare for the work you want to do _next_, something that I've done many times and still do. From there, I think focusing on Elixir is a great idea. You _could_ also use serverless (https://s3.amazonaws.com/awslambda-reference-architectures/mobile-backend/lambda-refarch-mobilebackend.pdf) as a similar kind of learning tool, since even though you'll need an ability to _write code_ at a high level of detail, you'll also need to _design_ your solutions at a large, systems-wide scale, and this is what many engineers miss. But Elixir really brings everything together very nicely, so I think it's perfect for this task. While you're learning, I'd say try to avoid using libraries as much as possible and use the language and OTP to solve problems. You'll be reinventing the wheel a lot, but remember, it's not meant to be production code and if the goal is accelerated learning, handcrafting everything yourself will support that best, in my opinion. *Constraints like this force you to focus on understanding and solving the problem yourself.* Build a mobile backend for an app you made with just Elixir, ETS, Mnesia, and the rest of OTP and you'll learn just about everything you need to know that way. It's not so much about the tool, but _what is this tool meant to solve_, and thinking in this way will help you translate your skills across different stacks more easily. Stick to it, concentrate on developing your capability, and the opportunity will come. Some useful links: https://elixir-lang.org/getting-started/introduction.html (of course!) https://www.manning.com/books/the-little-elixir-and-otp-guidebook (my personal favorite Elixir book) https://github.com/donnemartin/system-design-primer https://github.com/checkcheckzz/system-design-interview https://github.com/binhnguyennus/awesome-scalability http://www.redbook.io/ Also, there are so many great talks, screencasts, etc. out there on Elixir, it would be pretty difficult _not_ to learn if you just dive in, and the community is *amazing*! Hope this helps, and good luck! 
I wrote a library to allow snapshot testing of json web responses https://github.com/sb8244/elixir_response_snapshot
What do you expect this line to return? :proplists.get_value(nd_nm_char_list, node) :proplists.get_value(999, [{'price', 999}]) It returns `:undefined`, You are passing `999` as the value for `nd_nm_char_list`. There isn't anything related to a closure here.
&gt; You are passing 999 as the value for nd_nm_char_list I'm not passing it
I got the same understanding as /u/haqkm. Can you put the whole contents and variables in a file we can execute with `elixir path/to/file.exs`?
Hi!! This is a really valid point :) I centralized all the macros and "heavy lifting" in `Errol.Wiring` precisely not to have the DSL take over your codebase, just define the *wiring* and let the rest of the implementation be about passing functions around. I don't see an easy way to use behaviours to define this and still have the supervision tree set up for you, but if you have a clear idea I'd love to see an issue proposing an alternative DSL going in this direction! I didn't want to force people to use macros either, that's why the `Errol.Consumer.Server` module is also fully documented so you can start a consumer on your own without going through this DSL. The reason to have this macros is that I wanted your `Wiring` modules to be compiled into a `Supervisor` that you can then handle/supervise/start the way you prefer. Another proposal for defining consumers would be to use something like: ```elixir &amp;UsersConsumer.account_created/1 |&gt; consume("users.account.created") |&gt; bind(""account_created") ``` but you wouldn't be able to use this macros on their own I didn't see the advantage besides making it look more like *the elixir way*. Thanks for the feedback! It's very much appreciated :)
Great little project and write up, thanks!
The Scrap Exchange is definitely a treasure :\) Thank you for the tip about the services page \-\- fixing it now.
Gotta ask. Is there a real-world example where property-based testing is useful. To me one test-case is usually enough. Mathematical induction kinda way. If it works for one or two, you can assume that it works for all. Also I'd imagine that doing a lot of property-based testing would slow your test-suite quite a bit.
From the top of my head, I can pick the following example. Suppose you are saving the payment details of a user. Those details consist of Cardholder name, last 4 digits of credit card and an expiration date. You write the test and use "John Doe" as a cardholder name. Everything works fine, until one day some user decides to an emoji in the cardholder name. And you get: ``` "Incorrect string value: '\xF0\x9F\x94\x94' for column 'cardholder_name' ``` Could you prevent that kind of errors, yes for sure. If you think of emoji before releasing the code. But I guess in most of the cases you (not you exactly, hypothetical you) won't think about every possible case. If you have a proper string generator to use in your property-based tests, that might help to catch the case and maybe some other. Even if you think about special characters in the name, you need to provide several tests to cover all those cases. Again, property-based testing may do that dirty work for you. And reduce the number of tests. Is it slower? Yes, sure. The testing is all about trade-offs, sometimes you may want to sacrifice the tests execution time to get more robust coverage. Of course, that does not mean you need to use property-based tests everywhere. 
Even the emoji example still requires you to create string generator with emoji case in mind. So I'd just create a test case with emoji input.
Even though, you do it once for many property-based tests.
Yeah. I think it's a matter of having a use-case when you need generator of inputs that can cause edge-cases and you can apply it in many test-cases. So many cases.
This video tweeted from the elixir-lang account a couple days ago is a very good example: https://www.youtube.com/watch?v=AfaNEebCDos The stream_data repo also has some examples of properties that were used to find/understand bugs in Elixir itself: https://github.com/whatyouhide/stream_data/blob/master/test/stdlib/string_test.exs
Nice. Those are great examples.
Nice!
First time hearing of alchemist.camp. Looks nice!
If my wife wasn't in school I would totally apply. I love Germany! 
That's very exciting! Have you also announced it on the [Elixir Radar](http://plataformatec.com.br/elixir-radar)?
Yes, I have :)
That's too bad! Once she finishes you should check our website, we always have new positions available.
Isn't it possible to just update the article in place?
&gt; past data can be used in the future in ways that aren't immediately apparent If only all devs thought this through. Thank you!
Instead of using render, just use: html(conn, html_content) [check the docs](https://hexdocs.pm/phoenix/controllers.html#rendering) for more info.
They said the talks would be available within the next month. Check their YouTube channel regularly to find out when they upload them https://www.youtube.com/user/ErlangSolutions, but I'd guess they'll be posted in this subreddit as soon as they are available.
First video from Lambda Days (also organized by Erlang Solutions) were published after one week, the last video after month. So I guess with Elixir Conf will be the same
ah...icic
Love me some HTTPoison. One thing I noticed is that your require Logger is not in a module but global. You probably want this in the module: https://github.com/f1sty/retall/blob/master/lib/github.ex#L1 https://elixir-lang.org/getting-started/alias-require-and-import.html#require In the iex examples, they're globally applying it; this is good for demo but not best practice.
Thanks for your feedback. Yeap, gonna fix it. Also this is escript is more like on a prototype stage, so there is still much more to fix:)
I &lt;3 U
The [unicode module in Erlang](http://erlang.org/doc/man/unicode.html) supports converting to and from unicode and that's it. Elixir doesn't have something like a Latin1String module that works on latin 1 - although one can probably be implemented by hand without much work.
Awesome post. I hadn't read the series so I thought "hey, is that the hexdump guy?" when I saw the hex dump
Easier than supporting Big-5, for sure!
Well, it supports unicode out of the box, but as you can see in the article you can convert from ISO-8859-1 to UTF-8.
https://www.youtube.com/user/ErlangSolutions/videos The first few videos just went up, figured you might not get a notification on youtube but might here.
oooh bootstrap, yeah that makes sense. It's hard to tell. 
The sheer amount of work required just to get the project going is staggering. So I suggest you begin anyway. Then show us the progress or if bored/failing — you can quietly drop it.
I love this idea. Some of dialyxir's messages are baffling. 
If it's successful outside Elixir then it could be, but there are significant technological challenges with doing so (and why it hasn't been done). There is a PDF paper out there explaining why success typing is the strongest type system possible for the Erlang VM but I can't find it at the moment. There's also a EVM vs JVM PDF that's pretty good as well (on my phone so hopefully someone can link them).
In general, I think this could be done to a degree. The biggest technical challenge are process boundaries since sending a message is basically a type information void. You'd lose type information anytime you cross a boundary, local or distributed. Same goes for apply calls since the function you're calling is often a runtime value and can't be verified at compile time. If you scratch those things (and maybe any others I've missed), you may still be able to get something useful out if it. Just don't put the expectation that you'll have an Elm quality, fully type spec'd compiler because until you can find a way to computer those runtime boundaries at compile time, it won't happen.
I would be really interested in reading that PDF if you have the time to find it. I guess I'm not sure what you mean by "The best possible for the Erlang VM". As far as I know, the VM can be completely separate from the type checker. For example, flow type is a powerful JS type checker that's built in OCAML. Obviously, I would like to write the type checker in Elixir if possible, but it seems to me that the Erlang VM shouldn't add much in the way of road blocks.
Great point about process boundaries. That has been in the back of my mind since I decided to start looking into this. I wonder how other strongly typed languages handle this. I think Scala with Akka is pretty close to the OTP model in some aspects? Maybe I'll give that a look-see.
&gt;They're referring to \[the original paper\]\([https://it.uu.se/research/group/hipe/papers/succ\_types.pdf](https://it.uu.se/research/group/hipe/papers/succ_types.pdf)\) on success typing, but they don't make nearly as strong of a claim. It's worth reading regardless, imo.
There’s a PR in progress to make them better. https://github.com/jeremyjh/dialyxir/pull/118
I guess you're already familiar with the Elmchemy project?
Another great write up! Keep up the awesome work! 
I recommend you to read the recent discussion in the forum: https://elixirforum.com/t/how-to-make-dialyzer-more-strict/13854/33 As José and others pointed out, it is unlikely you can convert typespecs to a ML-type system such as Haskell / Elm without having to compromise on something, such as type inference or the amount of typeable Elixir code, as typespecs are much more expressive than ML-types.
Thanks Dave!
Nice project... :) I see that sandbox Lua counts function calls in the sandbox, and tries to limit functions that can allocate large blocks of memory ... that's great already. Have you also considered wall-clocl running time and memory usage? The former would be easy from the elixir side, the latter with ulimit's on the ous sandbox ...
I faced a similar problem in the past with a library I was making, where I wanted to show relationships (including messages). The way I decided to handle it was to create files which could contain a list of matches, that would match against the arguments passed into a gen* modules message sends. While that served my use case just fine, for a typing tool it would only solve half the problem. Another issue that comes up is you won't necessarily have access to the typing information of the destination. As you can send messages to a server that isn't an explicit dependency of the project sending the message. And then there's the whole issue of runtime generated code. But as you gave the example of wanting to make it work like Elm's static typing, maybe you could solve all of these problems the same way as Elm handles ports. So essentially just treat it as a blackbox. Although then you're basically just ending up with dialyzer again with the exception of better warnings, and forcing that everything needs to be typed. 
Yes sorry, that's more accurate.
You can actually already pass in timeout and reduction values to limit it I guess based on the code examples in the repo. https://github.com/rvirding/luerl/blob/develop/examples/hello/hello_sandbox.erl As for memory consumption. I may be alright because scripts in my case are supposed to execute in under 3 seconds or die, but will probably still look for a solution down the road. My solution will probably revolve around the sandboxed code running in its own beam process that I can track memory on / kill if needed.
I'm reading some Erlang books that will help with running production services. Namely Erlang in anger and the recent happi book that was posted here. Learning about GC and things to avoid has been very enlightening.
That's a clever way of logging in to a site.
I love this article. 
Doesn't pg2 use global which basically means joining a group puts a lock on all nodes?
It's missing at least one: crash a NIF.
good shit. i've been keeping my eye on beamjit since i heard about it.
That is 100&amp;#37; correct, but since I never did that myself \(I never wrote a NIF\), I wasn't able to \_show\_ how to do it or to see what the result was ;\)
In Phoenix, the "view" is used to render the results. https://hexdocs.pm/phoenix/Phoenix.View.html The defaults are to render content using templates, but you can play games, e.g. rendering results in code or having the same method handle different output formats. For example, one API we have supports XML and JSON this way: def render("error.json", %{reason: reason}) do %{error: reason} end def render("error.json", %{changeset: changeset}) do %{error: render_errors(changeset)} end def render("response.json", %{response: response}) do response end def render("error.xml", %{changeset: changeset}) do XmlBuilder.doc(:result, [XmlBuilder.element(:error, render_errors(changeset))]) end def render("response.xml", %{response: response}) do results = for {key, value} &lt;- response, do: XmlBuilder.element(key, value) XmlBuilder.doc(:result, results) end defp render_errors(changeset) do errors = Enum.map(changeset.errors, fn {field, detail} -&gt; "#{field}: " &lt;&gt; render_detail(detail) end) Enum.join(errors, "|") end defp render_detail({message, values}) do Enum.reduce values, message, fn {k, v}, acc -&gt; String.replace(acc, "%{#{k}}", to_string(v)) end end defp render_detail(message) do message end
&gt; Do I need to put the logic in a separate function and just call that function for both the API and the template controllers, or is there a better way of doing this? Yup, that's exactly it. This is entirely the motivation behind Phoenix's concept of "contexts" - putting your application logic in a separate layer that's NOT tied to the web. I highly recommend reading the [Phoenix Contexts](https://hexdocs.pm/phoenix/contexts.html) documentation.
Yea, more specifically it uses \`global:trans\` which acquires a lock on terms of the type \`{{pg2, group\_name}, pid}. It's a bit more fine grained than nodes.
Just wanted to add here that returning `render(conn, :index, videos: results)` will dispatch to `render(conn, "index.html", ...)` or `render(conn, "index.json", ...)` depending on content-negotiation.
I set up transactional emails via Swoosh and Amazon SES, because it writing welcome emails to all the learners who signed up on [my site](https://alchemist.camp) each day was beginning to become a drag. I'm going to automate password recovery next. After that, I'm going to start working on some gamification to motivate learners and on compiling good external resources that can help with various elixir-related tasks. I also recently bought *Phoenix in Action* and am looking for some time to go through it.
Huge undertaking! That said, as an ML fan, I'd love to have stronger checking. I understand the historical reason that dialyzer had to use success typing and only reject programs it can prove to be wrong, but I'd love a from-scratch type checker that only _accepts_ programs it can prove to be right (from a type perspective), at the expense of rejecting some valid programs. I know people take issue with Elm's types. I don't know Elm, but from what I understand it doesn't support Higher-Kinded Types (HKT) like Haskell. But I don't know if that's the extent of it, since rust also doesn't support HKT, but is plenty productive. I believe pony lang is a typed actor based language with message passing, so I don't see why inter-process communication would make it impossible. Worst come to worst, some sort of hacky approach just for GenServers would solve 99% of my message passing use cases! Obvious inspirations are facebook's flow and TypeScript. Another random thought I just had about typed messages is that sounds a little like protocol buffers or cap'n proto. A lot of software is built with those, and those messages have encoded types and some degree of polymorphism. I think if your type checking is rich enough to match those, it should be fine for production code. &gt; What features would you want to be included? * At the minimum sum ("enums") and product ("tuples") types. * Conveniences for handling `nil` (a la Swift's `?`). * Exhaustiveness checking * Some amount of polymorphism (this is where it gets hairy and I'm not super clear on what the levers are here).
How long are talks supposed to be?
They’ll be full length talks, so around 35-45 minutes (with break time in between of course).
Wow! I’m so excited about this, thanks for the heads up, hopefully I can make it!
We hope so too!!
As a general rule I'd say you should be relying on the higher level abstractions most of the time. It's good to learn the underlying principles of spawn, send, and receive to understand what's really happening when using gen_*
Unless you really need to make something that spawns a lot of processes efficient or some other edge case I can't think of, you should probably use the OTP abstractions. You can get better integration into the tooling (better hot code upgrading integration into release tooling, enhanced debugging/tracing support, sasl logging reports). You can roll your own OTP abstractions and get all that free integration via `proc_lib`: http://erlang.org/doc/design_principles/spec_proc.html
I haven't been writing much of it myself. I was digging in the task code to see the difference in two functions. The task module is essentially a wrapper around send and receive with some basic edge cases handled. I think I'll stick to it when I find myself needing that behavior. Otherwise, lots of genserver call and cast.
Even if you're writing your own behaviors, there's usually an existing abstraction you can build on. If nothing else, a gen_server will do ya.
I think this is a cool project. Keep it up for sure. I'll look at using it for a project to see how it works out.
Generally you won't. Most of the time you'll be using OTP abstractions, but if you find you have some code where you won't ever need any of the functionality OTP provides, then that's when you normally would use those lower level operations. However elixir already provides a number of other less feature-full abstractions such as agents and tasks (as you mentioned). So generally you'll just use those in that situation. Only time I can think of using receive is in two situations. The first is where you might not want not want to spawn a new process from the caller, but the function still expects to receive a message from some other process (that isn't the typical spawn a task workflow). The second is if you had some really complicated receive pattern/synchronisation (maybe you wish to do some work sometimes rather than always waiting in a receive loop), but I'd be very skeptical of why you'd want this (overhead of just spawning new processes as needed likely won't matter). 
If you don't require a dsl, I might suggest https://github.com/infinitered/elasticsearch-elixir. ES has a lot of good docs and knowing exactly what calls are going on could be beneficial. AWS elasticsearch should work with any library as it's just a URL exposed
I'm using that lib, it fits my needs very well and it's pretty simple.
A multiplayer web game I've been working on [https://bulletz.io](https://bulletz.io) it's still in pretty early stages and isn't really fun at all but hey it's getting there!
Aren't agents and tasks built on top of genserver? They are *more* featureful, if I'm not mistaken
My bad, looks like an agent is. A task also seems to follow OTP (rather than simply being a spawned process as I assumed) as it's using proc_lib under the hood to spawn the process. 
I've been using Elastix, works well, very simple. Doesn't cover everything, but it's a nice wrapper.
I started a project with that library and we intend to pull it out. It doesn't do much for you, and if there is an error with ES, it doesn't tell you what it is at all. We've just used the direct http interface everywhere, so at that point you may as well use a regular http library.
I released a new version of my project (https://github.com/sirko-io/engine) which is aimed to predict and precache resources (pages and assets) which might be requested by the user in their next transition. Thus, when the prediction is correct, resources are served from the browser's cache. Actually, there are 2 parts of the project: the backend in Elixir and frontend in JS. The prediction model is very simple, so I am looking for improvements now.
That would be actually an great feature... 
[This](https://hexdocs.pm/iex/IEx.Helpers.html#open/1) is the best answer I could come up with: open Some.Module.fun/2
Links!
Nothing fancy yet, just a little app that connects to the Reddit API that scrapes post score over time and inserts the data into elasticsearch. Fun to see the trends of posts over time.
I tried to sign up, but got an Internal Server Error. Just figured I'd let you know.
https://www.erlang-in-anger.com/ is the one I've read so far. It's about 85 pages of content and doesn't go too deep into nitty gritty things. Makes it a good read. I am going to start https://happi.github.io/theBeamBook/#introduction soon
Thanks \- Yeah I think using supervised GenServers to represent the agents and using another GenServer to represent the "stage" makes for a pretty easy to maintain parallelizable game architecture. Writing an [Agar.io](https://Agar.io) clone would be pretty fun \- if you do it definitely drop me a DM and I'd love to look it over with you/let you see how I structured this game/work on it a bit.
If I do it wouldn't be for quite some time. I'm already working on a game that uses Unity as a front-end and I'm trying to get that out before I move to something else.
These benchmarks are super promising. I'm always a little discouraged as how low elixir/Erlang/Phoenix is on the TechEmpower benchmarks. I know those benchmark very specific, even esoteric things (and very much do not encapsulate developer happiness), but hopefully these changes will allow a few uptics in overall throughput.
I wrote this post to detail some lessons I picked up while debugging why 200 websockets would take over 500 MB of RAM sometimes. I ended up getting it down to multiple thousands connections in almost no RAM overhead.
I had a similar problem in production. Specifically: I was sending big payloads when clients were joining the channel and only sending small updates later on. From what I understand this caused big heap allocations for websocket connection and transport processes, and the GC was never being triggered because memory usage in these processes practically wasn't growing. My solution was to manually trigger gc in both processes after handling the join. Code can be found here: https://groups.google.com/forum/#!msg/phoenix-core/OCVzVm4C9PA/XG205gCVCgAJ (ws_info :garbage_collect callback has been added to phoenix so there's no need to fork it anymore)
Is there a rejected PR to show someone tired to add it and failed? I thought the awesome series was just community driven.
One reason is that python has a lot of the best libraries for this type of work.
Can you give some examples ? I would like to learn a framework like Keras.
Where to even start? It all builds from numpy and scipy and pandas to scikit-learn, spacy, nltk, gensim, pytorch, first class tensorflow bindings, the list just goes on and on. For what OP is asking stuff like Dask is coming up.
Floating point math is pretty slow in BEAM. Of course you could use native functions, but AFAIK you lose out on concurrency and they are not feasible for long operations like multiplying huge matrices. However, there is a book called “Handbook of Neuroevolution Through Erlang” that you might want to check out if you are interested. Probably the only book on machine learning in Erlang. Also, if your are looking for Erlang-like concurrency with adequate floating point math you can check out Scala. Akka framework implements actors that are close to Erlang’s processes and JVM has multiple linear algebra libraries.
The problem with AI in Elixir for me is that BLAS computations heavily rely on internal mutability of some data (ex. matrix multiplication). While you can implement it in C and then just expose proper NIGs in BEAM there are other problems: - Dirty schedules became default only recently, till then one CPU heavy process could overtake whole processor time. You could use ports or servers, but then you would get nothing from BEAM only troubles with maintaining connection - Python seems easier to grasp by mathematicians, especially as there is much more tooling like gplot integration, IPython, etc. That is the same reason why Matlab, Fortean and R are die hard in their respective fields (engineering, math, statistics) - There are other languages in the field that provide functional features, top of the shelf example is Prolog which is here longer that Erlang itself - Elixir is young, and creating such libraries take time, a lot of time, especially in immutable languages - No big player backing on such project. Tensorflow have enormous backing and Python API is first-class citizen, one could even say that Tensorflow’s Python API is treated better than native C++ - If you ask question “why nobody” then ask yourself “why you don’t” and in most cases you will get answer to the both of these questions
Tensorflow?
They are all just wrappers around C libs though. 
Python just calls into C libs for all that work. I presume Elixir can do the same.
I don't for the same reason I presume others don't. The path of least resistance already exists which is python. I guess somebody has to blaze the path.
In fact, Pandas is often calling C or FORTRAN written in the 1960s. We could call those libraries from Elixir using NIFs, but it's not really playing to the strengths of the platform. Generally speaking, managing a pool of Python processes works pretty well, as long as the serialization overhead is small relative to the work being done. Concurrency and working with large data sets is a general issue for Python: http://wesmckinney.com/blog/apache-arrow-pandas-internals/ Elixir can fit into this pretty well as an orchestration layer. It is also generally good for processing binary data. While Elixir is about half the speed of C, it is very easy to take advantage of all the cores on your server. On a podcast people were talking about processing uploaded JPEG images at large scale to extract the location from the EXIF information. Using Erlang actually performed very well at this. 
I just pushed a library to hex that helps define struct-to-struct mapping functions. It's called cartograf, and while it is still early days for it, I think it could prove very useful in a few scenarios. The use case that drove me to make it was having to convert between protobuf structs, structs used for ecto, and structs presented to the user through my web-api. With cartograf though, it is super easy to create a function to convert from one struct to another, no matter how the struct shapes and fields change. The documentation isn't complete, but the tests are in case anyone wants to pull it down and play with it. https://github.com/Herlitzd/cartograf
It can and we are doing this for photogrammetry where I work. Soon machine learning as well, so maybe we will end up with reasonable bindings to tensorflow or similar soon :)
Re: tensorflow... the C API is designed for bindings and they are moving more of the functionality to the C++ implementation and exposing it via the C binding API. Why? golang bindings, which makes tons of sense if you think about who is behind these projects. Training looks like it will remain easiest in Python for a while but applying trained networks to data which is where the practical applications are is there for the picking. Being able to conveniently apply ML as part of your phoenix app would be rather nice :) We are using it for semantic segmentation of images and 3D models and have made first steps to driving that from Elixir .... if we manage something useful from the exercise we will share it :)
How will it help me?
To be fair you could rank it in the top 20, but its because there are not enough books to fill 20 slots. I do mean to read the book though. I used Elixir for some computational biology stuff. It worked well but was probably not efficient.
Pretty much all of these are built on top of C wrappers. Or they are derivatives of those libraries.
For individual tasks, this makes sense. I think OP was looking for Machine Learning tasks which are usually serialized as you indicated. I'm not an expert though.
There's a GSoC project for Tensorflow bindings (https://summerofcode.withgoogle.com/projects/#5406400314867712)
Can Julia and Erlange/Elixir work together (i.e., good combo of strengths/weaknesses)?
&gt; NIFs running for more than 1ms can cause errors and performance side effects, like slowing down the scheduler. That restriction is gone nowadays if you mark it as a dirty NIF: [http://erlang.org/documentation/doc\-10.0\-rc1/erts\-10.0/doc/html/erl\_nif.html](http://erlang.org/documentation/doc-10.0-rc1/erts-10.0/doc/html/erl_nif.html) &gt; A NIF that cannot be split and cannot execute in a millisecond or less is called a "dirty NIF", as it performs work that the ordinary schedulers of the Erlang runtime system cannot handle cleanly. Applications that make use of such functions must indicate to the runtime that the functions are dirty so they can be handled specially. This is handled by executing dirty jobs on a separate set of schedulers called dirty schedulers. A dirty NIF executing on a dirty scheduler does not have the same duration restriction as a normal NIF. 
Is there a reason you can't just call `Process.sleep/1` in the new process, before it does anything?
Oh wow, that is fantastic news. Will try to get in touch with them!
Not as nice as nifs, but yes you can drive julia scripts from elixir.
You should edit your post to include the real problem you're trying to solve. This screams _XY-problem_.
You should shift your mindset.
Yes. They run on a dedicated set of “dirty” schedulers (two sets technically: CPU-bound and I/O-bound). If you try to run more dirty NIFs in parallel than there are dirty schedulers, they’ll queue up. Since Erlang/OTP 20 long garbage collections run on dirty schedulers automatically. On 21-RC1 the file I/O functions are also implemented using dirty NIFs, rather than an async thread pool. There’s a good explanation here: https://medium.com/@jlouis666/erlang-dirty-scheduler-overhead-6e1219dcc7 and here: https://github.com/tuncer/re2/issues/9#issuecomment-184846992
Awesome. A couple of years ago I wanted to write a distributed neural net learning using actors and I ended up picking Scala and Akka because of the problems with NIF's. Would be interesting to use some C matrix lib now with dirty schedulers and see how it stacks up against Scala.
Sure but it’s a lot of effort still they are not just loading some shared object libraries. Elixir has a lot of the properties that make Python popular for this kind of thing and even some that python doesn’t as op says but Python is basically a de facto standard along with R at this point.
Again. It seems to me that a highly distributable and concurrent language would be a natural fit for this kind of work
You're arguing with the wrong person.
And they all exist now so people can do real work with them now
Thanks I'll keep an eye out for your stuff. I am just starting to get into photogrammetry and processing of remote sensing equipment. 
oh, cool! if you end up doing anything in that vein with elixir, drop me a line in case there is mutual interest and we can collaborate ... 
I am an absolute noob at this stage. Frankly I don't even know where to start so I am just reading at this stage. 
Everyone starts at the beginning :) feel free to ask questions if you run into anything puzzling ... and happy hacking!
Cause it's slow for number crunching. I did Erlang with Project Euler and it's slow as hell. Your other comments seem to comment about distributed. There's disco (http://discoproject.org/), if that's what you want but number crunching isn't it. If you're gonna say python stuff is implemented in C/C++ and whatever, then I'm going to point out writing NIF safe code without messing with BEAM schedule is hard. Python and R doesn't have such a complex state of the art system of concurrency so the C++ implementation doesn't have such a restrictions to care when coding. The best BEAM is going to be is to provide the infrastructure to enable batch process or real time process. I don't believe there is a good momentum to do ML in this language and unless the ML paradigm changed enough to fix the BEAM model of concurrency. An example is website just happened to fix the concurrency model of BEAM. There is some weird fringe stuff such as https://www.springer.com/us/book/9781461444626 . Since erlang's process can be model as graph or neural node. 
Honestly where do I start? Is there a tutorial someplace that you know of? What's the algorithm for mosaicking or orthorectification or creating DEMs and such?
openmvg has some really good documentation that covers quite a bit of the algorithmic side. but each of the topics you listed are not small topics on their own. it's why tools like arcgis are so popular. but there is info online as long as you are willing to search a bit. e.g. on orthorectification: https://www.google.ch/amp/s/www.geospatialworld.net/article/review-of-digital-image-orthorectification-techniques/amp/
A few reasons come to mind: * Scientist that use scientific computing are often people that don't write code all day. They just want to write the code and get it done. In that sense, they are more likely to stick to a language that they know or that feels similar to one they know. Functional programming and the actor paradigm are great, but they take some getting used to. Compare that to just using a language you already know. * Libraries such as Numpy offer a great amount of functionality out of the box. As far as I know, elixir and erlang don't offer similar libraries. At the very least the community around those libraries is way smaller. Also worth noting that these libraries are implemented in C which makes them very fast. * BEAM is not that great at raw computational speed. Where it really shines is low latency when responding to requests, but that's not very relevant for the types of applications you're talking about. * Even if you're okay with all of the above, rewriting an algorithm in a different programming paradigm is *hard*. Furthermore, some algorithms don't get much use out of extra parallelism (Amdahl's law), so just spinning up a few extra instances in python might be enough to get all the parallelism you ever need. 
It's important to break apart the concept of "thread" in the Elixir language. You don't have traditional threading model and it becomes easier to think about when you think about the process model. In Elixir's case, when you spawn a new Task or start a new GenServer, a process is created. That process is going to wait for incoming requests (GenServer) or execute a function (Task). In either case, if you call `Process.sleep/1` from the Task/GenServer, you will make that process, and only that process, wait the requested amount of time before executing. I would use this if wanting a Task to wait. If I was wanting a GenServer to do something after X seconds, I would use `Process.send_after/3`, which will send a message to the process after a certain amount of time. Because GenServer responds to messages to do work, you can think of this as saying "do this work in X time". For your question, Task/sleep seem like an acceptable solution.
Arcgis seems like a black hole where I am going to throw money into for the rest of my life. 
The link from the PaperClip CFP back to the main site doesn't resolve. It's missing the www.
Nice series of posts. One semi-non important question/observation: This is the first time that I've heard/read this approach as being called a `Token Flow`. I've always heard of it referred to as context. Is this how it's commonly referred to?
Short answer: https://davejingtian.org/2017/10/06/why-list-and-charlist-are-confusing-in-elixir/ + https://hexdocs.pm/elixir/Inspect.Opts.html
When you are not sure what a value is in `iex`, put an `i` at the beginning of the expression: iex(2)&gt; i Enum.to_list 7..12 Term '\a\b\t\n\v\f' Data type List Description This is a list of integers that is printed as a sequence of characters delimited by single quotes because all the integers in it represent valid ASCII characters. Conventionally, such lists of integers are referred to as "charlists" (more precisely, a charlist is a list of Unicode codepoints, and ASCII is a subset of Unicode). Raw representation [7, 8, 9, 10, 11, 12] Reference modules List Implemented protocols IEx.Info, Collectable, Enumerable, Inspect, List.Chars, String.Chars
Thanks for the tip I will remember that
Erlang legacy. Otherwise if you would write `'abc'` in IEx session you would get `[97, 98, 99]`. 
I've seen context and middleware. I've never seen it called `Token`. Trying to google it just gives me a bunch of articles about OAuth2. All that checking of the `halted` property at every step feels like a very manual version of a monad.
To my knowledge, this is not commonly referred to as Token. I used the word "Token" in this series to illustrate how this "thing" is moving through a business process (similar to a Token on a game board).
I used the word "Token" for this blog series on a concept in Elixir. I have also seen this called a context before, but that term has another meaning in the world of Phoenix. &gt; All that checking of the halted property at every step feels like a very manual version of a monad. I wish I could speak to that, but my knowledge of monads is very limited. The described MO is simply how Plug, a popular Elixir library, does it. I really liked it from the start and finally found the time to explain it in a series of blog posts. 
&gt; Nomoko Was it you the guy presenting "Rendering the World: 3D Reconstruction at Global Scale On the BEAM" at the Beam lite conference in Milan?
Guilty as charged ...
Great talk I really enjoyed it
Ah cool, glad you did! Had a blast there, and look forward to the next conf I can get to ...
BEAM is very good at what it does, but I don't really like Erlang's syntax.
Having started to dabble in more 'functional' programming concepts in JS, Elixir felt like a good way to increase my understanding of those ideas using a grammar/syntax that I enjoy. I also kind of bought into the party line about the stability and capability of Elixir/BEAM as a way of managing the backend.
honestly? cool name, cool looking syntax, cool terms like "fault tolerance", "easy concurrency", etc. in practice im just a web developer so i cant really take advantage of most of the things i learned because im too fucking dumb. so i decided to go to uni and im now in the second semester of my first year of an actual CS course that im enjoying a lot (but im still at the basics relatively speaking)
I finally began to understand Erlang’s conventions after a helpful conversation with someone at work. Elixir made more sense after that. I found myself frustrated with python for projects that went beyond prototypes. I wanted the properties of the erlang runtime and so instead of approximating it I decided to use it. I have been happy with my decision. I learned it at work porting a prototype from python to elixir. Launched it and found it ran continuously for months after without hiccup. 
I want to build telephony things. Erlang's history in the industry combined with Elixir's rad syntax makes it a good choice.
the branding is on point
My professor invited me to go with him to the first Elixir conf in Austin because he knew Jose. Listening to all the presentations was very convincing. My other two favorite programming languages are Ruby and Clojure so it was an easy sell for me :p
I had heard of Erlang before, but I never invested any time into learning anything about it. I knew it was created as a telecom platform and I knew what OTP stood for, so I just didn't look any deeper into it. I had used Ruby on Rails for a couple web projects and I basically liked Ruby. I think because Jose was very involved in the Ruby world at the time I learned pretty early on about Elixir and I just read his "pitch" about it somewhere. The syntax had that very basic, surface familiarity of Ruby (same as C++ and Java had for C programmers - different language, but just a hint of familiarity that makes it easy to get started). His "pitch" was more about how Erlang's features were designed for telecom systems but just happened to solve the same things that we're trying to do in web systems these days. So I played around with it early on but it wasn't until Phoenix matured that I tried building anything with Elixir. Phoenix/Ecto/mix help get things close to (but still not quite to) Rails's productivity, Elixir's general simplicity makes everything feel more understandable and maintainable to me compared to Ruby, and Erlang/OTP runtimes make things fast and stable. As Michael Scott would say, "Win win win."
Out of all the languages I know, it is the most elegant, with a real lot of thought out in its design. I love the white paper driven approach of its development.
For me a lot of micro reasons to enjoy it over others but the one that tops; the competitive advantage possible to gain in many types of web projects compared to other language/envs. I'll build it faster and better
Took a position and inherited a Ruby on Rails app. This thing was built by a 15 year vet but it’s a mess. It’s so fragile. Every little change has massive side effects. I can feel the aftershock ripple through the codebase. It’s not small either. I’m not saying you can’t build crap in elixir but I’m over tracking down mutable state transformations. Plus I’m ready for a change. I also believe elixir will be see a wider adoption and will prove to be a lucrative career choice. In 10 years when someone inherits my crappy elixir app they’ll be pissed off they can’t just mutate state and then they’ll rebuild it in “Python on Bike Lanes”. 
Because the language and tooling is very neat and precise. I never felt that I am learning a functional programming language. I tried Clojure earlier but parenthesis was bit off putting in addition to functional programming concepts. Digesting these two at the same time was not healthy :)
because I was learning erlang and wanted to use a popular web framework 
I had a co-worker who I look up to who was really hyped into it. He knows I like to ride the wave and so he started talking about it more and more. Next thing you know, we have about 3-4 microservices running and more on the way. Biggest reason I wanted to learn it was to just expand my horizons and he swore by it.
I started a side project and I wanted to write it in Clojure but felt like context switching from Ruby (which I used at work) to Clojure might get annoying. Elixir &amp; Phoenix felt like it might give me the productivity I was used to with Rails with the some of the benefits of Clojure (FP, thread first macro, immutable data, good concurrency story, etc). One year later, I switched jobs and now use Elixir at work and on the side and couldn't be happier.
Come from a Java and C background, very interested in the concurrency and fault tolerance approaches built in. Always wanted to get into Erlang due to OTP and the above reasons, but couldn't be bothered to learn the esoteric syntax. I at first had a hard time because I despise Ruby, but Jose and Co. really succeeded in making Elixir only cosmetically related to Ruby. The Dave Thomas book also had me pumped. Currently I enjoy it because it fits the niche of in between a quick bash script and a full fledged java microservice. I can crank out a scheduled fault tolerant job in a maybe a few hundred lines of code. While this isn't terribly impressive itself, it has the "batteries included" feel that you don't get when you try to schedule a ruby script or java jar in cron. I had always thought the raw performance could be better though, but it really hasn't been a problem so far.
Because it's like Scala just a million times better
I already loved Erlang. Thus learning Elixir, a beam language with a more fresh and new approach, seemed a logical choice to learn for my „one programming language a year“ approach. And I didn't get disappointed: I love Elixir.
Was php web dev. Dabble around in nodejs and erlang. Realize Erlang was awesome. Hang out at Erlang meetup. Erlang peeps asked, "why don't more dev use Erlang?" I basically said, "Erlang needs something awesome like Ruby got Rails." They all disagree and said it's bullshit and still wonder what's wrong with Erlang adoption rate. Elixir came about and the community seems better. It's like Ruby less like Erlang peeps at the meetup. Elixir missed the boat that Ruby had, Elixir is coming in where web dev market is saturated but everything is fine. Less hype probably less tribalism unlike Ruby or NodeJS bs. Ruby had a lot of tribalism especially early day they were shitting on jruby and then rift between main core Ruby and other implementation. 
I was working on a .Net project that, from what I knew of the BEAM via conference videos, was a shitty clone of the BEAM. Then I made a rough proof-of-concept project in Elixir for one of our many services. Without _knowing_ idiomatic BEAM or Elixir practices (but knowing a fair bit of FP), my POC was 3 orders of magnitude more efficient than our .Net implementations. From there it was easy to convince managers that using Elixir was worth the effort and then I needed to get better at it.
Had an eye on it in the distance for a bit. But since others shared most of my favorite reasons I’ll mention another. I was big into Clojure for a while but soured on some community culture things such as how beginners were treated. It was an experts only club in way and if you wanted to join you really had to do the work. I always felt that software is more a people game so I immediately recognized Elixir’s community had nailed it and really cared about investing in that aspect. Instead of fighting learning it was a breeze and probably the easiest language to learn for me to date. I also liked that Elixir is very lisp’y. If you haven’t looked at the macro system or AST it’s basically a lisp. But the great thing is Elixir can have is all the benefits without the purity of being isomorphic which IMHO is super cool but doesn’t make my programs better. Also best documentation of any language 
 * I needed a websocket that could handle large volumes of messages * The problem was almost stateless * Needed a high level of reliability * Needed a high level of scalability * I hate JavaScript * I worked with F# before * For street creds
Same here, tried to sign up but wouldn't let me.
I heard about it on the Ruby Weekly newsletter, and at the time that was exactly what I was looking for. But it was this video: [https://www.youtube.com/watch?v=SVisr\_gYA1w](https://www.youtube.com/watch?v=SVisr_gYA1w) that got me really excited about learning it.
I've been dabbling a lot more into Erlang and honestly if you got rid of the punctuation I'd probably like it more than elixir. There's something about all the `do..end` that's been starting to bug me for some reason.
For simple tasks Elixir is a functional, dynamically typed language with beautiful syntax and pretty damn good performance. It is so easy and enjoyable to use Elixir to solve small problems. For more complex systems it provides powerful and easy to reason about cuncurrency. Honestly, after learning elixir I don’t think I will ever use a different dynamic language. 
I was going to learn [Nemerle](http://nemerle.org/About) because of the macros and somebody on Hacker News suggested I look into Elixir instead. I did and haven't turned back.
I wanted to write a simple, actor-based, 2D online game server. It results in [lkn_core](https://github.com/lkn-org/lkn-core), and a demo game server called [lykan](https://github.com/lkn-org/lykan). Still a toy project, but it has been a very fun and pleasant journey so far.
I do not know of this setting, although I still have some advice that might be applicable: Have you looked at setting fullsweep_after to something lower, like 10 or even 0 (extreme, always do a major gc)? This could give you the benefits you're looking for.
The JVM and the EVM work completely differently in this respect. The EVM does not have a single heap to even set a size on, there's one heap is contained within each process. I'm not sure but I suspect the per process heap size to be unbounded, though you can look around for it. The more common scenario is to discard the entire process so that no garbage collection cycle is needed at all. There was an article not too long ago that talked about this but I'm on my mobile and don't have time to find it now. Can you explain more what symptoms you see and what you're trying to fix? Memory management is quite different due to immutability, so there may be some tips we could give you if you post some sample code.
I needed to write some configuration management software, and I was looking for a dynamically typed language with syntax niceties. I already had a lot of experience with Python and JavaScript but couldn't bear having to use them for new software. My prototypes in Clojure and Rust didn't work out very well. Everything about Elixir felt right as I started learning it, so I kept going and I'm still very happy with it two years later.
Its syntax is nice and it leverages decades of best practices and patterns available in Erlang / BEAM VM. When I learn a new language it's usually because I have something to build in mind and this is no different. I could have built the app I'm building with frameworks I know very well (Rails and Flask) but I chose to use Elixir / Phoenix because I think learning a functional language could potentially make me a better programmer in general. That are there are a few components of the app where I know I'm going to benefit from Phoenix channels. Also, I don't treat learning new languages as a drop in replacement for something else. Elixir will just end up becoming another tool in my tool belt. Perhaps over time I'll use it more, but it really comes down to what type of libraries are available in the languages I know when it comes to building out projects.
I want to create a library for creating a image made by titles or mosaic. Something like this [https://nearsoft.com/blog/putting\-it\-all\-to\-work\-elixir\-poolboy\-mogrify\-andreamosaic/](https://nearsoft.com/blog/putting-it-all-to-work-elixir-poolboy-mogrify-andreamosaic/)
1. I assume this is locally. Hot swap can happen locally when watched files change. Phoenix has this setup out of the box and it works well. It's fast enough that I've never thought about it. 2. Distillery does package the BEAM VM (erts) by default. This is why you need to compile packages on the same architecture OS as what you'll be running in production. 3. There is `mix test --stale` and also there are test watchers, but I haven't used them. It looks like https://github.com/lpil/mix-test.watch supports --stale option as well. In general, I feel like Elixir / JS are pretty non-comparable. You can use a JS actor model, but it fundamentally is going to have differences from how the erlang process model works. You will surely be able to create an efficient workflow that allows you to be productive and fast.
BTW, this is what Phoenix uses for change detection https://hexdocs.pm/phoenix/Phoenix.CodeReloader.html. Note it's a plug and requires that the request comes through the web. You could put this in a non-web environment through a timed genserver or something if you wanted to.
I wanted to code in a functional way. After doing some tests, I ended using it for every pet project where I needed a backend. BEAM is very good and the syntax makes it fun to code.
Thanks for your reply, however recompiling into IEX every time I change a file is not gonna work when I have too many files. I don't think crashing would be a problem, we have supervisors, right?
Thanks for your reply, this does sound really good. And yes, I meant locally for development purposes only. I agree Elixir and JS are totally different languages, however, as long as you implement the actor model correctly, the differences don't matter. Still, I much prefer Elixir since it has a good community and there are many tools available already. For JS, the few libs that do implement the actor model are incomplete.
Awesome, thanks for the link! It is definitely something I'll try and adapt for my needs.
Thanks for your reply, how fast would you say the recompilation is \(for a more sizeable project\)?
I'm not 100%, but I think recompile only compiles files that have been changed! 
I'm actually pretty sure I'm wrong in my previous comment. Only the file that has changed gets recompiled and the virtual machine handles the rest of the linkage changes. Which means that it is all dependent on how fast the module compiles. I've never really worked on a significantly large project, so I've never paid attention to compilation.
You are correct now and then. There is a mix task in Elixir called `mix xref` that shows how modules relate to each other in a project. If they have a compile time dependency, then they are recompiled at compilation time. Otherwise the VM handles the rest at runtime. 
What I'm looking for is easy and efficient distribution and a way to structure code so that it will be easily composable. The actor model fits both of those bills. I think just starting distribution at the process\-level rather than VM\-level \(and optimizing based on locality\) and enforcing isolation harder \(throwing errors via linter or build system\) is enough to get it to work for most practical problems. The bigger issue is the lack of tooling. A different runtime like Beam.js \(which is dead\) with bidirectional integration would've been the best, but it seems like that's not gonna happen.
One solution around this is to simply cluster NodeJS across all cores \(and use the same distribution patterns you would use for horizontal scaling\). Another solution would be to use a multithreaded runtime like Nexus.js or just invent a new one with the actor model built\-in. I agree the actor model isn't a first\-class citizen in JS, but once you've got an actor model working, you can abstract the details away and just think of your problem from the new layer. It may sound unorthodox to mutilate JS to the point where it doesn't even resemble it's old self, but this has been done before succesfully.
There is no reason you can't use node to file watch and run certain tasks. ie. nodemon --ext ex --exec "mix test"
Oh very cool. I didn't know about that mix task.
"It may sound unorthodox to mutilate JS to the point where it doesn't even resemble it's old self, but this has been done before successfully." I'm pretty sure that this is the foundation of JavaScript. (joke)
It kinda is, tbh. It's the embodiment of the "Improvise. Adapt. Overcome" meme.
Easier to statically analyze Elixir code within Elixir. And if I want to change a source code file and have the tests files associated with it run \(maybe not even the whole files, just the tests that affect that file\), it will probably be easier to stick within the same language.
The right article at the right time. We're just getting to a stage where our first Elixir project goes into production in a few weeks and we're still figuring out best practices. Thanks a lot!
For that you can use hot code updates. They are reasonably straightforward, similar to database migrations, but for GenServer state. If you use a map to keep state, then it is easy. Much better than the old days of Erlang records. On the other hand, you will always have connection glitches in, e.g. a chat system. So if you build in a way of reconnecting on failure, then you can deal with it, thou you can get a thundering herd of reconnects to deal with. Depends on the application. We use Blue Green deployment for AWS. It doesn’t keep from dropping connections, though it could allow a smoother transition, i.e. taking down one server in the ASG at a time.
Another approach if you have really sensitive requirements could be to maintain a separate set of servers for websocket connections and bridge the communication between the websockets and the main application via Node.connect or possibly a different distributed communication mechanism. This would allow deploys to either codebase w/o impacting the other, but you would need to make sure that the API contract doesn't change.
I think you may be interested in cortex https://github.com/urbint/cortex
Does this one help, or thinking something different? https://stephenbussey.com/2018/01/08/designing-elixir-supervisor-trees.html
Thanks! Please let me know if you don't see anything that you'd benefit from. Every suggestion helps me balance my writing list over time.
I think deployment is one very topic that needs much sharing. I'm coming from dockerizing node apps and using it with kubernetis. Is using something like kubernetis even a good idea with the Erlang vm?
I had so much trouble with erlang/elixir deployment... it's just easier to give up and use docker or whatever works.
Some metaprogramming would be nice
Utilizing Elixir alongside big data tooling (Spark, Hadoop, Elasticsearch, etc.).
This is what I did as well, but I'm curious to read about it and look at alternatives!
Web dev in general. Express and Flask make it look so "easy". I would like to see more articles around "look how easy it is to {spin up a web server, parse csv, resize an image}". Less emphasis on "coming from rails". I feel the narrative doesn't fit a lot of developers who are interested in elixir/phoenix. I, for example never touched rails in a workplace until about 1 month ago, but I've worked with PHP and Python for many years prior. (I actually think PHP developers are a large pool of people who'd be pretty happy coming to elixir/phoenix). I second content around deployment. More information about production deployment would be awesome. Especially using AWS, GCP, Azure etc. An aws employee on twitter called elixir developers neckbeards who don't use the cloud anyway. I would like to see that narrative to change. More structured beginner friends tutorials would be excellent. For example, in python https://automatetheboringstuff.com/ is a common suggestion for new devs. Content along those lines would be great to get developers to try elixir. Automate the boring stuff [Elixir edition] would be pretty valuable.
I'm surprised by this - granted I've only used Distillery inside of Docker but I found it to be pretty straightforward. There are a few gotchas that I never solved (like reading from STDIN) but for the most part it was much easier than I was expecting Our primary Elixir app runs in Docker and Kubernetes though. It feels like we reinvented the wheel going that route but it does fit better with all the rest of our infrastructure and gives us freedom to not use Elixir without losing a ton of functionality
From one of our project retrospectives - think about how things fail and how you want them to restart. We originally separated things by domain in their supervision trees and at the end of the day just wound up with a bunch of global processes (sometimes pooled or sharded) that had strong dependencies on one another. They maintained a lot of state so one going down can cause cascading failures throughout the system until things normalize, and those failures tend to be cause big interruptions. We've eventually gotten to the point where these dependencies are at least one-way dependencies, but it's still not where I think we want to be Today we probably would've broken things up a lot more - many processes with small bits of state that can crash and reboot themselves properly. Our app is essentially a task processing framework so we have heartbeat processes for our workers, stuck detection for jobs, job dependencies which are managed via queues for each processor, and all sorts of recovery mechanisms. If we could change things we'd probably create a tree of all of these processes that manage one single worker instance/job and then scale that out by creating more instances of this process tree, tossing them in supervisors for fault tolerance. But right now it's just a bit of a big global mess (which to be fair has uses as well such as making analytics, monitoring, and inspection easier)
This is a good suggestion. That twitter comment sounds nuts! Where can I find this?
The issue is that reasoning about restarts is very hard for newcomers (and sometimes even experiences devs). My recommendation is to actually think about the startup. What is the order you expect processes to be started? That takes them 90% of the way. After they do that, think about what should happen when each of them fail: is the supervision strategy appropriate? If so, ship it.
&gt; An aws employee on twitter called elixir developers neckbeards who don't use the cloud anyway Good god, you cannot be serious...
This happens when the VM can't talk to epmd (the port mapper daemon). If you have any firewall rules or something else is listening on that port already, there may be an issue.
Can you elaborate more on this problem?
pretty excited for his new book.
This sounds like a fun idea to explore. I'm sure there's some super elegant way to approach this in erlang process architecture that I'm not sure about yet. Would be interesting to research though! Off the top of my head, it could be beneficial to have a process which holds the pool and then that pool can be dynamically resized (close pool and re-open of different size if pooling mechanism doesn't allow dynamic size changes) via a genserver call back. There could be a process that polls every minute looking at the count and adjusts the pool size at thresholds. Downside here is that unless connections can be transferred between pools (or pool dynamically sized), you would have a reconnect period. Will probably look into this further over time! Thanks for the idea.
&gt; I'm sure there's some super elegant way to approach this in erlang process architecture that I'm not sure about yet. Right? I feel like there *has* to be something I'm missing, and that I can't be the only person to ever want to do this. I just can't think of what it is. 
I would say they are complementary. Kubernetes is a standard solution for packaging and deploying apps. If you run a lot of apps, you want your ops team to be able to manage them without knowing all the details. You get better utilization of your servers by allowing them to deploy standard units and manage resources at a higher level. You can put an Elixir app into a container and deploy it, but containerization doesn't provide as much value as it may for other languages. The Erlang VM doesn't depend much on the operating system. The mix build tool tightly manages runtime library dependencies, and building a release combines the VM and the app's libraries into a single tarball that you can deploy as a unit. So we don't find it particularly useful to use Docker/Kubernetes to deploy. Erlang/Elixir makes it very easy to take advantage of all the CPU cores available, so you generally benefit from having one instance with lots of CPUs instead of lot of little instances. And it can be a lot cheaper to do this in a dedicated server environment instead of the cloud. So on the whole, Kubernetes is not that big a win for Erlang, but they work fine together. I expect that we will be using it more in the future as public cloud offerings like GKE become more mature. Right now, we mainly deploy to dedicated servers and cloud instances using AWS CodeDeploy. I am in the process of writing a big blog post series on deploying apps in production: https://www.cogini.com/blog/best-practices-for-deploying-elixir-apps/ It includes a template for building and deploying apps using Ansible: https://github.com/cogini/elixir-deploy-template
I actually just discovered dynamic supervisors before seeing your comment, but thank you for the explanation! I think that helps me a lot.
 epmd: up and running on port 4369 with data: name rabbit at port 25672 This is the response i get from epmd -names. And typing epmd seems to return no errors, but it doesn't indicate anything happened...
So epmd is definitely working and there is already a node connected to it. You can try killing it via the activity monitor (or command line) and try again.
https://www.rabbitmq.com/networking.html It seems rabbit also uses the epmd and it is already running epmd on that port as I'm running rabbit in docker. Could this be the issue and how do I work around this? Do I need to start a new epmd on a different port, or some how allow iex to use the same one as rabbit?
I sorted it now, thanks to your tips that pointed me in the right direction and updated my OP to hopefully help anyone in that situation. epmd was working but it was an instance running in docker because I'm running rabbitMQ in docker and rabbitMQ runs its own epmd (hence the `name rabbit at port 25672`) when I checked `epmd -names` I simply changed my system EPMD port to something other than the default and started a new epmd server and it worked fine! Thanks for the help!
I am not anti cloud, I do a *lot* of cloud and DevOps work. For example, we recently migrated a customer from bare metal to AWS. They have a dozen Rails apps, each running in dev/test/staging/demo/prod environments, and they need to run in multiple countries for legal jurisdiction and performance reasons (US, EU, China). There there are definitely advantages to the cloud. It's better than the legacy self hosted mess that many companies have. The health care world has mostly decided that Amazon is "secure", so it's a lot easier to get through compliance reviews if you are hosted in AWS. On the other hand, there is a lot of cost and complexity to the cloud, and some people don't understand that there are options. The cloud vendors are all "rah rah cloud," but who is there to talk about bare metal? I also work on high volume Elixir systems that run dozens of those $100/month servers, and the hosting bill would be pushing $100K on AWS. From an Elixir advocacy perspective, we can definitely reduce costs and improve reliability: See my presentation at Ruby/ElixirConf: https://www.cogini.com/blog/presentation-incrementally-migrating-large-rails-apps-to-phoenix/ I am doing my part to show regular devs how to get things running: https://www.cogini.com/blog/best-practices-for-deploying-elixir-apps/ and https://github.com/cogini/elixir-deploy-template I am working on another series which uses Terraform + Ansible + AWS CodeDeploy to deploy to the cloud. The complexity is pretty high, though. I am looking forward to hosted Kubernetes reducing that, but that needs some time to mature. While I would love to see Elixir support in Lambda, you are not really taking advantage of Elixir. Lambda is nice for small chunks of code which respond to events and interact with the AWS APIs, but not for larger apps with persistent state. The security model is a big question. Amazon could provide [Erlang on Xen](http://erlangonxen.org/) hosting, but it comes down to the pricing model. You can do it yourself now, building your own AMIs and deploying them to an ASG, still pretty hard core. You are relying on AWS infrastructure to respond to demand, and it's not that fast.
We use Gigalixir and it has been very smooth. 
It feels like the author is missing the main complaint about `gen_event`, which is the poor error semantics. If a `gen_event` handler crashes, it is gone forever, unless you write a good amount of boilerplate code to add it back.
For the record I really enjoy your blog and I hope you keep putting out great content. I'm not trying to critique any one person. I wasn't advocating for Elixir in lambda (Although if it was an option I would probably use it). Elixir and OTP pretty much negate the benefits of lambda. It was brought up and an AWS employee on the serverless team had a perception of elixir I didn't like. I don't want that perception to propagate and put off potential newcomers. Obviously, they have an incentive to keep people on their platform. Selling elixir can be pretty hard. At least where I live. I believe getting some content out around the "basics" would help. Of course languages like java, node, and python and a huge head start. Just as a suggestion for content I'd like to see, I would like to see more basic to the point content. Like I stated "Automate the Boring Stuff - Elixir Edition" would be pretty a pretty valuable resource. Regardless, Elixir and the libraries tend to have great documentation and I look forward to fresh content coming out daily. 
I honestly read the article 3 times and couldn't extract something interesting and/or useful :/
Sure, why not. I've been doing elixir professionally for two years now -- why did you start learning elixir and what are you trying to get from if?
The book is a good start, but I mean, metaprogramming is a good topic I am interested the OP could write about.
I started learning elixir because I was interest in a job opportunity that used it. I ended up not taking the job, but I loved elixir and have kept learning. I want to become familiar enough with it that I'd be confident in using it for more than just side projects. 
Still typing away at my sci-fi mmo. I do have a playable build that people can try out if they're interested. https://s3.amazonaws.com/plex-dev-builds/plexdev.apk It's still very much an alpha but feel free to leave comments here or in a PM.
You should check out the elixir forum, great community and a lot of helpful people (my handle: hlx)
Telephony use erlang and have a downtime equal to 32ms per year. I decided to learn some erlang stuff but it sound like a really hard language because of the syntax. So I move to elixir and then I discover a really amazing language that use some amazing feature that help you to think differently (eg. Pattern matching, functionnal programming, meta programming ...). 
Be specific what would be the bare minimum product features and how much would you pay for it?
I don't think he wanted to commission one, but was wondering that given the high overlap of elixir/Erlang selling points and needs for these API gateways how come nothing had already been written for this market. I'm also pretty sure that its for this exact reason that most elixir/Erlang people don't encounter the issues that need an API gateway in the first place and so don't feel the pain points that cause their introduction.
I don't think a generic proxy exists today as a product, but you can certainly build one. You can use [Terraform](https://github.com/poteto/terraform) to do this in a Phoenix app. You can also use [Absynthe](https://absinthe-graphql.org/) to do this using GraphQL as the front end interface. It's useful as a way of making existing apps more reliable. I cover that in [this talk](https://www.cogini.com/blog/presentation-incrementally-migrating-large-rails-apps-to-phoenix/).
I'd be happy to review code. I don't have as much stuff available to review in return, but, I mentor frequently and have done Elixir at a previous company. So, can certainly give my fair share of opinions. :) 
Awesome. Yeah, I'm also looking forward to (and curious about) the Mix improvements. The basic idea that it pretty much always makes sense to defer config to runtime is why I made [DeferredConfig](https://hexdocs.pm/deferred_config/readme.html). Or, rather, to defer the filling of patterns like system tuples, or mfa tuples, to runtime; makes it easy to test a prod binary artifact on a dev's machine by just tweaking ENV vars, make it Mix-agnostic, etc. I feel like 'app env as a way to configure runtime behavior dynamically during the lifetime of the service' isn't such an important use case -- we have ets and many other options available as sources of truth/ways of changing or polling for the current 'settings' for a running service; app env is a poor/limited API by comparison. It's suited to values that are known at compile-time, even if they're not fully evaluated until later.
Threatened? Why?
Well I get that Elixir is further ahead in development than this one, but its a decentralized crowdfunding platform built on Ethereum... sound familiar? 
One of us is confused. Elixir is a programming language that as far as I know has little to nothing to do with the crypto currency scene. Is there an elixir coin or crowdfunding platform you’re referencing?
Well the main reasons I can see for using a API gateway is for fronting applications that don't handle concurrent requests well, that don't offer high availability, handling versioning differences, etc.
I was so confused
Really liked this article. I've been feeling much the same regarding configs. Although what turned me off was not just poor runtime configurability, though that was a contributing factor. My other issue came about from how I was designing my system, I opted for building microservices as separate projects (rather than a single umbrella), so this led to development and test environments having to keep duplicating the copy of all of the configs from the other services. Which overtime started to become very annoying. I've experimented with some ways of tackling that issue, some brought about other issues. I eventually settled on something that solved some of the issues but was still less than perfect. But I like some of the ways you mentioned solving the problem, so will probably be revisiting this once again in my projects haha. 
That's awesome. Sometimes I just need some opinions. If you're on the elixir slack, DM me your handle
Accenture built something along those lines: https://accenture.github.io/blog/2017/11/09/introducing-rig.html 
Platformatec's blog posts a lot of stuff on elixir. Not sure how to filter it for language (en and pt) or on Elixir tags.
I've been working on a free/libre video surveillance system written in Elixir/Phoenix with a mostly react frontend. I'm hoping to distinguish my system by offering very high performance through hardware acceleration of video decoding on various platforms, including the raspberry pi. And also transparent reliability, in the sense that it recovers from errors and tells you when something is wrong that it can't recover from. For example, if your disk is full or if the system can't write the disk fast enough, it will give you a precise, actionable error. Once I get a few more pieces in place I want to implement video analysis by feeding frames to machine learning based object detection systems running in a port. Focusing first on tightly constrained problems with real utility: Is there a package on my porch? Is there a car in my garage?, etc. Elixir has been a joy to use so far. The main hangups have been with documentation, especially supervisors. I couldn't figure out how to use the new DynamicSupervisor with phoenix. Oh well I'll keep using :simple_one_for_one until I can't :)
We have feeds of our blog: * https://www.cogini.com/feeds/atom.xml * https://www.cogini.com/feeds/rss.xml It's a bit eclectic, covering development, devops and startup product design, so you might prefer to select by category: * https://www.cogini.com/feeds/category-development.atom.xml * https://www.cogini.com/feeds/category-development.rss.xml or by tag: * https://www.cogini.com/feeds/tag-elixir.atom.xml * https://www.cogini.com/feeds/tag-elixir.rss.xml
There is Saša Jurić’s site: http://www.theerlangelist.com/rss
We're replacing our dynamic SQL query engine written in ruby and replacing it with our new QueryEx package. We're also planning on porting over our security layer called Securables to elixir in the next few weeks. I expect us to be running this in production in about two months. https://github.com/markglenn/queryex Basically, this allows you to build an API for a SQL database that includes side loading data, automatic joining of tables, and your basic filtering and sorting. We've been using our Ruby version in production successfully for the past 5 years, but it's hard to keep it running fast due to the speed of ActiveRecord.
I run my local Python on Bike Lanes meetup.
The question is not about api behind the gateway. It’s about the gateway itself. There no api gateway that work like a proxy ( but with more features ) that use the Erlang machine :/
Wow it seem awesome. if I understand the client subscribe to some event and does not consume directly the data. I mean, basically in API world people use http verb with parameters to obtains / create data from/to an endpoint. Here it’s like the client just ask to get notify if an event occurs. If it’s been like a think it can be amazing!
I think it's quite a good use case for Elixir, especially when the back ends are less reliable or able to handle load. We also get to write code in Elixir that runs in the proxy instead of lower level languages or snippets of lua. I am not sure if the requirements are generic enough to make it a standalone product like HAProxy as opposed to a collection of plugs to handle different requirements. 
Would [this](https://github.com/Nebo15/annon.api) be the kind of thing you're talking about?
Yes i think, I gonna check and maybe participate thanks a lot!!!
Launched my first elixir project the other week so I’m working on refactoring it. It’s a sweary travel guide called [What the fuck should I do in?](https://whatthefuckshouldido.in/). It’s not too complex as it saves a bunch of results from foursquare locally and then randomly picks one, but for some reason some foursquare queries only return a few results, whilst others return &gt; 90. I’m also working on my second project, which uses public data about politicians. Turns out there’s a lot of politicians in the world, so it takes more than an hour to seed the database. I tried using tasks to parallelise it but it didn’t seem to work, so I might take a look at that soon too. 
Cool article! I'm inspired to finally give Credo a try.
I'm working on some imaging bindings for libvips and opencv.
I had been using Erlang (so already loved the Erlang VM) and I heard about this new language being developed on top of the VM. Checked it out, it was still early in development but it had taken shape where it had features I wish Erlang had. Some of these things were things like the powerful macro capabilities (as opposed to Erlang's simple C-like preprocessor), the build system, etc. 
Why are you trying to use DynamicSupervisor with phoenix? You can split your functionality with Phoenix being only your web “frontend” (the frontend of the backend). This way you can call any function from your Phoenix controller.
Sounds really cool. Maybe in the future it can be expanded to more sources other than Foursquare. It is pretty much dead in my country :(
What services is more used where you are?
Thanks for the reply and given what I wrote it definitely makes sense. My application is actually split between a backend and a phoenix frontend so what I said was wrong. What I meant is I couldn't figure out how in my application.ex to start a DynamicSupervisor. Looking at it now I guess I'm still using the deprecated Supervisor.Spec module.
There is no default. Apparently people gave up contributing to platforms like that one on Mexico
What about Yelp?
Alchemist camp on YouTube
Just now saw your comment here. I narrowed that problem down to an interaction between the referral marketing service I've been using and certain JS ad\-blockers people have been using. I believe, based on the logs, that you did create an account and should be able to log in with the creds you provide.
I have four years or so of anonymous Elixir experience but with a nomadic schedule so wouldn’t be able to commit to much but would extend a private offer if you PM me we can trade emails and even text/phone if needed.
Hey, welcome to the community! Hit me up with a PM if you ever want someone to kinda just chat with or pair with.
On mobile so no way to test your code but take a look at Ecto.Multi. https://hexdocs.pm/ecto/Ecto.Multi.html
Test with benchee. Parallelize it, not sure if a 296 ms average is bad or not for ecto, but you are running them serially. 
I realize Im doing it sequentially, and that wasn't ms it was seconds as in like 5 minutes. Incredibly slow, this is not really a parallelization issue just yet.
Just to be clear and isolate the db have you ran it with creating the user maps and everything else except the changeset and insert?
...296 ms _average_...
How are you generating the password? If you're using bcrypt make sure it's 0 pass so it's really fast.
I dug into coherence's password generation and it seems you may be on the money there
Yep there you go
I do live coding on Twitch three times a week. You can find the channel here: https://twitch.tv/joebew42. What I do there: try to contribute to existing elixir open source projects, build new playground projects, learn something new about elixir, practice Clean code, TDD and Refactoring :D
Yes. I don't use it now but just reading 200 pages of a beginner book opens your eyes in some kind of way. I was programming js, c, python before. Genserver, supervisors, and the process spawning stuff is just cool. 
Highly recommended! Joe's stream gave me the motivation to keep learning Elixir. Now I have some Elixir related works on my side-hustle! Thanks, Joe!
The deal itself may be moot, but I agree with the poster’s assessment that Phoenix is a ready replacement for RoR/Node.
Consider opening a bug report on coherence because they should instruct users to set the pass to 0 by default in the test environment.
Ive found this to be more true of Erlang. Although Elixir / Erlang are effectively the same language.. the emphasis with more of the Erlang learning resources is more about a different way of programming, specifically focused on error handling and robustness. The emphasis with more of the Elixir learning resources are more about how it can be a replacement for, say, Ruby, but with multi-threading for free. This is just what i felt when reading Elixir / Erlang books, and it's not to say that the Elixir books don't cover the same stuff as the Erlang books, they do and they are very good.
Yeah I opened a feature request
It's really great to have state so separated from logic. Even when I try to do it in different languages things tend to be hard because most libraries are not built with that style of programming in mind.
My path was: - Syntax - Data structures - FP (use pattern matching, etc...) - How to architect the project (files, modules are not classes, etc...) - Grabbed an OTP Erlang book. (Beautiful syntax, somewhat annoying) - Read code and try to contribute Good luck
Upload your code to github and dm me for feedback. I’m more than happy to help.
I recommend reading the [Getting Started](https://elixir-lang.org/getting-started/introduction.html) guide. It's fairly short and lays out the features pretty well.
It helped really understand concurrency and race conditions in other languages that share memory. 
actually, learning any language brings new insights to your "main" language. After learning elixir I've really looked in some parts of JS I never thought of before, also python is good to learn for nicer naming and overall aesthetic part of your code. 
It is an elegant language, that and I tend to write complex web applications that incorporate different microservices for things like machine learning classifiers or job queues or for my latest project I'm looking to build out a microservice for syntatic correctness checking for different programming languages and between elixir's decent FFI, OTP + the languages first class idea of umbrella apps AND being compiled so its much quicker than ruby and I am a happy guy.
Macros are amazing and I don't know how I'm going to go back to languages that don't have them. There are things you can do with them that you cannot do in other languages without crazy duplication. Take a look at `kernel.ex` if you get a chance and look at ALL the language features you can implement with them. When you get to sufficiently large code bases, they create abstractions that allow you to DSL over the wiring and create very expressive solutions to your problems. 
There is a focus on reliability. Ruby programmers are all like, "look at this new DSL I have for making HTTP requests." Elixir programmers are like, "cool, what if it times out?".
Cheap and easy processes mean that you can model the natural concurrency of your application. You get a request, handle it, give a response back. Or you model a chat system with one process per connected user, and one process for the chat room. The code is simple. In other languages, you have to deal explicitly with non-blocking I/O, thread pools, synchronization.
Is there an archive somewhere? Twitch seems to only have the three most recent videos?
If you’re doing this, also use the param option on the resource function to specify a better key for your slug parameter (i.e. name in this case).
Hi, unfortunately Twitch keeps only recent videos! I am thinking to export videos on YouTube and create a sort of permanent archive there.
Elixir has some amazing properties. But for me, unfortunately I gave up on it. The main reason - it has lower productivity than Ruby / Rails or JS / Node, more verbose and more complicated. It's true that Elixir is way better than Node.js - but the thing is for most apps what we need is cheap and fast development, as for robustness and great performance and stability - those are not so important. 
I'd find that interesting! I was looking for your videos about building the chat service, but couldn't find them.
I haven’t dug too far in Elixir but it isn’t as hardcore as Haskell. Haskell is more an academic language. It is good to learn (especialy learn you a Haskell book/site) because you go through relearning how to manage state and to make pure functions, how to avoid side effects, and write good functional code, then you get to monads and realize reaity is not that clean. Those concepts are what carry over to stuff like jnderstanding state. Haskell is also huge on recursion. I’d imagine you could put all of the same concepts to use in Elixir. Haskell and the accompanying book (learnyouahaskell.com) are good to see the ideal way of doing FP, but Elixir should give you more in the way of practical applications. Elixir also has a easier to follow syntax coming from OOP especially Ruby. Elixir is definitely not just Ruby plus FP tacked on (Python more fits that) due to the underlying language.
pattern matching makes me love love love elixir. It's just ridiculous how awesome it is and how I lived without it. Now when I program in languages without it, i miss it a lot. 
I wouldn't use any of those libraries. I would use comeonin and bcrypt to hash passwords and verify authentication credentials manually. It's not complicated at all and you will know *exactly* how your system works. For auth, just create a simple permission module. Say you have a Listing module and db table `listings`. Create a ListingAuthorization module to check if `can_view?/2` or `can_edit?/2` and pass in your resource and your user, to return true or false. Don't fall into the rails habit of reaching for libs for every little thing. You may not need it.
https://medium.com/@jpiepkow/accesspass-yet-another-elixir-authentication-library-7ea59734a49 Disclosure I made it and it is still slightly black box when it comes to the schema but there are some issues open on the repo I plan to get to and change that. It is slightly based off addict but with some changes I made in order to not be locked into addicts view. There is a ton of info on hex about it as well.
Thanks everyone. I appreciate the help and offers. I'm gonna try to delve deep after the weekend. 
That dude. Whooooh. Crazy. 
You mean like this? [http://nithinbekal.com/posts/phoenix\-authentication/](http://nithinbekal.com/posts/phoenix-authentication/)
Hi, you are right, I'm thinking to export all my videos on YouTube in the future. If you are interested in the chat, you will find the code on github: https://github.com/joebew42/ex_chat BTW, in one of the next episodes I will continue to work on this project ;)
Agreed that it isn't complicated, but I am curious if anyone else develops in Windows and has to manually run vcvarsall.bat amd64 and then compile Bcrypt from the same shell, every time. There has to be some alternative to writing/running a simple script.
This is helpful, thanks for sharing.
I think this entirely depends on who's teaching Elixir. Reading Saša Jurić's [Elixir in Action](https://www.manning.com/books/elixir-in-action-second-edition) was a revelation to me. If someone is teaching Elixir / Phoenix as if it were a more performant RoR, I think they are missing the point.
I am in that course on Udemy and it is a bit outdated. The instructor says he is going to update it soon. 
Glad to help! It was super confusing for me at first and I spent a ton of hours writing this, so I'm glad it was useful
It is literally the best article I have read on Phoenix contexts, great job!
Thank you, that means a lot!
Wrong sub 
Because it says Blockchain?
oh yup. my b. someone posted about elixir token last week or so. 
Hey, joebew42. Do you use OBS? I use it to record my screencasts and it also has broadcasting functionality. It might be a good solution if you want to do both. I'm considering it myself actually due to some people on IH suggesting I try Twitch.
Hey alchemist! Yes, I am using OBS and I am very happy with it! Thank you for your suggestion, I never tried the "collections", I will give it a look just to learn something more about this world :)
I find in elixir I transition from ! Methods to ok tuples over time (prototyping with !, deploying with tuples after writing unit tests). Also the with clause is simply amazing for making coding the happy path work well with error handling and robustness.
Oh, hey -- this looks awesome. It resonates because I spent the better part of last year dealing mostly with the client side of the flow you use as an example :) for an android/ios travel + day-of-travel app. And so I've also got the JS-land 'sagas' stuff in mind to compare with. The systems our app integrated with were so painful that now we're talking over inserting our own server-side layer between the user and the crufty backends we talk to. So this sort of "retry" and "save-point" logic in Elixir has been kicking around in my head for a while, and it's a good time to run across this.
Yeah, that looks like a pretty good guide. I'd also recommend making yourself a simple plug that checks if the user is authenticated and adds their info to conn.assigns rather than having to use that current_user() fn everywhere. Something like this: https://gist.code.espn.com/falksonu/fcbb16569641351eca096acbf5e69bb8
What's the name of the UML program you're using?
I used Draw.io which is pretty great!
I'm not sure what OBS is. But i'll look into it. So this would give an option to share a screen while live coding?
Coming from Scala with its lean towards immutability, pattern matching and the Actor model, maybe not much. Coming from Python and JS, you should grow a fair amount (and actually have an easier time with something like Haskell in the future as well).
This sub
I think Allan Kay would be pleased at where you're headed. 
In order to learn Elixir I set myself a task: build a server (and later a client) for a network protocol that I am also currently developing. The protocol is basicly modified variant of MQTT with some added functionlity but not as general or verbose as AMQP. I know about RabbitMQ etc. etc. but I wanted to learn Elixir so decided that it is a good task. Another benefit is that it may also benefit my day-job someday. Server can be found [here](https://gitlab.com/Shakti213/lighttel-server) and some shared modules that is intended to be shared by both server and client are [here](https://gitlab.com/Shakti213/lighttel). 
Hey, Shakti213, just a quick heads-up: **basicly** is actually spelled **basically**. You can remember it by **ends with -ally**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Feel bad, I'm student but with a @student.42.fr :c
It's an ebook. You can probably find it for free in a couple of days time.
If you had a real use case for `with` in your test you could also add an `else` case with `flunk`.
If you are really lacking funds I will buy you a copy 
darn already own it, great book though.
Thanks mate, someone gave me a copy of the ebook :)
&gt; If you have a pragprog.com account with a valid email address ending in .edu Just wonderful... At least have the honesty to say it's for American students. 
RTFA before whining &gt; In addition to .edu in the US, the offer is valid for the following other educational domains: rug.nl, th-koeln.de, post.au.dk, iesdonana.org, .edu.cn, .ac.uk, .edu.br, .edu.au, uwo.ca, .education.nsw.gov.au, uanl.mx, edu.pl, usp.br, .ac.jp, .ac.nz
Still not all available for free to academic students in general. 
That's probably a common theme in your life seeing how you are retarded 
Kys
Very true. Though I'm having a hard time imagining when I'd use `with` in tests rather than plain old assignments.
No problem. If you really like the book, Dave has a really good online course as well. https://codestool.coding-gnome.com/courses/elixir-for-programmers 
Yup. Both universities I attended used .ca for their email domains
Thanks for reading. You're right, I didn't address how \`gen\_event\` behaves when installed handlers have errors. If I want some piece of event handling logic to be supervised, I usually install a handler that forwards a message to a registered process under supervision. My main point was ultimately that I think \`gen\_event\`'s model of executing handlers sequentially within a single process is a more flexible default behavior than the behavior of the various proposed replacements.
Yes, there are known solutions to "restarting" installed handlers but it is not always straightforward and even the fact that extra work is required catches a lot of people by surprise. So it is a bit dangerous to push people towards `gen_event` and not discuss its number one pitfall. I don't dispute there are cases `gen_event` is well suited but they are not as frequent as one would expect. Concurrent handling should be preferred. If you are certain that you don't need sequential handling, there is no reason to use `gen_event`. As a matter of fact, if there is a `gen_event` and I want to install a concurrent handler, I would need to: 1. to implement the handler that forwards the messages 2. to implement a "watcher" that needs to act in case of three different failure scenarios: a. the gen_event server itself crashes b. the handler you installed crashes c. the process I am forwarding messages to fails 3. implement the code that handles the forwarded messages On the other hand, if I need to integrate with a dispatch mechanism built on top of a supervisor (or even better, on top of a process registry), all I need to implement is a simple process/GenServer. I find the reasoning of making concurrent code harder to write because of the one off chance you may need sequential execution to be a bit backwards. 
While I understand your frustration, I don't think this is a helpful feedback either. What could be improved? What is missing? Put yourself in the author shoes.
&gt; So it is a bit dangerous to push people towards `gen_event` and not discuss its number one pitfall. Fair! I will write an update to my post warning people about how `gen_event` behaves in the presence of errors. As per point 2, I haven't thought deeply about it, but I'm not certain a "watcher" process is required: a. I usually put `gen_event` processes pretty early in the initialization sequence for `rest_for_one` supervisors, so my bases are usually covered for this. Various processes that are started later in the initialization sequence can install whatever handlers they like to the `gen_event`, and I can be sure that they will be added to a new `gen_event` after a crash. If a process that adds a handler during initialization crashes, then there's nothing to do if messages are forwarded using calls, as the old handler will throw an exception and be removed silently (yikes.) b. If your handler forwards messages with raw sends, it will not crash. If your handler casts to a `gen_server`, it will not crash either. If it calls to a `gen_server` that does not exist, an exception will be thrown, and the handler will be removed, which I suspect is what one wants anyway. c. If you do a call to a `gen_server` that doesn't exist, then an exception will be thrown and the handler will be removed. If you do casts/raw sends, then the process that receives the forwarded messages, which should probably be responsible for adding its forwarding handler in the first place, should check the installed handlers and conditionally use `gen_event:swap_handler/3`. instead of `add_handler/3`. d. Usually when I use `gen_event`, the supervisor that starts the process acts as the watcher. In these cases, the supervisor's supervisor is responsible for restarting. You're not the first to state that sequential execution of handlers is an unlikely use-case for event handling. I expect that my opinion will change over time, but right now I prefer defaults that are flexible over defaults that sacrifice flexibility for the sake of the more common use-case(s). As I mention in my post, I'm happy that `gen_event` exists as a part of OTP, mainly because it has let me build and ship software quickly. I'm certain that there will come a day when I will need something different to manage event handling, but it hasn't happened yet, and in the meantime I've gotten software projects off the ground faster thanks to `gen_event` and the pattern of installing handlers that use calls to forward events to interested `gen_*` processes. Thank you for taking the time to write a reply. It's really nice to hear different perspectives.
The [official guide](https://hexdocs.pm/phoenix/overview.html) is quite good.
Excellent. You have thought about all of the cases and scenarios, but it is actually very hard for somebody to put all of these pieces together when they first use a `gen_event`, even for experienced developers. For example, your solution for a) doesn't work if the `gen_event`was started in another tree, as we see when integrating with a third party supervisor such as `error_logger` and `sasl`. b) can only be simplified if you don't care about losing messages, but if you do, then you need to handle it. Etc. So overall there are just so many different ways it can fail that it is hard to put it all together. My suggestion would be to find less error prone ways to make this work. For example, if you are interested in sequential execution, then you can simply perform sequential calls using a GenServer + Supervisor. If you want to have sequential calls and avoid the cost of copying of messages, then an ETS table and MFAs can be a good alternative (which is how the new logger in Erlang/OTP 21 works), etc.
There is an entire book about phoenix framework. https://pragprog.com/book/phoenix/programming-phoenix
+1 for this book. It was extremely helpful for me, somebody that had almost no experience working with web stacks. I do recommend looking into the `1.4` version of the book though (which is currently in beta), since the changes made in phoenix 1.3 have a noticeable impact on how you structure your app.
Cool. Thanks!
I don’t think I’d say Option #2 (NodeJS Backend) would be as over-engineered as you’d think. Take a look at this library I wrote for building a React rendering server on the NodeJS side ([Isorender](https://github.com/chancedickson/isorender-node)). This library has both a client and a server for NodeJS, so you’d have to write a client for Elixir, however if you use Ports and design your server to communicate with stdin/out, it turns out to be a pretty barebones client, just a GenServer that serializing maps into JSON, sends them over the port, waits for a response, unserializes it and then sends it back to the initial request pid. I like this model for working with an external rendering server, however I may be biased since I wrote a small library for doing so. :)
Thanks, it looks more simple than I thought, I'll check it out. Still not a drop in solution that *just works***™** like react\_on\_rails, but maybe keeping a node server for rendering is not so bad after all. Another advantage is that I think I could implement everything as client\-side and add SSR at the end, without having to refactor much.
[removed]
Oh yeah, it’s certainly not drop-in. I think my Elixir client implementation (that I really need to open-source) is about 100 LoC for the Elixir client and about 150 LoC for the Node server. After thinking about the issue, I remembered that the reason I did not release the Elixir client for the Isorender server was because using Elixir Ports and communicating via stdin/out makes it _super_ easy to scale the rendering server horizontally if it becomes a bottleneck. Since the NodeJS processes can be wrapped in a GenServer using Ports, you can spin up as many of the GenServers you need and send requests to them in round-robin or some other load balancing fashion (but that may be a little over-engineered if you don’t necessarily need it). It also makes it a lot easier to start up your Elixir server since instead of starting the NodeJS server then starting the Elixir server, you just start the Elixir server and it starts up the rendering server(s) for you in a managed way.
I have been trying to learn elixir since quite some time. The one thing i wanted to get a hang of was otp. You only really get it once you build something in it and then the fun starts. As a result, I tried to build a redis clone in elixir that relies heavily on genservers , supervisors, registry. The otp tutorial on official site was helpful as well since it already has something like this. I've implemented some commands and the project is in no way complete. So I thought maybe I could get some helping hands and we could build something good . what say ? 
Glad you’re enjoying elixir and OTP. Out of curiosity, why did you want to continue to build on this project instead of building out [redix](https://github.com/whatyouhide/redix)?
You're confused: this isn't a Redis client, this is a Redis *server*.
You’ll want to follow this: https://elixirschool.com/en/lessons/advanced/escripts/ You’ll still need to make a elixir module to even if you are writing a single escript. 
I see. Thanks for that explanation. I hadn’t dig into OP’s code, yet. But glad there’s also an existing implementation for this. I’m always for 1 paradigm over 50 (*cough* JavaScript *cough*) and a tight community.
This is dope. I'm just starting out with Elixir and, after going through a few books, have been looking for *read\-world minimalist* examples. Thanks for sharing.
If you want to just save it as an \`.exs\` you can perfectly do it, if you want the script functionality you can use escript as /u/dj_goku mentioned. You can still use dependencies and yes, you'll need a http client library just like a normal module.
so would it be better to just do a "mix new ..." then mix deps.get in the project, then create a script file within the project? Would this be the preferred method rather than creating a stand alone script? I guess the dependencies would all be published with the project this way? 
You might be able to use the http client included with OTP. https://virviil.github.io/2018/04/06/elixir-do-you-have-http-requests-you-are-doing-them-wrong/ has some examples and comparisons between the major options. 
As a fellow Rails / Phoenix developer I am biased towards Turbolinks. I really do think server side templates, Turbolinks and sprinkling in a little extra JS where needed is a combo that works wonderfully for most web apps. With that said, I'm using Turbolinks now with a Phoenix app (I'm learning as I go too) and it's working really well. Sounds like you want to go React either way but I just wanted to say you can make blazing fast sites with Turbolinks outside of Rails and have it all work out.
I'm glad you brought up your bias. I've only worked at a few places and they've all used full JavaScript frontend's. As I've been learning elixir, I've been questioning why we don't server side render and sprinkle JavaScript where it's needed. I was wondering if I was the only one thinking this. I'm going to try out turbolinks, thanks!
I'm liking that path more and more, but got so used to React for UI that I don't feel like going back. Maybe with enough BEM and a nice file structure I can still reason about my UI with "components", and include those in templates. I'll have to do some experimentation.
No problem, you're definitely not alone. I go a bit deeper into why I prefer this style on my site at https://nickjanetakis.com/blog/server-side-templates-vs-rest-api-and-javascript-front-end. 
There are two use cases for embedded schemas: 1. as the same suggests, embedding a schema inside another schema. These are persisted as JSONB columns in postgres. 2. as a struct with 'typed' fields, supporting casting and validation with `Ecto.Changeset`. You can use these to validate API params, or any other data coming from an external source. 
I've used them for the 2nd use case. It happens quite often that a user-facing resource doesn't map exactly to your backend structure. That's a good place for an embedded schema I think. For instance one could use an embedded schema called `Registration` for signup forms. After validation, this then maps to a `users` and a `credentials` table in the backend.
Thanks! So embedded schemas don't map to the database unless explicitly done so?
Pretty much. Here's two good resources on the matter (which I have referred to extensively in the past): https://medium.com/@abitdodgy/building-many-to-many-associations-with-embedded-schemas-in-ecto-and-phoenix-e420abc4c6ea http://blog.plataformatec.com.br/2016/05/ectos-insert_all-and-schemaless-queries/ Hope these help!
About "Reaxt", it is developed, eavily used (dozens of big companies's big projects) and maintained by my company Kbrw. Drawbacks for you can be that : - open sourced examples and docs are not at all up to date... We need to do some work on it for external users - we do take our time to update to new React or wepack versions because we have to ensure stability to our existing projects 
A genserver is by itself a single elixir process. If you send more than one instruction it will queue the subsequent ones (in the process mailbox!) If you want it to perform multiple jobs at once and/or in parallel you can simply fire as many processes as you need from your Genserver. Although you can do that, I recommend checking out some libraries that do that for free, like Poolboy. All in all Genserver is just an abstraction to help you expose a elixir process that will communicate with other processes. Hope that helps...
I believe that one of the foundations of the actor model is the notion that processes are singular, independent, atomic things. To that end, when you run a single process it's scheduled on to a CPU. It's always going to be on that 1 CPU, with the ability to only process one message at a time (unless you suspend the process, but that's outside the scope of this question I think). I don't believe elixir has any magic that will migrate processes between cores while "hot", but I could be mistaken on that. It definitely won't process 2 messages at the same time though - in order to process 2 messages at once you need 2 processes spawned. /u/alvesl is correct in that you should probably be using Poolboy for your usecase, since that'll ensure that you can submit your work to a worker pool, which will achieve the desired concurrency/load sharing you want. 
I'm 99% sure the schedulers can "steal" from other schedulers if they are too busy, so there's no guarantee of a process running on a specific scheduler/thread/core.
Hi! Thanks for answering. Maybe it's the docs that made me feel like the project was dead/not maintained. I was planning on using phoenix to create the API probably, can Reaxt be used alongisde it? I've read about some issues with the web folder or something. I could run phoenix with --no-brunch/--no-webpack, and depend on the Reaxt asset pipeline.
One core. There is no concurrency within the process so you can’t get any parallelism out of it. If you want parallelism, you’re going to need to spawn new processes. This is actually pretty easy. You can use a DynamicSupervisor to spawn your workers and have the state of your GenServer track the rest. You’ll want to supervise them so you get crash messages and to find them if you use the observer for debugging. You may want to use a monitor in your GenServer to handle crashes of workers, though. You can also use calls in parallel, if that fits your use case better (you can return noreply on the initial call and to send an explicit reply later). Getting it right has a lot of details. You could also just create regular Elixir processes, though I can’t vouch for that working well if you start to use Erlang release functionality for code upgrades, app failover, etc. All of that said, this is all available as a library in the form of poolboy. It provides a pool manager that is a lot like the controlling GenServer and has pools of workers to give controlled parallelism. [Here](http://hashnuke.com/2013/10/03/managing-processes-with-poolboy-in-elixir.html) is an example of using it with Elixir.
I think his idea was that he could fire off multiple casts to a GenServer and he was hoping it would process them in parallel (which really doesn’t happen).
... and depending on what your exact workload is, a pool may be a good fit (e.g. lots of completely independent jobs) but a [GenStage](https://hex.pm/packages/gen_stage), possibly aided by the [Flow](https://hex.pm/packages/flow) library, could be more appropriate if processing has a pipeline nature to it (well defined produces and consumers). It is hard to tell from just OP's posting to know, but the options are there. As an aside, processes being non-concurrent is a feature: it is the unit of serialization in the concurrent system. &gt; and to find them if you use the observer for debugging Observer lists non-supervised processes.
While the observer lists non-supervised processes, they’re not always easy to pull out of the list in a running system like you can when browsing the supervision tree. And, again, a supervisor gets you crash reports—which are especially useful when the worker dies so fast that you don’t even see it in observer. (The supervisor also insulates you from crashes, though I’m not sure that OP has really thought about crashes and recovery yet.) I went for poolboy mainly because OP seemed to want parallelism at a single point. GenStage and Flow are great tools for managing data flows and concurrency; but neither is entirely built for pure point-parallelism. Not that the OP might not benefit from a more comprehensive design, but either of those would be a significant paradigm shift to adopt. Of course, this is all speculation without additional details...
&gt; I don't believe elixir has any magic that will migrate processes between cores while "hot" It does. It's not magic, just standard [work stealing](https://en.wikipedia.org/wiki/Work_stealing). See [Erlang Scheduler Details and Why It Matters](https://hamidreza-s.github.io/erlang/scheduling/real-time/preemptive/migration/2016/02/09/erlang-scheduler-details.html). The VM will also shut down schedulers when the system is idle, and wake them up when it gets busy. That being said, of course, the process is still only on one scheduler at a time.
As the concurrency aspect has already been answered I won't repeat it. But regarding handle_cast vs handle_call, this is more to do with how other processes will interact with your GenServer process. When a process sends a call request to a GenServer process, that process sending the request will wait for a reply from the GenServer process (or timeout). Whereas if a process sends a cast request to a GenServer process, that process sending the request will **not** wait for a reply and continue on regardless of if the GenServer even successfully received the message or not (this is behaviour you could experience when you're working with distributed processes; while I could be wrong I don't think this behaviour should ever occur if the processes are on the same node?). If you have many processes sending cast requests to a given GenServer process, that GenServer process mailbox is still pooling them up to operate on them iteratively (one by one). 
[elixir-socket](https://github.com/meh/elixir-socket) supports both WebSocket servers and clients.
Phoenix uses Cowboy. You can just use Cowboy directly.
While there's been some comments about pools, if you just want to partition your work to utilize multiple cores and you don't fit neatly into the "pool" or "flow/gen_stage" model, you can use the Registry module and have your GenServer "route" different requests to different servers by some kind of partitioning scheme. Also, not mentioned, but using call's instead of cast's for performance is not always a good idea. It's usually a good idea to use calls for backpressure reasons (so you don't fill up the server's mailbox), but 99% of the time, this is a "correctness" decision, not a performance decision.
Oh, and you can also reply to a GenServer call asynchronously (using `GenServer.reply()` instead of responding with `{:reply, term, state}`) if you've got long-running tasks in your GenServer.
Definitely I would use cowboy directly which is extremely easy (if you're comfortable with elixir and reading erlang code)
Btw, the DynamicSupervisor has a `:max_children` configuration that does exactly what you did, but built-in. :)
Nice! I had no idea. I'll have to refactor and update this.
Why not in phoenix? out of curiosity 
Didn't click, but I'm gonna go out on a limb and say this is a fancy wrapper around :erlang.term_to_binary and :erlang.binary_to_term
 As a bonus, you will see how to use Sagas to organize your domain contexts.
If only they could fix the history without that patch that I always have trouble getting to work...
Yeah, it is built on those two and a bit of meta programming :)
this is really cool :D
I may just use vagrant and set up a vm if I can't find an answer. Thanks anyway!
The patch is no longer required from Erlang/OTP 20. See IEx docs: https://hexdocs.pm/iex/IEx.html#module-shell-history
I don't use a Mac, but I'm guessing you're missing some the boringSsl libs on your Mac maybe?
Yep. I'll just do a vm and use linux.
I wrote a blogpost at some point about how phoenix uses cowboy for websockets, [https://www.zorbash.com/post/phoenix\-websockets\-under\-a\-microscope/](https://www.zorbash.com/post/phoenix-websockets-under-a-microscope/) it be worth reading.
I had a similar problem at one point and resolved it by installing openssl via Homebrew. brew install openssl 
Wow, this fits perfectly into what I'd be wanting to do with Elixir as we do a lot of work with Kafka too. I'd be interested in learning what libraries they use with Kafka and how full-featured they are compared to, say, the confluent streams libraries.
I'd love to hear from others about this, as well. I am evaluating some work we need to do around our own solutions built out around Kafka and Elixir is a top candidate.
I’m a little new to Ecto. But I think you’d need to add a migration file like you have for the alter_header. And add the names and values as references on the header table if you want them added to the db 
You have to switch the position of the `belongs_to` and `has_one`. `belongs_to` goes into the schema that has the foreign key, so it should be in the `Header` schema in your case. See also: https://hexdocs.pm/ecto/Ecto.Schema.html#belongs_to/3 
Just finished working on a real-time [Todo app](https://github.com/sheharyarn/ztd) over RabbitMQ as an experiment. You can have multiple "worker" instances that synchronize with other workers and an "engine" instance. Here's a [video demo](https://to.shyr.io/2tebNiP).
Forget to comment after I tried. This is a really nice project. Thank you!
Hey, so that worked! I've pushed new commits which introduce the (expected) behaviour. Now I need to get the Changesets to not crash when inserting a new record. This is casued by the \`unique\_constraint\` is not met. Thanks for your help :)
Hey, the schema fix worked for me, but I did modify the migrations as well. Thanks for your help :-)
Hacking away on a video course hosting platform. Besides working on the app in my spare time, I'm also thinking of ways on how I can (or if I should) open source it.
Do they use Phoenix?
The HackerNews discussion got quite big https://news.ycombinator.com/item?id=17313087 Not sure why the original article didn't link to the Github repo either. https://github.com/PagerDuty/db2kafka 
Not sure why the original article didn't link to the Github repo. https://github.com/PagerDuty/db2kafka 
:)
We at [aviabird](https://github.com/aviabird) are working on an open source e-commerce framework in Elixir. Codename [snitch](https://github.com/aviabird/snitch). We have done frontend e-commerce framework in past [angularspree](https://github.com/aviabird/angularspree). The project is still in early stages. We are planning to go live with www.ofypets.com by 30th June. We are also accepting contributions from the community but since we are moving pretty fast, we recommend getting in touch with us if you want to contribute. 
We at [aviabird](https://github.com/aviabird) have worked on a payments library [gringotts](https://github.com/aviabird/gringotts). It is heavily motivated from [activemerchant](https://github.com/activemerchant/active_merchant) from the ROR world. We have integrated 9 gateways so far and plan to do more in coming months. Contributions are welcome! 
Elixir does seem like a perfect fit for the kind of service PagerDuty provides.
I love the idea of phoenix, I'd definitely use it later. I just want to get deeper understanding first 
I'm building a scheduler that takes containers and turns them into serverless API endpoints. This is for work, and I'm possibly hiring in July. So if anyone is interested in this kind of thing drop a line.
Gotcha, was just curious, I like it because it allows older clients to still participate ( longpolling )
Hi, any pointer to where we could find information about that HTTP client (Github...)?
Nice article! I'm wondering what are the security guarantees offered by [hex.pm](https://hex.pm) regarding the integrity of the packages: how do I make sure the binary has not been altered by the developper before publishing, or on the [hex.pm](https://hex.pm) platform directly? Because one can imagine, for instance, a plug leaking the HTTP Authorization header to a rogue server (using httpc...).
Thats awesome, I was just looking into doing this with elixir/nerves last night. Thanks for posting!
I thought I read about the EVM finally getting a JIT compiler, was this part of that or is that still to come?
JIT is definitely not released in here. As far as I know the JIT is under work, but I'm not sure what is the status.
That should also be a significant runtime (and compile?) performance improvement as well right?
JIT is by definition a runtime performance improvement AFAIK
httpoison
Yes but in Elixir, compile time occurs during Erlang runtime.
This is correct. Still, can we expect a noticable difference here? Sounds to me like it would take a really good JIT or a really bad compiler to be noticeable but I'm not able to articulate exactly why...
Hey, moljac024, just a quick heads-up: **noticable** is actually spelled **noticeable**. You can remember it by **remember the middle e**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey [u/moljac024](https://reddit.com/u/moljac024), it's perfectly okay to misspell things. You should totally use spellcheck when you're writing formally, but on Reddit it's really not a big deal.. and it's not like that "tip" is going to help you remember the spelling anyway! I *actually* hope that you have a nice day. ***** I am a bot.
Begun the bot war has...
You should be able to use `:zip.zip_open/1` to get a zip file handle, and then use `{:ok, [contents]} = :zip.zip_get(handle)` to get the contents of the file. If you want to get a list of filenames and extract specific files, `:zip.zip_get/2` and `:zip.zip_list_dir` as needed. One problem that might be tripping you up is that you have to use character lists with some erlang libraries (as is the case here). If you were supplying that filename by Elixir string, that's a binary. Use `~c"filename.ext"` or `'filename.ext'` instead of `"filename.ext"`. 
&gt;And it’s a really bad practice because if you change your auth system, you have to update all your services and redeploy them. That is a pretty big leap. What is good or bad practice regarding microservices and auth really depends on the use case. 
hackney
If you have the file path, you can use file_path |&gt; String.to_charlist |&gt; :zip.unzip (or any other) and this will return { :ok, list_with_files } so that you can read them in the directory or whatever you want to do. The .to_charlist is because of how the :zip on erlang expects to receive an "Archive" and not a strijg, as pointed to the other comment here. If pass { cwd: "your current dir" } it will extract the files in the folder specified.
Right well that was why I put it as a question, I don't think we will know until we try it
I'm using httpc and hackney with tesla.
What's really bothering me is that the contents I'm getting back is just the filename of the file inside the zip. I have no idea how to get the text INSIDE the file. 
I finally see now what's happening. For the longest while I was frustrated that I only got the filename back from `zip_get/2` but actually I never bothered to check the local directory - there it is! The unzipped file! I was trying several different methods with the hopes that the unzipping would produce the file contents instead of just the filename, but I see now that it's just writing the extracted file to the local directory. I'm wondering, is there a way to read directly into memory instead of writing to disk? I can work with either way but it's easier if I not deal with extracting the file to disk, then reading it, then having to delete it later on. I am currently just trying to build a web crawler that looks at a webpage, sends a `get` request to retrieve the zips, reads them into memory, then dumps them directly to a database after validation. Writing to disk would slow it down. 
Why not just write the whole back end in Python or Elixir? It depends on your use case, but Elixir isn't known for being good at number crunching or data processing. It's well suited to a web app though. Check out Phoenix, it's Rails-ish, but in Elixir.
If you read the docs for `:zip.zip_open/2`, there's an "option" for extracting to memory instead of file (raw or "cooked"), so try `:zip.zip_open(filename, [:memory])`, then `:zip.zip_get/2` should get you what you want.
irrelevant comment I have used phoenix before, this project needs certain python modules, and I don't like phoenix nearly as much as flask
Good luck building your app then :)
If you need to use certain python modules and like using Flask, my instinct would be to try using Python for everything. Using both Elixir and Python is adding complexity to your system, and I'd think very hard about whether the benefits you're gaining from adding Elixir are actually worth that complexity.
&gt;Elixir isn't known for being good at number crunching or data processing. This is probably the single myth that doe Elixir the most harm. The most straightforward way to get good number crunching in any language not compiled to native code is to bind to numeric libraries that are. This is how python does it, it is how those who use Elixir / Erlang for "number crunching" do it. That said, \*most\* workloads people are thinking of when they say "jobs" are not numeric, which makes the observation unhelpful. As for data processing .. again, it depends on what you mean by "data processing". But there are enterprise-grade distributed key/value stores, message brokers (e.g. RabbitMQ), complex message passing systems (e.g. MongooseIM and ejabberd), crazy amounts of telecom, and on and on all written on the BEAM. So ... 
There are two very different answers to this that come to mind: A) It really depends on what you expect from this "workhorse" application and how it will be driven. Having a message broker can indeed simplify a number of things in cases where you need generic message/work queueing, but it is also means more moving parts, more to deploy, more to manage. This can be cheap next to the benefits of not developing your own solution, having something that provides reliable/durable management of the messaging, etc. Emphasis on "can", as it can also just be a source of complexity if your application does not really utilize/benefit from the benefits they bring. It may be easier all around to treat the Elixir app as a "microservice" and just pass requests directly to it via HTTP or the socket protocol of your choice. Fewer moving parts, less application complexity .. but then QoS and the rest is up to you. However, depending on your application that may be a complete non-issue. The other thought that comes to mind is: B) Phoenix is not the only option for web-on-Elixir. Using Plug on its own is often more than enough for applications that do not need the complexity of Phoenix. There are also libraries like [Raxx](https://github.com/CrowdHailer/raxx) that take a miuch more straight-forward approach (albeit less flexible / powerful) to the topic. So if you are thinking "it's gotta be Phoenix or else not Elixir", take a poke around :) It would make your life a lot easier if you could use Elixir for the whole app (see above) As for requiring certain python modules, as you note in a comment here, unless those modules are needed to called from within h ot-paths of the appication, you could consider using them via something like [ExPort](https://hex.pm/packages/export). Out of curiosity: what sort of Python modules do you require that are missing from the Elixirverse?
Fair enough. I suppose I didn't phrase things well. What I was getting at is that Python has plenty of widely used and battle tested numerical libraries, and I don't think Elixir can say the same. As for the second part, yeah I was a bit vague. It just seems to me that OPs plan here is introducing tons of extra complexity and not necessarily using the right tools for the right jobs. Still seems like sticking with Python top to bottom is the easiest option here.
So why not just use Python top to bottom then?
I’ve explored this going from the opposite direction (phoenix we app with python interop so I still could use some data science libraries I didn’t want to port) I initially worked with Kafka (great option but more powerful than I needed), then found faktory which looked very promising. There’s also Apache thrift, but I haven’t explored that route too much. I ended up just slimming my dependencies down to a single library (https://taku910.github.io/crfpp/) and interacting with it via porcelain + poolboy while writing everything else in elixir. My main reason for not using python was to keep deployments simple. If this is for a personal project, do whatever suits you. If this is something someone else might have to maintain, make sure the complexity you’re taking on gives enough value vs a simpler monoglot solution. 
How good is this book and is there any other that could help me improve my Elixir knowledge? Some things you should know: 1. I'm a slow reader and learner, I can only learn in my own pace 2. I have an incredible lack of attention sometimes 3. and other times I could read 400 pages in one sitting I've been learning to program for 9 months now, I started with Node and Express with JS, with the course Web Development Bootcamp by Colt Steele on Udemy, then I saw that Elixir and Phoenix was the right choice for what I want to build and work, then I got the Elixir Bootcamp course by Stephen Grider, also on Udemy, however, the beginning I felt that it was soooo much easier than JS and OOP, but sometimes it gets so complex that I can't even remember what he said last, there's too much information that I feel that requires me to read a lot of documentation, so a book would be helpful too Thanks in advance :) PS: I'll be posting the same on /r/learnprogramming 
I doubt this book would be good for learning elixir itself. I'm guessing this is more of a book on how to get your company to start using it in their tech stack. If you want to learn Elixir, I would recommend Programming Elixir. It's especially good if you don't have experience with functional languages.
Agreed. I believe the book even says so in the preface. It is a great book though once you are 6 to 12 months in.
Thanks, I'll check it 
HTTPoison, at least because it supports SSL correctly: https://blog.voltone.net/post/7
This book would not be good for learning elixir as a language. I just finished reading it and it is more geared towards adapting elixir at a company. That covers converting to functional programming, hiring for elixir, deploying for production and monitoring a production application
I prefer Tesla over HTTPoison. I feel like it has a better API.
It is nice to see they are mostly quality of life improvements instead of big bang features. It helps keep the language focused.
Good article. I was also using rails for a little bit and I must say auth + authorization in Phoenix are things which should be adopted from rails. Like you said, device is great and this is what coherence is going to achieve eventually https://github.com/smpallen99/coherence it just needs more community's love.
Elixir is fantastic language, I'll choose it any day, but Python is more mature and there are tons of library's specially if your are working in Maths and stuff that will help you get up and running fast. If I were in your'll place I would choose only one language that I am comfortable with. Choosing two languages/frameworks will only add more complexity. If you are use to python, use it. There's nothing Elixir can do that python can't. It boils down to your comfort level. And if you choose to go with Elixir , kudos...
&gt; I also keep forgetting to add the `do` to my function definitions. Why is this needed? Are functions blocks? Actually, kind of—they are block arguments to a `def` macro. Personally once I got used to this I loved it, because it is entirely consistent through the language: when I write Ruby now I forget that `module`, `class`, `def`, and `if` *don't* need `do` but many other methods and DSLs do: `each`, `it`, and `context` for example. Small nit: you refer to some Elixir things as classes/methods (rather than modules/functions), which is minor cognitive dissonance that will fade. Also worth noting: you can configure Ecto to use `created_at` if you'd rather by doing `inserted_at: :created_at` in your schema's [timestamps](https://hexdocs.pm/ecto/Ecto.Schema.html#timestamps/1). Well written!
Barring any more official solution, you can turn any HTML document into an Epub using [pandoc](https://pandoc.org/)
Holy shit, this is GOLD, THANKS!!!!!
I will try Coherence on the next app!
Ah that makes sense about “do” then. On the timestamps, sure I saw that but why not do what Rails does when almost everything else about migrations is the same?
From ExDoc's README: &gt; By default, ex_doc produces HTML files, but, you can also create a EPUB document passing the option --formatter epub
This I know, but the challenge for me was to do in the Elixir Docs, which is the same from GitHub that we can clone If you could provide the snippets to do it in sequence, I'd be very thankful
I don't think Phoenix sets out to be as approachable by Rails programmers as possible, so why do what Rails does? Inspiration is different from mimicry. In particular, it makes sense to me because you 'create' *objects*, but 'insert' *data*, a crucial difference between the two fundamental paradigms of their host languages.
Follow the instructions on the main Elixir repo for building documentation, only, before you call `make docs`, modify the Makefile. Here is the section you'll want to modify: ``` docs_elixir: compile ../ex_doc/bin/ex_doc @ echo "==&gt; ex_doc (elixir)" $(Q) rm -rf doc/elixir $(call COMPILE_DOCS,Elixir,elixir,Kernel,-c lib/elixir/docs.exs) ``` To the end of `$(call COMPILE...` add -f epub, so that it'll look like: ``` docs_elixir: compile ../ex_doc/bin/ex_doc @ echo "==&gt; ex_doc (elixir)" $(Q) rm -rf doc/elixir $(call COMPILE_DOCS,Elixir,elixir,Kernel,-c lib/elixir/docs.exs -f epub) ``` Then call `make docs`. The epub will be in the appropriate `/doc/` folder.
Thanks, haven't had the chance to try it yet, but thanks anyway :) 
Sure but every single migration feature is exactly the same syntax as Rails no? Would make sense that created\_at is then. Just referring to this one part where it's so closely mimicked.
I always just make a tiny wrapper around gun. However I usually work with WebSocket clients and that’s been the most robust solution I’ve found.
Hi! I'm writing the Elixir client for BarrelDB (a document-oriented distribited database in Erlang) as a part of the Google Summer of Code (https://summerofcode.withgoogle.com/projects/#6150885181227008). I've already finished a RESTful client (https://gitlab.com/barrel-db/Clients/barrel_ex/tree/develop) and I'm finishing up the stream functionality for the native Elixir client, which will be updated soon in the repo. Next up, I'd love to tackle an ecto integration, where I'll try to emulate the functionality of the ecto_mongo package, in order to make Barrel a viable option for Phoenix developers. 
I've been working on a GraphQL implementation of the undocumented NHL api. Using absinthe and absinthe_plug (no phoenix). https://github.com/smoak/nhl_graph_api
I have been working on Horde, a distributed supervisor and registry, built using CRDTs. Horde was borne out of my experience trying to integrate swarm into a project I am working on. https://github.com/derekkraan/horde https://medium.com/@derek.kraan2/introducing-horde-a-distributed-supervisor-in-elixir-4be3259cc142
I realised it's hypocritical of me to block Google Analytics with uMatrix when I browse the web but then add it on my own sites, so I'm writing my own 1st party analytics thing in Elixir with Raxx and PostgreSQL. It's going to be very minimal and only have the features I need. Planned features: * Simple analytics views with session tracking (page, referrer, UA, screen size, device type, GeoIP) * Realtime view with SSE * Auto-pruning of old data to get rid of personal information * Support for multiple sites
Very cool, looks like they use Elixir for GIS. Any details available anywhere? I work in transportation and I'm a pretty big fan of Elixir, currently use R but would definitely be interested in seeing other options
Will this be recorded? Even if it's just informal this would be really cool for all of us outside of London.
I have been learning how to get a frontend UI written in Elm to talk to GraphQL (with subscriptions for realtime updates) over Phoenix WebSocket channels. I ported Evan’ Czaplicik's TodoMVC Elm application as the frontend just to use as a simple, fun example. Code is here: [https://github.com/pzingg/todo\_absinthe](https://github.com/pzingg/todo_absinthe)
I am experimenting with an Elixir interface to Rserve, so if there are efficient AI routines implemented in R, they should work. I Use a GenServer to send computation requests to R over a TCP socket, and then parse the results. Not sure if this is interesting/useful/memory and CPU efficient, etc. but for orgs invested in R development it might be a solution. I ported an Erlang Rserve parsing library [https://github.com/del/erserve](https://github.com/del/erserve) to Elixir, fixing a few bugs along the way.
What is GIS?
Agreed. I wish I could be there. Please record and publish :) 
Hi! Yes it will be recorded
Hi! Yes it will be recorded
Hi! Yes it will be recorded so we recommend you catch that recording to learn more.
thanks!
Geographic Information Systems. It's a system designed to capture, store, manipulate, analyze, manage and present spatial or geographic data
AFAIK there is none built in security guarantees. I remember that there was utility package for that. However how do you imagine it to work? What would be your “source of truth” for given package?
You're not talking about running Elixir/the beam VM _on_ the Android device right? You could essentially just do something like Cordova right? Ive Never done what you are asking personally, but I know it's been done. 
I'll try to make it clearer, what I imagine is making the UI in Materialize (optimized to Cellphone sizes), Templating in Phoenix, and running the backend on a server like Firebase I know I can use Postgres as a Database, but making this connection to Android is kinda hard for me to imagine and explain to someone I'm still very new to Elixir and Phoenix, but I had some experience with backend and frontend with Node and a little with Ionic and Android
Phoenix is going to be your backend, and it \_serves\_ your frontend to normal browsers. It's \_not\_ your frontend in itself. So what i imagine you will want is some hosting service (heroku, etc). This will serve your web api endpoints, websockets, etc. You may end up having two frontends. The one that you build out with Phoenix framework, and another one that just uses those api endpoints, but is not itself served or rendered by Phoenix because it will be packaged as an app. this is as far as i know, how most native (or hybrid apps) work. They are just a frontend (app) into your backend (phoenix). I don't know much about Firebase, But i don't think in that case you woudn't be using Phoenix, you'd be using Firebase. I may be wrong on this. I thought Firebase was a framework in itself. 
[Geographical Information Service](https://en.wikipedia.org/wiki/Geographic_information_system), basically mapping. R has a lot of great libraries for it, but it's kind of slow and I can see Elixir being a good fit with the right libraries
Awesome, I'll check it out
If you want to do it your way you would make the native app and have it wrap a web view that renders normally like a browser window and then nothing changes for normal Phoenix app development except whatever restrictions android's web view has, but last I checked they were just wrapping a decently modern version of webkit so you may be fine. That said I don't think this is going to be the best user experience by far. Why not build a native UI that makes API calls to an API written with Phoenix instead?
See, since I'm new, I'm still collecting ideas, what you just told me has changed my thinking about it in some way, meaning your method is more effective and I'll be using it when I get the chance, thanks ^^
Are you putting it inside &lt;script&gt;&lt;/script&gt; tags in the .eex template? 
in your app.js you must add functions you want to call in a global scope. The simplest is to do window.test = function() { console.log('test') } So in your templates you can call window.test() But it would be better to export an object of functions to have at least one level of namespace.
I'll say create a separate file and new module, something like `assets/js/project.js` and declare module inside it. Something like window.Project = (function() {} let insideFunction = function() {} return { outsideFunc: insideFunction } )(); Import import by adding below line in footer in app.html.eex. This code will execute above function and will set Project as global variable. &lt;script&gt;require("js/project");&lt;/script&gt; Now you can call `Project.outsideFunction()` from anywhere just as regular javascript code. &lt;script type="text/javascript"&gt; let something = Project.outsideFunc(); &lt;/script&gt; Creating modules will help you to seperate code and maintain simplicity. This isn't the only one module pattern and there are other ways you can write modules, don't worry about them for now.
yeah
OH! I was looking into exporting these functions but I failed to do it properly from the look of this example. Thanks for the tip!
this was very helpful, thanks for the tip! I forgot about exporting these functions like that, and did not consider JS modules at all. 
Not op, but was interested and this works. Is there a way to also make this work in different templates, and not just the app.html.eex?
Yeah, it will work in all phoenix templates as long as you initialise them with `&lt;script&gt;require("js/project");&lt;/script&gt;` in layout file. It's just normal JS, modules are just like objects, attributes and functions wrapped in one variable.
I actually meant moving the require statement
Yeah it should work anywhere after ^(app.js)
I was working on a smaller phoenix project today. That was small enough that I didn't want to introduce an SPA, but I needed different js running on different pages.
Suggestion: use the `static_path` helper instead: &lt;%= if @conn.assigns[:scripts] do %&gt; &lt;%= for script &lt;- @conn.assigns[:scripts] do %&gt; &lt;script src="&lt;%= static_path(@conn, "#{script}.js") %&gt;"&gt;&lt;/script&gt; &lt;% end %&gt; &lt;% end %&gt; I don't know how `require` functions in a browser, but I guess it will do the right thing in modern browsers. Surely at least using a `&lt;script&gt;` tag will allow the browser to load the `.js` files during the initial request instead of having to evaluate the JS first.
That's valid as well, but I believe you'd have to edit your brunch config to catch all files, or to add each file individually, whereas with require the brunch config doesn't need to be touched.
&gt; whereas with require the brunch config doesn't need to be touched. Interesting - now I'm curious how exactly that is working. Your shim guess makes sense to me.
I think, you should use conn, because in params like second param in call/2 is data, that user send to this path like JSON. I think you can use pattern matching like: defp call(%{params: key} = conn, _params) do key |&gt; #some_fun conn |&gt; #any_fun end
Is there a difference in behaviour for an external service making the request vs you opening it in a browser? Also, you don't need to use `Kernel.`, `Kernel` is imported by default so just `inspect` is fine.
Hey, Just a few things before I’m gonna tell you what we did at Yodel: - I’m still a Elixir novice and continue to learn everyday about Elixir and the awesome things you can build with it. - We moved AWAY from flow again, as we had similar problems bringing ordinary GenStages and flows together. This may change in the future however. After bringing up the issue on Elixirforum [Flow into/from GenStage](https://elixirforum.com/t/flow-into-from-genstage/14262), josevalim (agreed)[https://elixirforum.com/t/flow-into-from-genstage/14262/10?u=ream88] to do something about it. We enrolled something similar to this: defmodule Supervisor do use Supervisor @flow [ Producer, ProducerConsumer, Consumer ] def start_link(_) do Supervisor.start_link(__MODULE__, [], name: __MODULE__) end def init(_) do children = [ @flow, worker(Task, [&amp;create_flow/0], restart: :transient) ] Supervisor.init(List.flatten(children), strategy: :rest_for_one) end defp create_flow() do @flow |&gt; Enum.chunk_every(2, 1, :discard) |&gt; Enum.map(fn [producer, consumer] -&gt; GenStage.sync_subscribe(consumer, to: producer, cancel: :transient) end) end end (And yes our flow is way more complicated than this example) 
Thanks for the answer! one question, as you are using GenStage.sync_subscribe then you dont have to use subscribe_to within init/1 right? like this consumer example {:consumer, :the_state_does_not_matter, subscribe_to: [Worker]}
Something is not quite right here. A few things to try: * Change the route to `post "/my_callback/:key1", CallbackController, :my_call` (not sure where you got the `param` option from, but I can't find it in the docs - the param name is inferred from the path) * Make sure your `post` route is within a `scope` block with a proper pipeline to decode the content type, e.g. the default `:browser` pipeline, which includes `plug :accepts, ["html"]` * Change from `defp my_call` to `def my_call` (controller actions shouldn't be private AFAIK)
Correct, I subscribe from the outside via the Task at end of the Supervisor chain.
I see, mm how do you actually plug the Flow into the Producer? I mean you subscribe your workers but where do you actually create the Flow, inside the Producer.start\_link?
The Absinthe GraphQL library makes use of these to implement the subscription API.
You could try for example when the user makes a successful purchase you generate a hash or random unique ID, save it to a key-value store and when the user visits the "thank you" page with that hash/unique (in params for example) ID you simply check if it exists in the store. If it does, allow the user and remove it from store, else don't allow the user to access. Also using the key-value store, you could use the same idea but instead of having to specify the hash/unique ID in request params you could put it in cookies and then check the cookies for that value whenever the user accesses the "thank you" page. (never used either options but seem reasonable IMHO)
Well, you can’t really stop the user from visiting the URL. And doing this may not be the best design, as browsers may refresh the page in unusual circumstances (i.e. when WiFi drops out briefly on a phone or laptop). To get your desired behavior, I can think of two solutions. You could set a cookie on the browser (say, thanked=&lt;order_number&gt;) on successful purchase. You can even do this on a redirect (though there have been [issues](https://bugs.chromium.org/p/chromium/issues/detail?id=150066) with that. When the page renders, it could validate that the cookie exists the order number matches (to prevent suppression thank yous for concurrent orders). If it does, it can delete the cookie and render the page. If not, it can redirect to somewhere sensible. Alternatively, you could create a cookie per order number, but you’d want to give those a relatively low expiry time to prevent the browser always spamming you with unneeded cookies and do not trash up the users cookie jar. You could also give a query param encoding the time and only allow the page to be rendered if the passed in time is within 5 minutes, else redirect somewhere sensible. Another idea is to render the thank you into the existing page with AJAX, so there’s no URL to hit.
Is there any specific reason you dont want to query DB ? Because it the best way to do so. If you are restricting something its best to handle that logic at the endpoint itself. Well there are solutions with cookies, localStorage but why complicate it. In most cases best solution is the simplest one.
Why exactly do you want the user to access it only once per purchase? Is there an action that is triggered on the success page f.e. a generating a coupon code? In that case I would recommend you to extract such an action and move it to be triggered after an order has been placed and just before routing the customer to the success page while having all necessary information provided in the URL. This would treat the success page as a simple presentation of previously generated information, which is way more appropriate in my opinion. For example you might generate a coupon code right after an order has been successfully placed and redirect to the success page with the URL containing that coupon code. (/order/success?orderId=1000&amp;couponCode=100-100-100) 
I really have to motivate myself to begin elixir
I don't understand that
Route the page to POST requests only, pass some parameters from purchase page.
a user can be redirected to the page from PayPal website by GET only
The question still remains. What is so special about your success page that you're trying to limit it to be only accessible once?
You liked that? This is your god now: http://www.enterpriseintegrationpatterns.com/ !!!
nothing. i don't want a user to access it freely
Neeeel: http://www.enterpriseintegrationpatterns.com/patterns/messaging/ !!!
So when there is nothing special about it, what is the point and what are the benefits from preventing it being freely accessible? To me it seems that you are trying to solve a problem that doesn't need to be solved as there are no consequences when a user might approach the success page several times or by somehow guessing its URL. I mean for the latter case you may introduce a query paramter "order_id" that must be provided and redirect to a 404 page in case it's not present.
&gt; So when there is nothing special about it, what is the point and what are the benefits from preventing it being freely accessible? I want so! back to my question
Other users here already proposed solutions and even told you about the downsides of your approach im general. Regardless I guess you have multiple options whether it be a time limited token stored somewhere (cookie, url) or just a regular token stored on the server (db, session). Another idea that just crossed my mind is to validate the http referer against a whitelist (e.g. only allowed if the client is coming from paypal). Keep in mind that this may be easily spoofed as it’s freely up to the client to specify it. Now it’s up to you to choose the one option that fits your needs. 
 def circuit_break(service_name) do # .. if error_rate &lt; error_threshold do false # don’t circuit break else true # circuit break end end Why not just `error_rate &gt;= error_threshold`?
I assume when you say db is overkill is prob because you don’t want to explicitly write to the db just for that right? But I think a query is totally acceptable, here’s how I’d do it: - probably every purchase has a hashed id - append the hashed id to the url - upon request, server checks if it’s a valid hash, if it is, allow page to render, otherwise redirect. The only requirement that is not really met is that people might be able to access this pate later if they still have the hash Id (you asked to render only once), but I think that’s totally fine and different than “Accessing freely” - they are just going back to the page tha displays something about the purchase. As a bonus, you could render small info about the purchase, like date, amount... then your page might even be useful. Hope it helps!
is this smarkets? I tried interviewing there, I got 2 out of the 3 hackerrank questions correct on all test cases, and the third one correct for like 8/11 test cases. Didn't get to an on-site. Ridiculously high hiring standards. 
Hey Nixonite - yeah, Smarkets are a really tough nut to crack. But no this isn’t Smarkets :)
Yes, we could just return \`error\_rate &gt;= error\_threshold\`. But we have additional error reporting logic for the \`true\` case which I skipped here.
Generate a {:unique_key, true} and store it as a genserver key value store. Route your thank you page so that it's GET /thanks/:key. Then if the key is found then delete the key and render the page for them, else redirect.
Have you thought about sharing the circuit breaker data across servers using pg2 or some type of native erlang messaging? This could allow pure Elixir circuit cache that is updated across the cluster, with very little code change
It's super productive once you get going, and you give up nothing in performance or reliability to get that productivity! What languages have you used in the past and what kind of project do you want to build?
thx
thx
I do not know if it is officially recommended, but I always include paren for consistency between definitions, specs, calls.
Does mix format pick one or the other? If not I don't know if there's a standard convention. The reason for requiring parenthesis for no argument function calls is because it's ambiguous (at first glance) whether it's a variable or a function call without looking to see if there's a function of the same name or a something was bound to that name (variable) in the scope. Defining functions doesn't have that same ambiguity. 
I'm working on a browser-based game. [https://imgur.com/wnc9VxT](https://imgur.com/wnc9VxT) Taking advantage of the umbrella apps to separate the front-end + controllers from the app logic. Using some realtime features/websockets for chat and some player interaction. Right now experimenting with code organisation and http2. [https://github.com/archdragon/game\_engine\_elixir\_phoenix](https://github.com/archdragon/game_engine_elixir_phoenix/)
I'd just keep it simple. Make an EEx template for a page but don't make a route for it. Render that page from a controller when a purchase is made. I made a quick video for your question [here](https://youtu.be/rhkbb25B7BU). Hope it helps! Edit: I made this before seeing in your later comments that you can't make a POST request. Ah well...
The preemptive scheduler. As far as I know no other mainstream language or VM has one other than operating system kernels. Most of the interesting things that are in the BEAM are rooted in solving the problem of always being available. There was a recent talk about the solid foundation the BEAM gives us where the speaker started a node with only one scheduler (one os thread) and was still able to make requests while one request was blocking calculating some ridiculous prime number or something. So if you compared this to JS or Go which have cooperative schedulers if one request blocks the thread with a synchronous task you’ve screwed your performance. BEAM makes some trade offs to get consistency in a world of chaos. 
It’s not really binary, things exist more on a spectrum. I would say properly using hot code reload and multi-node deployments are advanced. Performance optimization is advanced.
I'm on my phone and it is late but isn't this because module attributes are set when compiled whole configuration values are read at runtime. So when the attribute is set there is no confirmation value? Forgive me if I missed it, I've been binge watching the Vietnam war on Netflix and my brain is fried. 
While unrelated you saying ‘binary’ reminded me of binary pattern matching. That’s just magical to me :-)
i meant in regards to what the skills of Erlang developer
Ah my bad! Then I would say manual process management outside of common abstractions like GenServer. More advanced than that is NIFs. 
All conventions are shit, unless you follow them and vice versa, all conventions are good unless you disregard them. I think the most widely spread convention is to omit the parentheses for function definitions without args, but if you prefer to do it with parentheses, I can’t think of a good reason against it.
And heavily discouraged unless you really need it...
supervisors macros
This is so true. I’ve gotten into infinite loops a few times and it took me longer than I care to admit to realize it was happening, because everything else was working fine.
What? I was under the impression that binary pattern matching is THE way to parse binary messages?
Coming from both Java and Ruby, I have a hard time placing macros in a world of readable code. A huge amount of the Ruby codebase I work on is incredibly difficult to read and reason about due to rampant metaprogramming. It may be concise, but it's completely unreadable to the unititiated. To this end, I've completely avoided macros. If time saving mechanisms are merely linear, then they usually aren't worth doing for readability and portability IMO. I'm open to be convinced otherwise though.
I tweeted about how'd I'd rank my Elixir comfort level once: [https://twitter.com/mafinar/status/972556015588622336](https://twitter.com/mafinar/status/972556015588622336) (I think beyond 5 could be "advanced"?)
Do they pay like $200/hr or something lmao
Phoenix framework is like "lets macro all the things !". no beginner can understand its code, very frustrating.
Upvote for gun!
Heavily discouraged by whom?
Do you happen to remember which talk this was?
What do you guys thought of this? I watched and it made a lot of sense to me. Wanting to hear your thoughts on these you beautiful people
After some searching I found it. Added it to my main comment. 
There's been a big discussion about it on the Elixir Forums: [Should we adopt Dave’s way of building applications as a series of components? ](https://elixirforum.com/t/should-we-adopt-daves-way-of-building-applications-as-a-series-of-components-daves-talk-has-now-been-added/14428)
I agree that extensive coupling is bad. I disagree to the level at which he wants to decouple everything out and I disagree with his take on project structure but that only follows because I disagree with the first part. Why are what he calls libraries and what many people would call service classes/modules in multiple separate what I call apps what benefit do I derive by now adding an overhead of server communication and the other pitfalls that come with server communication like handling what happens when suddenly my application can't talk to say a calculator like one of the examples he had on one of his slides. I personally think microservice architectures are the way to go, maybe with a monolith sitting in the middle, maybe not. So, while I can appreciate what he's saying I believe those microservices should be self contained units with their own business logic contained in the unit. If you find yourself sharing a lot of configuration across multiple microservices you've potentially identified another service that you should have broken out or -- you failed at your separation of concerns. What I mean by that, for example in something I am building, a service launcher for machine learning cyber security, the api does not need to talk to a database so it has nothing relating to ecto in it while the service that represents a running job doing what ever to the ml model does talk to ecto to store meta info about the job that ran. Initially I thought well couldn't I need to store the model name or time or something from the api and while I could of, that same info was just as easy to make available in the later service and make that the only service that talks to the DB. So when architecting something with a little extra thought you can usually draw lines and either dumb something down like my API or just not add the functionality to begin with if you think it belongs somewhere else.
There is a topic at Elixir forum about this: [https://elixirforum.com/t/should-we-adopt-daves-way-of-building-applications-as-a-series-of-components-daves-talk-has-now-been-added/14428/88](https://elixirforum.com/t/should-we-adopt-daves-way-of-building-applications-as-a-series-of-components-daves-talk-has-now-been-added/14428/88)
The only thing I found to their effect is a performance concern, [http://openmymind.net/Elixir-Binary-Matching-Performance/](http://openmymind.net/Elixir-Binary-Matching-Performance/)
I agree with phoenix framework's directory structure comments, its looks confusing and not to the point. May be this should be discussed in next major releases. 
I agree with phoenix framework's directory structure comments, its looks confusing and not to the point. May be this should be discussed in next major releases. 
I agree with phoenix framework's directory structure comments, its looks confusing and not to the point. May be this should be discussed in next major releases. 
I agree with phoenix framework's directory structure comments, its looks confusing and not to the point. May be this should be discussed in next major releases. 
I don't think any framework's goal should be for beginners to easily understand the source code. Simplicity of using the framework should be much more important that simplicity of understanding the source code. I don't know of any framework that is straight forward and simple to understand for a beginner. Can you give an example of what Phoenix source code macros are particularly confusing for beginners? Do you think these should be rewritten without macros purely for the sake of being easier for people new to language to better understand the source code?
&gt; All conventions are shit, unless you follow them Hence why OP is asking this question.
I think it's only a matter of time before the Elixir community gravitates to a more effective way of using some kind of component organization as described by Dave. It may not be exactly like Dave describes, but there's definitely momentum in that direction. It just feels right to build separate mix applications for different concerns. I especially make effort to separate my persistence/ecto applications. I don't like how Phoenix glues a lot of database into the business logic. The challenge is bringing Phoenix's ease of entry to building applications to building things as Dave describes. Phoenix gives you a reasonable structure for applications and lots of generators to get you going. I'd like to see that same level of low-barrier-to-entry using the decoupled component approach.
&gt; I don't think any framework's goal should be for beginners to easily understand the source code. Sure, it's not its goal. &gt; I don't know of any framework that is straight forward and simple to understand for a beginner. Fair point. The problem here is that Phoenix macros add layers of indirection *everywhere*. It's the next level of "not straight forward". &gt; Can you give an example of what Phoenix source code macros are particularly confusing for beginners? Last day I was looking for the differences of implementation i between `broadcast` and `broadcast_from`, took me some time. &gt; Do you think these should be rewritten without macros purely for the sake of being easier for people new to language to better understand the source code? I don't think rewriting what already work is something I want to think about.
I mean what he says makes sense here and there. I don't particularly agree with everything. But I often find that's the case with any of his talks. I don't _personally_ see the issue with how things are now. I find writing Elixir the current way is quite easy and pleasurable. But as always, there is room for improvement.
Are you running this in iex? Functions run within iex use the interpreter which has different performance characteristics. For proper benchmarking you'll want to at least create a `.exs` file and do `elixir foo.exs`. When I do that I get the following results: %{avg: 6564.0, min: 4585} %{avg: 4035.5, min: 3636} %{avg: 3906.8, min: 3193} %{avg: 3820.2, min: 3167} The Integer functions are distinctly faster. Notably your benchmark also includes the time required to iterate 100k items, which will dilute the differences between the `is_` functions. Even still, the built in ones are faster. You can see what they do by just looking at the source code: https://github.com/elixir-lang/elixir/blob/v1.6.6/lib/elixir/lib/integer.ex#L31
I was running it in iex, when using a .exs file it evened things out a lot more, with the stdlib funcs being a bit faster. Thanks for pointing out the iex vs exs thing. But I'm still not sure why `require` is needed to run these functions. I see in the source that they are implemented as defguards, which my understanding is are basically macros. Why would the stdlib not have a version of the functions that can be called without using `require`? This is the first time I've seen stdlib functions that must be required first.
Speaking as a noob who got into Elixir/Phoenix before any other web framework. Phoenix isn't any more or less user friendly than something like Laravel. The main difference I've found is that Phoenix lacks beginner friendly documentation, there are quite a few things that you're just expected to be used to, which is understandable if you're a rails veteran. A good example of this is that other than one video series from Alchemist Camp there aren't any explanations/tutorials for writing CRUD for a many-to-many relations schema. 
My guess would be that they are implemented as defguards to be, evidently, used in guards, but making two more distinct functions seems counterintuitive: they would need to have a different name, and the team would have to support it. I think, a simplest require is not a high price for reducing complexity and not having multiple functions, some of which may be used as guards :) 
&gt; The main difference I've found is that Phoenix lacks beginner friendly documentation I don't really know of any frameworks that have beginner friendly documentation. Docs are, in my experience, always created to be a reference tool for people who already know the framework, or at very least have experience in similar frameworks. All frameworks leave the "beginner docs" to ancilliary resources like books, tutorials, articles, videos, etc. Beginner resources are great for beginners, but once you get more experienced, they are terrible as reference material. Sometimes you just want to look up the args or options a function takes, and that's it. Official docs should contain no more info than they need to. Usually, what the function name is, what args/options it takes, and *maybe* one example, that's all. Anything else is starting to become a tutorial, and tutorials and docs are very different things. If Phoenix lacks beginner resources (though I've found the opposite to be true, it seems to be *all* beginner resources), it's because it's a new framework, built with a new language. In general, learning to program for the first time on a new language, and learning web dev on a new framework is going to be really difficult. I love Elixir/Phoenix, and I would recommend that everyone who knows how to program or is in webdev check it out, but I probably wouldn't recommend it to someone who is totally new to programming/webdev at this point. That's not to say it's not possible, it totally is, it's just going to be a bit harder than it would be with Rails/Django/Laravel/even Node. But if it's working for you, more power to you.
Why did you post the same info that was already contained in the first response to parent comment?
I did not see the comment. I watched the video, then went to look for the discussion in the forum and then I posted. In the mean time, ejstembler posted the same link. 
The problem I have with a lot of these "beginner" is that they do not take much time to explain how all of this code works. They just give you code that is expected to work and leave it at that. When you're learning that isn't very helpful. I'll use relationships as an example. Look at the difference between the documentation for [ecto](https://hexdocs.pm/ecto/associations.html) and [eloquent](https://laravel.com/docs/5.6/eloquent-relationships). The latter is a lot easier for a beginner or a developer new to this framework to learn from, the one for ecto is ok but not as good as the other one. 
Ah. I was just curious. I knew there had to be some explanation.
The standard library is, generally speaking, subject to the same rules as everything else, which provides a nice and consistent experience for everyone. The Logger module also works this way, you have to `require Logger` before the `Logger.debug` macro can be used. &gt; run these functions To your point specifically, these aren't functions, they are macros, which produce compile time transformations of your code. `require` helps guarantee the correct compilation order, and also ensures that any meta-programming is always called out explicitly.
If you provide some code we can execute and see the behaviour it would make it much easier to see what is going wrong. Maybe put the code in gist.github.com.
Isn't Elixir also pretty slow?
My point remains that docs are not supposed to be beginner resources. If the docs explained what the code did and why, I would consider them bad docs. If you want a deeper explanation, then one should he looking for beginner resources or tutorials, not official docs. Official docs are mostly a reference for people familiar with the tool. 
Can't help but think of the influence from how things are currently being done in the ECMAScript community as of right now. - so many node modules that do just one thing in hopes of doing it well. _sound familiar at all_ ie, what Dave describes as a library in his talk. - definitely **don't** agree with using phoenix the framework to manage the frontend aspect of a web application. 🤷‍♂️ especially with so many great ECMAScript libraries to chose from, ie. React, Vue, etc etc. And the fact that phoenix relies on a templating engine to produce it's "HTML output" just seems like an extra moving part to slow things down. I mean just look at what the Ember guys n gals have been going through, and how React was able to learn from the prior frameworks / libraries and was able to work with JSX as opposed to using a "templating engine". That said, I think Phoenix will more than likely stick around for a while but not as frontend framework, but more so as an _application_ (insert bad joke there) that behaves as the API aspect of a web application. That said, if I'm already writing ECMAScript on the fronted why would I want to cause brain hemorrhaging jumping back from Elixir / Erlang 😬 to ECMAScript when I can write the API and the UI all in ECMAScript. Sure Elixir and it's friends may be more performant for concurrent connections for high availability apps, but for my particular use cases, using Nodejs with Express gets the job done for all things API related with a web app 🤷‍♂️. That said, knowing that Elixir spawned from the short comings of the Ruby / Rails community, and applied a lot of its short comings, but also solved a lot of the scalability issues with Rails is interesting in of itself. But something that I find even more interesting is, that I can't help but feel that a lot of people got introduced to Ruby via Rails, nothing wrong with that, but I do little work with rails, and can't help but feel _my crude opinion_ that it's glory days are in the past, but from all the rails apps I cobbled together it's nice knowing how to edit a brew formula when I' m in a pinch. And in closing I'm particularly more interested in the apps that Elixir could be applied to outside the web application space. **TL;DR;DC** Great talk, loved ❤ the passion, and I'll definitely continue to follow Elixir and the community when I can.
&gt; And the fact that phoenix relies on a templating engine to produce it's "HTML output" just seems like an extra moving part to slow things down. As a fun side note, the templating engine (EEx) is uniquely fast among languages and frameworks because templates are compiled into functions that use IO lists, which [as explained here](https://www.bignerdranch.com/blog/elixir-and-io-lists-part-1-building-output-efficiently/) allows the VM to make excellent usage of low-level system calls when rendering them. The same blog continues to explain how Phoenix takes advantage of this fact [here](https://www.bignerdranch.com/blog/elixir-and-io-lists-part-2-io-lists-in-phoenix/).
The guard-compatible functions in `Kernel` (the ones you do not have to require or preface them with a module name) are direct analogs of the ones available in erlang. Each one corresponds to a *single* BIF (built-in-function: a memory-safe, highly-optimized function implemented in C within the VM, those properties being why they are allowed in guards). The name-spaced guards, as you observed, are implemented via `defguard`. They are effectively compound guards offered as conveniences for common operations within that domain. Adding them to Kernel would mistakenly imply that they are primitive guards like the ones you are thinking of.
Continued learning Elixir by implementing a server and a homegrown publish-subscribe/telemetry-sending protocol. Mostly I have experimented with code organisation and making parts more modular, often driven by writing integration-tests. [Server](https://gitlab.com/Shakti213/lighttel-server) [Shared library](https://gitlab.com/Shakti213/lighttel), intended to be shared by both server and a future client. [Protocol specification WIP](https://shakti213.gitlab.io/lighttel-specification/#publish) with [source](https://gitlab.com/Shakti213/lighttel-specification) 
Nice! Although I'm not sure about configuring this library using app env as described in the README. Are there cases where you can't pass all the configuration options directly to `instrument_plug` ?
I believe it's designed to be quite fast in multi-threaded processes.
I am not an expert, but i suspect that calling with \`Module.function()\` is recommended for several reasons: 1) to remind you that it's a function, and not, say, a map dereferencing, which could get ambiguous if you're using an \`@variable\` 2) to remind you that it's a function call, and not, say, a function value. It's more useful to less experienced programmers whose eyes haven't adjusted to the &amp;function/arity notation yet. doing \`def my\_func do\` because it's 100&amp;#37; unambiguous and saves characters on your limited width
Author here. A detailed blog post can be found [here](https://medium.com/@sfhrizvi/writing-lispex-a-lisp-interpreter-in-elixir-423cd2c439ac).
Sorry if I'm misunderstanding your question: You can override any configuration value for that plug when calling `plug PlugInstrumenter`. Or if you're using `PipelineInstrumenter`, you can pass options to the `use PipelineInstrumenter` invocation that will also override the app env config. You don't need to do any app config if you don't want to, but I think it's convenient.
I feel the same way, a lot of these gripes are fairly minor. That said, better organization of GenServer code would be VERY nice, and that is a real thing.
You can’t. Phoenix will always render `”#{Plug.Exception.status(exception).#{format}”`. 
&gt;This is probably the single myth that does Elixir the most harm. If anything we need to keep repeating the myth because synthetic benchmarks are overwhelmingly numerically heavy (because those are easy to write). Honestly, at the point where you need anything with a matrix or differential equations, you should probably not use a BEAM language.
What languages do you observe people using for those tasks? What languages do you suggest they should use?
Mostly people use callout to python/numpy/scikit/tensorflow, or natively Java/Scala, if the rest of their framework is in that (but probably tough to integrate otherwise). I think python is terrible for this, to be honest, and would much rather people use something like Julia, but it's hard to build momentum away from something that is popular to something that is better, but not well-known. If I had a lot of time (I don't) I would make something that could use elixir to marshal binaries to Julia, since both are functional, have AST-as-first-class, and encourage use of distributed-deploy-as-task.
Right, python. Which is no better or worse than a beam language with bindings (at least since dirty schedulers), but with the advantage that you get threading and even clustering. You mention tensorflow and it makes a fine eaxmple: there are now Elixir bindings for it roughly equiv to what one gets with golang (python still owns the training game at this point). If we stop telling ourselves it is not possible or a good idea, maybe we will make serious progress on these matters. And I do not think the goal should be to take users from Python or whatever, but to make the BEAM ecosystem as good as it can be so that it is as useful for those of us using it as possible.
And, I think that if BEAM tries to be everything for everyone it's going to fail. Even though a lot of people use it, Tensorflow is awful - the reason why it's awful is because it makes serious compromises that make it mind-bendingly difficult to use (and other totally insane things like the build system), and difficult to evolve. It's lucky that it has the support of Google (which is not exactly known for elegant code) and therefore can ship out new features rapidly, like distributed TF, which, btw, is where things are moving. Ironically despite (or perhaps because of) being a distributed language, I don't see dTF being integrated to Elixir so easily.
Thanks, good to know app env config is optional. Even though it's convenient and lots of libraries expose config this way, the global nature of it can sometimes be problematic: https://hexdocs.pm/elixir/master/library-guidelines.html#avoid-application-configuration 
If you ultimately want to customize the error pages in Phoenix this may help [https://elixircasts.io/custom-error-pages-in-phoenix](https://elixircasts.io/custom-error-pages-in-phoenix).
Do you have a blog for the game (or your projects in general)?
**How to customize the NAME of NotFound page template**
The quality of TF is another, unrelated though interesting, topic. I agree that the BEAM should not try to be everything to everyone, but the idea that common computational tasks are far enough out of scope to fapl under that umbrella is a massive stretch. The BEAM ought to be good enough for common tasks, and the common need for computational tasks is beliwd by the frequency with which it comes up on BEAM language discussions.
Site appears to be down
It's been down for about 30 seconds 4 time this hour. I've been doing load testing with [Loader](https://loader.io).
Could the episodes be cashed in memory for a few minutes to prevent hitting the DB each time?
For sure! I could store them in ETS and then only need to load from the DB on the first request after rebooting and each time an episode were edited. Also, I did some more tuning and got it up to 5,000 reqs/second for loading an episode page... which is kind of nuts. E.g. if peak traffic times were 100x normal then that would mean it would be fine for 4.3 *million* views per day. So performance tuning definitely isn't something I should spend any time on, except for fun.
^The linked tweet was tweeted by [@honeypotio](https://twitter.com/honeypotio) on Jul 04, 2018 09:51:43 UTC (83 Retweets | 207 Favorites) ------------------------------------------------- 🎥 Get ready to explore the origins and evolution of the \#Elixir \#programming language with [@josevalim](https://twitter.com/josevalim) , [@mobileoverlord](https://twitter.com/mobileoverlord) , [@chris\_mccord](https://twitter.com/chris\_mccord) &amp;amp; other big names from the \#ElixirCommunity! Stay tuned for the official release of [@honeypotio'](https://twitter.com/honeypotio') s “ELIXIR: A MINI-DOCUMENTARY” on JULY 12TH! 🍿 [Attached video](https://video.twimg.com/ext_tw_video/1014437341866446848/pu/vid/1280x720/WzxfBYArkvhI5RHT.mp4?tag=3) ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Changed my career for the better, LOVE elixir :D
Might as well use webpack 4 no?
&gt; I’m really happy that Phoenix 1.4 will be using Webpack instead of Brunch by default. &gt;I’m personally not a big fan of creating SPA style Javascript applications. I’m more of a “sprinkle JS when needed” type of person while leveraging server side templates and Turbolinks, but I do rely on a lot of SCSS and some JS to power my apps and Webpack is quite popular and well supported. It's really not complex to use SCSS with Brunch. I'd say it's a lot simpler than dealing with Webpack, though the point about momentum is very true.
!RemindMe in 7 days
I will be messaging you on [**2018-07-12 07:49:05 UTC**](http://www.wolframalpha.com/input/?i=2018-07-12 07:49:05 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/elixir/comments/8w6hd2/elixir_a_mini_documentary/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/elixir/comments/8w6hd2/elixir_a_mini_documentary/]%0A%0ARemindMe! in 7 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt;!RemindMe 7 days !RemindMe 7 days 
!RemindMe 8 days
I tried, but in the case of using it in a real project (basically the same as this example app but with 10k+ lines of SCSS) compile speed was 60% slower than 3.x.
It's more than just SCSS. There's SCSS, autoprefixer, ES6 JS, loaders for images and fonts, and minification in production. I'm sure Brunch can do all of this but I've used Webpack in the past, so I already had some prior knowledge of how the config would be set up. Webpack 4.x will be even easier to config but I haven't quite figured out why it's slower than 3.x yet.
!RemindMe 8 days
!RemindMe 8 days
!RemindMe 8 days
How would you go about expanding a nested struct into a syntactically correct fragment. In order to deal with variable depth maps, it would have to generated different fragment texts.
I think we pretty much agree. Brunch can do it fine, but a huge marketshare is an incentive to use Webpack. Also JS sprinkles instead of immediately setting up React/Redux/Babel/Flow/Immutable/the kitechen sink/etc... for a fledgling product.
I disagree with calling things "advanced" it discourages people new to the language from trying to gain a new skill or understand what's considered by popular opinion to be harder.
Yes, but that wouldn’t be a problem as `.` is operator as any other, so you can easily extract that from AST. Thanks to that you can easily nest it as far as you like. 
!RemindMe 8 days
I built a project generator that scaffolds a nif for you. https://hexdocs.pm/nif_gen/1.0.0/readme.html#content I've been doing this manually for so long, and I finally had enough. Hope it's helpful to someone else
Check your changeset function and make sure its casting necessary params. Also I think you are passing body as a map `%{body: %{"key1" =&gt; "var1", "key2" =&gt; "var2"[.....]}` Why are you using `Plug.Conn.fetch_query_params(conn)` ? You already got params in function arguments. Its not required to fetch it again. Better pattern match of params if possible like def handler1(conn, %{"column1" =&gt; column1, "column2" =&gt; column 2} This way you filter out unwanted params.
I don't want to filter them out. Save all of them.
Okay, that's not a problem, you can take all params. 
i don't understand what you suggested
&gt;Check your changeset function and make sure its casting necessary params. Check your changeset function and make sure its casting necessary params. 
it does
!RemindMe 7 days
What /u/i_am_pro is saying is that your action code above is equivalent to this, which is much simpler: def handler1(conn, params) do Repo.insert(%MyModel{}, %{body: params}) But you’re not actually using a changeset here which I think is the problem. Try this: def handler1(conn, params) do MyModel.changeset(%MyModel{}, %{body: params}) |&gt; Repo.insert() 
thx
Out of curiosity, have you tried Parcel? It is supposedly zero config.
It pisses me off when someone writes fizzbuzz without abusing gcd(3,5) = 1
I haven't heard of Parcel before. I looked at their docs and closed my browser after a few minutes because I couldn't find any examples on how to accomplish setting up common asset pipeline.
I'm still learning the ropes with Elixir but I much prefer the cond examples (2 or 3). In this specific case I prefer 2 over 3, but there is definite value in naming a condition with a function to better describe it.
Can you elaborate? 
Is in on-site? Would you be open to freelancers?
I didn't know you `gcd` could be used for fizzbuzz, but I think what he's trying to say is divisibility can be checked using gcd. e.g. `gcd(n, 15) == 15 is the same as rem(n, 15) == 0`. Learnt something new :)
It's an interesting approach. I liked the idea of configuring and deploying assemblies (although I'm not quite sure how noddy should scale exactly). And while I liked the concept of components I have a few issues with them. For one I'm worried they would be too granular (especially when he was saying ideally should just be a single file). So would you have a component that sets up and exposes interfaces to a DB, and then other components that manage some functionality of that DB? But then you've introduced tight coupling between those components, need to manage component dependencies, and will likely need to update a number of components in unison. Whereas if you treat components like services then you alleviate those issues, but the restrictiveness of how components need to be built is rather limiting (versus if you were to just structure them as their own application/with their own supervision tree hierarchy). Another issue is component inter-dependencies, what happens if two components depend on each other or if a collection of components have a cyclic dependency. Do you move logic into the assembly now to remove those dependencies, or do you make the components granular enough to remove the inter-dependencies (but then suffer the issues with granularity). I also don't really agree with his sentiment about umbrella applications. I think they work when you think about them as simply as a way of organising projects. So whenever you're working on a project that should have separate applications, but it makes sense to develop those applications together in a single project. For instance if you had a chat application and an email application, developing those together might not really make much sense, so I'd treat them as separate projects. But if I had a chat application and an API to that chat application then developing those together makes sense, and so I'd stick them in an umbrella project. 
No, the fact that 3 and 5 are relatively prime mean that `rem(n, 3) == 0 and rem(n, 5) == 0` can be written as `rem(n, 3 * 5) ==`, so you save on division. 
From https://parceljs.org/getting_started.html parcel watch index.html Starts watch mode and recompiles the changed parts of the `index.html` dependency graph.
True.
You are right about 2 and 3, I find them more readable too . However, as you immerse yourself into Elixir, you'll find 6 and 7 become readable too.
Is that a Phoenix-like app? 
ugh... I've been putting off learning webpack and there's a new version of it. I've done grunt before but webpack looks disgusting to learn. Is there any book recommendation? I learn via books better than anything else.
Wut... Elixir is slow for numerical stuff. You should try projecteuler in erlang or elixir and see how long it takes to solve the prime number problem. The only thing I can see it do is to use for is for low latency and lots of user connections while calling R script via rpc. 
Yeah there's a lot of configuration required, but luckily version 4 requires a lot less config. I haven't upgraded yet because 3.x is working just fine and I had performance issues with 4.x. I don't know of any books off hand. You may just want to skim webpack's docs and then look at my Webpack config as a working example, and start googling the bits you want to know more about in detail.
An implication of cond however is that each condition will be evaluated until one is met. This can be problematic if those expressions had side-effects or if evaluating them had a noticeable performance impact. Whereas the compiler and VM are optimised for handling pattern matching, so it is usually preferable if you can alternatively represent it as such. 
How does case fare in this case (pun intended)? Would the compiler and VM treat that in the same way as pattern matching on a function?
that was fun
Any performance difference will be very negligible. Assuming you have the same pattern being matched in a function as the case expression, the actual match instructions generated should be exactly the same (give or take which inputs it's referencing). The only difference would be one would be a separate function (so will have the overhead of calling the function) while the other would be embedded in another functions body (though this will lead to a bigger BEAM file if you repeat it). Plus the compiler could do anything at the low level in the future but the same truth should remain, that the performance would be much the same. Main things to consider are whether you'll have multiple inputs (more convenient to handle in a function than multiple case statements or putting results in a tuple IMO), the additional contextual information a function would provide is beneficial, you'll need to repeat that expression in multiple places, etc. 
Cool thanks. Most of my cases have been used to replace using if conditions. Things like pattern matching on nil or anything else, instead of doing an if else.
(I started thinking about this after reading this article: [https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5](https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5)) Well, first I thought [hex.pm](https://hex.pm) packages were compiled, so I imagined having a hash of the package in the mix.exs project that includes the [hex.pm](https://hex.pm) package (and retrieved from GitHub project page, or whatever but from another channel), and have it checked against the download package. There's a flag telling the Erlang compiler to compile in a deterministic fashion, for a specific OTP version of course, that could be use to have deterministic builds ([https://en.wikipedia.org/wiki/Deterministic\_compilation](https://en.wikipedia.org/wiki/Deterministic_compilation)). However that's not the case ([https://twitter.com/voltonez/status/1011246857287356419](https://twitter.com/voltonez/status/1011246857287356419)): [hex.pm](https://hex.pm) is source code, which makes sense: no need to care about OTP version. Moreover, I guess the Elixir compiler can have much wider side effects because of macros (like downloading stuff using an HTTP client). Therefore, I guess it could be possible to either have a hash of the source code or even code signature in mix.exs and check it against source code downloaded from [hex.pm](https://hex.pm). This is, however, much more complicated than just referencing the GitHub in your mix.exs, which on security perspective has the advantage of having one less third-party to trust. Using [hex.pm](https://hex.pm) seems a bit to risky to me for plugs and other libs that deal with HTTP request.
Not really sure what you're saying, that R is significantly faster for numerical computations? It's not, R is very slow but most of it's libraries are highly optimized compiled C/C++/Fortran so function calls are very fast. 
There is [hoplon](https://github.com/nietaki/hoplon/blob/master/README.md) tool that try to compare released sources with the published ones, but that is still only heuristic and nothing other than reviewing each dependency by yourself will save you from malicious libraries. The little pro in this case is that when library was once published and you have fetched it (and saved to `mix.lock`) you can be almost certain that no one tampered with the source that you have in `deps`.
GitHub is home to over 28 million developers working together to host and review code, manage projects, and build software together.
Every developer “worth their salt” knows how to implement FizzBuzz, It is a program which prints the following:
The compiler is about 10-20% faster. There are lots of factors that contribute to that result - the BEAM emulator is faster itself, the compiler received some performance improvements and the file system was completely overhauled to use NIFs and dirty schedulers instead of port drivers.
A simple plug that can be used to wrap plugs with an instrumentation callback. PipelineInstrumenter can be used in a similar fashion to Plug.Builder to instrument a plug pipeline.
It's slowly becoming more common to serve brotli compressed HTML, CSS, JS and JSON assets, as it speeds up page loads and decreases bandwidth costs.
The main focus of this article will be on getting Webpack working with Phoenix. The Docker bits are all optional.
@erlang_org @emjii @scrogson @FrancescoC @jlouis666 @cmeik Thought you might want to check this out too! 👀👆😋
Pretty neat article on building off of `GenServer`. Could anyone provide context for when you would want to do something like this? I'm trying to find a real-world example of when this kind of thing would be useful. My initial guess is a GenServer could be useful if you wanted to roll your own Sidekiq or some other sort of cron job processor.
I am far from an expert, but my understanding is that a genserver is really just a thread that can synchronously or asynchronously respond to messages and update or return state. I’ve used it for: - a “server” that can quickly store data from other processes in memory, respond with an :ok, and then asynchronously save that data to disk, allowing the other process to continue without waiting for an expensive disk write. - a “server” that listens for incoming socket connection requests, and then spawns new “servers” to manage those connections - a server that acts as a gateway to a third party api, with the ability to log and/or throttle requests that come through 
You would never do something like this in practice. The author makes it clear that this is an exercise to understand how the OTP implementation works, and the OTP implementation is decades old and well-tested, so there is no need to write your own. Think of it like writing your own malloc in C, or your own dict in Python. 
honeypotio's “ELIXIR: A MINI-DOCUMENTARY” on JULY 12TH!
As you may guess, this article is not about rebuilding the Elixir GenServer. It’s already there and it works great. And that’s what interests me the most: why it works great?
Phoenix Framework creates a new process for every request. This processes are lightweight Erlang processes and not OS threads or processes and wholly managed by erlangs VM. Erlang VM uses pre-emptive scheduling which guarantees that every process which exists inside erlang VM will get a slice to CPU time no matter what, even if one of the process is extremely cpu intensive. So if your app us getting two request simultaneously, there will be two processes and both will get equal cpu time. How they process data is upto you. You may swap more processes to parallelise tasks. GenServer is not only for concurrency, they are for fault tolerance and state management. How many request a GenServer can handle at a time depends on its implementation, by default it works just like a queue, processing one request at a time.
@i_am_pro has pretty much covered the whole question. Some addendum: Typically when using phoenix cowboy is your webserver. Here is some info from its documentation: &gt; By default, Cowboy will use one process per connection, plus one process per set of request/response (called a stream, internally). &gt; The reason it creates a new process for every request is due to the requirements of HTTP/2 where requests are executed concurrently and independently from the connection. The frames from the different requests end up interleaved on the single TCP connection. &gt; The request processes are never reused. There is therefore no need to perform any cleanup after the response has been sent. The process will terminate and Erlang/OTP will reclaim all memory at once. &gt; Cowboy ultimately does not require more than one process per connection. It is possible to interact with the connection directly from a stream handler, a low level interface to Cowboy. They are executed from within the connection process, and can handle the incoming requests and send responses. This is however not recommended in normal circumstances, as a stream handler taking too long to execute could have a negative impact on concurrent requests or the state of the connection itself. Also, typically GenServers are single processes (unless they delegate to other processes by spawning them or using some kind of worker pool). So, if your GenServer is sequential 2 requests would take 20 seconds just because they are stuck at the Genserver. GenServers when not designed properly can become bottlenecks for your applications.
Thanks for sharing the idea. For shared storage we have only considered Memcached or Redis, haven't thought about using pg2 which does seem to fit the problem. I'm open to exploring it. 
Hope you don't mind some feedback. 1. Race condition prevention is due to the immutable data, which isn't exclusive to functional programming. 2. You can absolutely deadlock and starve your processes if you're not careful, and even if you're careful sometimes, especially if you're writing a distributed application using `:global`.
Thank you for your feedback. I did not know that. Where can I read more on the subject?
Well I don't have anything specific, but you can contrive a situation where two genservers simultaneously `call` each other and end up blocking with no timeout set which creates a deadlock. This is usually easy enough to catch though.
Thanks, that's pretty clear and helpful and confirms my suspicion of how it operates. Good stuff to know before writing my program. 
I've got a little bit lost after this part "You would think that Elixir is excellent at parallelism, but it’s not.". Could you share some more details on why Elixir is not good at parallelism?
 Elixir GenServer. It’s already there and it works great. 
mobileoverlord, chris_mccord &amp; other big names from the ElixirCommunity!
 I had the exact same thought.
Looks like you’re trying a random route that doesn’t exist. (Looks like you’re navigating to /fdsafdsafdsa..... etc) If you don’t have a matching route (or a catch all route), this is the type of error I’d expect. 
what you expect - crash with 50 lines of stacktrace?
Well, if you look about 8 lines into the stack trace, there’s a NoRouteError So I’d say you need to fix your routes. If you’re serious about Phoenix development, I highly recommend the Programming Phoenix book. It will get you going in no time. 
Is the question here is why is it crashing but still being able to show an error page?
&gt; Well, if you look about 8 lines into the stack trace, there’s a NoRouteError So I’d say you need to fix your routes. &gt; I'd say - you didn't understand my question
yes
Race conditions and deadlocks exist in Elixir/Erlang: https://www.quora.com/Is-it-possible-that-Erlang-Elixir-with-OTP-suffer-from-race-condition Perhaps you're thinking of Rust, which performs pretty clever analysis to [prevent data races](https://doc.rust-lang.org/nomicon/races.html). It still doesn't solve the general problem though.
You trap exits and handle it there. 
Good stuff. Thank you for the info.
See: https://github.com/elixir-plug/plug/issues/723
Is the serialization of process execution also to blame for helping to avoid race conditions? It's possible to still have business race conditions but the types of race conditions and how often they occur is much less. Immutability doesn't come into play with GenServer state if I did something that fetches the value, modifies it elsewhere, and updates the value. This cross process operation is super race condition susceptible. But if I perform the operation in a single process that also owns the data, then serialization prevents race conditions
thx
It's only on-site unfortunately acroca! Fingers crossed will have some remote positions coming on in the near future though. You can log into https://functional.works-hub.com/ and select Elixir + Remote as your preference and I can keep you updated!
&gt; New York, NY, US Hmmm.
Registration/login required to even just look at jobs let alone apply = massive fail Single biggest reason why I know a lot of people (including myself) wouldn't touch functionalworks
Yep well you can see a preview breakdown of the roles and then the company name + info once you log in, but that is liable to change so thanks for the feedback!
They have a satellite location in Boston, where they are building their Elixir team! 
How did you found out, /u/erlangfactory?
Hey guys, we've just [released the documentary!](http://doc.honeypot.io/elixir-documentary-2018/)! Many thanks once again to José Valim, Chris McCord, Justin Schneck and all the other elixir enthusiasts and experts who helped us make this film! [http://doc.honeypot.io/elixir-documentary-2018/](http://doc.honeypot.io/elixir-documentary-2018/)
So excited!
They have a satellite office in Boston, but headquartered in New York, and Boston is where the Elixir team is! I will make another job posting for that...
Can you provide more details? It is not clear what you want to achieve. The more you can elaborate about the problem, the better the answer will be!
See [Phoenix.View.render_to_string/3](https://hexdocs.pm/phoenix/Phoenix.View.html#render_to_string/3): ``` string = Phoenix.View.render_to_string(MyAppWeb.MyView, "my_template.html", layout: {MyAppWeb.MyLayoutView, "my_layout.html"}) ```
Elixir is designed for concurrency, not parallelism, like [Go](https://blog.golang.org/concurrency-is-not-parallelism).
Agreed. Not excellent compared to what? CUDA? It's not exactly *hard* but it's also not much of a concern. Pick the right tool.
Somehow I completely blanked and missed Empex this year. Oops.
The “with” tagging pattern is brilliant 👍
Is there an alternate mirror? I keep running into "This video is not authorized to be embedded here. Learn More" no matter the permissions I throw at the site.
I had the same issue as well. It must be one of your extensions. Once I tried disabling them or opening it on Firefox, it was all good.
The mini demo is fun but other than that I'm not sure about the goal of this documentary.
Probably interpreting list of numbers as a string, so when you IO.puts it, you get "garbage." If you want to see the contents of the list, use IO.inspect instead. 
It just came out. Nice documentary, shame that it's made by a company which uses spam-like advertising all over reddit. :/
Does anyone know the font on Jose's terminal at 5:05?
https://www.youtube.com/watch?v=lxYFOM3UJzo
Looks like hermit, maybe 🤔 https://pcaro.es/p/hermit/
you don't need more details
then you don't need an answer. :)
It is aimed for non-Elixir developers who have no idea what the language is for, how the community works, etc.
Considering erlangfactory are the ones putting these conferences together it's a pretty weird title of the post as it makes it seem like it's some random person who just found out a special offer is available and not the conference organizer promoting a special offer. Somewhat disingenuous.
yes, that's what I tried to point out. But with bad cynicism
from you - no
So what is your strategy? Ask vague questions, be rude to people trying to help and then [erase the question](https://www.reddit.com/r/elixir/comments/8xvdl0/404_error_causes_my_app_to_crash_internally/), making it impossible for other people to learn from the discussion? I just want to be sure so I don't make the mistake of trying to help again.
Here we go: [https://github.com/ericmj/xhttp](https://github.com/ericmj/xhttp) One of the reasons we were working on it is because there was a possibility that Erlang would not ship with an HTTP client, so we needed one for Mix. But it seems that Erlang will always ship with one after all, so at this point it is a bit unlikely it will be part of Elixir and we (Eric and Andrea) are not working on it as actively as before.
Awesome! Now do one for rustler too 🙏😂
Link isn’t working for me. 
What it says?
Video does not work for me (United States)
Idk why it could be, maybe copyright issues? There's J.S. Bach playing on background, but I thought it's public domain now, also have not other ideas.
“This page isn't available. Sorry about that. Try searching for something else.”
https://youtu.be/laUMgDLthE4 try this one
That one works, thanks!
“LINK DEAD CALL OPERATOR”
The original link worked fine for me. I'm in the US. Cool stuff btw! Now you just need a Bluetooth keyboard.
NOTE: For those, ho can't open link in the header, here is short one - [https://youtu.be/laUMgDLthE4](https://youtu.be/laUMgDLthE4)
Yeah, also I tried to run Phoenix - and it work just fine, serving on its 4000 port) 
Have you looked at LFE (lisp flavored erlang) 
Why would you want to pattern match anything but a head?
Yeah I have seen LFE, it's by one of the Erlang's original creators, my aim though was not to mimic that. I made this for people who are new to Elixir, as writing an interpreter is a great learning method. 
Can you give an example?
Do you know about Yecc and Leex? 
Nobody forces you to do it. I like it very much.
you do realize that if you don't pattern-match in the head, you'll have a whole bunch of extra boolean/branch logic inside the function? It's not like it's going to get any less pretty by not doing it in the function head (and you don't have to!)
I added the example. 
Yes. I do realize that. In fact that's how I've been programming my entire career. Passing vars/objects in a function and then doing things with them in a procedural fashion. The beauty of that approach is it allows you to easily debug things. You can set breakpoints where `image` is being set in my example. But if you're just pattern matching at the argument level, to my knowledge, you can't debug anything there.
 how to install Elixir on Android phone in no time. Enjoy. 
which it has grown since its creation back in 2011.
why it works great?
Interesting thread, what would you propose as a cleaner alternative? 
Yeah, honestly, because I'm so new at it, I have no proposal. I'm just thinking that it might be hard to debug things. I would prefer passing in primitives to my functions. I think that makes for way easier debugging.
Fair enough. My background was primarily in languages like Python and Javascript before I came to Elixir so it was odd at first for me too. I will say the error messages Elixir provides in cases it can't match are really helpful. I hope it grows on you too. 
Well, either the pattern match will pass, in which case all relevant names get bound, or it will fail, in which case you should hopefully get a descriptive error that says something about no match found, and by simply looking at the function heads you can see what it expected and why it differed
You can still pass primitive list into function and use a case statement inside.
Is it by chance [this](https://www.youtube.com/watch?v=6U7cLUygMeI) video? Lib looks cool, have you had a look at [ExActor](https://github.com/sasa1977/exactor)? It might fit your needs too.
How do you do :gen_server.reply/2 in this model?
I've never found genserver to need any cleaning up. I also prefer explicit code which is this isn't. Elixir and erlang benefit from less magic than ruby or rails. Why try to bring more magic to the ecosystem? To save a few lines of boilerplate?
Traditional genserver is *very* hard to read, because the handle_caxx need to be aggregated, forcing separation from any function that encapsulates the GenServer.caxx. Boilerplate generally is an opportunity for error. I'm generally opposed to magic, so some way of de-abstracting the transformation would be nice. I can't think of it. On the other hand, I don't think this is any worse than, say, plug. 
Yeah, that's the video! I can't say I loved everything in it but his point about genserver hit home. Exactor looks great, maybe I should use that since it's more bsttle-tested!!
Haven't implemented it yet.
&gt; Traditional genserver is very hard to read This is the first I've ever heard someone ever day that. I've heard by fair share of complaints about Erlang/Elixir, and the complexity of larger systems is one of them, but I've never heard of someone saying that a single GenServer file itself is "very hard to read". If you understand pattern matching, and what a gen_server is doing, then the fact that there might be a few `handle_call` functions one after each other shouldn't really phase anyone.
You should be defining the `start_link` inside the GenServer module. So you can call `MyServer.start_link`, instead of `GenServer.start_link(MyServer, ...)`. This allows for setup/config to happen in the file itself. You should not leave the setup/config to the user of the gen_server to handle. The code could be drastically improved from it's current state. I would work on that part before trying to extract boilerplate from gen_server. Perhaps once you use those boilerplate functions as they're intended, you'll see that they server an important purpose.
It might be too much magic to do it this way, but you should either have call take 3 arguments all the time, or detect a 3 argument definition for the from. In any event, using `from` for async replies is a very important pattern to preserve.
Thanks for the suggestions! I've been thinking hard about this one :)
&gt;I've never heard of someone saying that a single GenServer file itself is "very hard to read"/understand. That's rather surprising. [https://www.youtube.com/watch?v=6U7cLUygMeI&amp;t=12m20s](https://www.youtube.com/watch?v=6U7cLUygMeI&amp;t=12m20s) I didn't necessarily like or care about everything he said in the video, but the part about GenServer struck a chord. I think his solution (later on the video) is a bit too clever, with unnecessary unicode things going on, etc.
I have a defined start\_link elsewhere. The unit tests are at an early stage of development, the TestClassic/TestServex modules were intended to isolatedly test the call and cast macros.
I think your opinion of pattern matching is based on the fact that you just learned it and so you don't see the real world advantages of it yet. If your argument is that it has no place in argument lists, I still disagree. In your example it would have been %Identicon.Image{image | color: {image.hex[0], image.hex[1], image.hex[2]}} But the difference is this version doesn't fail until it gets to that line, whereas the pattern match version will fail before it even executes the function.