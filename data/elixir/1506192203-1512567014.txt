For a web developer, I think.
The best way is probably to provide a generator that copies the migration to the user's application.
Thank you!
Yeah I'd probably say the same. People may say that all the stuff you aren't using is a waste of resources, but I don't know how much that matters. Unused parts of the library may add a very small amount to compilation time, but unchanged files aren't recompiled so any effect on compilation time would be rare, and if think that the memory/load time cost when you start your app would be negligible. As for running supervisors you won't be using, remove them from your supervision tree. Not serving static assets? Remove that plug from your endpoint. I like to thin down what's generated by default, because I'm pedantic, but I don't think you're saving much overhead by using phoenix over just plug. One exception I'd make is something suuuuper simple, like a status HTTP endpoint, but then I'd probably just use cowboy (unless it required auth, then I'd go to plug).
I'm a web developer.
I did something similar for [ecto_job](https://github.com/mbuhot/ecto_job/blob/master/lib/ecto_job/migrations.ex) Consuming apps generate their own migrations which call into the library code to do the work. 
As a tech manager, the answer is simple: I would not use Phoenix/Elixir for most things can resemble a CRUD app. Other tech ecosystems have very mature and complete offerings for CRUD that are far easier to hire for. None of these ecosystems, however, are Haskell, Rust or Go. Compared to _those_, Phoenix is remarkably better for even CRUD.
What Elixir libraries exist for high precision mathematical calculations? I work in fintech and we currently use Python, but I am curious as to whether Elixir is starting to develop libraries that are comparable to those in the Python ecosystem. 
[removed]
[open_api_spex](https://github.com/mbuhot/open_api_spex) similar to [phoenix_swagger](https://github.com/xerions/phoenix_swagger) for open API spec 3.0 and a few other goodies like typed controller params.
I published a pure Elixir CRC16 function to hex yesterday: ex_crc, At work I’m finishing off the first drop of an Elixir/Rust/websockets BTLE device manager and driver platform SDK for internal dog fooding. 
Not doing any elixir at te moment, but keep in mind that the Kubernetes API talks HTTP, so with a bit of work you could use any HTTP library. The work would mainly be about handling certs properly.
Kazan looks active enough to me (~ 20 days). More of the common functionality isn't changing a lot, so even something 6-12 months old should be fine enough for most operations
Not sure if it does k8, but take a look at [this](https://github.com/GoogleCloudPlatform/elixir-google-api) project and see if it can be adapted to your needs.
Thanks! I'll take a look.
I’m writing MMORPG server at work.
Can you share any more details. I'm working on an mmo on my own time.
Thanks for the rec, but I did look at this while looking for a google storage library. I spent all of yesterday trying to make it work (for [google storage](https://github.com/GoogleCloudPlatform/elixir-google-api/tree/master/clients/storage)). First, I used the [already published hex package for google_api_storage](https://hex.pm/packages/google_api_storage). I couldn't get insert to work. I went back to the entire project to generate the client (maybe something changed?), and the client generation wasn't working. Submitted a [PR](https://github.com/GoogleCloudPlatform/elixir-google-api/pull/10) this morning, and generated the new client--but nothing changed, and it just came out with a bunch of empty new files.
That was the type of work I was hoping to avoid. :(
I hope so. I spent two days trying to find a suitable google cloud storage library, and have come up empty. 
Are you asking if you can have race conditions in Erlang/Elixir code that utilizes OTP? The answer to that question is: Yes.
All code can have bugs. Of course it is possible, but not very likely, that OTP code has race conditions. Code using OTP libraries, on the other hand, can of course have race conditions.
Race conditions certainly, but not data races. 
One example I found https://elixirforum.com/t/avoiding-race-conditions-with-genserver-call-2/4304
X-Post referenced from [/r/programming](http://np.reddit.com/r/programming) by /u/jailbird [It's Windows 3.1 All Over Again](http://np.reddit.com/r/programming/comments/72by8e/its_windows_31_all_over_again/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
I think you should read this [post](http://nathanmlong.com/2017/06/concurrency-vs-paralellism/).
Oh look, yet another article about how node.js is the Devil that only uses callbacks (what, coroutines have been added to javascript?! meh, doesn't matter) and OTHER_SOLUTION is better. Don't get me wrong, I'm learning erlang and elixir for a reason, but this kind of article is getting tiring.
So what I don't see about this: If you use only one system thread, then whatever you do at a higher (VM) level, you only have one piece of code executing at a time on a single CPU. You can either have a VM swap context, or swap context by having an event loop, or completion routines or whatever. If you want to use more than one CPU core, then you have to interact with system threads to achieve this. 
Can you both share details? How do you test this? Where do you even begin? Is a frontend/game client already built? I’d love to know more. 
And the BEAM does it for you as it starts one scheduler per core and distributes your processes among them.
Earlier this year at ElixirDaze I demoed how even single-threaded BEAM can help us. The first demo starts [here](https://www.youtube.com/watch?v=5SbWapbXhKo&amp;feature=youtu.be&amp;t=392). Hope you'll find it interesting :-)
I don't think the goal of the article is to necessarily paint node.js as the devil. We need to be able to have those discussions about the pros and cons of different technologies. node.js has a lot of positive things going for it but the async model is not one of them.
Come on, don't tell me you never came across one of the **numerous** articles about the cons of node's concurrency model that cropped up since it got popular. Also I think the critique of that model isn't completely fair, because if you refine it like Nathaniel Smith did with the [trio library for python 3](https://github.com/python-trio/trio/) you get something rather interesting, a way of doing concurrency with a) an imperative language b) a really tight control over what happens when c) a "native" way to handle the basics of backpressure, while in erlang you need to use even more message passing to get it. Now of course for the pedants, I'm not saying node.js follows trio's strict philosophy, although you can follow it to a certain degree when programming with node.js (eg. it can be easier to handle backpressure with streams rather than with coroutines). I think it's good to be aware of the strengths of other models of concurrency even when using erlang's VM.
I've posted in one of these threads before. I'm using Phoenix with channels as the main communication path to the Unity client. I started with creating the models for my most primitive objects, for instance a ship, created some unit test for the functions and then built my way up. Most of my testing takes place on the channel level now where I'll establish a connection, send some commands, then assert that things changed as expected. The client is also being built from scratch using unity. This shouldn't take very long if you've done a decent job with your unit testing.
Hey everyone, I want to share our latest update of development toolbar `ex_debug_toolbar`. Thanks to feedback from community, we improved stability and added a bunch of new features. Most notable is a history panel ([screenshot]( https://github.com/kagux/ex_debug_toolbar/blob/v0.4.0/screenshots/history.png?raw=true)) which allows you to view and inspect previous request ([screenshot](https://github.com/kagux/ex_debug_toolbar/blob/v0.4.0/screenshots/history_loaded.png?raw=true)). Other changes: * _(new)_ support Slim templates (`phoenix_slim` package) * _(new)_ `debug` config key to enable to verbose logs * _(new)_ `ignore_paths` config key to skip tracking certain requests by paths * _(improved)_ breakpoints no longer use distribution code There is so much more we’d like to add (separate dashboard, channels, visualize query explains, interactive breaks, etc). I just wish we had more time to work on the project :) So contributions, feedback and new ideas are very much appreciated!
Nowhere I said those articles do not exist. I have only replied in regards to the article *this thread is about*. To be clear, I agree with you that those articles exist and are annoying, I just don't think this is one of them. The critique of the model is fair because it is still mostly concerned about async I/O. It means one expensive CPU operation will cause all other requests to wait more than they should. [Trio](https://trio.readthedocs.io/en/latest/tutorial.html#a-kinder-gentler-gil) has the same limitations. And before you say "then don't block the CPU", it is worth reminding such expensive operations can be out of your control, such as garbage collection. To me the event loop is like memory allocation, I have no interest in managing it and it should be fully handled by the programming language and the runtime. async/await makes it better but it still does not change the fact most developers should not have to care about it at all. In regards to back-pressure, when it comes to I/O, most languages do so by letting the contents sit in the buffer and delegate that to the network stack. That's how `gen_tcp` in Elixir/Erlang works, you don't need "even more message passing" as you claimed. If by any chance you were referring to GenStage, note it is about back-pressure *and* multi-core concurrency. At the end of the day, if you don't provide M:N multiplexing, you are limited in terms of resource sharing and you throw predictable latency out of the window. It has been more than a decade since [we have been warned about the importance of multicore programming](https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf). Failing to acknowledge this is only going to hurt those communities, since they should be looking for ways to expand their programming models. 
There are other job boards out there, but the aim of this is: 1. Make a real (pet) project on Elixir+Phoenix 1.3.0 2. Do it following ElixirStatus design (I really like that one!) 3. Try to make job offers more visible (includes posting to social networks) and easier to submit. 4. Just for fun! Hope you like it! [Github](https://github.com/odarriba/elixir_jobs) [Twitter account](https://twitter.com/jobs_elixir)
I had a race where one genserver called into another which then caused a call back into the first. Since the first is not going to respond to any more requests until the second responds, that is a race condition. Surprisingly (to me) elixir helpfully told me that it detected a race condition, crashed both processes and I was able to debug it pretty easily once I traced the path through my program.
Can you recommend any resources for learning this paradigm? From concurrency and parallelism to message passing, it's still nebulous to me.
Can you expand on your last paragraph? How would processes communicate?
I think it's rare but not impossible
At startup the BEAM creates one scheduler thread per hardware thread it can see. Processes are then run in those scheduler threads. If there is no processing pending the threads sit idle and do nothing. In a clustered deployment the VMs ("nodes") need to talk to each other to maintain the cluster, so in such cases when your app isn't doing anything the VM can/will wake up from time to time to do some work. But generally it is throttled to your application's processing. You can also control how many scheduler threads are created at start-up by passing the +S parameter on vm start. edit: you could also just run it on your dev machine and observe it's behaviour there.
No, I would not expect this to be a problem. As mentioned, the BEAM starts up a number of schedulers equal to the logical CPUs available to it. But if it's not doing any work, they'll all be idle. The CPU credits on these burstable AWS instances are only consumed if the CPU is doing any work. All four CPUs at 0% is the same as one CPU at 0% – no CPU credits will be consumed.
I am migrating a php web app to elixir/phoenix
I think for a library letting the user either call in to the migration or generating the migration could be the way to go. Although, this gets tricky when the library gets updated. How I chose to handle this in my applications (standalone services rather than libraries), is they get the adapter and migrate themselves on app start. Though they can be configured to avoid this. My goal for those projects however was to make them as self contained as possible (they're still not really at that level yet). 
Can't look it up right now but pretty sure Phoenix has a notion of "pipelines" for exactly this use case. So you'd have an API pipeline that yields JSON and another that renders HTML. Whether you use separate controllers is entirely up to you. Personally, I would. 
One thing you could do to cut down on the nesting and help readability is to define the push function 4 times with pattern matching instead of using case. Generally pattern matching with functions is preferred over case. 
Ugh, I can't believe I forgot pattern matching functions. Thank you! I'll re-write it using pattern matching. 
Thanks for this!
You can create two different routes, the regular HTML version and a /api/ one. Your controllers will probably be separate as one will handle calling the json view rendering and the other HTML view rendering.
Since the extension exist, the next step is to define the Ecto.Type: https://hexdocs.pm/ecto/Ecto.Type.html In your migration you will do something like this: add :search, :tsvector And then in your schema: field :search, MyApp.TsVector And MyApp.TsVector is implemented based on the link above. If you have more questions just ask.
I'm working on [my own URL shortener](https://www.reddit.com/r/elixir/comments/73068x/heres_shrtener_my_first_completed_project_using/) (not that I think the world needs Yet Another Url Shortener), to learn more about Elixir. It's pretty simple &amp; open source! :)
I'll second what /u/TheSultanOfSwagger said, and I'll add that if you have a process you need to communicate with (i.e. the Rpn.push calls), a GenServer is probably more suitable, as it would abstract out the receive loop and it's a common pattern that helps other users understand what your code is doing. EDIT: I'm no Elixir expert, but to me the idea of an Agent is just to store state, while a GenServer stores state _and_ mutates the state by communicating with it.
I'm working on an automated trading engine as a personal project, composed of: * Websocket clients connected to the markets * Bots detecting certain patterns and opening/closing trades. * Phoenix+React webapp to query the status of the system. I could've found something easier to start with... And just got the go ahead from my client to rewrite a huge betting odds comparison system, from untested, spaghetti PHP to Elixir. XML parsing, data deduplication, all exported via REST endpoints. So I guess my trading engine is on hold, since I'm actually being paid to work with Elixir now. Couldn't be happier!
Haven't seen the code. Just something I noticed. The url requires protocol (http|s) to be recognized as such. I wouldn't make it so strict but hey, these are your specs. The problem is that when I enter www.google.com I simply get a "is not a valid URL". It had me scratching my head for few seconds.
Thanks for the feedback, /u/vagara! I will write some specs and make improvements to it.
Suggestion for optimisation: If the same url has been used before, then return the existing short code.
I can't really answer the question, but shouldn't scaling up be an option if you start seeing heavy loads? I'm sure there's gonna be a lot of variety between Phoenix apps, so maybe some real world observation on your side would be the best route. 
I am afraid of only one thing. What if I build my new app using Phoenix (with more struggle than I'd need to put using Rails, so that it perform better in the start and is easier to scale once I get too much load), what if it performs as if it's a Rails app.
.
It definitely won't perform as a Rails app. Most accounts from people moving from Rails to Phoenix is that it performs around 10 times better. Bleacher Report said they moved from 80 machines in Rails to less than 8 in Phoenix with better response times. Some time ago they mentioned the Hex API, which is the package manager used by both Erlang and Elixir communities, runs on small dyno on heroku (I guess $9?). Although you should probably consider running two smaller VPS just for redundancy. Edit: [here is one recent article on the topic](https://medium.com/@SergeyChechaev/rails-and-phoenix-microservice-synergy-5433598ab333). They used 8 large instances running Rails and they still could not achieve the same numbers as a single large stance running Phoenix. 
So your app (with 25K concurrent users) is some kind of chat application or something similar? Is it backed with the postgres or something like redis or what? I mean what do those 25K users do?
You could also pull out the operation into an anonymous function: # + case fun = fn left, right -&gt; left + right end # - case fun = fn left, right -&gt; left - right end Then you can pass `fun` and call it: Agent.update(pid, fn state -&gt; [first, second | rest] = state new_head = fun.(first, second) [new_head, rest] end)
.
The whole point of hashids is that you can go from integer id to string and back again. You don't have to store the `shortcode` column at all – just normalize it at runtime. def get_url_by_shortcode!(shortcode) do [id] = Hashids.decode!(@hashid, shortcode) Repo.get!(Url, id) end However, if you ever expect to replace Hashids with something else (and do it in such a way that won't collide with existing hashids already in the database), then you'd want to store the string code directly, like you're doing now.
... The devil is in the details, is rails slower than Phoenix? yes. Can you bury your single node with 5 concurrent users on Phoenix -- yes. Bad performing code is not dependent on your development platform. Something as simple as N+1 queries on badly structured tables without indexes can take down a pretty big server in short order.
Phoenix scales pretty much linearly with number of cores and ruby is notoriously sluggish that you typically see 10x baseline performance on the erlang vm. You could run rails on JRuby to get that difference a bit smaller, but ruby generally scales poorly. If you are planning to use websockets, phoenix will blow rails out of the water (rails 5 active cable even had terrible memory leaks after release) Pretty much any engineering blog mentioning elixir or erlang backs this general notion up (pinterest, Discord, riot, whatsapp and many more) even if they are not using phoenix in particular. 
I can’t offer an objective answer to that. It’s not an Apple to apples comparison. However I do want to talk about architecture a bit. Elixir, and Phoenix, offer up an entirely different way to solve the problem in comparison to Rails, Node and other single thread, single process systems. As you probably know the scaling solution for them involves virtualization. Docker basically. To get around the GIL and run multiple copies of your application multiple times in multiple processes. Recently the trend is to break up the app and run different parts of it as separate applications offer finer granularity and other benefits, ie micro services. Elixir doesn’t work like that. Your application isn’t one process,it’s many hundreds, thousands, millions? doing little jobs in isolation not on one machine but a cluster of them and with a supervision tree making sure the various parts keep running the way you want them to. They talk to each other by passing messages and when something breaks, as it does, the damage is contained and recoverable no matter how important a part it is, ever the entire app worst case. It’s distributed. Processes run on whatever node and sends messages to whatever node and receives them from whatever node. Your workload is distributed in a net split resilient cluster and all that means fault tolerance and scale. So what happens if you deploy your app on your server and it isn’t fast enough to handle the load you throw at it? I think you can answer that. You throw another machine at it and that is all. What do you need for Rails besides a http load balancer, redis, and a whole boat load of other stuff, dependencies! So maybe the question is not will this particular machine run my app but what happens when it won’t. I dispute your assertion that elixir/Phoenix is more work. It will take time to get used to, it’s an investment, but you earn that back many times over by the time you hit production and it’s all gravy from there. You can build, deploy and scale an application right out of the box in Elixir. No saas services to pay for or support or get burned by when they get DDoSd or otherwise fail. Fault tolerance and distributed concurrency aren’t plugins, they are built in. Reconsider the problem. 
As an additional anecdote to the linked article: Rails spending a lot of time on json serialization is spot on. I had an endpoint returning a single json object for a detail view taking about 220ms including about 20ms of postgres. Unsatisfied with the long response time, I used the cprofiler and found that 160ms were spent on json serialization alone with about 50000 (!) calls to to_s and 25000 calls to new. Some of this was due to reflection heavy ActiveSupport code, which is basically doing lots of string manipulation under the covers just to figure out what classes and methods to call (on every damn request)... 
Did you end up fixing your rails performance problem?
Yes and no: Since that detail view would only change when someone does something in a CMS (rarely), we could just cache the rendered json response in redis (cache-hit responses were about 5ms, since almost no work besides a redis get was necessary then). Had it been dynamic or user-specific data, we'd been out of luck. Also, caching (and therefore invalidation concerns) like that introduces a lot of complexity, which I try to avoid if possible. That's why I think baseline performance does make a huge difference if it means not having to rely on caching as much. tl;dr: In this specific case, we could find a solution, but not for the general case edit: You have to keep in mind that pulling something like Redis as an additional dependency into your project/infrastructure can be a huge additional overall complexity and source of failures. Often it's a single point of failure, a point of congestion plus having all the problems every system connected via network has. I think Ruby is way too reliant on Redis for concurrency (sidekiq jobs, synchronization) and caching...
Elixir should make for a good first language, you won’t have some of the bag habits and assumptions the rest of us do. 
I've been writing code for over 25 years and I'm incredibly jealous that you get to START with Elixir. It's a wonderful language and really approachable.
All programming languages suck. That's no excuse not to learn them. Learning Elixir first is fine, but you still want to learn JavaScript. You can skip PHP though. That one doesn't really have any redeeming value. Unless you plan to design languages. Then you should study it for what not to do.
I would not suggest it actually, unless you have a lot of patience and understand concepts quickly. Learning the core concepts of programming in my opinion should be in whatever language has the best support/learning resources and isn't dead. The docs for elixir are good, but I would argue they are not geared for beginners to programming concepts, and the community definitely isn't. Not that they aren't welcoming, just there's no content built for that audience. For reference, your post is the first time I've heard someone say this question who doesn't already program. 
Why are you picking up programming? Are you looking to make programming a career? If so how quickly would you like to get a programming job? Elixir is a great language. If you’re purely learning (at least for now) as a hobbyist then go with Elixir. If you’d like to find a job in the current industry and can’t afford to learn a technology where jobs are a few years out, then don’t go with Elixir. In the later case JavaScript or Ruby are good choices. I’m a big Elixir enthusiast, but the reality is that easily finding an Elixir job is a few years out.
This! The job market for Elixir devs is slim. In a few years it might pick up. But if OP is looking for an entry level job, then I would learn Ruby on Rails.
a lot of the benefits of elixir (the genserver/supervisor model) are going to fly right past your head you're still going to pay the cost of not having lots of free googleable help for any given problem you run into probably not the best idea. i dont think a first language choice matters that much tbh, but it should at least be a popular one so you have easier access to help
If you do choose to learn Elixir, I highly recommend [The Little Elixir &amp; OTP Guidebook](https://www.manning.com/books/the-little-elixir-and-otp-guidebook)!
As other people have pointed out, all programming languages have shortcomings. Elixir is no exception. The one thing I'd say against Elixir (and any functional programming language, really) is that for most humans it seems to be easier to wrap your head around an imperative language, because the control structures map almost 1:1 with the way we think about "recipes", whereas functional languages use more convoluted forms that approximate better with a mathematical definition of a function than anything else. For what it's worth, I can think of at least one minor nit I have against Elixir: it doesn't have built-in function currying, which is something I really enjoy in Haskell: http://blog.patrikstorm.com/function-currying-in-elixir
The first language I learned in school was Scheme, which is more on the functional end of the spectrum. I am very grateful these days I was exposed to those concepts early on.
Thanks. I got the picture. But I have a doubt. The structure of vector is %Postgrex.Lexeme{word: word, positions: positions} Example [%Postgrex.Lexeme{positions: [{1, :A}], word: "a"} Now while retreiving from the database this is fine. But when in I want to insert into database I dont want to specify the positions(I want to specify only the weight) I want the db to handle that. Any idea how that can be done? It could be convinent if I have the words and weight and the positions are set automatically. Thats how I would update in the db.. UPDATE tt SET ti = setweight(to_tsvector(coalesce(title,'')), 'A') || setweight(to_tsvector(coalesce(keyword,'')), 'B') 
I think elixir would be an awesome first language. It really encourages good habits. However, you should probably also get some exposure to C early on as well. Between the 2 of those, you should be good to go as far as fundamentals.
What about using AnyCable instead of ActionCable?
&gt; Can you bury your single node with 5 concurrent users on Phoenix -- yes. That situation is more complicated than the example makes it sound though. Only ways I can think of where a scenario like the above could work is if those processes all at one point interact with one shared process that has the bottleneck (could be a DB operation, single poorly implemented worker, etc.); but then they're not exactly concurrent. But if you kept those 5 user connections as purely concurrent requests, then even if those individual requests end up taking forever, the VM should still happily chug away with any new connections you throw at it. I guess if you had a memory leak (crash VM), or a bad NIF you could do it. 
A nice read! What kind of deployment do you recommend for phoenix apps instead of SaaSes like heroku?
The Ecto.Type can just read and write to the DB using the data structure. So you would need to have this logic in your application. If you want to do it in the DB, you have to use Repo.update_all alongside fragments. Something like: query = from t in "tt", update: [set: [ti: fragment("setweight(to_tsvector(coalesce(?,'')), 'A') || setweight(to_tsvector(coalesce(?,'')), 'B')", t.title, t.keyword)]] Repo.update_all query You can put those behind macros if necessary but that's the main idea. 
Heroku is fine and you should still see an order of magnitude improvement there compared to Rails. But if you want to get the best bang for your buck then a VPS, EC2, and so on.
I use nanobox.io for deploying. Very nice.
&gt; Bad performing code is not dependent on your development platform It definitely is. Even your N+1 example is harder to happen in Ecto because if forces associations to be loaded explicitly instead of magically. The development platform has direct influence on bad code and on poorly performing code - it isn't the only influence though.
AnyCable comes with the requirement of extra dependencies, one option even being Erlang itself, while Phoenix works with no external dependency at all, not even Redis.
Alexis has gone through the experience of Elixir as a first language and shared it at ElixirConf: https://www.youtube.com/watch?v=TUOeFdFvOk8 - I haven't seen it yet but it will probably be interesting to you. Let us know what you think.
Elixir has lot of support from big companies, you just need to know where to find... Support from large community should not be only thing you should be looking in a programming language. Look at PHP very large community support but one of the shittest programming language
I don't use Rails anymore, so I cannot comment on that. That said, if I had the requirement of persistent connections I would always try to build it on a platform that is good at it, like Phoenix or Akka, even if the main application was Rails.
I know I found functional programming easier than imperative programming when I started. 
AnyCable uses Go and Erlang under the hood. Any of the two options can be chosen.
[joy of elixir](https://joyofelixir.com) is a work in progress book that you can read free online that is aimed at people learning to code. The Elixir language and community is wonderful, good luck! 
Thanks for that! Looks very interesting...reading it now in ihop lol
I think you can absolutely study Elixir as your first language. It might even be an advantige that you have not been exposed to object oriented programming before learning a functional language, which is what Elixir is. That said, I usually recommend Python to people who want to learn to program. The reason is that it has a friendly and intuitve syntax, it's very easy to find learning material (also on numerous free MOOCs), it's easy to find answers via google and there are a ton of libraries to get stuff done. But if Elixir attrackts you more — go for it. It's a more interesting language than Python.
thanks this really helps. Adding the logic seems like beyond the scope to me. I'l need to run a raw sql query. Any idea on how to use fragment with `insert_all` instead of update_all?
Yep. I think functional programming is tough to learn if you've already spent time doing something else, but diving in fresh it's actually easier to wrap your mind around 
LISP isn't really a thing anymore - If you're referring to Common Lisp, it's not a pure functional language. In fact it's not really even an impure functional language. It's truly multi-paradigm, but lends itself to using a functional style where appropriate. You can mutate all over the place and pepper side effects wherever you want though. For a functional Lisp, try Racket/Scheme or Clojure - or if you're attached to running on BEAM there's always LFE 
Especially if they want to get into the market, and move onto elixir asap.
It is not possible afaik, sorry.
I wouldn't recommend Elixir as a first language. Many of the benefits of using Elixir are in the OTP system and how it relates to computing at scale. None of that stuff will be comprehensible until you've spent a few years working on serious projects. Even experienced programmers struggle with their first exposure to OTP, I don't think junior devs stand a chance.
Why the downvote?
thanks, I'l stick with db triggers for now
Hey man I'd say go for it! I'm down to help whenever you need it. 
[removed]
That’s very nice of you! Will be calling you every five mins :)
The Elixir By The Bellyful one was also a good intro. 
That. My first language was (C64) Basic, then 6502 machine language, then Z80 assembler, then C. I would have been productive quite a bit quicker with any of the languages mentioned here ;-) I think that Elixir is a fine first language. Python would also come to mind. I would not learn a language specifically to get a job, I would learn it to learn programming, understand computers and algorithms and all that stuff, and then if you like it, it's simple enough to grab a book from the library and learn something people will pay you to program in. But at first, focus on "does it look like I will be having fun in this language?" (for example, can you quickly build the sort of stuff you want to build?), because having fun will remove most of the barriers to learning.
Err... if you're "experienced" you have years of exposure, in 2017, to OO and state sharing etcetera. I think that a beginner actually has an easier time getting on board with OTP concepts because there's nothing to unlearn. It's a bit like a Squeak-in-the-classroom movie I once saw where (IIRC) 4th graders were doing manipulations that effectively amounted to differential equations - as long as your oblivious to the "fact" that differential equations are hard, they're mostly not ;-) 
EC2 under no circumstances should be listed as a best bang for buck. EC2 and similar are really expensive! If you find hosts with dedicated hardware, you'll find it a fraction of the cost. I like Scaleway's prices though haven't really stress tested on there. You can get an 8 core with 32GB RAM for $24/mo. AWS is going to be ~$180 for an m4.2xlarge instance. That's almost an order of magnitude higher! https://www.scaleway.com/pricing/
Yeah I started with an an Atari 400 and a basic cartridge myself. Then not much till I was 20ish and taught myself C++. I'm constantly jealous of the younger geeks. They have fantastic languages and things like raspberry pi and arduino.
Are there more rails jobs than python jobs at this point?
+10000 Started with Java. Took me years to understand how to write code that didn't mean shooting yourself in the foot. I'm talking clean, modular, maintainable code. Most of the techniques, approaches, and vision I learned doing this are called… defaults in elixir :) Go for it :)
I find it goes both ways. Some things in imperative programming click easier, some things click easier in functional. Recursion, for example, is much easier to understand in functional programming, but using recursion for simply iterating over a list kind of confuses a lot of people. I remember that being a huge issue for my peers in university.
My first functional language was Haskell, and it's kind of hard to top it. Smalltalk, on the other hand, was very easy to forget :P
Any Linux vps environment is fine depending on your needs and priorities. Heroku is not the best choice. The ERTS works much like an OS and that isn’t what Heroku and PaaS systems are designed for running. Docker either. You’ll want a complete VM to extract the most out of ERTS and your app. 
Turbolinks in a nutshell is just a javascript library that takes over clicks on a page to load them via ajax. Backend with a small exception for redirects, doesn't care about turbolinks presence. So if ios adapter works with Rails, it should work with Phoenix. P. S. for redirects you can use this package I built https://hex.pm/packages/turbolinks_plug
As a programmer, you will end up learning and using multiple languages, so which you start with is not super important. It's more important that the language supports you in doing what you want to do, e.g. make web apps, do scientific work or just help you get things done. These days I mainly use a combination of Elixir and Python myself. I normally recommend starting with Python as a first language. It's easier to start from zero, and there are more introductory materials. It's one of the most popular languages, and is very useful for scientific programming and general scripting. There are lots of libraries you can call on to do common tasks. The Python website documentation is quite good (https://www.python.org/). The book Think Python is good (http://shop.oreilly.com/product/0636920045267.do) from a more theoretical perspective, and Automate the Boring Stuff with Python (https://automatetheboringstuff.com/) is good for more practical things. Having said that, I think that the core Elixir language is fine to learn as a beginner. Functional programming is in some ways easier, because it is consistent, more like math. The Elixir standard library has a lot of thought put into it. This book has the most pedagogical approach I have seen: http://shop.oreilly.com/product/0636920050612.do This may also be useful, though I haven't read it myself: http://shop.oreilly.com/product/0636920030980.do All languages have their domain, and the area for Elixir is making web applications using Phoenix and reliable/scalable network services in general. It's great for that, but if you are first starting it may be a bit overwhelming. It's common to write simple programs when you are first starting out, but simple standalone programs are less common in Elixir world. You would normally be writing modules as part of a web framework like Phoenix. It is certainly possible to use the iex interactive shell, and you can write simple modules and call them from the command line. 
Why wouldn’t you want to use hoy code swapping?
Because it requires carefully updating all processes and state in your applications. For example, if your process receives message `{:foo, bar}`, you cannot change it to `{:foo, bar, baz}` because for a period doing the hot code swapping it will receive both `{:foo, bar}` and `{:foo, bar, baz}`. So you need to handle both for a while. You also need to carefully update state using code change callbacks and similar. And again, you can't simply rename a field, you need to keep both fields for the next deploy. All of this amounts to constraints on development and requires more extensive testing, which means increased development costs. Given the wide range of tools and techniques for doing blue-green deployments, hot code swapping should be a last resort for the cases you really need it, for example you have long running connections that can't be dropped.
Thank you very much for your clear explanation. I thought it wasn’t that complicated. 
I'm working on a wysiwyg crawling platform. With an internal dsl for data transformation. Frontend is Vuejs
I have a port of cucumber that could use some help. https://github.com/cabbage-ex/cabbage
Hey, that's a great idea! Are you planning on doing something like "let's play tdd"? You're welcome to check out and contribute to Phoenix developers toolbar (and soon a dashboard) https://github.com/kagux/ex_debug_toolbar If you have any questions, hit me up on elixir's slack, same nickname. 
I'm participating Startup Weekend with a friend and we're building a web app that allows a part of a website to be updated with email. (website has a piece of javascript that downloads the content from our server) - Elixir - Phoenix - Flat files as a database (just couple of models) - Ecto for form validations - Mailgun for sending &amp; receiving email - Digital ocean and nginx So far the "flat file db" has worked perfectly. We are well aware that it can get us only so far. We're taking the "quick and dirty" road since we're building a MVP. Here it is: https://iorma.xyz
You're in the right place. Start learning Elixir. 
I am learning Phoenix from "[Phoenix Inside Out series](https://shankardevy.com/phoenix-book/)" by Shankar Dhanasekaran ([@shankardevy](https://www.twitter.com/shankardevy)).
https://pragprog.com/book/cdc-elixir/learn-functional-programming-with-elixir
Imagine you are trying to compute the sum of the elements in a list. If you came from an imperative language, you would try this: sum = 0 for x &lt;- [1, 2, 3] do sum = sum + x end But the above does not work in Elixir. Any new variable or variable reassignment inside the `for` block does not leak. When faced with this issue, you could come to reddit or to elixir forum and ask "how do I leak the variables in the for block?" or "how do I make the variables in the for block available outside?". In Elixir, this is simply not possible. You are asking how to translate an imperative idiom to Elixir. It is much better if you ask "how to sum all of the elements in list". Then we can explain how that problem is solved in Elixir and tell you all about Enum.sum.
In my personal experience job hunting, Ruby on Rails jobs are way more common. If you are doing machine learning or some sort of data science, then Python would be pretty common. But for the typical web development job, I think there are way more Ruby on rails jobs than Python based jobs.
Suppose you want to implement an if condition in an imperative language, you'll do something like: if num == 5: print('equal to 5', num) elif num &lt; 5: print('less than 5', num) else: print('greater than 5', num) In Elixir, it's much nicer to accomplish the same via pattern matching, something along these lines: def do_something(num = 5), do: IO.puts('equal to 5 #{num}') def do_something(num) when num &lt; 5, do: IO.puts('less than 5 #{num}') def do_something(num), do: IO.puts('greater than 5 #{num}') Advantages: * Easy to test * Small functions * Easy to reason about * Looks cleaner Disadvantages: * Verbosity * You have to be aware of the flow
Good point. Yea most Ruby on Rails shops have a few small elixir projects. My company is a Ruby on Rails shop and has a few small elixir projects and plans to add more. So that is probably the best way to eventually migrate into elixir.
https://stackoverflow.com/questions/41356447/whats-the-need-for-function-heads-in-multiple-clauses
Hey hi, I don't know rails, but I have implemented a similar functionality client-side. Could you tell me what is the role of the rails library server-side ? What it is needed for ?
It's very similar. I just wrote this simple Plug based API: https://gitlab.com/Nicd/peliturbiini-followed-since I run it in dev with `mix run --no-halt`. When I make a release with Distillery, I run that with `path/to/bin/follow_time foreground`. That's the same as with Phoenix AFAIK. You can take a look at my project's supervisor to see how it starts Plug.
A blockchain based cryptocurrency proof-of-concept in Elixir: https://github.com/robinmonjo/coinstack 
Hey, Mostly two things: * convenience methods for developers to build turbolinks attributes in backend templates * handling redirects. Turbolinks follows redirects transparently. So when you request such page, it loads correctly content after redirection, but it doesn't know that URL changed. For that it expects backend to hint new URL in a header.
Oh ok so you can show the actual URL in the address bar ? Thank you :)
yeah, exactly!
Interestingly, I met someone who worked at Twitch at Elixirconf a few weeks ago. I don't recall how much Twitch does in Elixir, but the guy had some background in Erlang.
Ok ! Thanks 
about how faster plug that phoenix? how much less resources does plug consume?
I disagree with choosing Elixir as a first language. Working with the BEAM is fantastic, but I think you'd be better suited choosing another language that is closer to POSIX (fork/exec) to understand the concepts first. Then you won't be disillusioned that things are so easy if you go from Elixir to another language. As others have pointed out, the job market for Elixir is not as strong as other languages. In my opinion, Erlang/Elixir are great second languages. I think I'd rather direct you to learn a modern scripting language first (Ruby, Python, JS) as it will be closer to a classical language, it will be easy to work with, and it will stay useful for a long time (Elixir is passable as a scripting language, but the others still rule that domain)
Phoenix is very light, it's just a collection of plugs. Also it totally depends on what you do with it. Don't make your choice based on resource usage unless you are targeting some embedded thing. The project I just linked using Plug is running on my server and using 72 MB of resident memory. My blog that uses Phoenix is using 86 MB of memory. My service https://codestats.net/ that also uses Phoenix and does a lot more stuff (incl. channels, DB, and background jobs) is using 145 MB of memory.
Plug has fairly good docs: https://github.com/elixir-plug/plug#supervised-handlers We use pure Plug for one of our smaller services because Phoenix felt too heavy and it is fine
86 MB = website. and how many megabytes does the virt. machine BEAM consume?
I am not sure, I have not benchmarked that. Probably in the order of 20–40 megabytes. But you need to get your own numbers, these aren't really comparable.
GenServer was a perfect idea, thank you for that! My client code ended up looking a lot simpler, and I took the idea from /u/TheSultanOfSwagger to use pattern matching to make the call code look cleaner, too. This is what I ended up with: https://pastebin.com/UUgTZN6R Thank you all so much for the suggestions! I went on vacation for a bit so I wasn't able to try out these things until today. 
Cool, thanks for the additional info
I like that idea of longer, practical code kata's. Going to try it out :)
I've been thinking about doing something similar, but I always got stuck on how to actually connect to markets. What services are you using?
Right now I've integrated the Websocket APIs of Coinbase GDAX, Bitfinex and OKCoin. Ideally I'd like to write an implementation of the FIX protocol, but that's far down the line. Now I'm stuck on the hard part: write the trading bots. Since I'm not an expert of fintech, I'm doing a lot of reading on various techniques and algorithms, then I'll have to write a "sandbox" layer over the actual markets to test the bot implementation without spending any money. It's very complicated and I'm out of my depth (I'm just a regular full stack engineer), but it's fun!
Good job, that looks like idiomatic, clean Elixir! One suggestion: you can pattern match the state in the function arguments: instead of def handle_call({:put, :+}, _from, state) do [first, second | rest] = state new_head = first + second {:reply, :ok, [new_head | rest]} end You can write: def handle_call({:put, :+}, _from, [first, second | rest]) do new_head = first + second {:reply, :ok, [new_head | rest]} end Which might be further transformed to: def handle_call({:put, :+}, _from, [first, second | rest]) do {:reply, :ok, [first + second | rest]} end
can you explain more when you say "net split resilient cluster"? What exactly are you referring to that makes it resilient to net splits?
So, stylistically, you can change the first 2 function clauses to read def permutate([_]=list), do: [list] def permutate([a,b]=list), do: [list,[b,a]] This helps with readability. And because the list is always a list, you can use `length` instead of `Enum.count`, though this might make less of a difference in execution time than all the shuffling that's being done. As far as complexity/efficiency, that's something I would have to play with. It would be a fun exercise to turn this Enum-based algorithm into a Stream-based one, and that could also help defer some of the complexity.
A simple way is to use list comprehensions. I've translated this example from the Erlang programming examples guide at http://erlang.org/doc/programming_examples/list_comprehensions.html. defmodule Combination do def permutate([]) do [[]] end def permutate(list) do for head &lt;- list, tail &lt;- permutate(list -- [head]), do: [head] ++ tail end end Combination.permutate([1, 2, 3]) # [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] I doubt this is the most efficient way (with the repeated list concatenations using ++) but it's pretty clear. In general, if you find yourself counting things in guards to decide which function to execute, you should take a step back and think how you could capture the pattern in a function argument instead. Also, using temporary variables to hold intermediate state (like shifts_count and shifted_list in your gist) could be an indicator that you might have missed a more functional pattern. 
`Enum.scan(list, list, fn(_, [ h | t ]) -&gt; t ++ [h] end)` will get you all of the shifted lists. Scan is a great function that I use a lot, it's like reduce except the accumulator is added to the end of a list. It's great in cases like this where you operate on the previously mapped element. Then for the recursive part, you can just do something like |&gt; Enum.flat_map(fn([ h | t ]) -&gt; t |&gt; permutate |&gt; Enum.map(fn(permutation) -&gt; [h] ++ permutation end) end) Which is the same as your algorithm except 1. We compute all the shifted lists first, instead of doing them on the fly 2. We take advantage of the pipeline operator to a. permute the tail and b. distribute the head across the permutations In general we want each step in the pipeline to be as atomic as possible, so in the end it might end up looking like this: def permutate(list) do list # Get a list of "shifts" of the given list, e.g. [1, 2, 3] should return [[1, 2, 3], [2, 3, 1], [3, 1, 2]] |&gt; Enum.scan(list, fn(_, [ h | t ]) -&gt; t ++ [h] end) # You can now recursively permutate the tail of each list, which will give us a tree-like structure of permutations |&gt; Enum.map(fn([ h | t ]) -&gt; { h, t |&gt; permutate } end) # Add the head to each child permutation, i.e. { 1, [[2, 3], [3, 2]] } should become [[1, 2, 3], [1, 3, 2]] # This collapses our tree-like structure into a list of permutations |&gt; Enum.flat_map(fn({ h, t }) -&gt; t |&gt; Enum.map(&amp;([h] ++ &amp;1)) end) end So we take advantage of pipelining, destructuring, the awesome standard library (scan and flat_map), and function capturing.
&gt; do: [head] ++ tail (Apologies for replying to my own post) This could be do: [head|tail] instead. 
The suggestions here all work nicely, but you may also want to have the option of doing this in constant space, e.g. not having to enumerate all of the permutations at the same time. This is possible using [factoriadics](https://en.wikipedia.org/wiki/Factorial_number_system), which map to unique permutations of a set, giving you something like this: defmodule Permute do def all(list) when is_list(list) do permutations = (factorial list) - 1 for n &lt;- 0..permutations, do: nth(list, n) end def nth(list, index) when is_list(list) and is_integer(index) and index &gt;= 0 do factoradic(index) |&gt; (fn f -&gt; List.duplicate(0, length(list) - length(f)) ++ f end).() |&gt; Enum.reduce({list, []}, &amp;reducer/2) |&gt; (fn {_, permutated} -&gt; permutated end).() end defp reducer(index, {input, acc}) do {value, remaining} = List.pop_at input, index {remaining, [value|acc]} end defp factorial(list) do Enum.reduce 1..length(list), 1, fn x, acc -&gt; x * acc end end def factoradic(i), do: factoradic(i, 2, [0]) def factoradic(0, _step, acc), do: acc def factoradic(i, step, acc) do mod = Integer.mod i, step rem = Integer.floor_div i, step factoradic rem, step + 1, [mod|acc] end end Then you can ask for any Nth permutation of a list, or you can grab them all at once if you really want to with Permute.all/1
**Factorial number system** In combinatorics, the factorial number system, also called factoradic, is a mixed radix numeral system adapted to numbering permutations. It is also called factorial base, although factorials do not function as base, but as place value of digits. By converting a number less than n! to factorial representation, one obtains a sequence of n digits that can be converted to a permutation of n in a straightforward way, either using them as Lehmer code or as inversion table representation; in the former case the resulting map from integers to permutations of n lists them in lexicographical order. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/elixir/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
good bot
Just to let you know, a compiler optimization pass will turn a list literal that you are prepending onto another list into the cons syntax.
What's cons syntax? `[head|tail]?` `[1|[2]]` results in a `[1,2]`, is it more efficient than `[1] ++ [2]`?
If the left hand side of `++` is known to be a list literal, the compiler will optimize `[a,b,c]++list` into `[a|[b|[c|list]]]`. That's why you can use `++` in *some* instances in a pattern match, but only when the compiler can infer how many items to pull out of the left hand side of `++`.
Thanks
maybe you could use something like https://hexdocs.pm/elixir/Code.html#eval_string/3 to get where you want?
I can't tell which you're after but either `elixir -e` if you want to do this from outside a repl or `Code.eval_string` if from inside one.
In a few ways it may be better, and in a few it may even be worse. The point is, with any platform, if you don't know what you're doing, and don't know how to write good code, you can write a bad system. It's entirely possible to write a Phoenix app that is slower than a Rails app, even if the type of app plays well with Elixir's strong-points. Knowing how to use your tools, and knowing how things run under the hood can absolutely be crucial. It's like people who say "Node is non-blocking". Node itself isn't non-blocking, in fact it's incredibly easy to block it if you don't know what you're doing. Erlang is non-blocking by design, but that doesn't mean it's not possible to completely screw things up with poorly designed code.
 I occasionally use functions from `lists` like `unzip3` that don't have equivalents in `Enum` or `List`. The various *set modules, array, queue, digraph don't get much attention. 
Yeah, I recently took a look an the inner working of `queue` and it's pretty interesting the way it makes FIFO/LIFO faster, even with Erlang's use of linked lists. I found that to be interesting, though I haven't used it much in the wild yet. I'll take a look at some of the others. I really with IEX had the `h Mod.func` thing for Erlang lib stuff, that would be fantastic.
so many to choose from ... how about the built-in ssh server? https://www.erlang-solutions.com/blog/secure-shell-for-your-erlang-node.html
You can create a file called *.iex.exs* next to your *mix.exs* file that will be executed on startup by *iex*. I use it to define aliases like so: alias MyApp.Accounts.User alias MyApp.Blog.Post 
My most recent addition is [QuickAlias](https://github.com/thoughtbot/quick_alias). I find myself in every project having to write down aliases which happens to be really annoying. Edit: To be clear, it's to be used only in `.iex.exs` like specified in the project README.md, not in your actual modules.
`mix xref caller` which helps a lot when refactoring.
Oh lord, please don't use this. The point of `alias` is explicitness- if you see `Foo.bar()` called in a module you know that it either comes from the `Foo` module, or that you can check the top of the module to see the exact module `Foo` refers to. If you use QuickAlias and check the top of the file, you might see: use QuickAlias, MyProject use QuickAlias, OtherProject So which project does `Foo` come from? There is no way of knowing short of checking each project. tl;dr: Just write down aliases. Edit: Since OP isn't advocating using this in modules, my visceral NO! is directed not at them but towards anybody who sees this and thinks that they could also use it in a module.
Property Based Testing with the excellent propcheck library. 
You can use bash to create a temp file from the stdin and then execute that file. That would be probably the simplest way. 
Yeah that's terrible. Even the example is bad as you can write it out as `alias MyProject.{Foo, Bar, Baz}`. One (shorter) line and no guessing where `Foo` is coming from.
I think you're misunderstanding or not reading the page... It's intended for use in .iex.exs file so it would just do it for the repl, which is where I find lack of that most annoying... Sure you can explicitly do it but every item you add a new module you'd have to remember to update .iex.exs
Yep, that was my intention. Maybe he didn't read the library description. I should've made it clear though.
I did see that it's for .iex.exs, but it wasn't clear if OP was suggesting to use it for only that. I'm against it everywhere- it's probably harmless in .iex.exs, but it's not that hard to manually alias a module, and then it's explicit. On the other hand, maybe somebody sees it and decides to use it for aliases in their code base, and that's no good. Edit: Since OP was not suggesting to use it for anything but .iex.exs, apologies to them for responding so vehemently.
Yeah that's fair... Though tbh I could imagine using it there briefly while developing a new module and not yet sure what aliases I want, and wanting code to just not break for lack of prefixes/aliases while I figure it out :-) I agree it's not a good idea in practice, and especially not if used on multiple different name spaces, but we can't give people powerful tools and then complain we don't like how they use them.. or, well, we can, but let's do so in the spirit of constructive criticism rather than outrage!
&gt; but let's do so in the spirit of constructive criticism rather than outrage! Quite right.
I heard about this on The Elixir Fountain podcast and have been wanting to try it out.
One nitpick - You are comparing ActiveRecord's: Model.find_by(name: name) To Ecto's: Repo.one(from t in App.Model, where: t.name == ^name, limit: 1) This side by side comparison makes Ecto look quite a bit more verbose than it needs to be. You should instead change it to: Repo.get_by(App.Model, name: name) So it's more directly equivalent
I also much prefer composing queries. I never used `from t in ...` as it feels clunky.
Is git deploys and compiling on the prod server a common approach? I've always used a dedicated build server (Jenkins, Buildkite, etc) to produce a tarball / docker image that can be deployed to multiple servers.
I'm speaking anecdotally, but I was surprised at how long it took me to find out about `pg2` when I was learning elixir. It wasn't until I got curious about the phoenix channels implementation that I discovered it. From memory, I don't think there's any mention of it in either Programming Elixir, Elixir in Action, or The Little Elixir and OTP Handbook. And considering elixir is hyped for distributed programming, I figured it would show up at some point.
on top of my mind I would tell `Ecto.Changeset` When dealing with data and data transformation validation is a key component and usually you end up writing custom code. With `Ecto` you can use the same validations used for schemas, without having a schema data = %{} types = %{first_name: :string, last_name: :string, email: :string} changeset = {data, types} |&gt; Ecto.Changeset.cast(%{}, Map.keys(types)) |&gt; validate_required([:first_name]) iex(12)&gt; changeset.errors [first_name: {"can't be blank", [validation: :required]}] 
that's what I've historically done as well. I see this as a really nice side project solution. 
Why not implement *Item.my_predicate* like so (here renamed to *filter* for clarity): defmodule Item do def filter(query, filter) do # You can have as many arguments as you want, as long as query is the first one. from i in query, where: ilike(i.name, ^filter) # Your actual predicate code should go here end end You can then use it like so : query = Item |&gt; Item.filter("elixir%") Repo.all(query) You can even compose everything (assume the functions exist) : query = Item |&gt; Item.filter("some item") |&gt; Item.sort_by_creation_date() |&gt; Item.exclude_soft_deleted() Drew Olson has [a good article](https://blog.drewolson.org/composable-queries-ecto/) about query composition in ecto : 
because in my case there's no "name ilike"
I hacked this up to learn Elixir + Bitcoin - it's a proof-of-concept and has some limitations preventing it from becoming viable in a production context, namely the cost of determining transaction input addresses when you've got to request them from the bitcoin daemon over RPC, and there are &gt;1500 transactions per block, each potentially having several inputs (plus a constant stream of new transactions). One fun part was translating the standard script parsing stuff from C++ to Elixir: C++ version: https://github.com/bitcoin/bitcoin/blob/master/src/script/standard.cpp My translation: https://github.com/sweetmandm/coin_notifications/blob/master/coinpusher/lib/primitives/script/standard.ex
You can SSH in every Erlang/elixir project. The VM has an ssh-server 
from https://elixir-lang.org/getting-started/meta/macros.html : "Elixir already provides mechanisms to write your everyday code in a simple and readable fashion by using its data structures and functions. Macros should only be used as a last resort. Remember that explicit is better than implicit. Clear code is better than concise code." As far as I know, Macros exists to make your code more compact because they give you more flexibility than functions. However, the blog says: "So every macro in that code is there because it has to be. What that means is that at least 20-25% of the code in this program is doing things that you can't easily do in any other language." and that's a little... loose. For example, in Rust println is a macro because Rust does not have variable argument functions. In Python print is just a function because Python has variable argument functions. So, macros let you do things that cannot be done easily in YOUR language. So the real question should be if Elixir is more flexible than Lisp, then i guess that Elixir is "weaker".
There's also [lfe](http://lfe.io/) if you really want lisp.
I don't have much experience with macros in either language, but from my understanding; macros in Elixir are Hygienic and compile down into ASTs, just as LISP does. There are definitely differences in the AST structure and probably quite a few in how, but overall I'd say they are about equivalent give or take a reasonable level of whatever strong-ness and weak-ness actually mean. A good deal of ExUnit, Plug, Phoenix, and other major platforms in Elixir require the use of macros, as does Elixir itself in order to accomplish what it does. Even things like "if" are just macros. See more [here](http://theerlangelist.com/article/macros_1).
What is the logic in your predicate then?
Whether learning LISP will make you a better programmer in Elixir, I don't know. I suppose it could, but you're going to be tackling different problems in a different manner with the same kind of typing structure. People gleam inspiration and knowledge in different ways but if you want something that is going to be contributory to Elixir, then LISP is probably not the right choice. Another highly-concurrent CSP language like Go (I haven't tried it) or a much lower-level language like C or Rust would probably help; more just to actually understand those very few edge cases when Elixir/Erlang concurrency deadlocks or races. Another good choice is to move in the opposite direction into something like Haskell, OCaml, or F# to get a better understanding of or control over types and general functional language implementations of things. That stuff trickles into your Elixir code, even though it is dynamically typed, and it makes your code easier to debug, read, and change over time. I do not like the JVM so I can't comment much on Clojure, but I do hear some good things about it.
&gt; And more importantly, will learning common LIPS make someone a better Clojure or a better Elixir programmer? Learning LISP will make you aa better programmer, full stop. It forces you to think about programs differently than Clojure, Scala, or Elixir, because it approaches the problem of programming from a different collection of biases. I don't know what "strength" means in this context, so I couldn't really tell you what's stronger or weaker. LISP is *different*, and that's reason enough to learn it. Then you should also go and learn Prolog, for a radically different approach to programming unlike anything else you've probably done.
I can to Elixir from Clojure and one of the first things I thought while learning was “ha... this is a lisp”. I certainly consider it so because the AST is homoiconic and build with run time data structures. Don’t believe me? Check out the talk about writing a pretty printer at the last ElixirCon it’s quite good! I will say Elixir biggest advantage is not being considered a lisp directly because there’s no baggage about ‘how’ it should look. So in the pursuit of being beginner friendly and productive there’s no aversion to syntactic sugar or library dsl’s —
This is great! I always want to have both a template and function style builder for html in my toolbox.
&gt; Learning LISP will make you aa better programmer, full stop. I don't agree with this. I gave LISP, what I feel is, an honest shot and I didn't really take away anything I didn't already get from Elixir or Haskell.
Elixir is not homoiconic, it's AST can represent many forms that the syntax cannot.
&gt; there’s no aversion to syntactic sugar or library dsl’s — plug being a fantastic example IMHO. This is actually one of the things that completely turned me off from the Ruby ecosystem, people went full retard with macros and crafting DSLs. I like the Elixir way of using macros for default behaviour implementations like `use GenServer`, which I think is quite sensible, but I hope library authors continue to exercise restraint.
Well, here's what LISP does that Elixir and Haskell doesn't: * Sparse syntax: LISP syntax is *extremely* simple, but can express fantastically complex programs. Elixir and Haskell don't demonstrate that level of simplicity * Code-as-data: LISP's syntax is also its primary data structure- everything in LISP is a list (pedantically, s-expression). That's a very different way to think about a program 
To your first point yes, but I don't see that as a pure benefit. In my case I had to pay closer attention to understand code because it just seemed to meld together if I wasn't careful. To your second point, yes but where does the benefit come in? Is it because it gives you a robust macro system? If that's the case, then I concede the usefulness, but I know I'm not alone in hating coming to a new codebase and having my progress slowed down because the macros can obfuscate the code pretty significantly.
TIL about HyperScript. Personally I think Pug or Slim still preferably, but, nice choice of exercise. What did you learn?
It's about thinking about programming differently. It's the same reason I recommend learning Prolog, too. You don't need to master it. You don't need to use it on a daily basis. But getting familiar with languages that have radically different paradigms changes how you program, even when you're not using them.
I don't want to ssh into iex, I want to ssh into the shell outside of elixir/erlang.
&gt; the AST is homoiconic I know, that's why I said. ^
I couldn't agree more. But I think what I'm trying to say is that some pretty powerful abstractions can be gained in certain domains and people have standardized on some of those like plug. I still think the hierarchy should be &gt; data &gt; functions &gt; macros
I'll give you an anecdotal data point. I've been migrating a legacy Rails app running on Heroku over to Elixir, in a few stages. For background, my application has a very seasonal and sporadic traffic pattern—it manages voting for college life organizations, and they all tend to vote at once, at the same time, at the beginning of the semester. I have nearly 1000 groups using it, each of which may have between 75-300 users. Serving that traffic at peak load requires about 25 professional dynos (the 1GB version). stage 1: I just put up a single dyno, hobby level, running an elixir app with very few responsibilities—basically every user logged in opens up a websocket to the Elixir app and sends it a copy of a couple requests that are also sent to the Rails app. I wanted to see how it would handle the number of connections we get. The requests in question are the most common ones (voting), which are probably 90% of all requests. 1 dyno handled every concurrent user without breaking a sweat—indeed, it never went above the halfway mark on memory, which should not be surprising since it basically was doing nothing, just a quick write to the database (in a parallel table to the one I actually report on.) Stage 2: Start pushing actual work through the Elixir dyno. Again, no sweat. It runs on a professional dyno now, and is responsible for many of my reads from the database. Still a single server, still handles traffic from every user, and there is no perceptible difference in response times between the low points where no one is using it and the rush of users logging in to vote. This, I think is a critical point to realize: there is a very smooth curve in latency using BEAM applications for web traffic under extreme load. More on that in a second. Under Rails, even using an autoscaler, handling that kind of traffic pattern (high write load which invalidates caches, followed by reads, caching will only get you so far in handling it, even if you background the requests) there is almost always a few minutes at the beginning of the rush during which the system becomes unresponsive for a significant percentage of my users as the response queues fill up and requests start timing out. This is an incredibly frustrating experience for users. Stage 2.5: As I'm finishing out the conversion, I wanted to do a load test to see just how far I can push the application. So I fired up loader.io and gave it a realistic request script that does a big read, fires off a few writes, the re-requests the original read (which is now invalidated from the writes). This is the most common driver of load in the current system. Using a single professional heroku dyno (512 MB, extra RAM would not have been useful, though using the dedicated dynos might have improved numbers somewhat) I was able to peak my load on the Elixir app at 3x that of what the Rails app does during the height of my season (again, that requires 25-30 dynos to handle). This was backed entirely by reads and writes from the database, no optimization using the tools you get for free in Elixir like OTP (e.g., one optimization I've made since does the statistical calculations in a GenServer and keeps that in a process so any subsequent reads don't need to hit the database, which has taken tens of milliseconds off the request time.) Stage 3: Next season (spring) will be the first to use Elixir exclusively on the backend. I've got no qualms about it at this point, on a performance basis it blows the doors off Rails for my use case. Note that performance is only one metric you should evaluate. Another is how well does this platform support sane development patterns? Does it lead you towards usage patterns that are unwise? Probably obvious, but I believe Elixir wins on this front as well. Do you think you'll be able to be quickly productive under pressure? This is the one metric that you may not be comfortable with for awhile—there is a period of relearning patterns for writing software any time you change platforms. There will be a transition period and it will frustrate you at times. But once you get over the hump its well worth it. My advice would be to take baby steps—write apps the same way you would in Rails (e.g. do your work in the controller or in "model methods", i.e. functions in your schema module.) While you're doing that you can learn about the native BEAM concepts like OTP you're not familiar with now. Then you can rewrite/refactor functionality into something better. Alternatively, do your learning on a project you don't care much about. However, I've never gotten much mileage that way—I almost always need to be working on something that I do daily and its too easy to put hobby projects aside. Hope that's helpful info!
You have to work pretty hard to create something on BEAM that will handle load in the way you describe. Even a naive approach to writing an app in which single requests take forever to fulfill will still handle traffic spikes sanely. The main way I've found to kill performance there is to have too small a database connection pool or do distributed calls poorly (e.g. transfer large payloads over dist). But even with that your requests will still get a response. A sudden flux of traffic in something like Rails is going to result in lots of requests that are just dropped on the floor.
I also prefer a templating language for general templating, but for more dynamic things like generating a navigation from a tree I prefer a more programmatic approach, where something like this shines. This was a great exercise on pattern matching (especially the abbreviation parser*). In my first iteration it was full of conditionals (I don't have a functional background), but it felt great to slowly refactor it all to functions with multiple clauses. (*) https://github.com/sebastiandedeyne/hyper_ex/blob/7800112103f2f5b796bc8ef4611eb48375f19ea2/lib/hyper_ex/abbreviation.ex 
&gt; I know, that's why I said. ^ Hmm? I put `is not` however. Elixir's AST represents anything that Erlang can represent, however there are things that Erlang can represent that Elixir cannot. In many cases you can work around it by `unquote`ing the invalid part in-like in the syntax, and I guess that could be considered making it homoiconic, but the syntax 'itself' is not. ^.^;
Thank you for sharing. I'm currently building an Elixir web framework. I'm taking more a react.js like approach to create html. e = &amp;create_element/3 e.(:body, [], e.(:div, [class: "wrapper"], e.(Logo, [], nil))) I'm hoping to automatically be able to generate the HTML and JavaScript for react.js.
What is known about plans of Phoenix migrating to it?
some custom logic
It should come to Phoenix once it lands in plug https://github.com/elixir-plug/plug/issues/599
You will have to expand on that a bit for folks to be able to help.
Just an idea: start the remote node via a shell command in the test `setup` block, then connect to it using `Node.connect`, and then finally kill the remote process using an `on_exit` handler.
When I kick off the test, is it the same node thats running the setup block though? I need two nodes. The test will work if I have a node laying around for it to connect to, but I need things to work in an isolated, CI environment. I may have to change some architecture.
That's what I was trying to get at… use `System.cmd/3` to fire up an additional node process (OS process).
I see what you are saying now! Ill give that a shot thanks!
You can use the same approach [ex_nsq](https://github.com/lambdafn/ex_nsq) uses for [running the test on multiple nsq nodes](https://github.com/lambdafn/ex_nsq#running-the-tests) You create a [`Procifle`](https://github.com/lambdafn/ex_nsq/blob/master/Procfile) with all the commands and then run it before running `mix test` 
This is a good approach too, thank you!
Nice reply, thank you!
http://erlang.org/doc/man/slave.html#start-1
Elixir's metaprogramming capabilities lend itself to a far better DSL than this. Other projects have already done stuff like this, take this project for example: https://github.com/smpallen99/xain
I'm aiming for a html-elixir language that transpiles to elixir, similar to [jsx](https://facebook.github.io/jsx/). In the end you will end up writing: def render do &lt;body&gt; &lt;div&gt;&lt;/div&gt; &lt;/body&gt; end and the elixir code will be generated. Because of this I don't care much about the intermediate format.
In almost all cases ActiveRecords seems to be easier and more intuitive to use
I think what a Lisp is can be, is better simply demonstrated by Racket and Matthew Butterick's 'Beautiful Racket'. https://beautifulracket.com/
A friend wanted me to build him an Android app, but I convinced him that a web site would serve his needs. Now just to nail down the requirements. (I've been avoiding Java and the mess that is mobile development for a while.) 
The [ExSpirit](https://github.com/OvermindDL1/ex_spirit) parsing library. Compile times can be somewhat slow, but it's very fast at runtime. It is the Elixir parsing library with the most features. It has all the PEG-style operators you would expect (alternative, sequence, lookahead, lookahead_not, etc) and a state system that makes it able to parse context-sensitive languages like XML or python without any lexer-based tricks. Documentation is still a little bit rough, though.
Hm... This whole Kata thing is cool, and might be useful to create familiarity, but the fact that this can be regarded as an exercise probably hints towards the need for a good solution for user authentication and authorization in Phoenix apps that "just works" most of the time and can be customized the rest of the time.
I'm working on an AWS library. The available ones don't do what I need them to do so I've built my own that mixes all of their best characteristics: https://github.com/wrren/baiji.ex 
This is a deadlock (not so much a race condition). I'm also impressed when Erlang detects this kind of deadlock and quits instead of just hanging.
At the risk of quoting Joe Armstrong, that's badass.
Cool! Love the extensibility of mix, definitely putting this in my vim config
Thank you so much for this! This was exactly what I was looking for. I tried the other suggestions mentioned, but a slave node was perfect. Thanks a ton dude!
Actually there is something better that you can do. Setup `equalprg` and/or `formatprg` and use `gg=G` and/or `gggqG` respectively. 
Except, of course, for what it is and what it does _to_ the files you specify.
&gt; The Core Team really has thought of everything. "Everything" being exactly what every other linter &amp; automatic-formatter does.
Is there a planned release date?
You can read this great article by Saša Jurić about wether you should spawn a new erlang process (in the form of a GenServer or not) or wether you should not: http://theerlangelist.com/article/spawn_or_not
I love this kind of self explanatory keywords
Things I’ve used them for in my Phoenix apps are things background tasks, scheduled jobs, caches. 
Great article summarizing my scattered thoughts!
GenServers are an implmentation of code-with-state, which also includes a standardized pattern for robut message passing. So when you need to communicate repeatedly over time with a consistent state, a GenServer is one of the go-to abstractions. It makes it easy to take asyncronous actions, provide a syncronization point for data between separate processes, have long-running background tasks, manage worker pools, etc. When you use Phoenix, you are already using a ton of GenServers .. you just don't notice it so much because they are part of the core of the system, and Phoenix (.. and Ecto, and ...) provides ways to easily extend / add functionality to them via plugs, channels, controllers, etc. So even if you never use them directly, your Elixir applications are almost always powered by them. That said, the use cases for code-with-state-and-a-message-based-API is very, very common. There's already a comment here about background tasks, and that is one of many.
First off, the macros in Elixir are the "real deal". Code that takes an AST and returns a new AST. Second of all, ["por que no los dos?"](http://lfe.io/) :)
You are already using genserver. You’ll use it for two reasons: 0. Process Isolation. It keeps the called process context separate from the calling context by passing messages rather than calling functions directly. 1. Process isolation. Genservers are supervision children so if you want to supervise some processes which aren’t supervisors then they will be Genservers. This combines with 0 to set the blast radius when it all goes bad. Each time your Phoenix app gets a request, a process — a genserver, is started and that request is processed as a single thread of execution start to finish. If your app throws an exception during that execution the process dies and life goes on. The Genserver process is a rip-stop for failure recovery. Phoenix does most of this and makes most of those decisions for you by isolating requests from each other. If you need further isolation or parallelism then that’s where you would start your own genservers/supervisors. 
For anyone interested in swagger 3.0, there's a new package available: [open_api_spex](https://github.com/mbuhot/open_api_spex/) Contributors welcome!
I've been doing one of those toy problem sites. I've been going back to fundamentals and taking time to write docs, doc tests, and specs for every function. I've learned a lot as well from seeing other's solutions. It's easier for me to digest their logic when it's a trivial problem.
I've been looking for any established idioms for Elixir. Using pattern matching functions over case sounds like it could be one of them. Do you know if there is a list of idioms or rules like this? As an aside, if I do the pattern matching multiple functions route, should I define spec for each one or just the first of that name/arity?
Noooo! I have a project idea that's similar to this. Really want to browse the source, but really _don't_ want to at the same time.
I'm certainly looking forward to trying this. Macros are great but an approach of just functions, everything explicit, sounds solid too
Haha save yourself the effort and copy the struct definitions and dialyzer types for all the swagger objects at least! It was a real grind transcribing the spec into Elixir code 😄
Do the background jobs survive restarts?
You have to build them in a way in which they can - eg persisting their state somewhere. 
Where did you persist them?
I would be interested in seeing the source code for this. Will you share it?
It isn't open source, but it is possible that I will extract something further on. There is a cool custom designed CRDT keeping the notes in sync for example.
I basically wondered if you implemented OT
OT (Operational Transform) used to be the way to do collaborative editing, but CRDTs (Conflict-free Replicated Data Types) seems to get more common. The main benefit is that you don't need a central server transforming operations. As CRDTs are eventual consistent it is enough that all messages reach all clients (even if out-of-order). I hope to utilize this fact by adding support for off-line use further on.
I like it. One thing while testing it out was when I create a new note it makes a new one marked as Untilted and I still have to click to start typing. I know i'm being picky but I'd like to click new note and start typing the title right away.
Totally! The current behavior is temporary until I get the proper code in place. Have to do some refactoring first. I want RexPad to be really streamlined and feedback like this is very helpful!
Should put this on https://news.ycombinator.com as Show HN. If it makes the front page you will get tons of feedback and servers will get tested with load.
Will do! I just want a soft start with the beta test. That is why I am posting in this friendly community. Aiming for a bigger splash in a week or two (or three).
Which CRDT did you end up using? And do you have any plans on open sourcing that? :-)
I'm not sure if this is included, but having some way to render mathematical equations would be nice. Something like https://github.com/goessner/markdown-it-texmath could be useful.
Not OP, but DETS or Mnesia are possibilities for out of the box erlang solutions.
Looks awesome, tested out the real time collaboration and it was very smooth, nice work. I think how you made the shareable links not require a sign up to view is great. On the homepage, in the Work together section did you mean to say subset of notes with friends and colleagues? Right now it says colleges. Also in the simple yet versatile section, "easy to use and don't get in your way" sounded a little off to me, should it be won't or does not?
I wrote a Dashboard Application for the Logistics Industry to handle the needs of Phone and Freight Broker/Dispatchers.
Looks really cool. It took me a little while to complete the "challenge" of converting the bullet point to a task. I kept clicking the hamburger menu at the top right of the note instead of the pencil button (then the pencil button would go away because it would deselect my text). You might want to reword the challenge and give it a step by step or something. I did eventually figure it out, but it took me too long and I felt like an idiot when I did figure it out. Cool name, btw ;)
This looks really nice! Personally, I'd like to see an demo of the editor before signup. These apps are a dime a dozen, but the experience here is the differentiator, and you should showcase that as early as possible.
No, that's possible for now, and it is not likely to be in the near future. I have looked a bit into it and it would certainly be possible so if there is significant demand I will add it later on.
I have a custom made CRDT. It is a tree with tombstones recording the full history of the notes including who wrote what, when. I have no immediate plans to open source it, perhaps later on when the code has stabilized.
Thanks a lot! I will update the texts on the homepage.
Thanks. I certainly want to remove any stumble blocks on the "challenge". In this case, I should change the menu to not remove the note focus. I could also mention the pencil button in the text. Long term I will do away with the pencil menu altogether and replace it with something more natural. Cool name indeed! :) 
Yeah it's a real shame. There are a lot of great languages out there. Quite a few are faster than elixir. Many can also do well with concurrent workloads and distribution. But Elixir has so many nice things in one package: + Fantastic tooling + Great macros + OTP! + Code that is easy to reason about So much more to that. OTP itself deserves a long list. The total package is what makes the language great and difficult to compete with. Too often people see the surface and go head on without taking the time to learn how to really take advantage of these things. I know I was that way.
The plan is to have a "try it" link next to the signup button that will get you a full account with saved content. As you only will be logged in the current browser session, you will then be prompted to provide an email and password to save the account. Thanks for the good feedback!
I mean.. this is a few links from this very subreddit, all of which can be found in /r/elixir/top/?t=month.. I know elixir is all about recursion and stuff, but maybe this is bordering on redundant?
Im on android chrome. I created new note, but when trying to hit any button on the keyboard, its as if I hit the back button. Goes out of the form focus and keyboard slide out. The symbols can be typed though. Only happened when I try for alphabets and numbers
I'm a huge vim fan, and love its easy mnemonics: `gg=G` -- "go, go, equal guise" `gggqG` -- "Go go great quoting GHOST" 
You should x-post to /r/elm
Yes. In /r/elm I did instead comment on "What are you working on this week": https://www.reddit.com/r/elm/comments/72cm1r/what_are_you_working_on_this_week_week_of_20170925/dnhuime/
**Here's a sneak peek of /r/elm using the [top posts](https://np.reddit.com/r/elm/top/?sort=top&amp;t=year) of the year!** \#1: [Meet Ellie](https://www.humblespark.com/ellie-announcement/) | [13 comments](https://np.reddit.com/r/elm/comments/5ta0x0/meet_ellie/) \#2: [Tour of a 4,000 LoC Open-Source Elm SPA](https://dev.to/rtfeldman/tour-of-an-open-source-elm-spa) | [23 comments](https://np.reddit.com/r/elm/comments/69wrfq/tour_of_a_4000_loc_opensource_elm_spa/) \#3: [Elm Roadmap FAQ](https://github.com/elm-lang/projects/blob/master/roadmap.md) | [6 comments](https://np.reddit.com/r/elm/comments/68pngi/elm_roadmap_faq/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
Thanks. I have to look into that. There is a similar unresolved issue on iOS where the keyboard doesn't automatically change between caps and plain letters. 
Gonna be part of 1.6 iirc
This looks really good! Seems like the frotnend is all elm ? If so would you mind describing the approach you used to manage content editable ? 
oh, or are you using js for that ? 
No, it is mostly Elm with some JS for things that Elm still can't do. Working with content editable is no picknick and its API is huge and inconsistent. I basically follow the ideas described in the Trix readme (https://github.com/basecamp/trix), to treat content editable as an IO device. The trick is to find the right balance, what to do yourself, and what you leave to the browser, to avoid as many edge cases as possible.
Nothing amazing, just an over engineered automated script for transforming a directory of .md files into PDF. [Here it is for fun](https://github.com/mattdharmon/convert-md)
I"m just getting started w/ Elixir. I'm continuing to refine my first library, Pulsar. https://github.com/walmartlabs/pulsar Pulsar is for CLI programs, it presents a in-place updating, textual dashboard that processes can write updates into asynchronously.
I'm providing Rails example, but it applies to any technology, Phoenix too
Did you decide to learn Elixir?
In your final note it might be worth explaining that GET/HEAD requests don't require CSRF prevention because CSRF attacks are blind and rely on useful side effects. GET/HEAD requests should never mutate application state, so CSRF prevention on them is pointless unless you are using Http verbs incorrectly.
Actually I decided to learn more popular languages, such as Javascript and PHP due to its ubiquity. I know Elixir is probably a better language to start off with, but if I need to hire programmers I realized I will pay top dollar, if I can even find one! But it seems like something I will learn in the future, as everyone has good things to say about it.
Sometimes it is, sometimes it isn't. It can happen that the month is a bit dry with the new exciting Elixir news and then it bubbles up to reddit as well.
&gt; unless you are using Http verbs incorrectly Unfortunately a lot of ill designed frameworks and languages encourage being able to take parameters as either a post or a get, and sometimes they do so without the developer being aware :-/ 
I really dislike when sites block the plaintext content of the page because I don't allow their site to run scripts. In this example it's a blank white page with a header and that's it. I could look at the page source to see the content, but that's more work than it's worth.
This is great man! Funny enough I'm doing something similar but this will help a lot to check me in the right direction! 
Thank you for this contribution. Couple quick points of constructive criticism: - Not seeing any Elixir here. Not a biggie. - Also I notice there isn't any Angular JS code. Don't worry, this isn't a deal breaker. - I see you didn't quite get to the CRUD aspect. So basically just keep the above in mind for next time, but keep up the good work.
How does it differ from Phoenix?
Heck, if it's exactly the same as Phoenix but doesn't try and foist Brunch on me as a JS build tool by default, I'm sold! //I've only worked with it for a short time, but I really hate Brunch. It's like if Wes Anderson made a JS build tool.
Just swap it out. Changing from brunch to webpack (or any other build tool) can be accomplished by changing one line in your config file. 
`mix phoenix.new Wat --no-brunch`
I know you can change it, I just hate it. 
&gt; It's like if Wes Anderson made a JS build tool. That's so funny! :D
True. It's just so weird, instead of the sort of defensive "you can easily opt out!" why not just switch to what everyone is using? I get JS fatigue, but this smacks of stubbornness.
It certainly will not try to `foist Brunch` on anyone. As much as is sensible I want it to be a collection of well defined build blocks that work very well on their own, it's probably still a framework but only just.
Just ordered a copy of Programming Phoenix on Amazon.
Seems like it's supposed to be closer to Plug.
What is everyone using? Webpack seems to be the most popular but having used it at work, I despise it just as much as Brunch. Chris and the rest of the team (and plenty of other people using Phoenix) seem to be happy using Brunch.
Yet every time the discussion of switching to webpack comes a lot of people say webpack is a hard to use mess. If Phoenix used webpack I bet we would have a similar thread "hating" on webpack instead.
Brunch could have better documentation but I still prefer it over webpack. Still on the lookout for something better. 
I mean, WebPack is atrocious and painfully complicated, but Brunch's documentation isn't merely *bad*, it's *insulting*.
Correct. IMO the default should be “nothing” otherwise known as “put things in priv/static however the hell you want”. 
I am 100% sure that will also generate complaints.
There is a equivalent interface layer called Raxx that is quite usable on it's own. useful for people who like the minimalism or making simple API's 
Sure, but no offense Plug is minimalist and simple and fits nicely in the elixir programming paradigm while Raxx is closer to ruby style, which I personally abhor and honestly consider it to be an anti-pattern.
This. I don't understand why developers whine about default that are easily swapped. No matter what the Phoenix team chooses, people will complain. Yet instead of taking 5 mins to switch build tools (or write a script to do it for them) developers create[1] and switch to new libraries. Why? [1] Not the case with Tokumei, but I've seen it in other ecosystems
Correct!
Neat! I saw the bit about custom compilers but can markdown be the blog post format instead of json?
Yeah absolutely. In fact only the front matter of the post (post metadata) is in JSON format, the other parts (post excerpt and body) are in markdown.
Fair enough. I thought plug was simple until I had to use it and started reading through the source code. Admittedly I had some unusual use cases, such as signed HTTP messages and streaming to the server. Raxx is absolutely based on Ruby's rack, even down to the name. I think that pure callbacks are nice, and somewhat reminiscent of how you define a GenServer. however I would certainly say stay with plug if its working for you 
I actually started learning Elixir a couple of weeks ago. I have very little knowledge in programming apart from quick tutorials I followed in Python and Javascript. I really love Elixir so far. I think the syntax is great, and it somehow it seems to make a lot of sense to me. I struggled a little to understand pattern matching and things like the use of the pipe operator, but now I think it's fantastic. 
This is just a link to Stephen Grider's Elixir and Phoenix Bootcamp course on Udemy reposted by a spammer.
The main difference is that there is no model layer or assumption of a model layer. It uses Raxx instead of a Plug which allows web applications to be defined using only pure functions. It also works to lead users to adopt best practises when it comes to cloud native applications. This last point is definitely a work in progress but still a start
Say I wanted to create a simple webapp backed by an sql-server that allows users to register/login. I should rely solely on HTTPS. Is this easily done in Tokumei?
too much comments
HTTPS is supported and using that will allow you to use HTTP/2.0. There is no assumption made about your model layer or content, so there is no consideration for localization or talking to a DB. Adding Ecto and gettext should not be hard as tokumei will set up a standard mix project with the web components well isolated. The rest is up to you
I rather have too much than too little.
I know of [`scaper`](https://github.com/Anonyfox/elixir-scrape).
The random cookie generation is really inefficient. Using a reference via `make_ref/0` is the best solution, and generating random bytes from the `:random.uniform/1` might be a better solution as well.
NIF's can be safe but still be problematic for the BEAM schedulers if they take too long to execute. OTP 20 has dirty schedulers enabled so it's less of a concern, prior releases requires compiling BEAM with support enabled.
How is this different from http://erlang.org/doc/man/rpc.html ?
You could describe/implement/abstract your entities as processes. A user or customer could be a gen server composed of other child processes. An order that the customer places could be a gen server or gen statem (depends on the business logic). So now you have two entities that are connected by a relationship (a customer places an order). Order get's processed and sends status messages to the customer.
I'd rather the comments stay in the @doc It makes code harder to read otherwise, especially if they're obvious
Seems to me you are trying to reimplement GenServer's handle_call functionnality.
You could try the [job board](http://plataformatec.com.br/elixir-radar/jobs) to find more potential hires. Some criticism since you didn't ask for them: - The requirements do not scream long term project for someone to take the contract, since it only builds out a feature single feature of the site. - With the above, not offering a range of payment for building out a single feature sets off warning bells to me as well.
Awesome. Thanks, this is exactly what I'm looking for!
Thanks for the input. This specific contract is not long term, but we also never claimed it was. If anyone looking at it is looking for a long term contract, this is not for them and they should be able to tell that from the listing. However, as I mention in this post and in the job posting, this contract may lead to a full time position. As for the range of payment, some parts of what we are asking for are already done. We didn't want to give some number of hours that it should take and have people think that we are crazy for such a low number. We thought it would be better if we sat down with the candidates, explain exactly what still needs to be done and come to a mutual agreement on how long it should take and at what price point. There will most likely also be a some miscellaneous tasks that we get the person to complete as well (as mentioned in the listing). The feature listed is just the important part of the contract. 
[Meeseeks](https://github.com/mischov/meeseeks), a library for parsing and extracting data from HTML and XML with CSS or XPath selectors. [Pearly](https://github.com/mischov/pearly), a library for syntax highlighting using Sublime Text syntax definitions.
Rustler provides some tools to do work outside of the BEAM and call back in when the work is complete, providing a solution for that execution time issue without any need for dirty schedulers. Here's an example from html5ever_elixir: https://github.com/hansihe/html5ever_elixir/blob/master/native/html5ever_nif/src/lib.rs#L110-L165
Can you explain what is going on at a high level? I'm not familiar enough with rust to be able to understand.
Rust starts up a threadpool and, when parse_async is called, moves the work of parsing HTML with html5ever to that threadpool. When the parsing is complete (or an error happens), an appropriate message is sent to the Erlang process that called parse_async. In Elixir-land that just looks like: https://github.com/hansihe/html5ever_elixir/blob/master/lib/html5ever.ex#L20-L28
This is really cool! Long term, would you like pulsar to become comparable to something like [blessed](https://github.com/chjj/blessed), or will its scope be more focused?
No, my initial inspiration came from `docker` and the way it showed parallel progress of multiple download/extract operations. Jumping into ncurses means clearing the screen, which I want to avoid. I think an Elixir port/reimplementation of blessed would be blessed though.
They are building their own core banking system from scratch in Elixir? That is awesome. A medium sized local bank in NZ, has been stiffed for USD80mln and climbing to do that in SAP. 
Their previous post, [why Elixir?](https://blog.trustbk.com/why-elixir-546427542c) describes some of the reasons behind that decision.
If it's going to be anywhere near as good as elm-format I'm sold. Honestly, going back to writing Ruby/Elixir was hard for a week after I found that. Is anyone planning on creating an Atom plugin for this? 
Just tried this out, the incremental dialyzer is a game changer. 
Well, it may be when they finish their webpage...
Well… we'll never *finish* the webpage. That's certainly not our strong suit. In any case, at this time we're looking for sponsors. Once we have enough prizes to give, we'll announce the date for the contest, find a jury, publish the rules and open registration for the game. These are the very first steps, but the contest is **definitely going to happen**. There is no doubt about that.
This is some great stuff! Definitely going to check this out as soon as 1.6 lands.
None of the burger menu links work for me, iOS, official reddit client embedded browser. 
It would be good to have a link to a mailing-list or some way to get updates
Fixed :) - still ugly, but now it works.
[https://spawnfest.github.io/#contact](*Fixed*) with links to social media. Still super-ugly, but it's something ;)
Hey! Let me start by saying that the way you've analysed and layed out the problem is great. It really helped me follow your reasoning and thought process. If you allow me to suggest a couple of things that could improve your design a bit (I will expand each one of them afterwards): * supervise the activity buckets using a supervisor * simplify the activity registry API by simply returning the bucket pid * register your buckets through a `via` tuple, using your current process registry library (syn) **Supervising the buckets** The most important entity here is the bucket. It contains activity information for a specific category i.e. users, rooms and posts and **synchronizes access over this data**. At the moment, the activity registry plays the role of the bucket supervisor (each bucket is started through the registry, using the ActivityBucket start_link function). This works just fine, however there is a small catch when doing this. Because you have started the agent using the start_link function, the agent process is linked to the registry. If the agent happens to crash, it will take the registry with it. There are different ways to solve this. You can make the ActityRegistry process trap exits from any linked process using: Process.flag(:trap_exit, true) Incidentally this is how the Supervisor behaviour works. However, I would recommend you to follow another approach. Leveraging OTP best pratices, you can have a process with the Supervisor behaviour overseeing the bucket processes. One of the advantages of this setup is that it now allows you control the restart strategy of your buckets when they crash. It also opens up your design for fault tolerance, allowing you to organise this supervisor in different supervision chains, as you see fit. **Simplifying the ActivityRegistry API** The registry process is currently doing two things: * bucket lookup/creation * updating a bucket with a given activity One of the advantages of erlang/elixir processes is that your operations are synchronized inside the process, as it only handles one message at a time. This really simplifies concurrent data access. You definitely want this guarantee, especially when you lookup/create a name to bucket mapping. And if you look carefully at the second statement, doesn't the ActivityBucket already provide this guarantee? So, you do not need to go through two message queues to guarantee synchronization, as dealing with the bucket process should suffice. Also, this makes the API of the registry simpler, as it will focus on only one thing. Here's an example of how you could update an activity in a bucket: bucket_pid = ActivityRegistry.lookup_room_bucket(name) updated_activity = ActivityBucket.increment_room_bucket_activity(bucket_pid, activity) # do something with updated activity... Or using the pipeline operator: updated_activity = name |&gt; ActivityRegistry.lookup_room_bucket |&gt; ActivityBucket.increment_room_bucket_activity(activity) **Using a via-tuple to register the bucket process** I do not have a lot of experience with global registries, so there must be some challenges around scaling the solution I am going to suggest. Hopefully, someone with more experience can chime in! The advantage of registering the bucket in the cluster, rather than the registry, is that you'll no longer need to have a single registry process in the entire cluster. The ActivityRegistry process will receive a lot of messages (e.g. from the http handlers when they need to retrieve a bucket to update the activity). Having only one single ActivityRegistry process in the cluster really reduces your throughput. But like all performance optimizations, you should definitelly measure this. The book, Elixir in Action, has a very similar example to this (except it is with todo lists, instead of buckets). Here is the code: https://github.com/sasa1977/elixir-in-action/tree/master/code_samples/ch12/todo_distributed/lib/todo I also recommend reading Chapter 12, as the author goes very deep into how should you design something like this (including the trade-offs between different solutions. --------------- A process looks very similar to an object instance. So coming to from an OO application modeling background, it is very easy to use/think of processes as if they are objects. It is important to not forget that *processes synchronize data access*. Saša Jurić expands this statement on his blog post: http://theerlangelist.com/article/spawn_or_not I believe (and please correct me if I am wrong), by reading through the code, that your approach resembles the OO model for this problem: The activity registry is the class instance you expose to your clients, and the bucket instances are kept inside the registry. Just a curious observation! I hope some of these suggestions make sense. I will definitely read through the rest of your codebase!
 cookie = Enum.random(0..(1024 * 1024 * 1024 * 1024)) If you jsut want a random number here, use the erlang function http://erlang.org/doc/man/rand.html#uniform-1 :rand.uniform(upper_limit)
This is amazing. Thank you for taking the time to understand the code and give that feedback. I was about to request a design review at elixirforum basically for the reason of getting this kind of info. At first glance I wouldn't discard any advice there, and good reading materials so after I try some of these changes out let me update you and give my thoughts. You've probably accelerated my otp career This project has been my platform for learning elixir and getting back into functional programming after 10 years away from prolog. Therefore you'll see various stages of code quality but I'll take whatever you got for feedback
Also, The Stephen Grider Phoenix course is a disaster. Most of his courses I'd say are great, but the Elixir one is a nightmare. Stay far far away from that.
I'm curious, is it actually really inefficient? While I haven't looked at how ranges implement the enum protocol, I'd assume it should be able to handle these types of operations in constant time? Obviously it's still going to be slower than the alternatives (due to some additional operations), it wouldn't be as slow as you're making it sound though. 
No worries. You should still try to get some more feedback in the elixir forum. There's plenty of guys there that will be able to help. If you want, I can review on the pull request directly. Or carry on in the elixirforum :)
It might be made faster in Elixir 1.6 (https://github.com/elixir-lang/elixir/issues/6955) but if you look at how the Enumerable protocol works currently, Enum.random has to use the reduce callback every time to peek into the range.
This is great. I'm really new to Elixir, and this is exactly the kind of thing I'm looking for.
Ah that's good know. Didn't realise so few enumerable operations could actually take advantage of a range (or any alternative kind of data structure for that matter). Cool to see it being changed though. 
yeah absolutely that community seems pretty great. I'll post there and include PR. Probly a few days and I'll get to it all
Where is it? Seems like that'd be important information if you're trying to attract sponsors...
It’s all online. There will not be any physical location 
Clarified it on the website and sponsorship form. Thank you very much, /u/mgwidmann
Hi everybody, I wrote this blogpost after playing with Phoenix for a few weeks. I am still relatively new to Elixir/Phoenix but had a great at ElixirConf and am now trying to contribute to the community. Cheers
So it's online then? No physical venue? 
What do you have in mind? We're 100% open to suggestions.
I'd suggest putting it below the date
We added the rules of the contest. Check them out here: https://spawnfest.github.io/rules
How was it integrating channels with Elm? I've toyed around with Elm quite a bit but never done any realtime/socket based stuff with it before. Did you have to use a port to the JS channel client implementation? Or were you able to do it directly in Elm? Was there any issues fitting it in with TEA? 
Sweet. I liked it. Small typo here: "Let’s extend hour test file by adding..."
I use the default channel js that comes with Phoenix and then communicate over ports. Works fine. Since I did that part of the app, there has emerged a few Elm alternatives, but I have not evaluated them. In the long run, I will try to move as many things as possible to Elm. Have a look at https://www.youtube.com/watch?v=P3pL85n9_5s to get some best practices on ports.
I had a pretty terrible experience on their free tier and was charged when I shouldn’t have been.. That said, I’m sure they’re decent, particularly if you’re fluent in Mandarin 🙃
Yeah, I can see that. I've been charged by AWS for random shit too. I guess it's being careful of which products to add. 
Yeah it was my fault for not reading the fine print, but I was disappointed with their customer service the most, but I don’t think I’m the target market, and I don’t speak Mandarin so 🤷‍♂️
Got these changes in and added a few extra touches. Big enough overhaul that it's easier to view new code rather than a diff. Here's the post on the new design https://elixirforum.com/t/code-review-request-genserver-stuff-for-site-activity/9568 cheers!
[typespecs](https://elixir-lang.org/getting-started/typespecs-and-behaviours.html) are also great for documentation. 
Finally have my first personal production Elixir / Phoenix / React app in the hands of beta users! If you work with clients, check it out at [getdrum.com](www.getdrum.com)!
I've been working on a native elixir z-wave library for a while now, finally getting to a stage where I think it might be useful!
[open_api_spex](https://github.com/mbuhot/open_api_spex/) for defining swagger 3.0 API contracts, cast &amp; validate params, swagger-ui and test helpers. Needs some work to handle polymorphic schemas, but already quite usable for typical crud APIs.
ooking at the source code the enviromental variables you need to set are HTTP_PROXY and HTTPS_PROXY https://github.com/elixir-lang/elixir/blob/e95f564b7448ffdcfaf5124d74698232c3d02a0e/lib/mix/lib/mix/utils.ex#L597 eg. HTTP_PROXY=http://myproxy.com:8000 mix deps.get 
Elixir/Erlang is technically general purpose, but you really don't want to be using it for things like writing command line tools. I would need more clarification as far as what you mean by rest API with strict timing requirements. If you mean guaranteed response time, then no. BEAM is built around soft real time. But you get that out of the box. The strength of BEAM is concurrency and distribution, and its weakness is CPU intensive tasks. 
&gt;Would you write a command line tool in it? I have, but it wasn't as intuitive as other language (the CLI part. The rest of the code 👍) &gt;Would you write a rest API with strict timing requirements in it? This would be a much better fit
Make sure to check out Clojure if it's functional programming you primarily want. It's LISP-based so it's a lot more different, syntactically, but it runs on the jvm which would be a more familiar environment to you
As unpopular an opinion as this is, I think learning JS is a much better bet. It fits both your examples (maybe not so strict on the timing front, though) and is extremely desired in the industry right now while Elixir or even some of the other languages being suggested are just not. I think you'll be hard pressed to find work if your primary language is Elixir, but I've never tried. 
Well, at least where I am from (Gothenburg, Sweden) Elixir is picking up momentum pretty quickly. Starting to see local companies requesting Elixir/Phoenix knowledge, especially places that where previously mainly rails-shops. I think learning Elixir/Phoenix actually a higher payoff (but also higher risk) venture. There are lots of js-folks out there with many years of experience, learn Elixir/Phoenix and you will not have as much competition if it takes off.
For command line tools there is a packaging option called escript which makes it very easy to make CLI tools with elixir. 
Learning JS is great if you want to earn the least amount of money and have the most competition for that low paying work. Why would a Java developer make a career move into JS? Elixir is distributed, concurrent and fault tolerant and if that’s what you want to build it is perfect. It’s not a scripting language and it lives within a sandboxed VM so its terrible for writing programs like CLIs. It’s very good at running services and things which run in the background. It is soft-realtime and preemptively scheduled. 
I picked up the book recently and I would say it’s still great. Yes there’s some bits that have changed, but you’ll pick up the changes easily as you move throughout the exercises. I guess it depends when the updated version will ship, though. 
I think it will be out Publisher: Pragmatic Bookshelf; 1 edition (December 25, 2017)
Yes. 
I'm not sure where you have been working, but quality JS developers are in very high demand. The problem is good Javascript devs are few and far between, so companies just hire 10 to make up for it. 
Im waiting 
I already had it and hadn't read it until after the move to 1.3. With that it left me translating exercises to the new syntax instead of focusing on learning the fundamentals, however, I will say that it may be a good thing because I was more engaged and it got me debugging earlier. So, it depends on how dedicated you are. I would wait if you want a more up to date resource. This makes me wish I bought the ebook version with the number of changes that came out. Oh well, I'll probably by the new edition just because it's a great read.
I love Elixir but with OP coming from a Java background I would definitely agree that checking out Clojure would be worthwhile.
Yes, I meant response time strictly below 50ms.
If you're coming from Rails I think Phoenix guide is enough: https://hexdocs.pm/phoenix/overview.html I just went through Programming Elixir and it was enough for me to jump into Phoenix. It's similar enough to Rails so you spend more time "how do I do a thing?" instead of "what do i even do?".
It is good to know many companies are picking up Elixir! Moving from Ruby to Elixir/Phoenix makes perfect sense to me. Not so much from Java.
I did check Clojure before focusing on Elixir. Clojure is great for many things but I did not like the syntax much.
That would depend on what you do with it. My blog renders in less than a millisecond but it has no DB access. DB is the major bottleneck on my sites with Elixir.
Thanks for this. I will check it out.
CL tool, if you need easy concurrency in a CL tool, yes; otherwise no. &lt;50ms is pretty easy. We got that without even trying (and massively fucking up with string copies). You do need to embrace the environment though: writing Java in Elixir will not work well for you.
2 months? I’d probably wait. It’s a good book, but when the new one arrives you’ll probably want it. So I think it’s between buying it once or twice. 
It's great for concurrency, stability, and messaging but it lacks speed and flexibility of heavyweight languages like Java. I'd stick with Java and learn VertX if you need speed. That said elixir is a very fun language and Erlang is amazingly designed for its niche purpose stable concurrent distributed messaging. 
An even more obvious option for him would be Scala. It is heavily functional yet object oriented, runs on the JVM and the syntax is _nearly_ as delightful as Elixir's.
doesn't akka solve the same thing that elixir does?
Akka is a framework for modelling concurrency in code. Elixir has more to offer, especially the BEAMVM.
A heroku add-on for scaling application dynos. Personally use it for scaling sidekiq workers on another production Rails application. Looking for Alpha testers! If anyone is interested PM me.
This.
Akka does something that’s based on some of the same ideas (Actor model, process supervision, etc), but it doesn’t have the preemptive scheduling of the BEAM, so you need to use async calls with callbacks to avoid blocking the underlying threads. This interacts in some really weird ways with the actor model and is one of the reasons I’d recommend Elixir/Erlang over Akka. You also don’t get forced into the message-passing model: you can still share mutable data between Akka processes, which can be a tempting trap for someone new to the Erlang way of thinking. 
I would second the note that if you want to do FP but stay close to the Java ecosystem, Clojure is the best path. I do not like Scala. That being said, Elixir and BEAM have some distinct advantages over JVM for certain tasks. Startup time is lightning fast, so CLI tools make sense (as long as you already have Elixir installed). However, if you jump from OO Java to FP Elixir, you will be taking on a new language, new syntax, AND a completely different way of designing your code AND a completely different ecosystem. I've been playing around with Elixir, building simple toys, and looking for a way to introduce it at work. 
Lisp and Clojure syntax seems alien the first couple of weeks ... then once you are used to it, everything else seems needlessly baroque. The minimal syntax lets you "see through" to the underlying code easier, but you have to embrace it before you can appreciate that.
I think you'll be hard pressed to find free solutions. Having said that, there are a bunch of cloud VPS providers that are pretty cheap. OVH, vultr, digital ocean come to mind.
Java and Elixir/Erlang are good at different things. Java has a raw linear code speed advantage that Elixir will never match. The JVM is really quite good at running your code. Elixir isn't slow (it's faster than Ruby for sure, which [can barely say Hello World in 50ms](https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=json&amp;l=8t4z5r&amp;d=x&amp;f=191c0-jz6rk-4ftog0-4e0w-efew00-1kw0-42sjm), and in no-database cases often ends up with sub- or single-digit-millisecond latencies), but you will always be able to make single-threaded Java to be faster than single-threaded Elixir. Java also has tons of libraries. Seriously, just search Maven Central for whatever you're looking for and you'll probably find multiple libraries to do it for you. Elixir has a decent number of libraries, but not nearly as many. Elixir has two main advantages over Java: 1) The concurrency support is top-notch. The BEAM is fantastic at scheduling many, many processes and having only immutable data and sharing through message prevents entire classes of concurrency bugs. You can make highly-concurrent code work in Java, but the code will be a lot nicer in Elixir. 2) Error handling. It's fairly easy to have a poorly-handled exception cause problems in a much wider area in Java than in Elixir. Elixir's process isolation and supervision-tree model limit the blast radius of failures and allow the overall application to keep running relatively well even in the case of catastrophic failures in a different part of the application. In short, if you're building something that's highly inherently concurrent (e.g. making multiple database or API queries per request) or that absolutely, positively needs to stay running at all times, Elixir is probably your best choice. If you're doing something that relies heavily on single-thread performance (e.g. heavy-duty number crunching), Java is probably the better option.
I've used gigalixir for one of my side projects and it just worked.
Heroku's been a little difficult on us. * For some reason, the [countries](https://hex.pm/packages/countries) package crashed the server pretty hard. * Using them with a separate DB(such as RDS) is a nightmare without a library to do the heavy lifting for you, which I didn't find(but Ruby/Python have). We still use them for our staging/quick test servers, but we plan on moving off once we have a solid need for the additional infra.
&gt; however, I will say that it may be a good thing because I was more engaged and it got me debugging earlier. I was initially quite annoyed that the I had to 'translate' the exercises, but in hindsight I agree with you that as a result I engaged much more with what I was learning. I found the Programming Phoenix book quite good, but I did feel like it glossed/skimmed over a lot of stuff, and often focused on a Rails-like approach instead of a more Elixir/OTP focus. There's nothing wrong with that (it's probably the sensible approach), but it did leave me feeling like I was building on somewhat shaky foundations. Being forced to rewrite the examples really helped out with that. (I can also highly recommend Programming Elixir, by the way)
you can make soft guarantees, but erlang isn't designed for hard real-time. But as the other poster that replied to your comment said, that would all depend on whether or not you're making calls to other systems, but you probably already know that.
Good experience here so far with Gigalixir. 
Literally just went live TODAY with a Phoenix-backed production site on Gigalixir and Google Cloud Postgres! Couldn’t be happier. A single command to start Travis-CI which then deploys to staging if the test suite passes, another single command to deploy to production after some QA. Jessie Shieh has been SUPER helpful! (also an ex-Googler! Gigalixir is hosted on Google Cloud.) I have successfully hit Devops Zero! (I’m a one-man army so I had no choice!) Another of many nice things is that unlike Heroku, Gigalixir won’t force-restart your server every 24 hours, which means I can use app-side caches which will then be much more effective. You can also do hot deploys, which I don’t think is available on any other host...
curious what was difficult about RDS with elixir on Heroku? Seems like postgrex with the database url should work fine.
Hey there, just wanted to say that I'm the founder of gigalixir and I'm here to answer any questions you might have or help is any other way. Just let me know!
I did just that, and I was continuously getting authentication errors that no one could resolve. Eventually we gave up and just punted for when we fully migrate off of Heroku.
Something that has yet to be mentioned on this thread is the fantastic community, leadership, and documentation that Elixir has. Seriously, check out the docs for Phoenix or Ecto and you will see what I mean.
Yes, I am thinking about Scala too.
Yes, the CL tool can utilise concurrency. It will actually make requests to a rest API and also needs to recover from API errors.
Thanks for this. I bought an Elixir course on Udemy to get myself upto speed.
Man, weird... I connect to it all the time on my laptop on a client project that way. I haven't tried rds from heroku per se, but I just kind of assumed it would work if i needed it to. Thanks for the tip!
Not OP but i was going to build a server for my small website using elixir as I didn't think there would be free-ish hosting options available on the net. gigalixir seems great and I am going to give it a try!
I can attest /u/jshieh runs a great service and helped me get my static site blog up when I was using Obelisk. I still owe you that integration!
That's great! I'm available if you need anything at all, OP or not =)
Did you register for the English site? www.alibabacloud.com
I did indeed!
I can also vouch for Gigalixir. I just started learning Elixir recently and I tried to deploy an app on Gigalixir. I gave up after a few tries because I couldn't figure out what I did wrong. After a couple of days, I received an email from /u/jshieh asking what went wrong and why I didn't go through with Gigalixir. I explained my situation and he helped me get up and running. Apparently, some instructions were not obvious in the Getting Started section of the documentation, but I think he fixed the documentation afterwards. He's a real stand up guy and it's very likely that I would stick with Gigalixir because of the fact that he reached out and helped me with my problems early on. It still has a lot of missing pieces in it, but I think Gigalixir is the better option compared to Heroku if you want the Heroku experience in Elixir.
Did you try opening a ticket using the console? My Alibaba account got incorrectly black listed a month ago but it's now fixed. I can't speak Mandarin either, the support engineer wrote to me in English. The only problem for me was their heavy preference of using DingTalk for real-time support. It seems to be a pretty popular messaging app in China, probably a product of Alibaba as well.
What's up with the formatting of those prices?
It's in Kuwait.
That's what I'd assumed too. I might be missing a particular setting I couldn't find in RDS' settings though, so don't necessarily take my word for it.
That explains the Yuzu. 
Recommend starting with [Phoenix](http://phoenixframework.org). Their documentation is quite good, and it'll get you set up with principles of REST APIs and general backend development pretty quickly.
The docs are good, as well as the [Phoenix book](https://pragprog.com/book/phoenix/programming-phoenix)
Works fine for me from Heroku to RDS, I host https://github.com/openpantry/open_pantry on heroku free tier with free/micro RDS instance... had to set RDS VPC to very/most permissive settings, but with good strong password etc I don't see a big problem with that
I highly recommend the [PragProg Elixir](https://pragmaticstudio.com/elixir) course. It pretty much walks you through everything you're looking for—handling an HTTP request and from start to finish, building up to your own small phoenix-like framework.
I'm thinking about this course as well - were there other resources that you used along the way that helped supplement the material?
I went pretty all-in on Elixir for side projects, so I also picked up the [Phoenix Book from Prag Prog](https://pragprog.com/book/phoenix/programming-phoenix) and the [Elixir Book](https://pragprog.com/book/elixir13/programming-elixir-1-3). The Phoenix book is in the process of being updated to account for some framework changes, so you can either buy now on PragProg and get a free ebook update when that becomes available, or buy now and work through on an older version of Phoenix. I think the target release for the update is Dec 2017. If you're just looking for video courses, there's also [LearnElixir.tv](https://www.learnelixir.tv/) and [LearnPhoenix.tv](https://www.learnphoenix.tv/), which are good cheaper video courses.
I just signed up and pushed my first app. I'm super excited to use this service as it seems to make Elixir deployment super easy. That said, I think you should update the docs for [adding an existing application](https://gigalixir.readthedocs.io/en/latest/main.html#modifying-an-existing-app-to-run-on-gigalixir). One thing it doesn't say is that you have to do `gigalixir login`. I was getting prompted to log in when I would try to push and was getting frustrated. After digging through the docs I was able to find that step but I just think it should be there as well. 
Be aware the book is a bit outdated. I would wait for the 1.3 update which is almost due. And there will be no free update obviously. 
I use just Plug, which is more flexible and lightweight for just a REST server
gigalixir works great for me although I'm using it in a very hobby capacity with a generic setup and low traffic. The error messages could be better but honestly the documentation was pretty good and its a solid alternative to heroku.
Thanks for the feedback! It's this kind of stuff that really helps us improve the product. We'll fix that right away. 
We're really happy here you gave Gigalixir a second go =) We're currently working on building out the web interface so that it has feature parity with the command-line interface. We have a long list of features to add after that also, but we'd love to hear what you guys want most so we can prioritize it.
Thanks for the feedback! Do you know which error messages exactly need improving?
By backend do you mean writing a service that handles HTTP requests and does something with them, or just writing Elixir services in general? I've been reading a couple books on Elixir, and I could recommend them both, but none of them touches on Phoenix or the lower-level HTTP libraries.
While I have you, how long is the normal setup time for a new app? I created an app this morning and still get the default 404 page when navigating to the page. It's been over 12 hours too
What would you recommend instead?
When I had deployed my app incorrectly, my app just returned a generic error message. The log command also wouldn’t exit; it was just hanging with no text. It would be nice if a. the logs didn’t hang, and b. there was a log message like heroku has where it will log that it’s waiting for something to expose itself on a port and then after a few minutes log that it gave up.
Normal setup time should be just a few seconds. If it's been 12 hours, then there's probably something wrong. Usually it's because the app isn't listening on port 4000 due to a prod.exs configuration issue. Email me at jesse at gigalixir.com and tell me your app name and I'll take a look. You can always reach us at help@gigalixir.com also.
That is a GREAT idea. I'm going to implement that next week =)
data in your code actually a tuple. The first element is always :ok or :error. The second element will be your data WHEN first element is okay. Learn to use iex. Things will be so much easier.
In iex it still does the same thing though. iex(3)&gt; "../test.csv" |&gt; File.stream!(read_ahead: 100_000) |&gt; MyParser.parse_stream |&gt; Stream.map(fn [name, age] -&gt; %{name: :binary.copy(name), age: :binary.copy(age)} end) |&gt; Stream.run :ok
Nevermind, I solved the issue using iex like you suggested but I'm not entirely sure why it works tbh. 
Yeah, iex will behave the same. Just that debugging is easier in it.
It's right in the doc: https://hexdocs.pm/elixir/Stream.html#run/1 &gt; This is useful when a stream needs to be run, for side effects, and **there is no interest in its return result.** Most likely the examples you were looking at were doing some side effect with the stream (e.g. printing it with IO.puts) rather than turning it into a list.
Also of note, why are you calling :binary.copy on your strings?
tbh, I'm not sure, I saw it in the nimble csv tutorial so I kept it because I just want it to store it as a string.
Waste of time no, but there significant changes the way you structure your your app. Check the keynote by Chris Mccord if you haven't - https://youtu.be/tMO28ar0lW8
The haskell and elixir ecosystems aren't quite the same. Haskell's main use isn't in web development (although [Servant](https://haskell-servant.github.io/) and [WAI](https://github.com/yesodweb/wai) are quite powerful). And you'll find a much smaller demand for comonad, profunctor or any other paper-inspired data structures in Elixir-land (have a look at [Witchery](https://hex.pm/packages/witchcraft) if it's your thing ;).
To further clarify: the changes are just in the code that Phoenix generates for you. All of Phoenix APIs are exactly the same. So definitely not a waste of time.
It not just the code that Phoenix generates, its way you think about modeling your app
Repo it is not going away. Repo is the door to the database. The main diference regarding to models etc. is that in phoenix 1.2 there was a folder `web/models` where you could group all your applications models and every model had to `use MyApp.Web, :model`. That call was mostly importing conveniences to the file. use Ecto.Schema import Ecto import Ecto.Changeset import Ecto.Query, only: [from: 1, from: 2] Now the files of that folder should be put in various contexts and you don't have that `use` call available. However you can import whatever you like in these files. 
All of the differences from converting from Phoenix 1.2.x to 1.3.0 can be found [here](http://phoenixframework.org/blog/upgrading-from-120-to-130). In addition, you should watch the video provided by noSleep for understanding not only how to translate a 1.2 app to a 1.3, but how you would fundamentally architect the project differently.
There are actually quite resources dealing with 1.3. I recommend https://shankardevy.com/phoenix-book/ if you don’t want to wait for the official 1.3 book. The difference is that a project in 1.3 feels like a well refactored version of 1.2. Though you still can learn the core concept and what Phoenix can do, I would avoid 1.2 book if possible since it can teach a bad habit now. 
There is a migration guide in Github, I just had a problem with the assets folder. But answering your question, the major change is related to project structure. Although you should refactor your project to avoid work with an obsolete project structure.
Hi sorry it wasn't my intention to compare the two languages and I actually hesitated whether to post this question or not. But, it wasn't very clear what Haskell is really for and it was hard to find practical information on Haskell online so thank you for your detailed explanation :D I still think ecosystem and the quality of libraries is important for a language in order for it to be useful, though, so I'm still curious..
Credo is the de-facto linter
The *next* function is overly clever, you could instead do: def player("X"), do: "O" def player("O"), do: "X" This pattern matches on the function input and runs the corresponding function clause :^)
Deeply nested code in `read_move_from_user` looks like it could be a pipeline using the `|&gt;` operator.
TIL Phoenix doesn't use semantic versioning 
Here’s a DailyDrip episode implementing a basic neural network in Elixir with [Karmen Blake’s neural_network_elixir library](https://github.com/kblake/neural_network_elixir). It's free for 24 hours. I’ve been having fun digging into his code, and I’ll be doing more of that tomorrow.
&gt; :^) looks like you ate your nose :\^)
Great! Glad you liked it :D
Elixirs hexdocs, exdoc and doctests really encourage every package to be properly documented, with examples of usage for public API functions. Even better when authors take the time to put typespecs on each public function. I've yet to see any other language ecosystem have such a consistent approach to package documentation. Most other package managers just end up linking to the README of the GitHub repo. That being said, there are still lots of packages that don't exist in elixir, and you need to be prepared to contribute to the libraries you depend on. Luckily Elixir makes it easy to fork a repo, make your changes, depend on your own fork while waiting for upstream to merge your PR. 
You could always model your apps this way. It was just the generators that encouraged poor practice of sticking business logic in controllers. The biggest change from 1.3 for me was the fallback_controller mechanism that gets rid of some error handling boilerplate.
1.3 is a backwards compatible release no?
The heart of backend services is often the database. Ecto is a beautiful API that gives just a enough abstraction to make life easy, but feels close to SQL and avoids many of the problems in other ORMs. The [getting started](https://hexdocs.pm/ecto/getting-started.html) guide and the [whats new in Ecto 2](http://pages.plataformatec.com.br/ebook-whats-new-in-ecto-2-0) book are a good start.
Don't be sorry, no one's gonna behead you. :p Haskell and GHC are mostly a playground for CS research, advanced type systems and category theory. I'm not saying it's unuseable outside of those fields, but most of the extensions to GHC are about that. There has been an effort to distinguish the experimental, more research-oriented extensions from the more mature ones that are used in production systems, led by [this proposal to GHC](https://github.com/ghc-proposals/ghc-proposals/blob/stable-extensions/new-proposal.rst).
An open source project called Citybuilder: http://citybuilder.microflow.io/ The back-end is all in Elixir. Will be making a post on it sometime. 
Oh, you know, come to think of it, we do have a particular security policy set up for that database. That could very well have been your issue. Sounds like you've settled on a steady state in the meantime though, so better luck when you move off heroku!
Which books would you recommend?
Thanks all! edited the post to reflect your insightful suggestions
The ones I read were "Elixir in Action" and "The Little Elixir &amp; OTP Guidebook". Both are pretty good at explaining why OTP is great, but "in Action" delves into the details, whereas the Guidebook is a bit shallower but implements a much cooler project overall. For example, "in Action" does a much deeper dive into the language and walks you through implementing some of the concepts (such as Supervisors) using pure Elixir, before teaching you what's already available. The Guidebook will explain the concepts and then tell you to use them. 
I asked myself the same question. I was excited to get into the world of Phoenix / Elixir, and chose to read through the current 1.2 edition, and reconcile the differences while following along the Phoenix 1.3 docs. It wasn't difficult to do. The differences that stood out most are that scaffolding differences (which are pretty easy to grasp), and the fact that channel presence is listed as "coming soon", but you can now do :) So I would say, if you're excited to get into it, I'd go with the current edition and just deal with it. I don't regret my decision.
TDD is just a process, not really some tooling. Write test, see it fail, make it not fail. ExUnit is fine for that. https://hexdocs.pm/phoenix/testing.html is actually pretty good as far as testing in Phoenix goes. It helps a lot to see how other tests phoenix apps. You got: https://github.com/hexpm/hexpm https://github.com/thechangelog/changelog.com and mine: https://github.com/GBH/loaded.bike
Like /u/GroceryBagHead says, it's more about process. Functional programming actually makes TDD pretty simple. Most of the tools I've found myself lacking, have more to do with making it faster/easier to write certain kinds of tests. * While ExMachina is better than nothing, it's very poor as a Factory library. * Certain levels of test gathering(contexts, etc) are kludgey at best and difficult to make clear. * Many libraries make it near-impossible to mock them out effectively. I'd recommend- just try to force yourself into TDD. You'll find it's easier than you think very quickly.
What would you recommend as an alternative to ExMachina? I'm in the process of learning Elixir from a Ruby background.
For now, I don't have an alternative. I've often been thinking about what one might be however.
I used ExMachina for most of my early test fixtures, but lately I've been using factory functions that just use plain ecto schemas. ExMachina's not bad, but I'm less convinced the value it presents is greater than the potential cost of another dependency. If you're designing your application interfaces along good context boundaries, its pretty simply to consume those from a factory function, which creates a fixed point in your tests that is less likely to change. The danger in using automated factories like ExMachina is that your tests are coupled to your database, not your application interfaces, which means that the latter can change without breaking your tests (depending on how finely grained your tests are, this ranges from "meh" to "wtf") but your database can't change much without breaking your tests (which makes them a PITA to keep green—and makes you less likely to run them.) As an example, I have one context that covers some data, the configuration of which is non-trivial and heretofore was primarly manual, but all in the database. I used ExMachina to set up these structures for tests, but the factories were brittle and even for a testing API the interface was clunky as hell. Refactoring this, I created application interfaces to do the job, which has the advantage of simplifying my life when I need to configure a new customer. I also consume the same APIs in my tests, getting rid of a slew of EM factories. For less involved matters, Ecto still wins in my book, since you can pass a struct containing your data graph to Repo.insert &amp; friends. What I gave up was basically sequences and other dummy data generators, but they're pretty trivial to concoct if you really need them. 
I'm a bit late but if i'm not mistaken Google Cloud Storage is API-compatible with S3—perhaps ex_aws would work?
&gt;I'm a bit late but if i'm not mistaken Google Cloud Storage is API-compatible with S3—perhaps ex_aws would work? No, you're karmajunkie.
What makes you say that exmachina is a poor factory lib? I’ve used it for a while now and it’s great. 
The biggest two issues I have, have to do with changesets and associated records. For the former: It acts like they don't exist. Which means it's very easy for your factories to get out of sync with your code. For the latter: I'm not quite awake enough to explain, but often associated records can be a real pain. Timing issues, alternate factory issues, etc.
Is this ready for a production app?
Shout out to dailydrip.com. Josh Adams does a great job of teaching test-driven development. 
Thanks for the feedabck guys, I know what TDD is as a process, but learning the ins and outs of how each language and framework deals with it is where i am looking for help. It seems backwards the way theyre doing it in programming phoenix as they write the tests after the fact rather than leading with tests and then creating functions to make the tests pass. I'm sure they have their reasons but it would be nice to see some examples of how to "discover" the code rather than just being shown how it is supposed to look at the end.
&gt;I'm sure they have their reasons but it would be nice to see some examples of how to "discover" the code rather than just being shown how it is supposed to look at the end. No, you're justlasse.
thanks for the recs! based on what you mentioned, i'm thinking of looking at elixir in action first :)
One thing to add is [hound](https://hexdocs.pm/hound/readme.html) for black box (functional) testing. It works great with Phoenix.
you really shouldnt need data generation libraries. If you do tdd properly you will probably enf up using an architecture like ports and adapters. Moreover as the other guy said with bounded contexts and aggregates you end up in a place where big things that would normally need a factory ends up being composed of small things that you understand well - meaning you can get away with a simple integration test. TDD does not mean test at the module level. I have never used any helper libraries for TDD beyond a test framework for many years. When i look back on how much i used to use MOQ in .net and how coupled it made my classes to each other by virtue of huge quantity of fragile tests not actually testing behavior but rather particular implementation it makes me smile top myself.
I recently ran into the same issue your having finding good sources for TDD in elixir. In order to figure this out I decided to give a talk at my elixir meetup group. I will tell you it forced me to do a lot of research on my own. Here is a link https://github.com/rsgrafx/TestingTalk - The readme is pretty much the talking points I followed. It includes with a lot of examples and links to blogs / videos I watched. Hopefully this helps in some way.
I think #1 sounds like a fair point. I'd encourage you to open an issue on the repo bringing it up. :) I've had a few issues with the latter in the past, but recently haven't run into it.
You bet. There are lots of people running production apps on gigalixir. Let me know how I can help.
Thank you I will check your talk. Would you be open to chatting about it on occasion? 
It's probably the way to go, at least to understand the basic concepts.
I push distillery builds to Digital Ocean. It's been no-nonsense reliable for me - just like elixir.
Nice. What's your server setup? I'm interested in playing with DO and distillery, but I'm not excited about having to configure / secure an ubuntu box or something like that.
The default images on DO are secure. As long as your application is secure you should not have to worry about it.
There is a tool called Gatling, but I don't think is has been supported to work with OTP 20 yet. https://github.com/hashrocket/gatling However, there is alternative solution called edeliver. https://github.com/edeliver/edeliver And from the looks of hex.pm it appears to be the most popular solution for deploying elixir / phoenix apps. https://hex.pm/packages?_utf8=%E2%9C%93&amp;search=deployment&amp;sort=recent_downloads I hope this helps, and Happy Halloween. 
Highly recommend this book for TDD with Phoenix. https://shankardevy.com/phoenix-book/
What do you use to push? Are the distillery builds just an app build, or full ERTS?
I just scp the full ERTS build from the command line. I'm aware of ways to make this hot upgrade, but I log in to prod and unpack, stop, and start. I know many people would probably automate more than I do, but this works for me.
Via edeliver to DigitalOcean. For reference: [ansible provisioning](https://github.com/GBH/loaded.bike-provisioning) and [the app](https://github.com/GBH/loaded.bike)
I was looking for the simplest yet reliable way to deliver the application to server, restart it and so on. Found [that](https://github.com/schnittchen/carafe) capistrano's set of tasks. Although I didn't tried that yet :). But plan to.
Yeah that would be cool.
Distillery / edeliver ... used this guide: https://medium.com/@zek/deploy-early-and-often-deploying-phoenix-with-edeliver-and-distillery-part-one-5e91cac8d4bd
We make debian packages for our project using Distillery and my plugin: [exrm_deb](https://github.com/johnhamelink/exrm_deb).
Do you have a preferred Im platform like slack or similar ?
Since Ecto 2.0, ExMachina is mostly redundant. You can just construct schemas and optionally insert them into the Repo. Chapter 7 "Improved associations and factories" of [What's new in Ecto 2.0](http://pages.plataformatec.com.br/ebook-whats-new-in-ecto-2-0) shows a very simple alternative factory module pattern.
I will recommend 1. 'Phoenix inside out' series by Shankar which I'm reading currently and am loving it. 2. Programming Phoenix 1.3 when it's released.
Ive used Gatling before on digital ocean. SHAMELESS NERVES PLUG BELOW On another note Nerves supports x86_64 machines now, so in theory one could deploy a VM with nerves. It would be a simple "mix firmware.push $server_ip" and would only take about 45 seconds to come up. 
It's in a Docker container managed with kubernetes on AWS. The deploy happens with some custom scripts that are part of a gitlab pipeline. I'd like to take a look at helm so I can get away from the custom scripts.
Build into a docker container that's deployed onto kubernetes through rancher. 
Last time I deployed anything into an environment remotely resembling production, I did so by creating a Docker container for it, then opening up an SSH port so I could 1) push up the master branch of the associated Git repo and 2) kick off hot code reloads. It wasn't pretty, but it got the job done.
I build containers, push it to registrów and use Kubernetes as platform to run it.
[removed]
I do the same thing with Lightsail.
Have you thought about using rsync and systemd?
We use Nanobox :-)
Is it commonplace to put passwords and cookies up for all to view on public github projects?
Generally, no. Ansible allows encoding stuff like that though. Also I think you're referring to db password? Database doesn't listen to outside so that password kinda doesn't matter. But yeah, could be encrypted.
Ditto. ~20 boxes up and running. We love it.
Kubernetes on Google Cloud. It gives us everything (clustering, autoscaling, secret management etc) except for hot code deploys which we don't use. Wrote about it [here](https://blog.polyscribe.io/a-complete-guide-to-deploying-elixir-phoenix-applications-on-kubernetes-part-1-setting-up-d88b35b64dcd)
Snap, I was at this conference but didn't see this talk. Thanks for posting it!
Nope. This is what I know, and it's working nicely.
Yeah - usually on slack. same handle
I'm in your boat. I ended up installing Phoenix 1.2 to make sure "Programming Phoenix" works. Even then, there are some errors. It's kind of shocking, really, that the book starts with installing the dependency as the version from the master branch. Crazy!
1: `add_n` is a function that takes a single argument (`n`) and returns a function which will take a single argument (`other`) which will return `n + other`. 2: We are calling`add_n` with `n=2` and binding it two the variable `add_two`. Meaning, `add_two` is a function which will take a single argument (`other`) and return `2 + other`. 3: We call `add_two` with an argument `other = 3`, resulting in 5 being returned.
The concept behind this is called currying. https://stackoverflow.com/questions/36314/what-is-currying
Thank you! This was excellent!
Thank you. So basically the closure call then accesses the inner function. Is it common to use currying?
I would use a Enum.map like so: http://elixirplayground.com?gist=19ee5a1a082a20c681b5b3481324fd29 ``` 0..90 |&gt; Enum.to_list |&gt; Enum.map(fn x -&gt; Task.async(fn -&gt; IO.puts x * 100 end) end) |&gt; Enum.map(fn y -&gt; Task.await(y) end) ``` 
Sorry if I'm being pedantic, the terminology is a bit off. A "closure" is the same as an "inner function" that is bound to an environment: https://en.wikipedia.org/wiki/Closure_(computer_programming) So basically, the "outer function" returns a closure (the "inner function") that is bound to the environment of the "outer function" and therefore has access to its parameter. Is it common? I'm still new to Elixir, so I can't say how commit it is within the community, but given that it is a functional language, I assume it will show up once in a while. I think it's good to think about why something like this is useful. You can use it to break down functions so that you don't have functions with long lists of parameters. I hope this makes sense. 
**Closure (computer programming)** In programming languages, closures (also lexical closures or function closures) are techniques for implementing lexically scoped name binding in languages with first-class functions. Operationally, a closure is a record storing a function together with an environment: a mapping associating each free variable of the function (variables that are used locally, but defined in an enclosing scope) with the value or reference to which the name was bound when the closure was created. A closure—unlike a plain function—allows the function to access those captured variables through the closure's copies of their values or references, even when the function is invoked outside their scope. Example. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/elixir/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
`Task.async_stream` gives you concurrent list processing. There's options to configure the concurrency and whether you need the results in the same order as the inputs.
Damn I just finished this course. What specifically made it horrible? I didn't mind it but I don't have any elixir experience
Currying is not idiomatic in elixir. It's much more common to declare functions with multiple arguments. If you need partial application then a simple lambda shorthand is used: `add2 = &amp;add(2, &amp;1)` 
Didn’t know about that. Thanks for sharing!
You're awaiting each task immediately after starting it, so of course, they run one by one: Enum.each(data, fn(x) -&gt; t = Task.async(__MODULE__, :concurrentstuff, [x[:name]]) Task.await(t) end) You need to start all tasks, *then* await all of them them. Keeping the notation close to your example, this would look like: tasks = Enum.map(data, fn(x) -&gt; Task.async(__MODULE__, :concurrentstuff, [x[:name]]) end) Enum.each(tasks, fn(t) -&gt; Task.await(t) end) And as someone suggested you can simplify that by using Task.async_stream.
Sub-topic: what are the different techniques used by people here to deploy from a Mac, to a Linux (Ubuntu) server? Various flavours I've heard about so far: - Telling distillery not to include ERTS ([link](https://elixirforum.com/t/best-way-to-deploy-from-mac-to-digital-ocean-droplet/6760/2)) - Using Docker to cross-build ([link](https://elixirforum.com/t/a-beginners-guide-to-deployment-with-edeliver-and-distillery/5665/10?u=thbar)) - Using a "build server" with the same architecture as your target server (overkill if you are targeting a single-server deployment) I'm curious to know if there are other techniques used in the wild.
This is also example of writing nested macros, as this is &gt; [use macro to write macro that generate macro used in macro](https://twitter.com/hauleth/status/925103932044709889)
Build in CI using Docker
I very much appreciate the correction. I was writing some of my own after reading yours and Rschmukler's responses. It makes a lot more sense now. And now I know the vocab as well.
Also use nanobox here, love using it.
Great to see this natively supported -&gt; "At Lab Zero we develop on macOS but run Linux clusters for some of our deploy targets. Bootleg does the work necessary to compile and build our releases on server architecture that matches the target deploy environments." Can't wait to try it out - thanks for sharing.
This is so interesting. Can you elaborate?
Disappointing to see yet another Capistrano-alike. Setting aside that objection, I'm still not sure what it offers besides aesthetics/NIH over something like [edeliver](https://github.com/edeliver/edeliver) or [gatling](https://github.com/hashrocket/gatling), or even [HashNuke's ansible-based stack](https://github.com/HashNuke/ansible-elixir-stack). I loathe this imperative, developer-laptop-driven deployment model.
yep, deployment should be part of a full fledged CI/CD pipeline.
Well it would probably take a little work, you could build a system that has _everything_ you need on it, (IE PostgreSQL, and friends), then you would build your phoenix app just like normal, then when you're ready to push to prod, you would build your firmware, and deploy it. I'm not sure how it would be deployed, (because afaik, no one has done this before.) but your deploy pipline would need to somehow write the image produced to a media (hard disk) of sorts to boot off of it. Then as soon as it had been deployed the first time, you could do `mix firmware.push &lt;your domain&gt;`, and it would upload the firmware (over SSH) and fwup would apply it. (fwup is the package built bundle and distribute firmware images)
I would put the |&gt; at the beginning of the lines. So from: ``` def read_move_from_user do IO.gets("Next Move: ") |&gt; String.trim |&gt; String.split(",") |&gt; Enum.map(&amp;String.to_integer(&amp;1)) end ``` to: ``` def read_move_from_user do IO.gets("Next Move: ") |&gt; String.trim |&gt; String.split(",") |&gt; Enum.map(&amp;String.to_integer(&amp;1)) end ```
For maintenance I think a recursive function is easier to understand than a macro: def cartesian([], _f), do: [] def cartesian(lists, f), do: cartesian(Enum.reverse(lists), [], f) |&gt; Enum.to_list() defp cartesian([], elems, f), do: [apply(f, elems)] defp cartesian([h | tail], elems, f) do Stream.flat_map(h, fn x -&gt; cartesian(tail, [x | elems], f) end) end Though as a macro learning exercise it's a good one. The big lambda that is passed to `Macro.prewalk` is probably better as a named function with pattern matching to remove the `case` expression.
MongoosePush is a push notifications server for APNS and FCM. MongooseICE is a STUN and TURN server. Both MongoosePush and MongooseICE are brand new standalone servers, coded in Elixir, under Apache 2.0 license, available on-premises! You can use them with or without MongooseIM. What do you think of these?
You can make a cartesian product without nesting by just putting multiple parts into the for comprehension: iex&gt; for a &lt;- ~w[10 20], b &lt;- ~w[a b c], c &lt;- ~w[xx yy], do: {a,b,c} [{"10", "a", "xx"}, {"10", "a", "yy"}, {"10", "b", "xx"}, {"10", "b", "yy"}, {"10", "c", "xx"}, {"10", "c", "yy"}, {"20", "a", "xx"}, {"20", "a", "yy"}, {"20", "b", "xx"}, {"20", "b", "yy"}, {"20", "c", "xx"}, {"20", "c", "yy"}]
Thank! Sorry if this is a dumbass question but can I use this as part of a webrtc solution in order to deal with NAT?
Of course, that's the goal... MongooseICE is an implementation of the open standards STUN and TURN, so you can use it with XMPP/Jingle, SIP, WebRTC, etc.
Thanks for this review! Very helpful. I started with Programming Elixir 1.3 based on your comments so I can get used to the syntax. I'll move on to either The Little Elixir @ OTP Guidebook, or Elixir in Action afterwards.
I think a good book to read is this one: http://learnyousomeerlang.com Fred does a great introduction to the erlang's actor model, and the later chapters focus on building applications following the message passing model. I think Rob Pike cover the difference (concurrency vs parallelism) pretty well here: https://blog.golang.org/concurrency-is-not-parallelism In regards to getting teams to understand the model, I think it's important to understand there's two parts to the language: * modules - you can group a bunch of functions that create/operate on a specific type of data (e.g. a list of todos), as you would with methods in your classical object model (object encapsulating the data + methods that operate on it) * process - independent component, that synchronizes commands (messages) sent to it, processing them one at the time I hope this helps. I am always learning new things about this!
That is why I want to introduce [Sup](https://github.com/pressly/sup) in my workplace, as this in no-bullshit Ansible. Also in any new project we start I am trying to do automatic deployment from GitLab CI, so no-one has access to production or staging machines.
I find `https://github.com/tpope/vim-projectionist` much easier to work with. The only problem with this is that there are no other editors that have support for `.projections.json` file.
It might be helpful to list what extra generators it provides in the readme. Or the documentation. Reading the code the best I could tell is that there's a "Posts" generator.
The first block in the readme displays the two commands this package adds. I’ll make it a bit more explicit tomorrow :)
Duh
The differences between 1.2 and 1.3 are not as drastic as they seem. "models" are broken up such to separate your application logic from your data definitions. That's probably the biggest change. There is a directory structure change, but it is minimal. Once your code loads it's more or less doing the same things it was in 1.2 (just some functions might live in another module)
Elixir lets me build a reliable distributed system in under 200 lines. Java lets me build a very efficient and maintainable core and gives me lots of levers to pull. They do different things
As a beginner, I would recommend learning first about web servers. This would be something like Rails or Phoenix and learning about databases. Then you can learn about asynchronous processing and operations and move into deeper concepts from there
Thanks for the recommendation - and totally agree with it! Do you know of any particular resources / texts that introduce databases with a focus on beginner friendly concepts? Really appreciate it!
Have you followed all the steps in the readme?
Hi kagux, I'm planning to share interactive streaming sessions with you, where I show how you can apply the good practices of software development, such TDD, test-first-programming, Refactoring and Clean Code in order to learn a new programming language (e.g. Elixir), learn new libraries or frameworks (e.g. Plug o Phoenix Framework) and contribute to some Elixir open source projects (e.g. ex_debug_toolbar or other). What I am doing right now is going in depth with Plug, I already made some open source contribution during the last Hacktorberfest event. I plan to move on by exploring something about the Phoenix framework. I am looking forward to hit you on the elixir's slack, maybe there we can find other interested at this Twitch Channel. Do you think it could be useful to share my channel in the elixir's slack?
Yes, the readme describes how to build the documentation for each of the services provided. That documentation is reference for the available modules and functions, it doesn’t describe how to actually instantiate/implement any of them.
Contributing to documentation and teaching material being created by the fine folks at Elixir Bridge. http://elixirbridge.org/
I don't have any off the top of my head as I've mostly learned that stuff on the job, but any SQL tutorial should do
Maybe this PR helps? https://github.com/GoogleCloudPlatform/elixir-google-api/pull/30/files and https://github.com/GoogleCloudPlatform/elixir-samples
yes, thank you /u/dplummer - I haven't had time to test this out, but it looks consistent with what someone else was saying, where you need to get a `Connection` object and then work with the functions in the library from there.
This is really good
heroku and aptible
To answer your questions: Is Elixir a good replacement for Java? No Is Elixir a general purpose language like Java? Yes Would you write a command line tool in it? Sure Would you write a rest API with strict timing requirements in it? Definitely. The problem with the question "Is X a good replacement for Y?" is that the answer always depends on exactly what the problem is you're trying to solve, so you're always going to have to assess the problem first and then do research on how best to solve that problem, and language and library choice should result from that research. In the case of your specific problem, a low latency REST API, Elixir is probably a good fit for at least the HTTP part of that API, because it's built on Erlang's BEAM VM, which is designed for high availability, low latency network applications. However, if you have heavy computation involved, you may need to use a different language to implement the computation IF Elixir alone isn't fast enough to hit your latency requirements, as Elixir isn't built with fast low level computation in mind (so your main API might be written in Elixir, but that API may need to offload heavy computation workloads to code written in another language optimized for that).
In the `LongPoll` example, `handle_info` sends a response to a request that isn't explicitly passed in as a parameter. Does this mean that the `Raxx` interface is process-per-request?
Yes, each request is handled in a separate process. This ensures that there is no contamination of a handler process from requests/responses that were previously sent in a pipeline (HTTP/1.1) or on another stream in the same connection (HTTP/2). Cowboy has also moved to a process per request/response exchange as part of supporting HTTP/2
+1 for this. In using docker you also get a nice consumption pipeline for others to use as well. 
I am currently finishing the [Phoenix for Rails Developers](http://www.phoenixforrailsdevelopers.com) book. I plan on launching it on December.
Great informative article 
The suggested fix still includes a preload. Is the preloaded relation still included when a select clause is used? 
I think comments are still loaded, but they’re not using all the data by just selecting what they need. The article could use a more revealing example...
That article is useless without specifying the columns that have been omitted in this case. Omitting one datetime column shouldn't lead to this result.
It's articles like this that remind us why we need a downvote button. The article title is about preloads, but nothing changes at all with respect to preloads. As far as I can tell the point of this article is "don't load all of your blog's post content into ram all at the same time". Good advice but 1) nothing to do with preloads 2) there's no hidden trap here. The poster wrote code that explicitly did something foolish.
Hello! Thank you for your comment ! The article is about the difference between holding data in the db vs memory. It is virtually irrelevant what columns where optimized, you just need to select what you need. Either way I can see how people could get curious about that now- I’ll try to improve for the next one. Thanks for reading.
Hello. Thanks for your comment! This is still about preload since you can combine preloads with selects- that is the most important lesson here and that stored data takes more space as they are brought into memory. I just thought that the code itself was so simple that did not matter. If you look at the ecto docs in a few seconds you can understand how to do that, next time I’ll keep people like you in mind. Thanks for your feedback 
Hello! Great question. The reason why I don’t fully show the example is because the select can get messy. If you just want to select parts of the preloaded assoc you might need to use fragments. In this case, for a very simple example we just optimized the select for the post struct. I can see why that would be confusing now- next time I’ll work better on the examples. Anyway, you are correct,’you can include a “shorter” compact association with the preload, but the query might not be fully supported only using ecto.
Thank you! :)
I have updated the article with a better example, please let me know if you have questions.
I have updated the article with a better example, both explaining why preload might need to be avoided and also making it very clear why this could be a hidden trap. 
Thanks for the comment! Based on your suggestion I have edited the article to make it more clear,
I was able to watch this on mobile, but not on desktop due to Vimeo privacy settings
Thanks for the updated example, replacing preload with explicit join/select makes sense. I've never used it but the docs suggest you can supply a custom query or function to control preloads: https://hexdocs.pm/ecto/Ecto.Query.html#preload/3-preload-queries
No problem! I can now see there should have been a better example to start with. Regarding custom preload, I actually have used it as well, it can work in some cases but I’m not sure if you could add a custom select there, maybe it would work. Another deal breaker for me was the join, since where I work we try to avoid big joins all the time we ended up with two separate queries.
Sorry to hear that. I was able to watch it on my desktop. Unfortunately I have no control over those privacy settings but will forward the comment to skillzmatter
Started working on an application graphing library. It's similar to mix xref, but I needed the ability to generate different kinds of graphs. An example generating a graph showing the application dependencies (how they interface with each other) for the Erlang runtime and my library (and it's dependencies): https://i.imgur.com/bc4QrvI.png (mobile users the image is quite big) Currently you can graph the application dependency, module dependency, and call graph. With some minor customisation options. I still need to add support for styling the graph, and showing messages (at least those that can be detected in the compiled binaries/aren't created at runtime; though I think it'd be cool to add a monitoring aspect later on). 
Wow, very nice lib. I like the approach and I definitely agree with the motivation, more readability, etc. A quick question: wouldn’t this kind of defeat the purpose of TDD though? You’d have to write your code before the test right?
Co-author here. Thanks! assert_value implements a superset of normal assert functionality. So it should not limit you in the style of testing. The way we use it ourselves is a hybrid style of TDD. We define interfaces with stub implementation and write tests for them first. Then we work on the proper implementation and keep re-running the tests as we go. In practice it is very hard to come up with correct expected values by hand anyway. So the best you can do is to have the tests capture the current behaviour.
Really clever. Like a VCR for controller tests. I would not use it though. I don't test resulting html. I care more about what controllers are doing so I occasionally check for `conn.assigns` to make sure proper stuff is doing to be used in the template. Writing output serializer for rendered pages seems like a pain. That's just me though. I'm sure most will find this very useful. 
VCR is an interesting analogy. Haven't thought about the similarity before but it totally makes sense. The HTML serializer is just an example. You can use assert_value to test at any level that makes sense for your code. We should clarify that in the readme. Thanks!
Cool! Great work!
Sorry for the confusion. The documentation and samples are very much a work in progress, but we're working on it. You're correct in that you create a `Connection` struct with an oauth access token and pass that as the first argument to any API call. Take a look at the links /u/dplummer posted as the elixir-samples repo will continue to accumulate sample use cases for several API clients. As you may have noticed, all of the API clients are generated via codegen as we don't have resources to handwrite each client. Feel free to file an issue on the GitHub repo and we'll make sure to take the feedback into account. Just know that we're working to make it easier to use our APIs in Elixir.
I personally wouldn't recommend against hot upgrades. However it adds some complexity to the deployment process (where you'd have to upgrade the state of any genservers that has changed internal structure). It's also popular to use a docker based architecture where hot upgrades isn't possible. It pretty much boils down to your needs. If you need hot upgrades, use it. If you don't it's probably not worth the extra work it adds to each deploy
We used hot code reload for a single file. It's very useful especially when a customer wants to fix a bug right now. But making hot upgrades is not very easy, and you should take into account many things. There should be very important reasons to use hot upgrades, for example - highest availability (nine nines) and reliability, thus it is useful only for critical systems like telecom, banking and so on.
But if you're doing number crunching you might as well use Julia because it's functional (a natural fit for math), fast ~0.7-1.5 of c usually, and it's scaleable (only hll to achieve a petaflop deployment)
Hot reloads is tool that has its uses. But in most cases where you will use Elixir these uses aren’t needed. When you have web application that serves users data in per request basis (classic web apps)or you can allow reconnection (chat apps, notification system, etc. if message is delivered one second later, you will loose nothing). But when your applicattnion cannot allow such disconnections (mostly VoIP) then you have no choice, but hot update. 
Looks like you were writing a similar post about Kotlin. You accidentally put &gt;Work with Kotlin requires a plugin. Under the Sublime Text section
IntelliJ CE is free and works with the Elixir plugin
But... but what about vim?
Has anyone had luck with a good vim setup? I've been trying to use Alchemist.vim to no avail.
Yo could use emacs with evil plugin, there you go &lt;3
Hot code upgrades are a selling point if your service needs them. The question is then, when do you need them? The answer is pretty simple: if bringing down a node (for any reason) results in loss of service, and that loss of service is unacceptable (for any reason but probably SLA guarantees or loss of revenue) then that's when hot code upgrades should _start_ to be considered. In practice, like another poster said, this usually only applies to services that 1) require persistent connection and 2) require a continuous stream of data, VoIP being a great example and 3) bringing down a node would put too much pressure on the rest of the cluster (although this should be a signal that your cluster config is suboptimal) But really what it comes down to is that technology like kubernetes+docker+CI/CD pipelines makes deploying really easy if you do it that way, like absurdly easy and more importantly painless.
Thanks for chiming in. I may be missing a lot but looking at [edeliver examples](https://github.com/edeliver/edeliver/#examples) it seems like a piece of cake to do hot upgrade ...
Thanks for your reply. It seems like K8/Docker are being recommended because hot upgrades are complicated and have not been abstracted for simple/reliable/consistent deployments. And if it were simple then we would not be distinguishing between application that need hot upgrades and those that don't. The question is, **what are the issues that make hot upgrades complicated and non-uniform**? It seems Genserver or things like Agent (built on genserver) follow a pattern ... but those that don't follow a pattern will be hard to abstract .... wdyt??
If hot upgrades are recommended for only VOIP like apps since they are hard to perform consistently then how does a service like [Gigalixir](https://www.gigalixir.com/) do it regardless of the app type. Seems like if someone can make money doing this then it should be fairly simple to abstract it into a tool ... but I will let the experts chime in. 
Are you sure that the do hot upgrade not hot swap? There is huge difference between these two and while first is very hard second is moderately easy. 
I'd love some more in depth blog posts about why I'd choose those strategies, and how to wire several different subtrees together. The "Little Elixir &amp; OTP Guidebook" did an ok job, but it'd help to see more examples of setting up supervisor trees to accomplish real work. Ideas off the top of my head: * How to setup retries of potentially flakey work * Same, but with backoff &amp; other logic * Splitting work between different processes * Splitting work when there's more dependencies between the processes (this may just end up being GenStage or Flow, but who knows). 
hmm ... I had no idea there was a difference as it seems to me a hot upgrade will require hot swap too, isn't it ? Could you expand on this a bit or point me in the right direction?
Yes exactly! Consider it's like when you're doing changes to your database except it can potentially be thousands of different databases that has to be migrated. It's also pretty hard (maybe impossible) to test that the upgrade will succeed before actually doing it 
Hot swap mean that you create new instance of the application and redirect new traffic to it, let old instance finish what it is doing and then kill it. There is no downtime during deployment. But new users are using different instance than old users. Hot upgrade mean that you replace running code inside currently running instance. Both old and new users are using the same instance, but during deploy you just switches modules to new ones. --- The main difference from OTP developer point of view is that the first one reset state of all `Gen*` and `Agents` while the second one allows to maintain them.
The pain point for a hot code swap is that you need to run commands in the BEAM. These include `:code.purge` on the old module with the code you're trying to hot swap, then `:compile.file` the file with the new code and then `:code.load_file` to load the newly compiled module. If your module is a genserver, you can implement a callback that would do something like this def handle_cast(:upgrade, state) :code.purge(__MODULE__) :compile.file(__MODULE__) :compile.load_file(__MODULE__) # maybe tell supervisor to spawn new processes {:noreply, state} end Which then leads to the next question, how do you automate all of this? That's really what it comes down to.
Also be mindful of any dependencies you have and are upgrading as part of your deployment. If a dependency has any processes maintaining state and that state has changed in the new version of the dependency, will it upgrade properly?
I have been using it just fine. It just requires some patience to go through setup, but it’s worth it.
I've never used hot code upgrades in practice. But I'll go over how they work and talk a little about the problems I can think of with them: Here's an example: defmodule TheCount do use GenServer @vsn "1" def start_link, do: GenServer.start_link(__MODULE__, []) def init(_), do: {:ok, 0} def increment(pid), do: GenServer.call(pid, :increment) def handle_call(:fetch, _from, state), do: {:reply, state, state} def handle_call(:increment, _from, state) do new_state = state + 1 {:reply, new_state, new_state} end def code_change(old_vsn, state, extra) do {:ok, state} end end This is our initial version that's in production. Its state is a simple integer that it's keeping track of. We label the version of this GenServer with `@vsn "1"`. But let's say that later on our requirements are changing so that the integer can not only increment but also decrement (okay, easy enough).. but it will also need some sort of "undo" operation. This means we need to track not just the current state of the counter but also whether our last action was "increment" or "decrement". We'll need to change our internal data structure from a simple integer to something like a map, maybe `%{count: 0, last_action: :increment}` as an example. Here's version 2 of our module (I'm not implementing the actual undo/redo feature since that's beyond the scope of what I want to demonstrate): defmodule TheCount do use GenServer @vsn "2" def start_link, do: GenServer.start_link(__MODULE__, []) def init(_), do: {:ok, %{count: 0, action: :init}} def increment(pid), do: GenServer.call(pid, :increment) def decrement(pid), do: GenServer.call(pid, :decrement) def handle_call(:fetch, _from, state), do: {:reply, state[:count], state} def handle_call(:increment, _from, state) do count = state[:count] + 1 new_state = %{count: count, action: :increment} {:reply, count, new_state} end def handle_call(:decrement, _from, state) do count = state[:count] - 1 new_state = %{count: count, action: :decrement} {:reply, count, new_state} end def code_change(old_vsn, old_state, extra) do action = if old_state == 0, do: :init, else: :increment new_state = %{count: old_state, action: action} {:ok, new_state} end end If you want to play with this to see how it works, copy each of the snippets above into files "count1.ex" and "count2.ex". Then do: c "count1.ex" {:ok, pid} = TheCount.start_link TheCount.increment(pid) # do this a few times if you want TheCount.fetch(pid) # Now let's upgrade TheCount... :sys.suspend(pid) c "count2.ex" :sys.change_code(pid, TheCount, "1", [:extra_params]) :sys.resume(pid) # If all went well then we should have a new version of TheCount TheCount.fetch(pid) So you can see in `code_change/3` that we're having to manually convert our old state to the new state. This is why Elixir's hot-upgrade feature isn't really some kind of magical, transparent feature and there's not really much Elixir can do to automate this for you. Your code just needs to follow the pattern/abstraction. What's not really well-defined with any convention (that I'm aware of, someone correct me if I'm wrong) is how to test this type of thing. In the example above I had two versions of `TheCount` defined in `count1.ex` and `count2.ex` files, and we loaded them in iex. But in the source tree of your app or library you're not going to have multiple definitions of your module, you're only going to have one. So how do you test that it's going to upgrade correctly? `TheCount` as it's defined in your source tree is going to be the latest version of the code. That's the part that's murkiest as far as I can tell. You can come up with your own system for doing things, like maybe have another module `TheCountStateConverter` defmodule TheCountStateConverter do def convert_from("1", old_state, extra), do: ... def convert_from("2", old_state, extra), do: ... def convert_from("3", old_state, extra), do: ... end Then you can unit test this converter module and have `TheCount` just call into this module from `code_change/3`. Another issue is the situation of open source libraries or apps. Say you're maintaining some library with a GenServer that handles code upgrades like this and your GenServer's state has changed 5 times in releases. You can't assume that someone upgrading their app with your library is upgrading from the previous version of your library.. they could be migrating from a GenServer that's `@vsn "1"` up to the latest `@vsn "5"`. In this case you probably need to have some way to migrate the data from 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5. That's all I can think of right now. Anyone feel free to chime in and tell me if I've said or done anything wrong in all of this. :)
Short and sweet, nice! :)
Interesting blog post about learning Elixir. Looks like the community was super helpful in the process, which is really cool to see!
@vlatheimpaler a big thanks for a very detailed and well explained reply. I understand the issue much better now. The last argument about GenServer library upgrade is a hard problem and probably not solvable. But the previous example of `code_change/3`, and then using `TheCountStateConverter` to test your states, makes me think of some kind of simulation machine which simulates upgrades from existing to new states.
@vlatheimpaler in the example of `code_change/3` if I wanted to persist the state (`count`) across deployments without using hot code upgrade, how will I achieve that? some options that come to my mind are 1. store the `count` in some sort of database and read the state in `init` 2. run at least 2 nodes A &amp; B of the same genserver and then in the `init` of A one read the state in from B node. P.S. being a noob in elixir/erlang I am not sure if this would be even possible.
Well, you say "without using hot code upgrade".. so in that case you're not using `code_change/3`. You really just want to do this with a standard `GenServer.call/2` I think. defmodule TheCount do def save_state(pid), do: GenServer.call(pid, :save_state) def handle_call(:save_state, _from, state) do # Insert your file or database saving code here... {:reply, true, state} end end 
This is spam, and nothing to do with Elixir.
I'd say it depends much on what you value with ruby/rails today. Rails is known for the plug and play magic that in almost all cases "just works". In elixir you will have a harder time using a package without actually understanding what it does which could be a both a weakness and a strength. To me there is the case where you in views you always have to pass the object you're working with to helper functions. Consider this: ```elixir = if is_published?(@article) do p Published ``` versus ```ruby - if is_published? p Published ``` The example above isn't that big of a deal but when you'd have to pass multiple arguments it's easy to miss the way rails can do it
* No fixtures or factories out of the box. Ex-machina is pretty good if you want to use factories. Saw some library for text fixtures but haven't tried it. * File organization is a bit confusing. Especially after contexts were introduced. Sometimes I'm not sure where I can cram a file. * Lack of ActiveRecord is not that bad. You just need to think how to get all the data you need on the view. Honestly, besides figuring out conventions and "how do I do a thing?" it's pretty pleasant to work with.
Use strict doesn’t make JavaScript statically typed, it just throws out more runtime errors for things like forgetting to declare a variable before assigning to it. I don’t know if any language that is sometimes dynamically typed and sometimes statically typed and it sounds like a recipe for disaster to me
You mean [Elmchemy](https://wende.github.io/elchemy/) by the wonderful Krzysztof Wende?
Not spam Elixir is in the video watch it and you will find out 
this is r/elixir. as in elixir the programming language. nothing to do with elix or whatever the cryptocurrency is. You're in the wrong neighbourhood
You can't test Elixir code as easily as you can test Ruby code (dynamically stubbing out methods). This can be frustrating but pushes you towards a better design (you can live with an absolute mess in Ruby and still be productive thanks to a great testing story) Metaprogramming in Elixir is much more powerful and complicated than metaprogramming in Ruby. My personal opinion is to avoid it and most libraries that do it. I recently had to deal with extending a library that used a huge amount of metaprogramming and it was extremely frustrating There are no step debuggers. `IEx.pry` is a thing, but it is a crutch, not as good as Pry for Ruby, and isn't helpful for debugging concurrent processes. Tracing is the preferred debugging approach - the libraries for it can be a bit archaic Note that Erlang has a lot of shit built-in. Most of the libraries I've wanted (unless you're looking for client wrappers or something) have existed in Erlang in some form The last point I'll note is that there is *a lot* of stuff in Elixir (and Erlang/OTP). Phoenix is well and good, but if you're doing single process end-to-end request handling you're probably not taking full advantage of a lot of what Elixir offers. We've been using Elixir for one of our back-end processing pipelines and it has been really great. I'm grateful that Elixir can stand on its own and be productive without its web framework, but it's something to know going in
Typescript and dart 1.x are exactly that, and it works wonderfully in both cases.
Did you see the Factories chapter in the [What's new in Ecto 2.0](http://pages.plataformatec.com.br/ebook-whats-new-in-ecto-2-0) ebook? I don't think there is a need for ex_machina with what Ecto 2.0 provides.
&gt; You can't test Elixir code as easily as you can test Ruby code (dynamically stubbing out methods) It is definitely possible and there are libraries that do it but the general consensus is that it is a bad idea (which is a good thing IMO). &gt; Metaprogramming in Elixir is much more powerful and complicated than metaprogramming in Ruby Agreed although I am not sure if the magic in Rails is more tolerable. Elixir macros are compile-time only and it completely horrifies me that Rails is changing my code at *runtime*. &gt; There are no step debuggers There is a GUI debugger and Elixir v1.5 has the new IEx.break!. But none of them are step by step and if that is what you really want, then you'll definitely miss it.
ex_machina follows the same concept as described in your link. It removes a bunch of boilerplate code you'd have otherwise. Totally recommend it. 
Erlang ships with a debugger, you can do the usual stuff there: step, break, conditions, etc. Not as slick as ruby though. For mocking, there's meck library in erlang, I think there is a wrapper in elixir. However, it's best to avoid going this route, telling you from personal experience of working with elixir after ruby. I usually go for either passing dependecy stub to function or for simple stuff just let it call the dependent module. For dependecies I highly recommend double or stubr. 
I am aware but ex_machina then becomes yet something else to learn with minimal benefits. I already know Ecto so I prefer to focus on the tools it provides.
&gt; Agreed although I am not sure if the magic in Rails is more tolerable. Elixir macros are compile-time only and it completely horrifies me that Rails is changing my code at runtime. Yeah maybe it's worth expanding on this a bit. To be clear - avoid metaprogramming and question it whenever you see it. I think viewing Ruby as a scripting language that runs at runtime and `class_eval` and friends as simply changing your context makes it tolerable for me. How you metaprogram in Ruby is mostly by programming Ruby code how you normally would (albeit in a different mindset). Elixir is a different beast here. Expansion is done at compile-time meaning your manipulating the AST. The syntax for working with macros, quoting/unquoting, binding values - it's all very different from your day-to-day stuff in my opinion even if your objectives are the same when metaprogramming in Ruby. So just don't use that stuff :)
Oh - another thing I miss is easy Linux integration. Integrating with the world outside of the BEAM can be a pain
I find this particular example a tad questionable, working around immutability instead of working with it. Age is inherently mutable, would it not be a better idea to instead use a function which gets us the age on the fly? You could even generalise the concept of age into a time_since function and write a wrapper function that takes a person struct and passes its age into time_since. 
I think it makes complete sense to see Ruby under that perspective but if we are comparing Elixir and Ruby from the perspective of Phoenix and Rails and how we use them to build long running systems, then it is hard to accept the runtime aspect of Ruby's meta-programming. It is fine to meta-program everything on boot but I wish I could just freeze everything after that. In any case, I agree with you that generally you should avoid meta-programming. Especially if it is happening while your system is serving requests.
Oh hey, look! A tutorial: https://www.erlang-solutions.com/blog/how-to-set-up-push-notifications-with-mongoosepush.html
Hi everybody, I attended Elixiconf this past year and have been working on creating useful content for the community (I wrote this article). Let me know if you have any feedback! 
How practical is Elmchemy for a Phoenix developer? Can we use it for developing Phoenix applications?
I knew what "use strict" is, I just wanted to say "some option like that" which turns on "static mode". Anyway, thank you!
You are right I didn't mean `code_change/3`.
I started on my first Elixir app - https://ccpsnorlax.blogspot.is/2017/11/large-scale-ambitions.html
Worth to mention that almost everything you see in Elixir is a macro. [`defmodule`](https://github.com/elixir-lang/elixir/blob/05418eaa4bf4fa8473900741252d93d76ed3307b/lib/elixir/lib/kernel.ex#L3257), [`def`](https://github.com/elixir-lang/elixir/blob/05418eaa4bf4fa8473900741252d93d76ed3307b/lib/elixir/lib/kernel.ex#L3495) even [`defmacro`](https://github.com/elixir-lang/elixir/blob/05418eaa4bf4fa8473900741252d93d76ed3307b/lib/elixir/lib/kernel.ex#L3547). You shouldn't use too much metaprogramming, but when it is well written then it isn't that hard to read ([example that I am proud of](https://github.com/hauleth/ecto_function/blob/fe920c1326f589d7b7391e67a51bc8b5a30a5ef5/lib/ecto_function.ex)). I kinda like Elixir metaprogramming possibilities, but you shouldn't overuse them.
I do not think so as there already is [`Typespec`](https://hexdocs.pm/elixir/typespecs.html) and [`Dialyxir`](https://github.com/jeremyjh/dialyxir) which checks if callers respect required parameters' types.
@article |&gt; is_published?
&gt; You can't test Elixir code as easily as you can test Ruby code (dynamically stubbing out methods). This can be frustrating but pushes you towards a better design (you can live with an absolute mess in Ruby and still be productive thanks to a great testing story) I really can't disagree with this more... Testing in Elixir is much, much easier, precisely because it keeps you honest. When you run into something that's hard to test, in any platform, you should step back and ask why. In Ruby, its so commonplace to violently break into your objects to skip over that question that nobody really stops to ask it. In Elixir you don't have that option so you should draw back to looking at what coupling you've got in place that makes those tests difficult to write. 
José in his last conference talk mentioned almost in passing that the new changes to the compiler used for some of the metadata stuff for the better stacktraces could be applied towards new kinds of tooling. Since the language already has a syntax for types Typespec, it's not unreasonable to think in the future the compiler might start giving warnings around obvious type errors.
What is your problem with Alchemist.vim? Works for me (only it is a little sluggish).
I don't get omnifunc completions at all - I don't know if it's my machine setup or something else. I still need to try the older version that works with alchemist-server.
Are you using any autocompletion plugin or just `^x^o`?
I'm using deoplete. It seems like it might have some internal config I have to set, when I use plugin's `:IEx` shows a bunch of errors: `[error] Postgrex.Protocol (#PID&lt;0.260.0&gt;) failed to connect: ** (DBConnection.ConnectionError) tcp connect (localhost:5432): connection refused - :econnrefused `
for non trivial queries ecto is better, but one off User.first vs MyApp.User |&gt; first |&gt; Repo.one
I have been working on writing blogposts to fill gaps in knowledge on Elixir topics. My first was [making an example authentication system using Guardian 1.0-beta](https://medium.com/p/session-authentication-example-for-phoenix-1-3-using-guardian-1-0-beta-a228c78478e6) (all of the other examples I could find were pre-1.0-beta) and my latest one is attempting to de-mistify supervisors by [creating our own supervisor that monitors and restart dying processes](https://medium.com/p/let-it-crash-creating-an-example-supervisor-in-elixir-using-otp-36ea4236b02b). I will probably continue to write on more OTP related topics.
Would there be anyway to include versioning as part of the nodes? I guess different version could just be separate nodes. The reason I ask is mainly to due with some umbrella apps I am working on.
See the [typed Elixir](https://elixirforum.com/t/typed-elixir/1388) thread for one experiment in implementing type checking purely in Elixir macros.
I was trying to show how to work with Maps and Structs. I agree, probably example of using "age" was not the best. The better implementation can store birth date and work with it. If we abstract out of "age" and the particular implementation, I think the general idea of immutability to avoid side effects. Once you get data from somewhere and transform it into the data you want to present, that data should not be changed somewhere in the middle.
thanks. Fixed
How would you promote a build through a QA -&gt; Staging -&gt; Production pipeline with travis and gigalixir? 
At the moment no, as it's simply using xref to get the relationships. But in order for me to add support for messages, I'll need to analyse the beam files myself anyway. So I could easily pull the version information from the app file. So I'll definitely add support for that in the next stage. 
Damn I though Heroku was expensive, but $100/mo for 2gb of RAM?!?! No thanks Gigalixir. I'll stick to AWS, Heroku, or DO, or just about any other server provider.
Heroku force-restarts your app daily. There is no way to turn that off and it is completely unnecessary in the non-memory-leaky BEAM world. Gigalixir does not. You’re also paying for a service, not bare hardware. And for a one-man show, Jesse has been extremely responsive.
This.
&gt; non-memory-leaky BEAM world. That's a ridiculous statement. While I agree that daily restarts are not the answer, to claim BEAM has no memory leaks is just absurd.
Yes. It is possible to create a memory leak in BEAM. But it seems far more likely that you will inadvertently create one in a mutable/OO lang.
Can you even run something on 200 megs of ram?
Different branches. Only production branch can deploy. QA/Staging do not. Something like a gitflow.
I use [vim-elixir](https://github.com/elixir-editors/vim-elixir) and [alchemist](https://github.com/slashmili/alchemist.vim), combined with [ale](https://github.com/w0rp/ale) which runs [dogma](https://github.com/lpil/dogma) and [credo](https://github.com/rrrene/credo). Finally I use [YouCompleteMe](https://github.com/Valloric/YouCompleteMe). The whole setup works pretty well. The only thing that I lack is running my code from within vim.
Thanks! I'll see if I can get it working with YCM. 
Yep, without even tuning it out Phoenix API projects rarely exceed 200 MB ram as reported by the ECS container metrics.
Ah, that makes sense. I just realized I'm running on 500meg instance with os, nginx, postgresql, etc and it's just around 60% memory utilization. 
After using elixir for several months, I had to write some ruby. My colleagues reacted with: "Ever heard of early returns?" Turns out I'd unintentionally removed them from my vocabulary :)
Create/improve plugins for better Vim integration with Elixir. 
I've been looking for things to write blog posts about, maybe I'll make a short post about each of these.
"Ok, given these well documented tools, what do I do with them" is a rich vein of blog source material. 
I really want hot upgrades but they aren't currently working for me in my (mid-sized distributed) phoenix project. My app keeps state for recent activity and some other things within a certain time window so stopping nodes causes me to lose that atm. Since it's something of some interest I'll try to run one again in the next couple days and trouble shoot. Will bring the results back and see if there are any new insights or at least pass along the error output. Hopefully its not just some dumb thing I'd done
I thought this was helpful too. I basically just cleaned my dependencies and ran it again. https://stackoverflow.com/questions/34400665/phoenix-error-module-not-loaded-not-available
This looks sweet as heck. Did you style the website? How do you achieve that wavey look? 
MongooseIM 2.1.0 is out, and it introduces MongoosePush - that will help ops deploy and devs build push notifications in the chat system. This tutorial will walk you through setting it up and configuring it &amp; the client to work with it. 
That is actually the way of functional programming so not really exclusive to phoenix/rails. The idea being you have a set of functions that can cause action on a set piece of something as compared to a set of functions attached to a something. I personally love functional programming because of what you described above. the is_published function is no longer tied to @article and can be extended to many different types of data if needed(although often a bad idea)
They're just images with transparent backgrounds (pngs). Check out the background images for those sections and you'll see how they're done :) Thanks for saying it looks great though haha!
spacemacs is also pretty awesome :)
Hi! I am the tech lead of a new Elixir/Erlang project at Motorola Solutions and I am looking for team members that can join me in Copenhagen. These are the characteristics we are looking for: * Ideally you have experience with a functional programming language (e.g. Erlang, Elixir, Haskell, Lisp or ML) * If you do not know Erlang/Elixir you are keen to learn * You can design a highly performant concurrent application and know the pitfalls of concurrent programming * You know an imperative programming language (e.g. Python, C, C++ or Java) ​Strong ability and enthusiasm to learn new technologies in a short time
I am aware of that, just wanted to share the only thing i miss from when working with rails. It was kind of expressed in a wierd way where i could have just said that when writing views i miss that i had to write less code to achieve the same thing. Thanks for making me realize my previous comment could be seen as a bit wierd :)
Are you looking for part-timers/student developers as well, or only full time team members?
Remote work?
Lisp has been able to do this for decades. It's not new. It's the reason that, despite normally thought of as dynamically typed, Lisp compilers like SBCL are closer in benchmark performance to Java or C++ than to other dynamically typed languages. Look at it another way, how is this different from when you use a FFI to C from a language like Ruby or Python? The idea is that some code needs to be more strict and efficient while others need to be more flexible. Being able to control that when needed is a good idea for languages.
Remote work? Can a student/part-timer apply?
I've been learning Elixir recently if only for the merits of Phoenix and channels with highly concurrent capabilities, but the Nerves project makes me want to find an excuse to build a business that can leverage hundreds of iot devices. 
I'm not really convinced Nerves makes a lot of sense for IoT devices unless you're clustering them. My cursory understanding of 'IoT' is that for the most part the devices are independent and would communicate with a centralized location. In fact, elixir would be a great choice for a stack that would be responsible for ingesting data from a fleet of IoT devices. Having said that I'd love for some counter-examples if anybody has any.
So what is the footprint of BEAM with Elixir and/or Erlang compared to something such as Rust, Go, or C?
Thanks! I've got a few more apps which are good, I'll be updating the list tomorrow! Cheers! 
Hell with remote work! I'd eagerly move to Denmark to work at this position.
It doesn't look like you're supplying a timeout to assert_receive—if your test is exiting before the message is received then that might be your problem. I frequently run into it in tests. If you do assert_receive {:DOWN, _, _, _, _}, 500 Does the message show up in the mailbox?
it's probably not really fair to compare with C or Rust since they don't have a big runtime, but it'd be interesting to see a comparison with Go
It's not that the message is not being received, it's the the updates made in the body are not being made. i.e.: def handle_call({:DOWN, _, _, pid, _}, state) do remove_user_from_ets {noreply, state} end So in my test: Registry.register(worker) Process.exit(worker, :kill) # Registry handles message here assert_receive # of somesort (currently using the macro) # The user is still in the ETS table for another few millis. assert :ets.lookup(:registry, pid)
I will likely never run Elixir on my device but the backend is written in Elixir for these reasons and more.
Could you describe what you're trying to test more broadly? There may also be another way to accomplish what you're trying to do :)
I think it's a fair thing to compare... it's pretty important after all
Well with C you're pretty much only at the mercy of your own memory use and binary size. With Nerves, &gt; Pack your whole application into as little as 12MB and have it start in seconds by booting a lean cross-compiled Linux directly to the battle-hardened Erlang VM. It's not going on a micro-controller any time soon.
We are most urgently looking for someone to fill a full-time position. But we are also keen to talk to students looking for an internship or side-job.
Sorry, we are looking for someone to join us in Copenhagen.
Do you want students to just shoot an application your way through the full time application or do you have anywhere else you'd prefer I reach out?
Just send an e-mail to maarten &lt;dot&gt; faddegon &lt;at&gt; motorolasolutions &lt;dot&gt; com. Please include a description of what kind of position you are looking for and a CV (in Danish or in English). Thanks!
Cheers. I'll send you an email tonight!
Sorry, we are looking for someone in the Copenhagen area. We are most urgently trying to fill a full-time position. But we are also keen to talk to students looking for an internship or side-job.
Honestly, I thought it would be really cool to do that too but after looking at it, the cost is just too high. Nerves only supports specific chips and most of them are not production grade either. You have the raspberry pi, beaglebone black and lego ev3 as supported targets (not including a generic x86_64 and QEMU target). All of those are hobbyist hardware and have a hobbyist price tag to match. With hobbyist hardware like this, if you need a production run there is no guarantee that there will be enough units to actually support that run.
It's great for small sites. I'm working on a job board that is using Phoenix and Elixir and I keep the jobs in a GenServer as I scrape them instead of actually store them in a database. I re-scan the source 1 once a day and keep the details in memory. I limit how many jobs I have at one point in time, so that keeps the memory footprint low.
Is remove_user_from_ets a synchronous or asynchronous function? If you're just casting a message I wouldn't expect it to remove the user from ets for a few milliseconds longer. You can use :erlang.process_info/2 to inspect the mailbox like so: :erlang.process_info(pid, :messages) But as a matter of some opinion I think it makes for more brittle tests.
&gt; You can use :erlang.process_info/2 to inspect the mailbox like so: &gt; That's what I'm using in my current implementation (see the macro above). In the process I'm testing. Processes link to it, and when they die, it recieves a DOWN message, and clears them from the ETS table. So even though that's pretty fast, it still takes longer than it takes to test. So my process that's being tested needs to - Receive the message. - Lookup and delete the user from ETS. My process doing the testing needs to: - Link some process to the Registry. - Kill that linked process - Check that the message arrived in the Registries mailbox - Check that the process's PID is no longer in the ETS table. But it seems to take longer for the registry to process the message, and remove the PID from ETS, than it does for my test process to see the message arrived, and finished testing the ETS table.
I think the biggest issue Scala has as a whole (which you'll have to evaluate if its an issue for you on your particular project) is that Java will always come leaking in somewhere. Usually through dependencies. The two different methodologies don't go well together whereas with Elixir, Erlang OTP is building upon the same concept instead of flipping it on its head. That means that you don't have much more than a syntax change when going between them. This makes a big difference in the reliability of the application and overall complexity or mental effort required to understand the codebase. If you're project can rely on only Akka based technologies (and you can be sure that won't change) then I'd say theres nothing wrong with choosing Scala. However, IMHO, thats a hard guarantee to give for any real world project.
I use akka.net for around a year and have spent about a year playing with elixir. Pros and cons? Truly undecided. I spent about 15 years using .net so tbh i like the change. I found that there was a lot more boiler plate in .net. Traits in your world help a lot though. Mainly i love the combination of dynamic typing (or static if you choose), functional and actor model to be really helpful. In terms of when akka vs erlang i think the main driving real decision is about who around you will have to work on the code. Personally id elixir all the things. I just work faster in it. However i want to do it. The thing i like about akka is that clustering and distribution is something you do in lesson one. In elixir its something people talk about but then everyone is a rails dev loolking for a nicer way to write websites. It's a shame that you don't hear more about gossiping, the whole genstage and backpressure thing looks very good but most of the community doesnt use it a lot wheras in akka people are constantly attacking those styles and problems. So i find it very hard to compare directly tbh. I haven't gone back to .net in a year - just node and elixir. I'd imagine java will be the same.
Was Motorola Solutions part of the Zebra acquisition a few years ago? I'm unclear as to what parts of Motorola got siphoned into that besides the RFID/scanner divisions.
There's an experimental `credo` rule that can be turned on to force `@spec` on all public functions. You can modify it and bring it internal to also force `defp` to be `@spec`d very easily. This can then be turned into a build step, in combination with running `dialyzer` to force something along your lines. You can additionally turn things on like `--warnings-as-errors` and heavy use of pedantic`credo` rules to get to a nice strict-esque mode. 
Seems you're looking for :erlang.trace/3 http://erlang.org/doc/man/erlang.html#trace-3 Here's an example of how to use it: {:ok, error_tracking_pid} = ErrorTracker.start_link :erlang.trace(error_tracking_pid, true, [:receive]) ... # Some code that will eventually lead to the message you want to trace and wait for assert_receive {:trace, ^error_tracking_pid, :receive, {:"$gen_call", _caller_pid_and_ref, _args} }, 1000 # Check your ETS table here 
Something to be aware of with Akka vs Elixir/Erlang/OTP/BEAM if you're used to Akka is that Akka is based on cooperative scheduling, so if you block an actor, you block the underlying thread. If you have N underlying threads, you can only block N actors before you start being causing serious performance problems - you basically have to use other concurrency primitives, like Futures. In my opinion this gets very ugly very quickly. BEAM languages use preemptive scheduling*, so you can use blocking calls all you like and not have to worry about blocking the underlying OS threads. You also get per-actor garbage collection - the BEAM doesn't need to stop the world in order to collect garbage, Java usually does unless you use a nonstandard garbage collector. You ALSO get immutable data by default, which is really nice - you can get immutability in Java, but it usually involves more boilerplate and the runtime can't take advantage of the immutability. *: Not really in implementation terms, but for most purposes it acts like it. Read about BEAM internals if you want.
The only thing that Scala has as an advantage here is its type system. Everything else Elixir/OTP does better. And I'm saying this as someone who likes Scala and works with Akka daily. tl;dr If you don't mind dynamic typing, you should choose Elixir/OTP
I have a couple years of experience with Rails and just finished my last professional Rails gig because I'm interested in switching to Elixir and Phoenix. Other than rails and messing with a few JS frameworks my experience has been limited to OOP. Would you guys be willing to relocate someone from the States?
I would really love to work with you guys in Copenhagen, I do understand Danish (I'm Norwegian), but I still have some stuff I have to do here in Austria.
The tutorial uses compile time env vars to create a docker image, which is then stored in S3 with a public_read ACL. Am I missing something, or is this a great way to leak your database passwords?
Credentials open to public view? Sounds like something you should _definitely not do_.
&gt; http://erlang.org/doc/man/erlang.html#trace-3 This looks like something I could use. It just seems weird to me that this isn't something already done in ExUnit. It seems like a pretty common use pattern: Spawn some worker. Perform some action. Verify that the worker received some message, and did some work due to your action. In Rspec there's a `expect {}.to change{}.from(x).to(y)`. I feel like Elixir could use a `assert, do: fun() -&gt; :trigger_action_that_causes_message end causes(pid) to_receive {:some, msg}, and assert, do: fun() -&gt; :check_state_after_message_is_received end`. The syntax is not as elegant, but the concept is the same.
There's no reason you couldn't write a macro or dsl to accomplish that. Perhaps as a library to augment ExUnit? 
We are deploying our elixir apps with docker. the config files are mounted into it as volumes with bounded access. before starting we recompile inside the docker container. I am considering to test other ways as well like reading a config file on start. I think it is possible to set these values in the Ecto.Repo module. At least the adapter option exists. I didn't have the time to check for other options as well. 
Recompiling inside the container shouldn't be needed if using releases with REPLACE_OS_VARS and "${VAR}" configuration variables. 
If you have processes A, B, C, where B sends a signal (message) to C, the only way A can reliably know when C has processed the signal is if C tells A using a message. Inspecting C's message queue is not reliable because if you see 0 messages you don't know if C is processing the signal, done processing the signal, or if the signal just hasn't been delivered yet. Why not inspect the table in a loop until it looks empty or it hits a timeout, say 1000ms? Then the test stays simple and not closely tied to the registry's implementation details.
You still need to make sure the registry finished processing the message. An easy way is to call :sys.get_state, but any other synchronous call would do.
Good point. The S3 storage definitely should be private, we just didn't want to complicate this post. Though, will surely mention it and update. Thanks for the heads up!
Scala's type system is, as usual, an advantage just in the sales brochure. It stops being an advantage shortly afterwards, and then quickly turns into a burden. http://evrl.com/programming/scala/2017/04/04/scala-part-ii.html for more detailed thoughts. Personally, I'd avoid the language like the plague, never been happier than when I managed to introduce Elixir at my current company. Also realize that Akka tries to be dynamically typed. Square pegs, round holes. When I tried to use Akka, it felt somehow contrived and not really natural. If you like the model, go to the source, not some mediocre copy.
To be honest, the "good" garbage collectors by now are part of standard Java, at worst it requires some thinking about command line options and tuning. BEAM's GC is quite primitive and forces you to think a bit harder at times (like moving large amounts of state to ETS). On the balance, I think it's not a tie breaker - both systems work in this respect and both systems have seen decades of work on their memory management.
It's not really the right comparison. Erlang was built to control embedded systems, not to be an embedded system, so to say (it's soft realtime, for starters - that may for some systems be a larger bummer than its footprint). For a larger project, I could easily see an OTP system handling all the hard work of coordinating microcontrollers, sensors, humans, etcetera, while a networked system (using I2C or whatever) of microcontrollers does the "hard" work. I think Nerves is very much targeted at that. It's a no go on 100% of microcontrollers because it needs Linux, which needs an MMU, etcetera. Of course, for my home work, I am seriously considering whether I am still going to bother with C on the pile of AT-class microcontrollers I have lying around, when an RPi0 can be had for $5 and then I can stay in my comfy full OS environment :-) 
Exactly. For a hobbyist, it makes sense to by a bunch of RPi0s and not save $4 per &lt;whatever you're building&gt;. For a company, it makes sense to have maybe a longer development period but do save the $4 (or more!) between an RPi and a proper microcontroller. Also, don't try to drive, say, a stepper motor from something that can't do hard realtime - it's the simplest thing to do on a µC and quite hard if not impossible on an ARM system running Linux. The bad thing about this "IoT" meme is that it heaps all sorts of stuff together. I wish we could just ignore the marketing and talk about embedded systems and the classes of embedded systems we developed over the year. 
&gt; In elixir its something people talk about but then everyone is a rails dev loolking for a nicer way to write websites. That's unfortunately been my experience with Elixir, and it's extremely frustrating in a lot of cases.
It's not even the $4 in savings but the fact that there is no guarentee there will be availability if you need it. On top of that, they know they aren't targeting production grade hardware so they don't need to worry about breaking changes in hardware design because it might annoy a hobbyist but it could ruin a company. Saving $4 is great, but having a product that you know will be there and can continue on when you need to ship more units is much more important. Unfortunately rPi and beaglebone don't provide either the saving or the production line guarantees.
Then you can trace with flags 'call' and 'on return' and specifically trace pattern on the function that updates the ets table. Like I said, read the docs. 
BEAM is not the only, and quite likely not the best, option for embedded Erlang/Elixir - the alternative is GRiSP. It's BEAM ported to a real-time operating system RTEMS: https://www.grisp.org/specs.html
Yeah that's fair. It's really what I was trying to say, in that its not meant for everything. Only reason I still use microcontrollers and C is because of power usage and hardware costs. For hobby projects I'd do the same.
I’m familiar with the docs. I prefer to make tests not too tightly coupled to a specific implementation, as it makes refactoring difficult.
Why are you keeping so much state in ETS?
To each their own!
If you really think type inference is the big idea in Scala and only using it as "better Java" is "practical", than I can only conclude that you don't understand much of FP and wanted Scala to be an OOP language, which it quite frankly isn't very good at. Akka has high-level abstractions that are not dynamically typed and even raw actors now have a typed variant. The bigger problem here is the JVM, which isn't built for actors in particular, so certain things aren't enforced (e.g. preemptive scheduling, immutable data, blocking of system-threads), so you have to stick to best-practices more than on a dedicated VM (surprise!). Scala also doesn't have much to do with that, as Akka has the same APIs for pure Java as well.
I've been through this hell, and I'm desperately looking for a better way.
I went along this year, and I wrote up an internal blog post at work, which I've reproduced below. Sadly no links to the videos yet, as they weren't up at the time I wrote this last Friday, but you should be able to find them online soon. I’ve rated the talks from 1 to 3 on the “lambda scale”. Note the rating is my personal opinion on how interesting I found the talk, and I've only included the ones I classed as good or better (some didn't make the final list). λ – Good λλ – Very Good λλλ – Highly recommended **Opening Keynote: Automatically Scalable Computation – Margo Seltzer – λλλ** This was very interesting. Margo was one of the inventors of BerkleyDB, and is now a professor at Harvard. She was talking about their latest research project that tries to optimise programs over time by learning what they are doing and speeding them up. It was pretty complicated stuff, but very interesting, and they have shown some impressive results on certain cases of computation. **Flying Spaghetti Monster (Type Systems and Microservices) – Chris Ford – λ** Chris’s talk discussed how we can use emerging type systems to help reduce errors in distributed systems. He made the claim that “Idris is the hipster language of choice”, and that it could be used to implement some pretty advanced concepts, such as encoding the states of a Finite State Machine in the type system, so the compiler would enforce that you cannot make an invalid transition instead of relying on checks in the code. **Finite-state machines? Your compiler wants in! – Oskar Wickstrom – λ** This talk followed up very much from the previous one, and Oskar showed how by using more expressive type systems (first moving to Haskell and PureScript, and then to Idris), we can encode finite state machines and get compiler enforcement. Idris is mainstream apparently! **Infinite Lambda Calculus – Einar Høst – λλλ** I saw Einar and his co-presenter Jonas a couple of years ago giving a similar talk, but this time they had moved on, and in a very entertaining talk showed how you could implement recursion in the lambda calculus, despite it not having self-referential abilities. The entire talk was live coded and presented with their unique Norwegian sense of humour. Highly recommended. **Distributed systems: What can go wrong will go wrong – Anne Currie – λλ** Anne gave a talk on potential problems you can run into when trying to develop and deploy distributed systems. Based on her experience of working with them for the last 25 years or so, so told of the journey from distributed systems to monoliths, and the emergence of distributed systems again, but highlighted that most people working on them nowadays weren’t around the first time they happened, and so haven’t learnt the lessons from the past. She covered some interesting topics. **A Little Taste of Types – David Christiansen – λλ** David is one of the main Idris developers (did I mention it’s mainstream now?), but in this talk he introduced dependent types via a simpler language, Pie, designed to contain just the basics as a tool for teaching dependent types. **Keynote: Some History of Functional Programming Languages – David Turner – λ** David Turner (of SASL and Miranda fame) gave an interesting talk on the history and evolution of functional programming languages. He showed where almost all of the common constructs used in todays languages came from, along with some interesting anecdotes from him many years spent in this field. Should make a good talk to watch if you have an interest in functional programming languages. **Would Aliens Understand Lambda Calculus? – Tomas Petricek – λλ** An interesting talk, more on the philosophical and linguistic side than about programming. Tomas goes into the philosophy of what is mathematics, and what metaphors are required to understand something like lambda calculus. This talk makes a bit more sense when you consider that many people consider lambda calculus to be discovered, and not invented, hence the question “would aliens have discovered it independently?” **Peeling the Banana: Recursion Schemes from First Principles – Zainab Ali – λλ** Zainab gave an interesting and engaging talk that covers basic category theory and recursion schemes. She presented her code samples in Haskell, so a basic understanding of that might help follow along with the talk. One of the best implementations of the Factorial function you'll see :) **Colossus – The First Electronic Computer – Phil Hayes – λλλ** Whilst the title of the talk refers to the Colossus, most of the talk is about how British code-breakers tried to crack a German cipher during World War II, which frankly is more interesting than a talk about the computer itself. Incidentally, the details of the computer were a state secret until the year 2000! A very good talk, and one you should try to watch. **Closing Keynote: Winning the War on Error: Solving the Halting Problem and Curing Cancer – Matt Might – λλλ** If you watch just one video from this conference, this is it. At times he was speaking pretty quickly, but he had a lot to cover, from solving the halting problem in computer science to curing rare diseases. A very engaging speaker, and a great presentation to boot. You must watch this talk.
This is fascinating! Thanks!
Also since no one here seemed to mention it, your `fun` parameter is actually a block of code so your macro can do defmacro assert_received_by(pid, msg, do: block) do quote do # ... # Do this instead unquote(block) # ... end end ```
If you are only comparing Akka **Actors** to OTP then you may find Elixir to be easier. However there are more parts of Akka than just the actor components, and I don't think its fair that a lot of people here are dismissing Akka as a copy of OTP. For example, Akka Streams (which are my favourite part of Akka) were a big part of Elixir's GenStage (links below). Link to end of Jose talk where he thanks Akka Streams: https://youtu.be/srtMWzyqdp8?t=58m34s Link to blog post (CTRL+F "akka") where Akka team is given a shoutout at the end: http://elixir-lang.github.io/blog/2016/07/14/announcing-genstage/ 
Same here. It's great that we have a web framework like Phoenix, but I hope Elixir does not become synonymous with Phoenix like Ruby &amp; Rails.
&gt;I would like to use Elixir for backend stuff. What sort of backend stuff? What's your goal for making said backend stuff? It could be that Elixir is the perfect candidate for your project and the others aren't even worth looking at, or it could be the other way around as well.
I realized this like an hour and a half after posting. I apologize for the unnecessary vagueness. It'd be for the backend of web applications or any other applications where there could be a lot or even a mass of requests to handle at once. 
So why do you want a statically typed language? To slow you down more?
I’m not the other poster, but I like it because the performance is very consistent: http://theerlangelist.com/article/reducing_maximum_latency And because public tables work great as internal caches. So for instance I have a websocket client that connects to an external service and keeps a table updated with its state, which is then accessed when processing HTTP requests. Even if there’s a lot of requests, the websocket client is unaffected, so the system scales well.
There's advantages for both, but if you're dealing with backend application code having explicit types helps catch runtime stuff before you ship it for production. I don't really care that much about typing styles; if you can do both easily then you're at slightly more of an advantage than someone who can't. To get a black and white on advantages of both, there's [this](https://stackoverflow.com/questions/125367/dynamic-type-languages-versus-static-type-languages#125379) StackOverflow post.
Two things: first, does it need to physically log in as the user? Instagram has an api that you can use to do things like this. Not sure if it meets your needs but... Second, Instagram doesn’t like people automating things like this. It is likely against their TOS, so you might get punished for doing it.
You've identified pretty much my problem. Iirc, Instagram has changed it's API, so that actual liking is coming from the user. That's why I was using something like Watir. I'm not really worried about being shut down by IG. I doubt more than maybe 5 people will see it. I'm just trying to connect and put together a more intricate application than what I've built before. 
Call me arrogant, or obnoxious, or both - but to make up my mind about the discussion I don't need a StackOverflow comment, just my 40 years of programming experience (damn, I'm getting old). Dynamically typed languages have always won in terms of productivity in my experience. I can't actually recall any static programming language that made me whistle through code - it's a theoretical advantage, mostly, that in my experience never pays off in practice.
What you're looking for is using OAuth with Instagram. Check out https://github.com/omniauth/omniauth-instagram
I'm not trying to use Instagram as a authentication system. I'm storing usernames and pws and at a later time having them like each other's most picture at as close to the same time as possible. 
This is pretty thorough for a free course: https://elixirschool.com/en/ The guides on the official Elixir and Phoenix pages are great as well. The most helpful free guide for me isn’t an Elixir course at all, but an Erlang one. Learn You Some Erlang is quite good, but you will have to connect it back to Elixir once you finish. The good thing is it isn’t that hard and it’s helpful to learn the Erlang syntax anyways
To first learn the basics of functional programming in elixir I recommend [programming elixir](https://pragprog.com/book/elixir13/programming-elixir-1-3), very approachable and doesn't overwhelm with advanced concepts. From there the [programming phoenix](https://pragprog.com/book/phoenix/programming-phoenix) book takes you through the web framework and some Ecto database coverage. It's worth learning Ecto in depth, it can be a very powerful tool. [what's new in Ecto 2.1](http://pages.plataformatec.com.br/ebook-whats-new-in-ecto-2-0) goes into some more explanation than you get in the docs.
Now is a [free weekend on Code School](https://www.codeschool.com/free-weekend), you can start learning here. Anyway buying a books (programming elixir and programming phoenix) will be better option than that.
I would write this as a long-running process, GenServer in particular that auths on init, and I would probably use tesla for the http client for this use case. See: https://hex.pm/packages/tesla
Have you looked at the guides at https://elixir-lang.org/ and http://phoenixframework.org/? I found them to be surprisingly informative compared to the homepages of other languages/frameworks, but they were one of the last places I looked.
I've spent some time looking in to doing it this way and I think I might give it a try. I see that I can use tesla to log in with Instagram. What about integrating with JavaScript? For instance I can log in and navigate to the instagram user's recent media, but to actually like the image right now I wasn't able to use a headless option in Rails (that I found) because of the JS.
This is excellent, it should be part of core. To use a function in a pipeline it needs to return a value to be used as input to the next stage. That’s incompatible with a result tuple as a return so you end up making compromises like having a ! function wrapper for raw values and a plain version returning a tuple. I’d like to see the pipeline operator unwrap an {:ok, value} tuple automatically. On the article though, there is a feature of Elixir which is designed to work like a Result monad: *with*. If you have a pipeline of operations where one operation depends on previous results rather than values use with: ``` with {:ok, value1} &lt;- fun1(), {:ok, value2} &lt;- fun2(value1), do: value2, else: raise “oops” ``` With is like an adult version of |&gt;. Doesn’t look as cute but it’s much more capable. 
Sorry but to me Phoenix is similar to rails only in superficial ways and the developers have indicated they want to make the distinction more pronounced. I think the first time someone will realize "this aint rails" is when you try to add authentication. You will find no official or even endorsed solution but a hodge podge of community added apps where none has taken the full lead.. Unlike Rails you are on your own. You might like that. I don't as for something like authentication on a new programming stack I like some guidelines for security. I am not sure how the developers think someone new to Elixir is going to be in a position to even evaluate whats secure and whats not. From there it won't take much time to see that functional languages are a whole new thing that requires you to bend your mind around if you are not coming from that background. You are also going to bump into some dissonance in training - The vast array of training , and SO questions and answers you find for rails you will not find for phoenix as is only natural given their time on the scene. However for your stated goal of expanding knowledge Elixir is a good go but just don't expect to be doing a vast array of applications with it. Its sweet point is - I would say - its extraordinary concurrency performance because of its Erlang roots. To me its a specialty language and framework but if you need or want apps that need high solid consurrency and scaling like I do thats not a put down. 
with doesn't treat the tupples like a result monad. though it is certainly valuable solution. I personally don't use it because it is too flexible. e.g. ``` with do: {:ok, %Item{}} &lt;- get_item(), ... ``` If get item an ok tuple will end up in your error handling code and possibly passed through. or you have error handlers matching on ok tuples, I think very odd. `OK.with` deliberately raises an error if anything other than the expected value or explicit error is returned
It doesn't but it achieves the same result without simulating monads. If `get_item/0` in your example returns something other than `{:ok, %Item{}}` it will end up in error handling code or raise a match error by design. If you wanted to accept any struct you could match a map: `{:ok, %{}}`. @spec get_item() :: {:ok, %Item{}} | {:error, any} Would have dialyzer report the mismatch if `get_item/0` returned the wrong type result. It depends on what you consider odd. Optionals/generics/monads aren't a feature of Elixir but pattern matching is. To me a simulated monads are more odd than pattern matching comprehensions, in Elixir anyway. In Rust and Swift I use monads for this as they are a convention of the language. I still think |&gt; should unwrap result tuples. I'd be ok with |} as a pipeline operator expecting to unwrap a result tuple if there wasn't a clever way to have |&gt; do both. That would make pipelines way more useful more of the time.
There are other libraries that do result tuple pipelining, eg [ok_jose](https://github.com/vic/ok_jose) 
"Yeah, lemme just copy the docs real quick and know I have an article for my blog."
You may find what you're looking for in here https://hexdocs.pm/httpoison/HTTPoison.Base.html
What do you mean by API wrapper? Do you mean just a calling an API from inside some software of your own? If so, all you need is an HTTP client (HTTPoison is excellent). If you need something more, we'll need more description of your needs.
I've used this library for a few test projects. https://github.com/teamon/tesla It seems like an interesting way to go. I've been making a wrapper around the govc binary but it's returning some odd values for some commands. If you're making anything public I could send some issues or pull requests your way.
I usually endorse everything Stephen Grider does and this is only a partial exception. I got this course and the content is great but it's nowhere near as lengthy and complete as his other courses in javascript. He doesn't go nearly into as much depth in this course and it really left me wishing for more. 
I really appreciate the info. Thank you!
I refunded it. It takes a lot of understanding to go from Object Oriented programming to Functional. I'm working through the Programming Elixir book by Dave Thomas and it's awesome. Stephen in that course simply dives right into syntax while failing to explain any sort of reasoning behind it. I'd stay away, personally. You have to learn how to "THINK ELIXIR" not just type out functions.
I'll check that book out. Thank you. 
The Dave Thomas book is definitely my defacto reference for elixir. Every elixir dev should read it once, and also do the coding gnome video series from him.
yeah, thought so, I was just curious if there is any good-practices or how-to on writing HTTPoison clients...
yup, just calling an API from commandline tool, format the output in various interesting ways (like JSON dump, format to CSV etc.), stuff like that, just to get hang of Elixir by using it to write something simple.
that library looks interesting, altough I am not quite sure how much it offers over using the HTTPoison... certainly, if I can get something presentable together, I'll stick it on my github, right now I am knee deep in API docs :)
Yep, HTTPoison is the way I'd go; it's simple and straightforward. I've written a few clients in it and have found that if it's just a call to a path or two I use the `get` etc functions, if it's something with proper restful structure, I use the `HTTPoison.Base` mixin.
I've done most of this course, there's some good info in there and I liked the small side projects. If you are new to programming it's probably a great series, however, as an experienced ruby/rails developer I found it *really* slow. I was running this on 1.5x/2x speed just to get to the main points. I ended up buying the Pragmatic Studio course instead and found it much more engaging and helpful: https://pragmaticstudio.com/elixir
Can second the Programming Elixir book. I also come from a PHP/JS background and I find very easy to follow. Some of the new programming paradigms are real eye openers!
I can't recommend this course any less. It is by far Stephen's worst work. There are only two projects. It teaches Phoenix 1.2 instead of the newest version. It doesn't cover a lot of topics. Stay far away.
I'm half way through this course right now and came to recommend it. It's awesome for someone with prior experience. 
Docker has a place, but I don't think Elixir deploys are where its at anymore. I use to be in this camp and did our deploys this way, but since we've switched to using a build server + distillery and beam deployments I won't ever go back.
Not new to programming but new to functional programming (which makes me feel new). I going to check out that pragmatic course now. Thanks for the suggestion.
That seems to be the theme of everyone who reviewed the course. Definitely am staying away. Thanks!
I've got this course and although I haven't made it very far in yet I think it should be a solid buy. 
Looks like there is a sale happening on pragmatic studio. 40% of all courses with coupon code ```THANKS2017 ```
I'm on section 9 lecture 70 and I think it's pretty great. Hadn't touched elixir or backend programming much in general and I feel the course is doing a great job explaning the how and why of both elixir and phoenix.
Definitely wanna hear your review when you're finished with it. 
Went through it... And I simply cannot recommend this one more! As someone who has been programing for a while now, I found the little projects (like the image one) to be truly a fun experience. I enjoyed the instructor, as he isn't monotoned and doesn't glance over topic's like how many Udemy instructors tend to do.
I generally find HTTPoison to be not a great library, and especially the Base module. It adds a lot of needless macro redirections that make debugging code significantly harder and quite hard to follow the control flow of the program unless you're intimately familiar with HTTPoison. My proffered approach is using raw hackney, it's not really that much more code. If you really want something with more bells and whistles, Tesla is much better than HTTpoison.
Well, I made some tests on the GitHub API and indeed Tesla looks very nice, especially authorisation using the client feature can come in handy... I will most probably try different approaches, as this is my first project in Elixir and it´s not a critical app...
It was updated earlier this month with a new section on Phoenix 1.3. I haven't checked it out myself but yeah, I wouldn't recommend it either. 
You can use distillery with docker. For all my production systems it goes: 1. Push to Gitlab 2. Gitlab ci builds an image(by compiling the app using distillery) and runs tests against it 3. Gitlab pushes image to registry 4. Gitlab triggers helm update which pulls from the registry and cycles the nodes for no downtime updates Thanks to libcluster I still get application clustering on kubernetes too and stuff like kube-lego/nginx make life easier though for the later case most people aren't deploying regularly to new domains like I am so probably not as important.
It was a section on how to update your app from 1.2 to 1.3. That course was incomplete for like a year, and at the end there was this half-hearted attempt to finish it from him. I just don't think he liked Elixir.
Just bought the Pragmatic Studio Elixir + Elm bundle a while ago based on these recommendations! Super happy so far, thanks!
That was my impression too, that he's just not into elixir. He keeps saying stuff like, "Phew, that was some nasty code!"
The course is too slow. For any level, in my opinion. Very inefficient use of time. That's my feeling about most all Udemy courses: they could be condensed to 1 or 2 hours if composed efficiently, as are videos on egghead.io. There seems however to be a competition whereby each course must be 10, 20 hours, 30 hours, or the value isn't there, when the opposite is the case. 
I would suggest trying exercism.io. There are around 80 exercises. It does assume you know another programming language, and can search for stuff in the Elixir documentation. It's not really for beginners, and you need to be decent at algorithms. But it does force you to create programs (short ones, usually 100 lines or less) which many courses don't do a good job at.
I started doing that. I’m having trouble cause I’m not the greatest at algo’s and having to do them in a functional way makes it a little difficult right now. I’m gonna get through exercism though. I should probably start a study group for elixir with it. Thanks for the advice. 
Author here - I think the backend story is much more developed at this point for sure. While I still prefer C for most everything embedded related, I could definitely see using Elixir as a local IP coordinator or a gateway bridge between the internet and some local mesh network. Maybe one day!
When I wrote this, I had in mind the specific use case of edge routers/bridges. Most of the time in industrial applications, the actual sensor devices will be on some pretty small micros and use something lower powered than WiFi directly. You will need a device to translate whatever it is they are using (ZigBee, LoRa, etc) into the higher-level IP network while also serving features to local users (like an admin panel). Handling lots of concurrent asynchronous messaging while serving dynamic web pages sounds like the perfect fit for Elixir to me.
Totally agreed! The tooling is not where it needs to be to support high-quantity production right now. Since Nerves uses Buildroot, it would be possible to spin your own board support package, but most folks would rather use established build chains. I would love to see them target something like the low power i.MX chips or similar for production level systems.
Agreed! I hope the article did not portray that I think that all systems should use this framework (or any framework); there are a huge spectrum of requirements in the embedded world and I will not be putting down C any time soon. I think Nerves could become a great option for things like gateways and am hopeful for its future, but there is no such thing as a silver bullet in this space.
I just moved to elixir and this is exactly what I was looking for. Thanks for helping me out!
I've stopped looking at Udemy completely for this reason. I feel like the courses are long and drawn out, and not to mention when they offer 90% off their courses, but they still cost the same as competitors it makes me feel like I'm falling for a dumb marketing ploy when I buy their courses.
Kubernetes + Jenkins it's working fine for me 
I bought that too. Pretty happy with it too.
Glad that you have found it useful!
Same experience here. Would have been far better off never having made a Udemy account. In fact, for anyone reading, if you want to learn something programming-related, don't go on Udemy. You'll find far superior resources online with a simple online search. Grider is better than most all others on Udemy, but still I've found his other courses to be infuriatingly slow and repetitious. And I'm neither an experienced developer nor a great programmer.
Hah. Agreed.
Couldn't you just link directly to the article instead of linking to a Twitter post linking to the article?
That was a nice looking Trello board 
This is exactly how I learned Elixir and Phoenix and [posted the source code to my side project on Github](https://github.com/acconrad/peergym) in case anyone wanted to see one of these real life side projects from the ground up
I always find it pretty annoying when people say that you shouldn't learn for the sake of learning, that instead you should have a problem in mind to solve. On the contrary, I like to learn various languages so that if I encounter a problem I know what tool to use.
Oops! Sorry about that, will remember for next time.
No worries, thanks!
I think he's highlighting the difference between learning _about_ something, vs training yourself to become familiar enough with it to use it. Eg, I follow the /r/rust subreddit, read many blogs about lifetimes and the ownership model, was very excited when 1.0 was shipped. But could I actually sit down and write a program in rust? Nope :) 
I learned Elixir this way, great advice. I picked a project that interested me personally, contributed to some dependency OSS projects, have a talk at my local Elixir user group meeting and had a senior level job writing Elixir full time by the end of the next week. Don’t let your current job dictate your next. 
You can only learn a language by using it. If you don’t write code you don’t know shit.
h
thanks! Didn't find this on google so had to ask here. 
This might be the shortest, most helpful comment to exist.
Pro tip: since maps implement the Enumerable protocol, you don't need to call `Map.to_list/1` at all. Just pass the map directly to any function that accepts an enumerable and you'll enumerate every `{key, value}` tuple. Conversely, you can convert from such a list back into a map by using `Map.new/1` if you know it's a list, or `Enum.into(enumerable, %{})` if you're not sure if the enumerable is already a map.
Ignoring unexpected query params may lead to subtle bugs. You can use `reduce_while` to signal an error while processing the params and return a 4xx response.
I've made about half of it. I like it. At least it is definitely worth these $10 (during the promotion period). I think you need to take into account that that is a workshop and not a course. There is a difference. The good part is that you are practicing to do the apps together with the instructor. The other part (can't call it bad), that this workshop should not be a single source of information for you. It should go hand in hand with a book or other resources. Regarding the book, I would recommend Dave Thomas book. It not only contains the explanation of the topics but also asks you to do the exercises. By doing them you can dramatically increase your level of understanding.
Another learning technique is a "koans-based" approach: basically writing focused unit tests (or integration tests) on something that I want to dive in. I'm publishing that online [elixir-playground](https://github.com/thbar/elixir-playground/blob/master/test/koans_test.exs), which is a nice way to show that you're involved into a language since some time (useful to get gigs etc). This works even with very limited time (e.g. 15 minutes per day), helps keep a momentum even when time is scarce, and is less heavyweight compared to a side project in my head.
&gt; elixir-playground Yesss, I like this approach as well. Writing tests is a great way to take notes. I've been thinking about the "heaviness" of side projects too, and my conclusion is to keep the side projects as small (and demo-able) as possible. Some of my hobbies (like making games in [PICO-8](https://www.lexaloffle.com/pico-8.php)) encourage this miniature approach to projects.
Yeah, I didn't care much for Base in HTTPoison or HTTPotion either. So I've been writing a little something specifically for building API wrappers and composing REST calls, based off Elm's HTTPBuilder. https://hex.pm/packages/http_builder Comes with adapters for hackney, HTTPoison, ibrowse, and HTTPotion. (It's still early days for the module, so any feedback is appreciated) It basically builds up a Request object, then passes that off to your chosen adapter to make the call. The adapter contract is loose, which I have mixed feelings about. But you can do a lot with HTTP responses, and the goal of the library is to make composing calls easier - what you do after the call is made is up to you.
Any reason to use this over Plug? Cowboy has HTTP/2 support so in turn so does Plug.
How big is your app? Do you find it works for serious production level stuff? I'm building a payment gateway and I'm considering it.
This project was started before Cowboy 2.0 was finalized and that 2.0 release took a very long time so I was not relying on it. Ace is in Elixir so the code is accessible to Elixir developers who are not yet comfortable with erlang. Also the Raxx interface is much simpler because it is pure. Of course at the moment there are far more prebuilt plugs and then phoenix so if looking for convenience then Plug is the answer.
Using tentacat (GitHub API wrapper) to search all public repos containing dot files to find the most popular plugins. With rate limiting, it's about a 24 hour job to process all users per dot file. I think it's a good example for a supervisor /genserver app. Phoenix/Elm front end to follow for reporting.
just started learning erlang maybe 2-3 weeks ago, only now getting into elixir and it's a smooth transition, so now learning phoenix from the hexdocs and book. So basically nothing, but I did want to implement some interview-style algorithms &amp; data structures for practice in either language sometime soonish. 
Some gems like devise, where you bundle install.. run a generator.. migrate and you are good to go. Recently, I had to use counter caching.. which is 1/2loc in rails.. not so straightforward with Ecto. But overall it’s satisfying to see tens of micro seconds response times as opposed to milliseconds in rails!
Still working on my sci-fi MMO. I have the server running on a lightsail server and my Unity client up to date in terms of server features. Currently adding more features to the server to make my way to beta.
That sounds very interesting! Can you give us a list of features or a more detailed description of what you can do/will be able to do it?
Sure. Each player begins with a board containing 19 tiles. The center tile contains a system, for now just single planets. Theses systems can have infrastructure built up which provides resources on each turn. Turns are automatically generated over time and are used for various other actions like building fleets of ships. Fleets are made to of groups of ships and have 2 main jobs, scanning, which allows you to find a new system on an empty tile, and combat, which includes invading other peoples boards and plundering their systems. Of course the invading fleet can be fended off by a fleet of the owning empire or even another enemy fleet. That's the gist of it. That's other features like being able to sell and buy resources on a market. Alliances, which I'm not sure will fully entail. Archaeology, which will allow the player to explore their systems for artifacts that can be used in a crafting mechanic. And more!
It’s not invitation only. Should be straight forward to sign up
I signed up without issue using my Github account. Should just work (TM)
Mostly, getting things ready to broadly introduce Elixir at work early next year. It’s a corporate gig, and our current languages have a lot of convenience tooling around our specific stack and platform. So the past few weekends have been spent documenting existing tools, writing deployment/CI guides, and throwing together a couple libraries to handle feature-parity. Because when I finally give my tech-talk, I don't want to have to finish with "… and working with our current infra might take some effort". So, on that note - I reworked my HTTPBuilder library a bit: https://hex.pm/packages/http_builder - It's a library to help compose HTTP calls and write SDKs, based off Elm’s HTTPBuilder. Early this week I revised the HTTPClient adapter contract to focus on building the request, without handicapping the response (and maybe went too far? Hrm). I also added three more adapters - it now supports HTTPoison, hackney, HTTPotion, and ibrowse. I also wrote and published CFEnv a couple days ago: https://hex.pm/packages/cf_env - a cloudfoundry helper/convenience library for parsing, and retrieving the JSON values stored in the CloudFoundry environment. Yesterday, I started working on a smoke testing/health-check Plug middleware that specifically fits in with our blue-green deployments. Still have a few libraries to go!
Added a [plug based demo application](https://github.com/mbuhot/open_api_spex/blob/master/examples/plug_app/README.md) to open_api_spex. API with swagger 3.0 and swagger UI and no Phoenix required :) Redesigned [ecto_job](https://github.com/mbuhot/ecto_job) interface so that jobs are just maps, not MFA tuples. Coupling queued jobs to module names in code makes refactoring more difficult.
Not sure if I would consider it cheating, however your current functions are really just wrapping a pattern match assignment. What you wrote: [head|tail] = list However you will want to cover the other cases, these could easily be function definitions as well. example: x = [1,2,3] x = [] x = [4] case x do [] -&gt; nil [head] -&gt; head [head|_tail] -&gt; head _ -&gt; :error end or: defmodule ListHelper do def get_head([head]), do: head def get_head([head|_tail]), do: head def get_head([]), do: nil def get_head(_), do: :error end ListHelper.get_head([]) ListHelper.get_head([1]) ListHelper.get_head([1,2,3,4]) ListHelper.get_head("something")
pattern matching is OP so wanted to consult what others here thought about that, okay yeah I guess it's the most straightforward way
Are they expecting to see you have detailed knowledge of the underlying data structure? Or that you can simply build an interface like that? Cause it's a strange question in the context of elixir. As a list is actually a linked list already, so are they wanting you to simply wrap some functions around that? If not, maybe try building an implementation from another type (like a tuple or a struct). 
I would definitely call that "cheating". The module gets compiled to Erlang bytecode, which the VM will then execute. You can see what bytecode will be generated by disassembling the function. For a module called "Test" with a function "head" that takes 1 argument, do: `:erts_debug.df(Test, :head, 1)`, and look at the file "Elixir.Test_head_1.dis" that gets written in the current directory. In this case: ``` 000000001D2602F0: i_func_info_IaaI 0 'Elixir.Test' head 1 000000001D260318: is_nonempty_list_get_list_frxx f(000000001D2602F0) r(0) x(0) x(2) 000000001D260328: return ``` So, your head function is a wrapper that calls Erlang's built-in ["get list element"](https://github.com/erlang/otp/blob/db67b2c3d1198b2093cb9add3aa55c59bb368ab5/erts/emulator/beam/instrs.tab#L635) function. It's not an implementation - it's just calling a built-in implementation. Broadly speaking, you can't implement linked lists in Erlang, because the language does not support pointers. You should try doing it in C, it will be much more useful for interviews and give you a better understanding of what happens inside the VM for languages like Erlang/Elixir.
If someone would ask me to implement a linked list in Elixir, where a linked list is pretty much a primitive, I'd probably wish them a nice day and walk away. Having said that, I'm sure that if you'd really wanted the job, you could do it using 2-tuples as cons cells. At least you wouldn't be cheating :-)
there is no 'they', I'm just flipping through typical interview questions and wondered how it could be done in a functional language. I don't think it's really so appropriate since it's so fundamental to erlang
I see. Well in that case, if you're looking at it from the scenario that you have some algorithm you want to implement and you plan on utilising a linked list, then what you've done is the right way to go about it in Elixir (using the list term). If you're trying to familiarise yourself with the underlying details of a linked list, then I'd suggest just reimplementing it using one of the other types (or if you're feeling up to it, make a linked list protocol, and provide an implementation for it using many different types), that way you're exposed to more of the underlying details behind implementing one. 
&gt; Broadly speaking, you can't implement linked lists in Erlang, because the language does not support pointers. You should try doing it in C, it will be much more useful for interviews and give you a better understanding of what happens inside the VM for languages like Erlang/Elixir. You don't need pointers to implement a data structure that acts like a linked list. While you won't be able to quantify the same performance guarantees as an implementation in C, you can still implement the basic logic behind one. If you were taking a very literal approach, you could do it using structs. Defining a struct that conforms to `t :: %MyList{ element: any, next: t | nil }`. Or if you wanted to make it a more functional approach without using lists, possibly could use a tuple conforming to `t :: { any, t } | nil`. Or something along those lines (many different ways it could be done). 
I said "broadly speaking" because you can always simulate mutability with ETS, but it's useless as interview preparation (IMHO). The point of linked list questions is to see if the candidate understands pointers.
It doesn't have to be mutable though. As already mentioned a list in Elixir is already a linked list (in fact lists in many functional languages are implemented as linked lists). An implementation of a linked list just gives you some algorithmic guarantees, such as how efficient it is to get an element at a certain position, or inserting or removing an element at a given position, etc. So even though the VM may reference count certain values, or copy other values, it doesn't really matter, as be algorithmic complexity of your implementation remains the same (at the abstract level). Actual performance of the implementation will certainly be different, but it's still a valid implementation. 
My point has nothing to do with performance or complexity. I’m saying interview questions about linked lists are meant to ask about pointers, and Erlang doesn’t have pointers. The tortoise and hare algorithm for instance makes little sense with immutable cons cells.
Phoenix uses some OTP under the covers, but you won't really need to worry about it too much for a simple web app. I say go for it and dive in. When you want to run some job in the background, or use channels, then that might be the time to read more about OTP. 
I started using Phoenix within a day or two of wrapping my head around Elixir. I mean, I really know next to nothing about either one, but I'm doing okay so far. I'm not saying you should do that. That's just what I'm doing. And it's going okay. I don't even know what OTP means.
If you're not familiar with MVC frameworks like Phoenix, you should spend some time getting up to speed. The guides do a pretty good job of getting you on your way, though.
Okay thanks!
I am familiar with MVC. I have used Laravel and Django(which is close enough xD).
LOL SAME. I don't even know what the acronym means yet. I haven't gotten that far in my book :)
You don't really need to know OTP before starting on phoenix. Having said that, once you start implementing more complicated apps, especially using channels, you'll probably want to familiarize yourself with OTP, and also ETS to a lesser extent.
It helps to briefly look at plug, which phoenix builds on. Eg build a hello-world API with Plug.Router and Plug.Builder. It took me a while to realise that the Phoenix Router and Controllers are also plugs, and that you can route to any plug, not just Phoenix controllers. And Controllers can define a plug pipeline that runs before any handler functions. 
Oh my, you are already dangerous.
Wholeheartedly agree with k-selectride!
Elixir is still exotic enough that some companies may not let you choose it to implement code. I'd think you want to solve the problem in Java, Python, or C#. You don't want to go into an interview and find out that you're not allowed to pick the language of your choice.
safety first
Okay I will take a look at OTP before I try real-time stuff.
Why the decision to have each player/entity it's own gen_server? What type of protocol does the client use to connect to the server? 
Having each player/entity be a genserver is probably an anti-pattern. Processes aren't objects in the contemporary OOP paradigm. Now granted you know more about your game than I do. But it'll probably be easier if you store entities as maps/structs in a genserver, or ETS table (depending on how many separate processes will be querying). The simple reason is, imagine if you have one process that needs to get information from N entities at one time, where N ~ 10^3 , it would have to send N messages each time. Easier to just store it all in a single data structure and only have to send a single message. Of course, you will need to be wary of memory pressure due to copying large pieces of data back and forth from message passing. 
I don't really know why I thought of this, I just assumed it was the right way to do it. The server listens for tcp socket connections and receives packets (separated by newline) which then can be processed for whatever they need to be (a move command, a spell, etc).
That's a good point. When I was doing a simple erlang test, everything was stored in an ETS table and it would query the data as needed, but I assumed that was not ideal.. funny how that sometimes works out :) As far as memory pressure, I think I can be smart about what data it returns, so it doesnt copy the entire entity (for example if I want the id's of all entities in an array, it can just return that). Thanks!
I think it would probably depend on the type of target server. Are you trying to build the lightest weight thing in the world? maybe that's perfect. Want to just build a rock solid API with endpoints for clients to communicate with? Phoenix channels would probably still run on anything lightweight that you would want. So I guess it's more about what you want to learn / do. What goal are you trying to hit? Just learn the language / have fun? Or spruce up your knowledge with OTP / beam VM / gen_server. I think a good analogy might be something like: So you want to make a hamburger, why are you going out the pasture to get the cow when you have a butcher a block from your house?
I'll look into this, but I am not exactly sure I understand. Opening a socket connection and sending a message separated by a newline is as about as simple as it gets. Do phoenix channels offer something simpler than that?
It wouldn't be simpler in implementation per se. But you *could* get a lot of benefits to it. Like will there be a web client. Or a view or administrative actions? Will there be an API to look at? Using plugs for tcp might just be the simplest. 
I see what you mean, the web api might want to do some of the same things as the client, so the overlap would be "for free" doing it this way.
Yeah. I do a lot of projects just for fun to exercise certain things. So please don't take it as me trying dissuade you. 
Afaik you can simply use the tools Ecto provides, such as schemas and changesets. If you do not want to use a database for your project, simply don't start the Ecto subapplication. [This](http://cultofmetatron.io/2017/04/22/thinking-in-ecto---schemas-and-changesets/) article shows how you could use it. I'm sure there are other libraries just for data validation, but I just like using Ecto's tools.
I have a MUD written in Elixir and I landed on having rooms essentially be my unit of concurrency. So each room is a GenServer, but within a room all monsters / characters / items are just part of the room GenServer state. When a character/monster moves from room to room their state is removed from one room's state and added to the next etc. This way I still have a lot of concurrency, but since most interaction between entities takes place when they're in the same room it's easy to just handle that in one place. I haven't thought through how you'd translate that to a 2d graphical rpg but it might give you a starting place to think about.
Don't need to know anything about OTP if you're making simple CRUD apps. Phoenix guides are pretty good especially if you have experience with Rails/Django/etc. Looking at existing Phoenix apps helps tremendously. Like https://github.com/hexpm/hexpm or the one I built: https://github.com/GBH/loaded.bike
That's a good idea. The issue is a world is one big "room", and so it'd be impractical to combine it. Thanks for a good starting point.
As far as timers go I wanted everything to be realtime (as opposed to traditional muds that had a global tick every n seconds). So one character might swing their weapon every 1.5 seconds, another every 2.1 seconds, frequency of hp/mp regen can vary etc. This is pretty easy to do in elixir with Process.send_after if every entity is a process, but as I mentioned my entities are just data in room processes, and naturally I want their timers to just work as they move from room to room. So what I ended up doing is having each room have a timer and that timer is set to fire whenever the next thing in the room has to be done, so the room has something along the lines of a Room.next_action(room_state) function that returns the reference (via make_ref()) of the entity the action is for, the name of the action, and how many ms from now the action should happen. Then the room does a Process.send_after calling a function with that information which handles the action and then queues up a timer for the next action. If the entity the action was for is no longer in the room that's fine, just queue the next action. If an entity moves to another room the room checks their actions and if something for that entity is set to happen sooner than the current timer for the room it just cancels the timer and starts a new one.
Ya, my original plan was for "send_after" to be used as a timer for various events, but tied to the entities themselves, but as other posters have said, this might not be a good idea. that's interesting approach, but I think would become too inefficient when dealing with thousands of events firing pretty frequently, especially because the equivalent of a "room" would be the game world, and the state would be much larger to continually be passing around (or is this a misunderstanding on my part?) 
Calling a function with a large piece of state isn't passing it around, if you're sending messages with large bodies that makes copies of that state and can be inefficient.
oh thanks, that does help a lot :)
I've used vex before on a project. It's ok, but I'm not crazy about the API. https://github.com/CargoSense/vex
I'm sure it "Should just work", but unfortunately it just doesn't. On top of that, the admin email seems to be a dead end. &lt;sigh&gt; Thanks
Ooh, got a link to the source?
I'm working on my own game and also recommend using Phoenix Channels. There are some benefits that I've come to rely on. For instance, you can create different types of message types very easily as Topics, I have a general 'update' message that contains state updates and 'info' messages that are basically alerts, like you've just been invaded. You can also build on top of that with their broadcasting system and have many clients subscribed to the same channel and send messages to all of them. This works great for building chat. Phoenix also has a Presence library which allows you to track who's online. I'm sure you can see the benefit to that.
You can always section off the world. I don't know the structure of your game, but splitting each dungeon and city and anything else that makes sense into its own process would work well.
Honestly, from what you've described, and the few crappy throw-away games I've built in phoenix (shitty checkers, has no king condition), there's no reason why you couldn't just use channels for your backend. No need to muck about with too much genserver stuff
It’s an interesting problem. Might consider asking around /r/gamedev, stipulating that you’re using a functional language so the typical patterns may not be ideal.
the gen_server is what will be keeping state for things.
Ya, I have done quite a bit of game dev stuff with C++, so I am struggling to think in a new way while doing this :)
bought.. thank you
FWIW, I toyed around a bit with the Entity-Component-System (ECS) pattern in Elixir. I landed on having every Entity be a GenServer, but a pretty passive one - basically Systems are the active processes (they do the work on deciding what happens, that's also how ECS is supposed to work), but with having all the Entities being processes Systems can simply send messages to them and all the actual updating and bookkeeping then happens in parallel. So more a freebie "if this runs on an 8-core machine, it's nice and quick" than actually putting behaviour in genservers that would represent players and objects etcetera. I still need to write something larger than a toy example with it, but the small experiment (an overengineered Pong ;-)) showed that this works well and code is nice and clean. 
WombatOAM? Hasn’t that been around for years?
Thank you so much for making this post! it really helps newbies like me!
Thank you! Feel free to reach out if you have any questions. 
Thanks for writing this! I have almost exactly this problem, streaming records from an Ecto query into both CSV and XLSX files. I looked at implementing a forking operation by using processes and sending the record to both sinks, but it has the problem of potentially filling up the mailbox. Using Collectable and Stream.into looks much cleaner.
Hi, I'm sorry to hear you're having trouble signing up. I looked and can't see any emails from you, can you let me know your username please? Thanks.
This seems like a great approach. I like some of the sanity-checking that dialyzer provides but often forget to add method `@spec`s. A rule like this would let a particular project decide that they were important for their style, without forcing the core compiler to make decisions about what a `strict` mode is. It also allows the possibility of there being multiple type-checking systems that operate solely as external libraries. Dialyzer is great, but what if another project comes up with different type semantics that work well for a certain style of project?
Nice tips and examples. Pattern matching is one of my favorite features of Elixir that I really miss in other languages. I use `if/else` so little in Elixir it almost feels like a code smell.
I got on by logging on via GitHub. Turns out my mail provider was blocking the messages, and they weren't even making it into my spam folder. Thanks
Hmm, what email provider is that? I've not heard of any of the big ones doing it as of yet.
It would be easier to do pattern matching if guard clauses gave you more flexibility to call functions from arbitrary modules.
Definitely gets slow for me too, but based on output I think its based on how each call is appending to the IEx history %IEx.History.State struct... the history IEx is using isn't enabled by default but is available with a param config in OTP20+ I beleive, and I turned it on, guessing you did also, though you'd think if that were the only issue it would effect Erlang shell also. Maybe the two calls aren't quite equivalent though and in erlang that call is only one line of history, but somehow in IEx it seems like every seperate call to Process.info is winding up as a seperate item in the History struct.
there's some good reasons they can't, as i understand it.. you can use macros as guard functions and use list literals, but no dynamic length lists for instance... the compiler needs to guarantee the code in the pattern match terminates, and if you call arbitrary functions you run into the halting problem :-)
Could you please open up an issue so we can investigate? Thank you.
Sure thing, Jose. Just wanted to make sure it was a real issue, and not just something I was experiencing before opened an issue on GitHub. I'll open up something now.
Yeah, that's why I was unsure whether it was a "bug" or not. It's certainly not something anyone would ever need to do in a real world app, but I figured it might be a symptom of something else, so maybe fixing looking into what's causing this, would help fix/improve some other stuff. I don't think it's just a case of appending something that's creating a large chunk of memory, because a few times I was playing around with it, it run Process.info a few times, it returned each time, but seemed to keep eating memory, even after the function returned, which seems like something that shouldn't happen in FP (especially since this function doesn't seem like it would have any async stuff in it).
Yeah ideally we'd confirm no such behavior with history feature off, I assume it wouldn't append to or include the struct at all in that case, I actually posted on elixir forum how to turn on the history feature recently.. maybe I'll verify in a few
I went and opened an issue here https://github.com/elixir-lang/elixir/issues/7080 Also have a potential PR ready, but that's really just vanity in kind of wanting a chance at getting a PR merged into Elixir core :-)
It's thru Yahoo, but it's not a yahoo.com domain (although I'm not sure if that matters). 
It does, it's a data point, thanks. Well try to get someone to test with a Yahoo email. Thanks!
I’m thinking about doing it. Though I haven’t had the time yet :) I’ll post here when I get some solutions up.
holy fuck someone teach that guy some web design
There's subreddit: https://www.reddit.com/r/adventofcode/ first two challenges look trivial. but im a relative elixir noob. will take a stab tomorrow. 
https://github.com/jfornoff/advent-of-code-2017 Wouldn't call myself an expert, but I'm getting paid to write Elixir 
Another tip when publishing a package is to tag releases in GitHub and set the `docs: [source_ref: "${version}"]` config in the mix file to match the tag. This allows users browsing the docs to navigate to the source at the correct commit. 
I'm an Elixir noob doing it... I'll post mine once I'm at a computer
https://github.com/sotojuan/advent but I'll probably go slower than most as I'm busy.
Shell_history is to store typed commands on disk so you can reuse them between sessions, and is built into Erlang (Elixir does not care about that flag). IEx Shell history is a different mechanism, probably used to remember commands and their results within a session.
I guess that's fair, but maybe it makes sense to link them? and not store history in IEx at all unless also storing it in erlang shell_history, since the result can potentially be to blow up the process over time, in some pathological (and maybe realistic?) situations.
“You can hammer a nail with a stone, but how many carpenters use them in their work?” While the first day problem was almost perfect for programming language operating on lists with pattern matching (aka most functional programming languages). The second day was made for AWK or Excel, you operate on rows and columns which is dead simple in tools that I have had mentioned. My solutions can be found in my repo https://github.com/hauleth/advent-of-code-2017
Here’s mine: https://github.com/matthewoden/AdventOfCode2017 I’m trying to do more with recursion and binary pattern matching. 
I don't think they should be linked. The shell_history flag is useful for systems that don't have a writable disk. It's not meant to disable history altogether: the Erlang shell itself keeps in-memory history no matter if that flag is enabled or not.
Thanks for the tip, got me back in action. Side note, I am a Linux user, so only adding dep / loading was required. 
Oh interesting... Though if that's the case it's weird the above problem wasn't an issue/didn't slow things down in erlang bit did in iex. I should test whether my "fix" actually fixes anything, I didn't get around to that yet, wonder what else could be the problem if not? Or maybe erlang puts it in an ets table and iex should also? Curious if anyone knows/will try and investigate a bit.
IEx stores shell history in the evaluator's process dictionary (which gets dumped by `process_info`), while Erlang stores it in a separate process. You'll get the same issue in Erlang if you do `{links, [Pid]} = process_info(self(), links).` to get that process, then repeatedly call `process_info(Pid)`.
Started here: https://github.com/Linuus/advent-of-code-2017
Honestly, what OTP stands for isn’t even indicative of what it really is. Don’t worry about what it means and just understand what it can do. 
Interesting. That makes sense. That's why I was hesitant to call it an issue, as I assumed there was a logical explanation. At the end of the day, I really shouldn't be running a debug command so many times. What mostly raised a flag for me, was the difference between what I saw in the Erlang vs Elixir shells. But your explanation makes perfect sense. Either way, it was a good learning experience. Thanks for the explanation. 
Getting paid to write Elixir? Does that mean you're being trained to learn Elixir for your job?
I'm employed as an Elixir programmer, yes :-D
But you said you weren't an expert? So your company lets you learn on the job? To contrast, because there are so many Java programmers out there, few companies would let someone learn Java on the job (at least, from scratch). On the other hand, there are companies that realize there aren't a lot of, say, Elixir (or Clojure) programmers, so they might hire someone that seems bright and teach them. Just curious if that's what is happening.
Will this be recorded? I am interested but I don't live in UK. :/
Hm I guess you could say that, currently finishing up my masters degree and doing the Elixir job on the side to pay my bills. Not that I was explicitly hired to learn Elixir, but of course there is continuous improvement of everyone's skills involved, since it's a fairly young language and most people are relatively inexperienced
From a quick look at the code, this case doesn't seem like a good fit for tuples. Try using maps instead. They should have better performance on modify.
Oh I like this idea a lot.
I tried with arrays and it was slooooow. Switched to using maps where my keys are indexes and it was done &lt;1s. https://github.com/d4be4st/advent-of-code-2017/blob/master/task5.exs
Wasn't Jose against the idea of a standard formatter? I remember him saying on the mailing list that a standard formatter is a limitation on ways to approach problems. Wonder what changed his opinion.
Looks like some good changes!
Earlier in the language the style was still being developed so creating an official formatter would limit the style from developed and improved. The style we have now is consistent and stable enough that a formatter makes sense now.
Great to hear! Do you have any feedback? Anything you’d like to see in the next post? We’re aiming for February as the next installment.
Yeah, makes sense. 
Switching to maps helped. I'm now down to ~12 seconds d4be4st Not sure what your input was... but on my input your solution took roughly as long as mine (12-13 seconds) BTW my code after changing to maps: https://gist.github.com/ynonp/7fd9279c7cbdd1052656a846ba3f6d09
I really like your day 3 solutions. I'm stuck on part 2 myself.
Yeah, day three gave me trouble, especially part two. I refactored the walker into its own method so I could focus on the “business logic” of the solution. Apparently there’s a mathematical sequence that’s an easy(?) solution, but I’m not that clever.