Exactly the reason why we started the project.
&gt; properly reloads when files change This sounds like your trying to couple your test to fs too much. 'Properly reloads' sounds like a function to me, or some pipeline of functions. I would test that the function(s) act as expected under expected circumstances. &gt; doesn't crash on improper file format Again, I think you're coupling your tests too much to fs. Why does "doesn't crash on improper file format" involve fs? That sounds like it's a single function that takes the file format and either returns :ok, or :error. &gt; correctly parses data This also sounds like a single function that takes the files contents, and returns the parsed data. Why does it have to involve fs? Maybe all of these functions and your interactions with fs live in one module. If so, consider splitting them out into something like FileParser and FsWatcher. That way, you could test the FileParser seperate from FsWatcher. You should aim to make your functions pure, and push impurities to the outside of your application. If you really cannot seperate the two and it all has to take place in one module, consider taking fs as a function parameter. Modules in elixir are first class citizens and can be passed around. That way, your functions are still pure, and you and inject anything you want during testing. 
I don't need use the name `File` of the module Interactive Elixir (1.4.1) - press Ctrl+C to exit (type h() ENTER for help) iex(1)&gt; cd "Documents" /Users/pablo/Documents 
`clear()` and `pwd()` are other nice IEx.Helpers functions, though the warning about omitted parens make them a bit awkward to use bare.
It might be nice to silence the omitted parens warnings for the IEx.Helpers to facilitate this kind of usage.
I came to Elixir basically because it looks nice compared to Erlang. I love the Erlang/Beam vm model, but i can't stand writing Erlang code. So i was pretty excited to basically be able to write Ruby that compiles to Erlang. 
&gt; I wanted a language that could modify it's own AST. Any particular reason?
thank you :)
I really liked the video :) is the calculation so slow, though? It get why adding a cache is an nice example of holding state in a GenServer, but from looking at the formula it's premature optimization :D
I appreciate the advice. I'm going to work on moving the interaction with files to be separate. After thinking about what you said, this at least seems simpler than my current implementation 
It reminded me a situation with CoffeeScript. It was advertised as JavaScript replacement, a magical code that compiles to JS, but it failed in terms of adoption and devs now prefer ES6. I am a little afraid that the same thing will happen to Elixir and devs will prefer Go.
im still building FarmbotOS https://github.com/FarmBot/farmbot_os and contributing back to the Nerves Project when i have time: http://nerves-project.org/ and i recently started building my personal website with phoenix: http://porkinternet.com/ its not much yet but is going to be a html5 web game of some sort when i finsih
s/method/function/g
I wonder if game servers is a direction Elixir could grow in.
http://www.mz.com/ : these guys built their realtime games pipeline in erlang
I hope escripts will become more popular. Pattern matching and recursion have helped me solve many problems with little effort. I've already been able to sneak it into my job on several occasions. 
[removed]
Getting a 500 on their website. 
Excellent article!
[removed]
league of legends chat infrastructure is in erlang
Not sure if I understand. You say you have not looked into Nerves, but say Elixir is a great language for these applications. How do you get to that conclusion? Just want to understand this better, not trying to be a jerk.
Not a good start for a demo of Elixir 😂
The benefits of interest to non tech decision makers are the productivity (lower costs) and reliability (better value over time) while allowing for affordable scalability as/when needed without inducing upfront costs to achieve that.
Productivity benefits can be attained via established technologies like Ruby/Rails. AWS makes scaling dirt cheap and relatively risk-free when compared to going with a new language/framework. Elixir's problem when trying to make the sale to non-technical people is that there are solutions in place that are as good as elixir with the name brand already in place. Most applications won't experience the scalability issues that elixir solves, so that's a big risk to take, from their perspective, to solve a problem they don't even have yet. IMO, the way to make the sale to them is to praise its reliability, which you mentioned, but also that you get the productivity gains from something like rails with the speed of something like java for the UX. 
I dont think we disagree.. it is a package deal thing. E.g. RoR does not provide the same scalability or reliability advantages. Whether you need that today or even ever is a moot point when you can get it "for free" (nothing is ever really free ;) and mitigate that future risk entirely. Similar arguments can be made for other solutions. It really helps that Elixir is extremely well suited to the sorts of software a huge % of teams are writing these days, and that fp and other topics elixir champions are accepted now. Unlike technical ppl, non-tech decision makers are both used to and generally good at making fiull-package benefit decisions. (Generalisations, exceptions abound, but ime generally true.) Brand name absolutely helps but most tech starts without that. Small wins build brand and Elixir is doing pretty well there actually with an increasing number of publicly visible wins. Taking those wins and using them as supporting evidence when pitching the package argument can work at a higher rate than elixir's current market share (which means growth is there to be had). Yes it will not convinced everyone now, but growth only requires an accelerating rate of adoption which is certainly achievable here. (This is not purely hypothetical; I have seen this work in practice. :)
Yeah, I think that we aren't disagreeing either. I would argue that choosing to use Elixir is not a "Freebie" by any stretch of the imagination. You need to hire elixir developers, of which there are few, so building a team may be very tough if you're looking for quality. It may just not be there in the labor market yet. And I don't think ignoring the scalability issue is a moot point either. Start-ups ignore issues like this all the time because the most important thing is time to market. Enterprise level companies can probably afford to take the hit, though, so that might be where the energy to evangelize is best spent. You do make a great point that elixir and phoenix are well suited for the types of software that are needed today. Websockets are going to change the internet. It's only a matter of time. Your argument does break down a bit here, though: &gt;growth only requires an accelerating rate of adoption which is certainly achievable here. You're basically arguing that growth just requires growth. What were you trying to say there?
Choosing to adopt a technology, especially a new one, is indeed not free.. that is true of any tech, suited to the task or otherwise. So having a good set of compelling "out of the box" advantages is key. I agree with you on startups. Most fail. No surprises. Many revisit their choices later. Elixir can do well as that second address-the-shortcomings choice. At the same time there are a hell of a lot of established companies not well serviced by their current choices. Lots of opportunities there. As for the growth comment.. I find many look at new technologies and consider growth to be a matter of eating the world right from the start. Thus is largely because we tend to hear only the tail end of success stories, skipping the long boring slow beginnings that led there. And this leads to a common expectation of early riotois growth being necessary, let alone realistic. Stating the obvious it may well be, but recalling that big-g-Growth is nothing more than accelerating the rate of adoption in the early days can be useful in checking those expectations. 
They're probably not using Elixir for their website; Phoenix has a default 404 I believe.
[removed]
[removed]
Looks close to what Microsoft at some point tried to do with ASP.NET. Everybody hated it, and it prompted Mr. Spolsky to write his famous "Leaky Abstractions" article.
I've seen a couple articles of where a company rewrote a rails app in phoenix and saw they were able to scale down from something like 100+ to ~10 instances. Similarly, someone I met at a local elixir meetup said they were able to reduce their scaling by quite a bit just by re-writing a bottleneck in their rails api in phoenix. Ended up saving them like $10k a month just from that.
The internal convention for the projects I work on is to simply alias each dependency in each module. The goal is to be able to tell from any file where a given function is coming from. We even delete the web.ex file that Phoenix generates because it hides imports. Import is also discouraged, but import/only is OK when it improves readability. 
&gt; Certainly you won't see a lot of exclusive elixir/phoenix dev positions, but that's to be expected. I rarely see any job posting that is exclusive to only any one language. 
Maybe. and Maybe. I think the macro part is dependent on how you go about approaching things outside your own view of the program. If you are the only person using it, then go ahead and do whatever. If you plan to, or even think it may happen, release this module into the world, then I'd keep away from macros. That's my viewpoint.
To be clear, I'm against unclear macros. If you're asking about how to properly apply a complex macro then I'm not going to be much help.
Performance heavy tasks could be delegated to C, C++, or even Rust via NIFs. https://github.com/hansihe/rustler https://github.com/goertzenator/nifpp See https://github.com/McEx/McEx for an example. That way you get the benefit of OTP and hot code upgrades, _and_ you get to keep your shared codebase and efficient code.
Yes! A bit late, but there's an easy way to do that: opts = [foo: "foo", bar: "bar", baz: "baz", qux: "qux"] pops = [:bar, :baz] {optional_args, remaining_args} = Keyword.split(opts, pops) # &gt; {[bar: "bar", baz: "baz"], [foo: "foo", qux: "qux"]} 
I think anything which isn't JVM-based will struggle for adoption. Businesses know how to reliably deploy and manage apps on the JVM. It's a solid, proven tech stack, and it's getting faster all the time.
Uhm, what about Go then? I think it's well past its "niche language" stage, and it's not a JVM language.
Any feedback helps.. and your feeling is more important than my data. I would love your opinion on the platform itself, if you give me 2-3 important topics for you I can send you a link... you never know it could be more interesting than expected..
Good points, thanks!
At square enix, do you guys use elixir for anything else?!
I'm playing with event sourcing / CQRS in Elixir. Every aggregate gets its own process, which cuts down a LOT on DB queries and building up aggregate state and eliminates the big performance penalty of having an aggregate with a lot of events. IMO it's a good showcase of OTP's strength. It's a bit of an academic exercise at the moment but I'm hoping to use it for a project some day.
I would take a look at Elixir in action, it does a good job on explaining a wide variety of topics and it doesn't take long to read.
I have a similar background and read Programming Elixir. It was a very good resource and I didn't feel like I needed to be retaught (many) basic concepts 
This is the best answer. Sasa does an amazing job not only introducing you to the language, but also teaching you how to think when building an OTP application. Coming from OOP you'll need to learn functional programming, the BEAM's semantics, and finally OTP design. Elixir in action does a good job smoothing out the transition between each of this topics.
[I feel similarly](https://www.reddit.com/r/elixir/comments/5s22ob/best_resources_to_learn_elixirphoenix_in_2017/ddg6fed/). Elixir in Action all the way. 
Definitely Elixir in Action. It is thorough, whilst also being concise.
Totally stolen from here: http://erlang.org/pipermail/erlang-questions/2006-June/020777.html But it works! (using erlang modules) :application.start(:sasl) :application.start(:os_mon) :memsup.get_system_memory_data You can also execute commands from elixir using the System.cmd/2 or System.cmd/3, like so: System.cmd("vm_stat", []) # in Mac System.cmd("free", []) 
Thank you! This works perfectly.
The [little elixir and otp guidebook](https://www.manning.com/books/the-little-elixir-and-otp-guidebook) is another one that doesn't spend too long on the basics before getting into the interesting stuff.
Been looking for something like this. Some of these projects are well maintained. 
For learning Elixir I would suggest looking at Elixir in action. Other suggestions in here are also pretty good. If you have a lot of OOP experience then I would also suggest having a look at http://learnyousomeerlang.com. Programming in the Elixir platform is a bit different than architecting an OO application. Even though some concepts can be used interchangeably, you first need to come to terms with processes and message passing. A process is not a class/object, a concept that you are familiar with. You also have to accept that message communication is unreliable (unlike a a method call). I think Fred's book does a good job in explaining how and why do you model your solutions in that way. The current momentum in Elixir is amazing. However, we must not forget to remember that it is *not* just a faster ruby. I always prefer to say to people that _modelling systems in an actor/process based platform is all about resource pools, nano services and their interactions_. If you've developed or maintained any distributed system before, you should get the analogy and the pros/cons of the paradigm.
You're welcome.
I'm an experienced developer who's been working with Ruby for the last 5 years. I've been reading "Programming Elixir" by Dave Thomas and its really good so far. It has a good balance of reading and exercises. It feels like it is written for people with experience in other languages who are coming over to Elixir rather than someone learning a first language. 
Hi, You may be interested in Exercism (http://exercism.io/languages/elixir/about), its like URA or Spoj, where you can find several exercises in several languages. When you resolve a problem, you submit your solution and your solution becomes available to anyone on Exercism community, so you can find several ways other people used to resolve the same problems. I found Exercism to be a valuable source for Elixir Tips &amp; Tricks, because people resolve the problems in so many different ways, and you can see their solutions, that's wonderful! You can find some program samples from from my GitHub: https://github.com/frbaroni/exercism/tree/master/elixir
What do you mean with "programs"? Applications that run on terminal? Applications that user interacts directly? Any code that encapsulate a state? It is important to define that, since elixir is fp and the examples you gave are imperative and oop. Most of the things you would expect from a language like java, python, ruby, can't be expected from elixir/erlang. First of all creating an elixir application are related directly with OTP, since an application is an abstraction inside the OTP principles. To create an out of the box application in a fast and direct manner, I can suggest you this "how i start" written by José Valim: http://howistart.org/posts/elixir/1 The Getting Started guide is really good, and if you do the Mix and OTP section will help to understand more: http://elixir-lang.org/getting-started/mix-otp/introduction-to-mix.html
Since I am used to thinking about programs with state, then something along those lines. I'll take a look at your links.
Yeah, basically: https://hexdocs.pm/distillery/upgrades-and-downgrades.html#a-word-of-caution TL;DR: you depend on library authors to put in extra effort and have to be super careful yourself. If the internal state changes without correct upgrade procedures in place you will have a bad time. Most stuff I build is used from mobile devices that loose the connection from time to time anyway so we rather put the effort in to make that work nicely instead of optimizing one part of the system that doesn't have a lot of impact on the overall experience. If one was dedicated to doing such upgrades there is the possibility, but most apps don't need it IMO.
there are a few other oauth libraries that might get you closer that haven't been mentioned yet. I always look here first https://github.com/h4cc/awesome-elixir
This will only get you started on all those questions I think but check out on the side menu below the main elixir guides there are a bunch of guides focused on OTP architechture http://elixir-lang.org/getting-started/introduction.html. For the Phoenix question, it isn't a matter of OTP or Phoenix I wouldn't say. Phoenix is an OTP app and if you delve into I think under lib or priv there is a module that lists all the supervised processes you are running. If you go through installing most ETS open source libraries you'll add them to this list. You would get used to the design principles over time and refactoring toward them seems pretty easy in most cases but I hope someone lists a good fast resource for design principles here. I read Joe Armstrongs erlang book as he has a great way of explaining things that I appreciate and he is now a fan of elixir btw
In languages that don't support tail recursion. Sounds like he's doing a talk to OOP people/people who don't really know what recursion is.
Erlang/OTP has a lot of tools for concurrency, and processes are cheap, but you don't have to use them. That is, the best way to architect your system is to look at the "natural" concurrency in your system and organize around that to the extent possible. As Joe Armstrong says, "We do not have ONE web-server handling 2 millions sessions. We have 2 million webservers handling one session each." (http://joearms.github.io/2016/03/13/Managing-two-million-webservers.html) If all your requests are independent, then you can write logic which handles each request in a single process. The tricky part becomes sharing state. In traditional web applications, that state is kept in a relational database, and it becomes the bottleneck. So whatever we can do to move state out of the db, particularly transient state like sessions, can be a win. Normally we would use something like Redis or Memcached, but in Elixir we can keep state in ETS. ETS is the solution to a lot of scaling and coordination problems. It provides fast, concurrency-safe storage to applications, and is something that everyone should learn about. Beyond that, OTP has standard mechanisms for making standard independent components, used to keep state or do something concurrently. So you get GenServer as a generic server and more specialized services to handle state machines or events. If there is much logic at all, a good way to architect things is to create a GenServer module for the server lifecycle callbacks and a stateless library module to handle the logic. That makes a clean separation. http://learnyousomeerlang.com/ is a very good introduction to Erlang and OTP. Applications are how you package independent components, sort of like gems. So if you have a component that has a standard interface and can be reused between projects, then put it in an application. You may have issues about startup order, but the best way to deal with it is to make the system resilient to problems, i.e. https://medium.com/@jlouis666/stacking-theory-for-systems-design-2450e6300689#.1j497zusw Umbrella applications are interesting when you are not sure exactly who is the "boss", e.g. you are making an embedded communications device which talks to some hardware and uses Phoenix for the UI. These parts are loosely coupled but still managed and deployed together. Phoenix generally has very good performance, so you are unlikely to have scaling issues initially. The scaling approach is to avoid having unnecessary bottlenecks, e.g. every request is serialized through a single GenServer which you put in because you wanted to be cool :-). Look at HTTP layer solutions, e.g. HTTP caching with Varnish or ATS. Maybe put the state in JWTs, e.g. http://lucumr.pocoo.org/2013/11/17/my-favorite-database/ Beyond that you are looking at problems of shared state between processes or between servers in a cluster. The Erlang community has been dealing with this kind of thing for a long time and there are interesting tools to help scale applications across across a cluster of machines and manage them. Phoenix chat's presence system is powerful. There are nice libraries like https://github.com/uwiger/gproc or systems like Riak http://basho.com/products/ (or Riak Core). 
I think you're wrong about the JVM. There are plenty of languages that are using it, but Java is by far the only one driving it. Java might have ~17% on the TIOBE index but probably half of that score is maintained through raw inertia. Sooner or later Oracle's practices and the shear weight of ugly enterprise Java codebases is going to cause that number to collapse. IMO we're going to see a long tail emerging. There will always be a few big standard languages like C and C++, but there will increasingly be a healthy market and community for languages that solve more specific problems. It's going to be a good time to be in the business of rewriting decrepit Java codebases. 
Exercism has very basic problems and very boring ones.
Hi. Is there any list of topics it covers so far? I have a pretty good understanding of language syntax so far and I would like to see more advanced/practical topics. Is it similar to the [elixirsips](https://elixirsips.com/episodes.html) list?
Études for elixir has all the basics and a couple of apps towards the end: http://chimera.labs.oreilly.com/books/1234000001642/index.html
&gt; I am looking for some resources that cover these topics, so i can read up on that stuff later when i have built some basic stuff. Can you give me some recommendations? I think the best resource for the kind of doubt you have is the [OTP Design Principles User's Guide](http://erlang.org/doc/design_principles/users_guide.html). If you is comfortable with the concepts of processes and genserver, I think it will be easy to read the [Erlang Docs](http://www.erlang.org/docs) I guess it would be good to know what do you understand as "OTP". Do you mean the Supervision Tree structure? All the vm resources(like, ets, dets, mnesia, gb_tree, gb_set, gen_fsm, gen_server)? The point is, the BEAM and the OTP has this many resources and is design in such a manner that it is easy to design a system that doesnt rely on outside sources(I mean, outside of BEAM). But addressing your points directly... &gt; When should i use OTP and when is it overkill? The question should be "why wouldn't you use otp?". Using or not, the resource is still there, inside BEAM. Doesn't matter if you dont use it, the moment you start the vm it will be there. &gt; When should i use Phoenix and when is it overkill? Do you need a resource/abstraction that is inside Phoenix? Use it. But to talk about "overkill" you must set a base point. Are you thinking about Phoenix compared to other frameworks? Or are you thinking on Elixir options, like using [Plug](https://hex.pm/packages/plug) directly, using [Maru](https://hex.pm/packages/maru), "pure" OTP application? &gt; What parts of my project should go into a separate application? The beauty of building an OTP application is that if you structure your Supervision Tree delegating responsabilities to the right "branch" of the tree it can easily be splitted into different applications, I would recomend this talk by Jose Valim: https://www.youtube.com/watch?v=B4rOG9Bc65Q &gt; How can i structure my Phoenix project into separate applications, like a Umbrella project in Mix? Chris McCord addressed that exactly here in this keynote at ElixirConf 2016: https://youtu.be/qPiZTxUAaVM?t=21m58s &gt; How can i apply DDD principles using OTP or Phoenix? You can use it to design your Supervision Tree. I think the Jose Valim talk and the OTP Design Principles link will help with that. &gt; How do i scale OTP and Phoenix applications? Are there Routing frameworks available? Phoenix applications is easy, it already is prepared to communicate with another nodes. If I remember correctly it is done by Phoenix.PubSub OTP as a whole, you can start any GenServer as a global resource, so it will start only one even if you're running a cluster of nodes. Again, it relies on the way you organize your Supervision Tree.
[It was also posted](https://www.reddit.com/r/PostgreSQL/comments/5tzitf/is_postgresql_good_enough/) on /r/postgresql 8 days ago and there's a small discussion there for anybody interested. There's an even bigger discussion over at [HackerNews](https://news.ycombinator.com/item?id=13641377) too.
https://github.com/boldpoker/edeliver
i guess since i use phoenix i could use GitHub or Travis CI post to my phoenix app with some security verification and have it git pull and run recompile. guess id have to run migrations manually tho 
oh man that looks really cool. 
I've been use http://nanobox.io for my personal projects (its free for personal) and I like it a lot. It gives me room to expand in the future, while keeping it dead simple for getting the app "out the door". EDIT: Also, their slack channel is incredibly personable and helpful. Tyler and Sander did a great job of helping me whenever I needed it. EDIT2: Err sorry, meant to mention this. They have hot-code upgrades on their roadmap, which would solve your problem.
If the goal is to test yourself and your problem solving skills, then this is a valid point. Since OP is asking for CS1 and CS2 types of questions to help learn the language and Excercism is a great resource for that, this point is not valid.
+1 for Nanobox. I use it for development and deploys (but I'm also a part of the Nanobox team, so I might be biased :) )
The Nanobox page for Elixir says it's still in the process of being implemented on Nanobox... and is looking for Elixir experts to help. (Can I? :) ) It certainly does look cool! I want to try it out
Elixir is used in highly concurrent, fault tolerant systems. It's built on the erlang VM and compiles down into erland code. Erlang runs roughly 50% of all the telecommunication systems in the world. There's a web framework called Phoenix that is built with it as well. Phoenix is rails-like, but with much less magical, hand-waving involved. Phoenix also makes websockets darn easy to implement. Elixir does not enjoy a wide audience at the moment. Consider this Sub's subscriber count that of r/ruby or r/rails. There aren't many jobs yet. There is buzz though, and a lot of people who were big in the rails/ruby community have come over here and are working in Elixir. It might be the next Ruby/Rails, in which case jobs and salaries might sky rocket if you know it. Those are all compelling reasons to learn it. Beyond that, it's beautiful, fun, and a way to program that, once you wrap your head around it, makes development dead easy.
The 3D-mathy-collisiondetection-pathing bits are computed on the client, not the server, and you specifically are attacking the idea of a "game server". It would be prohibitively expensive to do all the 3D computation for all the clients on the server.
I'm by no means an OTP expert (so feel free to correct me), but you can always opt for something like poolboy to manage a pool of processes if you do not need state, while still keeping that fact hidden from the 'interface consumers'.
If that is the case, then why do things like PunkBuster and other countercheat techs still exist? If the server is the ultimate authority in all cases, then it will override anything unless it itself is hacked
Well, there are certain cheats that are impossible in a well architected game, like unlimited health. Since the server knows what the real health value is, you can't convince it otherwise. But there are cheats like hooking into the graphics drawing routines to make walls transparent (wallhacks). There are also plenty of cheats that use information your client technically has access but doesn't display, like ESP hacks. In reality, your client has positional data on enemies around you (for movement prediction purposes), but if they're behind walls the client of course won't render them. But a hack could read the memory of your local game instance and draw indicators on screen, revealing their positions [(example)](https://www.oldschoolhack.me/hackdata/screenshot/4edab815781002f784c1426d1aa0f300.jpg). A hack could also use positional data to move your crosshair to their head (an aimbot). There are also some grey-area cheats where you could replace the textures of the game with solid colors to increase visibility and give you an advantage. Client side anticheat like punkbuster do things like verify the integrity of game assets and make sure nothing is hooking into the game process.
You're right, it is a tough problem but we have experience with it - Erlang. Members of our team have actually been involved with Elixir/Erlang for a while. Two members of our team provided the groundwork for EXRM (@tylerflint is called out in the exrm readme) using patterns we established in creating releases for our Erlang projects. Edit - just reworded a few things
Wow! Very nice!
Yes pooling will relieve the synchronous bottleneck. I just question the need for any new processes to be created if there isn't any resources to manage or state to maintain. In the common scenario of web apps running on cowboy connected to a database with Ecto you've got each request being processed concurrently with a pool of connections to the DB. The code you write in the middle can usually be stateless functional code transforming a request into a response.
You could use hot code upgrades. A simple demo is [easy to setup with distillery](https://hexdocs.pm/distillery/walkthrough.html#building-an-upgrade-release). However, things become more complicated in practice, for example if you have stateful processes, or change the shape of your supervision tree. Testing the upgrade is also not trivial, so I usually advise that this should be your last option. If you want to minimize your downtime, you should run your system on multiple machines anyway. If that's the case, you could do a rolling upgrade. You remove one machine from the cluster, upgrade it, return it to the cluster, and move on to the next. Another cheap trick, which I use for my blog, is to start an upgraded instance next to the old one, then reroute the traffic to the new instance, and politely stop the old one. I do this on the same machine, owing to docker containers. I start the new container with a different port mapping, change iptables rules to forward to the new container, and then stop the old one.
Yeah i run an embedded system running Elixir in production and that can be hairy moving the supervision tree around, or changing the shape of a stateful map of a genserver. I like the multiple machine idea. 
[removed]
The ecto migration when creating a table already set an id field and set it's default value as autoincrement on the database. To change that behavior you must configure the migration manually. All that is explained in the [documentation](https://hexdocs.pm/ecto/Ecto.Migration.html#create/1).
There are other projects than just Phoenix... like [Nerves Project](http://nerves-project.org) for embedded systems. That is use by [Rose Point](http://www.rosepoint.com) and [FarmBot](http://nerves-project.org). There is a [github repo](https://github.com/doomspork/elixir-companies) listing companies that use Elixir, most of their staff usually writes blog posts talking about their usage... and there is the [Elixir Status](http://elixirstatus.com) that is a good way to know what's going on with the community and have a lot blog posts about elixir.
Would you use autoincrement as customer id?
That's not how it goes mate. Try to learn something before you ask questions. 
There are quite a few decent tutorials on the Web that cover this topic. A quick search brought up a few: http://nithinbekal.com/posts/phoenix-authentication/ https://medium.com/@andreichernykh/phoenix-simple-authentication-authorization-in-step-by-step-tutorial-form-dc93ea350153#.7oztg1bur Enjoy!
I might be putting in a pull request soon to do this. It does seem super handy.
It depends on your architecture, and your goals. The implication of an autoincrement ID is that it potentially makes information accessible very easily. Imagine visiting the profile of a user on your websites happens via the url `/user/1234` you can assume that `/user/1233` exists as well. That potentially makes scraping profiles of your users trivial. If you want to avoid that, consider using an UUID instead, or don't make the ID public.
I suspect they'll add more, but then make those parts not free?
We have a followup course already called "Mixing it Up With Elixir" that goes more in depth. https://www.codeschool.com/courses/mixing-it-up-with-elixir The goal of the "Try Elixir" course was to give a general overview of the language. We've been working with the Elixir team to have something with a low barrier to entry for them to include on the http://elixir-lang.org/ site for beginners to try things out. 
If you get tired of wondering where all the functions come from, I'd recommend deleting web.ex entirely. It's pure sugar to dry up imports in your controllers / views / Ecto schemas. 
And after that, move as much as you can to `import only` or better yet, `alias` to remove the question of where stuff comes from.
&gt; Is it to give you the feel that Phoenix is part of your application instead of just being a separate library? Yes. &gt; Or is it to be able to easily upgrade the system by adding shared behaviors inside the application specific Web module? Also yes. The default Phoenix setup gives you a very Rails-y experience, but you don't have to stick with that. Being able to customize the context of your controllers, views, etc. is very powerful and flexible. Like you said, you can easily tack on functionality that you need often. You can even "inherit" these imports from one another; something like this: def authenticated_controller do quote do use MyApp.Web, :controller plug MyAuthenticationPlugHere end end Then you can just do `use MyApp.Web, :authenticated_controller` and you get authentication functionality for free. (That's a simple example you can also accomplish in the router by using pipelines)
This is the correct answer. It is solely a convenience mechanism for common imports and aliases across your web modules. &gt; Does anybody know why they did that? Is it to give you the feel that Phoenix is part of your application instead of just being a separate library? No. No decisions we make ever target trying to make phoenix "feel like it's part of your app instead of a lib". That mentality certainly wouldn't justify any feature.
Elixir sits on top of the Erlang VM architecture what has been around for a long time. The right way you refer to is to leverage the strengths of that architecture. It's not a general purpose do all language like say C++ is. Elixir/Erlang is designed to be reliable and scalable but not necessarily performant at the process level. The key is consistency. You'll get 10ms latency on web-sockets whether your managing 10 streams or a million. If you think about its roots Erlang is designed to packet switch at scale and never crash even if it sometimes might fail to succeed. 
Have you looked at dialyzer for elixir/Erlang? You can catch type errors.
Yes I did and It's not the same. We can use dyalixir but the usual/normal workflow is not that and the libs and 3th party source code will not have type specs so the quality of the analysis will be poor! 
I agree. However, what Elixir/Erlang lacks in the type checking department, they compensate on the error handling side, especially compared to Go. Having mechanisms to reason how your application will restart in production is extremely important because there is no type system that will save you from errors coming from the network, filesystem, OS, etc. I would love if there was a language with both.
Do you plan on adding an otp or Phoenix course in the future?
[removed]
I use [porcelain](https://github.com/alco/porcelain)
Elixir s2 But actually the merith of this facility should be Erlang's hehe
true ... but still :-)
[removed]
Adding a swagger-ui plug to phoenix_swagger https://github.com/xerions/phoenix_swagger/pull/60
This only works if your app is stateless. If you have globally registered processes or long lived connections then you need some kind of coordinated upgrade.
For the love of Jose Valim, when TF will this magnificent language explode?
Moving some database queries to Elixir based services (previously on Django) and testing the GPS Server already on Elixir (previously Twisted/Python). Eventually will move the whole project sans admin panel to Elixir. Fleet Management and Tracking System.
You don't. But with [Port](https://hexdocs.pm/elixir/Port.html) you can manage the external process like it's a service. If you close the port, the associated process will be killed. If you spawned a daemon you can [retrieve the OS pid](https://hexdocs.pm/elixir/Port.html#info/2) with `Port.info(port, :os_pid)` and send a `kill` or a `taskkill`or whatever command available on the host OS. 
[removed]
Will hot code deploys require a certain cloud service to work?
Awesome. Thanks for the info.
Try renaming the file as `.ex`, or making sure you're `cd`'ed into the correct directory
When you typed `elixir simple.exs`, the elixir program looked for the file simple.exs inside the directory you were currently in. You say you created the file user/documents/elixir/learning/simple.exs, so before typing `elixir simple.exs` try typing `cd ~/Documents/elixir/learning` to change your current directory to be that one. To prove that you're in the right place, type `ls` and you'll see a listing of all of the files in the current directory. You should see simple.exs there.
Your Elixir is correctly installed, and the program is correct. The problem is that you are not in the right place, since the terminal does not start in the same directory as where your example.exs file is. Try watching this quick [Terminal tutorial](https://www.youtube.com/watch?v=-Vl4rpZVA6I) first. It will show the very basics about how to navigate in the file system using only terminal commands. Have fun!
The pile-o-models always bothered me, but not enough to ever do something about it. I like this new approach in 1.3 a lot.
Really happy to see these changes in the default Phoenix structure. 
Gotta join the new-structure-loving train. Really looking forward to it, hopefully it'll be the paradigm shift that'll defeat struggles in long-running projects, adding feature after feature.
Great article. I wish more companies used something like this. I don't know if you're interested, but you can do this with for comprehensions for count &lt;- 0..11, into: %{} do ... instead of piping it into the Enum.into(%{}).
Thanks for the link, I have watched his talk from Elixir Conf a few times but the sound quality was horrible on it. 
You haven't yet "coded the happy path and embraced crashes". Also, guards let you do quite a bit of parameter checking right upfront
Nice!
Cheers, that's really cool.
I think Phoenix creates these by default? BTW these aliases will not show up in "mix help"... took me a while to find out they even exist.
Yes! Goodbye, `/web`! Goodbye Elixir on Rails!
I think he mentioned that in his talk. His talk should be up on YouTube now. https://www.youtube.com/watch?v=tMO28ar0lW8
I think that there are a few options to explore here. You could create a test/resources directory and store the csv files there and then look into how to reference and read them in your test. What I would do, though, is create a test_helper that creates a CSV file in your operating system's temp directory and returns the absolute file path. In the setup for each test, create this file and then delete it in your teardown. This way any test that might alter the file won't affect any test that comes after it. This last approach will likely slow down your tests quite a bit as it has to write and delete the file each time, but you can decide how best to work with that.
furthermore, you probably want to separate the concerns of reading the file from actually parsing it into different functions. So your tests should just pass the strings representing the CSV into your functions, but not actually read and write to the file system. Then the actual application code would be something like: File.open("path_to_file.csv") |&gt; parse_grades() where parse grades is under test using the string method I described above and you don't really need to test File.open as this is in the core of the language.
Phoenix has been 1.0.0 since August 2015 :)
Yeah. I don't know what your data looks like, but here's the general pipeline I would be thinking about. File.open("path/to/file.csv") |&gt; parse_grades() # returns something like [chemistry: 89, math: 92] |&gt; convert_to_grade_points() # [3, 4] |&gt; calculate_GPA() # 3.5
Any favourites so far?
But that's Ruby? How's that a race? (even though elixir is at 1.2 now)
I think it's related to the fact that a Hanami 1.0.0.beta2 post shows up immediately above/below this post if you are subscribed to the right subreddits (it does for me). It's just funny, since Hanami is an emerging Ruby technology as a alternative to Rails, and Phoenix is an emerging alternative to Rails in a language often approached as an alternative to Ruby.
It's quite similar to the pipe you described above. Most of the code is dealing with validating user input (cmd args and csv formatting), but using `with` and `{:ok, data}`/`{:error, reason}` tuples make this quite nice to read. Here is my main pipeline if you are interested: # module Grades.CLI def main(args) do with {:ok, path} &lt;- parse_args(args), {:ok, data} &lt;- open_grade_file(path), {:ok, course_info} &lt;- Parser.parse(file) do course_info |&gt; Summary.summarize |&gt; Summary.print_format |&gt; print_result else {:error, message} -&gt; print_error(message) end end
That.
Good post, well done. Depending on the design of course.. another option is to keep your GenServer state or the Map in this case inside an Agent. Wrapping the state this way may increase your asyncability inside the GenServer itself - especially during blocking or other more thread safe - while maintaining the synchronicity of the call and avoiding the race - at the small cost of two extra lines of code for an Agent.get_and_update dispatch.
Thanks, I agree. Agent could be a good use case for this but my concern with using Agents is that the API is too open and can get unwieldy quickly. I've also built a small game in this way using gen_statem with success. Modeling the game state as an FSM scales really well when the manipulations you need to do on the state get complex.
So one of my dependencies hates the fact that this is a RC version: Failed to use "phoenix" (version 1.3.0-rc.0) because phoenix_haml (versions 0.2.1 to 0.2.3) requires ~&gt; 1.1 * phoenix_live_reload (version 1.0.8) requires ~&gt; 1.0 or ~&gt; 1.2-rc mix.exs specifies ~&gt; 1.3.0-rc * This requirement does not match pre-releases. To match pre-releases include a pre-release in the requirement, such as: "~&gt; 2.0-beta". I guess haml dependency needs to allow for `rc` releases explicitly? So odd.
You have a few options depending on your familiarity with Elixir, the goals of your caching, and how you're looking to grow the architecture over time. As you'll read everywhere, Elixir provides phenomenal building blocks (through Erlang's OTP libraries), which can help here. More specifically, you can power a cache through some of the basic constructs: * An Elixir [Agent](http://elixir-lang.org/getting-started/mix-otp/agent.html) is the simplest wrapper around state. You can throw a value in, and get that same value back out. Compute something expensive once, and throw it in an Agent along with a timestamp. * An Elixir [GenServer](http://elixir-lang.org/getting-started/mix-otp/genserver.html) would be a step above Agents, which allow you to add more business logic to the state management, to handle key expirations, etc. Rails' default (in-memory) cache layer would provide a similar approach to using a GenServer. It will work perfectly fine for *one web server*. However, if you need to load balance multiple web servers, you either need to: * Allow your web servers to communicate with one another directly (to expire keys and update values), through either OTP's [distribution](http://learnyousomeerlang.com/distribunomicon) protocol, or something like [Phoenix PubSub](https://hexdocs.pm/phoenix_pubsub/Phoenix.PubSub.html) (via OTP or Redis) * Keep your cache external to your webservers, and communicate with the cache directly (this is the approach commonly taken with Rails). So regardless of how many servers you have, they all reference the same cache store. For external cache, you can connect directly to either Redis or Memcached via third party libraries: * [Redis Packages](https://hex.pm/packages?_utf8=%E2%9C%93&amp;search=redis&amp;sort=downloads) * [Memcached Packages](https://hex.pm/packages?search=memcached&amp;sort=downloads) **tldr- Build your own, or use a third party package. Since you're asking this question, you should likely just use Redis directly (if you truly need a cache).** 
[removed]
I have only a single node.
If you need to cache, `con_cache` is more than enough for your use case. `cachex` looks a bit more complex, so I would go with something simpler.
I don't even know whether I would worry about it all that much. Just throwing it in ets and reading it from there is fine as long as it's only on 1 server (which is likely because it's a blog). Things only get slightly complicated in that case. If it's on multiple, cache expiry becomes a distributed systems problem (what if a server goes offline for 10s while the cache delete command is issued, then gets added to the pool, and users see 2 different sets of latest articles randomly). But instead of thinking which parts of your app are expiring, you're skipping thinking critically about caching strategy. This is your blog, so the unpredictable traffic would be in a surge of anonymous visitors, most likely. In this case a CDN configured as a reverse proxy to your website (like Cloudflare or something more powerful, like Fastly) might be best. You can aggressively cache (using HTTP headers to the CDN) stuff closer to the client, if the client is not logged in, anyway. When that list of articles is updated, you can expire the CDN cache of anonymous users via an API call. In this case, you've delegated the complexity to another layer of abstraction, but you've also reduced latency quite a bit. And because you've only got 1 layer, there's only 1 spot for things to go wrong. But if you do two types of caching in this scenario, you have to realize that cache hits can overlap. If the call to flush your local partial cache returns before that flush is complete (ie, is an asynchronous call), then when you expire the next cache layer, it still might pull an old/expired value from the previous local cache. Cache layers can add on top of each other, and a lot of caches will return right away when you try to delete so that you spend as least time possible "waiting" in your app...but at the cost of correctness.
I love where Phoenix and Elixir, as a whole, are headed. I just wish I used them at work so I could be getting paid to learn them instead of it being a hobby pursuit. 
[removed]
A good write up, but what the fr\*g is this cr\*d: &gt; Phoenix 1.3-rc.0 was just released, and while it's still not a final release, it already feels solid as h*ck. 
/u/Swanros it seems the syntax highlighter in your blog broke. I can't see sh*t. ;) 
It's our dream stack, too! :) Remote is "in consideration", but we much prefer in-house engineering, particularly on the platform side of things. Plus, NYC is amazing, and we can help relocate!
Just a theoretical question, but how would you tackle replacing an existing server with caching (which already has some predictable amount of regular load) with a Phoenix app without caching? Just deploying and seeing if you need it is risky, so what do you do?
Of course! Thanks for checking it out.
And that's the way it should be!
Are you able to load test the existing application and your new phoenix app? If you have predictable load, using something like Gatling could be very insightful. 
Haven't heard of that I'll have to check it out. I've been hard pressed to find anything that realistically replicates load other than testing a single endpoint.
For situations where you really don't want downtime, a common thing is to have a load-balancer copy the traffic off to a file or to another server. Some tools like httperf can re-generate the traffic for most single-server sites if you just hand them the dump file. Other folks have the second server re-issue the requests to your "replacement" app (with things like emails off and not using the production database). This way you get to see how both sides work "live". Though you probably wouldn't do a monolithic replacement of a production website anyway. What usually happens is that you start to program a single feature in a new language and use the load balancer to coordinate those requests from the main app. Slowly, you replace the old application feature by feature until it no longer remains. You can still use the above methodology in the microservices realm by writing a small server to duplicate traffic.
Cheese and rice man. What's with all the cursing. 
You aren't using the idiomatic way to get the first item of a list, which would just be `hd(list)`. This will likely perform much better than Enum.at(0) because while the overhead for Enum is low, `hd` is such a crazy fast function that every bit matters.
Nope. It's not really broken, you just forgot to add Elixir to highlightjs custom JavaScript pack. Their CDN JS just has the most common languages, which doesn't include Elixir.
It feels weird to me to add anything other than error handling in the fallback controller. I'd add the generic successes to a different post filter/controller, configured maybe in web.ex. Edit: The reason is because I feel I should go back with the errors (thus fallback), but forward with the successes. 
OK, giving a bit more of a thought, I'd really just use the fallback for error handling specific to the subject you are dealing with, User, BlogPost, or its bounded context, like rollbacks and compensations. Then I'd put a global Responses post-filter controller at web.ex level to deal with all those REST-like response concerns. On the other hand, I think this last one should largely be a job for Phoenix, using a generator that gives you a conveniently configured convention to follow.
Exactly. Do NOT make analogies. You'll make huge design mistakes.
Easy fix is to link to the dependency like `"ex_admin", path: "deps/ex_admin"` and then edit mix.exs of that dependency to include `or ~&gt; 1.3-rc` `override: true` didn't do shit for me.
Well, unfortunately, the language looks exactly like Ruby. This makes the "forget everything you've ever known" trick a little difficult. How do you go about the paradigm shift other than to relate ideas to other ideas you know? For example, Structs are like objects with only state and no behavior.
Process. More discussion about this http://stackoverflow.com/questions/15147924/how-do-erlang-actors-differ-from-oop-objects
You legend, thank you!
- [The Getting Started guide](http://elixir-lang.org/getting-started/introduction.html) for features/syntax of the language - [Elixir in Action](https://www.manning.com/books/elixir-in-action) for a in depth study of the VM and OTP - [Programming Phoenix](https://pragprog.com/book/phoenix/programming-phoenix) for web interfaces.
Ok I'm guessing you are in the REPL. Your code works. But you don't 'receive' anything. You simply view the return if the REPL that says it sent ':x' You process receives the message, return the value (still on the process), the value is not used, and the process dies. If you want to visualize the value, inspect it: x = spawn(fn - &gt; Testmod.test(3) |&gt; IO.inspect end) I hope it helps :) Also please use more expressive variables names. x and y all over the place are hard to read and don't convey meaning.
I'd first go with the very very basics, pure HTML, CSS, its selectors, and pure, vanilla JavaScript to fiddle with a basic static web page based in your own file system, like downloading a very basic pages(like CS professors bio pages from colleges sites) and seeing their source code: http://webdesignrepo.com/frontend.html#Learning W3Schools.com used to be bad site for learning(and many will still diss them for their past), but I'd recommend them now. --- Second, learn about web servers, how they serve static pages(nginx with [the basic config](http://nginx.org/en/docs/beginners_guide.html) is a very simple one), learn about HTTP at a little lower level (open your browser's developer tools, and click on Network page, or use CURL in verbose mode to send HTTP requests), and then go study the Programming Phoenix book, so you can delve into serving dynamic web pages with Elixir and Phoenix. --- Third, learn about AJAX, and use JQuery to facilitate getting small HTML fragments from web servers and append them to full pages. Later delve into delivering JSON from Phoenix, and making your JavaScript client code in your browser grab that data and do something to your HTML page. Don't bother with JavaScript frameworks (except small parts of JQuery, as XMLHttpRequest is unfriedly) and tools until you have a good grasp doing pure JS.
You have a good point... Someone could probably jump right in to Phoenix without needing to know how everything works (right away at least)
It's required when you need a supervision tree for processes in your project. It's not required when your project doesn't require is own processes; this could be in the case of a utility package as you mentioned, where all of your modules contain pure functions, or if your project has a dependency that has a supervision tree, but does not need processes itself, for example an HTTP client that depends on `HTTPoison` (which depends on `hackney`, which has a supervision tree), but only implements callback modules.
I liken the actor model to objects with a functional interface. As everyone here is saying, it's not exactly a correct analogy, but I find it helpful for making the mental shift from OO to OTP. When it comes to straight elixir, though, you can liken modules to ruby modules with `extend self`; they're straight up functional constructs, that don't change the state of anything.
Why did someone downvote this? These are excellent resources, and in this order make for a good progression; I've read them all, as well as others mentioned in this thread, recommended them because they are the best, in my opinion. If you disagree with this as a set of resources, at least say why. This is what OP asked for, so if you have some difference of opinion, say what it is, instead of pushing someone else's opinion down without reason.
[removed]
The best analogy to Objects are Processes. 
Fixed, thanks!
What made you switch?
My favourite feature of OOP: interfaces, is present in elixir as protocols.
good point
can't wait for the videos to be online
It always got your back. 
Hello, I followed your guide but I got an error at the end of the procedure when I try to run the Phoenix server after all the configurations made... Any clue? Thanks! mix phoenix.server [info] Running PhoenixSemantic.Endpoint with Cowboy using http://localhost:4000 &gt; @ watch /Users/user/Documents/workspace/phoenix_semantic &gt; webpack --watch-stdin --progress --color 0% compiling Webpack is watching the files… Hash: 8ebba1d60b0a25e9b7c3 Version: webpack 2.2.1 Time: 1121ms Asset Size Chunks Chunk Names app.js 1.03 MB 0 [emitted] [big] main [1] ./web/static/js/semantic.js 1.31 kB {0} [built] [2] ./~/phoenix_html/priv/static/phoenix_html.js 1.03 kB {0} [built] [3] ./~/semantic-ui-less/definitions/behaviors/api.js 39.8 kB {0} [built] [4] ./~/semantic-ui-less/definitions/behaviors/colorize.js 8.12 kB {0} [built] [5] ./~/semantic-ui-less/definitions/behaviors/form.js 52.6 kB {0} [built] [6] ./~/semantic-ui-less/definitions/behaviors/state.js 20.8 kB {0} [built] [7] ./~/semantic-ui-less/definitions/behaviors/visibility.js 41.9 kB {0} [built] [8] ./~/semantic-ui-less/definitions/behaviors/visit.js 15.8 kB {0} [built] [9] ./~/semantic-ui-less/definitions/globals/site.js 14.1 kB {0} [built] [10] ./~/semantic-ui-less/definitions/modules/accordion.js 20 kB {0} [built] [11] ./~/semantic-ui-less/definitions/modules/checkbox.js 26.1 kB {0} [built] [12] ./~/semantic-ui-less/definitions/modules/dimmer.js 20.7 kB {0} [built] [13] ./~/semantic-ui-less/definitions/modules/dropdown.js 135 kB {0} [built] [14] ./~/semantic-ui-less/definitions/modules/embed.js 19.9 kB {0} [built] [25] ./web/static/js/app.js 732 bytes {0} [built] + 11 hidden modules ERROR in ./web/static/js/app.js Module not found: Error: Can't resolve 'style-loader' in '/Users/user/Documents/workspace/phoenix_semantic' @ ./web/static/js/app.js 23:0-30 ERROR in ./web/static/js/semantic.js Module not found: Error: Can't resolve 'semantic-ui-leKaabilss/definitions/modules/nag' in '/Users/user/Documents/workspace/phoenix_semantic/web/static/js' @ ./web/static/js/semantic.js 15:0-56 @ ./web/static/js/app.js ERROR in ./web/static/js/semantic.js Module not found: Error: Can't resolve 'semantic-ui-less/definitions/modules/video' in '/Users/user/Documents/workspace/phoenix_semantic/web/static/js' @ ./web/static/js/semantic.js 25:0-52 @ ./web/static/js/app.js 
I manage to fix the first error: first of all I needed to install `npm install semantic-ui-nag` and then I found a typo in your article... In web/statis/js/semantic.js you have this line: `import 'semantic-ui-leKaabilss/definitions/modules/nag';` that should be obviously `import 'semantic-ui-less/definitions/modules/nag';` 
I'm not, but I could. What's the Nerves project?
That's great. I will resolve the typo errors right away. Thanks for pointing them out. I didn't get the error or didn't require to separately install `semantic-ui-video` and `semantic-ui-nag`. However I will check that again and will make the necessary changes. Thanks again :)
[removed]
Agent is a GenServer ([agent.ex](https://github.com/elixir-lang/elixir/blob/master/lib/elixir/lib/agent.ex#L163)) so it stands to reason why a hand written GenServer would be faster. :)
Sure. I will change it. Thank you for pointing this out.
[removed]
Hey guys! I’ve been working on this course for about half a year, absorbing as much knowledge as I possibly can about Elixir and Phoenix. :-) Most people agree that the best way to learn a new language or framework is to build something useful with it. However, it can be hard to spontaneously come up – let alone follow through – with a good project, especially without some guidance. That’s why, in the "Discover Elixir &amp; Phoenix" course, I try to explain things in a way that I personally would have wanted to be taught – by building a clone of Facebook Messenger and learning new concepts and patterns in every chapter. If you’re curious to see what the final product looks like, [check out my demo on Heroku](https://messengyr.herokuapp.com)! Cheers! PS: the course uses Phoenix 1.3, so you’ll also learn to use the new generators and how to organise your code into contexts!
I really enjoyed this post, they do a great job breaking down the different parts of the language into small and understandable sections. It just bugs me when I see stuff like this because it might confuse people who are new to the language. &gt; Elixir is a Ruby-like language The syntax is similar and that is it. 
That's a dangerously misleading tagline.
But Ruby *is* simple. In fact, its simplicity is one of its core features. Although, that doesn't mean that becoming an expert Ruby dev is as simple. :) And I don’t think it’s a coincidence that many Elixir developers are also Rubyists. In my opinion, the experiences *are* comparable. Both languages are high-level and geared towards developer happiness. The tooling is also quite similar (IRB -&gt; IEx, Rake -&gt; Mix…). Not too mention the fact that Elixir’s syntax is obviously very inspired by Ruby.
The problem isn't not wanting to be associated with Ruby. The problem is that by marketing Elixir as Ruby++ you get an influx of people who either stay and fight their tooling because it's actually a world apart from what they're used to or leave in frustration with not getting the familiar tools they were promised. As for whether Ruby is simple, that's highly subjective. I don't think something that has three or more ways of doing everything can be called simple but that is my opinion.
I'm currently going through that path (I do have web experience; though not full-stack) and I have to agree that it's a logical progression. That said, it's not *adequate* until you try doing something yourself instead of just following instructions. No substitute for 'real world' experience.
That website isn't working for me, it crashes on Windows x64 on Chrome.
This looks promising. Have anyone here used it?
I think the most natural Elixir data structure for parsed JSON is a simple map with string keys, right? So something like: ``` { "foo": { "bar": 1337 }, "baz": [ 1, 2, 3 ] } ``` Would become: ``` %{ "foo" =&gt; %{ "bar" =&gt; 1337 }, "baz" =&gt; [ 1, 2, 3 ] } ```
Sorry, I don't think I made my intent with this post clear enough. That's indeed the default mode of operation for the parser. However, in my experience, some of the ways people usually represent data in JSON are fairly awkward to work with directly in elixir. One of the things I would personally want out of a parser is the ability to convert this into something that's nicer to work with in elixir. An example of this would be the JSON `[{"type": "comment", "author": "some_person", "text": "Hello"}, {"type": "reaction", "variant": "like", "author": "some_other_person"}]`. Optimally, I would want this to be converted into something like `[%Comment{author: "some_person", text: "Hello"}, %Reaction{variant: :like, author: "some_other_person"}]`. I want the user to be able to easily specify how this should be done. Instead of trying to come up with artificial use cases, I thought I would post here and try to get feedback on what kind of JSON data people actually commonly parse, and what format they wish they had it in on the elixir side. If I have a clearer idea of what people actually want, it would make it much easier for me to design the actual API.
You can't avoid design. It is the same as in Ruby &amp; Rails as it is with Elixir &amp; Phoenix. Rails just lets you get along a lot farther before you realize that you did not put enough thought into your design. I still love Rails and Phoenix, but for different reasons. Elixir and Phoenix have made me rethink my design process around Rails applications as well. 
Fantastic. I literally just made a post asking about how to get in to web development. I like that this doesn't make a ton of assumptions and just teaches you by throwing you in to it.
Like most everything `conn`-related in Phoenix, the session store is implemented via a plug - in this case, [Plug.Session](https://hexdocs.pm/plug/Plug.Session.html). That plug's configuration lives in your `endpoint.ex`. You want to set the `max_age` option. defmodule MyApp.Web.Endpoint do use Phoenix.Endpoint, otp_app: :rhr # ... # The session will be stored in the cookie and signed, # this means its contents can be read but not tampered with. # Set :encryption_salt if you would also like to encrypt it. plug Plug.Session, store: :cookie, key: "_my_app_key", signing_salt: "DEADBEEF", max_age: 60 * 60 * 24 * 14 plug MyApp.Web.Router end
yes. Design is key. I still love The Rails Way -- I love that I can have a nearly working app in just a few minutes or hours. The problem usually comes farther down the line when something doesn't work due to poor design. It certainly not a 1-for-1, but sometimes I spend more time fixing that one problem then if I had slowed down and designed it right the first time. With Elixir and Phoenix, I feel like we are doing more of the planning, and then recycling that process for Rails projects as well. Not to mention, OTP is pretty cool. 
Another aspect that isn't discussed here (and maybe it's too early to compare) is the cost of maintenance. I've upgraded Rails apps from 2.3 -&gt; 3.0 -&gt; 3.1 -&gt; 3.2 -&gt; 4.0, including Ruby versions from 1.8.7 -&gt; 1.9.2 -&gt; 1.9.3 -&gt; 2.x (or something like that, I'm a little fuzzy on the Ruby versions now). The upgrade from Ruby 1.8.7 was tough. The main things I remember were text encoding issues and Date.parse() changing from MM/DD/YYYY to DD/MM/YYYY. I'm sorry, but that's a fucking *horrible* change to make. I know it should have been in non-American format from the beginning, but they could have done this in a non-breaking way (e.g., add Date.parseUniversal() or *something* else). Rails was a fairly tough upgrade from 2.x -&gt; 3.0 (ActiveRecord). And again from 3.0 -&gt; 3.1 (asset pipeline). 3.1 -&gt; 3.2 wasn't as bad, but I think if you had kind of complex routes then it was some work. 3.2 -&gt; 4.0 strong parameters was some work but again wasn't that bad. But there were also small things here and there that were a pain: at one point they changed request.xhr? return value from a boolean to a truthy value, which didn't break a *lot* of projects.. but it *did* break some projects, and for no added value. --- I know Elixir and Phoenix are much, much younger so it's not really fair to compare them. But here I go, I'm doing it anyway. So far my general impression is that Elixir/Phoenix maintainers treat their APIs with much more thoughtfulness and care, and they don't yank the rug out from under people. When things do change they seem to give nice warning/error messages to help you. They seem to deprecate things and tell you, "This is going to break in a future release, so fix it now" rather than just breaking it. Phoenix 1.2 was the first release with a really big new feature, and it had zero impact on your existing apps. Phoenix 1.3 is the first release with a really major sweeping change to how you write your apps, and it didn't break my app when I upgraded. I *did* go and convert my app over to the new conventions of 1.3 but I was really, really impressed by how I could upgrade to 1.3 and just make a few changes and my app was still working perfectly. When Rails made major changes it took considerable effort to get my app updated to support it. (edit: spelling)
Full disclosure: I'm on the Nanobox team. We're currently in the process of building in hot code deploys. It's one of the many reasons we love Elixir and Erlang. At the moment, deploys are atomic, meaning we spin up a new container/server, deploy the updated code to it, reroute requests to the new container/server, then shut the old down. Obviously with hot-code-swapping, the update will happen on the existing server. With how we're using Docker, it won't get in the way of this process.
Generally in elixir you would not need to cache something like that. 
I'd like to add that one of the issues that really compound upon how tough Ruby/rails upgrades can be is that Rails only supports very few versions into the past. So you can't just stick to a version that works for you and enjoy security patches as they come. You're forced to upgrade and to upgrade often as a result. Hopefully, Elixir and Phoenix don't follow this pattern and continue providing the replacement function before deprecating functions, and making you aware of these deprecations during compile time. 
I like the presentation of the individual guides a lot. I might go through this when i get around to learning Phoenix (as an addition to reading Programming Phoenix), to get some hands on experience aswell. I don't know if the price tag is maybe a bit high for the course, but i don't now how big the later chapters are as well.
Most of the later chapters are much longer than the first ones, so I don't think you'll be disappointed. :-) Cheers!
11/10 - would read again. Thanks, I love the details.
Fascinating report, thanks for details.
ArcEcto is more of a hack than a properly architected library. (I would know, because it's my library.) I've certainly learned a lot since then (it was my first Elixir package), and I'd love to give it an overhaul. Importantly, the problem comes down to the fact that we are performing **two very separate actions** which can each have their own failure scenarios (uploading to S3 and updating your database), which I attempted to hide behind one action (`Repo.update!(changeset)`). This is a problem, and I should have avoided trying to make that work, and instead embraced the fact that they are two completely isolated actions. Small nitpick: Even within Rails you'd want to use `after_commit` instead of `after_save`. Uploading a file to S3 during `after_save` would force you to have very long-running transactions, since the uploading would happen when a transaction is open. 
I actually much prefer `Ecto.Multi`. Why do you not like it?
Yea, I agree. I got acquainted with `Multi` for a small project of mine and I thought it was fine. Only thing that could be improved are the docs. The structure of the tuples when there's an error and what to pass to `run` aren't super clear, off the top of my head. Granted, I never really did any Rails dev so I didn't have any expectations or habits coming in.
&gt; I see it uses limit and offset, which unfortunately is very expensive for large batches as offset is linear. For streaming it is almost always better to use IDs. I don't know how you got that; it does **not** use offset anywhere. You can paginate using cursors, the default method, which simply passes through to Ecto to let it do its own thing, i.e. wrapping `Postgrex.Stream`. Alternatively, you can paginate against a key, which uses builds a `Bourne.Stream`. &gt; Ecto streaming is built at the adapter level, which means only a single query is emitted and data is streamed through the connection. Integrating Ecto with GenStage would indeed be really neat but ideally you want this implemented at the adapter level, i.e. inside Postgrex. Ideally, yes.
Thanks for the reply. Seems I still have a lot to learn here. 
&gt; I don't know how you got that; it does not use offset anywhere. You are right. Apologies. I saw a call to `offset/1` and I thought it was Ecto's offset but it is a locally implemented function. You are using exactly the approach I proposed, thank you for clarifying.
This also has the benefit it decouples the image ID from the user ID and keep those fairly apart. I like it. Btw, it may be worth adding those instructions and recommendations to the `arc_ecto` project itself to provide folks some guidance. I think file uploading is a commonly used feature in Phoenix applications so we need to make sure they have a good experience. And please let me know if there is anything I can help with!
That's sweet dude! Finishing a side project is a wonderful feeling. Browsed through it and it looks neat and nicely commented. Keep it up!
Thank you :)
:)
Working on a "backend" for web-forms. The idea is that people that are not so tech savvy, can add a form to their website with the fields they need, and have the action point to what I'm building. They can then see their entries appear as they get submitted in their form - or get notified by email. I plan on building integrations with Zapier, or feeding entries in to Google Sheets etc. I'm just having fun really :) Elixir is great!
:D
How did you get started? Did you just already know enough? 
Just finishing writing proxy in Elixir. 560MByte/sec on GCE n1-standard-4, loadavg 3.8, 3k clients. Also work on Vim IDE for Elixir- https://github.com/gasparch/vim-ide-elixir checkout and tell me what you think. Has unique feature like representing trace file nicely and navigation around it :)
(:
I just concluded work on http://battlesnake.stembolt.com/ last Saturday. Preamble: &gt; BattleSnake is a programming competition held in Victoria, BC. Teams of students and developers build web-based AIs for the classic arcade game "Snake". Started as a For Fun™ project last year to rewrite the the [BattleSnake](https://www.battlesnake.io/) server application. Worked on it professionally from mid-January until the aforementioned Saturday. [Github Repo](https://github.com/StemboltHQ/battle_snake) [App](http://battlesnake.stembolt.com/) (still online for a while) [Event page](https://www.battlesnake.io/) [Api docs](https://stembolthq.github.io/battle_snake/) Currently working on a University timetable and registration application, using Elixir and Java.
I have read quite a bit about that in the past and came to the conclusion that it does not really matter. At work everybody uses past tense, so I didn't want to break their convention. For my own projects i use past tense aswell, since i think it is easier to read. If i had to work on a project where they use imperative commits, i would do so aswell. I also like to include small developer oriented summaries about the commit (or the last couple commits if it is a bigger feature that i merge into another branch), indented two lines, so you can still run `git log --oneline` for a short summary and `git log` for a more patch-notes like presentation of the commits.
First I read through the [Getting Started Guide](http://elixir-lang.org/getting-started/introduction.html) on the Elixir homepage to get a general overview. I did some F# before getting into Elixir, so i didn't have any problems adapting to the functional paradigm. After that i worked through most of the [Exercism](http://exercism.io/) Elixir track. I stopped at the 58th exercise since they started introducing problems that would be better solved using a imperative language (in my opinion). The first 30 or so got me some good hands on practice on how to use the `Enum`, `String`, `List` and `Stream` modules. Also there are a lot of very smart people who already did the tasks, so I picked up a lot of little tricks along the way comparing their solution to mine. Lastly I read through the [Programming Elixir](https://pragprog.com/book/elixir/programming-elixir) book by Dave Thomas. This didn't really introduce any new concepts, but it was a good read. I definitely learned the most doing the Exercism tasks. Currently i am reading [Elixir in Action](https://www.manning.com/books/elixir-in-action) by Saša Jurić and I like how he doesn't spend too much time on the basics. He also explains some more in-detail stuff about Erlang, immutability and so on. I have not gotten to the OTP part yet, but i am looking forward to it a lot!
`endpoint.ex` is not just the plug configuration – it's the actual plugs themselves. The endpoint is started in the supervisor at your application's entry point (`my_app.ex`) and is the interface between your application and the web. It even has the router in it. Remember, Phoenix Is Not Your Application™. If you really wanted, you *could* move the plug configs to `config.exs` and read them back in `endpoint.ex` when defining the plugs, but that crosses the web/application boundary. It's better to keep web-related config in web-related files.
I'm aware of that, but he uses it as an example of his premise. When he says: &gt; This is a big win both for the syntax of writing it and for the cognitive load of reading it. But some pitfalls lurk. If he says that **pitfalls lurk** that means that something that wouldn't happen in the case statement would start to happen when using with statement, and that is not the truth.
&gt; record.id is not available until it's actually saved Has anyone considered just generating a GUID/UUID client-side (or being handed one on form load from the server, more likely) just to give it SOME identifier before it's actually persisted to the DB and gets the autoincrementing one?
Admittedly the example was taken from the docs and not from my code. The original method just assumed that whatever was returned from that block would be acceptable to the write_line/2 function. Take a look at the link. The main point I was trying to make is that when you're handling the pattern match it's much better to have the chained functions return a tuple that lets you later understand where the result short-circuited from the `with` block. The `else` syntax is indeed cleaner and I have already updated the post with that feedback. Thanks!
No, I'm not confusing it for pattern matching. `with` is effectively chaining pattern matches. But when you are debugging an application where you got an unexpected result, I find the pattern I described easier to follow than an error that was passed down three layers of functions and should have been handled here instead with a nice tuple identifying where it short-circuited the `with`. I updated the post with the suggested `else` syntax which was not in the Elixir docs on `with` but was suggested by readers.
No, if you read what I said, I was pointing out that it's easy to not understand where the with statement short-circuited if you don't return enough information from the chained functions.
I ended up generating uuid as part of the changeset: https://github.com/GBH/pedal/blob/master/lib/pedal_app/web/models/photo.ex#L25 
I guess it's more a question of taste... I'm really more used to pattern match on function calls then use control flow statements.
Sounds fun! :) I think I like Elixir and vuejs equally 
I use it. I really like it. It's a happy medium between using Heroku and a raw EC2. I like that I got up and running quickly, but the resources it uses are transparent. As an example, that means in the future if I need to use stand-alone GenServers that communicate with my Phoenix application there's a path for making that happen. I don't think it's possible to have two Erlang nodes communicate with each other on Heroku. There are other advantages to having resources be transparent such as scaling, and costs.
I tried to pay for the course twice and the payment processor charged me a buck each time, each time rejecting the payment in the UI. I know it's not my card because I just charged almost 40 bucks on it for something else in the exact same timeframe. I sent a message to your live help last night but never got a response, FYI!
Hey there! I did send a response. Check your email. :-)
Ueberauth is pretty neat, but Guardian is one I tend to avoid because of its use of JWTs, which aren't the best choice for user sessions: http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/
Guardian, and JWTs in general, are nice to work with. What's unclear to me how this is going to gel with Phoenix 1.3 contexts. Folks are recommending creating multiple schemas unique to each application context. So for an underlying `users` table, you could have `MyApp.Billing.User`, `MyApp.Profile.User`, `MyApp.Blog.User`, etc. Which one would would you pick to be the Guardian "resource"? Would you have to customize it per-controller? Seems like an unnecessary abstraction.
I think the problem comes in when you look at the coupling within the user's schema itself. One generic `User` schema will have many fields and associations, but only a subset of those are relevant to an individual context. For example a `Chat` context won't care about the user's `billing_address`. If you want to keep the contexts decoupled and only have them interact at their API boundaries, then you shouldn't have underlying data accessible that can be modified behind the scenes, crossing that boundary unknowingly. Personally, I feel that if you understand when you're going "too far" with the above case and can refactor it out, that it's probably OK to have a handful of "common" schemas that span the boundaries. I need to do some more reading and experimenting and see how the 1.3 discussions shake out before confidently striking that balance, though.
Here's an idea that could cover every use case you presented and many more (I'm on mobile, so I'm not gonna bother with any code examples): Allow a user of this parsing library to define a module with a `use MyParsingLibrary` statement. This module would implement several callbacks, something like `parse_list`, `parse_object` , `parse_num`, `parse_bool`, and `parse_string`. The inputs to the "primitive" callbacks `parse_num`, `parse_bool`, and `parse_string` would be the corresponding Elixir primitives, and they would output a value corresponding to these. A use case I see for overriding the default callbacks for these would be to pattern match on strings to convert to dates. The inputs to the `parse_list` and `parse_object` callbacks would be Elixir `List`s and `Map`s, parsed in the "default" way. Their output could be a tuple like `{:continue, value}` to continue parsing the outputted value or `{:halt, value}` to just return the outputted value for that part of the tree. You could pattern match on some part of the `Map` to convert it to a struct, or do a pattern match with `List` to enforce a certain length. Since you might only want certain things to be parsed a certain way within certain branches of the parse tree, I'd also provide a sort of "context" that can be passed down between recursive calls. I'd implement this as a `MapSet` of atoms, although it might be better to do it as a `Map` because of the pattern matching capabilities. Just some ideas.
Looks like this is it, thanks! Just wondering but is that how most other Elixir/Erlang programs are ran as well?
I just rolled my own: For a session, generate a random token, store the token in the session cookie, store the the session data in a database table with the random token as the primary key. I should probably clean it up and put it on hex or something, but it's not too difficult.
You can use `mix run`. Basically, you can create a Task module, define a `run` function, and get the list of arguments that are passed in from the command line as the function parameter. [More info here](https://hexdocs.pm/mix/Mix.Task.html)
I currently using Distillery for build my production app and Docker Swarm for deployment in my servers.
How does your Docker build process look like? Right now I use containers that include elixir and erlang and otp and just run `mix phoenix.server` directly in the `COMMAND`, but there must be a better way. I tried using Distillery, but two problems made it more difficult than I had imagined: 1. The fact that you need to build the release on the same architecture you'll run the application on 2. The fact that environment variables are "burned-in" at compile time (sure you can use {:system, "VARIABLE_NAME"} but not everything supports this pattern).
all of my production systems run as 'releases' built with Distillery as haqkm mentioned above. Elixir is not installed on my servers, etc.
Are you using `Phoenix.Token`? That's pretty much its exact use case.
1. Separate "builder" and "runner" dockerfiles. - the "builder" has msaraiva's gcc-elixir as the base, and runs the mix tasks to build a release. - My build script creates the builder image and then does a "docker cp" to copy the release binary out. - Then the build script creates the runner, which doesn't have mix or other build tools, and simply vendors the release artifact. 2. I use [deferred_config](https://hexdocs.pm/deferred_config/readme.html) to support that config pattern everywhere in my otp apps, including phoenix apps. - If I need to configure a different (not one of my own) OTP apps, and the value is a string, like an url, then the release builder's `REPLACE_OS_VARS` works, but then you have a separate 'prod.release' config, which is different from your 'prod' config. 
Learned a lot from your comment, thanks for the details :)
As others are saying, releases are great for self-contained binaries. Another thing you mentioned was the "entry point." Given the vm (preemptive) and framework (processes organized in otp via apps/supervision), moving beyond single-file scripting to supervised applications means that the question "where's my code's entry point?" translates into "when my OTP app get started, what's its entry point?" -- and the answer to that is basically 'in the `Application` callbacks'. 
in swarm mode we have only a hostname env variable no NODE_NAME or NODE_IP. I'm thinking use the hostname for the name of the erlang vm and use the DNSRR mode for discover all ip related to a services.
&gt; which makes it either hard to revoke or indistinguishable from server-side session state. Isn't what the `salt` argument is for? You could store the salts per-user in the user table, and remove/randomize it to invalidate a session. Though I guess at that point it's just the exact same case you are already doing, just with one more layer of indirection because you're storing the user ID directly in the token. Not trying to argue here, just trying to understand.
Full disclosure: I work at Nanobox, but I hope to provide an objective answer. We've had a lot of Elixir developers recently deploying apps using Nanobox and they've told us it's been a good experience so far (https://www.reddit.com/r/elixir/comments/5y9uzm/elixir_deployment_with_nanobox/dew40fy/).
&gt; Elixir will always be more verbose than Ruby I have found this not to necessarily be the case
Really interesting write up! Thanks for that :)
Thats a nice Article about us :) 
The linked article says: &gt;There were two ways to attack a standards-compliant JWS library to achieve trivial token forgery: 1. Send a header that specifies the "none" algorithm be used 2. Send a header that specifies the "HS256" algorithm when the application normally signs messages with an RSA public key. But to send this headers, wouldn't the attacker need to have access to the secret? He will have to encrypt those to send it, right? 
Working on a Phoenix project for Eve Online. It's a tool for hunters that does a background check/threat assessment on targets.
Yeah. I've taken this approach on a couple of personal/ work projects before. Right now it's probably preferable to import what you need. Part of this post was to familiarize myself with the bootstrap-loader to see if it made the process any easier. Right now it still feels a bit hacky and it has too much setup, but I'll be interested to see how it works out once bootstrap 4 has an official release/ gets more stable. I conceptually like just having one file where I can turn on/off SASS/JS features that I need as I go, but there's too much setup at the moment with using externals-loader in the webpack config.
This is amazing stuff! Thank you for the link.
Suggestion for your nested cases. Instead of doing a case to check {:ok, _} You should do a with statement with {:ok, _} &lt;- HTTPoison.get do For cleaner code :) It would also be better to do function matching for your args instead of another case statement! 
https://github.com/rrrene/credo has a few help wanted labels that are unclaimed
I have. It's a really good introduction. Basically all of Stephen Grider's courses on Udemy are really good. 
Thanks for taking the time to tell me you liked it. How long did it take you to finish?
Nice, thanks. Last time I tried, I found it difficult to work/debug Floki into the repl. In python with beautifulsoup, I can easily print the current list of nodes of my css selection. With Floki printing wouldn't print the node content. Did you experience something like this ?
I took it. It is a good intro, and he does a pretty good explaining things. I wouldn't say complete, though, because he doesn't cover sockets very well as he says the Phoenix 1.3 update is going to break project file structure. There's still unreleased videos to come out once 1.3 hits. Though the course catalog says it's 14.5 hrs of video, I find his vids are very easy to understand at double speed; this isn't always the case with udemy instructors. So theoretically, it can take &lt; 10 hrs, but my experience with it was 2-3 hrs/day for a week.
I would second that it's very good, he's a likeable guy with a knack for explanation. Some aspects I find he gets bogged down in, and some get glossed over for my liking, but I suspect that's very much an individual thing based on my experience. I certainly wouldn't recommend it if you have no prior programming experience (but then...it's unlikely you'd be starting with Elixir). I feel like an extra pre-Phoenix module would be nice, I really enjoyed making the little profile image generator app. 
I don't remember if I ran into the exact problem you mentioned. But overall, the python REPL + Beautiful soup experience definitely felt more user-friendly. 
I don't get ... What's the point of pasting the course description on Medium? A direct link would be enough.
~~Edit: Sorry I didn't actually read the first part of your post or follow that link :O - Will update in a minute~~ Edit: It appears I actually don't understand your question :P The #beginners channel in the Elixir Slack https://elixir-slackin.herokuapp.com/ is a great place to ask questions like this. Since you're asking here though: (I used https://hexdocs.pm/elixir/File.html#stream!/3 as a reference for this answer) As some standalone code to run in iex or a `.exs` file: File.stream("path/to/file") |&gt; Enum.each(fn(line) -&gt; IO.puts(line) end) As a function in a module: defmodule FileReader do def readlines(path) do File.stream(path) |&gt; Enum.each(fn(line) -&gt; IO.puts(line) end) end end FileReader.readlines("./README.txt") 
I have and thought it was a great resource. It is not "complete" but it does a great job covering some of the basics. 
There's a very active http://elixirforum.com for when you have questions and want deep rather than immediate (on Slack) feedback.
I wrote a little thing on how I was able to get a semblance of distributed Elixir going on a Heroku dyno from my local shell. Hope someone else finds it useful and if you find any problems or have any suggestions on better ways to do it, please let me know!
Finally managed to get something deployed if any of you want to check it out/give feedback it can be found here: https://www.formbackend.com Thanks! :)
I would also very much like to know if this is possible.
I've signed up - but your answer doesn't seem to output the number of the line before the text 1 foo 2 bar 3 baz
 File.stream(path) |&gt; Stream.with_index(1) |&gt; Enum.each( fn({line, number}) -&gt; IO.puts("#{number}: #{line}") end) end
It's a random-image-generator type of app that basically copies what Github does to generate default images for user profiles. 
Coherence and Openmaize do not use JWTs. Of the two, Coherence does it better in my opinion - it uses a token that's stored server-side to identify the session (which can therefore be revoked), whereas Openmaize just sticks the user_id in the session AFAICT.
I'm also looking for the best authn/ authz Phoenix addon for a future project of mine and those were two of the options. I also had in my list addict, ubberauth and authable, the last one also provides an oauth provider. Any thoughts on these? Thanks. 
Thanks! I'll get the hang of it soon enough.
Gracias por compartir.
one option is to use Phoenix Channels if you are going with Java - https://github.com/eoinsha/JavaPhoenixChannels
What happened to your scatter plot? :O https://raw.githubusercontent.com/derniercri/slap/master/doc/plot.png
Look for external node protocol in Erlang docs. It is relatively easy to implement, I've done it few times. Also there is goerlang project on github if you favor golang. 
It probably comes from the fact that metrics list is not ordered. This part is still a WIP.
Can I ask what your issue with Tsung is? It is built with Erlang, which should satisfy your distributed OTP requirement.
Well, I expected this to be in English with a title in English. It's a bit misleading. 
I need to create some data seeds and generate (100)^2 requests to be able to test the performances of my API with a poor cache coverage. Spending time to learn a specific DSL based on XML would be a huge loose of time while a can write complex scenario in few lines of Elixir code.
You are correct, sorry about that 
There are benefits to learning the current tools instead of making your own. The thing you benefit with learning Tsung, or any other load testing tool out there, is that you can test multiple services, not just HTTP. They are also battle tested, so you know the results you are getting are as close to true as possible. Whereas with creating something new, you could have a bug in your code that is leading you to believe that you either have amazing or horrible response times, when it is actually the opposite. With that said, I am not against you creating your own tool, I just think you would benefit more from learning current tools.
So basically: Ruby/Rails = simplicity, and Elixir/Phoenix = simplicity with technicality. 
&gt; what does Elixir have to offer/what makes it different from other languages used for functional programming? IMO, Elixir's main feature is that it gives us an easy to understand language with access to BEAM and OTP.
Found [this](https://www.sitepoint.com/elixir-love-child-ruby-erlang/) article that's helpful.
I think I meant more so "functionality" rather than "technicality." 
I don't think it mean what I thought it meant either.
I think it'd be worth my while to learn both. I've been spending a lot of time looking online for sources to learn Ruby (and it's frameworks) and writing some small programs, and I'm definitely getting a firmer grasp on it. I found some sites (just today) to learn a bit of Elixir, and also purchased a book too. So 4 months from now I'll probably shake my head from seeing how I didn't understand the differences between the two languages.
Isn't it discouraged to use keyword lists as keyword arguments in functions? For example, keyword lists are order dependent when matching, so I can't call Mod.foo(b: 1, a: 3, c: 2) I think there are some other weaknesses that I can't remember at the moment :)
Yes they're order dependent and don't support default values, so it's not the same as what you get from other languages. But for the case of clarifying the meaning of primitive function parameters they work well. Edit: you could use a map if you really need the flexibility, but the syntax isn't as clean.
This series could be of interest, but not sure if it's complete yet: https://medium.com/@aditya7iyengar/searching-sorting-and-pagination-in-elixir-phoenix-with-rummage-part-1-933106ec50ca
Whether this behaviour is "nice" or not is a matter of opinion. To me, the horrific dependency management of Golang is one of its major detractors. Elixir has a .lock file and caches dependencies locally, which to me seems to be a neat solution - you can pin your dependencies with accuracy but don't need to "vendor" them to avoid issues like you may have with centralized Gem/Egg directory structures. The deps directory is .gitignored, and that's the correct decision.
To make it concrete, http://erlang.org/doc/apps/jinterface/jinterface_users_guide.html - it turns a JVM into an Erlang node which enables you to communicate with it just like any other Erlang node. Note though that Erlang will do a decent job of wx UIs and that is totally accessible from Elixir.
You can also use http://github.com/inaka/jinterface_stdlib from there
Really amazing explanation - thanks for sharing!!
If you have internet to pull your repository, you have internet to pull your deps. If you do not have internet to pull your repository, you can still move the entire directory, including your deps, over to a USB stick or something, plug it into your internet-less machine and build the project.
This looks so clean and nice. I'll dive deeper into it later, but is there any support for pagination that is based on scrolling, the way some sites might display more records as you scroll closer to the end of the a list?
Thanks, I found the Interoperability Tutorial. To do the client in another language is a consideration of ease of installation on the 3 major systems and the fact that the clients users should already have a Java runtime installed.
I deploy to my own Ubuntu nodes on DigitalOcean using Distillery and Gatling. https://github.com/hashrocket/gatling
Oh that's cool! kw_opts |&gt; Enum.into(%{a: default_a}) Should work to provide defaults too?
You can treat your deployment as code or as an artifact. If you want to treat it as code then the lock file is the nicest way to make it version control friendly. If you want to treat it as an artifact then download all of the dependencies and tar it up. There's never really a need to store the full dependency tree in version control.
Yup! Good call.
i deploy to ec2 instances using distillery and edeliver
If you want to vendor deps, you can reference them using the `path` syntax: {:some_dep, path: "./vendor/some_dep"} I personally just use the standard method of hex packages and git references, but I don't think mix will stop you from vendoring. 
Right, my question had to do with whether there was something built into this library that would easily integrate with how they're doing pagination to bring that support. Obviously you have to implement it on the client side.
Did you rename the project? The Readme still links to https://hexdocs.pm/jinx.
tl;dr I wrote utility functions to help writing custom Mix tasks with dependencies and watch support so I could replace the JavaScript based build systems that I so dislike. Read the post for more information about my motivations. :) It's probably not that well planned or useful for others but it seems to work fine for my simple needs. Code is here: https://github.com/Nicd/fbu (it's still missing good documentation and it's not pushed to Hex).
After using both for some time, I think the Elixir way of treating state leads to fewer problems down the road and forces you (in a good way) to consider how you're managing this state (errant state causes most runtime bugs IMHO)
Could you distribute the package with pre-compiled binaries to get around the Rust compiler dependency (at least for common architectures)?
I struggle to see the benefit here. At a glance it looks like you're basically just implementing an elixir version of NPM scripts with added complexity. Maybe I'm missing something.
That's a valid opinion. I have two points in response. 1. NPM scripts don't offer dependency support or watch support AFAIK, so you would need to implement something to do that. I haven't searched if something exists already. This ties to my next point, which is... 2. minimizing the amount of JavaScript I need to work with. As I mentioned in the post, it's just personal preference, but I much prefer writing Elixir. Out of interest, where do you think the most problematic complexity is? Do you find some part of using it would be annoyingly complex when compared to some alternative? I'll appreciate any feedback. :)
If you run into any problems, feel free to PM me and I'll see what I can do to help. Here's a write-up that inspired me: https://dennisreimann.de/articles/phoenix-deployment-gatling-ubuntu-digital-ocean.html
I'd appreciate any feedback on it :)
as you will become more proficient, you can check out AppUnite, very good software house specialised in Elixir, always looking for great talent
Thank you so much. I have saved your comment to review that git commit link for the future. I'm still a student so I have a lot to learn about proper commit messages. For the moment the files I really need reviewed are my controllers in todoapp/lib/todoapp/web/controllers and my models and context in todoapp/lib/todoapp/account and todoapp/lib/todoapp/todolist 
Hey folks, I also wrote a small introduction to the library over at the [Elixir Forum](https://elixirforum.com/t/meeseeks-a-library-for-extracting-data-from-html/4315). If anybody has any questions I'd be happy to answer them.
I'll make a note for myself to take a look at this later :D
Thanks!
How is this different from Floki? https://github.com/philss/floki (doesn't need Rust installed either) I use it for parse html for test assertions.
Is elm still a thing? Seems like the hype on that died out fast.
Damn. It'd just be fitting for the name, is all. 
The hype died , the following and growth are solid.
This is an example application that shows how to use Cowboy 1.1 in conjunction with React and Redux to create data driven Single Page Applications. It is an enhanced Todo list web app that pretends to serve as an example to learn how to build web applications with Elixir (not Phoenix) and React. In this project you will find how to implement features such as: **Backend** * Anonymous authentication (encoding and signing user with JWT) * RESTful JSON API (Cowboy REST handlers) * Serve static files (Cowboy static handler) * Authorization (decoding and verifying JWT) * Data modeling and persistency (Ecto + PostgreSQL) **Frontend** * Component based SPA (React) * Application state management (Redux) * Async operations handling (Redux Saga) Hope this is useful for you guys. [Here](http://174.138.84.252/) is a deployed version of the app.
Very nice, thank you.
Thanks, you're welcome.
Author of rustler/the html5ever NIF here. Would being able to eliminate the Rust dependency for common os/architectures be a large improvement to usability?
No rush, it's on my radar but I haven't even looked too deeply at it to figure out how I'd want to use it if it existed.
Thanks! Nice explanation.
Was able to implement pagination that worked with my existing ecto queries and templates in about 15 minutes with this lib https://github.com/elixirdrops/kerosene grabbed it from the awesome elixir curated list
I need an article like this but for Python/Django and Elixir/Phoenix. lol
Off topic question but, have you tried integrating new Elm code with an existing react/react-native app using something like: https://github.com/stoeffel/redux-elm-middleware I've been wanting to try something like this because https://github.com/ohanhi/elm-native-ui is still so young. 
Working on a new startup, Extra Turn - Netflix for Indie Games. Been toying around with Elixir and Phoenix for about a year so decided to build this with it because.....it's awesome! Very early days so far: https://www.extraturn.co/
Is there anything about the article you didn't understand? I went from Python/Django to Elixir/Phoenix but since elixir/erlang is somewhat conceptually different I didn't try to "map" features from one to the other, ymmv of course.
I'd like to add one more tip, in your `config/dev.exs` file, delete the username and password lines for the database connection. This will allow you to work with other developers who have different postgres login setups (usually it's your username). This is how it is in Rails, too.
I'd have to take a deeper look but a quick inspection of the code base makes what you've experienced a more interesting phenomenon if it is indeed indicative of a deeper problem. From docs: "String interpolation also invokes `to_string` in its arguments. For example, `"foo#{bar}"` is the same as `"foo" &lt;&gt; to_string(bar)`." Source: https://github.com/elixir-lang/elixir/blob/e769afbed96b6b9eee6a4f4ac4a6ea00bc0630f7/lib/elixir/lib/string/chars.ex#L11
They do different things. As u/allfictional mentioned, interpolation calls Kernel.to_string() on everything, which means protocol overhead. https://gist.github.com/mischov/a37cf1fbe57f77056fcf316c50082247
Are you testing this in iex? Iex is a lot slower than compiled code, make sure to actually create a module in a file and test it that way.
It's a bummer how long the deploy takes. Blech
I use timex_ecto https://github.com/bitwalker/timex_ecto. I don't know if "should" or it is best practice. Ecto does provide these modules for a reason. If they are not enough then look for something like timex_ecto. I use it mostly for the date arithmetic functions.
I recommend Ecto's types `:naive_datetime`, `:utc_datetime`, `:date` and `:time` as they use the built-in Elixir calendar types.
The link is broken. I get a "page not found" error.
It's not magically there by default, but it's not that complicated. A mere Supervisor goes a long way in achieving fault tolerance. How can this article not mention Supervisors? For those interested: http://elixir-lang.org/getting-started/mix-otp/supervisor-and-application.html
First comment: Check out distillery, it's the "new version" of exrm and seems to be the way forward for builds. The disadvantage list is true for any application and doesn't seem to be specific to Elixir or Phoenix. Docker works best, IMHO, as stateless containers. There are many generic web applications you could write in Phoenix where this would be perfectly fine. You scale out by running more containers and/or adding more underlying hosts. The disadvantage to Docker is that it makes clustering more difficult. Erlang clustering needs a defined list of applications to cluster with. In the Docker world, your application can come and go, move hosts, have varying numbers of running instances, etc. That's all good, but makes clustering much more difficult. You generally have to have some form of registry and code to join/remove nodes, etc. All that being said, many application do not necessarily benefit from clustering. If you're building a stateless web application without any sort of websocket communication needed between different people hitting different instances, then you can probably just not cluster. In that case building into Docker is just fine. 
&gt; distillery Thank you for your opinion, that's interesting. What about overhead, If the application is about upload/store static files. Do you think Docker container lead to waste overhead ?
Regarding the size, I agree that it's not significant but about the CPU and I/O stuffs, I am abit worry about it. Docker could make a VPS getting weaker. Anyway, do architecture for Elixir application is about to think differently. I have to think back my plan about this issue. I strongly believe that in future, people could make a thing which can manage nodes in cluster for elixir. At that point of time, using docker and docker container manager could be meaningless. 
You can use elixir in containers. But if you're writing distributed software, you need to go higher-level. Ie, not just being able to create, store, and run images as containers, but a toolset that lets you easily describe how many instances of your OTP apps you need to run, in what units to deploy them, how to do rolling deploy of new releases, etc. Kubernetes comes to mind. Configuring it on your own machines may not be the best use of your time; I'd suggest going GCP+GKE for now and then, if your project 'outgrows' GCP (for cost, ie storage/bandwidth reasons), **then** look at moving to a Kubernetes or OpenStack install on your own vps/colo servers.
Well, if you develop on MacOS and deploy containers with Alpine and happen to include a dependency that comes with some C++ code... that's the point where releases start to make sense :)
You are right about this point, as a consequence Using docker to isolate environment only is not a good choice. I am thinking about another feature such as upgrading. @BBSHoss claimed that it's good to be able to do rolling upgrade along with Kubernetes and HELM, because hot reloading leads to difficulties to test upgrade and downgrade. 
Thank for your opinion, About the difficulties to test upgrade and downgrade on the production environment, can you give some example about this one. 
Along the lines of not charging for months no games are played (good idea, btw! And I want a Switch! Currently hooked on ME:A believe it or not...), maybe charge a lowish hourly rate so that dabblers ::cough:: dirty casuals ::cough:: won't have to pay the full 9.99 but hardcore people will pay more? ... Although that would end up defeating the predictable accounting advantage of a subscription model... but you're already doing that if you're not charging on months not used. From a minimizing-cost-of-microtransaction perspective you could do what the iTunes store does and wait until more is due or some period of time has elapsed and then charge... As a fan of Bitcoin, one untapped market are young gamers without credit, there should be a way for kids to pay nominal amounts for game time (perhaps with parental permission and CC, perhaps via BTC) You should also use a unit of value that is separate from currency so that you can do things like award more of that unit for achievements, getting friends to join, promotions etc... gifting units of it to other users etc... I know a number of other games and game systems already do this, perhaps to get around legal issues
This is written very thoroughly, I love it.
Wow this is a fantastic answer, thank you so much. I'm going through this little bit by little bit. I saw you mention Flow a few times, is that this? https://github.com/elixir-lang/flow
Just to answer both in this reply, yes to that Flow. Flow runs on top of GenStage, and these are built on top of OTP. As for running things on a schedule, there's a cron-like library called quantum. You'd still be responsible for making sure you don't miss a scheduled update if it was supposed to trigger and you had an outage at the same time. But what you'd do is on startup, see if quantum is currently running the invoice job (for instance), and if not, you can run it yourself separately for the cron "tick" you missed.
Great article. I've been reading this new Elixir book called Functional Web Development with Elixir and Phoenix (https://pragprog.com/book/lhelph/functional-web-development-with-elixir-otp-and-phoenix) and I've been uncomfortable with the overuse of processes used in the example project. This article really confirms my concerns and I hope the author of the book takes some of Sasha's advise before releasing the book. Don't get me wrong. The book is very good it's just a classic example of using processes (Agents) unnecessarily to model objects. 
I haven't read the book you linked yet, though it's on my reading list, so it's possible my comment might not be accurate. I don't think you're being entirely fair, after all Agents are meant to be a genserver abstraction specifically for holding state. I say that in the sense that there's going to be some overlap between OOP class instances and processes. I also want to say that even though Sasa argues against using several processes for the hands, the deck, etc, and he's probably right in this case, that doesn't mean you should be thrifty with spawning processes. I would actually err on the side of using more processes when you're starting to model your problem domain. I don't want this post to come across as me singling you out, but I think it's a good springboard for a discussion.
There is opportunity still for a Que-style durable job processor backed by postgres in Elixir. I would use it!
&gt; I never use Sidekiq or Redis because 99% of my jobs are critical, and I don't like the idea of everything being lost if something dies Most people running Sidekiq use a redis instance or cluster dedicated to the task with persistence enabled. It's quite robust and well tested. Source: Running Sidekiq Pro/Enterprise at scale in the cloud for ~5 years. 
I agree on the pain points. However IMO, most of them can be mitigated in a controlled release environment. Hot reload is not always desirable, but if used correctly can be a blessing.
Speed is one. Doing things correct should be a factor, too. Release is self-contained. The design principles of Erlang, not Ruby. Release lets you do micro services while keeping all the applications in an umbrella.
IMO/IME, and I say this with limited experience with Mix, so I'm open to being wrong. Use mix as a runner. Put the code into a module, test the module directly. Theres no need to test that mix works the way it is supposed to. I did this with rake tasks in Ruby/RoR world and it was vastly simpler to test my rake tasks this way.
This makes sense, thank you. I watched this 1 hour GenStage video and it helped clarify a lot of things, not even with GenStage but OTP in general. So in your apps do you typically think in terms of 'jobs' or do you think in terms of some kind of supervisor which starts up processes at particular times?
Not sure what you're asking me :) I think in terms of "activities", where activity is some task that needs to be done, and whose failure should not imply failure of others (and vice versa). Therefore, I usually say that different activities should run in separate processes. It's not as simple as that, but this is the general idea. Famous examples include HTTP connections (each connection is handled in its own process), database connections (same thing), periodic and background jobs (again, separate process for each), ... If we're talking about a job queue, in a simple implementation you'll likely have one process which starts job in a well defined order (say by pulling items from the database, or wherever), but each job will be running in a separate process. That way a failure of one job won't disturb others. Likewise, a failure of job starter won't crash currently running jobs. Not sure if that's what you asked though, so feel free to elaborate your question :-)
Not a direct answer but relevant- here's [a fairly provocative slide from Evercam from a couple years back](https://speakerdeck.com/mosic/elixir-at-evercam?slide=6) :)
&gt; Have you ever had a database migration go awry? Take longer than expected, do something unexpected, etc? Now, how much of a pain was it to fix? This was probably the hugest new pain in Rails when I moved from a postgres shop to a mysql shop (the former did transactional migrations with a plugin).
If one isn't concerned about hot code uploading, what's the "happiest path" to deploying a Phoenix app into production?
&gt; 1 hour GenStage video and it helped clarify a lot of things, not even with GenStage but OTP in general. Which video did you watch? I'd be interested in having a look. 
&gt;[**ElixirConf 2016 - Keynote by José Valim [66:04]**](http://youtu.be/srtMWzyqdp8) &gt;&gt;Keynote by José Valim &gt; [*^Confreaks*](https://www.youtube.com/channel/UCWnPjmqvljcafA0z2U1fwKQ) ^in ^Science ^&amp; ^Technology &gt;*^6,137 ^views ^since ^Sep ^2016* [^bot ^info](/r/youtubefactsbot/wiki/index)
Yeah, that's a decent option. All that code was already in a module &amp; tested, but the interface to call it was quite different. I probably didn't *really* need to test it, but wanted to give it a try. I think for more complex `Mix` tasks testing is spot on, but in this case it may have been overkill.
I meant performance. Measure! I did measurements on our code base it was roughly between 10% and 15%. Release forces you to define application dependencies and this means less code is being loaded into the beam. 
This article helped me wrap my round around the somewhat confusing and under-documented custom accessor functions. Definitely worth checking out if you're having to deal with complex data structures.
as u/0x5345414E mentioned, you have to use the pin operator. The reason is that when you just write %{field: value} in your filter, you're saying filter in only thing with a field: field and any value. When you use the pin operator, you're saying filter out anything that doesn't have the field: field with the exact current value of value. The pin operator changes variables in pattern matching to use their actual value, and not act as a wild card that can get reassigned. Let's say we have a variable 'x' equal to 5 x = 10 //perfectly fine. ^x = 10 //no match, 5 doesn't match 10 
Can you explain why they all see the empty array when you print out `game.players`? It was summarized here but I don't 100% follow. &gt; This is a classic check-then-act race condition. It’s important to remember that the way GenServers work is they operate on each message in their mailbox one at a time and in the order they are received. The 5 get_state messages come in and the server processes those and returns the current state. Then every player sees a stale state and 5 new messages come in to add the players to the game state. Is this because when you call `Task.async` It adds 5 messages to the stack before even a single `GenServer.call(pid, {:add_player, nick})` gets added? Follow up question: If hypothetically you tried to add 100000 players (just to make it take a long time), would you start to see the state change somewhere in the middle? (I'm trying to determine if it would remain [] until they're all done being added, kind of like async/wait, or if it would start to fill up at some arbitrary point, and its just hidden from the article because adding 5 items is faster than it takes for the first once to process)
As a newcomer to Elixir, even though I found it helpful to know about certain "mappings" (irb/iex, rake/mix, etc.), I agree with not trying to map everything directly. Some of the different approaches/paradigms are refreshing. I've updated the article to include a note about it. Thanks for the feedback!
[inflectorex](http://www.github.com/girishramnani/inflector) Module to singularize and pluralize English nouns.
Some of these already exists, but I decided to make one that uses Phoenix 1.3 and that has a handy mix task for setting up the app, including handling all of the renaming. Hoping some others might find it useful. EDIT: SASS it is everyone! EDIT: I decided to have this boilerplate support multiple frontend frameworks. There is now a simple `config/setup.exs` file where you define the configuration you want. `mix app.setup` will setup everything, then remove all boilerplate clutter. I'm looking to support all the major frontends, along with different specific setups for each frontend, different stylesheet options, etc.
Check the code, he already does use ETS
I could marry you. But for now, let's fork?
Test what should happen after they received the message... meaning, that they connected. This will prove the publishing works.
There are other options, if you want to go into OTP. Might be an overkill for what you're doing but take a look: http://erlang.org/doc/design_principles/spec_proc.html google for erlang sys module.
Nice work, mate. It can definitely help some people.
https://github.com/kuon/backy - has done a pretty good job for me, including simple/hackish rate limiting..
Thanks a lot! 
Fair enough. I'll submit a PR tonight. Edit: Neat, I'm PR #1. I avoided temptation to add other things like SASS instead of LESS, font and image loading, etc. Let me know what else I can help with.
Great article, I learned a few things :) One part got me curious: &gt; Let’s override the public Ecto query functions. This is not ideal: we need to ensure we override all of the functions. If the function signatures or names change in later versions, we’ll fail to capture some slow queries and/or possibly break at compile time. &gt; &gt; Therein lies the danger of metaprogramming. Is there a good way to use metaprogramming here to enumerate over the public Ecto API at compile time such that your trace-wrapped methods are always current and exhaustive? Perhaps `Ecto.Repo.behaviour_info(:callbacks)` is a good start?
Awesome! Left a comment on it :)
Was this inspired by the F# support for [units of measure](https://fsharpforfunandprofit.com/posts/units-of-measure/)? Which (of course), as soon as I learned about it not long ago, I lusted after It would be cool if (in a guard for example) you could pattern-match on specific units
Yes ! Exactly ! Im currently writted thé support of fraction an report!
&gt; Was this inspired by the F# support for units of measure? It is inspired, but not exactly the same goal. (Months ago, I've attempt to write it in OCaml : https://github.com/xvw/ppx_measure Abacus, is "just" an approach "learn quotation" in Elixir and it is a tool to manage "abacus". But in my work, I have to manage some more complex issues using a kind of units of measure, so i'm currently writing a big extension of abacus (as another package) exclusively for units of measure, you can follow the code here : https://github.com/xvw/mizur Actually it is the same of abacus (except for the syntax), but i'm plan to manage fraction and report. Thanks for your message ! 
I did not know about Nerves, seems interesting.
Give in to that temptation! We need SASS on this thing :)
I think I'm succumbing to the peer pressure; I'll most likely replace LESSS with SASS very soon.
I assume that these users are processes with PIDs that you store on the process state record. If they are generic PIDs can't you create these processes in your test and then have them assert they have been matched?
Why don't just test a pure function without side effect? Just test function based on retuned value rather than testing captured output 
Honestly, I'm tired of people fighting Elixir. I'm content to just resign to the same role as Erlang: quietly ruling the world.
What's the deployment story with meeseeks? During development rust is needed but what about production?
The ruby guys seem butthurt, and I'm not sure why. I'm a ruby guy, and I am loving elixir.
How is this different to Inflex? https://hexdocs.pm/inflex/1.8.0/Inflex.html
Hey, I'm one of the Ruby guys (the third from the left). I'm sorry if I seemed to be butthurt - could you help me by saying which of my behaviour made this impression? Overall, I'm very happy we've had this panel. I learnt more cool things about Elixir and I'm eager to learn more. I'm especially happy that there's a number of people in the Elixir community who try to use it with DDD/CQRS/Event Sourcing. It sounds like that's a nice fit!
Actually it was mostly the guy on the far right, you sounded pretty reasonable to me. I actually just wrote a blog post on elixir + event sourcing, still on the front page of /r/elixir 😂
That was a good post! Especially the code examples were cool! I like the DDD posts, as they create this shared "domain" language among developers, where the language features are less critical - easier to jump to another technology. 
Thanks, I'm glad you enjoyed it :)
At one of the last ElixirConfs they took an informal poll of what language people came from before Elixir and like 95% of them were Rubyists. I think there will be a significant exodus. Subjectively, I'm enjoying Elixir more than Ruby (and Ruby was already a huge win over other alternatives that people STILL use to this day...)
It seems it's defined multiple times against different numbers of arguments, which is par for the course in Elixir. You could always look at the Phoenix source code to find out why
oh gosh that guy in the far right was terrible. couldn't keep watching.
This seems really strange to me. (I never got much enjoyment out of Ruby though, so maybe I'm missing the point.) It seems like some Rubyists felt that Ruby was the best language [for themselves personally], and now they think the same about Elixir, but the only similarities between the languages are syntax? Does this group care about the semantics of a language, or just the syntax? If I step back I suppose there is nothing wrong with having strong feelings about syntax since it directly effects the experience of writing code. However, I've [personally] come to believe the underlying semantics of a language are more important than the syntax on top, and so this is why it seems strange to me that Ruby-fans would like Elixir when the underlying semantics are so different.
So the answer is yes, but depending on what you're trying to do it might be a bit involved. If you are trying to get the HTML value of a div's contents you can do that, but Meeseeks's API won't really help you at all. You'll need to find the div's children, get those nodes, get the html for each node, and string join it. If you want to search a node's content for other info there might be easier answers. If you tell me a bit more about what you're trying to do I can give you a more detailed answer. You can find me on IRC (freenode, #elixir-lang) as mischov, on the Elixir Slack as mischov, or just send me a private message of Reddit.
Function to extract html content from a result: def html_contents(result) do document = result.document result_children = Meeseeks.Document.children(document, result.id) child_nodes = Meeseeks.Document.get_nodes(document, result_children) child_nodes |&gt; Enum.map(&amp;Meeseeks.Document.Node.html(&amp;1, document)) |&gt; Enum.join("") end Use like: Meeseeks.one(html, css("#content") |&gt; html_contents
Certain Rubyists were getting tired of running into the same Ruby limitations over and over again (Global Interpreter Lock, rampant dependency explosion, etc.) and Elixir fixes all the frustrations that came out of years doing Ruby in an OO context. Syntax matters a lot to some, but apparently not all, programmers. Learning Elixir's different semantics were very interesting to me.
Disclaimer: I've never used Ruby, only read about it. * They both have powerful metaprogramming facilities. Elixir does them with macros, while Ruby does them with reflection, but to a library user they seem identical. * Build tooling with package management, so the only thing a prospective developer needs to install is the language runtime. This has sort of become the standard lately (Mix = Bundler = Gradle = Cargo = NPM = Nuget), but old memories and old codebases both die hard. * The REPL. It might not seem like a big deal if you're used to Ruby and JavaScript, but it's very different from what Java, C++, etc provide. * The Ruby and Elixir type systems are more alike than either are to languages like C++, Haskell, OCaml, and Rust. In both Elixir and Ruby, I can do this (it would be more idiomatic using pattern matching, but for this example, the branch is what matters): if is_tuple(some_var) do function_expecting_a_tuple(some_var) else function_not_expecting_a_tuple(some_var) end In other words, they're both [unitype] languages. Combined with the metaprogramming features, you can write code that is both terse and readable. [unitype]: http://www.theorangeduck.com/page/defence-unitype
Can you explain what RCP is? Did you mean RPC, because Cacamas' response would be what you want.
Ruby and Elixir are both web first languages. That's the big similarity I see. A Ruby web dev who is looking at languages that solve some of the problems he has will see a lot of good stuff in Elixir.
Ok. What protocol is that other application using to communicate remotely (assuming it even has one)? e.g. Is it exposed using some REST endpoints, or does it use some binary protocol, etc? Otherwise if it has no remote communication functionality. You'll then need to set up an elixir node on that computer, which will expose your own remote communication protocol (could simply be OTP, or something else if you wanted to access it using other software/languages too). And then just talk to the process directly (use either ports or something like [porcelain](https://github.com/alco/porcelain)). 
&gt; Ok. What protocol is that other application using to communicate remotely (assuming it even has one)? e.g. Is it exposed using some REST endpoints, or does it use some binary protocol, etc? json rpc
I came to elixir about a year ago after over ten years and multiple products in Python. I also spent some time with functional languages like F# and scala so the transition wasn't too bad. once I made sense of the mental model in Erlang it was great. Elixir has been an outstanding choice where I used to use Python in web services and the like. This piece covers some of the fundamentals well I think and can help Python users see the benefits of elixir. Myself I love type safety and immutability and that sweet sweet robust runtime. Plus the mix tooling is amazing. Python is now largely for throw away code. 
I know I might be chiming in late, but I just wanted to add in that Elixir apps can have a lot less operational complexity. You usually don't use anything like Redis or Memcached. You don't reach for some 3rd party service or some library for much outside of a database. I see people doing it a lot with email, but the only reason to use a third party email service is so that you don't make your app as stateful and operationally complex and queue mail when servers are down. Re: the comments about elixir code not being old enough to be crufty *yet*, I think there are many other factors than age that can contribute to cruft. The larger (and harder to replace) Elixir libraries are conservative about adding features in general, so retiring older features won't happen as often. Elixir/erlang also encourage much more explicitness when exposing functionality from modules. But I'd also mention that since most of the libraries are often so simple and small, it's actually easier to make fixes yourself, in the case you end up with some orphaned library to support. There's also a weird phenomenon, that sometimes libraries in erlang are just "done" or "finished". They have a limited scope, and there's no reason to add more code or documentation. I fully expect some Elixir libraries to "finish" at some point in the future. The only library I don't feel comfortable tinkering with is probably the Query DSL API in Ecto, because it does a *lot* of macro manipulation. But someone who has been using Elixir for 6 or 9 months should be able to understand almost all the code in most of Plug or Phoenix or even the Elixir standard library...the language is just so small, there aren't that many "esoteric" features that library maintainers use. If something has 10 stars and maybe a few dozen users, as far as you can see, but is only 300-400 lines of code, it probably wouldn't take more than a few minutes to debug anything that's wrong with it. And I think there might actually be far fewer corner-cases in Elixir/erlang code in general because the primitives are just so simple. The number of things in the language is so small, it's much harder to get yourself into trouble around something like concurrency. For instance, you have to *implement* deadlocks yourself.
Type safety? On a dynamic language like Elixir/Erlang?? Probably talking about dialyzer... But even that it's really far from type safety. 
In Erlang, strings are normally represented as lists of integers, where each integer is the code point for some (ASCII) character. There are also binary strings, which are more like strings in other languages. In Elixir, binary strings are the default, but if Elixir encounters a list of integers, and those integers look like code points for characters, Elixir will treat the list in question as if it were an Erlang string and display it accordingly. In this case, you have two chunks that can be interpreted as Erlang strings / character lists - specifically, lists of ASCII control characters. Elixir thus displays them accordingly. In most cases, this is not a huge problem. It really only affects things like IEx. Code expecting lists of ordinary integers will handle charlists just fine, since charlists are still lists of ordinary integers. This is, by the way, the difference between single quotes and double quotes in Elixir. The former defines a charlist. The latter defines a string.
That's a bit of a hyperbole. There are plenty of libraries with typespecs and Elixir's standard library has them too. Although dialyser doesn't give you the same guarantees as a proper static type system, it can definitely help find some bugs that would be otherwise hard to catch.
Update: now ultimate-phoenix-boilerplate
It's really `IO.inspect` if we want to be absolutely correct here :) But yeah, that's what I hoped to convey in the second-to-last paragraph.
This was great but both sides seemed kind of weak and the conversation started to degrade as arguments were repeated. We enjoy both languages and choose to use either Ruby or Elixir based on project requirements. We are totally in love with elixir, but there are some great parts of the rails + gems ecosystem that are so nice it is hard to pass up. It is so subjective that it is always a judgement call. I think that the additional planning that we are doing just to choose between the two of them for each project has made us better architects and designers as a byproduct. When in doubt about choosing, take a step back and ask yourself what are we really trying to accomplish. 
In this case, I think not doing that would actually be a POLS violation in cases where the list really is meant to be an Erlang-style character list (namely: when interfacing with the Erlang ecosystem).
But the confusing part of the behavior only manifests itself upon display, no? Such as in the REPL?
How do you account for changing current rates? Can it do that? 
I shared this in the Absinthe channel in the Elixir slack and sparked some interesting convos: &gt; [10:45] thorsten-michael @seanclayton Thanks for sharing this. I'm at the same point in an app just now. What I dislike is the idea of using my Repo directly in my resolvers, for I just circumvent the seperation introduced by the context that way. Same for using absinthe_ecto. Or am I missing a point here? I'd use Blog.all_posts() in my Blog.PostResolver instead. &gt; Whereas an Absinthe core contributor chimed in with: &gt; [11:29] benwilson512 well the thing I liked about your blog post is that by putting resolvers IN the context it isn't dirty anymore modules in a context absolutely SHOULD have direct access to the schemas and such in that context it isn't entirely clear about how that pans out for associations across contexts but it's a good start &gt; Thoughts?
I'd go with Repo.update_all https://hexdocs.pm/ecto/Ecto.Repo.html#c:update_all/3
Fun fact: you can even define an alias in a function body and it will be scoped to just that function.
I think I got that. My hyperbole remark was strictly about "You do not have type specs in any lib so dialyser is pretty much useless outside your own code...and even in your own I bet almost no one use it.". I don't think the part about no libs using Dialyzer is true and although it definately doesn't give you the same guarantees as Eml's or Haskell's type systems, it's certainly not useless in my experience. PS Maybe a bit pedantic, but Diayzer gives at least one guarantee :) It won't report false positives for Erlang code. Using Dialyzer with Elixir results in some warnings about structs, but appart from that it gives no false positives in Elixir too. 
Excellent. That's exactly my use case
This was just posted on the subreddit 5 hours after you: http://geoffreylessel.com/2017/introducing-react-phoenix/
I'm currently doing this (I have NFI if it's "correct") def touch_changeset(struct) do updated_at = Ecto.DateTime.utc |&gt; Ecto.DateTime.to_iso8601 struct |&gt; cast(%{ updated_at: updated_at }, [:updated_at]) end Then I just call it later. I happen to be using this in an Ecto.multi so that when I create a child record, I update the parent's updated_at. Seems to work fine. I really don't know if this is the "correct" or intended way of doing this though.
Looks like this doesn't do any server side rendering at this time. Instead does some react-ujs like rendering (props are passed as a json encoded data attribute, then sent to the client as a div, then parsed and re-rendered). Not a complaint, just more of an observation. Would love to see it support SSR at some point, but totally get that it's a bit of work to get there :)
Look at this course example: https://www.ludu.co/course/discover-elixir-phoenix Use phoenix as a websocket provider / JSON API. React simply plugs into the websocket data. No knowledge of each other on either side. In this way, it would be trivial to swap out a react front end with an angular front end, etc.
I have it set up in a personal project that does server-side rendering, but it currently requires two other dependencies. The `target_id` option in `react_phoenix` is there to support it. I wasn't sure how much to discuss SSR at this point since, while `react_phoenix` does have support to make it happen, it can't do it on its own. Do you think it would be better to point out how to get a site set up with SSR using `react_phoenix` even though it requires 2 more external dependencies?
What about some Tensorflow bindings, for example https://github.com/tensorflow/rust Or even better, the tensorflow guys are porting some stuff to go https://github.com/tensorflow/tensorflow/tree/master/tensorflow/go
It's worth writing an additional blog post about. Can/will it play with [reaxt](https://github.com/awetzel/reaxt)?
&gt; Do you think it would be better to point out how to get a site set up with SSR using react_phoenix even though it requires 2 more external dependencies? If it can do it, definitely :)
I also think it's conceptually simpler as well. You don't have to worry about configuring webpack/brunch to work with React. As far as react, look into create-react-app in order to make a react app separate from a backend.
Yeah, it's unfortunate that Secure Scuttlebutt is 100% node based right now. It seems like it would make more sense as a generic protocol that can be implemented in anything. Good luck! :)
How meta. Discord's backend is written in Elixir.
Tensorflow bindings for Elixir could be a lot of fun. A bit difficult to justify given how easy Python is to learn. But, definitely fun.
Eric Freeman and Elisabeth Robson are the worlds best Head Starters! :)
Try using genstage, it's directly applicable to what you're doing.
I've got an experimental branch going that adds its own server-side rendering. Would you mind checking it out and letting me know what you think? https://github.com/geolessel/react-phoenix/tree/server-side-rendering#5-optional-enable-server-side-rendering The readme points to the hex docs for the module, but since this isn't on master, it isn't on hex yet. You can read the module docs here: https://github.com/geolessel/react-phoenix/blob/server-side-rendering/lib/react_phoenix/server_side.ex
I've got an experimental branch going that adds its own server-side rendering. Would you mind checking it out and letting me know what you think? https://github.com/geolessel/react-phoenix/tree/server-side-rendering#5-optional-enable-server-side-rendering The readme points to the hex docs for the module, but since this isn't on master, it isn't on hex yet. You can read the module docs here: https://github.com/geolessel/react-phoenix/blob/server-side-rendering/lib/react_phoenix/server_side.ex
It looks like Schrockwell has mentioned this already, but I just recently announced a package that will do just this. I use react-rails all the time and I just wanted react-rails in Phoenix. My focus was on ease of setup and use (and staying with the default of brunch). I'd love to get your thoughts on it. https://github.com/geolessel/react-phoenix/ I've also got an experimental branch going that adds its own server-side rendering. That will hopefully be in master soon.
Can you link the app? I tried to build something similar but I ran into an issue with phantom js. For my project, I needed to use Hound so I could interact with some JS on the page before I scraped it. I have not been able to figure out how to run this concurrently because I can't figure out how to spin up new phantom js processed for each call. Do you have a way to address this? 
Thank you, I had already read and bookmarked it. It really is a great article and I think I've learned a lot from reading it.
https://labs.uswitch.com/genstage-for-continuous-job-processing/
This looks like exactly what /u/MaximumStock wanted
Looks good to me!
I would send the Processing Module when building the scrapper. Scrapper.start(%{ some: 'params', here: 'if needed', processing: [ExtractLinkProcessor, ExtractCSSProcessor] }) For instance I have created a bot that has many commands / features I wanted to split easily. I created a list of module that is used to handle everything. I think you could apply the same behaviour (take a look here : https://github.com/Grafikart/GrafikartBot-Elixir/blob/master/lib/discordbot/bot.ex#L17)
Looks good. I'll have to try it out. react-stdio depending on a specific version of react is kind of a pain, I guess. But that's not really your issue ;)
I just have finish Mizur : https://github.com/xvw/mizur ! 
If `--learn` didn't sound good, `--watch` or `--pause` could work. 
The biggest impediment to learning elixir and Phoenix for me was constantly asking 'which module does this functional come from?' In particular I was very confused about Controller.render vs View.render vs the render function in my own view modules. Having an alternative form for the generators that didn't assume any imports were present in the web.ex mixins would help a lot.
An Imgur API client: http://github.com/jordanadams/imgur-elixir Core functionality is there. Slowly finishing the implementation of all the endpoints. _Ignore the install instructions. It'll be on hex once the endpoints are done :D_
I've been working over the past few months [on a piece of software for veterinary teams](https://instinct.vet/), to help them keep track of care and treatment. The server component is a couple of OTP apps built with Elixir and [Absinthe](http://absinthe-graphql.org/). No source to share for now but I can't recommend Absinthe enough! This library is absolutely awesome if you need to build an API server, it's been such a time and headache saver (using it with Apollo). Edit: Absinthe 1.3 is out - huge update including middleware. I contributed by adding built in date / time types. :)
Cool little trick, if you're strictly curious about knowing which hands rank where in relation to which other hands (say in an AI). While there are C(52, 5) different hands you can have, having 4 diamonds and a heart is the exact same thing as 3 clubs and 2 hearts, etc. so it collapses down to ~2.5k hands. Now the next observation we make is that for most hands, suit doesn't matter, but if it does we still need a way to distinguish it, but again, a flush in hearts is the same as a flush in spades in terms of card ranking. The trick we now pull out is the Fundamental Theorem of Arithmetic, which says that for some natural number N, N can be factored into primes in exactly one way, excluding permutations of the factors. We take advantage of this and assign each card a prime number. 2=2 3=3 4=5 ... A=41 Now, by multiplying the prime numbers together, we get things like a 2 3 A K Q hand is 2 * 3 * 41 * 39 * 37, and if they are all the same suit, you multiply by 43. You can then take these 2.5k hashes, rank them against each other in a lookup table, and know in constant time for the number of hands how hands rank against each other by just multiplying their card's values together with either 1 or 43 if same suit and seeing where it falls in the list.
How does this differ from [bypass](https://github.com/PSPDFKit-labs/bypass)?
One option is to get a Piratepad, write a rough 2-3 page article outline, and invite others to contribute. Or do it on Github. Once people saw the 1st draft, they might join in. We could be waiting years for Head First to get round to it. ¯\\_(ツ)_/¯
I'm working on writing a type safe language on top of the BEAM. It's written in Elixir and targets the Elixir AST. After the Elixir AST is generated it's quite easy to produce native BEAM bytecode. I would say the language is comparable to the ML family of languages and Scala. In my language type signatures are required for each function in a module and anonymous functions must be annotated with types. I don't find it terribly verbose and I think it adds to the clarity and intent of the code. Everything else is inferred, so it does have local type inference. Right now all of the work is being done locally but once I finish up a few more features (Finish up polymorphic functions, ADTs) I'll throw it into a repository. 
W...wow. That is an amazing trick! A serious TIL!
This was for future use-cases in case I wanted to reuse the Hand logic elsewhere. Now that you've mentioned it, I could have probably structured it better. Good spot :)
bypass has a more functional API though and simply uses plug. rodeo seems to force you to define modules for every option.
Yes I'll fork it. Writing rough notes here for later. - Learn how flags like --no-ecto, --no-brunch and --table are recognised: [Mix Phoenix.new](https://github.com/phoenixframework/phoenix/blob/7fbf4fc0567a3276c978b434c4f0c658228af276/installer/lib/mix/tasks/phoenix.new.ex) - Work out how to pause scripts: `mix? = install_mix(install?) brunch? = install_brunch(install?) extra = if mix?, do: [], else: ["$ mix deps.get"] ` - Mix Raise: `@spec raise_with_help() :: no_return() defp raise_with_help do Mix.raise """ `
I did not know of bypass when I wrote rodeo. Thanks! Looking at the usage example, I feel rodeo requires less code + setup in my test case.
Have you seen [Alpaca](https://github.com/alpaca-lang) :) Sounds like they've got similar goals so that could be something to get ideas from.
I have! I definitely have taken some inspiration from Alpaca. I think the concurrency model is interesting. I have yet to decide how I want to handle concurrency and side effects. I think once the early draft of my language is usable I'll create some discussion and get some opinions. 
Thanks! Our team just ended up deleting web.ex and adopting a no-imports coding style guide. Unqualified function calls always refer to a function defined in the current module, and all others are qualified with a module name or alias. 
Thank you for work. Is there any chance you would consider a more functional API instead of one that relies on macros? For example, with_webserver should be a regular function, there is no reason for it to be a macro and no reason for it to inject variables into the user code. For example: with_webserver Teapot, fn port -&gt; assert HTTPoison.get!("http://127.0.0.1:#{port}/") == "I'm a teapot" end In the code above, you don't need to worry if the do/end block changes the semantics of your code and you don't need to worry about magic variables such as `port`. Everything is cleaner. 
Plug support is deinitely planned. The module definition is by design, allowing for resuable code over different test cases. But even without the need to reuse a handler module: since they only need to implement 1-3 functions, they produce little overhead when defined within the test case itself. Passing a function or a simple tuple (`{status_code, headers, body}`) might be a good feature, though, yes.
tl;dr - give it a try and benchmark it! If you're seriously interested in playing with it, I'd personally encourage you to give it a shot. You might find this fledgling NIF project interesting: http://stackoverflow.com/questions/5300910/erlang-bindings-for-cuda-or-opencl Just like in Python, the high-perf stuff would need to be in low-level code - but just because "Python already does it" is not a legit reeason to not try a different approach. There might be some performance gains from not dealing with imperative concurrency that lend themselves better to ANN architectures.
Summary: Don't know about RoR, but I know about python + html + js. It's only easy if your application can work within some really tight constraints, namely the WSGI protocol. The rest of the text is a long and rambly comment in which I try to explain why I think phoenix might actually be easier to learn than the mainstream python frameworks. No comments on RoR because I've never used it. RoR users might weight in with they experience if they want. **Disclaimer**: zero formal training in programming; might have been doing lots of things wrong. The parts where I talk about python's limitations might be hilariously wrong, but I've read experienced python devs say similar things... I don't know ruby (much less RoR) but I've learned python. I actually find webdev in Phoenix more intuitive than webdev in python using frameworks running on top of the WSGI protocol, such as flask or pyramid. In python you have WSGI, which is a protocol you use to talk to a real web server like Apache or Nginx (by the way, Phoenix doesn't need this bexause it ships with the cowboy webserver, which is as real as it gets; sure, you might want to proxy the requests through Nginx, but you *don't need to*). The WSGI protocol also forces you to treat every request as its own little world, with no state or comunication with the rest of the framework. Want some state? Better hit the database? Want something else? Tough luck. So forget event streams, real time comms and background jobs. Well, you can get them, but you need to install something like redis or celery, which run in separate processes which are hard to communicate with (basically a copy of erlang's processes, perhaps :p). Oh, and WSGI is not good for long polling either, as it keeps a thread per open connection. You have gevent, but library compatibility is not the best. If you don't like WSGI, you can use I have tried to use a wrapper around asyncio (aiohtto), which has some interesting capabilities, but AFAIK to get some real multiprocess pubsub you need something like redis running in the background. You also have some blackbox middleware the web framework puts before every request. This includes DB calls and other time consuming operations, thus making it very hard to optimize for performance, and sometimes even makes it hard to understand what's going on. Also, speaking of performance, python is a great language translate your thoughts to code, but it's reaaaaaaly slow. In python, when I had an idea for an app, I'd often ask myself: "how do I do this feature?" I'd read the docs and the answer was often: "Well, do you really need this feature? Have you heard of how super stateless web programming and WSGI is the greatest thing ever and the answer to all out problems?". Some were more direct and would say: "Forget it. If you need this you can't use WSGI". The author of flask, a WSGI wrapper, once suggested in a blog post that a good way of handling real time events was to have a different webserver - not running WSGI - to handle the realtime parts of the app... I don't want to implement a completely different auth protocol for a webserver running on another framework... The problem is that non WSGI frameworks only have the bare minimum functionality, and would force me to implement things I didn't want to (or wasn't qualified to) implement myself, like inter-process communication, user auth and async ORM mappers (python has probably the best ORM in the world, SQLAlchemy, but the good doesn't work with async code). I don't see these problems with phoenix. In pheonix, if I want to implement a feature, I just read phoenix's or elixir's docs and implement the feature. Want realtime sync between clients belonging yo the same user? Pretty hard when using python. Using Phoenix? Just create some phoenix sockets and subscribe them to the user's topic. Want to start long lasting server side job in an Ajax HTTP request that returns a result when the job is done but which doesn't cancel the job if the client closes the connection (i.e. visits another webpage)? What if I want to notify other clients of the result?also not trivial using python. Using Phoenix? Just spin a new Supervisor and run the job using result = Task.Supervisor.async_nolink(:task_supervisor, job) and at when the job is done send a message to the channel. This way the job runs independently of the request controller and the request controller can use the `result` and send it back to the client when it's done. The pheonix way seems to be: think of feature, read docs, implement feature (I'm not at the stage were I need to worry about performance, so I can't comment on that). The python way seems to be: think of feature, think really hard about wanting to step out of the self contained request controller, read about celery, read about redis (maybe even try it out), read about how your long polling / thread based solution will never scale beyond 200 users or so, think of how important this feature is to your app, ask your users to refresh the page to see the changes. This was followed by: 1. try Java, supposedly great with concurrency. On the other hand, too verbose, complicated build workflow, most frameworks seemed to have the same problem as python's regarding real time features. The ones that seemed good (great, even) had demo apps with unreasonably high latency. Way too slow for me to invest time with them. 2. try other JVM languages: 1. clojure is cute but has no actual web frameworks. Also, takes forever to compile and requires developing inside a REPL to get feedback in reasonable time 2. Scala promises that a program that compiles won't crash with a type error but does not deliver... My first program (gut cloned from a project template) using the supposedly super typesafe DB driver *slick* failed at runtime with a type error that the template mantainer couldn't help me with. It has the Play framework which regularly breaks compatibility in minor version releases... 3. Frege, which is a haskell port to the JVM but (like haskell) uses lazy evaluation by default so it's out. 3. Look up go - like clojure, I couldn't find a comprehensive web framework with nice built-ins, the kind I was used to in python 4. Lookup C++ (really!) - apparently good web franeworks, BUT no package manager; very low level, crazy build workflows, horror stories about memory management bugs, which lead me to: 5. Rust - nice low level languge, like C++ it's crazy fast, macro-expansion time HTML statically typed templates BUT no full featured web frameworks, and didn't seem to be a real improvement over python 6. Read something about erlang - crazy syntax, from a swedish telecom company, made for 9 nines reliability globally distributed super complex real time hot code deployment with low level networking - wtf, this is way out of my league, better go away. Guess WSGI is not so bad, after all. 7. Read about elixir and phoenix, watch Chris McCord's presentation, fall in love. After that, look up an authentication library (found coherence), look up and admin interface for ecto (found ex_admin), fall in love further. Python is only easier if you feel comfortable working within its limitations. With time it wraps your brain and you stop dreaming of the application you want to have to focus on the application python allows you to write. There are some python web frameworks not constrained by WSGI such as Tornado or Aiohttp. I can imagine Aiohttp + sockjs as a way of implementing channels and integration with redis to implement pubsub. This would make something comparable to phoenix, feature wise. I don't know what could replace supervisors (maybe celery? I never used celery myself, but from my yet incomplete understanding of supervisors it seems like a passable solution). I don't want to bash python. Python is my favorite programming language for almost everything. My frustration with python is only in the webdev domain, where I felt needlessly restricted in what I could do.
Perhaps you could just expose `rodeo.base_url` instead? Would make usage a bit nicer
Thank you! Units of measurement is one of the things I love about F#.
I am a little confused. Is this something that you would like to see come out of the Elixir community, or is this a project that you yourself are planning on leading? &gt; * Take no cut. Giving project funders one hundred percent of funds raised, only asking for tips if they're successful. &gt; * Curation/quality-control would be done by the crowd using upvotes, reducing the need for staff. Given these two points, how would you plan on paying the staff, or even pay for the server costs? &gt; * Focus on USEFUL products that re-energize neighbourhoods If this is meant to be neighbourhood specific, why would I want to use this service over posting something at my local community centre? I am not trying to deter you, or anyone else, from building something like this. These are just the first things that come to mind.
yeah, this post is confusing O_o
I decided to delete the OP, and repost it when it's edited better, + I have an open-source prototype to show. Thanks for your feedback, sorry it wasn't clearer! 
Thanks! You're right, English is not my first language, I need to add it to the list of things I need to learn :D
For the basics of Elixir: * [Getting Started](http://elixir-lang.org/getting-started/introduction.html) * [Elixir School](https://elixirschool.com/) * [Lauren Tan's talk](https://www.youtube.com/watch?v=r4ulu8wo_GI) at ElixirConf For FP concepts: * [F# for Fun and Profit](https://fsharpforfunandprofit.com/) * I think that [this post by Saša](http://theerlangelist.com/article/spawn_or_not), even though it's about processes, gives an excellent overview on how to (and why) write a program the functional way. 
I wish I had seen this earlier. I just spent the past two days going from Phoenix 1.2 to an umbrella project. It was not a fun process. I think the way things are structured in 1.3 would make it a little nicer. 
This project is insane, and you are a good person.
Cool project! &lt;3 Elm, Elixir, compilers, etc I'm curious about a few things: 1) Why not write the compiler in Elixir or Elm? Javascript seems like an odd choice. 2) Why not target Erlang or Core Erlang instead of Elixir? The compiler is is now Elm -&gt; Elm AST -&gt; Elixir -&gt; Elixir AST -&gt; Erlang AST -&gt; Core Erlang -&gt; BEAM, which seems rather over the top. All the extra stuff Elixir gives you over Erlang (i.e. Macros) are lost when using it just as a target language for Elm. 3) How are you managing side effects? Elm is a completely pure language, seems like it would be hard to integrate into the Elixir &amp; OTP ecosystem with such a different way of working. Also, have you checked out [Elmer](https://github.com/elmer-compiler/elmer_compiler) or [Alpaca](https://github.com/alpaca-lang/alpaca)?
1) The compiler is written in Elm, but Elm compiles to JavaScript, and the example takes lion part of the codebase 2) The answer is: Tooling. By targeting Erlang or BEAM you sacrifice all of the goods that people wrote for Elixir already. Which is mix, hex, nice testing libraries and so on. I really like them :D 3) You don't really have much side-effects in Elixir except for sending messages, and they also aren't used that much. Most of the time you just implement pure-ish GenServer. You can see one in the example And yes I've heard about Alpaca, and also about Purerl. Haven't heard about Elmer, but the project seems abandoned. Purerl is obviously another thing, while Alpaca is a great project and I'm looking forward to see it develop, but developing a language from scratch is a huge-normous-gantic project, and I'm afraid it might be too much of a time sink for the creators
Ah! My bad, I was tricked by the yellow bar. If you stick it in a `dist` or `vendor` directory I believe github will be clever enough to not count those lines. I feel if I were to try and write pure Elixir code and shun use of `send`, `GenServer.reply`, `:ets`, etc I'll still end up at some point needing to use some side effects. Is abstracted away the canonical Elm runtime does i.e. with `Cmd msg`s. Or can we use an IO type, or extendable effects in the style of Purescript, or something else? I'm really interested in how Elm would manage side effects when we don't have TEA :) Hex works great in Erlang projects, and I'd say rebar3 is possibly even better than mix. There's nothing stopping us from using mix to build an Erlang project or rebar3 to build an Elixir project, so perhaps the Elixir target isn't quite so required? ExUnit is a tricky one though, its failure printing is much nicer than Eunit's and I miss it when I don't have it. Hopefully one day someone will add the pretty diff-ing to Eunit. :)
Not to mention errors `bad_argument`. That tends to hurt ;) I didn't know that rebar3 is so good right now. I left Erlang language right after it came out. And it was half-baked back then. We'll see about side effects. The project is really early stage. But I believe any problem can be solved some way. There is no flawless idea. And I'll develop this one until the flaws will become worse than gains.
Also just noticed the live demo. That is super cool. &lt;3
I feel it's probably fairer to say that this (at least right now) is an Elm-like language. startLink : a -&gt; Pid startLink default = ffi "GenServer" "start_link" ( Stack, default ) This code from the example has FFI, has side effects (that are not even expressed in the type signature), and is partial. I feel any one of these is enough for a language to qualify as significantly different from Elm, even if the syntax is almost the same.
&gt; Which is mix, hex, nice testing libraries and so on. Non-macro Elixir libraries can be called from plain Erlang just fine. And Hex can deal with Yecc, which compiles to an Erlang AST just like Elixir does.
There's a slack group in the subreddit sidebar. I'm on mobile otherwise I'd paste the link Edit: I'd like to note that I'm not sure of the degree new-person support it has, I don't check it very often. 
Is there a good tutorial or something on using raw postgrex instead of ecto. 
Check out http://elixirforum.com 
Pretty sweet. Any way to call Repo.get() and still preload associations?
`Repo.get(MyType, id) |&gt; Repo.preload(:some_assoc)`
Use the IRC channel
credo might help
This might help [style guide](https://github.com/christopheradams/elixir_style_guide).
I agree with all the advice so far, particularly reading code from major libraries. When I first started with erlang, I was surprised at how much easier it was to read other peoples' erlang code, and I'm really happy that elixir code seems to have the same property. But I'd also add in that playing around and getting yourself into trouble is a great way to explore. See how far you can push things, see what the downsides are. Play around. See what it takes to pipe through an operator, for instance, or pipe through a `case` statement. Try out the `with` statement. One fun exercise would be to write a bunch of Enum/Stream statements and then roll your own recursion. And then reverse that...solve something via recursion first, and then move it to Enum/Stream. Do the same things with for comprehensions. You don't even have to go into macro-land to really push yourself as a beginner. If you push yourself into challenging territory, you can see the logic behind some choices that might only seem aesthetic in the way elixir "idioms" have emerged. A lot of the idioms people come up with are based around refactoring and clarity, and a good way to do that artificially might be solving coding exercises in as many strange ways as possible.
One of the exciting/challenging things with elixir is not the base language itself but the underlying erlang/OTP mindset + the unique take that elixir has on functional programming. There are certainly some idioms in the language itself, but id say making the mindset shift from imperative programming to functional programming is what initially caused me the most head scratching and subsequent stretching of my problem-solving skills. Then you layer on the notion of processes + supervision that you get with OTP, and you begin to see that entire trains-of-thought on software design that you might be used to go out the window. Managing state becomes an explicit construct with things like Agents and genserver. Enumeration using recursion becomes a go-to construct instead of something to be shunned. Things like concurrency and distributed workload become "easy". The list goes on and on, but I would say to buckle in and get ready for one hell of a ride if you haven't gone down the rabbit hole yet. 
I think the forum is a better venue for asking questions. While you can get help on the slack channel there tends to be enough activity of others posting that your question might get lost. At least that's my experience.
Yeah, this is what I'm trying to avoid.
 from(u User) |&gt; where([u] i.id == ^id) |&gt; preload(:todos) |&gt; Repo.one()
Made a 750words.com clone using Phoenix + Elm. https://github.com/MainShayne233/five_hundo Demo is at http://fivehundo.herokuapp.com (password: five_hundo)
Looks good, especially with the new 1.3 database structure. It's more memorable for students if you make an interesting example app, Geo does that here: http://geoffreylessel.com/2016/f1-standings-with-ecto/
Stackoverflow is pretty friendly to questions tagged elixir. You'll generally get an answer within a minute or two of posting.
Some open source phoenix apps to check out: https://www.reddit.com/r/elixir/comments/611l69/awesome_opensource_projects_made_with_phoenix/?st=1Z141Z3&amp;sh=befaec18
It entirely depends on the application. Before assuming that a single query will actually be better, you should profile your application to find out what parts are taking a long time. Also note that on the Elixir side of things, if you are preloading multiple associations, Ecto will do those queries concurrently. Which may mean that it will actually be faster to do multiple queries. Just a couple of things to think about.
What syntax exactly specifically besides having terrible memory?
I highly recommend [Programming Elixir 1.3](https://pragprog.com/book/elixir13/programming-elixir-1-3) by Dave Thomas as a starting place for learning Elixir, and I also recommend backing off of Phoenix a bit until you have a firm understanding of the basic syntax and principles of Elixir. Phoenix is a fantastic project, but it is _not_ a great way to learn idiomatic Elixir. Once you're feeling comfortable with Elixir in general, I'd move to [Programming Phoenix](https://pragprog.com/book/phoenix/programming-phoenix) by Chris McCord. Phoenix as a whole is a _lot_ easier to grasp once you've taken hold of how to do functional programming properly. I know it seems like a lot of reading, but it will absolutely pay off.
I think you're hoping that someone here will have a silver bullet and you'll magically be a Phoenix Ace in a month or two. Learning to code in general isn't really like that. There is a huge perseverance component and that feeling you're having now of "admitting defeat" is normal. I think that we're trained to believe that we can do anything we put our minds to but there is a lot of hard work that goes into being a proficient coder. I started learning Haskell over a year ago, and couldn't wrap my head around it. But I didn't give up, I took a different route via Elixir and now Phoenix and Elm. I've learned core concepts that helped me understand other things that I was having trouble with. Some others have suggested you focus on Elixir rather than Phoenix and I definitely agree. I couldn't understand Phoenix without spending a decent amount of time on Elixir. Phoenix leverages many things in Elixir but hides the complexity from the developer so it makes it harder to know what components are responsible for. /u/_tsuujin has provided some good places to start on Elixir. I suggest you think of specific questions that you're struggling with and hope onto the Elixir Slack group. There are channels for all your needs and the community is very welcoming and helpful. Or ask around here. Good luck, and don't give up.
Exercism helped me get a good handle on the syntax. If you're coming from Python, you need to remember that you're using "dumb" containers; you're not calling methods on the containers, rather you are calling methods in the type's module to do what you need. So, instead than thinking "I have a dict, so I'll call .keys() on it" you have to think "I'm working with a map, so I'll *pipe it through* (or apply) Map.keys" in the same way you'd call len(), map(), filter(), etc. Easiest way to get used to this is to have the docs open in a browser nearby, then when you want to do an operation stop and think about what it is you're operating on (a list, say), then go straight to the docs and look at that module (Enum, for something iterable) and look at the methods in there. Then, start with your item and pipe it though that method, e.g.: myitem |&gt; Enum.at(2) Takes a bit of time to stop thinking like "for item in thing" and switch to "with this thing, do this, then that, then this, then that" (thing |&gt; that |&gt; this |&gt; that) especially if you haven't done much pipeline processing on the terminal, but it's worth it. Also, try and leverage pattern matching. Write lots of small functions to split your processing up into smaller, easy to read chunks, and use pattern matching and guards to selectively apply them. Exercism can help learning this, and it helps keep your code clean.
Exactly this. When I started learning Elixir I had experience in Haskell and Python which really helped. However, I dived into using Phoenix straight away and now I am having to go back and in many cases start from scratch with many parts of my code. I found the [slack community](https://elixir-slackin.herokuapp.com/) to be really good and friendly too.
Yeah, I couldn't fully grasp it as well until I calmly sat down and took my time to go over that book. Also, try to do the exercises on the end of the chapters without looking the answers first. 
This one is a bit unconvetional but have you tried writing the code down by hand into a notebook? When I'm learning a new langugae, syntax tends to be the hardest part for me as well. I find that looking at source code and writing forces my brain to engage it in new ways and syntax ends up sticking better. Try it! may work for you. I learned javascript, elixir, haskell, rust and python this way.
Awesome! Looking forward to reading it.
2 questions; 1. Have you considered the ramifications of the Phoenix 1.3 changes? Sticking to pundit's style of API under 1.3's recommended structure seems trickier to maintain the level of magic. 2. What does rampart bring to the table over [bodyguard](https://github.com/schrockwell/bodyguard)? (genuinely curious if I'm missing something - I'm not trying to be hostile :))
How is this different from the other faker libraries? https://hex.pm/packages/faker or https://github.com/marocchino/ffaker
Thanks everyone for great suggestions. My journey as a new alchemist has just begun. Wish me luck.
Thanks everyone for great suggestions. My journey as a new alchemist has just begun. Wish me luck.
Why do we need convention based frameworks for authorisation? Is it so hard to call `MyAuthModule.authorize_index(conn)` from a controller? Elixir shines when the data flow of the application is explicit.
I would say some useful helpers such as unique, cycle, possibility to set a locale at runtime, possibility to hook the data ... 
I do agree with things being explicit, although I would argue that Rampart isn't exactly a convention based framework. Certainly not to the same degree as something like Rails. The only part of Rampart that is non explicit really is the specification of the action that is being called, but there is nothing stopping your equally from simply calling the policies authorization function directly. It would be almost as simple to wrap authorization into your own module and call it as you suggest, and this would be a lot more explicit, but for a larger application I imagine you'd end up with writing quite a bit more code just to be slightly more explicit. At the end of the day I think it boils down to preference. I don't think Rampart is hiding what is going on to the point where you have to start hunting for things, but equally if you prefer to be 100% explicit about what's happening then you probably don't gain a massive amount by using something like this. It just simplifies things slightly :)
1. I thought the primary changes to Phoenix 1.3 were around the applications folder structure and the changes in the generators? That and the 'contexts'. In theory, using this in the contexts (or ANY module for that matter) would be very easy, as the function name would just be taken from wherever it is called, or specified, so using it in a context would be the same as in a controller (so long as there is the conn). It might need adjusting to allow it to operate without a conn for use in those modules but I don't see that being a massive issue. 2. ha to be perfectly honest, probably not all that much. I had a very brief look around and couldn't really see anything so I never found BodyGuard. Looking at it, it would appear though that BodyGuard has slightly more functionality. I guess my main gripe with it is I don't like the `can?` functions in the policies, but that's just a personal preference as apposed to a disadvantage of the library.
Nice work ! Thanks a lot ! 
I found the Elixir path on exercism.io to be a very effective and practical hands-on way to get thinking about functional programming and writing idiomatic Elixir code. http://exercism.io/languages/elixir/about Being able to review code and ideas from other devs on that site attempting to solve the same problems was a big help as was all of the direct feedback from those same devs when they commented on my own code submissions. Best of luck whatever path you take.
It should be pretty simple to implement the Phoenix messages in a Ruby client. I wrote a C#/Reactive Extensions client (https://github.com/bratsche/kastchei). I basically started by just writing a simple Phoenix app with some channels and went into the Chrome devtools and observed all the messages there. After that I looked in the Phoenix JS sources to answer any other questions I had.
So in my config I have this : config :spellbook, Spellbook.Repo, adapter: Ecto.Adapters.Postgres, url: System.get_env("DATABASE_URL"), pool_size: 20 And I am setting the variable in the terminal like this before trying to start the server. DATABASE_URL=postgres://{username}:{password}:database.30dkaneh8.us-west-2.rds.amazonaws.com:5432/{database_name}
Thank you mate :)
So... not trying to be a jerk, but I think it's important to understand how environment variables work - I apologise in advance if you do and the following examples are moot: foo=foovalue iex System.get_env("foo") Results in `nil` On the other hand, foo=foovalue iex System.get_env("foo") results in `foovalue` Because... command line set environment variables are process-specific. _Unless_ you export them. export bar=barvalue iex System.get_env("bar") Will correctly yield `barvalue` So... either set DATABASE_URL in the same command that starts the server, or export it, then start the server.
You should specify your `DATABASE_URL` using the tuple: `{:system, "DATABASE_URL"}` as shown in the example in the docs: https://hexdocs.pm/ecto/Ecto.Repo.html#module-urls Also, I think the new recommended approach is to implement the init callback in your repo module and read the variable explicitly from the system environment, see https://hexdocs.pm/ecto/Ecto.Repo.html#c:init/2
Let us know if you fixed it.
So this was an issue, I did need to change the : -&gt; @ after password. Thanks for pointing that out.
Check out the section in the docs for [Migrations](https://hexdocs.pm/distillery/running-migrations.html#content). 
I wanted to play around with Elixir hot reloading but on a minimal snippet, and ultimately ended up generating live midi events. Code is available on [github](https://github.com/thbar/demo-elixir-reloading-music/blob/master/README.md) and slides are on [speakerdeck](https://speakerdeck.com/thbar/elixir-hot-reloading-and-midi-events-generation). Let me know if you have questions!
Thanks! Definitely an inspiration!
Damn Phoenix seems nifty as hell. As for the templating part, I'm pretty sure I misspoke. Before I say anything wrong again, [here's the Wikipedia explanation](https://www.google.com/search?q=what+is+haml+used+for&amp;oq=wha&amp;aqs=chrome.1.69i57j69i59j0l2j69i61.1438j0j4&amp;client=ms-android-sprint-us&amp;sourceid=chrome-mobile&amp;ie=UTF-8) of Haml and [here's an example](http://stackoverflow.com/questions/15895551/using-angularjs-within-haml-views-of-a-rails-app) using Haml and AngularJS together 
Non-Mobile link: https://en.wikipedia.org/wiki/Haml *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^64582
I do know that for my VMs and containers, I had to install OpenSSL. Do you have openssl installed wherever this is being deployed?
the server has openssl version 1.0.2.g
I am going to be digging into Gitlab's build/deploy pipeline with the goal of getting CD working for Elixir/Phoenix projects.
I've been working on a platform-as-a-service for Elixir apps for the past 6 months and just launched the beta. It supports umbrella applications and can scale to multiple nodes. It even allows you to cluster your nodes using distributed Elixir as well as hot upgrades and remote observer. If you're interested in a beta invite, let me know. Or you can fill our the beta invitation request at www.gigalixir.com.
Just wanted to point out that if you're interested in distributed Elixir, but also want the simplicity of a platform-as-a-service like Heroku, you should consider www.gigalixir.com. Full disclosure: I'm the founder.
I'm working on a platform-as-a-service for Elixir apps. www.gigalixir.com. http://gigalixir.readthedocs.io/en/latest/main.html#what-is-gigalixir
definitely. I think Heroku gets most of the way there, frankly (tough to beat "git push heroku master" to deploy), but has some glaring flaws when it comes to taking advantage of Elixir's capabilities. There is definitely a market IMHO for an Elixir-focused deployment solution.
It's not an OTP app, but the Exleveldb wrapper library is documented and very beginner friendly reading.
gigalixir actually also uses "git push gigalixir master" for deploys, but does things very differently behind the scenes.
Hey, I'd be happy to give it a shot with my staging environment and give you feedback on it... I'll be honest though, I'm a little wary of putting production code into a new PaaS. Heroku, expensive though it is, I've got a lot of experience with and I know where the dark corners are. I assume you're reselling another cloud here; which cloud are you on? What makes gigalixir different from say just using kubernetes on google's cloud?
Not elixir, but everyone should red the readme for re-frame: https://github.com/Day8/re-frame
[Rust](https://www.rust-lang.org/en-US/index.html) is a functional systems language that'd be pretty good if you've come from a heavy C/C++/C# background. [Here is a comparison](https://www.slant.co/versus/1540/5522/~elixir_vs_rust) of Elixir vs Rust if you're interested.
I also believe that rust is a good option, but that Slant comparison seems to be pretty hard on Rust side. Rust is used now by Dropbox on its core, that seems pretty tested to me, async io seems pretty robust at least on Tokio and the rust documentation is pretty good, also the book and rust by example are there. As a side note, someone is implementing the actor model in rust https://github.com/andrewjstone/rabble
The icons above Node clustering, hot upgrades etc. are not working for me. Just square boxes.
Very interesting read! I was actually considering building a phoenix/Vue application decoupling the API and the UI so they could be developed separately. Our current tools use RoR which renders Angular pages, which might be the the worst option.
I haven't tested DETS or Mnesia specifically, but I don't see any reason why they wouldn't work. Yes, you get a writable volume available within each container, but the volume is not persistent and will be lost if you restart the container. Restarts should be very rare, though.
Just let me know when you want a beta invitation or you can fill out the form on www.gigalixir.com. I'll also be happy to throw $75 on your account for helping us test the beta.
Rust is on my list for sure, although comparing Elixir and Rust isn't very fair as they target vastly different use cases, imo.
I felt reading OTP source itself was useful. Slightly confusing at times but that + the Elixir GenServer docs has worked well for me. Granted, I've also read Elixir in Action and like books to get a feel for OTP at a high level. Nothing beats the docs/source for getting intimate with it though
Awesome. Thanks for that first link because its a phoenix 1.3 app. 
From my experience there are significantly more people in slack than in irc, although core elixir developers and other popular libs developers are usually in irc. Personally I prefer Slack, someone usually has time and courage to answer my newbie questions :)
Having done some Clojure before jumping on Elixir and being familiar with re-frame, I can only recommend reading it. 
Slack. Never been to the IRC. One thing is that it's the "free" tier, and the community is apparently big enough that 10,000 messages is just a couple of days, so the history of a channel frequently only goes back a very short time.
+1 on "One and Only One Process in a Distributed System" by Nathan Herald. Informative and entertaining.
It's probably not widely used, but my go-to stack is a React app on the front, backed by Create React App tooling, a GraphQL data layer with Apollo client on the front-end and Absinthe on the back-end, and a Phoenix server holding everything together. I'm using Postgres as my de facto database, when I need one. I've written a few articles describing how to set this kind of thing up. Maybe they'll help, or give you some ideas? http://www.east5th.co/blog/2017/04/03/using-create-react-app-with-phoenix/ http://www.east5th.co/blog/2017/04/10/using-apollo-client-with-elixirs-absinthe/
Thanks for sharing this! I'm Alekx and I produce ElixirCasts. If you have any topics you'd like to see covered in the future, please let me know in the comments. Cheers!
This looks absolutely awesome. 
Wasn't able to make it, any idea if the talks will be posted, and if so when/where?
If you search on YouTube you can find some talks from last year, so I expect they will be(?)
STAY
DEALER WINS Dealer: 20 __ __ __ | || || | |QS||5C||5D| |__||__||__| Player: 13 __ __ | || | |9D||4S| |__||__| ^^Made ^^by ^^/u/Davism72. ^^Send ^^feedback! ^^Source: ^^https://github.com/mattdavis1121/reddit-blackjack-bot
There is rocket in rust, which is not as fast as iron, but still is faster than phoenix. https://github.com/tbrand/which_is_the_fastest
There will be a video on Youtube ?
That's definitely on the list :) Thanks!
Wao, thank you, I gonna look at it :D 
Awesome, thanks! Just about to begin Elixir and it definitely lowered the rate of 'mini-wtf-heartattacks'.
This doesn't seem to do anything. `sudo make install` copies files over and completes fine, but nothing is held over between iex runs. in `~/.erlang-history/`, 3 files are created: `log.1`, `log.idx` and `log.siz`, which all appear the same no matter the content of an iex session. Anybody have ideas on troubleshooting? 
For me it works in both ctrl+c ctrl+c and System.halt. You could open an issue on github
&gt; This content is only available to registered subscribers.
are you sure this belongs to /r/elixir ?
We've heard whispers of them being made available in the next week. Watch this space...
I have not seen this, but it seems like it's more focused on Phoenix in particular and not as much on intermediate/advanced Elixir/OTP like you say you're looking for. As far as books go, `Elixir in Action` is good. It's an intro book, but it's the best intro book there is in my opinion. It's better at explaining things like GenServer than other books. On the more advanced side is `Designing for Scalability with Erlang/OTP`. That one is in Erlang, not Elixir, but it sounds like that wouldn't be an issue for you.
I'm pretty sure he wants to remove the Ruby backend and replace it with an Elixir application. His question was how much different would the client code be to switch to phoenix. Honestly I don't think it would be too bad, but the complexity would actually be the Rails Action Cable client JS. You'll find using the phoenix JS client is surprisingly simpler. IMO, the Action Cable JS library is trying to use too much OO and Ruby influence.
Oh yeah, I think you're right. Sorry if I misread the first time. :)
Thanks :)
Is ECTO similar to hibernate ? Does anyone who knows both well enough compare in what ways ecto helps you avoid the performance problems and complexity of hibernate.
tl;dr we produced five weeks of free [DailyDrip](https://www.dailydrip.com) content introducing people to everything from the basics of the language up through making your first Phoenix app. From there, we're going to continue producing content as we build out [the firestorm forum](http://www.firestormforum.org)
for starters, it's free. and if you subscribe to our service we have over a hundred hours of content on elixir, elm, and more
If the quality of these courses are anything like elixir sips, you're better off spending the $10. Was never impressed. Seemed low quality. 
Really cool idea! Is the generated application a standalone binary?
That's a good question. It's not a standalone binary: file ./app ./app: a /usr/bin/env escript script executable (binary data) So in order to run it requires escript http://erlang.org/doc/man/escript.html to be installed (which includes in default elixir/erlang toolchain) I am going to add this to readme description 
Thanks a lot for your answer José! Looking forward to see the new project you're working on :) 
Does this mean I can simply rearrange my folder structure and potentially my application/supervision tree structure and be up-to-date with 1.3? Edit: Nevermind I found the migrating guide.
It's easier than that – you can simply bump your phoenix dep in `mix.exs` to `"~&gt; 1.3-rc"` and change nothing else :) Of course you can also follow the upgrade guide which walks you thru updating to the latest directory structure conventions.
Any word on how 1.3 release is coming along? I just started a new site project on 1.3-rc. Mostly painless, any hiccups just taught me bits I didn't know ;)
It looks like it's already fixed in master: https://github.com/elixir-lang/elixir/commit/627a3070ce9020fa4abfa17435558fda1944ed32 and https://github.com/elixir-lang/elixir/commit/2a900db540697504758da11284125a14591497fe
Yet, I think that the concept of "models" could be preserved :)
This is a good way to think about it. The important thing is Ecto.Changeset and your schemas are *data structures* that you expose over your public APIs. Forms and parameters in phoenix are protocol driven. The `phoenix_ecto` project implements `Phoenix.FormData` and `Phoenix.Param` protocols for Ecto so you get support for changesets out of the box. So it's not coupled to Ecto in any way and you can implement those protocols for any data structure in your domain. So the ecto "details" that fall out of our apis are only public datastructures – the internal details around how persistence happens with business logic is the hidden part.
Thanks for the clarification, Chris. Since `Ecto.Changeset` is so decoupled from the actual underlying database (folks are using them [as form objects](https://blog.lelonek.me/form-objects-in-elixir-6a57cf7c3d30), etc.), is there any internal movement towards splitting it into two libraries, ostensibly one being "schema + changesets" and the other "database persistence"? It seems like a natural progression, but it's probably not easy, and I don't know how it jives with Ecto's goals.
I'm planning to go over moving the env vars into secrets in the next part, so that's coming soon. Thanks for the tip about conifgmaps! I didn't know about those but that's exactly what I've been looking for. I might add that in to a future part where I talk about keeping your deployments identical between staging and prod. I didn't want to make this post too long or overwhelming by going over all the deployment options, but since my example uses 2 replicas and the default for maxUnavailable is 1, the example configuration should also have zero downtime deploys. Thanks for the feedback!
Ah, I remember now -- a quick search jogged my memory. The process I'm talking about is the one mentioned here: ["Specifying ImagePullSecrets on a Pod"](https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod) &gt; This approach is currently the recommended approach for GKE, GCE, and any cloud-providers where node creation is automated. It's more of a yak shave to set up, but once done, I'm not relying on any google-environment-specific k8s support. Same config works for slow e2e tests, etc. Agreed re: not disheartening newcomers and using local docker in minikube!
What didn't you like?
The Phoenix book has a single edition which targets 1.1 and should work with 1.2 without many problems. The new edition will target 1.3. Given the book is still 6 months away, I would recommend getting it now. We hope we can provide free updates but unfortunately I cannot guarantee it in any way.
The contexts are still useful, yes. Within an umbrella application it serves as the "public API" if you will. Additionally, it allows you to quickly see which applications are crossing into what other applications. Detecting crossing of concerns is what umbrella and contexts are designed to help with.
This isn't a solution, more of a workaround, but have you considered using chocolatey? https://chocolatey.org/packages/Elixir
I have tried chocolatey but when installing via chocolately, I get this error when attempting to install hex: ** (Mix) httpc request failed with: {:failed_connect, [{:to_address, {'repo.hex.pm', 443}}, {:inet, [:inet], :eacces}]} Could not install Hex because Mix could not download metadata at https://repo.hex.pm/installs/hex-1.x.csv.1
Or maybe download the precompiled Elixir zip manually https://github.com/elixir-lang/elixir/releases/download/v1.4.4/Precompiled.zip
Awesome write-up, thanks very much! I'll have to try Phoenix again for my next project.
&gt; Pretty sure my app leaves tons of crap behind when records are deleted Postgres allows for these types of ON DELETE scenarios! As long as you're using foreign keys, the database will handle cascading deletes for you very easily. Definitely worth the time to learn!
Concepts of contexts and umbrellas are similar in a way, because they help in maintaining boundaries and isolation between parts of you system, but umbrellas are much more strict. The definition of Erlang application is a functionality that can be started and stopped as a unit. Lets say we are writing a blog and we have commenting subsystem. How much is it integrated into your application? Is it like Discuss where even if the blog post itself is offline, you can still view and respond to comments? No? Then probably it is tightly integrated with your blogging engine. It still should be in its own context to separate concerns, but it might be using the same underlying database. Yes? Then it is more like Discuss, a separate subsystem with separate storage and it is a candidate for extracting to umbrella. The rule of thumb is to use umbrellas where you can use separate storage and contexts everywhere else. Many quite big apps use only one database. It doesn't make sense to configure them separately in Umbrellas and you can't stop one part without bringing entire system down. It doesn't make sense to extract them to umbrellas, but you still don't want to tangle stuff to much. For example your blog post module should not use any internal functions of commenting subsystem just because it is in the same app. You can separate those in contexts and you will quickly see when someone uses deeply nested function in wrong module: Comment.Author.Name.smartly_truncate(blog_author_name) Blogging susbsystem using a function deep down from commenting subsystem smells fishy. At first glance you see that you would rather extract name handling functions somewhere or even duplicate the code in case where `smartly_truncate` should behave differently for comment authors and blog authors. Should we extract only `Name` or entire `Author` module? Contexts make you _think_ about it upfront. If you didn't have contexts and only flat structure, there would be a module called `Author` which could use module called `Name` and then someone in `Blog` would use `Author.smartly_truncate` and someone in `Comment` would use `Name.smartly_truncate`. Later when someone needs to change the function behaviour only for comment authors someone would add stuff to `Name`, because he grepped in Blog susbsystem and didn't found references to `Name`, so he thought it would be safe... Flat structure can easily get tangled. Contexts are a tree structure where each node should only use functions from modules one level underneath it. This is programming utopia of course, but contexts are gentle push towards better structure.
tl;dr: I made a Rails app in Phoenix. Seriously though, nice write up, and appreciate you sharing your experience. You're just scratching the surface of Elixir and Phoenix, though.
I do have `:on_delete` hooked up: https://github.com/GBH/loaded.bike/blob/master/priv/repo/migrations/20170306121212_create_waypoint.exs#L6 It ensures database consistency, but does nothing if you want to delete files associated with records for example. In Rails world you manage that via `:has_many, dependent: :destroy`. Rails doesn't want to contain any logic on database level. 
That's right. And that's why it's so great. Easy enough for simple Rails-like apps with ability to do so much more.
One of the ways to tackle this is by actually "nilifying" the associations and then have a worker that will remove the nilified entries and associated files. You can use a background job processing to schedule removal but, if that is too much complexity, just have a GenServer that checks the database every hour or so. The trouble with any action that you perform on `after_destroy` in Active Record is that, if for some reason the transaction fails, you will have removed all of the files but the data will still be around. That's one of the reasons why callbacks are so dangerous.
A Phoenix v1.3 API with a React.js frontend. I ended up deploying both projects to a digital ocean droplet. https://github.com/ipatch/kegcopr_api https://github.com/ipatch/kegcopr-frontend
Have an upvote :) The code looks very clean. I'll be poring over all the files. Noice.
If you are doing things inside a transaction, you should use after_commit :destroy_related_whatevers_function, on :destroy This is laid out in the [rails guide for AR Callbacks](http://edgeguides.rubyonrails.org/active_record_callbacks.html#transaction-callbacks)
Yup, I am aware of `after_commit`. I find it a very unintuitive callback though. Everything you do after the destroy operation is by definition happening *after commit*. I would rather write: user.destroy! user.delete_associated_files It feels transaction callbacks exist exactly to solve issues caused by the existence of callbacks. In any case, I am glad to see this exact example is shown in Rails Guides because it is a topic that definitely deserves more attention.
&gt; Everything you do after the destroy operation is by definition happening after commit. In this instance, the commit refers to the end of the transaction. If you have multiple destroys happening (main record, related records, etc), these happen in sequence. None of them happen after the commit. They happen inside the transaction, which is rolled back if any of them fails. If you are also using those callbacks to delete files in the filesystem, or any other operation outside the database, of course the transaction being rolled back wouldn't affect them. The only way to delete them when the records are *confirmed to be deleted* is after all the delete operations at the DB level are confirmed. If you are using a DB-level callback to manage non database-related operations, you're gonna have a bad time.
So think of it this way. blog_web is an app that is just the presentation layer. Another umbrella app, blog, will provide `Blogs.most_upvoted/0` for example which the web layer would use for the index route. This keeps HOW the data is fetched as an abstraction away from blog_web as it doesn't need to know how that works. The `blog` application can now freely get the information from anywhere provided it returns the data in the same format. Contrast this with performing an ecto query directly in the controller. This keeps your controller code simple, and since the controller is often the integration point for everything in the app, it's one of the hardest to test sometimes and this makes it easier since it's responsibilities are reduced.
this is awesome, I've been jumping on the apollo + absinthe bandwagon myself
I've used it for side projects as well, wish I could use it in the day job but need to get Elixir there first...
It's ok. Writing decoders is probably one of my biggest issues with Elm. Though you'd have to do that with a JSON API too. With that said, because GraphQL has introspective capabilities, you could actually leverage that to generate the decoders and type information for you. There actually is a library that does that, but unfortunately that library hasn't been updated for the most recent version of Elm. I'm hoping either support for that library picks up again, otherwise an alternative library is created. Since if there's something like that, then it could actually work really well (GraphQL could actually become the preferred communication method for Elm to communicate with backend services, compared to REST or JSON APIs). 
Cool, thanks for the write up! How long did it take you for the whole app?
I'm too new to elixir to give a truly informative answer, but I have found with elixir/erlang/BEAM you have to think about things differently then you do with traditional OOP services. For instance, distributed programming is baked into elixir/erlang/BEAM. With these tools you wouldn't necessarily spin up a new service, you could add a new node to an existing distributed service and then distribute the load across the nodes of the same service. Take a look at "[Distributed tasks and configuration](http://elixir-lang.org/getting-started/mix-otp/distributed-tasks-and-configuration.html)" and see what your thoughts are.
Jose Valim himself wrote an article about how Elixir fits in with the microservices trend. See here: http://blog.plataformatec.com.br/2015/06/elixir-in-times-of-microservices/
The concept of microservices in elixir/erlang is an interesting one for sure. You can define an `application`, which can group any number of OTP constructs, and they're started and stopped as a unit, essentially providing an entry point to the code. So these, in a sense, can be microservices, but the more appropriate question is whether these applications should be grouped up together and living in the same runtime. I think at a certain level the erlang runtime encourages monoliths, after all the initial flagship ADX telecom switch shipped with 1.7 million lines of erlang. However that doesn't mean that the code has to be a giant monolithic ball of spaghetti. Umbrella projects let you break things into individual applications managed at the top level by mix and including them as dependencies in your project. As they start to grow you should be able to break them out fairly easily and you can cluster them and use erlang's built in rpc to remotely interact with processes and whatnot, or use http calls, or something like a message queue. so I think the summary here is start with a single 'monolith' with functionality split into logical applications, and then break those out into their separate services when they start growing too big, or demanding too many resources when under load.
Four easy steps amigo: Step 1: use generator Step 2: take note of files created and their contents Step 3: realize you'll need to use at least one generator (migration file) Step 4: Delete generated files and go through notes from step 2.
The main difference between Elixir/Erlang and other languages is that applications run within a concurrent, distributed virtual machine environment. Other languages and tools tend to communicate through an external, neutral protocol like HTTP and inherit the responsibility for managing that communication. The Erlang VM (BEAM) takes care of most of that and the protocol is native and internal so you get most of the infrastructure you'd attribute to a micro service platform out of the box. To take advantage of all that goodness you typically want to stay within the warm embrace of the BEAM and avoid the expensive and complex jump to some intermediate protocol. You can definitely do it, use HTTP/JSON/xMG when necessary but given the choice you'll want to pass messages between processes within the BEAM. If you understand the microservice architecture then you will find Elixir to be a natural and enjoyable fit. 
How I've been going about it is to build my microservices around OTP. Now I use a separate project for each service (as with my use case I'm not sure if every service will end up being written in elixir or not), but you could easily have all your services in the one umbrella project (would definitely make things simpler). But essentially one service I create as an umbrella project that consists of at least two sub-projects, a service (the OTP app/service logic itself), and an API (so it's easier to interface with from other projects/services). The API project basically just ends up wrapping functions around sending messages to the service. While the service project is an OTP app, and implements all the nitty gritty details of the service (workers/supervision tree, logic, data stores, etc.). The nice thing about using OTP for services is that communication can be done in standard elixir (don't need to depend on some other protocol), you can configure them like you would any other OTP application (e.g. specify the number of nodes, their failover strategies, etc.). While I haven't gotten to release builds yet, my approach will be just configuring all the services to package everything up neatly. Edit: Here's some examples of what some of these services look like so far: * [identity service](https://github.com/ScrimpyCat/gobstopper) * [contact service](https://github.com/ScrimpyCat/sherbet) * [mailer service](https://github.com/ScrimpyCat/cake) At the moment none of them are setup for distribution, nor optimised for how they could work (e.g. could they be clustered, etc.), but that stuff is simple enough to add support for later. 
sounds very interesting... and would you share the domain of your project?
&gt; Rails doesn't want to contain any logic on database level. Yeah, I like that. It's so simple when all the logic is in your app and not hiding in the DB :/
thank you. I will PM it to you. That way post can be more about elixir and I can lay it low until its been out and tested longer
It probably feels immature because it makes you do more things. When you start building complex apps I think AR is absolutely useless. One needs to be writing more complicated queries and whatnot. I absolutely love that Ecto gives you full control of everything
Good write-up. Coming from Ruby, I'm also checking out Phoenix Do you feel more productive compared to Rails? I feel like Ruby is more expressive so for the same feature you can deliver faster with Ruby
It's still in active development, but currently detects some types of SQLi, directory traversal, XSS, etc!
More productive than Rails? Not really. But this is due to my experience and familiarity with the platform. Also Rails has benefit of tons of developers polishing it for years so it's very rare where you going to encounter "how do I even do this?".
Could I have a link as well? And is the code open source? 
This looks promising, thanks!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/hackernews] [Elixir is growing - Building a Reddit clone in Elixir](https://np.reddit.com/r/hackernews/comments/6cn68f/elixir_is_growing_building_a_reddit_clone_in/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Nice job. If you would like any help with the writing part of sharing what you learned, I would be glad to help. I'm learning Elixir as well. I'm trying to reteach what I learn in hopes of better understanding the language myself. 
thanks!! That is a generous offer. I'll mark your username as I'd probably take you up on that. I've got a few more things coming up that could be interesting to write about for sure. and god speed on your learning and teaching, the more the merrier in the elixir world
The first example could just be `&lt;%= render "_jobs.html", jobs: @jobs %&gt;` assuming the partial is in the same view as the current template.
I used the Amnesia package and was set up quickly in phoenix but only for some usages; for me it didn't replace postgrex. Hard to say whether it is a good idea without knowing more about your app's usage and future but as for possible.. definitely seems ok far as I know. You lose ecto but gain simplicity in many ways. Only gotcha for me was going from dev to prod. I use a barebones setup on production which is fine for amnesia except for the commands for initial setup which relied on mix for me. Still haven't had a chance to get around that fully but I know it would be possible.. just a matter of solving some of my ignorance of mnesia. You need more advice that what I gave but thought I'd share that much!
Also, a lot of times people miss that AR is a moving target, there's a lot of stuff that's gone in over the last few years to make building more complex queries easier. It's pretty rare that I have to write a query by hand. One of the methods that a lot of people don't seem to know about is `#merge` which will merge the conditions of one query into another. That said, there are still areas that AR can be a real pain, but I've worked on some fairly large projects and rarely had a show-stopper.
I think this is what makes me most excited about Phoenix in the future. It seems to be a solid enough platform now that there are plenty of people getting involved, which means that hopefully it should lead to the same kind of community that Rails has around it. As much as I love working in Ruby and like a lot about Rails itself, the real power comes from the amount of polish and the size of the community and the toolkit that goes along with it. I'm very keen to see how Phoenix develops over the next couple of years.
Nice blog posts! I like that you didn't use arc/arc_ecto. I like arc but I don't like arc_ecto performing two different actions for one function call (Repo.insert/update). Using just ExAws or arc is the best way to do it imo. You also covered setting up AWS/S3 which most posts don't do, and that's great since setting it up can be confusing. You do have a few errors in the third post though. :) _image = ExAws.S3.put_object(bucket_name, filename, image_binary) |&gt; ExAws.request! # build the image url and add to the params to be stored updated_params = upload_params |&gt; Map.update(image, image_params, fn _value -&gt; "https://#{bucket_name}.s3.amazonaws.com/#{bucket_name}/#{filename}" end) `image` in the last line should probably be `:image` and `filename` should probably be `unique_filename`. You could also use `Map.put` instead of `Map.update` to simplify creating `updated_params`, since you wouldn't have to create an anonymous function or pass in a value that won't be used (`image_params`). updated_params = upload_params |&gt; Map.put(:image, "https://#{bucket_name}.s3.amazonaws.com/#{bucket_name}/#{filename}")
I am new to Elixir so CMIIW: When you pass a function as an argument to a function that expects a lambda (or anonymous function), Elixir can't explicitly handle a passed `Module.functionName` and call it internally. Instead, if you use the `&amp;` operator like so `Stream.filter(&amp;myfunction)`, it is able to implicitly convert `myfunction` into a lambda function that can be used by `Stream.filter`. This is why it is able to work with `Steam.filter(fn(x) -&gt; myfunction(x))` because the passed function is a lambda in this case. See: http://culttt.com/2016/05/09/functions-first-class-citizens-elixir/
Thank you for the analysis. What I am trying to assess is, if I manage to port the application to Elixir/Erlang stack, am I getting the HA/FT/Distribution etc almost free (assuming we did a good job in porting) ? In the absence of docker/kubernetes how do Erlang apps get these complex characteristics ? They do, right ? One question the mgmt wants to know is : "is it more economical to deploy/support a Erlang app" ? Is Erlang a clear choice for new projects ? what characteristics/aspects tip heavily in favor of Erlang/Elixir vs against them ? 
Thanks! TIL
The big gotcha with mnesia is that you must either have all your data in memory (disc_copies holds the entire database in memory as well as disc) OR deal with the limitations and higher latency of DETS backed tables. There are alternatives like the mnesia eleveldb backend (phoneposting or I'd link it, easy enough to Google), but they aren't officially supported and I can't vouch for how easy they are to set up or maintain. Mnesia also has issues if you go to more than one node - the distribution features aren't great for the modern Cloud-based use case. I really can't recommend mnesia as a primary data store unless you really, really know what you're doing. It's frustrating, because otherwise mnesia is pretty cool. 
Despite their few obvious similarities, it's probably best for you to think of Kubernetes or other container orchestration solutions as **completely orthogonal** to OTP/Elixir. You use, or don't use, a container orchestrator with Elixir for many of the same reasons you would using basically any other language/framework. **You just aren't forced to use them if there's no good reason to.** That isn't always true in the other direction. Ie, OTP/Elixir lets you choose not to use container orchestrators where, realistically, in many other languages the end game for your 'app' is that coordinating your microservices using your orchestrator's API becomes an app concern (which, as OTP demonstrates, it often *is*), and you end up writing custom Kubernetes schedulers or other deeply integrated components, essentially as part of your application's code, sewing yourself to an orchestrator, calling it "cloud native" and then wincing whenever the stitches tug on you when you move fast. So, you don't **have** to use an orchestrator in the same way. However, I still use Kubernetes. Why? - because container images are an acceptable build/deploy artifact, - because with GKE it's just small percentage increase on the cost of a raw cloud VM (and if I need bare metal in the future there's a path with k8s, but most people are just provisioning cloud VMs, not bare-metal, and are choosing not to run an orchestrator for reasons that vary from sound to unsound). - because some pretty smart people agree that hot-code-reloading should be reserved for use cases that demand it, and rolling deploys are easy with k8s (not that hot-code-reloading isn't possible), - because `minikube` is awesome for testing distributed software locally - and because Kubernetes (and most other orchestrators) give me the value-add of IP-per-container (ok, 'pod'), and dns-based discovery, so it's easy to deploy distributed software.
Stupid question: why having 2 separated repositories? Can't front end files be directly inside the Phoenix app?
I think many of those questions are better punched into Google to get a solid answer. I'm no pro by any means, and primary use Java in my day-to-day. I think you should distance yourself from the idea of "porting" the app to Erlang. The constructs of Erlang vs Java just do not translate, and you're better off starting with a requirements document, then designing an OTP system around that. OTS does provide very good FT and HA abilities, but I'm not sure I'd consider them free. I suppose the best analogy I can come up with right now is how a Tomcat server handles asynchronous requests - if one happens to crash, it won't bring down the system, but you also have to handle the bad behavior if you want to recover, except every logical chunk of functionality maintains this same behavior. I would love to use Elixir in more new projects, but living in Java land means I would also be on the hook for training anyone else who is a stakeholder. Your success here really just depends on your team and how willing they are to take on new languages into their ecosystem. As for economics, It's very rarely worth it to rewrite something that works. I have zero context for your organization, but unless there is some unbearable support burden, "if it ain't broke don't fix it". Ultimately I'd say, "go for it". Rewrite some of your codebase in Elixir/Erlang and see how it goes. Present to your team and boss your findings. The only way to answer your questions is to get started.
You mentioned a few features in Mongo in other comments that I don't think will be an issue in this CRUD app for your day to day usage. After installing postgres and adding a user, actually your dev flow will be more about mix and ecto. You get all CRUD operations and migrations for nearly free using generators and you'll be able to see the code and make changes or new operations easily. The only issue left would be the fact that it is a dependency and if you find that annoying in your env not much to do about that. You may not like the flow of connecting to the database during development to tinker, but at least the generators also give you a nice html page with forms that cover crud
He mentioned the hot code reloading, which is possible, but runs against the docker/kubernetes concept of `cattle not pets`.
Indeed u/mr_luc did. The hot code loading is one thing I don't see myself having a use for in the kinds of things I normally use.
Yeah, I agree. Given that my current use of elixir is purely to experiment, I don't want to lose it; but I could totally see losing it for a production environment.
Mostly, k8s on GCP gives you a bunch of things that you need anyway: cluster accounts and permissions, secrets, declarative deployments, deployable artifacts, blue/green deployment, service discovery. When it comes to overlapping in the sense of *conflicting* features, 'must choose one or the other,' nothing really springs to mind; they're orthogonal. Even the cloud-native bits, you can do those as well if you want to. You just have the option of using OTP/elixir to do the things it does well instead of needing to lean on the orchestrator.
Yeah, sounds better. Thanks!
Nice write up and demo project! Thanks!
Just curious, but why redis over ETS?
I'm on the last year of my Computer Science degree, writing my end of course paper about IoT simulation. In the end of this year I have to deliver a working proof of concept, a system I'm developing with Elixir and Phoenix. I'm now in the proccess of comparing different simulators, seeing if there is anything I can reuse or improve in the existing ones. My system has to be configurable via a web app. I'm thinking [Tsung](http://tsung.erlang-projects.org/) is very promising. *Sorry if my English is incorrect in any way. Not my native language.*
"Mnesia also has issues if you go to more than one node - the distribution features aren't great for the modern Cloud-based use case." To be honest, Mnesia handles distribution excellent. What it doesn't handle great is unreliable network.
The simplest way I can think of would be something like: %{:en =&gt; 1, :jp =&gt; 4, :zip =&gt; 0} |&gt; Enum.map(fn {k, v} -&gt; [Atom.to_string(k), v] end) If you really don't need the Atoms converted to strings you could simplify even more with: %{:en =&gt; 1, :jp =&gt; 4, :zip =&gt; 0} |&gt; Enum.map(&amp;Tuple.to_list/1) 
Which leaves us with l = for {k,v} &lt;- %{:en =&gt; 1, :jp =&gt; 4, :zip =&gt; 0}, do: [Atom.to_string(k),v] Thanks!
In reality you probably just want to use `Enum.to_list(map)` and work with that result (a list of tuples for each `{key, value}`).
Agreed, but in the second example, since you're creating a keyword list (which is what I'd recommend), you can do: `Keyword.new(%{:en =&gt; 1, :jp =&gt; 4, :zip =&gt; 0})` or `Map.to_list(%{:en =&gt; 1, :jp =&gt; 4, :zip =&gt; 0})` 
Nice idea, actually I don't want to keep the atoms. The Enum.map solution is better in my case.
Thank you so much, that looks like what I want. I was thinking that I should do something about my pattern matching and this solution will cover more use cases.
I was thinking about that, but the keys remind as Atoms and I need strings.
You should definitely look at the changes that Phoenix 1.3 brings to the field. It makes dealing with such problems a bit easier. http://swanros.com/phoenix-1-3-is-pure-love-for-api-development/ https://www.youtube.com/watch?v=tMO28ar0lW8
Where are you seeing that? I just ran `phx.new` and under `web.ex` there is not a single reference to `Ecto`. If you run `mix phx.new app_name --umbrella` it will completely break out the application into separate `app_name` and `app_name_web` applications if you want that amount of separation.
And that's where​ my question starts: Is umbrella the way to go by default? I'm aware that a base `phx.new` only pulls in Ecto as a dependency but doesn't tell you what to do with it. I just wondered whether I should be using an umbrella by default, basically.
I think there is still some debate whether you should use an umbrella be default. Personally, I'm in the "don't use use an umbrella unless you actually benefit from it" camp. If you do not use an umbrella and at some later point decide that you do need one, it should be fairly easy to convert.
It's beautiful, isn't it? I have wrote several tokenizers and parsers in Elixir/Erlang and it's always a pleasure. They generally look very much like this but I have found that another interesting approach is pattern matching directly on the binary. For example: iex&gt; &lt;&lt;c :: binary-size(1), r :: binary&gt;&gt; = "abc" iex&gt; c "a" iex&gt; r "bc" With the ability to match on the front of a binary you can write a general function for collecting characters that match a given pattern. It doesn't necessarily have to be a regular expression but I opted for it for my use case. I call the function `take_many`: def take_many(bin, regex) do take_many(bin, regex, &lt;&lt;&gt;&gt;) end def take_many(&lt;&lt;c :: binary-size(1), rest :: binary&gt;&gt; = f, regex, token_acc) do cond do c =~ regex -&gt; take_many(rest, regex, token_acc &lt;&gt; c) true -&gt; {token_acc, f} end end def take_many(&lt;&lt;&gt;&gt;, _regex, token_acc) do {token_acc, &lt;&lt;&gt;&gt;} end I use this guy all over the place inside of my tokenizer. It works like this: iex&gt; take_many("123abc", ~r/[0-9]/) {"123", "abc"} That aside, everything else is pretty straight forward. You can match on things like brackets, whitespace, keywords, etc... rather easily. def tokenize("(" &lt;&gt; rest, lnum, tokens) do tokenize(rest, lnum, ...) end def tokenize("\n" &lt;&gt; rest, lnum, tokens) do tokenize(rest, lnum + 1, ...) end That's the gist of it, really. There's a lot of minor details but I didn't want to bore the hell out of you. I used this method to write a tokenizer for an entire language in a couple of hours. It was fun. I am not sure how well this performs compared to working with lists. (prepending, reversing, converting...) Someone told me that memory is allocated at the tail of binaries and appending to them is fast. I initially thought it was o(n). It runs fast enough for my use case but I'm still very curious what's actually going on here. Anyway, enjoy! It turns out powerful pattern matching semantics are good fun for processing text and implementing languages. 
With respect to the following point: "Applications that do large amounts of background processing." I think it would be useful to read about some concrete examples. Don't you still need a job queue for most things? 
Anything that has to do websockets has a huge advantage with Elixir/Phoenix.
Not job queue per se, but dispatching work in background is still thing worth doing. Ex. mail delivery, pushing mobile notifications, and with WebSockets or SSE you can perform almost all actions in background. 
Ok, so let me try to answer another question you asked. &gt; And that's where​ my question starts: Is umbrella the way to go by default? If you are comfortable with having explicit boundaries between your applications and following them, yes. We have seen teams that say "my code is organized because I use umbrellas" and then they have cyclic dependencies between their apps. Or modules from one app are reaching into all modules from other apps without any sort of contract. We have also seen people breaking apps into umbrellas while all of them depend on the same operational database in production, which means they are actually coupled and need to be versioned and deployed together. So if you want to use umbrellas because you have explicit boundaries that you want to respect, then by all means, yes. But if your aim is splitting code apart into files, then you likely won't gain anything compared to multiple directories in the same app, and rather make your codebase more complex.
Thank you. That's exactly the kind of explanation I was looking for.
Process mailboxes aren't persisted by BEAM, but as far as I know, there's a whole range of options available, from ETS (Erlang Term Storage) to various available libraries.
You can use them for bidirectional communication with the front end as well. For example, you can use Ecto.Multi to set up a pipeline that broadcasts a message to a channel upon a successful database transaction, essentially using channels as a controller.
Currently notifications and chat-like features, and not much else. Will probably do more at some point, but not necessary atm.
I don't think it uses selenium underneath, but I went to a meetup about a year ago and the people hosting developed this library which looked interesting. Might fit your needs. https://github.com/keathley/wallaby
Anything where you need to do any amount of server-side processing apart from simple data storage and retrieval. The benefits of immutability greatly cut down on complexity and state management bugs, which run rampant in every rails app I've ever worked on. All the concurrency, process model, program flow, destructuring, etc side benefits are just icing on the cake after that. Ruby is a very unpredictable environment to work with beyond trivial sizes. And if you don't have a problem now, just add time and it will definitely appear.
Seemed like more of a long winded advertisement for his services than anything.
Looked through this, but the slides could use some context, or perhaps the author could provide context here? I can't really tell clearly what the slides are trying to say about Elixir OR Haskell except in a few select cases, and there I'm not necessarily sure... looks like these are slides from a talk, but notes for the talk alongside might help?
I'm using them in [OpenPantry](https://github.com/MasbiaSoupKitchenNetwork/open_pantry) for realtime stock updates as guests move items into their cart, and will also be using soon on the admin side to notify people preparing food packages when new orders are finalized
I did this a while ago but thought it would be fun to share. This is a quickie spaceship simulator, where each ship is a process, being rendered and interacted with from Unity3D. Full code, of course, is available. Someone was asking about Unity in a Slack I was in and it made me think "I should make that episode free and share it". Done. :)
Elixir has zero downtime deployments.
Have a look at this blog post: https://medium.com/@cschneid/background-jobs-in-elixir-phoenix-60dddf4ce207 
Maybe a somewhat controversial question, but are there any use cases where RoR is actually more effective than Phoenix? As far as I can tell, the biggest benefit behind RoR is that it's (relatively) trivial to find engineers because of boot camps and (in my opinion) it is marginally easier to learn RoR. Also, I suppose, the ecosystem of RoR is larger and more mature. But basically it's my understanding that if Phoenix had come out first and struck a resonant chord like RoR had, RoR would not have even half the community that Phoenix has right now. Which is to say, the main thing RoR has going for it is momentum.
I don't know if it's necessarily unconventional, at last to me, but the basic logic would go something like this... defmodule Foo do alias Ecto.Multi def create(changeset) do Multi.new |&gt; Multi.insert(:foo, changeset) |&gt; Multi.run(:broadcast_add, &amp;broadcast_add/1) end defp broadcast_add(%{foo: foo}) do AppName.Endpoint.broadcast!("topic:foo", "foo", %{key1: foo.key1, key2: foo.key2}) {:ok, :noreply} end end So that sets up how to use `Multi` for when something gets created in the db. Now in the controller that handles this db transaction you replace the `Repo.whatever` call with something like def create(conn, %{"foo" =&gt; foo_params}) do changeset = Foobar.changeset(%Foobar{}, foo_params) case Repo.transaction(Foo.create(changeset)) do {:ok, %{foo: foo}} -&gt; conn |&gt; put_flash(:info, "Foo created successfully.") |&gt; redirect(to: foo_path(conn, :show, foo)) {:error, _failed_op, changeset, _changes_so_far} -&gt; render(conn, "new.html", changeset: changeset) end end The nice thing about `Multi` is that at any stage of the pipeline if one of them fails then it aborts so you won't get into a situation where a db transaction fails and you end up broadcasting to the channel anyway. So I was a little inaccurate in my previous post, you obviously don't do away with the controllers for the db transactions, but in this sense you _do_ remove the need for creating HTTP endpoints to request the data from the client side. Instead, the server just pushes the data up directly to the client.
I'm planning on using them for location tracking services (so the realtime location data can be repeatedly sent to the server and broadcast to all listeners). As well as for updating and managing orders in realtime (on the business end/essentially like a realtime PoS). Might have some other uses in my current project but don't have anymore at this point. 
I have a background process which matches one set of data against another. I use channels to broadcast to anybody listening how it's going. I've since expanded it and now have a generic job tracker system which will allow me to have multiple task tracking bars on one page if needed.
To say that I'm not a Erlang/Elixir/OTP/anything expert is a laughable understatement, but... it might be possible, but why would you want to omit certain machines from being able to do certain kinds of processing? Seems to me like it's best to spread the work over all machines. (I had to Google this) You can set process priority with `process_flag/2`/`flag/2` in Erlang/Elixir (respectively), so you can just set "background" processes to `(priority, low)`. You can even set certain parts of your API to `(priority, high)` or `(priority, max)` if it's something essentially super urgent (like serving your homepage or API calls your homepage makes, for example). Thanks for asking the question, btw. I wouldn't have looked it up if it weren't for your question.
Seems to be this Simditor: http://simditor.tower.im Or Trix: https://trix-editor.org 
Why isn't the intellij plugin working, log a bug if it's not. I got it setup super easy, and it's really nice.
Can you post a walk through or tutorial or something on "Up and running with elixir plug in in intrlliJ "? I don't know how to configure settings to run the elixir files
vim + tmux ftw
You can't simply run elixir using run button in intelliJ?
Most of my apps are all run via a web interface, for example `mix phx.server` or `iex -S mix` for REPL.. maybe you can do that, but not sure, sorry! :)
JetBrains product (RubyMine or IDEA) + elixir plugin. Best solve.
**Here's a sneak peek of [/r/unixporn](https://np.reddit.com/r/unixporn) using the [top posts](https://np.reddit.com/r/unixporn/top/?sort=top&amp;t=year) of the year!** \#1: [\[GNOME\] When people ask why I use GNU/Linux...](https://gfycat.com/FrayedEverlastingAplomadofalcon) | [266 comments](https://np.reddit.com/r/unixporn/comments/5crgng/gnome_when_people_ask_why_i_use_gnulinux/) \#2: [\[Kindle\] Debian on my Kindle!](http://i.imgur.com/Nxb8R0X.jpg) | [295 comments](https://np.reddit.com/r/unixporn/comments/6a4whs/kindle_debian_on_my_kindle/) \#3: [Fully automated color changing \[i3\] \[Hardware?\]](https://gfycat.com/SecretSimilarDuckbillplatypus) | [144 comments](https://np.reddit.com/r/unixporn/comments/6al0o8/fully_automated_color_changing_i3_hardware/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
Lol
Here, let me google that for you. You can always look at the plugin repo: https://github.com/KronicDeth/intellij-elixir#steps. If that doesn't work, then you can always file a bug:https://github.com/KronicDeth/intellij-elixir/issues.
The `:rpc` module lets one run code on your choice of machine.
I tend to like languages that do not need a heavy lifting IDE to refactor or spew out boilerplate. If I was stuck wring java I would look for an IDE, if I am using a sane language I will stick with vim tyvm. 
Changeset exposes a function, traverse_errors, that's pretty much what you're looking for. Also you don't need to call Atom.to_string when interpolating as that's done automatically.
It seems like `traverse_errors` just iterates through a changeset's errors. I'm looking for a function that straight up returns a List of string errors.
Run `Mix.Task.run "app.start"` at the top of your task to make sure the current application and all of its dependencies are started.
I thought Ecto errors are kept separate so that you can translate them.
I developed a plugin for SublimeText https://github.com/edelvalle/SuperElixir Still not merged into Package Control yet, but can be downloaded and installed manually.
Among other things, I'm learning Elixir. I'm almost done with Programming Elixir 1.3, and it's a great book. Elixir also seems like a nice language. There sure is a lot to like although I'm still having trouble with it being dynamically typed (I like statically typed languages), and I'm also not really feeling it with regards to having exceptions and :ok/:error-tuples instead of using something like Result&lt;T,E&gt; enum. That's really my two biggest gripes with the language so far...
Or you can just use neovim and the built-in terminal emulator and forgo tmux entirely. =D
From the docs: "This function is particularly useful when associations and embeds are cast in the changeset as it will traverse all associations and embeds and place all errors in a series of nested maps." So you get a map back. You can then iterate through the map or flatten it out into a single-level (flat) map or list.
why duplicate the renderer and not extend it through composition? defmodule MyHtmlRenderer def render(blocks, context) do Earmark.HtmlRendeder.render(blocks, context) |&gt; autolink |&gt; replace_emoji end end
Anyway, thanks for posting it, I didn't know about Earmark
nice job, gonna switch to it.
I use Neovim + Tmux.
Yeah I did too until I became comfortable with `:term`. You should really try it out. The best part is you can do what I do, which is have a terminal in a corner of the window instead of taking up a full section. Check [this](http://i.imgur.com/Wjx1ieC.png) out.
Add a user count! 
To reduce the "douchenozzling" you should have people enter a username to use and when you hover over a letter it can show what user put that letter there. Awesome stuff though! Love the idea and would love to put it onto a tablet hanging in my kitchen. 
How would that reduce people being idiots? They will just put in a name that means nothing to them. Or even worse, a name of someone else.
It is amazing. We had a little battle where some guys tried to make a pile of letters. I was in the other "team" trying to spread back the letters. It was very fun. Of course people can't stop writing insanity, but the concept is there.
I think you're missing the point. `changeset.full_messages` will never be a thing because its just data, it can't be computed. It would have to be passed into a separate function to get the full_messages and theres basically no point cause as you showed its 2 lines of code. I think phoenix generates this out of the box for you in your errors view if im not mistaken.
Alright, than I'm feeling obliged to add touchscreen support.
Sorry :-( ... working on it
I was on your team. GO TEAM ANTI-PILE!
Offical guide?
pkg install elixir and it's done (then simply install phoenix via mix as usual) ps : tested on FreeBSD 11
Yay I wrote covfefe 
coming up next
touch support just went live
done
The guides on the elixir website are pretty good. I personally liked Programming Elixir.
I would recommand https://www.learnelixir.tv/ and the documentation that is really well written
This. I read through one of the earlier books, but yeah the programming elixir book is fantastic
http://learnyousomeerlang.com/ &lt; not completely elixir related but it does teach you about OTP and how do you model your problems using processes. Always remember that Elixir is not Ruby and Phoenix is not ROR. Understanding that processes are synchronization points and not objects can save you a bunch of trouble later on. I would also recommend elixir in action: https://www.manning.com/books/elixir-in-action
As suggested in other messages, I would probably go with porcelain or some elixir/ruby interop solution, then wrap https://github.com/yob/pdf-reader from there.
Just to be clear: Going with this path sacrifices the ability for hot code reloads because of everything going in a docker container right? So this would mostly be for applications that don't ever have that need(i.e., most of them)? Are there any other disadvantages to going this route? And in general: Thanks for this writeup. I'm probably going to put it into use in the next few weeks, as my deployment strategy for Elixir isn't as solid as I'd like.
Programming Elixir, for me, was invaluable. It taught me how to think differently about Elixir vs other languages.
https://github.com/ricn/pdf2htmlex will convert to HTML and from there parsing down to text is real easy.
Can I just chime in to second the 'minimizing other dependencies' bit. Getting the level of management that k8s gives you, running on Google's infrastructure, is really great. I'd point to secrets as one example, and the example you used in your article, of dns-based service discovery thanks to an overlay network as another. I don't have to set up zookeeper or vault; k8s considers those value props as just 'table stakes' for containerized deployment, and rightly so.
Why did you change the message to be `{data: btoa(JSON.stringify(payload))}` versus just sending the `payload`? Isn't Base64 always going to be more bytes? The phoenix.js library already calls `JSON.stringify()` behind the scenes.
You've described a function. Don't overthink it - just make a function on a module that takes the arguments and returns a formatted string. If you wanted to get fancy you could use EEx. defmodule MyTemplates do def my_template(some_var) do "This is #{some_var}." end end
I was just playing around with stuff. This thing is not really tuned for performance ... or a purpose.
what if I need to store that string template in a config file?
OK, was just wondering if there was some advantage I had missed.
You can use [EEx.function_from_file/5](https://hexdocs.pm/eex/EEx.html#function_from_file/5) to have the template compiled into a module at build time. Or if the config file is going to be changing during runtime, then you can't compile the template ahead of time, so use [EEx.eval_file/3](https://hexdocs.pm/eex/EEx.html#eval_file/3) in that case. Or you could define a custom config file format (YAML, JSON, whatever) and use [EEx.eval_string/3](https://hexdocs.pm/eex/EEx.html#eval_string/3) directly.
why do you assume that all that config file contains is is Elixir code with the &lt;%= %&gt; in it? config file! the `"some string {some_stub_var}"` -- is just one of the values. 
I bought a RPi and touchscreen, mostly to play with but with a couple of ideas including kiosks/stock management consoles for my [OpenPantry](https://github.com/MasbiaSoupKitchenNetwork/open_pantry) project, sometime down the line when it's out of prototype and into "production" use... There's a kiosk package I found for nerves [this one I think](https://github.com/fhunleth/nerves_system_rpi3_kiosk) that I was hoping to get basically just auto launching a browser going to my webapp and possibly working with a USB barcode scanner we have a few of lying around for keyboard input or something for scanning items... I got as far as getting a nerves app to blink lights forever, but when I tried the kiosk it didn't boot and I wasn't sure how to debug it without much of any input/output system besides the touchscreen I was trying to boot the kiosk too.... signed up for Nerves 2 day course before ElixirConf in september though, so basically punting on worrying about until then, unless I find someone who wants to play around with before then.
At a high level, you've nailed it. How far you take the concept of bounded contexts I think is still up to you. E.g. Should a particular schema be shared amongst contexts, or should it only be accessible through a single context's functions? How many contexts do you have, and how many models per context is too little or too many? I think it depends a lot on the particular application and how the contexts are modeled.
 this one, thank you very much :)
Hello, I managed to get elixir running in a terminal in my android phone, so I don't think it should be very difficult to run phoenix on a raspberry pi. You should be able to install erlang from your package manager (this depends on the distro you're using in your pi), I didn't find elixir in the package manger for the distro I set up in my phone, it was enough just to download the compiled version for Linux, extract it in a folder and add the binaries to the path. From this moment on it's just a matter of installing phoenix using mix...
You can check http://nerves-project.org/ , it allow to deploy elixir on raspberry and other boards. Nerves will take over the full board so is like 1 board (sd) for elixir project (or multiple using umbrella projects)
I have used it with nerves and it was straightforward. I generally use the Erlang packages from Erlang Solutions, as the distro packages in stable distributions can be pretty old. Get the latest Erlang package for Raspbian from here: https://packages.erlang-solutions.com/erlang/
Thanks so much - this is awesome! I can't believe how easy they made making a embedded linux distro!
Yes! Been waiting for a gofmt for Elixir. Gonna try it soon hopefully :D
I've been using Meeseeks on a side project, and it's been great to work with. Thank you so much for your work on this!
My pleasure. :) If you encounter any questions, rough edges, or possible improvements while working with Meeseeks please don't hesitate to open an issue.
Looks like a solid gig...
Interesting- submitting my resume. 
Updated link: https://blog.discordapp.com/how-discord-handles-push-request-bursts-of-over-a-million-per-minute-with-elixirs-genstage-8f899f0221b4
it's shockingly easy. and it boots directly into elixir in a shockingly short amount of time. great project to play with
Oh hey, so this where all those stars came from! I'm the author of this tool, which is still very much a work in progress right now. Leave a reply if there's anything you'd like to know about it :)
Looks interesting. Is this job open to remote employees?
Elixir newbie, so nothing ground-breaking. I'm going through various tutorials, and since I learn more from real-world use cases, concurrently refactoring(?) my static blogs and sites (originally created using Jekyll, Middleman, Pelican). "|&gt;" is freaking amazing (*it's the simple things, really*)
A few years back, Pragmatic Studio did trainings at different locations, but has since moved to online videos (which can be downloaded). This particular training is run by Mike and Nicole Clark (Pragmatic Studio is run by Mike and Nicole).
I agree, this has been a good course so far. It's slowly getting more advanced the further we go in. I already knew the basics of Elixir, and this is giving me a better footing. Next, I'm thinking of getting the "Phoenix Inside Out" book. Has anyone seen any other new books or videos coming on Phoenix (besides the latest Pragmatic one that's in beta)?
Yup: * https://github.com/elixir-ecto/db_connection * https://github.com/elixir-ecto/postgrex * https://github.com/xerions/mariaex
You can use low-level drivers, such as [postgrex](https://hex.pm/packages/postgrex) directly. You can find a simple usage example in the [docs](https://hexdocs.pm/postgrex/readme.html).
[moebius](https://github.com/robconery/moebius/blob/master/README.md#sql-files) is an alternative to Ecto that feels closer to plain SQL.
Not sure why a screenshot is needed since it has no front-end stuff but if I do have a demo here https://hqc.io/posts, it is my personal blog built with Nabo.
There are many instances where using Ecto doesn't make sense. Ecto actually uses database drivers to talk to the database. I for instance use the `postgrex` hex package to talk to my database as most I have an ETL project and most of my app uses raw SQL. From the postgrex docs iex&gt; {:ok, pid} = Postgrex.start_link(hostname: "localhost", username: "postgres", password: "postgres", database: "postgres") {:ok, #PID&lt;0.69.0&gt;} iex&gt; Postgrex.query!(pid, "SELECT user_id, text FROM comments", []) %Postgrex.Result{command: :select, empty?: false, columns: ["user_id", "text"], rows: [[3,"hey"],[4,"there"]], size: 2}} iex&gt; Postgrex.query!(pid, "INSERT INTO comments (user_id, text) VALUES (10, 'heya')", []) %Postgrex.Result{command: :insert, columns: nil, rows: nil, num_rows: 1}} I have a little wrapper that makes it easier to execute sql defmodule DataLoader.PG do # "COPY hotels (id, name, city, destination, country, location) FROM STDIN DELIMITERS '|' NULL 'NULL'" def copy(enumerable, copy_sql) do transaction(fn(conn) -&gt; pg_copy = Postgrex.stream(conn, copy_sql, []) enumerable |&gt; Stream.into(pg_copy) |&gt; Stream.run end) end def exec_multiline(sql) when is_binary(sql) do transaction(fn conn -&gt; sql |&gt; String.split("\n", trim: true) |&gt; Enum.reject(&amp; &amp;1 =~ ~r/\s*--/) |&gt; Enum.join("\n") |&gt; String.split(";", trim: true) |&gt; Enum.each(&amp; Postgrex.query!(conn, &amp;1, [])) end) end # exectes a query def exec(sql, params \\ []) when is_binary(sql) do transaction(fn conn -&gt; Postgrex.query!(conn, sql, params) end) end def transaction(fun) when is_function(fun, 1) do env = pg_env() Postgrex.transaction(env[:name], fun, pool: env[:pool], pool_timeout: :infinity, timeout: :infinity) end def pg_env do Application.get_env(:data_loader, :postgrex) || raise "Persistence config not available" end end The configuration has this info: config :data_loader, :postgrex, database: "hm", username: "postgres", password: "postgres", hostname: "localhost", name: :data_loader_pg, pool: DBConnection.Poolboy, pool_size: 14 
Nice article - short and to the point!
I like this example. Can you (or anyone) refer me to any longer reads or videos on using contexts and umbrella, especially in the same app?
Do you have any links to blog posts or videos you think would be helpful to get a deeper understanding of how umbrella and context work, especially together? Thank you
SECTION | CONTENT :--|:-- Title | Chris McCord | Keynote: Phoenix - Gauging Progress Description | Filmed in Barcelona at ElixirConf EU 2017 ElixirConf EU is a community conference created to promote education, networking and collaboration within the Elixir/Erlang/Ruby communities. Length | 0:49:07 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Great! I haven't seen these yet.
Thanks this is very useful
Thanks, looks promising
Oh. I thought it would come with a simple theme of some kind, so you could play with it without having to write a bunch of code. Thanks for the demo though.
In this video Chris McCord explains it pretty well: https://youtu.be/tMO28ar0lW8 You could still use umbrella apps and have each application still be responsible for the transformation, validation and storage of data. Using contexts, validation and storage are one application and the interface (web or channels) are another. That means your web apps dont need to understand anything about where the data goes or how it's stored. In contrast you could just do all that inside a single app and just have several small monoliths if you will. Contexts help you to decouple how the data comes in and how it's expected to be presented with how it's stored and validated.
SECTION | CONTENT :--|:-- Title | Lonestar ElixirConf 2017- KEYNOTE: Phoenix 1.3 by Chris McCord Description | Lonestar Elixir 2017- KEYNOTE: Phoenix 1.3 by Chris McCord Chris McCord is a programmer with a passion for science and building things. He spends his time crafting the Phoenix Framework, working with the fine folks at DockYard, writing books like Metaprogramming Elixir, and teaching others the tools of the trade. Length | 0:51:44 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Indexing UUIDv4 is not very beneficial when all the IDs are completely random. I like the idea of using KSUIDs for primary key in Ecto instead of UUIDv4/binary_id mainly for that reason...
Note this will need to be updated for the next version of Phoenix as the web directory has been removed
&lt;3
&gt; Elixir, the solution behind Pinterest and Heroku Really? I could be out of date, but I don't think Heroku even uses Elixir at all...
I saw the segment post the other day and thought about building this too. Thanks for saving me the effort :) I wonder how this shakes out when using something like dynamodb/s3? With these nosql stores, you'd want to have a completely random id so that data can be evenly distributed between shards. Does anyone know how to actually test for that kind of key distribution? It's not something I've ever really dug into, however, I'm sure someone around here has ;)
There's a small amount of Elixir at Heroku, but there is a lot of Erlang.
I've been working on a free platform application to help people find tutors/instructors in the Bay Area. https://www.cirqled.com
Removed? My understanding is that it is to be moved under lib, no?
I heard about the projections some time ago, but really why overcomplicate things? I like your solution because it's so simple and also easy to extend... for example I use rspec a lot, so I just added the line "nnoremap &lt;leader&gt;er :CtrlP spec&lt;CR&gt;", easy peasy :)
Yup :)
Pinterest or Heroku? :)
Heroku. I also heard that Pinterest are not doing any further Elixir.
I don't know if OP works at TpT, but I'm interested in how they handled feature work during the 2 month span covered in the article.
The OP does work at TpT! Good question. My understanding of doing migrations like this (via reading random blog posts and anecdotally through talking to others in the industry) is that your question is often a point of contention between Engineering and Product. Engineering claims that rebuilding infrastructure to be a solid foundation will allow us to iterate more quickly in the future. However, Product suffers during the migration with decreased velocity. Estimation is hard, so the migration takes longer than expected (if it didn't we'd have a serious dearth of interesting posts like this one!) and it causes tension between Product and Engineering. Before we started this migration we drew a line in the sand and said "all new development will happen on our new infrastructure". We had buy in from everyone involved. In practice this meant that while we had a couple of people struggling through scaling issues, we had others building new features, getting them out behind feature flags to QA and BETA testers and iterating based on early feedback. As of right now, the already built experiments are releasing on a weekly cadence to the new page and our product teams couldn't be happier. Does that answer your question?
Farmbot is using Nerves. I'm the embedded systems developer for Farmbot, and a Nerves Core contributor, so my opinion might be a little bit biased, but i &lt;3 Nerves
Awesome, thanks for your contribution to Nerves. Any idea if nerves is going to support bluetooth?
We have been working on Bluetooth. Bluez is a huge dependency that we have been trying to find a better solution. I have bundled Bluez into a couple personal projects and its very hard to work with.
That's cool. I like the opaque header. How did you deploy it? We're writing a complex blogging engine here. Development has been fine, but deploying to Digital Ocean with Distillery and Edeliver is harder than we expected. I read your post about worque: https://github.com/qcam/worque I was looking for a todo-list CLI app only yesterday. Thanks for sharing this. 
You are correct, it is not bundled by default, simply because it is so huge. None of us have had a huge amount of time to put into it lately because we all have full-time jobs, but some good ideas have been kicked around after reading thru the Bluetooth parts of the kernel. We could always use contributers. Theres always a need for documentation so even if you don't have code to contribute, you can help that way. That is one of the best way to learn Elixir imo, to read thru source code and help document it. (really that goes for any language). I've been doing Elixir for going on 2 years now, and been contributing since I started in little bits here and there. I just recently started helping out more because the nature of my job means I require more features that would help the rest of the nerves/embedded community. If you have something to contribute, just throw it out there we are pretty good about pull requests and issues. 
Yes, I think so. I'm impressed that you landed on dead-ending the legacy platform at the beginning of the migration, given that new features developed in the interim would initially have pretty narrow exposure. It sounds like your culture was already set up to roll out that way so it was not as much of a constraint as I'm imagining it to be.
I'm pretty new to Elixir and working on building an API client for a payment gateway system, so I'm intrigued by some of your design decisions. I'm using HTTPoison and Poison as well. I'm trying to decide the best way to handle transient (e.g., network) errors, and have tentatively decided to return `{:ok, decoded_json_payload}` or `:error`. I thought about providing additional context in the error case, but I haven't figured out a good way that sufficiently abstracts the underlying HTTP client library. That is, I don't want people depending on the behavior of the HTTPoison library. You've decided to expose HTTPoison's errors through `error.reason`, which is on the opposite end of the spectrum. I'm not sure what the best approach is, design-wise. I don't necessarily want to expose the full range of errors that could happen when making a network call, nor do I expect the user to truly act differently if it was a DNS lookup failure or a TCP connection error. I'm wondering if I should go with a middle-ground approach, maybe returning a `:temporary_error`. My library also throws on other error conditions, since a failure to parse an API response from the server seems pretty exceptional to me. As an Elixir newbie, I'm still trying to figure out what conditions fall under the "let it crash" category. Anyways, if anyone can chime in with advice, that'd be swell!
Maybe, `{:error, :transient}` and `{:error, :bad_response}`? But then there are the actual error responses returned from the API, which at the moment would look something like `{:ok, %{"error" =&gt; %{"reason" =&gt; "foo"}}}`. Should I treat API error responses the same as network or JSON parse errors, or leave it where, if you got an `{:ok, result}`, then `result` is simply guaranteed to be an actual response from the API server (i.e., it could still be an error response)...? So many design questions. :)
So this is what I've gone with. Basically the library will take a map of parameters to send, will reduce this to only valid parameters, and pass it along to the appropriate endpoint. Responses are parsed from JSON, but otherwise untouched. You will get one of: * `{:ok, decoded_result}` * `{:error, :transient}` * `{:error, :bad_response}` This gives the user the most freedom in terms of which parameters to pass along (since only a few are actually required), and which response parameters are interesting for their needs.
Well, I found a resource. https://www.youtube.com/watch?v=antnsMgA4Ro Derek Banas explains how to get Elixir set up in Atom.
The question already has answers, have you looked at them or tried them?
&gt; GenServer.init function, your data gathering will only run whenever the GenServer is started. I know. I need a simple answer.
Upvoted because I want to see more content of this nature, but this article is kind of rambly and I didn't actually get much out of it, other than that Jake really wants me to visit toolbox.chat which was linked no less than 3 times. For comparison, there is only one code sample, and it's not formatted or highlighted. That's not a very good promotion:Elixir ratio.
:) more support makes me happy!
Yes the answers are mine and from a coworker
Sorry, just updated the theme and GiyHub pages gone 404. Trying to bring it back. Yet I suspect there's something wrong with GitHub pages.
Fixed now. But I couldn't find the root cause. So dropped docs and gone back to master/source.
Can you handle authentication/authorization in Apache/nginx/other proxy, and pass the result down to Phoenix?
I wanted to learn a bit of Elixir. First, I've started with Phoenix and observed that the development was going on too smoothly. And I suspected it is because of Phoenix's magic. That's why I've tried to write a Telegram Bot (not a generic bot). Here I've omitted the more complicated parts like parsing/destructing different messages, answering to button clicks, handling a swarm of user processes (I've used gproc for this). The main concern here was to build a foundation that helps people from other PLs to think in Elixir, and share it!
The study so far, especially with children, tends to show the contrary. IE maps and reduce, but also in general declarative programming are more natural to children than for loops and conditionals. There are a couple example i could fish out if you want. Sorry for being that late, vacations...
Thanks for making this free, /u/knewter! (Saw you post it on Slack yesterday)
I started porting a python library to control a quadcopter https://github.com/ConnorRigby/crazyflie_client Still WIP
It's mostly the same as always using async/await since elixir blocks only the current process and not the whole VM, just as await blocks the current function until the promise is resolved. In node you get concurrency by using the event loop, in elixir by using processes. When using Phoenix, as each request runs on a different process, doing blocking operations only affects that request. 
Each request is happening in its own process, so if you do something slow (like let's say someone uploaded a large avatar and you're resizing it) then it won't halt any other users, it will just halt the current user while it's resizing. If you want to run *that* in a separate process then you could do something as simple as `Task.async()`. That way it performs the image resize in another process and lets the current request respond to the user immediately. And if you need something that's longer-running then you could use a `GenServer`.
Yes, that sounds like a perfect use case for GenServers. I don't have much experience with ETS yet, but that sounds like a use case where I might look into using ETS to store the data and use a GenServer (or a set of GenServers) to retrieve the data and dump it to ETS. The docs on Elixir's website are pretty good: * https://elixir-lang.org/getting-started/mix-otp/genserver.html * https://elixir-lang.org/getting-started/mix-otp/ets.html
Consider some GenServers where one GenServer is responsible for periodically (achievable by sending messages to`self()` with `Process.send_after/3`) sending out a `handle_cast` to a GenServer that refreshes data, and on completion, sending a `handle_call` to a process to write it out to DB or filesystem, sending a `handle_call` to cache GenServer that loads from ETS and a Supervisor that can restart that GenServer on death to a known good state from the filesystem writeout if it dies, and a simple restart for the other ones. Also look into Cachex for your particular problem, it handles a lot of the ETS + refresh things for you.
What does this mean for elixir?
Excited to see if there's any performance gains from this new Erlang-version.
Maybe I can now see poop emojis in my application logs.
That was fast...
Here you go: https://brainlid.org/elixir/2017/06/14/security-scanning-phoenix.html
Hopefully Elixir &gt;= 1.4.5 will take use of all these new features included in Erlang 20.0.
It looks like 1.4.5 just dropped today but still runs on Erlang 18.
Ah ok. Do we have word on if it will run on 19 or 20? I'm guessing they just started discussion about it since Erlang 20 is very recent.
not that I know of, but I am not much in that loop. 1.5 is not out yet, and that will support 18, so they may not have even begun considering which version would be next. it would only be natural to me to target the current stable release when that dependency is bumped, though issues such as distribution availability will also come I to the decision process no doubt.
Right. I'm referring to new elixir features that may be dependent on new Erlang features. I'm imagining Phoenix, for instance, using the new SSL features but that would require a min version of Erlang and I don't see Phoenix requiring that unless elixir does.
You've never worked with scala, I presume?
I'm not sure, but it seemed like it was working for me. I think the PR just has to do with setting a different directory to use as history.
Elixir 1.4.5 supports Erlang 20 according to the changelog. https://github.com/elixir-lang/elixir/blob/v1.4/CHANGELOG.md#v145-2017-06-22
I have been using remix for a while and it works pretty well. I do notice it didn't do a great job of picking up new files. What interests me here is that this appears to want to pull in a bunch of tools like credo...
This library makes a bunch of bold claims but: 1. It doesn't discuss where it sits in the trade-offs of distributed systems. I would at least like to know if it is about consistency or availability in the CAP terms 2. It has no docs 3. It has no tests Building distributed systems requires analyzing a series of different trade-offs and figuring out which ones work best for you. There is no silver bullet. If this is simply a wrapper around Erlang facilities, then I would rather use the Erlang facilities because they are at least documented and there is plenty of information about their trade-offs online. There is plenty of space for interesting distributed work to happen with Elixir and the Erlang VM but we need to push for highly documented and tested code. Otherwise we are potentially misleading new users. Even with Elixir/Erlang, writing replicated, distributed and fault-tolerant code is still difficult and a wrapper library won't make it easy.
How do you define a function "from param1 in param2"? Quite new to elixir language.
Actually you can view the source of any function/macro by clicking the "&lt;/&gt;" besides functions in Hex.
It's called a macro. Macros can transform source code during the compilation process. Unless you're very familiar with programming in Elixir its best to stay away from macros at first. It's tempting to start there, but it's quite unnecessary for most application programming. 
`override: true` didn't help for me as well. Thanks for the tip
Don't use atoms that aren't known at compile time. There really aren't that many times where you MUST use atoms. Poison.decode! (Mentioned in the article) Actually defaults to using string keys instead of atom keys unless you request it use atoms, and there's a big ol' warning about this exact issue in the docs for the option to use atom keys. There's also an option to use atom keys, but only reuse existing atoms to prevent this issue. This is one of the biggest gotchas with Elixir/Erlang and there's plenty written about it but people still seem to get bitten quite frequently. I wonder what we could do to help that. Warn on creating new atoms at runtime maybe?
I'd do the atom =&gt; string conversion for user-defined config files, since those files are likely to contain identifiers that are used all over the place.
The atoms table is similar to the symbols table in Ruby, meaning that the value is atomic and app-wide. This is good for performance when the value doesn't need to reallocate memory. However, as the article indicates creating dynamic atoms will add up as the atoms table never gets cleaned up (by design) To ensure that you do not fall into this trap you should always use `String.to_existing_atom/1`. It will only allow you to use an atom value from the existing table. This will avoid the DOS attack on your app.
Atoms are never garbage collected so they will remain in memory indefinitely. There's a lot of benefits from this and you could say it's what differentiates strings and atoms. You should never turn strings from input into atoms that aren't known explicitly at compile time. Theres never a reason to do that.
Yeah, that's a decent summary of the article, but not an answer to my question. 
&gt; String.to_existing_atom That will throw an exception though. And since we don't really rescue things here, ehh....
Sorry I didn't read the article. I don't know how well I can explain this but I'll give it a shot. Atoms are literals, constants who's value is their own name. Internally what happens is that atoms are represented as ids and stored in a table called the atom table. Now I'm a bit rusty but either the id's have a max limit, the table does or both but that's where the limit comes from. Atoms are meant to represent things there can only be a limited amount of. Module names are atoms, true and false are atoms and developers can use them in their code to differentiate between things (think where you would use enumerables in other languages). Think if erlang didn't have atoms and used strings or binaries instead. Strings are really lists so you would have to compare every element in that list. Binaries are faster to compare but they can be completely arbitrary in length. Atoms can also be arbitrary in length when you look at the code but because the virtual machine represents them as fixed length id's they are really fast to compare. This is really important for performance, especially when atoms are used for every function call. You can't really ever tell if you will ever need an atom again so it's impossible to know if they can be garbage collected, having to rebuild the atom table would be problematic as well since it is so heavily used internally (booleans, modules etc.) Hope that makes any kind of sense.
Not related to elixir Edit: apologies there is a elixir related section and I can't read. -_-
Those are great ideas. the concurrency control, in my mind shouldn't matter, you just add the events to the event queue as they happen. Ideally these events are idempotent, and represent independent changes. I suppose that getting events out of order could cause potential race conditions for replaying to current state.
Ecto.Query.from/2 is a macro. It will receive the raw syntax of the arguments, so for example when you call from f in Foo, where: f.bar The from macro will receive two arguments, the first one: {:in, _, [{:f, _, Elixir}, {:__aliases__, [alias: false], [:Foo]}]} You can see there "in" is an operator. The macro can translate the syntax into whatever other syntax it wants. You can learn more about the Elixir syntax in the [Syntax reference page from docs](https://hexdocs.pm/elixir/master/syntax-reference.html#content).
Huh, TIL. Very well written and informative. I've known how the beam handles concurrency for a long while now but I always thought that "all concurrency" uses preemptive multitasking. It'd be interesting to see a comparison on which languages/frameworks use preemptive multitasking vs those that use cooperative.
any chance of getting prezto support?
Thanks, this is super helpful!
aaah i bet the single body / multipart is the thing! I'll look into it. Here is my code, for reference: defmodule ObjectServer.Router do use Plug.Router require Logger plug Plug.Parsers, parsers: [:urlencoded, :multipart, :json], pass: ["*/*"], json_decoder: Poison plug :match plug :dispatch #heartbeat request get "/", do: send_resp(conn, 200, "{'objectserver':true}") #pathway for getting a file. put "/:object_identifier" do Logger.info "got a post request for a file to be stored as #{object_identifier}" Logger.info "#{inspect conn}" send_resp(conn, 501, "{'resp':'put method not yet correctly implemented'}") end match _, do: send_resp(conn, 404, inspect conn) end I send a message using curl: curl --upload-file test.jpg http://localhost:8321/ And the logger records this: %Plug.Conn{adapter: {Plug.Adapters.Cowboy.Conn, :...}, assigns: %{}, before_send: [], body_params: %{}, cookies: %Plug.Conn.Unfetched{aspect: :cookies}, halted: false, host: "localhost", method: "PUT", owner: #PID&lt;0.281.0&gt;, params: %{"object_identifier" =&gt; "test.jpg"}, path_info: ["test.jpg"], path_params: %{"object_identifier" =&gt; "test.jpg"}, peer: {{127, 0, 0, 1}, 37380}, port: 8321, private: %{plug_route: #Function&lt;1.32664883/1 in ObjectServer.Router.do_match/4&gt;}, query_params: %{}, query_string: "", remote_ip: {127, 0, 0, 1}, req_cookies: %Plug.Conn.Unfetched{aspect: :cookies}, req_headers: [{"host", "localhost:8321"}, {"user-agent", "curl/7.52.1"}, {"accept", "*/*"}, {"content-length", "22695"}, {"expect", "100-continue"}], request_path: "/test.jpg", resp_body: nil, resp_cookies: %{}, resp_headers: [{"cache-control", "max-age=0, private, must-revalidate"}], scheme: :http, script_name: [], secret_key_base: nil, state: :unset, status: nil} 
Watch presentation linked in that blog post: https://www.youtube.com/watch?v=q8wueg2hswA It's really good (also I like criticisms towards node.js)
SECTION | CONTENT :--|:-- Title | What every Node.js developer needs to know about Elixir - Bryan Hunter Description | Node with its sweet-spot of quickly standing up back-ends has caught fire in dev shops around the world. Depending on your business case, that fire can yield a high-fiving “we did it!” celebration, or a charred project timeline with scorched, haggard developers. When is Node OK? When is it dangerous? What’s the alternative? Many seasoned Node developers are discovering Elixir makes a great lifeline when Node turns creepy. They're escaping to a polyglot approach: JavaScript in the browser, Elixir... Length | 1:05:40 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Great Post Thanks a lot it helped me a lot I am also going to share it to my friends and over my social media. Also, Hackr.io is a great platform to find and share the best tutorials and they have a specific page for Elixir This might be useful to your readers: https://hackr.io/tutorials/learn-elixir
Cool stuff. Definitely going to take my time going over it. However, knowing next to nothing about Twitch however, I was kinda disappointed "Kappa" had nothing to do with the mythical beast.
There are some advantages, some differences, what not. If you have this question in mind, I suggest you to read what is BEAM, how does it work (in abstract, high-level terms) and how it is different from mostly any other virtual machine, language runtime, etc. In the end Erlang is just a nice and convenient way to write BEAM instructions (correct me if I'm wrong here) while Elixir is built on top of Erlang. 
Thanks for the answer, will give Phoenix a try, see how it compares with Loopback
Just to answer 1: Javascript VMs are going to run circles around the Erlang VM on things like basic loops. Elixir/erlang's performance properties benefits are going to come from its special runtime properties. In a standard web development scenario with tons of short-lived processes and a few long-lived stateful processes, you will see much more consistent latency numbers that are often competitive or better Node latency numbers. And that latency will stay a lot more steady even under full loads.
for anyone curious as to the solution, this can be resolved by doing the PUT command differently: `curl -v -X PUT "localhost:8321/test.jpg" -F "file=@test.jpg"` 
SECTION | CONTENT :--|:-- Title | What every Node.js developer needs to know about Elixir - Bryan Hunter Description | Node with its sweet-spot of quickly standing up back-ends has caught fire in dev shops around the world. Depending on your business case, that fire can yield a high-fiving “we did it!” celebration, or a charred project timeline with scorched, haggard developers. When is Node OK? When is it dangerous? What’s the alternative? Many seasoned Node developers are discovering Elixir makes a great lifeline when Node turns creepy. They're escaping to a polyglot approach: JavaScript in the browser, Elixir... Length | 1:05:40 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
SECTION | CONTENT :--|:-- Title | What every Node.js developer needs to know about Elixir - Bryan Hunter Description | Node with its sweet-spot of quickly standing up back-ends has caught fire in dev shops around the world. Depending on your business case, that fire can yield a high-fiving “we did it!” celebration, or a charred project timeline with scorched, haggard developers. When is Node OK? When is it dangerous? What’s the alternative? Many seasoned Node developers are discovering Elixir makes a great lifeline when Node turns creepy. They're escaping to a polyglot approach: JavaScript in the browser, Elixir... Length | 1:05:40 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Because he represents the great community behind elixir that thinks about developers when buildings the language - documentation as a first-class citizen, helpful error messages and lots more.
JavaScript gives you an event loop. Elixir gives you millions of event loops.
Just to address #2: You don't avoid runtime errors with typescript; you avoid type errors at runtime. But as with every language in existence, you're absolutely guaranteed that things **will** eventually go wrong, which is why Erlang's approach is to supervise and monitor processes and handle failures out of band. It sounds complicated but having defaults for when stuff goes wrong is very pleasant compared to having to catch every error everywhere lest the system crash.
I personally tend to stick a lot of my cleaning/data formatting methods in the module that also defines the schema. For me, the context module is generally used as a high-level wrapper on everything else. A good way I've heard Chris McCord speak about it in the past, is that you should rarely be using your nested modules that far outside of your system. There are exceptions to this- such as in umbrella applications, or for one-off pieces- but it's a good rule of thumb.
The top post explains it all, but basically if you're designing any web app, apis, whatever, elixir will always beat node for stability, availability, and concurrency. Common examples used are whatsapp and facebook - elixir wouldn't blink an eye at the amount of users connected at once per server. I don't think you'd be able to achieve that with node without massive server farms and a lot more architectural tricks to ensure complete stability and availability. With elixir it's pretty much "out of the box" functionality.
One minor nit: while it's easy to say that elixir is built on erlang (and I often do when talking to new people), it is more accurate to say that it is natively interoperable with erlang in the sense that you can call erlang functions without any real ceremony. Otherwise they are both languages that compile down to BEAM byte code. Similar to how there are now a bunch of languages that run on the JVM. 
That, indeed. JS doesn't seem to scale well, either in terms of performance or in terms of complexity. When I'm half-joking I always say that the '90s had VisualBasic, the '00s had PHP, and the '10s have JS - apparently every decade gets its own crappy language ;-).
deleted ^^^^^^^^^^^^^^^^0.4360 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/25529)
deleted ^^^^^^^^^^^^^^^^0.0139 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/42545)
I have a personal deep dislike for it, based on experience with several implementations.
And he's the most responsive project lead I've ever seen. There's been several times I've posted an issue or PR as just a regular user, and he's responded within minutes, with friendly and helpful feedback.
I'm not that fond of the idea that it's out of the box; yes, it has constructs that makes a lot of things easier to do in general, but the developer absolutely needs to understand how they work, and how to use them responsibly.
I'm actually not sure I understand what you're saying. Your code snippet can be reduced to `someVar == null`, but anyways why would an object-oriented language have strings and numbers as objects? I can't think of any object oriented language that has that, except I suppose Ruby? But... even more importantly, why does that matter and why is that a disadvantage to JavaScript while an advantage for Elixir?
Ruby, Java (numerics in Java 9 I believe) and C++ x == null does not return true if x is not defined. I'm merely pointing out the negative design aspects of javascript. Elixir has its own advantages and disadvantages. All of this depends on your use case, and it's important to have a full understanding of this before making decisions. So the question is Elixir "better" than Javascript (or PHP, Fortran, assembler) is inherently unanswerable.
Also good bunch of elixir's functions just call appropriate erlang functions underneath and don't `reinvent the wheel`, plus OTP :)
It's in erlang, so you kinda have to read the erlang documentation, but here's the one built into the VM: http://erlang.org/doc/man/inet_res.html
Could you just make a system call to dig?
no
I've had same issue and did a small wrapper around inet_res https://github.com/kagux/ex_dns_client here's how to lookup ns records `ExDnsClient.lookup("example.com", type: :ns)` it accepts same options as inet_res 
What I usually miss in DNS client libraries is the ability to specify the nameserver ip you want to query
actually, you can do it. in inet_res or my library I suggested above to lookup against localhost ExDnsClient.lookup("example.com", nameservers: [{{127, 0, 0, 1}, 8053}])
Is 8053 a port designation? Whoa. Nice feature.
yeah, copied from a test example 
Are you proxying to Phoenix with anything, like Nginx? You could cache at that layer with Nginx or Varnish
I can do it in Nginx, but I eventually want to add complex TTL and cache expiring strategies, which I presume would be easier in some sort of middleware, but maybe I'm wrong.
That should be very easy with [ConCache](https://github.com/sasa1977/con_cache). Either cache the rendered page itself, or cache the expensive DB queries only.
Some googling didn't really lead me to anything to be honest. Varnish might be a really good fit in this case, because you can interact with it to purge stuff from the cache
As far as I understand it, I could cache expensive DB queries with ConCache, but it isn't clear to me how I would use it to cache rendered views...
Just do something like this in your controller: def index(conn, _params) do page = ConCache.get_or_store(:my_cache, :main_page, &amp;do_render/0) html(conn, page) end defp do_render() do Phoenix.View.render_to_iodata(MyApp.MainPageView, "main_page_template.html", %{}) end
Thanks, I'll try this out.
Definitely give it a go. In terms of apps I'd actually build something similar to what you built in go so you can really compare the two, however a hashing app might not be the greatest in elixir because it's not that flash at number crunching
Its main strength relies in concurrent message passing right? So things like a chat app?
Have you had a chance to measure the render time vs the data lookup time? View render time in phoenix is extremely fast, I don't think I've yet seen a situation where view caching brought much benefit. Usually it's enough to just use something like ConCache to have the data in memory so you can avoid DB lookups.
Chat type apps are definitely it’s party trick but it’s pretty nice for regular web stuff too. 
Hmm okay cool, thanks I'll take a look 
I learned elixir by doing these problems and had quite a fun time with it: https://adventofcode.com/
I'm building an event driven back testing system for forex and possibly stock strategy back testing as well as starting on a forex trading algo platform 
For me, the main reasons are: dynamic type, meta-programming and built-in distribution.
Yeah, I guess it might not be a problem, but I was trying to avoid any duplicated work. I'm setting up a few tests to see what's really necessary. This is a rewrite from another language, so there are optimizations that were necessary in the last version that might not do much good in elixir.
What kind of duplicated work are you trying to avoid?
Well the view will stay the same for periods of time, in which view rendering would have to take place for each request. What I have in the old version is that the response is cached, and the cached version is dealt out until it expires. This really helped in the old version because there is a lot of templating work that gets done.
Understood, and there are view caching options. I would just make sure to benchmark rendering with pre-existing data before going through the effort of doing so.
Just out of curiosity, what would those options be? Something along the lines of what dmor said? Or would it be much more involved?
His solution looks fine! One main thing to note is that each cache is local to a particular server. If you end up wanting to do cache invalidation you'll want to make sure to call your invalidate function on every node.
Yeah, cache invalidation has been one of my bigger worries. I usually use redis for something like that, but I guess that approach would work for something like that since I could switch out Concache with any arbitrary cache function. Thanks for the help!
Sure, but I can't stress enough the importance of measuring the differences here. ConCache is `:ets` backed which is an extremely fast in memory key value store. The invalidation story here isn't much harder than redis, you just gotta run the function on each server instead of on just one. A lot of folks come from Rails and look towards memcached or Redis for view caching by default, but render times are night and day different between the technologies.
One of the biggest differences between Go is how you build highly concurrent/parallel systems. CSP vs the Actor Model are two different paradigms. Whereas concurrent programming in Go involves spawning goroutines, coordinating/communicating, and waiting, programming in Elixir is much like building a group of small coordinated programs in an operating system. In many ways this model is an advantage. Since each Erlang process is isolated in memory, each can crash without jeopardizing the entirety of the application. So you can specify how each individual process handles crashing and restarting. Another advantage is that building these small separate programs (Erlang processes) can make the mental overhead for highly concurrent programs much lower. I attribute this too not having to spend so much of my mental capacity figuring out how to coordinate the concurrency since I'm building out many small Erlang processes that have single responsibilities. There are a few other things as well, but I think the concurrency model might be the biggest advantage. Not to say Go doesn't have its advantages, each have their sweet spots. Anyways to answer your questions specifically, a chat app is a good place to dive in. I'd try not to use Phoenix Channels and build something more barebones while learning OTP, Elixir/Erlang's framework for building concurrent applications.
Do this in native Elixir by calling the built in Erlang module you can do: iex(1)&gt; :inet_res.lookup('google.com', :in, :a, nameservers: [{{4,2,2,1}, 53}]) [{172, 217, 11, 46}] (53 is the default DNS port) 
I thought this tour to build a chat app was pretty cool: https://www.ludu.co/course/discover-elixir-phoenix BTW once you master pattern matching and argument deconstruction (and guards), you won't want to build software in any other way, warning you 😂 
The twitch Kappa is a mythical beast. Kappa
Happy to try it, thanks for the link
This is great. Thank you for sharing. Do you happen to have the code you used available to the public?
I did some research on this about a year ago. My memory is pretty fuzzy. Maybe some of this is helpful, maybe none of it. Erlang/Elixir on Xen seemed pretty dead to me. IIRC I tracked down the twitter feeds for some of these projects, and I think one admitted defeat. Someone may have picked the projects back up during that time. Where I saw potential was on another hypervisor that offered broader language support. It could have been KVM, I can't quite remember. It may be worth it to see what the other hypervisors are offering. I know there are people out there who are interested in using this technology with Nerves, so that may be another thread to unravel. Keep us updated if you make progress!
Glad you enjoyed it! As for the code, I just pushed it to github after cleaning up a couple of things. It will contain the code for each episode as we go along, as well. I'll link to it in future episodes from the video description. Enjoy, and feedback (as well as topic requests) very much welcome! [https://github.com/aseigo/exploring-elixir](https://github.com/aseigo/exploring-elixir) 
This is awesome! What front-end framework did you use for the UI? That's one aspect of building with Phoenix I've never quite been able to wrap my head around.
No front end framework, just usual vanillajs plus some libraries. The style/css I'm using milligram 
I'm building a bot building/hosting platform, that will allow you to develop and run bots across messaging platforms (slack, messenger, etc). Is an interesting exercise at several levels.
https://www.youtube.com/watch?v=SDKiLO2XwIs
This project of yours is a really fun kind of ambitious. I don't 100% know where it's going, but I wish it all the best.
You can `spawn()` processes (though it’s an abstraction, since JavaScript has a single event loop), and `.send()` and `.receive()` messages between them. There are probably other implementations out there, but this one tries to stay close to Elixir semantics. It's missing some things like `receive`'s `after` option, and linked processes and such. But lemme know what you think!
So the whole "parallel" execution is just a setTimeout call? I bet you could achieve something more interesting with generators.
With the Ludu course what Phoenix version do they use and if your don't mind what is your overall review of the course? To me it seems a little short and was wondering if it was really worth the money. 
I wonder if this could use service workers for spawned processes if they didn't need to interact with DOM etc?
Phoenix 1.3-rc I thought it was worth it, the later chapters got much longer/more involved which was good Also, the creator of it was very responsive 
I mean, until I checked these comments, I assumed web workers were in play- they're a "perfect" tool for modeling actors, and you could always give them a reference to a renderer object that passes messages to the main loop if they needed to touch the DOM (the way Angular 2 does it).
I think generators/sagas are getting pretty close to basic process semantics. There's even a discussion issue in redux-saga about "do we need supervision now that we have sagas (which are generators usually in a little receive-loop of some kind)?"
for very beginning - try to write palindrome checker - to check if "A man, a plan, a canal – Panama!" is a palindrome - disregarding case/punctuation. That will make you learn recursion at least ;) There is at least 2-3 ways to write it and some of them are more efficient than others :) This should take 2-3 hours at most. More complicated - try to write simple stack machine as an exs script - getting commands like push, pop, +-*/, swap, print from stdin and printing results out. This should take 3-4 hours. To learn messaging/supervision - try to make same stack machine as a GenServer and have separate server responsible for interacting w/stdin and put everything into supervision tree. This rewrite should take 4-8 hours until you wrap your head around behaviours/supervision. Reading book on OTP really helps here. Next big step - learn how to add tcp/udp server or some framework on top of that and make (REST) API for the stack machine. Should take 4-5 hours. Good way to learn binary manipulation/pattern matching + writing tests using ExUnit - write [OSC protocol](http://opensoundcontrol.org/introduction-osc) encoder/decoder :) This is 8-12 hour project depending on how much testing you want to put there. To really feel power of elixir/erlang - try to write simple caching http server using just gen_tcp using ETS tables as object storage. This can take up to a 40 hours if you did not worked low level with HTTP protocol - learning how caching works in HTTP + solving concurrency problems when several clients request same resource :) If you want some more intermediate complexity tasks - message me and I'll check what else I have :)
These are all amazing, more please if you have them :D
Thank you. I just posted some exercises from trainings I did here - https://medium.com/learn-elixir/comfortable-learning-curve-for-learning-elixir-part-1-67231042fec I'll write about rest of the points in more details and post on Medium - subscribe and follow articles there ;)
Current state of the statistic aggregation function helpers can be checked there ~~https://github.com/hauleth/ecto_olap/blob/feat/statistics-aggregators/lib/statistics.ex~~ (link is now obsolete, branch was deleted)
Out of curiousity, did you run the numbers against OTP 19?
No, I didn't. 2 versions was already taking a fair amount of time, so I picked 18 since that is the minimum requirement and seems to be quite common a choice, and 20 since that is where the optimizations I was attempting to measure first appear. would be interesting to see the numbers though.
Thank you!
database server in Elixir with near real-time updates streaming :))) very interesting and challenging project ;)
Nice project! When wrapping an API I like to keep the names identical. It should make it as easier for a new developer to google the function name and get to the postgres docs for more details.
I've checked, and Oracle use the same names so I went with it instead of grouping functions in modules.
Yep, probably! I don't know too much about service/web workers, so I'll have to look into that. The setTimeout call was just to ensure that PIDs are defined. But ignoring service/web workers and Node.js `child_process` and such, I was mostly just interested in practicing API design.
Couldn't you just render this point moot by using containers for both?
Indeed, delivering containers helps, but the benefits only go so far compared to producing an artifact. One of the bigger problems is dealing with repositories and dependencies. npm is notorious for being unreliable (aka down), and a container will not fix that. This ends up being a pain you drag all the way across your CI process. Node also doesn't resolve dependencies unless you use `yarn`, which is no magic bullet. `mix` is much saner on both those fronts.
I had a ton of fun building a Slack bot framework (using the websocket "real time" API). Things I like: * I wasn't in a framework, which I like when I'm starting out (doesn't mean you can't have another side project with Phoenix at the same time) * It wasn't trivial, but it wasn't enormously difficult either * You get to choose the structure of your OTP architecture with regards to processes, supervisors and the like. This is particularly relevant if your bot integrates with third party APIs or does webscraping. 
Does using `path: 'deps/my_dep'` change any compilation behaviour? You can just do e.g. `mix deps.compile my_dep &amp;&amp; mix test` (or `mix do`) to achieve the same without needing the edit.
There's no need to change your mix file at all. You can just open the deps folder after doing `mix deps.get`, find what you want and then run `mix deps.compile`... Mix does not compile after fetching, compiling happens when the first mix task is run. I do this all the time when I want to understand what I've potentially done wrong.
Nice, any clue on how to receive emails in elixir using IMAP? I am working on this app to do this, but I want to use elixir for it and I can't find any package for this. 
Opens source? Commercial? Is there a github repo?
Undecided yet, so far is more an practice/exercise for me to get the hang of FP and Elixir-Erlang. Would love to DM with you if you are interested on learning more of what I'm building 
I really like being able to add `npm` dependencies to via `npm i --save` and ruby decencies with `gem install`, so I made a package you can `archive.install` and have a globally available mix task that lets you `mix depz.add dependency`. https://github.com/MainShayne233/depz/
Really nice intro to a great feature - keep up the good work!
Hey sounds pretty interesting! You able to provide some more info on the sort of things your doing and how you're using elixir to achieve it?
thanks! if there is anything in specific you would be interested in seeing I future episodes, just let me know .. topic suggestions and other feedback is more than welcome.
I am really enjoying them as well! Since you are asking for suggestions, I would love a follow-up to the episode above. The best part of `child_spec/1` is that GenServer, Task, Supervisor and so on automatically define `child_spec/1` for you and you can configure it via `use`, so most times you don't need to define `child_spec/1` in the first place. Also, it seems the next RC for Elixir v1.5 will have a debugger in IEx, so a look into that would be great too: https://github.com/elixir-lang/elixir/pull/6307