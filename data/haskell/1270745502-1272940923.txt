You mean like people who refuse to teach a way other than they learned?
there's also lazy-scheme which is provided by PLT Scheme. http://docs.plt-scheme.org/lazy/index.html
&gt; But you're misrepresenting the talk "I was unclear in my talk." Fixed that for you.
It's "(. fromMaybe def)", my mistake with liftM.
You can't boot Linux without the Linux kernel. So, your analogy suggests to me that as a community, our goals should be to discourage Haskell programmers from using implementations other than GHC, and to discourage Haskell library writers from expending their time on portability. Is that a reasonable interpretation?
Do you have a well scheduled plan and willing to accept newbish Haskell developers?
There are already a few attempts to revive the Amarok 1.4 style of project, albeit not in Haskell. Why duplicate effort? Most other haskell products are revolutionary in some way, not just clones.
I find this series of articles interesting because the (at least partial) solution seems somewhat obvious to me but very hard to grasp for many. Having worked with big nasty libraries and big nasty frameworks I recognize the gripe and think it's legitimate. Having worked at the UNIX command line and in C, I think that the "UNIX philosophy" can be of great help here. Lots of small, single-purpose tools that can be used together provides a lot of reuse, but still allows for rich problem solving and expressiveness. To to engineering analogy, let's look at EE: lots of small, single-purpose components available, with larger assemblies sometimes prepackaged where sub-functions are common enough to warrant them. Crack open a CD player and an MP3 player from different manufacturers and you will **not** find a shared "audio framework."
Lots of small, single-purpose components work great, when they are well-documented, work in consistent ways, and share common standards for connectivity.
When components are small and single-purpose they are easier to document, understand, and implement correctly. I think the difficulty in grokking UNIX is that you must become conversant with a vast array of small tools before you can approach real productivity. This shouldn't be a barrier to a professional coder. OTOH, complex libraries and frameworks may let you be *somewhat* productive pretty much out of the gate. But to tackle a full, real world task you also need in-depth knowledge on par (or more) than familiarity with the UNIX tool set. But... massive libraries and frameworks tend to have much more API/ABI churn over time, with whole paradigms coming and going over the space of a few years in the worst cases. So over time you have to replace some significant portion of your working knowledge, often *during* a project.
In terms of impact: encouraging more investment in shared tools, rather than forking tools, will definitely pay off. We have too few resources to fork carelessly.
&gt; Sometimes design patterns introduce classes to represent abstractions like iterations, strategies and decorators Yes, or as we call them, "functions". The proliferation of ad-hoc workarounds for a lack of first-class functions is indeed a major problem in Java and C++ libraries.
Also, news at 8: jdh30 is a douche.
&gt; Scientists said, “Yes, yes, I know exactly what you mean!” Yes, because you've never heard of scientists standing on the shoulders of their predecessors. Indeed, particle physicists are first tasked with re-finding relativity with only Pythagorean teorems as their base.
I'm not trying to be contentious, but I absolutely hated this article. It's length made it tedious to read, compounded by the fact that he needs to *get to the fucking point*. The first 90% is hand waving about how bad libraries truly are (gasp! you've been lied to by some library conspiracy) and then the last 10% is, "Well, I can't really present an alternative. Actually, libraries are pretty great, we just need good libraries". Yea, no shit we just need good libraries. What was the point to his previous malingering then?
`((-&gt;) b)` is a container whose positions are indexed by elements of `b`. Any additional 'shape' to the container comes from structure on `b`.
If you strain and squint you can kind of see it as one. Start with the (contravariant) functor `Hom(_,R)`. The continuation monad is just the square of this. Now `Hom(A,R)` is not a container which contains elements of `A`, but it could be thought of as a container whose shape is determined by `A` which contains elements of `R`. (Which is why it is contravariant: if we can project one shape onto another, we can pull back the contents, but not, generally, push them forward.) So then `Cont r a` is a container whose shape is a container type. Thought I don't see a sense in which it is a container of `a`s. So, yeah, you would have to strain a lot.
Part of why it works so well for Unix command line tools is that they share common communication standards. Pipes, for example. It gets a bit more complicated when you're trying to use unrelated libraries together. &gt; When components are small and single-purpose they are easier to document, understand, and implement correctly. Then I'd like to know why most of the libraries I look at on Hackage have poor documentation, typically limited to type signatures, and a brief description of each function. Rarely are there examples, or hints on how to use the library.
I found the most efficient way is to do both. It's akin to sometimes writing the type signature, sometimes the code, first.
&gt; Part of why it works so well for Unix command line tools is that they share common communication standards. Agreed. &gt; It gets a bit more complicated when you're trying to use unrelated libraries together. For focused tools is less of a problem. If I have a tool to fetch some XML, send the result through another tool to manipulate XML, send it through a XML to JSON converted, ... if something blows up it shouldn't be too hard to find out which step went wrong and if it's a problem in my code or the library. But if I'm using the MegaDataMagick library from within the TodoElMundo framework it may not be so easy. &gt; Then I'd like to know why most of the libraries I look at on Hackage have poor documentation Because no idea, however good, can *force* everyone to follow through? Whatever the methods and tools, some kind of acceptability standard would need to be chosen and enforced. I am not familiar enough with the contents of hackage to comment specifically, but I've seen the same in other places.
[Harrop is the herpes of the FP community.](http://coding.derkeiler.com/Archive/Lisp/comp.lang.lisp/2007-06/msg01515.html)
I was never clear how you guys were going to get ghc-compiled code through the app store review. What was the plan? iPhone is a closed system. 
I have to hand it to dcoutts, he maintains class in [overwhelming](http://www.reddit.com/r/programming/comments/bm1u8/safe_robust_programming_practices_in_haskell_via/c0nqyvu) [circumstances](http://www.reddit.com/r/programming/comments/bm1u8/safe_robust_programming_practices_in_haskell_via/c0nr1qf).
&gt; The evil way, which shall not be named. Lambdacat is watching you. :)
I'm pretty sure that you don't have to show your code to Apple. However, it's pretty easy to run statistical analysis on a binary and guess what complier was used. I can't speak from experience on submitting an app though, I have yet to submit mine. (And I'm not using Haskell on this one). 
I haven't tried using Haskell on the iPhone yet, but I wanted to. I was assuming that it used -f-via-c, but maybe not? How does the evil mangler deal with ARM assembly given the insane prelude/postlude instructions (STMDB, LDMDB)? 
So, has anyone previously published a Haskell-based program on the app store?
Are you just doing the modeling in Blender? Can you go into greater depth about the capabilities of the engine?
&gt; Then I'd like to know why most of the libraries I look at on Hackage have poor documentation, typically limited to type signatures, and a brief description of each function. Rarely are there examples, or hints on how to use the library. This is an issue with Hackage and the Haddock-based system is that there's no obvious way of creating *prose* documentation which will be processed alongside the inline documentation. Like the writer said, having a page of description and a few lines of example does wonders, and this is something which impresses me greatly about GitHub (I don't use it but I've browsed a few projects) --- the automatic marking-up and publishing of the readme file on the main page encourages people to write good readmes.
I think they were trying to reason themselves to a conclusion. It's a legitimate method of essaying, for exploratory purposes. You don't have to like it. I'm just worried by the proliferation of sushi photographs that seems to accompany most software-blogging posts these days.
Yep.
RyanT5000 and a few guys had a small startup that was using Haskell for an iPhone game. I do not know that they have successfully submitted anything to the app store, but this will be a bit of a blow to them.
Completely agree, but then again, I wouldn't say that his commentary is irrelevant to e.g. Common Lisp or Scheme programmers. Nonetheless, to continue in that vein, Paul Graham said ""Peter Norvig found that 16 of the 23 patterns in Design Patterns were 'invisible or simpler' in Lisp." One discussion of this appears at: http://c2.com/cgi/wiki?AreDesignPatternsMissingLanguageFeatures
&gt; a bit of a blow to them Understatement of the year :( EDIT: Their startup is named [ipwn studios](http://ipwnstudios.com/bloodknight).
It might be an interesting project to create a tool that outputs Objective-C or C++ code that appears to be handwritten rather than generated. Some thoughts: * Code generation would have to have include a degree of randomness in the selection of target language constructs to minimize detection via statistical pattern matching * If Apple introduces a requirement for human review of app code, developer comments should be passed through to the generated code, and realistic variable names used. The tool might need to integrate something like [Wordnet](http://wordnet.princeton.edu/). * It may be possible to specify an intermediate language that can be targeted by the code generation tools of many languages (Lua, Scheme, C#/F#, Flash, etc) and then put effort into a making a stochastic code generator that outputs human equivalent code typical of an Objective-C or C++ developer. Something in the spirit of LLVM, but where the target machine is current Apple regulations. 
I had actually been investigating using their Haskell Port myself for a quick project or two, but I was cynically waiting for them to serve as a Miner's canary, to see if they could survive the App Store process. I'm glad now that I never got past sketching an outline for those projects.
I think "unbounded lists" is a somewhat better term than "infinite lists" :)
When I read these posts at work I worry that my coworkers might mistake my programming fetish for a food fetish. 
One of the nice things about these unix tools is that all the good ones are basically just functions for mapping data. They take an input, they have an output, and they do something with that input and largely unrelated to the outside world. It's very functional, which makes it easy to reason about.
I just released a 3d game I wrote completely in Gambit Scheme for the iPhone. You don't have to submit the code. I don't think they'll reject these apps, but you cant bet on it if they discover the native language. Read more abut my app here: http://jlongster.com/blog/2010/04/05/farmageddon-available/
Sadly much less than some of us would like, and its use is rarely pointed out. But we are patient.
WTF? Was this really necessary? Screw you, Apple!
No, no! Far worse is the State monad. "But wait," comes the cry, "It is indeed a container! It contains a state value! I put things into it, and take them out! Have you gone mad?" Which is all true, of course, but for the fact that it's *not a Functor with respect to the contained state value*[0], rather the *return type of the state computations*. One express ticket to misleading intuitions, please! In general, any `Functor a` involving a function type--the well-known ones being `(r -&gt; a)`, `(s -&gt; (a, s))`, and `((a -&gt; r) -&gt; r)`--is not going to mesh with naive conceptualizations of "Functors as containers". The nature of Functor's definition *does* lend itself to container-like things, and because of that tortured analogies usually exist for others, but not in a way that's going to help someone who doesn't already understand the mathematical definition. Speaking of tortured analogies, eruonna's interpretation of Cont is marvelous! I now wonder how one might similarly "explain" State. [0] Actually, something like State but functorial in the type of the state variable would be (and is) useful, but can't be a Functor (even of a contravariant flavor), never mind a Monad. Makes a good excuse to use GHC's rebindable syntax, though...
&gt; You don't have to like it. -Shrug-, I wasn't under the impression that I did, but I think it's important to invite critical opinion. I didn't say that his "method of essaying" was illegitimate, though for me it was too without insight to merit the length. He almost stumbled on something good when talking about CPAN and library "aliveness". That could merit its own article just because it really transcends the idea of libraries. Now we're talking about a networked repository of everyone's work. How to manage a *living* world of code is so interesting. [This post about Cabal](http://www.reddit.com/r/programming/comments/bm1u8/safe_robust_programming_practices_in_haskell_via/c0nr1qf) comes to mind! It would be incredible to have an ecosystem that can store these stats. Like organisms, could we have programs try to plug themselves into libraries automatically and then keep a networked record of the interaction? Is their a future where you can query a networked ecosystem to do a task without picking the library yourself? Going in the other direction (down to the code level) I'd love to hear of people exploring runtime metadata (in a more elegant way than Java's annotations) for library interaction. In the way that you can use types in Haskell as a preliminary specification, is there way to use documentation (available at runtime) to do ad-hoc connections of libraries? Could I query for a library that was implemented using \_\_\_'s algorithm as opposed to \_\_\_'s algorithm? All more meaningful areas of navel-gazing than "waa, there are too many xml libraries".
In hopes of defending comp.lang.lisp: I'm all for ignoring juvenilia, but there is important context for that post. He started with a post claiming that "Lisp pollutes your mind and makes you a worse programmer". When called out as purposely stirring up trouble he says "I knew that would work well here". Thankfully, HC is a place to be proud of and people aren't playing these games.
I work for a big company and tried to switch some of my work to Haskell. Unfortunately, company policy and tech departments can make it difficult to move forward. I had to fill out quite a bit of paperwork and even still, I need to get a manager's approval and cite a "valid" reason for the request. The fact that it's FOSS almost makes it harder because it has to go through a lengthy approval process. For now I'm stuck with MatLab.
...heh. From near the end: &gt; When languages have syntax that allows us to mark objects as immutable or functions as free of side-effects, we should use them: such notation is documentation that the compiler can check for us. The absence of such facilities from extremely dynamic languages such as Ruby is a weakness. That's indeed quite an endorsement of Haskell coming from someone who (as far as I can tell) has never used it!
Seems like a great deal of effort for a platform that is clearly hostile to us.
will probably re-release it once I get the design right ..
yes. i'm only working on the renderer right now, it's an early prototype of a deferred shading system.
Well, its only in the first planning stages right now, but I could indeed come up with a schedule, and considering I'm a newbish Haskell developer myself, I would definitely welcome the help. I want to do this mostly as a learning experience, not just as an attempt to recreate my favorite music player ^_^
My English teachers used to always yell at me when I did that. :-)
as far as i can tell, it's quite common to ship static libs with iPhone apps. It's the way PinchMedia does its reporting framework, for instance... I don't think it'd be totally trivial to distinguish a Haskell-compiled static lib from a C-compiled one.
This is why you shouldn't pay for a device this ridiculously locked down. You're directly rewarding Apple for screwing you and a bunch of other people. Better yet, don't buy a device from a content provider, period. Apple runs their app/music/video/book store, therefore they have a financial incentive to lock you out of third party content. Get the device made by the no-name manufacturer whose entire business model is predicated on you pirating content. Even if all your media is legally obtained, you know they won't lock you out.
I believe it would be. C functions look very different from haskell functions after they've been compiled. I remember seeing a paper a while ago about determining which C compiler was used on a binary through statistical analysis, but now I can't find it. 
You won't get the design right, it will better each time but each time you will have still something not quite right. This kind of stuff kills projects. 
Or we could just develop good applications for other platforms and not for iPhone, and let Apple suffer... I've been reading good things about HTC's new phones, with reviews along the lines of "It does everything the iPhone can do, but often better". These are the same guys who make the Nexus One hardware for Google, and their phones run Android, so not a crisp fruit in sight. :-)
http://www.slate.com/id/2249872/
But, but... monads are like Twinkies!
&gt; generate Objective C code Generating the code isn't allowed anymore. You can try, but you aren't allowed to proudly announce on your site that your iPhone apps are made with Haskell. Or discuss it in open forums and mailing lists. You have to hide your tools, if you want to be sure. 
`r -&gt; a` is actually quite like a container in a certain sense. In a dependent type theory, it's a special case of the dependent product; first one considers families of types indexed by some other type: x : S ⊢ T[x] : Type Then one can form the dependent product: Πx : S. T[x] which can be thought of in a variety of ways. For one, it's similar to a general set theoretic product, where usually one thinks of a set of sets, rather than a family of types. You can then form the Cartesian product of said sets (even if the set of sets is infinite). But of course, we can also think of the dependent product as a function: given an `x : S`, it returns a value with type `T[x]`. And applying a function to `x` can alternately be thought of as projecting out its `x`th component. The special case occurs when `x` is ignored by the family: T[x] = a Πx : r. a = r -&gt; a In this case we've generalized finite `n`-ary products of `a` to `r`-ary products, where `r` is an arbitrary type. So functions 'contain' one value of their codomain for each value of their domain. Edit: I should note, there are cases where this is even more suggestive. For instance, we might naturally think of values of the type: (co)data Stream a = Cons a (Stream a) as containing an infinite number of `a`s. But it's well known that this type is isomorphic to `Nat -&gt; a` (ignoring bottoms if you have to). Simiarly, vectors of a given size `Vec a n` are isomorphic to `Fin n -&gt; a`, `Fin n` being the type with `n` elements. And thus you can get lists via `Σn : Nat. (Fin n -&gt; a)`. Et cetera. I think in general you can encode a ((co)inductive) container by inductively defining a type `Pos` of positions in the container, and letting the container be `Pos -&gt; a`.
I'd be in, too, if the player innovates in some sense. I think taking the Amarok 1.4 concept as a basis for something better is the way to go.
Unfortunately, all the alternatives suck. It's all fine and great to back open hardware/software, except nobody has yet to create an open device that's any good.
I doubt Apple will go after anybody except apps generated from Flash, and possibly Mono-Touch. This clause was clearly designed to target Adobe without explicitly naming them. Hell, there are tons of games in the store already that use Lua for scripting levels, and that's clearly against the developer agreement (even the old one) but Apple doesn't seem to care.
I think he's using his own non-standard definition of the word scientist here.
What about the Nokia N900? It's not open hardware or anything, but it runs a real Linux distro that you get root on. Even Android is far more open than the iPhone.
Isn't the Nokia N900 the phone with the completely fake ad that shows a really slick UI that turns out, in reality, to have practically nothing in common with the video (no transitions at all, really poor responsiveness, choppy graphics, etc.)? Every single non-iPhone smartphone that I've seen has been a huge disappointment in terms of actual usability and user experience.
I guess u got that confused with the n97.
&gt; Thankfully, HC is a place to be proud of and people aren't playing these games. Well, except for the "are there any female Haskellers" topic recently, in which someone posted flamebait and then professed to be amazed and shocked at the reactions he received, but that was a meta-topic, not about actual Haskell code.
But GHC development is sponsored by Microsoft Research! No-one ever got fired for "buying" Microsoft! ;-)
&gt; no transitions at all, really poor responsiveness, choppy graphics, etc.? I have an N900 and that doesn't describe it accurately at all. You must be thinking of some other device, or maybe an early prototype device. Or else someone reflashed the N900 you saw with another Linux distro.
Develop for open phones like the Nokia N900 instead! Unfortunately the market for N900 apps is probably tiny right now relative to the market for iPhone apps. But I have the sense that Nokia are in this for the long haul, and the N900 is really only an early "first cut" at a Linux phone for Nokia (although of course it's based on earlier devices, which were Linux-based but did not have cellular network access). BTW: The N900 currently runs the Maemo Linux distribution, which is quite slick and very different to the kind of Linux you may be used to. Maemo is being superceded by Meego, a merger of Maemo and Moblin, which will be targeted at both phones *and* netbooks.
This article gets a few technical details wrong, but is spot on about the big picture. This is not what Haskellers mean when they say "lazy IO" -- they mean the IO actions like `getContents` that perform IO as you evaluate. That sort of "lazy IO" is actually heavily frowned upon for real apps, so it's a good thing it's not mentioned in this post. :) &gt; Because Haskell is lazy, and IO routines... are treated as lazy values, you can pass around tasks, with all their arguments bound... and not have to deal with a lot of the usual glue The "what" here is correct but the "why" is a little bit off. Lazy evaluation may be the historical reason we have first-class IO, but it's not necessary for the proper functioning of first-class IO. An IO action is a completely inert description; even if you *do* force its evaluation eagerly, no IO is performed. The key idea is that in Haskell, execution (of IO actions) and evaluation (of function application) are two distinct processes, and execution doesn't depend on evaluation order, lazy or not. As I said, the big picture is spot on: &gt; When you design a language to operate via side effects, then you have to deal with those side effects immediately, as you arise. That means you can't easily reason about it at a higher level... I have a feeling that the functional community (and the rest of the world by proxy) is only beginning to discover the value of treating imperative routines as if they were monadic values. Where it *really* gets powerful, I believe, is in concurrent programming. Using functions to compute thread actions, sending actions in message channels, composing transactional actions and asking for atomicity exactly where you need it... all of these techniques require a first-class treatment of imperative programming. &gt; Haskell's treatment of imperative programming and side effects is possibly the most derided feature of the language. Yes, and it's largely based on misconceptions. As long as people think of this `IO` type as a way to tag impure functions, they'll see it as an irksome limitation. It's often how Haskellers explain IO to beginners, but it's an incorrect model which hides most of the power and elegance of Haskell's treatment of IO. And it doesn't help that Haskellers often use the word "imperative" as if it's the antithesis of everything Haskell stands for. Haskell is a great imperative language and it's important to show this off. By the way, you don't need to understand monads-in-general to do this stuff. The `takeM` functions from the article are nice and general, but could have been written for the `IO` type specifically. At that point, the abstraction called "monad" is irrelevant; you can think about the concrete world where `do` and `&gt;&gt;=` are simply ways of gluing IO actions together.
&gt; Maemo is being superceded by Meego, a merger of Maemo and Moblin It's amazing how they keep coming up with stupider and stupider names... (Satisfied owner of a Maemo device, just saying...)
Writing code in Apple-world is like writing newspapers in China.
I would love to write android apps in haskell, doesn't look trivial yet though, but nothing is insurmountable.
&gt; Part of why it works so well for Unix command line tools is that they share common communication standards. Pipes, for example. Pipes (or even newline-separated results) are pretty low-level "common communication standards", there's all kinds of ad-hoc formats built on top of that which the *working* utilities on the sides of the pipes don't share, reason why you usually have to perform string munging on the results (via combinations of sed, awk and cut) to be able to feed the result of command1 into command2.
"Doesn't seem to care" seems a bad base to build your software business on to me. I agree that this change is aimed at Adobe's tools, Apple don't care one way or another about oddball developers trying to compile functional languages, but they have a habit of turning round and changing their mind about enforcement of their terms. I for one am no longer prepared to invest valuable time and effort in iPhone apps; bring on Android Haskell.
But think about what this means really. A very exciting, important iPhone app gets made with Haskell. And then development details have to be kept secret when it should be a much-talked-about achievement. Like some sad Apple version of "Don't Ask, Don't Tell," fearful of being found out. How much abuse will developers take from this company and still ask for more? Apparently plenty. Very sad.
The iPhone sucks as well. No background processing is a critical flaw. What exactly is missing from the Android phones. Please mention specifics rather than the vague nonsense we generally hear on these topics.
&gt; If Apple introduces a requirement for human review of app code That simply isn't feasable for them, they'd need 20 times the number of reviewers they have right now.
&gt; Develop for open phones like the Nokia N900 instead! Too bad the N900 is a really shitty phone.
That alternatives suck is just flat-out not true. Android is excellent on the HTC MyTouch. And that's not the latest hw/os. There are at least four Android phones that I know of right now, from different manufacturers and with different mobile companies. And you can buy an *unlocked* Nexus1. My biggest bitch at this time with Android is it's difficult today to use anything other than Java for development. That's not a mandate, it's just where Google has invested their energy. They don't give a shit what you write in.
Well if you get a haskell compiler that targets the JVM it shouldn't be too difficult to write haskell apps for Android. They have a tool that converts JVM bytecode to Dalvik.
The problem is Apple apply their rules arbitrarily and unevenly.
It's a shame that Google hasn't published specs for the Dalvik VM -- that would open the door for other development languages on Android.
Perhaps consider web apps and html5. [These guys](http://www.nextstop.com/) have a nice approach and you even get an icon on the iPhwn. Cross-platform and no censors, er reviewers. 
Since a Boston hackathon never seemed to come together, I may have to try and do this.
Apple has a demonstrated track record of being willing to use its power to reject apps for any number of reasons. Any sane developer on their platform must consider the probability of incurring costs from Apple due to them simply deciding not to release your app for some reason, or having it horribly delayed by the review process. I said "probability" for good reason; it's not an absolute and perhaps in your judgment the positives will override the negatives, but you must consider this as a negative. From that standpoint, is it really such a good idea to hand Apple such an easily-detected reason to evict your app? The scenario I would worry most about is: Apple accepts my Haskell app. A bee gets into Apple's bonnet about alternate language implementations sneaking through, as some other project pisses them off. (Or maybe mine, but probably not.) Apple implements their detection routines. Apple either cuts my app or forbids any future updates using Haskell. Not only is this in some sense the worst case scenario, it is also, in my estimation, the most likely. It is likely that with some work you could sneak some stuff by Apple for a while yet, but if they're serious, they're going to get better and better about detecting this. Theoretically, in a long-term arms race, Apple would be the losers. Eventually alternate language implementations could get the point where they would produce binaries indistinguishable from conventional Apple tools (by compiling down into source code for Apple's tools to compile that looks human-generated)... but are you going to wait around for that, bearing in mind that Apple could well blacklist individual developers who get caught in the middle of that arms race with tools that mostly, but don't entirely, work? Basically, trying to force this has to be seen entirely as a bet that Apple simply isn't serious about this clause, because if they are, you lose. It's not a bet I would take, but then, I was completely unwilling to lock myself in the Apple trunk anyhow even before this.
"probably tiny"?
I also work in defense, but the only thing we've dared to build in Haskell are a couple of models that existed solely for quickcheck purposes to make sure that a design was sound.
I'm not sure how well documented it is, but they do provide full source for the dalvik vm.
Soon to be renamed IMPwn3d Studios.
Unlike the last paper written by the same group (available [here](http://research.microsoft.com/en-us/um/people/simonpj/papers/c--/dfopt-popl10.pdf) as a PDF) this paper actually describes their new version of the hoopl library AND how to use it. You can download it from here: http://hackage.haskell.org/package/hoopl The paper is very interesting - people who like strong static guarantees will be pleased.
Would Galois' experience here help? We've got e.g. experience reports for the DoD on the use of Haskell in systems where assurance matters. What would help make your case stronger?
It's a real bitch to program for and has inadequate APIs (if you want access to the accelerometer, be prepared to sacrifice a majority of your CPU cycles to their ridiculously bad interface to it, for example)
Have you actually written stuff for Maemo? I've done a fair amount of N800 development and it was painful to say the least. Scratchbox is a pain to work in, random APIs don't work the way they should, and in general it's not fun. More recently, a friend of mine tried to do some basic accelerometer work on the N900 and found that the only interface to the accelerometer will eat up a majority of your CPU cycles just getting you samples at 100Hz. The N900 is a nice device and I like Maemo on paper, but my experience with it has been pretty negative.
I'd like to see more samples of how to use this library. The paper is good but more examples is always better. I also wonder if their library could be used to convert a CFG into SSA form?
Why did I never hear of this? A Boston hackathon would be awesome.
I'm working on something right now, but it's not public yet. It's basically a watered down version of C-- that I'm trying to optimize with Hoopl (right now, only the basic types and definitions are in place.) Nothing more complicated than the paper shows: basic constant propogation and constant folding, etc. Once I get results I would like to post the source however. :)
I'm in!
They do say that they're developing for multiple mobile platforms...
yeah, I don't know what happened to the Boston meetups, either
or just use the native interface on android and compile to ARM
wow, [their description](http://ipwnstudios.com/bloodknight/news) sounds surprising and ambitious: &gt; iPwn Studios is a Boston-based video game studio started in 2009 by two Harvard Law graduates. &gt; &gt; For the past 7 months our 25-person team has been hard at work on our first title, Bloodknight, which will bring the frenetic action of Diablo-style RPGs to the iPhone, Palm Pre, and other mobile platforms in a way that hasn't been done before. Our homegrown game engine was built using Haskell and supports multiple cores and multiple mobile platforms. Our core team in Boston is working toward a release date in the first quarter of 2010. &gt; &gt; iPwn Studios is always looking for great people to join the team. If you're an artist (2D or 3D), programmer (Haskell preferred), musician, voice actor, or game designer - or have other game development skills - send your resume to jobs@ipwnstudios.com. We're based in Boston, but we'll consider telecommuting arrangements when appropriate. in contrast to [id Software](http://en.wikipedia.org/wiki/Id_Software#History), for example: &gt; The company was founded in 1991 by four members of the computer company Softdisk &gt; &gt; ... &gt; &gt; the id Software team began the development of Commander Keen, a Mario-style side-scrolling game for the PC, once again "borrowing" company computers to work on it at odd hours at the lake house at which they lived in Shreveport, Louisiana. I guess the bar is higher today and perhaps making a good game takes more work, though there are still [examples of "one man teams" making successful games](http://www.galcon.com/) out there. 
Is there any value in separating the instancing off into other libs like chp-mtl, chp-transformers, chp-mmtl? These would depend on the general chp library where the existing code lives without the trans instances. So if I wanted to use chp with mtl, I would install and import things from chp and chp-mtl
Do it! Might I also suggest something using Clutter/ ClutterGtk?
you don't have to pull both mtl and transformers (which both provide the same module, you have to explicitly hide one of them to load that module)
Most math graduates haven't heard of monads, unless they specialized in algebra, category theory or the like. I really don't get why people whine so much that Haskell was harder to understand to non-mathematicians than to mathematicians - I have no idea why that should be true. What makes Haskell special is that it is a purely functional language with non-strict semantics and an advanced type system, and a community that exploits those features. So please whine about those aspects, if at all.
I haven't found any sales figures, so yeah, I'm guessing probably tiny.
dph? obsidian? the parallel array packages in ghc already? stream fusion? (Obsidian is particularly interesting, making use of the GPU)
hmatrix binds to a couple of numerical C libraries. I haven't worked with it yet, but it would be my starting point for numerical Haskell code. It fails to match your feature list, though.
I think that it is unfortunate that we need to pull in MTL to get "MonadIO" like functionality. I would really prefer that MonadIO (or something similar) were part of base and was the standard for things like System.IO. I get tired of writing my own lifted versions of these modules.
that's a lot of code:/ how hard was it to write?
Quite likely. I don't pay a whole lot of attention to them, but I glanced at an image of the N900 and it looked like the same form-factor.
I think VoidHPhoenix is right, I was thinking of the n97 instead. I haven't actually seen an N900. But that itself is pretty telling, the fact that I haven't even heard anybody talking about it isn't a very good indication that it's a viable competitor to the iPhone.
Do you really think Steve cares if people cross-compile to the iPhone? All he cares about is killing Flash. This language was clearly designed to let Apple reject Flash apps without actually naming Adobe. Remember, this isn't Apple trying to kill everybody else, this just Steve trying to kill Flash. I wouldn't put it past them to use this against MonoTouch too, simply because Mono is a Microsoft technology, but I would be extremely surprised if they bothered trying to detect any other type of cross-compiling. Another thing that I think is worth mentioning is that my interpretation of this clause (and remember, IANAL) is that only code that links against Apple APIs are required to be originally written in Obj-C. This means that if you do what I've seen various Haskell-on-iPhone tutorials suggest, and use Haskell to write business logic code that doesn't ever touch Cocoa APIs, and then call these exported functions from Obj-C, you should be perfectly fine. The only issue would be if you tried to use something like HOC to call Cocoa APIs from Haskell code.
&gt; The iPhone sucks as well. No background processing is a critical flaw. Is it? I can count on one hand the number of times I've wished I could switch apps without quitting the current one. Of course, I don't use Pandora, and I suspect that app is responsible for 98% of all requests for background processing. Besides, I don't know if you've been paying attention but yesterday Apple announced iPhone OS 4.0, coming this summer, which includes multitasking. And not surprisingly, it's done in a very specific way that's designed to preserve performance/battery life, something that the standard solution of allowing background processing would not. The multitasking in iPhone OS 4 allows for 7 categories of apps that can do background processing (one such category is playing music), as well as an API for allowing your app to be suspended without being unloaded from RAM, which means apps designed to take advantage of this can resume where they left off transparently, as if they had been running in the background, without actually impacting performance/battery life. Just as with copy&amp;paste, I'm glad Apple took the time to do this right. &gt; What exactly is missing from the Android phones. Please mention specifics rather than the vague nonsense we generally hear on these topics. I don't have an Android phone myself, so it's hard to be extremely specific, but every example I've seen of an Android-powered phone has always struck me as having a bad user experience. Hell, Android didn't even ship with multitouch support.
here is a great, "how to write a compiler in haskell" type blog entry. http://augustss.blogspot.com/2009/06/more-llvm-recently-someone-asked-me-on.html it's neat, because it's ... it's the whole thing. It's got a parser, a typechecker, and code generation. Hopefully it'll give you some ideas about inference. You might also check out the Finally tagless paper. it's a really kick ass way to embed a DSL. http://www.cs.rutgers.edu/~ccshan/tagless/jfp.pdf i'm not real sure what your plan is, parse matlab and interpret in haskell? check out parsec. there's a great chapter in RWH. (buy the book! totally worth it) compile to haskell? that finally tagless is one way to go, you might also check out template haskell for... sort of macro expanding out your basic blocks. I don't know much about the matrix calculation stuff. i doubt you'll get faster than gsl/blas/lapack that hmatrix provides, but maybe there is some new hotness i haven't seen yet. Just coding up some stuff from numerical recipes can be fun too.
ahh haskell paper from rutgers... never thought rutgers uses haskell
Just treat the iPhone in the same way hackers treat installing Linux on the SNES or PlayStation. You can tinker, break, and play with the hardware to your heart's content. I'd thought that was the main goal of getting GHC to target ARM processors...
&gt; high performance array ... Automatic vectorisation algorithm Either the (just announced) Repa library for flat arrays, or dph for nested arrays. &gt; automatic parallelisation dph, repa &gt; slice access dph, repa, vector, bytestring &gt; SSE instructions ready none, other than using the LLVM backend to GHC, which can pick up some of this. &gt; no FFI dependency all, other than hmatrix / blas. hmatrix is the best multidimensional lib, with transparent BLAS/LAPACK, but Repa or dph are the future. 
[ccshan](http://www.cs.rutgers.edu/~ccshan/) is super guru famous fun guy in Haskell land.
It's really up to us on how it goes, but there were a lot of really good things about 1.4 that I would like to see implemented. It's going to take some time getting it set up and started, but anyone interested should email me at bheklilr2@gmail.com and we can start setting things up =)
You can see the full client from the paper if you download the software: git clone -o tufts git://ghc.cs.tufts.edu/hoopl/hoopl.git Also, the linked version of the paper is **already obsolete**. Please link to http://www.cs.tufts.edu/~nr/pubs/hoopl.pdf
Does anyone have a sense for the rationale for this? What's the business case?
when you say 'dph', do you mean 'data parallel haskell' in general or there is a specific library that I can use call 'dph'? 
interesting, never realised when I was around New Jersey
I mean `ghc-pkg list` dph-base-0.4.0 dph-par-0.4.0 dph-prim-interface-0.4.0 dph-prim-par-0.4.0 dph-prim-seq-0.4.0 dph-seq-0.4.0 The data parallel Haskell array libraries (which are in beta).
Killing Flash. I wish them success in that, but still.
Ironically, the solution to the floating garbage island in the Pacific will probably be worked out in Haskell! I'll put ten bucks on it, adjusted for inflation. Any takers?
Full relevant quote: &gt; But if Apple were simply trying to block Adobe from cross-compiling Flash to create iPhone apps, it could have added the changed text to its existing license agreement and spoiled Adobe's CS5 party immediately, rather than just threatening change that appears fated to kick in when Apple delivers iPhone 4.0 in June. &gt; &gt; The primary reason for the change, say sources familiar with Apple's plans, is to support sophisticated new multitasking APIs in iPhone 4.0. The system will now be evaluating apps as they run in order to implement smart multitasking. It can't do this if apps are running within a runtime or are cross compiled with a foreign structure that doesn't behave identically to a native C/C++/Obj-C app. &gt; &gt; "[The operating system] can't swap out resources, it can't pause some threads while allowing others to run, it can't selectively notify, etc. Apple needs full access to a properly-compiled app to do the pull off the tricks they are with this new OS," wrote one reader under the name Ktappe. Sounds a bit... *weird*, but would be a cool technology if this is really how it works.
http://daringfireball.net/2010/04/why_apple_changed_section_331 imho comes pretty close to Apple's rationale.
This will sound harsher than I mean it to, so sorry. I don't understand the purpose of your project. To me the biggest problem with Matlab is the language. Some commands behave inconsistently (change their behaviour when a matrix has dimension 1xn for example), the type system is crude, the syntax is ugly etc. (Sorry Matlab). The advantage of Matlab is lots of pre-written maths and graphing functions. You project would seem to allow people to write code in the Matlab language, and translate it to an environment where they don't have the maths and graphing functions available, which seems backwards if anything.
I can't imagine a language *worse* than C for whatever those tricks might be!
In any case, if this were true, it would mean that it is perfectly OK for Adobe to, say, compile Flash into their, let's call it, iC and compile that iC with Apple's iCompiler.
By all means, a music player written in Haskell sounds to me like a neat addition to the community, just thought you should be aware of this remake: http://code.google.com/p/clementine-player/ and here is a rather excited post about it: http://www.omgubuntu.co.uk/2010/04/clementine-ghost-of-amarok-14-in-qt4.html
They don't want cross-platform development. Cross-platform software commoditises the hardware, which is obviously not in Apple's interest. Especially now, as Apple has the upper hand in the breadth and quality of software for iPhone-like devices, it is not in their interest to have quality apps available on, say, Android, too. If developers have to decide between developing for the iPhone or Android, and given that there appears to be more money in going for the iPhone at the moment, it is in Apple's interest to force developers to make that choice.
There are many issues we face with matlab code 1) matlab is getting shower for what we do. but we still have legacy code that we must translate. 2) deploy matlab cross platform is trouble 3) dynamic type is scary for production code my goal is only to translate all the numerical algorithms to various target that we can deploy for client. If this is a valid project, of course I will tries to rewrite all the build in functions that is necessary. Mind you that most of the non-core function are provided via their language in matlab. so my translator would still work in this case. PS: also it is intellectually rewarding to just even think about the problem.
Android has multitouch support. It is a hardware feature, not software. In any case it is the biggest gimmick I've ever seen. It almost never actually makes the job easier, just more exotic. I'm not sure what your understanding of other multiprocessing phones is but Android multiprocessing is very involved and works in a way that doesn't affect the performance of the phone. It is a solved problem. I suspect Apple will have just copied what Android has done from day 1.
hmmm, I might have to use that in the mean time =P As I've said, its more than just having an Amarok clone, it's about learning more programming. I've only been programming for about a year, and mostly in Haskell and Python. This would force me to learn a lot more about GUI making and control, obviously learning about music and sound control in Haskell, learning SQLite for the library functions, and possibly learning some web stuff too. Considering most of my stuff so far has been mathematical in nature (I love projecteuler.net!), I view this as a very positive opportunity for me to better my skills and abilities.
I propose to rename `Haskell 2011` into `C-&gt;` (read "C fun") to make it apparent that Haskell is the black sheep of the C family of languages and can be used on the iPhone.
Since you ask, unsafePerformIO. But a novice and intermediate Haskell developer should basically never use it; if you want it, you probably need to poke a path back to the main IO action represented by "main".
Thanks for the explanation. I can understand your reasoning now. My intuition is that this would be a massive project. I'm just guessing though. It might be possible to mitigate 1) by re-writing the time consuming parts of the code as mex functions. 2) I can see how this would be a problem--you've got the expense of licences to worry about as well. I guess you've evaluated Octave. 3) Yes it is scary, but look at all the production PHP and javascript code. The inconsistent behaviour I mentioned is scary to me too. If you have too much legacy Matlab code to translate by hand, I suppose you are in a difficult position. Whatever you decide to do, good luck.
This is the best summary I've seen yet.
&gt; how hard was it to write? Moderately. Once I mistyped the implementation of one of the functions. I caught that when I was proving a simple lemma. Sometimes I tried to prove lemmas that were false. Sometimes I proved lemmas that were true but too weak. At first I defined extractMin in terms of deleteMin, when it should actually be the other way around. I rewrote the interface using classes and records when I discovered that Coq doesn't like extracting modules to Haskell. I spent some time trying to work around some of the restrictions of Coq's strict positivity requirement before giving up and inlining some data types. Towards the beginning of the project, it took me a while to come up with a way to [characterize how a heap should behave](http://code.google.com/p/priority-queues/source/browse/brodal-okasaki/PQSig.v). This was complicated by the fact that findMin and extractMin need to say that the same element is the heap minimum, even for types where "same element" is not a decidable property.
I don't understand the "no FFI dependency" caveat. I assume for cross-platform reasons? Nonetheless, my (limited) understanding is that there's really nothing better than lapack/blas &amp; co. for high performance matrix calculations at the moment. Maybe one day the array and dph work will let their algorithms be rewritten in a vectorised manner, but until then we're stuck with them. HMatrix is quite nice, but its gpl (if that matters). Meanwhile, the blas bindings are lower-level but offer all the key bits. Both provide smart static dimensions using type-hackery.
cross-platform is the main key why we cannot deploy matlab. Client base uses various chips and OS and matlab is really bad in that area. Also Blas is one problem because it is expensive and hard to convince client to get architecture-tuned blas on their machine aside the fact that all the machine specific support that we might need to give. 
I in particular wish that as many of the standard IO functions as possible where already lifted. Having to use `liftIO` all the time sucks!
I think this article pretty much sums it up: http://arstechnica.com/apple/news/2010/04/apple-takes-aim-at-adobe-or-android.ars
Interesting article, thanks!!
"Hi Steve, heres my new app for the iPhone it was **originally** developed in C but we migrated to Haskell because it's just more awesome." I would love to see someone try to make Haskell to "readable-C" compiler and try to fool appStore into accepting an app written with it. A shortcut to this could be to make ghc output c with random comments and names from a fictional language with a random word generator. If the generator is good enough it might look like Japanese or Chinese, "oh, this must be Japanese or Chinese or somthing..." Or does it have to be in English... 
Blas is expensive? Like, $/€/£ expensive? Netlib Blas is free, Atlas is free, BSD license. Your best bet is to try to link hmatrix with these. You can ship them in your binary. DPH is cool and everything but it's not something you should be shipping to customers just yet (maybe in 6 months or a year.) And for non-Blas functions that you might need you are still (currently) better off using the FFI and writing your own C functions. The FFI is very nice. C functions which simply loop over arrays are as easy to parallelize using OpenMP as anything in Haskell, and you can use SSE intrinsics to ensure that things are vectorized, rather than crossing your fingers and relying on the compiler. DPH will be awesome when it hits 1.0, but even then there will still be some lag time before the rest of the HPC/numeric ecosystem crystalizes around it. If you're planning to deliver this code within the next year I would recommend to relax your constraint against the FFI. (Oh wait, I just realized hmatrix is GPL. scratch that. You will be able to give your client all the source?)
Obviously we need to start charging for GHC.
&gt; Android has multitouch support. It is a hardware feature, not software. Exactly. The OS as shipped has zero support. The underlying event model is there, but the OS does not make use of it. &gt; In any case it is the biggest gimmick I've ever seen. It almost never actually makes the job easier, just more exotic. You're kidding, right? Multitouch is a completely different user interaction metaphor than mouse&amp;keyboard, but that doesn't mean it's a gimmick. Most apps I use on a daily basis on my iPhone or iPad are significantly enhanced with multitouch, and some wouldn't even function without the multitouch interface metaphor. Not only does it lend itself extremely well to many tasks, but multitouch is a lot more intuitive than a mouse/keyboard combination as well. Give a 2-year-old a traditional PC, they won't have any clue what to do. [Give a 2-year-old an iPad](http://www.youtube.com/watch?v=pT4EbM7dCMs) and they'll be using it like a pro in no time. &gt; I'm not sure what your understanding of other multiprocessing phones is but Android multiprocessing is very involved and works in a way that doesn't affect the performance of the phone. Can you explain Android's multiprocessing model? I haven't heard anybody say anything about it besides that it has multiprocessing.
Easy, comrade! Just trying to add to the pool of your information, not to discourage you! Doing something for the hell of it, for the learning experience, is how many cool projects got started :) Also, projecteuler was lots of fun, I should get back into that, I'm probably 100 problems behind at this point...
code.google.com/**p/lastik/** Ooooh, shades of libiberty...
Nice, this looks like it has a lot of potential. A few comments: * I would like to see more details about how the Lastik workflow compares to Ant and other build tools, beyond the Haskell syntax. Perhaps a link to a wiki would be a good start. * You wrote "The programming language has the most comprehensive library of any programming language available...". Um, I think Hackage is fantastic, but that claim is way over the top. You may lose quite a few potential users if they see an exaggerated claim like that on your front page.
On point 2: fixed accordingly
here's what I like about java and haskell - you put files in the right dirs (mirroring module/package structure) and it just works, without any build scripts (ghc/eclipse).
OK, is this what you are trying to say: that anything in Hackage can be made available directly to a Lastik build script, whereas in Ant you need to call an external Java program to access anything outside of Ant's own libraries? In traditional build scripting, calling external programs is not considered a limitation. Build scripts have a "shell script" feel to them, where you consider any command that can be run from the shell prompt to be effectively part of your scripting language. In Ant, the role of the shell prompt is replaced by Java. Your approach seems to be that there is an advantage to having the facilities of a full-blown programming language right inside the build language without having to invoke external programs. That is interesting; I wonder if it is true. Build tools are very down-to-earth practical things. You just want to get your project to build with the minimum investment of time and effort. So the proof of the pudding is in the eating - what does the Lastik workflow feel like in practice, and how does it compare to other tools?
Upvote for "No piss-farting around."
The Haskell base libraries are much more comprehensive than the core Java libraries. However, you also don't have all of the Java libraries available to you when you use ant, unless you go to extraordinary effort (have you ever tried writing an ant plugin?). I'm not trying to say it, but I will. Apache Ant attempts to be a programming language with functional features (notice that you can change the order of targets without affecting program outcome). It does an incredibly sloppy job at it. Ultimately, I am not trying to better than Apache Ant. That's shooting too low and I don't think it is a particularly virtuous goal. However, in the unfortunate event that I am asked to use Java as if it were practical, at least I don't also incur the penalty of inferior build tools. I just want a practical tool for building Java libraries. Nothing more.
That's true to a certain extent, so it's a good default for simple cases. But sometimes that convention just has the effect of pushing complexity into your source control tool, which isn't always the right place for it. Also, it is a bit of a wart that path names and directory structure information have to be duplicated in the syntax of your programming language. For some projects, I would prefer to be able to override that default and specify manually where to find my modules. Then the build manifest lives exclusively in the build system where it belongs. 
I would not use software written by people who wrote a page like that. Not by choice, anyway.
Can it call Ant Tasks? Gradle isn't bad either.
Yeah, but there are BILLIONS out there that do anything you need to do in a ant build. So unless you can call a ant task, its not very useful, because you can't reuse anything that already exists.
I have a tshirt from a project back in college that reads "I am a graduate of the printf school of debugging." I assume this use is discouraged? 
Well, be sure you know how to use the GHCi debugger. I found the [the Monad Reader Issue 10](http://www.haskell.org/sitewiki/images/0/0a/TMR-Issue10.pdf) discussion the most useful. But for when you don't want that, check out Debug.Trace. It is less useful than in other languages due to laziness, but it is not useless. And I find it a helpful way to see the laziness manifest, too. (It was a bit of a shock the first time I saw my trace appear in the _middle_ of the output of my Show instance.) It isn't that you should never use anything that uses unsafePerformIO; conceptually `main` itself uses unsafePerformIO. (I haven't checked, for all I know it literally uses it.) Just don't use it yourself; all the obvious uses have been wrapped up for you already. And some not-obvious ones.
No, the real power of a build system is being able to specify precisely steps that *aren't* compilation (e.g. building docs). But not many people need to do that, especially with Haskell, given that most build instructions can be put in pragmas when using GHC, or left to cabal's defaults.
There are a lot of uses for that feature that aren't directly related to the programming language you use, e.g. translating a human-readable translation file format into a binary one, copying additional files into OS X Bundles, running coding style or other static analysis tools,... Most Haskell projects just don't use those because most Haskell projects are relatively small.
A "matlab replacement" is a very large project. You really need to gauge the scope and support before attempting that. Does your client need to support legacy code only, or is there ongoing development in matlab? If it is the first case, you may be able to rewrite the parts of matlab that are actually used, ignoring the rest. If the second case, then an EDSL might be the answer, but only if you really need limited capabilities. Overtime projects like dph and repa should make the algorthmic side of things very attractive to code in haskell or an EDSL. 
This seems very similar to the MonadRandom package on hackage.
And "generators" is an incredibly generic name for such a specific task. :-(
&gt; have you ever tried writing an ant plugin? Yes. One even lately. &gt; However, in the unfortunate event that I am asked to use Java as if it were practical, at least I don't also incur the penalty of inferior build tools. I would say (from experience) that build tool is probably the least of your concerns when you are writing and cursing Java. I've even learned to not notice half-minute build times, that are so common in bigger Java projects. Waiting for the shit to build is much nicer than writing it. ;)
I agree with you. It will always be the case that we are going to use matlab(or numpy/scipy) for model prototyping and there is nothing that will replace that workflow. Their syntax are well understood by people in the group. so translator is very useful 
When I hear "generators" I think [the technique](http://en.wikipedia.org/wiki/Generator_%28computer_science%29) that adds in some lazy evaluation like code to eager languages.
I think there are many concerns when using Java, and this is a big one. I don't use Java voluntarily; or any impractical tools for that matter.
Thankfully, all those things are also available to you without ant.
Like what?
Childish, petty, insulting, and ignorant.
Can you provide an example of at least one of those?
That's cool. I've been toying around with SDL in Haskell a lot this month. This should help me.
It's not, in fact it's quite different. MonadRandom basically lets you write randomized computations with a random number generator subsumed into the backdrop of the monad, whereas generators is a little bit more than that. MonadRandom proceeds essentially like the identity monad except there is a random generator available. Generator proceeds like a *list* monad except there is a random generator available and the lists are not merely concatenated but merged.
Upvoted for passionate hatred of C++ :)
i'd rather use rake; there's too much haskell syntax (and semantics! why should i write `Just "1.5"` in a makefile? i would expect the dsl compiler to figure it out) leaking into lastik.
Thinking about it, the conspiracy theories rampant in blogspace are probably an exaggeration. Apple reviews the source code of each app submitted as part of the approval process, so they need the source code to be written in a human-readable way in a programming language and development environment that their engineers completely understand. Of course, there is no love lost for Adobe and for cross-platform development tools. Even if Apple doesn't go out of their way to try to kill them, they certainly won't spend money to actively support them.
Great job. What it would be even better is maybe transforming this to literate haskell with explantions, so that it can be used for learning SDL without referring to the original LazyFoo tutorial series.
Yes I've been thinking about it, I think first I'm going to cabalize this and put it up on hackage and then I might make a branch for literate versions. However now I really feel like starting on some new projects in Haskell (all related).
I hope you find it useful, let me know if there is something that doesn't make sense.
no piss-farting around? A "full-featured" programming language? As opposed to...? You clearly despise Java - why would I use a tool to build Java written by someone who hates the language? Why would you write it? So you can get your hate on better? 
w/r/t getting additional explanations in, are you willing to accept patches? (also, posted this to /r/programming to hit a wider audience. because it's that cool.)
It might make sense to also create lazyfoo-sdl-lib package that will contains useful utility functions from tutorials.
Sure, if someone finds a problem or wants to give/suggest improvements send me message on github.
Ant is not a full-featured language. It is not turing complete. The libraries of Java are not as comprehensive. I do not despise Java and I project no emotion toward it whatsoever. I happen to know a bit more about it than most other people. What you are exhibiting is called a projection bias. If you were to say these words, then you'd have this ulterior motive. You are unable to comprehend the possibility that something other than this is occurring. I think the shoe is on the other foot.
&gt;It uses a full-featured programming language As does Ant. &gt;The libraries of Java are not as comprehensive. As what? How are you defining "comprehensive" and how are you defining "the libraries of Java" &gt;I do not despise Java and I project no emotion toward it whatsoever. * "Piss-farting"? * "in the unfortunate event that I am asked to use Java as if it were practical..." * "I don't use Java voluntarily; or any impractical tools for that matter." &gt;Ant is not a full-featured language. It is not turing complete. There is no end to your stupidity is there? 
A very well explained solution; even a Cryptol newbie like myself could follow along with and understand the logic behind the code.
Bye.
&gt; so they need the source code to be written in a human-readable way in a programming language and development environment that their engineers completely understand. But I thought C++ was one of the allowed languages?
This appears to be from April of last year, and it showed up on planet haskell due to some sort of rss feed bug. Nonetheless an interesting article, though it seems there was a followup which has since been taken down.
AFAIK, Apple does not review the source code. They do check for private API calls on the final executable, though. Do you have any links describing the source review process?
Are you running Yi using the terminal graphics mode or the Gtk/Pango graphics mode?
A very nice resource for using Haskell's SDL bindings! Thanks. But, if I may editorialize a little bit, the reason this is so useful--in fact, that "porting" is possible at all--is that the SDL bindings are a shallow wrapper around SDL's C API, in all its imperative, impure glory. Even PyGame, another shallow SDL wrapper, adds more functionality than these, and that's in a language with much less culture shock vs. C. One of the things on my Haskell TODO list has been to see if I can munge SDL into a more functional interface--perhaps bolting it onto one of Conal Elliott's FRP experiments, but even a less IO-heavy library would be nice. I'm glad to see interest in SDL from the Haskell community--maybe this will motivate someone into doing what I haven't gotten around to yet?
I find it quite interesting that Cryptol has baked in a notion of finite (data) as opposed infinite (codata) structures.
If they don't yet, I would interpret this change to mean that they plan to. It fits their model of how the App Store works. And it makes a lot more business sense than the paranoia of the blogs.
Basically all android applications have to be designed so they can be killed and restarted at all moment. When the machine really needs the resources it just uses these mechanisms to give the appearance that they are still running. It still does multiprocessing but in a way that allows the phone to safely shut down applications when something vital comes up.
&gt; As opposed to... XML, presumably.
Reading http://www.devwhy.com/blog/2010/4/12/its-all-about-the-framework.html , it seems to me that it doesn't have anything to do with the developers themselves. Rather, the situation is similar to the [MacBasic](http://www.folklore.org/StoryView.py?project=Macintosh&amp;story=MacBasic.txt) precedent. The good news is that Apple has no reason to reject apps written in Haskell except for the precedent it would set if found out.
In other words, you can use Pandora in the background, but you'd better be prepared to have it stop playing music at an arbitrary time if you use up too many system resources with other apps?
There are ways to tell the VM that a particular app should be shut down last. Regardless music should go off if a vital function like an incoming call needs to run.
I was thinking the same thing. I was going to wait until my game was more functional and mature -- and I was better and more comfortable with Haskell and monads. As it is right now, it is almost a straight port.
&gt;Note: I intend to write the first version of the game without any use of monads, if at all possible, other than the basics like IO, Maybe, and []. You can already see where a monadic pattern is showing up with UIState and eventLoop. I’m avoiding it on purpose and will convert things over to monads at the end of the series. Why would you want to avoid state monads? I think eventually you will have some complex state transformations and all that boiler-plate explicit plumbing is going to look ugly. This is what state monads are for, they abstract out explicit plumbing boiler-plate code, there is nothing impure about them. You can keep your code generic by using type-classess like MonadState (used with flexible contexts) instead of hard-coding a particular state monad (or monad transformer stack) into your function types. You can keep your ADTs/modules pure and isolate state transformations. I just don't see the point of avoiding a good abstraction. As your game gets more complicated eventually you're going to have to deal with multiple game states (I mean intro, levels, paused,ending,etc) with global counters and stuff like that. When it comes to gameplay/logic this part of a game is heavily stateful. In which case unless you're doing FRP you probably want to use IORef/STRef/MVar/TVar for this in the end. I'm not saying that all parts of a game is heavily stateful but there is definitely a layer/part that is unavoidable. On an unrelated note, I'd suggest not putting so many functions into your main function's *where* part. It looks all cluttered.
For sure. I could have already built up a StateT transformer for my event loop and have it clean up some code. I did the research and started writing the code, actually. But I scrapped it for now because I wanted to do something different with this game. My intention is to get far along in the game and say, "See! All of this is done without the big scary monads you hear about!" And then show how monads clean up the code and are not that hard at all. By waiting I want to build up a bigger code base to sweep through. I just put the notice at the start of the post to alert the knowledgeable reader that this is in the pipeline, just not quite yet, because it's already apparent where they could be used. I remember that, when I was getting started learning Haskell, this was something I wanted. Something a C programmer could dig into that was practical, not as contrived, a little familiar and not too complex. Edit: Yea, I was going to rip it out the eventLoop and make it a top level function, but I forgot to. That'll be in part 4. Part 3 will be profiling.
Are you planning to publish the result?
I am not sure it's novel enough by itself for an academic paper. Perhaps the proof is interesting enough for a proof pearl or as an experience report. If the data structure can be extended to support other operations it might be of sufficient novelty to warrant publication.
The problem is that Haskell, for all its claims to purity, is not pure. Idealistically, people would use Maybe or (Error e) in all those places instead of using error or undefined. But that introduces problems of code complexity. Even more idealistically we'd have enough dependent typing to be able to discharge the possibilities of errors when we can prove they can't occur, but that's even more code complexity. Alas, that's not how Haskell works. People don't always want to deal with the burden of correctly annotating possible errors or proving their absence. And for good reason! Just look at Java's checked-exceptions, or at the usability problems of dependently typed languages. We must play the hand we're dealt: Haskell semantics allow \_|\_ and require functions to be monotonic. IMHO, lumping exceptions in with \_|\_ is a gross hack since exceptions are, definitionally, distinguishable from non-termination. In the terms of Haskell's semantics, spoon is using the same hack. (Though it's a nice hack to have on hand, in order to combat the hack of folks using \_|\_ instead of a proper error monad! :)
*Edit*: Redacted my previous comment, it was based on a flat-out wrong source.
Considering how often people encounter errors about taking the head of the empty list (i.e., that they encounter it at all), obviously people aren't verifying the simple precondition. The longer I spend coding Haskell the more firmly I believe that head, tail, and similar partial functions are simply bad form and should be eliminated from the language (i.e., the Prelude and language spec). They're holdovers from Lisp and ML, but not ones we should be emulating, IMO.
Yes, but fail does not belong in Monad, and should be scorned until such a time as it is moved into its own MonadFail class.
Fair enough well I'm not saying it's impossible [super nario bros](http://github.com/mokehehe/monao) (mario clone) does this. I've only seen just one use of IORef there and it's not used for game object/global states, it does everything by explicit plumbing/passing but sometimes it's not pretty. Personally I would have wrote one article explaining the various ways to deal with stateful computations before proceeding. Anyways don't let what I wrote put you off! mapAccumL/R and foldM are your friends.
I could just be wallowing in ignorance, but it seems to me that State monads aren't worth it (except maybe in the case of generating random values). I will be looking forward to seeing if you can convince me that they reduce boilerplate while not reducing the transparency and clarity.
Who are you responding too? I'm going to assume me. &gt; but it seems to me that State monads aren't worth it (except maybe in the case of generating random values). I will be looking forward to seeing if you can convince me that they reduce boilerplate while not reducing the transparency and clarity. Then I don't think you really understand state monads and how much stateful computations are involved in fully complete games. So you want me to convince you? how about you take [my code](http://github.com/snkkid/LazyFooHaskell/tree/master/lesson28) (which is a port of [this](http://lazyfoo.net/SDL_tutorials/lesson28/index.php) and not nearly as complex as a fully complete game, even a simple one) make a version without using monads (or IORef/STRef/MVar/TVars) replaced with explicit state plumbing then convince me instead.
cool, thanks. I'll have to take a look at that when I have more time.
The state monad is all of [ten lines long](http://www.haskell.org/all_about_monads/html/statemonad.html#definition) or so, most of them _very_ simple. If you so much as pass a state value between four or five functions, you've officially lost on the code complexity front if you're doing it manually. There's nothing special about the state monad, nothing magical. It's an abstraction of what you're doing anyhow. It's easy to get the idea that &lt;font name="GloriouslyCursive"&gt;The State Monad&lt;/font&gt; is some sort of awesome, inspiring thing that takes oodles and oodles of code to implement and you're somehow better off if you don't use it, but it's not. It's drop-dead simple, it has virtually no "meaning" of its own. It is not impure, it isn't cheating, it's not pulling in a 5MB library. _Not_ using it when it is called for is the bad idea.
Is there any chance of getting these on a web server with a standard port number? My work firewall won't let me see it.
data-accessor also has some incredibly good combinators for the state monad. A state monad operation on a field of a record can be lifted to operated on the entire record. Also data-accessor can be used for more than just records, but indexes into arrays or maps as well. Also data-accessor can be used to access "virtual" fields of a records, so if you have a record for standard cartesian represenation complex number you can still have accessors for the "angle" and "magnitude" fields of the complex number type. [data-accessors can often replace pointers in OO problems](http://www.reddit.com/r/haskell/comments/b87sc/how_do_you_manage_an_object_graph_in_haskell/c0lgw3o). There is probably more that I haven't thought of.
try a web proxy, or google cache
Not haskell
I thought this post should be of interest to the Haskell community because, while the article doesn't talk about Haskell directly, quite a bit of what the author (deliberately-provocatively) frames as "the Ponzi scheme approach" to language popularization is occurring in Haskell-advocating circles.
I only skimmed it, but I would suspect that what he's complaining about is that the power and control of core contributers and evangelists increases rather quickly as the language adoption grows in size. But this isn't unique to programming languages. Economists have noticed these patterns in other areas of society, namely allocation of wealth, company sizes, etc.. Some people have shown that the internet graph has a similar distribution in terms of connectedness.. They tend to have the same distribution with popular individuals and companies being way more than the rest combined. I think they're called Log normal distributions or Pareto distributions.. not sure. I don't think this is a problem related to technology.. just to human social networks and the way trust and referrals spread to very well connected individuals vs very talented individuals. Or I could be completely wrong. This is just a hunch I have based on reading a lot of economics essays that I don't understand in complete detail. I'd love for a commenter to point out flaws in my logic.
Oh, Zed Shaw. It's (kind of) like calling coal mining a ponzi scheme because gasoline comes along and destroys it. But people still mine coal, and still write code in C++. But I would like to see this kind of discussion more often, and ask the question, "How do we build a community for Haskell?"
Good call. Proxies are blocked but Google Cache works, just about.
I do enjoy Zed's contributions. Always good fun.
&gt; How do we build a community for Haskell? We've been doing fairly well at this, even though the size of the community has been growing fairly quickly. Of course there are many aspects, such as keeping haskell-cafe sensible. One I think is particularly important is keeping the three pillars of the community talking to each other, the pillars being: * the academic community; * the open source community; * and the commercial community. Each have slightly different goals but they can all benefit each other while at the same time benefiting themselves. So how do we keep these communities helping each other? I think it is mostly a matter of keeping them communicating and using mostly the same tools. That means using the same forums (mailing lists etc) and arranging conferences together (ICFP, CUFP, Hackathons). Sharing tools is also important, as I argued in [my CUFP talk last year](http://blog.well-typed.com/2009/09/slides-from-the-ihg-talk-at-cufp/). It allows us to directly benefit each other, rather than just sharing ideas.
I actually agree with you, for the most part. The finale of part 2 was going to be the switch to state monad to handle the event loop. But now it's like the [Seinfeld episode](http://www.youtube.com/watch?v=TuEdU_lrtZk&amp;feature=player_embedded) where Kramer keeps driving the car on 'E'. I want to see how far I can go before I cave. Actually, I'm just looking to convert a few sections at a time. Right now the gain will be minimal.
&gt;Programming languages are nothing more than a ponzi scheme. worst analogy ever, and I have read a lot of monad tutorials.
Unfortunately my ISP blocks incoming port 80 so I use a DNS forward and port 6780 to get around it. Would 8080 have worked? I was using a VPS server because I had a great deal on it, but dropped it to save money about 6 months ago. T_T
Is there a good point-by-point comparison of `data-accessor`, `fclabels`, and `lenses`? I've done several projects where something like this would be incredibly useful, but I'm nervous about committing to one of the three packages when all three seem to be in use.
There are some places where I see something *somewhat* similar to this happening within the Haskell community. I think this is the wrong diagnosis though. The problem isn't the people advocating a library or approach, promoting an idea, etc. They are trying something, getting excited about it, trying to make it work in as many places and ways as they can... this is all great! The problem, to the extent that there is one, comes from the celebrity aspect of it all. Especially in the Haskell community, it's too easy to forget that a lot of these "big ideas" are basically the thoughts of one person. Maybe two. A half-dozen at most! These are smart people, but they aren't always right, and they don't always know today what they'll find worth supporting 5 years from now. If there's anything the Haskell community should learn from this, it's to *support* people in trying new ideas... but just be realistic about the level of committment that exists.
I think that would be a very useful thing.
I could do a follow-up comparison of syntax; it might take a little bit more digging to figure out whether or not there are fundamental problems with any of the three that would require a rewrite.
first of all not directly linked to Haskell, secondly I think the correct comparison should be [pyramid scheme](http://en.wikipedia.org/wiki/Pyramid_scheme), not [Ponzi scheme](http://en.wikipedia.org/wiki/Ponzi_scheme). However I find the comparison with one of these schemes fundamentally flawed in many ways. For instance: the schemes are bound to collapse at some point, but there is no guarantee that a programming language will loose popularity, and I don't think "investing" in a language, that later becomes unpopular, is "money lost." 
The unofficial motto of Haskell is "avoid success at all costs"
OK. I am starting to get the picture. I am very familiar with the idea of numpy/scipy as a matlab replacement. The big advantage I see (matlab experts can correct me) is that an alternative language like python or haskell offers easier foreign library integration. For my thesis I used some bindings to TAO/Petsc that would allow access to optimization routines that could also handle sparse parallel vector-matrix calculations through python. If haskell libraries like hmatrix were then built on top of native haskell libraries that support parallel calculations (dph and repa perhaps) then many users would get over their syntax inertia hump and use it in straight haskell. The existence of hmatrix might also provide some comfort to those users making the transition. It would also help if the language eliminated scary little omissions from floating point support. (I would like to write x == Infinity, not x ==1/0 .) Obviously there are further advantages to haskell, such as static typing, and there have been some ingenious proposals on how to use it to make more matrix-vector using programs correct. However, I don't see those lighting up the eyes of the average matlab user right away. 
Does this guy know what "ponzi scheme" is ? Or is he just spewing bullshit like those teabaggers who shout "nazi" and "communist" in one sentence ? 
There's a commercial community behind Haskell??? All seriousness aside (because the above wasn't a joke), Haskell does a great job at growing their community. Despite the esoteric nature and their vertical learning curve of the language, they still manage to net just about everyone who's heard of lambda calculus.
Version 0.0.0.0? Isn't that just an empty darcs repo?
Thanks for advertising this new feature Brent! And thanks for implementing it in the first place :-). As Brent says, give it a try and let him know of any bugs or feature requests.
First bug/feature-request I've noticed: we should not offer BSD4 as a license option. It's just confusing to offer it. The only package on hackage I know of that ever used BSD4 did so by accident :-) **Edit:** Fixed! I've removed BSD4 from the list of suggested licenses in the Cabal library (which is where cabal init was getting its list from).
While the post doesn't mention Haskell, it does have direct relevance. In particular, many of the major theoreticians in Haskell have since moved on to Agda (and to a lesser extent, Epigram). In general, folks who get hooked on Haskell's ideology of purity and correctness soon become interested in dependently typed programming. Whether this can be called a ponzi or pyramid scheme? &lt;shrug&gt; But many have commented about the Agda mailing list "stealing" all the deep discussions on type theory which used to occur on the Haskell-Cafe mailing list. And HC has since been languishing in search of a new grounding now that the theoreticians and elders no longer post so often.
You wouldn't by chance have this working in Windows, would you? 
&gt; I think they're called Log normal distributions or Pareto distributions.. not sure. Usually [scale-free networks](http://en.wikipedia.org/wiki/Scale-free_network) (as they're called) follow a Zipfian distribution (i.e., a [power law](http://en.wikipedia.org/wiki/Power_law))
Not yet, I've been using fedora in a VM since Haskell is better supported on linux (although it's much better than it use to be). I tried on windows recently but I had problems building haskell SDL-image package and I didn't spend any effort at the time to get it working but I did see there is a work around. What's the problem?
Quite interesting, but the prospect of having to enter through so many items looks like it would get quite tedious. I'd prefer to use something like Mr. Bones, a Ruby tool for generating gem project skeletons. You give it a name and it applies it in a few reasonable places, but leaves it to you to edi the generated files to clean up the FIXMEs. You can alter the default template, though, so that you always get the license, E-mail, author, etc you want in place of most of the FIXMEs. In any event, nice work.
&gt; the prospect of having to enter through so many items looks like it would get quite tedious. cabal init --non-interactive That will use all the defaults and heuristics/guesses. You can then edit the generated .cabal file. &gt; I'd prefer to use something like Mr. Bones, a Ruby tool for generating gem project skeletons. You give it a name and it applies it in a few reasonable places, but leaves it to you to edit the generated files to clean up the FIXMEs. Sounds like that would be equivalent to cabal init -n -p mypackage There are a number of flags (like `-p` / `--package-name`) to set specific options. They're useful if you're using the non-interactive mode (`-n`/`--non-interactive`).
Ah, nice. I just ran "cabal init" and took it at face value. I'll have to play with this some more. Thanks!
Lovely to see this coming out of its `mkcabal` roots - well done Brent and Benedikt!
I'm not sure you should find this too surprising, tho. Not to seem too much like a boy with a hammer, but once you start figuring that the language design is done, you lose the people who are interested in languages. That's a recent transition for Haskell.
Oh it's not surprising. I'm just saying that it's the same pattern for Haskell as for the languages mentioned in the link, and therefore relevant to /r/haskell. That "1/2 of the C++ standards committee left C++ for Java" is just as you say. The design of C++ was basically done by that point, and so the language designers left for another language needing design work. Once Haskell's type theory is pretty well understood, the type theorists will move on to uncharted waters. Same thing. Language designers and theorists go about programming in a very different way than coders and hackers. Theorists will always go where there are things to theorize about; whereas coders will go where there's code to work on. This has the side effect that theorists will be "flighty" in their language preferences whereas coders will be "hidebound" and reluctant to switch. The author is apparently more of a coder and is offended by the fact that the theorists are so capricious with their influence over his language of choice.
Okay I've managed to get all SDL bindings needed to work on windows now following [this](http://www.mail-archive.com/haskell-cafe@haskell.org/msg44816.html).
I think the main problem with Haskell today for use in more projects and commercially important projects is the stability of certain core libraries. Just the other day I tried to build a little bookmarking tool in Haskell again and tried to find a persistence library (database or similar, wasn't really picky) that worked but none of the available ones, HSQL, HaskellDB,... did compile. That kind of thing just shouldn't happen, not for something as essential to most programs as persistence.
Awesome! We should get the word out about this more, especially for folks new to haskell and learning to prepare their first packages. Learning the language and learning a new build/packaging system at once can be sort of a steep curve, and this really streamlines it.
I think that's not really true. There's no hard and fast line between working on dependently typed languages and working on Haskell. There's still strong and significant work being done on Haskell, including w/r/t the type system. Work on dependently typed languages informs development in Haskell as much as the other way around, and since for the moment general-purpose dependently typed program remains a far off goal, Haskell is the host language for these projects, and the folks working on these projects continue to push to find new ways to expand the expressive capacity of Haskell (e.g. McBride's `she`). And -cafe is an interesting, but noisy and somewhat frustrating place. But that's an expression of a growing Haskell community, not the opposite.
I tried for quite some time to get something working last night but failed. I couldn't get past installing the SDL bindings. Errors with duuplicate main's I believe. I'll give it a shot again tonight with a fresh install of WIndows. I think all my playing around with msysgit, msys, mingw and cygwin, as well as the mingw in Haskell Platform 2010.1 RC might have caused some problems. Thanks for the link.
Which bindings SDL or SDL-image/ttf? Where is sdl-config installed? make sure configure step is not picking up a version that is in the mingw's bin folder (if it is just temporarily rename the one in mingw/bin). Just extract the SDL dev files (I don't mean the haskell bindings) in the *"Haskell Platform\2009.2.0.1"* folder as is. Like said before if this is SDL-image/ttf bindings failing follow the link I posted earlier using cabal with downloaded package and not cabal install.
SDL bindings, not SDL-image. I was copying things into my msys/1.0 folder and trying to build from the msys shell.
You probably know this but if you don't want to put SDL in the standard paths you have to say where there are (-I and -L for gcc) via cabal file. Usually you just extract them over the root of MinGW since the SDL lib archive mirrors the directory structure but Haskell Platform comes with it's own build of gcc so extract the archive into where gcc.exe in the Haskell Platform directory is (for me it's in *"Haskell Platform\2009.2.0.2*) and make sure configure doesn't pick up a copy of *sdl-config * that is in MinGW directory make sure it picks up the one in the haskell platform directory (should be the *bin* folder).
just copy comments from above the function declarations in the haskell version. This could totally work...
&gt;The author is apparently more of a coder and is offended by the fact that the theorists are so capricious with their influence over his language of choice. I don't think that's fair to the author. C and C++ were not developed by programming languages researchers, nor were Ruby and Python. The only language he mentions who had someone with a PL background anywhere near its design is Java.
&gt; I don't think that's fair to the author. His complaint is that people (in particular, people on language design committees) keep moving onto the next language, leaving those who maintain works in older languages in a lurch. I think it's fair to say that this is a concern with maintaining code, exacerbated by those with theoretical concerns not sticking around forever. I make no value judgements when I say "coders" or "theorists". I've worked on both sides of the fence, and both sides have accused me of belonging to the other camp. Personally, I think trying to turn descriptive distinctions into normative ones is damaging to everyone involved.
I think you've misinterpreted what I was saying. I never claimed that work on Haskell was dead nor that the Haskell community was shrinking. Far from it! What I said is that many who had taken Haskell as their primary target of research have since moved on to other languages. Phil Wadler works more on Java, XML, and Links these days. The Agda community is putting their efforts into Agda. Certainly these people still maintain close ties to Haskell, and certainly they're willing to communicate ideas in both directions between Haskell and whatever other language. But Haskell isn't their primary target. This is the same sort of thing that always happens to successful research languages. The ML community also turned to work on different ML-like languages, e.g. OCaml and Dependent ML. That Agda and Curry and others use Haskell as the base language to extend, if anything, speaks very highly of the liveliness and stability of Haskell as a platform to work from. But that doesn't mean they're working on the platform itself.
&gt; SPJ works more on Java these days. By "SPJ", do you mean Simon Peyton Jones or someone else with the same initials?
It's first-class. If you don't like having to apply the Just function, simply write a combinator that does exactly that.
I typed [haskell import] into google and the first hit looks like it covers it. http://www.haskell.org/haskellwiki/Import
Log on to irc.freenode.net channel #haskell. There's people there all the time and they're all really friendly and eager to help out beginners.
From your question it's hard to tell what exactly you're having problems with. I suggest you read [How To Ask Questions the Smart Way](http://www.catb.org/~esr/faqs/smart-questions.html), which is geared specifically towards computer-related questions, as this will help you get the information you require faster in future.
I don't suppose we could have the AGPL added? :)
Perhaps you tried at a bad time of day when lots of people were away from the keyboard, or perhaps people missed your question because they were so focused on an existing discussion. It happens sometimes.
*sigh*. You still aren't very good at asking questions. Read the link I provided. Seriously!
Importing is as easy as import *module_name* at the top of your program. For example, module Main where import Data.Char would import the Data.Char module into your program. You mention being new to linux, but what does this have to do with it? You may need to install the Happy and parsec libraries, in which case you should specify your distro, and also look into cabal install and probably the haskell platform. Also, following greenrd's link will help avoid confusion, because you can help narrow in on your precise problems.
I forgot to mention 2 more things, cabal file for SDL is not configured to look into the header directory /*&lt;default-include-path&gt;*/SDL and also make you sure you rename any *library-name*.lib files to lib*library-name*.a EDIT: it appears you need all the lib*filename*.a library files should go into the directory /&lt;-your-path-&gt;/Haskell Platform/2009.2.0.*/gcc-lib so it seems I also had files all over the place the first time I had it.
 this Gist brought to you by GitHub
http://tunes.org/~nef/logs/haskell/10.04.17 I asked about this on #haskell, so check the logs for more discussion. Among other things, edwardk mentioned that there's a pointed functor between functor and applicative, and tried to give some concrete examples that are seen in common day to day. snips: patch-tag: So Map Int could be a nice example of functor but not a monad (and edk agreed) &lt;edwardk&gt; http://hackage.haskell.org/packages/archive/monoids/0.1.36/doc/html/Data-Monoid-Lexical-SourcePosition.html is pointed, but not applicative and various other things were discussed, most way over my head :) 
Are you trying to use haskell interactively, as with ghci or hugs, or are you making a .hs file and compiling it? If you're using debian or ubuntu, what are the names of all the packages you installed?
the prelude is the standard module that automatically gets imported, you are not writing in the prelude.
I'm guessing you found that here: http://research.microsoft.com/en-us/um/people/daan/download/parsec/parsec.html That's aimed at windows users. "c:\parsec" is a windows path. On linux, paths use / as a separator, and they start with /, not a drive letter. Do you have the parsec and happy packages installed? If so, I believe ghc should be able to find them already. For compilation, I recommend using --make. It'll find your dependencies for you. ghc -o sam --make sample.hs Here is the documentation for the version of GHC you're using: http://www.haskell.org/ghc/docs/6.8.2/html/ If you have any more issues or questions, do like you did in your post above, and paste the full text of the error message. Good luck.
A common, plain-text editable, machine parseable file format would be great.
&gt; SPJ works more on Java these days. I think you're mistaken... Perhaps you meant Wadler, who did spend some time this decade looking at Java Generics.
HDBC is by far the [most popular database](http://www.galois.com/~dons/hackage/april-2010/popularity.csv), measured in cabal-install's. Did you try it?
Ah yes, slip of the brain there.
Indeed, though I'd meant to say Phil Wadler. [Simon's work](http://research.microsoft.com/en-us/people/simonpj/#current) is still rather Haskell-centric.
yes, the prelude (which you can't change and comes a standard library packaged with your compiler) automatically gets imported, but, unless you are reusing function names from the prelude, you shouldn't have to worry about it; i think if one of your libraries tries to redefine a function from the prelude, it will produce an error. However, if you want to keep the functions from the prelude from filling up the name space, then you could do one of two things: prefix prelude functions by explicitly importing the prelude qualified, or explicitly import the prelude hiding certain functions; you would do this like so 1) import qualified Prelude as P 2) import Prelude hiding (map) -- might need to check this syntax
I finally got all of the puzzle pieces to fit together and work. The libFILENAME.a helped me out of my last hurdle. Thanks.
Well, isn't that part of what you're trying to figure out, whether or not happy and parsec work the same way and what the differences are if there are any?
Maybe you know something I don't, but I don't know what new research Phil has done with Java in the past nine years.
Yes, same thing, doesn't compile either, some kind of error about UTF8 Bytestrings and other Bytestrings. Bytestring seems to be a bit of a clusterfuck, it has been responsible for about half the Haskell compile failures in the last year or two on my machine (despite clean reinstall in the middle of that period in case you were wondering about that).
Yes, it’s possible to divide these classes further (e.g. the monoidal stuff can be divided into a zero element and an associative combination, like ArrowZero and ArrowPlus). In practice, however, there aren’t many useful examples that support pure but not &lt;*&gt;, or arr but not &amp;&amp;&amp;, or mempty/empty/zeroArrow/mzero but no mappend/&lt;|&gt;/&lt;+&gt;/mplus.
Ocaml - extra fast, huge commercial support, great implementation of hashtables, vocal community, nice module system and at the end of the day, when something doesn't work you just can't print it. what's the point of that?
Good marketing is a vital component for you? No one is disputing the fact that the iPhone is a commercial success, one can still argue that it's overrated.
If nobody is talking about it, that means nobody at all is using it. I'd expect at least some of the early adopter people that I read to be talking about it if it's any good, regardless of the marketing involved.
Or you could, in sequence: (1) Write C code by hand but make it look generated. (2) Get the app rejected. (3) Sue :)
Trying to learn OCaml after Haskell seems impossible for me.. The lack of type-classes and the mess this creates is unbearable..
&gt; when something doesn't work you just can't print it. what did you mean by that?
I think Paczesiowa meant that Ocaml has no type classes, hence no "Show" class, hence no "deriving Show" mecanism. However, there is a library with automated conversion between OCaml values and s-expressions : [sexplib](http://ocaml.janestreet.com/?q=node/13).
Thanks for the hard work, the package works great.
ok, that is not /r/haskell material.
Eh, link is a PNG of a nice boat. I was kinda hoping for some Haskell.
This was a teaser from BONUS. The publication date and new chapters are still coming soon...
Yes but it's a pirate boat! edit: Alright, because you requested, you will see that there are now new sections on newtypes and monoids, along with pretty pictures. The monads chapter that people keep asking me about (i don't know why though!) is not quite ready, but i'll put it up before the volcano blows us all up.
Epigram is the stretch-language for Haskellers, the way OCaml is the sitting-on-the-couch language :-)
I still think that anyone able to understand metatheory behind epigram is already following it (blog directly or some /r/otherreddit), other people won't find it interesting enough to start taking more interest in epigram. there are better (more interesting and easy to approach) things about dt languages.
will ghc+llvm+android work?
We can surely let the upmods decide relevance.
thanks dude who made this!
You can thank 'refold' aka Mikhail Glushenkov.
you're right.
You are the total man, especially since I had just gotten to applicative functors. Have a (pirate) upvote.
Nice, thanks!
You should probably put up a news page to see what sorts of updates have been made to the site. That RSS feed doesn't cut it for that sort of thing.
No. LLVM has no powerz on android.
The original "Monadic Parser Combinators" papers by Graham Hutton and Erik Meijer (which Parsec is based on) are great reads: http://www.cs.nott.ac.uk/~gmh/bib.html#pearl Once you understand the concepts, the reference docs at http://legacy.cs.uu.nl/daan/parsec.html and http://hackage.haskell.org/package/parsec should help you find what you need.
yay for new material! :) (but why didn't the rss get updated?)
you might want to look at other parsers written with this stuff i think theres a C language parser someplace on the haskell wiki? I'm working on an SQL interpreter where i'm using parsec to read sql commands and translate them into data structures which i then evaluate later on it's really easy, think of writting parsec parsers like a writting EBNF, but your BNF syntax is executable code. if parsec isn't good enough you'll have to look at happy, which I hear is alot less flexible than parsec
Yeah, the current RSS is pretty week, I actually hacked it together with php in like 5 minutes, it just reads a text files and vomits out the barest possible that's still considered valid RSS. When I update the upcoming chapters I'm going to post it here, but otherwise after I'm done (or maybe before) I'm gonna make a proper blog and everything.
That would be Agda or Coq, wouldn't it? You'd have to be a bit of a masochist to choose a semi-documented research project subject to constant change as your "next language".
I have a sql parser which uses parsec available on hackage here: http://hackage.haskell.org/package/hssqlppp I don't know if it's well written or idiomatic parsec usage though...
Honestly? You don't. There may be a couple of tools written in Haskell for proving theorems about C code, but by that same reasoning with sufficient elbow grease you could "prove C code in Python". ;)
Small example. Good one. I worked on a project to do just this, it's still ongoing and is a multi-million dollar effort, and all under lock and key. I'll give you a heads up, this is a very difficult undertaking. First of all, you need a strategy to deal with the combinatorial complexity of code. The first strategy is to "filter" the code down to elements relevant to what you're proving. The other strategy is to covert the code into a state box machine and proceed to do proofs form that direction. The state box machine approach is the more difficult, but more useful. Get the Dijkstra's book "The Discipline of Programming" and read it carefully. Take your goal of proving C code with Haskell, and work through the examples in the book with the simplest C syntax making each example work in Haskell. Then post your journey on a blog. There are those who would be very interested in lurking and following your journey. If you have a clean record, you might get a job offer out of it.
Who are you working for? Can you give any details about the project?
I was working for the government, but I talk too much. It's got a three letter acronym. It's concerned with computer security.
It would be really cool if there was a way to save and resume GHCi sessions.
hey focus!
and why did you make this suggestion. did **you** actually read that book ?
In principle it could work just by saving the log of bindings. The problem would be IO `&lt;-` bindings since they could take a long time to replay.
I still haven't mastered the art of GHCi ...
I have a .ghci file, which is handy. It lets me do :hoogle from within GHCi, and it enables -Wall. I use "undefined" a lot when writing code. If I want to know the type of something, I change it to 'a' (character a), and it shows me the type. Sometimes i use -ddump-splices to see what Template Haskell code is generated. I use :! when I want to execute something in a shell from within GHCi. I use :info and :browse to see more information about an identifier or a module.
I both agree and disagree on 1. I think that it would be nice if the interactive environment reverted to the last good version and give a error that the import didn't work. But, then if you're not careful and don't read the error-message properly you might think that everything's fine and not understand when your code isn't doing what it's supposed to. Loosing imports isn't really that big of a deal as you'll write them in the source-file anyway. 2. Do you mean like lambda-expressions and expressions in let and where clauses? You do not want these to appear in the GHCi. The reason for this is simple. Lambda-functions has no names so they would be impossible to call outside of the function anyway. Functions in where and let clauses are usually functions you don't want to use anywhere else in the code. That's why you define them there. If you would be able to call them from the GHCi there would be no point to doing this any more. If you really need to make sure that a function in a let or where clause is doing the correct ting you can just test it by using a lambda-function in the ghci. If you are finding yourself making too large functions for this to be sensible, start splitting them up.
I have a tiny bit of [emacs assistance](http://www.nobugs.org/blog/archives/2010/04/06/quickrun-for-incremental-haskellemacs-development/) which I find very useful. During development, I keep some test data and some proto-tests in the main source file, and with quickrun I can run them with a couple of keypresses. It kinda *feels* like you have persistent bindings even though you don't actually have them.
Hmm... my first instinct is to say that I think it would be very intuitive if IO bindings were just evaluated once, and the resulting value saved for when the bindings are replayed. However, it's clear we'd then spend the next few years repeatedly answering questions like "why didn't the value of 'a' change when..."
A quick fix is to write your test functions in the module you're testing. I don't mean formal tests, just the kind of ad hoc poking and prodding you want to do from GHCi. The imports for your module now get your test working. Just remember to clean up after yourself. If you're just trying to manage namespace pollution with your locally scoped functions, then use the module export list to manage this. Admittedly, this general problem can be tricky if you have a local definition because you want to pick up some pieces of an outer scope. The best rule of thumb here, even though it can be frustrating, is that if you need to test something that you can't easily test, then you've made a design mistake. If you simply must have nested scopes, write the top-level function, test it, then *very carefully* splice it back in as a local definition. :)
http://cryopid.berlios.de/ http://www.checkpointing.org/
Where did you go to college, out of curiosity?
Haskell is a programming language, not a proof assistant, or a code checker. There are tools that produce verified c code (I think cryptol does?) and are written in Haskell. There are also tools written in other languages. One thing that folks have done is created automated tests that either provide random checks (via quickcheck) or checks by exhaustion (via smallcheck) of properties of underlying c code accessed via the ffi.
BTW: is it possible to save everything you have defined in a session? It should be possible to save to a filename (as a module), keeping the definitions loaded, then edit and reload the file. Is that possible now?
Don't be accusatory. Good programmers interested in formal proof would have read it. It talks extensively about proof around imperative programming.
I am not being accusatory, I just asked the man if he read the book or not.
Emacs, emacs, emacs, with haskell-mode. I put my imports or temporary definitions right in the file and edit as I go, with a quick C-c C-l when I want to reload. I wouldn't use GHCi in a regular command line. I think vi has an equivalent, but I'm not too sure.
s/the/a/
Here's a simple one. Turn on ghci command history if it isn't already. It was turned off on mine (HP running on macosx 10.5.8). 
You might want to try using [feed-cli](http://hackage.haskell.org/package/feed-cli), a command line tool for updating/generating RSS entries.
Well Agda's documentation is sparse as well. For example, can you find a complete up-to-date grammar for the syntax?
I find ghci very helpful, but at times it does seem a bit course. I would really like to see ghci borrowing ideas from lisp's slime. Basically Slime lets you write your program in the REPL, and save the REPL session. In GHCi you can bind functions to the prompt by using the keyword let. If you could edit those bindings, read them as code and write them to a file, then you could develop your software without bringing in the text editor. Wouldn't it be lovely if you could do: Prelude&gt; :module +Data.Foo as Foo Prelude Data.Foo &gt; let frekle xs = concatMap Foo.bar xs Prelude Data.Foo &gt; :save session.hs Prelude Data.Foo &gt; :edit frekle xs = foldl Foo.foobar Foo.empty xs Prelude Data.Foo &gt; :show Defined frekle :: [a] -&gt; b frekle xs = foldl Foo.foobar Foo.empty xs Prelude Data.Foo &gt; :save and the contents of session.hs would be import Data.Foo as Foo frekle :: [a] -&gt; b frekle xs = foldl Foo.foobar Foo.empty xs For me this would be a big productivity boost, because I usually write the function I want in ghci, and then "commit" it to a text file. It would be nice if the distance between writing the function in ghci and putting it in a text file would be smaller. Of course this could be done manually as follows: write your function in ghci until you are happy with it. Then save it in a text file, and set it in the interactive mode using :r. You will however have to update the text file aswell as GHCi, but I think it is preferable to writing it in a textfile and then using :r in GHCi,because if it breaks, it's all dropped and you can't debug.
I was looking at haskell-mode, and it didn't seem to offer that much. I was hoping that i could enter new definitions and load them into ghci piecemeal, but it was not the case. I'm back to to using ghci on the command line, side-by-side with vim.
What's wrong with just blatting the whole buffer over to GHCi? It's not like loading a module into the interpreter takes a long time. 
I assumed the OP meant verified code like the secure kernel project --- I think that involved some prototyping in Haskell? And a theorem prover was involved. But then the C was written by hand from there from what I remember. Though there was some chunk of generated C too, from some declarative specification.
well, I'm often in the middle of changing things, and I don't want to have to and comment out my half-written code and insert "undefined" everywhere
I really like the form of this, much better than slides.
A direct link to [http://hackage.haskell.org/platform/](http://hackage.haskell.org/platform/) would be better.
"However, the language you have to describe the concept might not be adequate to describe it precisely. So in that case, it has to "do the best it can", getting as close to the concept as possible. This idea of doing the best you can but as little else as possible, is what adjunctions do. " Wow. This sounds like Rough Set Theory.
what's not intuitive about little arrows?
No I can't, and obviously Coq wins by a mile if you want documentation. But Agda's core is stable, there are some good tutorials available and more people working on it. I'm certainly not slagging Epigram, which is a really valuable project (produced by people with brains the size of planets, needless to say) but it would be easier for a haskeller to dip their toe in the water with one of the other options I mentioned, certainly if they're anything like me and want to start small with introductory exercises etc.
That and more; I consider Dijkstra's former student Kaldewaij's book The Derivation of Algorithms somewhat clearer. The science of programming from Gries and Principles of program analysis are also books to check out. These books together, if you understand what's in them, should get your brain ready for understanding it would entail to prove C code with Haskell. 
As far as I am concerned, nothing. Dots aren't hard, either (they're arrows, after all). There's just too much ivory around to make sense of 99.9% of what's written about the patterns of their connectivity.
&gt; I use "undefined" a lot when writing code. If I want to know the type of something, I change it to 'a' (character a), and it shows me the type. You can directly ask for the type of all identifiers using: http://github.com/sebastiaanvisser/ghc-goals/ Unfortunately nobody has uploaded it to hackage yet.
More or less: we developed an executable model in Haskell (i.e., a Haskell program that behaves like the kernel, but doesn't actually run in kernel mode) and then wrote the C version by hand. We used Isabelle to show that the C was a refinement of the Haskell model (i.e., if the C code does something then so does the Haskell model). We did generate a bunch of C for dealing with packed bitfields/unions. We also showed that the Haskell model is a refinement of a more abstract model (which is essentially the spec of the kernel). There are a fair few papers: [here](http://ertos.nicta.com.au/research/l4.verified/) is a good place to start.
There looks to be a bit of overlap with http://darcswatch.nomeata.de, with DPM keeping more detail with patch statuses, though darcswatch makes the status of the project more public (that is, it gives an indication on the existence of contributors, and how long it takes for patches to be reviewed).
I don't bother with ghci at all any more. if you use the ghc-mod for emacs (on hackage) which comes with solid flymake support out of the box, you get on-the-fly typechecking and instant feedback. I'm currently working on some extensions to automate workflow stuff - ie, if you're referring to variables that don't exist yet, create them at the top level as undefined. ghc-mod is a really solid piece of work, i'm really impressed.
Make brane theory intuitive!
It's been submitted before. 
thats cool, did you actually write your own typechecker? i was thinking about just using a combination of the read function and exception handling to decide a type of something at runtime. right now i just handle strings, but the stuff is there to do all the primitive types
I suppose that a Defined or \_Defined or something could be made a default definition in ghci, so you could write a oneliner to send \_Defined to the filename of your choice. 
I would say that the main difference between darcswatch and DPM is that the former is mainly targeted at developers whereas the latter helps reviewers doing their work. For example, darcswatch allows developers to keep track of their patches sent to multiple repositories, a feature not supported by DPM. Conversely, DPM comes with support for a lightweight workflow for patch reviews, something that is not possibly with darcswatch (but there is a roundup integration for darcswatch).
Chance for the programming languages community to advocate for formal semantics?
so you're the same guy as spgarbet ?
That's a great project! Any books/papers other than the ones already named in this thread you would recommend? 
the operations reminds me a bit of [Excelsior](http://www.j-paine.org/eusprig2005.html). (Actually I read Excelsior later and it reminded me of this).
Calls to `if null r then else`; calls to `head`! Come on people, we can do better than this can't we?
Book PDF will be available on TPB I take from that picture?
The motivation for writing hssqlppp was to make writing plpgsql based apps a lot easier, but also just to start writing code and see where it led. I wrote part of a typechecker (using uuagc) - it helps with catching a lot more errors in the sql code sooner. There are lots of other handy things you can do if you have the types available at 'compile' time. Parsing sql seems to be quite complicated, but parsec made it very easy - it's sometimes hard to believe just how powerful it is. I found the type checking much harder - I've written the code which typechecks joins about ten times now, and think I still haven't found the right approach.
Good slides, but how does Category Theory help with software estimation? 
I'd like to see an equivalent to C-M-x in Slime, where you can send a single function definition to the REPL without reloading the whole file. That would accomplish what you want as well. You just write the function in Emacs to begin with, and keep resending to ghci until it works. This is exactly how I used Slime.
Who said it does? I don't see that in the slides.
What is ‘software estimation’? As indicated on p. 2, &gt; What kinds of things can you do with Category Theory in Software Engineering? is one of the key questions. p. 18 answers (or starts to answer) the question: &gt; So what? (for the software engineer)
terminal - do you think it would work better via gtk?
I don't really know what you are looking for exactly. As far as OS verification is concerned, you might want to look at [Operating System Verification -- An Overview](http://www.cse.unsw.edu.au/~kleing/papers/os-overview.html) by Gerwin Klein (the project leader for l4.verified).
I was just making fun of the Software Engineering discipline that was just concerned for a long time in methods to estimate project cost. The term Software Engineering has been associated with so many bad ideas since the term was coined that I don't think it's good marketing to use it anymore. 
I would argue that in a Ponzi scheme it only is in your rational self-interest to enter the scheme if you believe you will find yourself near the top of the pyramid, whereas with a language, even if you are near the bottom of the adoption curve you can derive benefit from the wealth of content available in that language, produced by those who came before you. And unlike a Ponzi scheme, the knowledge that you have gained by working in one language does in part transfer to the next language, whereas your money is likely gone when the Ponzi scheme collapses.
There is. It tends to see most of its adoption in the financial or high assurance government and chip design sectors, it is hardly mainstream, but there is definitely a commercial community.
Absolutely. I support the WHILE language!
Wow. This is easily my favorite paper this year.
Impressive and nicely documented. Really nice application of the Iterator pattern!
yes, I came here to suggest that exact paper. In fact, that was the that helped me understand monads in the first place.
if he was indeed a student of Kaldewaij I think fusc() was not his invention which seems rather odd.. so basically the ideeas which he exposes in his book are of Anne Kaldwaij's ?
Nice tool for team managers! It sounds like you don't really need to use amend-record - you can create a new patch that has exactly the same name. Right? I hope so, because amend-record isn't always possible. Perhaps you should make that point a little more clear. Who is Richard Developer? Is that Dave's brother? How did he get into this?
They have to use separate input systems. What events are received using terminal mode may depend on your terminfo databases. These may be incorrect for your system. Emacs and vim often use internal terminfo databases to work around these issues. 
I'm at the abstraction and design stage of similar software tool(s). Ping me at (my username) @ gmail.com. I will be reading ... everything you've written in the near future. I'm sure I'll have a lot of questions, if you can spare the time.
We should look at merging in the features we've got in cabal/cabal-install. In particular it supports command completion.
Tulane / University of Tennessee
I have read it, carefully.
Thanks for the references. I probably pick those up on my next Amazon splurge.
will gtk2hs (together with native gtk) be included in platform?
This'll be pretty useful, thanks!
yeah that paper is an overview and doesn't show how you actually prove C code.
did you solve the problems in the book ?
See the [procedure for adding new packages](http://trac.haskell.org/haskell-platform/wiki/AddingPackages).
My initial response when hearing that it's quasi-quoted was negative, but actually it looks like a pretty good solution. 
I'm glad you are proceeding with this despite some dissent among the mailing list folks on haskell-web-dev. Great stuff!
It is still not working for me.
I'd like to note: this is perhaps the worst bug report I've ever read. Being more constructive: What did you try? What happened? What did you expect to happen? What platform do you have? What build of GHC/Cabal/cabal-install do you have? Do you have GTK installed? Have you succeeded in building gtk2hs before (non-cabalized), not tried to, or had a build failure you were hoping this work would fix? Did you cabal-update? etc.
Note: the `-f-gtk_2_20` stuff will not be necessary in the final release (I've sent in a pile of patches).
Very clear introduction. Category theory is that simple?
As Roman mentions, just using this mechanism (on ST at least) is unsafe, however it would be a nice basis for a library. Any takers?
That's so beautifully filthy:) well done, Roman.
To clarify, this isn't actually available yet via cabal to users, correct?
great, glad it was useful :)
Sounds good. Also cabal/cabal-install was exactly the kind of app I was thinking about; it could probably do with cleaning up its help output, categorizing the list of commands it supports etc.
Woo!
Man! I just finished building the last version. :(
CLDouble? c2hs?
ditto. ghc 6.12.1 was so much faster than its predecessors too. not that either are slow compared to the competition ;)
http://hackage.haskell.org/trac/ghc/ticket/3353 is still open, so probably not. I'm going to remove c2hs from hubris, at least.
People interested in this might also want to take a look at: http://community.haskell.org/~ndm/cmdargs/
Sorry that was not meant as a bug report. To answer your questions: What did you try? &gt; cabal install gtk2hs-cast-gtk What happened? Resolving dependencies... 'hint-0.3.2.3' is cached. Configuring hint-0.3.2.3... Preprocessing library hint-0.3.2.3... Building hint-0.3.2.3... src/Hint/InterpreterT.hs:23:17: Could not find module `GHC.Paths': Use -v to see a list of the files searched for. cabal: Error: some packages failed to install: gtk2hs-cast-gtk-0.10.1.2 depends on hint-0.3.2.3 which failed to install. gtk2hs-cast-th-0.10.1.0 depends on hint-0.3.2.3 which failed to install. hint-0.3.2.3 failed during the building phase. The exception was: exit: ExitFailure 1 What did you expect to happen? Success What platform do you have? Mac OS X 10.4.11 What build of GHC/Cabal/cabal-install do you have? &gt; ghc --version The Glorious Glasgow Haskell Compilation System, version 6.10.1 &gt; cabal --version cabal-install version 0.6.0 using version 1.6.0.1 of the Cabal library Do you have GTK installed? gtk2 @2.14.5_0+darwin_8+x11 (active) Have you succeeded in building gtk2hs before (non-cabalized), not tried to, or had a build failure you were hoping this work would fix? Tried several times before and failed. I was hoping this would work. Did you cabal-update? Yes 
dcoutts moved c2hs to code.haskell.org and applied the patches needed for 6.12.
Dammit! Avoid success at all costs!
AFAIK the current solution to such boilerplate code is to use template haskell, not that I've ever used it. &gt; For example, say you have a list of items that were found to be complementary in terms of content, but are of different types. In such cases, type witnesses are unavoidable. What does it mean for items to be complementary in terms of content? I suspect such complexities of type witnesses are can easily be avoided in whatever problem is at hand here.
They're not advertising the use of it on the Bump website. Besides, that's why I didn't post to /r/programming. ;)
Thanks for the pointers. I'll check out template haskell, and try to think about that code again, outside the box.
HList should work again!
Yes, you don't need to do an amend-record. Just creating a new patch with exactly the same name as the original one suffices. "Richard Developer" (at the end of the article) was a typo. It should read "Richard Reviewer". Well spotted, thanks!
You may not have to think outside the box (though there is nothing wrong with that), but just think inside the Haskell box (though the Haskell box is almost disjoint with the normal box).
What was the HList issue?
Other way around ; Kaldewaij was a student in Eindhoven of Dijkstra.
This is very cool, and I think it's the best suggestion for improvement in this area i've seen. Someone please implement in GHC.
http://hackage.haskell.org/trac/ghc/ticket/3850
Tom Schrijvers wrote a few papers with SPJ, so it (whatever it is, still downloading video) either will be implemented or there is a good reason against implementation. 
Ooooh, shiny indeed! Finally a nice way to solve the whole "Set is not a Functor/Monad" question. However, am I right in thinking that this will also require a revamp/refit of a large number of basic libraries?
Yes, but I believe in a backwards-compatible way. This is very exciting.
It looks like the constraint families are backward compatible for the instances, but what would the type of a restricted mapM be, for example. Well, time to read the paper, I guess!
We implemented this for the CnC library back in December, but it blew up when we used it on anything larger than a toy example. An email from Ryan Newton in my inbox: &gt; Hey, by the way, I implemented this, had problems, and talked to Simon Marlow about it. &gt; It turns out that sparks are not for IO... the spark pool is fixed size and it will just drop the sparks if it overflows. (And in 6.14 they're saying sparks won't even count as roots for the GC.) What would be needed to make this work is a real expanding work-stealing deque (a la Cilk) (or queue), rather than just a bounded work-stealing queue.
It's not on hackage just yet. Will be some time soonish.
why are you all so afraid of overlapping?
Looks like you've got the `ghc-paths` package registered but the actual files have been deleted. Did you ever `rm -r ~/.cabal` without also unregistering the packages? If so you'll likely run into this problem with other packages. In the immediate case, try `ghc-pkg unregister --user ghc-paths` and then try installing again. BTW, running `cabal install gtk2hs-cast-gtk` has little to do with whether the cabalised gtk2hs packages are working. The gtk2hs packages are not on hackage, so if you want to test them you've got to follow the instructions in the article.
I don't see why dropping sparks is a problem (there is a more detailed answer to your comment in my blog).
But watch out for the evil hacks ;-)
It isn't in your case. I read the description not the implementation, before I dashed off an overly-smug reply. =)
If you're referring to the dissent about the indentation issue, I take full responsibility: I didn't make it clear at all that I was *not* following Haml on that issue. There's a [page explaining the indentation rules](http://docs.yesodweb.com/hamlet/indentation.html) up now, so hopefully that particular dissent has been fixed. I hope to get more constructive criticism like that in the future; hopefully I can make Hamlet even better!
Give this a go: [c2hs-0.16.2](http://hackage.haskell.org/package/c2hs-0.16.2)
The Haskell type Set is neither a functor nor a monad. The Ord constraint on Set exposes its implementation via binary trees, and binary trees are neither functors nor monads. If you want Set to be a functor, you need to hide its implementation better, not add new features to the language to further detach the meaning of classes like Functor for the math they (claim to) represent.
Really? It had been a while since I compiled a GHC release, and I knew it took a while, but I didn't remember it being that long. I left the house and came back and it was still compiling. o.o
Because if you import an extra module, instead of getting a compilation error, you get modified semantics...
Just out of curiosity, and from a position of at least a little ignorance... is there still a justification for data families? Or is it just that the injectivity assumptions made it easier to implement (I know, for example, that data families were implemented and included in GHC long before type families were.)
Use, or wait for, the Haskell Platform...
with great power comes great responsibility. can you really imagine real life situation, that there are two overlapping instances, and an import brings third one, that sits between those two?
That's not what I'm referring to. Say you are using a broad instance for (forall a. a) -- and now you import a more specific instance... 
Sounds like a good summer of code project, but those seem to be already allocated for this year. ;)
It isn't uncommon for data families to be exactly what one wants. For instance, if we're making generalized tries: data family Trie k :: * -&gt; * data instance Trie () a = UNil | UJust a -- newtype instance Trie () a = TUnit (Maybe a) data instance Trie [k] a = LT (Maybe a) (Trie k (Trie [k] a)) ... It's true that the unit instance is just Maybe, so we could make due with a synonym family. However, the list case genuinely requires a new, recursive datatype. And there are other similar cases. So, if you lack data families, you'll have to have (for certain families) lots of extra data definitions scattered around whose only purpose is to be the target of type families. It's needless indirection. I haven't thought about class families enough to know how they'd compare. The talk said that class synonym families were always the more elegant choice in their investigations. That's clearly not true for type families versus data families.
I have a really hard time thinking about real-life example of this. in fact, orphan instances should prohibit such cases.
I already use the Haskell Platform, but because I'm on Ubuntu Hardy, I have to compile GHC and then compile the platform. I'm not going to install this version until it's on the platform. I was bullshitting more than anything.
 module A where constraint family C a constraint instance C a = Show a foo :: C a =&gt; a -&gt; String foo x = show x module B where import A data NonShowable = NonShow (IO Int) constraint instance C NonShowable = () bar :: C a =&gt; a -&gt; String bar x = "I may not be able to be shown." module C where import A import B baz :: NonShowable baz = NonShow (return 5) quux :: String quux = (bar baz {- okay -}) ++ (foo baz {- not okay -}) {- foo :: C a =&gt; a -&gt; String bar :: C a =&gt; a -&gt; String -}
This seems to be more of a counterexample than a supporting example. First of all, you'd clearly like for `Trie ()` to be `Maybe`, but you aren't able to do so, because `Trie` is declared as a `data family` instead of a `type family`. In the second instance, you get to save one line declaring a new data type... But then things get way worse. Given your type for `Trie [k]`, we're going to need a gazillion other instances for the element types of lists -- `Char`, `Int`, and so on -- just to indicate that a "trie" of that key type is just an ordinary map. Here, it would be really nice to be able to just say, for example, type instance Trie Char = M.Map Char type instance Trie Int = M.Map Int But you can't. Instead, you need to build brand new types for all of these. And all of this, apparently, is to save declaring top-level names for recursive data types that are actually interesting. At best, I see this as a use case for some syntax for "anonymous data declarations" or some such thing, but certainly not a reason for a new kind of type-level function that guarantees injectivity by requiring that everything in its image be a brand new data declaration. What I suspect, actually, is that there is a reason that the injectivity guarantee that this speaker referred to, but I still haven't seen what it is. Perhaps there are certain things that are forbidden for type families but allowed for data families, because that property is needed to ensure they are... defined? decidable? type inferrable?
non-existing extensions != real-life. anyway, if in module C you omit importing A or B - you get error (no foo, or no NonShowable(..)), so this example is invalid. 
No, we don't want to use `Data.Map.Map` for most things. For instance, `Integer` also has a new datatype, for some sort of bit trie. The `Int` case might look like `IntMap`, but for that to be a loss, you have to already assume that it exists. It does in the case of `IntMap`, but when it was written, the only choice was to write separate, monomorphic structures for each type. Had data families been around at the time (along some kind of collection organization based on them), what we know as `IntMap` could conceivably have been `Map Int` instead. And then there are trees, byte strings, and every other algebraic datatype you could conceivably want to use to key a trie. Are all of these interesting, and deserving of the top-level name `FooTrie` (and maybe even a separate package full of monomorphic functions working on them) in addition to `Trie Foo`? Injectivity is, certainly, useful as well. I think 80% of the questions about type families on haskell-cafe and elsewhere boil down to something like the following not working: type family Foo a :: * foo :: Foo a -&gt; Foo a foo x = foo x and the reason is that `Foo` is not injective. You can work around this: foo :: a -&gt; Foo a -&gt; Foo a foo w x = foo w x but it's ugly (and the number of witnesses you need can easily get out of hand).
Perhaps it was mentioned in the video, but does anyone have an example of a problem that might be solved with class families?
Right, this seems like a issue with any backwards-compatibility. If we add an associated constraint to the Functor class, say, then clients of the Functor class methods (trivial example: fmap' :: Functor f =&gt; (a -&gt; b) -&gt; (f a -&gt; f b) fmap' = fmap ) will no longer typecheck.
&gt; The Haskell type Set is neither a functor nor a monad. Not even in a subcategory of Hask?
Heh, I was just reading the release notes and thinking "I guess it's wrong to reject `data (Show a) =&gt; T a`, but why would anyone ever care?" (answer: they don't really.)
The diagram x --- F ---&gt; xF | | g gF | | v v y --- F ---&gt; yF (which hopefully comes out monospaced) still doesn't commute when F is `Set`. The paper makes this "work" by adding a hidden condition on y, which (to me) seems to change the meaning of `Functor` away from the category theoretic one.
I don't really understand your objection. Are we not talking about the extension that the video linked to here was presenting? And are we not talking about why the presenter of that talk said that overlapping instances should be disallowed in that extension? As it happens, I'm not sure if my example is valid or not, because I'm a bit hazy on how everything with that new extension would work out. However, that is the shape of the argument. In general, overlapping instances allow (fully qualified) identifiers/types/whatever to mean two different things in two different modules. In the case of overlapping type class instances, we have: module A where class C a where foo :: a -&gt; Int instance C a where foo _ = 0 bar :: a -&gt; Int bar x = foo x module B where import A data Blorf = Blorf instance C Blorf where foo _ = 1 module C where import A import B main = print (foo Blorf) &gt;&gt; print (bar Blorf) This prints 1 followed by 0, even though in context, both foo and bar have type `Blorf -&gt; Int`, and we have defined `bar x` to be `foo x`. So we've lost the ability to do semantics-preserving inlining. Some people don't think that's a big deal. But, the same argument applies to overlapping type family instances, so `A.F B.T` may mean different things in different places. This makes the type system _unsound_ (you can write `unsafeCoerce`, or things like it). And I assure you, this is a real problem, which can't be dismissed by saying that I've violated some module import rules for a challenge. In the early days, the type family implementation was missing some checks, and allowed overlapping in certain cases, and you could use it to produce segfaults. So, if we are talking about the extension in the story, the question comes down to whether _you_ can prove that overlapping constraint families is sound, or doesn't violate some other property we think is important. If it's about type classes, then, well, you may not care about inlining being semantically sound, but other people do. It is, in fact, one of the selling points people bring up for Haskell; lack of side effects makes various program transformations admissable in Haskell that wouldn't be otherwise. But overlapping instances can break that.
I was talking about overlapping class instances. I certainly wouldn't approve of any extension that makes it possible to write unsafeCoerce (if I could, I'd get rid of undefined), I haven't written a single type family, because of overlapping instances - why would I learn another extension that is less powerful than the one I'm already very familiar with? about inlining - doesn't inlining happen when the types are already resolved? and that example still isn't real-life, no one writes this kind of code.
`Set` is a functor over the subcategory of Hask with types-with-an-Ord-instance as objects and `compare`-preserving functions as arrows (`compare s t = compare (toList s) (toList t)` probably works for set comparison, if it isn't already defined). `Data.Set` even has a function for the action on arrows, called `mapMonotonic`. This is, of course, not the sort of insight the paper is promoting.
I'm a little lost in this conversation, but as I'm sure you are aware, `Set` is also a functor over the full subcategory of Hask on types-with-an-Ord-instance (i.e. with arbitrary functions), using `map`. Sure, `map` has to re-sort the internal binary search tree, but that is just an implementation detail. This seems entirely relevant to the paper, given that it is an example in the slides :) Edit: OK, I suppose I have to restrict to types which satisfy the "`Ord` laws", whatever those are (e.g., `a &lt;= b` and `b &lt;= c` implies `a &lt;= c`).
GHC may well do inlining after it has chosen dictionaries. However, at least as important in some people's eyes is the ability to reason about their programs. The overlapping makes reasoning more complicated. I cannot reason that since `bar Blorf` is defined to be `foo Blorf`, and `foo Blorf` is 1 where I am, that `bar Blorf` is also 1. I need to know what `foo Blorf` is in the context where `bar` is defined (which you yourself have mentioned may not technically make sense, because `Blorf` may not even be in scope where `bar` is defined). These substitutions are non-local. As for my code not being "real-life," well, it is a minimal example.
Absolutely correct. I misread the original question as being about whether `Set` was a functor in Hask, not in a subcategory of Hask. Incidentally, I think I would personally prefer that the `Functor` class did not come with an (in some subcategory) addendum. This doesn't mean I didn't misread the original question tho.
Data.Set.map works as the action of a functor on morphisms only when the morphisms respect (==), otherwise map f . map g = map (f . g) will break. I don't think there's a need for monotonicity though.
I'm not sure if this isn't a bit of a straw-man argument. `bar`'s type is more restricted than `foo`'s, so there's a bit of a hint that something beyond pure equality is going on here. Perhaps we shouldn't be surprised that the semantics of Haskell has to take account of qualified types?
Yes, I was being overly vague and including something like "`a == b` if and only if `a` and `b` are indistinguishable (w.r.t. some set of exported operations)" in the "`Ord` laws", besides the obvious ones like transitivity. I guess in practice one sometimes encounters instances which don't satisfy this law (`Double`, to reference a recent haskell-cafe thread).
Then you probably want the [TPHOLs paper](http://ertos.nicta.com.au/publications/papers/Winwood_KSACN_09.pdf) from last year. To summarise, we want to show refinement between the Haskell spec and the C implementation. We do this by showing a correspondence property for each function, essentially stating that the C function has the same effect on the state as does the Haskell function (modulo a state relation). We have a C parser inside Isabelle which converts the C source into something like an abstract syntax tree. We then use Norbert Schirmer's verification condition generator (VCG) and (more frequently) a number of correspondence-specific rules and tactics to pair each line of code in the Haskell spec with the corresponding line(s) of code in C. One interesting thing that came out of our approach is that we could do most of the nasty proofs at the Haskell level: the spec had enough detail that most of the results carried over the state relation. Can I ask what is your interest in this? tl;dr use a parser. custom rules/tactics, and a vcg.
I got Haskell SDL working in WinXP with some difficulty, but I can't for the life of me remember how. It's possible that I'm repressing the memories. The thing that annoys me about SDL is the stupid main() swap trick it pulls with the preprocessor--it renames your main() and substitutes its own that does some Windows-specific initialization. For some reason this doesn't work so great with Haskell code, can't imagine why! The simplest workaround that I found was to export my Haskell main function via the FFI and call it from a thin C wrapper compiled with SDL's silly trick. Ugly, but effective. The same trick was necessary on OS X as well, and as usual everything Just Works(tm) on Linux.
you can also see it as a requirement to impose on the morphisms rather than on how (==) is defined. i.e. you'd accept as morphisms of the category only those functions f such that forall x y, x == y -&gt; f x == f y. 
Incidentally, I wonder about SPJ's pre-fix comment--I believe he's correct that GHC wouldn't reject a type based on such a context, instead only enforcing it at the term level. So I'm curious what the purpose of that line was, since it's clearly implausible that SPJ would understand GHC's type checker better than Oleg. ;)
yay! please do this has been keeping me from fooling about with it.
I had 6.12.1 already installed, so I compiled the haskell platform for completeness when it came out. Initial tests seems to be fine for the new one.
If you mean constraint families (the things they are talking about mostly in this video), then here's one of their examples. class Functor f where constraint Inv f a fmap :: (Inv f a, Inv f b) =&gt; (a -&gt; b) -&gt; f a -&gt; f b instance Functor [] where constraint Inv [] a = () fmap = map instance Functor Set where constraint Inv Set a = (Ord a) fmap = Set.map In other words, this lets us declare a Functor class for "partial" functors like Set, which are restricted to operate only on types in certain classes.
Yeah, that may well work. But, RayNbow just asked for a subcategory for which it was a functor, and I was 100% sure about the one I mentioned, and not about others, so I played it safe. I guess the odd case is something like: toList :: forall a. Set a -&gt; [a] Types like `forall a. F a -&gt; G a` are frequently cited as ensuring that their elements are natural transformations from `F` to `G`, but toList is not natural if we're talking about the full subcategory, because: toList . map f = map f . toList doesn't necessarily hold. It only holds if `f` is monotone, or if `map` for lists is redefined to sort as well. This may not matter for just functor stuff, though.
Well, if we had a nicer type language, we might be able to actually talk about categories other than those whose objects are 'all Haskell types'. If one can do so, it's not unreasonable to want to talk about functors over those categories. The constraint families can be viewed as identifying what the objects are for the category the given functor is over. It will still always be a subcollection of all-Haskell-types, but that's probably better than nothing.
Yeah, there's a type hint. But, for instance, there's another extension, IncoherentInstances, which allows you to define `bar` inside `C`, even though both instances are in scope. There's a type difference there too: bar :: a -&gt; Int bar x = foo x baz :: C a =&gt; a -&gt; Int baz x = foo x Those do two different things. I think even people who think overlapping instances are okay tend to think incoherent instances aren't good. But the incoherence is actually fundamental in overlapping instances. It's just that without the second extension, you can only fail to cohere across module boundaries, instead of within a single module (or you can use existential types, which don't have similar incoherence checks). I don't think it's too extreme for people to look at this and remark that overlapping itself seems rather ugly (for open classes, at least). I think the argument is more compelling for the proposed constraint families, though (and it's of course compelling for type families). I'm not 100% sure how they'd work, but it's possible my original example (or one like it) would get you a `C a` constraint that meant `Show a` in one spot and unconstrained in another, which is a problem.
Every time before we release our software (C++, not Haskell) I have to go through and update all of our library dependencies and tools (like MinGW) one by one. This usually takes a couple of days. I know how to do it without snags by now, but I keep thinking that on Linux this would all be automatic.
Be still my beating heart, a nicely designed website associated with functional programming.
There's a WIN32 file in the SDL Cabal package that lists how to do it.
Works for this community too... what's stopping people contributing? Comments?
Why? Leaving aside that that file gives wrong directions, and leaving aside the silly ritual required to make GHCi happy, why, if the procedure has been known since 2009, isn't it built into the .cabal file?
wxWidgets used to have a binary distribution for Windows, which worked. OpenGL/GLUT works perfectly well everywhere, except that you can't compile it without MinGW (maybe Cygwin could work too?); but if the versions included in the Haskell Platform are ok for you, that's not an issue. I have to agree about the autoconf hell, though. Also last time I tried to install MinGW (to compile a custom version of OpenGL), I simply couldn't manage it, somehow the official MinGW distribution was broken... I dream about a lightweight FRP-style custom widget toolkit using pure OpenGL; while that's not native, at least it would work everywhere...
i use java at work n it fizzles me brain
the propensity of haskell standard library developers to reason in ways other than what i'm used to/prefer. it's a big road block.
Could you be more specific? Library developers like those on Hackage?
Well, one reason I can imagine is that projects like cabal-install seem to be severely understaffed. To give you some anecdotal evidence, I've written a patch to add [world file support](http://hackage.haskell.org/trac/hackage/ticket/199) to cabal-install in [Feb 2009](http://www.mail-archive.com/cabal-devel@haskell.org/msg04753.html). In [Dec 2009](http://www.mail-archive.com/cabal-devel@haskell.org/msg05665.html) I was told that the patch looks good and asked to update it to the latest darcs checkout, which I did. However, it still hasn't made it into the main tree so far. While I'll happily continue to update the patch outside the tree, this long time span might be deterring other potential contributors. (I'm aware that most maintainers work on these projects in their spare time, for which they have my utmost respect.)
1. too busy 2. library-churn makes keeping up with current set of hip standard libraries too much work.
ok, [this appears](http://i.imgur.com/OrjU7.png) on page 7, what does it mean ? how about [this one](http://i.imgur.com/VOacx.png) , is there any difference between those signs in the two expressions ? what are the pre-requisites for reading the paper you just gave me(Hoare logic seems to be one of them..) ? I need to be able to build a list of pre-requisites(reading materials, and stuff) and then take them one by one like * First-order logic * Hoare logic * Isabelle * Norbert Schirmer's VCG and then go through them one by one and learn them at a minimal level so I can understand the paper you just gave me. that's because I want to approach things in systematic manner.
GHC would throw an error when typechecking class instance using such type and there was missing constraint from that context. for monomorphic types you would know, that you made a mistake (since they don't have such instance), and for polymorphic ones you only have to insert it again, but it should help you remember what it means and if it makes sense. it's a really bad substitute for static type system, but it's better than comments. and it's not about understanding the type checker - type checker can be buggy (like in this case) it's about types and Oleg was born there.
If they did a "low hanging fruit" thing like the KDE people do I'd say you'd start to see a lot more contribution.
ah, you also asked what my interest is. I want to write bug-free code.
how many people were actually working on this ? was it just you or more people ? Here is [Norbert Schirmer's VCG](http://www4.informatik.tu-muenchen.de/~schirmer/verification_environment.html) 
I have the same problem. It's tears and blood every time. edit: Fortunately, the Haskell Platform 2010 juste came out on windows and is very easy to install. However, I've had to compile sqlcipher (sqlite with encryption), which required me to make openSSL work on Windows. That was the hard part.
oh, I'm not working for anyone, just a student interested in writing correct and bug-free code, and because I saw you people were able to do this I thought "Wow, that looks nice, I'd like my pet projects to be bug-free".
what if every package on hackage had a TODO list and people could vote on specific features, that way you could see the most desired thing on hackage.
right, that's why people write so many papers on formal methods and they prove a kernel to be bug-free, because they use "elbow grease"
I can't wait for 6.12.3, if I'm not mistaken it will support shared libraries on mac osx! ([ticket 3550 is active](http://hackage.haskell.org/trac/ghc/query?status=infoneeded&amp;status=assigned&amp;status=merge&amp;status=infoneeded_new&amp;status=new&amp;group=status&amp;milestone=6.12.3))
1. time 2. also, time Yes, I know it's a pathetic excuse because you make time for things which are important to you, but it's still true. My promise: I have a patch sitting on my laptop at home that I will submit to the package maintainer *tonight*. You may come round my house and harangue me if I've not done it. EDIT: I did send it upstream! Tiny contribution made! Now I'm off to settle down with a dram. Good night folks!
Sorry about that. I've been very busy last few months with writing up my thesis. In the last few weeks I've been managing to find a little time to review Cabal/cabal-install patches. You might have noticed a few go in. There's still several (including yours) that I've not reviewed yet. Also, there's no harm in prodding me. I'm also a bit forgetful :-) EDIT: btw, I cannot pull from http://darcs.monoid.at/cabal-install/ I get 403 permission errors. Can you check the permissions of files under the _darcs directory. Or attach a new patch to ticket #199. EDIT2: If we're doing patch review... :-) He's some suggestions for next time. For a new feature, try to split up the patches a bit more to make review easier / more obvious. For example it could be split into the core infrastructure, the bit that updates the world file when new packages are installed and then separately the additional features of the `--one-shot` mode and the special handling of the `world` target.
That was actually a quite good idea, a very crude version of getsatisfaction.com or alike.
* Gtk2hs is almost impossible to install on Mac (at least without X11), that's why i can't use, so i will never contribute it. * Some months ago it was a major hassle to install hxt with ghc 6.10.4 via cabal install because of dependency problems to tagsoup who noone took responsibility for. I gave up, so i won't contribute to it. * I expect similar problems with wxHaskell, that's why i won't try to write GUIs in Haskell anytime soon, so i won't contribute to anything GUI related. Libraries seem to break all the time, and if they don't, they are poorly documented. **Make things easy to use (easy to install and easy to understand)**. If people can't use, they have no reason to contribute.
There might be a general feeling that being able to help Haskell requires super-human knowledge.
No harm done :) @EDIT: The permissions should work now. @EDIT2: Thanks for the suggestions, I'll keep that in mind.
I still suck at it.
You seem to have confused Cabal for a build tool; don't worry, it's an easy mistake to make! In fact, Cabal is not a build tool at all: all the dependency chasing etc. features that one might expect it to do is built into GHC's `--make` option. .cabal files are a standardized way to specify flags to GHC. If the SDL workaround involves anything other than specifying particular build flags, Cabal won't be able to handle it.
If nothing else, perhaps this argument suggests the need for a semantics of type classes and qualified types that would allow us to do something more than generate samples that, given suitable assumptions about the compiler, would probably be bad. :-)
This is the main reason for me (although I'm on windows). I have so little time to do "off-hours" programming that I really don't feel like spending it 99% on installation hassles. If I can't get stuck in and do some coding pretty quickly then I'll just do something else instead, and that obviously guarantees that I'll never end up with anything worth contributing. 
Maybe you can try with qtHaskell? 
My haskell coding skills would be laughed at :(
You're right, some of the procedures in that WIN32 file could be integrated into the .cabal file. In particular: Extra-Libraries: SDL if os(windows) Extra-Libraries: SDLmain Then the issue about where you actually installed the SDL C libs can be handled by: cabal install SDL --extra-lib-dirs=C:/SDL-1.2.12/lib --extra-include-dirs=C:/SDL-1.2.12/include If there is genuinely a problem with naming, ie SDL vs SDL.dll then that needs reporting. I was under the impression that the linker on windows will automatically pick up .dll files. If not, it's a bug that should be reported.
The fact that Cabal's build system isn't especially brilliant, and the fact that it delegates much of the work to `ghc --make` doesn't mean it's not a build system at all.
Thanks, got it in my local tree now, no conflicts. I'll move a few bits about before pushing (moving stuff from Main to D.C.Install).
&gt; Gtk2hs is almost impossible to install on Mac (at least without X11), that's why i can't use, so i will never contribute it. Unfortunately this is something of a chicken and egg problem. The gtk2hs hackers do not have access to OSX and the OSX users do not want to contribute and test the necessary changes. Same problem with windows, though to a lesser extent since Windows is rather more commonly available. The OSX tax is really very high. :-( Less than £100 for Windows 7 but more than £500 for OSX (mac mini).
I've also considered contributing to EclipseFP, since i think it has potential and Eclipse-like IDEs are badly needed. The latest version requires you to 1) manually obtain the Scion server from 2) a darcs repository. I don't use darcs, but went through the hassle of installing it on Mac and pulling it. It was not compatible with the patched ghc 6.10.4 necessary for Mac OS 10.6. With ghc 6.12 EclipseFP stopped working at all. So now i am in the situation that i can not use Haskell for GUIs, i don't have a rich Eclipse-like IDE, i am scared of Haskell XML-programming because cabal might break hxt again, i expect similar problems with database programming and web services. Haskell is my favorite language, but i more and more fail to see how i can get any real world task done with it.
Haskell on Windows needs a installer that installs all the packages that use C libraries. "Haskell Binary Platform" or something. Also, a mailing list and a wiki to centralize information. I gave up on Haskell for a while because I needed Windows on my home box. I just reinstalled Linux so I could start a Haskell project. It's really the fault of mingw for not doing it's their own package manager, but Haskell is suffering.
I meant when you're compiling your own code. At least for me, 6.12.1 was faster than 6.10.4 by a long shot. But when you're measuring compile time for a meg or two of code in the low single digits, that's an order of (or two) magnitude lower than what it'd be for any C++ compiler.
Almost every time I think of something to contribute, I find that someone else has been there already. For example, I thought I could write a better mime library, with a better API, but when I actually had to use the thing, I realized that the existing mime library worked better. Incidentally, that's how I learned a lot about Haskell: by reading other people's code for packages that I thought I might be able to do better at. There are about two or three absolutely random things I've found that I would've wanted in missingH and I ought to submit them to the package maintainer for consideration, at some point. They are 1) andF :: [a-&gt;Bool] -&gt; a -&gt; Bool, the corresponding function for orF, and takeM :: Int -&gt; [m [a]] -&gt; m [a].
Really, they do. Formal methods are often quite tedious. In the case of "proving the seL4 kernel to be bug free", they merely proved that the abstract specification of the kernel was bug free, by re-implementing it in something that was more readily proven correct. Then given that Haskell model, they went and proved a bunch of properties about it using Isabelle/HOL to show that a number of bad things don't happen in the model. With that they can be reasonably assured that at least the model is sound as Haskell is a reasonably nice language to prove theorems about, despite its lack of a formal semantics. They did not directly prove that a particular C implementation was correct. However, with "sufficient elbow grease" they could then hand translate the Haskell specification into a C implementation, as the specification can be given in small enough steps that the translation is "obvious". They may have even proven the equivalence of the C and Haskell model, but I wasn't involved. Ultimately, this is far from an automatic process.
Because I lurk in the hope of picking up some of this new funky language, but never get round to working with it due to paying work.
I think it's less to do with OS X users' refusal to contribute to gtk2hs and more with their unwillingness to touch GTK itself with a ten-foot pole. It really sucks badly on OS X.
outdated and uncentralised documentation system. At least this will be one major reason why it won't be the first choice in commercial environment. 
Installing stuff can be quite difficult. I've tried to build gtk2hs, SDL and GHC on Windows, but there's a lot of weirdly- or non-documented stuff and it requires a lot of extra software. It's basically installing Linux on Windows. I think I may have gotten SDL to compile before, but not the others. I'll tell my story for GHC, at least as I remember it. I gave up when I was supposed to run a Perl script through msys at some point. I had to muck around to get it to work ("perl" was making my command line hang for some reason), and when it finally worked the script crashed. After some debugging in Perl (a language which I don't speak), I figured that it was trying to access /usr/bin, which obviously does not work well on Windows. I had no idea how to fix this, the docs did not mention it, and at this point I was tired of all the hoops, so I figured I'll contribute when I get a linux system at home someday. gtk2hs... I stopped when it asked me to install GTK, with no link or precise directions. Do I need to put stuff in my path, do I need to compile it, will it work even if it's built on MSVC? I think I installed whatever package looked the most obvious and gtk2hs still complained, so I didn't know where to go from there and gave up. Of course, making the build system cleaner isn't really glorious work, and it's not research paper material. If I get more time eventually, maybe later this year, I might take a stab at it.
documentation is all on hackage? (of course, it could be better...)
If you wanted to add an extra step--say, wrapping the main function in a small C file, or adding code-motion graphs, or what-have-you--to a build specified with `make`, or `mk`, or Ant, or Maven, or MSBuild, or XBuild, or CMake, or SCons, or Franchise (if you can find it), or probably countless other build systems, you could add a stanza or two to the appropriate script and be done. To do the same thing with Cabal, you have to hack around with Setup.hs. [EDIT: As Duncan points out below, my original claim that you had to change Cabal itself was wrong.] One could look at this as suggesting that Cabal is a build tool, just one that's inferior to everything else out there. It seemed closer to its intentions to suggest that Cabal is a packaging mechanism that knows enough about GHC to be able to invoke it automatically.
Centralised in the sense that I do not have to double click ten times to find it. Maybe hosted on Hackage? 
+1 for documentation. There seems to be the idea among Haskell experts that simply knowing the type signature is enough. Thus, foo :: String -&gt; [String] -&gt; Int should tell you everything!!! Documentation with examples is essential given that FP is fairly hard for the average developer.
Agree with the libraries and documentation. I think it's time to expand the haskell-platform project, standardising a level of documentation (including translations), including tutorials on how to get common things done with a library, keeping the library up-to-date, and providing some small guarantee that the library will still be supported a few months from now, and of course including the latest GHC and related tools. To borrow an analogy: Hackage et al should be considered upstream, haskell-platform should be the equivalent of a Linux distribution.
&gt; Ultimately, this is far from an automatic process. no problem, I just want to know how they did it. I don't mind it not being automatic, I have a brain, and I'll use it.
&gt; Documentation with examples is essential [...] examples is the thing i most often miss in Haskell documentation. Just like in a man page, 5-10 examples at the end of the documentation is sooo helpful and in most cases only takes a few minutes for the developer to add.
There's also a [prototype implementation on github](http://github.com/dorchard/constraintTermExtensions). I haven't tried it yet, but it looks to be a preprocessor for .hs files.
You can do custom build stuff in the Setup.hs. See the `UserHooks` API. However it is a bit clumsy. You get IO and a bunch of data structures and functions from the Cabal lib. It's not exactly user friendly.
I'm eternally hopeful that the native Gtk+/OSX backend will improve. There's several big apps that are apparently using it successfully now: http://sourceforge.net/apps/trac/gtk-osx/wiki/SuccessStories
Hackage hosts all the haddocks that it can build; what else do you mean?
I still don't understand your complaint. Are you _asking_ if docs are hosted on Hackage? Because the answer is "yes". Do you have a problem with what you see? If so it's not clear what. (Honest questions.)
What does "would" mean in your first paragraph? Does it mean you think GHC ought to throw an error, but doesn't? Can you give a concrete example where the error would occur?
[hoogle](http://www.haskell.org/hoogle) and [hayoo!](http://holumbus.fh-wedel.de/hayoo/hayoo.html) are handy for that.
+1 on that. When hacking Perl, 95% of the time I can get somewhere by just looking at the "synopsis". EDIT: Try to figure out regexps by looking at Text.Regex some day, for example!
When I used to use OS X, I would track these projects that were going to do a native implementation. They would all make some decent progress early on, then completely disappear. I imagine there's a loch ness monster awaiting anyone attempting to make it.
I've been bitten by exactly the same types of issues. A year ago I enthusiastically [wrote directions on SO](http://stackoverflow.com/questions/1095778/simple-haskell-graphics-library/1098402#1098402) for getting FreeGLUT and OpenGL to work with Haskell. I came back a few months later and found that later versions of GHC and OpenGL effectively broke a process that I had used successfully twice before, for reasons I have never quite been able to determine. I realize Haskell is bleeding-edge, but these issues are frustrating. I'm glad to see that similar issues are biting programmers more experienced than myself. 
If I didn't hate Windows with such a searing passion I might be persuaded to help. I've seen gtk2hs/wxWindows mentioned several times in these posts. As it stands now, I just get in, cobble things together to get it to build and then shut it down again to return to linux. That's my own barrier to entry in Windows related issues, I guess.
Cygwin's gcc didn't work when I tried it. Stick with MinGW. 
Qt is even worse.
ok, I was thinking about something different. it seems to work, it's weird that pattern-matching on a value of data-type with context brings up its constraints, but using it as-is they aren't brought into scope. and since you can't pattern-match on constructor-less type, it doesn't matter. but you still get a nice comment, that is syntax-highlighted:)
&gt; If you wanted to add an extra step to a build specified with make, or mk, or Ant, or Maven, or MSBuild, or XBuild, or CMake, or SCons, or Franchise, you could add a stanza or two to the appropriate script and be done. To do the same thing with Cabal, you have to hack around with Setup.hs. But, but... Setup.hs *is* the appropriate script to which you are adding a stanza or two.
^ This. Haskell _is_ intimidating to people who don't have a decently deep math background. 
See Duncan's comment about user friendliness. Adding build steps via Setup.hs does not compare favorably with, for instance, adding new rules to a makefile.
Personally, I'd love to contribute, but I keep running into the chicken/egg problem Duncan mentions -- a) I have a cool idea for a project, b) I learn that it will take library X, c) library X doesn't work on Windows without rubbing my package.conf in the juice of the nic-nic bug (and I'm stuck on Windows for most of my day...:P), d) frustration. I realize that my frustration could be solved by finding the people who share my frustration and working on a solution together. But I simply haven't found enough people yet. I've returned a few times to Haskell, and I see a lot of good omens on the horizon. The Haskell platform helps. The documentation gets better. The community grows. I find myself starting to grok concepts that previously confused me, like monads. So I have no doubt that I will contribute at some point, but I'm not quite there yet. 
And hackage 2.0 will/should soon allow upload of haddocks that can't be built on the main hackage server, but do build on participating cabal-install clients.
I think that people posting articles on solving specific problems in Haskell can be a pretty good source of examples. It can be hard to decide on a blessed few canonical examples of a function, so letting google sort it out isn't the worst thing in the world.
Actually, learning Haskell is intimidating to programmers who are deep in the imperative paradigm, no matter how good or bad their mathematical background is. Besides, learning Haskell makes maths less intimidating :)
I've been using it for a while. It has a lot of bugs and is very difficult to build under GHC 6.12 due to dependency building problems.
Haskell programmers generally try and reason with monads or monoids or some variation there of that make it that much harder to have a conversation about a piece of software. This is frustrating when a few conditionals could do the same job I'm known as "the haskell guy" among my groups of friends but i still consider myself fairly conventional about how I write code. Just because you can write a program in the type system doesn't mean it's a good idea.
I would like to contribute but I don't know where to start. Ultimately, I will probably need someone to work with me, but I don't personally know anyone who is willing and able to do this. I know a lot of very beginner haskellers and have spoken to a lot of very expert haskellers on irc. If someone were to say "this is something that you could do and would help, and I'm willing to point you in the right direction a couple of times" I think, long term you would end up with lots of good people (I would like to think that I could be included in this group). TL;DR: establish a mentoring system, where people who know a lot point people who don't in the correct direction. My university society does this, it seems to work pretty well.
And a nice place to collect such simple examples is http://www.reddit.com/r/EnHaskell
Maybe someday when I am smart enough to write good code I can contribute to open source. As it is I bet others would rather not deal with my shitty code and I the world is better off without my code. :-)
I love cmdargs, but I ran into a few issues trying to use it in a pre-existing larger application. Mostly, I want to be able to some base options from a config file, and the machinery to figure out what my flags are isn't exposed. Another issue is that I have some flags I'd like to use that actually affect the help page. For instance I allow a --locale (which falls back on the LC_MESSAGES, LC_ALL, etc. locale) that I use to swap out my usage instructions using gettext. (and another localization option or two to help the compiler locate l10n resources like po files) So to support localization I currently have a tiny getopt pass before i hand things off to cmdargs, and then I build a mode with the appropriate gettext built in. Unfortunately, while this almost works, this doesn't let me localize the messages about verbosity and help themselves, so I'll need to dip into the internals to make it work seemlessly. Other pieces that are currently out of reach using the public cmdargs api: * Auto-generating a man page (huge scope creep I admit) * Having any way to abstract over large blocks of common options. It would be nice to be able to nest them in sub-structures. I currently have to use the c preprocessor to build up a big flat data type. It would be nice to be able to say something like: data CommonArgs = CommonArgs { locale :: String , ... } data CompileArgs = CompileArgs { withExtraLibDirs :: [FilePath] , warningsAsErrors :: Bool , errorsAsFatal :: Bool } data Mode = Install { commonArgs :: CommonArgs } | Build { commonArgs :: CommonArgs } | Configure { commonArgs :: CommonArgs , compileArgs :: CompileArgs } * It would be nice to be able to kick it into a mode that I can use to supply info back to a bash autocomplete script * sub-commands! foo route add ... foo route delete ... That said, cmdargs is a lot of fun. =)
Excellent idea. For suggesting it, I volunteer to mentor you a bit - sm on #haskell.
I would love to have a personal connection to someone who could teach me more about Haskell. I would also love to teach people who know less than me.
&gt; Hackage et al should be considered upstream, haskell-platform should be the equivalent of a Linux distribution. That is precisely what we consider it to be.
&gt; The OSX tax is really very high. :-( Less than £100 for Windows 7 but more than £500 for OSX (mac mini). http://en.wikipedia.org/wiki/OSx86
In what way?
Reminds me of [Objects to Unify Type Classes and GADTs](http://lambda-the-ultimate.org/node/3837)
You haven't really given any examples beyond "they use big words that I don't entirely understand". Monads and monoids are about recognizing recurring (mathematical) structures in your code and factoring out the redundant code. They're powerful structures but are not complicated beyond having scary names. It does take a bit of a mental shift to be able to start thinking in abstract mathematical structures but they're there to "improve code reuse", not to confuse. And writing real code in the type system is pretty rare in most Haskell. We may sometimes try to encode simple invariants in types but in general the type system is not expressive enough to be able to handle our properties effortlessly (and without too much ugly).
I have some small operations tools I'd like to write but there's no way I could ever use them at work unless I got them accepted into Ubuntu or something like that -- so I put it off. Contributing to GHC is difficult. A lot of the stuff they need can only be done with great understanding of compilers and functional programming and its hard to find good examples to work from. I think it might be easy in this day and age to help port stuff to JHC, though, since you can crib from GHC. I once made a tiny little patch to GHC, to allow newlines in the prompt, and it was held up for years (I believe mine was scheduled for 6.12 back when I made it against 6.8). 
Pretty much what they say: the second is the simpler, it describes executing the statement c in state x and ending up in state x'; the Gamma there is a map from function name to function body. The first one is the second where instead of having 1 statement you have a list, so if the first statement returns early (i.e., does something like return or break) then we start on the next one in the stack. As to understanding the paper, I don't know if it makes much sense for you to get all the details unless you are trying to replicate the project; this paper is at an academic conference, so we assume a fair bit. Maybe take a look at [Gerwin's lectures](http://www.cse.unsw.edu.au/~kleing/teaching.html). Hoare logic/VCGs are pretty common in verification, so you might want to start there. I haven't read it, but Norbert's PhD might be a useful intro (I would avoid getting bogged down in the implementation details, though). 
I have to admit, my first reaction is to say that reasoning with monoids and monads and other structures is the point. I'm sure there *are* gratuitous uses of these things, though -- maybe you could point some out?
I don't know the exact number, and it varied over time. There was at one time 5 people doing the core proofs full-time, not counting the large number of people working on the other necessary stuff like parsing the C. It was definitely measured in man years and millions AUD (roughly 1:1 USD at the moment).
So far it seems to be working. Awesome work, guys!
Monoids, monads, catamorphisms, etc. actually make it *easier* to have a conversation about a piece of software; you just haven't learned the language yet. You could think of those things as "functional design patterns."
I've contributed to Haskell projects in the past. I don't anymore because I'm working on a Ph.D and my work for that tends to be disjoint from anything the open-source Haskell community is interested in. In what remains of my free time, I like to do things like singing and going skating that keep me sane enough to go back to work the next week. That, however, is personal whining. On a more constructive level, I do try to submit bug reports when I find a problem in GHC, Cabal, darcs, etc. I don't always, because the amount of work involved in creating a reproducible bug report is high. It's also frequent enough to get a reply saying "that's not really a problem" that I don't have the energy sometimes to risk getting shot down. I don't feel like there's really an attitude in the Haskell community -- and this problem is inherited from the open-source community in general -- that all feedback is helpful feedback. If there were, I'd be a lot more free about reporting bugs. tl;dr: If you want your users to report bugs, then treat them as if you value their opinions.
Clearly foo is a function that splits strings on every instance of the character '☃'. *Edit*: Damn, I misread that signature as just String -&gt; [String]. Now my joke isn't funny :(
I agree -- this is indeed bad. Haskell is such a beautiful language it's a shame to see such poor library maintenance. How can one get the benefits of FP in such an environment? 
Several individuals have been in communication with the GHC developers, as can be seen by the existence of a fix in 6.12. Unfortunately, this doesn't help much for people still on 6.10, so the suggested workarounds are highly recommended if you are running Haskell scripts as CGI.
I've put one or two small packages on hackage, but am intimidated by the Cabal packaging process. I feel like I have to take two hours to figure it out every time. I probably just need a bit more experience with it. 
If you want stability, just use the old library.
does this mean we're mainstream?
GHC --make does the right thing, but SDL does some screwy stuff with the .lib files that GHCi doesn't know how to handle. I think there is already a bug reported for this, but it isn't something I would consider high priority unless using SDL becomes common. This is just blue-sky, but the part for extra directories would be better if Cabal let flags be strings and not just booleans, e.g. `-fsdl-root="C:\prg\sdl-1.12.12\"`, and then the cabal file could have `Extra-Lib-Dirs: $(sdl-root)\lib`. Or else a standardized flag like --external-package-root. And way off into blue-sky-land would be a way for a build to automatically check a few sensible locations, such as `["..\sdl-1.*", "\sdl-1.*"]`.
Any chance for Hackage to provide automatic testing of API versioning? It could auto-detect uploads that break an API, but which haven't properly bumped the version number.
I didn't say I thought I was right, I'm saying it's a problem when standard library code is unintelligent to most people dabbling in Haskell. Factoring out patterns is great, but just like any programming device it tends to get counter productive when overused (think java design patterns). 
Installing wxHaskell on a Mac consists in (a) installing wxWidgets [not relying on the system one, unfortunately] and (b) running cabal install wx. If you're using MacPorts and GHC 6.12.1 you may experience some iconv-related difficulties, but the MacPorts maintainer is well aware of and thinking about the problem. It's fairly easy to work around by just building wxWidgets yourself.
That sounds very reasonable, it could run provided tests for the previous version released.
this post is pertinent to this discussion http://article.gmane.org/gmane.comp.lang.haskell.cafe/73748
Hi Brian, &gt; Darcs is horrible but nobody is willing to move to something better. Example: I &gt; tried to pull GHC so I could contribute some changes to it. Oh dear, I see you did indeed have a lot of trouble. Sorry for that! &gt; I used the recommended steps from its wiki. Downloading the giant tar.gz file &gt; of old patches took forever (slow server?). I have some good news here. Recently, the GHC repository on darcs.haskell.org has been updated to use hashed format repositories, which means that instead of of downloading a giant tarball of patches, you can run darcs get --lazy http://darcs.haskell.org/ghc On my machine (UK) this takes something like 7 minutes the first time I run it. I've also heard reports from people (West Coast USA; does this make a difference?) that it takes 2 minutes for them. In any case, I this is faster so I hope you'll have an easier time at it in the future. Also, aside from the lazy fetching, one handy feature of the new hashed repositories is that what you retrieve is cached, so subsequent gets are instantaneous. We hope to have at least one Google Summer of Code project this year. One of the candidate projects is to improve darcs network performance by (A) making the pristine state available as a tarball which Darcs would automatically fetch (B) introducing a smart server. &gt; Then the Darcs pull failed b/c somewhere it is trying to move a file that is &gt; open. I tried to pull Darcs to fix it and the pull failed because of a &gt; similar issue (attempting to delete an open file, IIRC.) Do you recall what version of Darcs this happened with? If this sort of thing happens again, we would be very grateful for a bug report on http://bugs.darcs.net &gt; I could not download older Darcs binaries because they've been scrubbed &gt; off the internet. I realise you said "binaries" but http://wiki.darcs.net/Releases offers source tarballs to older versions of Darcs. Also, you can darcs get our wiki to find links to older binaries: darcs get --lazy http://wiki.darcs.net cd wiki.darcs.net darcs changes -v Binaries.page | less Sorry, that's a very roundabout way of doing things, maybe you could lend us a hand in making this more nicely organised &gt; The Darcs developers' plan is to solve these issues is to give Windows Unix &gt; filesystem semantics, somehow, sometime. I'm afraid I don't understand :-( We're keenly aware that our Windows support lags behind support for Unix-like platforms. In my opinion, things have gotten better since our Salvatore, our Windows Czar, joined the team, but we definitely have a lot of room for improvement. Unfortunately, our recent Darcs 2.4.x release has run into some mmap-related trouble on Windows. We've restored links to the Darcs 2.3.1 binary for now and are working to rectify the problem. &gt; Regardless, I pulled Darcs from a Linux machine and then fixed the problems &gt; that cause its build to fail (!!!!) on Windows w/ GHC 6.12. I believe these issues have been resolved recently (I'm using GHC 6.12 on Linux and MacOS X). We'd certainly appreciate patches, either by darcs send or via our patch tracker web interface on http://bugs.darcs.net &gt; Then I tried to "darcs send" patches for Darcs and for GHC, but then I ran &gt; into more problems. Oh, argh on that :-( Getting darcs send to work can be tricky because it wants an MTA underneath. For folks who don't want to configure, say postfix or exim, we recommend just using [MSMTP](http://wiki.darcs.net/Msmtp). Better documentation on our part would be good (and a good contribution!) Anyway, I hope some of this has been useful and I'm dreadfully sorry that Darcs could be an impediment to you contributing more to the Haskell community. Please let us know if there's anything we can do to help. 
Haskell has been seen! http://tiny.cc/27hqf
Half the problem he's discussing is that they didn't even change the version number of the library after making API-incompatible or semantically incompatible changes. Using the old library only works if you can say "I depend on any version of this library prior to X."
I agree with the sentiment, but feel the need to point out that Haskell is hardly the first language with this approach.
Catching that given example in code will be virtually impossible in an automated fashion. It is almost literally the most minor change possible to make, from every perspective except the one that actually matters. Anything that "catches" that will "catch" absolutely everything. Which brings to mind the idea of requiring more testing (and building a culture of more testing) and using those tests as the API specification automatically; as long as the tests don't change, your API didn't change. Lacking enough tests to check the API is a bug under this regime. Heck, I'd be willing to call it a bug anyhow. FP and Haskell may _reduce_ the need for testing but it does not eliminate it. Once again, CPAN can provide a good model here. (It really is a good thing.)
Haskell users used to be described as tolerant of backwards-incompatible changes to the language, never mind libraries (I can't remember where I read this but it might have been [The Haskell Road](http://homepages.cwi.nl/~jve/HR/) in the context of the Haskell98 effort). You've turned into a bunch of suits since you stopped avoiding success :-)
Just remember, we saw the instability problem 2 years ago, and launched the Haskell Platform effort to address this -- *required* stability, with long release cycles. However, we're only a few months in, so the impact isn't being felt yet. Wait till we've had 10 years of versioning stability, like the Python core has.
The version number thing is why we need the package version policy and the tool to help us make sure we are following the policy properly.
This is the first step: http://hackage.haskell.org/trac/summer-of-code/ticket/1565
Seems like the author of the article is just bored to death by Java's nulls
With my Cabal maintainer hat on, I'd like to think that I/we do value bug reports. If someone thinks I'm being crotchety or dismissive please tell me quietly. I promise not to bite people's head's off and will try to do better.
Which bits are tricky? Would using `cabal init` and `cabal check` help? Is it the slightly sad state of the user guide?
&gt; gtk2hs... I stopped when it asked me to install GTK, with no link or precise directions. Were you trying to build gtk2hs from source on Windows? That is indeed rather tricky. Presumably you were trying this because the most recent installer for windows is built with ghc-6.10.1 rather than 6.10.4 or 6.12.1.
Sigh. Still so much work to do.
Better yet, don't wait, help out with QA work: CI for the HP, testing, fixing open tickets etc.
hoogle is currently broken
Part of it is how it takes just about as much effort to set up on OS X as GTK does. And part of it is how the widgets never quite fit together right in the native version. Every app I've ever seen has had serious problems with buttons and text widget layout in particular, seriously squashing or clipping them.
I don't think that coupling one's commit bit with a bit of care for others' needs makes one a "suit".
&gt; Part of it is how it takes just about as much effort to set up on OS X as GTK does. qtHaskell or Qt? There are 1-click installers for Qt. Yeah Qt is not Cocoa but it's lightyears closer to it than GTK, the main things being that the menu bar is where it's supposed to be and ctrl-key shortcuts automatically get remapped to cmd-key.
You're so corporate now, catamorphism ;)
I agree, but there's a need to see both sides of the story here. In particular, I strongly disagree with the suggestion to leave old, superfluous names laying around when there are obvious replacements. Instead, bump the version number, document the incompatibility, and move on. Java famously followed the dictum of "no backward incompatibility, at all cost", for quite a long time. That's why instead of declaring an annotation, you declare an "@interface", and other such nonsense. It's also why these days, C# is the easy winner for the best language design in that general space. So... document incompatibilities with version numbers? Yes. Avoid them and keep bad design, or pollute namespaces with a bunch of deprecated names? Please, no.
I really can't wait. It's a great example of practically applying the type system for large scale analysis.
&gt; didn't even change the version number of the library after making API-incompatible or semantically incompatible changes That's not possible. Hackage will reject the package upload. However, people don't necessarily understand or follow the PVP, which prevents these API problems. 
Hylomorphism is still underground and hip. concat $ replicate 666 "FUCKIN INDIE!" (This produces kind of a cool diagonal-stripes effect when you run it at the GHCi prompt.)
a bit offtopic: I find gmane totally unusable. I hope I'm not alone :) The pipermail version is so much more friendly, and the cafe is archived at [http://www.haskell.org/pipermail/haskell-cafe](http://www.haskell.org/pipermail/haskell-cafe).
While I do agree that the Haskell Platform does promote stability, we have to understand that it comes at the cost of stagnation. For example by including the inferior MTL over a more modern approach such as monadLib or the MMTL, we will encouraging lots of new packages to be developed using these old libraries. Network effects will cause a critical mass to be formed around these old packages and we will never be able to move beyond them. The same thing has already happened with the Prelude, and the Haskell Platform is just widening the scope of this problem to more libraries.
I think that the Maybe approach is a bit more sophisticated, because every reference value in Java can potentially be null, besides you can't do this with primitive values, and wrappings for primitive values got their own set of subtleties.
Using dependencies on version ranges like that in a .cabal file is also problematic. Often it doesn't actually break with a version upgrade, but you have a whole lot of packages that depend on very specific version ranges, and they cannot work together because of the too-strict version specifications. I think dependencies on version ranges should be specified externally to the package, and ideally, dependencies should be specified on package signatures, and not versions. This would still require people making semantic changes to their interfaces to change the interfaces' signatures somehow..
too much work at daily job.
The begin is always hard. But for me cabal works great - put my small application on windows/linux - cabal install. For me it is much simple than configure/automake/autoconf tooling.
ratings + comments + marked deprecation
Anyone got the title of or a link to the paper Duncan mentioned?
Yes, that was why. Hopefully the cabalized version will be easier to handle.
Isn't that really an issue with the httpd? Or the lack of an intermediate layer, like FCGI?
I'm trying to remember which one I mentioned. :-) Was it this one? * [Combining events and threads for scalable network services](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.124.2927) by Peng Li and Steve Zdancewic.
On the MTL example, I don't believe it's as bad as you think. We started with the defacto standard mtl package. It being in the platform makes it much easier to synchronise a switch to an improved mtl-alike. It lets us signal to the whole community when to make the switch and in which direction. The alternative is that we have a long transition period when some packages use one and some use another and most authors who don't even know the difference between mtl and the others just ignore the issue. As a smaller example, note that the new platform release switched from QC1 to QC2. I hope this will help to reduce the confusion in this area. Similarly I expect that at some point the parsec3 maintainers will make the argument for the platform to move to parsec3. Then we can all make the switch over a shorter period of time.
I agree with most of this. The way I have always imagined it is that hackage has a low barrier to entry, but that we provide as much quality information as possible and use that to enable users to distinguish the high quality well maintained packages. As for larger scale coherency of the package collection, one metric I'd like to see is whether each package can be installed consistently with the current/recent platform. What I mean is not if it actually builds, but if it is possible to resolve the dependencies for the package in a way that is consistent with the platform. For example, if it's only possible to install a package using QC1, and the current platform uses QC2, then we say this package isn't consistent with the platform. (Note that this covers indirect dependencies too.) With this information we could have a "bitrot report" listing the most important/popular packages that are no longer have deps consistent with the platform. A further scheme I'd like to see is a role of "distro maintainer" for Hackage. These would be people who look at the dependency graph of the important/popular packages and prod maintainers to adjust dependency constraints so as to keep things more consistent. Along with the package maintainers they could look at build reports for packages and help adjust dependency constraints to keep things building.
I disagree because pipermail imposes the arbitrary restriction that threads have to fit into a month.
Is QC2 documented somewhere? It's such a shame that we have many great libraries with nonexisting documentation and no examples how to use them...
Just jump in. I'm pretty sure you'll find that's not true.
Of course, you can always just use laziness. =) data Tree a = Leaf a | Branch (Tree a) (Tree a) deriving (Show) repmin :: Ord a =&gt; Tree a -&gt; Tree a repmin t = t' where (t', m) = go t m go :: Ord a =&gt; Tree a -&gt; a -&gt; (Tree a, a) go (Leaf a) m = (Leaf m, a) go (Branch l r) m = (Branch l' r', ml `min` mr) where (l', ml) = go l m (r', mr) = go r m *Main&gt; repmin (Branch (Branch (Leaf 1) (Leaf 2)) (Leaf 3)) Branch (Branch (Leaf 1) (Leaf 1)) (Leaf 1) 
Is the PVP published?
Yea I noticed that. =( Bad timing on my part to try and talk it up, I guess. Hayoo! still works, but is slower.
Yeah, I hadn't looked too closely before posting, and it looks like this is for traditionally strict languages.
I mean, technically, speaking, you can do the same thing in Java with generics. It's just kind of annoying and painful and generally not worth the effort. 
Due to injectivity, data families are often exactly what you want because they let type inference run 'backwards' from the family to the arguments, whereas with a type family it can't. This makes type inference possible in a number of situations with data families where it can't be done with type families. More importantly there are some classes that can be defined with a class associated data type for which a class associated type doesn't work class Foo a where data Bar a :: * data Baz a :: * quux :: Bar a -&gt; Baz a you can define quux using data families, but unless at least one of those is a data family, the above class can't be defined without lots of newtype noise or other dispatch tricks.
Which ones? All of the languages I can think of make their types nullable by default. Haskell's approach is unusual is that the default is non-nullable types - you have to explicitly step into the world of nullable types.
Yep. Because the last one overflows a fixed number of characters past the number of columns on your screen, you get a curve with a fixed slope, a.k.a., a line. Exercises for the interested reader. Consider the following, and predict and find shapes made by the commas in a console. [ round (1.1)^n | n &lt;- [1..1000] ] [ product [1..n] | n &lt;- [1..100] ] Project: find a list of integers which, when printed out, makes a circle out of commas.
ML, notably. Ada goes out of its way to discourage nulls; you can only use them with unrestricted pointer types. Nulls are strangely popular among imperative languages; they are necessary on occasion, but less than you might think, even without garbage collection, and certainly not often enough to make them the default.
Don't smileys mean what I thought they meant? I obviously needed to supplement it with a sarcasm tag.
If you think that's horrible, just wait until you see the error messages when something goes wrong.
This is the PVP as I understand it: http://haskell.org/haskellwiki/Package_versioning_policy
[They can be quite verbose](http://everything2.com/user/tardibear/writeups/strange+errors)
would you mind explaining what is going on with m here: (t',m) = go t m
Ahh, that's where the magic is. Since Haskell is lazy, "go t m" is (typically) implemented as a thunk which will produce the desired value on demand, and that thunk refers to the value it will eventually produce. Since Haskell's data structures can be partial, this doesn't necessarily lead to non-termination. For a much better, more detailed explanations, Richard Bird's "Using circular programs to eliminate multiple traversals of data" is quite good, though AFAICT it's not available for free online. Wouter Swiestra's "[Why Attribute Grammars Matter](http://www.haskell.org/haskellwiki/The_Monad.Reader/Issue4)" also discusses the repmin problem among others. My article "[Lloyd Allison's Corecursive Queues: Why Continuations Matter](http://themonadreader.files.wordpress.com/2009/07/issue142.pdf)" discusses a similar program; figure 3 uses Richard Bird's arrow-based notation to pictorially describe what is going on.
The subject is a link, click it. Now you should get the nice threaded interface.
very interesting, thanks a lot for the links!
Nice find, BTW :-)
m is being bound to part of the answer produced by the functon and then given to the function as an additional argument. As the function works, it helps compute m, but wires up every location in the tree to point to the same, as yet undetermined answer. Looking at any of the values in the leaves forces the computation to compute the answer, but until then they are all just looking at a thunk. This is, ultimately, the approach used to 'tie the knot' on mutually recursive data structures in lazy languages. In C/C++ or any other struct language if you wanted an infinite list of 1s you'd have to first allocate the first node, probably with its next pointer initialized to null or an undefined value and then mutate it to point to the final answer. In Haskell you can just say ones = 1 : ones which is a much simpler version of the same thing I did here. ones becomes a thunk which when evaluated will give you 1 consed onto itself, and will replace itself with its evaluated answer. The end result (after some fiddly work with the garbage collector removing the intermediate answer) is effectively the same structure you would have obtained in a strict language with much more overt mutation. 
thanks for the info!
And if I were less of a doofus, I would have tested whether it already did it. Indeed, flags can be strings. I was sure I tried that, and it didn't work for some reason. Indeed, reasonable defaults can be tried, since missing directories are a warning and not an error. According to the documentation, I shouldn't be able to use variables in directory names. So the only thing I need to hack is the handling of directory names. It also doesn't handle spaces in directory names properly. (When was Windows 95 released again?) EDIT: and the more I play with it, the more bizarre it gets. Cabal handles spaces in directory names properly, but only if you use double backslashes or single forward slashes to separate directories. If you use *single* backslashes, even in a single place, it fails.
Yes, but point was that I don't like that "nice" threaded interface.
I don't see how that follows.
GIMP and Inkscape OSX packages still rely opaquely on X11 (transparent is OK though, there are a number of gorgerous X11 apps) and look off but are usable. The most glaring inconsistencies are the usage (lack thereof) of the menubar and the mix-and-match widgets (such as Gimp's color choice stuff). Again, fully usable but pretty ugly. I might myself hack at GTK+ on OSX, but not in the near future unfortunately.
in that case please also provide a [link to the post in the pipermail version](http://www.haskell.org/pipermail/haskell-cafe/2010-April/076693.html) so that people could follow it 
touché :)
Top-down vs. bottom-up here seems somewhat analogous to `foldl` vs. `foldr`; in both cases the latter sees only "the current item" and "the result of processing the rest". The uniform linear structure of a list seems to avoid the problems described, though. To extend the analogy, while `foldl` is (I think) generally considered worthless, `foldl'` has practical value. I haven't used Uniplate, but would a strict, top-down traversal have any utility?
It sounds to me like the semantics of `transform'` (which totally ignores memory usage, running time, thunk count, etc.) are the problematic bit. If so, converting from a lazy definition to a strict one certainly won't help, as the strict version of a function will always agree with the lazy version wherever it is defined.
For foldl/foldr in both cases the function processes the entire input list, and while it gives you the accumulated information, it doesn't choose "where to go" based on that argument. foldl is often used to reduce a complex value to an atomic value, so makes sense to operate strictly. transform on the other hand is much closer to a map, mapping a complex value to another, so I don't think being strict would help - it would be like a strict version of map.
&gt; For foldl/foldr in both cases the function processes the entire input list foldr can skip processing the "rest of the list" if the function doesn't use that argument. I don't know if this counts. I suppose transform' goes further and creates the structure to process and in that sense it is different than foldr. 
&gt; For foldl/foldr in both cases the function processes the entire input list, and while it gives you the accumulated information, it doesn't choose "where to go" based on that argument. Like yairchu said, folds do get to make one "choice": whether to discard the already-processed portion of the input. `foldl` can throw out the (already computed) accumulator value, and `foldr` can throw out the (potentially uncomputed) result of processing the rest of the list. But upon further reflection, I think the main difference is that `foldl` doesn't get to *look ahead* at the unprocessed list, whereas `transform'` would. Neither `transform` nor `foldr` actually gets to make any significant choices, being given only parameters for which the recursion is a *fait accompli* and the option to ignore them. The equivalent to `transform'` would be if the folding function received and returned the remaining unprocessed list, with the recursion continuing down the (potentially arbitrarily modified) list, which sounds like a recipe for the same sort of confusing mistakes you observed with `transform'`. So I suppose a sane top-down transform would need to conceal the recursive parameters somehow? It's easy for `foldl` to do that on lists, but it doesn't seem to generalize well. &gt; foldl is often used to reduce a complex value to an atomic value, so makes sense to operate strictly. transform on the other hand is much closer to a map, mapping a complex value to another, so I don't think being strict would help - it would be like a strict version of map. Which is why I mentioned that I haven't used Uniplate, and thus don't know what the normal usage of `transform` would be; so, my apologies for the naive questions. I'm not sure I see the analogy to a map, though--it sounded to me like `transform` is for substituting arbitrary functions in place of constructors, which is pretty much the definition of a generalized right fold.
That's a pretty bad choice of name, indeed. The author likely didn't consider anything about what to name the library. Perhaps we should have a guide.
Hi, That sounds bad. I should be responsible for that name. The name was picked based on the original (internal) project name that we've been using. @don, pls kindly share the guide-lines and we can migrate the library. Kenny
Hey Kenny, Well, we need to think a bit about what a good naming convention is. But by the sounds of it, it shouldn't contain the words 'haskell' or 'library' :-) Something to do with regex, perhaps. E.g. regex-tdfa regex-parsec regex-pcre are all existing packages. So this is regex-???? and you pick the distinguishing characteristic. I propose: regex-derivatives Sounds cool, no?
Yes, regex-derivatves is a fine name for that package. Is there a procedure in place for renaming packages in Hackage? 
Thanks, I will think along that line.
This is a good example of the point I keep making on this issue. In this example, LLVM is having to do a lot of analysis and heavy lifting to do something that would much better be done by GHC at the STG -&gt; CMM layer. It would be both cheaper and more reliable. Simon M says essentially the same thing: &gt; &gt; 1) Does it still make sense to pursue these optimizations in the native &gt; code generator? &gt; &gt; Well, this transformation is something that would be done earlier than the native code generator, probably as part of the STG-&gt;C-- phase or in one of the phases that follows it. It's important that we still do transformations like these in GHC, even if in some cases LLVM can figure out how to get the same results on its own, because in general we have more information than LLVM and can make more informed decisions. A good example of this is the fact that in GHC we know that stack and heap addresses cannot alias, whereas LLVM cannot know that (is there a way to tell it?).
I think that breaks referential transparency... might as well just start a new project with a new name.
In the ruby world we have names like unicorn, mongrel, and sinatra. None of them give you very much information but in the end are easy to remember once you know what they are. Mario on the other hand is well named http://github.com/johnbender/mario ( my own :D )
I got my start in Haskell from the Gentle Introduction and a book on SML. True story. Though it was massively helpful when Richard Bird's "Introduction to Functional Programming using Haskell, 2nd ed." came out. 
This was an unbelievably helpful reference when I was first learning. Of course, I recently read LYaH, and I wish I'd read it first. I wonder if it's as good an introduction as I imagine it would be.
Now children for your bedtime story, and it's as gentle as a wounded scorpion.
Yes, but wouldn't you think it stupid for a ruby library to be called xruby-library? 
Yes, upload under a new name. Hackage does have limited support for marking packages as deprecated or superseded by another. The only way currently to mark them as such is to email Ross and ask him to do it.
funny thing, this package was [listed on reddit](http://www.reddit.com/r/haskell/comments/bvppd/regular_expression_matching_using_partial/) not long ago. If it were to follow the convention of the other regex packages, it should of been named regex-PDeriv (beacuse the modules are named Text.regex.PDeriv .)
Our java project has a thing named "service", and a stupid "service layer". So we have some signatures like: com.xxx.xxx.service.ServiceService.findAllServicesByServiceName(ServiceName serviceName)
Thanks for giving me my first chuckle of the day.
Wrong conclusion - no Linux users are using darcs 1.*. I am a Windows user, and have darcs 1.0.9 on at least 8 machines.
Note that the recommendation from the darcs team under most circumstances would be to move to hashed repos with darcs 1 patch format, as opposed to the darcs 2 patch format. See http://wiki.darcs.net/DarcsTwo#three-upgrade-sizes
Why not upgrade to darcs-2.3.1?
I think you've explained it better than I have :-) I think of transform as more analagous to map since you're mapping from a type, to a value of the same type. But you are right, it's much more like a right fold in the way it operates.
Uniplate also provides a function 'rewrite' which applies a function as long as possible instead of only once like 'transform'. Although it is not stated in the documentation, 'rewrite' also works bottom-up (it is defined in terms of 'transform'). I once wrote a lambda-calculus interpreter using Uniplate by writing a 'step' function which implements a single reduction step. Using 'rewrite' I could apply the 'step' function repeatedly until a (head-)normal-form is reached. I noticed that 'rewrite step' performs innermost evaluation and that there is no top-down variant of 'rewrite' to perform outermost evaluation. I had to define my own top-down variant of 'rewrite'. Although I understand Neil's reasons, it's funny that outermost rewriting is not supported out of the box by a Haskell library for generic programming ;)
We can argue about styles, but Yet Another Haskell Tutorial is by far the best Haskell learning resource I could found.
Thanks everyone for your suggestion here. I've renamed the project to 'regex-pderiv' instead of 'xhaskell-library' in hackage. Now is there a way to remove that 'xhaskell-library' page or redirect it to 'regex-pderiv' on hackage? Kenny
In a sense, `transform` is like a `foldr` with side effects: the remaining list to be traversed can be mutated on the fly. (Not that anyone would want to have such a thing for lists.)
Seconded.
Ah, having rewrite' would make sense - the problems with ordering and predictability go away if you are applying the transformation to a fixed point. In general, I find very few people use rewrite, transform/descend/universe/descendM/transformM are the standard ones - everything else tends to be a bit more specialised.
Darcs and Windows don't play well in many versions - I found one that works, and now I'm loathe to move. I have tried to move a couple of times, but something always gets worse.
i always tell people about gentle intro when they ask about learning haskell and then RWH of course
Another very similar point that I've been on the verge of writing down for the haskell mailing list is announcements about libraries particularly ffi bindings. The number that say something along the lines of: Announce: hxyz Haskell bindings for the xzy library or Announce: Harrots Haskell bindings for the carrots library. Yeah okay fine, but just give me a one sentence summary of exactly WHAT the xyz or carrots library DOES. So that I don't have to google it and find out it has no interest for me or worse I don't google it and miss a good chance to reuse and existing library for something I require. phew, sorry rant over.
Ok. I've sent an email to Ross. Kenny
You should add a factory. Makes it more enterprisey.
ServiceService sounds like a factory service.
[well...](http://en.wikipedia.org/wiki/XRuby)
I don't actually think it's too horrible. It's also not fair to compare the compile time implementation in C++ to the runtime implementation in Haskell. 
Yeah, asking people to wait 10 more years... :-) I'm finding Haskell, despite some issues with mature and controlled packaging updates for some cases, typically is still a faster turnaround time for complex coding tasks than many alternatives.
(Maybe Int) is roughly similar to (int *) in some other languages. The biggest difference is my runtime doesn't crash on me when I attempt to perform certain computations with a Nothing :-). 
There seems to be a lot of use of Darcs 1.* as recent as this February. I wonder what caused this spike. Maybe plot legends shouldn't appear as plain overlays on the graph but either outside the rectangle or in a distinctive frame. 
We should make sure YAHT and the GIH are more easily accessible. Or updated for modern times...
With LLVM's forthcoming metadata abilities, this sort of information can be embedded in the IR, and the optimization passes need only be extended to handle this extra info.
Worse than *no* information, the library being called `xhaskell-library` makes me think that it's an X11 library, so it's explicitly *wrong* information
Trust me. It should be IService service = ServiceService.getServiceFactoryService().createFactoryForServicesByGroup(ServiceGroup.ENTERPRISEY_SERVICE).getServiceByName(name, ServiceQuantityControl.SINGLETON) All we need now is a webservices layer and I think we are done.
Haskell /= Java, you mean!
You're certainly not downloading xmonad, by the looks of it. Also, note that darcs 1.0.9 is full of bugs, slow and old :/
I'd ask 'file' which it is, but...
Valid Java: x &gt;&gt;= 1; Do improved heuristics have a point? In any case, you could pass in a polyglot program and make it tell you lies (or partial truths).
Passing queries as arguments is something that the RFC explicitly says that you can do, so I assume it's something that many servers *will* do. And yeah, if you're running FCGI or whatever, you're safe.
&gt; Though it was massively helpful when Richard Bird's "Introduction to Functional Programming using Haskell, 2nd ed." came out. I loved that book.
That is interesting. I have actively used Darcs in Windows XP for at least 4 years, always the latest version available. I never had serious problems. Lately I have been using it with Vista, also without problems.
I am designing a DSL just for that called Ponzi. 
You can always make file lie; just toss in a magic number. 'Oh, I didn't mean that #! to be there as part of a shell script, it's there as part of a tutorial on scripting.' Is there anything interesting in that point?
I've used 'rewrite' frequently when writing code transformations. Whenever I wanted to apply simple rules as long as possible, like eliminating "case-of-case" expressions or inlining non-recursive functions, something like 'rewrite' was quite handy. I believe to remember that many of my programs which transformed code had the form 'rewrite something'.
I hope you're not going to charge much, we're not madoff money you know.
&gt; candidateFactors :: [Integer] &gt; candidateFactors n = takeWhile (\x -&gt; x*x &lt;= n) primes Does not type-check.. said here because there's no way to leave a comment in the original post.
Of course, the conjugation of verbs can be very subtle, and one understands that the code meant here is only trying to address the simplest case; but, as an answer to both “How *would* one (start to) solve the general problem?” and the author's implicit question “What would this look like in another (programming) language?”, see [Lingua::EN::Conjugate](http://search.cpan.org/~rwg/Lingua-EN-Conjugate-0.310/lib/Lingua/EN/Conjugate.pm). (If you want to know what it would look like in another *natural* language, you can consult [Lingua::IT::Conjugate](http://search.cpan.org/~acalpini/Lingua-IT-Conjugate-0.50/Conjugate.pm), and probably any number of other languages found by searching for ‘conjugate’ on CPAN.)
To my rather great surprise, copy-and-pasting `[ round (1.1)^n | n &lt;- [1..1000] ]` produced the same output as `replicate 1000 1`. Can you imagine why this would be? I'd love to blame it on a typo, but I literally cut-and-pasted. What makes even less sense to me is the simple Prelude&gt; (1.1)^8 2.143588810000001 Prelude&gt; round (1.1)^8 1 EDIT: Parentheses: `round ((1.1)^8)` is the beast one wants.
And a big thank you to everyone that sent a proposal that didn't get accepted. We got many high-quality proposals which we unfortunately couldn't all get accepted. Last year Haskell.org had 5 slots, this year we're back up to 7. This is despite the growing number of organisations participating in GSoC and the mostly constant number of available slots.
Isn't that name a bit derivative?
Not really. Sure, you can make a Maybe&lt;String&gt; object, but what stops *that* object from being null? That's not solving the problem; that's just shifting it back a layer.
Well, the same could be said for undefined in Haskell, no?
I agree that the metadata annotations in LLVM offer some interesting opportunities, but the biggest challenging is going to be passing the information along in a way that is actually useful. As dcoutts points out this particular transformation should probably be done at a higher level. While it could be possible to pass the relevant info down to the LLVM level, you still have the problem of maintaing and propagating the metadata through all the LLVM transformations. All of the built-in LLVM passes are not written to ensure the metadata doesn't get invalidated at some point. That said, I'm really interested to see how much we can leverage all of the LLVM infrastructure, and what new opportunities it offers.
The simplest solution is to simply return a list of eithers instead of an either of a list. As in: lerfendi :: String -&gt; Reader ConfigType [Either String a] That will require a conditional branch on each element though, so if performance is very critical this will be bad. Unfortunately, the only way to avoid that performance penalty while still allowing for lazy processing is to use IOExceptions, which makes for ugly, impure, hard to debug code. If you look at the Data.Binary code, thats exactly what they did.
This is a fun post, I really enjoyed it! You can easily make the *pastForms* function much more complete using resources such as this [online list of irregular verbs in English](http://www2.gsu.edu/~wwwesl/egw/verbs.htm) from the Dept. of Applied Linguistics at Georgia State U.
Well, if you really are looking for a more sophisticated approach, look at [GF](http://code.haskell.org/gf/), the Grammatical Framework. That is a huge international effort, funded by the EU, to develop true high-quality machine translation between many human languages. Much of the programming aspect of the work is based in Haskell. Complete grammars have already been specified for 15 languages. Many more Haskell resources related to Linguistics are on the [wiki](http://www.haskell.org/haskellwiki/Applications_and_libraries/Linguistics).
Try attoparsec with iteratees? http://gregorycollins.net/posts/2010/03/12/attoparsec-iteratee
There's also this approach: data Stream a b = Elem a (Stream a b) | Error b lerfendi :: String -&gt; Reader ConfigType (Stream a String) That still involves a per-element conditional, but it's possibly easier for the compiler to optimize, and at any rate semantically cleaner when errors are nonrecoverable.
&lt;SELF-PROMOTION&gt;parsec 3.1 + iteratee: http://hackage.haskell.org/package/iteratee-parsec&lt;/SELF-PROMOTION&gt; I'm not quite sure about the gain of speed in parsec 3.1 + iteratee (I seen benchmarks showing that 3.1 is as fast as 2.1) - and 3.1 seems to work similarly to attoparsec (continuations).
Even being out of date, I used YHT to supplement my understanding from RWH so it was quite helpful.
Reader over Writer over Maybe seems like a fine stack to me. If you handle it properly (i.e. with newtypes, etc) then it shouldn't feel more complex or clunky. Whenever you have an error, then `tell` it, and whenever you can't recover, return Nothing... that way you distinguish between failure and messages.
Try http://hackage.haskell.org/package/uu-parsinglib :)
Interesting thought. I think the answer is no. In Java an object can be null, it can be checked for, and it's usually handleable (by treating it as some sort of empty object or something). If a reference is undefined in Haskell it's usually (?) an error and I don't think it's possible to check for. I could well be wrong about this, of course, and I await enlightenment.
What's the advantage of using JSON over Haskell's native automatic serialization (read, show)?
Half the time the problems were with wget/curl not being installed, being the wrong version, wrong type of ssh etc.
Immix is pretty awesome. Look forward to seeing that one.
It is possible to check for some bottom types with hacks, but it's not recommended. But you are true in saying that hitting an undefined is almost always an error. This makes it easy to look for: just search for "undefined" or "error".
In my experience, huge amount of memory consumption with parsec is often a sign of some lazyness-related issue. So you could try and look for that. You can also try to set a small stack (eg. +RTS -K256k) and run the parser on a (very) large input; if you got a stack overflow, then most probably there are unevaluated thunks growing somewhere.
oh that's really insightful. can you please repeat, how to add two numbers?
I'm a little worried about switching to a different tool and hoping that'll solve everything without me having to think about my code. It's not like I haven't tried that before, but... :-)
&gt; social Hackage 2.0! :D
I'd look for tutorials on left factoring grammars in general, as a way to think about how to eliminate/reduce backtracking. a quick google gives, e.g.: http://en.wikipedia.org/wiki/Left_recursion http://theory.stanford.edu/~amitp/yapps/yapps-doc/node3.html http://www.zenspider.com/Languages/PCCTS/LR2LL.html among many other hits. 
Good job :) Skimming through the list of accepted organisations I nearly had a nerdgasm imagining installing ghc-llvm on a Haiku machine. Two times seven plus five slots for a couple of worthy projects.
you're parser is really long, do you run a lexer as well?
Mark Carroll is the Elmer Fudd of computer science.
I took my first baby steps in functional programming with [A Gentle Introduction to ML](http://www.dcs.napier.ac.uk/course-notes/sml/manual.html). Looking over it now, it still looks quite good.
In my opinion, comparisons of this sort can only be good for the Haskell community in the long term. Distributed computing is, as far as I am aware, a weak area for Haskell, but it doesn't have to be that way. Most of the advantages Haskell has over Erlang are in the core language (performance, static typing, nice syntax), whereas the main advantages Erlang has over Haskell are all the things that the libraries do to make life easier. The interesting thing about that is that Haskell is in a much better position to subsume the functionality of Erlang* than vice versa, assuming there's sufficient interest in the community to do so. It's easier to add new libraries than change the core language. For those of you who haven't tried Erlang, I highly recommend it. I used to be dismissive of Erlang because of performance, and my argument went something like this: "What good is it to have a language that scales to hundreds of nodes, if it's 50 times slower than native compiled code? It seems like I would be better off with a couple of servers and a faster language." Now, I see that I had missed the point - many distributed computing problems are fundamentally IO bound, rather than CPU bound, and if I can implement a server in the fraction of the time, that is often far more important than whether the CPU is 90% idle or 99% idle. * some of the dynamic code loading features of Erlang may be an exception.
Can you move away from String parsing to bytestring or text?
These kind of articles are very difficult to write without invoking flames -- it is a testament to jlouis' care and consideration that there are very, very few disputed results here. I can't think of a cross-language comparison in recent times that had less controversy, and more meat, than this article. Well done!
His aim is to hunt Bugs, but he usually ends up seriously injuring himself and other antagonizing characters?
I was going for fumbling and goofy, a self-important buffoon, etc.
&gt; your language of choice *facepalm*
I find it very hard to accept the whole "Let it crash once a day" notion. What if these rare bugs result in a worse bug? Due to the [Principle of explosion](http://en.wikipedia.org/wiki/Principle_of_explosion), these rare bugs can become far worse than what you would expect initially. 
Can someone please help me understand that post? What exactly does the author mean by saying that Scheme and SML have a "formal definition" while Haskell does not? Furthermore, one of the comments takes it for granted that this means that Scheme and SML have "formal semantics". If "formal definition" means syntax, how is the Haskell Report, and for that matter the Python Language Reference, less formal than R6RS or whatever SML has? And if it means "semantics", now I am really confused. Operational semantics seem totally irrelevant for a DSL whose entire purpose is to denote the meaning of something. And in my meager understand of the subject, I thought that it is still an open research question how to go about defining denotational semantics at all for an imperative language, with recent progress using monads. Whereas for a pure language it's rather straightforward.
Nice initial result. Good luck with the GSoC project!
What [pony-ful](http://www.djangopony.com/) Haskell web frameworks are there to put this to use with?
I'm hoping to do some happstack or hyena integration. But it should be usable in a pluggable way.
I guess I was looking for more meta-level advice than that. sclv's comment was on the mark in that I realized I had not only a lot of explicit backtracking, but some implicit backtracking from my use of functions like identifier and reserved (from the TokenParser module in Parsec). Once I started left-factoring my grammar, I realized I was losing all the modularity advantages of Parsec and that it would be easier to bite the bullet and switch back to using a Happy parser. I'm afraid that most of the other comments I've received reflect the "switch to a different technology and cross your fingers that it'll work rather than examining your underlying algorithms" approach to performance. Which I know is tempting, but has never served me well. I've had the same experience with generics libraries. Anyway, that's rather off-topic of me :-)
?
Kudos for making my homework more bearable!
After the amount of [Robot Unicorn Attack](http://games.adultswim.com/robot-unicorn-attack-twitchy-online-game.html) I've been playing, that theme looks awesome.
Meta away. It's good advice. Until you know what's really going wrong, you can't know _which_ tech you should switch to, if there's several. &gt; A novice was trying to fix a broken Lisp machine by turning the power off and on. Knight, seeing what the student was doing spoke sternly: "You can not fix a machine by just power-cycling it with no understanding of what is going wrong." Knight turned the machine off and on. The machine worked.
-XMakeSense just kidding.
So you could use it with [Hamlet](http://docs.yesodweb.com/hamlet/)? If so, Haskell webprogramming starts to look pretty cool!
maybe -XParametrizedModules
-XEquirecursiveTypeSynonyms Would add an `equitype` keyword to the language and allow you to write equitype Mu f = f (Mu f) and would somehow coexist beautifully with existing type synonyms, letting the compiler still "occurs check" them.
-XDoWhatIWant
Seconded. module Foo a b (bar, baz) where import Quux Int as QI import Quux Double as QD I'd also like to see improved record syntax, perhaps even inline modules (per-record) to allow name conflicts.
-XKindPolymorphism
-XBetterRecords
So a type constructor defined by `equitype` is equivalent to one defined through `type` except it blocks the occurs check somehow? Do you have a use case?
Then maybe: module Map a where -- ... module Map Int where -- Specialized module 
 module family Map a where ...
-XExcludedMiddleInstances not instance Monad Tree Tree is not a monad (compiler knows it). -XAlternativeContex func :: (Monad m || Functor m) =&gt; m Int -&gt; m Int func || Functor m = fmap (+1) || Monad m = liftM (+1)
Yeah, and the main use case is to be able to play with fixed points of functors without having to struggle with constructors/destructors of the typical newtype Mu f = In { out :: f (Mu f) } 
-XClosedTypeClasses (or Functions/Families)
What would it use if your m was both a `Monad` and a `Functor`?
-XWeakInstance weak instance Monad m =&gt; Functor m where fmap = liftM weak instance Monad m =&gt; Applicative m where pure = return (&lt;*&gt;) = ap Overriding instances have to be equivalent (may be more efficient).
Also see all the wonderful papers on [Strand Space](http://www.mitre.org/tech/strands/)!
Extensible records/variants, uniqueness and/or linear types, kind polymorphism, first-class existentials, closed classes/families, or patterns, empty case statements, datakinds, parameterized/higher order modules...
It would use the Functor. As in if both a and b are true in: func | a = ... | b = ...
I don't think you could use it with hamlet. Hamlet is another, different, option for html generation. One could port hamlet to use blazeHtml as a backend, I imagine, but I don't know quite what the point of that would be as hamlet's backend appears to be straight Text at the moment, which is already fine. The idea is rather that this would be a replacement for the html combinator library, as distinct from templating (hamlet, hstringtemplate, bravo, chunks, press, &amp; co) and as distinct from the *sp model of inlined code (hsp). Edit: Ideally, and generally for Haskell libs, the choices of persistence layer, html generation library, dispatch model, and server layer are largely orthogonal. Strong typing makes any ad-hoc plumbing a breeze.
-XTypeLambda might allow partial application of type synonyms and families. This would break inference but could be useful to make more expressive type-level programs
-XTotalHaskell
-XActualExistentialQuantification (would enable `exists a` as a counterpart to `forall`)
-XFirstClassRecordUpdates
-XDoWhatI*Mean*
Oh dear. Well, duplicating a few of other people's suggestions, here's what I'd wish for: {-# LANGUAGE GADKs #-} {-# LANGUAGE KindPolymorphism #-} {-# LANGUAGE FiniteRecursiveTypes #-} {-# LANGUAGE ClosedTypeFunctions #-} {-# LANGUAGE NegatedContexts #-} {-# LANGUAGE InstanceGuards #-} {-# LANGUAGE TotalFunctions #-} ...which is roughly asking for a combination of "let me make the type system more demanding" and "let me write more arcane types so that I can still get stuff done". As ridiculous as the above is, I might as well go all the way: {-# LANGUAGE DependentTypes #-} At which point someone will probably suggest that the extension I'm actually looking for is: {-# LANGUAGE UseAgda #-} Ah, well. Oh, and to be completely frivolous: {-# LANGUAGE UnicodeSyntaxLambda #-} Why does λ have to be a letter. :(
-XSolveHaltingProblem
-XNestedGuards as in: p | g1 | g2 = e1 | g3 = e2 | g4 = e3 (the guards have "fall-through" semantics)
The idea is tightly bound to the concept of "crash early, crash often". Once an error happens, kill everything related to it and restart the task at hand. The idea is to stop the error propagation as early as possible (before any kind of data or state can be corrupted and whatnot) and start from a correct state. This is why it is always strongly advised to only program for the correct case in Erlang, and to avoid all kinds of defensive programming -- only fix what you know how to fix. The idea is that by letting faulty processes crash as soon as possible, you get very little negative side effects and also clean logs pointing to exactly where the error is. If you want to read a bit more on it, I suggest you read thise [blog post by Mazen Harake](http://mazenharake.wordpress.com/2009/09/14/let-it-crash-the-right-way/) 
I believe there are feature of other languages that might be relevant here... some kind of standardized meta language, perhaps.
This is pretty much -XUseHugs. The [Trex](http://web.cecs.pdx.edu/~mpj/pubs/polyrec.html) system from Hugs was also [written up](http://research.microsoft.com/en-us/um/people/simonpj/papers/records.htm) as a general Haskell feature by SPJ, but was never actually implemented.
Sounds like what you really want is [-XClassAlias](http://repetae.net/recent/out/classalias.html)!
[-XHaskellTypeConstraintsUnleashed](http://tomschrijvers.blogspot.com/2009/11/haskell-type-constraints-unleashed.html) :p
I'd like `-XClosedDataKinds`, which requires `-XKindPolymorphism`, and `-XLocalInstances`, although it would horribly break the current type family infrastructure. I'd also like to see phantom data types have a kind other than *; that would also need kind polymorphism. `-XFiniteQuantification` as in `forall a in { Int, Char }. Foo a -&gt; a. Without this, the types of most functions involving GADTs are lies. For example: data GADT a where Foo :: GADT Int Bar :: GADT Char Baz :: GADT Bool partial :: ? -- forall a. GADT a -&gt; a partial Foo = 0 partial Bar = 'a' 
I understand - and I agree it is a good approach to handle unexpected bugs. But what I disagree with is considering those bugs as acceptable and not worth fixing...
&gt; As you can see from this signature, we have some code here that some people would consider “not elegant”. Those people include me. However, we must not forget that efficiency is our main goal. Besides, these functions are not exported to the end user. Implementations are allowed to be inelegant in order to implement elegant interfaces efficiently.
&gt; One could port hamlet to use blazeHtml as a backend This seems like an interesting option, and not too hard to implement. I spoke about this with the author of hamlet before, and he seemed interested.
+1 Every year, some student spontaneously comes up with this notation while learning basic Haskell in a 3rd year course. 
... as long as there are no bugs.
-XSymbolicComputation Prelude&gt; 3*(2+x) 6 + 3*x 
That can be done with `x`'s type being some suitable `Num` instance, right?
You can have phantom types with kinds other than * using -XKindSignatures: {-# LANGUAGE KindSignatures #-} data Phantom (a :: * -&gt; *) = Phantom x :: Phantom [] x = Phantom
Great stuff!
The type isn't really a lie, in the same way that "all cows on the moon are green" isn't a lie.
 {-# LANGUAGE PartialTypeSignatures #-} foo :: Some (Involved (Type ?))) -- ? is to be inferred
Would it be possible to build a finger tree around nodes that could only hold 1,2 and 3 children rather than 1,2,3 and 4? It seems like you'd still retain the amortized rebalancing properties.
Duncan, this looks very interesting. Is the intention specific to parallel code that is pure (dph, par annotations, etc), or aimed at concurrent code too, using forkIO, STM, and other fun?
Both/either, with the focus dictated by what people actually want to use.
http://twan.home.fmf.nl/blog/haskell/simple-reflection-of-expressions.details
brilliant, thanks
&gt; Why does λ have to be a letter. :( http://hackage.haskell.org/trac/ghc/ticket/1102 Basic summary: the lambda is a lower case, so the term 'λx' parses as an identifier rather than the beginning of a lambda term, and no other symbol currently supported has this property. So in short: it just complicates the grammar and parser.
Indeed. (Note that the FP language Clean does have nested guards)
This is possible already without being too much more ugly than explicit support: -- would have written: -- foo :: Some (Involved (Type ?)) foo | False = undefined :: Some (Involved (Type a)) foo = ... But this allows additional class constraints on the type variable 'a', which your notation doesn't suggest. Here is how you do the same for more type variables: -- bar :: Maybe ?? -&gt; ? -&gt; Some (Involved (Type ?)) bar x y -- it gets uglier to say some type variables are equal | False = (undefined :: y -&gt; Some (Involved (Type y))) y -- or to constrain multiple variables | False = undefined $ x `asTypeOf` (undefined :: Maybe x) bar x y = ... Tool support (ie for haddock) would be nice for cases like these. 
What are empty case statements good for? And you mean (case x of {}), right?
If you're going to object to a proposed language extension just because [Oleg found a way to emulate it](http://okmij.org/ftp/Haskell/types.html#partial-sigs), we're going to run out of language extensions real fast...
On the other hand, he's pretty up front about admitting major mistakes, and his explanations tend to be rather good (when correct). Sure, he's no [sigfpe](http://blog.sigfpe.com/), not even up to isomorphism--but really, who is?
They're a conceptually cleaner alternative to using `undefined` when you want to write functions with empty domain types. For instance: explosion :: Empty -&gt; a explosion x = case x of {} GHC has EmptyDataDecls (although there are other ways to get them if you have GADTs), but not the corresponding empty cases. As another data point, some people want -XTotalHaskell. That plus EmptyDataDecls (or GADTs) requires empty case expressions for functions like the above (because `undefined` isn't available).
Here are three that I can think of. They may be misguided or represent some faulty notion of how things work, or perhaps they already exist in some form. -XTurnOffLazinessInThisModule I suppose this may be controversial, so let me just say that I think laziness is a good thing most of the time, but sometimes it would be nice to be able to just turn it off entirely without adding strictness annotations everywhere. -XUnboxMultipleConstructorStrictFields It should be possible to unbox types like "Maybe !Int" or "Either !Int !Int". It should just allocate as much space as the largest constructor needs, like a C union. -XFailIfBangPatternHasNoEffect It should be possible to tell ghc not to compile some bit of code unless it really can make the thing next to the bang pattern strict. If nothing else, this would make it easier to figure out which bang patterns are being ignored.
I think the approach works for high service availability systems, where a few users getting burned is far less of a problem than taking down the whole system to fix it. Think telecoms switches (a few people end up having dropped calls) or instant messanging (occasionally not delivered messages). So when availability is more important than correctness. Now, you wouldn't take this approach on the space shuttle.
overloaded infix operators might be cool, as would the mentioned todos of higher order funcs and loop detection/unrolling. having a type system is definitely awesome, but otherwise I don't see an increase in expressiveness. Then again I haven't tried this yet. 
In what situations do you think it ignores bang patterns? `seq` works on every type, and actually has an effect. This is even the case for functions, so: foo, bar :: (a -&gt; b) -&gt; c -&gt; c foo f x = x bar !f x = x -- foo undefined 5 = 5 ; bar undefined 5 = undefined
Yes: Do it multi-pass. First tokenize, including the amount of following indentation in the newline-tokens, then replace newlines with explicit nesting tokens, then parse the resulting token sequence. (While you're at it, consider adding explicit nesting to your grammar, like Haskell's {;}) Or something like that, it's been a while since I did it. In any case, don't use state, it's only going to get you into trouble.
I have some old layout combinators that might be useful for you: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=25224#a25224 IIRC, they might do tokenization a bit differently than the stock tokenizers (I don't recall how they handle surrounding whitespace), so you may have to use them with some care. Non-offside newlines, comments, etc. all get collapsed into the whitespace and multiple spaces become a single ' ' token. The main combinator of interest is 'laidout' which runs a parser on each of the ;/virtual semi-colon delimited statements in the layout section. There may also be some niggling differences from Haskell layout, as this was designed for a very similar, but different language.
This of course requires some extra state to keep track of indentation level, so don't forget that Parsec is a modified State monad, and provides `getState` and `putState` to store user-defined state values.
There's no need for parsec state, you do a vanilla recursive descent on the resulting token stream, and I wouldn't do the transformation step in parsec. In fact, I found the source, and I didn't. http://gist.github.com/384677 To warranty whatsoever, especially fitness for any purpose :) I wrote the whole thing when starting out with Haskell and never even bothered to write an interpreter for it. It's a nice syntax for lisp if you're allergic to parenthesis, though.
Ah, fair enough--I was thinking of a parser I wrote that had a more elaborate system. I suppose I probably could have done something similar to yours, but (at least at the time) it seemed more straightforward to track the indentation as I went--essentially spreading your `lines` function out through a somewhat convoluted tokenizer. ...in hindsight that may have something to do with why I got fed up and abandoned the project. Hm.
Impressive work, but am I the only one uncomfortable with the name? Perhaps 'QuickSort' made such names socially acceptable in computer science, a name that only works now because everyone is numb to hearing anything but an abstract symbol. There's no exit strategy here, like the unfortunate term 'Modern Art'. Here's hoping that future namers avoid the cheese, and show more restraint.
&gt; In what situations do you think it ignores bang patterns? I think he means situations where it is infered as strict already, so adding extra strictness annoations have no additional effect.
-XInstanceMethodsTypeSignatures as in: instance Monad Maybe where return :: a -&gt; Maybe a return = Just (&gt;&gt;=) :: Maybe b -&gt; (b -&gt; Maybe a) -&gt; Maybe a Nothing &gt;&gt;= _ = Nothing Just x &gt;&gt;= f = f x 
-XConstraintSynonyms as in: constraint Num a = (Additive a, Multiplicative a, FromInteger a) and: -XConstraintSynonymFamilies as in: class Functor f where constraint Inv f e = () fmap :: (Inv f a, Inv f b) =&gt; (a -&gt; b) -&gt; f a -&gt; f b instance Functor Set where constraint Inv Set e = Ord e fmap = ... Both are described in [the paper](http://tomschrijvers.blogspot.com/2009/11/haskell-type-constraints-unleashed.html) 
-XExplicitSpaceAnnotations: Basically, every parameter of every function would have a space complexity annotation, with a default of O(1). If the compiler cannot guarantee that the function (or function application) will have a space complexity less than or equal the noted complexity, it issues a warning.
Or, perhaps, when we make an html library that is 10x faster, we simply explain that the "Blaze" in "BlazeHTML" merely means that it is capable of generating the blink tag, or that it can generate pages in firey, blazey colors.
I wished, porting SWT to Haskell would be possible. http://reddit.com/r/haskell_proposals/comments/9w7nk/adjust_the_swt_binding_generators_for_haskell/
Its fun to do so, but you basically give up most of the benefits of type checking once you ditch the occurs check. All sorts of crazy things start to unify.
The big headache with this proposal is that another instance coming into scope changes the meaning of your code, but I have a ton of code that can work more efficiently on a group, but could accept a monoid, that this would be perfect for.
or perhaps he was thinking of something more like -XFailIfUnpackPragmaHasNoEffect which would be a useful thing 
Some form of smart -XUnpackEnums would be kind of useful to let you say: data Foo x = Foo {-# ENUM #-} !Bool {-# ENUM #-} !Ordering unpacking via fromEnum/toEnum.
Rather tongue in cheek: -XDependentTypes to just stop beating around the bush. ;)
Hrmm, this seems to require that | be the first token in a fresh optional layout context for it to work, and I have no idea how to drop the brackets on that to make it comprehensible with explicit brackets. 
Let's find out. First, the items you slice off a digit are put into a node before they are pushed in the next level, so you can only slice off two or three things at a time, and that only makes a single insert. If digits held 1-3 items, then at the overflow to 4 we would probably have to push a pair of nodes, because if we went down to 1, then alternating viewL and cons could thrash. It seems like it might be safe if on an overflow insert only took 2 elements and pushed a 2-node (this does hurt some constant factors). I'm not entirely sure this is safe with viewL/tail though - when it has to recurse (because of a one-element digit) it takes a node an unpacks it back into a digit, so if digits only had size 1-3 then unpacking a 3-node would give a packed digit. On the other hand, even if the first insert after the tail has to recurse deeply it will produce 2-nodes, so alternating insert and tail after that will be constant time. I guess if nothing else size 1-4 digits are simpler because turning a node back into a digit then obviously produces a digit that will not immediately overflow.
/pops up Did someone mention something that isn't on Hackage yet? I wonder why it isn't there.
Relevant: - http://hackage.haskell.org/package/change-monger - http://hackage.haskell.org/trac/hackage/ticket/244 - http://hackage.haskell.org/trac/hackage/ticket/299 (I would've posted this there, but new accounts can't post 3 hyperlinks. Boo!)
Edwardkmett is right, what I really want is -XFailIfUnpackPragmaHasNoEffect.
Oh, okay. That makes sense. Although I'd prefer -XMakeUnpackingWorkForPolymorphicFields, despite that probably being a pipe dream. :) Edit: Also -XUnpackSums and the like, of course.
I like GIH and learned a lot from it. That said, it's not a tutorial. A tutorial starts by solving small complete problems and gradually introduces new concepts in order to solve bigger complete problems. GIH is more like an informal tour of the language spec with more examples.
Well, the point would be to keep it separate from regular type synonyms, which would still have an occurs check. So only `equitype` synonyms would drop the occurs check. Not sure how it would actually work, but this thread is for dreams, right? :P
&gt; What good is it to have a language that scales to hundreds of nodes, if it's 50 times slower than native compiled code? The point is simply that you will eventually need to scale, no matter how fast your one-node solution is. At that point it's infinitely simpler to keep buying more machines than to do a total re-write. The initial cost of starting out with more nodes is just not significant to a large organization like Ericsson. I might think twice before using Erlang in a tiny cash-strapped company, though. Your point about IO-bound versus CPU-bound tasks is also important but I think secondary.
&gt; Factoring out patterns is great, but just like any programming device it tends to get counter productive when overused (think java design patterns). Right. This is why `Monad` and friends are *actual code* with a standard reusable library (e.g. `Control.Monad`). The problem in Java is that they recognize these patterns but can't express them in the language, so they have to write books of meat-macros that you instantiate by hand. It's not consistent that you object to using the standard abstractions, and also object to the Java solution of reinventing the wheel every time.
`undefined` is like throwing an exception. It's not like a null reference. 
Preaching to the choir here. Maybe it should go in `/r/programming`; might start a nice flamewar there. 
This should work for cons, you can push down a node2 instead, but IIRC it probably doesn't maintain the correct asymptotics for append. Also, note on the nodes along the left or right spine are upgraded to handle 1-4 nodes, the other nodes are in the 2-3 form.
This tutorial abount monadic parser combinators has a section about that: [monparsing.pdf](http://www.cs.nott.ac.uk/~gmh/monparsing.pdf).
Probably got overlooked because candidateFactors is not included in the final version. Correct signature should be: candidateFactors :: Integer -&gt; [Integer] 
[Not really?](http://www.haskell.org/ghc/docs/6.12.1/html/libraries/base/Control-Exception.html)
I'm not sure what you're trying to say. Evaluating `undefined` will indeed throw an exception of the `Control.Exception` sort. You can catch it with `catch`.
I'd like to have something like that for tail recursive function calls. For instance, suppose you have a function "tailcall" that fails to compile if given a non-tail-recursive function (otherwise it acts like "id"). For instance, you could implement factorial like so: factorial n = tailcall $ go n 1 where go 1 acc = acc go n acc = tailcall $ go (n-1) (acc*n) If it compiles, you know that it runs in constance stack. (It also would be nice to have a stricter form which disallows heap allocation as well.)
Maybe the writers of GHC's exception library don't either? The following code launches missiles: import Control.Exception main = do handle go_ahead don't_launch_first launch_missiles don't_launch_first = don't_launch_first go_ahead :: SomeException -&gt; IO () go_ahead _ = putStr "go ahead, " launch_missiles = putStr "fire!" Is the output go ahead, fire! intended? I'd say it's fine to replace non-termination with an error but it's a bug to let programmers handle it. Without blackhole detection the above program would never launch missiles.
I don't see what bottom has anything to do with a flawed loop optimizer. *Edit:* Unless you mean *compiler writers* don't understand bottoms, a point that Seb illustrates quite poignantly.
At the very least any functionality that lets you catch nontermination should probably be prefixed "unsafe."
The issue is not just scaling, but redundancy and fallover.
Are you referring to the arrow or (a,b) which the arrow is pointing to? If it's the latter, Haskell calls this pattern matching and you can do this in all sorts of places such as arguments to a function and case...of statements. If it's the former, &lt;- can be viewed as the more general "bind" operation that is present in all monads; in the list monad it does precisely the same thing as what you see in the list comprehension (at one point, there were monad comprehensions, but it got removed for being too general.)
I think the answer to your question is that it does work everywhere: in let bindings, where bindings, case statements, parameters and so on. The reason your code fails is because count returns something of type Num, and then you're trying to match that against a pair. The compiler is complaining that it doesn't know about pairs being an instance of Num. Perhaps you meant: let count x = (x, x) : count (x + 1) let z = [a + b | (a,b) &lt;- (count 1)] take 10 z -- gives you the first ten even numbers
It's used outside of list comprehensions all the time. In your example, it doesn't work, because: The type of `zip fib (tail fib)` is `[(Integer, Integer)]`, a list of pairs (of integers). The type of `count 1` is `(Num t) =&gt; [t]`, a list of numbers. You are trying to draw pairs out of that list of numbers, which is why you get that message saying `No instance for (Num (t, t))`. 
It is certainly fear inducing. What can one do? Back your environment up before you try upgrading. Use vmware/virtualbox/ec2 snapshots. Other ideas?
This fails because count gives a list of a Num type, but the comprehension binding takes a list to 2-tuples. Technically speaking, the bind (&lt;-) operator can work on any type with the appropriate Monad functions defined. You need bind a list of tuple pairs or change the type of the pattern you are binding.
Thanks! This is called ["pattern binding"](http://www.haskell.org/ghc/docs/6.10-latest/html/users_guide/primitives.html) right? My brain glitched and wanted to see it as (a, b) &lt;- grabbing 2 values and assigning them (just like "destructuring assignment" in other languages). Too much switching between languages for me.
That's not a really good page in the GHC manual to look at. Try [this](http://en.wikibooks.org/wiki/Haskell/Pattern_matching).
Thanks, that makes a lot more sense. I mistakenly interpreted it as destructuring X items from the list and then assigning them to the variables on the left. Now that I see it's just pattern matching I understand why it didn't work.
I did something similar in my [repr](http://hackage.haskell.org/package/repr) package. Also Lennart Augustsson's [traced](http://hackage.haskell.org/package/traced) package might be of interest.
-XTypeVariableWildcards as in: const ∷ a → _ → a const x _ = x
-XLocalDataTypes as in: foo :: Int -&gt; Int foo n = ... where data MyLocalType = C1 | C2 | C3 Of course the constructors of 'MyLocalType' can not be returned by 'foo ' because they aren't known in the outer scope.
If this was enabled it would also be nice to have: -XLocalInstances as in: foo :: Int -&gt; Int foo n = ... where data MyLocalType = C1 | C2 | C3 instance Enum MyLocalType where ...
-XConstructorSynonyms as in: type State = Bool where Enabled = True Disabled = False Of course these constructor synonyms can also be used in patterns, as in: update :: State -&gt; ... update Enabled = ... update Disabled = ... 
Yes. But without knowing anything about you, your skillset or your background it is very difficult to make any relevant suggestions.
hrm this makes it difficult
And while we're at it: -XLocalTypeClasses 
[/r/SomebodyMakeThis](http://www.reddit.com/r/SomebodyMakeThis/) was made for suggesting programming ideas. As far as suggestions, how about a program that saves the name of every file and folder in a drive/folder into a text file? Should only take a few lines of code, right?
Visit the http://www.reddit.com/r/haskell_proposals reddit for interesting project ideas.
While I think about it, maybe it's nicer to have: -XPatternSynonyms as in: pattern Enabled = True pattern Disabled = False pattern synonyms can also be parameterized, as in: pattern Empty = [] pattern Singelton x = [x] pattern Cons x xs = x:xs and of course a pattern synonym is truly a synonym for any kind of pattern: pattern Foo x y = (1, (2:3:y:[]), Just x)
We could also lobby the Unicode consortium to support a special lambda symbol which is not a letter: "HASKELL LAMBDA" or "LAMBDA ABSTRACTION".
I think -XKindPolymorphism allows to parameterize kinds as in: data forall k a. Phantom (a :: k) = Phantom x :: Phantom [] x = Phantom y :: Phantom Int y = Phantom 
Consider Wadler's paper [Views: a way for pattern matching to cohabit with data abstraction](http://homepages.inf.ed.ac.uk/wadler/topics/language-design.html)
This seems to reflect a lack of understanding regarding the immutable data graph of haskell. 
Destructuring assignment _is_ (a very weak form of) pattern binding.
The other approaches folks have mentioned are probably faster, but this is actually an almost ideal problem for _scannerless_ monadic parsing. You can do things like `n &lt;- parseLength (many spaces)` and branch the parsing based on how `n` compares to the current level of indentation. Here `parseLength` is a combinator that takes any parser and makes a derived parser that returns the number of characters parsed.
yeah, absolutely, but it's hard to know how to respond - the modelling exercise he's trying to do basically can't go that way in Haskell. (Well, you can always chuck in some IORefs, but you won't get an idiomatic solution that way)
As an aside, those two block systems for the hexagon correspond to the decimation-in-time FFTs of radix 2 and 3. The triangular block system corresponds to the cyclotomic factorization f(z) = z^6 - 1 = (z^3 - 1)(z^3 + 1). The two trivial block systems correspond to the trivial factorization of f(z) with one factor and the complete factorization of f(z) into six linear factors based on the sixth roots of unity. The right way to understand FFTs is in terms of symmetries of regular polygons and properties of cyclotomic polynomials. They are really two sides of the same coin.
What I usually do to break the mutual recursion is give one or both types a unique identifier, such as "bookId::Int" or "authorId:Int", and then store a map from bookIds to books and/or authorIds to authors. Each book, then, can hold a list of authorIds instead of a list of authors, and each author can hold a list of bookIds instead of a list of books. Making changes can be a bit cumbersome (and error-prone in ways that the type-checker can't detect), but it's doable. I don't know if this is "idiomatic" or not, but at least it doesn't require any IORefs.
Author stated that "[his] haskell noobishness is entirely to blame" and probably wants some insight. Personally I belive that the post shows the OOP approach - what the actors are (Books/Authors) rather then what happens (parsing/storing on database/...). While OOP is very good in OOP languages it fails in Haskell as Haskell is not an OOP language or even imperative.
On the contrary, I believe Haskell is an excellent imperative language.
It's good to see another enthusiastic haskeller.
the best thing is that derived instance for Show - it loops.
bookId::Int is a reference, too
This originated from a [discussion about a reddit post on turning non-terminating computations into terminating ones](http://www.reddit.com/r/haskell/comments/bynws/c_people_dont_understand_bottoms/). The reddit post was deleted by the submitter so I have asked on the GHC mailinglist whether I spotted a bug or the behavour is intended.
almost everything is incorrect, but enthusiasm is important.
Unfortunately the author failed to tie the knot. Understandable since this requires an intermediate haskell coding level.
&gt; As a consequence, the semantics of my program depends on how I define the infinite loop It's more the observable effects that depend on nontermination. Or is this a distinction without a difference? Is it possible to construct an example where an expression, and not a computation, depends on distinguishing the bottom? Of course a viable solution is to prohibit catching `NonTermination` exceptions.
I'd never catch NonTermination myself (..unless perhaps if it's useful in implementing FRP), but it's a very useful instrument of debugging. Simply having &lt;&lt;LOOP&gt;&gt; written to stderr tells me a lot about what went wrong.
Can you give examples?
1. laziness is great because you can do lazy IO. 2. head of sorted list doesn't mean single traversal of the list - it depends on sort function. 3. other languages have to add iterators to language spec, haskell doesn't have to - haskell had to add the opposite - seq 4. purity and laziness have nothing to do with HOFs, type[classe]s, adts, monads, pattern-matching and literate programming.
Also note, you can actually have this (plus some other goodies) now if you use the [SHE](http://personal.cis.strath.ac.uk/~conor/pub/she/) preprocessor.
gtk2hs still seems like a conglomerate of different libraries e.g. GLib, Gtk, Gnome all available in one big package. Do you plan to split these in the future, so once it's all available via hackage developers don't need depend on the flags used (or installed libraries) when install gtk2hs and have better control?
I have a little quibble with the title "GHC dev" is ambiguous -- and implies authority. This is a discussion on glasgow-haskell-users, until SPJ or Marlow reply :-) &gt; Is the above output intended? Yes, catching exceptions in IO is the correct, specified semantics for [asynchronous exceptions](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.26.1040). You can't obseve the bottoms in pure Haskell -- you must resort to IO. The question of whether it is morally sound to have a BlackHole exception is an interesting one.
No, I meant people commenting on the article had all sorts of confused notions of what bottoms were, and the implications of collapsing them. Not that there aren't bugs in C compilers.
GHC is sooo cutting edge, it can solve the halting problem! ;) Next, how to calculate Omega in GHC Haskell!
Surely it's no worse than unsafePerformIO? That is, morally unsound but practically useful.
Re point 4 I think the author understood that they are orthogonal features.
Oh, unsafePerformIO admits more troubling programming practices than catching a black hole does, so yes, I'd argue unsafePerformIO is far more questionable.
Don't confuse the issue. GHC can detect at runtime a particular form of non-termination.
why?
Well, okay, `catch` is in IO, so I'm probably wrong about "unsafe", but surely being able to detect nontermination would break semantics if it wasn't in IO, no?
Sure, if it wasn't in IO.
It is, but the thing it points to doesn't have to be defined in its final form at the same time as the thing that points to it. This introduces the possibility of, say, changing the details about a particular book without having to update the author. 
-XSolvesHaltingProblem would be pretty awesome.
I didn't know about her, she's amazing!
Thanks for the link! *Views* look a lot like my constructor synonyms but are more general. I like them. So lets add: -XViews
I know, its a bad joke. Sheesh. 
What would be the right way of doing this in Haskell?
thx for all the constructive feedback everyone. i've added a "followup" section to the post that builds out a "Catalog", with methods for updating the catalog. hopefully this "ties the knot" in an idiomatic way :-) would love your feedback / code review again.
ACK for your point on authority (which should not convince anybody by itself). I was wary about handling black holes because I thought the semantics of my program was affected by the definition (rather than the semantics) of my infinite loop. But at closer look the semantics may just be "runs indefinitely or launches missiles" so both behaviours would be fine. Although I'd still prefer the NonTermination exception to be unrecoverable, I don't consider the possibility to handle it a bug anymore.
The NonTermination exception is useful. I find handling it suspicious. (&lt;&lt;loop&gt;&gt; is only written to stderr if you *don't* handle it.) Actually, my infinite loops are rarely (never?) black holes, so detecting black holes doesn't help me much when debugging.
The semantics of a program is often defined as its IO relation. I don't think you can make an example without IO because catch only works in the IO monad.
[Tony's comments](http://blog.tmorris.net/why-are-there-no-big-applications-written-using-functional-languages/) are relevant here.
Hmm. Possibly relevant. Though I'm not sure it is terribly relevant. There are larger code bases, and more complex systems, and older code bases. The question is: are there particular programming practices that become more visible, more important, at that engineering scale. And yes, looking at some of our code bases at work, there are key design choices that keep things together.
Is it possible to summarize what those design choices were?
See the linked article, which distills some of the lessons. Also, some of the lessons are in [this talk](http://www.galois.com/blog/2009/04/27/engineering-large-projects-in-haskell-a-decade-of-fp-at-galois/).
Also: Learn how the RTS works.
we really need a Haskell Best Practices book.
One (potentially dubious) way of specifying things is that the semantics of the program is to launch the missiles at time step ω+1. This is somewhat more formal than "launch missiles or loop" since it helps to explain what we mean by "or". The question then becomes: what does it mean for things to happen after time step ω? If we can't catch non-termination then clearly we can never reach anything beyond ω, and so (for us) ω+1=ω; but if we can catch them, then we can short circuit infinitely many steps and continue to launch the missiles. This would seem to imply that blackholes are actually ω, whereas other forms of looping are larger ordinals which exception handling can't circumvent, which is an interesting idea...
Why 'avoid partial functions'?
Because they can fail. 
Ah, okay. I read that as 'partial function application' rather than the opposite of total functions.
Wow, 50K lines of Haskell. Let's start by trying to figure out how complex something that takes 50K lines would be. One standard of comparison might be Haskell itself. Mark Jones has [written](http://web.cecs.pdx.edu/~mpj/thih/) a Haskell 98 typechecker, using 720 lines of Haskell. So, unknown Galois project is about 70 times more complex than a Haskell type checker. Perhaps that example's a bit unreasonable. Darcs is a well publicized Haskell project that has to include lots of details about UI and OS interaction and the like. Darcs 2.4.1 includes 26K lines of Haskell, so unknown Galois project must be twice as complex as Darcs. We still haven't managed to establish a bound on how complex this project must be, so let's try using GHC itself. GHC 6.12.2 includes 126K lines of Haskell (under the compiler directory), suggesting that it's about 2.5 times as complex as unknown Galois project. However, we might want to be careful using that number. The GHC typechecker is only 16k lines; codeGen and nativeGen are only 23k lines. So, while unknown Galois project is only 0.4 GHCs, it's still as complex as 3 GHC typecheckers or 2 GHC code generators. So, the linked experience report tells us that a demo of unknown project for an unknown customer with unknown requirements and specifications, roughly half as complex as GHC or twice as complex as Darcs, took six developers some number of months to complete without bugs. I find it difficult to judge the applicability of that datum to anything, except perhaps that it's a pity Darcs and GHC can't get help from engineers of that caliber.
The lessons from building many multi-year, large projects, can be boiled down to a reasonable set of recommendations, I think, which I tried to do in this talk - citing one particular project I'd just been involved in, which had good examples to motivate the talk. Not everything is in the slides, obviously. Feel free to contribute your experiences using Haskell on big projects. You worked at Aetion, didn't you?
http://www.haskell.org/pipermail/haskell-cafe/2010-May/077175.html
That would be nice, but first, we need enough empirical evidence to establish what the best practices are... Edit: From the downvote, I assume my comment came across as trolling, which was not my intent. My point is only that Haskell still has a relatively small user base, and even the kinds of project being mentioned by experienced users like Don in this discussion and the various places linked from it don't seem to be "big projects" by the standards of the wider industry. I'm absolutely not saying that Haskell couldn't be used for larger projects as well, only that on the evidence so far there don't seem to be many such projects we can analyse, and therefore trying to write a "best practices" book seems premature. To give a slightly more specific comment, the number of lines of code in a project isn't a very useful metric for judging project size because some languages are more concise or expressive than others. However, there are other ways to define a large project. One useful benchmark might be what happens when the development team is big enough that individual developers don't routinely interact with all the other developers on the project, and you have to start breaking the team down into smaller teams with separate responsibilities and then co-ordinate their contributions. This is partly a process issue, but it's also the point where you learn how well your module systems and interfaces and documentation tools work, and you have to figure out the best ways to use these things to make up for the reduced direct communication between team members. *That* is the sort of knowledge that would belong in a best practices guide, IMHO, and you can't simply extrapolate it from what worked on successful smaller projects.
Heh. Noticed one glaring omission...
Please pardon (and correct) any ignorant comments here. I am speaking at the edge of my experience and beyond the edge of my knowledge. Haskell incorporates C libraries quite nicely but I don't think that Haskell makes very good C-style libraries. In particular, I don't believe it's possible to create multiple independent libraries that can be dynamically linked into the same application (e.g., DSP effects that are used as plug-ins for Garageband). Assuming that the "Haskell as a C library" use case is important, it would very helpful to have GHC be able to multi-thread independently from the program it is linked into and to also be able to programmatically control the number of hardware-based threads. The particular use case I have in mind is writing an AI for Unity Pro in Haskell. The Haskell compiles and links into a single library with a C interface. Unity links the library and runs it on a single thread, unnecessarily limiting the power of the AI. If, independent of Unity, Haskell can spawn extra threads to take advantage of the 4 and 6 core CPUs out there (not to mention the quad socket beasts), it would increase the power significantly. Even better, if would be nice if the number of hardware threads could be changed while the program is executing. That way, Unity can dynamically alter the number of threads to match the needs of different sections of the game. I suspect that there are organizations out there that have similar needs, particularly when performing logic- and math-heavy rapid prototyping. Unfortunately, I am not able to participate. I am working part-time and mostly alone, assuming my meager experience was enough, I don't have the time to participate in a meaningful manner. This is a real-world use, though, and one that I suspect will improve the suitability of Haskell as a general purpose, parallel language.
The recent work on dynamic libraries makes it possible for ghc to produce C-style libraries that can be dynamicly linked into an application. Each such library will share a single instance of the GHC runtime system. It think it is possible to initialise the GHC RTS from C code in such a way that the number of threads can be controlled (by setting the RTS command line).
that post is 4 years old
I don't agree. I think most of it is correct, but with a few things wrong 
GHC is probably more like millions of lines of Haskell, except not "all at once", if you get what I mean. It's not like you write all the code and then stop modifying it - so if your'e comparing the time it takes to write you have to compare all the lines of codes *written*, not the absolute number of lines currently in the repository.
Is visitor really pattern matching? I would imagine visitor is more like "Foldable" and "Traversable". Or maybe 'transform' and 'universe' from generic programming libraries like Uniplate. I would say that Memento corresponds to the Undo Monad.
Isn't visitor basically just "Functor"? I suppose they're all part of the same family.
Well... the visitor pattern is sometimes used together with mutation to collapse the structure into a single value. For example counting variables in a OO AST.
It's not. I found the better word for it "equational functions" and used that instead. I've also mentioned foldable since it's a really common thing that happens when you write visitor code, although it's not the only possibility. Mentioned Undo monad for Memento.
&gt; GHC is probably more like millions of lines of Haskell .... Indeed. You shoulda seen the millions more *not* written. I write in Haskell so that I don't have to write tons more in some other language.
Presumably GHC is completely expressed by its code. If so, the complexity of GHC ought to be somehow tied to the code, and the effort required to make something is quite possibly related to its complexity. Alternatively, you could argue that the effort required to make something is determined primarily by the experience of the engineers. In that case, knowing that unknown Galois project ended up taking 50k lines of code tells us even less, as we know nothing about the engineers involved or their experience.
Actually I guess that iterators are sometimes used (Iteratee package). Proxy - depending on need: class Abc x where doSomething :: x -&gt; IO () data Base = Base Int instance Abc Base where doSomething (Base n) = putStrLn $ "Base" ++ (n+1) data Proxy = Proxy Base instance Abc Proxy where doSomething (Proxy b@(Base n)) | n == 0 = return () | n /= 0 = doSomething b doSomethingElse :: Int -&gt; String doSomethingElse = show doSomethingElseProxy :: Int -&gt; String doSomethingElseProxy n | n == 0 = "" | n /= 0 = doSomethingElse n 
I was under the impression that iterators were still useful only when IO was involved. Wrapped data types is a pretty good example of proxy. I'll add both of these.
So Functor and Traversable.
Tying the knot refers to something [completely different](http://haskell.org/haskellwiki/Tying_the_knot). More constructively: I find it strange that you wrap books and authors into one data type in your revised edition. This doesn't match anybody's advice nor your Ruby version, and it makes all kinds of runtime errors possible.
To be honest I don't see the relevance of the GoF book to FP especially Haskell. The patterns in GoF are solutions to old problems in a context (some old, some still relevant). [Peter Norvig went through this exercise himself when the book came out.](http://norvig.com/design-patterns/) What he calls dynamic languages fits better with functional languages. But I don't think going through the list of Design Patterns as a check list for language features is really useful. I'd like to see more real Haskell idioms and patterns instead. For example, there was a post yesterday where the author failed to ["tie the knot"](http://www.haskell.org/haskellwiki/Tying_the_Knot). This is a good example of idiom or pattern that could be documented better. I don't feel the haskell wiki above explains it well enough or distills the essence of the pattern well enough.
I think that going through the list of Design Patterns as a check list for language features is really useful. I'd like to see more real Haskell idioms and patterns as well.
I really enjoyed the Rabhi and Lapalme book mentioned in this blog posting. Forgive me for saying so, but one feature of that book (for me) was that it was very very short. Felt like we covered a lot of ground very quickly. Sort of a nice read if you've been programming in Haskell for a while and you just sort of need to take stock and review some of the elementary computer science stuff.
"Category: Idioms" is great, but seems to have quite a bit of noise among the gems these days: http://haskell.org/haskellwiki/Category:Idioms I always thought "data structures not functions" and the related pages make really excellent points. The more general principle I'd extract is "Types capture available information: choose structures which capture as much information as you need, and no more."
thanks for the feedback dmwit. i wasn't sure how to create the "catalogued" method (that method can take either a book OR an author, plus a catalog, and determine if that book or author is catalogued in the catalog). i've now refactored it (http://gist.github.com/387489), promoting author and book to their own data types, and making "catalogued" a function belonging to a "Catalogued" type class, which both Author and Book implement. is that the right approach?
Nice.
Yes, that looks sane!