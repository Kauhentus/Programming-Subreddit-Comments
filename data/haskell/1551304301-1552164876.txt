Thanks, this is really helpful. One thing (among many) that wasn't clear to me was the distinction between the `(-&gt;)` to bind the result of `IO` vs `let x = expr` for a non-`IO` assignment. One thing that I had a hard time coming to grips with is how pure acts kind of like a "cast" but it wasn't exactly clear to me how the compiler knew what context to lift the value to. I'm going to go off and thing about MaybeT... :)
&gt;https://repl.it/@sheyll/date-time Thanks, that's helpful. I think what's adding to my confusion is throwing IO into the mix, and getting the types to line up. The `let` suggestion really added to my understanding...
I really liked how the article is laid out and written; very clear, straightforward, and to the point. The API design of the `validity-*` libraries seems really appealing to me, especially since the biggest draw to Property style testing for me is in the promise of a declarative, low-friction/time/investment way to add tests that are more robust than a smoke screen. In particular, I liked how deciding on a strict and clear/unambiguous semantics for certain things allowed for generic implementations of the boilerplate (the main draw of a typeclass approach) while keeping the implementations of the core API in terms of those allows for piecemeal overriding (the main draw of a non-typeclass approach); really clever design. Will definitely have to try it out for my next project :) Quick note: instance Odd Int where validate (Odd i) = declare "The Int is odd" $ odd i I'm guessing this is a typo and it should be `instance Validity Odd where`?
There's another unfortunate side effect to this sort of thing which is that it becomes harder, if not practically impossible, to just open `foo.hs` and get an editing experience worth a damn. Variable rename? Refactoring? You'll be lucky to get tab completion for the standard library. To be fair, this isn't a Haskell/Stack specific thing; it's a growing trend among JS, Rust, Haskell, and basically every other language with a Language Server or OtherToolingSolution out there.
While we're on the topic of property testing - is there any randomised testing framework which -saves- counterexamples automatically to be included in future runs? Preferably by outputting a new .hs file with the counterexample.
&gt;Why not Cabal then? Who are you asking? People who spend their time to build IDE tools like the one in this thread? Why not ask the author of that tool? Or any other tool for that matter? Or do you think they should work for free for you rather than making something they want for themselves? 
The particular reasons as far as I remember were lack of willingness to collaborate or communicate from cabal maintainers. Requests to fix obviously broken things or add vital functionality or even accept patches were ignored for years. At some point you have to just move on and do it yourself (stack) &amp;#x200B;
&gt;It's not conspiratorial to question why they've put all this work into their own tool instead of contributing to the core tools, They tried, cabal maintainers do not allow anyone to contribute. No patches are accepted, reported bugs and vital feature requests are ignored for years. At some point you just have to move on and do it yourself. And THEN they wake up and hurriedly rush cabal v2 to catch up. But it is too little too late. &amp;#x200B;
Hmm, what if I made `&amp;&amp;` be strict in both arguments, to ensure `x &amp;&amp; y = y &amp;&amp; x` under the existence of bottoms? 
Thanks, I like your version better, will apply suggested changes :) I'm still wondering if the code is testable though. Haven't time to read about testing solutions yet, other than something about QuickCheck, but it's solely for pure logic (I guess), and I have everything (almost) within IO. Maybe when I start transitioning into full featured bot, with more complicated actions, there will be more chances. Now it's just a script.
`do { let x = expr; f x }` = `(\x -&gt; f x) (expr)` `do { x &lt;- stmt; f x }` = `(stmt) &gt;&gt;= (\x -&gt; f x)` It's the difference between monadic bind and normal (lazy) application. But, I think even I mess it up sometimes.
Interesting :) They went ahead and defined the generic case as `SemiIso s t a b` and `SemiIso' a b` for the simple case, in the same way `lens` defines datatypes. I didn't bother in going that far but I might do it on a second version if there's any interest or if I'm just bored :)
First, do the bottom-less proofs. After those are complete, then see what you need to do to extend them.
(Author here) Thank you for your kind words! \&gt; I'm guessing this is a typo and it should be \`instance Validity Odd where\` Yes, that's right. I'll see if I can fix that!
That looks really cool; will read! I can see already though that one major difference is an Rslt does not require you to commit to any kind of schema in advance. If you record "david #uses spoons", and the "_ uses _" template was not previously in the Rslt, it is now.
Not necessarily everything, but you do need to handle the case when querying the remote service fails. Psuedo example: queryRemoteService :: IO (Either RSError RSResult) mergeLocalRemote :: LocalData -&gt; RSResult -&gt; InternalResult censorAndPrettify :: InternalResult -&gt; PublishableResult backendFailure :: RSError -&gt; PublishableResult publish :: PublishableResult -&gt; IO () serviceOnce :: IO () serviceOnce = do rse &lt;- queryRemoteService let pr = either backendFailure (censorAndPrettify . mergeLocalRemote localData) publish pr The `fmap`/`&lt;*&gt;`/`(&gt;&gt;=)` for `Either err` propagate the first `err`or, or deal with the non-error case. `either` lets you handle the error case and the non-error case as long as the result of both is of a common type. When you just don't want to deal with it right now, or the "type tetris" is too much `error "Recognizable String"` is of any type; when it's evaluated WHNF, it'll throw an exception, you might even get a stack trace these days. Also, if the type checker is giving you way too much grief and you just want to test run whatever you have right now, there's a compiler flag to defer the type errors until runtime.
Thank you, I don't worry about bottoms and laziness until I get bottom-less proofs. But, could you elaborate why `fmap snd x = fmap snd y` doesn't hold, when we don't care for bottoms? Am I interpreting `=` sign wrongly?
Except for the MaybeT suggestion - which I spared since MaybeT isn't in base - I was suggesting the same :) I posted a link to an online IDE this might help with the formatting issues [link](https://repl.it/@sheyll/date-time)
&gt; fmap snd x = Cont $ \k -&gt; k 0 &amp;&amp; k 1 /= &gt; Cont $ \k -&gt; k 1 &amp;&amp; k 0 = fmap snd y You showed the (second) premise didn't hold in your original post.
Rows are just the type level, you use them as a phantom type and use that to e.g. index a record. How you do the indexing defines how the records work. To be clear: Rows are **only** on the type level, it is not a `Type` so they do not have any values. As said, you can use arrays and a phantom type to index it to get records
Huge thanks to everyone who reached out! I'm consistently blown-away by the huge response to these posts and the quality of the candidates. Thanks to everyone who DM'd or emailed me!
They are syntactically different, but aren't they semantically same? I mean, for any `k :: Int -&gt; Bool`, don't they always evaluates to the same value? Am I using `=` sign wrongly?
Are you assuming function extensionality? I generally don't since I value operational properties, even of pure expressions.
QuickCheck, at least through `tasty`, responds with some form of RNG-state used when a counterexample was generated. You can use that to replay that case. It's probably possible to convince `tasty` to store that and make it automatically run it again, but I don't know if someone's closed that circle yet.
As a complement to this, rather than a counterpoint, it is usually best from a QA standpoint to think of type system guarantees as tests that one does not have to write. 'Correct by construction' is something that is -enabled- by the type system, but not supplied by it. You're still on the hook to think through the edge-cases. In my experience, it doesn't actually get easier to write 'correct' programs for awhile. You either need to write something big enough to benefit from the small mistakes (like null pointer exceptions) Haskell saves you from inherently, or, you need to get good enough with the type system to start using it to catch problems for you, both of which generally happen after you've got a pretty decent comfort level. After that, it gets a whole lot easier. I'm not confident I've gotten any faster, but it certainly helps me think through the problem space more completely.
&gt; Are you assuming function extensionality? Exactly. I should have clarified.
In that case, yes, your counter example is valid and your implication is not. That's not exactly surprising since (a, b) -&gt; (c, d) is a larger set than (a -&gt; c, b -&gt; d) at least most of the time. cd^(ab) &gt; c^(a)d^(b)
At the risk of pointing out the obvious: it is the *other* program that reads *your* memory through timing its own execution. The choice of language of the victim program is largely irrelevant. So even if pure FP prevented programs from obtaining timing information (other comments address this matter), unless you force every program in the world to use it, then no, it cannot prevent Spectre and similar attacks.
There are different ways to have a successful GSoC application. You just have to make a strong case that your project (a) would help the Haskell community, and (b) is within your ability to deliver. If you proposed a project optimizing GHC or something like that, you'll be expected to demonstrate that you understand Haskell well enough to do performance tuning, and contribute to GHC despite the huge code base and learning curve, and that's a pretty high bar if you're new to Haskell. On the other hand, you could also propose a project that's less technical, but where you show a strong vision of what could be helpful to the community, or where you are just willing to jump in and do something that no one else has gotten around to. The last three years in a row, I've mentored students working on CodeWorld, and two out of the three years, those students were beginners in Haskell, but still managed to make a contribution. Those students needed a lot of guidance and even occasionally took more of my time as a mentor than it would have taken to write things myself... but their working on it got some things done that I wouldn't have gotten around to doing on my own. They also had the chance to get some Haskell experience, and get to know the community. One of those students is now in a programming languages Ph.D. program. That's definitely a success story, too.
That’s awesome. Thanks so much for the detailed response. My main takeaway is that I need to give some thought to things I think would be useful for the community that would be within my ability to deliver, even if I’d need a lot of help. Is that an accurate interpretation of your point? 
My point still remains that whether Rows support scoped labels or not and whether lacks constraints are used or not will have a big influence on how Records and Variants end up working. Also what is the reasoning for not using DataKinds and allowing them also on the value level (like how they would work in Agda if you extended my example to add in String keys)? Also if you have to use Arrays and phantom types for products that sounds to me like a bunch of `unsafeCoerce`, which I would rather not have in library code, and which is going to be awkward for GHC to optimize. I am hoping that Rows and Records and Variants and Products and Sums will become the new building blocks of Haskell and the built in versions will be entirely obviated / become syntax sugar. This won’t happen if Records are third party libraries with copious amounts of unsafeCoerce.
Going through the documentation and the code of rslt and qseq both of these will be mostly use for word phrases and relationship mostly .it will be helpful for bigger word projects and queries 
&gt; The particular reasons as far as I remember were lack of willingness to collaborate or communicate from cabal maintainers. That's very disheartening. Do you have have any concrete examples of this you can point us to?
&gt; cabal maintainers do not allow anyone to contribute. No patches are accepted, reported bugs and vital feature requests are ignored for years. That's a rather bold accusation that, if true, would call for consequences for cabal maintainers. Do you have any concrete examples of cabal maintainers behaving in this manner towards you or somebody else?
This is a good question actually. &amp;#x200B; I'm OK to give the same benefits for Paypal supporters. But it will require some manual management from me because I'll need to count these supporters. In opposite, Patreon has all the instruments that allow to not miss the benefits sending process. For example, private posts: Patreon has a convenient system to get them shared among the appropriate tiers. I probably should not share these posts in other way because it's an additional management and attention-time consumer. So I prefer Patreon. &amp;#x200B; But if you wish to use Paypal (and I have one person who has already donated me there), just remind me if you want some benefit from the tiers, and I'll see how we can do it in a convenient way for both of us.
Try many1 digit.
&gt; QuickCheck, at least through tasty, responds with some form of RNG-state used when a counterexample was generated. You can get ahold of the seed (and size) without tasty as follows: result &lt;- quickcheckResult prop case result of Failure { usedSeed, usedSize } -&gt; return (usedSeed, usedSize) And then you can rerun that test case with: quickcheckWith stdArgs { replay = Just (usedSeed, usedSize) } prop However QuickCheck makes no guarantee that the seed will be compatible with newer versions of QuickCheck. I think best practice would be to save the counterexample as a regression unit test. It would make sense to make QuickCheck aware of the bugs it has already found, so that you for example can continue testing before fixing the bug. If you are interested in this topic check out [Find More Bugs with QuickCheck](http://www.cse.chalmers.se/~nicsma/papers/more-bugs.pdf) and or Python's property based testing library [Hypothesis](https://www.drmaciver.com/2019/01/notes-on-test-case-reduction/).
Rows will support scoped labels but you can also add lack conatraints. The point why rows have to support scoped labels is that uniqueness of labels cannot be guaranteed at type level (no such thing as type level constraints). So it depends on how you use the rows. What you dont seem to see is that the definition of a row is that it is just on typr level, it is a new kind! Just like `Symbol`. You can use that to implement Records or variants (or more) on value level. Builtin records are not part of the proposal because they can be added later and would blow up the scope of the change. I do plan to do this in the future.
 helper 0 = [] helper n | n `mod` 2 == 1 = 1 : helper ( n `div` 2) | n `mod` 2 == 0 = 0 : helper ( n `div` 2) Could be: helper 0 = [] helper n | n `mod` 2 == 0 = 0 : helper ( n `div` 2) | otherwise = 1 : helper ( n `div` 2) Which means no double checking, and having an otherwise case good for for situations where not all of your guards will match, even if you thought they might. you could actually remove explicit recursion here with `unfoldr` import Data.Tuple (swap) to_binary 0 = [0] to_binary n = reverse . unfoldr f $ n where f 0 = Nothing f x = Just . swap $ x `divMod` 2 If you don't get what's going on: `unfoldr :: (b -&gt; Maybe (a, b)) -&gt; b -&gt; [a]` Unfoldr takes a function that might give back a pair, and if it does, the first element goes into the list, and the second element goes back into the function to find the next element. If the function returns a Nothing, the function stops and returns the list it has so far. divMod returns `(quotient, remainder)` when we want `(remainder, quotient)` so we use `swap` to flip the tuple, which has to be imported from the base library `Data.Tuple` You could just roll your own tuple from separate mod and div operations. As others have suggested using a binary choice type like`Bool`, you could turn `f` into f 0 = Nothing f x = let (q,r) = x `divMod` 2 in Just (r /= 0, q) Or even f 0 = Nothing f x = Just . swap . fmap (/= 0) $ x `divMod` 2 But at that point my obsession with solving everything through function composition probably hurts readability. 
Nice! Can you please also add the heart with raining characters in the examples? 
I am not an expert, but can you try your code with Megaparsec? It should be more or less a drop-in
You can use the {-# LANGUAGE xxxxxx #-} pragma to turn on extensions on a per-file basis
I've been using RIO in a personal project and I have to say I've been quite satisfied so far. I find it well suited and with batteries included. Regarding the RIO monad abstraction, I can say, it might be a bit controversial given that it's more targeted for the "working programmer" than for the abstraction-fan-boy but I found it refreshing how focused is on settling up on simple and solid abstractions/patterns that just work with little surprise. Like, use Reader for your environment and use a IORef to store a mutable state. Something I think we undervalue the necessity of having mutable state and Haskell has machinery to handle it pretty well! The value comes from splitting pure from impure logic. But when you need mutability, use it!
&gt; so that "unbatch" would handle one "Read [a]" and produce many "Received a" of some sort. So `myService` understands `Received a` but you get `Read [a]` out of your data source? In that case you need to carry some buffer to decide when to do a `Read`, so `Received a` can be interpreted using `Read [a]` and `State Buffer` effects. &gt; I'd like to be able to handle a message in a way that it is "acked" after it is successfully processed by "myService". How do you tell when `myService` is done processing a message? Does it perform a specific event (so you could handle it as an ack output)? &gt; I suspect that #2 may fall into a category of "freer cannot express ContT / bracketing", does it? Or there is a solution for it? Even if there is no general solution there are often plenty of easily solvable subproblems. - isovector had a few things to say about this meme https://reasonablypolymorphic.com/blog/freer-monads/ - The following paper discusses the problem in depth, with various solutions for "traditional" algebraic effects (of which freer is an instance), and proposes switching to a "higher-order free monad" as a more general solution https://people.cs.kuleuven.be/~tom.schrijvers/Research/papers/haskell2014.pdf
Surely the solution to the first part is as simple as adding a "digit" moniker with `&lt;?&gt;` to your `num` parser. 
My guess for part 2 is that since `many` accepts 0 elements, it successfully satisfied its expectations by seeing no digits, then went back to the top of the parser and moved on to expecting another `.`, but found `a`. I'm not enough of an expert to know how to fix that though. 
For part 1 couldn't you just wrap all of your `num` in `&lt;?&gt;`, or would that be too aggressive? 
Well said. Thank you.
Thoughts welcome!
This is awesome u/peargreen ! I've integrated it into Hoogle, so [https://hoogle.haskell.org/?hoogle=map](https://hoogle.haskell.org/?hoogle=map) now gives a "Uses" link in the right hand side.
That's my hope :)
 {-# OPTIONS_GHC -fdefer-typed-holes #-} {-# OPTIONS_GHC -fdefer-type-errors #-} module Foo where import Text.Megaparsec as T.P import Text.Megaparsec.Char import Control.Monad import Data.Void type Parser = Parsec Void String dottedint :: Parser [Int] dottedint = map read &lt;$&gt; sepBy1 num (char '.') where num = liftM (:[]) (char '0') &lt;|&gt; liftM2 (:) nzdigit (many digitChar) nzdigit :: Parser Char nzdigit = satisfy (`elem` ['1'..'9']) &lt;?&gt; "non-zero digit" --- *Foo&gt; parseTest (dottedint &lt;* eof) "1.." 1:3: unexpected '.' expecting '0' or non-zero digit
At first I was thinking, this is silly. Then it blew my mind. Nice!
I added the valentine example but it server doesn't support rendering of Chinese characters. I usually do it with xelatex but the version that is installed on my server is way too old. I'll update the server soon and then it should just work.
It's amazing how you guys manage to repeatedly reinvent and revolutionize the Haskell ecosystem with better tooling and now with the new standard library for Haskell. I was skeptical at first but after using RIO for a couple months it made me realize the awesome sauce I had been missing out for years in terms of productivity with Haskell. I'd say that RIO is as revolutionary to core libraries as Stack was to build tooling: In short, RIO is what you get when you turn best practices into a standard library. Keep it up!
I feel that you are not interacting with me in good faith. You accuse me of being biased and yet you seem to be biased yourself. Allow me to remind everyone of your [anti-Stack stance](https://github.com/tonymorris/do-not-use-stack/issues/1#issuecomment-435691293): &gt; **Stackage implies Vendor lock.** This one is self-explanatory. I cannot use intero without using Stack. Additionally, I cannot use some Stack projects without using Stack (go figure, right?). This strikes me as Not The Thing I Want almost immediately, as the motivation for having such a project seems ideologically manipulative (i don't like Cabal, therefore you must use Stack). Politics have no place in my dependency graph. I try and stay away from them. &gt; &gt; **Stack is fine, but Cabal new-* makes it redundant.** If you're on Cabal 2.4, I see no reason to use Stack whatsoever! It effectively makes the build functionally redundant (in fact, in Cabal, i've had even more success with new-* commands, since dependencies are not drawn from a single place, which can become corrupt after a time. Blowing out ~/.stack and ~/project/.stack-work is a fact of life on OS X if there happens to be conflicting symbols lurking. I have not had any of the same problems with Cabal new-* commands, and Cabal works with stack seamlessly if i need it. &gt; &gt; **Nix works better with Cabal** (this is just a fact - they've been working towards it for a while), and combining the two allows for the best support for projects that need to bundle tech that is not haskell-specific (for instance, zeromq). I work with Nix builds all day, and Stack is not good at handling this. &gt; &gt; On the plus side, Stack has Stackage, which nicely curates a set of dependencies which can be easy to navigate. But again, **Stackage is kind of redundant now that new-install and new-build are a thing.** &gt; &gt; ... &gt; &gt; What puts me off some of the Stack stuff is actually not the technology, but what I see from a lot of people on Reddit and Twitter and on Discord who happen to be Pro-Stack. I see anti-competition (for instance, recently, when someone who worked for FPco disingenuously publicly put down Servant and Snap in favor of Yesod by citing some very shady "facts" that were no longer relevant), which is antithetical to a healthy community. I also see manipulation in the way many arguments are presented (for instance, citing cabal hell in the age of new-* commands without mentioning their existence). Perhaps this is just ignorance. It happens often and without correction from knowledgable people enough that it looks to me like anti-competition.
you forgot to post the whole context: &gt;That was me in @pjrt's comment btw (at least, I believe), having heard the trope that Stack is bad, and it was an honest question. I have heard the same belief from several different people at this point. Now, being able to articulate exactly why I am not a huge fan of stack (though, not at the point where I'd say fuck stack), I think i can tell you why. This is not a critique of Stack, insofar as it is a personal case study, and shouldn't be construed as a directly negative or positive endorsement of Stack or Cabal. followed by more context: &gt;I understand that Stack solved a problem for the community, and I respect it and @snoyberg (obviously, hi!) immensely for addressing the problem in a robust way, but I see parity in 2018 between Cabal and Stack! That's great, because I think having a diverse community of packages and pespectives is The Point of why Haskell is great. What puts me off some of the Stack stuff is actually not the technology, but what I see from a lot of people on Reddit and Twitter and on Discord who happen to be Pro-Stack. I see anti-competition (for instance, recently, when someone who worked for FPco disingenuously publicly put down Servant and Snap in favor of Yesod by citing some very shady "facts" that were no longer relevant), which is antithetical to a healthy community. I also see manipulation in the way many arguments are presented (for instance, citing cabal hell in the age of new-* commands without mentioning their existence). Perhaps this is just ignorance. It happens often and without correction from knowledgable people enough that it looks to me like anti-competition. This is not grinding an axe - it's my experience so far, and you are certainly contributing to that. You can go through my discord server and find countless times I've asked people to lay off the Stack folks. What you're protesting is me asking you to to _stop fighting people_ on Reddit about build tools. You're still putting up a fight now! Just please stop.
Hell yeah. Thanx!
&gt; The comment about disingenuity was a Chris Allen post. Then why didn't you just say so and instead emphasized the fact that *some* person being a FPCo employee acted disingenuously? FPCo employees are allowed to have personal opinions which aren't endorsed by FPCo. &gt; You can go through my discord server and find countless times I've asked people to lay off the Stack folk Quite frankly I find that hard to believe as I've heard otherwise. But I don't care enough to spend time reading through chat logs so I'm willing to give you the benefit of the doubt that this is what you genuinely believe you're doing and leave it at that.
I thought hiding his name would save him from undue commentary from people reading it. I don't want people going after him, which seems to be what happens when you name names on the internet. "FPCo employee" seemed the most appropriate at the time, as a result. I have no opinions on FPCo in general aside from technical praises and criticisms. You could go through my entire posting history and not find a _single_ anti-Stack comment. I use MakeFiles or Cabal in my personal work because it is most general, and I use Stack at work. I'm working on contributing to both. _This is fine_. 
this is awesome :) Is there a way to download the svg?
I think you could do a `Data.Map` style thing where you only expose functions / type families that preserve that invariant. But that is a good point, it looks like expresso also does it the same way and does support scoped labels at the type level (just not in records/variants). &gt; it is a new kind! Right! But the way you introduce new kinds into Haskell at the moment is by defining them on the value level and then enabling DataKinds, and the way you do it in Agda is basically the same, anything you can use on the type level you can use on the value level. Unfortunately Haskell lacks the function re-use that you get in Agda, but it is at least possible to get constructor re-use. &gt; I do plan to do this in the future. That makes sense, yeah as long as they are planned to be eventually part of the compiler and not permanently in a third party library, then that sounds great. I'm very excited to see what you end up developing, lack of rows/records/variants is my number one pain point in Haskell at the moment by a very large margin.
this is really cool! While I can't wait to have dependent types, i really hope that the future brings us a system where the ideas from liquid haskell and dependent haskell get merged! &amp;#x200B; I never found the whole business of encoding stuff like invariants via data-structures very intutitve. Liquid haskell makes much more sense imho.
How does `smallcheck` compare to the libraries mentioned in this article? I've successfully used `smallcheck` in [a project](https://github.com/runeksvendsen/orderbook/) to find bugs that `QuickCheck` was unable to find. The main drawback is that it can be very slow. As far as I've gathered, generation time is `k^n`, where `k` is the "depth" parameter and `n` is the number of arguments that the function being tested takes. So, e.g. testing a function of type `SomeType -&gt; Assertion` takes time proportional to `depth` while testing a function of type `SomeType -&gt; SomeType -&gt; Assertion` takes time proportional to `depth^2`.
&gt; TODO &gt; &gt; - Improve bounding box approximations This got me wondering... Would [Diagrams' "envelope" concept](https://archives.haskell.org/projects.haskell.org/diagrams/doc/quickstart.html#envelopes) be applicable to this?
Hi! Author of the article that probably got you thinking about this stuff here. A few points: The `Member (Queue Message) r` constraint on `runQueue` actually suggests you have *two* `Queue Message` effects in `r`. You have one at the top of the stack as indicated by `Eff (Queue Message ': r) a -&gt; Eff r a`, and then *another* from the `Member` constraint. You only want the `Member` constraint to describe separate effects required to interpret this effect. Unbatching is easy enough. It's equivalent to the `pureInput` interpreter I give in my [post](https://reasonablypolymorphic.com/blog/freer-monads/), except that whenever you hit an empty list of things in the batch you ask for more. As such, the type of that will look something like `unbatch :: Member (Queue m) r =&gt; Eff (Reader m ': r) a -&gt; Eff r a`. Auto-acking is possible depending on what you mean by "successfully handling it." If you can just use a `Writer Message` effect to indicate to the program it's done, then you can reinterpret *that* into the `Batch Message` effect and call `Ack` on it. Hope that helps! Let me know if you have any questions about the specifics.
&gt; I have everything (almost) within IO Yeah, that's a good observation and something I noticed too. You can likely factor out some pure parts of your code from the bits that do IO . `IO` isn't necessarily an impediment to using quickcheck though
In this example from PACPIH: &amp;#x200B; [https://imgur.com/fTmQnaX](https://imgur.com/fTmQnaX) &amp;#x200B; How is "waitCatch" able to return type? IO (Either SomeException a) &amp;#x200B; I'm certain I'm just missing something, but it seems like there's nothing explicitly returning an Either. 
Can you give some details about the projects you used rio in? Were they greenfield or did you transition any existing projects? Was it for work?
Does anyone know a use-case for a function with a type like "a -&gt; m (b -&gt; m c)"? That is, assuming :~&gt; is a kliesli arrow with the same right associativity as -&gt;, is there a use for a function with a type "a :~&gt; b :~&gt; c"? I was messing around with some stuff and ran into that type a couple times. 
In `waitCatch`, `var` has type `MVar (Either SomeException a)` due to the definition of `Async`, so `readMVar var :: IO (Either SomeException a)`. Was that your question? (N.B.: In general, please post code as text, not as an image. Makes it easier to answer your question.)
This all was years ago. No one is going to waste their time searching through github, reddit posts, or trying to contact people who were communicating with cabal team. Google "cabal hell" and see for yourself. &amp;#x200B;
My question about Liquid Haskell has always been, does it work with runtime values? It would be totally awesome if it did. 
Since the burden of proof lies with the person making the claim and you don't seem to be willing to back up your accusations with evidence I'd strongly suggest you stop spreading such unproven claims which above all are harmful to our community. For all I know your memory of events from many years ago is most likely inaccurate, distorted or you might have been fed false information in the first place. Spreading inaccurate information about this controversial topic is harmful to our community. Please stop doing that.
Some of the most prolific use of quickcheck-style property testing is in Erlang/OTP, where `IO` isn't even annotated.
Excuse me, but you are the one spreading unproven claims that stack developers did it to splinter community and to profit from it. Besides I already told you about Cabal Hell. All you have to do Google it. If you are unable i'll just link you the article from WellTyped themselves: [https://www.well-typed.com/blog/2014/09/how-we-might-abolish-cabal-hell-part-1/](https://www.well-typed.com/blog/2014/09/how-we-might-abolish-cabal-hell-part-1/) Notice this article is from 5 years ago. And we endured under Cabal Hell much longer than that. &amp;#x200B;
Nice! &amp;#x200B; I am suddenly inspired to make mathematical videos for Youtube in a similar style to 3Blue1Brown.
This is awesome!
What do you mean by something working for runtime values? Liquid Haskell reasons about all possible values the data can take at run time but does not have anything to do with dynamic, runtime, checks. &amp;#x200B; Can you give an example of what you mean?
What would Liquid Haskell do in the case below, where a compile time failure is not possible? main = do year :: Int &lt;- readLn month :: Int &lt;- readLn day :: Int &lt;- readLn date = Date day month year
 data Date = Date Int Int Int main :: IO () main = do year :: Int &lt;- readLn month :: Int &lt;- readLn day :: Int &lt;- readLn let date = Date day month year print date Why isn't compile time failure possible? With Liquid Haskell you would annotate the date fields must be in a particular range or match some joined computation (associating the months with the range of the days). Then you would see an error on the \`let\` line since there is no guarantee the values produced by \`readLn\` satisfy the preconditions for the \`Date\` constructor.
Yes, I want to import diagrams just like I do with LaTeX (and soon gnuplot). Reanimate will be the glue that binds everything together.
&gt; Excuse me, but you are the one spreading unproven claims that stack developers did it to splinter community and to profit from it. This is making no sense. I did no such thing. You must have me confused with someone else. &gt; Besides I already told you about Cabal Hell. All you have to do Google it. If you are unable i'll just link you the article from WellTyped themselves: https://www.well-typed.com/blog/2014/09/how-we-might-abolish-cabal-hell-part-1/ &gt; &gt; Notice this article is from 5 years ago. And we endured under Cabal Hell much longer than that. This is also not making any sense to me. You made the claim (quoting your comment upthread) &gt; The particular reasons as far as I remember were lack of willingness to collaborate or communicate from cabal maintainers. Requests to fix obviously broken things or add vital functionality or even accept patches were ignored for years. At some point you have to just move on and do it yourself (stack) In fact, the existence of article you referenced appears to support the opposite of what you're claiming: The cabal developers analyzed the problem, came up with an actionable plan to "abolish" cabal hell *and* communicated their plan to do so via blogposts. I really don't see how you'd be able to derive "lack of willingness to collaborate or communicate" and your other accusations from the blogpost. Please reconsider if you're accurately perceiving past events or if maybe you are in fact mistaken.
Thank you and everyone else for your help. I don't understand though why megaparsec is able to handle my second issue while parsec doesn't. 
I was there through all this. You weren't. Their first attempt at Cabal Hell fix was introducing some options to generate "freeze" file from your current cabal file. It did not work out well.Not only did it not fix the problem, but it introduced another layer of complexity and confusion. As you see from their current rewrite eventually they accepted that the only way to fix cabal is to throw it out of the window (hence the new v2 version with all the new-foo commands) But to arrive to that acceptance took them too much time. And most people (me included) were not in a position to wait another decade. &amp;#x200B;
Looks nice, with some nitpicks: \- \`reverseTuple\` is swap from [\`Data.Tuple\`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Tuple.html). \- the signature \`turn :: GearState -&gt; Maybe GearState\` gives the impression that a turn might fail, when it's not the case. I would add that \`Maybe\` at the last possible moment, in \` getNextStates\`. \- The code of \`forward\` is quite similar to \`backward\`. Make it a single function that receives the modification function as a parameter. \- In \`forward\`, you are basically fmapping over the result of \`lookup (face, dir) connections\`. Leaving the pattern match is not that bad though. \- You are storing the history of movements in the \`GearState\` type itself, and then "adding to the history" in several places. Perhaps it would be better to store the history in a different way, and add an item to the history in only one place. \- Instead of having a \`search\` function with limit parameter, perhaps it would be better to simply generate a (possibly infinite?) list of movements, and then \`take\` some solutions out of that list. An empty list would be no solution.
Thanks! I like all of these. Any suggestions on the history storing mechanism? I have the vague idea that the Writer monad is applicable here, but I don't really know how to use it. 
Would you kindly provide an example? I've never used Liquid Haskell.
https://github.com/pashky/restclient.el gets you the HTTP client, at least. There have been attempts to make local history work in Emacs, but there's nothing on par with IntelliJ that I know of. undo-tree is part of the picture, but it's not really comparable. There are some tracker-specific packages to integrate with Org mode, and also https://github.com/arbox/org-sync/blob/master/README.md if you can write your own backend. I used org-trello for a while, and that worked well.
This analysis applies to decoding to `Value`, but presumably not necessarily to decoding to some other type. If the pipeline from `Value` to the ultimate result benefits from laziness, presumably you'll get that from `decode` but not `decode`'.
I can't disagree with that!
The comonad/distributive stuff has always been the part of `recursion-schemes` I didn’t fully grasp, but I get it now! Thanks!
Parsec is mostly unmaintained where as a lot of work has gone into improving Megaparsec over the last couple of years.
I should make it more clear that the parsing pipeline after `Value` for `decode` and `decode'` are essentially the same, there is no difference in the second parser layer. So I don’t think strictness makes a difference here. Seat back and reconsider this problem, it’s more like a trade off between time and space, the document should be more clear on this difference.
Sure. If I run \`liquid test.hs\` where \`test.hs\` has the above \`main\` and the post's liquid Haskell declaration of \`Date\` and annotations I get a type error of: **** RESULT: UNSAFE ************************************************************ /private/tmp/test.hs:38:14-21: Error: Liquid Type Mismatch 38 | let date = Date day month year &amp;#x200B; Voila, a compile time failure. The column range spans \`Date day\`. It goes further to tell us the inferred type: &amp;#x200B; Inferred type VV : {v : GHC.Types.Int | v == ?a} not a subtype of Required type VV : {VV : GHC.Types.Int | VV &gt; 0 &amp;&amp; VV &lt;= 31} So we provided an int (\`day\` in this case) and that date can be any value \`?a\` but it should be in the range of \`VV &gt; 0 &amp;&amp; VV &lt;= 31\` among other restrictions that aren't reproduced here. There is another, much more verbose, error for the whole use of \`Date day month year\` but it reproduced the entire set of restrictions on year/month/day and is thus hard to read.
Thanks, that is helpful! By "successfully handling" I basically mean "returns control and doesn't fail". The idea of "auto acking" is coming from this: I want to "ack" all the messages that I receive. But when I receive a message I want to transform it (extract some data, filter out uninteresting messages, etc.) so that my service could deal with what makes sense, not with wrapping envelopes etc. But the original message (including its envelope) is required for acking, so I wanted `autoAck` interpreter to behave like a bracket. Something like: runM . runQueue uri . flattenBatches . autoAck . mapReader f -- given (a -&gt; Maybe b) transform Reader a to Reader (Maybe b) . catMaybeReader -- don't care when there is nothing to handle $ myService but having `autoAck` still acking all the messages after the "downstream" is done with them. Is something like that possible? 
This might be relevant to this blog post. I've asked on StackOverflow about year and half ago about the difference between `decode` and `decode'` functions from the `aeson` library and received nice answer: * https://stackoverflow.com/questions/45374472/what-is-difference-between-decode-and-decode-functions-from-aeson-package But the blog post makes the point very clear, thanks for the writeup! 
What would be the best approach to memoize a function over bounded types ? Something like : f :: Word16 -&gt; Word16 g = makeLUT f Could this be done during compilation time ?
Since 20016, cabal has been giving away commit bits extremely freely! https://github.com/haskell/cabal/issues/3567
&gt; Previously: You had to install the tool yourself. It had to be the right version to match your IDE. It had to match your GHC version. It had to be configured to your package properly. I mean, there's dante, a lightweight fork of intero that doesn't need stack and people seem to be able to use it just fine :-) https://github.com/jyp/dante 
Lol, rule number one of discussing editors is never tell an emacs user "emacs can't do that"!
Like /u/tom-md said, Liquid Haskell will give you a type error if you do not perform the *necessary* runtime checks. Necessary is a key word there, these checks cannot be omitted since we know nothing about the runtime inputs. Static analyzers like Liquid Haskell can help us in two ways: 1. They allow us to omit runtime checks that are implied by the context, and thus unnecessary. 2. The force us to include runtime checks that are absolutely necessary.
The accepted answer is not clear to me: `For the array decoded with decode, the values are not forced, but the ones decoded with decode' are`. I want to add that the array's item is actually forced, but save in a list and suspended inside a thunk, waiting for packed to vector.
If you put masking tape on the piece of wood before cutting you don't get charing on top.
Given that Haskell emphasizes static checking and safety, why don't I hear about it being applied more to dangerous situations like aviation or medical devices? Maybe I'm biased in what I notice, but it usually seems like people are busy building web apps. APIs with Servant/Aeson, front end code with FRP stuff, etc. I know Swift Navigation uses Haskell for GPS applications (automotive?)...is anyone else taking advantage of the type safety for an application where safety is important?
diagrams has a lasercutter backend? awesome!
Yes, I think Stack had a positive influence on the cabal team overall. Lit the fire under them.
The laser cutter I was using takes svgs. Any line that's exactly 0.001in is interpreted as a cut.
Given the existing function getNextStates :: GearState -&gt; [GearState] perhaps you could use it to write a function getNextHistories :: ([GearState], GearState) -&gt; [([GearState], GearState)] and handle histories there, basically prepending the current state to all resulting histories. Also—I'm not sure it is a wholly good idea—you could write getNextHistories :: NonEmpty GearState -&gt; [NonEmpty GearState] That is, use `Data.List.NonEmpty` and simply consider the head of the list the current state. The Writer monad would be applicable on top of the List monad if we were doing depth-first search (what the monad instance for List does) but I don't see a natural way of using it here. 
Will the webinar be recorded and shared later on? I'd love to attend but the time is very unfortunate (3 am in my local time).
Write lots of code, it's the best way to learn.
&gt; I have no opinions on FPCo in general aside from technical praises and criticisms. Is this what you're telling yourself? &gt; You could go through my entire posting history and not find a single anti-Stack comment. I applaud your efforts of cleaning up your posting history. But despite what you're claiming *now* you seem to have had a strong preference of cabal over Stack in the past. I don't know if you're even aware of this but you're showing an alarming amount of gaslighting signs. This has been a revealing conversation which has reached a point where I see no reason to continue. But be assured I'll be watching you closely to see whether this is all just gaslighting or you're going to make good on your github-edited in claim of "having changed your anti-Stack opinion dramatically since it was made". 
I think the brilliant ["What I Wish I Knew When Learning Haskell"](http://dev.stephendiehl.com/hask/) by Stephen Diehl may be exactly what you're looking for.
Well, yes, but that gets me details, not overall ideas. For example, I've found that my old "import IO" now needs to be "import System.IO". But the overall structure of the standard library eludes me. I can find the [language extensions page](https://wiki.haskell.org/Language_extensions) on HaskellWiki, but the list says it is incomplete, some of the links are broken, and I have no idea at all how I'm supposed to find out about new extensions and what they do.
Thanks, I'll take a look at that.
Too little too late. They'll never be able to recover the lost time and opportunity. Also they disqualified themselves with questionable tactics such as [here](https://www.reddit.com/r/haskell/comments/7i4ukq/stacks_nightly_breakage/) and [here](https://www.reddit.com/r/haskell/comments/7kt36c/lts_stackage_with_ghc822_released_today/drhiwvg/) or [blocking Stack developers from cabal's github repo](https://twitter.com/snoyberg/status/940152919680266240) or wasting time developing infantile [malicious Setup.hs scripts targetting Stack users](https://github.com/tonymorris/do-not-use-stack).
Probably the [GHC User Guide](https://downloads.haskell.org/~ghc/8.6.3/docs/html/users_guide/glasgow_exts.html) is your best bet.
Haskell Prime: I haven't paid attention at all (it seems like committee stuff, not regular Haskell-user stuff) The Haskell platform: A way of installing Haskell + common packages. On any linux I prefer to just install 'ghc', 'cabal-install', but maybe on Windows/Mac it has more value. You should know about Stack / Stackage. It's a newer packaging system, which lets you build different projects using different versions of GHC (instead of whichever one version of GHC happens to be installed). It also allows you to group together packages under a single version instead of choosing the versions individually. If you're on linux, don't install Stack via the system package manager; always download the freshest binary instead. That said, Stack still fails spectalularly for me in different ways every time I revisit it, so I prefer hackage/cabal. Lenses are very much a thing, and are used by other packages, (e.g. wreq). I get by without knowing them though. There have been quite a few web frameworks over the years. I feel like Servant is the current king of that space, and definitely worth learning. I believe 'iteratees' were a solution to the lazy IO problem. I ended up using 'conduit' for that, though these days I would be tempted to check out \`streaming\` as well. Language extensions: I typically start my source files without any, and then turn them one-by-one, usually when the compiler tells me to, e.g. InstanceSigs and ScopedTypeVariables. When using 'aeson' for json serialisation, I use DeriveGeneric, GeneralizedNewtypeDeriving, and DeriveAnyClass, which really cut down on the boilerplate.
There is a new typeclass called `Applicative` lying between `Functor` and `Monad` that is quite useful and widely used. See also the `Traversable` typeclass. 
&gt; Stack still fails spectalularly for me in different ways every time I revisit it, so I prefer hackage/cabal. Please stop spreading such "Stack does not work" FUD
This is really cool, I always wondered quite what this was for. However, I wonder if we'll be keeping this... [https://github.com/ekmett/recursion-schemes/pull/51](https://github.com/ekmett/recursion-schemes/pull/51) talks about moving to gather/scatter rather than using distributitive laws and comonads. /u/gelisam \- any thoughts?
Skimming the release notes for major GHC versions should be a good way to get an overview of the important changes. [This page](https://downloads.haskell.org/~ghc/) has a list of releases with online docs.
Extensions are with a capital -X; the lower-case -x ([from the GHC manual](https://downloads.haskell.org/ghc/8.6.3/docs/html/users_guide/using.html#overriding-the-default-behaviour-for-a-file)) Causes all files following this option on the command line to be processed as if they had the suffix ⟨suffix⟩.
&gt; for a while people were mumbling about "iteratees" but they seem to have stopped and I don't know why Basically, Oleg's work on iteratees has turned into several different (easier/more user friendly) libraries for stream processing of data, the 3 most important of these (in no particular order) are: conduit, pipes, and machines. So the answer to "why did all the iteratees hype stop?" is "we have several amazing, production-grade, user-friendly packages for that sorta thing based on iteratees now, so there's no need to hype them further"
(Shameless plug:) I've written an up-to-date [list of GHC extensions](https://limperg.de/ghc-extensions/) with short explanations of what they do. It is quite long, fortunately or unfortunately.
Indeed, it seems you're right. In hindsight that makes a lot of sense - even if `decode'` wanted to be non-lazy going from `Value` to the ultimate result, I'm not sure it could do better than evaluating to WHNF.
You could use a vector for value lookup. That'd be pretty fast. You need another restriction for `getIndex :: Bounded b =&gt; b -&gt; Int`.
look like monadic bind.
We have found using cabal gives better reliability and consistency for production code bases, using nix to manage packaging as well. Stack has all the fun features, choose accordingly
Looks a bit too restrictive - there's a `day &lt;= 30` that I think should be `day &lt;= 31` and a `day &lt; 20` that I think should be `day &lt; 30`. Though it says that `Date 29 02 2016` works, so if it actually does, then I'm confused.
Watch [this lens video.](https://skillsmatter.com/skillscasts/4251-lenses-compositional-data-access-and-manipulation) Then you'll be mumbling as well :)
The logic is `month /= 2 || (day &lt; 30 &amp;&amp; ...` i.e. "either the month is not February, or the day of February should be less than 30 and either less than 29, or a leap year."
Too bad you cannot attend. Not worry though, if you register, but don't attend, you will still get an email sometime after the webinar with a link to the recorded video. 
Safety-critical systems are more than just having correct behaviour, usually things need to have correct *timing* too. So if there were a hard realtime variant of Haskell, maybe that would be used more in aviation.
Great thanks!
Looks like it’s headed for the chopping block. Bummer, since the theory is exceptionally elegant, but if the code was generating unlawful schemes then it should indeed be ditched. When this lands I’ll leave a note at the top of this article explaining what the deal is.
For the libraries, I'd start by checking out the documentation for the base package on Hackage. http://hackage.haskell.org/package/base Quite a lot of useful stuff in there (including the Prelude, which has changed a little bit). Probably the next most important library is containers: http://hackage.haskell.org/package/containers which is where FiniteMap (renamed to Map) and Set went to. As for extensions, it's quite fine to pick them up as you run into them, but yeah, they're in the GHC User's Guide. https://downloads.haskell.org/%7Eghc/8.6.3/docs/html/users_guide/lang.html
Considering that a Kleisli category arises from a monad and monadic bind is like “application” or curried “eval” of such arrows, that the type somewhat resembles that of monadic bind is to be expected, IMO. However, note that bind is `m a -&gt; (a -&gt; m b) -&gt; m b`, a different type. If `a -&gt; b -&gt; c` is the curried form of `(a, b) -&gt; c`, `a -&gt; m (b -&gt; m c)` is the curried form of `(a, b) -&gt; m c` for Kleisli arrows, and the parent commenter is asking about the significance of this. I suppose that the curried version allows for partial application in a monadic context or something.
And those were off the top of my head.
Exactly. In case anyone's wondering, to get there, I was looking at the difference between functor and applicative, and seeing if it could be applied to monads too. That is, a function with a type m (a -&gt; m b) -&gt; m a -&gt; m b. I've ended up calling this function "bindap", or "&gt;*&gt;=". It can actually be defined in terms of what monads already have, mx &gt;*&gt;= mf = join $ (&gt;&gt;=) &lt;$&gt; return mx &lt;*&gt; mf And it let's you do this with a f :: a :~&gt; b :~&gt; c f =&lt;&lt; ma =&lt;*&lt; mb So my question was, is there any f that has that kind of signature that's actually useful, or is it just a cool artifact of the type system 
Sorry, I didn't get it from the first glance through README, but does org-sync also check out the respective VCS branch when switching tasks?
[try](http://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Exception.html#v:try) is also just a function (just in case you're missing that piece of the puzzle).
I'm working on something I and I'm having trouble balancing laziness and my monads. More specifically, I have functions that produce `(Monad m) =&gt; [m a]`, and I'd like to be able to still do things like filter and fold (map is pretty easy). Is there any place I can look that has resources on how to handle this well?
This is a masterpiece. In one comment we have: - Dismissing other people's experiences as "FUD" - "RTFM!" - "You're holding it wrong!" I wouldn't have said anything, except that I've seen this same comment from you before when someone has expressed frustration with Stack.
I wish there was a way of converting a liquid haskell type to a function so you don't have to recode your run time check
This is really cool! My feedback (mostly on the article) after playing around with it last night: \- As far as I could tell, there's no link to the hackage (or even github) for the validity library in the article. Should add this in so that it's easier to explore further \- Your piece of code right above the "Overriding genValid to make it faster" section presents itself as a complete code snippet, but it still takes a bit of work for the reader to reproduce themselves because we don't know all the imports off the top of our head; which is exacerbated by the hackage link not being there. It would be great if you could modify these examples (both in the article and github readme that presents itself as a full example) to also include imports \- Once I found out that, I had to go through the same exercise for Text. Might be good to include an example (with imports included) using "validity-text" (or any other "validity-foo") to make this common case a bit more straightforward and demonstrate how these packages interact. \- For somebody using it for the first time, I wasn't sure if the best reference was the article or the Readme. Each has information that the other does not, so you kind of have to bounce between the two a lot. In any case, I really enjoyed the progression of the article and the thoughtful design of the validity library. &amp;#x200B;
Very nice! A few years back I made some finger-jointed boxes with Diagrams + laser cutter, but I never got around to documenting the pixel-to-inches hacks that I needed. https://github.com/bergey/demos/blob/master/Boxen.hs
How many of us were using Haskell in 2000? The oldest version of base on Hackage is from 2009. I suspect few people were even around *then*. I hope someone answers this question because it would be a very interesting history of most of Haskell's lifetime. In addition to other people's suggestions, I might suggest trying your hand at just building something and you'll soon find the newer concepts bumping into you!
Very cute, love the pixelated look! I'd agree too, Halogen is a lovely framework. I've been using it at work for simple UIs. We're currently favouring it for our UI work generally. The performance of PureScript for graphics also seems perfectly reasonable, I made some simple newtonian physics simulations, [elastic collisions that don't lose energy](https://chrisdone.com/toys/elastic-collision-balls/) and [one to simulate snooker](https://chrisdone.com/toys/elastic-collision-snooker/). It's true, things like `zip [..]` are just nicer in Haskell over PureScript. You miss non-strictness a bit, but otherwise I haven't noticed it much.
Out of curiosity: what were you playing with during this time? 
How beginner-friendly of you to insult the user. Definitely presenting the best face of the community here. 
https://github.com/Gabriel439/post-rfc/blob/master/sotu.md offers a nice overview over the Haskell ecosystem. Some parts are a bit outdated already though. http://www.datahaskell.org/docs//community/current-environment.html is a more up-to-date overview from a data science perspective.
&gt; the masterpiece Katamari Damacy on the Nintendo Switch. indeed it is a masterpiece
Also you probably don't want space leaks for a critical application
Not yet. Not without generating the animation locally.
Here you go: [https://twitter.com/snoyberg/status/940152919680266240](https://twitter.com/snoyberg/status/940152919680266240) Cabal developers blocking stack devs from github access. &amp;#x200B; There are more examples [provided here](https://www.reddit.com/r/haskell/comments/auwlx6/another_idea_haskell_and_intellij/ehjgwd4)
Compulsively reducing that definition gets me to `((&gt;&gt;=) . mx) =&lt;&lt; mf`, which is sort of pleasant to look at. Fiddling with typed holes and Hoogle gave up absolutely nothing for a useful `f`, though.
Running that through expression through a repl, I get :t \mx mf -&gt; ((&gt;&gt;=) . mx) =&lt;&lt; mf Monad m =&gt; (a1 -&gt; m a2) -&gt; ((a2 -&gt; m b) -&gt; a1) -&gt; (a2 -&gt; m b) -&gt; m b Which definitely don't look like anything I've seen before, definitely not a reduction of my (&gt;*&gt;=). Actually, whatever type that is, I think it's just about the craziest I've ever seen, so I admire you for that. 
Oh, whoops, you're right. I trusted the REPL too much and must have mistyped somewhere in there. No wonder I couldn't find a nice `f`. :v
This sort of user-hostility is part of why I don't use stack.
The proper reduction was `(=&lt;&lt;) . (&gt;&gt;=)`, which is even neater looking. Definitely thought I was going loopy for a minute there.
I started using Haskell with MacGofer in 1992 or 1993. I tried using Yale Haskell and GHC but they were impossibly resource intensive for my home Mac SE/30. I do remember following on Usenet and mailing lists the excitement over putting constructor classes and monads into Haskell 1.3. I started using GHC at work for an internal project in 1995 or 1996. I used Haskell for personal projects till around 1999, then stopped and didn't look back at Haskell again until 2011, for a variety of reasons (my personal projects gravitated to using OCaml and Perl). It was a huge, huge shock in 2011 coming back after missing more than a decade of developments!
Well *that's* really pretty! ...more unintuitive to figure out what it does, but very pretty. Now we just need to figure out if it's useful!
Wtf is wrong with you. Once it was investigated and realized that the block had consequences for interactions on common repos and not just personal repos, it was immediately lifted. The purpose of that block was to smooth over personal frictions not as an act of hostility, and when it became apparent for technical reasons that this would not be the case, it was fixed. What chip do you have on your shoulder that you keep dragging up this old, discredited junk.
That question was already answered. People who keep dragging the old discredited junk about sinister reasons for creating stack as a means to splinter the haskell community. When the people who keep bringing it up will finally shut up, so will I. &amp;#x200B;
 [1..10] &gt;*&gt;= [pure . (+1), pure . (+2)] so we can recover `&lt;*&gt;` from _whatever_ this is via mf &lt;*&gt; mx = mf &gt;*&gt;= fmap (pure .) mx
As you probably know, you can use `sequence` to do `[m a] -&gt; m [a]`, and then `fmap (map foo . filter bar)`, etc. But I think what you might be looking for is a streaming library, which lets you interleave effects with list-like API, and solves some other issues. You might check out `conduit`, `pipes`, or `streaming` (there may be a new hotness in the streaming space I'm not aware of or can't think of).
I was around in 2000 of course! 🙂 I first looked at functional programming in 1997 as part of an introductory computer science course that used Miranda. One year later I shortly considered using LISP and then delved into Haskell.
Also, the work you did was excellent. Thanks for making `cabal-install` a better experience for me.
The closest situation I'm aware of to what you describe is Jane Street, which uses OCaml (which has a similar type system to Haskell, but it's strict and doesn't control purity via the IO monad) for financial trading.
So, given that this transformation is safe for `Rational`, will GHC do the optimization for this type? And, if not, would it be safe to add this optimization to `base`?
NASA has all the best space leaks.
If you want to guarantee it is done at compilation time, use TH. If you can provide an `Ix` instance you can just use a lazy array. ISTR some memoization library that would use a lazy tree structure to memoizing over products (tuples or records) and sums on hackage but I don't remember the name.
I don't think GHC currently does this optimization, but yes it would be perfectly safe. 
Some criticism, hopefully aiding the project to find a fruitful direction. The largest problem is topic focus. While the title promises design advice, the five chapters are more heavy in monad-tutorial-like content (in the broad sense). The example domain (spaceships) is hard to relate to. The presentation was somewhat disorganized. I understand that writing text is an iterative process, but with such a large body of text, iteration would take a good while to arrive to a condensed presentation. Likely fix in order to finish on time and have good signal to noise ratio to readers: - Restart from zero. - Make strong assumptions about readers. Assume they have a strong command of Haskell. No need for tutorials. - Ditch fictional example domain. Describe design advice in the abstract. Small support example only if necessary, but rather assume the reader will get your point. - Don't try to sell the functional paradigm. It sounds boasting, and your audience is already sold (nit: FP in Scala book was terrible, 5 pages intro just about how good FP is trust us). - Aim for a short compact ebook of say 20 pages in total. Good luck!
First rule of patreon support: if you need to check your finances, don't.
Frankly it requires knowledge of runtime semantics for it to be clear when strictness is a performance advantage. Laziness and strictness are, after all, mostly just optimizations in terminating computations. I might even avoid the concept of laziness until the students are at a point that runtime semantics are relevant to them.
`foldl` vs `foldl'` was a tradition example. I'm pretty sure …Joachim Breitner? improved GHC's optimizer to handle the difference automatically, though. I think it's still a good pedagogical example. Maybe set `-O0`? Or find a flag for the new cleverness and switch it off. More generally, most functions that accumulate some value often benefit from strictness. If that accumulator is a tuple with non-strict fields, that's another classic space leak (even with `foldl'). Allocation is relatively expensive, so fixing space leaks kind improve runtime. HTH.
I really like this article by Alexis King. http://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/ I'm not sure it's the best _first_ thing to read 20 years later, but it gives the major extensions some characterization. Will accelerate you at some point. Good luck! Welcome back :)
Well, I don't expect them to *understand* when to use `seq` at this point. I just want to demonstrate that it can change things -- sometimes for the better. As for laziness, I think it has lots of impacts that are noticeable and useful to someone just learning the language: it allows us to create infinite lists, more generally it allows us to treat lists as streams, and it lets us write short-circuiting boolean operations.
&gt; foldl vs foldl' was a tradition example. I'm pretty sure …Joachim Breitner? improved GHC's optimizer to handle the difference automatically, though. Yes, that, or something similar, was my go-to example in the past, but then one year it didn't work the way I expected. I never considered turning off optimizations; I'll give that a try. &gt; Allocation is relatively expensive, so fixing space leaks tends to improve runtime. Good point. I think it's rather obvious that strictness can improve space usage, and that little note explains how it can improve time usage as well.
I believe you're not going to get asymptotic tine improvements from strictness, only constant ones (but those constants can get very big). It's only for memory that strictness can give asymptotic improvements.
Let's say you've got a web server, and you're keeping track of a how many requests you serve in an `IORef Int`. Whenever someone visits a page, you do: modifyIORef hitCounter (+1) Now, in Haskell this is lazy. So we aren't merely incrementing a counter. We're storing a thunk. And, after thousands of hits, this `IORef` will look like 1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+... Storing this value requires significantly more memory than simply storing the number. This takes more-and-more memory. With each extra bit of memory it stores, it increases the amount of time the garbage collector must spend traversing the heap. When does the `IORef` collapse the results into a more ordinary value? Only when you force it. So: print =&lt;&lt; readIORef hitCounter will actually cause all the evaluation to work out. So, instead, we use `modifyIORef'`, which evaluates the value to weak head normal form. Since WHNF for numbers is the number itself, this changes the hit counter to take constant memory. 
The sorcerer was a little jerky, but I had a good time! FYI: I noticed a possible bug when trying to compose a three letter object with an already composite object. It just didn't like it, but composing the three letter object with a single object (of any number of letters) worked fine. I'm a haskell beginner and have never touched purescript, but i can post an issue and maybe find the time for a pull request.
(Nice example! Thanks u/chrisdoner !!!) You can in fact convert LH types to functions to avoid re-coding if you like, for example, see this: [http://goto.ucsd.edu:8090/index.html#?demo=permalink%2F1551502899\_16725.hs](http://goto.ucsd.edu:8090/index.html#?demo=permalink%2F1551502899_16725.hs) &amp;#x200B; In essence we convert Chris' &amp;#x200B; \`\`\` {-@ type Day = {v:Int | v &gt; 0 &amp;&amp; v &lt;= 31 } @-} \`\`\` &amp;#x200B; into a function &amp;#x200B; \`\`\` {-@ inline okDay @-} okDay :: Int -&gt; Bool okDay v = v &gt; 0 &amp;&amp; v &lt;= 31 \`\`\` &amp;#x200B; which lets us reuse \`okDay\` both to define the type and the actual run-time check: \`\`\` { day :: {v:\_ | okDay v } -- semantically identical to Chris' type \`\`\` &amp;#x200B; and then in the code &amp;#x200B; \`\`\` if okMonth day month then if okDay day &amp;&amp; okYear month day year \`\`\` &amp;#x200B; &amp;#x200B; 
Pinging /u/SrPeixinho
That is a sound advice but my situation is not that alarming! I need to check if I can support the many projects I want to support while being consistent. 
Is it possible? Maybe, many things are possible. But it’s not a question that I think is possible to answer except by trying. Give it a try. 
I'd say the first step would be to translate the implementation to Haskell or another lambda calculus based language. The prospect of developing something like this in C seems overwhelming.
Note that if you compare the number of reductions, then lazy evaluation is *always* at least as fast as eager evaluation. But it may be that eager evaluation uses more space than lazy evaluation, and in practice, this may make a difference in wall clock running times.
That's awesome! Thanks for sharing it.
Can't speak for 2000 at all. But for 2009, don't judge by base. They only started putting base on Hackage afterwards, because it required special handling, like ghc-prim. I started using Haskell in 2007-2008 by which point [Hackage was already a web service populated with about 1,000 packages](https://web.archive.org/web/20081021114958/http://hackage.haskell.org/packages/archive/pkg-list.html), and some (myself included) have described 2007 as a turning point in Haskell's popularity. SPJ was doing talks like [A Taste of Haskell](https://www.youtube.com/watch?v=jLj1QV11o9g) about xmonad, and the IRC #haskell channel became the most populated language channel on Freenode, and reddit's /r/programming was spammed with Haskell posts all the time. Check out [this trend](https://trends.google.com/trends/explore?q=learn%20haskell&amp;date=all) that really kicks off around that period. 
My first reaction was “Idk who that user is but the person they really need here is Victor Maia” Then I realized lol
im searching a function that returns an arbitrary string that only consists of letters and the first letter needs to be lower-case. it is for a coding challenge and "x" counts as 3 tokens, whereas someFunction that returns a string counts as 1. the goal is to have as few tokens as possible any ideas? i can import whetever i want
System.Info's arch does the trick 
As a Stack developer and author of the early version (I don’t maintain it now), the effort was about solving client problems, coming up with a tool that matched our own workflow with a lot of defaults, like stackage, multi-package projects, autoinstalling GHC. A separate codebase gave us the freedom to move quickly and make opinionated decisions. I think that paid off a lot. I’d definitely do it again. I think this just comes down to whether a tool fits your groove or not. If it does then you’re willing to put up with bugs and rough edges. cabal-install has them, stack has them, and nix has them. For example, I tried Nix on MacOS once and it failed spectacularly too. But I didn’t look into it further because I’m not motivated to. An enthusiast would. It doesn’t mean I think Nix is bad, I was just unlucky. Meanwhile I haven’t used cabal since we released stack just because stack has all the right defaults for me. If one day cabal does everything I want with pretty minor configuration then I’ll switch back to using that and avoid the nontrivial amount of maintenance involved in keeping such tools up to date. If anyone has written or would like to write a page about how they switched from stack to cabal and enumerate how they achieve the same workflows and features that they valued in stack, I’d love to read that. I’m currently learning NixOS in a docker container. Regarding the hostility, I see that everywhere but I think a lot more on reddit and Twitter. Something about the platforms seem to make people loopy. I don’t know who the people in this thread are. If stack doesn’t fit your needs that’s fine by me. Keep enjoying Haskell in your own way!
Thank you! That seems like what I am looking for 
[duplicate](https://www.reddit.com/r/haskell/comments/avg1mi/quickcheck_hedgehog_validity/)
I didn't know his name, but I understood like 3/4 of the OP's post and searched for his article and had the same realization. [Here's one of his articles](https://medium.com/@maiavictor/some-functions-may-have-negative-complexity-im-worried-for-my-crypto-c53f6e7343d3)
&gt; But it may be that eager evaluation uses more space than lazy evaluation I guess you mean less space?
Not AFAIK, but it's hard to say without some actual code. Hold tight though; I'm working on getting bracket working!
Dan Doel has a [great overview](https://www.youtube.com/watch?v=McFNkLPTOSY) of some simple functions with different (and sometimes counter-intuitive) semantics along with their tradeoffs. 
When you have a sum type, where each case has some fields in common, say a and b, but some fields you unique to each case, do you represent it as, data Sum = C1 a b c | C2 a b d ... or as: data Common = Common a b Sum data Sum = C1 c | C2 d ...
Is there a way to optimize (like ghc -O2) the expressions that are entered via the ghci REPL? 
IMO STG is much better option for source language than GHC Core. GHC Core has too many tricky internal conventions, while STG is plain simple. 
Generally the second, though certainly subject to trade-offs if I want certain guarantees enforced by the type system or if one of them has significant performance of interoperability advantages.
I can never remember which one is Julian Barret and which one is Noel Fielding. 
in the very last episode right now (8 ) he introduces the basics of concurrency in haskell: MVars. Being lectures about parallel and concurren programming, I think that the pace is quite slow. Boring for medium level haskellers.
I also recommend the papers describing how Erlang QuickCheck is used for a database, controller networks, also Google Drive and Dropbox.
Yes. 🙈 Thanks!
Improved productivity only matters if it reduces work that *I* have to do. Rewriting emacs in Haskell means that you'd need to do a ton of work to rewrite the editor, and then a ton more work to rewrite the plugins you care about. Every time you want to use a new plugin, you have to write it yourself, rather than plugging it in. I'm not paid to maintain my editor setup. I'm paid to deliver working software. For "delivering working software" in my domain, Haskell makes a lot of sense. For other things, it doesn't - not because it isn't great, but because it doesn't work out time/energy-wise.
you’re asking the wrong question, my child.
You can see that these two are equivalent in a straightforward manner by just following the algebra. Start from the definition g = filter (isDigit . head) . groupBy (on (==) isDigit) Recall that function composition is nothing else than f . g = \x -&gt; f (g x) Therefore g = \x -&gt; filter (isDigit . head) (groupBy (on (==) isDigit) x) which is the same thing as g x = filter (isDigit . head) (groupBy (on (==) isDigit) x) or (just renaming `x` to `s`) g s = filter (isDigit . head) (groupBy (on (==) isDigit) s) Does that shine any light on things? (Yes, I know that in fact `f x = ...` is not *exactly* the same as `f = \x -&gt; ...` in GHC. I'm ignoring that for the purposes of this explanation.)
Ok! # Partial applications `filter (isDigit.head)` is a partial application. Filter has been applied to a predicate, but it needs a predicate + a list to return the filtered list. So `filter (isDigit.head)` returns a function that takes a list and filters it. `groupBy (on (==) isDigit)` is a partial application. `groupBy` wants an equality test function and a list to operate on, and returns a list of grouped elements (in lists). Since it has been applied to only the equality test function, it has returned the function that takes just a list and groups them according to the already bound equality test. # Composition So: 1. `filter (isDigit.head)` takes a list of something and filters it, returning the filtered list. 2. `groupBy (on (==) isDigit)`takes a list and returns a list of grouped elements 3. We know that `(f . g) x = f (g x)` so if the function you were trying to understand was written as let g x = filter (isDigit.head) . groupBy (on (==) isDigit) $ x Then you should be able to see that we've got the pattern `func1 . func2 $ x` where `func1` is just `filter (isDigit.head)` and `func2` is just `groupBy (on (==) isDigit)` `func1 . func2 $ x` just means: "apply `func1` to the result of applying `func2` to x" So that means we're grouping `x`, then filtering. # Eta Reduction What do we get if we knock `$ x` off of `filter (isDigit.head) . groupBy (on (==) isDigit) $ x`? The `$ x` is just the application of the function to the left on `x`, and the function to the left must be a function which groups then filters, which is what we want `g` to do. Well if we've got a function that does what we want `g` to do, why bother saying &gt; "The application of `g` on `x` is equal to the application of `&lt;other function&gt;` on `x`." if we can just say &gt; "The function `g` equals `&lt;other function&gt;`"? That's called eta reduction: if our function definition ever comes in the form `g x = f x` then we can just write `g = f` instead.
Ok let's start here: ``` let f s = filter (isDigit.head) (groupBy (on (==) isDigit) s) ``` The statement is pretty long, so let's name some statements to simplify it a bit: ``` let sel = filter (isDigit.head) grp = groupBy (on (==) isDigit) in let f s = sel (grp s) ``` Good so far? Now here's the definition of the `.` operator: ``` (g . h) x = g (h x) ``` This defintion matches the shape of the right-hand side of the definition of `f`, so we could define `f` this way instead: ``` let f s = (sel . grp) s ``` Note how `f s` is now defined in terms of running another function `(sel . grp)` on `s`. In a very real sense, `f` *is* `sel . grp`. This is a prime candidate for [Eta conversion](https://wiki.haskell.org/Eta_conversion) - basically, we can drop the `s` term from both sides. ``` let f = sel . grp ``` Now we can substitute the defintions of `sel` and `grp` back in: ``` let f = filter (isDigit.head) . groupBy (on (==) isDigit) ``` 
Thank you so much for all the replies. I finally got it. I think I got confused by the precedence rules. I thought `(isDigit.head) . groupBy (on (==) isDigit)` was the predicate. But instead the code is composing `filter (isDigit.head)` and `groupBy (on (==) isDigit)` &amp;#x200B; Thanks again!Really appreciate it!!
Yi failed?
&gt; Could Haskell work with (compiled) optimal graph reduction? Yes. &gt; Would it be faster? Maybe. It might also increase space leakage. ISTR having some weird issue with the full-laziness transformation keeping dead data around too long, and just generally allocating too many thunks as bindings where lifted outside of decision points and then referenced from both options, even though one could never evaluate the thunk. I know optional graph reduction is different than full-laziness, but I fear that evaluating under a lambda might allocate a closure that is never evaluated, which leaks both time and space.
 let f s = filter (isDigit.head) (groupBy (on (==) isDigit) s) let f s = let g = filter (isDigit.head) in g (groupBy (on (==) isDigit) s) let f s = let { g = filter (isDigit.head) ; h = groupBy (on (==) isDigit) } in g (h s) Recall the definition of function composition: (f . g) x = f (g x) and apply it in reverse: let f s = let { g = filter (isDigit.head) ; h = groupBy (on (==) isDigit) } in (g . h) s Eta-reduce: let f = let { g = filter (isDigit.head) ; h = groupBy (on (==) isDigit) } in g . h let f = let g = filter (isDigit.head) in g . groupBy (on (==) isDigit) let f = filter (isDigit.head) . groupBy (on (==) isDigit) It has absolutely 0 to do with `filter`, `isDigit`, `head`, `groupBy`, `on`, or `(==)`.
If it's actually covering the material from Parallel and Concurrent Programming in Haskell, then I wouldn't say it's a good first resource.
Any time the strictness analyzer is wrong. I.e. when a value is always needed, but a thunk/closure is allocated for it instead. Call by need is only faster when at least one value is not needed, and avoiding it's evaluation "pays for" all the extra bookkeeping.
&gt; "more" is "less" `less` is `more` but with more features, just like `more` was `pg` with more features. (Also, by the Yoneda Lemma we see that `more` is anything with (all of the) `more` features; forall f. f a = f More -&gt; a = More)
Feels like a repost, but I don't think it is. Last Plutus post was: https://www.reddit.com/r/haskell/comments/a97drh/professor_philip_wadler_on_plutus_and_haskell/
It seems like it isn't really being maintained anymore and from doing a little research it seemed a lot people had issues implementing it without a lot of hassle. If there are forks that are still active I'd be curious to hear about them. 
Every once in a blue moon I’d try to compile and run Yi. Never succeeded. Bummer. 
same
Not enough time and resources for such enormous undertaking as rewriting a huge and complex software system. No one is paying to do the work.
I don't think there's so much to be gained that would be worth the users you'd lose. &amp;#x200B; That applies to both questions in the title. &amp;#x200B; As an emacs user, I feel like the low-level font drawing and GUI-integration are the parts that a modern emacs could do better. But are there examples of Haskell programs doing those things particularly well? &amp;#x200B; Emacs packages do crumble a bit as they update out of sync with each other, but if we believe that a type checker catching those things would be beneficial, we must also weigh the impact of package-level compilation success/failure that we get from GHC. Specifically, I'd want lazy type checking so that if one function in a package no longer type checks against one of its dependencies, then that particular function should be broken but not the entire package. &amp;#x200B; That's in large part a consequence of interactive use: I'm sitting right there looking at the result of every function call, so I can navigate around breakage. Use of emacs as a batch elisp runtime is not that common, perhaps in part because it all works much better if a human is there to route around breakage. So we can pivot this question to a related one: is there an available niche for a text editing-centric batch processing system?
&gt; Specifically, I'd want lazy type checking so that if one function in a package no longer type checks against one of its dependencies, then that particular function should be broken but not the entire package -fdefer-type-errors (or whatever the flag is actually named) can probably do this.
Right, and that’s how we use GHC in editing scenarios today, but I don’t do that in general Haskell programming scenarios. So one question is if the value of Haskell is significantly diminished in some way if deferring type errors is the norm?
It think it's only the norm when you *want* to play fast-and-loose with an API / ABI because there's too much flux and not enough synchronization. And, honestly, I would rather editor plugins were *not* that type of environment. I find they break at the most inopportune times.
To add to this, a polished editing experience has a comparable amount of man hours to writing an entire language and it's ecosystem at this point. It's absolutely insane. Even with unlimited funding, the time alone required to get code out the door for something of that level of complexity is quite significant. Neovim succeeded because it started as a refactoring. I wouldn't be surprised if (at this point) any future kernel, os, language, compiler, editor, etc, that hits mainstream will do so because it either iterated off an existing product or lended itself exceptionally well to incremential adoption. Editors can't easily do either, unfortunately.
You mean that they get interpreted into a more efficient runtime code? I don't know, but I'd love to know. 
Fair enough. In my experience emacs and its ecosystem work pretty well, so your answer to this thread’s questions will be quite different.
Xmonad didn't fail, I believe? I use it and Emacs too. I have no problem with Xmonad configuration but I do have a problem with Emacs - it doesn't have strong typing which would make packages more reliable and easier to debug and maintain. So my guess is that it has nothing to do with Haskell per se, it's just a lot of work that no one is paid to do. I hope one day to take a good look at Yi's sources and see if I could make any good of it.
Philip != Manuel 
That is the most pragmatic thing I’ve heard in a long time. With so much debate over what tools are best that was refreshing to read. In short, just let be people efficient and focus on the important parts.
I still use XMonad on my primary system. I'll continue to use it as long as I can get it to compile.
is there a generator for dates? (it didn't come up when searching the repo)
/r/codereview
What’s the difference under the hood in GHC?
I think a useful approach might be to write a lisp interpreter in Haskell which would then host all the elisp ecosystem. This could also allow the editor to be extended with Haskell-native modules. 
It's good there is no remake. Two reasons: 1. https://en.m.wikipedia.org/wiki/Law_of_the_instrumen Rewriting something for the sake of rewriting with the only motivation being to use a different language is most certainly a mistake if not just simply tooling bias. I even doubt you are really going to reduce the number of bugs. These usually stem from complex architecture and complicated interaction of components. A language can be more or less suited for an architectural decision, but these decisions are what makes the difference, not the language on its own. At least not enough to justify a rewrite. 2. A rewrite is just that. A rewrite. Now you have invested a huge amount of time and are lucky to get the core functionality. Now you probably need to write a compatibility layer for emacs plugins so your rewrite doesn't stay irrelevant forever. I know some people will say this is the beauty of OSS. Maybe you have distracted some of the existing emacs contributors to spend more time on your rewrite. If you get a lot of attention, maybe you will cause a community split. In my opinion one should think twice before attempting a real and serious fork/rewrite of a popular project with a big community. What are your goals? Is there a real problem with the existing project? Do you have a vision? Or do you just like haskell? TL;DR there is just not enough reason/motivation. 
No, not as of now. Free feel to open an issue. There is a related `date`` function available in the Movie module: ``` λ&gt; import Faker.Movie.BackToTheFuture λ&gt; import Faker λ&gt; generate date "November 12, 1955" ```
Agreed! I had some references like those in the post originally, but cut them out to keep it more focused. But indeed, those are well worth checking out. Thanks!
Function application by spaces always has the highest precedence! It's super handy to remember. If you have operators around a bunch of functions and values with spaces in between, you always know that what's between operators will "group together" first. `f a . g b c . h e f $ x` is `(f a) . (g b c) . (h e) $ x` And if you're wondering, function composition is associative, so f . g . h = (f . g) . h = f . (g . h) = \x -&gt; f ( g (h x))` Meaning strings of compositions are nicely behaved: composing another function to a composition of functions just adds another function to the chain of function applications. Function composition also has one of the highest precedences, but not as high as space application. So: f a . g b &lt;$&gt; h x = ((f a) . (g b)) &lt;$&gt; (h x) `$` application has the lowest precedent f a . g b &lt;$&gt; h x $ j y = (((f a) . (g b)) &lt;$&gt; (h x)) $ (j y) When one `$` is involved, it basically always brackets up everything to the left and right f x $ g y = (f x) (g y) When multiple `$` are involved, things get tricky! To work out these problems you need to remember that `$` is right associative, so it brackets up **everything** to right. f x $ g y $ h z = f x (g y $ h z) = f x (g y (h z)) The reverse clearly cannot also be true. `((f x) g y) h z` is not `f x (g y (h z))` The same thing goes for other non-associative operators: you have to know whether they're left associative or right associative to work out how they parenthesize. (yes, if you're confused, "associative" means something entirely different from "left associative" and "right associative". Being "associative" means it doesn't matter if a thing is left or right associative, so things can be "not associative" but also "left associative".)
What type does `a` belong to, in the following example: adjacents :: [a] -&gt; [(a,a)] My understanding implies it can be of any type as long as it is complying to the data structure. Is it true?
Wow thank you for taking it step by step. I am a Haskell beginner and this was handy. Often times when you are learning something entirely new, having multiple impressions(or revisions) of same concepts helps tremendously.
Just use hasktags (http://hackage.haskell.org/package/hasktags) and then any editor that can handle ctags or etags..
 &gt; Editors can't easily do either, unfortunately. In a way efforts like the `Language Server Protocol` are it for editors. 
I will pass this on to the GOP, I’m sure they’ll have a use for it 😉
You can do this in two steps: f (g x) &lt;=&gt; (f . g) x by definition of `.`. \x -&gt; f x &lt;=&gt; f by eta conversion. So: f s = filter (isDigit.head) (groupBy (on (==) isDigit) s) f s = (filter (isDigit.head) . groupBy (on (==) isDigit)) s f = filter (isDigit.head) . groupBy (on (==) isDigit)
I'm certainly no expert, but I know that it can make a difference for performance, because it can affect how inlining takes place. (I'm not aware of any other difference that it would make). Looking at [part of][ghc-docs] the GHC user manual, there is the following: &gt; [...] GHC will only inline the function if it is fully applied, where &gt; "fully applied" means applied to as many arguments as appear (syntactically) &gt; on the LHS of the function definition. For example: &gt; &gt; comp1 :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c &gt; {-# INLINE comp1 #-} &gt; comp1 f g = \x -&gt; f (g x) &gt; &gt; comp2 :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c &gt; {-# INLINE comp2 #-} &gt; comp2 f g x = f (g x) &gt; &gt; The two functions `comp1` and `comp2` have the same semantics, but `comp1` &gt; will be inlined when applied to two arguments, while `comp2` requires three. &gt; This might make a big difference if you say &gt; &gt; map (not `comp1` not) xs &gt; &gt; which will optimise better than the corresponding use of `comp2`. (If you're interested, I would recommend [this][ghc-opt] excellent (and rather comprehensive) article I recently stumbled upon talking about GHC optimizations and in particular about fusion.) [ghc-opt]: https://www.stackbuilders.com/tutorials/haskell/ghc-optimization-and-fusion/ [ghc-docs]: https://downloads.haskell.org/~ghc/8.6.3/docs/html/users_guide/glasgow_exts.html#inline-pragma 
This seems very nice! Is it easy to integrate with `QuickCheck`?
I have some ideas and going to write you a PM.
`:set -O2 -fobject-code` in the reply will build modules with optimisations. You may want to had `-fforce-recomp` to ensure following `: reload` will reload everything. Note that it changes a few things related to reply behavior and you may need to manually import a few symbols which were already imported by default.
From a glance, it looks like it would be tricky to use `Fake` inside of `Gen` because the former has a `MonadIO` instance. (More precisely, it looks like `Fake` is fundamentally built on top of IO, while `Gen` is based on pure functions and just uses IO to provide arguments to them.)
I'm not that familiar with QuickCheck, but probably you can use \`GenT\` to integrate with Fake: [https://hackage.haskell.org/package/QuickCheck-GenT-0.2.0/docs/QuickCheck-GenT.html](https://hackage.haskell.org/package/QuickCheck-GenT-0.2.0/docs/QuickCheck-GenT.html)
As of recently, Emacs itself can be extended with Haskell-native modules.
These have been really great. It's a shame that the book is stalled. Is there any chance progress will pick up again? I'd hate to lose out on anything else that was potentially written (even if incomplete).
Thanks for the explanation, will be sure to take a look at the linked article. It feels like this is a flaw in the compiler, in that it should be able to transform the un-inlinable into the inlinable form automatically, but maybe I’m missing the reasoning for why this isn’t possible
Ignore this. Mistakenly posted in Feb thread instead of March.
What type does `a` belong to, in the following example: adjacents :: [a] -&gt; [(a,a)] My understanding implies it can be of any type as long as it is complying to the data structure without changing the type. For example if a list of `Integer`'s are passed then it should return only list of tuples having two `Integer`s. Please correct me if I am wrong.
http://www.esterel-technologies.com/products/scade-suite/ SCADE is a commercial formal verification suite for aviation, railway, and automobile control systems. 
This is doable in Haskell, but I do believe this is perhaps more straightforward in an OOP language. One possible solution is be making your module "first class" using a record-of-functions / [service pattern](https://www.schoolofhaskell.com/user/meiersi/the-service-pattern) approach, basically emulating an OOP object. There would be a record-of-functions representing an abstract repository. (I'm assuming that the functions work in IO.) When the repository goes against an actual database, the reference to the db connection would be hidden inside the functions, not visible to the repository-using code. You would need to assemble your records-of-functions manually, though there seem to be libraries like [registry](http://hackage.haskell.org/package/registry) that try to emulate the type-directed auto-wiring of components popular in OOP DI frameworks. One nitpick: It seems like we can't separate concerns to this level in Haskell because the Database module has no way to persist the database connection information a la the Singleton Pattern in OOP. Usually DI frameworks don't use "singletons" for that purpose, at least singletons whose single-instanceness is enforced by the class itself (they are an anti-pattern). They simply manage the creation of beans and ensure that the correct ones are injected during wiring.
 adjacents :: [a] -&gt; [(a,a)] It is implicitly universally quantified, so it must for for all types -- caller's choice.
&gt; adjacents :: [a] -&gt; [(a,a)] It is implicitly universally quantified (`forall a.`), so the implementation must work for all types -- caller's choice.
yeah this is a very practical solution
Bad motivating example. Floating-point division is total. Sometimes the results a non-numeric (Infinity, -Infinity, NaN) but they are floating-point values.
When a function is not saturated, an additional thunk/closure has to be allocated. If it is saturated, even if it returns a thunk, it's return value can be used directly. We don't want inlining to produce the additional allocations. If you write (the function as) single-argument lambdas GHC will honor that, but it's often not the most efficient approach. GHC can inline every call, but it uses saturation as a heuristic for when to avoid it. I think the STG paper covers some of the motivation of this.
This was a very timely read as I just finished par-con last night, which touched quite a bit on exceptions. Nice work :)
Could you please give some more explanation regarding differences between (.) and ($) ? if `(g . h) x = g (h x)` then it is the same as `g $ h x` \- no?
Could you please give some more explanation regarding differences between (.) and ($) ? if `(g . h) x = g (h x)` then it is the same as `g $ h x` \- no?
Thank you. In these diagrams, which lines count as being the "one reference" that exists to the given thing? (Which I assume coincides with that thing being owned by the reference/reference-holder?)
That's awesome. I haven't heard of the service pattern in Haskell so I'll look into that as a solution. \&gt; Usually DI frameworks don't use "singletons" for that purpose, at least singletons whose single-instance invariant is enforced by the class itself (they are an anti-pattern). The frameworks simply manage the creation of beans and ensure that the correct ones are injected during wiring, perhaps sharing some beans between services. I'd prefer to stay away from DI frameworks when possible. Spring and runtime exceptions have worn me down. ;) With that said, I think something along the lines of the actor model would work well for IO operations since that would allow them to be modeled as services that listen for messages. But for that to work we'd need to be able to initialize a module with persistent state, obtain it's handle and then write to it as needed. Hopefully the service pattern can provide a foundation for that. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
They definitely help! The glue code alone is still quite significant, but it definitely makes things more palpable. I see this most strongly with TypeScript where you have an industrial strength LSP client being written by a large company and everyone else gets to benefit from it too. Can't wait until more IDE experiences move to this sort of model.
Ohkay I see. For which specific use-cases do people opt for \`forall\` quantifier and not sure if it is a good practice? The way I see it, its as good as having no types.
Look up parametricity and free theorems for ways in which `forall` is better than "no types". Explicit `forall` is/was required to bring a type variable into scope with the `ScopedTypeVariables` extension. It is also required then the `forall` doesn't apply to the whole type using the `RankNTypes` extension. In face, an explicit `forall` isn't valid Haskell 2010. So, it's use would always be paired with some extension(s).
 f $ x = f x (f . g) x = f (g x) In `$` the second argument is a value to be fed into the first argument. It *could* be a function, but might not be. In `.` the second argument is a function to be fed the "third" argument, the results of that is fed into the first argument. It *must* be a function. In addition they have different precedence. `$` is very low, `.` is much higher. Yes, `(g . h) x = g $ h x`, but that's more of a coincidence than anything particularly deep connecting the two. `f . (g . h) x != f . g $ h x` and `(g . h) x y != g $ h x y` and `f (g . h) x != f g $ h x` and `(g . h) x . y != g $ h x . y`.
Thank you very much!
To clarify your final point -- "left" and "right" associative are about the operator itself -- it's about parsing and syntax. Whereas "associativity" is a property of the function, and is about semantics. Normally we conflate those two, but in this case it makes sense to think of them separately.
Yes, but this leaves you with a lisp-based emacs at the core and not as much of a path to an all-Haskell implementation. I guess it depends on what the end goal is.
How would you write a function which takes an integer 'n' and returns the three smallest primes (in order) bigger than n? &amp;#x200B;
Ohkay I see. I do not fully understand this. Will come back to it later. Thank you.
I think it would be an interesting experiment.
`take 3 $ filter isPrime [n+1..]` Just add ~~water~~ a definition of `isPrime`.
RemindMe! 10 days "When to-use/not-to-use forall"
I will be messaging you on [**2019-03-13 20:29:47 UTC**](http://www.wolframalpha.com/input/?i=2019-03-13 20:29:47 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/avtfzv/monthly_hask_anything_march_2019/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/avtfzv/monthly_hask_anything_march_2019/]%0A%0ARemindMe! 10 days ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt; For example if a list of &gt; Integer &gt; 's are passed then it should return only list of tuples having two &gt; Integer &gt; s. That's right. The type signature reads "`adjacents` is a function that takes as an argument a list of some type (call the type `a`), and returns a list of tuples of `a`s". `a` is a type variable, that is (roughly speaking) substituted for a different _concrete type_ depending on the context, in the same way in `addOne x = x + 1` you substitute a concrete _value_ for `x` at the callsite. Don't worry about "quantification" or the `forall` syntax for now (until you need/want to, which may be never).
It isn't quite clear what you mean. Why exactly does your Accounts module require a Reader? Maybe that's because it reads accounts information from a database? Can you show some code?
Just found this: http://hackage.haskell.org/package/semigroupoids-1.2.6.1/docs/Data-Functor-Bind.html#v:-62--62--45- You've rediscovered `Bind` from `semigroupoids`.
I think this is a case where a mutable map data structure would be worth your while. I don't know off the top of my head a great pick for that, but I'm guessing there's a pretty well designed library for such structures on Hackage. Another option would be to use parallelism, which might not seem "fair" if the C++ program doesn't, but it's likely easier to implement it in Haskell, so take the easy win! I'm guessing these input files are large enough that the performance of `showMap` is essentially overwhelmed. If that's not the case, then I would investigate if you confuse the `sortOn` and the `toList`. This is all without seeing any profiling results of course. :) My usual first plan of attack is to try to avoid unnecessary allocation.
Thanks for the fast reply, that works just fine, but I have use a given template in the exercise: `nextPrimes :: Int -&gt; [Int]` `nextPrimes n` `| n &lt;= 99`
I interviewed at Galois after I finished my PhD and received an offer. Although I ended up taking a different job (Sandia National Labs Formal Methods/Assured Digital Systems--we are hiring) I think Galois is an awesome place. Also, my academic twin (long time office mate, same PhD advisor, finished at the same time) did take a job there. I can only speak to what my interview was like, others may have had different experiences, and I'm sure the process is somewhat different for people in different situations. Basically, the interview was a hole day affair. The main activities were * One-on-one and small group interviews of a conversational nature about my interests, experience, and the way the company worked * A (prepared) approximately one hour technical talk about my research * A short whiteboard coding exercise (in C) which focused on questions of "how would you specify/verify this" * A pair programming exercise with a senior Galois engineer (in Haskell) which involved a fun computer architecture/language implementation problem. That probably was an hour and a half long. As pair programming, it involved talking through proposed solutions and ensured I wasn't going to get stuck trying to remember the syntax of cabal file or something. So, ultimately, a mix of the more academic oriented "tell us about your research" and more software company "show us how you solves problems" kind of thing. Hope that helps. 
Yes, that was helpful! Thank you. Although, I doubt that as an undergrad (since, unlike PhD students, I no have 3 year thesis under my belt) I'd be required to present on my research.
How would you implement this? I have the definition of `isPrime` but it doesn't quite work.
 f n = take 3 $ dropWhile (&lt;= n) Data.Numbers.Primes.primes Might use a tuple if I want the type system to verify I always return exactly 3: f n = g $ dropWhile (&lt;= n) Data.Numbers.Primes.primes where g (x:y:z:_) = (x, y, z) g _ = error "Found the largest prime!"
That has the same type (modulo constrant) as `&gt;&gt;=`: `m a -&gt; (a -&gt; m b) -&gt; m b`. I believe parent comment was looking for something of type `m (a -&gt; m b) -&gt; m a -&gt; m b`, which is close but come combinations of `fmap`/`join` away.
I completely transposed those in my head. Whoops.
The "service pattern" linked by /u/Faucelme is a great source of inspiration, but what is not clear to me is your description of the problem. Does your Accounts module need DB access or not? I think trying to model completely untyped "dependency injection" and leaving method resolution to runtime is just setting yourself up for disaster (sorry Java and C# folks). IMO if your Accounts module needs to talk to the DB there will be functions like `getAccounts :: DBConfig -&gt; IO Accounts` in the "service layer", and that's completely fine. The need for a "singleton" DB handle is an OOP idea, whereas in Haskell you can easily declare ["memory brackets"](http://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Exception.html#v:bracket) around resources that need allocation/cleanup (e.g. `withDB :: (DBHandle -&gt; IO a) -&gt; IO a`), and declare other functions that just use the `DBHandle` and do stuff with it, e.g. synchronize your Accounts.
Performances are already trickier to discuss. First of all, what is the C++ program doing, can you share that, we need to be sure that we are really comparing the same algorithms. Is your C++ program handling "unicode" or just bytes? You need to provide the test input, because 2-3 times does not mean the same thing if you have an input of 3 words (and in this case the running time is dominated by the output) or many thousands words. To play, I used an input of approximately 1 million words, generated by concatenating 100 times the output of the lorem ipsum generator ([https://www.lipsum.com/](https://www.lipsum.com/)) of 100 paragraphs. The input file is \~6.5M bytes. Your program (compiled with -O2) runs in 1.2s. I can reduce the running time of your program to 0.480s (more than 2 times faster, so it may be competitive with your C++ version) with a few simple changes: \- the \`notElem\` test in \`toWords\` iterate over a list, which is perhaps the worse data structure for the job due to the O(n) behavior and the ugly memory footprint of the list. We are lucky, that's a small list, so it does not trash all the cache. However, that's a lot to read. Replacing it by a \`Data.Set\` or \`Data.HashSet\` from \`unordered-containers\` helps a lot. You can also use a \`Data.Vector.(Unboxed.)Vector\` from \`vector\` because the list is so small that's just better if you can just put it in a tighly packed memory area. Most of my runtime improvement was won using this change (from 1.2s to 0.550s). \- I switched from \`Data.Map\` to \`Data.HashMap\` for a small gain. So the most important change was something like: \`\`\` import qualified [Data.Text.Lazy.IO](https://Data.Text.Lazy.IO) as T import qualified Data.Text.Lazy as T import qualified Data.Map.Strict as M \+import qualified Data.Set as Set import Data.List (sortOn, foldl') import Text.Printf (printf) import Data.Char (toLower) &amp;#x200B; \-toWords = T.words . T.filter (\`notElem\` ",.!?;,:-\\"'") . T.map toLower \+punctuation = Set.fromList ",.!?;,:-\\"'" \+ \+toWords = T.words . T.filter (\`Set.notMember\` punctuation) . T.map toLower &amp;#x200B; countWords = foldl' addWord mempty where addWord counter word = M.insertWith (+) word 1 counter \`\`\` &amp;#x200B; 
Note that this requires a third-party library.
Correct, only PhD students are asked to present a talk. I will also add that we have no language requirements. So if you don’t know C or Haskell, you wouldn’t be asked to do either of those for the whiteboard or pair-programming. Source: I work at Galois
If I had to implement the infinite list of primes myself, I'd just do trial division, but the sieve is faster.
... The comment literally has the implementation. What did you try? If you must have it as a declaration instead of an expression then: &amp;#x200B; f n = take 3 $ filter isPrime \[n + 1..\]
What are the best practices in cloud native Haskell microservice deployment? If it's k8s and containers what's the best image to use? How do you CI/CD with Nix and containers etc?
Sorry, I made a mistake in my code. It works perfectly. I am just pretty new to Haskell. Everything works just fine, thanks for the help again.
It seems from the website you don't sponsor visas?
I like it, but I find it a bit basic. Maybe it's supposed to be. But, for example, the main argument in the introduction is that you use exceptions for "exceptional cases" and e.g. some Maybe thing for something more common. This line is extremely thin, especially when you do e.g. file handling, networking or anything else that relies on stuff you have barely control over. The file does not exist: is that common or not? The file is on a different device (EXDEV): is that common or not? A little bit more OT: I too think that blurring the line is worse than sticking to either "purity" (rust "exception" handling) or exceptions all the way (Java, which has a better exception system than haskell). If you let programmers do these difficult decisions every day, most of them will get this wrong. Simply because they are probably not familiar enough with the domain to assess what should be an exception and what should be explicit. And also: consistency is out of the window. You are, again, at the merit of the library authors opinion. Welcome to C++, where everything is possible.
There's no better way
&gt; T.filter (`notElem` ",.!?;,:-\"'") . If L'Hôpital were alive, he'd be 😭 after seeing that his name didn't count as a word but his reaction did. ;) Also, `T.length` is not the "width" of a word, it merely counts the number of Unicode scalars. Width is always defined
Out of necessity. 3 years ago with cabal 1.x, that was (near) unusable, life was pain. For a 5k line web app project I would need to wait nearly hours to change any important aspects of my build. Stack solved the problem for me and let me compile stuff.
&gt;why don't I hear about it being applied more to dangerous situations like aviation or medical devices &amp;#x200B; Well perhaps this is an issue with perception verse reality: &amp;#x200B; Aviation * [https://smaccmpilot.org/](https://smaccmpilot.org/) * \[Copilot(pdf)\]([https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20120001989.pdf](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20120001989.pdf)) Crypto * [https://cryptol.net](https://cryptol.net) * [https://saw.galois.com](https://saw.galois.com) &amp;#x200B; I'm not sure about any medical devices, though I have talked with some people in the medical community about using a static property checker written partly in Haskell. &amp;#x200B; ... but perhaps it's an issue with reality. &amp;#x200B; The problem with using Haskell directly in a setting such as aviation or medical is... * it comes with a very large trusted computing base (TCB) typically including a commodity kernel (50k-2M LOC), a C library (100K +), and probably the GHC RTS (\~100k). * a rather complex compilation of the Haskell code itself - the compiler is awesome but no one is claiming it has fewer bugs than, say, compcert. * Lack of clarity around key critical properties such as worst case memory or execution time. The hard real time state of the art is pretty bad without throwing in a stop-the-world GC that depends on the high water mark allocation for the entire process. &amp;#x200B;
Another simpler option is the `foldl` package. 
This seems like a perfectly nice way to do this, FlexibleContexts is a very standard and uncontroversial extension at this point. Particularly since `array` uses MultiParamTypeClasses itself which basically guarantees the need for FlexibleContexts. 
Ohkay thank you for the reply
Thanks.
Thanks.
Well, constant ought to be good enough for this particular exercise. I just want a couple of code snippets to run and time.
Thanks.
I was looking at the open issues on diagrams-lib and noticed you opened a bunch of enhancements for Diagrams.ThreeD several years ago. Do you have any plans on going back to that?
This is quite interesting, but I am bummed out by having to repeat code. Can this be dry-ed up somehow for us to be able to have a single source of truth? I mean stuff like this: {-@ type Month day = {v:Int | v &gt; 0 &amp;&amp; v &lt;= 12 &amp;&amp; (day &lt; 31 || not (v = 04 || v = 06 || v = 09 || v = 11)) } @-} ------------ repeated: ------------- then if month &gt; 0 &amp;&amp; month &lt;= 12 &amp;&amp; (day &lt; 31 || not (month == 04 || month == 06 || month == 09 || month == 11)) Is it perhaps possible to lift this out into an `isValidMonth` function that then is used at both places? Maybe like this? {-@ type Month day = {v:Int | isValidMonth v day } @-} isValidMonth v day = v &gt; 0 &amp;&amp; v &lt;= 12 &amp;&amp; (day &lt; 31 || not (v = 04 || v = 06 || v = 09 || v = 11)) ------------ then later use it again: ------------- then if isValidMonth month day
A mutable map seems like a good idea, I will give it a try, thanks!
Don't forget [streaming](http://hackage.haskell.org/package/streaming).
What fun features? I was under the impression backpack support hadn't yet landed in stack.
Yes. I think Patrick Collisoni said in an interview that choose the tech your employees are exited about, regardless of what it is. I.e a developer exited about X will be much more effective with X than in Y that is (subjectively) better.
My personal pref is Visual Studio Code and Haskero. Works quite well for me.
I too have only used Emacs for Haskell.
On the Vim side, I have found hdevtools + ale to be the most stable and responsive, but: * it is still brittle * it is not an ide! 
I've used Spacemacs with Haskell Layer (intero backend). Also tried VSCode with Haskero. In my experience both of these work reasonably well, though first impressions I prefer how the Haskell layer in Spacemacs works (to be fair though, I've not done nearly enough Haskell recently to form a super valuable opinion so take with a grain of salt).
I love the idea of HIE, but can never seem to get it working consistently :/
I'm using Visual Studio Code with [Haskell IDE Engine](https://github.com/haskell/haskell-ide-engine) and its respective [extension](https://marketplace.visualstudio.com/items?itemName=alanz.vscode-hie-server). It works nicely, thought setting it up is not trivial, as they do not ship binaries. They have been improving the build reliability lately though. I'm also not a Haskell power user, I'm still just learning and experimenting with it, so YMMV probably.
clearly a blackboard
I found it to be quite good but HIE has a memory issue that makes it unusable. Once that's fixed I'll probably make it my go to tool. 
I've been using HIE with atom. I have only been able to ever set it up correctly using Nix tho.
I agree. I used to use Emacs with Haskell, but now I find VS Code to be a better option. I still keep a nice Emacs confit for use via SSH on remote servers, but for local I now really like my VS Code setup.
This might be a dumb question, but do I need to install ide tooling per-project? Like, do I need to install intero in each different haskell project I have or can I install once (somehow...) at the global level and then just use that for all my projects? Also, what's the proper way to install a global lib like this with stack?
Do I need to install ide tooling per-project? Like, do I need to install intero in each different haskell project I have or can I install once (somehow...) at the global level and then just use that for all my projects? Also, what's the proper way to install a global lib like this with stack? 
Atom with HIE.
Not sure if it fits the I part of HIE but my most stable and efficient workflow has been VS code on the left 2/3 of my screen with just some syntax highlighting and hie when it does t choke, and on the right 1/3 I use GHCID. Most people I’ve taught coming from other Langs scoff at the ghcid approach but give them a month and they start to prefer it over the red squiggles in the editor.
I have a code which return the subsets of a list of a given size. `sublists n xs = take (length xs - n + 1) $ sublists' n xs` `where sublists' _ [] = [[]]` `sublists' n xs@(_:rest) = take n xs : sublists' n rest` How could I modify it so it would return all sets of size "n-2"? (where n is the size of the list) 
My absolute favorite is to not even try to get anything IDE-like. Instead, just use a dumb but powerful text editor (a fairly vanilla vim setup being my weapon of choice), combined with a suitable feedback loop running in an off-hand window. It may seem primitive, but there are a few non-obvious advantages to this that make a huge difference to me: it's snappy, predictable, reliable, malleable, works across all languages, frameworks and stacks. There are few moving parts, and they're all "user serviceable" and loosely coupled. I use this approach for all languages and situations, though IME it works particularly well with languages like Haskell, where many of the things typically addressed with IDE tooling are solved in the language itself. Instead of scaffolding mandatory boilerplate, you can often use Haskell's abstractive power to achieve the same thing; or take type-error-driven refactorings (instead of resorting to a fancy refactoring tool, you just boldly make the bloody change and then fix all compiler errors until it works again).
My preference is vscode with Simple GHC (Haskell) Integration and Haskutil. I've tried Haskero, but I prefer these two plugins instead.
How about Intellij Haskell Plugin?
Awesome! Any reasons why you prefer these two? 
I'll give it a try! Thanks :)
Sorry I don't remember anymore
Did you manage to set it up with or without stack?
Best for me so far has been Nix+Cabal+HIE+direnv with Emacs. I get lots of type information, immediate feedback, and good completion. I haven't used the refactoring machinery very thoroughly, though, so I can't speak to that.
Personally I get a lot of mileage out of just running `ghcid` in another terminal, and `ghcid` is rock-solid since it's just a thin wrapper around `ghci`.
this was very convenient type search. there might be a chance to run it locally as described here: [http://hackage.haskell.org/package/Hayoo](http://hackage.haskell.org/package/Hayoo)
Set up with stack, though currently intero is installed to the project I'm working from, not globally. I'm looking for info about how to install intero globally and whether or not doing so will work properly =/ Id rather not install intero separately for every project.
That's what I'm using. I'm very new to Haskell, but I really like this setup. I use IntelliJ for everything else I do, so it feels very natural.
Great timing! This is exactly what I was looking for, this week.
+1. Unfortunately it doesn't look like the memory fixes are on the near term roadmap
The only downside (so far) is no integrated debugging. 
Vs code with HIE. I switched from spacemacs + intero because of poor nix support (GHCJS) and was pleased to find the experience to be head-and-shoulders above the other options. Installation via git and make build-all takes a bit of time to compile, but after that and installing the extension from the marketplace, everything just worked for me (OS X).
&gt; it's snappy, predictable, reliable, malleable, works across all languages, frameworks and stacks. There are few moving parts, and they're all "user serviceable" and loosely coupled. I use this approach. I use a Python script [1] to proxy commands and results between the editor and the `ghci` process. It is all very loosely coupled, as you describe. There is not much going on in the editor. It just sends a ":reload" command to the Python script, on a haskell file save, which it relays to the ghci process. It then gathers the GHCI's resulting output, parses into errors and warnings, and set the error list at vim/neovim using their respective rpc api calls. Then I jump between errors using the editors built in error navigation support..[3]. The python script is itself separated into a main process that wraps the ghci, and different editor adapters that handles the communication with the editor. And even the link between editor adaptors and the ghci wrapper itself is not rigid. The ghci wrapper just open's a network socket and wait for adapters to connect. So your editor adapter does not even have to be in python, and for example, if you are using emacs, you can write an adapter for Emacs in lisp and it should work. The biggest advantage of this set up, as I see it is that we can reuse the capabilities of the ghci interface itself, which if you actually look, are a lot [2], which even includes completion suggestions. Another advantage of using ghci is that you don't need to do project specific config separately in your editor. If the ghci works for your project, then you are good to go with editor integration. I made this after trying all the magical plug and play stuff. It is quite frustrating when magic fails to manifest. So I have kept magic out of this when possible, so I have to some things manually when using it. For example, when working on a project, I have to open the main file in the editor, and send a ':load' command with the current file name to the script for the ghci to start loading it. Then some times, I want to make a bunch of changes, without each changes triggering a reload at 'ghci', so there is a vim function that toggles sending the reload command with every file save... [1] https://bitbucket.org/sras/rcrepl/src [2] https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html [3] https://vim.fandom.com/wiki/Use_the_quickfix_window_to_list_all_errors
this yi config [https://github.com/chessai/yi-chessai](https://github.com/chessai/yi-chessai) builds with nix, so it will most likely succeed (if you want to try it out)
Another option would be for an editor to solve a problem that did not exist when other editors were created and for which those other editors could not be easily adapted. &amp;#x200B; For a long time it seemed impossible for anyone to compete with the Windows vs OS X on the desktop. If you created a new OS, there would be no applications, and without applications, who would use your OS? Desktop Linux still hasn't gone mainstream. But then smart phones came along and Android came into dominance. It was not possible to simply run existing Windows or OS X on that hardware, and so the initial lack of applications was not a deal breaker because there was not a better choice. (Yes, iOS existed, but the market was very fractured at the time. And, yes, Android has Linux under the hood -- but the point here is how they got around the 'lack of applications' deal breaker, and the Linux kernel did not help them in that respect). &amp;#x200B; Notably, Android did not displace Windows or OS X on the desktop -- it took dominance in a new market that did not previously exist. &amp;#x200B; Of course, it is difficult to foresee a situation where a bunch of people need an editor, but current ones can't be used or adapted. For example, maybe we figure out how to build neural networks out of organic matter and instead of writing code, you provide training data to teach the matter how to act like an editor. Of course, that editor won't be Yi or written in Haskell. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
My experience is that most IDEs are inadequate to allow for effective Haskell programming. Instead, I use the power of my gigantic brain to just imagine the codebase in its entirety and, as a creature of pure energy, directly manipulate the bits on storage to settle into the proper compiled form, making even GHC unnecessary. &amp;#x200B; &lt;/haskell-fp-one-upmanship-mode&gt;
Can you put ghci in one of its terminal windows?
Yes, you can. Just to be clear: I meant no possibility to set breakpoints in the IDE (at least, not without using the terminal).
`sl2 xs = sublists (length xs - 2) xs` ?
I use Emacs with ghcid in a separate window, that's it.
Damn, I just use vim + grep/ag/rg. I'll try your method next time. ;P
'stack build --copy-compiler-tool intero' will install intero once per ghc version, so that it can be shared between different projects, using the same ghc. It can then be run with 'stack exec intero' from your project.
You still have an order of magnitude more editor integration going on than myself ;)
I use emacs with intero. Not necessarily because it is the best IDE available right now, but because I work remotely in tmux, so things like VisualStudio Code would not work for me. &amp;#x200B;
Cool. Is it better in any way than [Haskero](https://marketplace.visualstudio.com/items?itemName=Vans.haskero)?
Thanks I will give it a go
I second VS Code. However, I use the `dramforever.vscode-ghc-simple` plugin. For a while I switched between this and Haskero, but I've been using `dramforever.vscode-ghc-simple` for the past couple of months without problems.
It almost works but it doesn't return all the possible outcomes. I tried implementing something similar. `subsets :: [Int] -&gt; [[Int]]` `subsets [] = [[]]` `subsets (x:xs) = subsets xs ++ map (x:) (subsets xs)` This generates all the possible subsets.
Same issue with me. Tried multiple different things to get it to work
&gt; So a nice separation of concerns would have the Accounts module just supply the data to store in the database and the Database module would store it. This way the Accounts module is blind to the how the data is persisted. Sounds like you want to define a simple data type in the `Accounts` module, and in your `Database` module you'll want to define: 1. A function that translates from the `Accounts` data structure to a data structure that can be persisted to a DB (ie. a data structure that maps to some DB schema) 2. A function that takes a `DBHandle` and persists the data structure from step 1
I work at Galois and also routinely do interviews. First off, the interview focus will depend on the candidate's goals. If the candidate is applying with an emphasis on software development rather than research, we will interview accordingly. If the candidate has a research background and interest, we will interview accordingly. In both cases we choose our interview team so that there is a skill or disposition match on the team with what the candidate is applying for. If you are a PhD graduate in static types, we will try to have a person with a ton of static types knowledge on the interview team. If your background and goals are to do research, we may ask you to give a talk on your work. In terms of overall structure: our technical interviews tend to last around 6 hours, including lunch provided by Galois. We have the candidate meet with 6-8 friendly people during that time and talk with them about a variety of aspects of the company. We look at things like: Does this person seem interested in Galois and know what we do? Does this person value an open, transparent culture? Does this person seem self-motivated, and do we think they'll thrive in our environment where nobody is going to tell them what to do? Do this person's technical interests line up with the kinds of projects we tend to have? When we talk about how we organize and conduct ourselves, how does that resonate with the candidate? Where are this person's technical and social strengths? Does the candidate seem interested in learning and exploring new technical topics? In terms of technical content: we discuss the kinds of projects we have (across a wide variety of domains), we do a short whiteboard coding session on a common Computer Science problem (or something more specialized if that seems appropriate to the candidate's specialty), and we also do a two-hour pair programming session on what we hope is a fun problem (i.e., not fizzbuzz). The pair programming session is done in whatever language the candidate feels most comfortable in. This means there is no extra credit for choosing Haskell if Haskell is not your strongest language! In the session we are looking at things like evidence of abstract thinking, problem-solving skills, communication with the pair programming partner, use of documentation, understanding/command of the language, mental modeling of the problem, and programming process. It is understandable that Galois is often perceived as an extreme Haskell shop, but that perception is not accurate. A number of Galois folks have said this elsewhere on Reddit but I'll repeat it here: while we do use Haskell quite a bit -- and many of us reach for it if we can -- some people at Galois do not know Haskell, and many do not use it every day and don't need to. We use a wide variety of tools and languages and those choices are driven by the needs of our projects. I've worked at Galois for almost ten years. In that time I think I've probably used Haskell 60% of time. The rest of the time was spent in C and ARM assembly with a bit of Python.
Feel free to upvote/add ideas to https://github.com/rikvdkleij/intellij-haskell/issues/105
That's what everybody used in my team for Haskell. The latest beta (44) brought many nice features and improvements. First start can be slow as it installs intero, stylish, etc, but it's a low price for all the features and nice UI it brings.
Not byitself, you would also need a different ISA which gives you control over instruction pipelining. The fundamental issue that happens (due to Spectre) is that current modern CPU's automatically parallelize CPU instructions (as much as they can) since its much faster then always having to wait for the next instruction (this is called speculative execution). Spectre arises because you have no real control over the pipelining (and in the few cases you do, it completely kills performance), which means that you can't stop the CPU from executing the set of instructions from a branch that is "protected" (and this is how timing attacks on the CPU cache can view these results). It can be argued that the general mainstream preference for iterative style languages such as C/C++/Java kind of cornered CPU manufacturer'ers to create processors in such a way because its very difficult to reason and parallelize in such languages (i.e. they made CPU's which just parallelize everything by default because its so hard to write parallel style code in such languages). Languages like Haskell can definitely help here because it has such abstractions but unfortunately such advantages can't be realized because the current CISC x86/64 architecture doesn't give you the control that you need on an assembly level.
I like your thought that blurring the line is often dangerous, but I think there are ways to draw the line without it being blurry. The way I think about exceptions, there are two categories: * Things that can be expected to happen (no matter how unlikely) and cannot be prevented be any amount of defensive programming. In library code, I return these with the `Left` data constructor. The `EXDEV` example falls into this category. * Things that should not happen. There is either mistake in a library or in its use. Another way of looking at it is that these are things that were already wrong at the time code was compiled, not something that went wrong after it started running. In library code, I call `throwIO` for such exceptions with the intent that no one should attempt to catch them. Earlier today, I made an attempt at drawing a clear line between "recoverable" and "unrecoverable" exceptions in the [package description of my `sockets` library](https://github.com/andrewthad/sockets/blob/c289d23fc5f085574063d71c8beffd3e35da4c38/sockets.cabal#L6-L42). I ended up making the additional concession that `ENOBUFS` and `ENOMEM` are always unrecoverable. Reasoning for this is provided in the package description. You may find the distinctions drawn in the description interesting, or you may have some tricky situations I've not yet considered.
This is exactly what is happening inside uu-parsinglib, in essence working in all possible paths through the state machine in parallel.
for me, `emacs` and `dante`. it's the best compromise between features and robustness. (c.f. `ghcid` is more robust, `ghc-mod` is more featureful). https://github.com/jyp/dante
If the mutable map in overly complex, just using a value-strict map seems like it could also help. Given that `Int` comparison is strict, any thunk/clouse in the values will be forced at some point, so value-laziness probably isn't saving you anything.
&gt; Is your C++ program handling "unicode" or just bytes? Also, there's a lot more Unicode punctuation than what is listed in the code given. Might want to filter based on some acceptable general categories or something like that instead of a specific blacklist of ASCII punctuation.
Yes, see link below: [https://www.reddit.com/r/haskell/comments/avr5yq/simple\_example\_of\_using\_liquid\_haskell\_to\_model\_a/ehlx8eb](https://www.reddit.com/r/haskell/comments/avr5yq/simple_example_of_using_liquid_haskell_to_model_a/ehlx8eb)
I'm using Emacs + Dante + structured Haskell mode with company, flycheck and attrap and I'm pretty happy with it. If you're willing to invest into the learning curve of Emacs and nix (not a requirement, but Dante has good support for it compared to other IDEs and nix comes with its own benefits) or have done already then it's quite satisfying.
Can I modify something that is not passed into the parameter inside a do block? Like full-on side-effect land?
For me, Haskero is just exceptionally slow. It often takes 10s at least to get feedback, and sometimes I just don't get any. It's usually faster just to switch and manually invoke the compiler. I'm using the ghcid plugin right now and it works well enough for feedback, but I don't get type info on hover, unfortunately.
STRef, IORef, MVar, TVar, IVar have the Hoare logic you want. Also, `accursedUnutterablePerformIO` is pretty neat. --- Why, tho?
In Haskell everything is basically defining things in terms of expressions. You either define functions or values, with the point of your code being building up to define the value `main` which is of type `IO ()`, meaning it represents some effectful action. Haskell doesn't have the means to express mutation other than combining values representing stateful action, and the way of combining two state actions into one representing the two being performed in sequence is `Monad`'s `&gt;&gt;=` operator. do notation is just syntactic sugar for using `&gt;&gt;=` and lambdas to sequence representations of actions. In fact, if you were to abuse language features to try to actually make a non-IO value mutate, your programs may not behave as expected because GHC's optimization techniques depend on things being referentially transparent to be valid. Taking away the immutability of the language would destroy GHC's ability to optimize as well as it does. So for expressing mutable algorithms, you're going to end up using some sort of Monad, probably with do notation: either `IO`, `State`, or `ST`
I'm trying to create a simple program that does crud of some file. Problem is my each crud operation has different function signatures. Like read wants to return nothing, but for the other three I want to return a `IO [data]`. I don't know what signature to give to the function calling the crud operations.
"imperatively" doesn't mean "without types". You still have to get you types right in C++ / Java, for example. To *me* it would seem like `IO [data]` is the proper type / return type for `read`, and everything else would have different types. Also, since you are interacting with the filesystem, I would expect all of them to "live in", `IO`, so it seems between `fmap`, `(&lt;*&gt;)`, and `(&gt;&gt;=)` you should be able to make them all fit together. Perhaps if you have more specific goals, or specific ways that types are matching we can provide better advice.
How would you code a basic CRUD menu, where each function has different signature (ex.: read returns IO(), CUD would return the changed collection back
Would I be able to create a function that has different return types? So one IO(), another IO \[Data\]?
Sure. Prelude&gt; let f = return [1,2,3] Prelude&gt; let p = putStrLn "Hello, World!" `f` is `IO [Int]` (or more general), and `p` is `IO ()` (or more general).
Not with `ghc`. Does your editor save backups? Does your filesystem store snapshots?
-- if given data, writes it. if not, reads it writeOrRead :: Maybe Data -&gt; IO (Maybe Data) writeOrRead Nothing = Just &lt;$&gt; readData d writeOrRead (Just d) = Nothing &lt;$ writeData d readData :: IO Data writeData :: Data -&gt; IO ()
I found that HIE works beautifully and consistently if the project's resolver is the same as the resolver used to build HIE. Obviously that doesn't work for everyone.
Haskero got crunchy when the codebase grew in size (18 months ago). Multi project configuration with .project files. I prefer Brittany’s formatting. If it doesn’t offer anything else, I’d check back in three months, the dev cycle has been quick. 
I would expect that for the way that a typical power user of both Xmonad and Emacs, the complexity of Emacs is an order of magnitude, possibly two, beyond Xmonad. Tiling window managers are actually quite simple. That doesn't mean they aren't incredibly powerful -- they just aren't that technically complex. Whereas an editor, all the plugins, language modes, etc, is a massively complex system. So it doesn't really seem like a useful comparison -- Xmonad may well have failed if it required more work! 
This is why I use btrfs and have a cron job to save a snapshot every few minutes. That way no mater what boneheaded thing I do to my fs I don't lose much work.
I recently finally installed znapzend because I accidentally typed `rm -rf foo/ *` instead of `rm -rf foo/*` without noticing it. Learned my lesson...
git? Backups? What filesystem are you using? You might be able to use extundelete.
If you have no backup, check the output of `ghc --show-iface file.hi`. That won't recover the file, but at least you'll have something.
Oh, nice. Yeah, ATMs actually do benefit a lot from parallelism I'm pretty sure.
Shameless plug for my preferred setup (which, crucially for me, supports navigate to library source code inside the IDE) https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8 
Hey, sorry for being late. Yes, definitely one could compile Haskell to optimal graph reduction, but I still think that doing so would be too expensive due to the oracle (an extra, expensive machinery that is required for full λ-calculus compatibility). To avoid it, one could add EAL annotations to Haskell, which would allow us to identify functions which don't need the oracle (most common functions don't!) and are much less expensive to evaluate (i.e., you could compile them to [SIC](https://github.com/maiavictor/symmetric-interaction-calculus), which is much more lightweight than BOHM).
&gt; I know optional graph reduction is different than full-laziness, but I fear that evaluating under a lambda might allocate a closure that is never evaluated, which leaks both time and space. That does not happen as far as my understanding goes, but if you have a solid example I could answer for sure?
I do not.
Doom emacs with the haskell lsp plugin (which i wrote!)
`ghcid` + Vim.
Well it depends on a lot of things... like what you want to do with the data you're creating. In haskell there's always many ways to skin a cat. Not worrying about persistent storage for a second, you could save your data collection to an IO Ref, which is a reference to a mutable variable you have to use IO to use. The create, read, update and delete functions would all take an `IORef` first which would tell them what they're operating on. If writing to a file atomically and persistently then your functions would maybe need a reference to the file instead. In both these cases, your CRUD actions need to mutate something that can only be accessed in `IO` they would need to be `IO` actions, and they need to be told what they're working on. A fancier thing to do is use the `ReaderT` monad transformer on IO This allows you to avoid explicitly passing references to persistant storage by making actions of a type representing actions needing a config (the info needed to access the persistant storage) which can then be run with `runReaderT` which you feed the config and the action you want to run, and it gives the actions the config and returns the resulting IO action. There are libraries for interacting with typical RDBMSs which will each have their own way of doing things And when you're opening connections to databases or opening files you want to make things close properly. A way libraries often deal with that is a function that takes an action requiring a database connection or file handle, which will then open the connection, do the action, then close the connection. Oh and you'll need to think about a UI, and how interacting with that UI has to lead to the relevant actions being performed. If you want a GUI then you might want to look into Functional Reactive Programming. [Here's an example of a non-persistant CRUD using the FRP based threepenny-gui](https://github.com/HeinrichApfelmus/threepenny-gui/blob/master/samples/CRUD.hs) And here's [the threepenny-gui project home page](https://wiki.haskell.org/Threepenny-gui) if you want to know more about that. **TL:DR there's a lot of areas to explore with that question unless it is made more specific** &gt; I feel like I am missing something about the user input, and input validation process. Maybe I mean lets imagine a very simple system: Your program just prints out a rendering of the database contents to console where each entry has a number, and the user creates, reads, updates or deletes by typing the action they want to perform, the entry they want to perform it on, and any extra info needed for the action. That's so simple! 1. Print out the current storage contents 2. Print a request for a command 3. Get a line of input from the user 4. Parse the input to a valid command datatype 5. If it parses, apply a function to the user command that turns each command into the relevant option that changes the storage. if it doesn't, tell the user their request was invalid. 6. Recurse
If only \`InputFile\` and \`OutputFile\` had different types...
Woah that is a lot to digest. Every time I go back to Haskell I feel like I'm biting of more than I can chew. So quick question, in oop or c++ you can use a loop + input as a primitive listener. Does such a thing exist in Haskell without FRP libraries extensions?
I use VS Code with Haskero as well. I like it, but there are a few problems. One is that it only loads intero for the global stack resolver, ignoring the one for your project. So I have to set the global stack resolver to the one for my project while I edit it. The other issue is that it can sometimes give meaningless types in mouseovers for things that aren't even variables. It also occasionally tells me it can't find a package for the symbol under the cursor. These problems are probably both from intero, not from Haskero.
Might be making the best of a mediocre day but, damn your comment made me laugh
concPair maybeA maybeB = do a &lt;- maybeA b &lt;- maybeB return (a, b) no IO involved
That's just `liftA2 (,)`, which is not the same as `concPair`.
So the idea is you just share code between the client and server? Lol. Haste just uses one program for both.
But doesn’t that mean your backend is in JS if it’s the same program and not code sharing? Also how would that even work, backend and front end have different concerns.
ghcid + vscode (with neil mitchell's plugin) work well together flycheck style. If something goes wrong just kick the daemon!
Haste can compile both as JS for the frontend, and to machine code for the backend (using GHC). The idea is that you write separate I/O actions for server and client, but they can share pure functions and types. Mostly types actually. This means that when you type check the program, Haste automatically ensures the type safety is preserved when the programs communicate with each other. If the client sends the server a `Maybe String`, the server gets a `Maybe String`. It even allows you to have a lot of implicit communication by passing functions back and forth (the functions are not actually communicated over the wire; rather Haste will send the arguments needed to evaluate the function back and forth implicitly).
Didn't you just describe sharing code between the client and the server? What is the distinction you are making?
Because they are in one program and compiled *together*. Its not just a shared code base, it is one program that compiles into two object files.
Well, I kinda disagree with your first example, since EXDEV for eg file move can be recovered perfectly by a copy delete fallback (portable file copy). What is expected and what is not is simply ambiguous and not easy to anticipate. If your API is based on things that are not easy to anticipate, it will become odd. Recoverable and unrecoverable exceptions is a slightly different issue, less ambiguous, but may still depend on the users use case. 
You can do this with `unamb`/`lub` (which uses IO under the hood in a very devious way: http://hackage.haskell.org/package/lub)
The unamb package has more low-level primitives of that kind: http://hackage.haskell.org/package/unamb-0.2.7/docs/Data-Unamb.html In particular, that's `concPair x y = unamb (liftA2 (,) x y) (liftA2 (flip (,)) y x)`. IMO, first-class laziness is an underexplored idea. This makes sense pragmatically, because if you do that in an uncontrolled manner, bottom becomes the "billion dollar mistake" `null` of other languages. Nobody wants that. But at the same time, we can't pretend that bottom does not exist in Haskell. In fact, it's a very useful tool, to reason about both performance (you don't want to force too little or too much), and correctness (if you have a recursive function which diverges, rather than unfold it operationally, you can check that bottom is a fixed point), so why not make it accessible programmatically? Some cool things you can do with explicit control of laziness: - Generating Constrained Random Data with Uniform Distribution http://publications.lib.chalmers.se/records/fulltext/195847/local_195847.pdf - Static analysis of free monads https://reasonablypolymorphic.com/blog/prospecting-free-monads/index.html - and of course, Keep Your Laziness in Check http://very.science/pdf/StrictCheck.pdf
&gt; Does such a thing exist in Haskell without FRP libraries extensions? Recursive call and IO.
:) I have nothing against editor integration provided they don't make the editor itself gasp for breath when they are invoked. Or use a ton of memory or only work/crash randomly... Even with my set up, I have to kill the python process when it (The wrapped ghci process) ends up using too much memory, or it needs more memory than I have explicitly limited. This is also another advantage of this set up, that I can look at the log/output of the wrapped ghci process, so for some reason it stops working, I don't have to look at the editor and keep wondering why I am not getting an output... So while I have to sometimes kill the python/ghci process, at least it won't take the editor down with it...and I just can restart the python/ghci process and everything ll work as usual...
From [the isomorphic js article](https://medium.com/airbnb-engineering/isomorphic-javascript-the-future-of-web-apps-10882b7a2ebc) mentioned in the slides, I think the motivation isn't just to share code base. There are two ways to render a web page: 1) the traditional way where the server render it and send it to the browser, then each change requires the server to render a new page; and 2) the single page app way, where you only send backbone pages and logics to the browser, and the client will access the API or the database to generate the final web page. The idea is to combine both ways by separating the process into two stages. First, the server render a full web page and send it to the client. Then the client goes into the single page app stage, i.e. the client will directly access the API or the database to update rather than ask the server to render a new page. Compared to the single page app way, it has the benefits of first rendering speed and automatic SEO (because the server returns a real page, not a bunch of logics). And it shares some code.
\_|\_ isn't a real value, you aren't supposed to be able to recover from it or even detect it from pure code. This is actually good, so that it doesn't just used like `null` (in C, C++, Java, C#, JS), `undefined` (in JS), or `None` (in Python). I believe spoon uses IO under the hood and try of course uses IO to catch impure exceptions. Parallelism is pure (Par monad) and predictable; concurrency is impure (IO monad) and unpredictable.
`concPair` is explicitly a limited form of concurrency that *is* predictable. It does not matter which side executes first. Also, the point of laziness is that you can deal with ⊥, but only in controlled ways. For example, `fst (a, ⊥) = a` is already valid haskell.
My favorite is dante in Emacs, which is a fork of Intero that supports multiple build systems well. It also has a nice feature that lets me interactively evaluate expressions in comments, so I don't have to context-switch over to a separate GHCI buffer.
&gt; It does not matter which side executes first. But, it does matter if one side is bottom, and while GHC RTS can detect certain bottoms, it can't detect them all. (IIRC, detecting all bottoms accurately is Turing-complete. Totality checkers err on one side, the GHC RTS errs on the other) So, in any case, it would just have to run both sides to completion. &gt; the point of laziness is that you can deal with ⊥ No, the point of laziness is avoid avoid \_|\_ when possible, by only evaluating what is needed. &gt; For example, fst (a, ⊥) = a is already valid haskell. Sure, but you can't use `fst` or any other non-bottom expression to determine if a another expression is bottom. If your expression would evaluate a bottom expression, it evaluates to bottom. If your expression wouldn't evaluate a potentially bottom expression, it can't a value that depends on that expression.
I would suggest you use something like git and use something like Makefiles, Bazel, or "stack build --file-watch" to compile your code. It's far more tedious to run ghc by hand than using some build system what will do that for you.
Ah, I had not considered recovering with a fallback shim like you suggest for `EXDEV`. That option throws a wrench into things. I tend to err on the side of not doing things like this, but I could see why a lot of users would rather it work that way.
What do you use to create such slides?
I didn't get it and now I do get it, thank you!! 
What benefit do you get from compiling them together?
The types will be represented the same way when sent over the tunnel, you can ensure the implicit communication works correctly, make sure they are using the same "version" of various protocols, in theory you can have cross program optimizations, etc...
Maybe [reveal.js](https://revealjs.com/#/)?
Good luck getting people that write Haskell, of all people, to use the word 'isomorphic' to mean something completely different and nonsensical. 
You basically already have the same level of those guarantees with the normal code sharing approach, as in both cases if the old JS is cached (e.g improper cache busting) or you use a stale binary and so on you have the same incoherence. The only benefit I can see so far is the way that you prefix with "in theory".
I also like to know about this.
This is exactly the intent (I have attended this talk and talked with the OP last week).
Thanks!
Technical language is a pile of made-up, transient conventions. "Isomorphic" meaning "the same code running in the frontend and in the backend" is simply a convention that stuck sometime during the historical evolution of web architectures (2012-2013?). No use being condescending about language being too informal, instead we should encourage all attempts at reaching out toward different communities, something Haskellers haven't been too good at in the past.
Pandoc can use the RevealJS template too ! https://github.com/jgm/pandoc/wiki/Using-pandoc-to-produce-reveal.js-slides 
The word 'isomorphic' has a very specific meaning. It's technical terminology. This isn't normal language, where your claim might make some sense. Isomorphic means isomorphic. It means nothing else. &gt;"Isomorphic" meaning "the same code running in the frontend and in the backend" is simply a convention that stuck sometime during the historical evolution of web architectures (2012-2013?). Lol it's nowhere near that old. It's almost about 3-4 years old, and it's just yet another example of moronic Javascript programmers co-opting terminology they don't understand to describe things that can just be described in normal language for marketing reasons and to make themselves sound smarter and more sophisticated than they are. &gt; No use being condescending about language being too informal, instead we should encourage all attempts at reaching out toward different communities, something Haskellers haven't been too good at in the past. We absolutely should not encourage Haskellers to reach out towards different communities. We absolutely should not act like it's a bad thing for Haskell's community to be insular. And tolerating people misusing technical terminology for personal marketing reasons is not 'reaching out' anyway.
Words can have different meanings in different contexts.
Says someone that's part of the community that spams every discussion of dynamically typed languages with *well ackshully they're actually unityped languages, types can only ever refer to something that happens at compile time ackshully*.
The word "intercourse" used to mean something like "exchange" or "communicate", then in the 18th century it began to become synonymous with sex. Words change - you're fighting a losing battle.
&gt; And tolerating people misusing technical terminology for personal marketing reasons is not 'reaching out' anyway. The marketing aspect of this post is pretty obvious by the use uppercase letters in the post title...
Meh, it is what it is
I don't understand, are you parodying your own initial comment?
I use https://gist.github.com/mikeplus64/81459f85f921f4e67394e842f22b88e9 this pretty janky script as my dante method to work within `nix-shell` and/or `direnv`, to not output `.hi` and `.o` everywhere, and to always work regardless of the directory within a project it is started.
Efficient λ-Evaluation with Interaction Nets (https://link.springer.com/chapter/10.1007/978-3-540-25979-4_11) describes a more efficient system than BOHM that does much less bookkeeping interactions. I agree that the compiler must avoid unnecessary runtime bookkeeping (related to optimal reduction internals), but it can be done with static analysis also. It does not require source language modification.
It all started long time ago with naming a new language... JavaScript while obviously it had nothing to do with Java. But, you know, it makes the marketing division happy.
&gt; So quick question, in oop or c++ you can use a loop + input as a primitive listener. Does such a thing exist in Haskell without FRP libraries extensions? Well uuhh, now the problem is I know Haskell more than I know any other language, so I don't know what a primitive listener is 😅 But given the situation, I'm going to assume it's something that listens to and acts on input or events For user input we could make a main loop like so: main :: IO () main = do config &lt;- mkConfig let go = do str &lt;- getLine case parseCommand str of Just cmd -&gt; performCommand config cmd _ -&gt; putStrLn errorMessage go go So we make our config (which tells us something needed to act on a command, like an IORef, or file handle), bind it to `config`, define a `go` loop in terms of `config`, and then do the loop which, being a loop, calls it's self forever more. For events you can do something like this: startEventHandler :: TChan (Event a) -&gt; (Event a -&gt; IO ()) -&gt; IO ThreadId startEventHandler channel reaction = do chan &lt;- atomically $ dupTChan channel let go = do event &lt;- atomically $ readTChan chan reaction event go forkIO go What this is doing is forking off a separate thread that reacts to a supplied `TChan` of `Event a` based on a function from `Event a` to an `IO` action we supply. `TChan`s are a way for threads to communicate using the STM (State Transactional Memory) library. One thread can post something to a channel and another can consume the contents sequentially. Here I guessed that one may want multiple non-interfering listeners of the same event so the even handler copies a supplied broadcast channel so when it consumes input, it doesn't stop any other handler consuming the same piece of input.
First, let's get some facts straight. /u/ocramz isn't wrong: [Isomorphic JavaScript: The Future of Web Apps](https://medium.com/airbnb-engineering/isomorphic-javascript-the-future-of-web-apps-10882b7a2ebc) is from Nov. 10/2013. There are quite probably older references. So, it is that old. Language even technical language evolves, gets misinterpreted and/or appropriated. You can fight it but it's no different than tilting at windmills. The cat is out of the bag, insulting a large group of programmers is an irrational and immature exercise. You can judge Javascript--it's trivial to do so--on it's technical faults without insulting people whom you have absolutly no idea of. Most reasonable mathematicians and computer scientist who have a real stake in the technical language and definitions, couldn't care less--and most are probably unaware of the appropriation of "isomorphism." People who rail against the use of language with rhetoric exactly yours are no different than the people whom you accuse of being "sound smarter and more sophisticated than they are." Your form of marketing is unproductive and a silly form of venting in public. &gt; And tolerating people misusing technical terminology for personal marketing reasons is not 'reaching out' anyway. The greater lesson here is tolerance--and reaching out is a form of that tolerance. 
Sometimes you might want to pass all-quantified values to a function (i.e. the scope of type variables is below that of the function you're defining) especially with existentially-quantified values (the actual type is hidden and only the general type is visible). class Foo x where {- ... -} -- A `Thing` may contain a value of any type as long as it fulfills `Foo`. data Thing = forall x. Foo x =&gt; Thing x countFooBar :: forall a. Num a =&gt; Thing -&gt; (forall x. Foo x =&gt; x -&gt; a) -&gt; a If you left away the `forall` inside the parenthesis you would specialize the value of the function at the level of specializing `countFooBar`. But then your `x` is specialized to a specific type and you can't use it on different types as needed for values of existential types. 
&gt;The greater lesson here is tolerance--and reaching out is a form of that tolerance. Tolerance is bad.
Good luck with your crusade to enforce mathematically rigorous language in programming circles (and note I'm not saying "let's rename Functor to Mappable"). 
You don't need to detect bottom, just run both in parallel and detect Nothing. If both are non terminating, the whole expression is non terminating, so there is no need to solve the halting problem.
I don't want people to use mathematically rigorous language. I want them to not use mathematically rigorous language.
Big surprise you want the Haskell community to be insular given how much of a douche you’re being. Fortunately, as a JavaScript programmer (in part) by day and a computer scientist / discrete mathematician by education, I do a whole lot of work to offset that by telling the unwashed JavaScript masses about Haskell 😱
I almost forgot to say... &gt; As for the Discord offer, I am definitely interested, though I will have concrete questions before taking up your time. I feel like I don't know enough to come up with specific questions. My time is very expendable most of the time.
(Author here) Thank you for the kind words. Some links: \- validity on github: [https://github.com/NorfairKing/validity](https://github.com/NorfairKing/validity) (contributions are very welcome!) \- validity on hackage: [https://hackage.haskell.org/package/validity](https://hackage.haskell.org/package/validity) \- genvalidity on hackage: [https://hackage.haskell.org/package/genvalidity](https://hackage.haskell.org/package/genvalidity) \- genvalidity-hspec on hackage: [https://hackage.haskell.org/package/genvalidity](https://hackage.haskell.org/package/genvalidity)\-hspec About documentation; note that there is a \`docs\` folder in the repository: [https://github.com/NorfairKing/validity/tree/master/docs](https://github.com/NorfairKing/validity/tree/master/docs) 
(Author here) `smallcheck` is for exhaustive property testing, which is something different from randomised property testing. This is why I didn't include it in the blogpost. Note that there are a bunch of other property testing-related libraries that I did not include in the comparison: `leancheck`, `speculate`, `quickspec`, `easyspec`, ...
Each object (agent) has a set number N of members (ports) where pointers (wires) point to/from. Each agent thus has exactly N references to it; no more, no less; and since each port has a wire to it's sister port, we know which N other ports refer to this agent. There is no need to traverse a heap from some root node, since we can travel backwards through pointers.
What's the motivation for this?
It's very good that someone gave this thing a term! I happened to independently "invent" this very same method as well a few years ago when I made [this small site](http://www.azlemi.org.il/en/) in Python (chosen rather than Haskell because I was thinking it would be easier to get people to contribute). It's somewhat obvious that if rendering the page on the client side takes a lot of time, why not use the exact same code to pre-render the page on the server side.. But now that this was given a term I can refer people to the concept.
Nice, I really like this. I'm trying to figure out the relation to the `Alternative` class, which seems to (vaguely) allow similar forms of branching. In section 7.2 they say: &gt; Selective functors also allow us to implement the desired parser, and arguably in a more direct style that does not involve trying one parser after another: ... So, it seems it's easier to skip the effects of one of the branches compared to `Alternative`, which feels somewhat intuitive. Is that always true however?
The next Mathematics of Program Construction (MPC) conference will be held in Portugal in October 2019, co-located with the Symposium on Formal Methods (FM). Paper submission is 3rd May 2019. Please share, and submit your best papers!
Don't hesitate to submit a PR, i don't have time to maintain the project anymore.
In zsh you can tab complete globs, so I sometimes do that as a final sanity check. Of course, the times I don't do are the times I live to regret!
There’s some discussion on Twitter https://twitter.com/andreymokhov/status/1102525008436432896
https://www.youtube.com/watch?v=G2y8Sx4B2Sk
Yes. And now dealing with such APIs becomes an odd exercise in figuring out whether something is an exception or wrapped in your explicit error type somewhere (which might also grow complex). I don't see the benefit in this exercise. It feels merely like a hint "you might want to deal with this one... or not". Such things belong in documentation. 
Even the most efficient oracle-included evaluators are still orders of magnitude slower than the oracle-less version though, right? You're right about your last point though, one can easily [infer](https://dl.acm.org/citation.cfm?id=1131315) EAL annotations so you do not need to change the source language at all.
&gt; One is that it only loads intero for the global stack resolver, ignoring the one for your project. This doesn't happen for me. Are you installing `intero` into your project like this? https://github.com/chrisdone/intero/blob/master/TOOLING.md#installing
&gt; Like, do I need to install intero in each different haskell project I have Yes. That seems to be the case. At least in my experience.
Modelling things with an OO inheritance hierarchy can be awkward in Haskell, as Haskell's type system does not support subtyping, where an object of the subclass "is-a" object of the superclass too. There are tricks to emulate it but they aren't particularly idiomatic. If you don't have inheritance you can emulate (immutable) objects with records of functions. The type of the record acts as an interface and you can have as many implementations as you want. Alternatively, you can also do some non-oo modelling with algebraic data types. When it comes to extensibility they work in the opposite direction as OO modelling, being easier to add new functions and harder to add new "classes"/cases. (Google for "expression problem"). IMO, the nicest things about modelling with ADTs in haskell are that you can use patteen matching syntax for case analysis and that the compiler will warn you if you forget to handle one of the cases. For example, if you use Maybe in haskell it forces you to always handle the error case, while in a language with nullable types that is easy to forget. Additionaly, if you modify the adt to add an extra case then the compiler will point towards all functions that need to be updated to handle the extra case.
Monad transformer stacks are a technique for dealing with effectful computations in Haskell. They don't have that much in common with data modelling.
"OS built on blockchain" sounds like https://dfinity.org/ What are the similarities/differences?
Isomorphic literally means "Identical Form" and thus is being used correctly here
Hmm, those are kinda completely different things, not sure how to compare them. What do you think is similar in particular?
&gt; 6) People start building things on it and it will go exponential because it is better than anything that ever existed. Seems to be the intent of both to be this super secure decentralized web platform, somehow using blockchain, that is supposed to be the future of everything.
Perhaps help me by describing how Dfinity achieves that? The main point of Moonad is to build an operating system on top of a proof language, i.e., replacing C by a dependently typed language. This open doors for many amazing things. For example, we can run our code in massively parallel architectures through interaction combinator compilation. We can build massively parallel processors. We can build a global, type-indexed repository of proofs and algorithms, similar to Hoogle, but as part of the OS, saving millions because people would stop reinventing the wheel (which is what most of devs do, because everything you written was probably written). This allows us to create a market for developers that are automatically paid for their work, because the computer can check it is correct. This has implications even for science, because once that is done, scientific publishing can be build right into the OS. You'll be able to import a paper like you can import a source code, you can check proofs mechanically making peer-reviewing obsolete. Basically, this manifesto is saying: "hey, if we build an OS on top of a proof language, we can have many cool things, why don't we?" That's all. I'm not sure how exactly Dfinity has to do with any of that to be honest, although it does seem like an interesting project!
Regardless of what it means, I still expect to see both metamorphism witnesses
I think you might be interested in (this video)[https://www.youtube.com/watch?v=Up7LcbGZFuo]. You can transfer DDD to functional, but definitely the OO modeling not as much.
I am totally sure that you are not going to "lose value" by learning the Haskell way of modeling domain. The Haskell way is different, but more natural, well-designed and powerful. Specifically about type interfaces and subtype relations : They are in Haskell too, under the name "type classes", just different from the Java and C# solution. Some things are more cumbersome then in Java \[for example fine-grained interface hierarchies\], but overall the Haskell system is much better because it is immensely more powerful. Java breaks down at so simple task as wrapping into an Optional. I mean : your type T may implement interfaces, but those will not be inherited by Optional&lt;T&gt;. Also Java can not handle methods with zero parameters. One such method is 'empty' from the Monoid type interface, which alone is immensely important. One could perhaps write a book about how much important stuff the Java type-interfacing is lacking behind Haskell's type class solution. I have a short [article about it](https://libeako.github.io/c/ID_1941809402.html) that you may want to read.
If *either* is non-terminating but the GHC RTS can't detect it, you have to run both forever and never get a result at all.
Well, that's what I meant. The only difference is the amount of work, more or less. Xmonad is just an illustration to the fact that writing nontrivial configuration and extensions in Haskell is a viable option. In fact, Haskell is even better for this purpose, as far as I am concerned. If Emacs was being created today, I'd say that implementing it with Haskell as opposed to Emacs Lisp would be much less of a burden (provided that someone comes up with a clever way not to recompile literally everything every time).
&gt; Haskell's type system does not support subtyping Not entirely true. There is no subtyping relation between types of kind different from `Constraint`, but otherwise typeclasses provide a form of subtyping.
Is your preference to throw everything but document what can be thrown like [System.Directory](http://hackage.haskell.org/package/directory-1.3.3.2/docs/System-Directory.html) does? I don't agree that this is the best approach, but I just want to make sure I understand your position correctly.
Sure, but we must be careful to not lead people to fall into the trap of trying to emulate OO patterns with typeclasses. Despite the similar name they are actually very different, being more like interfaces. More precisely, the thing that often trips people up is that you can't have heterogeneous data structures in Haskell. For example consider the following Haskell function showlist :: Show a =&gt; [a] -&gt; [String] showlist xs = map show xs The `xs` parameter to showlist can be a list of any type that is an instance of the `Show` typeclass, and implements the `show` method. However, the list needs to be homogeneous. You can have `showlist [1,2,3]` and `showlist [True, False]` but you can't do `showlist [1,2,False]`. Similarly, the addition operator having type `Num a =&gt; a -&gt; a -&gt; a` means you can do `Integer` + `Integer` or `Double` + `Double`, but you can't mix and do `Integer` + `Double`.
You never lose value by learning, unless youre somehow doing it _really_ wrong. Learning new ways of doing things has always just given me more insights on how to solve things in things I already know. Ie, learning new data modelling in **H**askell helps me solve problems in **C**++. There is opportunity cost of learning X when you couldve been learning Y. But I think thats pretty minor. 
There are two books I know which handle functional modelling so if you are interested in this topic I can recommend both to you. One is a still written at the moment but there are five chapters available: [https://github.com/graninas/Functional-Design-and-Architecture](https://github.com/graninas/Functional-Design-and-Architecture). Most parts of this book are in Haskell. And there is another book called "Functional domain Modeling by Debasish Ghosh, but here is Scala used.
&gt;Is that always true however? I may be misunderstanding what you mean by "always true", but I think the answer is positive, since we have the combinator `branch`: branch :: Selective f =&gt; f (Either a b) -&gt; f (a -&gt; c) -&gt; f (b -&gt; c) -&gt; f c It is quite general: the first parser selects the desired branch directly, by producing `Left` or `Right`. An `Alternative` equivalent of `branch x l r` would be something like `(failIfRight x &lt;**&gt; l) &lt;|&gt; (failIfLeft x &lt;**&gt; r)`.
Do you know anything about this one, is it any good? https://pragprog.com/book/swdddf/domain-modeling-made-functional
I'm thinking about buying his book, is it any good? https://pragprog.com/book/swdddf/domain-modeling-made-functional
From my time playing around with them last summer, there doesn’t appear to be much more aside from the official documentation. I was able to get a good amount done with the documentation, though. 
You are right that having oracles will degrade evaluator performance. But lambda calculus reduction requires oracles because lambda calculus variables are not linear. To support Haskell we have to deal with oracles also.
There's a user guide for happy [here](https://www.haskell.org/happy/doc/happy.pdf) and one for alex [here](https://www.haskell.org/alex/doc/alex.pdf).
Actually, from a quick look at DDD, it seems to be to a large extent set of ideas and practices to free the programmer from the OOP paradigm and let him think more in an abstract mathematical way (as in abstract algebra, but less formal). That should be, in principle, much easier in Haskell than in OOP languages. The only potential difficulty I can see would be in encapsulation, because sometimes Haskell doesn't let you hide the types of things as well as OOP systems do, or it requires some complex type level programming or spurious polymorphism used only to hide the types being used, not to apply operations to many types. OTOH, there is a trade-off between encapsulation and testability (and type-checking when compiling vs when running), so OOP sometimes foregoes the encapsulation or introduces some complex workarounds to marry both, e.g., some dependency injection/inversion. 
Yes but again, 99% of the Haskell functions you write in practice are actually compatible with EAL, so it is worth to have an oracle-less version even if not applicable to all programs.
Is the `Selective` constraint enough to support a `SelectiveDo` extension which allows pattern matching and bound variables in `do` blocks without requiring `Monad`? Type classes are way sweeter when you put a little sugar on them.
Aite thanks
That doesn't make sense. If one computation is non-terminating and the other isn't, then by definition it will terminate. If it returns Nothing the first computation can be aborted. There is never any need to detect nontermination, only termination.
I would consult /u/glguy's excellent [https://github.com/glguy/config-value](https://github.com/glguy/config-value) package. 
 concPair (Just $ last primes) (Just 3)
Thank you for this informative comment! I agree that the book concentrates too much on the details which should not be there. It tries to teach some language concepts and bits of Haskell (monads for example). This is certainly not what I want. I want to stay as high level as possible. (In the brackets I would say adding more explanations wasn't my only intent but also a publisher requirement). I had a lot of discussions about the reader with my publisher. I understand the necessity of keeping the reader in mind. That's the question I need to revisit as well. I don't want to start from scratch. This won't make the book that much better because I can fall into the same problems with the next try. I would rather leave the current text instead of writing it again. However It's very possible to replace the project. I'll need to think about too. I'm not sure how a book of 20 pages can accommodate so much info. Still, thank you for you advices!
I did not read it yet but I watched some of the videos from the author and I find it interesting, so if I have the time I will read his book. His home page is here [https://fsharpforfunandprofit.com/](https://fsharpforfunandprofit.com/)
Couldn't say! Haven't read it.
I'm the author, thank you for mentioning this! And actually I returned to the book recently and started a campaign for supporting its writing. I was just a week ago, so there is a Reddit post about the campaign [here](https://www.reddit.com/r/haskell/comments/avaxda/the_campaign_for_my_book_functional_design_and/). I've reworked the ToC and now my goal to review the chapters and to plan changes. After that I can proceed with writing the next chapters. u/Cock-tail u/himeji18 Feel free to contact me, I would be happy to explain things!
Thank you very much for taking the time to go through this, and apologies for not answering before. I'll quote and answer each thing in the rest of the reply ***** &gt;First of all, what is the C++ program doing, can you share that, we need to be sure that we are really comparing the same algorithms I have uploaded it [here](https://pastebin.com/U7kXsubY). I haven't written C++ code in a while so it's quite messy, sorry about that. I compiled it using `g++ --std=c++14 -O2 [...]` (`g++` version is 5.4.0). &gt;You need to provide the test input because \[...\] I tried with files from [this list](https://github.com/amephraim/nlp/tree/master/texts), as well as bigger files generated in a similar manner to what you did. &gt;Is your C++ program handling "unicode" or just bytes? I checked it and it's handling Unicode. &gt;the notElem test in toWords iterate over a list, which is perhaps the worse data structure for the job due to the O(n) behavior and the ugly memory footprint of the list. \[...\] Woops, didn't think about that, thanks for pointing it out. It seems to improve the runtime on my machine too. &gt;I switched from Data.Map to Data.HashMap for a small gain Oh, I already had tried that and it didn't seem to make much of a difference.
It was meant to be a "proof of concept", so I didn't put too much time into actually sorting out what counts as punctuation. I am aware that it's a terrible idea to use that kind of filtering in real-life code, but I thought it would take more effort than necessary to do it right.
Cool. A filter based on character category might be faster than traversing a list, though.
nvim + Ale + ghcid vscode + hie 
There is this nice tool which generates Alex and Happy files for you from a CFG: https://bnfc.digitalgrammars.com
Could linear types in Haskell help with the task?
vscode + hie on nixos. &amp;#x200B; [https://github.com/NixOS/nixpkgs/issues/14354#issuecomment-323591927](https://github.com/NixOS/nixpkgs/issues/14354#issuecomment-323591927)
That's _|_ matching the definition above
Domain modelling kind of naturally emerges in strongly typed functional languages like Haskell where developers tend to model everything as types and ADTs. In OO things get a lot more complex. OO style DDD in Haskell is a terrible idea.
&gt; If one computation is non-terminating and the other isn't, then by definition it will terminate. Surely, `Just 3` is terminating. So what (non-bottom) `Maybe (a, b)` value does this evaluate to, when the evaluation terminates? How about something slightly different? `concPair (last $ map (\x -&gt; if odd x then Just x else Nothing) primes) (Just 4)`, now the GHC RTS can't know which `Maybe` constructor will be used on the left.
No, that's not going to match on `_|_`, it'll simply match on the two `Just`s as indicated in the op. That is, I'd expect that expression to be treated like this: concPair (Just _|_) (Just 3) = Just (_|_, 3) So that bottom will slip through the same way it would with `liftA2 (,)`. Unless you go out of your way to match strictly for some reason. In any case, I don't think the function described in the op was meant to detect that sort of thing in the first place. 
This parsing example lacks the comparison against taking full advantage of the monadic interface. I could also write do '0' &lt;- char '0' bOrX &lt;- char 'b' &lt;|&gt; char 'x' case bOrX of 'b' -&gt; bin 'x' -&gt; hex It's difficult for me to see what selective functors bring to the table. One nice property is that they don't require monadic parsers, which might open up the landscape in terms of things like uu-parsinglib with it's amazing error correction abilities.
If you dont mind, please open an issue if it didnt work! There is a lot of effort currently into improving build reliability, features and stability. 
The more OO programming I did, the less I understood it. I have multiple big problems with the approach: * The creation of new types becomes a solemn ceremony: create the class file, create the test file, wire both into your build system, etc. This is the exact opposite of what I want: cheap types. The more types I have, the harder it is for me to screw up. * By binding functions to data, classes tend to accrete methods to service a variety of use-cases, because each use-case cannot break out into its own module. The terminal case for this is when you have a god object at the heart of the system. * Inheritance makes just about everything awkward. At any point, someone can come along and depend on private implementation details of your class. In Haskell is sometimes useful to define types and not export constructors. This gives you an encapsulation-like effect.
Very interesting. I wish it had more Category Theory perspective on it. I've read Applicatives are equivalent to *lax monoidal functors* [\[1\]](https://bartoszmilewski.com/2017/02/06/applicative-functors/). Since Selective Applicatives are using coproducts, does this mean Selectives are dual to Applicatives somehow? Maybe a lax comonoidal functor [\[2\]]( https://ncatlab.org/nlab/show/oplax+monoidal+functor) *1 [https://bartoszmilewski.com/2017/02/06/applicative-functors/](https://bartoszmilewski.com/2017/02/06/applicative-functors/) *2 [https://ncatlab.org/nlab/show/oplax+monoidal+functor](https://ncatlab.org/nlab/show/oplax+monoidal+functor)
We do have or have had employees from all over. I don't know the how's/why's of it all, but visas are a thing.
It would be useful to measure how many programs from hackage is compatible with EAL.
&gt; Surely, Just 3 is terminating. So what (non-bottom) Maybe (a, b) value does this evaluate to, &gt; when the evaluation terminates? If the second computation doesn't terminate and the first returns Just 3, execution is passed to the second computation, and the whole result in non terminating (so bottom). If it return sNothing, the second computation can be aborted. There is no need to _detect_ non-termination. &gt; How about something slightly different? concPair (last $ map (\x -&gt; if odd x then Just x else Nothing) primes) (Just 4), now the GHC RTS can't know which Maybe constructor will be used on the left. The GHC RTS Doesn't need to know anything about the constructors. `concPair _|_ (Just 4) == _|_`
Sure I will.
eh, right.
&gt; If one computation is non-terminating and the other isn't, then by definition it will terminate. --- &gt; if the second computation doesn't terminate and the first returns Just 3, execution is passed to the second computation, and the whole result in non terminating (so bottom). You seem to be moving the goalposts. First you said it would terminate if either did, now you are saying it will terminate only if both do? Can you give me a complete semantics that *doesn't* pattern-match on bottom?
You can do `echo *` to check what it will actually do before running a dangerous command.
I'm pretty beginner when it comes to Haskell, so may be a Dumb question, is it not kind of strange to have `Either`, which is an instance of `Monad`, used in the signature of `select` within the `Selective` class when `Selective` itself isn't a Monad? 
Hmmm... feel like I'm close to having a lightbulb go off about this stuff. Thanks again, your replies have brought me closer to understanding than anything I'd previously read. (I guess my brain likes to think in terms of machine-level representations.)
&gt; You seem to be moving the goalposts. First you said it would terminate if either did, now you are saying it will terminate only if both do? No, I said it would terminate if the first one did, and returned `Nothing`. &gt; Can you give me a complete semantics that doesn't pattern-match on bottom? See my EDIT above. This is the same semantics as what OP wrote above. 
The parsing example is Very cute!
Well that wasn't really my issue. I knew full well what I was *trying* to delete; I just typo'd. I would have done `echo foo/*` and then I still would have typo'd `rm -rf foo/ *`
Naïve question: What's the relationship between these and arrows? Arrows are also an abstraction between applicative functors and monads. They also have static and dynamic components.
Well, maybe I'm just being dumb, but I don't see a complete semantics that doesn't pattern-match on bottom. Are you sure you can't get what you want from `par` and friends?
Does anyone know when GHC's linear type plugin is expected to be released?
Apparently yes. For finitary selective functors you can write a bind operator: https://twitter.com/sclv/status/1102658162266685441?s=20 I don't know it there's need for a new extension though. Can't we just use ```RebindableSyntax``` and provide bind for finitary selective functors? 
I'm not seeing it listed in `ghcup` yet. Any idea when that will appear?
In the past I found it falls a bit short on describing how to wire them together. I made this repo for myself as a reference once I figured it out: https://github.com/dagit/happy-plus-alex
Does S7.1 answer your question?
I don't think there's any estimate, but definitely not 8.8. It looks like discussion has moved to converging on syntax, I'm not sure if there are other deeper issues to be sorted out though https://github.com/ghc-proposals/ghc-proposals/pull/111
No, that's more like [`Divisible`](http://hackage.haskell.org/package/contravariant-1.5/docs/Data-Functor-Contravariant-Divisible.html). There was a little Twitter discussion on exactly what the category theory behind this is. I think it probalby comes down to first identifying a product (tensor?) and unit in a monoidal category. /u/phadej possibly had some thoughts on this?
Sure, selective parsers cannot compete with monadic parsers in terms of convenience and expressiveness. But they seem to provide an alternative to `Alternative` parsers: they can also be statically analysed, and they support branching without the need for backtracking. We need to do a serious experiment before claiming anything else, and we claim nothing at this point :)
Here is an implementation of `bindS :: (Bounded a, Enum a, Eq a, Selective f) =&gt; f a -&gt; (a -&gt; f b) -&gt; f b`: [https://github.com/snowleopard/selective/blob/04a6ed3a38d36d09d402fb59956fdb08aa193c5e/src/Control/Selective.hs#L211-L238](https://github.com/snowleopard/selective/blob/04a6ed3a38d36d09d402fb59956fdb08aa193c5e/src/Control/Selective.hs#L211-L238) It's probably not a good idea to use `bindS` blindly though, since in the static context it will record all possible effects `f b` for every inhabitant of `a`! For example, a naive translation of the following code would be a disaster: do x &lt;- read @Int &lt;$&gt; getLine if x &lt; 0 then putStrLn "Negative" else putStrLn "Non-negative" As discussed in section 6.1, this will need to enumerate all possible `Int`s. To avoid this, we should really desugar it in the following way: ifS ((&lt;0) &lt;$&gt; (read @Int &lt;$&gt; getLine)) (putStrLn "Negative") (putStrLn "Non-negative") Now we need to enumerate only two `Bool`s. So, I think it will require a bit more intelligence than just `RebindableSyntax` :)
The relationship with arrows is discussed in section 7.1.
I believe this is the Twitter thread /u/ocharles mentions: [https://twitter.com/phadej/status/1102631278619381760](https://twitter.com/phadej/status/1102631278619381760) We have a candidate for the tensor product and with the usual unit `Identity`, but one can only re-associate this product to the left, not to the right: data (:|:) f g a where (:|:) :: f (Either x a) -&gt; g (x -&gt; a) -&gt; (:|:) f g a So, this doesn't form a monoid.
That's not even real code to begin with.
Hummmm! Very illuminating. Thanks!
I also want to point out that one have to be careful with categorical names. One example is that **both** `Monad` and `Applicative` are monoids in a category of endofunctors. But they are different monoids. In a similar fashion: --- A *lax monoidal functor* is quite abstract, there are three components: F : C -&gt; D -- functor unit : 1_D -&gt; F 1_C mult : F(x) &lt;&gt;_D F(y) -&gt; F (x &lt;&gt;_C y) (and those need to satisfy a bunch of laws) In case of `Applicative`: `C = D = Hask`, `1_D = 1_C = ()` and `&lt;&gt;_D` and `&lt;&gt;_C` are `(,)`. mult :: Applicative f =&gt; (f x, f y) -&gt; f (x, y) mult (fx, fy) = liftA2 (,) fx fy So it's **a** lax monoidal functor: we fix which monoidal products are used. Note: how Day convolution's type is like above `mu`, if you squint. data Day f g a where Day :: f x -&gt; g y -&gt; (x -&gt; y -&gt; a) -&gt; Day f g a --- For example a class class Functor f =&gt; Monoidal2 f where unit2 :: () -&gt; f Void mult2 :: (f a, f b) -&gt; f (Either a b) is **also** a lax monoidal functor: `&lt;&gt;_D = (,)`, but `&lt;&gt;_C = Either`. An exercise: what's laws that class would have, what it could be? --- So, what's `Selective`? Good question. One have to mix&amp;match to see which abstract category theoretical definition fits, when instantiated with right Haskell stuff.
If I use the -ddump-rn-trace flag for ghc, it gives me nice information which looks like this: "Import usage \[(import Control.Lens, \[&amp;, .\~, ?\~, At{at;}\], \[\]), ...". I can see there if there are unused imports and also for unqualified imports, what is exactly used from them. Does anyone know how I can access this information through the GHC API?
I do think that ... the current design for how it interacts with type checkign joinpoints is a hack thats not the right approach... but they plead finite time etc
It looks like someone has already created a [PR](https://github.com/haskell/ghcup/pull/71).
I'm not sure of the current status. I'm sure /u/mboes can offer some insight, however.
In chapter 10 of "Thinking Functionally with Haskell" by Richard Bird, he mentions the action done :: IO (), which does nothing (and so can be used as the identity for fold, for instance). I can't find a definition for it anywhere in the code for the book. Is there some standard function does the same thing?
I feel like laziness means I can use Selective to simulate any particular monadic bind, but not uniformly.
&amp;#x200B; &amp;#x200B; module Main where import qualified Accounts as A import qualified DB as DB main = do dbHandle &lt;- DB.createConnection runProgram dbHandle runProgram dbHandle = do \-- we get a request to save the user user &lt;- processRequest requestData &amp;#x200B; \-- Supply the DB handle to the Accounts module so it can obtain a database connection A.saveUser dbHandle user \-- We must pass the dbHandle via recursion in order to maintain the connection runProgram dbHandle 
This is along the lines of it and I think I could figure out how to do each of them in isolation. The issue I'm having is figuring out the model for application state in Haskell. For example, I don't want to open a new database connection for each request. It would be better to reuse connections. Where and how would those be stored and what's the best way for modules to make use of them? I'm sure someone will want to suggest using a connection pool library but that misses the point. I can figure out how to use the library, but what's the idiomatic way to store that connection pool in application state so it doesn't get garbage collected and need to be recreated? Someone suggested I can use a Reader to store application state, but that actually brings me back to square one because I now need a way to keep the Reader around. So whether it's MVar, State, Reader, etc, the only solution I see to keep state around is by explicit recursion via a main program loop as shown here [https://www.reddit.com/r/haskell/comments/awu93v/how\_to\_persist\_db\_connection\_information\_in\_module/ehvt9d4](https://www.reddit.com/r/haskell/comments/awu93v/how_to_persist_db_connection_information_in_module/ehvt9d4) I'm just not sure if that's the idiomatic approach or not. &amp;#x200B; &amp;#x200B;
&gt;The only potential difficulty I can see would be in encapsulation, because sometimes Haskell doesn't let you hide the types of things as well as OOP systems do You can implement Abstract Data Types using modules, by hiding your data type constructors and providing "smart constructors". This is exactly how `containers` is done, you don't how Data.Map or Data.Sequence are implemented.
If you are already in IO, I believe throwing everything is mostly what you want. System.Directory is not a good example in my opinion. https://hackage.haskell.org/package/hpath Here I document as far as possible and I also test most exceptions, so I know I don't accidentally break the exception API for the user.
What do you mean by "not uniformly"?
I think the win is mainly that the expression can still be statically analyzed, whereas this monadic expression cannot. Perhaps there are also some things that are selective functors but not monads (haven't read the paper, so maybe they mentioned some).
`unamb` is devious, since correctness depends on the two sides semantically agreeing. However, you can do what you want with just the "parallel or" which is por :: Bool -&gt; Bool -&gt; Bool por a b = (a || b) `unamb` (b || a) by writing concPair a b = if por (isNothing a) (isNothing b) then Nothing else liftA2 (,) a b similarly, you can write concMin a b = if por (a == 0) (b == 0) then 0 else (1 +) $ concMin (a - 1) (b - 1) which even works when the domain of naturals is flat. And some interesting history of programming theory: it is a classic result due probably to [Plotkin](http://homepages.inf.ed.ac.uk/gdp/publications/LCF.pdf) that the famous domain model a la Scott is *fully abstract* for PCF (simply typed lambda calculus with booleans and naturals)+por, but not for plain PCF. The attempts to rectify this problem by Curien, Berry, etc lead to a number of major advancements, including the notion of "stability" which then lead to coherence spaces, and so, indirectly to linear logic, and also, later, the development of game semantics (which finally presented a fully abstract semantics of PCF) Also, in philosophy of PL Theory, this tells us that the Church-Turing thesis is false at higher types. I don't remember who I got this insight from, it might have been Andrej Bauer or maybe Neel Krishnaswami (someone denotationally minded with a blog...), but the idea is that different reasonable models of computation/programming languages already have different answers to the question "what are all the computable functions from pairs of boolean to a boolean" (same if you replace "natural number" with booleans), even though the question "what are the computable functions from natural numbers to natural numbers" has, it seems, an absolute answer.
I doubt there is a function you can write in Haskell that has the type `Selective s =&gt; s a -&gt; (a -&gt; s b) -&gt; s b`, but if you let me take a look at the definition of the function you pass me, I can use infinite lazy sequences of `select` to perform the same computation. Basically, `select` lets me extract a single bit of information and make a decision based on it. Since we're non-strict, I can nest them to extract an arbitrary number of bits. I haven't thought about this deeply though so idk if it works out.
&gt; Perhaps there are also some things that are selective functors but not monads No, any monad can be given a `Selective` instance: examine the value of the first argument, and then skip or execute the second one (this implementation is referred to as `selectM` in the paper).
That seems backwards, unless I'm misunderstanding :) The hypothetical was that there exist types for which a `Selective` instance exists but a `Monad` instance does not; `selectM` only seems to demonstrate that a `Monad` instance existing implies that a `Selective` instances does as well.
Oops, indeed, my apologies :) Then the answer is Yes, and a good example is the `Const` functor. 
I think I see what you mean. You may be interested in having a look at this implementation of `bindS` for a variant of `Selective`: https://gist.github.com/copumpkin/d5bdbc7afda54ff04049b6bdbcffb67e#file-selectivesigma-hs-L53-L58 :) 
Yeah, `por` would also work. I was just thinking that `concPair` would be slightly nicer, but they can implement each other. Also, although `uamb` is devious, I don't think `concPair` would be, right?
`concPair` is perfectly fine. I point to `por` mostly to help steer towards papers from the 70s and 80s!
(Neovim) `ALE` + `hie` for linting is the best I I can have today, the ale completion seem to be off when using with hie. I use to have great completion experience with `ghc-mod` via `deoplete` using [neoc-ghc](https://github.com/eagletmt/neco-ghc) but then `ghc-mod` no longer working with new ghc. Will look into `hdevtools`, any recommendation?
Note that the above thing in the tweet doesn't do that -- it only records the effect that one desires, and so it really _is_ `bind`. It's totally feasible (if ugly) to generalize that to write a "bindS done right". Further, one could actually use `unsafePerformIO` to very unsafely actually get the binary representation of the thunk, and "read it out" byte by byte, then based on branching on that, only enter actual "proper" value. (i.e. since we're inside a machine, we actually only have finitary representations, even if our data structures "look" infinite -- this is actually a form of "Skolem's Paradox"!). So in "real" terms, `bind` is by a series of dirty hacks, fully recoverable from `select`.
See my sketch above: https://www.reddit.com/r/haskell/comments/axje88/selective_applicative_functors/ehw5x6l/
Ok, So `Const` is `Applicative` and `Selective` but not `Monad`. What about `ZipList` -- is that `Selective` too?
Which was merged just now: https://github.com/haskell/ghcup/commit/21ba3f371408d73b1ef77a63b6fcea56f1c26a69
There's an unfinished book on leanpub for this topic https://leanpub.com/alexandhappy
Hmm this looks exactly like I though any normal program that uses any kind of connection (file, network, database...) would look. What's bothering you in this scheme? I don't know about restarting a died connection though, how would you detect it has died? I guess there would be error handling in the IO monad, or perhaps in the DB monad, exactly like you would handle IO errors.
What's the use of a the return value if you don't have any way to deal with it? Can you provide a C or Python example of what you mean? A Haskell snippet?
I do Java on my day job and Haskell on the side. I don't use OOAD for both. &amp;#x200B; I just find it simpler to think everything as data transformation: 1. define the input 2. define the output 3. write a function that transform the input to the output (this in itself may contain multiple data transformation pipelines) &amp;#x200B; In java, this translates to dumb POJOs and thick service classes.
Not an answer to your question, but one more class of things: `Validation` is also `Applicative` but not `Monad`.
*Woah!* It's your **1st Cakeday** BytesBeltsBiz! ^(hug)
Validation is “constlike”.
Just compile it with cabal. It will work fine for the same version of ghc you compiled it with. Assuming it's supported. Works for me with non-stack 8.6.2
Thank you, I'll try.
Ale + hdevtools, you need the same version of ghc as used to compile your dependencies. If it's 8.6 - version from hackage won't compile, but there's a MR by me that makes it to compile. Can be used without stack and cabal as long as you provide all the flags to ghc.
The idea seems to be old : [https://mail.haskell.org/pipermail/haskell-cafe/2012-July/102518.html](https://mail.haskell.org/pipermail/haskell-cafe/2012-July/102518.html)
Switched from vim + ghcid to vim + ale + hdevtools due to memory leaks in ghcid. Then switched to vim + coc + hie because having to reanimate hdevtools for each new version of ghc is not fun. Hie seems to be more alive.
There will be some magic around cabal helper (it's in submodule but you'll need to compile it manually) and you'll need to put it somewhere and point at it using some environment variable - hie will complain. To make it work for the project I'm using minimal stack.yaml + package.yaml. basically telling it just use system ghc and not to do anything stupid
But that's because project I'm working on is neither cabal nor stack
For the record, you are talking about Windows, right?
Haven't read the whole paper yet, but I have an equivalent formulation which (imo) is prettier: newtype a -? b = Lazy { unLazy :: Either (a -&gt; b) b } infixr 0 -? class Applicative f =&gt; Selective f where {-# MINIMAL (&lt;*?) | liftS2 #-} (&lt;*?) :: f (a -? b) -&gt; f a -&gt; f b (&lt;*?) = liftS2 id infixl 4 &lt;*? liftS2 :: (a -? b -? c) -&gt; f a -&gt; f b -&gt; f c liftS2 g fa fb = pure g &lt;*? fa &lt;*? fb Full version: https://gist.github.com/LSLeary/c6a43e42bb08c27ef1debf4cc5f5b1a0
Linux.
Well, not quite. There are the Internal modules that leak implementation. Also, it's relatively awkward (without the Backpack module system extension) to say "I use here any container, either List or Map, I don't know which". Also, impossible to say, as somebody already mentioned above, "this is a list of some values, I don't even know if they are of the same type and I can't check". But don't get me wrong, I think Internal modules is a good practice and I'm fine checking if they are used in the code I'm debugging. And generally, I like the common set of trade-offs in Haskell code and I'm aware there is some wiggle room without sacrificing type-safety. Some people can even simulate OOP in a non-shallow way, e.g., https://programming.tobiasdammers.nl/blog. I guess what I'm saying is more about the culture than the technology. Historically, OOP is more about running and modifying closed-source or above-your-paygrade libraries, so no wonder.
There's nothing that bothers me about it, I just want to make sure that I understand the idiomatic way Haskell keeps values around for reuse because it's quite different than in other languages; and of all the Haskell material I've read I didn't actually learn about how to do it until after I worked through a book on Elixir. 
Is this really a new typeclass though? It seems like you can recover `select` just from Applicative: liftA2 (\e f -&gt; either f id e) :: Applicative f =&gt; f (Either a c) -&gt; f (a -&gt; c) -&gt; f c Or am I missing how this is different from the `select` they introduced?
They call this `selectA`. The problem with it is that it runs the effects of the second argument every time.
I actually don't see why it would be different from other languages. You open a database, a file, a network connection, whatever. You pass a handle around. That's normal practice in just about any language. Perhaps I don't understand something?
Can you explain how it runs the second argument every time? I would think laziness would take care of this and ignore the second argument in the case of a lifted Left.
&gt; What about `ZipList` \-- is that `Selective` too? Yes, any `Applicative` can be given a `Selective` instance simply by defining `select = selectA`. In case of `ZipList`, this leads to something similar to the [SIMT execution model](https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads): &gt; to handle an IF-ELSE block where various threads of a processor execute different paths, all threads must actually process both paths (as all threads of a processor always execute in lock-step), but masking is used to disable and enable the various threads as appropriate Similarly to `Const`, there are multiple `Selective` instances for `ZipList`. We still need to look into whether other definitions of `select` lead to anything interesting.
**Single instruction, multiple threads** Single instruction, multiple thread (SIMT) is an execution model used in parallel computing where single instruction, multiple data (SIMD) is combined with multithreading. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Glad to finally have the TemplateHaskell bug fixed on Windows
Yes, after sharing the paper, we were pointed to this mailing list thread, as well as to Jeremy Yallop's dissertation where he introduces `DynamicIdiom` type class with `branch :: f Bool -&gt; f a -&gt; f a -&gt; f a`, which matches our derived \`ifS\` combinator. Because conditionals are so fundamental, it is not surprising that selective-like interfaces have been showing up earlier. We will do our best to cover all newly discovered prior work in a revision, so please keep sending us links and pointers on anything related -- this is a call for everyone!
Try to implement the ping-pong example from Introduction using this approach -- you'll see that laziness doesn't help here.
It follows from the definition of `liftA2`: liftA2 (\e f -&gt; either f id e) x y = fmap (\e f -&gt; either f id e) x &lt;*&gt; y Even if `either` ignores the value of type `a -&gt; b` inside `y`, `&lt;*&gt;` will still combine the `f`s. Does that clarify it? 
`Applicative` separates effects and values in such a way that the latter cannot impact the former, so whether or not the function (value) uses the argument (value) can't make a difference to the combined effects. This is the major distinguishing feature of `Applicative` and `Monad`. The latter executes an `f a` to produce an `a`, the uses an `a -&gt; f b` to construct new effects dependent on that `a`. For the former we execute an `f (a -&gt; b)` to produce an `a -&gt; b`, then execute an `f a` to produce an `a` to which we apply the function, producing a `b`. To give a simplified example, consider: x :: IO () x = pure (const ()) &lt;*&gt; putStr "something" `const ()` happens to be lazy in its next argument, but `(&lt;*&gt;)` has no way of knowing that; as far as it's concerned it needs to run the effect in order to get the `()` value `putStr "something"` produces, and feed it to the function. Hence the string is printed. Note also that if it didn't do this we'd break laws; the following should hold: x = const () &lt;$&gt; putStr "something" = id &lt;$&gt; putStr "something" = putStr "something" where `const () = id` because it has type `() -&gt; ()`.
Yes, moving the function into the `Either` is indeed a viable alternative. We haven't given it a try yet, but maybe we should have -- thank you for sharing this experiment!
&gt; I have uploaded it here. I haven't written C++ code in a while so it's quite messy, sorry about that. I compiled it using `g++ --std=c++14 -O2 [...]` (g++ version is 5.4.0). Your haskell implementation is not similar to the C++ implementation in (at least) the following points: - The C++ implementation uses a static `switch` to filter the characters, when the haskell implementation uses a list. We already saw that replacing the list by another data structure can be a big win, but replacing it by a static \`case\` is even more win. On my previous example, I go down from \~0.490s to 0.340s using the following: ``` isNotPunctuation c = case c of ',' -&gt; False '.' -&gt; False '!' -&gt; False '?' -&gt; False ';' -&gt; False ':' -&gt; False '-' -&gt; False '\\' -&gt; False '"' -&gt; False '\'' -&gt; False \_ -&gt; True ``` - Your C++ implementation first split by words and then trim special chars from words. The Haskell do the opposite. I don't know if this can influence performances. - The sorting algorithm is different, resulting is slightly different output. That's not a performance issue, but it makes validation more difficult. This can be fixed by sorting first be count and then by word. &gt; I tried with files from this list, as well as bigger files generated in a similar manner to what you did. On the Bible example, my running time of the Haskell code with the modifications I depicted is 0.400s. Your C++ code, compiled with `-std=c++14 -O2` with gcc 7.4 is 0.210s &gt; I checked it and it seems to be handling Unicode. From what I'm reading, the C++ code works exclusively on `char`. So you need to take into account that the haskell code, by using `Text`, is paying a huge conversion price. Switching to `Data.ByteString.Lazy.Char8` reduces my running time from 0.400s to 0.321s. We are still 50% slower than the C++ version. It is now time to go back to profiling because we now have a code which is similar to the C++ in term of semantic. I obtain my profiling result compiling with `-prof -fprof-auto` and running with `+RTS -p` and the most relevant lines are: ``` COST CENTRE MODULE SRC %time %alloc countWords Main CountWords.hs:32:1-42 54.5 48.5 toWords Main CountWords.hs:29:1-61 37.6 47.7 hash Data.HashMap.Base Data/HashMap/Base.hs:137:1-28 4.8 1.9 ``` (I'm using the `HashMap` which, for me, gives a huge difference!) That's not really interesting. For now I think that the next step is to rewrite the loop using low level `ByteString` operations and use a mutable hash structure, but that's more intrusive work compared to what was already achieved by just using `ByteString`, writing a static `isNotPunctation` and using `HashMap`.
I like your encoding more and more -- the interplay between `a -? b` and `a -&gt; b` is very pretty indeed! If you DM me your name, we can mention this alternative in the paper giving you appropriate credit and linking to your implementation. 
*Eyy, another year! * It's your **6th Cakeday** Herbstein! ^(hug)
Glad you like it! No need to DM; this account is my public account. I'm happy to be credited as L. S. Leary or Lennox S. Leary.
&gt;Note that the above thing in the tweet doesn't do that -- it only records the effect that one desires, and so it really *is* `bind`. I'm sorry I don't follow. In what sense does your implementation "only record the effect that one desires"? Is it really different from the `bindBool x f = ifS x (f False) (f True)` as in the paper? `bindBool` records /both/ effects. How can it know which one is "desired"? During the execution, of course, all "undesired" effects will be skipped. &gt;So in "real" terms, `bind` is by a series of dirty hacks, fully recoverable from `select`. This part I think I get, and it's pretty cool! Thanks for the pointer to "Implicit Configurations" paper.
I've come across a few other options. In Java I could store some values as static class members so I don't need to pass them around. I can just reference the class and grab what I need without having to wire it throughout the application. The OOP singleton pattern applies here as well if you don't have a DI framework, which itself is another method to get values/handles where they need to be. In lisp-y languages I can set up a (by convention) read only global value and access them access them where needed by referencing them. In Elixir we can create Generic Servers which encapsulate their own state and access the servers via a registry so we can pass messages to them. So I've seen a number of ways so get state/config values where their needed in applications, Haskell is actually the first one I've come across that requires explicitly passing it around via function parameters. 
Is there a canonical library that provides this typeclass? I'd love to start using it *today* without having to invent my own.
I find it a bit unsatisfying that any Applicative can be a Selective. I was expecting there to be some law ruling that out. I haven't had time to read the paper yet, so sorry if that was already addressed. You don't have to answer if it's in there since I will end up reading it this weekend anyway. 
Yes, it's here: https://github.com/snowleopard/selective We'll put it on Hackage after finalising documentation and getting rid of some unnecessary dependencies. But you are welcome to use it today already!
Perfect. Thanks!
I like that you test the exceptions in the test suite. Very well done. I understand your approach now. Thanks for clarifying.
Ok, I guess I don't understand what you mean by "records both effects"? Do you mean it keeps a thunk of them lying around in arguments to a function? I guess I would describe that as "tabulates" which I find more clear.
I expect the extension to land in 8.10 (since ghc-8.8 branched off a few months ago and is not receiving major features anymore). The work is ongoing - I have recently merged several fixes to issues blocking linear types. The missing parts are (a) fixing corner cases such as unboxes tuples and Template Haskell (b) decision on the syntax (c) code review. If you are interested, check out [https://github.com/tweag/ghc/](https://github.com/tweag/ghc/), branch linear-types.
A bit OT, but I was looking at the [GHC roadmap](https://ghc.haskell.org/trac/ghc/roadmap) and I am now wondering why are multiple point releases being developed in parallel. For example, will 8.2.3 be ever be released, even though we are now already beyond well 8.6 ?
Beyond the user guides, I would suggest finding other repos that use happy/alex. Don’t know if it’s useful, but I did toy with Alex/Happy during a course in uni, to make a minimal interpreter for a made up specification called C--. You can find it here https://github.com/Tehnix/Cminusminus-compiler. 
So converting this to a time estimate: roughly ~2 years from now? (Judging by [this](https://ghc.haskell.org/trac/ghc/blog/2017-release-schedule) link, a major release takes about 12 months).
I just tested including a file in my local curl-runnings tests and like you, I could not get it to work. The support of `!include` is provided by `https://hackage.haskell.org/package/yaml` so I don't know what is going on. I'm using the latest release, 0.9.2. Maybe open a ticket against `curl-runnings.` 
IDEA + Intellij-Haskell. The former delivers best IDE experience, the latter adds Haskell support.
That was an argument for more frequent releases, which was subsequently adopted, aiming for two per year. https://ghc.haskell.org/trac/ghc/wiki/WorkingConventions/Releases With 8.8 on the way out now 8.10 would be expected later this year. 
Global state is evil. You restrict your program to a single connection, and make it really hard to do multi-threading. Even though static members/global variables/singletons exist in a language, one should use them with extreme caution. You can have global state in Haskell too (see `MVar`s for example) but it's not normal to use them for this purpose.
Aha, looks like we are talking about the same thing. What I mean by "recording all effects" is that if `enumerate @a == [a1, a2, a3, ...]`, then `bindS (x :: a) f` will necessarily need to contain (or record, or tabulate) all possible effects `f a1`, `f a2`, `f a3`, etc in a chain of `select` operators. Then instances like `Const` would collect all of these `f`s, while instance like `IO` would skip all but one. And if `bindS` is included into the `Selective` type class, then `IO` would be able to jump into the right `fi` directly via `bindS = (&gt;&gt;=)`.
I might yes. I'll wait a bit too see if someone else has some great ideas maybe. What does seem to work is this: in defaults use \`naam: &amp;naam 'Luke Skywalker'\` and then reference it using \`\*naam\` in the test file... but this prevents me from putting strings together like \`something/${naam}/something\_more\` unfortunately
8.4.4 was released after 8.6.1, but I think/hope that non-linearity should stay quite rare. Also that we get four minor releases. 
Thank you, once again, for explaining various relevant categorical notions in terms that I can understand. Your comments have been tremendously helpful!
It's quite common for this sort of thing to happen, I think usually to do with backporting bug fixes (especially security bugs). It extends the useful life if a "major" version (whatever that means for a given project), which is helpful if users can't necessarily update to a new major version easily. For example, postgres recently released versions 11.2, 10.7, 9.6.12, 9.5.16 and 9.4.21. 9.4 is over four years old, and 9.5 is over three years.
What libraries exactly? I'm not that experienced in haskell, but my rule of thumb for that was something like 1. Text by default 2. Bytestring for writing files \\ net 3. Strings when there is no other way Everyting lazy by default, use strict when too slow/too much memory and you profiled it.
I'm currently using a bit of a frankenstein configuration that works well. I use `neovim` + `ghcid` + `fasttags`, but with `TabNine` installed, using `hie` as an autocomplete oracle. `ghcid` gives me snappy error/typo responses and `fasttags` gives a reliable ability to jump around and the TabNine stuff "completes what I mean" on a shockingly regular basis.
I used to do this, but the constant targeted cosmic ray expenditures can be exhausting, and quite tricky in the presence of ECC RAM. I recommend working up to it gradually.
They all serve different purposes! Use the lazy versions when streaming, the strict versions otherwise; use the bytestring versions when dealing with bytes, and the text versions when dealing with characters. String is equivalent to Lazy Text in that regard, I use it in prototypes where performance isn't a concern just because it's slightly easier to use the builtin String than to import \`Data.Text\` and enable \`OverloadedStrings\`.
I didn't think of it that way, but I guess it makes sense.
&gt;From what I'm reading, the C++ code works exclusively on `char`. Yes, I was wrong, sorry about that. After further inspection, I am a bit confused about it: the C++ version correctly handles the accents in spanish texts like [this one](https://www.gutenberg.org/cache/epub/2000/pg2000.txt) one (that is why I thought it was using Unicode) but `ByteString.Lazy.Char8` runs into problems with them. &gt;For now I think that the next step is to rewrite the loop using low level ByteString operations and use a mutable hash structure, but that's more intrusive work compared to \[...\] You are right, I think it's hard to make any further changes without modifying the program too much. Thank you again for your help!
&gt; this is a list of some values, I don't even know if they are of the same type and I can't check You can't safely do anything with the values in the list, but you can use RankNTypes to express that you accept such a value as an argument: `[forall a. a]`. I think you can still use parametric functions on that list.
&gt; There are the Internal modules that leak implementation. Sure, but if you don't want to expose an `Internal` module you certainly don't have to. In JS and Python there aren't really private fields, so you *can* muck around with the internals if you need to. In Java you can use reflection to set the values of private final fields. In C / C++, the data layouts are predictable enough that you can use pointer arithmetic to fiddle with internals if you really need to. In practice Haskell provides at least as much encapsulation as C++.
&gt; to say "I use here any container, either List or Map, I don't know which". `Traversable` constraint, if you are consuming it. `a -&gt; m` and a `Monad m` constraint if you are building it.
Yet another reason to demand ECC RAM. :)
&gt; From what I'm reading, the C++ code works exclusively on char. Which almost certainly means *not Unicode*. `char` (despite the name) is for single bytes. There are more than 256 Unicode code points. You could assume UTF-8 and then trust in some of the properties of correct UTF-8 to avoid decoding/encoding, but that's not what `Text` is doing, that would be a better than for `ByteString`.
On mobile right now, but three quick comments: Piece shouldn't be a typeclass. It only has one instance. `attacks` should be a top-level function that cases on the chess piece type. Having piece as a typeclass can introduce the possibility of the dictionary showing up at runtime. Use strict fields for things like Int, with BangPatterns. Compile with -O2.
You mentioned in the paper that you implemented a library for these in OCaml to work with Dune. Is this library published on OPAM (or a similar repository)? I'd like to make use of these myself! I saw the Haskell library, but most of my actual work is in OCaml.
If you have some structure composed of many little strict `Text` or `ByteString` values, and you want to serialize it, should it be to a lazy `Text` / `ByteString` or to a lazy one? It makes more sense to serialize it to a lazy version, because allocating and copying memory to the new strict chunk can be expensive, and it's wasted effort if you simply want to dump those bytes into a file handle. So better return the lazy version (basically a linked list of strict chunks) and let the user choose if he wants to strictify or not.
Here it is: https://opam.ocaml.org/packages/selective/
Another way to look at it is that a composite function is a function which is output by a higher-order function. Let `h = f . g`, then `h` is a composite function, it is composed of `f` and `g`, i.e., `h` is the result of applying the higher-order function `(.)`.
Maybe we can do like [`Day`](https://hackage.haskell.org/package/contravariant-0.6.1/docs/Data-Functor-Day.html) where we take liftA2 :: (a -&gt; b -&gt; c) -&gt; (f a -&gt; f b -&gt; f c) and interpret type variables `a`, `b` as existential types liftA2 :: (exists a b. (a -&gt; b -&gt; c, f a, f b)) -&gt; f c represented in Haskell as data Day :: (Type -&gt; Type) -&gt; (Type -&gt; Type) -&gt; (Type -&gt; Type) where Day :: (a -&gt; b -&gt; c) -&gt; (f a -&gt; g b -&gt; (Day f g) c) liftA2 :: Day f f ~&gt; f which is a [monoid in monoid category `(~&gt;)` with `Day` as multiplication](http://www.fceia.unr.edu.ar/~mauro/pubs/Notions_of_Computation_as_Monoids.pdf). Maybe the same can be done here liftS2 :: (a -? b -? c) -&gt; (f a -&gt; f b -&gt; f c) liftS2 :: (exists a b. (a -? b -? c, f a, f b)) -&gt; f c data Night :: (Type -&gt; Type) -&gt; (Type -&gt; Type) -&gt; (Type -&gt; Type) where Night :: (a -? b -? c) -&gt; (f a -&gt; g b -&gt; (Night f g) c)
My experience: - Languages are similar enough so that knowledge is largely interchangeable - Haskell has a larger community and more learning resources (you are maybe referring to RWH for the outdated one?) - Purescript libraries have less documentation - It is easier to create GUIs and interact with JS with Purescript It depends on your background, but I think that starting with Haskell is a good choice. You will be able to try Purescript easily after if you want.
We built this system, which isn't Yesod specific, but also doesn't have any UI, for exactly this purpose: [http://hackage.haskell.org/package/hworker](http://hackage.haskell.org/package/hworker) &amp;#x200B; It's still actively used, \_buuuut\_, it hasn't been updated based on Redis syntax changes since 2.8 (essentially, some of the command syntax changed), as it simply hasn't been needed for the application where it has been running continuously for the last several years. I don't think that would actually be a big change (the whole application is \~450LOC, if you were up to fixing it).
The [DataHaskell](https://www.datahaskell.org/) people could be interested by this, or maybe guide you on how to do it.
Also, lists are not the optimal data structure for concatenations.
Modules don't use state. Functions use state. Functions are not methods, and a module is not a class. This is a bad intuition that you should drop. Part of why this is hard for you to think about is that modules do not store state. They are not classes. The concern of state is handled by the calling context, not the declared context. So state is handled not in the construction of these DBConnections, but by the code that calls that construction - You have to move your thinking up a level in the callstack, essentially. The most popular mechanism for doing this is using one (or multiple, nested) ReaderT monad transformer stacks in your application architecture - When the reader monad stack finishes evaluating, that DBConnection closes, so you can think of them like loops. Sometimes (often) they may explicitly contain recursive loops. You may, for example, instantiate a pooled connection near the top of the callstack, which explicitly loops until it receives a kill signal, and then client code is handled by green threads that use a signalling channel to use that pooled connection, which would include their own ReaderT stack that does not explicitly loop. You could get even more complex there and include things like closing inactive pools until further commands have been received, etc. Monadic recursive loops to keep references alive are quite idiomatic in Haskell, so don't shy away from using them - but do keep in mind that in general we avoid using long lived references, and that this means that although almost every program will contain at least one loop, most programs should not contain very many. 
Yes so you've correctly uncovered a limitation with yaml importing. Unfortunately, the yaml spec and the yaml parsing library in Haskell does not give us a way to interpolate anchors (\`&amp;\` and \`\*\`) inside of strings. Curl-runnings could certainly be (non-trivially) altered to give some special syntax to do this, but for now it is not possible. &amp;#x200B; The \`${}\` syntax you were originally trying to use is only for environment variables. Fortunately, environment variables *can* be interpolated, as it is built into curl-runnings directly. So one way to get this working would be to invoke curl runnings with the environment variable: &amp;#x200B; naam="Luke Skywalker" curl-runnings -f &lt;your test&gt; &amp;#x200B; Which would allow you to do \`something/${naam}/something\` like you are saying. &amp;#x200B; &amp;#x200B;
The set of open milestones doesn't necessarily correspond to the set of releases in-flight. Trac doesn't support any notion of closing a milestone beyond setting its completion date but doing so would confusingly suggest that a release was made. The other option is to delete the milestone but then we end up having to re-milestone the tickets assigned to that milestone, which we try not to do unless it's absolutely clear that the release won't happen. Of course, at this point I think it is safe to say that 7.10.4, 8.4.5, and 8.2.3 won't happen so we probably could delete them. I'll likely do this after the GitLab migration is finished.
Yep, as I said, awkward. :)
Excellent, thank you so much!
Here are some building blocks you can use to build it from scratch with some recent redis (don't forget hedis lib dependency): {-# LANGUAGE OverloadedStrings #-} module DB where import Database.Redis hiding (decode) import Data.ByteString.Char8 as B8 (ByteString, pack) import Control.Monad (forever) import Control.Monad.IO.Class (liftIO) enqueue :: HostName -&gt; B8.ByteString -&gt; IO (Either Reply Integer) enqueue redisHost s = do conn &lt;- checkedConnect $ genConn redisHost runRedis conn $ do rpush "queue" [s] getEnqueued :: HostName -&gt; IO (Either Reply (Maybe (B8.ByteString, B8.ByteString))) getEnqueued redisHost = do conn &lt;- connect $ genConn redisHost runRedis conn $ do blpop ["queue"] 100 -- 100 is timeout consumeSingle :: HostName -&gt; IO () consumeSingle redisHost = do item &lt;- getEnqueued redisHost theTask &lt;- case item of Right (Just ("queue", x)) -&gt; getItem redisHost x _ -&gt; return Nothing case item of Just x -&gt; processItem redisHost x Nothing -&gt; return () consumer :: HostName -&gt; IO () consumer redisHost = do -- borrowed from https://github.com/MichaelXavier/HollaBack/blob/master/HollaBack/Scheduler/Main.hs#L38 _ &lt;- forever $ do consumeSingle redisHost return () processItem = undefined getItem = undefined Put the consumer into an executable and it will process new items as they arrive while waiting until they arrive. Enqueue appends an item to the queue.
Do you allow remote work (from Germany in my case)?
If you want another example that has more than the basics, I am in the process of writing a parser for OCaml with Alex/Happy. &amp;#x200B; It is available [here](https://github.com/Ptival/language-ocaml/tree/master/lib/Language/OCaml/Parser/Generator), and features a little more advanced features like: \- keeping track of source location \- correctly parsing nested uses of comments and quotes (using start codes) \- demonstrates using the monadic lexer with a personalized state
This is cool. `-?` seems to be (almost?) exponential object: We know, that if exponential object exists, it's unique: and we have `-&gt;`. So `-?` should be isomorphic to `-&gt;`. And in some vague sense it is, it has just a bit more structure. We differentiate constant functions. ------------------------------------------------------------------------------- -- Product ------------------------------------------------------------------------------- fstS :: (a, b) -? a fstS = Fun fst sndS :: (a, b) -? b sndS = Fun snd umpProductS :: (z -? x) -&gt; (z -? y) -&gt; z -? (x, y) umpProductS (Const x) (Const y) = Const (x, y) umpProductS (Fun zx) (Const y) = Fun $ \z -&gt; (zx z, y) umpProductS (Const x) (Fun zy) = Fun $ \z -&gt; (x, zy z) umpProductS (Fun zx) (Fun zy) = Fun $ \z -&gt; (zx z, zy z) -- check: -- is fstS . umpProduct f g = f -- -- well, not quite -- -- fstS . umpProduct (Const y) (Fun g) = -- Fun fst . Fun (\z -&gt; (y, g z)) -- Fun (fst . (\z -&gt; (y, g z)) -- Fun (\_ -&gt; y) -- -- = -- -- Const y -- -- _but_ almost! ------------------------------------------------------------------------------- -- Expontential ------------------------------------------------------------------------------- evalS :: (a -? b, a) -&gt; b evalS (ab, a) = ab $? a curryS :: ((x, y) -? z) -&gt; x -? (y -? z) curryS (Const z) = Const (Const z) curryS (Fun f) = Fun $ \x -&gt; Fun $ \y -&gt; f (x, y) prop :: ((a, b) -? c) -&gt; (a, b) -&gt; c prop g = evalS . bimap (\x -&gt; curryS g $? x) id 
Here are the semantics: `concPair` evaluates as follows: concPair Nothing b = Nothing concPair a Nothing = Nothing concPair (Just a) (Just b) = Just (a, b) And all of these are true whether or not a and b can be evaluated to WHNF. Basically, to evaluate `concPair a b` to WHNF, do the following: 1. If `a` has evaluated (NOT “if a evaluates”) to `Nothing`, return `Nothing`. 2. If `b` has evaluated to `Nothing`, return `Nothing`. 3. If `a` has evaluated to `Just a'` and `b` has evaluated to `Just b'`, return `Just (a', b')`. 4. Evaluate `a` a finite nonzero number of steps, if it isn't already in WHNF. 5. Evaluate `b` a finite nonzero number of steps, if it isn't already in WHNF. 6. Go back to the beginning. You can't get this from `par` and `pseq`, because `par a b`, `seq a b`, and `pseq a b` are no more well defined than `b`. It isn't technically legal Haskell to compile them all down to `const`, but in pure code the only result of replacing them with `const` will be excessive laziness.
Note that this will lose items if the processor crashes after it has popped an item (i.e., it is an "at-most-once" queue). Especially if getting or processing items takes some time, this could be a problem, because restarting the application counts as a crash :)
You are right, as I said in [this reply](https://www.reddit.com/r/haskell/comments/awyb9q/how_to_write_an_optimized_word_usage_counter/ehxdsrp/) I stated it incorrectly; I got confused because it handles Spanish accents correctly. **** Irrelevant fact that I could not resist to add: `char` is [not necessarily](https://stackoverflow.com/a/881968/3414720) for single bytes, if by 'byte' you mean 8 bits. Potentially it could have enough bits to represent all Unicode code points, though I doubt that happens in practice on any machine.
Yeah, the C and C++ standards don't require char to be 8 bits. But, the POSIX / UNIX specifications do.
I completely get the reasoning behind that viewpoint, but you asked how other languages pass around a DB handle or config values. So I just provided a few examples. Of them all, I prefer the actor method used by Elixir/OTP. Anyways, since I've seen a variety of approaches (good or bad) in other languages, I just wanted to make sure I understand Haskell's approach properly. 
Thanks for that write-up. This is good info that doesn't show up in a lot of Haskell material. 
Thanks so much for posting this project, it's very cool! I've been meaning to take a peek at PureScript and Halogen for a while and this pushed me over the edge. I had no trouble installing purs using my distro's package management and the language is very approachable for existing Haskell developers. Halogen, however, is proving to be difficult to get started with. I've been reading the github purescript-halogen docs but am having a confusing time getting anything in there to build and run. Looks like there have been a lot of changes recently and docs are lagging behind. Can anyone help with some pointers for a complete Halogen newbie?
 concPair (Free Nothing) y = Nothing concPair x (Free Nothing) = Nothing concPair (Pure x') y = retract $ fmap (x',) y concPait x (Pure y') = retract $ fmap (,y') x concPair (Free (Just nx)) (Free (Just ny)) = concPair nx ny You'll have to use `Free Maybe a` and `Free Maybe b` (instead of `Maybe a`, `Maybe b`) as your interrruptable expressions, but something like concPair is available. --- I think steps 4 and 5 are a bit difficult in STG. I think the "has evaluated to" test in steps 1, 2, 3 is not allowed in pure Haskell, but I *think* that it roughly corresponds to the "updateable" bit in an STG closure. But, then I'm not a STG / Core hacker.
The real issue I had was seeing how all the individual pieces fit together in Haskell, specifically maintaining and using a DB Handle (as an example). And as with other stuff in Haskell, it's actually simple. I agree DI frameworks are not a good solution. I get run-time errors all the time while developing in Spring. But the point is, Spring has it's method for propagating state and configuration values throughout the application. Whether it's good or not, it's documented. I just never came across such documentation in Haskell and wondered, do I really need to keep a DB handle around using recursion? And do I need to manually propagate application configuration via function parameters, or am I missing something? Anyways, to answer your question, the Accounts module would need DB access. It would need to take such actions as saving and updating user information. So your recommended approach makes a lot of sense for the example. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Yes, currently Haskell doesn't have a batteries, horns and kitchensink-included solution like Spring, however there are a number of documented good practices here and there. For example, have a look at the RIO documentation : https://github.com/commercialhaskell/rio#monads .
Why don't you just hire whomever is best for the job? 
&gt; I also recognise the need to have a team that have diversity Because all the tech giants had that when they were getting started and surely would have failed without it, right?
Not my experience to be honest. Especially on twitter there is quite a diverse community of Haskell developers with different backgrounds, ethnicities, different countries, genders and experience. My best advice in this regard is to actively engage in the community and you will find some great people. 
What is your definition of *best*? It seems this company's definition of *best* includes an expansion of the experiences that inform the perspectives of their team members. Your definition of *best* may not encompass all the needs of the role this company is hiring for.
It doesn't seem to suit their needs if they have trouble hiring and hiring someone because they've got a skin color that their collection is missing seems a little bit messed up. But hey, I'm not hiring right? 
You have a few fallacies in action here: * False cause: You are eluding to diversity or lack of diversity as the cause of a tech giant's success/failure. * Appeal to authority: You are using the success of these companies as a lever to try to prove your point. * Bandwagoning: You are claiming that because these tech giants are so popular everyone should do as they do.
You are assuming that diversity means skin color. Diversity is highly situational and what is diverse for one demographic may be the norm for another. Why did you so quickly jump to skin color?
Don't be obtuse, the first thing people hear when they think diversity is more women and people of color. 
I think the issue is more that the haskell community is sort of small. If you are looking for an experienced haskell dev, there probably won't be that many qualified applicants. It might be easier to find an experienced XYZ dev with some hobbyist haskell experience (or merely interest in haskell), but that isn't necessarily what you want from a startup's first technical hire. And if you only have two qualified applicants in total, there's a pretty decent chance that they will both be white dudes, no matter what language community you are talking about.
My startup may be in a similar position in the near future. Our current plan is to not stress too hard over diversity in technical hires -- we'll do the best we can, but devs with professional experience in niche languages don't grow on trees. Instead, we'll put more effort into diversity in non-technical roles. For that matter, due to the precise positions we will be looking for, we expect a certain level of diversity to almost come by default. It won't be perfect, but oh well.
I haave met both IRL and I cam confirm :).
Team diversity has generally been shown to be positive for morale and diversity of ideas, so if you don't have a niche you're hiring for then diversity hires may in fact be the best. That said I think the best way is to make sure your offer is accessible to everyone rather than try to shoehorn anyone in.
&gt; Team diversity has generally been shown to be positive for morale and diversity of ideas, so if you don't have a niche you're hiring for then diversity hires may in fact be the best. I would quite like to see this study if there is one. One could argue that companies with high racial diversity outperform internationally simply because they need people who can communicate with whatever they're managing. This would imply that they're successful because of scope and communication, not diversity. 
Do you think it's going to be productive to rehash this argument here? If you're asking in good faith then all the thoughtful responses to your question that can possibly be made are a google away.
You may want to check in with Gershom or some of the folks involved with the NYC Haskell User Group, which I know has thought critically about inclusion and diversity in organizing conferences, etc. You may also want to reach out to companies that have experience training developers to use haskell (which I don't think you should rule out). Sorry I don't have concrete suggestions right now. As an aside: I'm not sure reddit is the best place to "ask the community". I feel there's an old guard that's retreated from /r/haskell (if they were ever on), and channels are a bit fragmented. Maybe the mailing lists would be more productive.
The first time I read it, I didn't think about skin colour or gender.
Total world domination is not the only (nor even, traditionally, the most important) metric of success or reason for starting a business. There are many people (even some working in tech) who consider e.g. FaceBook to have, by most metrics, failed. And, yes, there are some interesting arguments to be made regarding diversity there.
I'm going to give you an alternate viewpoint: you want skilled developers, from diverse backgrounds and experiences, who have an interest on $LANG or can learn it and be a part of the $LANG community. Probably you need just a 1 or 2 senior devs who have a good command of $LANG, then some the rest of the devs who can learn from guidelines of those seniors. Those 2 seniors are the ones you want to pick carefully **to ensure they agree on your understanding of diversity**.
Where are you located? That can have a big impact on the difficulty of hiring diverse team members.
Just to add to the meta conversation (I have no interest in involving myself in the argument itself here), I'd say your first two aren't necessarily right 1. They're not saying diversity caused success or failure; they're saying it was immaterial. 2. Appeal to authority is more about accepting someone else's argument because they are an authority. They're not citing an argument that some large tech company has directly stated; they're just using the category of large companies as examples. 3. Bandwagoning fits though. But I'll add that you'll be hard pressed to find a good argument without fallacies unless it's in the form of a rigorous research paper. Fallacies are just natural flaws in the way we speak and don't necessarily invalidate the point being made. For internet discussions especially, it's important to be able to see through them and respond to the content, not the words. Again, I have no interest in joining the argument itself here; I just find the fallacy of fallacies to be a kinda funny one ;)
What did you think about? 
I like this perspective. At the end of the day, there's only so much diversity in the industry *as a whole*. It can't be created from thin air just from hiring; it has to be injected by new people being trained. You want things to be better in the industry? Someone has to do the *work* to make it better.
Agreed. For senior hires there's only who there is. But as Haskell has grown in usage there's a _lot_ more people available at junior or mid-level roles, and correspondingly at least somewhat of a broader pool of demographics there. Don't just blame the "pipeline" but try to be flexible about looking _beyond_ it. The other thing here is a willingness to hire people who maybe don't have Haskell experience, but do have an interest and desire and FP knowledge -- coming from maybe, Clojure, Scala, even Python.
The Haskell community is relatively small compared to some other languages, so sourcing a diverse group of applicants from a field that is already pretty lacking in diversity (based on my experiences at university and the workplace) is of course hard. There is a fine line between making sure that people being hired fit into your workplace culture, and that workplace becoming an echo chamber - hiring with diversity in mind can help prevent this, and encourage diversity of ideas. As a woman, some things like gender quotas bother me because then I would be left wondering if I was hired as a statistic instead of my ability - I understand some people like stuff like this as they feel they are not regarded as a valid applicant in their field without them, but just be aware of hiring mindlessly for diversity and the effect that can have on morale for some people. I think it's fair if you have two equally skilled applicants that you might factor in diversity as an issue when choosing which one to hire, as it can be a beneficial factor in a workplace. If you are new, you will probably need at least one senior person with a very solid Haskell background to help lead the way - that way, if you are hiring with a diversity focus in your company, you are more able to employ people from different working backgrounds (ie highly experienced in another language, with less Haskell experience but a strong interest) and your pool of potential applicants increases greatly. Being open to hiring developers with experience in fields other than Haskell but with a strong interest is probably the easiest way to find diversity in your hiring, as the Haskell pool is a bit limited, and having a senior or two with very solid Haskell skills means they can help the less experienced people. 
Diversity of skills, although I might have misinterpreted the OP.
The last time I tried it, it had absolutely terrible performance. Autocomplete and suggestions were slow as hell.
I'm fairly certain you're right about 1/2/3. This could be implemented as follows: putM :: IORef (Maybe a) -&gt; a -&gt; IO () putM r a = unsafeInterleaveIO $ a `seq` writeIORef (Just a) retrievePair :: IORef (Maybe (Maybe a)) -&gt; IORef (Maybe (Maybe b)) -&gt; IO (Maybe (a, b)) concPair :: Maybe a -&gt; Maybe b -&gt; Maybe (a, b) concPair a b = unsafePerformIO $ do ar &lt;- newIORef Nothing br &lt;- newIORef Nothing putM ar a putM br b retrievePair ar br retrievePair ar br = do a &lt;- readIORef ar if a == Just Nothing then return Nothing else do b &lt;- readIORef br if b == Just Nothing then return Nothing else if isNothing a || isNothing b then retrievePair ar br else do Just (Just av) &lt;- a Just (Just bv) &lt;- b return $ Just (av, bv)
Not sure if Purescript has better learning resources. It's basically one outdated book (updates in progress) and a bunch of tutorials. Haskell has several good books, some of them pretty up-to-date, a relatively big community, a lot of nice documentation...
Now on Hackage: http://hackage.haskell.org/package/selective
There is an experimental realtime language based on Haskell, called [Timber](http://www.timber-lang.org/). You can specify a time constraint on any function, which is enforced by the compiler. It has OO-style message passing. It seems abandoned though... hasn't been worked on in 10 years.
The OP post literally says "diversity of background, skillsets and experiences". So either it has nothing to do with ethnicity and gender stuff or OP just avoids being explicit about it. I would assume the former.
How does "best for the job" sound in any way ambiguous? It's like "fittest to perform this particular set of tasks". Of course, this is just one definition of "best". The question was, why would you need any other one?
Is there any reason there is an AutoDeriveTypeable but no AutoDeriveData? It seems like being able to automatically derive data for all datatypes would be a handy thing to have.
Or: dap :: Applicative f =&gt; Day f f ~&gt; f dap (Day g fa fb) = pure g &lt;*&gt; fa &lt;*&gt; fb nap :: Selective f =&gt; Night f f ~&gt; f nap (Night g fa fb) = pure g &lt;*? fa &lt;*? fb `Night` and `nap`—perfect. :D
If can be useful for all sorts of things, but the first two use cases that come to mind would be - Extensible records - Simplifying the story for algebraic/extensible effects
Row types are intended to provide more static guarantees at lesser cost when dealing with records. You can check out some Purescript code to see them in action. Basically, they allow expressing a type of "all records with these specific fields (and maybe some other ones)".
&gt; Extensible records Do you mean something like being able to have more than one record with the same name? &gt; Simplifying the story for algebraic/extensible effects Are there any libraries where I can see this in action?
Examples: http://hackage.haskell.org/package/vinyl http://hackage.haskell.org/package/extensible-effects
Thanks for the links. I assume that row types would dramatically improve the ease of implementation of those libraries?
In addition to using strict fields, you probably also want to unbox them either with the UNPACK pragma or the -funbox-strict-fields compiler flag. Another minor thing is that that you have -threaded set in your cabal file, which is slightly slower when you're not using threads.
Compare the following: - `vinyl` with the record types that PureScript provides via row polymorphism [in this example](https://purescript-simple-json.readthedocs.io/en/latest/quickstart.html). - `extensible-effects` with [`purescript-run`](https://github.com/natefaubion/purescript-run), with [this example]() for additional context - Haskell’s myriad exception management patterns with [checked exceptions using open products and sums](https://github.com/natefaubion/purescript-checked-exceptions)
I can show an example from real-life Haskell application at our work that could really benefit from having row types in Haskell. 1. Imagine, that you have fat `User` data type with 20 fields. You just need to store different parameters in that data type, not much you can do to decrease number of fields. So this type just represents row in your SQL database table. 2. When you insert new user, we don't require to specify all fields because some of them are calculated and derived from others, some of the fields has default values. So now you have `NewUser` data type with approximately 10 fields from `User`. 3. At the same time, when you insert new user to your database, you don't specify id of the row, the id is generated by the database. But when you query users, you want to have id. So you need to have something like `User` but without id. 4. Users have passwords and probably other private credentials. In some places you don't want to expose this information, so now you have data type which is like `User` but without password. 5. Now you want to be able to update different parts of `User`. But not all fields of `User` can be updated. So you need to have data type like `UpdateUser` which contains about 15 fields from `User` that can be updated. I hope the idea is clear :) Sometimes data types have multiple fields and you have data types that are very similar to each other but not exactly the same. Having row types allows you to remove code duplication and boilerplate regarding maintenance of multiple similar data types. 
Thanks a lot for the concrete example! That makes a lot of sense. 
Yes
Thanks a lot. That last purescript example really cleared it up for me. Seems like they're useful and powerful.
In addition to extensible records, it would also enable extensible variants. Two cases where this would have been useful to me: * Extensible/shrinkable ASTs: you can have a compiler pass that adds or removes constructors and statically guarantee that you don't call the wrong function. The alternatives to this either involve a lot of duplication or inflexibility. * Extensible errors: A special case of the above, but it get really annoying when you have many sources of errors and want to be able to combine them.
According to /u/runek's [comment](https://www.reddit.com/r/haskell/comments/ax6s6i/comment/ehu6dtk) it works best that way, and according to the comment they are replying to it makes troubles with the global installation.
Is there an issue registeted on that? is someone on the project investigating it?
&gt; For example, when working on a project, I have to open the main file in the editor, and send a ':load' command with the current file name to the script for the ghci to start loading it. Doesn't vim/neovim have an "open" hook?
You've got a "meritocracy" undertone to your messages here, and wearing my feelings on my sleeve: that's nonsense. However, we're talking about "establishing hiring pipelines for a business" so we can sort of contain that conversation and have it in private if you want. But here, you can have a cynical but true opinion? &amp;#x200B; Hiring diversity lowers costs by allowing more people to complete for the same positions. Anyone running a business that wants to keep payroll under control loves having diversity in their hiring pipeline. &amp;#x200B; Now, if you actually want to have a \*representative workforce\* that's a whole different thing. And in seeking a representative workforce, you actually undo a lot of the cynical capitalist gamification that "solving the pipeline problem" often entails for crass corporate-types hiring.
Businesses often use proxy measures for difficult-to-quantify conditions like, "team effective at communicating." Why is this different?
After 10 years on a POSIX system I just recently opted for a Windows 10 laptop, also because of the Windows Linux Subsystem (WLS). Just to find out that a. WLS doesn't play nicely with the memory management of GHC and b. there is a blocking issue in the WLS that prevents to build a NixOS distro for it :-(( (Haskell and NixOS are two enthusiastic but *side* interest, so I didn't research *these* aspects enough [=at all] beforehand.
From my personal experience writing Purescript, they allow for much more ergonomic records while still being well-typed. Here's a small example in Purescript: import Prelude add3ToNum :: forall r. { num :: Int | r } -&gt; Int add3ToNum rec = rec.num + 3 This function takes as input *any* record that has a field labeled "num" with the type `Int`. You can get a lot of mileage out of this sort of abstraction over record fields. I personally use them as a substitute for the "HasX" style typeclasses you often see in production Haskell code (usually used for the environment type in a `ReaderT`-based transformer stack). Here's a function from my codebase that does this (with `type App e r m a = ExceptT e (ReaderT r m) a`): saveLoad :: forall e r m. MonadAff m =&gt; Array ImageSource -&gt; App e { format :: Format, scanPath :: FilePath | r } m Unit saveToLoad imgs = do env &lt;- ask dir &lt;- getScanDir -- This implicitly uses the "scanPath" label in the environment of the `App` monad let mkPath n = dir.path &lt;&gt; "/" &lt;&gt; "doc-" &lt;&gt; show n &lt;&gt; "." &lt;&gt; show env.format save = uncurry $ Image.saveToFile env.format idxs = 0 .. length imgs traverse_ save &lt;&lt;&lt; zip imgs $ map mkPath idxs
Is there an efficient way to parallelize a function with the following structure ? combinatorialgrowth :: a -&gt; [a] f :: [a] -&gt; [(a,a,a)] f ls = do base &lt;- ls firstpass &lt;- combinatorialgrowth base secondpass &lt;- combinatorialgrowth secondpass return (base,firstpass,secondpass) &amp;#x200B;
Is this what `-fobject-code` is for? I've never used it but that's what comes to mind to me. 
Whenever you have a function accepting more than 5 arguments, you could just convert it into a type like \`{param1: type1, param2: type2}\`, I do that in Elm and I love it. The idea to create a new type \`data MyFunctionParams\` just for that seems somewhat alien.
You can write a pretty nice FizzBuzz with the `ZipList` and `Ap` Applicative/Monoid newtypes. You can also entirely avoid divisibility testing. If you're interested in that you should have a go at it first, but you can see my version here: https://gist.github.com/LSLeary/7df9c04829ba3aa69d7099ce2e00eb7d I wouldn't focus too hard on point-free. If you want to use and understand partial application, you can define all your functions with single-variable lambas: `foo = \x -&gt; \y -&gt; \z -&gt; ...` and insert the redundant left-associative brackets in your applications: `((foo x) y) z`.
Whilst cool, I hope nobody is using ifF in production code - that is crazily convoluted for something that can be achieved using one of a number of good language features that are far easier to comprehend 
I know, I know, point free isn't everything =) mostly using this as a practice exercise. I'll check this out tomorrow, think about no divisibility testing before I look. Thanks!
yeah would not want to see ifF in code running something important hehe
Are you opened for remote work? I am based on Barcelona, Spain. Best 
In terms of gender, I consider myself as a semigroup, years ago I was an object. I'm of some color or another depending on the season. I have been living in some countries. I support convincingly whatever cause that my boss may support. Please consider hiring me.
[this package](http://hackage.haskell.org/package/haskus-utils-variant) provides extensible variants; \[i have not used it\]
Thank you! So this command did exactly what I needed it to do: stack repl --ghc-options -fobject-code -- my-pkg Now that I know what the answer is, I discovered that the GHCI user guide does mention this flag [at the very end of section 7.3.]( https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#loading-compiled-code ). It'd be nice if the Man Page mentioned this, maybe I should open an issue on GHC Trak.
You should be able to implement `ifF` in a simpler way. Something like: IfF p thenf els = bool els &lt;$&gt; thenf &lt;*&gt; p
Exactly, completely agree with /u/sclv . Also, as Haskell has grown in recent years, I think most of what you'd call the "community" shifted focus from abstractions/basic libraries/GHC stuff to applications, "how to do X in Haskell". Domain expertise (front-end, cryptography, real-time systems, databases, you name it) is what you should be looking for, along with possibly an inclination towards FP, rather than Haskell expertise per se. Haskell expertise can be built if there are one or two already experts in the company.
(BTW hi to the usual band of trolls who instantly downvote any topic that has the word "diversity" in it.)
Ahhh right, now I understand. Thank you! That would be a great feature to add though! Another small question: Is there a release for windows? (I am doing a poc for a job here, which would probably require running on windows machines/pipelines)
Of course, glad it's getting used! I haven't looked into windows releases since I don't currently have a windows machine. There is the ability to run this from docker though, so depending on your machines at work that's a potential solution
Of course, glad it's getting used! I haven't looked into windows releases since I don't currently have a windows machine. There is the ability to run this from docker though, so depending on your machines at work that's a potential solution
As others have said, it is not idiomatic Haskell for a few reasons: * You should write `attacks` as a function, not as a member of a typeclass * Your `Show` instances are invalid, they are supposed to print Haskell code. You could use a `showBoard` and `showPiece` function instead [here is a solution that I think looks more Haskelly](https://gist.github.com/bartavelle/5c29ae218c652a51e0a63a6a4dfa8e91) But this is all secondary. My solution, while looking better (in my eyes), is probably just as slow as yours (and might even be buggy, I did not test it). For this kind of algorithms, it will be hard to be as fast as Scala, Java, and even Python, unless you write Haskell code that looks a lot like what those languages are doing, or you write more efficient algorithms.
Is that how it's supposed to be: `secondpass &lt;- combinatorialgrowth secondpass`? In any case you're doing a lot of mapping here, which should be very easy to do in parallel. You can use the [parallel](http://hackage.haskell.org/package/parallel-3.1.0.1/docs/Control-Parallel-Strategies.html) library although I haven't used it myself.
&gt; At the same time, when you insert new user to your database, you don't specify id of the row, the id is generated by the database. But when you query users, you want to have id. So you need to have something like User but without id. This problem can be solved by having data types that can accurately model a saved/unsaved user, and doing that doesn't require row polymorphism. For example, the way that the Persistent library does it is to define a type that is something like: newtype Entity a = Entity Key a So now, if you have an `Entity User`, you know the user is saved in the database and can read the `Key` value to get the id. If you just have a `User`, you know that the user is not yet saved in the database.
Yes, this particular problem can be solved separately. In our case we use `newtype` with phantom type parameter for increased type-safety. newtype Id a = Id { unId :: UUID } data WithId a = WithId (Id a) a But this is just a single use case. Row types allow to handle such cases generically.
I'm excited about them as they allow a similar coding style to "duck typing" in Python, where you could have Person and Employee be two unconnected types that both have "name" fields, and you get to write a function that accepts either of them and pretty prints the name, but it's statically typed and you don't lose the type of the Person/Employee value.
As someone who uses persistent in production, I can say that the `Entity` thing is probably my least favorite part of persistent, and I also do not like how DB defaults basically can't be used. So while it's useful to point out this approach I will say that it really doesn't take away from how damn useful (and IMO crucial) row types would be. It is my number one pain point in Haskell development.
Yep! Just like currying allows us to easily have multiple arguments, this allows us to easily have keyword arguments (and btw this is exactly the calling style we chose in Lamdu). When C was developed in the early 70s, they went for positional arguments, and it made sense over keyword arguments because it requires less typing. When Smalltalk came in 1980 with an IDE and completions - they went with keyword arguments.
It was brought up about a year ago, https://github.com/haskell/haskell-ide-engine/issues/412#issuecomment-385033847
`dap` on them haters.. *wags finger* na-na-nah `nap` on them haters *nods*
OCaml has extensible variants, but calls them "polymorphic variants" (from subtype polymorphism, I think). [Here's a good article comparing a few different approaches to error handling in OCaml, including polyvariants](http://keleshev.com/composable-error-handling-in-ocaml)
May I ask a question? For me, `Night` does not seems to be a monoid. It doesn't seem to have an associator or unitor. Though I might be overlooking some clever way to make it monoid. -- This direction is possible without losing "Const-ness" on every bits nAssoc1 :: Night f (Night g h) x -&gt; Night (Night f g) h x nAssoc1 (Night alpha fa (Night beta gb hc)) = Night gamma (Night delta fa gb) hc where -- alpha :: a -? tmp -? x -- beta :: b -? c -? tmp -- gamma :: (c -? x) -? c -? x -- delta :: a -? b -? c -? x gamma = id delta = case (alpha, beta) of (Const tmp_x, Const c_tmp) -&gt; Const $ Const $ tmp_x . c_tmp (Const tmp_x, Fun beta') -&gt; Const $ Fun $ \b -&gt; tmp_x . beta' b (Fun alpha', Const c_tmp) -&gt; Fun $ \a -&gt; Const $ alpha' a . c_tmp (Fun alpha', Fun beta') -&gt; Fun $ \a -&gt; Fun $ \b -&gt; alpha' a . beta' b -- This direction does not seem to be possible without losing -- some of Const-ness from (-?) nAssoc2 :: Night (Night f g) h x -&gt; Night f (Night g h) x nAssoc2 (Night eps (Night zeta fa gb) hc) = Night eta fa (Night theta gb hc) where -- eps :: tmp -? c -? x -- zeta :: a -? b -? tmp -- eta :: a -? (a -? x) -? x -- theta :: b -? c -? a -? x eta = Fun $ \a -&gt; Fun ($? a) -- requires fa always theta = case (eps, zeta) of (Const c_x, _) -&gt; Const $ Const &lt;$&gt; c_x (Fun eps', Const (Const tmp)) -&gt; Const $ Const &lt;$&gt; eps' tmp (Fun eps', Const (Fun b_tmp)) -&gt; Fun $ \b -&gt; Const &lt;$&gt; eps' (b_tmp b) (Fun eps', Fun zeta') -&gt; Fun $ \b -&gt; Fun $ \c -&gt; Fun $ \a -&gt; eps' (zeta' a $? b) $? c -- This also requires gb and hc always -- And is there an unit I which makes this isomorphism? leftUnitor :: Night I f x -&gt; f x
I was waiting for you to show that it isn't :) thanks
Yes, `Night`'s lack of an associator is similar to that of the product `(:|:)` discussed later. I think we need to look at symmetric `biselect`-like methods (defined in section 6.2 of the paper) if we're looking for a monoid. 
&gt; try to port the assembly back into Haskell Would it not be easier and possibly saner than sieving through assembly code to write your numerical functions in C and use Haskell's FFI to call your numerical functions? &gt; then apply another 2.5x slowdown It's not correct to make this judgement from a microbenchmark as said benchmark is rarely representative of a complete program. 
Few more musings with -? -- | We can refine ordinary functions -- if @a@ is 'Finite' and @b@ is 'Eq' -- -- 'Finite' comes from @universe@ package. -- -- &gt;&gt;&gt; isConst $ liftQ not -- Nothing -- -- &gt;&gt;&gt;&gt; isConst $ liftQ (|| True) -- Just True -- liftQ :: (Finite a, Eq b) =&gt; (a -&gt; b) -&gt; a -? b liftQ f = case universeF of (x:xs) | all (\y -&gt; f x == f y) xs -&gt; Const (f x) _ -&gt; Fun f isConst :: a -? b -&gt; Maybe b isConst (Const b) = Just b isConst _ = Nothing -- | We can also write '&gt;&gt;=' bind like function (&gt;&gt;=?) :: Monad f =&gt; f a -&gt; (a -? f b) -&gt; f b m &gt;&gt;=? Const b = b -- `m` effects are dropped! m &gt;&gt;=? Fun k = m &gt;&gt;= k -- '&gt;&gt;=?' is not 'bindS'. And if you are into cubical Agda, then it's tempting to write HIT: {-# OPTIONS --cubical #-} module Selective where open import Cubical.Core.Everything open import Cubical.Foundations.HLevels const : ∀ {A B : Set} → A → B → A const x _ = x data _-?_ (A B : Set) : Set where Fun : (f : A → B) → A -? B Const : (b : B) → A -? B -- Const b and Fun f are equal when f is const b! magic : ∀ b f → const b ≡ f → Const b ≡ Fun f -- conversion to and from ordinary function to-? : ∀ {A B} → (A → B) → A -? B to-? f = Fun f from-? : ∀ {A B}→ (A -? B) → A → B from-? (Fun f) = f from-? (Const b) = const b from-? (magic b f pf i) = pf i -- if we start with function, we get back a function from-to : ∀ {A B} → (f : A → B) → f ≡ from-? (to-? f) from-to f = refl -- other composition is tricky. -- I have no idea how to fill the obligation, -- neither I have any intuition whether it can or cannot be filled. -- to-from : ∀ {A B} → (f : A -? B) → f ≡ to-? (from-? f) to-from (Fun f) j = Fun f to-from (Const b) j = magic b (const b) refl j to-from (magic b f pf i) j = {!!} 
Thank you, I'll look `biselect` more. Some questions regarding it. The paper introduces `biselect` in "another formulation" subsection which (probably) means using `biselect` instead of `select` neither add nor remove any power from `Selective` class. But I doubt it. I see `select` can be implemented through `biselect` (easy), and `biselect` can be implemented through `select` (paper has the code.) But: * Are these conversions actually an "inverse"? * Are `select` law and `biselect` law equivalent? One can be proven from another (assuming default implementation)?
I *think* that with Agda construction (https://www.reddit.com/r/haskell/comments/axje88/selective_applicative_functors/ehzl2j6/), where `Fun (const b)` and `Const b` are considered equal; you can show that "Const-ness" isn't missed.
&gt; main = putStrLn =&lt;&lt; unlines . fizzbuzz . enumFromTo 1 . read &lt;$&gt; getLine You could write this as main = putStrLn . unlines . fizzbuzz . enumFromTo 1 . read =&lt;&lt; getLine Which I think is nicer.
Let's assume we are not talking about skin color. Then I can't see how to justify OP's point that it's "difficult to find diversity amongst the Haskell community". Where's the evidence for that? Can't people from the same ethnic group or gender have different ideas?
Solved: I was able to get some help on FP Slack #purescript-beginners and found out that my AUR-installed purs 0.12.3 was causing problems, maybe with the dependency installation with bower, not exactly sure but I had the non-npm purs early in my PATH. In any case, removing that and trying the Halogen v4.0.0 examples works now.
It says "Updated: November 16, 2014" and yet it mentions tooling that didn't yet exist in 2014. Is OP a time traveller? 
aren't all haskeller 
So you are looking for some state subsidies mmm?
It has both polymorphic and extensible variants.
It is "another formulation", but they are indeed not equivalent: `biselect` is more general, since you can get `select` from it, but the other direction is lossy -- it "breaks the symmetry" as we say. As for laws of `biselect`, I'd like to write a blog post/an appendix on this topic, since the laws are a bit trickier, and require some further thinking/experiments. A side note on `select` vs `biselect`: the extra generality of `biselect` comes at the cost of complexity. One could imagine rewriting the paper with `biselect` playing the main role, but we decided against it, because it might obscure the main idea: selective functors -- whichever particular formulation you choose -- allow you to statically analyse effectful computations with branching. Introducing this idea with a simpler combinator like `select`, and then mentioning various other formulations at the very end, seems like a better approach if we want as many people as possible to understand what selective functors are.
Cool! I was looking for something like this but my hoogle skills aren't quite there yet, thanks
Here's an alternative for the definition of a composition of two functions where the second is binary: `(.:) = (.) . (.)`
Still I couldn't put my thought together, but I feel it wouldn't be possible to fully express "constness" in `-?`. This is a rough thought on it. Let me denote const function by `-&gt;[0]` and non-const function by `-&gt;[*]`. One can be thought `-&gt;` as duplicity-forgot function and `-?` as duplicity-tagged function. data a -&gt; b = forall p. Arr (a -&gt;[p] b) data a -? b = Const (a -&gt;[0] b) | Fun (a -&gt;[*] b) Then let's see "constness" of some functions. id = \f x -&gt; f x :: forall p. (a -&gt;[p] b) -&gt;[*] (a -&gt;[p] b) flip = \f x y -&gt; f y x :: forall p q. (a -&gt;[p] b -&gt;[q] c) -&gt;[*] (b -&gt;[q] a -&gt;[p] c) flip id = \x f -&gt; f x :: forall p. a -&gt;[p] (a -&gt;[p] b) -&gt;[*] b If you try to represent these facts with `-?`: id' :: (a -? b) -? (a -? b) flip' :: (a -? b -? c) -? (b -? a -? c) flipid' :: a -? (a -? b) -? b `id' = Fun (\x -&gt; x)` "works" in the sense you get identically tagged function back, similarly to "constness-typed" program returns identically typed function back. OTOH I don't think one can implement `flip'` and `flipid'` in an expected way, though I can't clearly state the why yet. Then, I imagine the fact `flip'` is not well expressed in `-?` is the core of the problem `Night` can't be a monoid. It is totally not sure though.
RIO looks like a much needed effort as so much Haskell documentation/libraries/etc are scattered about. &amp;#x200B; &amp;#x200B;
AKA the [blackbird](http://hackage.haskell.org/package/data-aviary-0.4.0/docs/Data-Aviary-Birds.html) (Name probably taken from [*To Mock a Mockingbird*](https://en.wikipedia.org/wiki/To_Mock_a_Mockingbird).)
**To Mock a Mockingbird** To Mock a Mockingbird and Other Logic Puzzles: Including an Amazing Adventure in Combinatory Logic (1985, ISBN 0-19-280142-2) is a book by the mathematician and logician Raymond Smullyan. It contains many nontrivial recreational puzzles of the sort for which Smullyan is well known. It is also a gentle and humorous introduction to combinatory logic and the associated metamathematics, built on an elaborate ornithological metaphor. Combinatory logic, functionally equivalent to the lambda calculus, is a branch of symbolic logic having the expressive power of set theory, and with deep connections to questions of computability and provability. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
How about `Noon`? data Noon f g a where Noon :: f (Either x y) -&gt; g (Either x z) -&gt; (Either x (y, z) -&gt; a) -&gt; Noon f g a Warning: I've only proven a couple of identity laws, not associativity, but it might work.
Since the input number is being used multiple times (to check if it's divisible by 3, to check if it's divisible by 5, and as the default output), I don't think the point-free style is a very good match for this problem, as you will have to duplicate the variable and plumb it around. The point-free style is much more useful and readable when you have a pipeline of transformations, where the initial input is only used by the first transformation, the output of the first transformation is only used by the second transformation, etc. Nevertheless, if for some reason I was forced to use the point-free style to solve FizzBuzz, here's how I would do it. First, I would define a few plumbing functions. dup :: a -&gt; (a, a) dup = (,) &lt;$&gt; id &lt;*&gt; id assocR :: ((a, b), c) -&gt; (a, (b, c)) assocR = (,) &lt;$&gt; (fst . fst) &lt;*&gt; ( (,) &lt;$&gt; (snd . fst) &lt;*&gt; snd ) These are technically written in point-free style, since I am working in the `(a -&gt;)` Applicative and thus never name the variable, but as you can see, I'm simply using `id` to refer to the variable (or `fst . fst`, `snd . fst` and `snd` to refer to each of the three input variables). Next, let's think about what we want to accomplish. We want to check a bunch of conditions, combining the corresponding strings if the conditions pass, and we want to produce a completely different output if any of the condition fails. That reminds me of the [`Validation`](http://hackage.haskell.org/package/validation-1/docs/Data-Validation.html) Applicative, which combines errors and only produces a success if all of the checks pass. import Data.Validation -- | -- &gt;&gt;&gt; map (fizz1 "fizz" 3) [1..6] -- [Success 1,Success 2,Failure "fizz",Success 4,Success 5,Failure "fizz"] fizz1 :: String -&gt; Int -&gt; Int -&gt; Validation String Int fizz1 s n = validate s ((/= 0) . (`mod` n)) All right, we are now well-equipped to check a single condition. But if `fizz1` returns a Failure, we lose our number, thereby preventing us from checking the other conditions! I want a version of `fizz1` which preserves its input. I can write this generically for any Applicative: import Control.Arrow import Data.Tuple sideEffect :: Applicative f =&gt; (a -&gt; f c) -&gt; (a, f b) -&gt; (a, f c) sideEffect f = first dup &gt;&gt;&gt; assocR &gt;&gt;&gt; second ( swap &gt;&gt;&gt; second f &gt;&gt;&gt; uncurry (*&gt;) ) I use `(&gt;&gt;&gt;)` instead of `(.)` because when my function compositions are split onto multiple lines, I prefer when the data flows from top to bottom. It's just a personal preference. All right, we're finally ready to write `fizzbuzz`: -- | -- &gt;&gt;&gt; map fizzbuzz [1..15] -- ["1","2","fizz","4","buzz","fizz","7","8","fizz","buzz","11","fizz","13","14","fizzbuzz"] fizzbuzz :: Int -&gt; String fizzbuzz = (, pure ()) &gt;&gt;&gt; sideEffect (fizz1 "fizz" 3) &gt;&gt;&gt; sideEffect (fizz1 "buzz" 5) &gt;&gt;&gt; snd &gt;&gt;&gt; validation id show Since `Validation` already returns its input `Int` in case of `Success`, returning the number when none of the conditions match was quite easy. If it was returning `Success ()`, it would only be slightly more difficult: -- | -- &gt;&gt;&gt; map fizzbuzz' [1..15] -- ["1","2","fizz","4","buzz","fizz","7","8","fizz","buzz","11","fizz","13","14","fizzbuzz"] fizzbuzz' :: Int -&gt; String fizzbuzz' = (, pure ()) &gt;&gt;&gt; sideEffect (fizz1 "fizz" 3) &gt;&gt;&gt; sideEffect (fizz1 "buzz" 5) &gt;&gt;&gt; swap &gt;&gt;&gt; second pure &gt;&gt;&gt; uncurry (*&gt;) &gt;&gt;&gt; validation id show 
Really thanks for answering this detailed question!
True, it does have something called "extensible variants" too, but it's not row polymorphic. There is no row variable. It's more of an open-ended nominal type. And it's not used very much I think.
I think parallel should be sufficient for this case -- data dependencies are tree-like not graph-like. But, if you need more control you can move to [monad-par](http://hackage.haskell.org/package/monad-par) or [lvish](http://hackage.haskell.org/package/lvish)
"New in Haskell Prime" :-P
Shit, I'm mexican. Hire me lol
Wow thanks for this, had no idea arrows existed til now. &gt; me reading https://en.wikibooks.org/wiki/Haskell/Understanding_arrows &gt; Arrows, like monads, express computations that happen within a context. However, they are a more general abstraction than monads 😅 This looks really interesting, it's gonna take me some time to figure out what's going on here :) Damn Validation is exactly the kind of thing I was looking for, that seems incredibly useful. I was thinking of trying to use Either but that seemed like a bad fit, and I ended up just using what I already knew to put the pieces together. Seriously, thank you, this seems like you put some thought into this, and this example will be really helpful to a noob like me 🙏
autocmd events: * BufNewFile ("open"ing a non-existing file) * BufRead / BufReadPost ("open"ing an existing file)
Yeah, I was reading about this earlier but thought it was unary to ternary for some reason How this stuff works still hasn't 100% sunk in yet for me, I keep trying to work through the type signatures on paper and getting confused heh
Oh, I imported `Control.Arrow`, but I am not using the `Arrow` typeclass, I am only importing it to get the following helpful functions: (&gt;&gt;&gt;) :: (a -&gt; b) -&gt; (b -&gt; c) -&gt; (a -&gt; c) (&gt;&gt;&gt;) = flip (.) first :: (a -&gt; b) -&gt; (a, x) -&gt; (b, x) first f (a, x) = (f a, x) second :: (a -&gt; b) -&gt; (x, a) -&gt; (x, b) second f (x, a) = (x, f a)
Yeah, most of the benefits were already mentioned. Better database APIs (stuff like joins can be typed a lot easier), deriviations of record types, open variants for exception or algebraic effects and more. I hope I can present a working version implemented in GHC at ZuriHac
True. Which approach would you suggest to get it right, then?
ooooh, okay. (&gt;&gt;&gt;) and Data.Function (&amp;) are the same right? I would expect first, second to be in something like Data.Tuple but I'm probably just misunderstanding how module organization works /shrug
Sorry, I'm actually going to retract this; it was a mistake to post on this sort of topic.
I would suggest, as others have, to open up your pool of candidates by being willing to teach new hires. If they're a senior developer in another languages you can ramp them up into Haskell fast enough that it will probably not make a dent on your team's velocity. And if you have a strong style guide, testing culture, and plenty of test/CI/CD tooling in place Haskell provides a rather level playing field for individual contributors of varying skill levels. &amp;#x200B; I think it might've been Bryan O'Sullivan, if I'm not mistaken, who gave a talk about how they run their teams at Capital Match on some podcast or other... I can't quite remember... but he was saying that they get quants to write Haskell code along side the expert Haskell programmers. It's the safety net of the operational tooling that enables them to be cavalier like that. I've experienced similar results on-boarding junior developers with no Haskell background. It's great knowing you can sleep at night and know it's highly unlikely that the build is going to be broken in the morning.
So what would this `User` type look like, if Haskell had row types?
It would be nice if the upcoming row polymorphism extension allowed something like this (although the "wrapping behaviour" it is largely orthogonal to row types).
This pattern (which /u/isovector) branded 'Higher-kinded data', has been used in my database library, [beam](http://tathougies.github.io/beam/user-guide/models/#the-identity-trick) for a few years now. Works great. Let's you represent all kinds of wonderfulness.
&gt; (&gt;&gt;&gt;) and Data.Function (&amp;) are the same right? `(&gt;&gt;&gt;) = flip (.)`, `(&amp;) = flip ($)`, so no. One is application, the other is composition.
Just because two things have the same type does not mean they implement the same function. The key thing to notice here is that \`const\` \_throws away information\_.
Mmm, that is true. I’ve never used comonads myself but they seem to have the same effect extend (+5) (Identity 10) flip (&gt;&gt;=) (&lt;$) (+10) (Identity 10) Apologies for such a contrived example but it’s all I could think to come up with right now 
&gt; could someone please break it down for me? Let's see, `flip (&gt;&gt;=)` (which already has a name, `(=&lt;&lt;)`) has type `Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b`, and so applying it to `(&lt;$) :: Functor f =&gt; u -&gt; f v -&gt; f u` means we need to unify `u -&gt; (f v -&gt; f u)` with `a -&gt; m b`, and thus: u ~ a m ~ (f v -&gt;) b ~ f u The `(f v -&gt;)` Monad is the same as `Reader (f v)`, except it can be quite confusing if you were not planning to use it as a Monad, but did so accidentally by using a function with the wrong number of arguments, as I suspect you did here. So in order to make things clearer, let's use `Reader (f v)` instead of `(f v -&gt;)`: (&lt;$) :: Functor f =&gt; u -&gt; Reader (f v) (f u) flip (&gt;&gt;=) (&lt;$) :: Functor f =&gt; Reader (f v) u -&gt; Reader (f v) (f u) That is, if you can produce an `u` while having access to an `f v`, you can also produce an `f u` while having access to that same `f v`, namely, by replacing every `v` in `f v` with that `u`. &gt; And indeed it seems to function the same as `extend`. On which types did you test that the two functions behave the same? `extend` is more complex than just replacing every `u` in `w v` with a particular `u`, maybe you only tested it with very simple comonads such as `Identity`?
&gt;maybe you only tested it with very simple comonads such as _Identity_? Ding ding ding! Thank you. That was informative. It’s got me interested, I knew of them but never used them. Thank you for the explanation (:
I think this may also be a big signal as to which companies are actually *invested* in diversity versus just paying lip service. I get the sense that it's slowly getting better among companies that have a mature outlook (and are *not* just signaling for the look of it). I know that my company at least *really tries* to hire based on suitability. Of course there *are* biases that will sneak in, but overall I think we're doing reasonably.
No way! Interesting, I’d never looked at beam! I wonder whether your Columnar wrapper could be re-used and shared with a form library? It seems like Index or Columnar could be in a general package. Thanks for the link by /u/isovector - it confirms my hunch that the “Person Validate -&gt; Validate Person” transformation can be derived by Generic. 🙌🏻
Yeah, specifically row types let us easily project and extend and join. Super nice! I used them for a compiled query language for client.
&gt; “Person Validate -&gt; Validate Person” This looks like [`sequence_NP`](http://hackage.haskell.org/package/sop-core-0.4.0.0/docs/Data-SOP-NP.html#v:sequence_NP) from [generics-sop](http://hackage.haskell.org/package/generics-sop).
As far as I know by my own experience, in many companies diversity is encouraged... As son as the "diverse" candidates look cool and behave like clones.
This is only valid for functors with at most one 'a' in them. e.g. Maybe, Identity. Otherwise you'll fail the comonad laws with this implementation.
This is one of the parts of beam that I found very compelling. Great work!
 data Pair a = Pair a a is isomorphic to `Bool -&gt; a` and can borrow the instance of Comonad from the latter. Assuming you pick a monoid on Bool that you like, e.g. ((&amp;&amp;), True), ((||),False), etc. When you go to use your extend implementation on this type it will fail to line up and to pass the comonad laws. 
Ah, gotcha... the &gt;&gt;&gt; style of composition reminds me a bit of how clojure's threading macro makes things read more sequentially, i.e. you have a value, then f happens to it, then g, etc.
Of course. it is done all the time. The essence of OOrientation is not inheritance, but the messaging/interfaces and the encapsulation of state: The state machine. In this sense, Erlang is a Object language. The actor model is pure OO. It is used in the MVC pattern all the time to create Haskell web frameworks server side and client side. React clones in haskell are pure state machines and the blessed FRP model of haskell is in essence the same. OO is deeply embedded in the mind of every programmer nowadays, even the ones who consider themselves as functional programmers. At the top level, almost every program in haskell was conceived with an OO mindset. Despite that the methods of are codified functionally, they are methods of objects. What happens is that these objects are masked as type classes, modules etc.
`fst (x, y) = x` and `snd (x, y) = y` are in Prelude, and maybe Data.Tuple. `first` and `second` from `Control.Arrow` are specific instances of `first` and `second` from `Data.Bifunctor`. (The cartesian product (`(,)`) is a simple bifunctor.)
It's not quite the same, but I wonder if something like the [Functor Functors](https://www.benjamin.pizza/posts/2017-12-15-functor-functors.html) might be useful / interesting to you. That kind of thing is threaded through [dependent-map](http://hackage.haskell.org/package/dependent-map), and there is a bunch of related work that has come out of Obsidian's use of those things, like `constraints-extras` and `vessel` (which is very new, but it looks pretty exciting to me). I'm currently working on a talk about these things, and will be hacking on some formlets code using these things as one of the examples.
Well this thread brought out a lot of usernames I don't recognise. Honestly, I'd say Haskell has one of the more diverse communities around. For example, I'd say... maybe a third to a quarter of trans women I know are Haskellers? 
I've lost count of how many times I'v tried to install HIE and get it into a working state...I've pretty much given up on it at this point
Interesting, this forced me to actually figure out functions' functor/applicative instances. I'm not sure I understand it well enough to actually use it myself, but it was fun to work through.
With small modification one can get almost there, but there are few cases with no luck, they are symmetric though! {-# LANGUAGE RankNTypes, GADTs, TypeOperators #-} {-# OPTIONS_GHC -Wall #-} import Data.Bifunctor import Data.Functor.Identity data Noon f g a where Noon :: f (Either u y) -&gt; g (Either v z) -&gt; (Either (Either u v) (y, z) -&gt; a) -&gt; Noon f g a type f ~&gt; g = forall x. f x -&gt; g x ------------------------------------------------------------------------------- -- Id ------------------------------------------------------------------------------- -- i'm not sure these are inverses idl :: Functor g =&gt; Noon Identity g ~&gt; g idl (Noon (Identity f) g p) = fmap (mk p f) g where mk :: (Either (Either u v) (y, z) -&gt; x) -&gt; Either u y -&gt; Either v z -&gt; x mk pp (Left u) _ = pp (Left (Left u)) mk pp (Right _) (Left v) = pp (Left (Right v)) mk pp (Right y) (Right z) = pp (Right (y, z)) reidl :: Functor g =&gt; g ~&gt; Noon Identity g reidl g = Noon (Identity (Right ())) (fmap Right g) $ \e -&gt; case e of Left (Left x) -&gt; x Left (Right x) -&gt; x Right ((), x) -&gt; x ------------------------------------------------------------------------------- -- Assoc ------------------------------------------------------------------------------- unassoc :: (Functor g, Functor h) =&gt; Noon (Noon f g) h ~&gt; Noon f (Noon g h) unassoc (Noon (Noon f g p) h q) = Noon f (Noon g h id) (mk p q) where mk :: (Either (Either u1 v1) (y1, z1) -&gt; Either u y) -&gt; (Either (Either u v) (y, z) -&gt; x) -&gt; Either (Either u1 (Either v1 v)) (y1, (z1, z)) -&gt; x mk pp qq (Right (y1, (z1, z))) = case pp (Right (y1, z1)) of Right y -&gt; qq (Right (y, z)) Left u -&gt; qq (Left (Left u)) mk pp qq (Left (Left u1)) = case pp (Left (Left u1)) of Right y -&gt; undefined -- :( Left u -&gt; qq (Left (Left u)) mk pp qq (Left (Right (Left v1))) = case pp (Left (Right v1)) of Right y -&gt; undefined -- :( Left u -&gt; qq (Left (Left u)) mk _pp qq (Left (Right (Right v))) = qq (Left (Right v)) assoc :: Noon f (Noon g h) ~&gt; Noon (Noon f g) h assoc (Noon f (Noon g h p) q) = Noon (Noon f g id) h (mk p q) where mk :: (Either (Either u1 v1) (y1, z1) -&gt; Either v z) -&gt; (Either (Either u v) (y, z) -&gt; x) -&gt; Either (Either (Either u u1) v1) ((y, y1), z1) -&gt; x mk pp qq (Right ((y, y1), z1)) = case pp (Right (y1, z1)) of Left v -&gt; qq (Left (Right v)) Right z -&gt; qq (Right (y, z)) mk pp qq (Left (Right v1)) = case pp (Left (Right v1)) of Left v -&gt; qq (Left (Right v)) Right z -&gt; undefined -- :( mk pp qq (Left (Left (Right u1))) = case pp (Left (Left u1)) of Left v -&gt; qq (Left (Right v)) Right z -&gt; undefined -- :( mk pp qq (Left (Left (Left u))) = qq (Left (Left u)) 
um... reader monad? Wow I still have a lot to learn, pretty sure everything I've learned so far is on the page there haha
What are you referring to as "upcoming"? It sounds like I might have missed an exciting development! Thanks.
Yep, I got stuck too, in a similar way :( I think the reason is that `Noon` packs the information into `a` too tightly. For example, in the expression (x ?*? y) ?*? z we lose the information about whether we had any `Left`s in `x ?*? y`, which prevents us from re-associating cases like `(Left _ ?*? y) ?*? z` into `Left _ ?*? (y ?*? z)`. Intuitively, we need to forbid the cases which are currently `undefined` in your implementation.
I have not used this package, but the standard escape for word boundaries are \\&lt; and \\&gt; for beginning of word and end of word respectively. A quick test seems to confirm it works: Prelude&gt; :module +Text.Regex Prelude Text.Regex&gt; let r = mkRegex "\\&lt;dog\\&gt;" Prelude Text.Regex&gt; subRegex r "mydog dog" "(\\0)" "mydog (dog)" 
Hint: `(f .) . g` means ``(f `compose`) `compose` g``, which can also be written as `compose (compose f) g`.
Just getting to this series now. It's awesome. In [part 2](https://blog.sumtypeofway.com/recursion-schemes-part-2/) I'm confused by the laws. The first is stated as an equation: `cata In = id`. That's clear. But the second is stated as an implication: ``` -- given alg :: f a -&gt; a -- and func :: f a -&gt; f cata (alg &gt;&gt;&gt; fmap func) =&gt; (cata alg) &gt;&gt;&gt; func ``` Is that `=&gt;` symbol supposed to be `=`? And the third is even stranger: ``` -- given alg :: f a -&gt; a -- and func :: f a -&gt; g a cata (f &gt;&gt;&gt; In) &gt;&gt;&gt; cata g ==&gt; cata (f &gt;&gt;&gt; g) ``` Is that `==&gt;` symbol again supposed to be `=`? And why does it stipulate types for `alg` and `func`, without ever using them?
It has, and that is exactly my point. I have ditched that auto magic behavior in favor of a manual/explicit action. What I gain by this is that I can explicitly choose which file to "reload" when *any* file in the project is changed. Also, If I send a load command every time a haskell file is opened, then it is a full reload at ghc, every time I open a file. Which I don't want. Also consider the case where I switch to buffer 'b' after opening a .hs file in buffer 'a'. Changes I make in 'b' might be be causing a compiler error, but I won't catch it because the script keeps reloading the file in buffer 'a' (Assuming 'a' does not have a dependency on file in buffer 'b').. Basically, the manual action gives me a lot more control on what is going on. And makes it a lot more easier to troubleshoot when something goes wrong. 
In my latest personal project I'm experimenting with your second proposal. I use an `Entity` data type: ```haskell data Entity ms a = Entity { id :: Id , val :: a , metas :: ms } ``` I personally appreciate to be able to make a distinction between a `NewUser` and a `type User = Entity UUID NewUser Metas`. This is useful to declare servant routes, and provide better types for my functions: `createUser :: DB -&gt; NewUser -&gt; m User`. I'm using a lot Generic (via `generic-sop`) to generate SQL queries. Still, the generated JSON keep that structure, it's ok for my use case because I don't really intend for 3rd party to use my API. But it would certainly look strange to peopled used to program in dynamic languages where it is more common to merge the metas fields with the values fields. I think you might be able to provide flat JSON representation by writing your own manual `ToJSON` instances for `Entity`. So, until now, I'm happy with that solution. I'm waiting until the day we'll have row-polymorphism or and equivalent mechanism that will provide algebra composability of records in Haskell. All the lib I looked at are not yet ready to be used (typically, limited to 8 fields to keep compilation time acceptable or apparently really slow at runtime).
Yep, those are the POSIX word boundary escapes. OP was using the PCRE escapes
Could someone do an in-depth comparision of Frege vs. Eta (and possibly, though less relatedly Idris on the JVM). Particularly calling back and forth between Java and them. (Can't do, not experienced enough with Java and JVM yet).
What do you mean by “a way to keep the Reader around”. It would mean your DB actions (that need a DB handle) would have the type `getAccounts :: ReaderT ConnPool m [Account]`. This means the function has access to the `ConnPool` that it can get by using `ask`.
&gt; And, if they take offense they're language fascists and fundamentally assholes. Anyone who doesn't take offense are language deficient and fundamentally pricks, fucking pick ur disease bruh
I believe this is what persistent does as well.
Not in-depth, but basically: - Eta is a fork of GHC rewritten to compile to JVM bytecode; as such, it is mostly compatible with Haskell (in particular, GHC 7.10.3). Much of Hackage has been ported to Eta as well to compensate for the remaining minor differences. - Frege is a separate, Haskell-like language. (I haven't looked at it much, but would guess that the differences are about on the same magnitude as those between Haskell/PureScript). Unusually, it doesn't compile directly to JVM bytecode; instead, it compiles to Java code, which then must be compiled to bytecode by the Java compiler. If you know Haskell already, I'd recommend using Eta - it *is* Haskell on the JVM, whereas Frege is a separate language. (Disclaimer: I haven't used Eta much, have never used Frege, and have only rarely programmed on the JVM at all. However, I do believe the above is correct. Feel free to correct me if I've got anything wrong!)
Ahw man so bad about the audio quality. I'm really loving this talk
less is more or less more of more
Maybe I'm misinterpreting what they mean by "standard library", but I think that the standard library of Haskell is base and not RIO. So I think it is pretty misleading to call RIO *the* standard library of Haskell. I think a better title would be "RIO, an alternative standard library for Haskell" or at least "RIO, a standard library for Haskell". If it were a hobby project I wouldn't mind this, but I'm extra pedantic because FP Complete is a commercial company and this is basically advertising for their (albeit free) product. I think it is great that they improve the Haskell ecosystem, but I don't like that they use misleading language to get people to use their contributions.
&gt; Your form of marketing is unproductive and a silly form of venting in public. I don't see how it is unproductive to point out a mistake. I don't see why people make a big deal out of this.. Of all the types of marketing out there, the most silly and unproductive ones are the ones that go against mere behavior of people irrespective of them being correct or not. And I think that is what you doing here, (and indeed what I am doing here too), because it takes absolutely nothing, no training, no intelligence, no nothing to do so..Any idiot can find arbitrary flaws in the way people behave and make a big fuss out of it giving them free/endless publicity...
It's propaganda. Author thinks that this is what Haskell's standard library should have been, and by wording it this way, subtly nudges readers towards agreement, or even the assumption that it IS the standard lib, or else that none had existed so far and this thing fills a gap.
I don't believe there is anything upcoming, or I also missed it.
Down with this sort of thing!
If we modify [`Co`](https://hackage.haskell.org/package/adjunctions-4.4/docs/Data-Functor-Rep.html#t:Co) to include a phantom representation type, we can derive data Pair a = Pair a a deriving stock (Show, Functor) deriving (Comonad) via (Co Any Pair) `deriving .. via (Co Any Pair)` versus `via (Co All Pair)`: &gt;&gt; extract (Pair 1 2) 1 &gt;&gt; extend id (Pair 1 2) Pair (Pair 1 2) (Pair 2 2) &gt;&gt; extract (Pair 1 2) 2 &gt;&gt; extend id (Pair 1 2) Pair (Pair 1 1) (Pair 1 2) and `via (Co Xor Pair)` &gt;&gt; extract (Pair 1 2) 1 &gt;&gt; extend id (Pair 1 2) Pair (Pair 1 2) (Pair 2 1) [Code](https://gist.github.com/Icelandjack/eea839698f3dd256ac5f79e05615dc07)
If you want to have separate types, you have to suffer a little bit. You need to enable `DuplicateRecordFields` and either leverage the `GHC.Records` machinery to select fields (and to update them https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0042-record-set-field.rst) or use something like `generic-lens` to generate lenses. In both cases the mapping functions will be a little verbose. However this approach allows you to avoid nested types and keep the accessors simple. It also allows for better generic instances for aeson etc., which is a big plus if you don't like to write them by hand. So ultimately it depends on what your priorities are.
I use the default extensions used by RIO, but I get my Prelude from `rerebase`, which is just `base` with more exports.
`type RepAs f rep = Co rep f` deriving Comonad via Pair `RepAs` Any deriving Comonad via Pair `RepAs` All deriving Comonad via Pair `RepAs` Xor
Well, I'm not opposed to something like RIO existing. I just don't see how calling it "the" standard library for Haskell, when such a thing has already existed for a decade or so, can be anything but dishonest.
It's a typo. The title was supposed to be "a standard library." I don't know why it showed up like this.
It's the dishonesty I am against also.
Copatterns / coinductive programming is the ultimate in immutable OOP. It’s lovely. 
Do you mean the `DeriveDataTypeable` extension (which does encompass both), or the fact that `Typeable` is always derived automatically and implicitly (which means that the `Typeable` part of the extension does nothing now)? - `Data` is largely made obsolete by `Generic`. To be fair, many operations are still more convenient to do with `Data`, particularly all the uni/biplate stuff, which is arguably the main motivation behind `Data`/Scrap your boilerplate, but I still see `Data` brought up in many other situations where better alternatives such as `Generic` now exist. - `Typeable` instances cannot be written type-safely by hand, and there is only one possible instance (because `Typeable` is only meant to witness that a type is itself), hence implicitly deriving them for all types is reasonable. - Contrary to `Typeable`, `Data` and `Generic` leak implementation details. Not deriving those instances when you don't need to allows for more tightly sealed interfaces. - Adding to the previous point, sometimes you still want to have some `Data`/`Generic` instances for abstract types, so being able to write artificial instances for those classes can still be useful.
The presenter does not appear to be a native English speaker, so maybe that grammatical nuance was lost on him.
By the way, we've just found an even earlier occurrence of the idea in an IRC chat back on 13 February 2019: [https://github.com/snowleopard/selective/blob/master/paper/irc-log-branchy.md](https://github.com/snowleopard/selective/blob/master/paper/irc-log-branchy.md)
What does it mean for RIO to be teferred to as "a standard library"?
I described the goal in the README https://github.com/commercialhaskell/rio/blob/master/rio/README.md#standard-library &gt; This library attempts to define a set of libraries as "standard," meaning they are recommended for use, and should be encouraged as dependencies for other libraries. It does this by depending on these libraries itself, and reexporting their types and functions for easy use. But please see the rest of that section for full context.
Ah. Violent agreement. Lovely.
RIO seems somewhat similar to ZIO Environment in Scala, both use a record-of-handlers and both aim at providing an alternative to more complex approaches to effect management. (Incidentally, I recently learned that the record-of-handlers approach is related to the Van Larhooven free monad. I guess it is some kind of dual to "freer"? One uses products, the other sums.)
&gt; ...TypeScript focuses on adding ways to type existing JavaScript... Yes. Maybe. Not really... I've written several TypeScript applications from scratch in strict-mode and never ever look back at JavaScript. WritingTS — especially in VSCode — is *very* pleasant and I can't remember the last runtime error due to improperly typed code. For those not very well versed in TypeScript: it has a control flow static analysis which tracks the types of values in local scopes based on runtime checks in if/switch/etc. It's really nice.
The library I linked to above ([http://hackage.haskell.org/package/hworker](http://hackage.haskell.org/package/hworker)) implements at-least-once (rather than at-most-once) processing by moving items from pending to working and then once successfully completed (or confirmed to have failed), removing them from working. And then after a sufficient timeout (application dependent, of course), items in working are considered to have been lost due to crash and are put back into pending. &amp;#x200B; Generally speaking, "getting it right" is a tricky thing, but usually doing things twice every so often is better than missing things entirely, and if you can have the important things that really can't happen multiple times (i.e., payment processing...) be idempotent, then everything works out. The slogan there is "at-least-once plus idempotency = exactly once".
&gt;It's propaganda.. One should be brain dead for them to come to /r/haskell and intentionally declare their things as the standard library for Haskell. This is probably a mistake.
I think the usage of the word 'the' is pretty common in titles like this. I don't think it's particularly misleading nor intended to convey canonicity.
If I had defined it as `RepAs` the original `Co` can be defined in terms of it type Co f = f `RepAs` Rep f
Hanlon's Razor would indeed suggest so. Though I find it a peculiar mistake to make.
[Opaleye has had this for over three years](https://github.com/tomjaguarpaw/haskell-opaleye/commit/ab56b599150ba8e42fe99e81d80141c2695e0f23#diff-75277548d1aef259def16b626f51de38), inspired by Beam. [The latest incarnation](https://github.com/tomjaguarpaw/haskell-opaleye/blob/cb10c1fbea19544edbf0c4d60c1ab979821c72e6/Doc/Tutorial/TutorialBasicTypeFamilies.lhs) is rather powerful and flexible. The most general version I know of, which is what is currently in Opaleye and which supports higher kinded higher kinded data \[sic\], is what I wrote up as [The HKD pattern and type-level SKI](http://h2.jaguarpaw.co.uk/posts/hkd-pattern-type-level-ski/).
I was also going to suggest something like this.
&gt; I wonder whether your Columnar wrapper could be re-used and shared with a form library? It seems like Index or Columnar could be in a general package. [Opaleye's implementation](https://github.com/tomjaguarpaw/haskell-opaleye/blob/0578c89bc3b19c76a091409f4fceb4889b579396/src/Opaleye/Internal/TypeFamilies.hs#L35-L53) is very simple and all you need to get started with. The best introduction is my article [The HKD pattern and type-level SKI](http://h2.jaguarpaw.co.uk/posts/hkd-pattern-type-level-ski/). I'd be very happy collaborating with anyone to provide some useful default functionality and make it an actual package.
There is a significant difference between a definite and indefinite articles. It's just an unfortunate and wrong choice of articles as it completely deflects from a discussion of the utility of RIO. However, the fact that it's backed by a corporation doesn't bode well for me but that's another matter. 
Yeah, you'd think they'd have learned by now to tone down their hubris...
Aren't those really aspirations and goals of FPComplete for RIO? I think that you may have more success if you were to have a neutral standards body where FPComplete would be another member of said committee.
It's a harmless mistake. As a species we do that all the time. Everyday, we make a series of harmless mistakes. For people who care about the technology/ideas being presented and find utility in it are engaged and couldn't care less of what it's called. For an individual, who isn't interested in the substance of presentation and can only harp on one word in its title, it's just a form public masturbation, i.e., venting in public. 
\`base-prelude\` functions similarly and is quite a pleasure to use. 
There's [an impressive FP library for TS](The type system can even be coerced [into doing some impressive FP patterns](https://gcanti.github.io/fp-ts/) (called fp-ts for some reason) that coerces its type system to implement many FP patterns.
I'm sure I wouldn't use a database library or a form library with types as complicated and unreadable as that. 😄 What you gain in power you lose in ergonomics there.
I wonder if any functions based on generics to help with the mapping have been written. It would be nicer in some ways.
Correct. If you search for “cofree interpreters”, you’ll find some work that has been done along those lines. 
Ended up going with this, for now, except for a slight difference: \`\`\` data DBMeta id v d = DBMeta { id\_ :: id , val :: v , derived :: d , created :: ZonedTime } \`\`\` That way \`derived\` is just specified by the type being wrapped (probably \`()\`).
/u/jaspervdj will you also do this talk in HaskellerZ?
Thanks, didn't know that. I had seen an example in the docs in the past like this: &gt; data Birthday f = Birthday { bdName :: TableField f String SqlText NN Req &gt; , bdDay :: TableField f Day SqlDate NN Req There's some kind of diminishing returns when any type or function has more than two arguments. It makes the user experience poor. I don't think this is your problem as a designer, but that Haskell doesn't have pretty type-level records built-in. The Halogen PureScript package has a similar issue--half a dozen type arguments--but they have a better chance. Conduit suffers there too. We're beholden to remembering place numbers instead of names.
At some point, probably, but not the March meetup since I'll be traveling then.
The VH free monad seems somewhat different from cofree interpreters though, the "programs" don't use a "sum" of functors for example.
As complicated as what?
One could do without one of the arguments by enforcing a fixed correspondence between Haskell types and SQL types (e.g. `String` always corresponds to `SqlText`, or vice versa). What do you propose to do about the choice of nullable vs non-nullable and required versus options? That's a genuine decision that the user must make.
https://github.com/tomjaguarpaw/haskell-opaleye/blob/0578c89bc3b19c76a091409f4fceb4889b579396/src/Opaleye/Internal/TypeFamilies.hs#L35-L53
Like I said, it's not a library design issue I'm observing. It's Haskell's inability to say e.g. `TableField f { hstype = String, sqltype = SqlText, nullability = Nullable, required = Required }` or whatnot. I did do a little exploration of supporting defaulting (for inserting rows) [here](https://gist.github.com/chrisdone/62a7c528ca5321747086259170d219ff#file-zimpl-hs-L380). This shifts the burden into the index. I'm not sure it's an improvement. I suppose it's an improvement in the sense that if you don't have any default fields, you don't have to specify the redundant negative. 🤔 `(Maybe Day)` (for "nullable") has that advantage, but I haven't experiment with that in this setting, just used it in other databases. So that would be: birthdayName :: Index i String -- non-null, no defaulting birthdayName :: Index i (Maybe String) -- nullable birthdayName :: Index (Defaulted i) String -- non-null, with defaulting Just thinking out loud. 
Yes, type level records would be great. And yes, you're right, one can remove another argument by using `Maybe`. I forgot about that one!
That's the implemntation, not the usage :)
came up with a cleaner way to define fizzbuzz once I looked at the (zipWith,zipWith, map, map) stuff going on. If you change to trying to fizzbuzz one at a time instead then you get: fizzbuzz = map $ max &lt;$&gt; show &lt;*&gt; ((++) &lt;$&gt; fizz &lt;*&gt; buzz)
I also don't look back at JavaScript in the sense that, if I'm going to write a JS application TS is my baseline. But what I meant with that phrase was that as a language it tries to stick as close as JS as it can. &amp;#x200B; There are few features that diverge from JS, namely Enum and Decorators which where added very early on. If you look from version 2.0 forward, what language feature was added to TS that didn't exist on JS?
That's about what I already gathered from quick research on the net myself :-) While Hackage availability is a huge point, what I'd really like to understand (but can't devote to much time researching) is, in an enterprise project setting which would work better at replacing functional, pure parts (Java packages; mostly quite direct mathematical transformations, [a number of doubles and categorical variables in, a double out]) of the codebase (developers would be very accepting to syntax). I guess the most important aspects would be calling the package from Java and ergonomic type interoperability. The java devs should ideally not notice calling code written in an other JVM language. ("drop-in replacement").
I know it, this is hopefully the first blog in a series, and in the last post I want to compare how to write a "complex" example using plain JS, TS with fp-ts and PS
I agree with /u/Noughtmare that it should be "a", not "the" standard library for haskell". FPComplete's questionable marketing strikes again. That said, I'm really glad experiments are being done with new standard libraries. I encourage everyone to click around `base` with fresh eyes, pretending to be a beginner. It's just not good. + Lots of things that are important are missing (an efficient string type, a bytestring type, hashmaps, etc). + Lots of things that are there aren't important (tons of GHC-specific stuff, the parsing and CLI argument reading modules for which better options exist). + Lots of things that are there and are important are wrong (partial functions, `nub`, etc.). It's embarrassing to sit with awesome non-haskeller programmers who are interested in haskell and have them see `base`. That said, there's one part of base that can't be replaced, which is the typeclasses. And here the story is actually great! The Applicative Monad Proposal, Monad Fail Proposal, and Semigroup Monoid Proposal were all FANTASTIC**. So the way forward to making new standard libraries*** is clear, we just have to settle on them. ** I would also be down for a Numerical Hierarchy Proposal. *** I don't think "standard libraries" plural is an oxymoron. The community is big enough to have a traditional and an enterprisey/webapp focused standard library. I just don't want to have more then 3 or 4 of them in the long run.
Both data structures that you describe in this talk are actually a variation on Priority Search Trees [1]. A priority search tree essentially stores items that have both a priority p and a key k, and is a heap on the priorities and a BST on the keys. In particular, the min/max element is stored in the root. From the remaining elements, the "smaller" n/2 elements go in the left subtree (which is again a Priority search tree), and the other elements go in the right subtree. Priority search trees are often used in computational geometry. For example, you can use them to store a set of n points in 2D (using linear space) so that you can report all points in a 3-sided query range [x_min,x_max] x [y_min,infty) in O(log n + k) time. [1] McCreight, Edward (May 1985). ""Priority search trees"". SIAM Journal on Scientific Computing. 14 (2): 257-276.
&gt; I think that you may have more success if you were to have a neutral standards body where FPComplete would be another member of said committee. I don't think we need a standards body to validate RIO's decisions, eg that `containers`, `unordered-containers`, and `vector` are recommended. RIO is open source, it can be forked at any time. A neutral standards body would have definite negative effects ("design by committee" has a bad reputation for a reason) and probably wouldn't bring comparable benefits at this stage.
Dealing with standard libraries sounds like the thing https://wiki.haskell.org/Core_Libraries_Committee is made for.
&gt; "design by committee" has a bad reputation for a reason What reason would that be? Isn't Haskell the result of such a committee? 
Careful now!
&gt; What reason would that be? Wasn't Haskell the result of "design by committee" and it turned out alright? However well it started (which was quite exceptionally well), it ended up with `base`. Are you happy with `base`?
GHC is and was designed by committee--so, there's nothing inherently bad in design by committee. My suggestion was more about adoption and not about validation. I'm hesitant and as well as others in adopting "a standard" that's backed by a corporation. 
I posted it because it looked interesting and thought someone else might enjoy it as well. I'm not employed or affiliated with them.
I'm happy with Haskell given the choice. The dog is all right but the tail needs work. I'd rathsr have that be addressed by the highly competent and respectful people of GHC or some other standards body than any corporation any day.
base is definitely not bad compared to other standard libraries in other languages. The problems you listed are widely present in other standard libraries as well. I don’t think Haskellers should be embarrassed by base, despite its shortcomings. Especially regarding total function, none of the top 10 most popular languages expresses as much an interest as Haskell for their functions to be total. It took me programming in Elm for a project to really get the hang of total functions. I don’t think it is an important issue for beginners. 
Actually, it does work on my MacOS, Here is my full code: `import Text.Regex` `main = do` `let r = mkRegex "\\&lt;dog\\&gt;"` `print $ subRegex r "mydog dog" "(\\0)"` `=&gt; output: "mydog dog"` &amp;#x200B; ghc --version The Glorious Glasgow Haskell Compilation System, version 8.4.3 &amp;#x200B; ghci --version The Glorious Glasgow Haskell Compilation System, version 8.4.3 &amp;#x200B; runhaskell --version runghc 8.4.3 &amp;#x200B; MacOS version 10.13.x &amp;#x200B; Here are the package on my MacOS: regex-base-0.93.2 regex-compat-0.95.1 regex-posix-0.95.2 regex-1.0.0.0 regex-pcre-builtin-0.94.4.8.8.35 regex-tdfa-1.2.3.1 regex-tdfa-text-1.0.0.3 regex-with-pcre-1.0.0.0 &amp;#x200B; &amp;#x200B;
Yeah, I'm pretty happy with base. It's not the only library I'm using, but definitely happy with it.
Last time I checked I only found functions to do automatic upcasting (removing fields) but nothing to downcast (add fields). However I am pretty sure it is doable. I should give it a try when I have time.
alright figured out no divisibility testing :) fizzbuzz n = zipWith max fizzbuzz' $ map show [1..n] where fizzbuzz' = zipWith (++) fizz buzz fizz = patt 3 "fizz" buzz = patt 5 "buzz" patt m flag = cycle $ replicate (m - 1) "" ++ [flag] I have no idea how your solution works but monoids are next on my list so soon tho haha
Yeah, the problem is really `base` is sort of a collection of primitives, not a genuine standard library. And on top of that, our real "extended stdlib-alike" is also the other core packages that ship with ghc. And there's no desire to push more into this arena, because then it places maintenance burden on the core ghc team, and couples libs to the compiler version. So there is a genuine need for an extended stdlib/prelude that's nice and uniform here. And it necessarily won't be coupled with ghc.
Yes, that addresses it well, thanks.
Ah, thanks for pointing that out. No, I've been using `stack install`. I'll try `stack build` and see if that works better.
Ah. In that case I don't think I can help you - I don't know enough about Eta, Frege, or the JVM.
OK, thanks for the work you have done on it. I've been informed in another thread that my resolver issue can be resolved (ahem) by using `stack build` instead of `stack install` for intero. The issue with looking up things that aren't variables might be something I could fix without too much trouble. The other issue with not finding a package... I'm not even sure where to start. And it might be mitigated by that `stack build` solution.
Is it possible namespaces on Hackage (if that's even an option at this point) would help here? Discoverability is an issue. If I could poke around the `haskell` namespace on Hackage, much like I can on GitHub, I feel it would be easier to cobble together a standard library of packages.
You can sort of simulate type-level records using newtypes and tuples: ``` data Smell = Rotten | Fresh data Soldier = Soldier { name :: String, rank :: Smell, cereal :: Natural } newtype Name = Name Symbol newtype Rank = Rank Smell newtype Cereal = Cereal Nat type Soldier' = (Name, Rank, Number) data SSoldier (t :: Soldier') where Steve :: SSoldier '( 'Name "Steve", 'Rank Fresh, 'Cereal 3 ) ```
Personally, I think a small stdlib is good. They are notoriously hard to version (and in particular to change incompatibly) since they are shipped with the compiler/interpreter. Virtualenvs help a lot here, but can have their own pain points. I like the size of the C stdlib, rather than something like Java 5 SE or .Net Core 3.0 or even POSIX / the Single UNIX Specifcation. I do like the idea of a batteries-included collection like the Haskell Platform or a Stackage release, something were either you get all your dependencies installed at once, or you are pulling dependencies from a set of versions known to already work together, but I wouldn't want it to be *always there*. I often like starting from bare bones, or pulling recent releases from PyPI / CPAN / Hackage / crates.io and I don't necessarily want the release schedules of all packages to be tied to the release of a platform. In many ways, Haskell is "just the way I like it". Most of the time, I'm just going to want to use GHC from the Debian repositories and user or per-directory cabal installs from hackage. But, when preparing a release or even pushing out something internal that wwill need to be maintained for a long time, I'd want to fix a set of packages and build against that -- either everything in a particular Debian release or in a a Stackage (preferrably LTS) release.
Well, I would expect everything on hackage to be in the "haskell" namespace. :P It is only for haskell packages.
You missed my point, I did not mean to suggest we use the namespace `haskell` to classify the Haskell packages that are written in Haskell. Rather, packages that are, for one reason or another, adopted by GHC HQ, Haskell.org, or motivated and prominent community members interested in standardizing packages (think the Haskell Platform). Check out the `haskell` organization on GitHub for what I was referring to. It's where you'll find `bytestring`, `text`, `container`, and many other core packages.
I think it would be as hard to find the right namespace / tag as it is to find the right package right now. If we had overlapping namespaces like "core-lib-committee", "platform", "stackage-lts", etc. But, if you can get buy-in by the hackage trustees, they can create a tag, add packages to it, and feature it prominently.
Seems like an ideal solution except to corporations whose intent is to control.
by the way dup = liftA2, and sequenceA is not far behind. You probably already know that, just thought I'd point it out as I learn.
Does this example deliberately contain puns or am I reading too much into it?
I feel I'm not being clear, by "namespace" I just mean an account name. Packages I upload would be under my username, and there could be a "haskell" user/namespace for core packages - that's all.
out of consideration for our non-native english speakers, my examples no longer require that readers understand my puns this doesn’t mean there aren’t puns
I think this is better as a "tag". Those are browseable on hackage, and I think it would be more clear that they would not affect the package's name (for dependency lists, for example). If we did want to make it part of the package's name, we probably *woudln't* want it to be the uploader's username, in case package matainership moved from one user to another.
&gt; More precisely, one thing that often trips people up is that you can't have heterogeneous data structures in Haskell. I beg to differ: https://pastebin.com/BrgPqjvC
Is your definition supposed to be `f x = x + 1` or `f = \x -&gt; x + 1`? Operationally, both will give you the same result but they differ w.r.t. inlining. For example, (code from base) -- | Function composition. {-# INLINE (.) #-} -- Make sure it has TWO args only on the left, so that it inlines -- when applied to two functions, even if there is no final argument (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c (.) f g = \x -&gt; f (g x)
That kind of heterogeneous list is just an (arbitrary-length) tuple. You still can't use them for OO-style dynamic dispatch. ;) Anyway, I am not sure if advanced type-level programming is the best place to start with Haskell...
Haskell is not an IDE, it's a programming language. GHC is the Glasgow Haskell Compiler, the main implementation of a compiler for the Haskell language. There are IDEs for Haskell - cf. [this recent thread from a few days ago on IDEs for Haskell](https://www.reddit.com/r/haskell/comments/ax6s6i/what_is_the_best_haskell_ide_experience/) - but you don't *need* to use an IDE; you can, as the text you quoted says, just write code in a text editor (e.g. Vim, Emacs, Sublime, etc.) and then ask GHC to compile it into a program for you, which you can then run, again as per the text you quoted. What programming background do you have?
awesome thanks for the help! a few more questions. my background is just taking in intro to python class (used anaconda/spyder IDE) and a class in C (used a different IDE). I want to go the route of text editor -&gt; GHC, but I've never done that. I just ran 'cabal' in my terminal and it gave me this: ********************************************************************** === Configuration for cabal has been written to /Users/Zach/.cabal/config === Executables will be installed in: /Users/Zach/Library/Haskell/bin You may wish to place this on your PATH by adding the following line to your ~/.bash_profile: export PATH="$HOME/Library/Haskell/bin:$PATH" === When documentation is built, a master index to all documentation will be placed in: /Users/Zach/Library/Haskell/doc/index.html You may wish to bookmark that file once it gets built (after the first cabal install). ********************************************************************** Warning: The update command is a part of the legacy v1 style of cabal usage. Please switch to using either the new project style and the new-update command or the legacy v1-update alias as new-style projects will become the default in the next version of cabal-install. Please file a bug if you cannot replicate a working v1- use case with the new-style commands. For more information, see: https://wiki.haskell.org/Cabal/NewBuild Downloading the latest package list from hackage.haskell.org cabal: no command given (try --help)
Oh that's much easier: ``` {-# LANGUAGE ConstraintKinds, GADTs #-} module Exists where data Exists c where Exists :: c a =&gt; a -&gt; Exists c apply :: (forall a. c a =&gt; a -&gt; b) -&gt; Exists c -&gt; b apply f (Exists x) = f x showList :: [Exists Show] -&gt; [String] showList = map $ apply show sumIntegrals :: [Exists Integral] -&gt; Integer sumIntegrals = sum . map (apply toInteger) ```
The latest release has a DateTime module now: [https://hackage.haskell.org/package/fakedata-0.2.0/docs/Faker-DateTime.html](https://hackage.haskell.org/package/fakedata-0.2.0/docs/Faker-DateTime.html)
The latest release has DateTime module now: [https://hackage.haskell.org/package/fakedata-0.2.0/docs/Faker-DateTime.html](https://hackage.haskell.org/package/fakedata-0.2.0/docs/Faker-DateTime.html)
What's the reasoning behind this choice? Is there a reason to not inline the second form?
&gt; What's the reasoning behind this choice? [I'm not a GHC dev so this bit is mostly speculation.] Since Haskell functions are curried by default, this mechanism allows the user to control things to an extent instead of leaving everything to the compiler devs. You can't stick to a simple rule like "inline only fully saturated calls" or "inline regardless of number of arguments" as the former might give bad performance if code is written in a point-free style (😭) and the latter might lead to code (and compile time) bloat for little gain. Having flexibility for something in-between is useful. That said, this isn't a silver bullet. You can end up with suboptimal performance if you're not careful, such as in this [bytestring issue](https://github.com/haskell/bytestring/issues/23). &gt; Is there a reason to not inline the second form? The second form will always be inlined if marked with an INLINE pragma (unless the function is recursive etc.).
my tentative takeaway from the compose example is that by default functions are inlined only if they are considered to be fully applied, and that partitioning parameters between the lhs and rhs of the definition can be used to indicate to the inliner that the typical usecase of the function is in a situation (pointfree etc) where it is not fully applied. but in the specific case of f above, f can only be fully applied, so i would assume that both forms would be inlined. more conservatively generalizing from the example, i might expect that only `f x = x + 1` would inline in 'f 2' as the number of parameters on the lhs of the definition exactly matches the number of arguments to which f is applied. but i doubt this is the case; otherwise using explicit lambdas at all in haskell would seem to be a significant performance pitfall. do you know for a fact that it doesn't inline (without a pragma)?
Yes, we both know Haskell's type system has support for existential types . But as I was saying before, are we *sure* we want to use them here? We definitely shouldn't give OP the impression that Haskell typeclass magic is the natural translation to common OOP patterns. Anyway, in this particular case you still can't do `showList [10, True]`, like you would be able to in an OO language. You first need to convert the individual elements to an homogeneous list of `Exists Show` or `Exists Integral`: xs :: [Exists Show] xs = [Exists 10, Exists True] But at this point you might as well skip the existentials and convert to a list of `String` or `Integer` instead. xs :: [String] xs = [show 10, show True] (This kind of stuff is why many consider existentials to be an antipattern most of the time, as I am sure you know)
If you would like to follow the Emacs way, here is some write-up: https://gist.github.com/Elvecent/866d018a3e6140d001ef1d987b72c778
&gt; more conservatively generalizing from the example, i might expect that only `f x = x + 1` would inline in 'f 2' I don't think that is the appropriate take away. Both of them will certainly inline with `f 2` but only the second one will certainly inline in something like `g = (. f)`. It's not an exact match criterion. For example, having more arguments usually means that inlining will be more useful, but having an exact match criterion would not make use of that observation. &gt; but i doubt this is the case; Yes, I don't think that's the case. &gt; do you know for a fact that it doesn't inline (without a pragma)? I'm not sure how general of an example you're talking about here (are you asking about 'f = \x -&gt; x + 2' specifically or generalizing to definitions written as lambdas). GHC automatically considers "small" definitions (such as `f`) as good candidates for inlining. --- Also, the compiler is free to do βη conversions (so long as it maintains the same semantics) which can change the number of applied arguments. This also means that lots of intermediate lambdas that get created go away.
People can actually tag their own packages now! Unfortunately they don't get persisted right between server restarts due to some hard-to-pin-down bug. Patches very welcome: https://github.com/haskell/hackage-server/issues/80
Well, not only that. But also we could use more uniform APIs without the cruft -- i.e. using `Text` pervasively instead of `String`, having a nice batteries-incuded tempfile handling function instead of just the raw primitives to build it, etc. I know the ropes well enough to find the right things to pull in or just knock-out the right logic myself. But there's still lots of common tasks that it would be nice to get from one place with a uniform style in terms of how it handles arguments, etc. I wouldn't even mind if it were made up of distinct packages which didn't have to move in lockstep -- it would just be nice of the naming conventions, argument passing conventions, etc. were standardized and if there were a few more high-level functions with more logic baked in for common patterns -- especially around IO related stuff.
So the last line there tells you what to do. Run `cabal --help` and it gives you help. One way to start is to run `cabal init` which walks you through creating a cabal package. Then you can create an executable package, and use a text editor to edit the `Main.hs` file it creates using your favorite text editor. To build it, run `cabal v2-build`, and to run it, run `cabal v2-run`.
Unfortunately the things recognized by the regex-posix module depend on which posix regex lib it links against on your system. An all-haskell alternative would be to use regex-tdfa, which documents the boundary characters it supports quite well: http://hackage.haskell.org/package/regex-tdfa-1.2.3.1/docs/Text-Regex-TDFA.html
A friend of mine's messages are _even more_ consistent. They simply alternate between "wut", "argh", and "doh".
&gt;Would it not be easier and possibly saner than sieving through assembly code to write your numerical functions in C and use Haskell's FFI to call your numerical functions? Calling FFI has multiple downsides. Number one is the overhead of the call. If you have something that takes 3ns in Haskell but 1.5ns in C, if you do an FFI call, you are adding say 2.5ns and it's no longer worth it. It is an actual problem because your call might be in a hot loop and called 10 million times at which point you are losing actual noticable, non-noise time. So your only choice left is to write Haskell and now you have to work very hard to make GHC produce the exact code you want from it. The number two downside is that GHC can't optimise at all at compile time once you're doing FFI. If I have ``` int add_one(int x) { return x + 1; } ``` and in Haskell I do ``` foo = add_one 3 ``` then GHC will _not_ compute foo = 4. It will _not_ constant fold anything where foo is involved as it doesn't know its value. So writing things in Haskell where inlining, evaluation and all the nice stuff can happen during compile time which you want.
Depends on the syntax. I guess it's better to ask /u/jvanbruegge because he is working on the GHC proposal for row polymorphism. I guess mostly the same as the current `data` definition. Probably different is join of structures is supported. But for me personally the main utility of row polymorphism is the ability to write functions (not to define data types) like this one: fullName :: { firstName :: Text, lastName :: Text | r } -&gt; Text fullName u = firstName u &lt;&gt; " " &lt;&gt; lastName r
&gt; More precisely, one thing that often trips people up is that you can't have heterogeneous data structures in Haskell. This is the statement you started with and what I was addressing, because it's one thing to claim it's unidiomatic, but it's sketchy to claim you "can't" do it. &gt; Anyway, in this particular case you still can't do showList [10, True], like you would be able to in an OO language. You first need to convert the individual elements to an homogeneous list of Exists Show or Exists Integral That is a very surface level difference that doesn't have any deep underlying meaning. It's just about whether upcasting is implicit (most OOP languages) or explicit (Haskell existentials). Any place you could do the above in an OOP language implicitly you can do in Haskell with just a few identifiers of explicit casting. &gt; (This kind of stuff is why many consider existentials to be an antipattern most of the time, as I am sure you know) I do agree with that part of course.
Also "fgdddgfsaasdf" and "fuck"
This article is clearly targeted at people that don't know Haskell and FP in general. The basic syntax and semantic differences are described well, but the article never mentions the biggest difference between the languages. Namely: you can pick up Typescript in two days. Purescript probably takes months without FP background. You can't honestly compare these languages based on basic semantic differences, it just doesn't give justice to Purescript's learning curve :) I think it's better to learn Haskell first. Desktop apps aren't conceptually as complicated as web apps, Haskell Prelude and libraries aren't typically as abstract, error messages are better, more mature ecosystem, etc. Learning Purescript first may not be possible for most people. To write a basic Halogen web app (like the recent Realworld Halogen project), you must know monad transformers, free monads, etc. Monads alone are notoriously difficult to fully grasp, and they are just a basic concept in Purescript. I don't think you can handwave the "do" notation as "it just sequences commands", error messages are too technical. Maybe it's that I am just not very smart. Would be curious to know what others think. Is here anybody that just picked up Purescript like it's Typescript? :-)
See also https://stackoverflow.com/q/11690146/388010
Inlining is really just inlining the definition at its call site, without beta reduction. So your former example is correct, but you shouldn't really see this in -dverbose-core2core because the resulting redex is immediately reduced. You should only observe the second form.
If one has many entities with that structure, perhaps one could write an associated type family like class Derived r where type Derive r derive :: r -&gt; Derive r data DBMeta id v = DBMeta { id_ :: id , val :: v , derived :: Derive v , created :: ZonedTime } I'm not sure if that would would you something though.
If you are looking to use separate types, and searching for a way to map between them, you could try `vinyl-generics` (&lt;/plug&gt;). It uses `vinyl` as an intermediate representation to upcast/downcast records, and then converts back to a plain record. Makes use of `GHC.Generics`/`generics-sop`/`DuplicateRecordFields`. Link: http://hackage.haskell.org/package/vinyl-generics 
I've been grappling with this since about my second week working with Haskell. It isn't a wart on the _language_, per se; after all, our ability to evolve the ecosystem is one of the greatest things about our community. It does makes for an awkward development experience, though. I even wrote this: -- The only constant of the Haskell universe is that you won't have -- the right combination of {strict, lazy} × {Text, ByteString, -- String, [Word8], etc} you need for the next function call. For my own work, I wrote some code that smooths the way somewhat on the interoperability front. I have a typeclass that does nothing but convert between different things (ie between text types). That's not original by any stretch; in this case the intermediate form is a rope type so the interoperabliliby challenge became "convert from whatever the supplying library gave me, work with the rope for a while, then convert out to whatever text format the next library wants." Using a typeclass method is an extra indirection (oh, the performance cost!) but I've almost entirely stopped caring about what text format someone gives me, which has been nice. `Textual` in [Core.Text.Rope](https://hackage.haskell.org/package/unbeliever/docs/Core-Text-Rope.html), if you're interested. AfC 
My meaning is that after a function finishes executing all of the variables it created go out of scope. So unless I want to open a new DB handle on each and every connection I need a mechanism to keep the ReaderT ConnPool from being garbage collected. So above was some slight venting at some of the suggestions that have been offered elsewhere and me missing the bigger picture. As [IronGremlin](https://www.reddit.com/user/IronGremlin) confirmed, \&gt; Monadic recursive loops to keep references alive are quite idiomatic in Haskell, so don't shy away from using them - but do keep in mind that in general we avoid using long lived references, and that this means that although almost every program will contain at least one loop, most programs should not contain very many. So "a way to keep the Reader around" amounts to where the Monadic recursive loop is in the application architecture and how the DB handle is passed to where it's needed. I fortunately have cleared that up from the other posts now. &amp;#x200B;
the title is so pure
haha Im a dumbass! 
ok sweet. So I actually did end up running `cabal init -p "myfoo"` from something I read. When it gave me the option of Library or Executable, I chose both. Then this is the last message it gave me, which makes me think something went wrong: Guessing dependencies... Generating LICENSE... Generating Setup.hs... Generating CHANGELOG.md... Generating Main.hs... Generating myfoo.cabal... Warning: no synopsis given. You should edit the .cabal file and add one. You may want to edit the .cabal file and add a Description field. 
Did you decide against `Maybe a` in favor of the N vs NN for a motivating reason? E.g. join subtleties with NULL or the fact that `Just (Just x)` gives back `Just x`? I'm definitely on the fence in the for/against discussion about using Maybe for representing NULL (either in SQL or Aeson).
&gt; simple I just gave "Simple GHC (Haskell) Integration" a try, and I'm impressed! I've got "HIE" working, but it was a slog. Simple does some really nice things! The way it quietly annotates with `:: Int` or whatever as you select a range of code is _brilliant_. Ran into one problem; Simple doens't handle multi-root workspaces yet, which is a shame. I'm pretty heavily invested in that feature; I often have an application and a library open at the same time and being able to hack on the two simultanously (which HIE does support) is nice. 
&gt; Our aim here is to formalize the call arity optimization of .. in terms of a statically checked feature of a core intermediate language. And similar to .., we seek an intermediate language that is equally appropriate for *eager* and *lazy* functional languages. We achieve both goals simultaneously with the same key idea: use the kind system to classify types by their evaluation strategy: call-by-value, call-by-name, or call-by-need. This sounds brilliant
&gt; TODO: add support for multiple packages in a directory Sounds like you got more than one `*.cabal` files in your directory 
This looks quite interesting! I wonder whether it could be adapted to also support dependently typed programming languages…
&gt; Warning: no synopsis given. You should edit the .cabal file and add one. &gt; You may want to edit the .cabal file and add a Description field. You can ignore this. This is just complaining about missing descriptions, which would be a problem if you were planning to publish your package but not when you're just doing a bit of programming. The second error indicates there are several `.cabal` files in the same directory, which _is_ a problem.
&gt; Does this function have *eta-nature*? &gt; *Mu*
how would I find the extra one and delete it? 
do you know how I can delete it?
Why not. The paper mentions &gt; Analogously, the polymorphic type `∀^r a:k.τ` and corresponding abstraction `λ^r a:k.e` are also annotated with their representation. If you combine `→` and `∀` into `∏` (or just add `∏`), I don't see obvious reason why it wouldn't work.
&gt; cabal v2-run Ok so update. I deleted the extra cabal file, ran `cabal v2-build` and `cabal v2-run` and it all looks good. It returned a msg in bash: Up to date Hello, Haskell! now what?
 &gt; Ok so update. I deleted the extra cabal file, ran cabal v2-build and cabal v2-run and it all looks good. It returned a msg in bash: Up to date Hello, Haskell! &gt; &gt; now what?
The `Hello, Haskell!` output was produced by your program in `Main.hs`. Now it's your turn to write some Haskell of your own into the `Main.hs` and run it. 
TIL Hackage has tags :)
I kinda prefer the more syntactic flavor of the types are calling conventions design, though this kind trick is cool. A big part of why I like the types are calling conventions design is that it leads really naturally to having function types naturally forming a pi-&gt;sigma telescope. I distinctly recall Joachim and Stephanie were doing a precursor to this types are kinds sort of approach a few years ago. Though some design details in this one seem a tad cleaner. 
Well... now you have a working haskell env I guess? You can edit your `Main.hs` to play around a bit with Haskell, and you should be able to drop into a REPL with `cabal ghci` 
Dang. Since this is named chronos-bench I expected it to use the chronos haskell library, with module named "Chronos.Bench". I would consider switching from time to chronos, because the latter is much faster. It should be more than suitable for this.
So something to note is that this machinery exists already in recursion-schemes. Term is Fix, Attr is Cofree in (comonad package), and histomorphism is defined in those terms. So you may be able to utilise the existing functions on those types. But admittedly I only glanced at your example on my phone :)
dope! I was using the online compiler rept.it before, and now it seems to be working almost just like that. I loaded main.hs by running `:l main`. The only text editor I have is the TextEdit program that comes preloaded on Mac. I can't download emacs because my computer is old and I'm not going to update it (homebrew requires an update). I just ordered a new comp that I'm gonna run linux on, and will have a different text editor. How can I use TextEdit, convert the file to a .hs file, and run it?
I pretty much just want a REPL so I can practice. similar to what I had with repl.it, but local
Oh, thanks for the suggestion. I'm benchmarking the switch right now. :)
Is it just me or does giving error messages properly basically get rid of all the niceties of applicative/monadic error handling? I wrote a basic typechecker recently, and to start with just made it of type `Maybe Type` and everything went really smoothly. Then I decided to add descriptive error messages for different things which could go wrong and it basically became a load of explit nested cases and ifs. Is there a nice pattern to not have to do this?
There's no 'conversion' needed. You just need to _name_ the textfile something with `.hs` at the end. But unless I'm mistaken I believe `cabal init` should have already created one or more `.hs` files in your directory (not sure, it's been a while since I've used `cabal-install`). Probably something like `src/Main.hs`? Just look through the directories that were generated if you don't know where exactly to look. Otherwise you can also take a look at the `.cabal` file for your project; This will have an `executable` section, and under that `main-is` and `hs-source-dirs` fields; The `hs-source-dirs` tells you which directory has the haskell files in it, and the `main-is` tells you which file (in that directory) `cabal` is expecting the `main :: IO ()` to be declared in.
&gt; `Attr f a`, though, is already shot through with the `Functor f`. That's fine, you can still replace the recursive occurrence of `Attr f a` with a new type parameter: data AttrF f a r = AttrF { attributeF :: a , holeF :: f r } 
w.r.t. to previous comments: TextEdit can apparently do word processing as well. Make sure the files you're writing are plain text files, not whatever it is using for text markup.
I tried naming a TextEdit file with .hs extension, it said "are you sure", then it disappeared from where it was. Now I'm trying to find main.hs, which I've seen before in bash, but now I can't find it
I'm afraid I'm not a Mac user myself so I can't tell you how exactly to operate TextEdit; I'd recommend maybe checking out [this article](http://www.iphonehacks.com/2017/06/plain-text-mode-textedit-mac.html) and seeing if that fixes your problem.
what's `vessel`?
Ok I'm so close. I found main.hs, and after I ran ghci in bash, I could run `:l main` before. But now I can't. I also got TextEditor set up and can save .hs files in the same folder as main.hs. But now it just seems like ghci in bash isn't looking for files in the same place as it was before. Do you know how I can see where ghci is looking for files? 
Are you running `ghci` or `cabal ghci`?
just ghci. Cabal ghci return 'unrecognized command' 
See my edit
I wanted to represent what was going on in the DB as faithfully as possible. As you say, one can nest `Maybe` arbitrarily, in a way that doesn't actually correspond to anything meaningful in the DB type system. That's why I'm averse to it.
Great! Now I'm partway there: I think I've written the machinery to `cata` over an `Attr`: ``` data AttrF f a r = AttrF { attributeF :: a , holeF :: f r } deriving (Eq, Show, Functor) unTerm_attr :: forall a f. Functor f =&gt; Term (AttrF f a) -&gt; Attr f a unTerm_attr = cata iso where iso :: Algebra (AttrF f a) (Attr f a) -- = AttrF f a (Attr f a) -&gt; Attr f a iso (AttrF a h) = Attr a h term_attr :: forall a f. Functor f =&gt; Attr f a -&gt; Term (AttrF f a) term_attr = ana iso where iso :: Coalgebra (AttrF f a) (Attr f a) iso (Attr a h) = AttrF a h ``` But now I don't even know how to write the type signature for a version of `history_has_a_2` that uses `cata` and `AttrF`. 
sounds good. I've never used discord. Im in the functional programming section. What's your name there?
I do greatly look forward to using that library. Before I get there, though, I want to try the tedious way, converting recursive types between their ordinary and functorial representations myself, so that I know what's going on later.
&gt; But now I don't even know how to write the type signature for a version of `history_has_a_2` that uses `cata` and `AttrF`. Why would the type signature change? It should still be `Attr AbcF Int -&gt; Bool`, but now you can implement it by converting to `Term (AttrF f a)` and then use `cata` instead of explicit recursion.
Just go into the Haskell/beginners channel, that's probably the best place
awesome thank you for all your help!
Thanks! Got it! ``` forHisto :: CVAlgebra AbcF Int -- ^ histo forHisto aTerm_abc_histo forHisto abc = case abc of AF -&gt; 0 BF a -&gt; 1 + attribute a + (if history_has_a_2 a then 100 else 0) CF a b -&gt; 1 + attribute a + attribute b where history_has_a_2 :: Attr AbcF Int -&gt; Bool history_has_a_2 = cata f . term_attr where f :: Algebra (AttrF AbcF Int) Bool f (AttrF 2 _) = True f (AttrF _ AF) = False f (AttrF _ (BF b)) = b f (AttrF _ (CF b c)) = b || c ```
I think this would be possible, but I'm unsure if it's worth the trouble. If you look at 2.1 Motivation, two of the four points are related to divergence, which isn't typically present in dependently types language calculi like the CIC. So, two reasons less to do this. It's an interesting view, combining evaluation strategies in a single calculus, but really GHC Core, or any other lazy core calculus, can already express call-by-value (`case`) and call-by-need (`let`). The only real benefit (and nuisance) in this setting compared to GHC Core is being able to encode arity (and its invariants) in the type system, and essentially being able to specialize every higher-order function for its function parameters. It's still an unknown (i.e. late-bound, virtual, unknown) call, but at least we don't need to look up the function's arity in the info table, so there might be some gains. I admire the approach mostly for its elegance to solve a common problem by generalising an existing technique (w/w transformation) known to work well. But I'm only half way through the paper, so I might change my opinion.
That’s `EnvT a f` aka `Compose ((,) a) f`
There are a few things left to do in this port: \- Port over the floating point arithmetic code from OCaml, re-enable those spectests. \- Implement checking of \`assert\_fail\` from the spectests. \- The evaluator consumes far too much memory; further optimization work needed, especially when recursive evaluation becomes deep.
Yes, I think the idea of a ghci-based IDE plug-in is they way to go, as it removes the need for external dependencies that need to be updated in parallel with GHC (e.g. ghc-mod). I’ve been thinking about creating a Language Server Protocol implementation based on ghci. This could then be used by multiple IDEs compatible with LSP. SimpleGHC seems like a good starting point, but I haven’t gotten further with the idea.