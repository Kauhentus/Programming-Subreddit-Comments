[Protolude](https://github.com/sdiehl/protolude) is my favorite. I use it as the base for a custom prelude in most of my projects. You might find the [Aelve Guide Alternative Preludes page](https://guide.aelve.com/haskell/alternative-preludes-zr69k1hc) interesting if you haven't seen it.
I think I went one level higher when proving a special case of the K axiom for types with decidable equality. But, I do believe higher type levels are even more mysterious that sixth-order functions.
&gt; Last and First monoids Isn't one of these `Alt Maybe` and the other one is `Reverse (Alt Maybe)`?
Keep in mind for other people reading your code then names are more readable than infix operators!
Depends what you are building. If your project is an "application" (i.e., something that nothing else is going to depend on), then an alternative prelude may make your life easier. If your project is a library, then I'd recommend against, or if you feel you must use an alternative prelude, try to not burden your users too much with it - that is, don't require anything from that alternative prelude as part of your library's interface, and pick an alternative prelude that has a low dependency footprint. As to ClassyPrelude: I have used it on one project, and direly regret it, even though the project fits the "application" profile. The documentation is kind of bad due to the way it re-exports full modules (which means that unlike the standard `Prelude`, the haddock for `ClassyPrelude` does not list every single identifier it exports, instead you have to hunt things down through referenced modules), and this turned out to be a bit of a productivity drain. Another issue with ClassyPrelude is that, due to its design philosophy of making everything maximally polymorphic, you often end up with type ambiguities - e.g., `putStrLn "Hello!"` with `OverloadedStrings` enabled will no longer compile, because `putStrLn` is now polymorphic over the string type, and it is unclear whether you want `Text`, lazy `Text`, `String`, or something else. Yet another problem with ClassyPrelude is that it doesn't give any version bounds for about half of its dependencies. Which is kind of problematic for a library - you'll get away with it if you happen to use stack and the right snapshot (which, by sheer accident, you might), but if you try to use it in a somewhat complex Cabal project (either directly, or because someone else depends on your library from a Cabal project, introducing `classy-prelude` as a transitive dependency), then it's hit-and-miss, and you may get surprising compilation errors depending on *what else* you depend on - probably one the most frustrating kind of bug to hunt down. Long story short, what I generally do is this: - For libraries, either just use standard `Prelude`, or assemble a non-intrusive lightweight custom Prelude to be used internally. - For applications, assemble a heavier custom Prelude, but still roll my own, and it's still going to be less intrusive than ClassyPrelude. - In general, build the custom Prelude on top of the standard one, and avoid hiding things from `Prelude`.
`Backwards (Alt Maybe)` is slightly better than `Compose`. But see my other comment. The other two points are still relevant. Also: `Backwards` is not in `base` at the moment. `Last` is a very simple data type with clear semantics. I can break my head trying to understand what `Backwards (Alt Maybe)` actually does (and I might not be the only one).
I'm a maintainer of the [relude](https://github.com/kowainik/relude) alternative prelude, and I can recommend it! We're trying very hard to provide the best user experience and excellent documentation for the `relude` users. `protolude` was mentioned here, but you can see the comparison between `relude` and `protolude`: * https://github.com/kowainik/relude#relude-vs-protolude-
&gt; In other words, literals “2” и “134” have no connection Sneaky `и`.
If beginners are using higher kinded data without getting lost - I don't think they should have much problems using Compose either. It should be possible to make their life easier by having it as an example.
If you don't know it already, you might be interested in this paper on [how data and codata are connected by de- and refunctionalization](http://ps.informatik.uni-tuebingen.de/publications/rendel15automatic.pdf).
https://dc25.github.io/minesweeperMiso is not fast on my smartphone. My web app is going to be used on smartphone.
&gt; Everyone frowns at you when you use these accessors because if `FooRecord` has more than a single constructor, and you use an eliminator for the other constructor, your program blows up in flames. I prefer to frown when someone defines accessors on a sum type. Accessors on a product type are very useful, don't give them up so easily!
Formality's wiki is useful!
&gt; One of the constructs of Category Theory is the co-category. It's called an "[opposite category](https://ncatlab.org/nlab/show/opposite+category)". "[Cocategory](https://ncatlab.org/nlab/show/cocategory)" is something else. .
&gt; This is something great, as it means we may have programming languages in the future that support both data and codata! There are already programming languages which support both data and codata: Agda (which later dropped the codata keyword in favour of musical notation [and later copatterns](https://gist.github.com/gelisam/041cf8bc332f7a44096548e22d2dfa3a)) and [Idris](http://docs.idris-lang.org/en/latest/reference/syntax-guide.html#co-data). Those are two dependently-typed languages, and this is no coincidence: the main difference between data and codata isn't sum vs products nor FP vs OOP, it's finite vs infinite. In Haskell, we use the same datatype for both finite and infinite lists, which leads to programs like `length (cycle [1,2,3])` which are well-typed but don't terminate. Termination is very important in dependently-typed languages, and so they define two versions of lists: `length` only works on finite lists (which are defined using `data`), whereas `cycle` produces a potentially infinite list (a different type, which is defined using `codata`).
Nobody's tagged u/i-am-tom yet, so I will.
[RIO](https://haskell.fpcomplete.com/library/rio) appears to be promising to me.
Why?
Something like this is how I got a run-time Integer (`labelCount`) into a type parameter (`o`): labelCount &lt;- basedOnData fileName case someNatVal labelCount of (Just (SomeNat (_ :: Proxy o))) -&gt; do (model :: MLP o) &lt;- constructModel Make sense? Verbose, but mechanical: I just do it for all runtime-dependent dimensions. Hasktorch is currently in the midst of experimenting with new PyTorch 1.0 bindings, and a Summer of Code project on getting some RNN examples implemented, both of which are really exciting prospects.
The most important page of all gives a scary 404: [https://github.com/kowainik/relude/blob/master/structure-of-this-tutorial](https://github.com/kowainik/relude/blob/master/structure-of-this-tutorial)
Watch out that it takes a lot of things for granted, especially if you do `stack new myproject rio` you end up with an undocumented project structure and some not-exactly-beginner-friendly and not-exaclty-well-documented modules like Options.Applicative.Simple
Could you point to the place where you found this broken link? When I click on a paragraph or any arrow in the `README.md` file, it redirects me to the correct place: * https://github.com/kowainik/relude#structure-of-this-tutorial _Structure of this tutorial_ is a paragraph in the `README.md` file, the link for the paragraph has a different shape from your link. Your link has a form of a file, and there is no such file, that's why the link is broken. Did you find some typo in the documentation? If so, I'm happy to accept the PR! Or you can just point to the place and I will fix it :)
Thanks! ))))))
No, it is a very clear example, thanks. We tried something like that in the beginning. I'll answer after publishing the second part of the blog, because don't want to spoil, sorry :-)
Does this replace the Racket version? Is this the recommended implementation to play with while working through The Little Typer book now?
IOHK is teaching Haskell &amp; Blockchain course: https://iohk.io/education/
Thanks for the thorough reply. I have been programming my way around it for a while, and will probably have to continue to do so since I feel that I am not quite there yet. If we take the minimum edit-distance example, there are a few issues. First of all, the `conquer` function you gave is already a few iterations after the very first naive implementation someone could come up with. And in Haskell that usually involves pattern matching on lists: minEdit :: Eq a =&gt; [a] -&gt; [a] -&gt; Int minEdit [] ys = length ys -- "Insert n characters". minEdit xs [] = length xs minEdit (x:xs) (y:ys) = -- For both string versions there is a character at the end. let score1 = minEdit xs ys + if x == y then 0 else 1 -- One of the strings should run out of characters first. score2 = minEdit (x:xs) ys + 1 score3 = minEdit xs (y:ys) + 1 in minimum [score1, score2, score3] Okay, that not asymptotically efficient, but it is something you might come up with if you encounter the problem for the first time and need a working first version, or are still *exploring* the optimal substructure. So you float out the "lookup" operation, making it a function argument. Furthermore, you notice that each subproblem is a *prefix* of the larger problem, and you have a *bijection* from string prefixes to their lengths. Oh and we would of course have a different traversal order in the version you gave, but that doesn't matter for the score itself. I would argue that for an unknown problem the challenge lies in coming up with the optimal substructure and the correct recurrence in the first place, and that replacing a recursive call with a function argument is *not the essence* of dynamic programming. This step is after all pretty mechanical. Okay, things are getting pretty "indexy" now. What about the solutions? Both `minEdit` and `conquer` actually sidestep this question and only return the minimal score. The solutions would be the "minimum tape of edit instructions" or something I guess. But how to best represent it? That is the point where I am "stuck" in the sense that I keep making lots of mistakes. For instance I might define an ADT like data Edit = Delete | Insert Char or data Edit = DeleteAt Int | InsertAt Int Char but while I can literally "calculate" `conquer` from `minEdit`, trying to return a `(Int, [Edit])` for instance is already pretty hairy because of all the indexing involved. For the naive "pattern matching" representation, I find this somewhat easier, but then when doing the conversion to index-land I goof it up again.
would be interested to see benchmarks of, say, a factorial function in formality
Hi all, Just wanted to share this with you. I was quite pleased with how it turned out. Brick is surprisingly easy to work with - the layout engine it uses is very familiar and easy to get to grips with. It only took a couple of hours before I was using it as naturally as any other layout system. The code for this project is not exceptionally *good*, but it does work and there's easy scope to tidy it up. Something in particular that I think could be neater would be the random number generation for the `shuffle` and `pick` functions. If anyone has suggestions on a better way to thread randomness through the game, I'd be happy to hear it!
`fact` uses constant space. This program computes `fact(1000000)`: ``` inf fact1m: init: &amp;(1, 1) step: get &amp;(i, n) = self get &amp;(j, k) = cpy i &amp;({j + 1}, {n * k}) stop: {fst self == 1000000} done: snd self ``` You can see the space it uses with `fmc -s fact1m`, `maxlen == 11`, thus it never allocates more than 11 nodes of 128 bits each. Note that `inf` is extremely slow right now, since it compiles and decompiles the term on each iteration of the loop. We can't measure speed on it right now, but it should be soon be implemented properly in our C runtime. It uses roughly 12 graph rewrites per iteration of the loop.
Thanks! Let me know if you have any question!
I'm glad to hear that you found Brick easy to work with. Cool application, thanks for sharing!
As far as the UI is concerned, my feedback is: use more colors, and try out `joinBorders`! :)
I'm a huge fan of love-letter, so thank you ;) I've opened a PR to fix a small issue I had when building your code. Note: for nix users, it works directly using: \`\`\` nix run '(with import &lt;nixpkgs&gt; {}; haskell.lib.dontHaddock (haskellPackages.developPackage { name = "love-letter"; root = fetchTarball [https://github.com/dixonary/hove-letter/archive/master.tar.gz;](https://github.com/dixonary/hove-letter/archive/master.tar.gz;) }))' -c love-letter \`\`\` I'm impressed that this can build the game in less than 10s as long as you have a fast enough internet provider.
Colors was the very next thing on the list! I've actually used the `ansi` package before and found it very easy to slot in. So that's definitely not a high effort thing :D It'd be super easy to just modify the "show" command for Player and Card to add in Ansi colours!
Thank you! I will take a look at the PR now.
Stay tuned, I'll probably end up using it for more apps/games in the future!
What's the `ansi` package? I don't see a package with that name on Hackage. Unless it uses `vty` under the hood, you won't be able to use it safely with Brick. You'll need to use the Brick/Vty attribute management API instead. As for joinable borders, see [the User Guide](https://github.com/jtdaugherty/brick/blob/master/docs/guide.rst#joining-borders).
Once this is further along you might consider making a screencast of the game in action. Also, for this game and others you make with Brick, I'd be happy to add them to the [Featured Projects list](https://github.com/jtdaugherty/brick#featured-projects) once you're interested in advertising them more broadly. I'm also happy to share them [on Twitter](https://twitter.com/brick_haskell/).
Oh, hold on, I think i'm getting my `ha*` languages mixed up. I think I had previously used the `ansi` package for Haxe, not for Haskell. D'oh. I used it to make [this rather lovely text adventure](https://github.com/dixonary/ansi-adventure). When you go into some rooms (for example, a sewer) it plays particular effects, like water going up the screen. If the water reaches the top of the screen, you have run out of time and you die.
Thanks! Honestly it's almost ready to be called "done" from my perspective. Just a splash of colour :)
&gt; If we think of the average Haskeller, who do we see? A poor, broken person. Tired head falls into the open palms, sobbing, deprived of the basic human right for [...] That's not how I see Haskellers, and I nearly closed the article there.
Sounds like an interesting point in the design space! &gt; the layout of the input influences the layout of the output It seems as though this would prevent my primary use case for Brittany (and any code formatters I've used in other languages): bashing out code without a care for the formatting and relying on the formatting tool to make it pretty and consistent with the rest of the codebase. Perhaps more generally it would be correct to say that although this tool will make code neat and readable, it will not help make the codebase consistent; I imagine that this is a common reason for people to use code formatters in the first place.
The nice thing is that using the fancy borders doesn't require any change to your layout. You just wrap the whole thing in a call to `joinBorders`.
Well, I found it funnny
This is interesting. `hindent` will need to be rewritten with GHC's AST if it is to have a future, but that undertaking is tantamount to simply rewriting the whole project. The only thing that would be left would be the test suite and a few combinators and types. I won't be implementing this, ever, so `hindent` will need to be sunsetted in a couple years, once the endless march of GHC syntax accrues enough new things for hindent to be impractical. After using hindent every day for the past 5 years since it was first made in 2014, I do stand by the decision to automate all layout, because part of the UX of hindent is that you can write lopsided code like this example and then hit a key and have hindent normalize it for you. That makes it more convenient to lazily type out code and copy/paste code around, and then it all snaps into place again. To use `ormolu` as my daily worker I'd have to patch it to do this. For example, [these examples](https://github.com/tweag/ormolu/blob/5f746eec919d17b7e684fc8367404a8177e92756/data/examples/declaration/value/function/case-multi-line.hs) show code that hindent would reformat automatically and I'd be anticipating that. Line 9 and line 14 are problematic because they create a dependency between the length of the pattern on the left, and the multiple lines on the right-hand-side, so they need cleaning up anyway. I'm happy to see they are going for one style. It would be nice if it re-used [the test suite cases of hindent](https://github.com/chrisdone/hindent/blob/master/TESTS.md) to (1) make sure it's tested funny edge cases, and (2) just use the same style because the world doesn't need another slightly different style. It's nice to have a GHC based one that's less like brittany which emphasises personal tastes. Regarding the dev, you are facing an thankless experience like the Battle of the Bastards to fill out all those cases. It's wise to try to crowdsource the effort at a hackathon.
I read that as tongue-in-cheek, considering it's talking about source code formatting. The joking tone was solidified with this bit: &gt; It's still vaporware, but that's just a bug we're a long way into fixing
I think the main purpose of formatters is to make code formatting universal across code base. But with the approach that considers initial formatting we still get different code style if several programmers with different initial code style work on the same project.
I agree with you. I like formatters that always give the same output for a given AST, regardless of how it was originally formatted. That being said, both gofmt and elm-format work this way and people seem to like them. They provide some degree of consistency while allowing people to make bigger-picture formatting decisions, like "should this be on one line or not".
Agreed. I want a formatter to do all the work for me. I'm also curious which syntax will influence layout and which will not. Do line breaks in all syntax remain or only some?
The dynamorphism is the tabulation approach; a chronomorphism can be used instead with similar efficiency. Basically, You have a coalgebra that generates your graph of sub-problems -- be sure to share common problems or performance can become exponential. Commonly use use a coalgebra like you would for a futumorphism, because generating multiple unfolds simultaneously can help with the sharing, or just be more direct. You have a algebra that solves one sub-problem in terms of the results of all it's sub-problems, and in addition to the "main solution" also records which sub-problem(s) were most relevant. So, not a simple algebra but one like you would use in a histomorphism, if you just looked a single step backwards, you'd be a greedy/hedonistic algorithm; having access to an arbitrary sub-problem is required in order to be doing dynamic programming. When you get the final solution out of this sort of generalized hylomorphism, if includes a chain of relevant sub-problems and if you walk it / force the spine that is the backwards pass.
I actually did that already :) It's in the latest commit &amp; release. Thanks for the tip-off!
The only thing that influences the output layout are linebreaks in an expression: if it is single line, it will remain in a single line; if it is multiline, it will be formatted using multiple lines, in a defaut way. That is, if you have one or three line breaks in the same expression, the output will be the same.
What if I need a number of elements that isn't 2^h - 1? If I don't ever read from the tail will it simply not be allocated?
I just used the browser HTML inspector and saw the sarcasm tags, then I laughed.
Is it available online. From India and badly need a course in Haskell and functional programming
Just fyi, I've seen math textbooks and teachers go both ways. Applying functions *to* values is the most common terminology in my experience but there's plenty of people who talk about applying a value to a function. I thought an example might help clarify what everyone's trying to say to OP. Here's what I think OP means by "dragging" `IO` throughout the code: ``` -- This function got roped into IO because it needs -- to work on an IO ByteString but doesn't do any IO. whateverFun :: IO ByteString -&gt; IO MyType myPrintTextFun :: IO () myfun :: String -&gt; IO ByteString -&gt; IO MyType myfun "command" p1 = myPrintTextFun &gt;&gt; whateverFun p1 ``` Here's what people are suggesting OP does instead: ``` whateverFun :: ByteString -&gt; MyType -- No IO in the body so no IO in the type. myPrintTextFun :: IO () myfun :: String -&gt; IO ByteString -&gt; IO MyType myfun "command" p1 = myPrintTextFun &gt;&gt; whateverFun &lt;$&gt; p1 -- "fmap" over p1 because it's a monadic value. ``` And you can actually take this a step further: ``` myfun :: String -&gt; ByteString -&gt; IO MyType myfun ""command" p1 = myPrintTextFun &gt;&gt; return (whateverFun p1) ```
Alice used a King to swap cards with herself! I don't think that's a legal move, is it?
It's the last link of the comma 2 here: [https://github.com/kowainik/relude#relude-vs-protolude-](https://github.com/kowainik/relude#relude-vs-protolude-), "Tutorial + migration guide" [https://imgur.com/a/gE1pOuT](https://imgur.com/a/gE1pOuT)
&gt; Regarding the dev, you are facing a thankless experience like the Battle of the Bastards to fill out all those cases. I adore that GoT references are reaching idiomatic quality. Though it escapes me what this particular idiom is meant convey.
I played a Guard and picked a random player, thinking it didn't matter, but I had forgotten that Alice was immune, and so nothing happened. Is that legal? I thought I had to pick a non-immune player if any non-immune player is available. That might matter for e.g. the King, if I have to play the King but I don't want to switch cards with anyone, I could pick an immune player in order to keep my other card.
Very interesting. Thanks for the explanation! I very much appreciate it.
You're right. Now that I have implemented immunity slightly differently it would be quite easy to exclude immune players from the list. There were a couple of "simplifying" changes to the rules that I made just to keep it simpler - for example that you can discard the Countess but you immediately lose, rather than being unable to. If you fancy submitting an issue on GitHub, I'll modify the program to faithfully implement the rules shortly :)
Good spot! I copied the Prince logic to the King. The Prince explicitly allows picking yourself. Whoops :)
This does not replace the Racket version. I just added the following to the README: &gt; I wrote this implementation so that people who know Haskell but not Racket would be able to read it and understand how the internals work. This one is probably not as nice to experiment with and/or use as the version written in Racket, as that version has many useful features in DrRacket, including tooltips on every expression showing its type, a pop-up list of TODOs, arrows from variables to their binding sites, auto-indentation support, "go to definition", and automatic renaming of variables. This version is just a batch-mode type checker and REPL. Basically, I'm teaching a class based on the book at PSU right now, and the students there know much more Haskell than Racket, so I wanted to do the implementation work in Haskell. This necessitated a version to point at.
I dispute the premise here. Which formatters actually in widespread use today are pure functions of the ast?
I'm a big fan of `rerebase` (or `rebase` if you don't want an implicit Prelude replacement). It re-exports everything I would consider "standard modern Haskell", and the dependency list is mainly what would end up in your transitive dependencies anyway for nontrivial work.
Let me know if you get this going. MY US Grant is waiting. Best wishes, Henry Laxen
One little refactoring you could do concerning your shuffle/pick functions is to use the state monad instead of manually returning a tuple with the updated stdgen. Basically, the state monad is implemented as `s -&gt; (a, s)`, which is exactly the same as the type of both of your functions!
I was thinking about State. But given that in each instance it is only used once, it seems like the State monad would just be an extra layer of packing/unpacking?
Not Haskell, but [black](https://github.com/python/black) doesn't seem to care about initial formatting. I've been using it for some time and really like this aspect of it.
This seems to be very similar in design to elm-format! Contrary to most other voices in this thread, I really love this style of formatter. I experienced I need to fine-tune code density to match its complexity. This is something I cannot configure using a config file and that cannot be measured by a tool automatically.
Also \`find -name '\*.so' | xargs du -hs | sort -h | less\` in the .stack directory seems to be useful.
it's implemented with newtype so it's the same memory wise
I would not recommend using a nonstandard prelude. It adds another dependency, often without a good reason. Lots of standard Haskell libraries break cross-compilation (which is probably not needed with web development, but should be considered).
Thanks for the recommendation. There was a series of blog posts dealing with recursion schemes that has been on by TODO list for a while. Unfortunately the documentation for the `recursion-schemes` package is ... well there are blog posts. I find this frustrating though, since this mimics my experience of when I wanted to learn graph algorithms. There is just no way to sensibly learn the basics with Haskell, everything is expressed way more awkwardly and around the corner. In the end things (sadly!) are way easier if you just use an imperative language, at least for learning.
&gt; if you try to use it in a somewhat complex Cabal project (either directly, or because someone else depends on your library from a Cabal project Some of my projects don't work with `stack`, FWIW. Or at least they don't work with `stack init` - since there's no dependency solver you'd have to manually override everything.
What do you mean by that? As opposed to lexing and inserting/deleting whitespace?
Sure, but in terms of code wouldn't it just end up adding runState to the right hand side, and change the signature of the functions, but otherwise be the same? Basically just a renaming rather than a simplification? Not a criticism, just trying to work out how to simplify the code :)
[removed]
Like /u/ephrion (I think) suggests, introduce another type parameter: data Post f' f = Post { body :: f String , author :: f (User f' f') , ... } I've been experimenting with this technique for ASTs, and it appears to work. My intention is to eventually release it as a library that depends on [rank2classes](http://hackage.haskell.org/package/rank2classes) and adds similar functionality for deeply nested heterogeneous trees.
On the lazy evaluator (removed after the introduction of ints, but will be re-added soon), yes, it won't ever be allocated. On the strict (parallelizable) evaluator, it will be allocated. As long as you keep the number of elements from 2^h to 2^(h+1), it should be worth it due to parallelism. If you really don't want to waste that space, you could use a different array implementation, since this is a limitation of this lib in particular.
You probably mean `data Post f' f = Post { body :: f String , author :: f' (User f' f) , ... }` So that uninteresting fields are held in an `f` and interesting ones are held in an `f'`. But it's more general if `f'` gets to specify what future `f'`s and `f`s are, but that requires a type/data family.
&gt; it's finite vs infinite I'd say this is induction vs coinduction. The difference between data and codata is that data is defined by how you can construct it, whereas codata is defined by how you can destruct/observe it. Other people pointed out that indeed there this property of codata of being characterized by observations seem to suggest similarity with objects in OOP.
You're right haha, I didn't see Main.hs. It would be kinda just a renaming in that case since you just put everything in your Game data type anyway and you're not really using monad for that (which is fine)
`prettierjs`.
Stack on windows comes with msys already, so you can remove chocolatey and msys from it - it will probably cause issues with libs. Run `stack exec bash` and try `pacman -Ss pcre` to see if there any packages for libpcre
Ok I've now tried to install libpcre with msys via stack and it's still giving me the exact same error message.
No, I don't distinguish between interesting and uninteresting fields, but rather between shallow and deep fields. That lets me map, fold, or traverse through all the fields in the tree, even though they belong to records of different types.
Try checking if there is a `-dev` version of package and also check a github wiki of haskell-gi package - there are some useful recommendations on setting up native dependencies on windows. You probably need to setup a xdg data dir env var to make pkg-config detect pcre lib
ok now I've used pacman in choco's msys2 and stack's msys2 to install each of the following \- pcre \- pcre2 \- pcre-devel \- pcre2-devel \- libpcre still to no avail :(
Did you follow instructions from haskell-gi wiki to add env vars?
Wait, sixth-order functions? My mind is blown! Where are those encountered?
I did, adding the PKG\_CONFIG\_PATH environment variable and setting it to the location of the pkg-config install worked. How on earth is someone supposed to know to do that? I've been searching for answers for hours and there's nothing that even remotely mentioned it prior to you.
Shallow fields are in `f` and deep fields are somewhere in `f'` in my example. If you want deep fields to be in `f'` inside of `f` you're starting down a path that ends in a type/data family, since you'll need another `f''` for an even deeper field.
Welp, on Linux you get all of this preconfigured mostly. But when you trying to bring Linux mechanisms to Windows you have to make some efforts. Regarding "how on earth is someone supposed to know that" - developer have to know his tools. I'm sure documentation have a section on this variable. It's just, as I said, preconfigured most of the times, so people rarely have to know that.
https://dl.acm.org/citation.cfm?id=969615 Parser combinator transformers. :)
Actually, now I'm building successfully but when I try to open ghci I get this: &amp;#x200B; &gt;GHCi, version 8.6.5: [http://www.haskell.org/ghc/](http://www.haskell.org/ghc/) :? for help &gt; &gt;ghc.EXE: Could not load \`libpcre-1.dll'. Reason: addDLL: libpcre-1.dll or dependencies not loaded. (Win32 error 126) &gt; &gt;ghc.EXE: panic! (the 'impossible' happened) &gt; &gt; (GHC version 8.6.5 for x86\_64-unknown-mingw32): &gt; &gt;loadArchive "C:\\\\tools\\\\msys64\\\\mingw64\\\\lib\\\\libpcre.dll.a": failed &gt; &gt;Please report this as a GHC bug: [http://www.haskell.org/ghc/reportabug](http://www.haskell.org/ghc/reportabug)
Not sure, but looks like this is an issue with libs because of multiple msys installations I mentioned in earlier message. Try removing all msys installations except one that came with stack
No. See https://github.com/blamario/grampa/blob/master/deep-transformations/src/Transformation/Deep.hs for the logic, and https://github.com/blamario/language-oberon/blob/master/src/Language/Oberon/ for some examples of its use.
This was indeed very helpful, and yes your example of what i meant by "dragging IO through" was correct. Since you mentioned fmap i might aswell ask another question if you don't mind. What's the exact difference between fmap and mapM - as far as i understand both - more or less - do the same by mapping a function over a Monad - only in fmaps case it's not a Monad directly but a Functor instead. What is one able to accomplish that the other isn't? This might be a stupid question but i thought i'd rather ask than stay stupid.
Are there any significant restrictions? Or, could I use something like Okasaki's RandomAccessList? Can I use these "imperfect" binary trees: data N = Z | P { p :: P } data P = E { p :: P } | O { n :: N } data Imperfect :: P -&gt; Type -&gt; Type where Leaf :: a -&gt; Imperfect (O Z) a Branch :: Imperfect p a -&gt; Imperfect p a -&gt; Imperfect (E p) a Tree :: a -&gt; Imperfect p a -&gt; Imperfect p a -&gt; Imperfect (O (P p)) a ? Also, do I get contiguous allocation? Either with the perfect trees or either of the two representations proposed above? Non-contiguous allocation can destroy performance because it reduce cache hits, even if it's doesn't alter the complexity class.
1. The only reason it stuck into my head at all is because I used it to plan my [Stardew Valley](https://en.wikipedia.org/wiki/Stardew_Valley) planting schedules, and it might have been a little bit of an overkill, but it felt necessary at the time. 2. I too wish there were more algorithmic material that didn't assume in-place mutation of a reference cell was constant-time and a primitive operation. I mean, they effectively are both, even in Haskell, but we try to mostly program with immutable values instead of reference cells. Still, never be afraid to whip out ST, STM, or MVar/IORef if they feel natural to the problem; Haskell makes it easier that any other language to refactor that later.
By the way, I re-added the lazy evaluator. You can notice the difference by entering the `/examples` directory and typing: fmc -s array_example &amp;("arr[0] + arr[1] + arr[2]:",30) {"rewrites":135747,"loops":16178,"max_len":65931} fmc -l array_example &amp;("arr[0] + arr[1] + arr[2]:",30) {"rewrites":3609,"loops":7466,"max_len":1104} The lazy evaluator outperforms the strict evaluator on the array example by 100x, since it doesn't need to allocate all the array (after all, the output only depends on the first 3 elements). &gt; Are there any significant restrictions? Or, could I use something like Okasaki's RandomAccessList? Any structure from Okasaki (and any algebraic datatype) can be expressed in Formality through Scott encodings. I will still put up some guides on how exactly ADTs and algorithms on them can be translated to Formality, but [here](https://gist.github.com/MaiaVictor/6de946cf9c17c09a2ccaf7a9348c43ea) are some simple examples of porting datatypes and pattern-matching. Recursive algorithms rely on Church Nats for setting a bound on the number of recursive function calls, see the `term_fold_f` on [this](term_fold_f) file for example. &gt; Also, do I get contiguous allocation? This would probably be implementation dependent, I'm not sure how those trees are layered in memory on my current implementation. Perhaps yes, but possibly not, and, in any case, this should be improved as there is much work to do on the compiler side.
A short answer is that ormolu should be substantially smaller and it needs a simpler implementation because it doesn't search the space of possible layouts of the code. There is some more discussion of this in [https://github.com/tweag/ormolu/blob/master/DESIGN.md](https://github.com/tweag/ormolu/blob/master/DESIGN.md)
I agree with everything you’ve said, and you’re probably aware of this, but just in case, for your java 8 example you can do orElseGet(() -&gt; getThing()) Which will only execute `getThing()` if the optional is non-empty.
`mapM` is like `fmap` but in monadic context, so instead of mapping `a -&gt; b`, as you do with functor, you map an `a -&gt; m b` over a `[a]` for example. The type signatures will probably give a good indication in how they differ: `fmap :: (a -&gt; b) -&gt; f a -&gt; f b ` `mapM :: (a -&gt; m b) -&gt; t a -&gt; m (t b)` When mapping over a list of `Int`s, and the monad being IO, this would make the example more concrete into: `fmap :: (Int -&gt; b) -&gt; [Int] -&gt; [b]` `e.g. fmap show [1, 2, 3] == ["1", "2", "3"]` `mapM :: (Int -&gt; IO b) -&gt; [Int] -&gt; IO [b]` `e.g. mapM print [1, 2, 3]` would print "1", "2" and "3" to the screen, and then return [(), (), ()]
&gt; The difference between data and codata is that data is defined by how you can construct it, whereas codata is defined by how you can destruct/observe it. Isn't that true of induction vs conduction though? I'd argue that a data type like data InfList a = More a (InfList a) is defined by how it is consumed rather than how it is constructed.
I tripped on that joke too — but glad I kept reading. I'm a Page Downer instead of Closer :)
You've got a lot of recommendations already, but let me answer your question outright. No, using a replacement for the Prelude is not "standard practice". By a fair margin, most Haskell code uses the normal Haskell prelude, and you are not doing anything wrong if you follow suit. At the same time, custom preludes are not weird. A sizeable minority of people do use them. There are a few good arguments for using a custom prelude: the standard prelude makes very poor choices with built-in types like `String`, and includes partial functions that can throw exceptions without help from the type system to avoid them, etc. (There is a wing of the Haskell community that feels very strongly about partial functions, especially, and will go to great lengths to avoid them. If you are in this camp, a custom prelude will probably look really good to you.) But whatever your motivation, there are costs: (1) you're building your knowledge and experience around a fragmented corner of the Haskell ecosystem, and you're stuck translating practices between your chosen corner of the ecosystem and its common types and such, versus everything else, and (2) while the custom prelude will be better in some ways, it's also less likely to be thoroughly maintained, since far more people are using the standard prelude. These are things you should weight against the benefits. Personally, when I teach Haskell, especially to children, I do so with a custom prelude (and a lot of other language customizations). But when I write my own Haskell in production, I stick with the standard prelude.
&gt; Handling of comments is dealt with implicitly by the rendering combinators Would love to read about how this works!
Thanks! Fixed.
Is this just for expressions? If I put a `where` on a separate line in an instance declaration, will it stay there? How about for `data` declarations?
It's definitely my favourite FRP library. I think the way it handles event streams needs a bit of work, but I recently had some thoughts as to how to fix that.
[Lens](http://hackage.haskell.org/package/lens)
Try https://haskell-miso.org on your phone. Or https://www.polimorphic.com
Cons is the list Constructor (hence the name). In Haskell that’s usually denoted by a colon (:), and Nil is the empty list, or [] in Haskell. If you want to follow the code from the paper you might want to define your own List data type: data List a = Cons a List | Nil As for your next question, what’s the problem with the input being a Node, and the output being a List? The set of inputs and the set of outputs need not be the same.
`Cons` and `Nil` are data constructors for lists. E.g. the list we'd usually write as `[1,2,3]` is actually just syntactic sugar for `Cons 1 (Cons 2 (Cons 3 Nil))`. `Nil` is the empty list, while `Cons` takes a single element and prepends it to the start of another list. Note that this is just the syntax adopted throughout the paper; the built-in list type in Haskell uses the infix `:` instead of `Cons` and `[]` instead of `Nil`, so the above example would be written `1 : (2 : (3 : []))`. `Node`, on the other hand, is a data constructor for trees. Lists and trees are different types, so their constructors can't be used interchangeably. The function being defined takes a tree as input, but produces a list as output. Lists may be nested arbitrarily, but they're still constructed by `Nil` and `Cons`. E.g. the list of lists of numbers `[[1,2,3],[4,5,6]` is actually represented by: Cons (Cons 1 (Cons 2 (Cons 3 Nil))) -- the first sublist (Cons (Cons 4 (Cons 5 (Cons 6 Nil))) -- the second sublist Nil) So in `mapmin (Cons nums rest) = ...`, `nums` is the first sublist of a list of lists, while `rest` is a list containing the rest of the sublists.
Thank you! Great help!
Just import a la carte. If you find yourself importing (or hiding from Prelude) the same things often, make your own little Prelude module in your project - basically re-export a parched Prelude.
I think you are tripping over the difference between type-level and term-level things. `Cons` and `Node` live at the term level, `ListOf` and `TreeOf` live at the node level. Part of the confusion might stem from how Hughes leaves out the explicit type declarations for the functions involved here, as well as the type definitions themselves. We can infer that the types are something like: data ListOf a = Nil | Cons a (ListOf a) data TreeOf a = Node a (ListOf (TreeOf a)) -- classic Rose Tree Note that the `ListOf` type is exactly isomorphic with Haskell's built-in list type, it just uses normal data type syntax instead of Haskell's list sugar. To make it a bit more obvious, here are the equivalencies of the isomorphism: - `ListOf a` &lt;=&gt; `[a]` (type-level) - `Nil` &lt;=&gt; `[]` (term-level) - `Cons x xs` &lt;=&gt; `x:xs` (term-level) - `Cons a Nil` &lt;=&gt; `x:[]` or `[x]` (term-level) - `Cons a (Cons b (Cons c Nil))` &lt;=&gt; `a:b:c:[]` or `[a,b,c]` (term-level) - `ListOf (ListOf a)` &lt;=&gt; `[[a]]` (type-level) Hence, the types of the functions involved here can be inferred as: maximize0, minimize0 :: TreeOf n -&gt; ListOf n map :: (a -&gt; b) -&gt; ListOf a -&gt; ListOf b minimize, maximize :: TreeOf n -&gt; n min, max :: ListOf a -&gt; a mapmin, mapmax :: ListOf (TreeOf a) -&gt; ListOf a So, to answer your questions: &gt; The first Question is that what is "Cons n Nil" in the first line? `Cons x xs` is a list constructor that constructs a list consisting of a first element `x`, followed by a list `xs`. This is how you would typically implement a linked list in functional programming: a reference to the current item, and a reference to the rest of the list. `Nil` is the empty list, so `Cons x Nil` is a singleton list containing the single element `x`. You could read it as "cons(truct) a list where the first element is `x`, and the rest of the list is the empty list". &gt; Why the input of the function is Node and the output of the function is Cons? `Node` is the only constructor of the `TreeOf` type; `Cons` is a constructor of the `ListOf` type. Since `maximize0` is a function that takes a tree and returns a list, we expect the argument to be a `Node` constructor, and we must return one of the list constructors, either some `Cons` or `Nil`. &gt; why it can change? It doesn't really change; one of them (`Node`) is used on the input side of the function, the other (`Cons`) is used on the output side. &gt; The second Question is that in order to implement the pruning, the mapmin is needed to redefine as the function below, but when the parameter seems very weird. From my perspective, its type should be a list of lists of number. Almost. `mapmin` maps the `min` function over a list; because `min` already expects a list of numbers, `mapmin` must take a list of list of numbers: `ListOf (ListOf Number))`. In idiomatic Haskell, one would write `Ord a =&gt; [[a]]`, because we're not actually interested in the precise type, or even it being a number type, all we need to know that it supports comparison / ordering, which is what the `Ord` typeclass captures. &gt; And the "cons" come again, can I replace it by Node?? Absolutely not, that wouldn't make sense. `Cons` belongs to `ListOf`, `Node` belongs to `TreeOf`. Since we're mapping over a list of lists here, there is no place for trees.
Small correction, it's "data List a = Cons a (List a) | Nil"
Haha thanks! I was typing on the phone and that completely slip by.
Just a quick remark: minimize :: Rose a -&gt; a maximize tree = max.minimize' tree The compiler will complain that `minimize` doesn't have an accompanying definition - it's because you forgot to rename the definition's name. Also you might want to fix the formatting of the bottom half of your post, currently some code isn't rendered as code.
How about these aspects: * A module system is program that is evaluated (or: elaborated) at compile time? Module expressions yield new modules. This could be also relaxed to permit modules being created at runtime - now leading to even more interaction with the core language. * Separate compilation: can modules be compiled independently and the results be linked?
Just saw ryan published another blog-post!
[removed]
Thank you! I'm very bad at Reddit, so this is hugely appreciated \^\_\^
There's an open issue for this at [https://github.com/i-am-tom/higgledy/issues/4](https://github.com/i-am-tom/higgledy/issues/4), and I think [/u/NihilistDandy/](https://www.reddit.com/user/NihilistDandy/)'s approach is the one we settled on. It is, unfortunately, not quite as pretty, but we can write a type synonym and forget, for the most part, about the scary things behind it. &amp;#x200B; Another approach of which I'm quite fond is defining an f that is more domain-specific, such as \`data Present a = Missing | Present a\` and saying \`\_ &lt;&gt; Present a = Present a; x &lt;&gt; Missing = x\`. It's a very rough example, but I hope it makes sense!
There's an interface for transforming in and out of the HKD shape - \`Applicative f =&gt; HKD MyType f -&gt; f MyType\` and \`Applicative f =&gt; MyType -&gt; HKD MyType f\` :) It's unfortunately about as good as we can get without more syntax sugar around records, but it's useful enough if your \`f\` is something like \`Validation\`, for example!
Tweag continues to write the things I'm about to write! &gt;In Ormolu, the layout of the input influences the layout of the output. I was going to write a formatter that had exactly this property. As pointed out in this thread, it's the behaviour `elm-format` has, and I believe it's the correct way to do this.
Looks like there is a fresh [paper](https://www.microsoft.com/en-us/research/uploads/prod/2019/03/ho-haskell-5c8bb4918a4de.pdf) detailing the concepts (with the `-&gt;&gt;` arrow).
WOW, thanks to your specific and understandable answer, I totally understand what I have mixed up. THANK YOU VERY MUCH!
Another possible representation is to add the identifiers to the original tree structure: data Tree0 i a = Node i a [Tree0 i a] | Leaf i a type Tree = Tree0 () type TreeI = Tree0 Id -- invariant: Trees are uniquely Id-entified. newtype Id = Id Int deriving (Eq, Ord) dedup :: Ord a =&gt; Tree a -&gt; (Seq (TreeI a), Id) That way once you get hold of a single `TreeI` node, you get direct access to the whole subtree below it, without additional table lookups, but the common subtrees are still going to be shared (which is the point of hashconsing).
That's true, that might be more convenient to use after the result of dedup. It doesn't really solve the problem of how to dedup the structure to begin with though. I am hoping to be able to construct `Tree` objects in any old way, without having any guarantee that things are deduplicated but with a healthy amount of natural duplication, and then compress the result into a `TreeI` for serialization. It's possible to try keeping it deduplicated the entire time, but that means putting everything in a monad so I can remember what's been constructed so far, and I can't just use the `Node` constructor freely.
&gt; The project aims to implement one “true” formatting style which admits no configuration. That's a complete deal breaker for me. I like almost all of the way this formats, but that point means that the tool is completely worthless to me unless I want to take every single one of its rules.
As I understand them, induction vs coinduction boils down to least fixed points vs greatest fixed points. Perhaps there is a relation with constructors vs destructors, but it's not immediately evident IMO. Also data types are not necessarily inductive (and respectively codata types) so I'm not keen on identifying the two concepts.
That `TreeCursor` definition looks overcomplicated. Perhaps it could be simplified with some recursion: data TreeCursor a = TreeCursor { siblingsAbove :: [Tree a] -- in reverse order , treeCurrent :: Either (Tree a) a , parentCursor :: TreeCursor a , siblingsBelow :: [Tree a] } deriving (Show, Eq, Generic)
Oh I see, if you are primarily interested in serialization then what I said is quite orthogonal to that. # Compression There's a neat description of the hashconsing algorithm as a recursive traversal: at every `Node`, compress its children, resulting in a `TRNode`, and then check whether it's already been given an identifier. So you need to keep track of a `Map (TreeRef a) Int` to look up identifiers of compressed nodes. -- Omitted the actual compression result (Seq (TreeRef a)) lyophilize' :: Ord a =&gt; Tree a -&gt; State (Map (TreeRef a) Int) Int lyophilize' (Leaf a) = hashcons (TRLeaf a) lyophilize' (Node a ts) = do ts' &lt;- traverse lyophilize' ts hashcons (TRNode a ts') In fact it's a pretty general catamorphism, which can be written with the recursion-schemes library: type Ref tree = Base tree Int lyophilize_ :: (Recursive t, Ord (Ref tree), Traversable (Base tree)) =&gt; tree -&gt; State (Map (Ref t) Int, Int) lyophilize_ = cata (\t -&gt; t' &lt;- sequence t -- compress subtrees ("cata" makes the actual recursive calls, and 'sequence' "folds" them together like traverse does above) hashcons t') Or in one line: lyophilize_ = cata (sequence &gt;=&gt; hashcons) # Decompression The other direction is even shorter. Starting from a sequence of compressed trees `Seq (TreeRef a)`, we decompress them *all at the same time*, with `fmap`. How does that work? The decompression function for a single tree (`water`) can first see a constructor, `TRLeaf` or `TRNode`, which maps in a straightforward way to `Leaf` or `Node`. As for the children of `Node`, we look them up in the final table of decompressed trees, which we are in the middle of building! It's fun to think about this like time travel: you can see what the future holds, but of course you must not look directly at your own actions to avoid a causality loop. hydrate :: Seq (TreeRef a) -&gt; Seq (Tree a) hydrate dry = wet where wet = fmap water dry water (TRLeaf a) = Leaf a water (TRNode a ts) = Node a (fmap (Seq.index wet) ts) This is also generalizable with recursion-schemes: hydrate :: Corecursive t =&gt; Seq (Ref t) -&gt; Seq t hydrate dry = wet where wet = fmap water dry water = project . fmap (Seq.index wet)
&gt; I think that some form of reference equality is required to avoid accidentally unfolding the input DAG into a tree An ordinary depth-first traversal of the input will only hold one path through the tree at a time. So, you don't need to worry about accidentally expanding the whole thing at once. You only need to look for something fancier if the tree is too large to fit even a single path through it in memory.
That's true, DFS traversal will not blow the stack... but it will still take exponential time unless care is taken to not revisit the same node many times.
Very cool! Are you using a particular `hashcons` implementation there? Seems like that's the magic sauce I need.
It will take proportional time to the number of nodes in the tree. This is the best you can do without pointer comparisons, because you *can't* take care to not revisit the same node. The input format simply does not allow it except by "cheating" and looking at pointers. If looking at each instance of each node once is unacceptable, then you can be sure you will be unsatisfied with any answer to your question except "well, look at the pointers then".
Agreed. I use Jetbrain's Webstorm with typescript and the auto-formatter partly depends on the input. It's a lovely balance where it does most of the work but I can give it hints by adding and removing a few new lines here and there. It's completely idempotent as far as I can tell.
Oh, I know that. That's why I said "I think reference equality is required". But there are plenty of impure things wrapped into abstractions in Haskell, and I'm hoping there's a package for this use case so I don't have to handle the pointers myself.
It's nice to be opinionated and not require configs. But it has to be a *good* opinion :-) Please 4 space indents! 2 spaces are a recipe for word soups and in larger functions become very unreadable. Also, code like: .... =&gt; Type -&gt; Type Is nice for alignment. But: the function-arrow is adjacent to the result type, when it is more "related" to the parameter. `=&gt;` makes more sense with the constraints, than with the type.
This is a DFS traversal dressed up with recursion schemes, and the elided `hashcons` is just the obvious map lookup you could write yourself.
Ah, I forgot a link to a gist: https://gist.github.com/Lysxia/b3d62a248b7eeb2b7a1df59a0dd5cc9b `hashcons` does a `Map` lookup, and if it doesn't find anything it generates a fresh identifier for the input `TreeRef`. So it's again a fairly generic piece of code.
Could anyone explain to me why &gt;GHC can take the &gt; &gt;f a \~ f b &gt; &gt;constraint and *decompose* it to obtain the simpler constraint &gt; &gt;a \~ b should make any sense? Is it that proof of `f a ~ f b` necessitates `a ~ b`? To my limited brain `a ~ b` does not follow from `f a ~ f b` in general, but I could imagine that `f a ~ f b` be recognized in GHC only in cases when `a ~ b`, and thus we can treat it that way... but the logic feels flipped to me. Could anyone clarify what kind of witchcraft happening here?
This seems to go against amalloy's observation in the other thread - how can you avoid hitting all the nodes in the tree with this? As a concrete example of the kind of problem I mean: tangle :: a -&gt; Int -&gt; Tree a tangle a 0 = Leaf a tangle a n = let t = tangle a (n-1) in Node a [t, t]
I'm not sure in which context this usage arose (Coq? Twelf? LF? Earlier? Anyone know?), but I tend to think of the terms *parameter* and *index* as having a slight difference in meaning. In particular, the arity of a GHC type family/synonym as you've defined it is the same as "the position of its last index." It seems like "index" is related to the more general term *family*. * Parameters are arguments of a declaration/definition that it cannot scrutinize, only "pass around/rearrange" (ie it is *parametric* wrt them) * Indices are arguments of a declaration/definition that it can scrutinize ("non-parametric") So eg: every type to the left of an arrow in a family's return kind is necessarily a parameter not an index, since GHC enforces that the family can't match on it. I gave the distinction in terms of "can scrutinize," but you get a similar but different distinction in terms of "does scrutinize". Both can be useful. For example, a type family that does not scrutinize the last argument it can scrutinize is a candidate for eta-contraction, thereby lowering its (GHC) arity. The distinction can be useful in the contexts of type/data families/synonyms, type classes, and GADTs (others?). In particular, I remember being surprised when first realizing that the position of the :: in a GADT's kind signature does not determine which of its arguments are ("can") indices vs parameters. Thank you for such a thorough nice write-up; unpacking all this stuff publicly is such a community service!
This is true if and only if the type family is injective, which means that f a ~ f b implies that a ~ b.
I thought type families were not required to be injective in haskell. How does the definition of `d` know/communicate that `f` is injective?
"Writing a formatter is a never-ending battle of fixing edge cases". (Or "constant struggle") Programming tooling in general is a thankless task because it's something that "should work" how people expect it to, but everyone has different opinions of what expected behavior is. On top of that, when it works, nobody notices, but when it breaks expectations (doesn't even have to be actually broken!)...
D.A. Turner wrote a good paper on codata: [Total Functional Programming](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.364&amp;rep=rep1&amp;type=pdf) The above paper agrees with /u/gelisam's generally useful comments and observations.
/u/heisenbug mentioned the recent paper by Csongor Kiss et al. It goes into this is much more detail. My short Reddit-comment summary is: because they wanted this equality decomposition to be/continue being sound, GHC HQ limited abstraction at arrow kinds to data types/families, excluding synonyms/families when they added data/type families to the language. Kiss is introducing another arrow kind that is not limited in that way, so that it can abstract over synonyms — but you lose that useful rule. In short, "GHC currently ensures (eg by rejecting partial synonym applications) that type variables at arrow kinds can only stand for injective type constructors."
Is "Thiel Capital" the money backing this venture? Or is it just a random blockquote? Kinda curious where the money comes from.
Data families are injective by construction but usually type families and data families get lumped together. So "injective type family" == "data family".
You can use `-XTypeFamilyDependencies` to impose injectivity via a fundep-like notation.
Hurrah! Thank you stack devs!
Sorry, I was editing my comment, didn't notice your reply 😅.
[Apply to Galois.](https://galois.com/) [See my other post about the interviews.](https://www.reddit.com/r/haskell/comments/awyb50/galois_inc/ehs0hbe/) Not everyone here does Haskell, but a great many do, and many of those people knew zero Haskell when they got hired. We train people in Haskell at all levels, and we provide professional development and mentoring in a wide range of areas. I agree with others here: knowledge of Haskell is less important than software development experience.
I did continue reading. I personally like the idea of a formatter that follows my patterns, and just polishes them. But, in team environments, I think having "One True Style" and even going so far as limiting the number of configuration options for the formatter is probably better. Maybe I've just been using prettier.io and black to much recently.
Oh, you're right that doesn't have complexity linear in the compressed tree, I didn't understand that's what you wanted. I don't think that's possible, it seems that hashconsing would have to happen from the start throughout the lifetime of the trees.
&gt; def Tres: &gt; [Dois] [Tres] &gt; (Tres a b c) I think you are missing the bindings for `[a]` `[b]` and `[c]` there.
Punctuation-first is vastly preferred, we use it for `,`, `.`, `++`, `&amp;&amp;`, `+`, etc. we should use it for `=&gt;` and `-&gt;` as well. I actually prefer tabs for indicating indentation level, with single space half-indents for `where` and `pattern -&gt; expr` alternatives.
Punctuation first is indeed nicer in many ways, and I use it too for most of everything. Specifically function/constraint arrows get associated to the wrong place that way, though.
That’s the point. It doesn’t matter. It’s moot. Humans adapt fast. Humans are very good at changing their behavior. Humans are flexible.
This may help: https://hackage.haskell.org/package/base-4.8.1.0/docs/System-Mem-StableName.html#t:StableName
I mean all source that parses to the same AST produces the same formatted output. Apparently prettierjs does this?
hindent does this, but I don't know what you consider to be widespread use.
This will be an infinite loop when the lengths are equal
You may be interested in observable sharing: [http://ku-fpg.github.io/practice/observablesharing/](http://ku-fpg.github.io/practice/observablesharing/)
I meant to express sympathy, no judgement, but I ended my reply in the wrong way. Whoopsie. I agree that "One True Style" sounds right for a team. I want personalization in the opposite direction: my editor should use my pretty rules when it loads the file and the team pretty rules when it writes the file. Devil's in the details of course.
I think this [post](https://ocharles.org.uk/blog/guest-posts/2014-12-22-template-haskell.html) from 24 Days of GHC Extensions is a nice intro to Template Haskell. This [post](https://www.stackbuilders.com/tutorials/haskell/generics/) is a good intro to GHC.Generics. (Psst, it's Aeson, father of Jason, not Aesop from Aesop's fables :P.)
Do you mean Aeson? And you're wondering how it automatically derives the encoders/decoders with fields from your datatypes? https://wiki.haskell.org/GHC.Generics explains it well: &gt;Generic serialization &gt;First you have to tell the compiler how to serialize any datatype, in general. Since Haskell datatypes have a regular structure, this means you can just explain how to serialize a few basic datatypes. Since every data type has a regular structure, and sometimes writing instances (like JSON instances) is a pretty mechanical process, it's easy to tell the compiler how to mechanically generate instances for some classes. Generics gives the compiler all of the information to generate the things corresponding to your fields. You can see examples of it being used in the source: https://github.com/bos/aeson/blob/master/Data/Aeson/Types/FromJSON.hs#L923 They also have a Template Haskell way of generating them, but I'm less familiar with Template Haskell. Macro magic!
Thanks! And oh! One of the smarter names I've seen in a while. Lol.
That is very helpful. Thank you!
Indeed, thanks!
I was hoping you would get some good answers (since I'm curious myself) but since you haven't, I'll at least leave this here, which might be interesting. [Nike is using Haskell in AWS Lambda functions](https://github.com/Nike-Inc/hal).
Are you concerned with instruction reordering? Or are the notes about strictness what's leading to your question (that doesn't affect correctness)? I think the short answer is you shouldn't need to think too hard about this use case; if you do `write x to ioref, send ioref to thread T, read ioref in thread T` you should expect to see `x` (I think). GHC doesn't have a strictly documented memory model so you should assume things work as documented, else in a sensible way. That said it might be possible to send an IORef to another thread in such a way that you violate the expected serial ordering on x86, e.g. a sequence of nonatomic writes like: thread T is busy looping reading IORef A, thread U writes X to IORef B then writes B to IORef A. In that case it might be possible that thread T eventually reads Y after following both pointers, and in that case you might need to use explicit barriers (or atomic ops with implicit barriers). I'm not really sure. I would be interested if you can produce an example like this though.
This is an interesting comment. I am confused as to how it would work. Could you write out the value for the example in the blogpost?
My point was that nothing in the signature communicates the injectivity and it is just hardwired in GHC which to me sounds very counter-intuitive.
Black preserves single vertical spaces: def foo(): bar() baz() The space will stay here, even though this has the same AST as def foo(): bar() baz() I think in most programming languages, most people would be quite upset to lose single vertical spaces within functions. Haskell might be an exception though.
I'm concerned with cache hierarchy effects and probably also instruction reordering. GHC has no concept of "send IORef to thread T", so how could I ever trust that I will really see \`x\` in the other thread? The "send" could be very indirect. For example, both threads could have the same IORef in scope already, and one thread could tell the other by any means that it is done accessing the IORef. Did you mean to imply that when any information makes the way from thread A to thread B, that I can expect that any previous information must also have arrived at thread B? I don't think that's true, considering that CPUs can selectively invalidate cache lines.
I see better where you're coming from now. My point was that in the absence of proper docs or memory model spec'd out from ghc devs that if the scenario you described (writing to an IORef, in some way sending to another thread, then reading it) goes "wrong" that it's not your problem. But that's probably not very useful advice I suppose. Certainly though if you're sharing say two IORefs and your algorithm depends on ordered stores and reads then you will need to use barriers in some way (from atomic-primops). But yeah I guess better advice would be to program defensively in your own code. You can rely on atomicModifyIORef being a full barrier, since it's documented that way (iirc).
I think, some PHP and Python code formatters are pure. I also think both languages having recommended guidelines does help. On the other hand I do thing, we are putting too much brand/aestetics and not enough hard science (ergonomics/readability studies on large groups of devs at various levels of experience and familiarity)
I feel like I progressed somewhat, mind answering a few more questions? :) (asking here so that others can see your answers) I ask the first questions in the form of statements. 1) Bookkeeping = Tracking which fan-in belongs to which fan-out. Important for translating a graph into a lambda term and more importantly, for elimination of fans. 2) SIC is important since it gives theoretical properties that automatically apply to Lamping's algorithm. You can reason about combinators algebraically, which is neat, but is currently not relevant in your work. 3) Formality-Core is basically a calculus similar to lambda calculus with a few more restrictions and is able to be so efficient because you can translate its terms to interaction nets (which can be transformed by the abstract algorithm). 4) Now for an actual question: What do you mean by working on an interpreter: Just the practical implementation (+ fitting it into the existing project) or are the theoretical properties of the interpreter the main concern? 5) If I understood correctly, it would be an interpreter that interprets usual λ-terms, but is written in Formality-Core. I have written toy interpreters in university before. What would I need to know to write one that is of use to your work? Thank you for your time and work!
Yes there are some. I'm asking for examples of big codebases or at least *many* small codebases that use them. The most widespread example of forced style I've seen is e.g. gofmt, and even that is lenient with some things as I understand it.
I think it all depends on the last sentence of the IORef documentation: "An atomicModifyIORef is never observed to take place ahead of any earlier (in program order) IORef operations, or after any later IORef operations." I'm not 100% sure what the exact meaning of "in program order is". Would that really apply to a writeIORef (not atomicWriteIORef) in one thread followed by atomicModifyIORef in the other thread, to observe the effects of the writeIORef?
Aaah so mapM maps onto a traversable that's *inside* a monad - so it maps to the contents of the "content" of a monad - where the "content" is basically a traversable like a list or something, whilst fmap maps to the "contents" of a functor - where the contents would be elements - like your example with Integers in a list. Did i understand that correctly?
`A.letter` is of type `Parser Char`. `A.many'` is of type `Parser a -&gt; Parser [a]`, so here it returns `Parser [Char]`, aka `Parser String`. To get `Parser Text` you can use something like `A.takeWhile`.
That would be easier if you had explained what kind of `Tree` is the cursor for. Assuming it's the `CTree` from your library, I was thinking something like TreeCursor{ siblingsAbove= [], treeCurrent= 2, parentCursor= TreeCursor{ siblingsAbove= [], treeCurrent= 1, parentCursor= TreeCursor{ siblingsAbove= [], treeCurrent= 0, parentCursor= error "I didn't think of the root", siblingsBelow= [], siblingsBelow= [CTree 4 []]}, siblingsBelow= [CTree 3 []]}
Thanks for the feedback. I added a newline to emphasize the two separate definitions. Does that clear it up?
&gt; Haskell might be an exception though. Absolutely not. I frequently use extra breaks in monadic code, as well as between top-level definitions, for conceptual grouping.
The module you mention is certainly not part of RIO. Sounds like perhaps a bad template, but that has no bearing on RIO itself.
RIO is also a newer project by the creator of ClassyPrelude.
Yeah, I think that most libraries focus on AWS Lambda right now. If it's reasonable for your application you might want to check out that instead. There's HAL which was linked, I've also tried out and liked [https://github.com/seek-oss/serverless-haskell](https://github.com/seek-oss/serverless-haskell).
1) Right, it prevents a fan from interacting destructively with another fan from a different duplication process. 2) If you mean [this](https://github.com/maiavictor/symmetric-interaction-calculus), yes, it is basically a handy textual syntax to write symmetric interaction nets. I like it for the mind-blowing factor, it looks exactly like λ-calculus, except without closed scopes. 3) Exactly. There are two versions though, [EA-Core](https://github.com/moonad/Elementary-Affine-Core), which is what you described, and [Formality-Core](https://github.com/moonad/formality-core), same thing extended with native ints. 4) I meant a practical implementation, i.e., finding a technique to evaluate full λ-calculus terms on Formality-Core (thus EA-Core thus EA-Net) without losing much parallelism and sharing. Once we find a technique that works in practice, we can formalize it; that's how I do it, perhaps it is an engineering mindset? 5) To write interpreters in Formality-Core, in general, all you need to know is 1. how to write interpreters in Haskell, 2. how to translate Haskell to Formality-Core. The first one can be learned from literature, the second one is basically a cake recipe, which is sadly not well-documented yet, but will be soon. This is laborious, but easy. Now, to write a full λ-calculus interpreter *that preserves a lot of sharing and parallelism* (probably using some variation of HOAS), that's a (much) harder task which I don't know how to do yet. Requires research. Learning how to write simpler interpreters is a great first step. BTW, I'm currently implementing Formality-Core in Formality-Core, you can follow it [here](https://github.com/moonad/Formality-Core/blob/master/examples/term.fmc). Luckily, using HOAS to write an efficient (i.e., sharing/parallelism preserving) FM-Core interpreter on itself is easy, because it already respects the stratification condition!
Can someone explain how does a record syntax for a type declaration work when the type are functions? For example `data Hi a b = { foo :: a -&gt; b -&gt; a , bar :: a -&gt; b -&gt; b }` How would one actually use to construct a type? Why aren't functions implemented?
I'm excited to share this episode of the podcast after we announced it last week! In this episode I talk with u/saralich, one of the engineers on my team, about u/jez_io's recent article: [Profiling in Haskell for a 10x Speedup](https://blog.jez.io/profiling-in-haskell/).
I would definitely favor creating a functional GUI library. After browsing this subreddit I stumbled on the GTK declarative [library](https://github.com/owickstrom/gi-gtk-declarative) which looks like a step in the right direction. I am still new to Haskell but I would love to get involved somehow with functional reactive programming so I will look into it. I wish there was an ongoing effort I could join... If you are aware or any please let me know. For now I will stick to ncurses I guess.
`Hi const (flip const)` Or: `Hi {foo = const, bar = flip const}` Assuming you didn't have some functions available that matched the type signatures of the foo/bar fields, you'd define them, and pass them in, just like you'd construct any other record. You may run into some troubles playing around with this in GHCI, because functions don't have a Show instance, so if you expect the REPL to `print` out a given instance of `Hi`, you'd be out of luck, because it can't. I suspect this is probably where you got the idea that this required some kind of special magic - I ran into a similar situation when I was learning. It's still valid Haskell, you just can't finish an input line in GHCi that evaluates directly to something that can't be printed. Making a function that will return a `Hi`, using the `let` keyword to assign a `Hi` to a variable, or using multi-line input are all good ways to work around the REPL errors. You could also define a bogus Show instance for your `Hi` type that just returns some boilerplate string if you really want to, but that's not a good practice to get into when working on "real" code. Folks assume that anything that can be an output of `show` could also be a valid input for `read`, so breaking that assumption with bogus `Show` instances is generally considered bad practice.
Ah, gotcha. I didn't notice that it was two different functions. The spacing definitely helps. Personally, I'd put the helper function in a `where` block rather than at the top level.
I think that's just saying that it promises to be a full barrier (in a cross-platform way), i.e. neither loads nor stores will be moved across that operation (on x86 this is just a property of all atomic ops like CAS). Normally for correctness you need to use barriers in pairs: one in each thread, but that depends on the context. Sorry I don't have a great link on hand about the nitty gritty of reordering and barriers but I know there are some good resources out there
It is not standard practice. At some point you realize that Prelude has some shortcomings and you imagine how it could be better. And when you are writing small beginner programs, perhaps most of the functions you call come from whatever Prelude has automatically imported for you -- so it seems like a big deal. Some people develop alternative preludes to explore what could be better. And, some of those might actually be better than the default Prelude if everyone used it instead. But as you get more experienced and develop larger apps, you realize that what Prelude happens to offer is not really that important. If you want to use `Text` instead of `String` then you just import `Data.Text.*`. If you don't want to call partial functions like `head` then you don't call them. You are not a slave to your prelude. You pick and choose the right libraries and idioms for your particular program. And if you right a different program, you might make different choices. What is or isn't in Prelude is of little consequence. In summary, using the standard Prelude isn't limiting you. And using an alternative prelude is not going to make things way better, but it is also not going to screw you over. It might make things mildly better at the cost of having to learn two preludes.
Wonderfully written and very informative - thanks for writing!
I’m curious why people are downvoting you, unless it’s just for lack of explanation? RIO is a bit more than just a replacement prelude, but reading the docs should explain that. I also find RIO promising, personally
David Ellerman gave a mathematical treatment of Double Bookkeeping accounting: https://arxiv.org/abs/1407.1898 Ellerman gives double bookkeeping accounting as a group: the Pacioli group, which is a category.
Does anyone have the paper for the [edit-distance](https://github.com/phadej/edit-distance) package algorithm (an implementation of [Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance))? The paper link in the repository is dead. I wanted to take a stab at implementing bailing out if things get too bad, although [it appears the author did try this at some point](https://github.com/phadej/edit-distance/blob/master/Text/EditDistance/Bits.hs#L94) and bailed out after things got too bad, so perhaps my prospects aren't too good.
 foo :: IO (ActionM ()) -&gt; ActionM () foo = join . liftIO
You could make `getID :: ActionM MyId` by using `liftIO`. This would require you also change the definition for `serveMyId`, but should make things cleaner. The transformation you asked for is pretty awkward, might be better to make this change and not have to deal with `IO` directly.
Alternatively, if you're using `getID` elsewhere you could redefine ``` serveMyId :: ActionM () serveMyId = json &lt;$&gt; (liftIO getId) ```
&gt;Convincing people at your current place of employment to use it. *Which will then go poorly because no one actually knows how to use haskell and haskell gets a bad name.* I strongly disagree. If you say "convincing" as in "talking, meetings, etc.", then yeah, it's probably gonna fail. If you say "Start coding something small but useful, and level up", then it works. I've done it at my company. Not gonna lie, I spent a few months learning Haskell beforehand on my free time so that my first day coding in Haskell at work wouldn't be for learning obvious simple things. I started by taking a tiny part of our code logic, migrated it to Haskell, then called in parallel our Java and Haskell code, compared the result (logged if they were different), and returned the Java result (to avoid regressions). After a few months with no log of discrepancy (and the functional style of code in Haskell being much, much nicer than its Java counterpart), the team agreed to try further. I started this \~1 year ago. Today 30% of my team code base is in Haskell, and we slowly migrate the rest to it (mainly by opportunity, to minimize wasting time recoding something that works™). Overall, it takes energy and at least 1 motivated person (and the rest of the team must be already using functional programming no matter the language, otherwise it's just too much of a different world, everyone will get frustrated). But hey, if we can do it, I think pretty much anybody can :D Disclaimer: I work at a company where teams are rather autonomous. There's no micromanaging bullshit. This may be a prerequisite.
Oh wow I was not expecting this; seeing this just made my evening, thank you! Happy to answer some questions that were raised in the podcast. First a little bit about me: I'm currently at Stripe working on [Sorbet], a type checker for Ruby. We chose to implement it in C++, and we focus a lot on latency. It has to run on Stripe's millions of lines of Ruby code in seconds, it has to respond to an IDE's requests in milliseconds, etc. Specifically some questions raised in the podcast: &gt; Why use a bit vector? I wanted to see how much of an effect data locality / few allocations would have. In Sorbet data locality is huge for our performance (for example, when we traverse to a method definition node in our AST, the method arguments are already in the cache). This bit vector representation definitely wasn't idiomatic—if I hadn't artificially inflated the need for performance, I wouldn't have written this. But I was hoping it would check the cache-locality / no allocations box. One downside to this approach that I didn't call out in the post: it forces the solution to not be parametric in board size. If the requirements changed and the board size became 9x9, I'd have to throw a bunch of the code out, versus had I used a list of booleans or something. &gt; 700ms is so fast already! Maybe... but for example in that same time Sorbet can °°type check°° about 70,000 lines of Ruby code! So I was feeling pretty bad about my little program that could only generate and check 100,000 random boards in that time 😅 [Sorbet]: https://sorbet.org
Please keep is updated on this
I would write `serveMyId` as follows: serveMyId :: Action () serveMyId = do myId &lt;- liftIO getId json myId And then it should be usable the way you did.
How are different serialization formats handled in Elm? Can I specify that I expect e.g. `text/csv` or `application/json` in my Elm code? And can I generate Elm (de)serializers for both these formats from Haskell code?
What do you mean?
No, the current design is all about JSON only, but I'd be happy if someone would like to explore other formats support.
I used to think the same. I was very upset with `elm-format` because it would ruin my formatting and do what I considered to be crazy things – like indenting things after `let`, but not after the matching `in` – but now that I have spent my *x* hours being annoyed (two years ago), I never want to go back to manual formatting or configurable formatting. It's just a thing I don't have to care about any more, and I don't *want* to care about it any more. I know this won't convince you – and I don't think it wouldn't have convinced me. Oh, and it *isn't* a 100% win – it's just that the upsides greatly outweigh the downsides, in my opinion. :)
haskell-miso.org is responsive enough. polimorphic.com is still useable but not fast. It seems miso can fit some use cases, but not others.
In the typical example of dependently-sized vectors, would the element type be a parameter and the length be an index?
Not for `Word`, but you could define an instance of both `Fractional` and `Integral` for a wrapping type with a prime modulus.
This might get you somewhere: https://hackage.haskell.org/package/data-reify-cse-0.0.3/docs/Data-Reify-Graph-CSE.html It's a naive fixed-point operation, so not sure about the theoretical perf. Also, I don't think the reconstruction phase is implemented, but that should be straight forward.
Google Scholar helped me find this [pdf](http://www.academia.edu/download/39402556/psc02.pdf).
This 404s for me.
If you are going to discuss someone else's article, why not try to include them (in some manner or the other) from the get-go?
Same.
I agree with your point in general, but in Haskell type families are not parametric. For example, GHC will not prevent you from defining a function like: type family KindOf (a :: k) :: Type where KindOf 'False = Bool KindOf 'True = Bool KindOf () = Type KindOf 0 = Nat ... Is `a` a parameter or an index? I don't know.
Hmm, that's odd. Does the new link work?
Indeed it does.
If your goal is to make a mobile app game for iOS / Android, a web view probably isn't the best option. I'd just write swift / kotlin.
Thank you! I read a bit in the docs and source code on Hackage, so your answer makes sense to me now.
&gt; 4) [...] finding a technique to evaluate full λ-calculus terms on Formality-Core (thus EA-Core thus EA-Net) without losing much parallelism and sharing. [...] 1) To clarify: One should be able to translate *any* λ-calculus terms into a Formality-Core term? Or do you mean that we just evaluate the λ-calculus terms in an interpreter written in Formality-Core? I am sorry, I still lack the understanding to know what you mean. (I guess you meant the former). &gt; Now, to write a full λ-calculus interpreter that preserves a lot of sharing and parallelism (probably using some variation of HOAS) [...] 2) Okay, I think I got that - the lower bound is the abstract algorithm given by Lamping - it can already interpret the full λ-calculus, but comes with expensive bookkeeping. So the angles of attack are to find more efficient rules for bookkeeping and/or minimize the bookkeeping upfront by translating as much as possible to Formality-Core. (Formality-Core itself is always evaluatable without bookkeeping). Or translate λ-terms into a form that is optimized for easy bookkeeping. 3) Engineering question: If such an interpreter existed and everything is done, we would end up in a situation where we would have to interpret both Formality-Core and full λ-calculus and just pick the best evaluation strategy based on the term we are currently reducing, right? &gt; BTW, I'm currently implementing Formality-Core in Formality-Core, you can follow it here. Neat! This is really exiting :D I want to spend some non-commital amount of my hobby time on building such an interpreter, first by checking out HOAS. I would also love to, as a side project, try to formulate translatability to Formality-Core as an SMT-Problem. After all, it is just shuffling around variable introducutions and assignments such that two constraints are needed. Maybe that could boost the amount of λ-terms one could translate.
To break this down: &amp;#x200B; foo ioAct = do act &lt;- liftIO ioAct act
[removed]
For your problem, can you use the `a` values as unique identifiers? That is, if you see `Node 'x' [Leaf 'y', Leaf 'z']` once, are you guaranteed that if you see `Node 'x' ts` again, that `ts` will be `[Leaf 'y', Leaf 'z']`?
On whether rhey accept GRIN?
No; in my real application this is an AST, and the values are application of named functions. Even if I had unique names on them, this would defeat the purpose of deduplicating - it would "solve" the problem by making the subtrees no longer identical. So for example if I have the tree `(x + x) + (x + x)` where `x` is a 4 times shared subterm but `x + x` is not shared, then I want to analyze the situation and produce the subtrees `x`, `y := x + x`, `z := y + y` where I've now made the tree totally shared (so that I can guarantee that if two subtrees are the same then they are represented by the same object). If I uniquified it to `y1 := x +1 x`, `y2 := x +2 x`, `z := y1 +3 y2` then I would not make any progress toward *actual* deduplication (identifying that y1 and y2 are the same).
An index; since `KindOf` not parametric w.r.t `a`; IMO.
One thing I noticed while running it locally was the profiling adds a 6x-7x slowdown. Is that normal? Also, how can I inspect the Core with `stack`? I used `-ddump-simpl` under `ghc-options` but that doesn't seem to do anything (?).
Blog post doesn't even mention Haskell. This seems to just be a desperate attempt to gain subscribers/customers. So, best case, is that this is irrelevant in this sub.
Fwiw, this tool doesn't seem very amenable to monetisation. The sort of work it does is not complicated, so even if it was closed-source, would be easy to replicate. Since it's open source, that makes monetisation an even stranger idea, since anyone could just stand up their own version of the code. Most big open source projects make money from donations/services built on top of the project. The sort of rate limiting approach doesn't seem to make sense here. That being said, it's a cool tool, and I hope your future attempts at monetising your labour fair better.
I think it is relevant: The Haskell ecosystem is almost completely open source, and the question of how to compensate people for their work is highly relevant, as it would lead to further growth.
&gt; the profiling adds a 6x-7x slowdown. Is that normal? Yep, that's definitely expected. The way GHC implements profiling tools is by inserting extra instructions around every section of the compiled code to record how much time was spent or memory was allocated in the relevant generated code. You can read about how it works in the user guide: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html#rules-for-attributing-costs A different kind of profiler that's better at not slowing down the program is called a sampling / stack profiler. These work by periodically stopping your program, looking at the stack / heap to record some information, and then continuing the program. They're probabilistic: if something took a tiny fraction of time, chances are we might never even know that it executed (because we never paused the program when it was executing). These kinds of profilers are usually better for profiling production applications, because you can ship the fast, uninstrumented code to production, and collect samples unintrusively after the fact. ([rbspy] is an example of a profiler like this; I'm not aware of a sampling profiler for Haskell) [rbspy]: https://rbspy.github.io/
Sure, but then maybe the title should be about monetizing an OSS project instead of a Haskell project? (Certainly this could be an honest mistake about the target audience, I don't dispute that.)
The title of the article doesn't mention Haskell for this reason. I put Haskell in the post title since the project was indeed written in Haskell and I figured my experience might be interesting for other haskellers trying to so the same.
In any case that comment was getting upvotes, so others apparent agreed. so I took the post down
*So, best case, is that this is irrelevant in this sub.* The tool in the article is written in Haskell - [https://github.com/aviaviavi/toodles](https://github.com/aviaviavi/toodles) And at best case it's irrelevant? Your comment makes no sense.
Ok, that's fine, but I think is sort of unfairly singles Haskell out, I feel. You'll also find that the *VAST* majority of the JVM (for example) ecosystem actually is built on OSS. Sure, there may be exceptions, but mostly it's all on Maven Central, including source. Btw, I don't disagree with the point of your article, I just think the title is a bit too click-baity. (But then you *are* on Medium, so you're kind of forced into it...) Making money from OSS *is* hard, but I don't believe in proprietary software[1]... I think the only viable way is consulting and/or customization. Thankfully, there's a *lot* of demand for customization and consulting :) [1] I mean, it exists, but at best you can live off it for a limited time -- the genie is out of the bottle -- but I think that OSS actually makes the "limited time" bit of patent and copyright law more realistic (as to what you should expect)
How is "written in Haskell" relevant? The article doesn't really justify that. There is **no** connection between Haskell and (paraphrasing) "monetization OSS is difficult". &gt; And at best case it's irrelevant? Your comment makes no sense. Worst case = "desperate attempt to gain subscribers/customers" (as in my original comment) Best case = Irrelevant Does that bit make more sense now?
If a project adds any value at all to a company, it's fair for that project's developer to get paid for it! That's a much more general point than just for Toodles in particular. &amp;#x200B; Also thank you, I hope so too :)
I have this in my vimrc: ```viml nnoremap &lt;silent&gt; &lt;leader&gt;st :! (cd `git rev-parse --show-toplevel`; hasktags **/*.hs)&lt;CR&gt;:set tags=&lt;C-R&gt;=system("git rev-parse --show-toplevel")&lt;CR&gt;&lt;BS&gt;/ctags&lt;CR&gt; ``` which uses git to figure out the top level directory, calls hasktags there, and then loads it
The simplifier output can be found in the `.stack-work/dist/x86_64-linux/Cabal-2.4.0.1/build/src` directory (or similar for you). You can grep for files with the extension `.dump-simpl`.
Is \`I\` the identity function here? Is this commonly used notation?
Hmm. Any idea where one could find out about that fixed point definition? I think of inductive/conductive types as being defined^1 by initial F-algebras/terminal F-coalgebras, personally. Which I feel like *suggests* construction/deconstruction. But my gut feeling may well be misleading me here. I'm by no means knowledgeable about these matters. ----- 1. I think this holds "up to isomorphism" in extensional theories, but not *quite* in intentional ones? Something slightly weaker is true there, iirc. But I don't recall the details.
&gt; Folks assume that anything that can be an output of show could also be a valid input for read, so breaking that assumption with bogus Show instances is generally considered bad practice. I see this claim often but I really don't understand the logic. Nobody uses `Read`. Even if anyone does, it's clear that you can't get any standard `Read` instance for computations, so by default the instance is not going to exist, you get a missing instance error at compile time, you glance at the type to understand why, and you move on. I think `Show` is for debugging only and printing a dummy string in place of unprintable computations is a perfectly fine thing to do. It is the simplest way to get a string out of a big record containing all other kinds of valuable printable data.
As I've always interpreted it, it's about REPL ergonomics. If you are messing around in GHCi with someone else's code, your expectation is that if you can inspect a value as the result of an expression, in your terminal window, you can copy/paste that value in that terminal and mess around with it, whereas if you can't, you get an error. I feel like this works really well for me, but in your own code that stays in your own project, I make no judgements, it's perfectly fine to break these rules - but if it ends up in a library I'm working with it'll annoy me and I'd consider it a code smell.
&gt;My own module is not in the root of git dir, &gt; &gt;\*\*/\*.hs it means search from root to all children, I think, &gt; &gt;if my module is in other dir, how you specify the path of my module, so that hasktags can link all the function to my module definition?
Yes, I think is common. The example if from *"The optimal implementation of functional programming languages"*.
This is a weird line of reasoning. It makes it easier to comment out a given constraint or input when writing it as: function :: forall x. Constraint =&gt; Argument -&gt; Result (also, removing or adding arguments is a one line diff for the affected line, which is simple and neat) &amp;#x200B; For symmetric binary operators, it's pretty much a symmetric issue whether to put the operator at the end of the first or beginning of the second line. And for those, it is nice to align them without spacing, so beginning of line "wins". But the Haskell community is too far in this style to get people to change... :-(
Good point. I agree that the constructor/destructor aspect is more evident in the categorical definition. I was thinking of the set theoretic/type theoretic definition when I commented. I think I read the set theoretic definition from Aczel somewhere, but here is a nice survey that mentions fixed points: [https://arxiv.org/pdf/1812.10026.pdf](https://arxiv.org/pdf/1812.10026.pdf)
It's a bit disappointing that this stuff got so hairy and complicated, perhaps it's unavoidable. Nevertheless, good to see progress in that area!
This cursor definition seems correct then, but the inner 'cursor' is not a cursor, it just has the same type. Indeed, a cursor represents both where the user is looking and the entire structure at the same time. I guess that's why I would be hesitant to use a definition like this. But thanks for the feedback! This was helpful for me!
https://www.cs.hmc.edu/~oneill/papers/Sieve-JFP.pdf
(Will answer soon!)
Your syntax for the guards is wrong. No equals sign. suaCor _ | "branco" = "paz" | "amarelo" = "alegria" ... Why do you have some the first five lines typed out, then guards for the rest? And if "cansei" is supposed to be the default, then it should be last.
What are you trying to do with the guards at the end? Those guards you wrote take a string, not a char. Guards are used like this: suaCor :: Char -&gt; String suaCor i | i == 'a' = "amarelo" | i == 'b' = "branco" ...
the thing is, i have to use a char to assign a color(example b for blue) and then assign that color to a message(string),that's my struggle
Could you return a tuple? suaCor :: Char -&gt; (String, String) suaCor i | i == 'a' = ("amarelo", "msg1") | i == 'b' = ("branco", "msg2") ... | otherwise = "cansei"
Check out haskdogs. Uses hasktags but looks more broadly.
Very exciting! Good luck!
I have her paper. The Data.Numbers.Primes wheelSieve is based in part on her real sieve. I just ran this against wheelSieve 4 and it was almost twice as slow. I ran wheelSieve 4 at work on a 64 bit/16 GB and it was really fast. I heard of some other that did a million in .2 seconds. I'm lazy like Haskell. I don't like lots of writing.
The otherwise branch would have to return a tuple as well.
fixed!
This is not well documented. You'd have to know the internal details of GHCJS. I would not recommend doing it. PureScript is close to haskell and is designed to expose its API to javascript. I recommend PureScript for this.
I already have a fully functional project written for GHC; recenlty, successfully ported to GHCJS, but only as a standalone CLI app.
I recommend that you wait for a haskell webassembly compiler to become useable.
Yes, /u/taylorfausak is right in this assessment. It is mostly a didactic vehicle. Anyway, many chapters later, when we introduce the idea of \`undefined\`, we come back to this example and show how \`forall input output. input -&gt; output\` is nonsense :)
&lt;3 this was my reaction too
I think it takes all kinds of books for all kinds of people with all kinds of thinking! I think this would have been the right book for me. This and super low level assembly. I’m not comfortable in the middle nor where things are reasonable and sensible.
The book has now doubled in length since this Reddit submission, and as of today it goes from zero to profunctors in a bit over 50.000 words.
Ah! It hadn't occurred to me that F-algebras would correspond to pre-fixed points. That paper really cleared some things up for me. Thanks!
In the sense of "a joke exploiting the different possible meanings of a word", just without the joke. Given data C = C {a :: Int} I can write f (C {a = a}) = a -- this is the RHS `a`, not the LHS `a` With record puns, I can just write f (C {a}) = a and exploit the multiple meanings of `a`, both the name of the field on the LHS, and the value that field has on the RHS.
i always understood it like this: a joke-pun uses the fact that the same word has multiple meanings¹. with records, the "word" is the record field, whose name usually refers to the accessor function, but with `NamedFieldPuns` it gains a second meaning – the value of the field. or something like that ¹ sometimes that's called "overloading", but that'd suggest that you can define it as you wish, like a typeclass
1. I'm not sure how those options differ, both look valid to me, i.e., we compile any λ-calculus term to FM-CORE by writing a sharing-parallelism-preserving interpreter (i.e., one that doesn't simply perform explicit substitutions). 2. I think the challenge is figuring out how to emulate the bookkeeping mechanism with an interpreter (i.e., without changing the interaction net system). It could be easy or impossible, I don't know because I didn't put a lot of thought on that. 4. In an ideal world Formality would be a Haskell/Python-like, high-level language, with optional box annotations for when you want an extra performance boost, so yea. Thanks for the interest! I'd love to see SMT-related approaches to this. Let me know if you find anything interesting!
I agree on principle, but I'd work on the example you gave for something that should be "effortlessly" completable; I'd say I'm quite comfortable with Haskell but I have no idea what you were going for here.
Sorry, I meant just replacing `_` by any definition that passes the type-checker.
Another question: does anyone know alternative names for this feature, perhaps in other programming languages?
Best of luck to the Student! Something that stood out to me in the post: &gt; In fact, I can think of only one common algorithm for which this approach is not perfect: it is Kruskal’s algorithm for finding the minimum spanning tree. Optimal here really depends on what you refer to. Adjacency lists/arrays use less memory, adjacency maps trade some memory useage for a faster lookup speed, and a matrix uses the most memory but also tends to be fastest for lookups in dense graphs. But in Haskell so far adjacency maps worked well for me, as they are decent in lookup but also easy to update.
`foobar = undefined` passes the type checker, but clearly isn't what you had in mind. If you also meant that it needs to be total, then it's impossible: `foobar (Bar absurd)` has type `forall b. b`, which has no non-bottom inhabitants.
Do you have a definition in mind? foobar (Foo a b) = foobar b foobar (Bar a) = ? For myself, I found having the abstractions up front while learning to be helpful. They helped me focus on recognizing the "shape" of different sorts of problem, rather than on particular implementation concerns. Granted, this had the side effect of making me quite bad at writing explicit recursion, but I don't miss it much. My background is in math, so just having "here are some things with these laws" was useful to me, but I can see that being less helpful for other people. For me, a lot of the intuitiveness of Haskell is a result of pervasive abstractions and pervasive polymorphism; there's a ton of detail I can just ignore when I recognize the shape of a problem, and I get that dopamine hit of "it compiles, so it works". This is in opposition to my experience in OOP, where "design patterns" are a thing that don't seem that universal and no one really knows how to recognize them well enough to use unless they're a consultant selling a book on design patterns. Honestly, the most useful thing pedagogically for me would be something focused on bookkeeping. Most of the code I write is a small, abstract core with a bunch of format munging and type acrobacy at the edges to get various things talking to each other.
There might be some evil hacks around it. Are you able to write inline JS with GHCJS? If so, what about raising a value that you only catch outside of GHCJS in your JS library wrapper code?
I’ve used https://atypeofprogramming.com to introduce Haskell to people with no CS experience. The response has been quite positive.
I recommend that you share what you have so far. I wanted this but didn't find anything close to what you're doing. Somebody may be able to contribute. I was thinking I could run the haskell program as a web worker and communicate through messages. Not quite seamless as you want, but workable perhaps.
Never said it had to be total, and I didn't expect it to be hard, sorry about that.
It can't be total, the solution is to get `a` from the `Foo a (FooBar a b)` case, send it to the function on the `Bar (a -&gt; FooBar b a)` case, and then extract `b` from the resulting `FooBar b a`. foobar :: FooBar a b -&gt; b foobar (Foo a fb) = case fb of { Bar fn -&gt; case fn a of { Foo b _ -&gt; b } } The point was just to make something which can easily be solved if you're comfortable with algebraic datatypes, pattern-matching, type-level variables, recursive occurrences and so on. Perhaps the example came up too artificial and ended up as a mini-puzzle, but that wasn't the intention. Just replace it with simpler exercises that cover those things separately.
I intended it to only have a partial solution, and I didn't expect it to be hard; check the reply above.
It can't be total, the partial (but terminating) solution is to get `a` from the `Foo a (FooBar a b)` case, send it to the function on the `Bar (a -&gt; FooBar b a)` case, and then extract `b` from the resulting `FooBar b a`. foobar :: FooBar a b -&gt; b foobar (Foo a fb) = case fb of { Bar fn -&gt; case fn a of { Foo b _ -&gt; b } } The point was just to make something which can easily be solved if you're comfortable with algebraic datatypes, pattern-matching, type-level variables, recursive occurrences and so on. Perhaps the example came up too artificial and ended up as a mini-puzzle, but that wasn't the intention. Just replace it with simpler exercises that cover those things separately.
This is true. Be mindful of your tone. But it is also true that we should give the benefit of the doubt when reading others' posts.
I'd move ADTs up to 2. Cant find a list head without understanding the structure of a list.
IMO, it's a completely terrible idea to teach a beginner about Haskell by writing partial functions everywhere, just like you wouldn't teach a beginner about C by using goto's everywhere. If you had an example that was total, I'd be in 100% agreement.
Part of learning how to write code is learning to read code others have written. The use of functor, applicative, and monad in Haskell is so omnipresent that delaying instruction on this topic leaves a newcomer totally unable to interact with the ecosystem for an extended period of time. That would be a bad idea, as many people learn by doing. I have nothing against spending more effort on ADTs, but it's probably not a good plan to delay Functor in favor of useless and non idiomatic code puzzlers.
I agree, I updated with a total example, but in retrospect perhaps this mixed many concepts and ended up being too puzzle-like. I really meant to say that you must be sure the student is comfortable with all those things separately.
In javascript it's called [destructuring assignment](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment).
Maybe skip list-head and present other simple functions. The point was to bring subjects that the user is already comfortable with from other languages, so he can get comfortable with Haskell's syntax before moving on to Haskell-exclusive subjects. It is overwhelming to learn new concepts when you're still struggling with the syntax itself!
I find it is unlikely someone will actually understand functors and monads without being comfortable with ADTs. The over-emphasis on teaching functors and monads before people understand ADTs and recursion leave them confused. Would you teach calculus to someone still struggling with fractions?
I'd say that the root cursor represents the node the user is looking at, whereas the inner cursor represents the *subtree* that the outer cursor is looking at. I don't see any problem with that generalization of the cursor concept.
I'm currently writing a proof of concept with worker\_threads.
or destructuring bind in Common Lisp
[removed]
Learners can use functors without knowing how they work, how to write them, or what they mean. The truth is people get bored if they can't get their hands dirty with something "real," and learners are going to quickly run into functors.
[removed]
For those who don't want to watch a 20m video, the points are: * Be courteous and polite. People submit code because they are trying to help, so don't slap them in the face for it.
Hello, reddit! I recently wrote a library called [`string-interpolate`](https://hackage.haskell.org/package/string-interpolate) after constantly getting frustrated doing string building in Haskell. If you're already using [`interpolate`](https://hackage.haskell.org/package/interpolate), string-interpolate is meant to be a drop-in replacement. Why should you use string-interpolate? * It's easy-to-use * It's fast * It handles Unicode properly * You don't have to think about converting between textual types Give it a shot!
&gt;I often see feedback and comments that could be good if they had been written in a different tone. Could you provide examples of feedback/ comments written in bad/ toxic tone (anonymized if necessary)? I find it hard to believe that tone -- which is prone to misinterpretation, especially by someone of different culture to you -- is the root issue here. (I'm assuming that the word 'tone' refers simply to the tone of the language, and not necessarily the vibes sent via words; the latter is the case when someone gives feedback while feeling say frustrated, which feeling is communicated as vibes despite it not being featured in words)
Nice! Finally something that I can replace my "something something perl6" library with and actually remember the library's name :) Kudos on performance speedup!
And verily, it came to pass: [statebox/cql](https://github.com/statebox/cql).
!RemindMe 1 day
it seems to me **Hasktags** does't support that, I did not see any option for that. I just send up generate each tags file for module is not under my root project, and I just merge them, but need to use -R to get the absolute path in tags file, this is all since tags file is nothing more than a **function name**, **path** and **line #**, at least for **Vim**
you might be able to get some inspiration from jsaddle
&gt;in retrospect perhaps this mixed many concepts and ended up being too puzzle-like "Type Tetris" is a valuable Haskell skill to have though. Writing implementations for things like that is something professional Haskellers do.
I will be messaging you on [**2019-05-31 19:02:09 UTC**](http://www.wolframalpha.com/input/?i=2019-05-31 19:02:09 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/buwlqy/difference_between_classes_interfaces_instances/epintp8/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/buwlqy/difference_between_classes_interfaces_instances/epintp8/]%0A%0ARemindMe! 1 day) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! epit32g) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I don't get it. What total solution do you have in mind? I can define fb :: FooBar Int Bool fb = a 0 where a x = Foo (x + 1) b b x = Bar (x + 1) a This typechecks, it has no bottoms, it's not circular, you never see the same Int twice...but you never see a single Bool no matter what you do. This is just a bad type to base a puzzle on.
You should make a git repo for your library if you want others to be able to keep up with bleeding edge changes made in the future.
Even when it does, it won't likely solve this problem, because the RTS will still be there and need to be started and stopped. It's a more fundamental property of how GHC-compiled code expects to run. If you load up the javascript debugger in your web browser, start debugging a GHCJS-compiled project and step a few times you'll probably quickly hit a block of code which looks like this: function h$runThreadSlice(c) { var count, scheduled = Date.now(); while(c !== h$reschedule &amp;&amp; (h$currentThread.noPreemption || h$currentThread.isSynchronous || (Date.now() - scheduled &lt; h$schedQuantum))) { count = 0; while(c !== h$reschedule &amp;&amp; ++count &lt; 1000) { c = c(); c = c(); c = c(); c = c(); c = c(); c = c(); c = c(); c = c(); c = c(); c = c(); } if(c === h$reschedule &amp;&amp; (h$currentThread.noPreemption || h$currentThread.isSynchronous) &amp;&amp; h$currentThread.status === (1)) { c = h$handleBlockedSyncThread(c); } } return c; } The while loop there is a device called a "trampoline", and is used to sidestep the fact that we can't recurse endlessly in Javascript without blowing up the stack. Haskell expressions are compiled to Javascript functions that return the continuation with which to proceed. When compiling for x86 or ARM for instance, instead of returning a function which will then get consumed by a trampoline, the code just jumps to that continuation. When it comes to wasm, I'm not sure what kind of machinery is in place, but it's going to be *something like this* -- perhaps wasm's 'loop' instructions can be used in place of jumps, I'm not familiar enough with wasm to really be sure.
(??? means blanks you need to fill in) You can define `Vec3D` as a data type - data Vec3D = Vec3D { x :: Float, y :: Float, z :: Float } After that you need to provide some functions which operate on that data type - add :: Vec3D -&gt; Vec3D -&gt; Vec3D add v1 v2 = ??? crossProduct :: Vec3D -&gt; Vec3D -&gt; Vec3D crossProduct v1 v2 = ??? -- similarly for sub etc. Type classes are, very loosely speaking, similar to interfaces in other languages like. You need to provide *instances* for those type classes by implementing the *methods* of the type classes. In your case, the type classes of interest are `Eq`, `Show` and `Read`. Very often, the compiler can derive them for you -- Modifying the thing we wrote earlier. data Vec3D = Vec3D { x :: Float, y :: Float, z :: Float } deriving (Eq, Show, Read) Instead, if you want/need to write these instances by hand, -- If you want to write the instances by hand, omit the deriving clause data Vec3D = Vec3D { x :: Float, y :: Float, z :: Float } instance Eq Vec3D where (==) v1 v2 = ??? instance Show Vec3D where show v = ??? instance Read (Vector3D a) where readPrec = ??? How did I find which method names to write in the different type class instances? I looked at the [Prelude](https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html) documentation for the different type classes and search for "Minimal complete definition" for each of them.
https://www.gitlab.com/williamyaoh/string-interpolate
In the end, you say &gt; Unfortunately, I haven’t been able to figure out how to get string-interpolate to have all three of 1) usage of efficient intermediate types, 2) defaulting to Show/IsString, and 3) allowing library users to customise the behavior for their own types. Any two together seem doable, but getting all three seems not to be. However, the following code works as I'd expect - newtype V a = V a deriving Show instance Show a =&gt; Interpolatable 'True (V a) T.Text where interpolate _ (V x) = B ( TLB.fromString ("???" ++ show x) ) If I remove the custom instance, it works with the instance derived from `Show`. So I'm not sure what the problem is, you've got all three now :D (right?).
I tend to use `(&lt;&amp;&gt;)` whenever I need to `fmap` a function that isn't something I can write as a short bit of point-free code as you don't need any parentheses and it usually flows way better.
Great post but does there really need to be six ads for their Haskell Success Program littered throughout the page?
Do you want to succeed or not?
It's hard to avoid so much success at all costs!
I think message passing is better than relying on implementation detail of GHCJS.
I'll try my best to explain. In Haskell, typeclasses can be thought of as interfaces. There are programmer defined typeclasses like `VecPredicates` and `VecOperations` that you have defined above in your post, but there are also the typeclasses defined in the Haskell `base` library\[1\] such as `Eq`, `Show`, and `Read`. `Eq`, `Show`, and `Read` are some of the fundamental typeclasses in Haskell. They are defined just like any other typeclass. The class definition of `Eq` for example\[2\] is: &amp;#x200B; class Eq a where (==) :: a -&gt; a -&gt; Bool &amp;#x200B; Any type that is an instance of the `Eq` typeclass has a `(==)` function that can be used to test the equality of two values of that type. For example, lets create an instance for a `Vec2D` type. Let's ask ourselves, "What does it mean for two 2D vectors to be equal?": &amp;#x200B; -- Our type definition data Vec2D = Vec2D { x :: Float, y :: Float } -- Our Eq instance for Vec2D instance Eq Vec2D where (==) :: Vec2D -&gt; Vec2D -&gt; Bool (==) (Vec2D x1 y1) (Vec x2 y2) = x1 == x2 &amp;&amp; y1 == y2 &amp;#x200B; Let's take a look at our implementation of the `Eq` instance for `Vec2D`. First we pattern match on both `Vec2D` values and extract their x and y values. We then test the equality of the x and y values. If the x value of the first vector (`x1`) and the x value of the second vector (`x2`) are equal, and the y value of the first vector (`y1`) and the y value of the second vector (`y2`) are equal, then the two vectors are equal. This makes sense because vectors in two dimensions are equal to each other when the dimensions of the two vectors are equal. Note the type signature for `(==)` in the instance definition\[3\]. The polymorphic type `a` in the `Eq` typeclass definition has been filled in by the concrete `Vec2D` type. &amp;#x200B; We could have implemented the `Eq` instance for `Vec2D` differently. For example: &amp;#x200B; -- Our Eq instance for Vec2D instance Eq Vec2D where (==) :: Vec2D -&gt; Vec2D -&gt; Bool (==) (Vec2D x1 y1) (Vec x2 y2) = x1 == y2 &amp;&amp; x2 == y1 &amp;#x200B; We've defined the equality of two `Vec2D` values differently this time. This definition doesn't really make sense though. There are usually many ways to implement the instance of a typeclass for any given type, but not all of them may be correct. &amp;#x200B; Let's try to implement the `add` operation under your `VecOperations` typeclass for values of type `Vec2D`. Once again, lets think about what it means to add 2D vectors together: &amp;#x200B; instance VecOperations Vec2D where add :: Vec2D -&gt; Vec2D -&gt; Vec2D add (Vec x1 y1) (Vec x2 y2) = Vec (x1 + x2) (y1 + y2) sub = undefined dot = undefined cro = undefined mul = undefined len = undefined &amp;#x200B; Here, we pattern match on the two vectors passed into the function like last time. Then we construct a new `Vec2D` that has `x1 + x2` as an x value, and `y1 + y2` as a y value. We have successfully defined `add` for values of type `Vec2D`. &amp;#x200B; Sources: \[1\] [http://hackage.haskell.org/package/base-4.3.1.0/docs/src/GHC-Classes.html](http://hackage.haskell.org/package/base-4.3.1.0/docs/src/GHC-Classes.html) This is the actual definition. I just simplified it a bit. \[2\] [http://hackage.haskell.org/package/base](http://hackage.haskell.org/package/base) The `base` library for Haskell. I recommend looking through it if you like Haskell. \[3\] Normally, type signatures are not allowed in instance definitions unless there is \`{-# LANGUAGE InstanceSigs #-}\` at the top of the source file. I'm using the type signatures for educational purposes.
That's not quite what `NamedFieldPuns` is
You're right! The main thing I was thinking of was defining new instances of `InterpSink` to customise the behavior based on *output* type, which I *don't* think is possible. For instance, if I wanted to have an extension library to interpolate into `text-utf8`. (I'd love to be proven wrong though!) I suspect that using rewrite rules might do the trick, but I'm somewhat hesitant to go down that route. It feels like the implementation would end up too brittle.
I was just looking at this library a few weeks ago. I think I ended up going with `interpolate` because I wanted multiline strings (which I can confirm it handles, so your table may need updating). If `string-interpolate` can do multiline strings, I'll drop it in tomorrow and try it out! Awesome work!
This is what I had in mind: data FooBar a b = Foo a (a -&gt; FooBar b a) | Bar b (b -&gt; FooBar b a) | End a b get_ab :: FooBar a b -&gt; (a,b) get_ab fb = (get_a fb, get_b fb) get_a :: FooBar a b -&gt; a get_a (Foo a fn) = a get_a (Bar b fn) = get_b (fn b) get_a (End a b) = a get_b :: FooBar a b -&gt; b get_b (Foo a fn) = get_a (fn a) get_b (Bar b fn) = b get_b (End a b) = b This is total and checks in Agda too. What you're saying doesn't make a lot of sense to me. I can also create an "ill" pair like: xs :: (Int, Int) xs = (fst xs, snd xs) You can call `fst` on it but you'll never get an `Int`...
Thank you for updating this!
This is what I had in mind: data FooBar a b = Foo a (a -&gt; FooBar b a) | Bar b (b -&gt; FooBar b a) | End a b get_ab :: FooBar a b -&gt; (a,b) get_ab fb = (get_a fb, get_b fb) get_a :: FooBar a b -&gt; a get_a (Foo a fn) = a get_a (Bar b fn) = get_b (fn b) get_a (End a b) = a get_b :: FooBar a b -&gt; b get_b (Foo a fn) = get_a (fn a) get_b (Bar b fn) = b get_b (End a b) = b This is total and checks in Agda too. `FooBar` is not an awful type to base a puzzle on. What you're noticing is that you can inhabit `FooBar a b` with bottom, but that is also true for any Haskell type: pair :: (Int, Int) pair = (fst pair, snd pair) This type-checks, yet you can never get an `Int` out of it, no matter what you do. Same principle.
What libraries are people using now-a-days for FRP? Are `Reactive-Banana` and `Reflex` the two main contenders? I've never done FRP and I'm looking for a good place to start. I want to use it with SDL for a simple 2d sprite based game. I saw some example code using `Yampa` and the Arrow syntax really made sense to me, but I don't see anyone talking about `Yampa` in the present tense. Would I be better off using `Reflex` or `Reactive-Banana`?
Oh, if you just want newlines copied verbatim into the output, string-interpolate already handles that fine. I was thinking special behavior around newlines, like removing them entirely or dealing with indentation when making that table.
I don't want to give anyone the impression that foundational knowledge about ADTs is somehow unimportant. But the utility of ADTs, much like the use of any fundament, is unbounded. Functor is, similarly, of boundless potential potential. You don't need to understand every possible use of either to write good code that does something useful - a baseline understanding is fine. Your instruction, and a student's learning, doesn't need to stop there, but having a broad but shallow understanding you can use is much better foundation than a deep but limited understanding that you can't.
Oh, awesome! I'll give it a run tomorrow. Indentation mangling isn't a thing that I need now, but I may open an issue (or think on a PR, if I find some time) to add it as a nice-to-have. Thanks again!
Good luck. Let us know how it goes.
As I said in my comment, my `fb` is not bottom, and contains no bottoms anywhere within it. Both my functions `a` and `b` return small values in the FooBar type; you could could give them strictness strictness annotations or use `seq` or bang patterns if you like. There's no *need* for a bottom, because your definition of the type permits non-bottom values that have no way to get to any value of type `b`. I could almost buy an argument that my `fb` is like `[1..]`, which must be "bottom" because `length [1..]` fails to return. In that case, really the problem is that `[1..]` is a coinductive structure rather than an inductive structure, and `length` is only defined for inductive types. But I don't even have to do that: my `fb` is perfectly inductive and finite, it's only the fact that your `get_ab` keeps calling functions it finds inside that makes it fail to terminate.
`a` and `b` are infinite structures, which aren't possible in a consistent theory. If you are able to inhabit your value, then you'd also be able to inhabit bottom. Notice, for example, that `Foo a (Foo b a) == a`, i.e., two different values are equal, which is absurd.
&gt; a and b are infinite structures, which aren't possible in a consistent theory Not true, you can use [Nu](https://hackage.haskell.org/package/recursion-schemes-5.1.3/docs/Data-Functor-Foldable.html#t:Nu) to represent an infinite structure as it's unfolding (coalgebra + seed) even in a strict, productive language.
Representing isn't constructing...
`string-interpolate` looks interesting, though. I like that you are focusing on performance! I'm using `neat-interpolation` package because: 1. It works with `text`. 2. It supports multiline strings with smart indentation handling. 3. The interface is simple. 4. The number of dependencies is relatively small. In most cases where I needed interpolation, this is what I usually want.
I'm not sure if this is quite the right setting, but just FYI, you can specify "git: &lt;URL&gt;" in your package.yaml and have the source repository linked on Hackage. (I'm guessing the lack of link from Hackage is why /user/emmanuel_erc didn't find it.)
I tend to disagree. I'm not sure the map-territory distinction is meaningful here.
That’s really cool, is the wrapper code by any chances open source??
You're welcome!
Not yet, but if there’s enough interest I’ll release them.
We should try to remember that avoiding success was what it was all about.
Consider telling them to learn a bit of [elm](https://elm-lang.org/) first. The language focuses on the easy yet useful concepts of FP, like for example ADTs. I would also guess that it is syntactically and conceptually close enough to Haskell that learning elm first makes learning Haskell easier.
This is something I tried doing with the Reading/Writing Simple Haskell slides and consecutively [Haskell Study Plan](https://github.com/soupi/haskell-study-plan/).
This seems to be personal. People usually struggle with monads, but you make functors out to be more of a hurdle than they are. Some people would like to call it `Mappable´, but they haven't gone past the container analogy - which *is* useful in the beginning, but just doesn't cut it for everybody. Fact is, at some point of genericity, things (mathematical objects) are bound to have weird names, that don't (and *mustn't*) appeal to the intuition you may have about them. And that happens all the time. We all accepted the term "Vector" at some point, for instance, and guess what, the definition of vector is *not* an array of numbers. But if this specific *instance* of vector space elements *suffices* for your purposes, feel free to use it - i.e. don't shy away from the container analogy. There is one issue I have with some people teaching, and that is that they appear to believe that "knowledge" in their specific area of interest is organized in a neat, linear, ladder-like manner. And unless you "understand" topic X (i.e., have taken to heart the same examples and intuitions I have), you have no business dealing with topic Y. Don't do that. I mean, it's great to be at the top of a ladder you can define yourself, but you are not helping people by trying to protect them. Or by holding them back from getting their hands dirty unless they have solved these "clean" exercises first. The *result* of this we can see here all the time: People who have finished "Learn You a Haskell" noticing that they can't program a lick of Haskell. To be fair, I don't know the perfect order in which to teach things. But in my opinion, you should let people write dirty programs that deal with IO earlier. Don't use `(&lt;$&gt;)`, `(&lt;*&gt;)` and `(&gt;&gt;=)`, or Kleisli arrows for that matter, people should not need to know about any of this crap before being able to read a string from the console. Let do-notation be ingrained into muscle memory, and treat `IO` as some "dirty tag". This isn't what someone else would recommend, but at least you can solve real problems at this point, and don't need to first "work their way up" to being able to implement things like `Writer`, only to be told that "actually, nobody uses it lol".
Thank you very much, you've helped me a lot.
Your answer is very detailled and understandable. In my opinion it's not quite easy for beginners to understand this concept, but your explanation gave me the necessary hint. Thank you.
Not sure why the downvotes but, again, you're simply not right; should I just lie, ignore and not answer? Here is FooBar in Agda, a **total** language: data FooBar (A : Set) (B : Set) : Set where foo : A -&gt; (A -&gt; FooBar B A) -&gt; FooBar A B bar : B -&gt; (B -&gt; FooBar B A) -&gt; FooBar A B end : A -&gt; B -&gt; FooBar A B data Pair (A : Set) (B : Set) : Set where pair : (a : A) -&gt; (b : B) -&gt; Pair A B get-snd : {A : Set} {B : Set} -&gt; FooBar A B -&gt; B get-fst : {A : Set} {B : Set} -&gt; FooBar A B -&gt; A get-snd (foo a fn) = get-fst (fn a) get-snd (bar b fn) = b get-snd (end a b) = b get-fst (foo a fn) = a get-fst (bar b fn) = get-snd (fn b) get-fst (end a b) = a get-both : {A : Set} {B : Set} -&gt; FooBar A B -&gt; Pair A B get-both fb = pair (get-fst fb) (get-snd fb) Hopefully this convinces you there is nothing non-total about this puzzle. Now as an exercise try constructing your `fb` on it (you can't).
[Here](https://gist.github.com/chrisdone/a3fecaba24002d3755fa4aebeeb77bbe) is a "readable" version. I've shared some feedback with our marketing/sales team, I don't know whether it's automated or manually inserted with the blogging engine, but it's way over the top.
What is the Iridium IR? It is impossible to google.
Also, check out [the awesome youtube talk](https://www.youtube.com/watch?v=-dHFOjcK6pA)
Am I? No. Do I wish I was? Yes! &amp;#x200B; I have several projects that I'd love to use Haskell on Jetson for -- but I am not allowed to start any new projects until I finish some of the old ones.
1. I think you may have replied to the wrong comment; your reply seems out-of-context, and I don't think I ever doubted the totality of your example code. I was disagreeing on whether there's a useful distinction between representing and constructing infinite structures in a programming language. 1. I don't believe I've downvoted any of your comments in this discussion. But, keep mentioning the voting system and you are sure to accumulate them quickly. 1. I must say, I really disilke new-style mutual in Agda; I prefer mutual blocks/keywords, visually.
I didn't realize it wasn't the same person from earlier, and it is quite unthankful to keep asking someone questions only to downvote when he answers as he knows.
Eh, it's just downvotes. No one really cares. I've had several conversations on reddit spiral into a cycle of read reply, downvote it, write reply, get downvoted. They continue for multiple iterations until one of gets fed up and abandons the discussion or until one of use starts making sense and the downvotes stop. (And, yes, both ending have happened to me.) I'd like to think at least one of those exchanges was positive overall, even if my karma in the discussion was overall negative.
Yea it is equivalent to asking someone a bunch of questions then showing the middle finger and turning around without saying a "thank you".
Why do you need to feed the attoparsec parser byte-by-byte? That seems like a very inefficient way to use it. Attoparsec is capable of returning the [unparsed rest of the input](http://hackage.haskell.org/package/attoparsec-0.13.2.2/docs/Data-Attoparsec-ByteString.html#t:IResult) togther with the result, can't you feed it a whole chunk at once?
Thanks for making it readable for me. I stopped reading the original link because of those obnoxious ads.
This looks awesome! I’ve just been porting Elm code to Haskell and it was more work than I’d expected. How does it handle typeclass instances with constraints?
Keep in mind that it may not be the person you replied to that did the down voting. Maybe you annoyed someone in another thread, and they decided to be petty and downvote you elsewhere. Anyone can join this thread and vote, without ever commenting at all. It certainly could be malice, but I have a better day when I don't think of it that way.
This can only generate Elm type definitions, Json encoders and decoders from Haskell data type definitions. It is not a Haskell to Elm transpiler. Sorry for the confusion.
I would be careful about a convenient way to convert `ByteString` --&gt; `Text`. Decoding UTF-8 data, however common, is still a partial operation, so that should be reflected in the type: decodeUtf8' :: ByteString -&gt; Either UnicodeException Text
Makes perfect sense. I was overly optimistic, haha. This is definitely going to save me a lot of time defining JSON encoders and decoders for some fairly large types.
Currently sketching out a new application with `polysemy`. Sandy has been incredibly helpful with explaining some of the concepts and helping get things working.
It's their own intermediate language used in this particular backend.
Yeah, it's definitely something to worry about. I chose here to make it total by converting any invalid characters to � (U+FFFD), since the goal was optimizing convenience in the 99% case and trusting the library user not to do anything stupid, rather than 100% correctness at the cost of programming interface. The recommendation I make in the README is to treat string-interpolate as such, and if the latter is required, to use `text-conversions`.
Just use something that's not partial. Like https://en.wikipedia.org/wiki/Windows-1252 ! Even though "positions 81, 8D, 8F, 90, and 9D are unused[...], the Windows API MultiByteToWideChar maps these to the corresponding C1 control codes. The "best fit" mapping documents this behavior, too." ;)
Wow, Finally! It remind me facebook’s pfff :D
Do lenses/prisms support a general approach to distinguishing between "getting failure"? For example: data Foo = Foo [Int] | Bar Bool makePrisms ''Foo -- fails because index 20 is too high &gt;&gt;&gt; let x = Foo [1..10] in x ^? _Foo . ix 20 Nothing -- fails because wrong data constructor &gt;&gt;&gt; let x = Bar True in x ^? _Foo . ix 20 Nothing I'd like to know that the first fails at `ix 20` whereas the second fails at `_Foo`. Maybe through the use of an `Either String` instead of `Maybe`? Cheers Haskellers!
&gt; Thanks for the interest! I'd love to see SMT-related approaches to this. Let me know if you find anything interesting! Thank you for your answers - sure I will do! For now I will read up on lambdascope and BOHM (if I understood correctly, those might be the fallback solution if there is no smarter interpreter to be found) and then think about my SMT approach for automatic translation of λ-terms into FM-CORE terms. Thank you for your work and the nerdcrush you gave me on optimal reduction! :)
"Field init shorthand" in Rust
Very cool to see this after hearing about it for so long. &gt; Haskell ✅ ✅ ✅ 🔶 ✅ Something something shoemakers' children never have shoes :(
Very good writeup. type HRK (f :: forall k. k -&gt; Type) = (f Int, f Maybe, f True) We can give a name to the kind of `f` (note, `Ixed :: Type` takes no arguments) type Ixed = (forall k. k -&gt; Type) It is useful with any higher-rank polymorphism, to use visible type (kind) application `@..` type HRK (f :: Ixed) = ( f @Type Int , f @(Type -&gt; Type) Maybe , f @Bool True )
 type family PKRetKind :: k -&gt; Type the binding site of `k` would be a lot more obvious if we could write type family PKRetKind @k :: k -&gt; Type
 note _ (Just x) = Right x note msg Nothing = Left msg f = (note "Not a Foo" . (^? _Foo)) &gt;=&gt; (note "Index Out of Bounds" . (^? ix 20)) ? I'm not comfortable enough with TH to get your to run in ghci, so I didn't test/type-check the above. `(note "Not a Left" . (^? _Left)) &gt;=&gt; (note "Out of Bounds" . (^? ix 13)) :: Either [Int] Bool -&gt; Either String Int` typechecks in my GHCi, so I think it should work. [`note`](https://hackage.haskell.org/package/errors-2.3.0/docs/Control-Error-Util.html#v:note) is on hackage [in multiple places](https://hoogle.haskell.org/?hoogle=String+-%3E+Maybe+a+-%3E+Either+String+a). Error messages generated through TemplateHaskell (or CPP or any other templating) tend to be on the poor side. However, it's relatively easy to operate in an `Either e` monad instead of the `Maybe` monad and lift things. You might also look into the "Validation" applicative -- it can return mutliple errors when moving from a untyped or insufficently typed representation to one that has all the guarantees in the type system.
Thank, I have read up on barriers and reordering now. Looks like my brain had reordering mixed up with cache coherency when reading the IORef doc, but it the doc doesn't say anything about cache coherency. Is cache coherency something that I never have to worry about when writing user-space code?
Maybe a dumb question but what is it used for?
It currently powers [this feature](https://github.blog/2017-07-26-quickly-review-changed-methods-and-functions-in-your-pull-requests/) at GH, and will be used in future cool stuff that I can’t yet talk about. (Soon, though!)
Abstract syntax (Sorry, had to)
Great article! Does a forkIO-like interpreter require similar use of Tactical as the bracket-like one in Resource?
I have a sum type representing valid version numbers for my schema, which derives `Enum` and `Bounded`. I'm using a case statement to match migration functions with the schema versions. Currently all left sides of the case statement are hardcoded values/constructors, but I'd like to make the last one (the latest version) be `maxBound` rather than the maximum value/constructor itself, because the function associated with the maximum version is a no op. Long story short, is it possible to have the compiler tell me when I haven't matched all cases for a sum type, while using `maxBound` instead of the literal value to refer to the maximum value? Hopefully that makes sense.
As long as we are on the topic of `Enum` and `Bounded` instances, I ended up writing this today: boundedNonEmpty :: (Bounded a, Enum a, Eq a) =&gt; NonEmpty a boundedNonEmpty = NonEmpty.unfoldr f minBound where f x | x == maxBound = (x, Nothing) | otherwise = (x, Just $ succ x) It is total, but it accomplishes that by using the `succ` function which is partial (on `maxBound`) and avoids that via the guard. I was wondering two things: 1) is there a way to avoid that in this specific case and/or in general in this kind of situation and 2) is there a way to write this without either or both of the `Enum` and `Eq` constraints?
Thanks! Yeah, every interpreter for an effect with an embedded computation must be `Tactical`.
This very much depends on the organization and the position. Some orgs hire to train, some want you fully bootstrapped. In my experience most orgs know training will be necessary and production Haskell experience is rare. Hopefully the organization's job description gives you some clues. Some general skills I like to see (which are negotiable depending on other experience/skills) are: * Knowledge of standard typeclass hierarchies. These are the glue that pulls code together and are daily drivers for a Haskell dev. * `Functor` \-&gt; `Applicative` \-&gt; `Monad` * `Semigroup` \-&gt; `Monoid` * `Foldable` \-&gt; `Traversable` * Understanding of Monad Transformers. Most production code will include monad transformers and being able to work with them is key. You don't need deep knowledge, but need to be able to decipher type errors that are produced in these stacks. * `mtl`: like it or not this library is everywhere. You'll need to understand constraint based effects and how to utilize them. * Testing: If a candidate submits a sample project without tests, they are getting dinged. Haskell's testing story is fantastic and you should know how to write unit tests with `hspec` or `tasty` and property tests with `quickcheck` or `hedgehog`. That is about it from base Haskell knowledge. Everything else gets fuzzier and more generalized to software development. If the company you are looking at is writing HTTP servers, then you might want to try building something in that realm using `scotty`, `spock` or `yesod`. Those frameworks will exercise some of the skills mentioned above.
I find long commands like "stack build --fast --haddock-deps" and such rather tedious, and error-prone, to type out. Does stack have a similar functionality to NodeJS's `npm`'s `scripts`, where you can define in the project's `package.json` something along the lines of `"build:docs": "stack build --fast --haddock-deps"`, allowing you to simply use `npm run build:docs` instead?
So essentially you want to assert that the no op case is actually off of the constructor that is `maxBound`, and you'd like this to be checked at compile time. Is that right? I'm not sure how to do that without using some kind of metaprogramming. It would seem to require first-class patterns of some sort.
Is there an operator version of map? Something along the lines of: `ham = ((iterate 2) \`mergeAll.map\` (iterate 3) \`mergeAll.map\` (iterate 5)) 1` makes it much clearer to me what you are doing.
This is a good list, and I’ll nitpick it a little and add servant to the list of http server frameworks. But I want to add a different flavor of advice. You should be prepared to talk about WHY haskell is a good language for writing software. I wore a hiring manager hat for an entry level haskell dev position and I can tell you what I looked for. I got a lot of resumes, (probably because of the job listing service we used) and to not spend all my time on hiring tasks I ignored ones that had no functional languages and no cover letter. After that funnel, I looked for evidence of passion about functional programming. If the resume had a github that showed working on haskell outside of work or school, that is good evidence of passion. OR if the cover letter had a bit about the virtues of functional programming or strong types or anything like that, I would try to setup a phone screen. In software, if you are a good match for the job, you can get away without a cover letter pretty easily. But if you are looking to stretch out of your skills a bit, a cover letter saying you are excited about it and why you are excited about it goes a really long way towards talking to a human that makes hiring decisions. There is also a good chance that a question about why Haskell shows up in the interview as well.
[`enumFrom` in the `Enum` class](https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#v:enumFrom) should already do most of that: boundedNonEmpty :: (Bounded a, Enum a) =&gt; NonEmpty a boundedNonEmpty = fromList (enumFrom minBound)
Yeah that's what I want. I had a feeling it wouldn't be attainable but I thought I'd ask just in case.
You don't need all the parentheses, right?
There is an operator version of map and is primarily used infix. It is &lt;$&gt; and I love it. Your example makes no sense. The map functions are in the wrong place to be effective. Shift them left by one. I do want to do this with &lt;$&gt;
Iterate takes a function and map takes a function so I always put function arguments in parentheses.
Then, you don't have enough, because `(.)` takes two (or three) arguments. I suggest you hlint your code; redundant brackets are definitely a readability issue.
On Linux, we have shell aliases, and our own shell scripts we put in ~/bin or somewhere else in the path. There's really very little need for every tool to do this.
If you're okay with using Template Haskell, you can adapt the following to your case: {-# Language TemplateHaskell #-} import Language.Haskell.TH import Language.Haskell.TH.Syntax (lift) -- you might have to use Con instead of Lit, or maybe some combination. litExpToLitPat e = case e of LitE l -&gt; LitP l; _ -&gt; error "Expected literal!" myFun x = case x of $( fmap litExpToLitPat [| $(lift (maxBound :: Int)) |] ) -&gt; "min" -- 1. Force evaluation of using $(lift ...) (needs a Lift instance, use DeriveLift) -- 2. Make an expression AST out of the newly generated result -- 3. Map the expression AST to a pattern AST -- 4. Splice the pattern AST into a pattern position _ -&gt; "not min" Related resources: https://www.reddit.com/r/haskell/comments/7yvb43/ghc_compiletime_evaluation/, https://ocharles.org.uk/blog/guest-posts/2014-12-22-template-haskell.html
Wow thank you! I don't have any experience with Template Haskell but I will give this a shot.
No worries! I've slightly simplified the code as `[| $( blah ) |]` is the same as `blah`.
Ah, good call. Thank you. This is definitely a step up from my solution in terms of succinctness and expressiveness and eliminating the need for the `Eq` constraint is a definite win but `fromList` is still a partial function. Of course we know that it won't fail in this case, but we know that `succ` won't fail in in my `unfoldr` solution as well thanks to the guard... so I'm still curious if there's a way to avoid partial functions completely and/or to eliminate the `Enum` constraint as well.
Would you mind summarising any differences in philosophy or functionality from [elm-export](https://github.com/krisajenkins/elm-export)?
 let ham = 1 : unionAll [map (2*) ham, map (3*) ham, map (5*) ham] I'm not really sure what I'm doing, I just started with your code and saw that the Wikipedia article said that it's useful to compute the sequence in terms of itself. This seems to do just that.
As I said in the post, the highest priority was to support the full range of Haskell data type definitions (excluding GADT's and Existentially quantified ones), and the full range of combinations of Aeson options. Another priority was to have tests that really test the Haskell/elm round tripping, instead of just checking for valid elm syntax/or ones that just compare generated code with a reference version. This comes at a cost, but it seems justified in this case. I also wanted to have an implementation that have a lower chance of turning out to be too limiting if people start using this and they require more features or find issues. There is one place I can think of that can be seen as a difference in philosophy. It is how Eliminator support types that depend on external types that you don't have access to the internals of. As I understand it, here is how elm-export lets you to describe the code that is to be generated, manually for such types. For example, say you have `ZonedTime` fields in all of your types (that you want to generate elm code for....i mean). Using `elm-export` you would do something like.. instance ElmType LocalTime where toElmType _ = ElmDatatype "Time" $ RecordConstructor "Time" $ Values (ElmField "time" $ ElmPrimitiveRef EString) (ElmField "zone" $ ElmPrimitiveRef EString) As I see it, this serve no purpose to define this in Haskell. It is not type checked to be in sync with the original data types. It is not auto generated. The only advantage I can see is that it can use types that are being generated (because it ends up in the same auto generated module). But if that is the case, then you have access to the type itself, and you wouldn't manually defining this (At least for most of the time). in Elminator, you would just pass reference to symbols from external elm modules where you can define the type, encoders and decoders in Elm itself. instance (ToHType a, ToHType b) =&gt; ToHType (MyExtType a b) where toHType _ = do ha &lt;- toHType (Proxy :: Proxy a) hb &lt;- toHType (Proxy :: Proxy b) pure $ HExternal (ExInfo ("External", "MyExtType") (Just ("External", "encodeMyExtType")) (Just ("External", "decodeMyExtType")) [ha, hb]) So I hope that is one difference in Philosophy, as you asked.
I personally excluded servant because it requires more type level awareness and type errors can get quickly out of hand. It can be a deep well to fall into if you are just getting going.
EDIT: Does elm-export supports generation of polymorphic types in ELM? I cannot make this work. data WithMaybesPoly a b = WithMaybesPoly { mbpF1 :: Maybe a , mbpF2 :: Maybe b } deriving (Generic, ElmType) spec :: Spec spec = Spec ["Types"] [ "import Json.Decode exposing (..)" , "import Json.Decode.Pipeline exposing (..)" , toElmTypeSource (Proxy :: Proxy SingleCon) , toElmTypeSource (Proxy :: Proxy (WithMaybesPoly () ())) , toElmDecoderSource (Proxy :: Proxy SingleCon) ] I am getting error: • Could not deduce (GenericElmConstructor V1)
Either, write the value before creating the new thread; or, use a reference type that's explicitly intended for it: an MVar or TVar.
Fair point indeed. But then there is the case of windows... This question might be more general than just a Haskell question, I realize.
I had to smile at the discussion that span out of this. I largely agree with your appeal to pedagogy. There is a tendency for us to overlook concepts and abstractions that were hard-won - and to be biased by the emotional satisfaction of finally understanding a thing, to an extent that we push that thing to prominence when we try to recapitulate our own learning experience for the benefit of others. For all that, I wonder if it's true to characterise the discussion that's arisen out of the sample puzzle as truly "effortless" :-)
I didn’t know that featured existed. GitHub probably has more advanced stuff I’m missing. That’d make a good blog post.
Written in Haskell, yet Haskell is the step child. Some things never change.
So, recently I found myself looking at the GHC source code ([Haddock](https://www.stackage.org/lts-12.26/package/ghc-8.4.4)). Is there a reason that every module is a top-level module? E.g. why are they not named GHC.BasicTypes, ... which sees a lot more common in other open-source projects I've seen.
I've been looking for a replacement for the 'lines of code' metric, perhaps counting the nodes in a callgraph would be more precise? Or maybe the symbol count?
Just for the record: Hamming numbers (as well as other smooth numbers) are available from `arithmoi`: http://hackage.haskell.org/package/arithmoi-0.9.0.0/docs/Math-NumberTheory-SmoothNumbers.html
"Oh brave new world, that has such languages in it!" Fun to think that the original phrase is said by a character named Miranda...
I was first introduced to Haskell in my PL class 2 years ago, but did not actually learn it enough to build real-world stuff. I want to pick it up for real recently, but I am not sure about the route I should take. During the PL course, I was following LYAH, but I felt like I was just learning new syntax, as opposed to a functional mindset. This time I researched a bit and found Haskell Programming From First Principles. I have been following it for chapters now. The book is certainly very good, but this time I feel like I do not do enough hands-on stuff. So my question is two-fold: 1) What is the state regarding haskell learning materials in 2019? Is this a good path I take? (I can handle materials which assume programming knowledge, just not functional) 2) Are there supplementary exercises you would advise to do hands-on, at the same time reading the book?
Personally, I would never require someone to know monad transformers. I don’t think they are important. On the other hand, being able to define a state monad (or continuation monad), is something I’d expect from a person claiming to know Haskell.
You can see why though, if GH want to analyse the majority of code in their repos then Haskell is, unfortunately, not their top priority ...
Your package contains a lot of cool and useful features! At our work, we are using [elm-street](https://github.com/holmusk/elm-street) package (which we've written by ourselves and maintain as well) for automatically generating Elm data type definitions and JSON encoders and decoders and much more. We've implemented this package precisely by the same reasons as you wrote `elminator`: other packages didn't solve our problems. And we couldn't improve either `elm-export` or `elm-bridge` due to fundamental reasons. But I don't see any primary reasons why your ideas couldn't be implemented inside `elm-street` (we are using `Generics` as well). Haskell already suffers from the problem that there usually exist a lot of packages for the same problem, and it's challenging to choose between them. We should try to communicate and collaborate more.
You don't have to read through a whole book before being able to start some real project. The Haskell ceiling is really, really, really high, but the minimal feature set you need to slap things together is super small. Pick a simple task, keep functions pure and total if possible, and use plain `IO` in the beginning for the rest, until have a good reason (which you could explain to somebody else) to do otherwise. This will already get you quite far. Two other books I could think of would be [Beginning Haskell - A Project-Based Approach](https://www.apress.com/gp/book/9781430262510) and the more recent [Practical Haskell](https://www.reddit.com/r/haskell/comments/bo17lw/practical_haskell_a_real_world_guide_to/), the reddit thread of which apparently has a free link for students. I would suggest you don't stick to LYAH and choose a book that comes with exercises. Haskell Programming From First Principles is a good book also, I think.
It’s fed with chunks in practice, but the byte-by-byte was for demonstration purposes.
I would have thought that such a tool is impossible because of the evaluation order difference between the 2 languages.
I wish something like json schema works on both value level and type level.
It is not a Haskell &gt; Elm transpiler. It just generate Elm source for Elm type definitions and JSON encoders/decoders from Haskell data type definitions using generics and Template Haskell.
&gt; Haskell is easier to teach than scala Felix from klarna.
Looking at the final piece of code, it feels like coerce might start showing up, `fmap Identity . runIdentity` should be just coerce - is it possible to have a functor where `fmap coerce /= coerce`?
In the book Thinking With Types, there's a chapter where he walks through automatically generating JSON Schema values from any (compatible) data type using GHC.Generics. I would highly recommend checking it out!
Hey cahsix, I hope you have a wonderful day.
Thanks! &gt;Haskell already suffers from the problem that there usually exist a lot of packages for the same problem, and it's challenging to choose between them. We should try to communicate and collaborate more. That is exactly what I am hoping here. There is no point in putting something out there that is more or less incomplete as the existing packages out there. I am hoping that Elminator can subsume the existing packages by being feature complete from the get go. That is also why I want people like you to look at it and tell me if there is any common use case that I have missed to address.
!silver
While it's definitely not as normal, I'm pretty sure cmd.exe does support executing .bat files out of your PATH without specifying the extension. There's also PowerShell (?), but I abandoned MS Windows in 2004, so I never used it. I may have been a bit gruff before; if so, I apologize. If the stack guys want to implement something like this, I think it could be a positive UX; I know that I use git aliases even on on Linux systems. But, at the moment, I don't believe stack has a feature like this, so you might look take a set back and see if your shell or OS can help you out.
You should definitely play around with Idris, maybe even go through the TDD w/ Idris book. It's certainly possible to load a JSON Schema value, use that schema to index/parameterize a type, and then read/write/manipulate values of that indexed/parameterized type.
I'm not a big fan of type-level programming in Haskell; I prefer Agda or Idris for that, but this is intriguing enough I think I will have to acquire this book.
Yes, no, maybe so. Yes, in some sense `fmap coerce = coerce` should hold (because `coerce` is a sort of super-`id`), but now the question is, "what does `=` mean?". Consider: data WonkyCoyoneda f a = Only (f a) | forall b. Mapped (b -&gt; a) (WonkyCoyoneda f b) instance Functor (WonkyCoyoneda f) where fmap = Mapped If we define `=` to be structural, then this is unlawful; `fmap id = Mapped id /= id`. But, look: extractWonky :: Functor f =&gt; (a -&gt; b) -&gt; WonkyCoyoneda f a -&gt; f b extractWonky f (Only x) = fmap f x extractWonky f (Mapped g x) = extractWonky (f . g) x Really, a `WonkyCoyoneda f a` is representing a `f a`, but there are multiple ways to write the same `f a`. We just state, by fiat, that we define two `WonkyCoyoneda`s equal if they `extractWonky` to the same value: `x = y := (forall w. extractWonky w x = extractWonky w y)`. `WonkyCoyoneda` then becomes lawful through a redefinition of `=`. `fmap coerce = coerce`, because both sides preserve the underlying `f a`, just in different ways. We must, however, hide `Only` and `Mapped`, because they don't respect our equivalence relation. --- Due to all this wonkiness, there is not a all-encompassing {-# RULE "fmap/coerce" fmap coerce = coerce #-} in the standard library. Instead, it is up to each `Functor` to provide its own rule. You can find `"map/coerce" map coerce = coerce` in `base`, and e.g. `containers` has one for `fmap @(Map k)`. For `liftYo`, if it is specialized and the `m` functor has such a rule, then `fmap Identity . runIdentity` will simplify to `coerce`. `newtype` constructors and fields will all transform into `coerce` (`fmap coerce . coerce`), the rule will fire (`coerce . coerce`), and then the whole thing should simplify (`\x -&gt; coerce (coerce x)`, `\x -&gt; coerce x`, `coerce`).
It's not necessarily `coerce` for a polymorphic `f`, since you have no guarantees that `f a` has role `representational`. Thanks for the kind words. Unfortunately we missed the cutoff for 8.8, but it should land in 8.10.
I'd *like* it. They are almost certainly going to be used. But, I'd be willing to teach, especially if they already could use monads effectively.
I literally got my Jetson Nano Dev kit in the mail last night and was just starting to scope out how to get Haskell running on it. I guess I need to build a patched GHC to make it work until they merge that patch, eh?
This is most likely a holdover from Haskell98 which did not originally include hierarchical module names, meaning all modules *had* to be top-level.
I believe the fastest Haskell implementation of a lazy sieve was available here: http://hackage.haskell.org/package/arithmoi-0.7.0.0/docs/Math-NumberTheory-Primes-Heap.html Eventually I removed it from `arithmoi`, because mutable bit sieve is still so much faster.
Cool, a static type checker for Ruby... glad you have created this.
It actually took me a while to find a program that crashed because of a missing barrier that _wasn’t_ GHC, so you might be able to get away without it for a while. I’ll put my patched binaries into cachix so others can use them.
For those like me interested in why they dropped PureScript: they were writing server(less) code, for which there is not a mature PureScript ecosystem, so too much time was spent on bindings.
Pretty cool! It's also interesting they're using and recommending `cabal new-build` and `ghcup`: https://github.com/github/semantic#development
Thanks! I am always fascinated about the types in Haskell. Definitely will check it out.
Great answer, thank you!
😢
If anyone it it’s likely to be /u/tmcdonell. maybe i should get my habds on a Jetson board...
I've been learning Erlang and I decided to implement a bit of the interface in Haskell. I've got the type `type Talker msg a = ReaderT (TChan msg) IO a` and I want to write a function `receiveTimeout :: Int -&gt; Talker msg (Maybe msg)` where `msg &lt;- receiveTimeout n` should be expected to try to get something out of the TChan for n microseconds and return Nothing if it couldn't find it. How would you go about this sort of timing with STM there? I'm worried that if I simply have it cancelled at a certain point, it may have already done things to the TChan and you could lose a message.
Kind of sad that haskell itself is not one of the supported languages for that feature.
Right now, what are the main differences between conduit and pipes from the user's point of view, e.g. in terms of features and performance? conduit used to have \`ResumableSource\` and some special consideration of resource finalization, but there was a [change early 2018](https://www.snoyman.com/blog/2018/01/drop-conduits-finalizers). &amp;#x200B; I have old code that uses \`ResumableSource\` because the way it process the later part of the input depends on what it read from the earlier port of the input. The old code fails to build with the new conduit and I'm thinking of reevaluating conduit and pipes to pick one based on new facts.
In asterius, you can switch on `--tail-calls` and the output wasm code will use wasm's native `return_call`/`return_call_indirect` opcodes for cmm control-flow transfer. Without the flag we still use trampolining, a cmm function sets a global pointer to point to next function, and the outer loop handles the calling. The "unregistered" mode of ghc compiles cmm functions to C functions which return the pointer of the next function. I suspect webghc does the same thing but not familiar with webghc internals. That being said, trampolining or not is definitely not an obstacle to calling compiled haskell code in either c or js. Under the hood you just need to assemble some closures on the haskell heap, trigger evaluation via one of `rts_eval*` APIs, then fetch the result and check scheduler status to see if the thread exited normally or got killed. The real obstacle however is rts reentrancy issue, and in the case of js specifically, the async issue. In case someone's interested I can probably draft a post..
`atomically` should leave all your `TChan`s in a well-known state, even if the resulting IO action has an asynchronous exception (e.g. Timeout) thrown during the operation. The whole point of `atomically` is that either the STM transaction is complete, or no changes were commited and any partial changes have been rolled back. At most I'd expect you might need use mask+unmask+bracket, but I don't think that necessary. Do you have a minimal example that illustrates a violation of the atomicity of `atomically` executed STM?
Now I wonder if GHC does something like ReduceThunks. &amp;#x200B; I wonder what advantages they see in Iridium over something like STG. I guess at the least you can apply imperative optimizations easier.
[https://www.futurelearn.com/courses/functional-programming-haskell](https://www.futurelearn.com/courses/functional-programming-haskell) I took this course a year back. A primer on haskell. For a decent depth learn you a haskell is good. And book my graham hutton has a also good deal of exercises.
From my perspective it doesn't make sense - x isn't *either* a number or an even number, so why model it this way? Assuming you're parsing a string and this is your output, and that you need both bits of information I'd say you should have: data OddOrEven = Odd | Even And then: Either String (Number, OddOrEven)
&gt; so why model it this way? Ok then my case would be like, how do I pattern match for a case called "both" ?
Do you mean you want multiple cases for the structure? data Matcher a b = One a | Two b | Both a b
You don't, because it is completely impossible for a single Either value to be both. It corresponds to a *disjoint* union of the two types. You would need a different type for this.
Yeah! Something like this! I liked the way you combined the product "Both" in the sum type.
Happy to help!
Yes. It will be helpfull to know about that "Overlapped" type. There are many realtime usecases that will benefit from this. Especially the inheritance in OOP. Say `class Animal extends Organism {}` How do I type saying EitherOrBoth&lt;Animal, Organism&gt; and pattern match it for Animal, Organism, or Both
I'm not sure if this is the best solution to your problem, but check out the [these](https://hackage.haskell.org/package/these) package which implements "an either-or-both data type".
When learning, it's great to discover and define this type, but FYI it exists as These https://hackage.haskell.org/package/these-1/docs/Data-These.html#t:These Using this library type could also open up some functions that work for it and so may also work for you use case.
Haskell got me into a practice like "Thats concept is already present". Thanks a lot for the suggestion. I will do it on my own before I use "These" type.
A packaged-up solution for Haskell is [these](https://www.stackage.org/haddock/lts-13.24/these-0.7.6/Data-These.html)
In Haskell, this pattern is not typically done with Either variants. Instead, use typeclasses.
I am more interested in type algebraic way, so that I can represent this as a equation in sums and products.
Haskell doesn't have inheritance, though. So in the context of Haskell, your question doesn't make sense, because a value *cannot* be both an `Animal` and an `Organism`.
But thats the case what model happens to be. Seems both case needs to be modelled explicitly.
I'm... really not sure what you're looking for here. A thing *cannot* have two types in Haskell. There's a ton of ways to model hierachies with ADTs and type classes and functions, but inheritance is not one of them. For example: data Animal = Cat | Dog | Rabbit data Plant = Tree | Flower data Organism = Animal Animal | Plant Plant An organism can be either an animal or a plant, but the value `Dog` has type `Animal`, and *not* type `Organism`.
But a Dog has the type `Organism&lt;Animal&lt;Dog&gt;&gt;` isn't it ? So this problem comes down to inheritance vs composition argument. So the presence of this inner level of pattern matching in OOP makes us to foresee this type composition. Or am I missing something here ?
No, `Dog` just has type `Animal`. You could have `(Animal Dog)`, which has type `Organism`, but then you can't tell from the *type* what kind of organism it is. You can pattern match on it to find out, though: whatKind :: Organism -&gt; String whatKind (Animal a) = "It's an animal!" whatKind (Plant p) = "It's a plant!"
Is dataHaskell project hit a pause?
[https://www.youtube.com/watch?v=h\_D4P-KRNKs&amp;list=PLguYJK7ydFE4aS8fq4D6DqjF6qsysxTnx](https://www.youtube.com/watch?v=h_D4P-KRNKs&amp;list=PLguYJK7ydFE4aS8fq4D6DqjF6qsysxTnx) I believe this playlist might suffice
It might be worth making the value constructor names different from the type names here.
&gt; So this problem comes down to inheritance vs composition argument. Yes. Your original example could be modelled as: data EvenNumber = EvenNumber Number An even number is a number plus something extra. This something extra is the knowledge that the number is even but it is invisible here because we can't express it in Haskell.
I learnt Haskell by starting with the book [Learn You a Haskell for Great Good!](http://learnyouahaskell.com/), which the author has kindly made freely available online. It's a gentle introduction to the basics of Haskell programming; although it's very slightly outdated, the vast majority of its content is still applicable. I would then highly recommend going through Stephen Diehl's amazing article [What I Wish I Knew When Learning Haskell](http://dev.stephendiehl.com/hask/) (abbreviated WIWIKWLH), an incredibly comprehensive guide to most of the Haskell ecosystem. After going through the first few sections of WIWIKWLH (the rest is fairly specialised to covering particular libraries and areas), the best way to learn is simply to think of any interesting project and then trying to implement it using Haskell. (If you want inspiration, I did a [Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life) simulator and a [`.pls`](https://en.wikipedia.org/wiki/PLS_(file_format)) manager.) Although the books are important, I learnt most of my Haskell knowledge by simply trying to build something and gradually getting better at my skills as I implement things.
The `x` h2 uses comes from different scope. It is obvious, if you use `a` as a name for variable: h1 a = iterate g a where g x = f x x h2 a = iterate g a where g = f a
I’ve got a blog, where I’ve been doing an introduction to Haskell series. [Blog Link](kylecotton.github.io)
There is a GHC proposal to rename modules: * https://github.com/ghc-proposals/ghc-proposals/pull/57
I follow [Haskell book](http://haskellbook.com) and listen to [Lambda cast](https://soundcloud.com/lambda-cast). The book is nice for systematic study and the podcast is nice for these aha moments.
They haven't been abandoned. I'd say it is mostly that: * On the practical side, the use cases for which `Arrow` is a compellingly convenient means of expression are somewhat more specialised than those of, for instance, `Monad` and `Applicative` (the latter was, in fact, discovered a few years after `Arrow`). * On the theoretical side, `Arrow` can be factored into separate concepts (that kind of explains why it has so many laws). For instance, an `Arrow` is a `Category` that is also a [`Strong` profunctor](http://hackage.haskell.org/package/profunctors-5.4/docs/Data-Profunctor-Strong.html). Those other conceps only found their way into Haskell years after `Arrow` was originally formulated. [Opaleye](http://hackage.haskell.org/package/opaleye) is an example of a popular contemporary library that uses arrows. For a very interesting, relatively recent post discussing arrows, see Will Fancher's [*Profunctors, Arrows, &amp; Static Analysis*](https://elvishjerricco.github.io/2017/03/10/profunctors-arrows-and-static-analysis.html).
It's common practice to use `-Wall -Werror` etc to prevent this sort of mistake, FYI. (Somewhat indirectly, in this case.) Shadowing names causes a warning.
There is a technical wibble. The category of strong profunctors gives you everything you need for talking about arrows, but what you get with Strong and `Category` isn't quite that notion. https://www.eyrie.org/~zednenem/2017/07/twist
I used arrows in a commercial project in 2010 - a rule engine for malware detection on web sites. It worked out pretty nicely. I've been meaning to investigate to see whether there's a more "modern" way to implement rules along these lines. Here are some example rules from that system: ```type Rule = GenRule Tree -- only requirement on t is that it be Foldable type GenRule t = ReaderArrow String (Kleisli IO) (t Resource) Bool -- data Resource = ... -- domain-specific type representing processes, windows, files, etc. rule_PdfExploit :: Rule rule_PdfExploit = (unsafeProcesses &gt;&gt;&gt; isAny) &lt;&amp;&amp;&gt; (processes &gt;&gt;&gt; has acrobat) &lt;&amp;&amp;&gt; downloadsPdf &lt;&amp;&amp;&gt; downloadsBinary rule_Clean :: Rule rule_Clean = no unsafeProcesses &lt;&amp;&amp;&gt; no files &lt;&amp;&amp;&gt; no windows &lt;&amp;&amp;&gt; no nuisances &lt;&amp;&amp;&gt; no registry```
Thank you; I have amended my comment.
I didn't realize that, thank you. I do not know that much about STM, I didn't know how strong the atomically guarantee was.
Thanks, that cleared it up entirely!
[This](https://blog.jle.im/entry/free-alternative-regexp.html) is an interesting post by Justin Le about writing a regular expression parser using a free alternative. Would the free alternative (without reaching all the way to monad) be powerful enough for handling context-free languages as well? I think the answer is yes, but the post doesn't explicitly mention it.
&gt; the way it processes the later part of the input depends on what it read from the earlier port of the input I personally like the [streaming](http://hackage.haskell.org/package/streaming) package. It doesn't have intermediate stages as a separate type, only `Stream`s and functions `Stream -&gt; Stream`, or functions that eliminate the whole stream and return to the underlying monad. I would have a function like this: ``` stuff :: Stream (Of a) IO r -&gt; IO (HeadParseResult, Stream (Of a) IO r) ``` It consumes the earlier part of the input and returns a result along with the rest of the effectful stream. You can continue your processing depending on the result.
&gt; see Will Fancher's Profunctors, Arrows, &amp; Static Analysis. Note that there's a chance I've made an error in that post which I haven't attempted to correct. It's been shown that [`ArrowChoices` are `Traversing`](https://github.com/ekmett/profunctors/pull/40/files), which indicates that *maybe* there should be some laws preventing the nutty hacks I showed with `Traversing`. It's possible that you shouldn't be allowed to create a `Traversing` instance that behaves differently than the free instance you get from your `ArrowChoice` instance, which would put my `Traversing` hacks squarely in the same realm as `haxl` again.
Coroutines are Arrows and can be used in FRP (functional reactive programming). There's a good tutorial here: https://github.com/leonidas/codeblog/blob/master/2012/2012-01-17-declarative-game-logic-afrp.md They let you cleanly express functional dependencies while maintaining state across multiple "steps" through the components of the coroutine. This is a good example function from the above link: playerPos :: Coroutine Keyboard PlayerPos playerPos = playerSpeed &gt;&gt;&gt; integrate startPos &gt;&gt;&gt; arr (\y -&gt; (10, y)) It shows how the current position of the player's bat is purely a function of the keyboard inputs as the game ticks on (hinted at in the function signature).
There's a "Learning material:" section in the sidebar.
 type Rule = GenRule Tree -- only requirement on t is that it be Foldable type GenRule t = ReaderArrow String (Kleisli IO) (t Resource) Bool -- data Resource = ... -- domain-specific type representing processes, windows, files, etc. rule_PdfExploit :: Rule rule_PdfExploit = (unsafeProcesses &gt;&gt;&gt; isAny) &lt;&amp;&amp;&gt; (processes &gt;&gt;&gt; has acrobat) &lt;&amp;&amp;&gt; downloadsPdf &lt;&amp;&amp;&gt; downloadsBinary rule_Clean :: Rule rule_Clean = no unsafeProcesses &lt;&amp;&amp;&gt; no files &lt;&amp;&amp;&gt; no windows &lt;&amp;&amp;&gt; no nuisances &lt;&amp;&amp;&gt; no registry
When would you ever hit the Animal-but-not-Both pattern?
Now that I am diving deeper into FM and FMC, I have yet another set of questions if you don't mind :) Assume I want to reduce waste as much as possible. Then instead of targeting FMC, I should target FM, as the later will be typed at some point and reject programs which do not respect the stratification condition. Is this correct? (I was rejoicing when I saw that FMC is somewhat more relaxed, but obv. there is no shortcut to make the magic happen) In [your introductory article,](https://medium.com/@maiavictor/introduction-to-formality-part-1-7ae5b02422ec) you show these both examples: // no box between bound and use location .main [val = | id] (val val) // exactly one box, good .id [x] x .main [val = id] | (val val) I don't understand the boxing in the second program. What exactly do we put into the box? What I understood is that you always have to box a value before being able to `dup` it, so the first program makes sense to me (boxing `id` prior to `dup`ing it). Another box related thing: [In the wiki](https://github.com/moonad/formality-core/wiki/Dups-and-Boxes), you write "dup x = #a ... | Unwraps a from a box, makes n copies of it as x". Does that mean that I can use as much copies of x as long as they stay in the same box layer?
 I accessed Reddit right when you asked! &gt; Assume I want to reduce waste as much as possible. Then instead of targeting FMC, I should target FM, as the later will be typed at some point and reject programs which do not respect the stratification condition. Is this correct? What do you mean by waste? Yes, by compiling to Formality (which will be reworked to be more user-friendly) you avoid programs that deal with boxes incorrectly during runtime (in the same way that typed languages prevent you from adding integers to strings). &gt; I don't understand the boxing in the second program. What exactly do we put into the box? In the second program, `(val val)` is inside a box, nothing else is. It is incorrect because `id` used to be on `layer 0` (no boxes surrounding it), but then is moved to layer 1 (1 box surrounding it). Yes, the boxing system basically is there to make sure that terms don't move from a layer to another. Yes, you can make as many copies of a value as you want, as long as it doesn't move from a layer to another layer. Note that a duplication is triggered by a lower layer, i.e., the duplication of a term on layer 3 is triggered by a `dup` on layer 2. This is what prevents things like `(λx.(x x) λx.(x x))`, since on this case the duplica Does this make sense?
And here it is: [https://gist.github.com/osoftware/5aad2ca13798cbc5919b43aacb0e33e1](https://gist.github.com/osoftware/5aad2ca13798cbc5919b43aacb0e33e1)
Gee, and I was already amazed by your responsiveness before you just instareplied! Going to bed now though, it is late where I live, even though tasty lambdas are waiting\^\^ &gt; What do you mean by waste? Sorry, I was being imprecise - I meant duplicating work that could have been prevented by satisfying the stratification condition. &gt; In the second program, (val val) is inside a box, nothing else is. It is incorrect because id used to be on layer 0 (no boxes surrounding it), but then is moved to layer 1 (1 box surrounding it). Now I am a bit confused - just to be safe: The second program is correct? (I think it should be according to how I understood your article: https://medium.com/@maiavictor/introduction-to-formality-part-1-7ae5b02422ec). Assuming that the second program is correct, then it makes sense to me. Also if your explanation "It is incorrect because ..." refers to program 1, then it makes sense. Btw, do you already have a compiler that translates λ-terms into FM-terms (but obv. not all of the possible λ-terms)? I would start with trying to formulate this as an SMT problem, but I would be glad for any starting point!
So, I've spent quite some time trying to grok recursion schemes by now. I'm not up to chronomorphisms yet, but could make some modes progress with histomorphisms. In [this blog post](https://blog.sumtypeofway.com/recursion-schemes-part-iv-time-is-of-the-essence/),a histomorphism is used to solve a variant of the coin-change problem, but it is one-dimensional. Since you seem to have some experience, how would you approach the more general matrix-like DP problems? I've tried using a histo inside a histo, but that seems to be a dead end. Maybe some clever choice of what to put inside the `Cofree`?
&gt; I meant duplicating work that could have been prevented by satisfying the stratification condition. I'm not sure I get it, if the program is not stratified then it isn't valid (it is a compile time error). The second program is: dup val = {x} x # val val It is not correct. Why you think it is?
I use them occasionally, probably more than most, hah. `optparse-applicative` has an arrow interface that I find more pleasant than the default one, and I’ve described things like circuits and build rules with them. Recently I wanted to wrap some explicit procedural `IORef`-based graph construction up in a more declarative representation with stronger types, which I realised I could use the free arrow for, then got `proc` notation for free. Unfortunately the `proc` desugaring isn’t very well optimised (last I knew), because few users are demanding it.
I created a library to make it a bit easier to encode/decode “extra” things on top of data types. Do you think this would help? https://www.stackage.org/haddock/lts-13.24/composable-associations-aeson-0.1.0.0/Data-ComposableAssociation-Aeson.html
Perfect, got it! &gt; You can easily check this with fmc! Will play around with it soon! :) Thank you!
 boundedNonEmpty :: (Bounded a, Enum a) =&gt; NonEmpty a boundedNonEmpty = minBound :| drop 1 [minBound .. maxBound]
Nope it's still active! You should check the gitter chatroom
1) you're taking a pretty good path! HPFFP is a big reference, and probably the best for first comers 2) in HPFFP, you have many of "implement this yourself" sections! But for more than these you should search through the sub for suggestions, it's a standard question. For example I've been told that at the end of HPFFP it's really good to implement your own parser combinator
I was interested in using arrows a couple years ago (for functional reactive programming). I have a couple of thoughts based on that experience: 1. The style for using arrows is very different than the typical style I would use in Haskell. It feels like another language within the language. For this reason I expect little use of arrows because there is a lot of learning overhead. 2. A number of libraries and packages were made based on arrows. But it seems they haven't matured and a bunch have been abandoned. It was hard to build a project around very experimental arrow libraries. That's mainly why I stopped using them. 3. I haven't noticed that there is a "killer application" for arrows. I think most problems can be tackled with the tools we have already. Functional Reactive Programming was supposed to be a major application of arrows but I haven't seen that develop much either (though I haven't been paying much attention recently).
Ah, very nice... from there it looks like boundedNonEmpty :: Enum a =&gt; NonEmpty a boundedNonEmpty = toEnum 0 :| drop 1 [toEnum 0..] actually lets us drop the `Bounded` constraint. Perfect. Thanks.
I use it atm for to create a server framework. A server is a function `Request encodedBody -&gt; Response encoded` and arrows makes modifying this trivial. For instance the setContentType function contentType : [(contenttype, a =&gt; encoded)] -&gt; arrow (Request b) (Response encoded) -&gt; arrow (Request b) (Response a) contentType checks if the request has one of the supported accept headers and then sets the correct response encoder and response content-type. This pipeline is trivial with arrows: contentTypes supported myArrow = myArrow &amp;&amp;&amp; arr (makeEncoderFromReq supported) &gt;&gt;&gt; unsplit setEncoder The end result is an api that reads like a specification and automagically handles most status codes, can easily be composed, easily be extended.
I'd like to point out that your own progression mentions teaching map before ADTs. Sure, maybe you didn't use the f word, but you introduced functors.
So whenever you use addition you're introducing monoids?
I mean you have to add a `Num` constraint in that though. I would personally stick to the Bounded approach although it depends on the use case.
Well, not `Num`, but `Enum`, which we already required... but I just realized in my eagerness to reduce constraint I got off track from my original goal which was to handle something `Bounded`.
You absolutely need `Num`, otherwise how will `0` and `1` be resolved?
I did try it out... it worked exactly as I wrote it without `Num`... `0` and `1` are just parameters to `toEnum`.
Oh oops. Totally skipped over the `toEnum` call. Yeah fair enough, although `toEnum` is often partial isn’t it? Ugh Haskell’s ordering hierarchy is so weird right now. Enum and Ord and Bounded are all completely unrelated to one another, when they should all at minimum share some underlying POrd or similar, I think subhask does a good job of it.
When I have to handle Animal specific function to be called on the object like `walkUsing4Legs(a: Animal)`
Sadly in Haskell you can't tack a field onto an existing data type. You have to create a new data type that contains both the original data type and the new information. You would make your first API call, pull out the data needed to make the second API call, make the second API call and only then construct the new compound data type.
Thanks for this! I did consider it but thought it felt wrong. So here I potentially have a RecentlyPlayedWithGenre data type.
In [Compiling to categories](http://conal.net/papers/compiling-to-categories/) they say "Cartesian categories are closely related to arrows [..]". What is the relationship between arrows and compiling to categories?
Strictly speaking, yes. However, addition is an arithmetic operation that we're all familiar with. Additionally, addition is a special case of a monoid, so you are not introducing the general purpose monoids. However, map is the generalized operation on functors, and we weren't mapping functions in grade school and have no prior context for it. Regardless, I just found it ironic that your headline was to not mention functors before ADTs, then you specifically advocate for teaching functor mapping prior to introducing ADTs
Then it's specifically an animal, but it's also still an organism.
Well, when developing "real" applications I rarely create my own monads from scratch, while I use transformer stacks all the time. Aftet comprehending monads, monad tranformers are easy step, but it's still worth to know what's the difference between ``ExceptT e (StateT s m)`` and ``StateT s (ExceptT e m)``
To get some reuse, you could parameterize `RecentlyPlayed` with a type constructor of kind `Type -&gt; Type` that would wrap each `Track`. Then you could have `RecentlyPlayed Identity` and `RecentlyPlayed ((,) ExtraTrackInfo`.
For `optparse-applicative`, have you tried using `ApplicativeDo`? My approach is to `ApplicativeDo` with `RecordWildCards`, so I can write something like:
Nice read: [https://github.com/github/semantic/blob/master/docs/why-haskell.md](https://github.com/github/semantic/blob/master/docs/why-haskell.md)
Did I miss the bit where they mentioned the HS -&gt; JS tooling they opted for when switching from PureScript?
You could read the responses from the requests as aeson values, use lenses to get the right fields, merge them, and only then convert to the haskell data-type. This way you don't get an incomplete intermediate haskell datatype.
SimSpace looks cool, but not sure if they hire overseas, I see US citizenship/GC as requirement even for remotes
While I use arrows on a daily basis (thanks to Opaleye), I don't quite understand what arrows can do that other stuff can't (eg. functions, monoids, functors, monads, etc.)
&gt; Sadly in Haskell you can't tack a field onto an existing data type. If you want a datatype whose "tail" varies you can do that though. data RecentlyPlayedWith a = RecentlyPlayed { ..., with :: a } type RecentlyPlayed = RecentlyPlayedWith () type RecentlyPlayedGenre = RcentlyPlayedWith Genre Some functions can work polymorphically on any tail; some functions will require a specific tail. replaceTailWithGenre :: Genre -&gt; RecentlyPlayedWith a -&gt; RecentlyPlayedGenre replaceTailWithGenre g x = x { with = g }
I'm sure he's advocating for teaching **list** mapping prior to introducing ADTs, not generalized functor mapping. `map` in the Haskell 2010 report only works for lists, not any functor. In Haskell the generalized function is traditionally called `fmap`.
I just found this blog series. It's _fantastic_! You should consider putting your blog on Planet Haskell :)
The GHC api has a bunch of things named with an 'X'. For example, https://www.stackage.org/haddock/lts-13.6/ghc-8.6.3/HsImpExp.html#t:IE: `IE pass` has a constructor `XIE :: XXIE pass -&gt; IE pass`, and all the other constructors take an `XIE_ pass` as their first argument. What are these for? It looks like the "X" might be for "Extension", but that's all I've got.
That is exactly right! The `X` constructors allow each data type to potentially have some extra constructors depending on the compilation pass (parse, rename, typecheck, &amp;c). There is more information and some relevant links here: https://gitlab.haskell.org/ghc/ghc/wikis/implementing-trees-that-grow
There's [a recent talk](https://www.youtube.com/watch?v=z2ete8VZnZY) as well!
https://atypeofprogramming.com Is totally worth a read-through.
Happy to see another use of Haskell in the mainstream!
&gt; There are many aspects of Haskell that make a project as ambitious as Semantic feasible: strong typing, lazy evaluation, and purity, to name but a few. Yet Haskell is essential for a separate reason: its support for rich, user-defined control flow. Rich, user-defined control flow is a direct result of lazy evaluation. It might be possible to achieve it in a mostly-strict language, but I don't believe that's clear -- I've never worked with a strict language (even one with a standard Lazy functor) where user-defined control flow is to seamless with the rest of the native control flow and as flexible.
Sure, that works fine. And this is one rare instance where I’ve used `RecordWildCards` recently, although in general I prefer `NamedFieldPuns` for the explicitness.
I think if arrows had been slightly more generalized, by removing `arr` and adding more methods to build the data flow graph - it could be a much more useful class. It could represent computations that are fully inspectable. That allows library-level code to compile them to GPU, or do any form of static analysis. Once "arr" is introduced -- the actual computation becomes opaque to all but GHC itself. At this point, I think the Arrow framework doesn't add much over usual Functor/Applicative/Monad (and occasional Profunctor) classes. I think that's pretty much what /u/conal 's [CCC](https://hackage.haskell.org/package/category-extras-0.53.5/docs/Control-Category-Cartesian-Closed.html) is about.
&gt;Editor tooling is sub-par (especially compared to language communities like Java and C#) and finicky - we often end up just compiling in a separate terminal. What is this about? Don't we have tools now, that can reliably give live errors and error navigation in editor? Stuff like fast-tags for code navigation? HLint and HIndent for code formatting and linting? Can't you access all of these from the editor itself?
Ha ha ha ha ha ha ha ha ha but it's not inconsistent. Dot is an operator, not a function.
The VSCode integration is good when it works but it’s pretty unreliable for me as well and requires compiling haskell-ide-engine from scratch which is a pretty high barrier to entry compared to other integrations.
&gt; ++count_static_typing_superiority_witnesses I smell state
&gt; Rich, user-defined control flow is a direct result of lazy evaluation Are you sure? PureScript doesn't have lazy evaluation, but it has the same user-defined control flow as in Haskell.
I don't get it. Isn't what the author is doing more or less typical use case for property based tests? Like a sorting algo where you can easily input properties of a sorted list. I would like to see this applied to real world dirty/messy use cases where it is not clear what the properties to be tested for are.
Aren't there tools that just wrap the ghci and use it to provide editor integration? I have myself written such a tool, and have been using the same for a while now, it works great. It just use 'ghci' so if 'stack ghci' works for you, then the tool is good to go. It was couple of years back that I wrote it, but since then I think I have seen many such tools appear for various editors. Why aren't more people using them?
I think killer apps are for samey languages. Ruby/Python/JS are so similar you need a killer app to differentiate them (Rails, NumPy, browser, nodejs, w/e). You move to a language in this circumstance because of (1) its killer app and (2) that it's pretty much the same as what you already know _but it has the killer app!_ Haskell is too different much all at once.
I’d love to see some examples in this documentation. Since a lot of technical jargon I used it would be nice to see some code, in order to better understand what they mean. E.g. I’d like to see an example of the following. &gt; Because Semantic is, at its heart, an interpreter, this feature is *essential* for rapid development: we specify, when constructing interpretation and analysis passes, how GHC should handle errors while executing untrusted and possibly-invalid code, simply by specializing our call sites. I’m sure there exists at least a couple different interpretations of what “specializing a call site” could mean.
Seems to be the same reason Facebook used it and one of the well-worn areas that Haskell has proven itself (language parsing/analysis). The section about their experience *using* Haskell compared to other languages is really interesting though.
&gt; Is this Haskell's "killer app" that will convince certain developers? At least one developer I know doesn't want to talk about broad, incremental, improvements but rather a single "killer app". Perhaps, a "kill app" for FP isn't a realistic goal given that most programmers' mindsets and investments are deeply entrenched in imperative, programming languages.
It might be due to the wide adoption of heavy IDEs that compile and report errors as you type. It's the workflow, I believe, for most programmers.
&gt; I've never worked with a strict language (even one with a standard Lazy functor) where user-defined control flow is to seamless with the rest of the native control flow and as flexible. Anyone know how `call/cc` compares with lazy evaluation for this purpose?
1) Can I use typeclass constraint in instance declarations? &amp;#x200B; 2) Suppose we have an Applicative Functor \`F a\`, how does one define the rule between the composition of the context \`F\` when comes to \`&lt;\*&gt;\` or \`\*&gt;\`? The example I've seen uses \`&lt;&gt;\` from semigroups, but how do I \_know\_ what it uses?
Laziness allows you a certain amount of user-defined control flow. A good macro system allows much more.
There are multiple VS Code Haskell plug-ins: https://github.com/dramforever/vscode-ghc-simple seems a lot more reliable, and doesn’t require compiling anything (uses GHCi internally).
&gt; Aren’t there tools that just wrap ghci […] Yes: https://github.com/dramforever/vscode-ghc-simple (and it’s the best Haskell IDE experience out there IMO)
The situation is generally that there's a lot of tooling, but there's no single, straight-forward way to use it all. C# users probably use Visual Studio Code, Java users use IntelliJ or Eclipse. Haskellers don't have professional tool writers; just a couple companies that sometimes get paid by clients to improve tooling somehow (Well Typed, FP Complete), but nothing like Microsoft or JetBrains (a 700 employee company). Haskellers don't like to pay for stuff, so any kind of crowdfunding effort is unlikely. The demographics of tool writers tend to be Emacs or Vim users, which means VS or Atom experiences receive less effort. We actually have a lot of tooling that is great but nobody uses it because it's hard to use out of the box. For example, Haskell Program Coverage (HPC) is something that I've seen rarely used in our community and in professional work. We put a lot of work into Stack to make `--coverage` work (work on `--profile` was pretty easy). The module handling it is a mess of flags and dir locations and files. Have you tried to use HPC by calling `hpc` by itself recently? I tried to do that with a client on a call and we ended up giving up and deciding to move the code we wanted coverage on into the test suite. Plus, the Haskell tooling ecosystem is a moving target. Cabal install hell used to ruin people's day, so we came up with Stackage and Stack, so you gain a step forward writing tools when you can assume stackage snapshots and packages-within-a-project, but then every second client project I see uses Nix, so now you're back to square one and a whole extra tool to learn. It's not even a bad direction; Nix is cool. We also have `cabal new-build` which expands the surface area. But the fact that we're still figuring things out also contributes to there never being a "just works" situation for Haskell.
If you're using Nix (which works on all Linux distro's), I'm providing precompiled Linux and macOS binaries for all haskell-ide-engine versions with https://github.com/infinisil/all-hies
You could default whatever field you know will be coming later to some empty value, then update it later on: ``` data RecentlyPlayed = RecentlyPlayed { title :: String, genre :: String } deriving Show emptyGenre = "" createRecentlyPlayedWithTitleOnly = RecentlyPlayed "High and Low" emptyGenre addGenre :: String -&gt; RecentlyPlayed -&gt; RecentlyPlayed addGenre g recentlyPlayed = recentlyPlayed { genre = g } main = do let recentlyPlayedMusic = createRecentlyPlayedWithTitleOnly updatedTrack = addGenre "Shit good music" recentlyPlayedMusic print updatedTrack ``` https://repl.it/repls/ImperturbableRegularMegabyte
Haskell’s “killer app” is the ability to write code that is clear, concise and correct!
never got my hands on a Jetson board unfortunately ):
Cool, I’ll have to try that out. I think part of the reason I started using HIE was because of the autoformatting with brittany which is a pretty critical feature for me. Maybe there’s some other way to integrate that into VScode.
Obviously OP meant Prelude.map. However, list map is basically just fmap that only works on lists (fmap for lists is defined to be map). My understanding is that Prelude.map only working on lists is a historical wart, and the only reason that it hasn't been generalized is that it will break too much code. Once again, we're splitting hairs here. Functors are really not that complicated. They have an operation. They have a name. They have a few laws that you don't care about if you're just using them. OP is advocating for teaching the operation, just not naming the concept or acknowledging the existence of laws. These two things are really are just a footnote, you could put a [1] next to them in text that links to a thing at the bottom of the page that says something to the effect of "this thing is called a functor. You can read more about it at link_to_the_chapter_on_functors." In my opinion, "If you're writing a Haskell tutorial, please don't mention functors before an in-depth exploration of ADTs" implies that OP considers ADTs to be more fundamental than functor map, and that they should receive an in-depth exploration before any mention of functors. Mentioning map is mentioning functors. All OP is accomplishing is not saying the word "Functor", which is about as useful as explaining for loops to a new imperative programmer without mentioning that they are called "Loops".
&gt; In this model, actions not only modify the project state, they also return another action, its involution, that reverses the effects of the original action. Thank you for teaching me a new word, but it doesn't make sense in this sentence. According to the Wikipedia link you have there, an involution is a function that satisfies `f(f(x)) = x`, i.e., is its own inverse. An *involution of a function* is identity, so your sentence states that an action returns itself. I think you should replace "its involution" by "its inverse".
Where Haskell shines and fits your needs: Concurrency. It is extremely and easy to even parallelize computations, because of the pure functional nature of haskell. DSLs. Those are at least sometimes useful when it comes to data science, since those make defining systems of any sorts quite simple to define. Also, take a look at http://www.datahaskell.org/
Yeah US/Canada for now
`State# RealWorld`
nice.
&gt; The demographics of tool writers tend to be Emacs or Vim users, which means VS or Atom experiences receive less effort. As far as I can see, it should be possible to create a single library which contains most of the IDE engine-logic. Emacs/Vim vs VS Code/Atom is just about managing text on a screen, which should be possible to factor out into a smaller bit of IDE-specific code.
You mentioned `text` moving to true UTF8 - have their been developments in that direction recently? Waiting on the edge of my seat here :)
Yeah, I seriously considered using the lens operator that incremented via a lens into the monad state, since this is /r/Haskell, but couldn't remember it off the top of my head. (Been writing Java-ish Scala today.)
I am a complete beginner yet implemented a logic simplification trainer &amp; proofer website, that shows what steps to take in a weekend. The power for grammar expression and their manipulation in haskell is insane! I also love how the community doesn't shy away from calling things what they are. 'oh, this structure creates a ring? yeah, let's call it that!' instead of 'object with 2 methods, look in the documentation for details because there are subtle, non obvious differences between their application.'.
Also, it just randomly stops working until I restart VS Code...
Haskell-ide-engine and the LSP is supposed to do this, but it's not as easy as I'd like it to be yet.
That's what haskell-ide-engine is going for, but from what I hear it's underwhelming.
But we already have that, and Haskell hasn't taken over the world yet :P
How could a macro system implement laziness? I mean, functions in Lisp do not expect thunks so you'd have to overload every single function application to deal with thunks?
There are relatively recent comments on [https://github.com/text-utf8/META/issues](https://github.com/text-utf8/META/issues), but it doesn't look like anybody determinedly pushes that project forward.
Thanks! This page in particular gave some fairly clear explanation and motivation: https://gitlab.haskell.org/ghc/ghc/wikis/implementing-trees-that-grow/trees-that-grow-guidance
Thanks! Forked.
You might be interested the paper "The Real Sieve of Eratosthenes" by Melissa O'Neill. Like you she uses a 2357 wheel but with a PriorityQueue instead of lists. At the end she discusses the list version and how does an analysis of its asymptotics. https://www.cs.hmc.edu/~oneill/papers/Sieve-JFP.pdf
Whenever I use explicit recursion, I am told not to, to use module functions instead so I never know. Your's does have three more 'map' functions. Iterate is, of course, recursive. At first I was using list comprehensions and 2\^e, 3\^e and 5\^e. and calculating the 3\^e X 5\^e in a separate function because of the copious coding.
How do you write a short-circuiting function/operator like `(&amp;&amp;)` or `(||)` or `(&gt;&gt;) :: Maybe a -&gt; Maybe b -&gt; Maybe b`?
You can generate large amounts of code that generate exactly the flow you want, turning that flow into something that looks quite like a normal function call. It's, IMO, quite inferior to the need-driven evaluation of Haskell, but amazingly useful in strict languages.
&gt; if anybody would like to chime in on where Haskell would shine over Python/C that would be appreciated. Refactoring in specific and maintenance in general. Referential transparency makes it easier to combine/split/move code. The more information you put in the types, the more complete the checks the compiler will do for you and that paired with coverage analysis can catch things that might be (temporarily) forgotten during the evolution of some code.
That's because it depends on `ghc-mod` and `haskell-src-exts`, which are too much of an effort to develop (due to duplicating GHC code). Currently, I believe the solution with the most favorable cost-to-benefit ratio is creating a wrapper around GHCi, since this avoids the aforementioned code duplication. It would be preferable to have GHCi available as a library of some sort, and execute the GHC-specific logic via that, but running the `ghci` executable in a background process is a simpler option.
In other threads, they've already been pointed at that paper, and read it. `unionAll` is doing something priority-queue ish.
@kuribas could you provide an example of this at all? Thanks
This looks great, would this play nice with aesons 'decode'? I'm not quite sure how I'd implement this in practice, this is the code in working with https://github.com/imjacobclark/Recify/blob/master/src/Types/RecentlyPlayed.hs#L57 - could you maybe provide an example of this?
I have the paper and read quickly through it. I have question about her wheel method. The Haskell module `Data.Numbers.Primes` `wheelSieve` is based in part on O'Neill's method. My function is almost twice as fast.
I'm a very happy user of haskell-ide-engine. It's fragile, so I need to restart the editor once in a while, but I think it's fantastic while it's working.
I suppose you could always write as an unfold, or using `fix`, if you want to avoid the explicit recursion. I'm not sure how to maximize sharing with an unfold, but I did always like expressing these types of sequence as fixed-points anyway.
I think it's even better to get rid of the `CLIArgs` type and write: do x &lt;- OptParse.option y &lt;- OptParse.option return $ do -- Your "main" goes here
Yeah, if you have a lawful `Arrow` instance, all you can inspect statically is an ordered list of side effects, without any information about the dependencies structure. So, all hope of parallelism is lost. This is still a meaningful point between `Applicative` (no data dependencies) and `Monad` (no static information) though.
It's well worth your time to learn to at least read Haskell code, better if you struggle through some problems and try to write some too. It forces you to think about the problem at a higher level since you suddenly can't just imperatively instruct the computer in what to do. Even if you don't end up using it in production, you might notice an increase in your proficiency with your original language. This has been the case for me anyway, I've had to fall back on C# to complete some tasks after struggling unsuccessfully for a while to implement them in Haskell. The actual imperative code turned out to be slicker and simpler than I would have written it originally. I've found this to be a benefit of Haskell experience; when you fall back to imperative code (for performance/efficiency or whatever) you might notice you have more conceptual clarity than before.
Can’t I get all this from a BST written in C and compiled to a .pyd? Perhaps not from Python but C is strongly statically typed. Why would an FP implantation be ideal over an OO implementation?
&gt; This looks great, would this play nice with aesons 'decode'? Sure, I didn't have any problems with using it with aeson serialization before. Though, I think I used some extensions so I could write separate instances for different "tails"; you could do that, though it's not the first thing I'd reach for these days. You can use the default Generic instance, if you get to choose the JSON format. If that doesn't work your could write a polymorphic instance with a context that mentioned the type variable maybe it's own FromJSON instance (e.g. `instance FromJSON a =&gt; FromJSON (RecentlyPlayedWith a) where ...`) -- the context you give will basically tell you what "inner parsing" of the extension value is.
Thanks for your detailed replies - I'm quite new to Haskell so there's a lot to take in there! I'll have a scour of the web to see if I can find any examples of this anywhere!
It's just `+=`, looks exactly like an imperative language :&gt;
&gt; (1.55 secs, 3,545,902,888 bytes) Is it `ghci` timing? Could you possibly measure performance of a compiled program (with `-O2`)?
You don't implement laziness, but you can implement any control flow operator you can dream of.
&gt; C is strongly statically typed. C is weakly statically typed. It's weakly typed intentionally; strongly typed languages don't allow treating a value of one type as if it were a different type -- i.e. treating a `long` like a `char[4]` or `char[8]`. Python is strongly dynamically tagged ("typed" for people that haven't actually read Pierce's TAPL). Python 3 + MyPy also provides a fair amount of static type checking, though not quite what you get out of Haskell. &gt; Why would an FP implantation be ideal over an OO implementation? I didn't say anything about FP. Referential transparency is more common in FP language than in OO languages, but not all Lisp expressions are referentially transparent. Plus, you can do OOHaskell (there was even a library for it and everything; with inheritance and single-dispatch and everything), but it never became super popular. Haskell's type system supports higher kinded types, which allows it to correctly type check some programs that type systems without higher kinded types either reject, or require a run-time verification in order to accept. Higher order functions are great, and they are really easy to use in Haskell, but you can get their same effect in Python (it even has lambdas) and even C (function pointer + context data ~= cloure; smart "constructor" functions ~= lambdas). They aren't the "unique" value proposition provided by Haskell; laziness, purity, and types are.
Only recently (at least for me) has become possible to have *some* Haskell support in IntelliJ IDEA (IDEs from JetBrains are my IDE family of choice which I use for everything, work and hobby programming). Even when it works, it is still quite basic. Since I mostly work in TypeScript in IDEA, I'll be comparing those 2 plugins. In TS I can setup formatting (code style) almost completely - https://www.jetbrains.com/help/idea/settings-code-style-typescript.html. In Haskell there are [virtually no options](https://i.imgur.com/9b2akOw.png) beyond line width. Navigation works as long as you have compilable whole project and are navigating inside project (navigation to libraries works like 70% of time). Similar goes with showing types or documentation - it most of the time works, but is unreliable and tends to break when current file is not compilable. Warning/error highlighting takes very long - few seconds, in TypeScript it is so fast I don't even notice the delay, and that's on a project of size as least 10 times bigger with much more dependencies (my HW isn't stellar, but I think it should run fine on SDD and older i5 with many gigs of free memory). And these few examples are a state "when it works", when it breaks, it's infuriating. Selecting auto-import and waiting MINUTE(S), not an exaggeration, for an IDE to unfreeze and not do anything (auto-import fails). Or error reporting suddenly stops working and you either see no longer valid error messages (you fixed an error, yet squiggly line remains), or you don't see *any* error messages, living in a lie that your code is fine and only after trying to compile it, you suddenly see a flow of errors. Or you select an automatic fix of an HLint issue and the IDE will delete a start of your file and replace it with (fixed) code which was supposed to be on an entirely different place - on a place where you issued the "fix" intention action. I could go on and on... I probably don't have to write TypeScript plugin is rock solid (e.g. no freezes or untrue errors messages, always working navigation, reliable type showing) and the biggest issue I have with it is that auto-import in some libraries is not working until at least one thing from the package is imported (a small thing I encounter one or two times a work day, but since it doesn't freeze IDE nor delete code it doesn't bother me, I just use a live template as a quite quick workaround). Don't get me wrong, I am grateful for at least that limited Haskell support, I get a few hours a week of fun toying with Haskell thanks to that. But it is nowhere near a point where I would want to use it for anything serious, for anything requiring me use it on a daily basis for many hours. I wouldn't mind paying 10$, 20$ or maybe even more, for a bug-free Haskell support in IDEA. As others wrote, I am probably in a tiny minority, true Haskell devs are probably using vim, emacs or something like that, so my (or our, meaning the minority) few bucks wouldn't be enough to pay even for a few bug fixes... I believe having a good *graphical* IDE is a requirement for a language to grow beyond a certain point and I think Haskell is exactly at this spot. I am still hoping IDE Haskell support will keep getting better.
I figured it was something like that... But I thought I need a `&lt;` or `&gt;` in the to indicate the returned the old or the new value, and `+=` would need the `1` constant, so I thought maybe `~= succ` might actually be closer. I'll work on it for next time. ;)
If you want to go that way, there's GHCiD. I think it works best with emacs, but fundamentally it just runs GHCi in the background, and recompiles/retests your code each time it detects file changes.
 instance heytingAlgebraBoolean :: HeytingAlgebra Boolean where ff = false tt = true implies a b = not a || b conj = boolConj disj = boolDisj not = boolNot [https://github.com/purescript/purescript-prelude/blob/v4.1.1/src/Data/HeytingAlgebra.purs#L55](https://github.com/purescript/purescript-prelude/blob/v4.1.1/src/Data/HeytingAlgebra.purs#L55) exports.boolDisj = function (b1) { return function (b2) { return b1 || b2; }; }; [https://github.com/purescript/purescript-prelude/blob/v4.1.1/src/Data/HeytingAlgebra.js#L9](https://github.com/purescript/purescript-prelude/blob/v4.1.1/src/Data/HeytingAlgebra.js#L9) &amp;#x200B; ¯\\\_(ツ)\_/¯ &amp;#x200B; PureScript defines the run-time semantics of the \`disj\` operation to be those of whatever PureScript backend you're using.
You would indeed need one or two `&lt;` to also return the old/new value; `+=` alone just returns `()`.
Thanks for the detailed response! I'm still not 100% sure on how I would implement this, so I will scour the web for an example of what you suggest, thanks!
So you are saying something like `boolDisj tt (head . drop 1000000000 $ repeat tt)` will return nearly instantly? If not, boolDisj isn't short-ciruiting. Is certainly looks to me like you'll have to evaluate the second argument in order to get a value to bind `b2` before JS even sees the `||`. Even *if* **all** of the above is wrong, that's not user-defined control flow. That's borrowing a specific control-flow from semantics associated with a specific primop. In Haskell there's not a few special-cased primops for this; instead it's result of evaluation being associated with the target of a case expression, so you can choose whatever order of WHNF forcing you want just by structuring your cases properly. (Patterns in the LHS desugar to case expressions; case expressions are simplified to only match the outtermost constructor splitting one into multiple nested as needed.)
&gt; Rich, user-defined control flow is a direct result of lazy evaluation Care to substantiate? As far as I know, the evaluation regime doesn't really matter. I wrote a lot more Idris than I did Haskell, but I've never felt limited by its strict-by-default regime. The "rich, user-defined control flow" is due to monadic programming IMO; the fact that the description of processes is separated from their execution, and that execution is often just a translation from one monad to another.
Indeed it is but I haven't used the compiler, yet. If your could provide the full command line with the file "remove_composits.hs"
Well, I am focusing on the wheel numbers and how to expand it. I create them manually by taking the list minus the multiples from which I take the deltas I use. Can I use a recurring factor list instead which is mostly primes and save calculation? Your point about sharing is also something that has been a concern. I'm not sure how to better share `n7sl`. Also, I have no aversion to explicit recursion but others tell me it is bad style. I don't know why. When I started Haskell I became enamored with `fix`. It was magical. Unnamed self-reference.
You'd want `%= succ`.
I would say you can definitely do numerics with Haskell. Personally, I'd say that the odds would be unfavorable though. Data Science, scientific computing and the like has never been one of Haskell's strong points. It's just a community thing, not many Haskellers are doing it, and hence the ecosystem can't compare with Python's. A nice overview can be found [here](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md). This document also should give you an idea of what Haskell is good at. Personally, I would say that while it wouldn't be my first choice for exploratory data analysis, for anything larger than a throw-away one-off, the ability to restrict what (if any) "effects" (in addition to returning a value) a function can have makes some piece of code easier to reason about. Furthermore, everything is an expression, even statements, meaning they have a type. This means something, and more errors can be caught at compile-time. No uninitialized variables, unless you really want to of course. Recursion is (after some initial getting used to) easier than iteration. There are more structured ways of iteration, and even if you do "primitive recursion" you can't accidentally forget to update the values your "loop" depends on. Then there's of course things like Sum types (tagged unions) or higher-order functions, or "typed holes". Especially the last one, paired with type inference, gives you a "driving force" and at least allows `me` to write things I would otherwise be too stupid to write. So at least along this dimension of "exploration", Haskell shines in my opinion.
&gt; Care to substantiate? `head . sort` is O(n) in Haskell due to the way laziness works. `||` and `&amp;&amp;` short-circut, but not as a special case built-in; If you define your own Bool and || and &amp;&amp; (can) also short-circuit. `(Just $ expensive_then_throw) &gt;&gt; (Just "String")` can be printed (giving `Just "String"`) nearly immedaitely, without the expensive computation or any stack unwinding. `ifThenElse` can be defined as a normal function, not even a macro, and correctly only evaluates one "side". You control exactly what gets evaluated and when based on how you structure you cases and pattern-matching, giving you exactly the control-flow you want -- which can and is used by several monads, but is not exclusive to monadic programming. We use (-&gt;) a lot to construct monads (in Idris, Agda, and Haskell) and in some ways it "hides" the influence of laziness because *every* language (-&gt;) doesn't evaluate much (it's stuck until it gets an argument). Laziness allows you to use co-data as control, not *just* (-&gt;) and data dependencies. &gt; I've never felt limited by [Idris'] strict-by-default regime Maybe you can help me with the preformance of [Implicit Queues](https://gitlab.com/boyd.stephen.smith.jr/idris-okasaki-pfds/blob/master/src/ImplicitQueue.idr), then? The Haskell code just does the right thing. The Idris code seems to have exponential slowdown based on the number of `snoc`s between calls to `head`/`tail`.
&gt; I have no aversion to explicit recursion but others tell me it is bad style Say instead that structured recursion is better style. GOTO : structure control flow :: explicit recursion : recursion schemes.
Fixed.
Am I missing something? Is there a tool for Haskell that's at least close to OCaml's Merlin? (And OCaml is not exactly mainstream either, but it's been a long time since I touched Java.)
Is there a Haskell implementation of Twitch that's just not listed at https://github.com/twitchtv/twirp#implementations-in-other-languages ?
&gt; head . sort is O(n) in Haskell due to the way laziness works. I doubt complexity arguments such as this generalize to something actually relevant, though. &gt; || and &amp;&amp; short-circut, but not as a special case built-in; If you define your own Bool and || and &amp;&amp; (can) also short-circuit. But they're not built-ins in Idris either. It's just `Lazy a` (Idris also has implicits, so no special cases here either as `Force` and `Delay` are inserted automatically). &gt; You control exactly what gets evaluated and when based on how you structure you cases and pattern-matching, giving you exactly the control-flow you want I'm not sure what this means. I want control-flow to be explicit and possibly typed, not a property of how the language is evaluated, and I find it much easier to think about strict evaluation when I need to think about performance.
Try ghc -O2 remove_composits.hs ./remove_composits +RTS -s
Forgive me, but I thought an FP language like Haskell would be great for something like numerical operations. Most of the posts I found said it’s great for mathematical expressions such as bound checking or Euclidean distance computations. Further, traversing a BST I thought would fit right in for an FP language since I’ll be be performing many operations on a fixed thing, not doing evolutions such as subclassing a tree. I suppose I’m not confused as to why I would use Haskell at all if I can implement my program in an OO language that allows for concurrency and faster speed than Haskell, if not only to get a better type checker at compile time?
Forgive me, but I thought an FP language like Haskell would be great for something like numerical operations. Most of the posts I found said it’s great for mathematical expressions such as bound checking or Euclidean distance computations. Further, traversing a BST I thought would fit right in for an FP language since I’ll be be performing many operations on a fixed thing, not doing evolutions such as subclassing a tree. I suppose I’m not confused as to why I would use Haskell at all if I can implement my program in an OO language that allows for concurrency and faster speed than Haskell, if not only to get a better type checker at compile time?
Thanks for schooling me on C, I really don’t code that much of it except when I need to squeeze out performance and bind it into a Python program as a DLL-of-sorts. Every post so far has been “typing, typing, typing”. Beyond that I understand that FP is a different approach when it comes to things such as side effects and true concurrency. But I can achieve concurrency with C, I can limit side effects in C (somewhat). In Python, it’s encouraged to let users make mistakes because everybody is treated as an adult; if you use the code incorrectly, you get undefined behavior. This I am lost, even after your posts, as to why an FP language like Haskell would give me benefit over C for something like implementing. CPython is built to bind with C extensions. Why use Python? Well it’s easy to learn, forgiving and speed isn’t that bad. Okay well concurrency sucks in it so that’s a good reason to look out, hence when I am here. Is typing the only real advantage over an something like C? I’m failing to grasp why Haskell would at all be better.
In my experience, it's rather easy with Nix and all-hies, and near impossible in any other way.
I have Jetson TX2 (also TK1) boards and I use Haskell at work. I was wondering to use Haskell for my Jetson board also, then I was searching exactly what you wrote here. I would really like to give a try, make some comparisons also.
&gt; I thought an FP language like Haskell would be great for something like numerical operations In principle it is! I was specifically referring to a community aspect I consider important, YMMV. &gt; Further, traversing a BST I thought would fit right in for an FP language Oh absolutely. In principle there is no limit to how sophisticated things can get, but it may be as simple as using the [containers](http://hackage.haskell.org/package/containers) package, or defining your own tree (a one-liner!) and automatically "deriving" the traversal function you need. I was speaking merely from my own personal experience, since you said you wanted opinions. &gt; OO language that allows for concurrency and faster speed than Haskell If you know what you're doing you can write *very* performant code, though some optimization may be necessary. But know that your intuition from "strict" (non-lazy) languages will not apply. And that is a good thing, since it means that what you may have heard about "nothing being able to change" etc. is just urban myth. You can *totally* alter the BST, you will basically return a "new" tree that differs by a "delta", the rest is "shared". Also, since you mentioned "bound checking", we have something called property based testing too, for example via `quickcheck`. For mathematical functions, I find this invaluable, especially so since it can help detect edge cases.
New to Haskell. How can I easily tell when I'm installing a library and need to use \`--lib\`? E.g., I just did \`cabal new-install random\` and got the OP's warning: "Warning: You asked to install executables, but there are no executables in target: random. Perhaps you want to use --lib to install libraries instead." What is the meaning of this warning? How should I proceed? (And why is this info not at [https://www.haskell.org/platform/](https://www.haskell.org/platform/), given that the Core download likely lacks needed functionality and Cabal's package installation guide is not up to date.)
And with the Selective class you can also recover much of the benefit of Monad and still be statically analyze-able.
I disagree. I'd be very surprised if an example could be given of macro-based control flow that couldn't be replicated fairly easily with laziness.
reusable code is nice too. I just don't get that in other languages.
Thanks for the ideas! \^\_\^
&gt; I would love to translate many prelude function (i.e. relating to lists) into Core. Is that practical or would the resulting Core be too much to understand? Just use ghc. You can [dump core](https://stackoverflow.com/questions/10693638/how-to-dump-ghc-simplifier-output-in-human-readable-form). &gt; 2 ghc. &gt; 3 Yes there is a pretty well defined [achitecture](https://en.wikipedia.org/wiki/Glasgow_Haskell_Compiler#Architecture) in ghc. In fact I believe most is described [in papers](https://gitlab.haskell.org/ghc/ghc/wikis/reading-list), which is slightly easier to understand than source code.
As someone new to Haskell, how can I tell when to use the \`lib\` option for a Cabal install? E.g., \`cabal new-install random\` produces the warning "Warning: You asked to install executables, but there are no executables in target: random. Perhaps you want to use --lib to install libraries instead." What are the implications of this warning?
&gt; But they're not built-ins in Idris either. I'm quite familiar. There was a period of time when the standard library versions *didn't* short-circuit because someone forgot the "Lazy" part of the type. Also, the promise of Force/Delay being inserted automatically covers many simple cases, but I've been required to add them manually to get things to type check many a time.
&gt; I doubt complexity arguments such as this generalize to something actually relevant, though. In fact they do. It's rarely quite a simple, but you can certainly (and may even accidentally) write code that results in a better complexity class when the results are only partially evaluated. A simple example is that `uncons :: Queue a -&gt; Maybe (a, Queue a)` doesn't pay for constructing the remaining queue, if you are just doing a peek, so it really can be the universal accessor. In a strict language, you need multiple accessors so that peeking repeatedly doesn't construct tails (or vice-versa depending on your queue implementation.)
I have to say it's a bit of a pain to set it up properly, but I've got it in a good working state now where it works rather reliably
&gt; I find it much easier to think about strict evaluation when I need to think about performance. Me too. That's certainly how I was trained, and given that Haskell is the *only* production-ready lazy language, it's not surprising. But, lazy evaluation is more flexible and compositional and you can get good performance out of it, though you may have to think about things differently. (That said, I want the optimal evaluation of Formality with Agda's type system and syntax. Should be even better than call-by-need without tuning, though it is even more foreign to my way of thinking about performance)
&gt; if you use the code incorrectly, you get undefined behavior. And, if you are happy with that, I don't think I'm going to convince you to use Haskell. While it can be used for other forms of analysis, the cornerstone of type theory is that "well-typed programs don't go wrong", we want to avoid as many forms of run-time errors as possible by detecting them statically and making them compile-time errors (or at least warnings) so that the *developers* can deal with them instead of the *users* dealing with them. --- There's a post of the /r/haskell frontpage right now about why GitHub chose to use Haskell. Facebook has also published some articles/talks on why they chose to use Haskell. Not all of it is types, but they are a big part.
&gt; You can totally alter the BST, you will basically return a "new" tree that differs by a "delta", the rest is "shared". Construct it out of `STRef`s, `IORef`s, `MVar`s or `TVar`s and you can actually mutate it in place, too. It's not the first approach we encourage in Haskell, since mutation makes things harder to reason about; but, they are certainly available
&gt; Haskell would be great for something like numerical operations Can be. But, naive Haskell code with have *lots* of pointer indirections (seriously, a surprising amount), and probably lots of non-contiguous allocations. This is easily kill performance, just by missing the L1 cache 2-3% more.
You may want to start with these slides and talk: http://www.erlang-factory.com/static/upload/media/1488806820775921euc2016intothecoresimonpeytonjones.pdf and https://www.youtube.com/watch?v=uR_VzYxvbxg
Haskell doesn't, and pretty much can't, require a common structure of data to inform behavior. When you write a function that can take multiple concrete types as input, you use a `class constraint` - In Java, that'd be like using generics and requiring some type that implements an interface. It's not exactly the same, but it's close enough to get the basic idea. For example: ``` allThreeAreEqual:: Eq a =&gt; a-&gt;a-&gt;a-&gt;Bool allThreeAreEqual a b c = a == b == c ``` In this function, all we know about the input is that we have three args of the same type, and that the type that gets passed in must be an instance of the `Eq` class. We can make things that involved overlapping classes - If we know how certain methods for a class will behave, we can use them together to make a kind of subclass. ``` Prelude&gt; :{ Prelude| class (Enum a, Bounded a) =&gt; BoundedEnum a where Prelude| wholeRange :: (Bounded a, Enum a) =&gt; [a] Prelude| wholeRange = enumFromTo minBound maxBound Prelude| :} Prelude&gt; instance BoundedEnum Ordering Prelude&gt; wholeRange :: [Ordering] [LT,EQ,GT] ``` But you can't -construct- an instance of a `class` at runtime in Haskell for essentially the same reason that you can't -construct- an implementation of an interface in Java, so there is no way to dynamically create different results for a given type that inhabits that class. So, we can have interrelated functions that "inherit" behavior, but we don't have relationships between structures of data in the same way. You could make a concrete structure that models an inheritance relationship as a tree - But there is no reason to do that, because data doesn't come pre-packaged with functions that act on it, so we don't. Instead, we typically just define structures that hold the data we need for a computation, and we talk about how those computations can be related to each other instead, independently from the structure of the data being computed.
So Haskell is not an ideal solution to replace a Python or C binding for performance based code in my case, is that the gist?
With regards to the first, most certainly with regard to functor, I'm not quite sure what you mean in the last sentence. Particularly of note here is that there's an isomorphism between your data type and Const Int a
I would guess not.
That's great! Thank you. Now I have something to gauge the slowness of my code with.
So if Haskell isn’t great for computations like the example I gave, what is it great for? I’m not asking what features make it a good language such as typing, but rather what sort of applications doesn’t it just crush in? Compilers? Is that it?
Looks like, in PureScript, \`(||) &lt;$&gt; (Maybe.Just true) &lt;\*&gt; (Data.List.Lazy.head &lt;&lt;&lt; Data.List.Lazy.drop 1000000000 $ Data.List.Lazy.repeat true)\` will eat up all my memory. The \`drop\` function will force the list defined by \`repeat true\`, so the evaluate semantics of \`||\` doesn't even enter the picture. I'm not sure exactly what about \`Data.List.Lazy\` makes it lazy, but you \*can\* do some thing in a lazy way using \`Data.Lazy\`. However, from what I hear, doing lazy things in a strict language can be hard to ensure it's doing what you intend.
If you want to install a library use \`--lib\`. If you only want to install an executable then don't. You sort of need to know why you are installing something before hand, otherwise hey, you might as well \`cabal new-install ACME\` or even use \`pip\` instead.
My `unionAll` is taking care of a few duplicates (not like before) and, of course, sorting.
Reinstallable `lib:ghc` will be useful as a way out of some corners that are presently otherwise impossible, but I hope it doesn't catch on as a general solution, since the compile times will be terrible.
Ah, yes, you're right. I think the "involutiveness" doesn't really apply at all, as it's not a single function \`f\` that is it's own inverse. It's rather a function \`f\` that, when applied with an inverse action, reverses the original action. I'll correct this in the article.
Thank you! I don't know how to do that, but yeah, maybe I should. :)
`data F a = F Int instance F where fmap f (F a) = F (f 0) -- works fmap f (F a) = F (f a) -- doesn't, because a isn't necessarily an int according to GHC `
Developer time is more valuable than CPU time. Haskell can be tuned to perform quite well: [vs. C](https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/ghc-gcc.html) [vs. Java](https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/haskell.html) (Python is also benchmarked, but they don't have a head-to-head page for Haskell vs. Python). But, much of that code is not anything a beginner would write. Typing alone is reason enough for me to use Haskell. It eliminates entire classes for problems, so I spend less time fixing run-time errors and more time implementing features. Referential transparency is also a big plus, as it makes the code easier to reason about, so when a logic error does get through it's easier to find and fix. I don't use Haskell because of a single "killer app" ([many](https://www.reddit.com/r/haskell/comments/bwah9q/why_haskell_why_github_use_haskell_for_their/epwj3yz/) of [us](https://www.reddit.com/r/haskell/comments/bwah9q/why_haskell_why_github_use_haskell_for_their/epwjpcy/) don't, not [really](https://www.reddit.com/r/haskell/comments/bwah9q/why_haskell_why_github_use_haskell_for_their/epwlxgr/)); I use it because it is a broad improvement in most areas, and a significant improvement in maintenance. Parsing (FB, Pandoc, Semantic), DSLs (Arguably Servant, and a lot of smaller projects), and painless parallelism (FB) are the strongest points I can think of for Haskell. But, I even as a C expert, I'd rather use Haskell for most tasks, especially if I want to keep the program/library around a long time and maintain it.
&gt; I'm not sure exactly what about Data.List.Lazy makes it lazy Probably the tail is lazy, so it's not forced immediately, but as you can see, that laziness doesn't pervasive enough because the lazy drop is evaluated though we don't actually need the value of it. GHC can make a decision to use the strict version of a function or the lazy version of the function based on strictness analysis of the call site. (Though it is often wrong/unsure and defaults to lazy semantics.) With use Data.Lazy in purescript or Lazy in idris, you have to make the decision when you write the function. The full laziness of GHC makes separate pieces of code compose better, by finding the fewest redexes needed on the path through the composition. (Fewest redexes isn't optimal because it can duplicate applications, creating more redexes to preform, but it's always better than strict evaluation order.)
https://planet.haskell.org/faq.html
I posted [this](https://old.reddit.com/r/haskell/comments/arkaif/rcrepl_is_a_python_package_that_wraps_a_ghci_repl/) sometime back. But there seems to be absolutely zero interest in it..I don't get it.
[State of the Haskell Ecosystem](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md), might be a bit outdated, but will probably have some of the information you are looking for.
The Idris interpreter has an IDE mode, where it sends semantically rich information about the current code via a socket to a text editor. Cuurently Emacs, Vim and Atom are supported. Maybe the GHCi developers could be persuaded to add such a mode as well?
generic-sop also can give some advantages here
What advantages does your solution have over `ghcid`?
Nice work, Sandeep. Thanks for open-sourcing and releasing it!
Thanks for pointing this out. I just tried ghcid's VS Code plugin, and it seems to work really well. Fast and fairly easy to install.
[removed]
Go on...
The adapters can communicate with the editor so that you don't have to keep it visible in a window. I can get visual indications in the editor letting me know when a :reload is in progress, if there are errors, warnings or if all the changed modules were loaded without any errors/warnings. If there are errors, then the editor adaptor parse the error/warning output, and set the error list in the neovim/vim editor. Once we have the error list in the editor, vim/nvim have built in shortcuts/commands to view and walk through the error list (quickfix window) and open each of them in the editor. This works so fast that if I find an error in a file, I sometimes forgo vim's navigation methods, and just save the file and jump to the first error location set from the adapters. You also can send any ghci commands to the script, and it will just forward them to the wrapped ghci process. I often use it to explicitly load a module initially, so that at every file save, the same module gets reloaded. Instead of Main or what ever that is loaded by default. The best thing about this is that if the python script get stuck for some reason, you don't have to kill your editor. You just need to kill the script and restart it. Basically editor is very passive component in this whole process, so it does not lag or slow down etc.
That's what's great about Nix. It makes the near-impossible possible, and the easily-possible near-impossible :P For real though, I think HIE can be somewhat easily installed by just cloning the repo and following the build instructions. It's a bit of an annoyance but I think the main problem with it is that users can't just try it out with a single command and a single Emacs/Vim/whatever package. It's just not streamlined.
Thanks Kahil.
That is hard do believe, given that nodejs has a very strong presence in serverless, and PureScript is pretty much the same as nodejs.
Can you share more insight which language you call Duckling lib from ?
I love that podcast. It manages to get a balance between being technical but not reading source code.
The last paragraph is particularly true. I just started learning Haskell, one of the first thing I did was look for vs code plugins. I abandoned that path. I now use only ghci and load scripts from it. Wouldn't be doing that in a real world project. The community really needs to look into graphical tooling.
I don't understand why "compiling in a different terminal" is bad. That's what I do currently (and I'm doing Scala). ghcid piped into vim is a great workflow!
https://www.hedonisticlearning.com/djinn/
Thanks!
&gt; Is typing the only real advantage over an something like C? I think you underestimate just how great a benefit Haskell's type system can be, which is why people keep going on about it. Is it just a better type system, you ask? And I say, there's no *just* about it. It's a better type system! That's enough. If you want other advantages, though: * Concise and expressive syntax * Algebraic data types (*perfect* for expressing all kinds of trees) * Pattern matching (objectively superior to chains of if-statements) * Lazy evaluation, meaning you get to play with infinite lists and such - it's a *fun* way to write code
Definitely intrigued, going to work my way through LYAH and see how I can apply it
At barebones my problem was (is) this: 1. Implement an tree with methods in Python Python is my dominant language, so it was fast for me to put together. It’s OO and thus I have a several classes with many methods (tree, node, mbr, etc.) If I feed a container to the tree, I’m constrained by the concurrency limitations of CPython (without spawning many processes). It was easier for me to use OO because I could categorize like operations for unique things. However, since I don’t subclass or take advantage of any polymorphic features, each object is singular (as in I only ever have have one kind of tree, that holds one kind of node, that have one kind of mbr) so OO may seem wasteful. 2. Implement #1 in Cython then C Still keeping an OO approach but removing a lot of performance (mainly evaluation) constraints by providing typing and bindings. However, without extensive work to implement a way around, I am still hindered by concurrency constraints. The upside, Python interops with C natively, so it works really well. However, it’s C and it makes me want to cry and hurt myself. 3. Look at an alternative Now why I came here is to assess if an FP language would be great for this. Does Haskell run as fast as C, maybe if I’m great at it; is it faster than Python if I’m not great at it, probably. Because I’ve only been exposed to imperative languages (mainly the procedural and OO paradigms), with the exception of a course using SML/NJ and Prolog (which was really fun), it is tough to wrap my head around why I would want to use FP over OO. I think I was getting caught up on the fact that using C as a procedural or “OO” language means that they are faster than FP. I wasn’t taking into account maintainability, typing (extensively) and referential transparency. I looked at it instead as “I can write Python, create a C binding and important that for performance and keep writing in Python and that’s pretty clean” rather than “I have a Python datatype (for example a list) and a program in another language. I have to spawn a subprocess to run this executable, somehow feed this Python list to it and get the results back into a Python useable form”. The latter seems clunky and wrong, is it? Is the fact that what the Haskell executable would do, how it would do it, how clean it is, whatever, that makes it worth doing? I appreciate all your insight on this. I’ve been looking at Haskell for only a few days and I definitely have no idea how I would use it.
&gt; That said, I want the optimal evaluation of Formality with Agda's type system and syntax. Should be even better than call-by-need without tuning, though it is even more foreign to my way of thinking about performance What does this mean
Thank you so much. I tried last evening not realizing I had to use a compiled file with this command, but this morning: &amp;#x200B; SPARKS: 0(0 converted, 0 overflowed, 0 dud, 0 GC'd, 0 fizzled) INIT time 0.000s ( 0.001s elapsed) MUT time 0.094s ( 3.134s elapsed) GC time 0.156s ( 0.190s elapsed) EXIT time 0.000s ( 0.000s elapsed) Total time 0.250s ( 3.325s elapsed) Alloc rate 637,517,750 bytes per MUT second Productivity 37.5% of total user, 94.3% of total elapsed Now, I'll work on what this means.
Good luck! It's a very different language from C and Python. Tips: * When in doubt, ghci's `:t` command is your friend. * Use https://hoogle.haskell.org to search for functions by name or by type. * Compile often (or just reload in ghci). * When you get to monads, if they don't make sense, try [this blog post](http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html) Have fun!
&gt; Maybe the GHCi developers could be persuaded to add such a mode as well? https://gitlab.haskell.org/ghc/ghc/issues/15461
Now that you have action inverses, you may want to consider using that functionality to improve your undo/redo stack. For example, you can have **redo** that doesn't wipe out all the undone actions. In your first diagram, where you have a d e b f c g the following action `h` could instead produce a h h⁻¹ b e c f d g Sorry for the late response, but I wasn't sure you were following on Reddit.
The first one I consumed yesterday evening :) Thank you for the other references!
About the IntelliJ Haskell plugin. The latest beta, beta48, should be better with respect to responsiveness. Otherwise create an issue.
Thank you for the link how to dump core! In hindsight, I realize that I wanted practical tipps from people that worked a lot with core, but what you and others have posted will be good to get me started.
Yes, I meant bindings to node libs. Nobody likes writing FFI code, and PureScript didn’t have the ecosystem at that point that let them avoid it. I don’t know if it has changed since, because I don’t know what the time frame was.
If you are concerned about the process spawning and parsing the output, I believe there are some libraries for calling Python from Haskell and vice versa, so you don't need the extra process.
Agda's type system is as complete MLTT as I've seen, and while Idris is comparable, it intentionally doesn't try to remove all inconsistency from it's type theory. Agda's syntax includes mixfix operators, which make it even better for DSLs than Haskell. Idris is less verbose in many places, due to implicit bindings, but the Agda syntax for type classes is more consistent. It's quite Haskell-like, and doesn't suffer from some of the problems of Idris where terms in error messages (or generated to fill a hole) aren't syntactically valid. Formality is a new language / core. I think it is based on Symmetric Interaction Combinators. Evaluating a SIC/Formality net/term avoids introducing any duplicate subterms, unlike call-by-need, so the amount of work it does to get to a value is always optimal (in some sense); it's also massively parallel. It should be possible to make it faster than our current evaluation strategies, since it is doing less work (in some sense). SIC nets are not how I think about programs / performance though, so it may be even harder to address any performance problems in Formality than in Haskell. It's capable of sharing *parts* of function bodies, and the normal rules of variable scoping don't apply to intermediate forms; it's a very different model of computation from Turing Machines, Lambda Calculi, STG, SECD, or the von Neumann architecture.
Thanks, but where can I learn the meaning of your terminology? The GHC User's Guide refers to installing packages, not installing libraries or installing executables, and these notions of "install" all appear very Haskell specific to me. The Cabal Users Guide does not seem to mention the `lib` option. As a new Haskell user, I am just trying to ensure that GHC can import the `random` package, which for some reason is not included with the GH Platform core download. I suppose from your phrasing that you are telling me that if I want GHC to be able to find a package that I install with Cabal, then I shd use Cabal's `lib` option. If so, then what is the meaning of "install an executable"? I'm going to guess that it means that Cabal puts an executable into some directory that GHC might not know about.
&gt; I believe having a good graphical IDE is a requirement for a language to grow beyond a certain point and I think Haskell is exactly at this spot. If this is true (and I don't think it is), someone else will have to develop it then. I don't use a graphical IDE for *any* language, so I wouldn't even know what features/functionality it should have. I think my situation is similar to many others in the Haskell community. I'm not going to stop using vim, and the current tooling available there works for me. (For others it's emacs, or something else, but there's a lot of us that just aren't going to use such an IDE even if it did exist.)
`TypeApplications` can be a good way to specify types in ambiguous situations.
&gt; you can't -construct- an implementation of an interface in Java *cough* anonymous inner class *cough* *cough* SAM lambda *cough* *cough* java.lang.reflect.Proxy *cough* (Haskell also has ways to "cheat" and construct instances, too. `Dict`, instances where all the methods are just field accessors, etc.)
A quick clarifying question: Are there any variables that are unused by all functions, or is it just that some of your functions don't use all of the variables?
More information about what you're trying to accomplish would be useful. Generally, \`AllowAmbiguousTypes\` requires you to supply more information at the call site - As the name implies, using this extension is generally going to adversely affect type inference, because the types are now ambiguous. This could also imply a need for \` ScopedTypeVariables\`, but I would strongly encourage you to provide this sub with more information about what your goals are - Use of \`AllowAmbiguousTypes\` can sometimes be a strong indicator that you're far enough off the golden path that you may want to revisit your approach.
That,or `FunctionalDependencies` [https://prime.haskell.org/wiki/FunctionalDependencies](https://prime.haskell.org/wiki/FunctionalDependencies)
`AllowAmbigousTypes` doesn't actually make them non-ambigous, but it moves the error from the definition to the use site. If the use site is still ambigous, you still get an error, though you may be able to make the use since non-ambigous. You might look into functional dependencies, if you believe the types present at the use site should dictate the other types. Otherwise, you can use proxy parameters so that all the types are mentioned, and use proxy arguments (possibly with explcit type annotations) in order to make the type non-ambigous at the use site. (Yes, `TypeApplications` can work, but I certainly don't think it's good library design to force that extension on your users.)
Here are a few options I can think of: * `TypeApplications` as mentioned by /u/rampion * Add `Proxy t` arguments to the other methods to specify the other type variables. * Split your typeclass into multiple: class ClassForX x where methodX :: x -&gt; Bool class ClassForY y where methodY :: IO y class (ClassForX x, ClassForY y) =&gt; MyClass x y where bothMethod :: x -&gt; y Instances have to specify all three, but use sites still only need the `MyClass` specification. * Also, often you don't really need all the arguments to be fully general -- use `TypeFamilies` and make an associated type: -- was class MyClass x y class MyClass x where type TypeY x methodX :: x -&gt; Bool bothMethod :: x -&gt; TypeY x -- ambiguous, needs one of the above solutions, -- or use `data TypeY x` as the associated type instead, -- to make each instance define a new data type instead -- of an associated type. (google `data family injectivity`) -- methodY :: IO (MyClassOutput x)
They should really teach it about `[]` type.
Sure - I would consider it much more of a code smell to try to work around these "limitations" in Haskell than I would in Java, but I think this still falls pretty firmly in the "please no" category of things I would not wish to see on a code review. Granted, that reaction can also come from the creeping realization that you've inadvertently stumbled into one of the rare, actual problems that justify the approach, but it's significantly more likely that there is just a better way to solve your problem.
On my faster work PC with 5 time the memory and again with `n7sl` INIT time 0.000s ( 0.000s elapsed) MUT time 0.078s ( 1.097s elapsed) GC time 0.094s ( 0.111s elapsed) EXIT time 0.000s ( 0.003s elapsed) Total time 0.172s ( 1.212s elapsed) &amp;#x200B; Alloc rate 1,578,764,697 bytes per MUT second &amp;#x200B; Productivity 45.5% of total user, 90.8% of total elapsed
There are a few ways to get around the problem. You haven't included the actual class here, so let's pretend that we're working with something like this: class Mapping key container where lookup :: key -&gt; container value -&gt; Maybe value size :: container value -&gt; Int The second method is the problem. # Option 1: Proxy The problem is that the second method doesn't contain the `key` type variable, so why not just add the `key` type variable to the method? class Mapping key container where lookup :: key -&gt; container value -&gt; Maybe value size :: Proxy key -&gt; container value -&gt; Int `Proxy` is a type defined something like this: data Proxy a = Proxy So you don't have to actually find a `key` to pass in, you can just annotate `Proxy` with the correct type. # Option 2: TypeApplications This is actually quite similar to the approach above, it just gets rid of some of the noise. If you `AllowAmbiguousTypes`, `TypeApplications` are the thing that let you specify the type variable at the call site: size @MyKeyType myContainer # Option 3: Functional Dependencies (This is likely the one you want) You can specify to GHC that it doesn't need to know the missing type variable, because it can infer it from the others: class Mapping key container | container -&gt; key where lookup :: key -&gt; container value -&gt; Maybe value size :: container value -&gt; Int Then, it will check that this really is the case at any instance declarations, and you won't have to use any type annotations etc. # Option 4: Type Families Yet another way to express the same thing, you can define a type family (which makes the above relationship implicit) like so: class Mapping container where type Key container :: * lookup :: Key (container value) -&gt; container value -&gt; Maybe value size :: container value -&gt; Int Strictly speaking, functional dependencies are more flexible than this approach, but their differences are subtle.
You can fake it by asking e.g. `f :: list a -&gt; (a -&gt; list a -&gt; list a) -&gt; list a -&gt; list a`. It gives a ton of results for that, none of which is `reverse` (oops! I gave it constructors for `list` but no way to figure out whether a given list is a `nil` or a `cons`), so I don't think djinn is very useful on recursive datatypes like lists.
&gt; Thanks, but where can I learn the meaning of your terminology? Experience, reading, and inquiring. &gt; The GHC User's Guide refers to installing packages, not installing libraries or installing executables Packages consist of sub components including executables and libraries. &gt; these notions of "install" all appear very Haskell specific to me Which ones? `pip`, `rake` and other language-specific tools have similar notions of install. &gt; am just trying to ensure that GHC can import the `random` package, which for some reason is not included with the GH Platform core download. And you already know how, right? `cabal new-install --lib random`. There's no reason for `random` to be in core. It is extra and unneeded by most projects, and not a great random number generator to boot. &gt; I suppose from your phrasing that you are telling me that if I want GHC to be able to find a package that I install with Cabal, then I shd use Cabal's lib option Yes. &gt; what is the meaning of "install an executable"? Build a program from source and copy the binary to your `.cabal/bin` directory. In OS-X and *nix this is default at `$HOME/.cabal/bin`.
It’s not that I’m concerned about it, the machine can handle it, but rather if it’s wise. Is it normal to write a portion of your application in one language, only to be called by another portion in a different language? For full stack, sure, because each component is different (somewhat). But for a client side application, where the GUI is written in Python, is calling a Haskell program the right thing to do? I’m sold on the type checking and maintenance, no arguments from me there. The hurdle I have yet to overcome is understanding how/when/where/why I should write something in Haskell over Python/C. We’ve already established that it would be wise for something that isn’t a throw-away and anything where concurrency may be needed. Yet, how do I make the call to replace my Cython/C implementation with a Haskell one? Sticking with my use of clustering, I can parallel process my data and navigate a BST with ease all in Haskell (or so I’ve gathered from the posts). I think there was a miscommunication about my earlier post, I’m not looking to do big NumPy or Pandas like operations, just using trees and geometry (amongst other mathematics) to perform analysis. So I firmly believe that Haskell would be a great fit here. Perhaps you could help with this hurdle? I’ve not written any application in multiple languages (excluding web apps that have say a JS front end and a Python back end). I’m also excluding C extensions for Python since that natively supported and when I use it in the application, I’m importing the extension and writing in Python but it executed the optimized C.
I don’t think it’s fair to make a blanket statement that FDs are more flexible than TFs. They each have advantages over one another. IMO people should lean towards TFs overall as they are more functional and intuitive.
I would advise TypeFamilies over FunctionalDependencies in most situations. They are more intuitive and functional.
Sure, they both have advantages, but you can't do dependence on multiple variables with a type family, or multiple dependencies. In this use case (trying to infer a missing type variable) functional dependencies can do more than type families.
At CircuitHub, we use effects liberally (currently through `simple-effects`, I'm exploring porting to `polysemy` at the moment but it's not quite there yet). As to what effects we have, a good stack is our persistence layer. First, we have a fairly unique looking effect: `Transaction t`. Specifically, `Transaction ( t :: * -&gt; * )`. So the `Transaction` effect is parameterised by a monad `t`. This monad describes the language of things that can happen transactionally/atomically. There is one method in this effect: `transaction :: t (Either e a) -&gt; m (Either e a)`. The intention is that `m` will run the effects of `t` atomically. The transaction can rollback if it returns `Left e`. Next up, we have a `SqlStatement` effect. This describes individual SQL statements such as `SELECT` etc, through the language of a combination of `beam`, `rel8` and `persistent` (unfortunately we use all three - I wouldn't recommend that!). This alone lets us write things like `foo :: (MonadEffect (Transaction t) m, MonadEffect SqlStatement t) =&gt; m ()`. Here `foo` can execute one or more transactions, and those transactions have access to SQL statements. However, we typically work at an abstraction higher than `SqlStatement`. We have decomposed our database into individual persistence APIs. For example, we have the concept of orders, so we have an `Order` effect with methods like `lookupOrder :: OrderId -&gt; m (Maybe Order)`. We then have interpretations (implementations) of these effects in terms of `SqlStatement` for production use. We also use some effect relays/interceptors that augment interpreters not dissimilar to aspect orientated programming. For example, we can take a transaction running effect and augment it to manage some Prometheus counters so we have telemetry as to how many transactions have ran, how many aborted, how many are currently running, etc. Likewise we can intercept `SqlStatetement` to build up a log of which statements are being called. The beauty of this approach is we can write code with transactions, but let user code determine what the transaction boundaries are. However, the use of a transaction doesn't commit to any particular implementation, so I can still go in and mock what's going on *inside* a transaction. For example, take `foo` from earlier. I can provide an implementation of `Transaction` that is essentially `id`, so all transactions succeed. My implementation of `Order` might just be to consult something in a `State (Map OrderId Order)` computation. Our use of effects is more extensive than just relational databases. We also have effects for external APIs we talk to (Shippo, Octopart, etc). These effects are interpreted into a HTTP effect (which again we can augment to log all HTTP requests), which is eventually interpreted to an IO effect. Hope this helps, let me know if there's anything you'd like me to clarify.
Just to give an example: import Data.Proxy data N = Z | S N class AddC (n :: N) (m :: N) (nm :: N) | n m -&gt; nm, n nm -&gt; m instance AddC Z m m instance AddC n m nm =&gt; AddC (S n) m (S nm) type family AddT (n :: N) (m :: N) :: N where AddT Z m = m AddT (S n) m = S (AddT n m) example1 :: AddC n m nm =&gt; Proxy n -&gt; Proxy m -&gt; () example1 _ _ = () example2 :: (AddT n m ~ nm) =&gt; Proxy n -&gt; Proxy m -&gt; () example2 _ _ = () This shows that both approaches can infer the output given two of the inputs. However, the functional dependency can infer one of the inputs given the output and another input: example3 :: AddC n m nm =&gt; Proxy n -&gt; Proxy nm -&gt; () example3 _ _ = () You can't do this with type families yet. TypeFamilyDependencies gets close, but that only works for single-variable dependencies at the moment (`n -&gt; m`).
Minor nitpick: `cabal new-install &lt;some executable&gt;` will create a symlink, not copy the binary. In cabal 3.0 (which will release soon, or you can build it from HEAD) you can ask for the binary to be copied instead.
Good question! I'm currently working on a web browser written in Haskell as a showcase for how to use polysemy (I'm teaching myself as I go!). The most interesting thing right now is the `Labeler` effect: data Labeler m a where GetLinkRects :: Labeler m [AABB Float] SetLabels :: [(String, AABB Float)] -&gt; Labeler m () Essentially, `GetLinkRects` is responsible for giving you a rectangle around each link on the webpage, and `SetLabels` allows you to render them on the screen. The idea is for link-hinting and following --- essentially that you can navigate the web without needing to click on anything. The interpretation of this effect does some DOM stuff to figure out which links are on the page, and does some manipulation to create new DOM elements. Nothing too out of the ordinary. But the interesting thing is this: the code that manipulates the DOM needs to run in a separate process than the rest of the web browser. That's annoying; at first I thought it meant I couldn't do any of this, and I was resigning myself to finding a new project to showoff polysemy. But then I realized that nothing was stopping me from interpreting my `Labeler` effect via an `RPC` effect! Since effects are _just data_ there's nothing stopping us from serializing them across the network, picking them up somewhere else, responding to them, and sending the response back. The interpretation looks like this: runLabelerOverRPC :: Member RPC r =&gt; Sem (Labeler ': r) a -&gt; Sem r a runLabelerOverRPC = interpret \case GetLinkRects -&gt; do sendMessage "Labeler" sendMessage "GetLinkRects" recvSomething SetLabels labels -&gt; do sendMessage "Labeler" sendMessage "SetLabels" sendSomething labels and we can write a handler on the other side that receives these messages, and just runs them in its own version of the `Labeler` effect. dispatchLabeler :: Members '[Labeler, RPC] r =&gt; Sem r () dispatchLabeler = do recvMessage &gt;&gt;= \case "GetLinkRects" -&gt; getLinkRects &gt;&gt;= sendSomething "SetLabels" -&gt; do labels &lt;- recvSomething setLabels labels [Some boilerplate reduction later](https://github.com/isovector/polysemy/pull/83), we can automate this for any serializable effect. Which means we have a lightweight, natural means of invisibly performing application code as RPCs! Cool!
At GitHub, our entire Haskell codebase is built with effects (specifically the \`fused-effects\` library). Indeed, the core interpretation primitives in our program are expressed with effects, and then interpreted in concrete, abstract, or typechecking domains as needed. There are a lot of effects in [the codebase](https://github.com/github/semantic), more than I can link here (search for data structures that derive `HFunctor` and `Effect`, if you want a full list.) But [here](https://github.com/github/semantic/blob/a7f680629894c28951ea60f9fe77f227207c41fa/src/Semantic/REPL.hs#L61-L71) is an example of using many effects—IO-exception handling, resource handling, context with `Reader`—in conjunction. I don’t have the spare cycles right now to describe every reason why we chose to use effects instead of monad transformers here, but I’ll provide one—the fact that \`mtl\` constrains \`MonadState\`/\`MonadReader\` to one state/reader type, thanks to the functional dependencies, makes it a non-starter for us. Our app relies heavily on nondeterminism, and we need some program state to be accumulated across all nondeterministic branches and some state to be pruned only to the branches that succeeded. Representing this ergonomically is very difficult with \`mtl\` but is trivial with effects. (FYI, I’ll be talking about this at my upcoming Strange Loop talk.)
Thanks for the suggestion! We’ve added some quick examples of what Semantic can do [here](https://github.com/github/semantic/blob/master/docs/examples.md), and we’ll be expanding this section with more detail at a later point. (A full discussion of this approach to the problem takes a lot of keystrokes!)
Yeah I’m aware of the current limitations of TypeFamilyDependencies and hope they get figured out in the not too distant future. I just wanted to avoid people defaulting to using FDs when I think TFs are, in general, the better approach. It’s annoying having a mix of FD (mtl) and TF (lens, mono-traversable, mtl-tf) libraries.
That’s fair
By my count, there's about 30 effect interpreters in that stack, and I may be undercounting! That will definitely give me a lot to look at. Thanks. I was hoping to avoid a "mtl vs. effects" argument here, so I'll ignore your third paragraph for now.
Yeah, we use a \_lot\_ of effects. Which is why we had to develop `fused-effects`, because existing effects implementations just weren’t up to executing that kind of code quickly.
Goodness, this is new to me. First I thought the file had to be compiled to work. But it didn't. Yesterday I was trying it without a compiled file but it didn't work. I miss my Unix system. The command line works if you put and .exe after the 2nd file name. I hate Windows. I was running them but not reading the screen from the top where the errors were. Finally now, 1 million primes. INIT time 0.000s ( 0.000s elapsed) MUT time 0.000s ( 0.836s elapsed) GC time 0.016s ( 0.040s elapsed) EXIT time 0.000s ( 0.003s elapsed) Total time 0.016s ( 0.879s elapsed) Alloc rate 0 bytes per MUT second Productivity 0.0% of total user, 95.5% of total elapsed
This is probably a more intro-level than you're looking for, but in case anyone dropping by is looking to dip their toes in, I found [this presentation](http://www.scs.stanford.edu/16wi-cs240h/slides/ghc-compiler-slides.html) (starting on slide 9) gave a good high-level introduction. Might be worth digging through the [references](http://www.scs.stanford.edu/16wi-cs240h/slides/ghc-compiler-slides.html#(53)) at the end, or looking at the rest of the [course](http://www.scs.stanford.edu/16wi-cs240h/).
Well I just learned how to read the **GHC** compiler profiling screen. In stupid Windows, you have to put `.exe` after the 2nd file name. Life is now better. This result is for **50,150** Hamming numbers. The example above in **WinGHCi** is for **10,000** INIT time 0.000s ( 0.000s elapsed) MUT time 0.000s ( 0.836s elapsed) GC time 0.016s ( 0.040s elapsed) EXIT time 0.000s ( 0.003s elapsed) Total time 0.016s ( 0.879s elapsed) Alloc rate 0 bytes per MUT second Productivity 0.0% of total user, 95.5% of total elapsed And what the hell does **MUT** mean?
So about a two percent performance improvement? Not too shabby! Aka pretty good. I wonder how well it would work on somewhat simpler Haskell program with a more obvious hot spot ? Like: how would these shake out on the nofib suite?
I do not quite understand why there is an order of magnitude difference between user time and elapsed time. Can you share a source code, please? You may be interested to compare timings against `arithmoi` (which employs a very involved and mutable implementation): import Math.NumberTheory.Primes main = print (toEnum (10 ^ 6) :: Prime Word) Snatching at a change, if you enjoy doing number theory in Haskell, I encourage you to join me in hacking `arithmoi`: https://github.com/cartazio/arithmoi/issues
Could you also use an injective type family for methodY?
Sorry! You didn't get any replies because your post was automatically removed by the spam filter. You could try again here, or you might have better luck in r/haskellquestions.
Here are my little toy examples (\*\*not\*\* real world), implementing a step-able, bidirectional type-checker for a dependently-typed language. &amp;#x200B; [https://github.com/Ptival/chick/blob/master/backend/lib/Typing/TypeCheckOps.hs#L42-L44](https://github.com/Ptival/chick/blob/master/backend/lib/Typing/TypeCheckOps.hs#L42-L44) \^ This defines the check/synthesize operations of bidirectional type checkers &amp;#x200B; Here is some code that uses those operations: [https://github.com/Ptival/chick/blob/master/backend/lib/Typing/TypeCheckOps.hs#L101-L120](https://github.com/Ptival/chick/blob/master/backend/lib/Typing/TypeCheckOps.hs#L101-L120) It looks quite ugly because of the error handling, thanks to which it gives nifty error messages (one of the benefits of bidirectional type-checking). &amp;#x200B; Here are two interpretations of the type-checking algorithm: [https://github.com/Ptival/chick/blob/master/backend/lib/Typing/TypeCheckOps.hs#L132-L156](https://github.com/Ptival/chick/blob/master/backend/lib/Typing/TypeCheckOps.hs#L132-L156) One of them builds a whole trace of everything that happens, so that you can read the algorithm as it is executed, which is nice to debug or teach! :-) The second interpretation just runs the algorithm without tracting. &amp;#x200B; Note that the interpretation itself relies on another custom effect for local context operations: [https://github.com/Ptival/chick/blob/master/backend/lib/Typing/LocalContextOps.hs#L39-L44](https://github.com/Ptival/chick/blob/master/backend/lib/Typing/LocalContextOps.hs#L39-L44)
Oh those are nice looking slides and seems like a good explanation of realWorld! Thank you!
I’m also in the no camp for this one based on everything I’ve read in this thread. Working with unstructured csv data, number processing, and basic web stuff can far more productively be done in something like Python or maybe even Julia or similar. Maybe even Elixir which is very newbie friendly and nearly concurrent by default and very web friendly. Go is probably okay but their type system is very limited and working with outside data like JSON and CSV without generics and other stuff always felt dirty. It’d be a good stepping stone into more systemsy languages though so I recommend learning it regardless at some point. It’s easy to start, harder to master. Haskell is a good learning experience and has a broad set of things it’s great at. But no language is all encompassing which is for the best.
Getting out of the books and tutorials and actually building something is something I wish I did earlier. There’s so much learning you can do without actually understanding how it all works in practice. It’s one of those languages you need to start by trying to solve simple problems then scale out from there. Other languages you can dive into and be productive fast if you have other programming language which is also not the best way either. You have to balance learning, trying, and taking it slow before running full speed.
I just became very interested in arithmoi. It has so many dependencies. I really want it. The data.Numbers.Primes was not impressive. Here's th source. import Data.List.Ordered (unionAll,minus) import Data.List (tails) d=[2,4,2,4,6,2,6,4,2,4,6,6,2,6,4,2,6,4,6,8,4,2,4,2,4,8,6,4,6,2,4,6,2,6,6,4,2,4,6,2,6,4,2,4,2,10,2,10] -- recurring deltas n7sl = scanl (+) 11 $ cycle d c2 = unionAll . map (\xs@(x:_)-&gt; (x*) &lt;$&gt; xs) $ tails n7sl main = print $ (minus n7sl c2) !! 1000000
Out of curiosity would you be willing to show us the code you are using to define your class, I would say that a large chunk of the time `MultiParamTypeClasses` aren't needed, as usually you have one "core" type and everything else can be type or data families.
&gt; And, if you are happy with that, I don't think I'm going to convince you to use Haskell. I know you probably didn't mean this in an absolute sense, but rather as a figure of speech. But in case anyone does take it absolutely: please don't go away believing that the only advantage of Haskell is that it keeps you safe from mistakes. It's not true! Yes, Haskell code can be written to check many assumptions at compile time. And yes, the ability to use Haskell in this way is an advantage. It's a much-talked-about advantage by a certain portion of the Haskell community who are very interested in it. But it's not at the core of what Haskell is. Haskell isn't a language that double-checks everything you say. Rather, Haskell is a language that gives you more expressive tools to communicate abstractions, and *one* of the *many* ways to use that expressiveness is to state the constraints of your system and let the compiler validate them. If you choose. But it's not required. (Aside: if you speak to someone about the weaknesses of Haskell and their first complaint is that there are partial functions - functions that throw exceptions, or can loop forever on some inputs - in the standard library, then it's likely you're talking to someone whose perspective on Haskell is caught up in safety. These people are complaining that Haskell, while it has an expressiveness that's very useful in reasoning about correctness of code, isn't 100% specialized on that goal. If they find that benefit motivating, good for them! You can always get more compile-time validation, though, if that's your thing, by using a specialized tool. LiquidHaskell, for instance, throws an SMT-solver at the problem and makes a lot of things easy that are still hard in Haskell. But if you think these people sound a little obsessive... well, I think so too, sometimes. They are missing the forest for one specific tree. Safety is not the only thing you get from Haskell.) To the /u/mahtats: from reading this thread, it looks like you came to Haskell having heard it's good at parallelism, and expected to find a language for squeezing performance out of multi-core hardware. Haskell is indeed good at parallelism, but from a different point of view. It's good at being a language in which you can describe things in an expressive way from which it's easy to deduce what can be done in parallel. It's not particularly good at squeezing every last nanosecond from your CPU. Indeed, anything you can do in Haskell can probably be done just as fast in C... but it will be a lot harder to get it right. Again, the strength of Haskell as a language isn't that it's a tool that is well-designed for one task, but that the language is more expressive, and one way to use that expressiveness is to deduce things about parallelism. Haskell has been a successful environment for research into parallel models of computation: nested data parallelism, software transactional memory, fusion rules that expose parallel expressions, parallelism combinators, etc. Those ideas have taken root and seen implementations in other tools; often tools that specialize in that goal. In the end, the absolute fastest implementations of these ideas may be done in languages that are closer to the machine. While much research has gone into efficiently compiling functional languages, their performance still won't quite live up to a language like C that's closer to just telling the machine exactly what to do. The research goes into how to generate code that's pretty fast *despite* the language itself being very high-level and expressive. As you look at other advantages of Haskell, you'll find something similar. Haskell is a general-purpose language, and isn't really specialized to any one use case. It's specialized in letting you express structures and abstract over common patterns that you simply cannot capture easily in mainstream programming languages. What you do with that is up to you. But, my opinion here, you'd be missing a huge opportunity if you didn't at least learn how to think in these ways. This is true regardless of whether you actually build something useful in the language.
Do you have any MSc studentships/projects for EU students?
So if I try to use only that function as a library in my java project, do you think it will be possible ?
&gt; What I want is to do something like Int a =&gt; to specify the type allowed for fmap function you can't write an `fmap` that only works for `F Int` – Functors can't have constraints, they must be able to "contain" any type (`F Int`, `F String`, `F (Maybe ())`, anything). could you explain whay you're trying trying to do in general, and why you're making `F` a Functor?
I hope you see the factually irrelevant irony in saying TypeFamilies are more functional than FunctionalDependencies
Btw, is the problem with incorrect schema generation itself solved in `servant-swagger` package?
Personally, I decided to get rid of swagger stuff in this project. I was unable to solve the issue. My front end is written in Elm, and I don’t expect other implementations, so I solved this issue by moving to servant-elm and elm-bridge. Works like a charm, and also code is now more simple and pretty.
&gt; I'm currently working on a web browser written in Haskell as a showcase for how to use polysemy (I'm teaching myself as I go!). I'm curious; are you using sdl2 for this, like in my [demo browser](https://github.com/chrisdone/vado)? I'd recommend it for the cross-platform factor and ease of installation.
I would like to see how resumable exceptions are implemented /used in semantic
What about extending the type family implementation with another family to emulate the other dependency: example2 :: (AddT n m ~ nm, SubT nm n ~ m) =&gt; ...
I just never had a concrete use case to create my own applicatives so that was just me messing around in ghci. Make sense though. Thanks.
It’d be very cool to see this done using the `serialise` package - I saw you planned to use Binary; Serialise is the de facto next generation of Binary with better performance and using a standardised encoding (CBOR).
Nothing quite so drastic --- building it on top of webkit.
There are too many packages. Does a guide exist anywhere for "what should I choose?"
Not that I know of - #haskell isn’t a terrible place to start by asking the question. Also Stephen Diehl [What I wish I knew when learning Haskell](http://dev.stephendiehl.com/hask/) covers many libraries, but I don’t know of an well maintained list of “what is the flavour of the month for doing X” (or “what has the community decided is the best way to do X as far as we know” - pretty sure Polysemy would fall into this category, if not now, then shortly).
Is it conceivable to have an `IO` monad transformer? Perhaps something like `type IOT m a = StateT RealWorld m a`?
Just to add one more thing to this excellent answer. It can be helpful to think of these interpreters as custom compiler passes for a language you made. When done right, many times you can show source to PMs and they can understand what’s going on at the business logic level.
It’d be cool to use or make a custom slant style ranking engine for libs in various domains.
I would be very interested to see what improvements something like Repa or Massiv achieve with this, I wouldn’t be surprised if they produce much more code which looks like what LLVM would be optimised to optimise for. Also JuicyPixels, and possibly some numerically intensive code using vector-space.
Haskell is quite good in complex data transformations in production: look at `Frames` and `pipes`. Mostly the leverage comes from the expressivity of the language and the robustness of the resulting code. Numerical computations can take work to get up to Java levels of performance unless your algorithm can use laziness to short-circuit computation (we still have ifaict, the one of fastest cover-tree implementations: http://proceedings.mlr.press/v37/izbicki15.pdf). If your computation can be expressed in array based computation, we’ve got a few strong options: massiv, hmatrix, accelerate, hasktorch, tesorflow. But these can be heavyweight programming idioms.
This is the big win for effect systems, as far as I'm concerned. You write your core algorithm in what amounts to pseudocode, then use effect interpreters to give semantics to the abstract syntax tree that code describes. It feels downright magical.
The book’s great. It’s use of `first-class-families` was a boon to a few of my type-level projects.
We can do that in Haskell, too. :-)
This kind of thing wouldn't be terribly useful. For any transformer, you have a "run" function that "peels back" the outermost layer of your transformer stack. So you have for example runStateT :: StateT s m a -&gt; s -&gt; m (a, s) runReaderT :: ReaderT r m a -&gt; r -&gt; m a So, effects like mutable state are local and not visible outside of the `StateT s m` computation. Every application of the `run*` function gives you back something that is a little "purer" so to say. Would you want that to apply for an `IO` action? You would need the transformer equivalent of unsafePerformIO :: IO a -&gt; a While this function does have its uses in certain situations, I would think this is not one of them.
This is the only package I’m aware of: https://github.com/tclem/twirp-haskell
&gt; It’s not clear to me why the mangler doesn’t seem to actually be necessary (for the binaries I tested, on my machine). Does anyone know if this is the case?
Yea, totes
No, you can do that in **GHC**, after adding enough extensions to choke a horse, and with a much inferior syntax. Let me know when type-level programming is in a Haskell report. ;)
Yes, but GHC only supports Haskell! (It is, of course, unpleasant unless you’re into such things, but it can still be done.)
I am a relative Haskell newbie so I installed cabal-install then cabal install athitmoi and it also installed all the dependencies. I don't have to do it, la la, la la, la la. I am so happy.
&gt; is calling a Haskell program the right thing to do? It's a engineering decision, not a moral one. Adding a new language to your program can make some things harder, but it can also make implementing new feature(s) much easier. Personally, as long as I can figure out the CI for building the multi-language result, I've got no problem mixing many languages.
&gt; I hate Windows. Install [Debian](https://www.debian.org/) -- it's what I use for work and home.
That sounds (analogous to) like some BDD frameworks like Cucumber, where the behavior is described in a high-level language, and that high-level language is tied to underlying code that implements it.
Hahahahah My last 286 multi-user desktop had Debian. I even had a printing terminal like was used to develop the Unix OS. I even used it once or twice times. Now, where I work, our network guys cannot tolerate anything but Windows. We also use and IBM i and they are lost on it. I quit my job at a hospital in part because they decided to move to a Windows based system. They had a Forth system from the OS up and was very fast with about 80 or 90 serial terminals. They had a Unix system for support also and then we used a Linux system for e-mail. I don't remember what flavor they were. I deliver Excel spreadsheets from data from programs and write Excel queries in SQL (.dqy). Some of spreadsheets are from Cygwin scripts which I could not survive without. It is so funny, When I worked for a school system they bought me a Unix system with terminals. I developed a hybrid database system which was hierarchical and relational using Unix tools. They had laser printer graphical reports from troff and data merging. I wanted a faster database system so they bought me MDB 4 a post-relational DBMS. It was a network model database system and consisted of a 'C' a function library. I drew schemas for the named relationships. Now I got the O'Reilly free book on graphical database and it is the same thing. A database with no database index files. Sweet.
That's a newer feature and I haven't read the paper. Do they work well with open type families? It seems like the compiler wouldn't be able to verify the injectivity if the instances are spread throughout various source files.
Alright. Nice to hear haskell&lt;-&gt;elm interaction works flawlessly.
The trick with effect/free monad implementations is that the language is explicitly *untied* from the implementing code; you can have multiple interpreters for the same language. This has some great knock-on effects in terms of helping you write tests, auditing/logging for specific interactions only, etc.
Why isn't this a valid data construction? ghc error isn't terribly helpful \`\`\` data G a = G 0 \`\`\` I want a type that takes any value and puts a 0 zero there instead. Seems perfectly sensible.
This is great! I'm trying to port some of the ideas of compdata to Scala but i'm struggling to find resources online. Is there any resource apart of the original papers you've found useful?
So the structure of a `data` declaration is data &lt;TypeName&gt; [&lt;TypeParam0&gt; &lt;TypeParam1&gt; ...] = &lt;ConstructorName&gt; [&lt;TypeParam'0&gt; &lt;TypeParam'1&gt; ...] So in your code `0` doesn't mean the *value* 0 (of some `Num`eric type), but instead some *type* 0. If you want a type constructor that ignores the type's parameters, that's easy to do: data G' a = G' Alternately, you can construct your own type to represent `Zero`: data Zero = Zero data G'' a = G'' Zero
Is smart constructor a library, ghci pragma or just a pattern?
[Just a pattern](https://wiki.haskell.org/Smart_constructors)
Is there a canonical class for types with an "isZero :: a -&gt; Bool" method? Like monoid, but instead of declaring \`mzero\` being able to detect a zero.
I've worked quite a bit with call/cc in Scheme - it can be tough to reason about, but then so can lazy evaluation. There are alternatives like delimited continuations, which give finer-grained control. As long as you're able to encapsulate the continuation usage in a library, so that ordinary user code doesn't have to deal with it, it's fine. But I do think you have to pay more attention to the design of the control flow than in Haskell; the main issue in Haskell is dealing with side effects (haha) of lazy evaluation, like space usage.
Cool. I'll slowly digest your comment. Thanks.
There's [`MonoidNull`](http://hackage.haskell.org/package/monoid-subclasses-0.4.6.1/docs/Data-Monoid-Null.html#t:MonoidNull) in `monoid-subclasses`. What do you mean by canonical? It doesn't appear to be in very widespread use, if you mean that…
Here is a very efficient implementation of quicksort, that will be automatically parallelized if needed: \[quicksort\]([https://www.stackage.org/haddock/nightly-2019-06-05/massiv-0.3.4.0/Data-Massiv-Array.html#v:quicksort](https://www.stackage.org/haddock/nightly-2019-06-05/massiv-0.3.4.0/Data-Massiv-Array.html#v:quicksort)) See this SO answer for more info oh how it is implemented, how it compares to others and what is the actual speedup: [https://stackoverflow.com/questions/19752983/is-it-possible-to-speed-up-a-quicksort-with-par-in-haskell/55885118#55885118](https://stackoverflow.com/questions/19752983/is-it-possible-to-speed-up-a-quicksort-with-par-in-haskell/55885118#55885118)
Do you actively want it to be something other than monoid for some reason? It seems like it's the intersection of Monoid and Eq: {-# LANGUAGE ConstraintKinds #-} type HasZero a = (Monoid a, Eq a) isZero :: HasZero a =&gt; a -&gt; Bool isZero = (== mempty)
I wanted to avoid the `Eq` constraint specifically, allowing types like `Maybe a` but without necessarily requiring `Maybe a`. Just wondering--premature generalization.
It's likely that the path where Data.Optional is located isn't in the search "index", but I'm not sure.
Thats the function I'm looking for. But I did mean something in widespread use. And the dependency footprint is a little large. I'll take it that there isn't really much call for it in the community. Thanks!
How would I fix that?
Which package do you want to import that module from?
Some EU students came for internships over the summer last year to work on type theory / formalise results in Agda. This type of thing is usually organised during the fall / early winter and achieved by directly contacting the researcher you want to work with.
Do you perhaps have a source for this? ``` data &lt;TypeName&gt; [&lt;TypeParam0&gt; &lt;TypeParam1&gt; ...] = &lt;ConstructorName&gt; [&lt;TypeParam'0&gt; &lt;TypeParam'1&gt; ...] ``` I think I am confused on when `a` denotes a type and when it denotes a variable, and when do I start using the syntax for a type declaration as opposed to say, writing a function.
Not Haskell, but ScalaZIO makes heavy use of (Kleisli) arrows to get rid of most overhead.
Wow, very nice work!
Could you outline your plans a bit? For example: \- what your goals/milestones are \- at what point, if successful, you might hope to make this mainstream in the sense of being officially merged into one of GHC/Idris/Agda
Could somebody please help me with understanding the state monad? I felt like I was starting to understand everything, until I came across this page and example: [https://wiki.haskell.org/State\_Monad](https://wiki.haskell.org/State_Monad) type GameValue = Int type GameState = (Bool, Int) playGame :: String -&gt; State GameState GameValue playGame [] = do (_, score) &lt;- get return score playGame (x:xs) = do (on, score) &lt;- get case x of 'a' | on -&gt; put (on, score + 1) 'b' | on -&gt; put (on, score - 1) 'c' -&gt; put (not on, score) _ -&gt; put (on, score) playGame xs startState = (False, 0) main = print $ evalState (playGame "abcaaacbbcabbab") startState What is the purpose of GameValue? I can't see it actually being used anywhere. Of course, it's part of **State Gamestate GameValue**, but the actual state seems to only consist of the **(Bool, Int)** tuple. The **(one, score) &lt;- get** should return **(s,s)** right? so wouldn't that give: **((on, score),(on, score))** ? I'm also very confused about how the recursive call to pkayGame "has" the next state. If it were playGame :: String State GameState GameValue -&gt; State GameState GameValue I could understand. I feel like without the recursion, using only bind, the state passing makes sense, but when it happens recursively like this, I'm finding it impossible to "trace" just where and how the state gets through to the recursive call. Really sorry for how badly-structured these questions are. I've been reading several different tutorials and trying to work things out for a week now, and every time I think I'm getting somewhere, everything just seems to become confusing all over again, and I'm confused about what it is I'm confused about! Cheers. Hopefully someone sees this who had similar problems and can advise me on how they came to understand.
The roadmap is roughly this: - integrate souffle datalog compiler to the system for fast analyses - implement basic GHC and Idris primops (arithmetics, arrays, mutvars) in the GRIN interpreter and native codegen - implement simple GC - simple backend support (x64 and WASM + some working programs) Our next milestone is to compile simple programs with GHC/GRIN to x64 and WASM. Then we will gradually extend the GHC primop support. Our goal is to make some programs compile with acceptable compile time.
Your first typeclass only has a few instances.The condition that must hold is that whenever there is an element `fx : f b`, then there must be *no* elements of `b` (That always terminate). Suppose there is an element `fx : f b`, and an element `x : b`. Then we have `contracomap (\_ -&gt; x) : forall a. a There is the contravariant functor, `Not a = Not { runNot :: a -&gt; Void}`, but this doesn't work, the best we can get is Not (Not a).
Ah, thanks! But what do you mean by `contracomap (_ -&gt; x) : forall a. a`? Is it `contracomap (\_ -&gt; x) ;; forall a, a` or is it `contracomap (something $ x) :: forall a. a`? Currently, I can't make anything of it - unless it's a hole, in which case, what's the `_` doing there? Regardless, for now, I'll disregard this (now seemingly useless) class
I’ve explained functors (the container analogy way at least) to scores of developers who have no experience in Haskell. They do get it. It’s not that hard. There’s no reason why a developer would need to understand recursion before they can understand and/or use a functor.
I think the "Benefits For Programmers" for the programmers can be made more clearly. I think it's to vague and would recommend you to include explicit examples where current tooling fails to communicate/optimize and why this is important (essentially: look for "Less could/would improve/be possible" etc. and try to be more specific).
I want to critique your [Cofunctor and its derivatives](https://github.com/schuelermine/Functors/blob/master/Functors.hs#L28). If a category C, if some object X fits a 'pattern', then you can say that the same object fits a co-'pattern' when viewed in C^op . So if we're in some category C, and object PAB is the product of some A and some B, then PAB is the coproduct of those A and B when we're in C^op (an opposite category has all the objects of the original category; only the arrows are different). A functor is a mapping between two categories that preserves identity arrows and arrow composition. My question is: does the concept 'functor' fit the notion of 'pattern in a category'? If it did then we could say "when some object X in category C is a functor, then X is a co-functor in C^op ", and try to reverse engineer a definition of co-functor. I argue that the answer is 'no' (experts, please correct me). 'Functor' doesn't make sense to me as a 'pattern in a category', in the way that products or coproducts do. --- It's a little confusing to figure out what to do when someone tells you `co-X = flip the arrows`. It's confusing, because in the case of `comap :: (f a -&gt; f b) -&gt; (a -&gt; b)`, the arrow that you flipped isn't actually a 'category arrow'. In `fmap :: (a -&gt; b) -&gt; (f a -&gt; f b)` the two 'category arrows' are the one in `a -&gt; b` and `f a -&gt; f b`. The arrow in the middle is just 'syntax'; Haskell code we need to write to get things going. In my opinion it's hard to figure out which arrows are which until you learn more non-Haskell-motivated category theory.
The state monad is just decoration for a function that has a “state” parameter both as an input and an output. Im simplifying of course, but thats the essence. The monad instance is useful because it lets a programmer compose such functions (literal function composition) without fussing about passing the parameter. To really understand it, try implementing the monad instance, State s, for this data (sorry mobil formatting) data State s a = State ( s -&gt; (s,a)) That is, implement return and &gt;&gt;=. I guess now a days youll have to implement functor and Applicative first, but implement all thise and youll get state monad.
This confuses me. Everything I found is that an FP would be ideal for parallel computing. I've got a BST, I need to compute a bunch of geometry on the tree. Why would Haskell not be a fit for that? To note, I'm not asking if the ecosystem is good for it now; I know its not, it wont beat Python. But I am also not looking to data science operations in the sense of massive dataframe manipulation. I'm not sure where this "number processing" came in this thread, but I never said that. Yes, I need to perform numerical operations like geometry checks using booleans like De Morgans, but thats just simple mathematics; at most I would need to do some planar geometry. So to traverse a tree, compute along the tree and return results, all in parallel...why not Haskell? Forgive me if it is sounding redundant, and again I'm sold on typing/purity/etc., but I am having trouble understanding when I should (not want) to use an FP language such as Haskell?
So, probably really dumb question. I'm a complete haskell beginner and I recently decided to take on the [synacor challenge](https://challenge.synacor.com/), you basically write a small VM in it and i thought it'd be a neat challenge. I've done it in C before and i thought it'd be interesting to see how differently i'd have to approach the problem functionally. The way I approached it is having the entire VM's state be a single object which gets updated at every tick, and that way the main loop can look something like: runVm:: VMState -&gt; VMState runVm vm | (flags vm) .&amp;. 1 == 1 = vm -- STOP flag is set | otherwise = runVm $ exec $ nextInstruction vm --Grab the next instruction and execute it, which then returns the new state So everything works fine, but I have a big problem: Part of this challenge is that you need to have an internal buffer that you should be able to **read from** and **write to** constantly at any index. This buffer is about 59k bytes big. When I started I just represented it internally as a `Data.Sequence` of Chars, which I thought would be fine since I read it was faster for writes than a plain list of char. Of course that went awful, and since then I've tried other things but nothing works, even `ByteString`, whenever the VM goes into heavy read/write operations it basically hangs for a few seconds. Of course back in C I didn't have this problem - I just had a large raw `char` buffer I could modify and reference by index, with every operation being basically O(1), is there just no way to achieve similar performance on such an operation in Haskell? I've been looking for a while and I just can't find what I'm supposed to be using here.
The [Haskell wiki](https://wiki.haskell.org/Type#Data_declarations) goes into the specifics. I also like [Real World Haskell's approach](http://book.realworldhaskell.org/read/defining-types-streamlining-functions.html)
No these are good questions. I believe Haskell can be highly concurrent far easier than most languages without having to shoot yourself in the foot too easily. I'm just speaking from experience after learning about ~10 languages that Haskell is a bit of a special language, which you should wade carefully into. The most important thing is tempering expectations because the language curve is high. You can build beautiful and well composed code in Haskell that is very dependable and easy to maintain. But coming from the Ruby/Python/Clojure/Erlang/Elixir/web world initially where I was used being able to jump in and hack out a program, then later learn how it all works. With Haskell that barrier is much higher but all very rewarding and teaches you many applicable skills elsewhere. My main point was about parsing unstructured data from CSVs and web endpoints, which is super simple in a weakly typed language where you dont have to figure out the structure of the data coming in beforehand, and properly wrap it in a typed struct. Then learning how to mutate and manage state is the next big learning curve as you learn to wrap functions in monads and other functors. Then you have to learn how to query complex objects efficiently so you go down the lens rabbithole and learn that whole thing (which is used heavily in every serious Haskell web app I've seen). If you came here asking to learn a new language for fun and for learning first I'd say sure. But for your particular usecase (ie learning a useful lower-level/faster language to make your stuff more powerful) I'm really not sure Haskell is the perfect choice. Once you really commit to Haskell I'm sure you could find many situations where it could be useful. But it requires dedication and patience, as most high reward things require.
According to [https://gitlab.haskell.org/ghc/ghc/wikis/injective-type-families](https://gitlab.haskell.org/ghc/ghc/wikis/injective-type-families) &gt;Open type families (including associated types) &gt; &gt;Open type families are typechecked incrementally. This means that when a module is imported type family instances contained in that module are checked against instances present in already imported modules. In practice this is done by checking equations pair-wise (a new equation against all already checked equations -- modulo optimisations). I actually was inspired by this post and used TypeFamilyDependencies with an associated type yesterday and it worked fine: class MonadConcurrentJobs m =&gt; MonadProcessJobs m where type Input m = o | o -&gt; m type Output m getInputs :: m [Input m] spawnAsync :: Input m -&gt; m (Async (Output m)) finalizeOutput :: Input m -&gt; Either SomeException (Output m) -&gt; m () makeItemKey :: Input m -&gt; Text I needed to make `Input m` injective since `m` doesn't appear on its own in the type of `makeItemKey`
Sorry, I used a backslash, which got rendered by reddit as just \_, it was supposed to be \\\\\_ -&gt; x
Although of course, when discussing categories, Functors are themselves arrows (between categories), so the dualization is different, but quite reasonable. If Cat is the category of small categories and functors, then Cat^op has the "cofunctors" as arrows
What's the difference between, &gt; cabal install &gt; cabal install --only-dependencies Both seem to install build artifacts into the sandbox dir just fine. What items are being installed with cabal install - if it's not actual dependencies?.
&gt; Our goal is to make some programs compile with acceptable compile time. Most realistic Kickstarter stretch goal I've ever seen.
I don't see how it's as reasonable as you claim. Continue your line of reasoning to come up with a definition for "cofunctor". At the end, I should be able to come to you with any mapping between two categories, and you would be able to decide whether or not my mapping is a "cofunctor".
summary or blurb for those of us who aren’t sure if the talk is up our alley?
OK
I've been programming for about 5 years, 3 in a professional setting. My background has been C/C++ to Java to Python. As I've grown over the years, I learn more and more about the tools I am using. When developing with Python, I've slowly come across limitations (such as those imposed by CPython's GIL) and learned how Python works at run-time, ultimately leading to the development of my own C bindings for parts of applications that I require speed for (such has traversing trees and doing cluster analysis on billions of points). Now as time goes on, I find myself falling into the "oh look shiny" rabbit holes. Take Haskell for example. I see a post about Haskell, I've never heard of this, do a bit of Googling, see it's a FP language, good for mathematics and its great for concurrency, oh I could use some concurrency. Do some more Googling, "OO is bad and FP is great", really? Well I primarily use OO, is that bad? Should I look into trying to convert some OO to FP where I can? Why not? Come here and post to see if its a good fit. So the ultimate reasoning was "OO is bad and FP is great" and that spooked me. 99% of my courses were focused on developing software using imperative languages through PP and OO; FP was used once or twice to demonstrate other paradigms for "one off" uses like war game simulations in academia, not for client side applications for a consumer marketplace. Fast forward through this post and Haskell sounds challenging and fun! I like the typing, maintenance and concurrency bits. I've read the GitHub and Facebook articles about how and why they use it. But I'm still stuck scratching my head: **when is Haskell a good choice?** I've seen parsing (okay, parsing a known CSV format returned by some web endpoint), I've seen ADTs (okay, building a traversing a tree), I've seen mathematics (I use a lot of it) and I've seen concurrency (I could use more of this). Yet after all that, I'm told "Haskell is probably not best for this". Um, okay. Then what is it good for if all those which align with what I needed is not good enough to say its a great fit? The ecosystem page says where it excels but I feel as though thats a "where is it flourishing as it pertains to community input/packages" and not "where Haskells design/features are best used". Is it big in numerical operations and data science, not according to that page, but Haskell itself would be great for certain cases but there just arent a lot of packages/support out there for it. Well I didnt need a package or support, I'll write the whole thing! I just wanted to know if Haskell was appropriate for what I was doing in Python/C since it aligned with [this](https://stackoverflow.com/questions/2078978/functional-programming-vs-object-oriented-programming) SO post. TL;DR: When is an FP language like Haskell a good choice to replace an existing OO/PP implementation?
In that particular case, I was orienting myself on the definition of [comonads](https://hackage.haskell.org/package/comonad), and it seems to me the analogy of "you can see inside it, but you can't put stuff in it" is continued with this definition. Is there a better name?
I don't think extending the analogy is appropriate here; comonads are still functors, not cofunctors. What would the laws look like? The same as the functor laws, just with different types? Also, are there any examples of one (besides `Identity`, which does not count)?
**BRIEF BACKGROUND** The type definition of `&gt;&gt;=` for `State` monads looks like this. **(&gt;&gt;=) :: State s a → (a → State s b) → State s b** Its important to note that when binding a value of `State s a` with a function `a -&gt; State s b`, this function can only access `a`, or equivalently, whatever the first element is in the 2-tuple seen in `State (\s -&gt; (a, s))`. &amp;#x200B; &amp;#x200B; It's probably useful to recap on the three main state monad functions we're using. I also prefer to talk about the `State` monad in terms of `runState` and ignore the constructor; `runState` is the actual state machine functionality we care about, whereas the type constructor `State` is just a wrapper around it. &amp;#x200B; * **Get** – We use this to get the current state of a `State` monad. It returns a `runState` which when given some initial state, will use this as both the output state and output value. &amp;#8203; get :: State s s get = state $ \st → (st, st) Due to how `&gt;&gt;=` is defined for the `State` monad, every time we bind a function onto some instance of `State s a`, this function will always only be given the current value of type `a` held in the `state` monad. So what if we instead use type `s` for both type parameters of `State` \- using `State s s` means that it is now type-correct to pass forward the state as the input of the next binded function. &amp;#x200B; When we see the code: `x &lt;- get` Desugaring this gives us: `state (\st -&gt; (st, st)) &gt;&gt;= (\x -&gt; ....)` where `x` would be `st`. &amp;#x200B; * **Put** – We use this to update the current state of a `State` monad. Given some new state, returns a `runState` where the output state is set to the new state, and the output value is set by default to unit `()`. &amp;#8203; put :: s → State s () put newState = state $ \_ → ((), newState) The lambda function used to define `runState` ignores any inputs, as the new state is already provided to the function `put`. When this is binded with some following function, the input that the lambda function receives will clearly be unit `()` \- this is useless, so we can just ignore the input in the lambda function. &amp;#x200B; When we see the code: `put st` Desugaring this gives us: `state ( \_ -&gt; ((), st) ) &gt;&gt;= (\_ -&gt; ....)` &amp;#x200B; * **Return –** We use this to set the current value parameter (of type `a`) of a `State` monad. Given some value of type `a`, we return a `runState` that when given some initial state of type `s`, will return the complete 2-tuple of type `(a, s)` containing both the value and state. &amp;#8203; return :: a → State s a return a = State $ \s → (a, s) &amp;#x200B; **ANALYSING PLAYGAME** &amp;#x200B; Okay cool, so i'll try and desugar **playGame**. I'm only going to do the pattern match for non-empty lists because it should be transferable. I'll also simplify the case-of expression so it doesn't get overly ugly. This is what we're working with below: playGame :: String -&gt; State GameState GameValue playGame (x:xs) = do (on, score) &lt;- get -- Step 1 case x of -- Step 2 _ -&gt; put (on, score) playGame xs -- Step 3 **Step 1** Recall that the line `a &lt;- get` is equivalent to `state (\s -&gt; (s, s))` `&gt;&gt;= (\a -&gt; ....)` Okay, so `(on, score) &lt;- get` is equivalent to `state (\(s1, s2) -&gt; ((s1, s2), (s1, s2)))` `&gt;&gt;= (\(on, score) -&gt; ..`**&lt;Step 2&gt;**`..)` **Step 2** Recall that the line `put st` is equivalent to `state (\_ -&gt; ((), st) )` `&gt;&gt;= (\_ -&gt; ....)` So step 2 can be written like `case x of _ -&gt; state (\_ -&gt; ((), (on, score)))` `&gt;&gt;= (\_ -&gt; ..`**&lt;Step 3&gt;**`..)` **Step 3** Recall that `return a` is equivalent to `State $ \s -&gt; (a, s)` So step 3 is simply `State $ \s -&gt; (a, s) &gt;&gt;= (\a -&gt; playGame xs)` &amp;#x200B; Putting everything together looks like: playGame :: String -&gt; State GameState GameValue playGame (x:xs) = state (\(s1, s2) -&gt; ((s1, s2), (s1, s2))) &gt;&gt;= (\(on, score) -&gt; case x of _ -&gt; state (\_ -&gt; ((), (on, score - 1)) ) &gt;&gt;= (\_ -&gt; playGame xs) ) Sorry, my explanation is quite messy and probably too informal, i have genuinely been awake for 73 hours now. I'm aware I haven't answered your two questions directly, but I'm hoping my description of the process can make something click. If it hasn't, I'd be happy to try and help again.
As someone who dreamed of doing something like this (whole-program compilation of GHC Haskell, crowdfunded) in grad school but failed miserably at each step, I wish you luck. Have my upvote and retweet.
Hey thanks! I'm afraid I don't have much more to point you to but I have a few suggestions: &amp;#x200B; \- If you are unfamiliar with recursive datatypes as non-recursive functors then I'd recommend following some language specific intros to recursion schemes first \- Actively playing with the compositional datatype examples helped me understand the constructions: [https://github.com/pa-ba/compdata/tree/master/examples/Examples](https://github.com/pa-ba/compdata/tree/master/examples/Examples) \- Sections 3 &amp; 4 of the Data types a la carte paper has nice Haskell examples of the underlying concepts but: \- I'm not familiar with Scala so I can't help you translate them directly. I'd look at some of the Scala recursion scheme libraries to use as a starting point for data types etc. (perhaps this [https://github.com/slamdata/matryoshka/](https://github.com/slamdata/matryoshka/) ) &amp;#x200B; Hope that helps!
I’m using Hakyll (and doing anything web-related) for the first time - I’m trying to render math with `Hakyll.Contrib.LaTeX`, but my tikz figures are all cut off. Does anyone have ideas where to begin changing things in order to get the figures to be created properly? This is the relevant code where markdown files are converted to html: &amp;#x200B; import Hakyll.Contrib.LaTeX (compileFormulaeDataURI) import Image.LaTeX.Render (EnvironmentOptions (..), FormulaOptions (..), defaultEnv) import Image.LaTeX.Render.Pandoc (PandocFormulaOptions (..), defaultPandocFormulaOptions) env :: PandocFormulaOptions env = defaultPandocFormulaOptions {formulaOptions = \_-&gt;FormulaOptions customPreamble "displaymath" 200} site :: IO () site = hakyllWith config $ do match "content/*" $ do route $ setExtension "html" compile $ pandocCompilerWithTransformM defaultHakyllReaderOptions defaultHakyllWriterOptions ( compileFormulaeDataURI defaultEnv env) Looking at the generated html, it looks like the cutting-off has already occurred when the image is stored as a base64 string. It ends up looking like [this](https://imgur.com/a/KIen3y2) instead of [this](https://imgur.com/a/ucvpZH1)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/1EaxTPD.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20eq5pkzv)
Using FFI you can communicate those easily. Read about FFI in the Ghc users guide. Stack build will create some `.so` files in your `.stack-work` folder that you must then give to the linker when compiling the C project.
~~Right, thinking about it, I now realize that every applicative is a cofunctor... so it makes even less sense.~~ Oh crap, it isn't! But every type that's a `Comonad` and an `Applicative` is a cofunctor... but most likely, these don't exist, you're right... EDIT: What about data Stream a = a :+ Stream a instance Functor Stream where map f (x :+ xs) = f x :+ map f xs instance Applicative Stream where pure x = x :+ pure x (f :+ fs) &lt;*&gt; (x :+ xs) = f x :+ (fs &lt;*&gt; xs) instance Comonad Stream where extract (x :+ _) = x expand s@(x :+ xs) = s :+ expand xs instance Cofunctor Stream where comap f = extract . f . pure
You still haven't mentioned the laws, which would probably be important, and your proposed instance of `Cofunctor Stream` does not satisfy the obvious ones (i.e. `comap id = id`, `comap f . comap g = comap (f . g)`). Specifically, consider `accumulate :: Stream Int -&gt; Stream Int; accumulate (h :+ t) = h :+ accumulate (map (+ h) t)` (thus, `accumulate $ 1 :+ 1 :+ 1 ...` -&gt; `1 :+ 2 :+ 3 ...`) and `tail :: forall a. Stream a -&gt; Stream a ; tail (h :+ t) = t`. Then `comap (tail . accumulate) 1` -&gt; `2`, but `(comap tail . comap accumulate) 1` -&gt; `1`. So any type constructor `f` with `in :: forall a. a -&gt; f a` and `out :: forall a. f a -&gt; a` gives rise to some instance of cofunctor, but does that make it *useful*?
Not exactly this, but close: [https://guide.aelve.com/haskell](https://guide.aelve.com/haskell)
So I found some .o, .hi and \_stub.h files. does these file include all of other imports in my Haskell Module when calling from C?
Oh, right. Hadn't thought about that. Though `comap id = id` holds. And you made an error, your `accumulate` doesn't work correctly: accumulate $ pure 1 = 1 :+ 2 :+ 4 :+ 8 :+ 16 :+ ... I suggest implementing it as follows: accumulate s = f 0 s where f y (x :+ xs) = y + x :+ f (y + x) xs
Seems like you should maybe use a mutable data structure. `vector` has mutable variants. Or you could take a look at the `primitive` package, e.g. [`PrimArray`](http://hackage.haskell.org/package/primitive-0.7.0.0/docs/Data-Primitive-PrimArray.html).
Thanks! I'll look into those
I believe this could be helpful for grokking (mutable) vectors: https://haskell.fpcomplete.com/library/vector
Oh my god thank you this is great soft documentation! Also I just realized I wasn't using optimization flags which really boosted my program's performance. However I still think i'd really benefit from using vectors, they definitely seem like the standard for the kind of stuff I need
are GHC/Idris/Agda creators know about this project? do they want to share the same backend?
If you don't mind a non-alpine, relatively huge image, there's this. [https://hub.docker.com/r/fpco/stack-build](https://hub.docker.com/r/fpco/stack-build). If (understandably) you want something alpine sized, couldn't you build ghc in the dockerfile?
1) are GHC/Idris/Agda creators know about this project? do they want to share the same backend? 2) idris is eager, haskell is lazy, how this is handled by GRIN?
calling /u/jkachmar
With `ghc-8.4.3` you can build a `ghc-8.6.5` bindist pretty easily. I haven't tried with hadrian yet, but with the make-based system, the only hack required for alpine is supplying `--disable-ld-override` to `configure`, the other steps are identical to vanilla linux builds.
&gt; or is it best to simply create a top-level namespace reflecting the name of this tool? Yes, this!
Well you'd have to pick a base category, and once you do it's fixed. So that definition would end up begin, a full endofunctor from a quotient category of C to C, (since an endofunctor from C to C often sends it to an image which is not all of C, as is the case in Haskell). In effect you simply reverse the notion of function.
1. GHC/Idris/Agda developers should be are aware of this project. There was some communication with them on various conferences and reddit in the past. If the GRIN optimizer will be beneficial for these languages I bet they will not be against it. 2. GRIN is a strict language, so the strict language support is straightforward. Lazy languages are compiled to GRIN by using [whole program defunctionalization](https://en.wikipedia.org/wiki/Defunctionalization) and by generating a specialized *eval* and *apply* GRIN level function to handle laziness explicitly. You can read about the technical details in Urban Boquist's [PhD thesis](https://nbviewer.jupyter.org/github/grin-compiler/grin/blob/master/papers/boquist.pdf#page=59). 3. The project has 3 developers. I've been working full time on GRIN for 1.5 years now. I funded this project from my saved money so far. There is also Andor Penzes and Peter Podlovics. Andor has a full-time software engineer position in the industry, so he works on the GRIN project in his spare time (mostly) in the weekends. Peter is doing his CS MSc. He joined this project last year when he looked for a cool Haskell related university project topic.
**Defunctionalization** In programming languages, defunctionalization refers to a compile-time transformation which eliminates higher-order functions, replacing them by a single first-order apply function. The technique was first described by John C. Reynolds in his 1972 paper, "Definitional Interpreters for Higher-Order Programming Languages". Reynolds' observation was that a given program contains only finitely many function abstractions, so that each can be assigned (and replaced by) a unique identifier. Every function application within the program is then replaced by a call to the apply function with the function identifier as the first argument. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
That looks great. Will you post it on https://discourse.elm-lang.org/ ?
Let's take a step back and talk about fmap as a function from `(a -&gt; b)` to `(f a -&gt; f b)`. If that mapping is a function, and satisfies the functor laws you have a normal `Functor`. If you require this function to have an inverse, you are talking about a "fully faithful" `Functor`. I usually use the name `unfmap` for this, rather than `cofmap` and tie its existence to the functor. An example of such a beast is `Identity`. A more exotic example is the embedding `Dict` of the category of constraints in Haskell into Hask. Given any arrow `(Dict a -&gt; Dict b)` you can construct an arrow from `(a :- b)` using my `constraints
Can you a two stages dockerfile, build the executable in a bigger images [/fpco/stack-build](https://hub.docker.com/r/fpco/stack-build) or somethings, and copy and run the executable in Alpine
This is great to know, thank you! Next step is figuring out how do do this automatically for each new release.
Maybe this can help you. That one is prepared to be used into Musl environments so should do the trick. https://github.com/redneb/ghc-alt-libc
Have posted it.
So a better idea would be data Faithfulness = FullFaithful | Full | Faithful class ReversibleFunctor f where unmap :: (f a -&gt; f b) -&gt; a -&gt; b faithfulness :: Faithfulness
I know some don't agree with me on this, but I think almost everything should be defined in a namespace that reflects its package name. This has two main benefits: 1. It helps make it more clear where the package came from just by looking at the module name. This is important because of hackage's unique names guarantees. 2. Avoidance of arbitrary namespaces. What is `Control`? What is `Data`? Why do we have so many of these strange prefixes? They lead to longer module names (thus more typing), inconsistencies in labelling due to human error, and most of the time make barely any sense. IMO Distribution is one such strange namespace, which Cabal uses everywhere. I think it should be Cabal.*, not Distribution.*. (What _is_ Distribution?) Obviously there are packages where this doesn't make sense, such as in libraries that define data structures (since there is so much overlap in top-level structure).
yes, this works, thank you! A minimal dockerfile for setting up GHC 8.6.5 : FROM alpine ENV GHC_VERSION=8.6.5 ENV GHC_INSTALL_PATH=/opt/ghc RUN wget https://github.com/redneb/ghc-alt-libc/releases/download/ghc-${GHC_VERSION}- musl/ghc-${GHC_VERSION}-x86_64-unknown-linux-musl.tar.xz &amp;&amp; \ tar xf ghc-${GHC_VERSION}-x86_64-unknown-linux-musl.tar.xz RUN apk update &amp;&amp; \ apk add bash perl alpine-sdk WORKDIR ghc-${GHC_VERSION} RUN ./configure --prefix=${GHC_INSTALL_PATH} &amp;&amp; \ make install
A better idea would be to split them apart into separate typeclasses if you really need the idea with an appropriate inheritance relationship between them.
I was talking about a notation for juggling called [siteswaps](https://en.wikipedia.org/wiki/Siteswap) and how we can represent it in Haskell. We can use the REPL to explore the data and find new patterns to juggle. It's not a very complex topic from a Haskell point of view, but it was one of the first things I did with Haskell when I was learning, and I think it's kind of fun. The Haskell coding starts about half way through, and I put the code [here](https://gist.github.com/paf31/6901f5747753233c10666a8d0e949b7d) for reference.
Is there a reason you want to use something linear like an Array/Vector/List? When I built a PDP8 emulator I used a [Map](https://github.com/TomMD/PDP/blob/master/Types.hs#L69) and was satisfied with the performance. It won't beat a mutable vector performance-wise but is pleasant to work with.
could you provide a sample (pseudo code)? I'm having trouble seeing the difference right now (sleepy)
Will the different workshops be recorded and put up online?
I'm trying to build something like class SumRes r where sumOf :: Integer -&gt; r instance SumRes Integer where sumOf = id instance (Integral a, SumRes r) =&gt; SumRes (a -&gt; r) where sumOf x = sumOf . (x +) . toInteger as per https://stackoverflow.com/questions/3467279/how-to-create-a-polyvariadic-haskell-function, but modified so that I can call it like `sumOf 1 "2" 3`. I added the basic `instance SumRes String where sumOf = show`, but that doesn't really make sense, I need to go the other way, but reversing the arrows directly is unintuitive to me. Any ideas?
(Thanks for the notification /u/ephrion) I have a small Proof-Of-Concept repository showing how you can use `ghcup` to compile a version of GHC with `musl` support in Alpine and build a project with `stack` that can be statically linked. https://github.com/jkachmar/alpine-haskell-stack Let me know if this helps! I can probably automate the process of building these somewhere and pushing them up to DockerHub at some point if they’d be useful.
The talks, including the GHC track: definitely. The beginner/advanced tracks: hopefully, but we can't promise it yet.
And the documentation track? Same as the beginner/advanced tracks?
Is it possible to simulate reading from standard input using doctest? E.g. given this file $ cat test.hs `module Main where` `{-|` `&gt;&gt;&gt; getLine` `Hello&lt;Enter&gt;` `Hello` &amp;#x200B; `-}` `main = undefined` ... when I run $ doctest test.hs it hangs indefinitely.
The talk will be recorded, if it's just people writing docs I don't think it should be recorded
&gt; 286 multi-user desktop had Debian That seems unlikely. There's never been a Debian release that supported the 286. There was for some period of time an effort to make the Linux kernel support the 286, but it was never mainlined into the kernel, and certainly never packaged for Debian.
&gt; Haskell is the _only_ production-ready lazy language (Smalltalk weeps from retirement.)
Thank you for sharing this!
&gt; Avoidance of arbitrary namespaces. What is Control? What is Data? Why do we have so many of these strange prefixes? They lead to longer module names (thus more typing), inconsistencies in labelling due to human error, and most of the time make barely any sense. Totally agree that overly broad top-level prefixes like Control and Data are near useless. &gt; I think almost everything should be defined in a namespace that reflects its package name. I disagree, only because I see the package/project name as subject to marketing, aesthetic, flavorful whims, were I think the module names should be treated like function names, and be as information-dense and spin-free as possible. Spyder would be a fine name for a hypermedia system (web) for tuner programs for chipped vehicles. But, "Spyder" probably shouldn't be in the module names for anything (unless it was some sort of "module alias" for or variant of a "Roadster" module).
do you have any suggestion to new ppl on if they should use stack or cabal? I was going to use stack, but then i see cabal has all these new features, and then i saw someone told me to use ghcup etc... and getting back into it all I'm wondering which tools i should be using
My bad. I had SCO Xenix on the 286 and Debian later on a 12 pound Dell laptop.
It seems you want to convert every argument to an `Integer`. `Integral` does that, but it's really restricted to numeric types. So replace it with a custom class (`SumResIntegral` below). instance (SumResIntegral a, SumRes r) =&gt; SumRes (a -&gt; r) where sumOf x = sumOf . (x +) . toIntegerSR class SumResIntegral a where toIntegerSR :: a -&gt; Integer instance SumResIntegral String where toIntegerSR = read instance SumResIntegral Integer where toIntegerSR = id -- or an overlapping instance instance {-# OVERLAPPABLE #-} Integral a =&gt; SumResIntegral a where toIntegerSR = toInteger
I don't think this makes a usable library. This isn't a constructive notion for the most part. Injectivity/surjectivity isn't enough to actually _find_ the inverses. There is a difference between a monomorphism and a split monomorphism, where you can actually find the retraction. Similarly between an epimorphism and a split epimorphism, where you can find the section. The 'split' variants offer you the inverses. Knowing that every function `a -&gt; b` gives you a different `IO a -&gt; IO b` doesn't, for instance, give you any ability to go backwards, despite the fact that IO is faithful. `fmap` for this is injective, every arrow is taken to a distinct arrow. This is true, we never drop the arrow on the floor or mangle the choice of some of the `a`s or `b`s. Parametricity won't let you. Similarly, all the instances you'd be able to write for the 'constructively fully faithful' class that uses our existing Category/Functor instances would be isomorphic to `Identity`. Working with a more generalized Category/Functor notion takes you pretty deep. My old Hask code or something that Iceland Jack has posted by now will get you closer. From there you could write a 'constructively fully faithful' class that allows `Dict` as an instance. -- | Retractfmap will recover the function sent to fmap, but all other bets are off for other inputs. -- @ -- retractfmap . fmap = id -- retractfmap f . retractfmap g = retractfmap (f . g) -- retractfmap id = id -- @ class Functor f =&gt; SplitFaithfulFunctor f where retractfmap :: (f a -&gt; f b) -&gt; a -&gt; b instance SplitFaithfulFunctor Identity where retractfmap = coerce data Name a = Name String a deriving Functor -- | this successfully retracts an fmap, but made arbitrary decisions. It is a left inverse to fmap though! instance SplitFaithfulFunctor Name where retractfmap f a = case f (Name "garbage" a) of Name _ b -&gt; b -- | fmap . sectionfmap = id -- ... class Functor f =&gt; SplitFullFunctor f where sectionfmap :: (f a -&gt; f b) -&gt; a -&gt; b instance SplitFullFunctor Identity where sectionfmap = coerce -- | retractfmap = sectionfmap follows from the other laws. class (SplitFaithfulFunctor f, SplitFullFunctor f) =&gt; SplitFullyFaithfulFunctor f instance (SplitFaithfulFunctor f, SplitFullFunctor f) =&gt; SplitFullyFaithfulFunctor f Basically, this just doesn't do anything interesting for Haskell data types and the off the shelf Functor/Category classes.
Yes, this is a *very* common problem - I struggled with the same thing. As far as I can see, there's basically three options: * **stack** \- focuses on reproducible builds, which means that if you compile the same project twice you will get *exactly* the same results. I found `stack` to work better on Windows too, as it includes an integrated Linux environment, but possibly `cabal` has caught up in this regard by now. * **cabal+ghcup** \- `cabal` is Haskell's original dependency manager. By now it's roughly at feature parity with `stack`, so the choice is mostly a personal preference. The main difference is that `stack` focuses on reproducible builds, while `cabal` doesn't. However, `cabal` is compatible with `stack` so it's very easy to switch between them. `ghcup` is a small helper to assist with managing versions of the Haskell compiler; `stack` has its own system integrated, but `cabal` requires 'manual' management. * **cabal+nix** \- `nix` is a Linux package manager focusing on reproducible builds. Many Haskellers like using `nix` with `cabal` to get reproducible builds. However note that if you decide to do this you have to learn two tools (`nix` and `cabal`); also note that `nix` only works on Linux, so I can't use it since I'm on Windows. However, I've heard very good things about using these tools together. I think the only real way to decide between these options is to use them and see what helps you most. Download `stack`, download `cabal`, create projects with both and see how much you like them. If you end up staying with `cabal`, try using `ghcup` or (if you're on Linux) `nix` and see which one you like.
Thank you!! Very helpful! I went with cabal+ghcup since I last posted my post, ran into some install issues, but I'm good now. &amp;#x200B; That is a good point about the reproducible builds though and I have used stack to success on windows in the past, long ago I remember cabal being really bad experience on windows for me. &amp;#x200B; I know people in the community have preferences, but I really do wish they would come together and kind of summarize all these things just like you did for me here, for the sake of beginners! (maybe it exists I don't know?) &amp;#x200B; Right now I'm just trying to piece together some kind of dev environment with these tools and neovim to get something workable for myself, I'm taking parts of [this](https://mendo.zone/fun/neovim-setup-haskell/) (i owe this guy a beer, really nice writeup ) and trying to figure out what works best for me. &amp;#x200B; thanks!
I just noticed that laziness semantics (i.e. infinite lists) pose a problem for translation Haskell into FMC. Do you already have a trick in mind for dealing with laziness? I am currently looking up how laziness is implemented and how strictness can be added to lazy languages. Maybe the solution is to make everything strict. The abstract algorithm should still be optimal. That would deal with lazy algorithms, but I worry about infinite datastructures.
Hyped to see DataHaskell in the list! Curious about what will come out u/ocramz
Hi! I'm still reading over your post trying to soak everything in so I don't have a specific question or comment just yet, but I had to say **THANK YOU!!** right away for taking time to write this explanation out for me, it is very very much appreciated :)
Interesting. I wonder why you copied the ghcup script into your repository though. We don't break API frequently. Can just fetch it from `https://gitlab.haskell.org/haskell/ghcup/raw/master/ghcup`. Also consider contributing to https://gitlab.haskell.org/ghc/ghc/issues/14502
Could anyone ELI5 channels and why I would need them?
I wouldn't recommend Reflex. It uses a really complicated model of computation, and requires MonadFix (recursive do) to work. I personally found it too difficult for little gain (and tbh recommend much more something like elm/ps + react for stuff like web frontends). Also, getting it to compile/using GHCJS is extremely slow.
live 10 kms away but cannot attend :(
`fold` has `unfold` as the opposite operation, what's the opposite of `traverse`?
Is there a reason you use ghcid with nvim rather than hie for both?
Below is my step-by-step process for how the MonadState / StateT naturally arise as one focuses on the problem of dealing with state in a functional language (It's in PureScript, but the syntax is very similar to Haskell): https://github.com/JordanMartinez/purescript-jordans-reference/tree/latestRelease/21-Hello-World/08-Application-Structure/src/02-MTL/01-Implementing-a-Monad-Transformer
You're welcome! &gt; I know people in the community have preferences, but I really do wish they would come together and kind of summarize all these things just like you did for me here, for the sake of beginners! (maybe it exists I don't know?) It's fairly new still, but this is basically the aim of the (Aelve Guide)[https://guide.aelve.com/haskell].
Thank you, that looks right up my alley. I would certainly say this desire to understand arose naturally - I'm making a turn-based rpg in Scheme, and I was passing around both the **(player, enemy)** stats tuple, and also a random-number stream. It was getting cumbersome as extra arguments seemed to be getting tacked onto every function. The state monad seemed like **the** solution to the problem, almost too-good-to-be-true, in a way! I think I could get away with using it in Haskell right away, but I'd like to understand it from first-principles as it were, so I can implement it in any (functional) language that doesn't have it, if need be. Your process seems just the ticket. Cheers :)
I suppose what's confusing me about GameValue, is, don't we also need access to the Bool part of the state in order to decide whether to invert it (using not) or leave it the same? I mean, the initial value is itself a **(Bool, Int)**. Or, is that because **&gt;&gt;=** is taking care of that (which can "see/use" the **s**, just not the playGame function? Sorry if this seems silly, it probably is; I'm just struggling to get it, for some reason. Is it because we eventually return an **Int** at the **very** end (in the empty case) so we have to be able to "remove" it from the monad at that point is **a**?
Its dual is: cotraverse :: (Distributive g, Functor f) =&gt; (f a -&gt; b) -&gt; f (g a) -&gt; g b Here are some links for further info (I genuinely have no idea what they're useful for though): * [https://hackage.haskell.org/package/distributive](distributive package) * [https://www.reddit.com/r/haskell/comments/4cmjeg/a_law_for_distributive/](distributive laws)
IANACT (I am not a category theorist), but shuffling signature around: traverse :: (Applicative f, Traversable t) =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) ??? :: (Applicative t, Traversable f) =&gt; (f b -&gt; a) -&gt; f (t b) -&gt; t a -- Replacing type variable names: ??? :: (Applicative f, Traversable t) =&gt; (t a -&gt; b) -&gt; t (f a) -&gt; f b We get some sort of combinator that lifts context-reducing function to function working through another context. As you can see, constraints got swapped - that's because we're still "pushing" one context through another, just with their order reversed - we can implement it as: ??? f = fmap f . sequenceA And it behaves as expected: &gt; ??? (ord . snd) $ traverse ((,) "a" . chr) [1,2,3] [1,2,3] I would like to know if there's actually some real name in place of `???`...
The process to get here was a little convoluted. In my initial attempts to get it working I was applying patches to `ghcup` to override some linker directives, patch some of the GHC build files, and compile `cabal-install` from source. As the project evolved more of that got pared back to the point where it’s 1:1 with the project upstream. I’ll make an issue to fetch from the GitHub project, thanks for the reminder!
OK
(As I understand it) problem with \`cotraverse\` is that it will only work with \`g\`s that are isomorphic to \`Identity\` - I can't see a way of implementing \`distribute\` other than discarding context inside of \`f\` and creating one around it...
Yeah not sure, hopefully someone with more knowledge on the topic can explain... Most I can come up with is g being the function type **(-&gt;)** so you can pass for example an algebra and a list of functions: somePredicates = [odd, (&gt;2), (&lt;5)] cotraverse and somePredicates 3 True cotraverse and somePredicates 7 False cotraverse sum [(+1),(*2)] 5 16 But that can be also written in a myriad different ways...
[removed]
That's unfortunate. I still have exams on Friday.
&gt; do they want to share the same backend? I don't see why not.
&gt; Sorry if this seems silly, it probably is; I'm just struggling to get it, for some reason. Is it because we eventually return an **Int** (as **score**) at the ***very*** end (in the empty case) of the computation, so we have to be able to "extract" it from the monad at that point as **a**? That's bang on mate! Nice one. What you've said pretty much captures how everything works together. If you aren't quite tired of Haskelly stuff at the moment, then I've expanded on this below in reference to your first and second paragraph. &amp;#x200B; You're not wrong to be confused what `GameValue` should be, and it indicates that it may be helpful to visualise how monadic computations are chained together in the first place. As long as we know the input type `a` and the output type `b` It doesn't matter if the type we pick for `a` changes. &amp;#x200B; An example for `&gt;&gt;=`'ing a `State` monad with a monadic computation is below. Well, note how I've chosen `a` to be a `String` in the initial `State` monad on the left of `&gt;&gt;=`, and the monadic computation on the right can use this string as input as long as we end by using the type `GameValue` as `a`. I've satisfied this by outputting the length of the string given. This shows how `a` could change. example1 :: State GameState GameValue example1 = let a = "banana" in State $ (\s -&gt; (a, s)) &gt;&gt;= (\a' -&gt; state (\s -&gt; (len a', s)))) We can chain other arbitrary functions to this. For example, below, I've inserted a new function in the middle which just sets the value of `a` to `Nothing`, and changed the last monadic computation which then sets the value of `a` to `4`, (satisfying the type `GameValue`). Notice how what we use for `a` has differed between the types of `String`, `Maybe x`, and `GameValue.` example2 :: State GameState GameValue example1 = let a = "banana" in State $ (\s -&gt; (a, s)) &gt;&gt;= (\_ -&gt; state (\s -&gt; (Nothing , s)) &gt;&gt;= (\_ -&gt; state (\s -&gt; (4, s)) It might help to read the monad laws and think how monadic computations can compose and interact. m a &gt;&gt;= (a -&gt; m b) &gt;&gt;= (b -&gt; m b) &gt;&gt;= (b -&gt; m c)
There is no ready to use compilation for 13.12 anywhere. But even when you try to compile GHCJS and make a bundle for stack, there's a chance it [won't work](https://github.com/ghcjs/ghcjs/issues/745). I ended up using an ordinary stack.yaml for GHC, and then tweaking manually the generated \*.cabal and runing `cabal new-build --ghcjs`
Are there any `(SplitFaithfulFunctor f, SplitFullFunctor f)` where the implementations of `retractmap` and `sectionmap` are different?
Not mathematically possible. If you have both a left inverse and a right inverse you have an inverse. Inverses are unique.
So why two classes?
Nice! But your incremental development workflow with quick feed back could be better. Here is how it works with my setup (Neovim instead of Emacs, A Python script instead of Ghcid) https://youtu.be/iblExnkhy4s
Actual adoption by GHC/Idris/Agda will be a big hurdle, I think - that's why I was interested in what you would need to get to that point.
Slightly less minimal but this is what seems to be working for me to get all the above + stack. ``` FROM alpine AS base RUN apk update &amp;&amp; \ apk add bash perl alpine-sdk wget curl libc-dev xz ################################################################################ # Intermediate layer that assembles 'stack' tooling FROM base AS stack ENV STACK_VERSION=1.9.3 ENV STACK_SHA256="c9bf6d371b51de74f4bfd5b50965966ac57f75b0544aebb59ade22195d0b7543 stack-${STACK_VERSION}-linux-x86_64-static.tar.gz" RUN echo "Downloading stack" &amp;&amp;\ cd /tmp &amp;&amp;\ wget -P /tmp/ "https://github.com/commercialhaskell/stack/releases/download/v${STACK_VERSION}/stack-${STACK_VERSION}-linux-x86_64-static.tar.gz" &amp;&amp;\ if ! echo -n "${STACK_SHA256}" | sha256sum -c -; then \ echo "stack-${STACK_VERSION} checksum failed" &gt;&amp;2 &amp;&amp;\ exit 1 ;\ fi ;\ tar -xvzf /tmp/stack-${STACK_VERSION}-linux-x86_64-static.tar.gz &amp;&amp;\ cp -L /tmp/stack-${STACK_VERSION}-linux-x86_64-static/stack /usr/bin/stack &amp;&amp;\ rm /tmp/stack-${STACK_VERSION}-linux-x86_64-static.tar.gz &amp;&amp;\ rm -rf /tmp/stack-${STACK_VERSION}-linux-x86_64-static ################################################################################ FROM stack ENV GHC_VERSION=8.6.5 ENV GHC_INSTALL_PATH=/opt/ghc RUN wget https://github.com/redneb/ghc-alt-libc/releases/download/ghc-${GHC_VERSION}-musl/ghc-${GHC_VERSION}-x86_64-unknown-linux-musl.tar.xz &amp;&amp; \ tar xf ghc-${GHC_VERSION}-x86_64-unknown-linux-musl.tar.xz RUN apk update &amp;&amp; \ apk add bash perl alpine-sdk wget WORKDIR ghc-${GHC_VERSION} RUN ./configure --prefix=${GHC_INSTALL_PATH} &amp;&amp; \ make install RUN apk add --no-cache vim emacs curl git libc-dev xz coreutils automake python3 zlib-dev shadow gmp-dev ENV PATH=${GHC_INSTALL_PATH}/bin:$PATH COPY --from=stack /usr/bin/stack /usr/bin/stack RUN stack config set system-ghc --global true ```
Looking forward to it! We've just posted more info on our plans for the advanced track over at [https://www.well-typed.com/blog/2019/06/free-training-sessions-at-zurihac/](https://www.well-typed.com/blog/2019/06/free-training-sessions-at-zurihac/)
I'd like to focus on technical problems first. The actual adoption is a cultural problem mainly.
As an aside, have you looked at Vega/Vega-Lite, as it gives a vocabulary for declaring visualizations, using JSON, which includes interaction (but perhaps not the dynamics you are looking for)?
Agreed - I guess the question is what technical milestone you'd need to reach before it would make sense to push for it.
&gt; Does anyone know how to remove the brackets from above code? 3 : [1,2,3] ++ [4, 5] Here you go.
This is wonderful, I'm hoping to attend both!
It looks like `Reflex` is mainly intended for web frontends? I think I wan't to use SDL so I'm going to try out `Yampa` and `Reactive-Banana`. Thanks!
``` let tail = [1,2 3] ++ [4, 5] in 3 : tail ```
Because there are types that are _not_ constructively full, like the `Name` example. You could construct a Cofunctor superclass above SplitFullFunctor and SplitFaithfulFunctor to give the operation. But users should be able to constrain the code by using the stronger constraint. e.g. having a class Monoid m =&gt; CommutativeMonoid m is useful even though there are no extra operations provided. Because now you can write combinators that can assume commutativity, and not have to just trust that the user will never call them with a non-commutative monoid.
Yep, they are associative :). Actually my point is I try to use (++) or (:) with $ on my code. e.g. ++ $ (...) when I combine them, I got compiler error.
Converting the prefix to an operator section works, but just shuffles the brackets around. (3 :) $ [1, 2, 3] &lt;&gt; [4, 5]
`do` can be used as the ultimate `()` removal tool. 3 * do 4 + 2 3 : do [1,2,3] ++ [4,5] However, in this case, the fixity works out so you don't even need the parens. 3:[1,2,3] ++ [4,5] has the current meaning. I use the `do` trick more and more in code for things like what p = Foo &lt;$&gt; do fromIntegral &lt;$&gt; foo p &lt;*&gt; do fromIntegral &lt;$&gt; bar p &lt;*&gt; baz p &lt;*&gt; quux p or to handle things like what = do result &lt;- some previous computation result &lt;$ do for_ xs $ \x -&gt; some complicated processing The only problem with it is having to tell `hlint` to screw off each time.
 (3:) $ [1,2,3] ++ [4,5] directly provides what you asked for, but see my other reply above.
You may want to start with this: https://wiki.haskell.org/Calling_Haskell_from_C
awesome:) I never though you can use **do** for that.
This is more like the set-up I have using [Intero](https://haskell-lang.org/intero), which basically uses `stack` in the backgroud to incrementally compile and add markers into the emacs buffer.
&gt;3 \* do 4 + 2 -- note the result type doesn't even have to be a monad. Why is that allowed? What does this expression desugar to?
I always wondered whether it'd be too awkward if I used `do` like that, now I have a reference to back it up. What do you think about `ArgumentDo` + this trick?
`ArgumentDo` will make it just that much more applicable.
3 * (4 + 2) `do` doesn't force the type of the right hand expression to be anything in particular. (It used to, but I think I managed to get SPJ to fix that around 6.12 or 7.0)
yeah right
`Distributive` is exactly equivalent to `Representable`, so the real question is what `Representable` does and is useful for. The idea is that certain data types can be represented as a function from a given type to the element type. For instance, infinite streams (`Stream a`) can be represented as functions from their indices to their elements (`Int -&gt; a`.) Sized vectors (`Vector n a`) can be represented as functions from their bounded indices to their elements (`Fin n -&gt; a`). And to connect it back to `Identity` (which is essentially containers with exactly 1 element): `Identity` can be represented as functions from unit to the element (`() -&gt; a`). Finally, functions (`r -&gt; a`) are trivially equivalent to themselves (`r -&gt; a`). One reason that this could be useful is that it allows containers of stable sizes (e.g. infinite or bounded at compile-time) to have a common representation (i.e. in terms of functions.)
In Ale, you can set it up to load hie for you. i don't use hie because it uses too much memory.
is that something that others can reproduce? Are you the author of the python script? Is it publicly available? &amp;#x200B; I used hdevtools, as it integrates with syntastic, but it's not maintained and quite a bit flaky. I'm looking for replacements. Atm I just run stack test --file-watch similar to what's demonstrated here... &amp;#x200B; PS. for reformatting brittany rocks
Keep in mind that GHCjs support is essentially deprecated as of Stack 2.0.
Okay! Made a few adjustments based on your comments and that thread: - I’m now downloading ghcup from gitlab based on the release tag and verifying its based on the SHA256 posted on the release page - I’ve incorporated some of terrorjack’s GHC build flags to the config I’ve got for both build types
What is the Haskell equivalent of Rust's `rustup doc --std` and `cargo doc --open`? These open up a web browser showing offline documentation for the standard library, and for your project dependencies, respectively. It's very useful when you need to read the documentation while having no connection.
The fun doesn't stop there! {-# language BlockArguments #-} module Main where main :: IO () main = print do (++) do "Hello, " do "World!"
&gt;The only problem with it is having to tell hlint to screw off each time. This is actually a bug - the `do` *isn't* unnecessary. We should report this as such and see if it can get fixed.
That's very nice, thanks for the link. On a quick look this seems like just the sort of design that I'd want to enable. They've defined a data driven interface to their visualization library. It looks like they also defined some objects in their specification for dynamic interactions, but this is a bit different than what I had in mind. It seems like their service takes a specification/data object as a single input to a visualization function i.e: `vegaViz :: Spec -&gt; IO ()`. They do allow dynamics, for example, they have a signal for detecting on mouseover do something, but the specification doesn't change. I had a frp type idea in mind, enabling `myViz :: Spec -&gt; Event t (DeltaOf Spec) -&gt; IO Spec`. So, at any time you could disabling/reinabling that mouseover effect. Does this make sense? Anyway, its a beautiful lib, vega.
I don't think there is anything wrong with using a db if you want persistence and query interface. If you just want some in memory state a IORef/TVar/MVar is gonna b simpler. &gt; but I felt that I was breaking the rules A lot of Haskell programs have an crunchy mutable state outer layer covering a gooey pure inner nougat so your probably not breaking any rules.
`(:) 3 $ [1,2,3] ++ [4,5]` Apply the cons operator (`:`) as a normal function rather than an infix by wrapping it in parentheses and putting it first. Then you can keep `$`.
Yeah - I think this is what I meant by the "this is not the dynamics you are looking for" comment. I should ask around to see if they have plans for something more-like what you are after.
amy vim integration?
what the fuck is going on
I'm guessing you're gonna be one of the lucky 100 to be reading this blog post today for the first time: https://aphyr.com/posts/342-typing-the-technical-interview
Relational databases are awesome for exactly this sort of thing.
Truly the goal of dependent types. The actual [code](https://gist.github.com/i-am-tom/034acf5eec02d9318d6b67a6316d6e98) which achieves it is incredibly concise and readable! How close is the extension to being finalized/included in a release?
christ
Having read that, I find myself questioning if I even know anything about Haskell at all.
Mine: https://meinwords.wordpress.com/2019/04/19/my-haskell-setup-2019/ It is OS, GHC version, and editor agnostic.
Bicontravariant is used in profunctor encoding of some optic kinds (e.g. getter, affine fold, fold).
It reports the code with `()`'s included in the modified splice, so it isn't _wrong_ per se. It is just ignoring stylistic externalities.
&gt; “You never… you never wrote an actual value. You… do realize that the type system is meant to constrain values, right?” &gt; “No,” you inform him, matter-of-factly. “No, that doesn’t sound right.”
What was that quote again? Ah, here it is &gt; Any sufficiently advanced Haskell is indistinguishable from witchcraft.
Option 5. Put `size` in a superclass that only has one type variable.
Burn the witch!
I prefer `3 * (4 + 2)`. However, I'm looking forward to trying stuff like `what`.
You could try ```haskell (:) 3 $ [1, 2, 3] ++ [4, 5] ``` or ```haskell (3 :) $ [1, 2, 3] ++ [4, 5] ``` but I suppose that just moves the brackets around.
&gt;is that something that others can reproduce? Are you the author of the python script? Yes. It is available at https://github.com/sras/repltalk. If you face any issues while trying it, please let me know. &gt;PS. for reformatting brittany rocks I do have HIndent setup. But something in that file is tripping it up.
What the fuck
... but why? Stupid question, I know. Because you can.
I'm curled up. Crying. Is this what the masters of lisp have experienced before me? Don't be false epiphany. It is bliss, pure beauty.
The fizzbuzz itself is a bit of a joke of course, but it serves to show interesting new features. Type families are a bit like functions at the type level. But they are also weirdly different from regular functions, for example they can't be higher-order (take another type family as parameter) which is the cause of much boilerplate and workarounds when doing type-level stuff. There is an incoming extension that makes type families work a bit more like functions in that regard, greatly simplifying some things. The type-level fizzbuzz is a neat example.
Thanks! Is it called the same though?
That was beautifull
Yes - [http://oleg.fi/gists/posts/2017-04-18-glassery.html#t:Bicontravariant](http://oleg.fi/gists/posts/2017-04-18-glassery.html#t:Bicontravariant)
Forgive me, Padre
I feel like I've had three big epiphanies since starting programming: - Lisp - Type-level programming - The actor model I can't wait for the next one!
There is [`vcache`](http://hackage.haskell.org/package/vcache-0.2.6/docs/Database-VCache-VRef.html#t:VRef) which bends the rules so you don't have to break them.
Try building a non trivial project in rust, big enough where you start thinking about architecture, preferably fully concurent (rust shines in that space). Make the architecture, and you'll learn fun things about life times.
onsite, dang
thanks again i'll take a look!
I don't really think of Haskell as something that requires pure code, but something that is pure by default and therefore you can be explicit about what state you are using. Re: using a database, if it makes sense, do it. One of the great things about an app with state in a db is you can query the DB, which really, really helps with debugging.
I look forward to stories of places where people used this marvellous set of techniques on something other than textbook puzzles. :D
I tried to `wget` the index file right now, as described in StackOverflow -answer. It seems to work here. Maybe there is some CDN weirdness, if it happens somewhere still.
It does indeed seem to be resolved now. Thanks for the issue link!
 curry :: ((a, b) -&gt; c) -&gt; (a -&gt; b -&gt; c) uncurry :: (x -&gt; y -&gt; z) -&gt; ((x, y) -&gt; z) it's all a matter of parentheses! i recommend working through it yourself, but here are the steps. first, move the parentheses around to make `curry` fit the `x -&gt; y -&gt; z` template: curry :: ((a, b) -&gt; c) -&gt; a -&gt; (b -&gt; c) -- ----- x ----- y -- z --- this leads us to we substituting `uncurry`'s type variables like this: x ~ (a, b) -&gt; c y ~ a z ~ b -&gt; c so finally: uncurry curry :: (x, y) -&gt; z ~ (((a, b) -&gt; c), a) -&gt; (b -&gt; c) -- substitute ~ ((a, b) -&gt; c, a) -&gt; b -&gt; c -- remove redundant parentheses which is exactly the type ghci reports.
Write out the types with fresh type variables and full parentheses: curry :: ((a, b) -&gt; c) -&gt; (a -&gt; (b -&gt; c)) uncurry :: (x -&gt; (y -&gt; z)) -&gt; ((x, y) -&gt; z) When we have an application `f x`, where `f :: p -&gt; q` and `x :: p`, `f x :: q`. So in `uncurry curry`, the whole expression has the type of the *result* of `uncurry`: uncurry curry :: (x, y) -&gt; z Then we match up the type of the parameter of `uncurry`, `x -&gt; (y -&gt; z)`, with the type of its argument `curry` (where `~` denotes type equality): x -&gt; (y -&gt; z) ~ ((a, b) -&gt; c) -&gt; (a -&gt; (b -&gt; c)) x ~ ((a, b) -&gt; c) y -&gt; z ~ a -&gt; (b -&gt; c) y ~ a z ~ b -&gt; c Finally we can substitute these types into the `(x, y) -&gt; z` from earlier, giving the expected result: uncurry curry :: ((a, b) -&gt; c, a) -&gt; b -&gt; c
\`uncurry\` takes \`a -&gt; b -&gt; c\` and turns it into \`(a, b) -&gt; c\`. \`curry\` takes \`(x,y) -&gt; z\` and turns it into \`x -&gt; y -&gt; z\`. Now in \`uncurry curry\` we have \`a \~ ((x, y) -&gt; z)\` and \`b \~ x\`. Why? Because we view \`curry\` as function of two inputs returning a function \`((x, y) -&gt; z) -&gt; x -&gt; (y -&gt; z)\`. So we get \`(((x, y) -&gt; z), x) -&gt; (y -&gt; z)\`.
\+1 for the mentioning the pure inner nougat. I feel that my programs sometimes have the same structure
Thanks A LOT guys. I understand now!
Did you mean `uncurry . curry` by any chance?
Is the `(~&gt;)` type defined somewhere? I don't quite get where it comes from.
https://www.schoolofhaskell.com/user/adinapoli/the-pragmatic-haskeller
This looks really handy, thanks!
!remindme 9h
I will be messaging you on [**2019-06-09 08:37:20 UTC**](http://www.wolframalpha.com/input/?i=2019-06-09 08:37:20 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/bycoj8/hsp_a_haskell_command_line_text_stream_processor/eqgimir/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/bycoj8/hsp_a_haskell_command_line_text_stream_processor/eqgimir/]%0A%0ARemindMe! 9h) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! eqgirjk) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I'm pretty sure it's part of `-XUnsaturatedTypeFamilies`. The extension is described in [this paper](https://www.imperial.ac.uk/media/imperial-college/faculty-of-engineering/computing/public/1718-ug-projects/Csongor-Kiss-Higher-order-type-level-programming-in-Haskell.pdf) but I do not see anything in the GHC repo about its development status.
What are it's goals or differences as compared to [hawk](https://github.com/gelisam/hawk)?
I realise you already have several good answers, but I have a slightly different method which may help as well. Firstly, look at the type of `uncurry`: `uncurry :: (a -&gt; b -&gt; c) -&gt; ((a, b) -&gt; c)`. So it basically 'groups' the first two parameters of its input into a tuple. So when you apply `uncurry` to `curry :: ((a, b) -&gt; c) -&gt; a -&gt; b -&gt; c`, you're just grouping the first two parameters: ((a, b) -&gt; c) -&gt; a -&gt; b -&gt; c \\\\\\\\\\\\\\//// (((a, b) -&gt; c), a) -&gt; b -&gt; c
Looks amazing! &amp;#x200B; Quick question: how does this compare to [`hawk`](https://github.com/gelisam/hawk)?
Unfortunately this doesn't really work as well as in other languages. You may know Java, and you want to learn Ruby or JavaScript. So you go through an intro tutorial to the language and start writing a project. This works well because Java and Ruby/JavaScript are actually pretty similar in a lot of ways. The things you know in java may not be idiomatic Ruby, but they'll work OK. You can pretty much write Java in JavaScript and learn the differences as you go along. Haskell is so sufficiently different that you'll be very frustrated trying to do this. It requires a totally new perspective and a very different amount of stuff to learn. I wouldn't toss a new programmer into the [Rails Tutorial](https://www.railstutorial.org/), even though I had great success learning Ruby and Rails with it, because it assumes too much knowledge for computers and programming.