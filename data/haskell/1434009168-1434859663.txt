I always aim for my Haskell code to generate utility!
Have you tested with many concurrent readers? The main reason to avoid `TVar` in practice is the fact that they suffer from thundering herd issues, whereas `MVar`'s enforce fairness and a more efficient wakeup.
[**@mxcl**](https://twitter.com/mxcl/) &gt; [2015-06-10 17:07 UTC](https://twitter.com/mxcl/status/608682016205344768) &gt; Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Good point, it was in the context of writing evaluator (scheme in haskell) and such. But you're right I should try to use it for an actual application.
Eh, maybe I'll have time to write a tiny C compiler in Haskell one day, but I'll continue to stay away from C++ if I can. I can only imagine how horrible it would be to write a parser for it, considering that there are some weird features in the syntax of the language that only exist to make it parseable in the first place (like the required space after nested template `&lt;..&gt;` brackets). Actually this just made me curious, and I found [this](http://www.computing.surrey.ac.uk/research/dsrg/fog/FogThesis.pdf) PhD thesis (via [StackOverflow](http://stackoverflow.com/a/243447)). On page 147 it states &gt; The C++ grammar is ambiguous, context-dependent, and potentially requires infinite lookahead to resolve some ambiguities &gt; int(x), y, *const z; // int x; int y; int *const z; &gt; Is a comma-separated list of declarations in which the first is redundantly &gt; parenthesised, whereas changing the final list element: &gt; int(x), y, new int; // ((int(x)), (y), (new int)); &gt; gives a list of expressions, the first two of which are redundant, and the third &gt; causes a memory leak. *shivers*... C++ is the stuff my nightmares are made of.
&gt; C is an M1 Garand standard issue rifle, old but reliable. C is reliable??? I wonder what that guy's favourite language is, because I couldn't possibly tell from that post. 
Right now I don't think I'm good enough for these roles, but I think I can get there. Do you have any advice for how one might develop oneself over a few years so I might be ready in future? For context what I'm already doing to develop myself is: * I'm a senior developer so growing in that role (though I'm working with OO c#); and * doing a maths degree with Open University in my spare time to improve analytical thinking.
NOBODY expects the...
I'm a bit confused... you don't know for sure that Hackage glitched for that Travis job, and yet you assume this was the reason, and jump to the conclusion that cabal's package downloading algorithm or alternatively the default mirror needs to change? What if this was simply a glitch on Travis' end? IIRC Travis had to introduce the `travis_retry` helper to workaround network connectivity issues [they were experiencing](http://blog.travis-ci.com/2013-05-20-network-timeouts-build-retries/).
https://regmaster4.com/2015conf/ICFP15/register.php You can register today.
My understanding is that there's a divergence of direction between the cabal team and the stackage team.
That's how straight jackets work, right?
Kind of related: On my computer, GHCi sometimes refuses to start and segfaults instead. When I install a package that uses TH, this can happen too, but without any warning. It just says "failed to install". From the output I can see if the compiler is running TH, and if it fails in this scenario, I simply try to install the package again. Yesterday I installed haskelm, and it took almost 10 attemts, but then worked. 
I too would be interested were the job in Glasgow. 
&gt; I think you are confused about what we mean by curation. What you are describing is the normal semantic versioning and dependency specification process that goes on with most software today. It is actually the other way around. I am not describing semantic versioning, I am describing the PVP. Semantic versioning says nothing about the specification of version bounds on dependencies, but the PVP does. &gt; And that of course is a good thing that everyone needs to keep doing. But the fact of the matter is that stackage advocates tend to not it. They frequently violate the PVP by not specifying upper bounds on their dependencies. In fact, I've actually talked to users who told me that they thought they didn't have to specify version bounds because they were using stackage! &gt; Curation goes beyond that and tests that certain packages work together beyond just the version bounds (for example by building and running the test suites of all versioned packages). This can catch many things that version bounds cannot This distinction usually doesn't matter in practice. In five years of professional Haskell development I can count on one hand the number of times running tests instead of just checking whether something builds has been an issue with package dependencies from hackage. But I've been been burned countless times by dependencies with missing version bounds. Without stackage, test suite failures would still most likely be caught in the normal process of most developers' normal release testing.
2 or 3 years of solid Haskell work, or equivalent in open source, is basically needed. C# won't be much use really. Have to show ability in functional design - we avoid simply typed, mutable code almost entirely.
Perfect thanks. I've done a personal site with Haskell/Yesod and some other personal projects already. I'm going to look for some open source projects needing contributions as a next step. You may hear from me in a few years when I think I'm at the standard you're expecting for Haskell. I love using it so I'm pleased it's beginning to look like a career option.
So, does anyone know where I can find a reference for the `stack.yaml` file? I need to add package dependencies there, somehow. Would be really nice if FPComplete tools honoured cabal files, though. I had the same issue on the online IDE, though at least the IDE has sufficient documentation describing how to add extra dependencies.
Did you experience those downtimes even after Hackage was placed behind the http://fastly.com CDN? 
Oh. Yes OK. I just kind of assumed that was happening. :)
thanks :)
O_O I... I think I'm gonna go home and rethink my life.
&gt; It's funny how people using dynamic type systems seem to think they are superstar programmers who can handle having the system in their head at once I have never, ever seen anyone express that view. People prefer dynamically typed languages for a wide range of reasons, such as fast prototyping, certain libraries (like RoR or matplotlib or ggplot), tight feedback cycles (compiling a yesod or snap application takes a while) or they simply don't think that static type systems bring enough benefits. That doesn't automatically make them all less aware of their own abilities or worse programmers or people who haven't seen the light. &gt;static type systems are the ones to admit that they really... suck at programming and need all the assistance they can get to get it right. This comment just sounds like a humble brag.
Yes indeed. I remember, many times, staring at Yet-Another-Incomprehensible-GHC-Error, willing it to just run the damn program, even if it does have a type error in it. Over time, though, several things happen. One is that the errors start to make more sense (my best tip is always to look at the exact location where the error is reported). And you just get more experienced and quicker at finding and fixing type errors. So getting the code past the compiler becomes much less of a burden. Then, more and more times you'll experience those wonderful moments where you finally get the code to compile... and it works correctly first time!
&gt; there's probably more than one type of programmer who uses dynamically typed languages. I'm going to go out on a limb and say that that is a very safe assumption. ;)
Why not just improve the error message and send a pull request without the fanfare?
That is weird! atomicModifyIORef should really be not much more expensive than a single `LOCK`-based CAS (whose main cost comes from incurring a full memory barrier like the `MFENCE` instruction, on Intel). A `TVar` would also need to synchronize *at least once*. So it should also pay for at least a single memory barrier. I guess `atomicModifyIORef` is doing something really expensive in addition to the CAS.
Newtype wrappers: newtype FirstName = FirstName String newtype LastName = LastName String createUser :: FirstName -&gt; LastName -&gt; …
The problem is you have no distinction in your types. You have a few options. One would be to combine fields into a record and then pass that record as arguments. This is basically like working with named parameters: {-# LANGUAGE RecordWildCards #-} data Args = Args { firstName, lastName, aboutMe :: String } createUser :: Args -&gt; User createUser Args{..} = ... I use `-XRecordWildCards` so you don't have to unpack all the arguments. Check the documentation (or my [blog](http://ocharles.org.uk/blog) if that's new to you). The other option is you `newtype` each argument type: newtype FirstName = FirstName String newtype LastName = LastName String createUser :: FirstName -&gt; LastName -&gt; User createUser (FirstName firstName) (LastName lastName) = ... This is pretty tedious with all the unpacking, but is very explicit about what is what (and that the set of first names is different to the set of last names).
Hi. :-) In persistent you can do newtype FirstName = FirstName String deriving (PersistField) instance PersistFieldSql FirstName where sqlType = sqlType . liftM unFirstName If you have like 5 of these, it's not a big deal. If you have dozens, then some TH to automate it may be in order. It's quite sane but it requires familiarity with the TH APIs.
Doesn't the first suggestion just push the problem down a level? createUser $ Args "Engage!" "Jean-Luc" "Picard"
For the front-end, I recommend [GHCJS](https://github.com/ghcjs/ghcjs), [reflex](https://github.com/ryantrinkle/reflex) and [reflex-dom](https://github.com/ryantrinkle/reflex-dom), if you need interactivity. :) Otherwise, just use something like ~~yaourt~~ yesod, or maybe scotty with blaze-html. EDIT: I'm dumb
In Haskell use of newtypes in encouraged and newtypes are guaranteed to have zero runtime impact and to involve no runtime instructions whatsoever (zero cost coercion). In other words, performance wise `createUser :: FirstName -&gt; LastName -&gt; AboutMe` is identical to `createUser :: String -&gt; String -&gt; String`
Only if you choose to use the short and risky way: initCFG = Configuration "nobody" "nowhere" "nowhere" False False "/" "/" 0 The verbose but safe way: initCFG' = Configuration { username = "nobody" , localHost = "nowhere" , remoteHost = "nowhere" , isguest = False , issuperuser = False , currentdir = "/" , homedir = "/" , timeConnected = 0 } source: http://en.wikibooks.org/wiki/Haskell/More_on_datatypes
Curious if you've used [Hack](http://hacklang.org/) and how that feels compared to Haskell.
That's great news, thank you!
for now the engineers on this team are stuck working in the islands of manhattan and brooklyn. some brave mad souls commute from new jersey. I dont think theres any good transsonic commuter options at the moment
That's a lot more modern than I was thinking! Perhaps a little bleeding edge for OP?
Haskeleton does support adding new files through the [`Haskeleton.hs` script](https://github.com/tfausak/haskeleton/blob/master/package-name/Haskeleton.hs.template).
Then ~~yaourt~~ YESOD. EDIT: I'm dumb
Beware that the zero cost coercion sometimes requires some refactoring/obfuscation. https://wiki.haskell.org/GHC/Coercible For example, you might need to use 'coerce' where you would might normally use 'fmap'. 
&gt; When starting out they allow the developer to score quick victories by putting together simple programs very quickly, even non-programmers can do it, this gives people the confidence to continue on to harder stuff. I would argue that they allow people to perceive incomplete programs as victories. They test the happy path and are unaware of the many problems lurking in the rarer and exceptional conditions that can happen during the execution of their program. Static languages force you to confront these situations as well which makes it seem harder but in the end you end up with a program that handles all those cases.
Do you mean Yesod? I couldn't find a yaourt on hackage.
Hurr, yes, yesod. Yaourt is my layer on top of the pacman package manager. XD
Why not? -- hide data constructor data CreateUserRequest = CreateUserRequestCtor { curFirstName :: String, curLastName :: String, curAboutMe :: String } -- expose this mkCreateUserRequest :: CreateUserRequest mkCreateUserRequest = CreateUserRequestCtor "" "" "" -- your function, client needs to use mkCreateUserRequest with field names createUser :: CreateUserRequest -&gt; Something createUser request = fail where firstName = curFirstName request lastName = curLastName request aboutMe = curAboutMe request 
It looks like templating facilities of Haskeleton and Hi are not so rich. I used mustache templates since it is possible to make almost any template with it.
[See Haskell Wiki about web frameworks.](https://wiki.haskell.org/Web/Frameworks) The web frameworks have different entry levels. E.g. Yesod is considered a complicated monster framework - can everything well, but you need time to learn how to use it. 
I don't have sufficiently coherent thoughts at the moment to contribute, but just to say it's a cool little example - I've made various toy languages which try to be more like the first than the second. [This one](https://github.com/Duta/stuttering-lang) happens to be on GitHub, though it's more of a joke language
Side note, but I think your function signature is missing a return value. Your function takes 3 arguments (`firstName`, `lastName` and `aboutMe`), so you should have an extra `-&gt; ReturnTypeHere` added to the function.
They both have their problems. * Neither explains what sort of errors entering a to-do item can give. In fact, error checking there was surprising to me, because it looks like you're just asking for strings. * Does checking the errors terminate execution? It looks like it just continues running. * Your second example looks like it asks for a single to-do, but then operates on a collection of them. * Why are you mentioning a specific database program in your second example? * What does "skip" mean in this context? It looks like it's some sort of print statement, but I'm used to "skip" meaning "do nothing". * I admit I'm totally unaware of notational conventions in scenario-based testing, but I would find something more mathematical looking *much* more readable than when/then with sort-of-English explanations. Something like `newToDo.completed is true ==&gt; newToDo.dueDate is ""` If I *had* to pick one of them, I'd go for the second, but not be happy about my choice. Personally when I write pseudocode it looks like Python, just with more built-in functions and data structures.
I recently tried Atom and I was quite surprised. It all just worked. The support for Haskell is basic but it has huge potential.
This is a really tempting opportunity! It's great to see /u/cartazio involved in pulling a team together.
you know my email if you wanna chat :) all the madness i was dealing with a few months ago wont happen to new folks who join.
Looking over it, I would spontaneously say that the second one is more readable, since the bracketing gives a bit more structure. However, neither of these exaples has any syntax highlighting which I feel can also provide this structure. Since modern editors basically all have syntax highlighting, this makes the extra structure imposed by the brackets slightly redundant. (This is also the reason why I hate reading haskell without syntax highlighting, it hase a very terse syntax)
Yes, that is what I meant.
How does Clojure solve it cleanly?
Thanks!
&gt; like the required space after nested template &lt;..&gt; brackets This has been fixed in C++11. You should look at C++ again, now that C++11 and C++14 are here. While I won't suggest writing a parser for it, the language has gotten a lot easier to use for everyday programming tasks*. \* What I mean by this is unless you're contributing to the [boost](http://boost.org) libraries, the vast majority of C++'s complexity doesn't tend to be a problem.
Num is ugly, but as far as I know we don't know a better solution. There is always some important type that breaks the laws should we go for a principled approach (floats typically), and fragmenting the classes into a large hierarchy is not really enjoyable to work with either.
&gt; Maybe you could provide a convert from Hi to turl Today I have added the missing feature that prevented me from converting the Hi templates. Now I'm working on importing Hi templates to trurl.
A close friend of mine attended the University. It's a very highly regarded university in India.
ghcid totally defeats the main feature of hack, which is quick type checking.
An editor lets you edit a file. If you get a really good one it can give you things like type popovers and compile-as-I-write and so on. And IDE, in contrast, manages a system. It does everything the editor does but it also does those things for the system as well. When working with Haskell in EclipseFP I didn't just get to have the code I was working on as I wrote, it was building the whole system at all times. If I make a change to some dependancy, all the files in my system that got broke by that change light up. I also have integrated access to unit tests, performance testing and various other necessary parts of software development. I get all the tools to manage the whole project lifecycle right in one place. I don't have to break focus of leaving my editor and typing a bunch of commands, it's just a key sequence (or clicking on a menu until you learn the shortcuts). And the other thing to remember is that Eclipse is a pretty awful IDE. It was the best we had for Haskell, but if you ever use Visual Studio+Resharper to work on a large C# project it will be very clear how much time a powerful IDE can save.
atomicModifyIORef has a retry + computation loop where it computes the update, then tries to CAS, and tries again. So if the update function takes any time at all, that can dominate, OR there could be cacheline ping ponging if theres super high contention and you have enough cores. I'll maybe try to look at the code on this thread this weekend when i have some time.
What a bleak imagination. :) Consider getting an internship, you could definitely gain some great experience and learn a lot too. It's usually interns that I see using print statements to debug professional software, or bad hires... https://plugins.jetbrains.com/oldimg/screenshots/org.intellij.clojure_2566.png 
You could try upgrading your Xcode to the latest, that might be the issue. FWIW I don't have these sorts of problems on OS X 10.10 with GHC 7.10.1.
Upgrading Xcode to the latest requires upgrading to Yosemite, and at this time, I can't risk the move. In a month, perhaps. Thanks for the suggestion though.
Why not using Phantom Types ? e.g. [Using Phantom Types for Extra Safety](http://blog.jakubarnold.cz/2014/07/08/using-phantom-types-for-extra-safety.html).
I thought we were moving some stuff to DWARF? Are you saying that we aren't moving enough to it?
I updated the code to check with different levels of concurrency.
Ah well, it was worth a shot. Thanks for checking and good luck with the recruitment. Sounds like really interesting work so I expect you'll be swamped with candidates; after all New York isn't such a bad place, even if it's not quite Glasgow ;-)
Sometimes just writing the same thing twice is the easiest solution: bid &lt;- liftIO randomIO now &lt;- liftIO getCurrentTime 
I'll attempt to implement what tomejaguar suggested: **Edit: I added some comments explaining what I'm doing** **Edit 2: added 'not', thx @mstksg** knightJump s a b = -- since the function find returns a Maybe we need to -- look at whether we got the right result maybe [] -- this is the default. We return [] if there were no plausible jumps pJumpUncurried -- this is the function we apply to the position tuple if we got one result where -- first I make a partial from the plausibleJump function that takes -- a tuple with the position as the last argument instead of two separate arguments pJumpUncurried = uncurry (plausibleJump s a b) -- all possble combinations with 1 or -1 in the first tuple position -- and 2 or -2 in the second rightPos = [(x,y) | x &lt;- [1,-1], y &lt;- [2,-2]] -- and now the reverse of those with 2 or -2 in the first and 1 or -1 in the second leftPos = map swap rightPos -- both together positions = rightPos ++ leftPos -- find the first one for which applying the plausibleJump function -- does not return an empty list -- this returns a Maybe a -- the function 'null' is better than /= [] and does the same thing result = find (not . null . pJumpUncurried) positions
so I guess we need people to step up and help :)
I would probably have `result` be result = find (not . null . pJumpUncurried) positions using `null` is probably nicer than `(== [])` because it doesn't have an Eq constraint... not that that's a huge deal here, but it's just a good habit :) or just probably even better, to get rid of boolean blindness, result = listToMaybe . dropWhile null . map pJumpUncurried $ positions which saves the recalculation of pJumpUncurried later in the final answer. And avoiding boolean blindness when you can is nice anyways :) 
Cool. I would probably `map pJumpUncurried` before the `find` which avoids needing to apply it again in the `maybe`. Then you can just use `fromMaybe` (or a `case` might be clearer). I would also use `not . null` instead of `(/= [])`. I'd also probably put type sigs on the definitions in the `where` clause. 
I'm not familiar with the problem, but would this work? knightJump s a b = take 1 $ uncurry (plausibleJump s a b) =&lt;&lt; positions where positions = -- as above It maps the plausible jump function to all the positions, concatenates the result and picks the first one (or empty if nothing was found).
You have a ton of redundancy in your code. Try to eliminate repeating words by capturing the varying parts into a data structure (container, e.g. a list) and use operations on that data structure (e.g. `map`, `filter`, `fold`).
Evariste looking well, considering. :D
+1 (with apologies for the side effect -:)
I like this transformation the most because it's clear where everything in the original code went. The other answers seem a little code-golfy (sorry).
Arrays for days, mang
More like a roll cage: "we'll keep you safe when everything disintegrates around you"
Is there any documentation about that somewhere (hi or haskeleton) ?
Just use trurl, I'm always available for help with it! :-) BTW, today or tomorrow I'm going to import Hi templates to trurl repository.
Try Atom with ide-haskell package. It has been making some very rapid advancements lately and is really decent to use.
Using laziness you can just build a list of every possibilities and take the first "interesting" one. import Data.Maybe kightJump s a b = head (filter (/=[])) [ plausibleJump s a b (-1) 2 , plausibleJump s a b 1 1 , plausibleJump s a b 2 1 ... etc ... ]) ++ [[]]] Of course, in your particular, the full list can dryied-up and be written in more conscise way. 
Does it have an Haskell plugin? Is it easy to install?
I have tried to learn how to use emacs several times, but I did not succeed. Is there a good way to learn emacs usage?
This may help you: https://wiki.haskell.org/IDEs as well as this, the Sublime Text 2 Haskell plugin: https://github.com/SublimeHaskell/SublimeHaskell
The tutorial it comes with is pretty good but, as with all things, it's just practice. You don't have to start off doing everything in the most efficient way, you can add new commands and shortcuts to your repertoire gradually.
I couldn't agree more. Profiling is useful for find really bad spots (as described in this blog post), but once you've done that the information you get is so unreliable that it makes it very hard to make progress.
Hopefully the TUF work for cabal would fix a situation like that. In stack, we already check the hashes of downloaded files, so a situation like that shouldn't ever arise.
GHC can now emit DWARF, which is a step in the right direction. This means in principle you could now productively use `perf` or a similar tool on Haskell code. That being said, it will still be a painful experience ("hmm, 20% of my cycles are spent in `c24_info`..."). A little bit of tooling could go a long ways in improving this situation.
Not using 7.10.x as someone new to Haskell is certainly not a shame! I would advice against using 7.10, unless you are developing libraries. I've not yet heard many shops that have moved their production code over to 7.10 either. 7.8 with Atom... I should try it myself if it has proper `ide-backend` suppport :)
Oops just noticed I misread `ide-haskell` as `ide-backend`... Still Atom looks rather nice for Haskell: https://atom.io/packages/ide-haskell
I find FP Complete's offering quite good, and free for projects whose source code can be public: https://www.fpcomplete.com/business/fp-haskell-center/. It saves the fresh Haskell programmer from having to setup a toolchain, and focus on writing new code. At some point, learning the toolchain and setup is well worth doing, but nothing wrong with getting to focus on the language itself in the beginning.
The problem with this is that you lose the ability to write createUser "John" "Doe" "Hello!" which you can easily remedy adding deriving (IsString) to each of the declarations.
Which would let you make the exact same mistake you can make with only String. If you just want to document the logical type, the "type" keyword is called for.
Seconded. They saved me a lot of time wrangling around with non-core tasks. Once I set up my own environment, I didn't really have any particular need for a fancy IDE. The code is pretty terse. To be fair, I didn't do any large projects.
Exactly.
There are reference cards for the Emacs key bindings (https://www.gnu.org/software/emacs/refcards/pdf/refcard.pdf) that were a great help to me when I got started. Really though the only commands you need to know to get started are how to open a file, save a file, indent and quit. Once you have those mastered, you can take advantage of more features.
It certainly used to, but it's improved quite a lot over the last few months. I find it to be pleasantly snappy now.
For the benefit of the OP I just want to add some neuance by pointing out that the Haskell experience is perfectly fine on Windows as well. The main wart is the occasional package with a platform specific build script that requires Unix emulation to run.
Thanks. I'll wait for the fix. Does the workaround cripple Leksah in any way?
IntelliJ with haskforce looked promising. Unfortunately I am not sure it is as active as it used to be: https://github.com/carymrobbins/intellij-haskforce/graphs/contributors Atoms.io looks quite nice. The last time I have checked (a couple of months ago) it was too slow but according to posters it has improved a lot in that area. Emacs (spacemacs) is cute and nice but fragile due to ghc-mod and a perfectible haskell-process mode. The fact that a tool such as `ghc-mod` doesn't work with ghc-7.10 yet (the hackage version) is a bit worrisome. 
My guideline is to never reach for TH except to eliminate a maintenance burden I've already introduced through code duplication.
Good to know, I might try it again then!
As a user of both Vim and several IDEs, I'd like to add nuance to your argument. * "Because Haskell" is a pretty poor argument to advocate for Vim or Emacs, because their Haskell tooling is nothing special; * In addition, many IDEs have excellent, possibly better keyboard integration, such that developing in Vim isn't necessarily faster or more straightforward. It still comes with a STEEP learning curve. &gt;the keyboard-oriented workflows of VIM and EMACS are super useful, and nothings beats the comfort and power of a good shell that you will find on Unix systems. This is quite subjective, and there's a hidden clause that goes "...once you've passed the enormous learning curve". I think people should learn Vim or Emacs as a spiritual growth thing, but getting to a point where you're actually productive - as productive as, say, a Visual Studio power user - is a *serious* investment of effort. 
I don't take orders from heathens.
I like vim but as soon as any IDE anywhere has true intellisence for haskell I am there.
Maybe [microsoft](https://visualstudio.uservoice.com/forums/293070-visual-studio-code/suggestions/7756542-haskell) will pay you.
&gt; Turns out that a lot of influential community members just don't believe in IDEs for some reason. As a vim user, I also get this. The tools for vim just don't seem to be at the same level of quality as other languages. golang is something I poked a bit before starting Haskell, and the tools for golang and Haskell are just worlds apart. AFAIK, in theory you should be able to make the tools for Haskell just as good or better than the ones for golang, but golang's culture is "get shit done" so they built tools that let them "get shit done". Haskell's culture seems more... academic, where people seem to take pride in being able to write code without any editor support. Honestly it is my biggest pain point with Haskell.
Perhaps this isn't the best place for an editor, IDE &amp; OS war, /u/brubbledubs and /u/PM_ME_UR_OBSIDIAN
apart from /u/meditans link which is very recommended, [frp zoo](https://github.com/gelisam/frp-zoo) might help.
This is just a text editor with a plug in to make it a bit nicer. It's still for editing a file as opposed to fully managing a project. But thanks for bringing it to my attention. I might use it for things that don't need an IDE.
&gt;Honestly it is my biggest pain point with Haskell. ...and also Haskell's one excuse for not having taken over the world already :)
VS is one of the best IDEs ever created and that's a fact. Saying that it's worthless garbage is a sign of intellectual dishonesty.
Why is everyone afraid of giving an opinionated answer? Seeing side-by-side comparisons of the various options doesn't actually help that much, compared to folks coming forward and telling us what works well and what doesn't based on their personal experiences.
It finally clicked for me when I was [reading through these lecture notes](https://www.classes.cs.uchicago.edu/current/22300-1/Schedule.html). The class isn't really about FRP but somehow it worked. As for packages, I find that Reactive Banana is stable, mature, widely-discussed and performant. Other packages like Sodium and Netwire have their reasons for existing but I would start with Elm, then Reactive Banana.
FRP allows you to build reactive things more composably. Functions of the form `MonolithicState -&gt; MonolithicState` aren't very composable. [This video](https://www.youtube.com/watch?v=mYvkcskJbc4) has one of the best descriptions I've seen.
&gt; Note that I am not asking which library to use, I found plenty of answers to that but it is all "I like Foo, use it". I am more interested in learning enough to answer the question for myself. Honestly, try rolling your own. It's surprisingly not that hard (I did it in Swift, as I was unimpressed with the available options). It doesn't take more than a couple hundred lines of code to get the basic ideas up and working, and it really clears your head as to what exactly FRP is more than any amount of reading / lecture watching ever could.
&gt; "stunt_penis"
You are assuming that we never used IDEs. But the fact is, most emacs (or other powerful programmers editor) users also currently use or used in the past IDE. I have decades of experience with VisualStudio, Eclipse, Intellij IDEA, Delphi, PowerBuilder, Foxpro. And i do not miss that experience at all. &gt;but I want to work on my project, Me too...but in haskell, not java or C#. Unfortunately EclipseFP never worked for me. It was always broken. And for many many other people too. Call me when you have actual working IDE for haskell. 
Perhaps because not that many people know more than one frp library (of their choosing) :) 
Just my opinion, so take this as one more data point, but I would treat Template Haskell as the abstraction nuclear option. Don't reach for it unless you still have a something that is causing you a problem after other avenues have been investigated and found lacking. That said, here are some justifiable uses: * Automatically implement an instances of a type class that would otherwise be tedious and error prone. * Embed fragments of a well known language in your code (e.g. Hamlet embeds HTML). Basically, people are far more likely to know HTML than whatever HTML building EDSL you might come up with so the result is actually an improvement in clarity.
Work on Haskforce is still going on in this branch: https://github.com/carymrobbins/intellij-haskforce/commits/scala-cabal-issue144 IDEA + Haskforce is currently my favorite desktop IDE as it just works after a very simple setup, including working autocomplete with ghc-mod and find usages.
I'll give you a link to Emacs haskell-mode: https://github.com/haskell/haskell-mode Note though that Emacs is a very special beast, you will like it or hate it. Be warned.
Depending on which `liftIO` is being used, there could be a non-negligible performance difference, no?
I agree. I never really agreed with "refactoring" which doesn't really change anything. In that case, both version are right. It seems a waist of time, to rewrite one for the other.
Interesting! I didn't even know ReactJS was FRP. Now I'm questioning my decision to go with Angular.
I agree with this but I'd add, "and don't use it to generate serialization code that should never break or change without human intervention unless you're willing to write some very comprehensive integration tests".
IMHO - the best way to know if a textbook is going to be relevant to you is to skim the table of contents, which is always freely available online. I've personally found *Clean Code* to be distilled idiocy, almost like a *$SUBJECT For Dummies* book. But other people I know found it insightful.
Personally I do all my FRP work in `reactive-banana` these days. It's a super minimal API that is built around the tools we already know - `Functor` and `Applicative`. There is a strong emphasis on FRP and being declarative - more so than what I found with `netwire`. With the arrow style, it still seems like you are building sequential code, but `reactive-banana` comes out much more declarative. Having only an internal notion of time, hasn't been a problem, I have tools like this realTimeLoop :: Frameworks t =&gt; Moment t (Event t NominalDiffTime,Event t ()) realTimeLoop = do (physicsStepped,progressPhysics) &lt;- newEvent (rendered,render) &lt;- newEvent let dt = 1 / 120 :: NominalDiffTime step accumulator lastTime = do currentTime &lt;- getPOSIXTime let frameTime = currentTime - lastTime accumulator' &lt;- fix (\loop accumulator' -&gt; do if accumulator' &gt;= dt then do postGUISync (progressPhysics dt) loop (accumulator - dt) else return accumulator') (accumulator + frameTime) postGUISync (render ()) step accumulator' currentTime liftIOLater (void (forkIO (getPOSIXTime &gt;&gt;= step 0))) pure (physicsStepped,rendered) to add a fixed physics time step (120fps) with a render event at the end. This kind of stuff is useful if you're doing game programming. I just shove this in to the start of my network, and I get an `Event` that fires whenever I should re-render (which can then sample all the behaviors it needs), and I get another `Event` that indicates that physics should progress (e.g., integrate the effect of gravity over the scene) - that `Event` carries a time delta with it to perform Euler integration (I haven't experimented with other solvers yet). `reactive-banana` plays well with external inputs, which I've found very useful as all the work I do tends to be building on top of other (usually C) libraries. Finally, there are warts - the dynamic switching story is way harder than it needs to be. I'm happy to still recommend `reactive-banana` in spite of that though, because it looks like that is [going to improve](https://github.com/HeinrichApfelmus/reactive-banana/issues/97). Also, there are problems with garbage collection of dynamically switched networks, but [that too will one day be solved](https://github.com/HeinrichApfelmus/reactive-banana/tree/gc-new) Alternatives I can endorse because they seem to have "got it right" are `reflex` and `sodium`. I [didn't have much luck](https://github.com/SodiumFRP/sodium/issues/52) with `sodium`, though that might be because I was trying to write `reactive-banana` code there - others seem to have much more success.
It's sort of pseudo-FRP[1], but it *is* very good because it's *simple* and you can almost always figure out what it's doing. With larger (i.e. non-toy) apps you will find yourself searching for a way to manage whole-application state sanely -- this is something React does *not* do for you. You can go with the Flux pattern for this, but personally I found it pretty verbose (and sort of contrary to the spirit of JS). If you can stand Scala, I found Scala.JS + React-js (for Scala.js) to be superior to React and pure JS. You still have to find a state-management solution that works for you, but at least you get types and you'll still get (really well-optimized!) JS as output. [1] It basically does one-way FRP. If you keep *all* of your state in a single variable and just use props to pass all other state down, it'll be basically equivalent to FRP. However, in practice this becomes rather impractical without such tools as focusing (lenses) and such.
Only until someone defines `instance Num [a]`
Yeah. Basically, it clicked for me when I was thinking about how to abstract out Qt's signals and properties into first-class types... and I realized that I was reinventing that FRP thing which I had read about, but which had seemed too esoteric to be easily grokkable. The intuition I ended up with is probably what dyed-in-the-wool FRPers would call "overly operational" -- in particular, I did not yet grasp [the tension between switching and purity](https://blogs.janestreet.com/breaking-down-frp/) -- but I think it's a lot better than nothing :)
Surely that would still error as `2` is not a list? Defining `ToList Int` as well though... 
Please avoid personal attacks, and maybe be a bit more modest. Your opinions are your opinions and not unquestionable facts. By not respecting the opinions of others you put both yourself and the Haskell community in a bad light.
Was that released relatively recently? I remember reading about it in some "future goodness" post. It fits perfectly if you're trying to apply static typing to JavaScript, but... ... having said that it still doesn't give you any way to do: data Foo = A Int | B Int and to pattern match on those types. Unless you define *classes* A and B and embed within them the appropriate methods/properties. That's a lot of boilerplate. (... and I see this as a fundamental flaw of union types. They are (combined with classes) in some way probably equivalent to sum/product/record types, but in practice I find sum/product types superior.)
Try to. I dare you! :)
I'm guessing OP is talking about `Arrow` being equivalent to `Applicative`.
+1. If you're serious about compatibility you *will* write all serialization by hand. (That doesn't mean you can't do shorthands for common patterns, but you *must* have *ultimate* control. This is why I *don't* trust safecopy. In its entire history it has had *at least* one compatibilty break. That's enough for me to want to write *all* serialization/deserialization by hand.)
It isn't either!
So, you don't think Netwire gets it right -- because of the sequential feel?
Well there was a quite active rivalry between conduit and pipes. Interestingly it did not turn out bitter and we all benefited from it in the end. 
Hah, true! I remember watching a Hangout-style talk with both the principals of pipes/conduit and at least one interviewer (can't remember which *-cast it was) -- they didn't seem to take anything personally or offer personal insults, so I think it was all done in good spirit. I don't think the dispute about which is "better" is quite settled yet, however, ... :)
`\x -&gt; someFunction x arg1` may be rewritten as `flip someFunction arg1`.
I made it clear from the start that you won't convert me. I hope I haven't come off as trying to convert you. I've used emacs. For years. My hands still hurt. And I'm not going to rip keys off my keyboard, or install a piano peddle or any of that other stuff to be able to use it productively. Again, it's a powerful text editor. So powerful you could eventually program it to be about anything. I'm past the age where such projects appeal to me. I want batteries included and as little between me and productivity as possible. I don't want to know about what packages I need and I don't want to know what incantations make emacs actually use them. EDIT: The point of continuous compile is that fairly quickly you get to the point that your files have dependencies between them. In EclipseFP, if I make a breaking change, the second I save the file I get an indicator on every file that no longer compiles. I don't have to vulcan death grip my keyboard for that to happen, pressing save did it already.
"Constant applicative form" is a noun. So you'd say something like "f is a CAF" rather than "f is in CAF". A CAF is an expression with no free variables that isn't a lambda. Example: `z = [1..100]`. Nonexample: `z n = [1..n]`. Nonexample: `z = \n -&gt; [1..n]`. A partially applied function is also a CAF, although I don't understand why. So this is a CAF: `z = (+) 4`. And this is not: `z = \x -&gt; 4 + x`. CAFs are often used to save the results of computing functions by assembling a data structure that contains all of the input/output pairs of your function and partially filling it in as needed. The classic example is calculating the Fibonacci sequence. fib :: Int -&gt; Integer fib n = fibs !! n fibs :: [Integer] fibs = 0 : 1 : zipWith (+) fibs (tail fibs) Here `fib` is a function and `fibs` is a CAF. So can we pull off this trick for any function? I doubt it. You would need some kind of sensible data structure for the domain of your function, which might be wonky. Consider `map :: (a -&gt; b) -&gt; [a] -&gt; [b]`. To memoize this you'd need to be able to store arbitrary functions and find them again later. The CAF trick is also arguably not the best way to memoize things in Haskell. There are a bunch of cool toys in [Data.Memocombinators](http://hackage.haskell.org/package/data-memocombinators-0.5.1/docs/Data-MemoCombinators.html) aimed at making memoization easy. Check out their example of `fib`: import qualified Data.MemoCombinators as Memo fib = Memo.integral fib' where fib' 0 = 0 fib' 1 = 1 fib' x = fib (x-1) + fib (x-2) It looks almost exactly like the naive implementation of `fib`, but this is memoized. It will also be faster than my earlier example since they are surely using something better than a list to store results. (e: I checked. It looks like an IntTrie, so I'd expect their lookup cost to scale with log n rather than n.) *****e: Oh! I just learned something neat. The benefit of partially applied functions being CAFs. Check this out: in Data.Memocombinators we have type Memo a = forall r. (a -&gt; r) -&gt; (a -&gt; r) (snip) -- | Memoize an ordered type with a bits instance. bits :: (Num a, Ord a, Bits a) =&gt; Memo a bits f = IntTrie.apply (fmap f IntTrie.identity) and in Data.IntTrie we have apply :: (Ord b, Num b, Bits b) =&gt; IntTrie a -&gt; b -&gt; a identity :: (Num a, Bits a) =&gt; IntTrie a So if I have a function like `f :: Thing1 -&gt; Thing2` and there are `Bits`, `Ord`, and `Num` instances for `Thing1`, then the expression `z = bits f` is a CAF by virtue of being a partially applied function. Inside the first argument to that function, which was eaten by the partial application, we have a memo table! z = bits f z = apply (fmap f identity) ^^^^^ ^^^^^^^^^^^^^^^ | | | |--The memo table. |--The function that we partially applied. So if I understand the behavior correctly, GHC saves the information we gain about that data structure because it's consumed by the CAF. 
Ah, yes, the poor substitute for a print (which has the full power of the language after all and is simpler) one has to use when dealing with bugs that are no longer reproducible when changing the program in minor ways. 
[Link to it](https://www.destroyallsoftware.com/talks/wat), for those who haven’t seen it before or want to watch it again.
F# and Haskell are both excellent tools. IMO, there really isn't a wrong choice between the two. If Haskell had F#'s tooling, though... or if F# had Haskell's type-level machinery... We'd have an incredible setup. I'm not sure which of the two would be hardest to achieve.
The evil empire is looking less evil every day!
Everytime I look at that hackage page I end up staring at the source code wondering how that memos
Personally I prefer the arrowized FRP of YAMPA, it simply doesn't have the "switching problem" or GC issues. I'm working on my own FRP UI library that embraces arrowized FRP for exactly these reasons. As for sodium, it's identical in concept to reactive-banana so I'm not sure I'd endorse it.
"undefined" is cheating a bit, isn't it? I mean I could define an instance that just returned "undefined" for all the methods, couldn't I? EDIT: I should note that I appreciate that the laws for Num are underspecified, but that just because Haskell's Num class is broken in general. (It should reflect some sort of mathematical structure like Semirings, &amp;c, but currently it doesn't.)
&gt; It should reflect some sort of mathematical structure like Semirings, &amp;c, but currently it doesn't. Unfortunately, not every `Num` type is a `Semiring`. e.g., `Float` does not strictly obey the semiring laws.
Looks like your average PHP session. PHP has a REPL, right?
No, but we lie about floats all the time anyway -- they don't even obey the symmetrty of Eq.
Abominations abound!
F# could either have erased HKTs (which would make reflection less usable) or have runtime tags like Scala. Either way would screw with the C# interop.
You mean reflexivity? I actually didn't know that. Although I'm not sure whether `Eq` instances are actually required to represent equivalence relations.
If you're thinking about going the vim route, I did a small writeup on some of the most useful plugins and settings: http://dzackgarza.com/tutorials/2015/05/30/setting-up-a-haskell-dev-environment/
I use haskell on windows and on linux, and my impression has been positive on both(after I've learned about all the setup traps). Here is my suggestion, get: * GHC 7.8 * cabal 1.20 (1.22 does not work with ghc-mod and you will be screwed if you try) * and Atom (amazing editor imo) Download the following addons for atom: * autocomplete-haskell * haskell-ghc-mod * ide-haskell * language-haskell * merge-conflicts (for git merging) in cabal install: * ghc-mod version * stylish-haskell Sit back and enjoy :) 
You failed the Rorschach test.
For a well featured + dead simple to get working haskell IDE, the closest thing I've found is https://github.com/begriffs/haskell-vim-now. It takes a while to install (building each needed executable in a sandbox so that you don't hit any cabal issues) but will leave you with vim fully configured with SO MANY bells and whistles for haskell. If you want a nearly 1-click haskell IDE experience, this is it. You'll need to `cabal install happy alex` before you run the script as well as vim-7.4 but these aren't generally tricky to do. Overall though, emacs has better tooling for haskell generally. When I was learning haskell I decided that learning emacs &amp; haskell at the same time is a bit too hard so I just stuck to vim. Also, if you set your editor to vim in shell you can use `:e [&lt;path to file&gt;]` to open up vi from ghci &amp; have the file loaded when you quit. This makes life so much easier when you're first starting out and realize that ghci doesn't do exactly what you think it does because you're actually stuck in a big-ole do block. Finally, IntelliJ now has a haskell plugin though I can't vouch for its abilities. 
It does seem a bit magical when you first look at it. However, it becomes clearer when you work through an example and consider the properties of permutations in lexicographic order. Here are the permuations of abcd in lexicographic order. We want to find the particular permutation at position 11 (counting from 0). 0 abcd 1 abdc 2 acbd 3 acdb 4 adbc 5 adcb 6 bacd 7 badc 8 bcad 9 bcda 10 bdac 11 bdca &lt;-- posn. 11 in perms of abcd; posn. 5 in perms of acd; ... 12 cabd 13 cadb 14 cbad 15 cbda 16 cdab 17 cdba 18 dabc 19 dacb 20 dbac 21 dbca 22 dcab 23 dcba Notice that the first letters of the permutations are in lexicographic order: a group of 6 = 3! = (4-1)! 'a's, followed by the same number of 'b's and so on. The size of the groups is determined by the number of permutations on 3 letters. So, in order to find the first letter at position 11 we divide 11 by (4-1)! giving 1 with a remainder of 5. This tells us that the permutation we want is in the second group of 6 (counting from 0), so the first letter of our permutation is the one at position 1 (also counting from 0) of abcd (i.e. b). Also notice that when we strip off the first letter of a group of permutations we're left with all the permutation of the remaining letters, also in lexicographic order. In our case, after removing the leading b we have: 0 acd 1 adc 2 cad 3 cda 4 dac 5 dca &lt;-- posn. 5 in perms of acd; posn. 1 in perms of ac; ... The remainder we calculated above tells us that we're at position 5 in the list of these permutations. We're trying to solve exactly the same problem, but with a smaller list (i.e. with b removed). This time around we divide 5 by (3-1)! = 2 giving us 2 with a remainder of 1. This means our next letter is at position 2 of acd (i.e. 'd'). We keep doing this until our list is empty. 
Okay, then... Functor?
It doesn't? I thought Z/nZ was a ring for all positive integers n? (And even a field when n is prime.)
I'm more worried about the evil empires that don't appear to be evil.
Seems like a good time to mention [this](http://www.slant.co/topics/2349) again. It still needs a lot more love, but the goal is to collect opinionated answers for posterity.
I think `netwire` lead to what still felt like very imperative do-this-then-do-that coding. It actually gets a bit better when you *don't* use arrow notation (you can just use `Category` + `Applicative`), but then you might as well just drop down to `reactive-banana` and switch approach entirely.
Is there any introduction material for `reactive-banana` you can recommend?
The thing is that I don't want an **Integrated** Development Environment. I want one with interchangeable parts; one which I can build up (not from the *ground* up) and say "oh, so that is how this works"; one which I can turn off or discard subcomponents if they get annoying, slow or buggy. And these *parts* should be somewhat generic components, not black box plugins that only work in one environment. They can be less generic if that is necessary to interface well with the *environment*. A small-scale example is to be able to edit normal prose and then invoking a spellchecker that interactively goes through the document, like ispell or whatever it's called. I don't have to care about the spellchecker when I'm editing text, because that is distracting. I know that there isn't one running in the background, ready to complain. But I can also turn off a sort-of *daemon* one, if I want such background processes.
Having only used `netwire` I don't think it would be far for me to pass that assessment :)
To see that conjunction is the product in a poset P, consider two elements a, b ∈ P (recall that a morphism a → b in P is the same thing as the inequality a ≤ b): * we have projections fst : a ∧ b ≤ a and snd: a ∧ b ≤ b * given any morphisms f : c ≤ a and g : c ≤ b there is a unique morphism (f,g) : c ≤ a ∧ b. That disjunction is the coproduct is just a dual argument. Since you come from rings and groups, you should ponder on the difference between the coproduct of Abelian groups vs. the coproduct of groups. For instance, what is the difference between ℤ + ℤ formed in the category of abelian groups Ab and ℤ + ℤ formed in Grp? The ambient category matters – you can't tell what is what just by staring at the type signatures.
You can't get such a warning in general. Suppose you wrote instance (Foo f, Convertable a) =&gt; Convertable (f a) where convert d x = convert d &lt;$&gt; x and then in an unrelated module someone defined `instance Foo [a]`. Then you have overlap with no chance of detecting it at the compile time of *your* module.
I feel that for Bool, True is like 1 and False is like 0, with &amp;&amp; a product and || a sum. In sets, monoids, groups, rings and fields, you can make the cross product of two objects and it's the product in that category, but you can only do the category theoretical sum in Set, since the need for a common identity element destroys the disjointness of the union. (For example, you'll have problems using a monoid structure for Bool and another for Integer to make a monoid structure for Either Bool Integer.) 
Autocomplete does not show up, shows up but is empty or just does not have the all the functions it should? It could be a problem with metadata collection. Does the Modules pane contain the functions you were expecting to see in autocomplete? The file `~/.leksah-0.15/collectSystem.report` contains a summary of the metadata collection status. How did you install Leksah (from the binary or did you build it locally)? 
I hope that in a few years FStar will be ready for serious applications. It supports dependent types and compiles to F#, OCaml and JS. I'm following the tutorial right now: [tutorial](https://fstar-lang.org/tutorial/)
OK, I'll try that. It's a pity that there's no debugger though. Leksah seems to be more complete.
I had the same problem with vim actually. A system that is so complex that the investment to configure it fully to my needs is too big. With Spacemacs the default layers plus some tweaks gets me to 90% of my needs. I think that is wonderful. I did not manage to get Spacemacs working with SHM and ide-backend though. So anyone who has that working: pls show me yr configs :)
I'm old school in this respect: I like to do as much as possible offline and have all my files on my hard disk.
Been burned by this, have you?
great! 
I'll try this. Right now after finishing the Scala Reactive course on Coursera I find myself in the same boat as OP - a bit curious about Haskell. So far I've tried the IntelliJ plugin, Leksah and Atom and they keep crashing. To be fair, when I first tried Scala it also took me forever to get it to work. Edit: ...Er, or not. I see that the link instructions are really for Linux. Any Windows stuff?
You need boobs, as suggested with the composition package. (.:) = (.).(.) 
Here is another way to write it. I did not do this very carefully, so be wary of mistakes. allTargeting :: Lesson s -&gt; WeightMap -&gt; Int allTargeting = ( fmap (foldl (+) 0) . sequenceA . sequenceA . (fmap . fmap) (Map.findWithDefault 0) ) [ Slot . timeslot , Day . day , uncurry Cell . time ] Edit: Yup. It's wrong.
Would not it be enough to use [type synonims](http://learnyouahaskell.com/making-our-own-types-and-typeclasses#type-synonyms)? This way there would be no need to use constructors, right? type FirstName = String
You're right! That is the arithmetic used for `Int`! I'm not sure why I thought otherwise.
That doesn't actually work though. What does is allTargeting = ( foldl (+) 0 .: sequenceA .: sequenceA . (fmap . fmap) (Map.findWithDefault 0) ) [ Slot . timeslot , Day . day , uncurry Cell . time ] 
Slightly off topic, but, if one *was* to rewrite `avg` to do everything in a single pass, they should check out the awesome [foldl](http://hackage.haskell.org/package/foldl-1.1.0/docs/Control-Foldl.html) library: import qualified Control.Foldl as L avg :: [Double] -&gt; Double avg = L.fold (L.sum / L.genericLength) or more generally: avg :: (Foldable f, Fractional a) =&gt; f a -&gt; a avg = L.fold (L.sum / L.genericLength)
Indeed, the CAS loop does not compute the update, but just atomically places a thunk that updates with the previous value. https://github.com/ghc/ghc/blob/master/rts/PrimOps.cmm#L584 The 'ed version forces this thunk after it is put in place. This benchmark does not talk about much at all if it is not running on the threaded runtime.
This is called dimension typing. [Here's a wiki page on it.](https://wiki.haskell.org/Physical_units)
I wrote and use [ghcid](http://github.com/ndmitchell/ghcid), which is a very simple IDE-like experience that integrates with any editor. Either "GHCi as a daemon" or "GHC + a bit of an IDE". To a first approximation, it opens ghci and runs :reload whenever your source code changes, formatting the output to fit a fixed height console. Unlike other Haskell development tools, ghcid is intended to be incredibly simple. In particular, it doesn't integrate with any editors, doesn't depend on GHC the library and doesn't start web servers.
Just wondering, is there already any example of a text adventure written in Haskell?
I would if I had any idea how those work! I never played them. Except [Sleuth](https://www.youtube.com/watch?v=0dx5atnX710&amp;safe=active), if that counts? Also I'm not the very creative type. So I couldn't come up with the content on my own.
I definitely prefer the applicative form because it removes the bound variables. If a value is unnamed, you cannot accidentally incorrectly refer to it. The applicative pairing operation is so common that I wish it were in defined in Control Applicative. I often define these myself a &lt;×&gt; b = (,) &lt;$&gt; a &lt;*&gt; b a &lt;+&gt; b = Left &lt;$&gt; a &lt;|&gt; Right &lt;$&gt; b Although the `&lt;×&gt;` operator looks like two Tholian vessels that are about to start building a web.
Probably a tonne, but none that are well known – or at least that I know of.
Are you using the latest available Xcode for 10.9? That's what I meant.
Ok, I'll have a look. thanks
I still haven't found any libraries for doing interactive fiction in Haskell. It makes me sad. I think Haskell could be great for that kind of stuff!
I'm not seeing F* going anywhere. It never made it past the research prototype stage.
I would be interested what are the problems with its composability. Could you write a small summary?
There are indeed a few things to keep in mind. The differences between foldl, foldl' and foldr are the go-to example. I also remember an example when sharing could result in a space leak, something like: x = do let list = [1..1000000] mapM_ print list print (sum list) The reasoning went as follows: because `list` is used in line 4 as well, the elements cannot be garbage collected and remain on the heap, resulting in huge memory usage. However, if one inlined `list` in both locations, like so: x = do mapM_ print [1..1000000] print (sum [1..1000000] ) ... the program is optimized to run in constant memory, because each time a number is printed on line 2, it is immediately marked for garbage collection. Could someone confirm this? However, most of the heavy lifting optimization-wise has already been done by library authors. The `wai` package, for example, has gone through extremely thorough optimization. The extreme composability of functional programming languages means that you can easily stand on the shoulders of these giants.
Thanks. I think I follow what you're saying, but this doesn't run for me so I can't actually see it. I think it's because putStrLn needs a char, not an int. I tried to use intToChar but it isn't in scope. I am a total noob.
Often, the point of making a `newtype` is to restrict the interface of the type. Automatically deriving everything would defeat this purpose. Also, sometimes you want custom instances that would not be the same as the auto-derived code, for example for `Show` and `Read`. It seems like there are two separate problems in this. The first problem only applies if there are `Show` instances already implemented. If you want a temporary fix for the first problem so that you don't have to type out the full constraint every time, you can use `PartialTypeSignatures`. Here's an example: {-# LANGUAGE PartialTypeSignatures #-} showIt :: _ =&gt; a -&gt; String showIt x = show x You can also enable `-fno-warn-partial-type-signatures` to stop the warnings from happening, but I wouldn't suggest it in this case. The warnings will help you remember to remove the constraints later on.
I see your point but isn't that more the exception than the rule, wouldn't you always want as many derives as possible?(maybe add some sugar to prevent it) Also I don't see why custom instances couldn't just always override the defaults instances? Secondly I am hopelessly dependent on ghc-mod so only 7.8 for me :/ and PartialTypeSignatures is a brand new feature in 7.10.
See also [semantic edit combinators](http://conal.net/blog/posts/semantic-editor-combinators). With the right glasses on, `(result . result) (foldl (+) 0) foo` is more readable than `(foldl (+) 0 .) . foo`.
Woops, missed that, sorry! You can use `print` instead of `putStrLn`. EDIT: Edited the OP.
Interpretation vs. compilation is a red herring. The languages you gave as examples aren't even very good ones: Haskell has an interpreter and CPython is a bytecode compiler. And anyway, *languages* are not compiled or interpreted: implementations are. Instead of thinking about languages (and their implementations) in terms of compiled vs. interpreted, it's more useful to consider their evaluation semantics, runtime systems, and so on. This is where you'll find the differences between Python and Haskell that most affect performance.
Thanks for the explanation. If you convert your `String` to a `FirstName` type synonym when it gets into the system, though, the type checker will not allow it to be used in place of a `LastName`, right?
- Create typeclass instances like functor and applicative to various data types - Build a static website generator or blog - Build a parser combinators library like Parsec - Build an interpreter/compiler for a programming language
Googled sample text from it. Apparently it has been pasted in many places verbatim over the years. It appears to be some sort of programming challenge with a fake back story. Haven't read it though because too long and boring sounding.
I think the general rule is that when creating libraries (or library functions) you try for the most general type possible so your call chains should be very shallow. When writing applications (I.E. the things using the libraries) you should be using the most concrete types possible (up to and including newtype wrappers of things like Strings) so adding new constraints would just be a matter of adding the type class declaration to the concrete type.
That would complicate things a lot. You can only have at most one instance of a type class for any type so this would need to be an exception to that rule, making the type system more complicated. You wouldn't be able to look at a source file and quickly determine what instances are being implemented and what those implementations are (whether they are default or not). To me, that is a pretty big downside. It's also not clear to me how this would interact with orphan instances. Also, the *most* instances you can derive for a `newtype` is *all* of the instances for the underlying type, but that is something you would often not want to do. I would say that that would be the exception, actually. Usually, you either want a `newtype` in order to restrict the interface from the underlying type or in order to make a instance of a type class that is different from the instance of the underlying type (such as `ZipList` or a `Int` `newtype` that does modular arithmetic). In both cases, you wouldn't want this behavior. Basically, to me it looks like something that solves a pretty minor problem (a bit of extra typing) by potentially introducing some problems, reducing clarity a bit and possibly changes to the type system itself (especially with regard to the first part about avoiding writing out constraints in function types). It might make sense to have an extension that lets you write something that tells GHC to derive everything it can, but I wouldn't want that to be the default operation. That's unfortunate about ghc-mod. It looks like a fix for 7.10 is in progress on github.
You forgot to add link to hackage.
The problem is functions such as (!) because nothing automatically derives show can't print the data object in question when throwing an error. Which makes finding such a bug a near impossible task. I mean at the very least auto derive a ToString class.
On the other hand, if you "could" print functions then you'd have to worry about the fact that now every function you write has to carry around enough information to print itself, and that you don't have to care just about how the function behaves on different values to consider it a "different functions" but rather how it prints. This pretty much shuts down almost every single optimization the compiler might attempt on your behalf.
In your second link, can you tell me what Exercise 1's answer is? That would help me understand how to do the rest.
I don't see how that necessarily follows? as it would only need to carry information it already was required to carry.
Which information is it already carrying? If you just wanted to print the type of a function as it's show then you need to suddenly start storing the types of the function somewhere.
Not necessarily. The optimizer spits out code that only bears the barest resemblance to the function you wrote. Once you start playing javascript-like games where you can "print" functions, now someone is going to come along and check to see if the string you print for the function is the same as some particular constant value or something. If your optimizer changes the definition of the function? (\x y -&gt; x) const (\y z -&gt; y) (\w y z -&gt; y) "oogabooga" are all equivalent functions extensionally. They do exactly the same thing. You can substitute one for the other in _every single possible context_ today. They won't produce the same string when your magic function printer prints them, and in the status quo we equationally rewrite down to simpler and simpler forms as we run rather than constantly build things up into messier and messier functions. In your world you have to keep all that noise forever because someone sometime might try to ask you for it and you have to be able to supply it. These functions are no longer equivalent! Moreover, the compiler takes things from its surface representation and feeds it through multiple intermediate layers down into entirely different language to execute. The high level semantics of the code you started with just aren't there after it has gone through the compiler. The type information is erased, etc. We can throw all that stuff away at runtime because it did its job at compile time, and carrying it around at runtime would change the asymptotics of your code. Your function isn't defined by its semantics on values its defined by a weird mishmash of its semantics on values, and how it prints when handed to your magic function. The optimizer now dare not change the latter because it'll change how things compare for equality if you compare the "toString"s of the functions! Little versions of this abound in other languages that try to shoehorn random extra semantics onto lambdas. e.g. scheme allows for you to check to see if two lambdas are the same lambda by allocating a "location" tag every time you create a lambda. This pretty much rules out whole swathes of optimizations because you have to live in fear that your users might try to check if your function is the same function object in memory closing over the same stuff as another function object in memory. You're adding a ton of semantics. Consider the equational reasoning steps allowed in http://arxiv.org/pdf/1309.5135v1.pdf sum (map sqr (down z)) = foldr (+) 0 (build (\c n -&gt; foldr (c . sqr) n (down z))) = foldr ((+) . sqr) 0 (down z) = let loop x = if x==0 then 0 else sqr x + loop (x-1) in loop z takes a high level specification and equationally rewrites it into something that is damn near optimal from a machine standpoint. They are extensionally equal, but behave differently internally. GHC will for you today change one into the other. The details of every closure a function happens to touch, etc. aren't something I want it to have to regurgitate on demand. It is an evolutionary dead-end in language design.
&gt; I for some reason need to do a quick trace to see the outputs of. I often run into the issue that I have to apply show constraints to every single function in the entire call stack. I hear you! I use `trace ` a lot when debugging, and it's unfortunate that I can't use it inside polymorphic functions. It's already pretty useful that `unsafePerformIO` allows `trace` to print its debugging information to the terminal even from a pure function, I wish there was also some kind of `unsafePerformMethod` which could call a method such as `show` on a value even if its polymorphic type doesn't have the necessary Show constraint. I was about to explain why it would be impossible to implement `unsafePerformMethod`, but actually, with proper support from the compiler, I think it could be done! The reason I initially thought it would be impossible to implement it is that values are not tagged with their type at runtime, so it would not be possible to unsafely ignore the type annotation and look at the true type of a value to find the corresponding Show instance. However, it's a feature which could be implemented by translation, either as an additional compiler pass or as a separate preprocessor. First, find all the functions making use of `unsafePerformMethod` and infer the extra constraints which would need to be added to the function's type signature. For each of those functions, generate two implementations: one with the extra constraints, and one without. The one with no extra constraints simply delegates to the other one, passing an undefined dictionary of method implementations. Thus, if you end up using `unsafePerformMethod` on a value which doesn't have the required instance or for which we cannot find the instance, the program will crash and that's what you get for using an unsafe method. Next, recursively duplicate all the methods which directly call one of our duplicated methods, each calling the corresponding copy of their callees. Finally, should any complication arise (compilation boundaries, higher-order functions...), use the copy which doesn't have the extra constraints and let it crash at runtime.
Sounds right to me. I think SPJ noted how where to put the commas in that statement in one of his talks.
Thanks I will look into AMP and FTP to see what they are. I bet they are exciting and helpful changes.
You're right. Fixed.
How so? I imagine it being very hard, but why would it be *impossible*?
I don't know much about Haskell, but it seems to me that your examples for logDiv use badly named arguments a and b instead of x and y.
With thunks and laziness I've imagined Haskell as compiled snippets threaded together by a runtime interpreter. I would be interested in feedback from those who know if this is a useful mental model. 
Short explanation: because depending on what a variable contains parsing differs, so you need to know the type of a variable (in an untyped language) to know how to parse a statement. http://www.perlmonks.org/?node_id=663393
And yes, you'd have a function at the border of your system to check the raw input (a `String`) and turn it into semantically valid data (a `FirstName`). Then you would limit yourself to only using it in the correct ways, with the functions that expected it.
Yeah, that's what I get for not feeding my examples to the compiler. Fixed.
I do not see any content worth reading or sharing there.
&gt;t's more useful to consider their evaluation semantics, runtime systems, and so on. Excellent point, thank you.
Could you not compile all possible valid parses then select it at runtime?
I was at a talk where he explained it this way: avoid $ success at all costs This of course is quite different from: (avoid success) at all costs Shortly after that talk, he invested his own money in FP Complete (where I am founder/CEO) so you know he does want to see Haskell succeed.
Instead of the composition-based approach of `(.)`, `(.:)`, etc, an alternative form of point-free programming is to use the `($::)` and `(~&gt;)` combinators from [pointless-fun](http://hackage.haskell.org/package/pointless-fun-1.1.0.6/docs/Data-Function-Pointless.html)
http://lukeplant.me.uk/blog/posts/why-learning-haskell-python-makes-you-a-worse-programmer/ Controversial but I'm open to all sides.
Maybe not quite what you're looking for, but I was thinking just a couple of days ago that while there are plenty of cases where you might *not* want to derive instances, I don't think there would be any problem with a language pragma that inverts the default, so everything possible is automatically derived and this can be turned off by an explicit `deriving` line, which could be `deriving ()` to derive nothing. The fact that there is no such extension very likely means I'm wrong about there being no problem with it, since it seems like a pretty obvious idea, but then again it could just be something nobody's gotten around to yet!
Does anyone know of a tool for type checking or compiling examples in Haddocks documentation? (a quick search did not avail me anything)
Perhaps you're thinking about [doctest](https://hackage.haskell.org/package/doctest)?
It's from one of the previous ICFP contests. It may even have been the one for which roconnor wrote an article for in The Monad Reader.
It's Perl; that's going to be a lot of compiling.
It's easier than I thought to get rid of at least some of the concreteness of `Lens.Simple.zoom` (= `Lens.Family2.State.Strict.zoom`: useboth' :: (MonadIO m, MonadState St m) =&gt; m () useboth' = do zoom_ int f zoom_ str g int += 1 str &lt;&gt;= "!" zoom_ l f = abstract $ zoom l f abstract :: MonadState s m =&gt; StateT s m b -&gt; m b abstract st = do s &lt;- get (a,s') &lt;- runStateT st s put s' return a
did you configure your cabal?
Or Befunge (a language designed to be uncompilable)
Unfortunately, to non-haskellers &gt; avoid $ success at all costs looks like &gt;avoid monetary success at all costs so its probably best not to publicize that phrasing too widely. 
https://ro-che.info/articles/2014-06-11-problem-with-mtl#merging-transformer-layers
Hi Edward, will you be passing also by Florence or nearby?
1. I second u/gelisam: this certainly needs explained examples, especially since many (including me) just heard about "concolic testing" for the first time. 2. The amount of setup this requires (including a patched jhc and an ancient version of llvm) is prohibitive. To have people try this, you could expose this as a web service or offer a downloadable docker image with everything prebuilt and preinstalled. 
That's a great example. But this is the Lens solution built on top of mtl, just like Ether builds on top of mtl. I'm not saying that mtl's antimodularity can't be fixed. However, with the Lens solution you can't `runStateT` to get rid of one `MonadState` and continue working with another. Modifying tuples is not the best solution in my opinion (especially if you have a lot of states). Also note that there are cases when you can't merge multiple `StateT`s into one (as /u/roche describes in his article).
I'm about to give up :( Neither cabal 1.20 nor 1.22 work on Windows. With the former "cabal init" doesn't work and with the latter ghci-mod doesn't work! Now I'm about to try IntelliJ hoping that it doesn't rely on "cabal init" to create new projects. As a last resort I'll have to install Ubuntu in a VM or go back to Scala and forget about Haskell. edit: I was wrong. The Haskell Platform comes with cabal 1.18! How can I upgrade to version 1.20? edit2: Nevermind, I found the right command here: http://blog.johantibell.com/2014/04/announcing-cabal-120.html
**EDIT**: Success! Thanks for the late night help on IRC too! Managed to get a cabal file set up and it compiles! I can't load foo.hs into ghci without errors because it doesn't know about the cabal file I guess. ORIGINAL PROBLEM: Nevermind :) Thanks! Copied from the pastebot site I'm trying to compile a program that uses the following imports: import Network.HTTP.Conduit (simpleHttp) import qualified Data.Text as T import Text.HTML.DOM (parseLBS) import Text.XML.Cursor (Cursor, attributeIs, content, element, fromDocument, child, ($//), (&amp;|), (&amp;//), (&gt;=&gt;)) It is from the second example on this page https://www.fpcomplete.com/school/starting-with-haskell/libraries-and-frameworks/text-manipulation/tagsoup I am on ISX Yosemite using this package https://ghcformacosx.github.io ghc --version; cabal --version The Glorious Glasgow Haskell Compilation System, version 7.10.1 cabal-install version 1.22.0.0 using version 1.22.0.0 of the Cabal library I've spent all night now trying to learn how to track down broken dependancies and it still isn't working. Is there a simpler way to do it? what is the right cabal install ???? to get it compiling? (I have figured out how to "cabal sandbox init" successfully, which turned out to be one of my early stumbling blocks) It's 3am. I'm going to bed. I pray someone knows the right cabal incantation to let me get this example working. Thanks! 
Yes, I've spent three hours trying to figure that out. Google results get lots of old links that I don't think are relevant and nothing leaps out as a definitive answer if you don't know what you're looking for. Hoogle isn't particularly useful for a beginner either for what I was trying to do. Mapping from Dotted.Module.Name to CABAL-importPackageTag isn't easy. Hoogle can offer up LOTS of seemingly good possibilities, again if you're a beginner. So yeah... I've been Googling. 
It's one (of many) ways it could work. I'm not sure how useful it is as a mental model, though.
In the original definition of Haskell there was automatic deriving. If you left out the `deriving` clause you would get as much as possible. This was removed for the sake of being more explicit; it was tricky to predict exactly what a left out `deriving` would give you. 
I usually present it with a colon: &gt; avoid: success at all costs
I think I did it! Maybe I should write a post about it for total beginners.
&gt;surely the fact that some other language doesn't have them is not particularly meaningful. It shows that lacking exceptions isn't a bar to attracting developer mindshare. I've seen programmers argue that they couldn't imagine using a language without exceptions, so having multiple successful languages without exceptions acts of a sort of social proof that it's okay for a language not to have exceptions, for people who are concerned about such things. It also acts as empirical evidence supporting the notion that exceptions aren't necessary for modern software development (although C already showed this, many would consider its lack of exceptions a result of its age rather than a design choice).
In a purely functional language, I would like every effect to be encoded in the return value. IMO, a function that throws exceptions without in being encoded in it's type is doing things it shouldn't do.
&gt; with asynchronous exceptions in particular seeming like they could make code a lot more difficult to reason about. They do, though I don't know how else you would handle events such as a keyboard interrupt. At least with exceptions you can recognize that the event occurred and possibly perform cleanup or recovery; the Rust mechanism you describe sounds inferior. Also, the only point at which you have to worry about asynchronous exceptions is in impure code, particularly where you acquire resources. Careful use of functions like [bracket](https://hackage.haskell.org/package/base-4.7.0.2/docs/Control-Exception.html#v:bracket) will cover you here. Asynchronous exceptions aren't a concern in pure code. Practically, it makes sense to [use exceptions for code that's in the IO monad](https://www.fpcomplete.com/user/commercial/content/exceptions-best-practices).
You are one smart cookie.
Those compiled routines would exist already though it'd end up being a subroutine call, like a library call in other langs.
Does this mean that Haskell does not have functions without arguments?
Giving `add` one argument gives you a new function, setting `addPlusOne` equal to that means that `addPlusOne` is the same function. add :: Int -&gt; (Int -&gt; Int) add 1 :: Int -&gt; Int addPlusOne = add 1 addPlusOne :: Int -&gt; Int
at the end of the article, it said it did indeed made him a better _programmer_ but it kinda messed up his code in a sense that he was never satisfied with it / unreadable, which demoralized him.
Success of a language comes with a lot of weight. The more users that you have, the more voices you have complaining at you whenever you realise that you'd like to change anything, even in cases where it's generally agreed upon that those changes would be a good thing overall. Haskell has probably already failed to avoid success in the sense that was originally intended. There's still a surprising extent to which changes are getting pushed through in the basic libraries, but things have been pretty conservative overall for a pretty long time now. In order to make fundamental progress on the language itself, we might need a new language at this point though. Personally, for example, I'd like to see something pretty close to Haskell, with lazy evaluation by default and properly coherent type classes, but with a full dependent type system. Doing this right while trying to keep the name "Haskell" would likely break too much code to keep everyone happy.
Sure but I'm not seeing how we disagree. There are languages that do and don't have all kinds of things. It doesn't seem to matter as far as mind share. So while I feel like exceptions are annoying and screw everything up, many popular languages have them and "do well." I don't think you can cite a popular language's features as all good, just not bad enough to ruin the language.
F* does this; it's ["parameterized by a join semi-lattice of effects"](https://www.fstar-lang.org/papers/icfp2015/full.pdf) (which are also referred to in the paper as Dijkstra monads): &gt;PURE -&gt; DIV -&gt; STATE / EXN -&gt; ALL &gt;At the bottom, we have PURE, which classifies computations that are pure, total functions. The effect DIV is for computations that may diverge (i.e., they may not terminate), but are otherwise pure. STATE is for computations that may read, write, allocate, or free references in the heap; EXN is for code that may raise exceptions; ALL- computations may have all the effects mentioned so far, as well as IO. So an otherwise pure function that might throw will have a return type of `Exn a`.
Approximately never.
I have never understood this expression and this time is no exception. :(
I don't oppose this library at all, it seems great. It was just the claim "mtl is anti-modular" that struck me as excessive. If you are trying to do something like what `ether` does, then tupling with `zoom _1` and `zoom _2` will seem like a hack, a band-aid etc. *This isn't what my example was an example of, though.* In my case, I *wanted* to operate with a (deliberately simple) state `St`. A `St` is composed of an `Int` and a `String`. Modularity suggests that I ought to be able to recycle my old `MonadState Int ...` and `MonadState String ...` gizmos in the construction of my new `MonadState St ...` items. It is this form of modularity is available with `zoom` and `magnify` but not with `ether`. Even that case is in fact very simple. Lenses needn't look to actual fields of a record-type. If you look at this [pipes-text example](https://github.com/michaelt/text-pipes/blob/master/examples/zoom.hs#L81) resolving a problem posed by Michael Snoyman, you will see that with `zoom` one is able to operate on a `Producer ByteString` state recycling predefined state-devices ('parsers', in this context) that look for: - a `Text` with utf8 encoding - a pair of `Text`s with utf8 encoding - a different pair of `Text`s with utf8 encoding, and - a pair of raw `ByteString`s. all of this *in sequence*; moreover, what type I 'see' in the state at any stage can depend on what the previous parsers turned up. The advantages of `ether` cannot be clearly expressed with the term 'modular'.
First of all, let's acknowledge that merging states into one layer is a hack. It's boilerplate-heavy and doesn't work with some monad transformers. You also can't merge a lazy state and a strict state into one, for obvious reasons. So manual lifting is something that allows you to side-step the problems with merging layers, but now you're relying upon a particular order in which monad transformers are stacked, which completely defeats the purpose of mtl - abstracting from this order. So when you abandon an idea (in this case abstracting from the order of monad transformers) to solve a particular problem (in this case unmergable states), I call that a band-aid, because it just fixes the problem where it bleeds the most, not on a fundamental level.
Ether-style tagging can be combined with Lens-style zooming, those are orthogonal concepts. My argument is that mtl alone can't be used in a modular way, you need to extend it either with Lens-style zooming or Ether-style tagging to get modularity. Both are mtl-compatible. Perhaps it's just bad phrasing on my part.
get isn't a function or method. It's a value ;) Haskell functions are only those values that have a function type.
I set for myself two rules: 1. Pure code shouldn't raise exceptions. It's awful. 2. If, in some particular API, the "best" thing to do is to crash, just raise an exception. If you're not actually doing something useful with the failure, you don't benefit by encoding it at the value level.
I'd be totally on-board with tweaking the Prelude such that head :: [a] -&gt; Maybe a unsafeHead :: [a] -&gt; a These kinds of power tools are fantastic to have around, but safety should be the default.
You could also provide either a `cabal` file or a Github project that the beginner could clone and install.
You should avoid asynchronous exceptions as much as humanly possible, mainly because they don't show up in the types. Usually the only legitimate use case for them is when you know the exception is unreachable but you cannot prove it in the types and even then you should consult more experienced Haskell programmers to see if there might be a way to more safely encode what you are trying to do. For synchronous exceptions, they are totally reasonable and most people use them when programming using `IO` because the `IO` in the type documents the potential for synchronous exceptions.
Ether introduces no boilerplate. If you want `StateT (s1, s2) m r` with Ether, use it - Ether is compatible with transformers. If, however, you want two states with unspecified order, Ether gives you the possibility to do so fairly easily, and with transformers you're stuck. No one forces you to abstract away the order, but isn't it nice to be able to? Sometimes I *want* the meaning of my code to depend on the order of layers. Can you do that with transformers alone? No. Can you do that with mtl alone? I don't think so. Another use case for Ether is fast and simple creating of your own effects. Say you want `MonadConfig` that behaves exactly like `MonadReader`, only it shouldn't conflict with other `MonadReader`s in your stack. With Ether you simply write this: ethereal "Conf" "conf" type MonadConfig = Ether.MonadReader Conf askConfig = Ether.ask conf With mtl alone you should write a whole bunch of boilerplate instances, and it gets even worse if you want more effects, because you need O(n²) instances in general.
Yeah, tutorials without fully qualified imports are worthless.
No, the denotational semantics of a non-total non-strict language are easier and more natural, not more difficult. The point is exactly that you are *not* "capturing the consequences of the evaluation strategy". Non-strictness frees you from the obligation to specify an evaluation strategy at all. That is where the power and expressiveness come from. But it is awkward to work that into the context of a language in which, for whatever reasons, you do prefer to assume things about the evaluation strategy, such as strictness.
&gt; No, the denotational semantics of a non-total non-strict language are easier and more natural, not more difficult. Easier/more natural than what? A total language? Hardly true. Total functions and sets are pretty straightforward. &gt; But it is awkward to work that into the context of a language in which, for whatever reasons, you do prefer to assume things about the evaluation strategy, such as strictness. But total languages don't assume anything about the evaluation strategy. You are conflating totality and strictness. Totality and non-strictness are completely compatible. This comment you made earlier: &gt; the non-strictness semantic approach focuses on domains and monotone continuous maps. Only applies for non-strict, non-total languages. Total non-strict languages have more or less the same denotational semantics as total strict ones. 
&gt; But the return type of the expression is a tuple. Not seeing that code snippet in context, I'm taking it at face value that a tuple is what is needed. Well, then we're arguing about different things. I'm seeing two IO actions bound to bid and now.
For me it's very important how I take apart monad transformer layers. With Ether I can `runStateT` to satisfy one `MonadState` constraint and continue working with another. With merged layers I can't. f :: MonadState (Int, Bool) m =&gt; m Char g :: MonadState Int m =&gt; m Char Try invoking `f` from `g` to get what I'm talking about.
I'm new to Haskell, can someone explain what those statements mean?
I don't follow your example. Wouldn't `runReaderT f True` be a type error? I'm not talking about the absence of the `Proxy` argument, but rather the fact that the type of `True` does not match the type of the environment required by `MonadReader`.
He is right that the `ether` approach makes it easier to run one Reader 'layer', leaving the other in place. This is made a little unclear by the fancy types of f, g and h. I was going to recommend this as the correct talking point. 
I never argued it was impossible, but then you'd have to write those `run` functions for every possible way of nesting one environment inside another. If we don't restrict ourselves to 2-tuples, then we have to write functions for tuples of all possible lengths. For all effects (`MonadReader`, `MonadWriter`, `MonadState`). Don't forget that `MonadState` can be deconstructed in various ways (`evalStateT`, `execStateT`, `runStateT`). Oh, and there is also `ExceptT`, for which we would have to work with `Either`s, not with tuples. But let restrict ourselves to 2-tuples. Consider those functions: f :: MonadReader (a, (b, (c, (d, (e, ()))))) m =&gt; m r g :: MonadReader (a, (c, (d, ()))) m =&gt; m r I don't think that boilerplate glue to call `f` from `g` is going to be even readable.
http://fpcomplete.com/ is the best bet for magna cum laude guys.
`a $ b c d e` is just an alternative syntax for `a (b c d e)`. So in normal English: we want to avoid "success at all costs" which is quite different from "avoid success, at all costs".
I'll agree that it can be a bumpy ride if you expect the same level of support that you get from Visual Studio. In case you're willing to try something lighter, you could use vim/emacs + ghc-mod, which will give you good autocompletion and error highlighting (although the learning curve for vim may not be worth it, of course). I think there are plugins for integrating ghc-mod with other editors like Sublime Text, so that might be worth a try.
`zoom` and `magnify` are fully compatible with Ether, by the way. They want `MonadReader` and `MonadState` from mtl, which you can provide for a tagged effect via the `ethered` function. ethered foo $ zoom _1 $ do -- something here 
If I'm not wrong we talked in the other thread where I asked about IDEs for Haskell. I thought I did it but then I found out that some things weren't working because of some errors. So many hours wasted... :(
I know, was just to add some humor :p as misinterpreting the motto is a common joke.
So, there's [stack](https://www.fpcomplete.com/blog/2015/06/announcing-first-public-beta-stack) which is just coming out, and seeks to make the whole "getting started with Haskell" thing nicer. The best editors for Haskell are emacs and vim. Both have quite good tooling support in the form of plugins, with emacs probaby coming out a bit ahead. [Spacemacs](https://github.com/syl20bnr/spacemacs) is a pretty good batteries-included option if you're willing to give it a go. Enable "haskell-mode" in the .spacemacs file and you'll be set. I've heard that Sublime Text and Atom also have decent Haskell plugins, though I have no experience with those.
ghci_mod didn't work, but now that I think about it, I didn't try Atom on Ubuntu. On Ubuntu I installed the haskell platform which comes with cabal 1.16 and ghc 7.6.3!!! Maybe I should try something newer but how? I'm not a Linux user.
Hmm, but `z n = [1..n]` doesn't have free variables. It therefore is a CAF, by your definition.
You can get a Amazon EC2 micro instance free for a year. Even after the free period expires the cost of the instance is pretty much negligible. 
I use Digital Ocean, it's $5/mo.
I usually use [this](https://github.com/bitemyapp/learnhaskell/blob/master/install.md) to install ghc and co. on ubuntu.
https://github.com/begriffs/haskell-vim-now
how do I enable "haskell-mode" in spacemacs? I'm trying to checkout spacemacs, coming from vim. I have the dependencies install and on $PATH and I add `haskell` to the list of `(setq-default dotspacemacs-configuration-layers '(...))`. this got me syntax-highlighting and I can use `SPC m h t` to get a known function's type, but I would like to get type errors, lints, auto-completion and more types of value under cursor. can you help? pretty please? :)
https://en.wikipedia.org/wiki/Exception_that_proves_the_rule
`a` and `b` are arbitrary types such that type `a` belong to `RealFrac` type class and type `b` belongs to `Integral` type class. 
The rationale for having them is described in "Tackling the Awkward Squad: monadic input/output, concurrency, exceptions, and foreign-language calls in Haskell", chapter 5 *Exceptions and timeouts*. &gt; All these events [errors] are (hopefully) rare, but they are all unpredictable. In each case, though, we would like our web server to recover from the error, and continue to offer service to existing and new clients. We cannot offer this level of robustness with the facilities we have described so far. We could check for failure on every file operation, though that would be rather tedious. We could try to avoid dividing by zero — but we will never know that we have found every bug. And timeouts and loops are entirely inaccessible. They were implemented because they were relatively simple and reasonably powerful as a failure mechanism.
For skipping two, you want "owl eyes" (avoiding the less community-inclusive name for it some people use): ((.).(.)) But that doesn't generalize nicely beyond two.
I think this would be a great thing. How could anyone write a Spark clone in Haskell without Semigroup being a superclass of Monoid. It makes no sense!
I'm interested in helping you get a working Haskell environment. Have you tried [Leksah](https://github.com/leksah/leksah/wiki/Leksah-0.15.0.2)? If everything installs without issue, I think it might be your best option. Is using Emacs or Vim out of the question for you? Even if it just means [just following these steps](http://sachachua.com/blog/wp-content/uploads/2013/05/How-to-Learn-Emacs-v2-Large.png) for Emacs? If so, that's fine... if Emacs is an option for you though (even only using basic features) I'd highly recommend it since it's what I use and can vouch for. If you just want a working environment now, I agree with /u/camaiocco about [FP Haskell Center](https://www.fpcomplete.com/page/project-build). Perhaps try it and let me know if it's missing any of the features you are wanting? I've also tried Intellij and couldn't get Haskforce installed. Though I didn't put much effort into it because Intellij was always kind of slow for me as well. I haven't tried EclipseFP because last time I tried Eclipse it was pretty slow for me as well. I used to be a big vim user, but haven't tried making a Haskell environment in it yet. However I think [haskell-vim-now](https://github.com/begriffs/haskell-vim-now) as /u/scientia_est_ars recommended would be best.
Did you try installing the Haskell Platform? It kind of encompasses the complete installer/package with language requirement. True, there isn't an IDE, and I don't really notice it cause I'm used to a vim/cmdline workflow, so I can't really comment on how significant that is. Also, yes, installing and configuring makes using Haskell difficult, but isn't it that way with a lot of software? I remember the first time I tried installing Arch Linux I had no idea what I was doing and configured the boot loader incorrectly and had to start over. But, the next time I tried, I had figured out most of the installation process and installed it successfully. Of course, then I messed up installing the window manager and the graphics card drivers, but eventually I got it all to work. It just took a lot of persistence.
Could you expand on that a bit? I can see how ```Applicative``` and ```Monad``` are essential, but how would one be unable to survive without ```SemiGroup```?
Yes, please do it already!
I don't use spacemacs specifically but I do use emacs. Some of the extensions for haskell require executables from hackage. Do you have `ghc-mod`, `hoogle`, `hlint`, `stylish-haskell` installed? Spacemacs also seems to support `ghci-ng`, `hindent` and `structured-haskell-mode`. I also use `codex` to generate ETAGS for a cabal project and all dependencies (requires `hasktags`). So, as a start try `cabal install ghc-mod hoogle hlint`. 
yitz was relating an experience he/she has had with Haskell that he/she feels parallels the experience OP was looking for, made a good point that static analysis in most conventional languages is *hard* and therefore IDEs don't really understand your code, and yitz was also relaying a possible reason as to why the Haskell ecosystem doesn't have these tools. I don't see anything irrelevant or smug here. IDEs have not historically been a thing we care about, therefore they languish. If you're so concerned, write an IDE.
&gt; This doesn't mean that I've never used simple editors. ...wait, I hope you're not mistaking Emacs or Vim for "simple editors". Don't be fooled by their modest appearance... Emacs is actually a fully fledged operating system in disguise... ;-)
I probably would have used `ethereal` for your `ethered`, and `etheric` for your `ethereal`. The difference is that "ethereal" is a modifier that can be applied (or not) to any abstract object, while "etheric" is an inherent quality that can't be separated from the thing it describes. Put another way, `data Ethereal a` and `class Etheric`. :)
This is a long thread, so I must have missed it. Could it possibly be that no one linked [Chris Done's blog post](http://chrisdone.com/posts/haskellers) about this?
I would probably write it as you have written it. I don't really want a completely revamped syntax for type signatures, just some syntactic sugar for common cases. (Obviously, this would backfire in many ways – confused beginners, etc. I know. It's a wishlist thing, not a rationally evaluated Haskell improvement proposal.)
Which new instance do you have in mind? There are at least two: instance Monoid a =&gt; Monoid (Maybe a) where mempty = pure mempty mappend = liftA2 mappend instance Monoid (Maybe a) where mempty = empty mappend = (&lt;|&gt;)
That one would be easy: Enum -&gt; Enum, because both parameter and result are of the same type. Of course if you have (Show a, Show b) [as someone else pointed out](http://www.reddit.com/r/haskell/comments/39u17p/beginner_why_are_function_definitions_written/cs6gu40) you do have a problem
&gt; ghci_mod didn't work, but now that I think about it, I didn't try Atom on Ubuntu. If you were using the standalone GHC (7.10), the version of Cabal (1.22) that came with it had incompatibility issues with ghc-mod ([#437](https://github.com/kazu-yamamoto/ghc-mod/issues/437)) for a lot of people. I wonder if this is what you ran into. GHC as packaged with the current Haskell Platform release (2014.2.0.0), which would be 7.8.something, builds ghc-mod without any problem, as it comes with an earlier Cabal release. At any rate, it's awesome to hear that you're gonna try again in a year. It really is a fascinating language. Hope things are better for you the next time around!
Once we make `Semigroup` a superclass of `Monoid`, less will be broken. But it's still two different types, so there will be cases where type inference will get it wrong. One quick example: GHC doesn't always generalize types in `where` clauses. So an expression in a where clause without an explicit type signature could be typed as `Semigroup` where until now it was typed as `Monoid`. That would lead to a new type error if you later try to use `mempty` in a context whose type unifies with the type of that expression.
And while we're breaking stuff, can we go with (+) and zero instead of mappend and mempty? It's mmadness.
The one which corresponds to the use of `Maybe` for modelling failure with prioritised choice. The name goes with the semantic idea, even if there are other semantic ideas which involve representationally isomorphic structures. No instance of `Alternative` or `MonadPlus` should ever do other than duplicate a `Monoid` instance. And when we have higher-order constraints, we should dispose of the surfeit of operators. I'm in a cleft stick here. I don't like the fact that Haskell effectively prioritises control operators over boring effectful operations. But that's the situation and it's not going to change. Accordingly, the monoidal structure that comes from the Maybeness of a Maybe type should be prioritised over the lifting of monoidal structure on the underlying value type. That is, `Maybe v` is the type of *computations* for *v* which have failure and prioritized choice, not the type of *v* values in the presence of failure.
Fair enough. I could see something like that being nice in addition to what we currently have. Also, I like what you did with IO' there. I think that really helps improve readability!
Emacs is the best IDE I have used for any language by and far.
On Windows 7 64bit SP1 * installed MinGHC 7.8.4 (64) https://github.com/fpco/minghc * installed Atom * installed ide-haskell * installed language-haskell * installed autocomplete-haskell * installed haskell-ghc-mod ==&gt; ERROR! Haskell-ghc-mod: ghc-mod failed with error code 1 'ghc-mod' is not recognized as an internal or external command, operable program or batch file. I'll try to install ghc-mod with `cabal install ghc-mod`. It says: C:\Users\Kiuhnm&gt;cabal install ghc-mod Resolving dependencies... All the requested packages are already installed: ghc-mod-5.2.1.2 Use --reinstall if you want to reinstall anyway.
I'm sorry you interpreted what I wrote as an attack - I really didn't intend it to be one. Haskell is 20 years old as a research language, but very new as a mainstream-track language in industry. I agree with you that the toolset has plenty of room for improvement. My points were: * There were reasons why until now not as much has been done as could have been. * Now that Haskell is quickly gaining popularity as a commercial development language, a lot more is being done. * But the result of that will be quite different than what you are used to in an IDE that is fine-tuned for languages that are very different in nature than Haskell. * Since a very different kind of IDE is needed and we can't just write a regular plugin for an existing one, it will take time until we get there. In short - it's going to be a fascinating journey. If you're interested - why not jump in and join the fun?
I'm actually heading through Florence on the way to Bologna tomorrow. I don't have too many plans behind getting on a train.
Previous thread on the subject: http://www.reddit.com/r/haskell/comments/30s1t2/proposal_make_semigroup_as_a_superclass_of_monoid/cpveavt?context=3 
We're actually in the process of working on implementing this proposal based on an earlier proposal this year.
I can probably help with spacemacs :). Read this: https://github.com/syl20bnr/spacemacs/tree/master/contrib/!lang/haskell then, if you have problems, either pm me here on reddit or go to the gitter chat of spacemacs and ask there.
I used GHC 7.8.4 because someone warned me of that problem. If you use the Haskell Platform on Windows, `cabal init` doesn't work because cabal 1.18 has a bug. I updated cabal to the 1.20 version but had other problems...
Ugh! I should have done a little research before I stirred this one up all over again. Thanks for the link, though.
What are the killing features an IDE gives you (apart from having to relearn everything each time you try a new language?) that you can't live without ?
&gt; No instance of Alternative or MonadPlus should ever do other than duplicate a Monoid instance Why would you want two type class instances to do the exact same thing? That seems like a waste of an instance.
First off, I am not op merely someone who experienced the same when I first began. Secondly I may have been a bit harsh, because I know you don't do it on purpose. It is just, I remember how annoying comments like that was when I getting into haskell. And while they fine points on their own to bring up. They don't belong on thread about someone completely new to the language, who is already feeling overwhelmed.
if you ran `cabal install ghc-mod` outside a folder that is a sandbox, you should be able to use `ghc-mod` in your console. If that is the case you should be able to run `where ghc-mod` to find it(assuming you have msys, coming with MinGHC). If you run `ghc-mod` in your console what happens?
Do you have some concrete examples? I doubt that I have ever used that `Monoid` instance in my own code, and I can't remember ever having come across it being used that way in a library in any obvious way.
I'd like to have: * good auto-completion + inline documentation * good debugger + REPL * smart indentation and formatting during typing * errors / warnings / types annotations in the code * refactoring (maybe less useful in Haskell???) ... and the IDE must be **fast**. It's OK if the annotations are delayed, but the typing, the formatting, etc... must be instantaneous. Also, I'd like to have the column selection mode.
Of course, silent change is a legitimate concern. It's time programming language design acknowledged change over time. Instead we have 1984ism, where everyone has to update with whom they have always been at war.
&gt; split off tack unwinding from exception handler search woah, never thought about it like that before. so instead of try/catch, you'll say "handling this error within this subexpression" or something?
Personally, I happen to think that the Maybe-as-upgrading-a-semigroup-to-a-Monoid instance selection is perfectly reasonable. I'm not in a hurry to push for all monoids being consistent with an unrelated class on a completely different kind in another hierarchy. Many folks like Monoids to use `mappend = liftA2 mappend`, and `mempty = pure mempty`, as it is a reasonable choice with even more instances than the one you favor here, which is also inconsistent with your vision, so I don't think you'd get uniform acceptance. There are far more of those out in the wild than cases where it lines up with `MonadPlus`/`Alternative`. The one real "go to" example of your proposed law is `[a]` -- which gets its status as such by being the free monoid, so any other instance would be quite surprising! The current Maybe-as-upgrading-a-Monoid-to-a-Monoid is just terrible, however.
But there are several ways to interpret `Enum -&gt; Enum`! Enum a =&gt; a -&gt; a (Enum a, Enum b) -&gt; a -&gt; b Enum b =&gt; (forall a . Enum a =&gt; a) -&gt; b
A regular happening in my world is that I write down a newtype constructor with the semantics I want, for which the Monoid rules would derive me a monoid, but because of this particular instance, it's not the monoid I want to use for the `Alternative` and `MonadPlus` instances. I am forced to write the bloody thing myself. The automatic derivation works compositionally at the * level, but the instances I really need are for * -&gt; *. Instead, I get random instances which are nothing to do with the conceptual meaning of `Maybe`. Much like I want Applicative and Monad to be consistent, I want monoidal structure to be consistent.
* good auto-completion + inline documentation decent auto-completion + out of editor documentation with haddock. * good debugger + REPL yee.. we still can't get a proper stacktrace, seemes like its impossible to make, all debugging is based around unit tests. * smart indentation and formatting during typing Hmm.. you'll learn quickly how to type/format pretty. * errors / warnings / types annotations in the code got it! * refactoring You mean find/edit right?
Wouldn't you be able to use the derived `Alternative`/`MonadPlus` instance? Many type constructors of kind `((* -&gt; *) -&gt; (* -&gt; *))`, like `StateT`, lift `Alternative`/`MonadPlus` instances correctly, analogous to how `Applicative` type constructors of kind `(* -&gt; *)` will lift `Monoid` instances: instance Alternative m =&gt; Alternative (StateT s m) where ... Is there a specific type constructor you have in mind that does not lift `Alternative`/`MonadPlus` in the way that you desire?
Wouldn't it be nonlinearity that's the effect (or rather, coeffect)?
I just read that one should indent `if then else` like this: f x = if &lt;long boolean expression&gt; then 1 else -1 Therefore, an IDE should put the cursor under the if automatically. Regarding refactoring, many of the most sophisticated features are related to OOP so I don't know what it'd be possible with Haskell.
You get pretty much that in Emacs/Vim. The main difference I've seen between IDE vs Emacs/Vim is IDE are usually "mouse centric". Being able to touch type usually reduces lots the need of a mouse.
I look at things like IDEs as productivity enhancers. Nice to have, but not strictly necessary. When I am learning something new, I am not going to be productive. In fact, too much tools and bells and whistles can be distracting for me. Maybe I'll try to learn something by slavishly repeating what the tutorial or learning material is doing. Not to mention all the reimplementation of "standard" stuff -- not something to do when you want to be productive. Personally, and especially if I was learning Haskell for the "enlightenment" experience instead of for doing some specific with it, I wouldn't feel much need for productivity enhancers. Not initially. Though I have to admit to trying out some Emacs Haskell packages. For the long term though, yeah, I might be concerned if I was planning to become *good* and *productive* with something (instead of just learning some of it, then re-evaluating if I want to continue learning it).
What I like about Windows (as opposed to Linux) is that you can do simple things without any prior knowledge because the interface is intuitive. Visual Studio is an example of such an approach. Moreover, you learn by doing because every menu and option tells you the corresponding keyboard shortcut and so you become more and more efficient.
First, it's worth noting that multiple `filter`s can be combined into one - it corresponds to the logical conjunction of all the `filter`s. Next, I'd note that both of your case analysis statements send `Nothing` to the list being filtered - that is, they are the same as `filter (const True)`. So, let's see how these ideas play out. First, I'm going to move the `case` statements inside each `filter`: filterByDate :: HasDate a =&gt; Maybe Date -&gt; Maybe Date -&gt; [a] -&gt; [a] filterByDate startM endM as = let as' = filter (\a -&gt; maybe True (fmap (a &gt;=) startM)) as as'' = filter (\a -&gt; maybe True (fmap (a &lt;=) endM)) as' in as'' Next, I want to combine those `filter`s into one. We have a few options. One is to directly combine the `Bool`s with `&amp;&amp;`: filterByDate :: HasDate a =&gt; Maybe Date -&gt; Maybe Date -&gt; [a] -&gt; [a] filterByDate startM endM as = filter (\a -&gt; maybe True (fmap (a &gt;=) startM) &amp;&amp; maybe True (fmap (a &lt;=) endM)) as Finally, we can tidy this up a bit: filterByDate :: HasDate a =&gt; Maybe Date -&gt; Maybe Date -&gt; [a] -&gt; [a] filterByDate startM endM = filter (\a -&gt; maybe True (fmap (a &gt;=) startM) &amp;&amp; maybe True (fmap (a &lt;=) endM)) Hope that helps!
I had to update cabal because `cabal init` didn't work. Now I have two cabal's (in completely different dirs). I hope that isn't a problem. Unfortunately, now I have this bug: https://github.com/atom-haskell/haskell-ghc-mod/issues/23 You see why I gave up!?
Can you tell me what version of Leksah you were using? Can you give me some steps to reproduce these things?
I really think it's very sad if the meaning of things when seen as components of the *-&gt; * hierarchy are so separate from their meaning in the * world.
Meanwhile, please explain why it is actively good design to make `Maybe` mean both lifted semigroup and failure-with-prioritised choice. Speak up positively for the status quo. Go on.
Why?
yeah, it's more like (*) implies (+), otherwise it would be (+).
Basic reading comprehension of types.
There's a hard limit to how efficient I could become in Windows, and I hit it, hard, years before I switched to Linux. I had thought I knew all there was to know until that point, but Linux opened my eyes. 9 years later, I still have to work on Windows at work, and I hate it. Everything grinds to a halt for me, and literally eveything is more difficult. Some things are next to impossible, and many are just a *little* bit worse, but pretty much nothing is better. I call Windows the "Death by a Thousand Cuts." This has been my experience this past decade. To me, the cost of discoverabilty is speed and composability. UIs let me do only what they've decided well ahead of time what I'm allowed to do.
OK then, I'm sorry. Glad to have you on the record. If we had a type-and-effect system, I'd agree with you. But just as I think it's important that `[]` induces the free monoid structure, rather than lifting that of the underlying value type, I think the same should hold of `Maybe`. That is, the inherent useful monoid structure characteristic of the head of the type (if there is one) should take priority over the parameter.
The latter is a tedious travesty. The former speaks for itself. It's my bedtime.
Why not make it a subclass instead? Then you can get a really simple default definition for `(&lt;&gt;)` by defining it to `(&lt;&gt;)`.
While I would like to see this, I doubt that this is ever going to happen in Haskell. There is indeed a disciplined approach toward this, you can base the numerical hierarchy on `Semigroup` and work your way up. `(+)` could also replace `(||)` for a boolean algebra notation (boolean algebra is really just a group with a dual boolean algebra that switches around the operators, think of the De Morgans laws). Again, although you could implement this in Haskell, I doubt that this will ever be standard in any way.
The Haskell Platform was supposed to be the complete installer and package with language and tools perfectly working, but everybody else seems to hate it these days. I don't know why: it works wonders for me on Windows.
I was using the newest version of three days ago (a new version was released today). As for the steps, sorry but I uninstalled everything.
How can you say that it works perfectly when even a simple command as `cabal init` doesn't work! The only thing I know is that I've never had similar problems with C++, C#, Python and Scala. I use VS for the first two, PyCharm for Python and Eclipse for Scala and everything worked perfectly on the first try.
I cannot reproduce your problem. `cabal init` works for me. What version of the Haskell Platform are you using? The one I have currently installed is the Haskell Platform 2013.2.0.0, which was two years ago, so perhaps something broke between then and a more recent version?
I don't believe that you can add auto-completion and refactoring as easily as you make it sound. I'd probably be better off writing my own IDE from scratch if I wanted the perfect solution (for me).
Yep, mine is the 2014.2.0.0. I had to update cabal to the 1.20.0 version to make it work. But neither EclipseFP, nor IntelliJ nor Atom work correctly. There's always some problem...
I'm pretty happy with the amount of reported issues this release has fixed (the issue tracker says [100 of them](https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2), but that's a bit inflated), so if you get a chance, *do* test it so I can just kick it out the door next week and be done with it. That'd be swell. As usual, thanks to all the users for their reports. Tentative release notes [are here](https://downloads.haskell.org/~ghc/7.10.2-rc1/docs/html/users_guide/release-7-10-2.html).
No it's not. Idris is strict by default, and has a different design philosophy behind its implementation of type classes. Both of these things have a pretty big impact on the style of programming which can be adopted in the language. Don't get me wrong, Idris is great, but it's not exactly what I'm looking for as my next favourite language to get things done in.
I've been playing around with [subhask](https://github.com/mikeizbicki/subhask) which opts for (+) and zero, and the numerical heirarchy are instances of Semigroup as you suggest.
Perhaps "extract function/module/etc", "make pointfree/pointful", "convert top-level if-then-else to guards/vice versa", etc? Man, all of this is really making me want to write a Haskell IDE.
Because not all semigroups are monoids. A monoid is required to have a unit `mempty`, whereas a semigroup needs only the associative binary operation `&lt;&gt;`.
Okay seriously, does this kind of decision still happen on a *mailing list* because of genuine issues with all other options? Is there a reason beyond simple inertia to pick such an awkward venue?
To each their own, but it's not necessarily as difficult as some might make you believe. There already exist numerous frameworks for this kind of stuff. Look up YouCompleteMe - it's basically an API between Vim and almost whatever you're using to compile or interpret your code. On top of that, it does just come with bindings for C/C++ over Clang, but there are dozens of other language bindings out there, ripe for the download! /shameless plug for YCM
I'm still very much in the process of becoming a good Haskell programmer, so I'd like to ask the advice of some of the more experienced people in this thread. I get the impression from responses thus far that it's not a good idea to use `error`, etc., to deal with, say, bad input by throwing an exception. If I'm writing a very short program (say, &lt; 100 lines) that I will nonetheless need to tweak, would the best error-handling mechanism be to just do everything in the `Maybe` monad (since that's the simplest error-handling monad)? Edit: to expand a little – the main reason I might use `error` is because it offers an easy way of throwing helpful error messages, which are helpful for debugging purposes. I could achieve a more sophisticated and pure version of the same thing by making my own error type and making it an instance of `Error`, but that seems like way overkill for a short program. `Maybe` can't provide error messages, and there's nothing computationally-intensive or potentially dangerous in this program, so might `error` be acceptable after all?
FYI there are two duplicate lines in the known bugs section of the release notes.
[Fixed](http://git.haskell.org/ghc.git/commitdiff/a9c540eb173720584c606d75430b3f55e9fd157d).
To be pedantic, bottom is a member of every type, so `foo x = foo x` and `foo x = undefined` are also valid functions of type `a → a`.
&gt; I can imagine having something that is focused specifically on the topic of library proposals, is archived, searchable, and can host a thoughtful discussion over a span of months is helpful to the goals of the libraries committee. Agreed. But a hosted forum, or even a newsgroup, would satisfy all those constraints with the added benefit that _for new users_ the interface for the archive and search is the same as for actual participation. If I join the mailing list now, I don't get twenty years of emails that I can browse for context; I have to go to the web archives, and holy shit are they ugly and hard to navigate, because email formatting conventions are a different world and threading is not an inherent concept. Make it a newsgroup and Google takes care of most of that for you now, *plus* you still have the option of downloading it all to a local client for offline access if that's still a concern for anyone (it might be). Forum software loses the latter benefit, but gains twenty years worth of improvements to organization and interface. I get how it would be an inconvenient transition for existing users, because their own local archives would no longer be in the same place as new conversations. But that's exactly the price being levied on newcomers, and I don't see a reason beyond "been there, got mine, your turn." Granted it could be a deliberate barrier to entry, to cut down on chatter. Putting aside the likelihood that chatter would be less of an issue in a more modern format, at least this would be a *reason*; I could accept it. Not agree with it, and not want to interact with a bunch of exclusionary hipsters, but the wall would have a stated purpose and I could just walk away from it. But I'm pretty sure that's not the case, and it's mostly just inertia as I surmised. And I think it's causing problems. Despite really wanting to participate, I still haven't been able to hold my nose long enough to subscribe to yet another load on my inbox, and I don't think I'm _such_ an outlier that nobody else is similarly dissuaded. So this is me agitating to bring attention to the issue. (In a place where the chance of decision-makers paying attention is very low. Never said I was a *good* agitator...)
Cool - that makes sense. I guess I'd just kind of forgotten about newsgroups :) There would be some unknown-sized risk that you might lose more people who are already participating and are happy enough with a mailing list than you'd gain from migrating to something else. Would be interesting to see what the people involved with the list thought. I'm basically for anything that gets more people involved - although with all other things being equal I'd rather not lose anyone who has already been participating. Good luck with the agitation :)
Just found https://visualstudio.uservoice.com/forums/293070-visual-studio-code/suggestions/7756542-haskell. Might be exactly what you're looking for, OP.
Even if I miss out on a few features in a polished IDE, I get a significant return on time invested by working with Emacs for most tasks. Most of my Emacs functionality is consistent and reusable between the various programming languages I use as well as daily tasks. I am in control of exactly the features I want and how they behave. If I need to modify some piece of functionality or add a feature, I am able to customize that using lisp and an extremely large and rich history of documentation and functions to learn from. It's also supported on a very large amount of platforms. I have used IDE's in the past. They still have a learning curve and they still don't work from time-to-time. If there was a feature in an IDE that I absolutely needed then I would probably use it for that specific task and still stick with Emacs for the majority of my work. Some Java tasks might just be that exception. I understand this is not everyone's cup of tea but it's frustrating to see posts like this when so many of the benefits of a modern IDE for Haskell are available right now (jump to source, integrated REPL, on the fly recompilation and source annotations, code formatting, jumping to and from errors, auto-completion, inline documentation, integrated hoogle, even refactoring). Most of that functionality is built on tools which aren't even specific to Emacs! 
Not really fair. OP didn't even manage to get his toes in the pool, just stared longingly at the water while fiddling with the rusty latch on the gate...
Dart is by Google, who can just throw money at it until it shines. Even so, its only compile target is JavaScript. Scala is built around the JVM. Its purpose is *literally* to be a better Java. So it too has only a single compile target, and tools designed for Java can be adapted without much hassle. Haskell targets native binaries across multiple architectures and OSes. ~~(In fact, so far as I know, typeclasses are impossible to represent efficiently on .Net or JVM; taking advantage of one of those ecosystems isn't even an option.)~~ GHC is tuned for time optimization of lazy behavior, and space optimization of immutable structures, two concerns few other languages have; and it does a good enough job to frequently rival languages that were *designed* for performance. And thus far it's been maintained primarily by a loose association of department heads, postgraduate students, and a few interested non-academics, all of whom do other things full time. I think you're comparing apples and oranges to Haskell.
Sounds good to me. Especially given some of the related stuff you've discussed before, I'd be interested - and I definitely don't think it would be offensive or disruptive. If you're unsure about that, and you're going to blog, I'd suggest setting up Google Analytics on your blog. Not everyone votes on things on reddit, but the number of viewers / average time on the page stats can certainly be motivating :)
Thanks for all the answers. It's day 3 of learning Haskell and there really is a lot for me to learn (and unlearn).
That's a good thought! Thanks for the advice.
thanks! I have followed this guide with only some success. I will contact you soon :)
Hmm, that does make sense. I recall Eric Lippert commenting in his blog that some types available in Haskell aren't feasible in .Net languages, and since neither F# nor Frege (on JVM) supports typeclasses my mind locked on them.
Probably Lippert was referring to higher kinded polymorphism, which is incompatible with .NET's reified generics (but not with the JVM's weaker reflection capabilities). It seems like it ought to be possible to fix that, though.
&gt; Agreed. But a hosted forum, or even a newsgroup, would satisfy all those constraints with the added benefit that for new users the interface for the archive and search is the same as for actual participation. If I join the mailing list now, I don't get twenty years of emails that I can browse for context; I have to go to the web archives ...and that's what http://gmane.org/ is great for... it exposes most relevant mailing lists via NNTP, and allows you to instantly access a malinglist's past discussions in your MUA (assuming your MUA also supports NNTP-folders), with proper mail headers allowing to reply w/o breaking the threading (which is one of my pet peeves...)
The property that for any type class C and any type T, there is a guarantee that instances C T are globally unique, so if you obtain two of these from different places, you know they're actually the same instance, and don't have to worry about which one is being used. It's not enough, for instance, to allow people to define whatever instances they like without checking for overlaps and then just pick whichever one you find first when trying to decide on an instance. Apart from data structures with invariants like Set/Map and their relationship with Ord (using two different orderings screws everything up), things get even more subtle once you have existential types with instances packed away in them, perhaps being unpacked by functions that also explicitly get an instance of the same class. Since you're not explicitly supplying the instance parameters, you *really* don't want to have to worry about which instance is getting passed along by the compiler, and the only reasonable way to not have to worry is if that instance is globally unique.
That would require some sort of region or linear types, which AFAIK aren't implemented as part of inline-c. In general, because Haskell is garbage-collected, "destructors" / "finalizers" are generally called by a finalizier attached to a ForeignPtr, IIRC. My practical experience linking C and Haskell is quite limited.
Semigroups and groups are usually written with (*) and one instead of (+) and zero. "One" is then the identity element, while "zero" is an absorbing element. The notation (+) is often reserved for Abelian groups (commutative groups) In Haskell the issue is that there are at least two ways in which numbers form a monoid: with (+) and with (*). Which one should we pick as the standard one? And what to do with the other? IMO there is no right answer other than to be explicit about it, which is the current situation with the Sum and Product newtypes.
The code looks similar to a try-catch but it allows you to e.g. decide to return a value from within the catch that can then be used at the position of the throw to continue execution (e.g. if the exceptional situation is a 'can not parse this unicode character' you could decide what to use as a replacement character for each occurrence).
For the record, https://ghc.haskell.org/trac/ghc/ticket/10365
Isn't (+) mostly used for abelian groups in maths though while (*) is used for non-commutative ones?
As others have mentioned, there's some excellent work in this area based on the idea that we can encode the units of a quantity using type-level integers. The `dimensional-tf` and `units` libraries are probably the current state of the art. The downside of this approach is that errors are reported in terms of numeric inequalities rather than the units they represent, exposing the underlying encoding to users of the library. This is a bit unsatisfying compared to units in F#. In [uom-plugin](https://github.com/adamgundry/uom-plugin) (see also the [Haskell Symposium paper](http://adam.gundry.co.uk/pub/typechecker-plugins/)) I've been exploring an alternative approach, using a GHC typechecker plugin to solve constraints on units directly. This should give better type inference behaviour and simpler error messages.
`Cofun` sounds scary!
For instance try to create a module with the name "chapter_2". It should fail because that's not a valid name for a module. But a beginner doesn't know that. Leksah doesn't complain but the module isn't created.
sorry about that, it is always kind of hard for me to spot duplicate posts, I looked at the last few pages of posts before posting this but I must have missed the existing link
I've taught Vim at my company, and the thing I taught was its composable language, showing how it's very like English, and thus not really hard to learn, and not thousands of hotkeys, but rather, dozens, which compose like a natural language into many thousands of statements. You 'speak' to Vim. Learn a new verb or noun, and you can fold it into the rest of sentences you know how to say. There were a lot of people nodding during the talks. They even asked things like "So, could I delete this paragraph and the next two with... d... 2... ap?" Yep! People seemed to get it. Emacs, on the other hand, seems to be thousands of things to remember.
&gt;even in cases where it's generally agreed upon that those changes would be a good thing overall. https://xkcd.com/1172/
That's just cultural conditioning. Producing fun takes work. Cofun is all about consuming the fruits of those labours.
God, all those `(&gt;&gt;?)`, `(==&gt;)`, which are actually all the same `(&gt;&gt;=)` function. I guess that could be weird and non-intuitive to a beginner, but I also think adding more and more operators might lead to misconfusion as well. It’s always simpler to learn one abstraction and reuse it wherever it’s possible than duplicating every now and then, even though it’s for educational purposes here. Just meta-thinking about that habit people have to follow when teaching new concepts. I tend to stick to known abstractions – eh, chapter **ten** and no actual use of *applicative functors* and *monads* while **LYAH** introduced them quite quickly? Am I the one only one who thinks something is wrong?
Awesome. Your first part was quite enlightening
You think you'd be better off writing your own IDE than learning how to use emacs or vim? Maybe you should just stick to whatever you're using now.
How about you go to @1HaskellADay, which gives a daily puzzle to solve, some very simple, some where you build entire 'Enterprise Solutions.' Like, today's for example. The archive of the problem sets going back a year are here, http://logicaltypes.blogspot.com/p/1haskelladay-problems-with-solutions.html
"A monad is like your mom. Everyone keeps telling you it's easy, and you really hope they're lying."
I didn't say that. I said that I'd be better off writing my own IDE than implementing all the features I need (auto-completion, refactoring, etc...) in vim/emacs.
Excellent Edward, I see that you will arrive at Florence Santa Maria Novella at 16:50. I shall wait for you at the train arrival. If there is any problem, you have my phone number. I was also going to propose to grab a bite at the central market, you obviously know Florence well :-)
Your workflow is the exact same as mine.
&gt; import and function name completion for any installed libraries so, auto-completion is already done. No need to implement anything. Refactoring is a different matter, but is so much simpler in Haskell than most other languages anyway that it would probably work very differently than in IDE's if implemented.
It's a bit unfortunate that all the examples seem to focus on handling effects from left to right in the big coproduct of effects. This could mislead the reader into believing that it is nothing but another stack of monad transformers when, in fact, it is absolutely possible to handle whichever effect you may want to. I guess the code would be a bit uglier though.
Then what the list monad does? See my paragraph about backtracking and non-determinism. The Transient monad is inherently for non-deterministic computations involving events and multithreading. For the examples of the article what I wanted to do is to make it as close in behaviour to the list monad as possible to allow the programmer to use the same intuitions.
I think you might have forgotten to wrap the partially applied `filter`s in `Endo`, but I love this answer.
Isn't Real World Haskell outdated or abandoned?
&gt; if you have used vim on linux all your life then installing is really easy and works great, but for everyone else it's a living hell I've used vim for about 15 years (on Linux, FreeBSD, and Mac at different times), and I've gotta say, getting a working Haskell setup and figuring out the tools and a reasonable workflow was still not that easy. 
You are right. It is entirely possible and valid to handle the effects in a different order. The general results in the paper allow for this (as well as adding new effects during the handling). We did not show any example of that in the paper because it requires a more involved setup, which was not the main focus.
The user has been banned, thanks for reporting, sorry it took so long to turn around.
Ah! Well, fair enough then. But we’re in 2015, and I don’t think *monads* are strange at all. Such thinkings make them strange. If you introduce *monads* to the beginners in the first place, they’re quickly demystified and people can say *“oh! that’s just that!”* whereas if you keep telling your audience that *“monads are strange and utterly hard to get your feet wet with”*, well, yeah, you just get people think that monads are hard. But they’re not.
1) Figure out the equivalent of Visual Studio or Xcode for Haskell (Leksah seems to have potential but still very hard to get comfortable) with decent debugging support 2) Figure out how to explain Monads without requiring (it would seem) everyone who reads about them feeling they have to write yet another article to explain Monads 3) Figure out how "average" programmers can develop in Haskell without having to be almost immediately concerned about performance issues (i.e. using the wrong version of fold). Regular developers shouldn't have to know the compilation environment that deeply. The recursive guide to Haskell: *No article about Monads can be understood until you have read two dozen other articles about Monads.* By the way, I believe strongly in the power and value of Haskell, but I just keep giving up trying to use it. Can't afford the time it takes to fuss with it. &gt; The Haskell community is still trying to figure out how to make the on-ramp easier. It can be frustrating at times, but I believe it's absolutely worth it in the end.
Perhaps, the construction of the source data takes a considerable amount of time inside the measured evaluation. And it appears in both compared expressions. If we are interested in comparing the implementations of `reverse`, we'd want to substract that common part. (Actually, I'd expect much more than being 2-times faster.)
Ok, you may have a wrong impression because the FPcomplete environment run the threads within a single core and the thread example present them with no interleaving. But you can run the examples in your computer and see how this interleaving happens.
Even in a completely explicit stack of monad transformers, "it is possible to handle whichever effect you may want to". There is no need to handle things from left to right, though the things themselves may be thought of as running 'from left to right'. You just need to remember where you left it, which is an unusually minute intellectual demand. import Control.Monad.State import Control.Monad.Writer import Control.Monad.Reader import Control.Monad.Morph import Lens.Simple import Pipes import qualified Pipes.Prelude as P p :: Producer Int (WriterT String (StateT String (ReaderT String IO))) () p = each [1..3] &gt;-&gt; arbitrary_stack r :: Producer Int (WriterT String (StateT String IO)) () r = hoist (hoist (hoist readerHandler)) p e :: Producer Int (WriterT String IO) () e = hoist (hoist stateHandler) r f :: WriterT String IO () f = runEffect $ e &gt;-&gt; P.print g :: IO () g = execWriterT f &gt;&gt;= putStrLn -- &gt; g -- -- -- 1 -- a -- -- 1 -- -- -- 2 -- b -- -- 2 -- -- -- 3 -- c -- -- 3 -- --1a--2b--3c readerHandler = runReaderT ?? "" stateHandler = evalStateT ?? "--" writerHandler = fmap fst . runWriterT arbitrary_stack = forever $ do n &lt;- await a &lt;- get tell a liftIO $ putStrLn a &gt;&gt; print n str &lt;- liftIO getLine tell $ show n ++ str b &lt;- ask liftIO $ putStrLn b tell b put (a ++ b) yield n 
Yes.
Thanks for your help. No need for apologies.
A neatly packed way to call with convenient optional literal arguments. Nice Hackage haddock documentation. I anticipate the need for some deconstructor like `maybe` in case you feel like being point-free instead of pattern-matching, e.g. `greet = option "Hello" ("Hello, " ++)`. Also, does an `IsList` instance also make sense, for further convenience?
possibly useful? ofMaybe :: Maybe a -&gt; Optional a toMaybe :: Optional a -&gt; Maybe a default :: a -&gt; Optional a -&gt; a
Yes, I was only objecting to this remark of gallais: &gt; This could mislead the reader into believing that it is nothing but another stack of monad transformers when, in fact, it is absolutely possible to handle whichever effect you may want to. which definitely *will* mislead many readers into thinking that 'it is not possible to handle whichever effect you may want to' even in a grotesque explicit `transformers`-style stack. 
A shameless self-plug. Here's how you can implement this library on top of [Ether](https://hackage.haskell.org/package/ether): ethereal "Br" "br" type Break = ExceptT Br break :: Monad m =&gt; r -&gt; Break r m a break = throw br loop :: Monad m =&gt; Break r m () -&gt; m r loop m = handleT br id (forever m)
Possibly both
That has been rapidly changing for the last 10 years or so. I would argue that for the last 4-5 years it has been the other way around, there are linux distributions featuring GUIs that are far more intuative to new users than the Windows GUI (but of course most people are already used to Windows by now). 
My plan is to propose adding a generalized version of `toMaybe` to `Data.Foldable`: -- You could implement this more efficiently toMaybe :: Foldable f =&gt; f a -&gt; Maybe a toMaybe = listToMaybe . toList Then you could use the `Foldable` instance for `Optional` to use this function. Similarly, you can generalize `ofMaybe` to work for any `Alternative`: ofMaybe :: Alternative f =&gt; Maybe a -&gt; f a ofMaybe Nothing = empty ofMaybe (Just a ) = pure a I'll probably add something like `default`, too, although under a different name since `default` is a keyword.
Alright, I'll add something like `option` I really want an `IsList` instance, but the problem is that the `IsList` type class requires a `toList` method which round-trips with `fromList`, which the `Optional` type cannot provide. I would prefer that `IsList` had a `FromList` super-class for types that support list literal syntax but that do not support list pattern matching syntax.
Yesterday I installed Ubuntu to try the Linux version of Eclipse with EclipseFP. I needed to create a desktop icon for an app. In Windows I can create a shortcut on the Desktop with a click whereas in Ubuntu it appears that one have to create a .desktop file by hand (or so a guide I read said), which implies that one must know its format. Is this supposed to be user-friendly and intuitive?
You can drag-and-drop from the Unity Launcher menu or from the context menu if you right click the application in the file manager. But shortcuts on the desktop aren't used in the same way as in windows. Most people use the launching method their desktop environment provides (in Ubuntu with Unity, this is the Launcher menu). 
I'm not sure how to write the proof of this, but the form State -&gt; [Event] -&gt; State is isomorphic to Auto Event State where Auto is an arrow in the arrowized-FRP semantics (see a library like YAMPA). However, the model using Auto is much more convenient for writing subcomponents and composing them later, as each subcomponent can have its own 'memory' (technically, stored inside its Auto's closure).
I think it's worthwhile having default blind types so that they can be used as a substrate for building non-blind versions wrapped in suitable newtypes.
I've wanted this for so long. Thanks for suggesting
Wouldn't implementing it in CPS yield better performance? Otherwise there's going to be a pattern match for each bind (something the compiler might optimise away though).
AMP was universally supported. FTP was not so clearly a smart idea and was controversial. Anyway, they were indeed both implemented in 7.10, so no point beating a dead horse.
I also take "exception that proves the rule" to indicate a situation where one *notices* or *perceives* an anomaly, which inspires awareness of a previously-unnoticed pattern.
I suppose the parentheses makes it look less like `loop` is somehow a special construct.
Obligatory meta-comment for voters: Please don't downvote comments below zero on grounds of "wrongness." That's not a helpful use of the voting system; it *reduces* the signal-to-noise ratio, because readers can't tell whether a -5 comment, which is hidden by default, is offensive garbage or a constructive question like this one.
That's in [this one](https://hackage.haskell.org/package/control-monad-loop-0.1/docs/Control-Monad-Trans-Loop.html).
We have. Bryan O'Sullivan is working on setting it up so that people can contribute fixes and improvements but I think it will take him some time.
I thought all those were a setup and expected a "instead of using all these custom operators you can use bind (&gt;&gt;=)".
@tschrijvers how do you justify the point of departure, which appears on page 3 of the slides: Monad Transformers Algebraic Effect Handlers No - composition - Yes 
&gt; we don't care what the tone is. I do. I'm still a human, even when I'm talking about Haskell. “In technical discussions people criticise ideas and not other people”, yes, I get that, but I would argue that it doesn't make much difference for people unused to hearing criticism. That said, I don't really see how “If for some reason you don't want to use Template Haskell” could make anyone bitter, even if it *did* have snarky connotations. I just wanted to comment on the general “we techies don't care what the tone is” attitude that I see every now and then.
Correct. The tentative plan is to add the class to base in 7.12, expose it in Prelude in 7.14, and make the superclass constraint go live in 7.16, with suitable warnings as it goes, so 7.12 will be a lot like 7.8 for the AMP, but with a slightly longer build up to the cut over.
&gt; we techies don't care Sorry; I agree with you. I included that sentence to acknowledge that the concern is most applicable to advocacy or marketing-type writing, where the reader is intended to think: what does this technology mean for *me*? Such a reader, if unable or unwilling to use TH, is more likely to be put off than in other contexts: "Oh, I'm not welcome here." (The fact that I can't readily think of an example of an "other context" suggests my point isn't very strong!)
Haskell in many ways remind me of Baldurs Gate. You'll spend the first 8 hours talking to inn keepers and getting slaughtered by lvl 1 goblin. But once the story takes off, all you can remember is how freaking awesome Baldurs Gate is.
Thank you for your service. This might make work a bit more fun.
An $editor fight? Honestly? Do you really think that's useful to him? Does that actually address his concerns? "Oh well if you just *X* and *Y* and *Z* then *Q* Haskell is very nice in $editor". Then provide a download that does that. The fact that it's *possible* to setup some editor to work well with Haskell doesn't mean the *editor works well for Haskell*. It shouldn't be that hard.
I'd very much like to see a writeup of that somewhere, along with code examples that use it. Having an unordered bag of effects that you can handle in any order is very much the point (for me anyway) of algebraic effects. We need to see whether the pain / awkwardness of using your approach in this scenario is better than the equivalent monad transformer code, or something super simple like [this recent post](http://www.reddit.com/r/haskell/comments/39qold/ether_mtlcompatible_extensible_effects_based_on/). But regardless, it seems like great work! :)
Is this the same as using [EitherT](https://hackage.haskell.org/package/either-4.4.1/docs/Control-Monad-Trans-Either.html)? I.e. `loop` being `runEitherT`, and `break` being `left`? 
Thanks! It is always good to reduce boilerplate by putting such things into packages. I repeated the aliases I mentioned above quite a few times. $1 /u/changetip
... Okay, fair; I obviously didn't read carefully enough to realize it was *intentionally* stupid rather than just mistaken. :) (Although in my defense I think a reasonable newcomer could ask that question in honest confusion.)
co-py that!
In common lisp, when you want to throw an exception you can instead say: "you know what, I can't handle this situation, dear condition system, please give me a result that makes sense." If the "give me a result" doesn't happen, the stack was unwound, but there is also the case where the condition system magically comes up with a sensible value. The textbook example is parse errors. You have a library that parses a CSV file. At some point in the file, there is a parse error. The parse library can't know how to deal with this (bail out or provide a default value). However, the caller of the library knows, so it has set up a condition where "parse error" will return a default value (or unwind the stack). This can all be handled by creating a callback mechanism, but in common lisp it is built into the exception handling system, which is a pretty elegant way of dealing with these issues, because the "callbacks" can go through multiple layers of library code and connect information known at a high level in the program with error conditions far down in low-level libraries. http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html
Aha. My comment pertained to the first simple part (with `clockSomething (obverse [1..1000000]`). Now, thanks to your answer, I'm learning a bit of `criterion`.
Cofree? 
Moving from Scala to F# doesn't make much sense. F# doesn't even have higher kinded types.
You can build the master branch of ghc-mod in a sandbox and it will work with cabal 1.22.0.0
For a second I thought you guys were playing [the name game](https://en.m.wikipedia.org/wiki/The_Name_Game). I was trying to sing it in my head but it just wasn't working.
I didn't try that. Same issue here :(
Can you share about your IDE refactoring experience with scala code? Is it on the OO side or FP side? Back to F#. It is closer to ML/Haskell in terms of syntax, like default currying, better type inference, (maybe) better function composition, etc. I personally found F# code flows much better than scala, as these little features help the authors to model and write code in the FP way.
&gt; on Windows Not that this makes any of that *impossible*, but there are a good many prior steps required.
Very nice post. I'm tempted to use this for some `lens` spelunking. I'm not sure if I have adequate caffeine supplies though...
I got it to compile on Windows a few hours ago. Maybe you need to place the sandbox closer to the root so it won't go over the limit?
&gt; What's considered sophisticated refactoring these days? This is a great question. I'll answer for the benefit of those not familiar with refactoring browsers. If you're looking for an example, then IntelliJ IDEA is a great example of a mature, intelligent and comprehensive refactoring tool (for Java). Refactorings can be performed automatically, without you needing to spend time manually tying up loose ends. (It works very reliably, even for refactorings that touch hundreds or thousands of files.) Because IntelliJ has a deep understanding of your code base and its interdependencies -- it can perform these refactorings reliably and quickly. Common operations like reordering a function's parameters can be performed effortlessly and quickly. In my opinion, working with a powerful refactoring editor allows you to spend more time in the zone and concentrating on the task at hand. As a software engineer, being in a state of flow and maximising the length of time one can be in flow is extremely important (to me). If you are working with large projects, where refactorings are riskier -- you want the refactoring tool to perform the transformation efficiently and without breakage. (Of course, breakage can usually be spotted by the compiler -- but that's not the point -- having to go around and fix everything up takes time away from your flow.)
&gt; [the magic of ($)](http://stackoverflow.com/a/20795832/1186208) That makes me sad for some reason :(.
I stand by my previous comment: [Haskell needs to take a lesson from Agda](http://www.reddit.com/r/haskell/comments/334x2v/cartesian_closed_comic_26_ide/cqi1jcq).
Cabal hell doesn't even exist anymore for `stack` users. In fact, I haven't had any dependency-related issues since cabal sandboxes, and now finally `stack` solves the "recompile seemingly all of hackage for every project" problem that sandboxes introduced.
I was working on this to present at BayHac on Sunday in a lightning talk, but I didn't finish up quite in time. Hope someone finds this helpful!
I can't seem to get around the fact that things like putStrLn produce IO(), so the contents of the IO are lost. 
mapM or foldM
Shoot, i never got past 1lvl goblins. 
In the interest of giving you the tools to become self serving: https://www.haskell.org/hoogle/?hoogle=%28a+-%3E+m+b%29+-%3E+%5Ba%5D+-%3E+m+%5Bb%5D Try crafting the type signature and use hoogle :)
There's a couple image processing libraries. I'm on mobile so I can't provide links, but I think you can use one called JuicyPixels, I use a lot one called "friday". 
I don't know, learning Nix has been quite challenging. There is not much documentation out there, and most of it is outdated.
[this](http://prog21.dadgum.com/23.html) might help you get started.
Having a play method on a card is indeed a very OO way of thinking about it, especially since in real life cards are pretty much static data. I'd be looking to write a Card type and a Table type to represent the cards currently in place and write play :: Card -&gt; Table -&gt; Table possibly using lens to manipulate the Table. From what I've seen of my students' Magic: The Gathering cards, the card can contain instructions for what to do when played, and if you feel you want to represent that as code rather than data, you can go a little bit more OO-flavored and incorporate an effect field :: Maybe (Table - &gt; Table) in your Card data type. 
I worked for about two years on a proprietary project that did just the kinds of things that you are describing. I don't know of any generally available library (in any language) that does it well. If the matrix is very regular and reliable, it's not that hard. If it has complex variations - such as arbitrary row and column widths, arbitrary row and column spans, and arbitrary cell contents that you need to detect - I convinced myself that in general this is an NP-hard problem, although I didn't write down a formal proof. Good luck, and have fun!
Another hint is to keep in mind that every monad is also an applicative, so the function you are looking for is often found in `Data.Traversable` or `Data.Foldable`.
Cabal hell doesn't exist any more for `cabal` users either, if you use `cabal` correctly with its modern features. It's also not necessary to "recompile seemingly all of hackage for every project", since cabal supports shared sandboxes. Even without shared sandboxes, unless you are constantly starting brand new projects with huge dependency sets, a fresh compile of the dependency set at the beginning of a project only takes a few minutes using parallel builds and seems like a good idea. Our projects tend to have on the order of 150-200 indirect dependencies. It takes me 5 to 10 minutes to rebuild a sandbox from scratch, and although I work on multiple such projects, I don't find myself doing that more than once or twice per week. So to me, it's worth that tiny cost to know that I have fresh builds direct from the source code, in my own environment, with my own settings. EDIT: To be clear, as I also said about Nix, `stack` is great work and looks like a really cool tool. We may end up trying it. But you are doing `stack` a disservice by implying that its reason for existence is to avoid "cabal hell" or "interminable cabal sandbox rebuilds", because those problems don't really exist anymore even with `cabal` itself.
Nix is a great direction. I'm looking forward for it to mature for all platforms. But calling it "escaping cabal hell" is just rhetoric. Cabal hell hasn't existed for quite a while now. It was caused by limitations of older versions of cabal in the face of a genuinely difficult problem. Now cabal is far more powerful and flexible. When people say they are experiencing "cabal hell", what it means is that they are using the tools wrong. So what we need to solve "cabal hell" is better documentation, and perhaps UI improvements, for existing tools, not new tools. Again, that is not to say that Nix isn't needed or isn't cool. It is! But "cabal hell" is not the issue.
True, but there aren't a whole lot of super useful packages that aren't yet on stackage. And if you find one, just notify the maintainer, or make the PR yourself.
&gt; The local sandbox still can't be shared between projects. It can be shared with cabal. Does stack somehow prevent that?
tl;dr cabal isn't a package manager
https://hackage.haskell.org/package/JuicyPixels JuicyPixels is a raster image generating library, not for analysis, although they provide primitives for loading JPEG and PNG images into a `Vector` data type: https://hackage.haskell.org/package/vector You can then use the `Vector` produced by JuicyPixels in the "hmatrix" package https://hackage.haskell.org/package/hmatrix With "hmatrix" you are provided with the linear algebra algorithms. Although hmatrix doesn't really provide any ready-made recipes for typical image processesing algorithms like edge detection, vector quantization, etc. So it isn't quite image processing, but it is almost there. If you understand the math behind it you can roll your own.
There is also mapM_, which only generates the side effect and throws away the value afterwards
if for some reason you'd want it to be different, you can always just wrap it into something like this: retainValue :: (a -&gt; IO b) -&gt; (a -&gt; IO a) retainValue a x = a x &gt;&gt; return x this code segment should also make it obvious why putStrLn and many others having IO () as return type is completely sensible.
I'm working on a card game right now. I'm using three monad layers. At the top is a state monad that contains all the physical game state. Below that is a free monad that describes client/server requests and responses and random numbers. The last layer is of course the IO monad. This system works OK, but the state monad is a bit of a bummer since its effects are so unconstrained. I might try to rework it into another free monad.
I'm sure you'll be interested in this: https://github.com/RaphaelJ/friday-report
Interesting to see Friday and Juicy in this thread. They are very nice libraries, and combined they can give a Haskell web app basic image manipulation functionality without using any system (C) dependecies or braking out in ImageMagik. I've raised an [issue for that](https://github.com/RaphaelJ/friday/issues/12). :)
It doesn't have all of Hackage though :(
The blog post [image processing with comonads](http://jaspervdj.be/posts/2014-11-27-comonads-image-processing.html) is nice.
I wrap everything in newtypes, Primitive Obsession exists haskell just as badly as in imperative languages. 
&gt; Cabal hell doesn't exist any more [...], if you use cabal correctly That's a big IF right there. The problem is you can use cabal incorrectly. And many users do, because of lack of documentation or experience. The best systems are those which do not allow you to do things incorrectly. I would expect the Haskell community to know that.. you know, like having strong types doesn't allow you to call functions with the wrong arguments? 
Use the unpack/install trick for the packages which fail to install automatically.
GHC needs to allow same package version to be installed multiple times. Until then we're in "sandbox hell"...
Deus Ex is another masterpiece which bored me to death at the beginning. Also, its dated (even back then) graphics engine didn't help. But I'm glad I stuck with it because it's the greatest game I've ever played. If Haskell were a game, it'd be Deus Ex.
For this you will need to create your own Embedded Domain-Specific Language (EDSL). All programming languages, including EDSLs require a notion of "memory," "objects," and "computation." So if your EDSL is for that of a board game: * "memory" is the game board, including the shared game board and the part of the board specific to each player. * "objects" are anything that can exist on the board, including avatars for players, cards, tokens, dice, etc. * "computation" are the rules for eacch possible card in the game. When a player "plays" a card, the card will contain a set of instructions that is "executed" which alters the state of the game board. Your EDSL should also contain logic primitives like IF statements, and FOR-EACH statements, and should probably also be able to throw exceptions. So lets say you have a card with the following rules: One thing about these card games is that the logic of the cards can be encoded in an Embedded Domain-Specific Language (EDSL). For example, if you have a card with a rule like: "Fire-Breathing Griffin" costs 4 food resources and 2 magic resources to use requires creature "Master of Enchanted Creatures" activated blocks user from casting water-related spells while in play deals 1 damage to any non-enchanted creature That way you can encode rules for your cards using a data structure which might look something like this: data ResourceType = Gold | Water | Land | Magic | ... deriving (Eq, Ord, Read, Show, Enum, Bounded) data Resouce = Resource ResourceType Int deriving (Eq, Ord, Show, Read) data Computation = Assert Bool [Conditional] | UseResource [Resource] | ForEach [Selector] [Computation] | ... deriving (Eq, Ord, Show, Read) data Card = Card { cardName :: String, cardRules :: [Computation] } deriving (Eq, Ord, Show, Read) ... exampleCard :: Card exampleCard = newCard{ cardName = "Fire-Breathing Griffin", cardRules = [ UseResource [Resource Food 4, Resource Magic 2], Assert True [CheckActivated (Find (Creature "Master of Enchanted Creatures"))], BlockUseOf [Find Spell [Select (Variety "water")]], ForEach [Find Opponent [Select AnyCreature]] [ IgnoreWhen [Select (Upgrades "enchanted")] ] ] } So the above data structure is a bunch of lists and data type constructors. Also, as you can see in the above example, Haskell's `deriving (Read, Show)` feature is used so that your data can be read to and written from files on a disk in human readable form. Then you need to implement a transormation function, which will probably be a type class, that can traverse your EDSL data types and update your game board state accordingly: class Computable t where compute :: t -&gt; EitherT CannotPlayError (State GameBoard) Result instance Computable Comptation where compute (Assert yesOrNo cond) = compute cond &gt;&gt;= \result -&gt; case result of BoolResult bool | bool/=yesOrNo -&gt; throwError (UnsatisfiedCondition cond) _ -&gt; return result compute (UseResource rsrcs) = do forM_ rsrcs $ \ rsrc@(Resource rsrcType amount) -&gt; do x &lt;- lookupResources rsrcType if x &lt; rsrcType then throwError (NotEnoughResrouces rsrc) else modifyResources rsrcType (subtract amount) return (BoolResult True) instance Computable Conditional where compute (...) = ... You may want to look into the lens library, it makes it much easier to deal with a complex state object like a game board than vanilla Haskell. 
Ok, let’s have a look to common idioms to do that. &gt; If I have a calculation that runs in a "loop", or a fold Let’s infer you’re using a `foldl`: foldl :: (Foldable f) =&gt; (b -&gt; a -&gt; b) -&gt; b -&gt; f a -&gt; b &gt; is there a way to get the results into the outside world as each iteration happens? Two possibilities. You traverse your structure and have a side-effect for each element. In case 1, you want the result. In case 2, you don’t. For case 1, use `traverse`: traverse :: (Foldable f,Traversable t) =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) Replace `f` with `IO` and `t` with `[]`: traverseList :: (a -&gt; IO b) -&gt; [a] -&gt; IO [b] Now, if you want to discard the result – i.e. case 2, you’re advised to use `traverse_`: traverse_ :: (Foldable f,Traversable t) =&gt; (a -&gt; f b) -&gt; t a -&gt; f () traverseList_ :: (a -&gt; IO b) -&gt; [a] -&gt; IO ()
I don't get to share the local sandbox, but 90% of my dependencies are from stackage lts-2.13, so I get to avoid 90% of the compilation every time I start a new project, which I still consider useful.
This is a great idea.
&gt; If we had a type-and-effect system, I'd agree with you. I don't understand this remark, could you explain this in more detail? Do you mean that if we had a type and effect system then the other instance for Maybe would be handled by composing effects, so that it would be redundant to have that as the Monoid instance?
+1 for free monad
I'm not an expert about ghc internals or musl. Can using musl interfere with any features on the Haskell side? (such as bound threads or some such?)
After watching the ghc-mod bug on github for months now I can say with confidence that it is ghc-mod that has a compatibility issue with almost every combination of GHC and cabal version (GHC 7.8.4 with cabal &lt;1.22 works but nothing else does).
The others have answered how to actually solve the problem you encountered, but I have to question need of performing the IO "inside the loop". This hints to me on bad composability. I would try to separate the pure calculation from the IO operations. As you know, Haskell is a lazy language so even if your function returns a list, it won't calculate the rest of the list until it is needed. Instead of fold, think of using scan which is like fold but returns the intermediate values, and *then* map the result to IO operations using mapM, foldM, sequence, etc like the other answers recommend. So instead of `b -&gt; [a] -&gt; IO b`, change it to a pure `b -&gt; [a] -&gt; [b]` and map the resulting `[b]` to `IO ()`.
The complement of Python?
Thanks heaps! Some of these would never have made it onto my list (I don't even have a middle mouse button :-) ). I'll make sure they all get added to the issues list. &gt; I wasn't able to set breakpoints and make the debugger work. Breakpoints in Haskell can be tricky to reason about at first. [Here](http://stackoverflow.com/questions/30701773/ghc-7-10-1-leksah-0-15-0-1-debugging-problems) is a good example of the kind of confusion that can arise.
I wrote [a tutorial](http://www.haskellforall.com/2013/05/program-imperatively-using-haskell.html) showing how you can mix lenses, `State` and `IO` to write a game in a traditional imperative and OOP fashion.
There's a [Dominion simulator](https://github.com/egonSchiele/dominion) that someone has written.
Remember that monads are "just data" that you happen to build using `bind`. If you write a function and an initial state with types like `f :: m b -&gt; a -&gt; m b` and `z :: m b` respectively then these are perfectly acceptable parameters to `foldl`: foldl f z :: [a] -&gt; m b -- or, the more general signature foldl f z :: Foldable f =&gt; f a -&gt; m b So, consider looking into how you can construct a function `f` of that type. It'll turn out that you can build one from a function of type `b -&gt; a -&gt; m b` if that's closer to what you have. 
But a tiny bit of description would be useful there. So, I suppose that this runs the benchmarks after every commit to the GHC HEAD?
I tried something like this yesterday with `control-monad-loop` (I wanted to see how `continue` was implemented). In fact `control-monad-loop` uses a sort of church encoded version of newtype Loop c e m a = Loop {runLoop :: m (Either c (Either e a))} i.e. newtype LoopT c e m a = LoopT {runLoopT :: forall r. (c -&gt; m r) -&gt; (e -&gt; m r) -&gt; (a -&gt; m r) -&gt; m r } The simpler type just adds another option to `Break`. (Here is a job for `ether`!). I reimplemented the stuff with the more straightforward type and the differences were no where significant. It was kind of amazing, really how far they tracked each other. Here's the extended module with both variants, and two of the examples. https://gist.github.com/michaelt/eb738a5b6a7524471e61 The trouble, I think, is that `Control.Monad.Loop` doesn't take advantage of the Church encoding to write a non-recursive version of `loop`. (The examples are using `foreach` which is somewhat different but I couldn't find a difference in other ways.) Taking advantage of a church encoding or the like would involve rethinking the relation between `loop` &amp; co, and `break` and `continue` -- if I understand what's going on. 
Unlikely, its just a libc, you can use uclibc too to similar effect. musl libc is designed to be statically linked into executables.
Hey thank you for the explanation. In the final line is it supposed to be ? ```putStrLn (show previousSum) &gt;&gt; return $previousSum + nextElement ?```
errge, awesome work! So as a note to any other haskellers trying to get ghc on alpine linux, i've managed to get to at least a bootstrap apk for ghc 7.10.1 and was going to submit that upstream along with a cabal apk soonish. I've been doing my work here: https://github.com/mitchty/alpine-linux-ghc-bootstrap I'll just dump my notes on what i found about porting ghc to musl here cause why not. First note, unlit and building a cross compiler doesn't work or might have a bug, it gets built with the host libc from what I found. So I have to do this: https://github.com/mitchty/alpine-linux-ghc-bootstrap/blob/master/bootstrap/Dockerfile#L89-L97 If you build a normal ghc without specifying -nopie, and tell the linker to not use PIC with -fno-PIC, you get this: https://gist.github.com/mitchty/29125de21ade1a04364f But as it turns out thats likely alpine linux's use of PaX. Long story short, .text relocations aren't allowed by normal executables. So if you turn it off, you can coerce ghc to work without any modifications but to ghc itself. https://github.com/mitchty/alpine-linux-ghc-bootstrap/blob/master/alpine/Dockerfile#L53 But that still causes issues with building base within alpine with your bootstrap ghc itself from what i've found. Been working on figuring out how to get ghc built the "right" way and get an apk submitted. But i'm not dealing with 7.8.4. But thought i'd throw this out there, I'm just at the point where I can bootstrap install an apk to generate a real apk with ghc/cabal as dependencies. In either case I might snag a few of the things you did in build.mk and for configure to see if that helps at all for bootstrapping ghc in alpine within itself. I just was farting around with using llvm as the backend, but it generates HUGE binaries, aka about 10 megs for a hello world. They're fast static binaries though. :)
Oh! By the way, the categorical dual of something is just that thing with all of the arrows flipped backwards.
IIRC, `mapM` is really just `traverse`. 
Would it make sense to have GHC default to using musl instead of libc?
&gt; Cabal hell hasn't existed for quite a while now I don't think this is correct and I hope that many feel the same way. I've used sandboxes in what seems to be the correct way as far as I can suss out and I still often end up with problems getting the dependencies to all build together. Sometimes I can't even get them to build after doing a complete clean, ie: ``` $ rm -rf .cabal-sandbox ~/.ghc ~/.cabal ~/cabal.sandbox.config ``` In the end I gave up and used Nix, which is a bit of a faff so far from idea. It may well be a documentation problem, as you say (although I'm inclined to say it isn't wholly a doc problem), but it's still a *problem*. And then you have the problem that, with every new project, you have to sit and wait for ten minutes for all the libraries you need to really start working to install. It's far from ideal.
There's yarr: https://github.com/leventov/yarr/blob/master/tests/bench-results.md
What is the point of MonadPlus now that every Monad is an Applicative? Isn't Alternative enough?
If you compare both versions: https://hackage.haskell.org/package/transformers-0.4.3.0/docs/src/Control-Monad-Trans-State-Lazy.html#liftCallCC you see that they do different things. The one uses the latter state, the other the earlier state in its return type. That should make a logical difference - so you cant just switch both. (I just took a brief look at it. Dunno if thats correct, though).
Applicative and Monad MAY behave differently. Take as example a construct for automatic paralellizing. Here you have Applicative as parallel computation (validating some laws, though) and Monad as the sequencial dependency-counterpart. So there may be use-cases for a different implementation of both. I see MonadPlus as introducing a 0 in a ring (with mappend as +, &gt;== as *, return as 1), thus defining fail _ = mzero would be the way to go i assume. This differs from Applicative i think.
I don't really like C and I write it plenty, trust me. I'd totally dig a system where I didn't have to worry if unzip'ing a file could compromise my computer. :) I'm just telling you how it is, and 'it' is unlikely to change any time ever in the near future I'm afraid (which makes the 'no-libc' approach essentially a huge amount of work for little to no gain, unfortunately).
Using the `reducers` package it becomes filterByDate startM endM as = reduceWith appEndo endos as where endos = catMaybes [ , startM &lt;&amp;&gt;\start -&gt; filter ((&gt;= start) . date) , endM &lt;&amp;&gt; \end -&gt; filter (&gt;= end) . date) ] 
This might give you some ideas: https://www.fpcomplete.com/school/to-infinity-and-beyond/pick-of-the-week/type-families-and-pokemon
Sure thing, just didn't know anyone else was working on porting/using ghc on alpine linux is all. Thats my main reason for throwing out my work in progress to an apk. I can/have apk's that work that are non position independent that install and "work" but I just found out sunday about what PaX itself is doing and have been trying to see if I can bootstrap natively without any linker or compiler cheats. But if nobody cares about a first revision being a work in progress no big deal. And I was going only for 7.10.1 mostly due to the cross compiling fun I had, but I also took a bit of a different tack for the bootstrap compiler by using the sabotage linux gcc cross compiler. I also cheated by installing ncurses into my cross compiler setup to work around the terminfo stuff. Tonight is a bit busy as well will be tomorrow but if you want we could both probably work towards apk's. Its to the point I can build a real ghc apk that depends on itself but since I thought I was the only person working on this have been working more on understanding the grsecurity patches and PaX and PIC code and how all this nonsense meshes together. I'm giving my box at home a bit of a workout with a couple changes and if I can generate initial bootstrap apk's from it I'll add in the ffi stuff and try again. I did some spot checks on compiling things vi cabal but nothing as extensive as you did.
Portable in this case is a misnomer. A fully static binary doesn't have any dlopen() calls, to libc or otherwise. Effectively they are portable within the same architecture, aka x86_64 stuff will/should run on any distribution of the same type. The consistency is the linux syscall interface, for musl libc this means your linux kernel will have to be about 2.6.16 or newer, .19 is preferred if you want to use threads as provided by musl. But other than that it will run anywhere. And no glibc is not portable, glibc has version numbers and what normally ends up happening is you build against glibc 2.1 say, but you want to run that binary on a glibc of 2.2, no worries works fine. But want to run that on glibc 2.0, and now you've problems. Static linking glibc is not an exercise for the faint of heart, and is fraught with pain. glibc is not designed to be statically linked into executables. musl however is designed for this purpose, what normally happens, in c at least, is a statically linked musl libc binary is smaller than a dynamically linked glibc binary. Hopefully that explains the why a bit more and the reason some few of us want this. Feel free to ask more questions!
It's pretty trivial to add a non-stackage package to your stack projects by adding it to the `extra-deps` list in your stack.yaml, or create a multi-package project and use the source for an extra package if you so desire.
If you only want to install an executable, with recent stack you can say `stack install`. That'll install it into `$HOME/.local/bin/` (whcih should be in your PATH), so you don't need `stack exec`.
How relevant is the haskell wiki? Seems this would be a good candidate for it, especially considering how fast reddit posts become irrelevant (that is, pushed off of the front page).
Yes, but nix is in general not very self-documenting for newcomers. When I last experimented with it, it was hard enough even finding source locations for errors, much less figuring out how to do anything independently without pretty focused instructions.
&gt; The phrases "fell victim to" and "what's wrong with alternatives to mtl" are overstatements. Granted. I was keeping the "Type Classes vs. the World" talk in mind; implicits vs. coherent type classes isn't black and white either, but Ed's presentation is pretty opinionated in its defense of type classes, and I expect a similar strength of opinion in an argument for the `mtl`. In both cases, the community (and especially the neophytes) are much more familiar with the disadvantages of the standard Haskell approach than with the disadvantages of the alternatives, so I appreciate the frequent reminders of the advantages of the current approach.
A `Table -&gt; Table` function may be too limiting, especially if `Table` doesn't contain enough game state. In principle (though in practice, only in joke sets like Unglued), an MTG card could require you to do something extreme, like play a different game and vary its effect based on the winner. I'm thinking something more general using continuations, like [this](https://joeyh.name/blog/entry/7drl_2015_day_5_type_directed_spell_system_development/) might be useful.
I believe that while technically `Applicative` and `Monad` *may* behave differently, those instances are considered unacceptable and non-law-abiding. See [this thread](http://comments.gmane.org/gmane.comp.lang.haskell.cafe/116279) for an extensive discussion – the tl;dr is that Applicative and Monad *must* agree, and that newtype wrappers should be used in cases where there are different Applicative and Monad implementations.
This throws away the informative String. Some monads have useful ways of preserving information about failure.
I actually have written some heavy duty temporal SQL query generators, and frankly, that only redoubles my recommendation to abstract the concept of time ranges and operations on them. In cases like that, I have implemented a range type that really represents a pair of SQL scalar expressions, one for the "since" and one for the "until." What the range operations do then is build SQL fragments corresponding to the various operations on ranges. In the case of temporal joins, the two most useful ones are: 1. Overlap test: given two ranges, generate a SQL boolean expression that is true if and only if the two ranges overlap. 2. Intersection function: Given two ranges that overlap (precondition; use the overlap test to enforce it), construct a SQL range whose members are expressions that evaluate to the since and the until of their intersection. Then your query generation logic delegates the task of composing the SQL range logic to this type and its operations. Two prerequisites for doing this sort of thing (and remaining sane) are: * Some abstract syntax tree representation of SQL queries and their parts. * Some sort of metadata representation of which column pairs on your database schema represent time ranges.
I think in Haxl, if you use `a *&gt; b` you get parallel computation, whereas if you use `a &gt;&gt; b` you get serial execution. They might agree about the result value, though, but not necessarily the effects. I think in this case it is even visible that the execution is parallel or serial.
Stack has a more beginner friendly UI than cabal (whose defaults do bad things). Stack uses lts-haskell/Stackage out of the box, if you want to use that. It can also deal with multiple cabal packages at once. 
&gt; user-friendly and intuitive doesn't necessarily mean fast. It's fine for casual users but and editors are different. It's a tool you'll use probably daily for years, and the entry cost is somehow irrelevant (especially if you learn vim/emacs , because you could use them for absolutely any language). As you said IDEs are user-friendly and intuitive which mean that EVERYBODY can use them, even people which know how to use and "editors". This gives editor people a superpower, they can use and IDE and a editor, whereas you don't have the choice and have to use an IDE. Your lack of this superpower is strong enough to make you give up haskell, which is a shame when you think about it : If you had gave up on everything not user-friendly or intuitive your probably won't be able now to walk, read/write , swim etc ... Funnily, pretty much everybody which has this superpower and have the choice between IDE and editors choses editors, so maybe those editors are more powerfull than you think they are. Also, you are obviously a "mouse-person" and probably can't touch type. In the same way, "touch typing" is also a superpower , you can still use a mouse, but also have the choice to not use it for everything ;-) 
Non-reusability was my naive understanding of the following passage: &gt; Packages are installed into isolated package databases by default. There is a layering of three package databases: The global database, the snapshot database, and your personal project's database. Many projects can share the same global database (base, bytestring, etc.) and the snapshot database (e.g. text, haskell-src-exts, etc.)—which means no unnecessary rebuilding of packages—and yet each project has its own package database, so they are isolated from each other and cannot break each other. https://www.fpcomplete.com/blog/2015/06/announcing-first-public-beta-stack
If it rhymes it must be good.
&gt; Are there monads that have "sensible" fail implementations that lack monadplus instances [STM is `MonadPlus`](http://hackage.haskell.org/package/stm-2.4.4/docs/Control-Monad-STM.html), but [has `fail = error` (implicitly, via the default implementation).](https://github.com/ghc/ghc/blob/c5911479f295242e16e396eb5d1369f2e4ce8de0/libraries/base/GHC/Conc/Sync.hs#L633) 
Exciting news! Some questions: * Can the GHC itself be copied out of the docker and used on random Linuxes which may not run Docker? If yes: * Can you drop the standalone ghc-musl into your home directory and use hsenv to fix up the paths? (Avoiding having to ever build GHC again for some old Linux distro would win huge.) * Can GHC API work? (Needed for ghci, ghc-mod, hint) Un-relatedly: Is there any hope to build a ghc-musl for fringe environments like Windows and OSX?
One of Nix's many features is a more intelligent way of implementing sandboxes. So if, as you say, "Sandboxes solve cabal hell", it necessarily follows that Nix does as well.
I don't see how this is an improvement over `cabal`. Can't you do the same thing with `cabal install` and `cabal run`? That's not to say that `stack` isn't an improvement, but I thought it was for other reasons.
Cabal already has a `--require-sandbox` option. It's a choice of Haskell toolset installation packages such as Haskell Platform, etc., whether or not to set it by default.
gah. sorry about that.
I'm not sure it is unfair to blame cabal. It's not just me having these problems, it's widespread. I can't provide details because I haven't got the project around and, in the end, I just gave up writing in Haskell. I could write them in Python or even Rust much quicker and with far less hassle. The problems may have ended for you, they may not have done for others. 
&gt; One of Nix's many features is a more intelligent way of implementing sandboxes. Could you explain how Nix does this?
&gt; Are there monads that have "sensible" fail implementations that lack monadplus instances Yes, for instance the following type: data M s a = Fail | Succeed a | Step s (M s a) It represents a computation, which takes some steps with intermediary results and then either fails or succeeds with a final result. It has a sensible `Monad` instance with `fail _ = Fail`, but there is no sensible `mplus` and thus no `MonadPlus` (at least without constraints).
&gt; What's the purpose of having this law if it's violated? The violation occurs in order to use the current state in its return type. It does answer your question.
As food for thought, what would happen if we had MonadFail m ~ MonadError String m where MonadError comes from / is equivalent to [Control.Monad.Except](https://hackage.haskell.org/package/mtl-2.2.1/docs/Control-Monad-Except.html) and fail = throwError I've always been keen for the option of something more informative than a String with various parsing libraries (some of which tend to use fail / mempty / etc...), and I can kind of see how that could be done with MonadError and classy prisms. It'd be nice if we could get fail our of Monad as well as laying some groundwork towards having the option of more structured error information (assuming that is something people want). Edit: Gah, I _thought_ that was on the mailing list... Something similar was mentioned [here](https://mail.haskell.org/pipermail/libraries/2015-June/025794.html) although there might be [just a few problems with it...](https://mail.haskell.org/pipermail/libraries/2015-June/025795.html)
The documentation for `MonadCont` doesn't state any law governing implementations of `callCC`. The function `liftCallCC'` as a Haskell function and no signature doesn't violate any law of course; a law is associated in the text with the special synonym `CallCC`. That it doesn't 'deserve' *that* name doesn't mean that its use in the instance for `StateT` is bad; it is only applied to `callCC` from the underlying monad. To find a mistake in this, we would have to know what the laws of `MonadCont`/ `callCC` are. Put differently: this objection would not arise if the definition of `liftCallCC'` were simply inlined in `callCC` definition in the instance for `MonadCont m =&gt; MonadCont (StateT s m)` 
I would imagine having total control and a clean slate to work with would be a big reason. stack still uses the `Cabal` library under the hood which could mean some of these improvements do see their way back to cabal install if anyone is willing to do the work. Having multiple tools *might* confuse newcomers but we certainly won't be the only language with that "problem". Python, ruby, and ocaml all have choices which can be confusing.
Is there a reason fail doesn't equal mzero for STM?
musl is Linux only, so unless you use some compatibility layer (there are, flinux comes to mind) you can't use it on windows or mac.
So then why not just wrap cabal in a better API?
That's basically what I was trying to do with stackage-sandbox: wrap cabal in an api that encourages shared sandboxes. However, fully sharing sandboxes between projects turns out to be rather fragile. Projects often need to deviate from each other in small ways. I might want to work on the bleeding edge of package A, while also working on package B which depends on the stable version of package A. These cannot share a sandbox. But with stack, they *can* share just the dependencies that they draw from stackage.
True, but you *can* just put multiple packages into the same "project." Or as others have mentioned, get more of your dependencies into stackage and then they'll be shared even if in different projects. In theory, stack can be extended to use your own "snapshots" rather than using the default of LTS Haskell.
There was a point when it was on by default. It causes me some confusion, but I soon learned to just always use sandboxes.
Dan Burton answered this question at BayHac this year. He basically said (paraphrasing) "we wanted these improvements over cabal, and we wanted them now". Presumably, rewriting everything from scratch was simpler than understanding and then extending what was already there. I see no problem with that. If you want cabal to do this, that, and the other thing, try hacking on it yourself; no one is stopping you.
because many MonadPlus dont follow the associativity law(to allow for infinite data structures) I will ignore that law. So the only laws we are burdened to prove is mzero &gt;&gt;= f = mzero. If you notice that is the same law that fail follows. I assume he gave us a correct MonadFail instance. QED?
When it comes to ignoring associativity, I found [this](http://stackoverflow.com/questions/15722906/must-mplus-always-be-associative-haskell-wiki-vs-oleg-kiselyov) interesting. I guess it comes down to whether you consider MonadPlus to be for "monoids with monads" or for "search monads". I hadn't really thought about it, and had just assumed it was the first one (and that if you wanted to ignore associativity, then you really wanted a different abstraction). Does anyone know if the definition has been nailed down further since then?
If you're after an end result that is either `Fail` or some number of `Step`s that were on the path towards a `Succeed` followed by the `Succeed` itself, this runs into problems with mplus (Step s Fail) b = Step s (mplus Fail b) = Step s b in that it can bring an intermediate step from a "failure path" across into a "success path". Edit: That would also require`mplus Fail _ = Fail`. I'm not sure if I'm interpreting the semantics of `M` correctly though.
Which example are you talking about? The only comment I see from /u/edvo only has the ADT and a little description of it: a series of steps terminated by success or failure.
In response to your edit, `mplus mzero b = mzero` directly violates this law: `mplus mzero b = b`
Nice! Thanks for the throughout answer. There is no change I'll be at StrangeLoop, but probably there will be videos? Regarding performance tuning: this sounds like a good project for a MSc or PhD thesis. Maybe even GSoC? 
Depending on what you want, I'd recommend Scotty, Spock, Servant, or Yesod. Roughly in order of most to least minimal.
Cabal is a lost cause. I once browsed the source and came out a disillusioned man.
That is a **terrible** approach. Adding a new card becomes hard and you need to edit every function with Card on the type. IMO having methods is the way to do. A card is data, yes. **So is a function.** The effect of a card is part of the card data, and that translates to a Haskell function. It is the most natural thing to do to have a function as a field of the card.
I *really* like servant for making RESTful APIs. I wrote a [post](http://www.parsonsmatt.org/programming/2015/06/07/servant-persistent.html) on combining Persistent and ~~Yesod~~ Servant, and I really have a hard time imagining a higher level/more productive approach to doing this. EDIT: lol i need to go to bed earlier. stupid homework...
... which I suggested at the end, yes. 
Do you have a blog post / example app somewhere that shows an example of doing this?
I have tried. I gave up after trying to navigate the source. 
I'm mainly interested in authorization capabilities. I know servant has a patch for basic auth, but they're not yet sure whether their implementation choices are even the right ones. I'd really like OAuth, though.
Hm, how are Scotty/Spock more minimal than Servant? Do you consider them more minimal because Servant is an eDSL?
No, but the example usage on its [hackage site](https://hackage.haskell.org/package/wai-routing) is easy to follow. To implement your own `Predicate`s you need to do a little more. I should write something about it and submit it to its haddocks.
I added some delay in the thread example to show better the interleaving of threads in Linux. The Windows scheduler apparently interleave threads faster. In the thread example the threads perform a very light work so in the linux scheduler the first thread finish before starting the next. This is the example with the delay added: threadSample= freeThreads $ do option "th" "threads sample" liftIO $ print "number of threads? (&lt; 10)" n &lt;- input ( &lt; 10) threads n $ do x &lt;- choose [1,2,3] y &lt;- choose [4,5,6] -- added some delay to show tread interleaving better in Linux th &lt;- liftIO $ threadDelay 100000 &gt;&gt; myThreadId liftIO $ print (x,y,th) This is an execution log of this example in FPcomplete now: Press end to exit Enter "main" to: to return to the main menu MAIN MENU Enter "nondet" to: Non determinism examples Enter "trans" to: transaction examples with backtracking for undoing actions Enter "colors" to: choose between three colors Enter "app" to: applicative expression that return a counter in 2-tuples every second Enter "async" to: for parallelization of IO actions with applicative and monioidal combinators Enter "server" to: A web server in the port 8080 nondet "nondet" chosen Enter "ex1" to: example 1 Enter "pyt" to: pythagoras Enter "coll" to: group sample: return results in a list Enter "th" to: threads sample Enter "file" to: example of file search th "th" chosen "number of threads? (&lt; 10)" 2 (1,4,ThreadId 156) (2,4,ThreadId 155) (2,5,ThreadId 155) (1,5,ThreadId 156) (2,6,ThreadId 155) (1,6,ThreadId 156) (3,4,ThreadId 155) (3,6,ThreadId 155) (3,5,ThreadId 157) By the way, all the menu options are active since keyboard inputs are events for the transient monad. so pressing "th" will execute the example again. 
I'm not sure it's fair to place `servant` in the first category rather than second. `servant` is (or has been, since the 0.2 rewrite) a web framework itself rather than a library one uses in addition to one's web framework of choice.
I think /u/Mob_Of_One means that scotty is just a small layer on top wai, in just one package with just two exposed modules. Simple, not scary and it's hard to get lost in there. *servant*, while very different from yesod which is surely the one that does the most, does come in several packages: server implementation, client-side function generation, etc. This might definitely be a bit more intimidating than scotty. Also, the API types are not always an easy sell, although some haskell beginners seem to be able to digest them without any problem, surprisingly!
In my use case `mplus p1 p2` should give me the first path that succeeds. It should not return a path, that has mixed steps from `p1` and `p2`. Your implementation might be useful for some other use case, but would not work for me. By the way, I simplified the type. The actual type is `data M i s a = Fail | Succeed a | Step s (i -&gt; M i s a)`, so you cannot decide whether a path will eventually succeed. 
Ohh... woops. Okay, I shamefully admit I stopped reading after the type. Hey, but be fair to me, that paragraph was a total plot twist. I just assumed it added more info. Sorry Andrew...! :( (... this all makes me wonder if we would be so biased against OOP style if OOP wasn't a thing and Haskell was C ...)
sproxy seems very interesting, especially since it should be possible to generate a bunch of the privilege rules for particular paths from servant's types.
Cabal does have its issues but to call it "a lost cause" is more than a bit hyperbolic. Some parts of the codebase show their age but this is true of most sufficiently old open-source projects. Really the project just needs more hands. It's absurd that such a widely used piece of code has exactly zero full-time developers. Spring-cleaning Cabal wouldn't be a glamorous task (and may even be unpleasant at times) but I don't think it would be nearly the Herculean effort that is often suggested.
I'm looking forward to hearing more!
I don't think so. Haxl is using some tricks to get as much concurrency as possible out of a specification but not more. It is meant to perform binds.
(Trevor here) There are some major architectural problems with HaNS as it stands that need to be sorted out first, but yes!
I'd appreciate some feedback on whether this approach goes totally into the wrong direction or is actually a useful improvement. I'm referring to this thread for some background information: https://www.reddit.com/r/haskell/comments/2o5558/is_network_library_poorly_implemented_or_am_i/ I while ago I wanted to play around with [SCTP](https://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol) in Haskell and found it was not so easy to do with the existing [network](https://hackage.haskell.org/package/network) library in Haskell. The deeper I dug into the topic the more I felt the library suffers from some design issues that cannot easily be overcome without breaking the API and putting all existing applications depending on it at jeopardy. You might want to the check the library's issue tracker and the linked discussion for details. I came to the conclusion that I could do a fresh and well-designed rewrite and have it coexist with the `network` library even within one application. If the rewrite turns out to be an improvement people could smoothly port their libraries to use the new library without the need to port everything at once. Here is (a non-exhaustive) list of things I believe to have improved: - No autotools required (this is especially problematic on Windows). The Haskell Platform that brings MinGW is just enough. - Everything that ships with this (core) library should be supported on every platform (i.e. the Unix sockets will live in a still-to-develop `socket-unix` package). - No conditional exports or platform specific behaviour. The `socket` library is interruptible even on the non-threaded Windows runtime (this is a little hacky at the moment, but it's at least correct and does not require tons of `#ifdef`s in the Haskell code). - No duck-typing addresses anymore: `network`'s `SockAddr` type is a finite enumeration. It has been expanded with `SockAddrCan` recently, but these kind of changes break old code or at least trigger non-exhaustive pattern match warnings. The `socket` library uses type families to solve this. - The `network` library keeps track of the socket's state. This is problematic as there are sockets that can be connected more than once and also introduces a source of possible inconsistency with the real socket state. The `socket` library just tries and throws exceptions when if something went wrong. Clean and simple. - Socket Options: Not all socket options are integers and the set of socket options is not finite as the `network` library suggests by using an enum for this. The `socket` library uses two type classes for this and new options (in external packages) may be added easily. - Exception handling: The `socket` library throws `SocketException`s. They can be distinguished from other `IOError`s and their meaning should be reliable independant of the platform.
I collected a list of Haskell REST API tools/services a bit ago here on reddit: http://www.reddit.com/r/haskell/comments/2r1l42/haskell_rest_libraryserver_breakdown/ Authors of the libraries provided some good motivating-case comments etc.
Are non-exhaustive pattern match warnings really a bad thing? Since I don't see the examples of the code in the old style and in your new style, I can't of course understand the issue well. But I'd consider it as an indicator that there are new things in the library, and the application code might need a re-work. (I've just been adding a new thing (a new data type option) into a program of mine(not network-related), and had a thought that it's bad that I have used default rules in function definitions (like a last `f _ = a default value`) to save typing. Because: when the new thing was added, I might need to re-work the logic of some of theses functions; the logict might become broken because the case with the new thing must be treated, but unfortunately I don't get the noin-exhaustive pattern-matches warnings. I wish I had them. Now I have decided to avoid default rules, and to try to write out all the values of an enum explicitly, to make the logic of my code more safe w.r.t. future changes.)
Superficial observation: Feels a bit weird to have to explicitly annotate the accept method. Especially if you're used to network's `(conn, _) &lt;- accept sock` I do like that you are trying to make sure none of the major platforms are second class citizens.
Could you explain this a little? I guess I know what you mean, but I'm not sure. It is correct that all socket values now have more type information than before and that you need to tell the type checker at least at some points what exact type of socket you mean. What I'm still a little unsure about is whether there are case where the accepted socket is of different type than the accepting socket. I assumed this is not the case.
I'm afraid I wasn't clear enough in my comment. * Warnings are good. If a new thing appears in the library, then there should be non-exhaustive patterns warnings in the programs that use the library. The author of the program then can revisit this place and check that the logic is not broken with the new case (add a new case). * Default rules are bad. They hide the places where the logic might be broken after a library update. So, the essence of my comment was: I'd consider avoiding warnings on library updates an "anti-goal". (And I'd recommend to program authors NOT to use default rules -- in order to get MORE warnings on library updates. Here you seem to have misunderstood me. I'm not suggesting default rules as a solution.)
Just a hunch, but I wonder if you could adjust the nice levels of the cabal and ghc processes such that they don't starve your system's memory? A few weeks ago when I was diagnosing hard freezes that happened when cabal installing large packages (ghcjs in particular), I adjusted nice levels, swappiness, and even tried a different CPU scheduler. Met with mixed results, but worth a shot, maybe? Though, if you're on Windows, I wouldn't even begin to know how to do any of those things.
Ok, now I got the subtile difference: **on library updates**. You're right. Nothing more to add.
It's pretty solid, I've used it at a hackathon. 
That's a pretty cool idea.
To put it in relation: The issue with the warnings is really not that dramatic after all and just an additional observation. The main issue is IMHO that you cannot extend the network library with external packages.
Have you used servant before? I'd be really interested in a comparison between rest and servant.
I'm one of them ;) But you are right that should be somewhat more prominently stated. We wanted to make it clear the uses of the API DSL are not *tied* to writing web services (`servant-client`, for example, can be a passable `http-client` or `wreq` replacement well outside the context of any web application). But we probably should just admit that by far the most common and most important use-case is as a web framework.
There's also a little ambiguity about what is meant by "servant" - we use it as both the name of one of the packages, with the expressions of the DSL, and the whole ecosystem. The servant ecosystem (including, in particular, the `servant-server` package) can certainly be called a framework.
I don't agree with all the advice. This is a very sweeping statement: &gt; Type classes are wonderful technology but are by far the easiest &gt; way to obscure a library. Avoid them whenever possible. 
This isn't your worst problem. When I worked on packaging Haskell for Gentoo we had special support for GHC on machines with less than 512mb. You need a special build of GHC that does not use "split objects" for its .a files (think libHSbase-4.8.a), otherwise just linking your program will cause ld to take too much memory and invoke the OOM killer. As others have said, if you're building for a cheap VPS or similar, the better approach is to build on a more powerful machine and just deploy the final binary to the target machine. cabal configure --prefix=${where-you-want-it} cabal build cabal copy --destdir=./image Now tar/zip up the image dir and deploy that to the prefix location on the target machine. (If you're using any libs that use data files you would need to do the above for those too, using the same image dir.)
Credits to Yuras Shumovich for this excellent blog post: http://blog.haskell-exists.com/yuras/posts/stop-abusing-cpp-in-haskell.html
Actually guard only requires alternative and with AMP the type was changed to reflect that.
I bet the Haxl monad is broken as well because if (&lt;*&gt;) is parallel and (&gt;&gt;=) is serial then that means (&lt;*&gt;) != ap. Which breaks a very important law in Control.Applicative. 
I tried both for a simple app and for me servant works better for smaller applications. For example, I wrote a [todobackend](http://todobackend.com) [implementation](https://github.com/jhedev/todobackend-servant) using servant, which was pretty straightforward and I really liked it. Using rest for something this small feels a bit overkill as it takes some time to get used to it (at least for me :) ). 
Then I suggest to take a look at the huge-impact libraries on Hackage: bytestring, containers, wai etc. Those are excellent examples of how to structure a project. When you decide to use config files (why not?), the [configurator](https://hackage.haskell.org/package/configurator-0.3.0.0) package is a pleasure to work with.
Read his github posts. Basically without the monad superclass you get a very odd pointed type which has no laws. 
As dcoutts points out, you are in for a world of pain trying to compile on such a small machine. In my testing on ARM I generally use machines with at least 1GB of RAM. Nevertheless, it is a little ridiculous that `cabal update` has a maximum RSS of 700 MB when run on my laptop. This appears to be a bug. I've opened [this ticket](https://github.com/haskell/cabal/issues/2660) so it can be tracked.
It's not a tutorial per se, but take a look at my Strava API client, [Strive](http://taylor.fausak.me/strive/). To answer your first question, I split the modules into actions, options, and types. And to answer your second question, the only secret is an API key, which the user provides to the client constructor. 
Actually, I take it back. I was clearing out my todo list just now and it turns out I started working on heatmap support in 2012. I have no idea whether I finished and it certainly doesn't build with modern `Chart` releases but the branch is [here](https://github.com/bgamari/chart-histogram/commits/heatmap). Judging from the email thread where I announced this, it seems my [chart-image](https://github.com/bgamari/chart-image) package may also be relevant here.
&gt; I believe this is a mistake but i cant find any literature on it. do [x] &lt;- "hello" return x If STM had mzero as fail, then this would be an implicit infinite loop.
I mentioned this to my supervisor and we reached the conclusion that, while exposing it as a web service would be awesome, right now it's not our first priority, sorry! That being said, it's something that I really want to see, so it *is* going to happen. I'll be sure to update you whenever I can.
Well, technically you could automate a lot of the repetitive bits (e.g typical CRUD endpoints) and regroup endpoints by "sections", as illustrated below. -- CRUD endpoints for entities of type 'a' -- indexed by values of type 'i' type CRUD i a = ReqBody '[JSON] a :&gt; POST '[JSON] () -- create :&lt;|&gt; Capture "id" i :&gt; Get '[JSON] a -- read :&lt;|&gt; Capture "id" i :&gt; ReqBody '[JSON] a :&gt; Put '[JSON] () -- update :&lt;|&gt; Capture "id" i :&gt; Delete '[JSON] () -- delete -- the last three could be written: -- Capture "id" i :&gt; (Get ... :&lt;|&gt; ReqBody ... :&gt; Put ... :&lt;|&gt; Delete ...) type MyAPI = "users" :&gt; CRUD UserId User :&lt;|&gt; "products" :&gt; CRUD ProductId Product So you can group things logically and try and define your very own notion of resource that supports your needs. Since those are just types, you can easily define them in different modules, transform them and abstract any kind of boilerplate into a reusable solution.
But shouldn't you use orElse with anything that could be an infinite loop?
https://www.cs.uoregon.edu/research/summerschool/summer14/curriculum.html Designing Dependently-Typed Programming Languages — Stephanie Weirich might also be of interest, it may be somewhat too advanced though
This looks very interesting!
Ok, thank you, i guess i have no other choice.
It has swapping, cabal update uses more than 500 MB of memory, it's rediculous.
a really basic api wrapper: https://github.com/intolerable/googl-haskell/blob/master/src/Googl.hs a more complex api wrapper: https://github.com/intolerable/reddit im using my own [`api-builder`](https://hackage.haskell.org/package/api-builder) package for these, if you have any questions about anything specific i'd be happy to help
The first piece of advice I give to anyone I meet who's interested learning about/implementing compilers (of any kind) is to *write the parser last*. Parsing is a rich, and for some extremely satisfying) subject, but it's probably the least important part of a compiler. It's also where almost every treatment of compilers starts. But it's a trap! You'll want to change your concrete syntax as you gain a better understanding what you're doing. You'll find that you'll need to experiment with a bunch of different ways of representing your abstract syntax. You'll realize that such-and-such clever trick would make everything so much cleaner, and then say "oh, but my parser is so beautiful! and it took days to handle that nasty shift-reduce conflict..." and then you'll be sad because you have to mangle your hard-won parser or keep it and have a dirtier rest-of-your-compiler. Also, concrete syntax design is actually pretty hard. It's a rat hole that keeps lots of people from ever getting to "the good parts" of the compiler. When you can't possibly get any farther without concrete syntax (perhaps because you need to start writing tests of larger programs, and coding in the AST becomes too painful), use S-Expressions. Aside from being perfectly sufficient concrete syntax in their own right, they're well supported in lots of places. Emacs already has great support (on its own, but especially with `paredit`); and since all those ruby folks got into clojure, I'm pretty sure there's plenty of great Sexp to be had if you swing that way. (I haven't done much lisp in Vim---emergency edits to my .emacs notwithstanding---so I can't say much from personal experience there). Speaking of S-Expressions, some great background reading on functional language implementation (though eager, impure, and untyped) is http://haskell.cs.yale.edu/wp-content/uploads/2011/03/CompByTrans-POPL89.pdf, and possibly http://www.cs.purdue.edu/homes/suresh/590s-Fall2002/papers/Orbit.pdf (I don't think this latter was available last time I was looking at this work, so I haven't read it yet). Good Luck!
&gt; In my opinion I think this is a better proposal for fixing fail, fail _ = mzero &gt;Pros: * Less work - MonadPlus is already adopted in the mainstream. * Follows the same laws as suggested in the MFP because of this MonadPlus law: `mzero &gt;&gt;= f = mzero ` * Almost all monads with sensible fail implementations are instances of MonadPlus and set `fail _ = mzero` &gt; Cons: * Some monads use the string argument for error reporting. * STM is a monad with a MonadPlus instance but errors out on fail. (I believe this is a mistake but i cant find any literature on it.)
Why is the API SOMETIMES SHOUTING and Other Times Using Caps, while at stILL othER tiMES using a bizARRE MIX?
How `stack` works? It (also) automates `cabal` in some way?
Is any of this open source?
You might find it interesting that my first draft did exactly this: Passing the types in. socket :: (Family f, Type t, Protocol p) =&gt; f -&gt; t -&gt; p -&gt; IO (Socket f t p) ... s &lt;- socket (undefined :: INET) (undefined :: STREAM) (undefined :: TCP) I then noticed that this is not necessary and might feel even more awkward. Not having this information in the type would sacrifice the neat trick with the type families for associating address families with address types.
It was indeed a bit of a plot twist, and I can totally understand if folk don't quite make it to the end of what I write. As my wife occasionally says, "you can't expect me to listen to _everything_ you say!" :) 
He also didn't have to wait for several minutes (or, depending on the project and the hardware, tens of minutes) to wait until everything in the sandbox compiles from scratch. He also didn't have to remember to delete the sandbox which otherwise would consume hundreds of megabytes of disk space.
&gt; add a couple more simple commands This is a small barrier to entry. If a potential contributor hits a speed bump on this part, they are that much less likely to continue towards attempting to contribute. Dealing with sandboxes is not always simple, especially the "test all four packages based on changes to this one" part.
Part of the reason I liked silk's rest is it did that creative part trick for me.
I think it also worth noting that I was also able to be sure that the build on my machine was using the same dependencies as the build that other contributors are using. But this can also be accomplished with `cabal.freeze` so, not much difference between cabal and stack on this point. (Also `.halcyon/constraints` accomplishes the same.)
Haskell is not strongly normalizing, as it allows general recursion, which lets you define non-terminating functions, i.e. `f x = f x`. But the Y-Combinator, as you've presented it here, has still no type in Haskell. Inside your outer lambda, you have an application `g a`, where both `g` and `a` are `(\x -&gt; f(x x))`. The typing rule for function application concludes `g a :: t0` from the premises `g :: t1 -&gt; t0` and `a :: t1`, so it has to give `(\x -&gt; f(x x))` two different types, which induces the error message you have mentioned. Here's a Haskell implementation I found in a [stackoverflow answer](http://stackoverflow.com/questions/4273413/y-combinator-in-haskell) a while ago: newtype Mu a = Mu (Mu a -&gt; a) \f -&gt; (\h -&gt; h $ Mu h) (\x -&gt; f . (\(Mu g) -&gt; g) x $ x) where `f :: a -&gt; a` and the sub expressions of the function application have types (\h -&gt; h $ Mu h) :: (Mu a -&gt; a) -&gt; a (\x -&gt; f . (\(Mu g) -&gt; g) x $ x) :: (Mu a -&gt; a) Apart from the newtype wrapping, both expressions still embody the concept of the original `(\x -&gt; f(x x))`. The `Mu` type constructor here takes the least fixed point of the type constructor `(-&gt; a)`. It is the type-level version of the `fix` operator specialized to the function type constructor. I found [this](http://mainisusuallyafunction.blogspot.de/2010/12/type-level-fix-and-generic-folds.html) tutorial introducing the general concept. Often the name `Mu` or `Fix` is used for the general version of the `Mu` shown here. *edit:* I think the implementation mentioned by /u/jozefg is nicer than the one I found on stackoverflow. It uses the general typelevel fixpoint construction and more closely resembles the original Y-Combinator modulo newtype wrapping.
Hi joey, I already came across your efforts when doing research on this topic and the current state of affairs in GHC as well as in the network library. You've already done great work on this :-) Here is my opinion: - I don't think that it's really necessary to support Windows XP nowadays. Considering the pain and the limited usefulness I think it's fair enough to reject such features unless someone is willing to pay for it. - The fact that it only worked with `-threaded` is a little pity, but we could fall back to my improved polling approach. So, having a working I/O manager would still be a desirable improvement for the Windows world when people are willing to explicitly enable `-threaded`. - It would be nice if (however complicated the waiting mechanism might be internally) everything just cumulates in a little opertion like `socketWaitRead :: Fd -&gt; IO (IO ())`. My master plan was to just plug your finished I/O manager in there and not need to worry about updating and potentially breaking all parts of the library (or even worse related libraries). Is that realistic?
Some comments here (and the link itself) should be relevant to what you are trying to do: http://www.reddit.com/r/haskell/comments/2yqwgi/type_directed_spell_system_development/ Basically, if you want your cards to potentially have really crazy effects that screw around with the rules of the game itself, then continuations are something you could be interested in.
Yes instead when pattern matches could fail the desugarer would require a monadplus instance 
I think it's great that you've taken the initiative to do this! I'll give it a shot the next time I reach for a socket.
It already exists for alpine linux, the build scripts pick it up if you don't force integer-simple to be used. bash-4.3# ldd /usr/local/lib/ghc-7.10.1/bin/ghc | grep gmp libgmp.so.10 =&gt; /usr/lib/libgmp.so.10 (0x7fb987127000) 
It's just a few lines of code ... unfortunately none of it is open source. It's something like : data AuthRight a where Pure :: a -&gt; AuthRight a :&gt; :: Ord a =&gt; AuthRight a -&gt; AuthRight a -&gt; AuthRight Bool :== :: Eq a =&gt; AuthRight a -&gt; AuthRight a -&gt; AuthRight Bool CurType :: AuthRight UserType ItemAccess :: Key Item -&gt; AuthRight AccessLevel TaskAccess :: Key Task -&gt; AuthRight AccessLevel ... Now it might be nicer to just use a free monad and ditch `Pure` and all the operators, keeping only the `FooAccess`, but I just needed simple expressions. Then I have a function like this that powers most endpoints : service :: (Key a -&gt; AuthRight Bool) -&gt; Key a -&gt; Webapp b -&gt; EitherT ServantErr IO b That authenticates the user, checks its access rights, and finally runs the provided action.
Nice, thank you!
Ok so the ffi stuff has been fixed in 7.10.1 I verified that. But I have a quick question for everyone, depending on how I build this ghc, the binaries it produces are vastly different in size when statically linked. With llvm and -O2, the helloworld program from the bindisttests folder is ~10 megs unstripped. With -O2 alone with native code gen, its ~7.5 megs unstripped. With -O0 for some things like base libraries I can get it to 1 meg which I think is how the gentoo port was compiled. But this all affects the resultant binaries runtime performance. So not sure what everyone would want. I'm leaning towards -O0 honestly just in case this port has hidden issues that take more exposure to expose. Anyone have thoughts/care? I personally don't care, and might prefer the -O2 -fllvm build but I'm weird that way. I'm going to build apks tonight with -O2 and non llvm backend mostly because it helps build these apk's faster. For the moment these apks for ghc 7.10.1 and cabal won't be in the alpine package archives until I sort out how to get them into alpine linux upstream if thats ok. ghc needing to be bootstrapped makes this more annoying than it need be. I haven't started on 7.8.4 either but I'll do all this in a bit. I'm still not 100% happy with the nopie bits but I don't quite understand all the moving parts to know if its truly needed for the alpine hardening setup.
&gt; The short answer is that by making stack a brand new tool, we were able to iterate and add new features much more quickly. Or you just want to have control over haskell ecosystem.
I fixed this by adding stylish-haskell as an external tool. You can pass it the `-i' flag and it works very nicely!
I feel you. I like Spock the most out of everything I tried, but I'd be willing to use whatever meant I didn't have to write another authorization system. The guy who wrote Spock also semi-recently created a user management librrary https://hackage.haskell.org/package/users. I'm skeptical of things like Servant that want to do a lot for me, but I haven't looked too far into it. 
we like to have competing libraries, they explore the design space and make each other better why don't we want to have competing build tools? halcyon, nix, stack, and cabal are each a different take, and who knows which is the best for any one situation?
&gt;I don't see how this buys me much. In this whole workflow I can pretty much s/stack/cabal/, add a couple more simple commands, and it works fine. These other simple commands are undiscoverable to newbs :( Off the top of my head, they have to remember to: * (install ghc and put on path) * (install cabal and put on path) * cabal update * cabal sandbox init * cabal install --only-dependencies * cabal configure --enable-tests * cabal test Compared to: * (install stack and put on path) * stack test If they forget to sandbox, they'll probably mess up their user package db when they install something else. The --only-dependencies flag is magic that took me ages to discover. Why should I need to cabal configure and enable tests at all when cabal test should handle that? By this point the new haskeller has given up. I see it all the time as I introduce people to haskell - they almost always quit because of cabal. &gt; But if I use stack I'm locked into stackage. This is great for the newbie, they packages will always install and work together. You can build packages outside Stackage using `extra-deps`. &gt; If these benefits are really that significant why not contribute them to cabal Cabal's UI is hopelessly convoluted. We could change it to something simpler but it would break backwards compatibility. The cabal codebase is also big and scary, having stack as a new thing helps speed up development and gives the stack authors more control over what they want the end state of stack to look like. &gt; so that every haskeller can reap the benefits without needing to switch their workflow to a brand new tool? Everyone can reap the benefits by downloading it now. Work flow switching is quite easy, you just install stack and write a 5 line stack.yaml, reusing your current cabal projects. 
Does `cabal-install` not want the same? What's the problem here?
This sounds pretty crazy. The stack authors are not trying to wrest control of the haskell ecosystem - they're merely trying to make a better tool to deal with some of the shortcomings of cabal. You can always keep using cabal if you want to. 
Does stack pay attention to a .cabal file if it extsis, or do I have to duplicate dependencies into the stack file if I want to provide both methods?
As long as the right versions are there! EDIT: ah, looks like the ability to choose a snapshot will help that greatly.
It's not crazy to think that what FPComplete's doing ( building its parallel ecosystem) is guided in part by business considerations, or to get a little annoyed when they pretend otherwise. But I agree it's nothing to get worked up about and indeed I think it's great that they've been able to explore these problems from a clean slate.
&gt; The short answer is that by making stack a brand new tool, we were able to iterate and add new features much more quickly. I think that's a great reason. That's exactly what happened with cabal-dev and cabal-meta, both of which I used in the past. But I think the community would benefit more if you took your findings and contributed them back towards improving cabal-install (which is what happened with both of these packages) rather than spending time and energy trying to get people to switch to stack thereby fracturing the community. In short, stack should be an on-ramp to cabal-install, not a completely separate road.
I Thaught IORefs weren't meant for modification across threads? I have tried using TVars but the exact same error occurs (i assume they use MVars internally) 
I think it's a *valid* concern that FPCo *appears* to consistently prefer to develop green-field solutions rather than work with existing infrastructure. I emphasize those words because I personally don't think it's a correct concern, and I suspect that it's an appearance rather than the truth. I find your justification persuasive. But it's proper for the community to question potential NIH syndrome, especially as regards central infrastructure projects.
&gt; These other simple commands are undiscoverable to newbs As I mentioned above this is not entirely true. Most newcomers I talk to already have sandboxes set up. &gt; This is great for the newbie, they packages will always install and work together. This is not true. My [problem with curation](http://softwaresimply.blogspot.com/2015/06/the-problem-with-curation.html) post provided a concrete example of this. Curation/stackage/stack/et al are not a panacea. &gt; Cabal's UI is hopelessly convoluted. We could change it to something simpler but it would break backwards compatibility. It seems quite plausible to me that "cabal test" could be changed to something that also does a cabal install if necessary. If not, then we can certainly create another command, "cabal go" for instance. &gt; Everyone can reap the benefits by downloading it now. Not true. Many of us are working on the next versions of the libraries that will go into the next stackage release. You can't use stackage in this case.
Is there a URL for this thing?
Not using sandboxes does not automatically end in cabal hell. Most of the time things build fine for me. It only ends in cabal hell if you install one thing then install something else that needs different dependencies than those already installed, or if you are installing things that don't have proper PVP-compliant upper bounds.
https://github.com/commercialhaskell/stack#readme
Yeah, but the business considerations driving this are that businesses starting out with Haskell shouldn't have to master a clunky, slow and error-prone package installer before Haskell. Removing big pain points is good for FP Complete's business and good for the rest of us. 
You can only leave the auto-generated `stack.yaml` alone if you have no extra-deps. I don't believe that stack is smart enough yet to correctly generate extra-deps without some human intervention. But the process of * `stack build` * copy suggested extra-deps into `stack.yaml` * repeat Usually goes most of the way. I just wrote up a `stack.yaml` for the lambdabot repo using this process. After the automated help, I had to do two more things manually: * select an older version of IOSpec than was suggested, because the suggested version wanted base &gt;=4.8 when I wanted to use ghc-7.8. * select an older version of utf8-string (the one in the snapshot was too new) Both are considerations that stack will probably get smart enough to do automatically, but it's not there yet. See also: https://github.com/lambdabot/lambdabot/pull/124
+1 for more Haskelly names. Predictability is important. A bizarre mix of capitalization is no good. &gt; SeqPacket &gt; Inet Yes to these. &gt; What to do with something like IPV6_V6ONLY? I think /u/bos has a good point here. We're not writing C. Consider dropping the IPV6 prefix on all of these [socket options constants](http://man7.org/linux/man-pages/man7/ipv6.7.html), as well as any other prefix-y constants. The prefix is there so that C programmers know these constants are all related. In Haskell we have sum types; we don't need the prefix. `IPV6_V6ONLY` -&gt; `V6Only` Maybe even consider eliminating [boolean blindness](https://existentialtype.wordpress.com/2011/03/15/boolean-blindness/) from this particular boolean flag. I suggest adding a link to the source for the meaning of the C flags, i.e. a webpage. Then the user has a guide if they're not sure what a constant means.
I feel like it should be noted that LTS Haskell relies on semantic versioning. LTS Haskell releases are semantically versioned with a major and minor component. A minor upgrade (e.g. from lts-2.13 to lts-2.14) can only include minor version bumps in the packages, and it is expected that LTS Haskell packages are semantically versioned. As for PVP proper, packages can both follow PVP and be included in Stackage. However, Stackage does not require PVP adherence, only adherence to semantic versioning and successfully building with the rest of Stackage. &gt; while package authors don't assume that you use one certain tool and break all other tools Well, let me give another example: ghc-only language pragmas. Authors who use language pragmas unique to GHC are leaving Hugs users in the dust. Should GHC feel bad for having better features? Should people avoid GHC, or cater to Hugs? I don't think so. It's no secret that `stack` is trying to be a better `cabal-install`. I don't think stack should feel bad for allowing authors to care less about strict PVP adherence. I do think authors should feel bad if they are neglecting the legitimate needs of their users. If you are the user of a given package that doesn't adhere to the PVP, then send them a patch! Offer to keep their dependency constraints up to date. The reason people shirk their PVP responsibility (particularly: upper bounds) is because they find it tedious and burdensome. If someone else is willing to do that work, then the tedium and burden is lifted. But if you are just throwing on pre-emptive upper bounds that don't provide any benefit to the package *today*, you might get some pushback, because pre-emptive upper bounds today usually creates an additional work item of bumping up those bounds tomorrow.
&gt; there's evidence that [it encourages behavior that causes problems for the rest of the ecosystem] I do see evidence that stackage has encouraged some people to be lax about upper bounds. I don't see evidence that this causes real problems, nor do I see evidence of other problems.
&gt; I think it's a valid concern that FPCo appears to consistently prefer to develop green-field solutions rather than work with existing infrastructure. Acknowledged. Skepticism is absolutely welcome. Criticism is absolutely welcome. You don't have to trust FP Complete; take a look at the source! Raise concerns in the issue tracker and on the Commercial Haskell mailing list! Make your own fork and do it better, or build the same features into cabal! I personally think that the project stands well on its own merit. Anyone with concerns: take a closer look, ask questions, let's hash it out. We've got nothing to hide.
The GHC API is many things; easy to get started with is not one of them. (At least, it wasn't for me. Your mileage may vary.) To make it a bit more accessible, I broke out the compiler driver parts of Haste and generalized them slightly. The result is a small library that lets you use GHC to extract various information from Haskell code in a fairly straightforward manner, without having to first figure out how GHC works under the hood. The plan is to add some additional scaffolding on top, to automate bootstrapping any custom compilers built using the library: automating storage and bookkeeping for application-specific intermediate code, loading dependencies on demand, that sort of thing. I'm curious if this may be of use to anyone outside of our department, and if anyone has any features or API enhancements to suggest to make it useful to a wider audience.
I have moved to use TVars for everything now, as many people have pointed me in this direction away from MVars. HOWEVER! I still get the error (even if i use IORefs and atomicModifyIORef!!) which is leading me to belive the issue is caused by a library that I am using (current potential culprit is the websockets library)
&gt; &gt; We do want to be empowered to make the Haskell ecosystem better, and we weren't getting enough of that when limited to just making PRs on cabal-install. &gt; Is that an assumption, or something that was tested? I don't want to put words in /u/snoyberg's mouth, but this is the gist of what I understood from what he's told me about his interaction with the cabal project. I'll leave it to him to confirm/deny/elucidate. &gt; I don't know if having a discussion about [reconciling stack and cabal-install] would reduce concerns about the fragmentation or stir things up further. I think it is definitely a discussion that should be happening.
&gt; They tell you what dependency versions your package has been verified to work with. They aren't guaranteed to tell you that, but they *can* tell you that, yes. More often, they tell you what versions the package is *expected* to work with. And if someone ever hits a case that doesn't work, then the issue is hopefully reported, and then the version bounds are adjusted accordingly. &gt; The community has a clear standard, the PVP. The community is far from united on this standard. &gt; This alternative approach is based on the assumption that you can synchronize the world. I disagree. It's based on the reality that a portion of the world *is* synchronized under the Stackage project. The whole world doesn't have to be synchronized in order to reap the benefits of a part of it being synchronized.
I don't believe this is currently possible, but should be doable. Pinging /u/chrisdoner.
Sure. Suppose you have two sandboxed projects. Project one depends on A B and C. Project two depends on A B and D. With sandboxes, you will end up with two copies of A and B. In Nix, all the libraries are located in the nix store, and each project is given access to only the libraries it requires. So you end up with a single copy of each A B C and D. Nix just tells the compiler where to find the necessary libraries behind the scenes. So when compiling project one, it'll tell the compiler where to find A B and C. When compiling two, it'll tell the compiler where to find A B and D. The compiler won't find libraries it isn't supposed to because they're stored in a directory named with a massive hash - a very undiscoverable location. Chroot can also be used to enforce this constraint of not finding libraries the compiler isn't supposed to a little more strongly.
snap depends on clientsession and has upper and lower bounds on this dependency. clientsession depends on a number of other packages and only has upper bounds on two of them. One of those packages, say crypto-api releases a new version that makes a breaking change. That change was PVP-compliant and its major version number was changed appropriately. Cabal thinks that clientsession is fine with this since it satisfies the nonexistent bounds. So it chooses the latest version of crypto-api in its build plan. But it just so happens that clientsession won't work with this new version and the user gets a build error. If clientsession had complied with the PVP and put the appropriate upper bound on crypto-api this problem wouldn't have happened. Cabal would have seen that clientsession hasn't been verified to work with that version of crypto-api, so it would have chosen a different version and everything would have built fine. I can't tell you how many times this has happened to me over the last few years. One day my package is working fine. The next day I have changed nothing and now my package won't build. It's always the same culprit...a package that don't conform to the PVP. The bottom line is that when a dependency of yours makes a major version bump, you can't assume your package is going to work with it. You need to check and explicitly warrant that it does.
&gt; One idea is to have cabal look at the upload date for the selected clientsession, and only choose a crypto-api that is older than that. That solution won't work because there might be bugfix releases for old versions that are not being updated to the latest versions of everything. &gt; My point is, this could be cast as a tooling issue. I have been saying that this is a tooling issue for ages. But in order for the tools to work effectively they NEED version bounds. &gt; Since snap and its deps are in stackage, you can just tell people who want to make a snap app to use the stackage versions. Or you could maintain your own cabal.freeze file of the "recommended" versions of snap and its deps, and tell people to build off of that. None of these approaches are acceptable to me because they overly constrain my users. &gt; There is no way to guarantee that people will put correct and good bounds on their packages. That's not a valid reason to not use bounds. We have Hackage trustees who have the ability to fix version bounds when it is discovered that they are bad and causing problems. &gt; But there is a way to get reproducible builds for a given project: lock down the dependencies. Guess what...version bounds are a more flexible way of locking down dependencies. Locking them all the way down to a single version is useful in certain situations, but is too limiting in general. And as you know cabal-install already has the ability to do this with its freeze file. 
Personally I have found that using Stackage (nightlies) has been really nice. But has there been any consideration of maybe adding a `hackage` resolver that just directly uses Hackage? I realize that it may not be considered best practice, but it could perhaps quell a lot of the anxiety people have about "relying on FP Complete". And I could see myself using it as a CI job (parallel to my normal jobs using stackage) to give me advance warning of any incompatibilities with the cutting edge in the ecosystem. Another thing I can imagine would help is to officially move management of Stackage under the umbrella of a community organization such as the Commercial Haskell group. I know Stackage is open source[1], but the "management" is another thing. [1] Actually, is it really all open source? Even boring deployment automation and stuff?
It could in theory. I personally don't see that happening anytime soon but I could be wrong.
I hear what you're saying, and I probably could have been more moderate in expressing this. That being said, if you have a type checker or some static analysis written on your AST, I wouldn't call that nothing to show.
I hope I didn't imply that questions don't belong here. I certainly don't feel that way. However, in light of OP's proposal for a questions only thread, I think not acknowledging a questions only subreddit first would be a mistake. On the flipside, imagine seeing a subreddit with a lot of haskell discussion, but is often about very advanced topics, and then finding out about /r/haskellquestions from one of the comments (because no one reads the sidebar as much as they should) and feeling like they finally found a good repository of questions from newcomers like themselves. 
Welp, never read some of the dark corners of ghc source code then or we may never see you round these parts again.
Ah, the time honored technique of Socratic trolling.
&gt; We could change it to something simpler but it would break backwards compatibility. It doesn't have to change backwards compatibility. Just make new binary called `cabal-new` or `cartel` or something.
The point of arrows is that some things are arrows but not monads.
You can also point to a git or http url directly: packages: - some-directory - https://example.com/foo/bar/baz-0.0.2.tar.gz - git: git@github.com:commercialhaskell/stack commit: 6a86ee32e5b869a877151f74064572225e1a0398 
If you're interested in type theory, the de facto standard intro text is Types and Programming Languages. It starts with an evaluator for the simply typed lambda calculus and from there extends it with more and more complicated features, like objects, subtypes, exceptions, polymorphism, etc. It is a great text for language designers, every type system discussed has an example evaluator and type checker/inferer (implemented in ocaml, but it only uses basic ocaml features, so any beginner haskeller should be able to understand it no problem).
&gt; you still get a very odd type class but with laws.
This is awesome 
Apart from what others have said, one good use for arrows is for modeling pipes and streams, kind of like the Bourne Shell (UNIX shell) concept of pipes, and Haskell has a language extension enabling the syntactic sugar for this kind of pipes programming. Arrows provide the Lego-block-like functions to which the pipe programming syntactic sugar translates, in much the same way that monads provide the Lego-block-like functions to which the imparative programming syntactic sugar translates. 
Applicative + Category gives all the power/guarantees of Arrow, iirc. 
I believe `stack exec ghc-pkg list | grep aeson` is what you're looking for. Generally, `stack exec` runs commands with 1) ghc configured to use stack's 3 package dbs (global, snapshot, project), and 2) the right ghc, as well as the snapshot and project bin dirs on your path as well.
Thanks. I think that is what I'm looking for.
TCO is apparently already on the agenda: it seems that it's [proposed for asm.js](http://discourse.specifiction.org/t/request-for-comments-add-a-restricted-subset-of-proper-tail-calls-to-asm-js/787) (see also the [Firefox bugzilla](https://bugzilla.mozilla.org/show_bug.cgi?id=1133529)), and is listed as a ["future feature" for WebAssembly](https://github.com/WebAssembly/design/blob/master/FutureFeatures.md#signature-restricted-proper-tail-calls). 
Adding to Dan's response: I quite like having an explicit list of extra dependencies. Sometimes cabal's constraint based dependency resolution doesn't work out so well, and it picks an archaic version of a package. By having a list of extra dependencies, you get to explicitly ask for this if you really want it. Instead of being at the whim of cabal's relatively opaque solver, you get to be in the driver's seat.
I would appreciate if the documentation prominently notes the C-names. I still like to look into my old unix books when doing network programming in haskell.
Does this mean, you can't interleave `cabal` and `stack` invocations on the same project?
You can interleave them, but they won't influence each other at all. They use separate directories for all of their build work.
You have X a Mu (X' a) Mu X' -&gt; a (Mu X' -&gt; a) -&gt; a ... I think the last two `Mu X'` should be `Mu (X' a)`.
You can look at the stackage snapshot online as well. If you have `lts-2.14` in your `stack.yaml`, you can see all the packages and version at https://www.stackage.org/lts-2.14.
I statically link my executables on Windows, and that's the default behaviour IIRC. When I wanted my friend to run my application, he just copied the 7MB executable. No hassle, worked like a charm. For libraries (when the end-user *is a developer*), using cabal seems fine.
That's correct. The equivalence relies on a bit more in Haxl, in particular the result of doing a concurrent/batched fetch should be the same as doing sequential fetches, but if we assume that, then we can assume `&lt;*&gt; = ap`.
Do you want to distribute sourcecode or binaries? For sourcecode i think stackage and cabal are sufficient - as people wanting the source want to develop anyway. What is needed is somthing to bundle up everthing you have in your working-directory .. like a cabal bundle &lt;target&gt; where target is something like "windows" "osx" "arm" "unix" etc. sadly this would also bundle all the dependencies into a package. But i think this is a good thing when you want to deploy to end-users. They just want to install their *.msi, *.exe, *.deb, ... and have things working. I think the usual unix-way of sharing resources is not (yet) feasible with Haskell as libraries are changing too fast and you cannot force a dependency on the client. i.e. i want to deploy my yesod-app and i just noticed a change in authorization for from version 1.4.2 -&gt; 1.4.3 wich will break beginning with 1.5 or 1.6. So either you clutter your code with pragmas like #ifdef yesodver &lt; 1.5 ... #else ... and basically replicate every change of any library in your code so the suggested `cabal build` can figure stuff out or you have to restrict yourself to "stable" libraries provided by your target - thus shutting yourself out from recent changes or whole libraries. tl;dr: * for sourcecode-distribution i think stackage is enough * for end-user-distribution we need to pack everthing into one package (or even one binary) and suffer that the enduser wastes diskspace as libraries don't get shared
I think support for resizing asm.js heaps has been added https://bugzilla.mozilla.org/show_bug.cgi?id=965880
I think the idea was always for cabal-install to work like this as well: always use sandboxes by default, and have commands like `cabal test` automatically install dependencies if needed. I'm sure pull requests would be accepted ;)
So your point is that upper bounds are good and the PVP is good. You're worried that by removing the pain from general users, package authors in particular will be too far removed from the pain of folks still using cabal, and will be lax with their version policy. Can we not get hackage and stackage to warn people or even error when their upper bounds are missing or worryingly wide? Surely that's targeting the cause of the problem, rather than forcing the entire community use a slow, clunky, over-complex and desperately error-prone build system with defaults that are strongly advised against by those in the know. Be stricter with the uploading minority and let the downloading majority have the nice tooling. I've waited _years_ for this major wart to go from the face of this beautiful programming language, and you feel it's a problem because it _doesn't_ slap me in the face on a regular basis with package version inconsistencies? It makes it _too_ easy for me? I can't agree with you, I'm afraid. 
I also want to be productive and produce maintainable code. I already decided that FP + immutability + types + reactive programming is the way to go.
&gt; I started this project to learn about signal processing. What resources are you using to learn about DSP? In particular, what do I need to read in order to write such a library?
So you advocate making the upload aspect do more checking. Sorry, it sounded to me that you didn't want people to use stackage, whereas you actually just want it (and other tools) to promote upper bounds more strongly. 
I want hackage to do that checking when you upload and reject the package if it is missing version bounds. I never considered the possibility that stackage might do that because its creators and advocates don't use upper bounds themselves, and based on this thread it doesn't seem like that has changed.
I think this is a fantastic idea.
I use Js_of_ocaml (and Js in Ocsigen context) and in my opinion, it's a very nice project.
This is phenomenal! I hope that in the not-so-distant future, this library (or some variant) will fully take the place of "network" at the top of the dependency tree.
I use Haskell for a VoIP call rating engine. It is very flexible.
GHCJS is probably fast enough for your UI, but it's at least 3 times slower than hand-coded JS. That's a deal breaker for me. Scala.js and Dart are much much faster. Also 1 MB is considered quite big if you want to support mobile devices as well.
I think that the situation will improve now that Scala.js is out of beta and more people are considering it for their next project. Let me ask you a question. Why do so many people use IntelliJ? What's wrong with the official IDE based on Eclipse?
Why are using `&lt;|&gt;` from Alternative in the second definition?
I would like to know more as well. We are doing experiments porting a substantial application to Elm, Purescript and now GHCJS (Reflex), and found little difference in performance, if any. The application is quite large even in the original Angular.js implementation, so the increase in size was negligible, the increase in performance, however, is noticeable.
btw, I think you mean Closure compiler, not Clojure :) 
Because I didn't type check my code :) Thanks for noticing!
Based on your requirements, I would probably recommend Clojure + ClojureScript. Works nicely on client and server, there are nice libraries and functional programming using immutable data structures. Additionally, ClojureScript compiles down to really efficient JS which might actually end up being faster than *native* JS (escpecially if you want to use something along the lines of react.js via om/reagent/reacl). ATM I don't see GHCJS generating usable JS if you want to support mobile or your SPA to be fast and responsive. I sure hope this is going to change but as of now, I'll stick to CLJS with the occasional look at Elm.
What I do depends on what my clients need. For instance, my next project is going to be a mobile-friendly forum. Faster and shorter JS means a better experience on mobile platforms. Faster JS also means lower battery consumption, so the faster the better.
&gt; But if the primary build tool changes, then the PVP could change with it. Consequently, as long as the majority keeps using `cabal`, there's no point in changing the PVP in a way that breaks for `cabal` users... I think it's perfectly fine if there's a group of developers want to experiment with alternative build tools such as `Stack`. But if you upload to Hackage, you're supposed to follow the PVP. Just like you wouldn't insist that left-hand driving is the only true way, while the majority is behind times adhering to the right-hand traffic convention... Please don't be a wrong-way driver!
I wouldn't hold my breath just yet. WebAssembly is a waporware and will stay so for at least a few years. 
It's a platform-dependent problem, and even then you'd want to consider your audience. `cabal-install` is a build tool, not a package manager, so you're right in that it's totally inappropriate. For OS X, you could target `brew` if your audience is tech savvy, but not necessarily Haskell savvy. You could also package things up into an app bundle for end users. For Windows, statically link the executable and put together an installer. For most Linux distributions, build packages for each major package manager. For Nix, you don't need to do anything, you're already done.
To clarify: &gt; &gt;&gt; 1) Frege does TCO, as far as I know. &gt; &gt; 1) Frege turns recursive functions into loops. To do this fully it would make the linker very tricky (because you will need to build all the functions that might recurse together into the same loop). Doing it "fully" would be doing a trampoline, which is perfectly implementable in C or Java. (Unless by "fully" was meant "make all the other Java code I call from foreign functions also not allocate any stack when recursing, but I don't think that's what was meant by "Frege does TCO.") &gt; A loop is a much simpler construct that only works on recursive ones (or mutually recursive ones, if you're clever). Yes, changing some functions that are self-tail-recursive into loops is a limited specialization that I implemented in the Fay compiler. That said, Haskell's laziness shares behaviour with a trampoline: force the thunk, get back a thunk, force the thunk, get back a thunk. This is why `forever m = do m; forever m` runs in constant space.
&gt; ATM I don't see GHCJS generating usable JS if you want to support mobile or your SPA to be fast and responsive. Supporting mobile...you might be right. Fast and responsive...I have a complex GUI that says otherwise. And GHCJS allowed this to be done with code that is MUCH more maintainable and less prone to bugs.
[This pleases me](http://2.bp.blogspot.com/-Iw67tDAvy2Y/UJvr44XrxoI/AAAAAAAABKA/JJPt_qvyoqI/s320/lisp.gif).
Notably, if the monad is commutative—as Haxl is—then a concurrent `Applicative` *does* agree with the `Monad` instance. That’s one of the major points of our ICFP paper.
I have often wanted this.
Yes, but you do need `-XScopedTypeVariables` in order to explicitly type patterns.
GC is notoriously difficult to get right...
As is usually the case in software, you have to make a tradeoff. If you anticipate a significant mobile user base, then maaaaaybe GHCJS-generated code will be too bloated for you. But I absolutely don't think speed will be problematic. Are a few milliseconds here and there and few extra minutes of battery life worth the substantially reduced code compleity, fewer bugs, and better maintainability you can get from using GHCJS? In the vast majority of common applications I think GHCJS is a clear win. Also, I believe there is a big overhaul to the GHCJS code generator in the works. I'm sure this will improve code size and probably performance. Even if you decide that you don't have enough experience with GHCJS to warrant using it for your next project, I would definitely recommend using it for small projects in your spare time so you can get up to speed and better assess whether it will work for you.
 main :: IO main = do msg &lt;- getLine let _ = msg :: String ... I know it's a little upside down, but that trick has often worked for me. I'm opposed to the OP's syntax because it would require some sort of heuristic to distinguish it from do io :: T where `T` is some type headed by the monad.
It can be garbage even if there reachable pointers to it. It's garbage if it will never be used again. Implementing this exactly is, of course, undecidable. The pointer chasing most GCs do is one approximation, but there are others. 
There is a new shared typed array support coming in major browsers. It isn't here today in a meaningful capacity, but it will give us access to browser-based atomics, mostly for supporting things like emscripten and multithreading.
"Vaporware" seems like a somewhat strong term for [something with a prototype implementation](https://github.com/WebAssembly/polyfill-prototype-1). It's not a working product yet, but "a few years" is pretty pessimistic.
In this case prototype won't cut it. This is not yet another javascript microframework developed by one guy in his free time with 3 followers on github :)) This is a huge project that hinges on implementation and support by all major players (MS, Google, Mozilla, Apple). 
Yes all your teachers and colleagues could be wrong. They often are if they never coded in production. There is more to it than skill or knowledge, by the way.
If your app is just going to handle infrequent user events with a small amount of logic then you should be fine. If it has to animate things or perform complex computations then it will depend on the requirements. There is a lot of cool stuff you can do with GHCJS that will probably tax some mobile devices. For instance you could live preview markup text entered by users (like the GHCJS based [markup.rocks](http://markup.rocks/) does). However I think it should be possible to scale back most apps when running on low power devices. For instance markup.rocks could scale back on mobile devices so it: * Only downloads the conversion code for the most popular document types. * Only convert the document when the user stops typing for 10sec. * Only convert when the user presses a preview button. * Sends the document to the server for conversion instead of doing it on the client. And when that kind of scaling is not possible you can always resort to the JavaScript FFI to optimise the performance critical parts of your application. The best bet might be to create an example app of what you fear will be a pathological use case. If it is slow or power hungry share it and someone else might have a good solution.
Fwiw, you can't "accidentally" install into the global package db, as that would require root permissions
I'd recommend trying it with the reflex FRP library. Ryan Trinkle has really streamline the process of getting up and running with his [try-reflex](https://github.com/ryantrinkle/try-reflex) repo. Even if you don't need substantial reactive functionality that still might be the easiest way to get started. But if you're building GUIs, then I'm guessing you'll probably want FRP sooner rather than later. Check out [Ryan's talk at the NY Haskell Meetup](https://m.youtube.com/watch?v=mYvkcskJbc4) for a nice introduction to reflex.
I mean user db. 
This is getting ridiculous. Think what you want.
You also sometimes want `Bifunctor` (e.g. for `Either` or `(,)`) or `Profunctor` (e.g. for `(-&gt;)`)
Why don't you write a tiny project in each language and compare generated code size and performance? I don't think it's wise to rely on hearsay. The amount of times that "conventional wisdom" is wrong is astonishing. You'll also be more confident in your decision if you test things out yourself.
Two good references about that (practical-ish, not historical): [1](http://blog.downstairspeople.org/2010/06/14/a-brutal-introduction-to-arrows/) [2](http://gergo.erdi.hu/blog/2014-07-12-arrow%27s_place_in_the_applicative_monad_hierarchy/). They also provide `proc` notation (analogous to monads' `do` notation) that's useful for certain complex data-flow wiring (take a look at [auto](https://github.com/mstksg/auto) for some examples).
/r/haskellquestions gets very little traffic compared to the /r/haskell; I think this proposal would be a large improvement.
The only problem is that I already know Scala (I use it prevalently as a functional language) but I know nothing about Haskell. I was looking for some reassurance that learning Haskell was a good investment for someone who already is proficient in Scala.
My experience is that it takes less time to learn something than to assess whether or not its worth learning. This is especially true for the case of learning Haskell from Scala. The two languages are similar enough that it shouldn't take you very long to pick up Haskell.
&gt; Doing it "fully" would be doing a trampoline, which is perfectly implementable in C or Java. (Unless by "fully" was meant "make all the other Java code I call from foreign functions also not allocate any stack when recursing, but I don't think that's what was meant by "Frege does TCO.") What I meant is that Frege does not use function pointers or anything in its trampoline (I could be confusing it with some other language though). So if A can tail call B and B can tail call A (where A and B are functions in different compilation units) then the linker will need to build a trampoline function that can call both A and B. A() = Trampoline_AB(0) B() = Trampoline_AB(1) Trampoline_AB(f) = while true switch f case 0: f = A_impl(); case 1: f = B_impl(); instead of just having A() = Trampoline(A_impl) B() = Trampoline(B_impl) Trampoline(f) = while true f = f() Does that sound right or is Frege smarter than that (perhaps it uses a mix of both sorts of trampoline)?
I'm thoroughly for this idea. /r/haskellquestions gets very little traffic, so I think this would help, both by encouraging people to ask questions and by encouraging people to read questions. A lot of subs have themed days, and a lot of spin-off haskell subs have little traffic, so I'd probably suggest something like "TIL - Wednesdays", "Best Of - Fridays", etc. in addition to e.g. "Ask Anything - Mondays".
That may be true, but I know of at least one person who has them both open all the time.
+1 for noticing the ambiguity.
Your syntax highlighter is bad, that's all.
&gt; I'd prefer to choose a technology which guarantees a certain level of efficiency. The guarantee that GHCJS tries to provide is that if something is O(x) when compiled with GHC then it will be O(x) when compiled with GHCJS. This is what allows code to be shared between client and server without fear that it will go from say O( N ) to O( N^2 ). There will be constant factor differences and GHCJS aims to keep them small, but not all of them will be GHCJS related (for instance a mobile device will not match a high end server). &gt; So why not use Scala instead of Haskell? Too much baggage for my liking. &gt; Is Haskell so much better as a language? Yes, I think so.
Check out Data.Semigroups.times1p times1p :: Natural -&gt; a -&gt; a This also performs more efficiently that most list-based replicating method because it uses repeated squaring. Only issue is you can't use it to obtain `mempty`.
&gt; The guarantee that GHCJS tries to provide is that if something is O(x) when compiled with GHC then it will be O(x) when compiled with GHCJS. That's the bare minimum!!! I guess this isn't obvious in Haskell because of lazy evaluation.
I don't mean to be inappropriate, but why don't you and GHCJS's developers join forces?
This is a really great idea! I hope the mods take notice.
Hallelujah, this should have been done 15 years ago. Brendan / Mozilla fought pretty hard to keep any concept of binary format, byte code, common IL, pretty much anything that hinted at the possibility of a language agnostic runtime ever happening on the (ironically) O/S agnostic browser. But I guess only Nixon could have gone to China ... 
Have you tried a Cabal sandbox yet?
A version of `ghc-mod` that's compatible with GHC 7.10 hasn't been released yet. According to https://github.com/kazu-yamamoto/ghc-mod/issues/437, cloning the repository, and `cabal install`ing it should work.
EclipseFP already gives you more than this. I never have to manually edit a cabal file, for example. And again, EclipseFP is extremely limited compared to the best IDEs. 
The fact that cabal does not default to using sandboxes is terrible. Every new user falls into the trap. I'm considering advising new people to skip cabal altogether and use the new LTS tools.
Using it we can make a Monoid + Semigroup based 'replicate' that can nicely act in O(1) time on things like Any and All that are idempotent. I use this fairly often. I should probably add it to Data.Semigroup.
Note: it is better to repeatedly double. This gives you O(log n) replicate for some Alternatives/Monoids. Using the machinery in semigroups, sometimes it can be O(1).
So would I solve this by using GHC 7.8? Would I want to have both versions of GHC installed simultaneously (how would that work?) or do I need to downgrade? 
How do I use Cabal sandboxes? Is it different for projects and global packages?
Depends on the definition of "join forces". We have some different ideas of code generation, among other things, which means it's pretty unlikely that Luite et al would just dump GHCJS and start working on Haste, and vice versa. This is not a bad thing. There's more than one way to skin a cat, and often nice things come out of multiple people skinning multiple cats in different ways. However, I definitely agree that there could - and should - be more of a joint effort regarding infrastructure, common problems and other things. It just... Hasn't happened so far, I guess. [ghc-simple](http://hackage.haskell.org/package/ghc-simple) is one fledgling effort to make some of the work on Haste more widely useful, but probably not really useful to GHCJS though.
&gt; But the same is true of sandboxes. This isn't true of sandboxes for the very reason that you can have several of them. Yes, you can't have packages with conflicting dependencies in one sandbox, but you can have several sandboxes. &gt; You can have cabal hell in a sandbox in all the same ways you can have cabal hell without a sandbox. Yes, but you're bazillion times less likely to, as every project you're working with has a separate sandbox. 
Yes, but the second command may not. Since every new project will add it's own dependencies, the chances of cabal hell increase dramatically. My experience has been the opposite of yours, most users I know have been bitten by this, some to the point of even being dissuaded from learning Haskell. The only time they escape the trap is when they have someone more experienced guiding them.
There are instances that "fail" with error, such as STM, where their mzero retries.
I imagine that this will break a lot of code because of all the manifest types everywhere. Does anyone have any metrics on how often people use partial pattern matches in do expressions?
The original proposal has a section talking about this. I compiled Stackage and looked for how many do-blocks get fail desugarings.
To make this useful you'd have to factor the rest of do-notation out of Monad too. You're not really meant to invoke fail yourself, but partial pattern matches desugar into calls to it, so it mostly exists as a syntax hook.
This is correct. I've been using it with 7.10.1 for a while now. It's not perfectly happy, but it works.
&gt; Yes, but you're bazillion times less likely to, as every project you're working with has a separate sandbox. If you don't know about `rm -fr ~/.ghc`, then I agree. But for years I've viewed that as essential knowledge. Sandboxes are a nicer way of doing the same thing. I think rather than just trumpeting "sandboxes!" we should educate people about what's really going on that causes these issues and how they can be avoided.
Apart from time, space consumption is another thing to care about. Laziness can sometimes cause space leak, for example, check modifySTRef' in Data. STRef
I got a relevant question: What's the general view in the community (especially those connected to the Report-writing process) about eventually fully including some of the more popular extensions (this would come with some thorough investigations to make sure the extensions fit with the standardization, which is a plus)?
Side effects: I became more aware of them and have since tried writing code without them where possible while abstracting out the 'effectful' parts. 
&gt;that would require root permission Hiya, Windows user here ;)
It is without irony when I say that coding in Haskell allows me to be a whole lot dumber, letting the compiler guide me. I'm trying to recreate that experience to the best of my abilities in other languages. In particular, - Make undesirable state unrepresentable in the system, or at least so hard to create that tests are bound to catch it even when that's not what they're actually testing - Limit the range of implicit state as much as you can (given OOP languages that's pretty futile to be honest though) And on the theoretical side, I care much more about semantics and understanding the program now, whereas before the superficial impression of "works alright" was enough.
If I have two projects with confilcting dependencies, should I `rm -rf ~/.ghc` every time I compile one after the other?
is there a compromise? like using a chart parser, slower than happy but easy to write (can handle left recursion). then one might rewrite the parade at the end.
Haskell made me a better C programmer ---- When writing C, I sometimes encode my sum types as virtual table structs, which give me type-safety. (Haskell trick!) When I need a "let" constructor (for a local variable) in the C preprocessor, I encode it via a redex (#define a new macro and call it to assign the variable). Also a trick I learned when I learned how "let" can be implemented (if you don't have let generalization, at lesat). Haskell made me appreciate types more ---- I learned that declaring lots of precise types for extra clarity and safety is a great technique. Most of the programming world re-uses Bools, Ints, and other types for everything, despite not quite matching, as if an extra line or two for a type-decl is expensive. Haskell taught me that with precise-enough types, I can actually reasonably cover the *entire* dynamic space of all possible inputs I could have. Haskell was a gateway drug ---- Haskell was also a gateway drug to Agda and Idris. Having learned Agda and Idris, and some of the type theory behind them -- I can now pick up new languages much faster. Even ones that have a lot of interesting type theory behind them. I can read advanced academic papers, despite having no academic background. Laziness ---- Haskell taught me about the virtues of laziness, and their cons. Not sure if that makes me a better programmer :) Build stuff ---- Haskell lets me build stuff relatively quickly, while also having some minimal *trust* in what I just built. 
I first approached Haskell because it has a multi-platform compiler. What I actually loved about it was that nulls were not baked in the language itself. After that point, working on Haskell in real projects has taught me the importance of thinking about the problem beforehand. Its type system has pointed many, many mistakes I would've noticed too late (on production environment, probably) in other languages. In time, I made me think "how will I make this and that fit together?" and implement the glue using higher-order functions derived from mathematical structures (functor, applicatives, monoids, monads). Then, I started to miss all that stuff in other languages I work with. All that effort made me think differently about coding in general.
It fails for my syntax highlighter as well, but this works for me: (msg :: String) &lt;- getLine
IMHO, that would be a step backwards: Scala + Scala.js &gt; GHC + purescript.
I thought there were people from all of those companies helping with this project?
I know the canvas backend supports some level of interactivity.
Why do you think JS is not a standard? Can you elaborate?
&gt; Laziness To me it seems that a language can't be truly declarative without laziness. It seems declarative means separating execution from semantics. Strictness means that the order of execution is encoded in the expressions - so not separate and therefore not declarative. **edit:** It seems like this is a point that is made too seldom. Laziness is often criticised and I don't think I've heard this being mentioned as a counter point. 
I don't know that Haskell made me a "better programmer," but it definitely made me go "Oh wow... I guess computers *can* help me design programs!" which had been unknown to me, during my years of working only with python/perl/php/javascript-kind of languages. If writing code that is testable and simple to reason about is being a good programmer, then Haskell might definitely make you a better programmer. Because after practicing Haskell, it will become easier for you to frame computations in terms of pure functions. And so you will be writing pure functions in other languages too. And since pure functions are provably simpler to refactor, test, reason about, etc. you will be writing better code in those other languages.
Haskell has made me a better programmer because now I know Haskell. Now I have a good understanding of what FP, declarative programming, strong + static typing, etc. are all about, and what they feel like. But I will say that I'm paid to write Java and I've had a hard time taking what I've learned from Haskell and applying it when I write Java. But that was never my goal. I just wanted to have fun learning a new language and see how far I could take it. Turns put I really love Haskell. YMMV.
Right, that's the case where sandboxes provide the biggest benefit. But I think that a decent portion the time people won't have two projects with conflicting dependencies.
In a way, that's sort of what the HaLVM is. In a much more tightly integrated way, with a different design philosophy.
Yeah if your goal is shared typed code, I don't think you can do better than Scala + Scala.js
Oh, it is a standard. I was arguing that it shouldn't be.
&gt;Haskell made me a better C programmer ---- &gt;When writing C, I sometimes encode my sum types as virtual table structs, which give me type-safety. (Haskell trick!) As a C programmer by day and Haskeller by night, I'm very interested in seeing this.
Imagine a parse function: typedef struct { enum Tag; union ... // yikes! } Cmd; Cmd parse_cmd(const Buf *); And then you need an enum, and you need to be careful when you switch on the tag, etc. Vs: typedef struct { void (*strangle)(void *arg, Enemy *); void (*hug)(void *arg, Friend *); } cmd_handlers; void parse_cmd(const Buf *, const cmd_handlers *, void *arg); Less tedious, more type-safe, yay! As for the preprocessor trick, imagine you want to use `__COUNTER__`, the new preprocessor token that generates a unique (in this compilation unit) number by incrementing at every use. You do something like: #define MAC(x) \ do { \ int _var_##__COUNTER__; \ use(&amp;_var_##__COUNTER__); \ } Oops! Each use of `__COUNTER__` will generate a new number. Use a redex to emulate "let": #define MAC(x) \ MAC_(x, __COUNTER__) #define MAC_(x, counter) \ do { \ int _var_##counter; \ use(&amp;_var_##counter); \ } And now it works!
- It's helped me manage side effects better. I make many more pure functions now that get tied together in something that has side effects. This has the extra advantage that it makes my code easier to test. - It has helped me recognize and name certain patterns better. Even when I'm not working in Haskell, I often now say "Oh, this should be wrapped in a Maybe," or "this should be generalized to work over all monoids." I used to have said "this value might be null; I'd better make it a pointer" or "I need to get this to work for both ASCII and Unicode strings, so I'll make a wrapper class with two subclasses." I tended to write very verbose, over-engineered code. Now that I can put names to the patterns, it's easier to streamline things properly. - When I worked in C++, I would get annoyed that functions could only have a single return type when I wanted to return several different things depending on the context. I learned Python, and was thrilled that duck typing let me return any type I wanted, but then became wary/cautious because a function's return type might be anything at all. Now that I know Haskell, I see that what I really wanted all along was an ADT, and I now tend to structure my Python like an ADT when necessary. Haskell gives me the vocabulary to talk about how the code ought to be structured, regardless of the language.
&gt; It makes me a bad programmer in other languages, and I don't care that it does. Would you still feel this way if you didn't get to write Haskell at work? I have to write Erlang and I don't even know what the hell is going on, ever, even in the applications that I get to build from scratch. I wish I could forget that static typing exists at all, so I could focus on actually programming instead of fighting off nagging thoughts that my efforts are just going to be thrown away in three months by some unfortunate successor after an unsuccessful refactor attempt. Knowing Haskell is a curse.
And it will take all of them collectively at least 5 years to deliver a first iteration of a usable product supported across all major browsers.
Well, it's the first programming language I'm learning in depth, so it's probably made me better in most respects. If I had to single out one example, I'd say that Haskell's typeclasses have given me a much deeper understanding of the fundamental distinctions between different kinds of data and constructs.
That was meant to be a sarcastic "just a few" when I linked to your response on the mailing list :)
But "it doesn't do so bad" and "plenty sufficient" don't sound so comforting. Scala.js is "almost as fast as hand-coded JS". So the question is: "Is Haskell so much better than Scala to justify the risk(?) of producing slower applications?"
I'm learning Java now because I have a new job that requires it. I'm finding Steams and Functions somewhat familiar and more fun than "for" loops. I wish I had those when coding C++ in my previous job.
Haskell taught me that programming wasn't worth the effort. Even with a language which does the Right Thing more than half the time, I came to realize that software is limited not by specification or correctness, but by inherent complexity, time costs, and enormous social pressures. I don't program very much now, but I do tutor from time to time. Whenever I work with someone in Java or C++, I cry for them. They are taught bullshit methods and the world is in denial about it. You can produce someone who can write code, but their understanding of computer science is typically vocational. (I wonder how much this kind of phenomenon appears in fields like law or medicine). On the rare occasions I *do* do some programming now, I still reach for Python first. There are a handful of things about Haskell that I never got over how tedious they are. Records and modules are verbose. Typeclasses seemed to make my life more difficult instead of easier, trying to figure out which types satisfy the constraints. Documentation was always awful. (Does Hackage still not properly SEO its content?) I would not unlearn Haskell if I had the choice. There was so much interesting stuff to see. But after the dust settled and I finally understood the `Cont` monad, I realized that what I liked was not Haskell itself, but the introduction of mathematical principles to programming. 
One could argue asm.js is a Javascript source code representation of byte code.
No, it's a bad implementation from the post I referenced. To be charitable, it might have been a rhetoric device rather than a serious implementation (it did come with a large caveat that it assumed good choice of pivots each time).
Just about every conceivable helper function of monoid a helper function of lists, as lists are the free monoid. monoidReplicate x = mconcat . replicate x
It doesn't have to be upside down (note the `mdo`): {-# LANGUAGE RecursiveDo #-} main :: IO () main = mdo let _ = msg :: String msg &lt;- getLine ... May leave you with a weird taste in your mouth though.
And I always read my own [multi](http://www.reddit.com/user/rpglover64/m/haskell), but we're still just a drop in the bucket.
GHC is like a teacher holding a cane.
I was thinking of something like a web app designed to replace a shared spreadsheet with 1000 formula cells.
Note that I am not the author. I thought it was interesting and never saw it linked here.
&gt; I think you'll find that the bleeding edge of hackage is not consistently co-compilable, whereas stackage is. I already know this. But apparently a decent number of people still want to use it as their main source of dependencies, and it seems like maybe that's a use case that could be supported without too much trouble? I don't think it should be the default, but if people really think they have a good reason to use it, it seems reasonable to allow them to. &gt; You want to take stack Maybe this was a typo, and you meant "Stackage", but if you really meant "Stack" then I think your understanding of the situation is not up-to-date. Stack is the successor to stackage-cli, which was an FPCo-"owned" project which was given to the care of the Commercial Haskell group. The Stack project has a number of maintainers (with commit rights and everything) from all over the Haskell community, even me! (against good sense, I think ;-) For what it's worth, the second part of my post was about putting *Stackage* under the umbrella of the Commercial Haskell group, not Stack -- which already is! &gt; out of the hands of a company (going back to assuming we're talking about Stackage, not Stack) This sounds like an assumption that somehow moving Stackage under the official care of Commercial Haskell would prevent the current developers from continuing to contribute to it. Given that Stack has gone through exactly this transition, I think we have very good evidence that other projects (Stackage) could make the same transition. I *love* FPCo. I don't think they've done anything wrong at all, and I think they have consistently kept the best interests of the larger Haskell community in their hearts. The thing that pains me is that there are people who do get scared of the mythical "lock-in" of Stackage. I am not very convinced by most of their concerns, but I also do think that long-term, community resources like Stackage (especially if it becomes the de facto source of Haskell code) should have community oversight. I very much doubt that such a transition would prevent FPCo from putting their resources into it just as efficiently as now.
GHCJS has Threads, MVars and Async Exceptions. Why would you want those? If you have a calculation to do that may take too long can send it to the server before you start and if the result comes back from the server before the client finishes you can abort the local thread doing the calculation with an Async Exception.
Well, at least you managed to find a way to feel superior to both groups. [/s]
I agree with your comments about STL. Concerning Java-like streams in C++, your comment prompted me to look for them, and I just found this: http://jscheiny.github.io/Streams/. Perhaps there are others as well. 
How does the struct trick make everything more typesafe? Because now you have to know whether you are passing a Friend or an Enemy? #include &lt;stdio.h&gt; typedef const char Enemy; typedef int Friend; void strangle(Enemy *e) { printf("Strangle! %c\n", *e); } void hug(Friend *f) { printf("Hug! %i\n", *f); } typedef struct { void (*strangle)(Enemy *); void (*hug)(Friend *); } cmd_handlers; void parse_cmd(const char *b, const cmd_handlers *c) { switch (*b) { case 's': c-&gt;strangle(b); break; case 'h': c-&gt;hug((int*)b); break; default: printf("???\n"); break; } } int main(int argc, char* argv[]) { cmd_handlers c = {strangle, hug}; if (argc &gt; 1) { parse_cmd(argv[1], &amp;c); } else { parse_cmd("h", &amp;c); } }
+1 Haskell2015?
I try to avoid projects with conflicting dependencies by using global Stackage LTS contraints in my ~/.cabal/config file. 
As for the tail recursion bit, doesn't Scala have compile-time tail-recursion optimization?
Why not just msg &lt;- getLine :: IO String
Haskell taught me a few things: - how to master recursion - the value of types - how to build bigger code from small parts - the value of immutability and controlled side effects - the value of higher order functions - the value of laziness - a bunch of features which will someday arrive to mainstream languages - how to build abstractions properly - how interesting programming languages and compilers are - the connection of math to programming - bunch of math stuff just clicked right away when I studied them in college - it was a door to many other languages - that it is easier to write functional flavored javascript than imperative javascript - more and also: - how programming is broken - how hard and verbose it is to program without immutability and higher order functions (or even kinds!) Haskell also made me have to "start programming all over again", where if I'd continued using C++ I would be probably learning on more interesting and advanced domains, though I will get there. 
Ahh, okay. That makes sense, thanks!
Small nitpick: It's 4 years around, not 7. It is definitively possible to use frege in android, people have tried this. But it is of course far from practically usable. (I wish people interested in this stuff would contribute more.)
Why shuldn't it be a standard?
Indeed, this is very interesting, thanks for posting! There is a very nice [2015 paper on example-driven code synthesis](http://www.cis.upenn.edu/~stevez/papers/abstracts.html#OZ15) that would be a relevant point of comparison (and I have been working on related ideas myself), I'll contact the author about this.
I think rather a language is preferably *pure* by default to be [ideally] declarative. Haskell is pure by default and lazy, Idris and PureScript are pure by default and strict. All three have declarative constructs like monads. See also [how do we all feel about laziness](http://www.reddit.com/r/haskell/comments/36s0ii/how_do_we_all_feel_about_laziness/).
&gt; (I wonder how much this kind of phenomenon appears in fields like law or medicine). Probably quite a lot, sadly.
I was trying to think how to express my answer to the OP but I think you've nailed it. The C# and Python I write for work now looks as close to Haskell as I can make it. I break everything into small, composable units without even thinking now.
Because the typical alternative of a union with an enum tag lets you easily access the wrong union field by accident.
Not directly related to haskell, but more towards general FP (languages, like clojure, elixir, and even elisp) i have definately used functional techniques in the language i use most at my dayjob, javascript borrowed from other languages. I rarely use loops anymore, and try to avoid mutable state at all costs. Javascript does not force this, but as a result my code has far less bugs and is very predictable. The one thing i miss most is probably pattern matching. Having no/less sideeffects also makes it trivial to refactor code. Javascript having its roots in lisp, clearly surfaces when you think diffrently about your code, plus es6 brings alot of new stuff. Soon theres even tco, so recursion is a valid option too.
I wonder if Feynman would have liked Haskell (*"Write down the problem, think very hard, write down the answer"*) =)
I don't understand example about MAC. For example where x goes and why do you need to create local variable _var_xxx when you throw it away later.?
Int, int64, double, and so forth.
&gt; fundamentally different from earlier approaches to bring a) Haskell fundamentally? It's almost the same as Haskell on JVM. 
Honestly, I know nothing about Android either, except that it somehow runs on my phone. Hence, I can't give any serious advice in this respect. I assume technically it is about exposing the existing Android Java classes and methods as Frege types and functions - this is similar to the Haskell FFI, but tailored for JVM needs. 
Take a look at: http://neilmitchell.blogspot.co.il/2013/02/chasing-space-leak-in-shake.html
Oh, `MAC` isn't a real/useful macro, but it could be a part of one. Imagine it does something useful with `x` and `_var_##counter` after the call to `use` :-)
It must be pointed out that what you can expect is on the level of Haskell 2010 (not GHC), plus a different FFI specialised and exclusivly for JVM needs, plus a simple record system that gets the namespacing issues solved.
no of course not. just putting it out there for folks who hack on editor pluggins.
Yes, this is how it was meant. Specifically, simplifiying a bit, earlier approaches targeted 100% GHC compatibility, essentially writing a GHC backend plus a runtime system (this is where things get hairy). Whereas Frege was created to be first and foremost a *practical* JVM language. This means, similarity with Haskell is valued highly, but sometimes it is more reasonable to deviate. For example, in Frege, Bool is an abstract data type, and there are two literals *true* and *false* (just like in Java). Why? Because we want to interface with other JVM languages, and that means that we ought to use the JVM primitive types. But JVM types are all abstract, viewed from Frege, whereas Algebraic Data Types are not. So, would we give up consistency and make an exception for Bool? Not at all.
This cannot be done currently in diagrams, although it is something we would like to have in the future. You can get part of the way there using the diagrams-canvas backend, but that only displays on a local host and cannot be embedded into a web page. The only thing I can suggest is to pretty print the svg with the -p command line option and edit the svg by hand.
I think because in general the monad might have a complicated type that doesn't have a simple name like IO in scope.
Yes, Haskell is such an enabling technology.
Not that I have any experience with that, but I feel like any JVM language would have to make talking with Java very easy, and since it's an imperative language maybe using a less purely-functional and more imperative language would be a better option. Have you seen this http://www.ocamljava.org/ ?
&gt; this is only option to do pure functional programming on the JVM I'm hopeful it will get some [excellent company](https://github.com/slamdata/truffled-purescript) soon.
As far as seamless type safe client-server communication is concerned, you're not going to beat Scala + Scala.js. IIRC, GHCJS requires FFI, and even then it's only a one way street. Also, Scala.js generated code is at least 3X smaller than GHCJS, and is *extremely* fast (faster than native in some cases). Of course, for Haskellers that's irrelevant, GHCJS or Haste are the state of the art here. Saying that, if you want the best of all worlds, go with Js_of_ocaml, that has a laughably small overhead of 4-6KB ;-), is fully type safe, and an ML, so you'll get your FP fix to boot.
Why, in Haskell there is no problem with "imperative". As SPJ said, Haskell is one of the finest imperative languages. And this was only half-joking. Apart from that, we have plenty imperative, non-pure languages on the JVM already. Of course, the well known and highly valued ML implementations are among them.
LOL. This is like begging for a bread in front of the mansion. No one is coming out :)) The only people who would spend their time and effort to create a haskell IDE are the ones who code in haskell. 
The whole point of WebAssembly is that Javascript is horrible, there are many websites which will describe why that is the case. The number of compile-to-javascript languages is enormous just because people have to fight constantly against Javascript's shortcomings. If you need a simple overview from a Haskell point of view, take a look at "The Javascript Problem" at Haskell.org.
I think the open source community would be wise to forego closed-source corporate crapware. Also, other than cabal problems (though stack seems promising), I find haskell development on Linux using vim or emacs to be quite nice. It's not perfect, but if we want another editor then open source is the only way to go.
In the past that was Simon Marlow (and Krasimir Angelov) they wrote the original Visual Haskell bindings way back in the day.
Thanks. This is the closest thing in the right direction that I've seen so far. I think that to support this feature, `diagrams` itself would need to be able to track a map of arbitrary data (maybe of type `Map Text Dynamic` or `Map Text Text`) that backends could handle in a specific way. Or maybe since people usually work with a monomorphic diagram, there might be a way to extend only the SVG version of a diagram with extra fields that can be set. But I haven't explored the internals enough to know yet.
`PartialTypeSignatures` let you omit the type constructor str &lt;- getLine :: _ String
The pain is in the pudding.
AFAIK, support for concurrency in Ocaml is bad (like in Python) which rules out Ocaml for the server side. Also Ocaml's type system is less expressive than Haskell's and Scala's.
I'm one of the developers of diagrams. So you are on the right track, you should be able to add an attribute in diagrams-svg that can be added to the style of a diagram. Then diagrams-svg would handle the attribute. If you would like to work on it I can help you navigate to the right parts of the code base - join us on #diagrams, irc. If not perhaps file and issue on github in the diagrams-svg repo and hopefully one of us will be able to get to it in the not too distant future.
The "Debug nowhere" part is sometimes a problem though. We really lack debugging capabilities, and printf-style debugging inside GHC is really not much fun.
Though the JS code results in less bugs, is it efficient?
I've tried Frege, and I was fairly impressed with it given the niche it currently occupies. Quite usable. EDIT: Never tried using it on Android.
The difference isn't in performance as measured by real benchmarks. The difference is that the Scala.js developers make bolder claims than the ghcjs developers -- that doesn't mean those claims are necessarily correct. To be quite honest I don't have any reason to believe they are, absent benchmarks...
That's not true about ghcjs -- there are many ways to build automated type-safe communication over ghcjs.
In GHCJS I want to import and invoke my Yesod routes, how will you do this? In Yesod I want to invoke some GHCJS method, how will you do this? If this cannot be achieved then might as well use Purescript or other lightweight/performant alternative.
&gt; separating side effects from evaluation order How do you do that without laziness?
Law and medicine are both vocational degrees (despite the social luster that attaches to them), so I'd assume it happens a good deal. Guess what: engineering is also a vocational degree.
I think I'm on the right track now. Expect a PR from me soon.
This is logically equivalent to saying that most of the time, people won't get into cabal hell - not particularly helpful advice for someone who has that problem now or who would like to know how to avoid it. 
I feel this is misleading. Stackage gives you a carefully chosen set of package versions that can _all_ _always_ be compiled together. If you add one of the packages from outside stackage, it could potentially be incompatible, but (key point) this is when you _leave_ stackage's set. Asserting that stackage can cause inconsistency is like asserting that wearing a seatbelt can cause injury in a crash. It's not untrue, it's just very misleading. The truth is that seatbelts massively reduce injury, just as stackage massively reduces inconsistency. Stack is an easier way for someone to install packages, and it's not that often that a newcomer would need something from outside stackage. There's no sense putting new folk through the pain of using cabal needlessly. 
&gt; [graduated magna cum laude] So did everyone else on this board. I doubt that, although I understand what you mean.
https://github.com/diagrams/diagrams-svg/pull/82
I guess I did attach a bit of a negative connotation to the word. Shame on me. 
That's good news. I'll keep an eye on it.
It made me a better programmer by teaching me the value of tracking side effects explicitly in types. I don't think I've ever had a bigger or more important revelation in all of my 30ish years of programming. (Well, alright... aside from the more "trivial" ones like "I can make the machine do things for me!" when starting out on this incredible journey that programming is.)
Really good to see this being written up - it's knowledge that seems to get informally passed down, but it makes a huge difference when it comes to inference and building pragmatic libraries. Thanks Chris! P.S. you still need to merge my suggestion that uses even more of this trick to `lucid` ;)
Thanks so much for writing this up. I had never fully understood why this worked.
I think the [exceptions](https://github.com/ekmett/exceptions/blob/master/src/Control/Monad/Catch.hs#L184) library is one of the first instances (hur hur) of this that I encountered. :-)
This goes back to oleg I think. He did it before we had `~`, so he had to write his own `~` which he called `TypeCast` (and is actually a bit more powerful than `~` still, though closed type families bring us closer). http://okmij.org/ftp/Haskell/typecast.html The use of TypeCast was the key enabling trick in all the magic in the `HList` library. I think very quickly after the introduction of `~` lots of us realized that it could do about 2/3 of what `TypeCast` did, with a bit less hassle.
Hehe, the easiest way for most users to tell whether adding a package will cause a problem is to cabal install it! It's just that it will find this out for you rather slowly, and because it's not really a full package manager, there's no undo. 
First off, the way Haskell already does it (encoding `IO` as a stateful function wrapped in a newtype) works even in a strict language. Laziness has nothing to do with how Haskell separates side effects from evaluation order. Laziness was the *reason* that people wanted to side effects from evaluation order, but the actual implementation of the separation does not rely on laziness. In fact, Standard Chartered has a strict dialect of Haskell which achieves the exact same separation just fine. However, the way Haskell achieves the separation is not the only approach. Another approach is to encode `IO` as a syntax tree representing the effects that you want to run. Evaluating the syntax tree does not trigger the effects. See these two posts, which explain the syntax tree trick: * http://www.haskellforall.com/2012/07/purify-code-using-free-monads.html * http://www.haskellforall.com/2014/10/how-to-desugar-haskell-code.html (The last section, on `IO`)
Just to add a little historical perspective, there was a period a time (at least a year, maybe several) when haste was a way more usable solution than GHCJS. I know this because about a year and a half ago, I played around with Fay, Haste, and GHCJS. Haste was like a much better Fay, and GHCJS was that thing that seemed like the most correct solution but that didn't really work yet and could only be built by the devs working on it. I remember reading posts about whether or not it was abandoned or if it was ever going to work out. So, at that point in time, the choice of Haste seemed like a no-brainer for anyone who wanted to use haskell client-side. At the present time, the situation is different. GHCJS did actually work out, and now common folks can get it installed and working.
Visual Studio Code != Visual Studio. It's a lightweight editor more similar to atom. 
Actually, I've just re-read the parent. We have two assertions: 1. Using stackage (a pre-checked, guaranteed consistent package set) can help reduce conflicts. 2. Using stackage (a pre-checked, guaranteed consistent package set) can introduce conflicts. ..and you feel that the first one is just as misleading as the second? I'm afraid that I feel that this assertion about relative misleadingness isn't just misleading, it's plain false. In the first we mean conflicts that regularly happen to ordinary users while using that particular tool, and in the second we mean that _some_ people who advocate stackage have also avoided putting package upper bounds, so _allowing_ someone using a _different_ tool (cabal) to install a newer version of something that is inconsistent with another dependency. Using stackage itself doesn't actually _cause_ any problem. &gt; pain on both sides I think that applies to upper bounds. I personally don't have a problem at all with upper bounds, but it's fair to say that overly restrictive upper bounds also cause problems, not just overly lax or absent ones. I'm not asserting anything about relative frequency here, but I hope we can agree that _accurate_ upper bounds based on empirical fact and kept updated are better than being incorrect either way.
&gt; Constraints only apply after GHC has already decided it’s going with this instance. This is the "Aha!" moment for me. Can anyone summarize why GHC makes this choice? Why not backtrack and try another instance if the subgoals aren't satisfiable?
For one thing, how can you be sure that your constraint resolution is unique -- i.e. you need to prevent the choice of instances (or ability to find an instance) from being determined the search strategy.
&gt; (so that head . sort is fast) Maybe you can take inspiration from the [leftist heap implementation with the MinHeap policy](https://hackage.haskell.org/package/heap-0.5.0/docs/Data-Heap.html) (or just use that) (heap package, not the heap**s** one)?
I was hoping someone would actually find it an interesting challenge to try and optimize my code so that I could learn from it. I'm not looking for an actual fast implementation.
Yeah. That is why you need *even stronger types* :D (what, no I couldn't possibly be talking about Agda, or Idris, or Coq, or...)
[`DependantHaskell`](https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell) ...well, I can hope :p
Would be nice if there was an online course. 
It forces inversion of control, yes. That's a downside. You can regain control by building up an ugly union if you want, inside your callbacks. But at the implementor's side, indeed it is safer because they can only call if they have a `Friend` now. At the user's side, it is safer because they can only use a `Friend` in the correct case, but not the other case. So it is safer in both sides of the API. Note that if the parsing is light-weight, you can just re-call the parser with different handlers at any given point you'd otherwise switch on a tag.
&gt; Although, anecdotal, Windows users seem to have said high tolerance. what do you mean by that?
From what I see (I haven't tried it) it looks like Microsoft have taken their key feature of Visual Studio - debugging, then put it in an new IDE compromised of mostly free software, stripped user freedom from it and put it online. Usually people spend their time begging outside nonfree cathedrals for things like GNU/Linux support since they've already bought in to lock-in, but this cathedral was only built two months ago. I don't get how spending time adding Haskell to this would be a good idea for the community or the poor IDE users.
-XOverloadedStrings -XGeneralizedNewtypeDeriving
&gt; You have to understand how instance resolution works It's noteworthy that both the trick and the thing it replaces use non-standardized Haskell language extensions.
I wonder if it's a coincidence that the ~ operator is used for the same reason at the value level: foo (~True) = ... instance a ~ Bool =&gt; Foo a where ...
by the latter, you mean stuff like instance resolution, dictionaries, sharing, etc? It's be cool to have a longer list of "stuff to learn about GHC once you've learned Haskell".
what do you mean by "backwards"?
Is this part of haskell98 or does it use a language extension I need to read? Looking up the ~ operator on hoogle leaves me mystified as to what this all means. EDIT: I decided [this was a good place to start reading](https://wiki.haskell.org/GADTs_for_dummies)
Well, you know I'm the occam razor guy who whole heartedly believes we don't need anything more than the good old lambda calculus...
I don't think your two questions are that related, are they?
Very much a coincidence. =)
FWIW- I rarely use either of these extensions.
Thanks for the link to the overview.
[ParsecT](https://hackage.haskell.org/package/parsec-3.1.9/docs/Text-Parsec.html#t:ParsecT), for example.
Persistent defines two functions, `fromSqlKey` and `toSqlKey` which work on Int64: instance FromText UserId where fromText = fmap toSqlKey . fromText The first `fromText` attempts to decode an `Int64` and might fail. That is why you use `fmap toSqlKey` over the resulting `Maybe Int64`. EDIT: docs https://hackage.haskell.org/package/persistent-2.2/docs/Database-Persist-Sql.html#v:toSqlKey 
Ah ok. I hadn't thought about the case of several ways to succeed, only that introducing more modules allow you to succeed where you previously could not. Thanks.
Not sure why servant doesn't just use path-pieces, but you can still define your instance with to/FromPathPiece
&gt; there's some trickiness associated with compiling dependent types. What is the trickiness?
Any idea why you keep getting downvoted in this thread? Maybe some unpopular opinion or disputed fact I don't know about.
Thanks for reporting the issue. Can you explain what it does wrong? Screenshot?
You're both wrong. Dark matter is simply code that has been commented out but still shows up in the line count.
Me either, I just like to know when/if i'm missing something :)
makes sense, thanks. 
Very interesting read! Haskell memoization is something I've been wondering about for a while so it's nice to see an article on it.
I don't know much about it, but I've heard it mentioned in this subreddit that [ocaml_of_js](http://ocsigen.org/js_of_ocaml/) is really good. so it might also be an option for you.
Some FP Complete folks made suggestions for changes to cabal, e.g. storage on S3 to reduce downtime, some security improvements and others, but were told no, no and no. Under those circumstances they've just rolled their own. I might be wrong, but my impression from reading the conversations on those issues is that it's not FP Complete's fault at all, and that they got spurned by the cabal folks on a number of occasions. I think "aggressively encouraging everyone into their ecosystem" is a different thing from blogging about their new, nicer, easier, ready-made solution to which package versions to use and how to install them. You might find that their ardent supporters are just folk fed up with cabal and delighted with the new tooling that removes the pain; folk tend to get evangelistic when they discover things that are dramatically better than what they had before.
A way to avoid that problem with the backtracking instance search is to require that there is a single unique instance in the end. Now the only issue is that adding an instance can make code that compiled before stop compiling; but if it still compiles, the semantics doesn't change.
Even *if* that version of events is 100% unequivocally true, it's *still* wrong to fork the ecosystem IMO. YMMV.
GHC will float out things that do not depend on the argument to the toplevel, so this will not work (it'll sometimes transform `\() -&gt; ...` to `let x = ... in \() -&gt; x` )
Afaik &gt; XNoMonomorphismRestriction Is now on by default since 7.8.1. But maybe it's only in GHCi... 
Wow. Does that mean Haskell has no concept of big-O space complexity at the language level, because optimizations can affect it? That's pretty wild.
Yeah, I use both all the time. `OverloadedStrings` appears in &gt;25% of modules in my projects. chris@retina:~$ find Emacs/packages/ Packages/ Apps/ -name '*.hs' | xargs grep OverloadedStrings | wc -l 121 chris@retina:~$ find Emacs/packages/ Packages/ Apps/ -name '*.hs' | wc -l 457 `GeneralizedNewtypeDeriving` appears less because I tend to put all my types in one module and use it once.
I've had some difficulties with that, for example inside GHC it's sometimes hard to load a module in GHCi. For smaller projects it works fine of course.
It looked like Oleg's [example](http://okmij.org/ftp/Haskell/#memo-off) for preventing sharing didn't rely on any extensions (just pragmas). Has the compiler gotten even smarter since then?
~~IIRC, /u/kamatsu has commented that this is fragile and unpleasant in practice, based on experience with Isabelle/HOL.~~ EDIT: See [reply](http://www.reddit.com/r/haskell/comments/3afi3t/the_constraint_trick_for_instances/cscwcfh) below.
I'm not sure, I haven't tried that yet. My experience comes from debugging the reflex FRP library, which uses weak pointers and therefore has to control sharing. 
They let people submit ICFP papers before the Hackage release :(
but if you are re-using the same FromText instance than the instance written for a header value or a query string param must be valid for a capture also. It seems like you could either use PathPiece for everything or you want separate typeclasses and it would be used just for captures.
Nice! Looking forward to giving this a read. Kripke stuff sounds interesting....
Assuming that the optimization improve things then big-O complexity is unaffected. 
&gt; This way of doing I/O is reminiscent of the stream based I/O that was used in early versions and precursors to Haskell, before monadic I/O was introduced. i find this section interesting, because it is my understanding that frp is in no small part motivated by a dissatisfaction with the IO Monad as a solution to the previous streaming / continuation based solutions in reactive banana, there is a bit of busyness with writing your core event loop and setting up primitive inputs, but i have been using the vinyl library in a convenient way to add new primitive `Event` without touching any of my event-graph-construction code something like import Data.Proxy import Data.Vinyl import Data.Vinyl.Functor (Const (..), Lift (..)) import Control.Concurrent.Chan (Chan, newChan, readChan) import Lens.Family2 (Lens') import Reactive.Banana.Frameworks (AddHandler, fromAddHandler, newAddHandler) type Inputs = '[Click, Fps] -- forgive me, i have no unicodes. in should be read as that set membership operator click :: (Click in rs) =&gt; Lens' (Rec f rs) (f Click) click = rlens Proxy fps :: (Fps in rs) =&gt; Lens' (Rec f rs) (f Fps) fps = rlens Proxy --------------------------------- -- We need to build a record of `Handler` and a record of `AddHandler` newtype Handler a = Handler { handle :: a -&gt; IO () } newRow :: ( Rec AddHandler rs, Rec Handler rs ) -&gt; IO ( Rec AddHandler (r ': rs), Rec Handler (r ': rs) ) newRow ( ahs, hs ) = do ( ah, h ) &lt;- newAddHandler return ( ah :&amp; ahs, HAndler h :&amp; hs ) genRecords :: Rec (Const ()) rs -&gt; IO ( Rec AddHandler rs, Rec Handler rs ) genRecords (_ :&amp; rest) = newRow =&lt;&lt; genRecords rest genRecords RNil = return ( RNil, RNil ) -- it fills any shape putty :: RecApplicative rs =&gt; Rec (Const ()) rs putty = rpure (Const ()) initHandlers :: RecApplicative rs =&gt; IO ( Rec AddHandler rs, Rec Handler rs ) initHandlers = genRecords putty setupInputs :: Frameworks t =&gt; Rec AddHandler Inputs -&gt; Moment t (Rec (Event t) Inputs) setupInputs = rtraverse fromAddHandler --------------------------------------- -- set up event registering code type Registrar = Chan (IO ()) -&gt; IO () registerClick :: Handler Click -&gt; Registrar registerFps :: Handler Fps -&gt; Registrar register :: Rec Handler Inputs -&gt; IO () register handlers = do c &lt;- newChan -- actually we need to do some `Async` work here, but i -- hope the picture is clear to folks mapM_ ($ c) (recordToList (registrars &lt;&lt;*&gt;&gt; handlers)) forever $ do act &lt;- readChan c act where registrars = Lift (Const . registerClick) :&amp; Lift (Const . registerFps) :&amp; RNil
Yes, assuming it improves things it won't make things worse :) (for the same value of things)
[This is a great and succinct blog series](https://ocharles.org.uk/blog/posts/2014-12-01-24-days-of-ghc-extensions.html).
How large? I can say its worked well on up to 5000 loc for me.
I like it. keep it up! more haskell libs like this
/u/eegreg, not sure if you will notice this comment. I am actually going through this tutorial right now. One of the things I am trying to figure out how to deal with hiding a portion of the fields when using Persistent's derived JSON for the table i.e., hide passwords and other not-often-used fields. Could you please explain how you would use a newtype wrapper to solve this problem? My current approach is just to create a new record and then populate the required values. Thanks! 
I guess the title could be a bit of a play on "Observational Equality, Now!"? I love the double entendre.
But FromText is entirely too ambiguous of a name as this shows. Virtually any parser could use a typeclass named FromText. But in different cases (as here) the source text may have slightly different characteristics. If you want a single generic name something that isn't asking for a global clash such as `ServantText` would be good. In that case you could have still have a default definition that uses path-pieces. But using separate classes such as PathPiece, HeaderText, etc seems like a much more sound approach.
data FrontendUser = FrontEndUser User instane ToJSON FrontendUser where toJSON (FrontEndUser User{..}) = object ["name" .= userName]
/u/AlpMestan, hope you don't mind asking you a somewhat related question to my post. I am sending Auth tokens in the header and many of the end points require it. Is there a way to define an operator that will do this automatically for each request? "users" :&gt; Header "Auth-Token" Text :&gt; Get '[JSON] [User] -- Naively I tried |:&gt; = :&gt; Header "Auth-Token" Text :&gt; -- So I can do something like "users" |:&gt; Get '[JSON] [User] Of course, I am treating my made-up operator like a macro and it will somehow magically substitute it in place but that does not work. I tried studying your source code and you seem to be defining the operator as data (path :: k) :&gt; a deriving (Typeable) The above syntax is all new to me as I have only seen data SomeType = Constructor { .. }. Any suggestions on how I can avoid duplicating the header capture in my route definitions? Thanks!
I have no experience with OS X, but sometimes you can get things to install by deleting the tmp folder and trying again. If that doesn't work, I would often have to delete .cabal as well, but don't do this until you get better advice from Mac people. There is a .dmg for Leksah, hopefully you have seen it: https://github.com/leksah/leksah/wiki/Leksah-0.15.0.3
&gt; Debian user myself, so I can't tell what the right way of installing GHC on OS X would be, but I'd assume that if you were to follow these instructions[1] , you'd get a working GHC 7.8 with a new-ish Cabal (1.18), and it should work. I assumed that too ;) Turns out not. Thanks for your other comments, though. 
reminds me [MissingH](https://hackage.haskell.org/package/MissingH) 
I should note they do have a GitHub account, so it's not "no code", just "no release".
I've manually deleted every haskell-y looking thing on this machine, re-installed The Haskell Platform and now am trying to build leksah again, more as a smoke test for the HP install now that I have a binary for leksah anyway. 
I noticed that you reimplemented a large portion of [split](https://hackage.haskell.org/package/split-0.2.2/docs/Data-List-Split.html) library. Is there a reason?
Yes, but I decided against it, as I have about 5 times in the past, eg for the filepath library. I find writing a one off doc generator is pretty easy and gives me flexibility to do custom things which are inappropriate in a generic tool, but make the tests better as docs for my users. As some examples: * In filepath I infer all single letter variables to be forall quantifiers. * In extra I use Eq on IO that captures stdout. * In filepath I run all tests against two different modules. * In extra == undefined means it throws an exception. If I had to use either filepath or extras doc gen tests on the other it wouldn't work as nicely. I do love the idea of a doc test package, and do encourage its use, but writing a quick one for a project gives a lot of freedom and not that much work. 
I'm really glad to see focus on testing IO code. I've been playing around with a derivative of /u/implicit_cast's idea that allows specifying the expected effects and their return values up front in the unit tests: https://gist.github.com/radix/8fe3a182488dc3b570c9 Any feedback would be welcome. Would a Free monad make this any easier to write? And I also need to figure out a better way to define the methods for the testing instance so they're less verbose.
To keep the spirit of what you're suggesting, you can do: type a :|- b = a :&gt; Header "Auth-Token" Text :&gt; b -- (i'm not sure your suggested "|:&gt;" is a valid type-operator identifier) However, note that servant will also let you write e.g type API = Header "Auth-Token" Text :&gt; API' type API' = "users" :&gt; Get '[JSON] [User] :&lt;|&gt; "messages" :&gt; Get '[JSON] [Message] -- or all in one type: type API = Header "Auth-Token" Text :&gt; ( "users" :&gt; Get '[JSON] [User] :&lt;|&gt; "messages" :&gt; Get '[JSON] [Message] ) i.e "factor out" the header. Alternatively, you could write a type family to not even have to manually write the Header. type family AddAuthHeader api where AddAuthHeader (a :&lt;|&gt; b) = AddAuthHeader a :&lt;|&gt; AddAuthHeader b AddAuthHeader (a :&gt; b) = AddAuthHeader b AddAuthHeader a = Header "Auth-Token" Text :&gt; a Something like this would take an API type and turn it into another one, where each endpoint is augmented with an additional argument (the value of the "Auth-Token" header, if it's there). This solution is however a bit involved for what you're trying to achieve though, where just factoring out the `Header` as shown above is definitely the thing I would recommend. By the way, feel free to use the IRC channel &amp; mailing list if you have further questions. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Pairing heap**](https://en.wikipedia.org/wiki/Pairing%20heap): [](#sfw) --- &gt; &gt;A __pairing heap__ is a type of [heap](https://en.wikipedia.org/wiki/Heap_(data_structure\)) [data structure](https://en.wikipedia.org/wiki/Data_structure) with relatively simple implementation and excellent practical [amortized](https://en.wikipedia.org/wiki/Amortized) performance. Pairing heaps are [heap-ordered](https://en.wikipedia.org/wiki/Heap_property) multiway [tree structures](https://en.wikipedia.org/wiki/Tree_(data_structure\)), and can be considered simplified [Fibonacci heaps](https://en.wikipedia.org/wiki/Fibonacci_heap). They are considered a "robust choice" for implementing such algorithms as [Prim's MST algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm), :231 and support the following operations (assuming a min-heap): &gt; &gt;* *find-min*: simply return the top element of the heap. &gt;* *merge*: compare the two root elements, the smaller remains the root of the result, the larger element and its subtree is appended as a child of this root. &gt;* *insert*: create a new heap for the inserted element and *merge* into the original heap. &gt;* *decrease-key* (optional): remove the subtree rooted at the key to be decreased, replace the key with a smaller key, then *merge* the result back into the heap. &gt;* *delete-min*: remove the root and *merge* its subtrees. Various strategies are employed. &gt;The analysis of pairing heaps' time complexity was initially inspired by that of [splay trees](https://en.wikipedia.org/wiki/Splay_tree). The amortized time per *delete-min* is *O*(log *n*). The operations *find-min*, *merge*, and *insert* run in constant time, *O*(1). &gt;Determining the precise asymptotic running time of pairing heaps when a *decrease-key* operation is needed has turned out to be difficult. Initially, the time complexity of this operation was conjectured on empirical grounds to be *O*(1), but [Fredman](https://en.wikipedia.org/wiki/Michael_Fredman) proved that the amortized time per *decrease-key* is at least for some sequences of operations. Pettie then derived an upper bound of amortized time for *decrease-key*, which is . No tight bound is known. &gt;Although this is worse than other priority queue algorithms such as [Fibonacci heaps](https://en.wikipedia.org/wiki/Fibonacci_heap), which perform *decrease-key* in amortized time, the performance in practice is excellent. [Stasko](https://en.wikipedia.org/wiki/John_Stasko) and [Vitter](https://en.wikipedia.org/wiki/Jeff_Vitter) and Moret and Shapiro conducted experiments on pairing heaps and other heap data structures. They concluded that the pairing heap is as fast as, and often faster than, other efficient data structures like the [binary heaps](https://en.wikipedia.org/wiki/Binary_heap). &gt; --- ^Relevant: [^List ^of ^data ^structures](https://en.wikipedia.org/wiki/List_of_data_structures) ^| [^Left-child ^right-sibling ^binary ^tree](https://en.wikipedia.org/wiki/Left-child_right-sibling_binary_tree) ^| [^Double-ended ^priority ^queue](https://en.wikipedia.org/wiki/Double-ended_priority_queue) ^| [^Heap ^\(data ^structure)](https://en.wikipedia.org/wiki/Heap_\(data_structure\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+csdfv20) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+csdfv20)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](/r/autowikibot/wiki/index) ^| [^Mods](/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Call ^Me](/r/autowikibot/comments/1ux484/ask_wikibot/)
The "Work Smarter" section of https://www.fpcomplete.com/user/edwardk/revisiting-matrix-multiplication/part-5 gives a pretty concise pairing heap implementation that works well in practice.
The `(~)` isn't part of Haskell98, nor Haskell2010. It was added to handle GADTs and type families, though it can be extended to be used elsewhere (e.g., as in the OP).
Why is insertAfter el ins = concatMap (\x -&gt; if x == el then [x,ins] else [x]) insertBefore el ins = concatMap (\x -&gt; if x == el then [ins,x] else [x]) -- No comments, no formatting, no special syntax: separateParens = insertAfter '(' ' ' . insertBefore ')' ' ' better than the previous attempt? They are both multiple lines/one line depending on how you look at it.