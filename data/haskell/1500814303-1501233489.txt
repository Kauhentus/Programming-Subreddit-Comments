Thanks for pointing this out, looks like my script ran afoul. This should now be fixed.
Can you open a ticket?
For the record they are now pushed.
Oh dear, it looks like no one ever wrote a release notes entry. I think the [extension's documentation](https://downloads.haskell.org/~ghc/8.2.1/docs/html/users_guide/glasgow_exts.html#record-field-selector-polymorphism) is the best resource.
`ghc-8.2.1-x86_64-deb8-linux.tar.xz`
Backpack is missing as well, and unbixed sums
The release notes summarize what is new: https://downloads.haskell.org/%7Eghc/8.2.1/docs//html/users_guide/8.2.1-notes.html. /u/ezyang can correct me if I'm wrong, but I believe the best documentation for Backpack is still the [Wiki page](https://ghc.haskell.org/trac/ghc/wiki/Backpack). I haven't written much about the compiler performance improvements. However, they fall into several buckets, * Optimization of the compiler itself (e.g. improvements in name handling, fixing a bug where instance resolution was far stricter than necessary) * Fixing super-linear complexity algorithms in the compiler * Improving code generation (which speeds up the compiler as well as user code) * Change the behavior of the simplifier such that programs are reduced more quickly, allowing us to do less work
What about forwarding pointers during GC? With a tagless `Int`, there is no room for them. If we replace the `Int` wholesale with the forwarding pointer, we need additional storage to mark it as forwarded, either by consuming a bit on the `Int` OCaml-style, which I dislike and which is a large change, or in an external GC-time bitvector, which is less cache-friendly AFAIK than we currently have (but probably we win more by having a smaller heap). Overall I like this and don't yet see show-stopper issues. The "magic" header would be needed for a couple of things like pinned objects and compact regions, and having "magic" for nursery allocation is also very important for performance (having one `HpLim` for each object type would be disaster). I assume we have thunks the same as before with black holes and all. Obviously this is a significant RTS change though and there would be some non-obvious issues. I really like that we get tagless ADT constructors by default, no matter how many constructors we have, and we can still do the usual pointer-tagging for small enough number of constructors.
OK, here it is: https://ghc.haskell.org/trac/ghc/ticket/14017
That's pretty cool. Thanks for making getting the new template haskell function added! 
Thanks!
Unfortunately, the release notes contains nothing related to backpack or unboxed sum.
Thank you for your response! This is great feedback. What you said about lenses and prisms is correct. It was a mistake to mention `Maybe` and `Either` and `SimpleLens Maybe Int`, `SimpleLens Either String` are wrong . Those are better suited for `Prism` since they are sum types. Probably best to just mention `(a,b)` and show how to define lenses on the first and second part. `SimpleLens Maybe Int` doesn't work because the kind of `Maybe` is `* -&gt; *`, we should pass something like `Maybe Int` with kind `*`. We could still technically define a Lens on something like `SimpleLens (Maybe Int) Int`, but that would return `Int` for both `Nothing` and `Just Int`. I guess you could set some sort of default value, but it seems to violate the idea that is a functional reference since a default value for `Nothing` is something that was not contained by it. Not sure if that makes sense or not. The type signature would look like this, but it's not that important. ``` SimpleLens (Maybe Int) Int = forall f. Functor f =&gt; (Int -&gt; f Int) -&gt; Maybe Int -&gt; (Maybe Int -&gt; f (Maybe Int)) ``` Let me know if that clarifies anything. I'll update the article in the next few days.
Yes, this was an unfortunate oversight. I have written a few words [here](https://phabricator.haskell.org/rGHCd3857ba405725e03b7fef9516f8a4bf62a247f91). I'll try to update the `master` branch [documentation](https://downloads.haskell.org/~ghc/master/users-guide//8.2.1-notes.html) to include this patch shortly.
I've been reading about space optimization over the last year, and if you want to go all the way down the rabbit hole, then you should take a look at [intensional polymorphism](https://www.cs.cmu.edu/~rwh/papers/intensional/popl95.pdf) with [tag-free](https://www.cs.cmu.edu/~rwh/papers/til/pldi96.pdf) garbage collection. The idea: have no restriction on layout of objects (e. g. by mandating that all objects must be pointer-sized), instead, code involving objects with statically known layouts can be monomorphized as in Rust, and statically unknown layouts are handled by passing dynamic layout information to polymorphic functions or storing them in existential types. Garbage collection can be tag-free because we can recursively recover layout of heap data starting from stack frame metadata, both statically known and unknown, since static layouts can be looked up from static metadata, and dynamic layouts are stored in stack frames as function arguments or in objects as existential types. Usually, the the vast majority of layouts in typical programs are known, and only things like polymorphic recursion, existential types or polymorphic values inside constructors necessitate runtime layout-passing. Even in those cases, layout-passing can be more efficient than type erasure because we never have to re-box unboxed data. This way, all polymorphic code and data types work uniformly over all layouts without needing to introduce extra `#` magic for unboxing. `Int` can be unboxed by default and `[Int]` would have only two words for cons cells (field data included). The tag-free-ness would also persist over the entire lifetime of heap data. The general approach is "type-preserving compilation", meaning that front-end types should be refined instead of discarded throughout compilation phases. There's a classic paper on going from [System F to typed assembly](https://www.cs.princeton.edu/~dpw/papers/tal-toplas.pdf) for a showcase. I think this is obviously the correct approach, but it has been historically hampered by lack of production-strength implementations of expressively typed low-level representations which can accommodate wildly different high-level source languages. 
Templates and concepts when they finally happen are more 'vertical' additions to C++. There also seem to be efforts to bring monads to C++ in some form.
Thanks! That is exactly the sort of feedback I am looking for. I've been thinking about this (and related) optimisations to the RTS for years and may be able to find the time to code them. The only thing I'd hate to do is spend a hundred hours familiarizing myself with the intricacies of the RTS only to find that there is a fundamental reason why it can't be done. So every comment by those experienced with the RTS that they don't see a fundamental problem makes me more eager to invest the time. As for your specific point about tagless Int pages during GC, it is much appreciated. I hadn't thought of that, but I completely agree that having a small GC-time-only bitvector is the better solution. I (and everybody else) would hate to change the semantics of underlying Haskell code (which stealing a bit would do). On the positive side, one benefit of this scheme unmentioned above, is that it allows you to speed up GC. Any block which is marked as Ints (or any other type which does not contain references) can just be skipped during the reference gathering stage of GC, rather than having each object in it examined.
The announcement has link to more detailed release notes but there was a typo. Here's the correct one: https://downloads.haskell.org/~ghc/8.2.1/docs/html/users_guide/8.2.1-notes.html
This is a reasonably fair question and it's a bit sad to see it downvoted. Perhaps it's a bit too provocative for a Sunday. Anyway, my personal opinion is that * The Text/Bytestring distinction is fine, indeed necessary and correct * String is a historical aberration and it would probably be better if it had never existed although its simplicity is rather wonderful * I consider the distinction between *stringtype*.Strict and *stringtype*.Lazy to be a mess. Really there ought to be *stringtype* and ListT *stringtype*, or something.
Ah so you can make going from `Adjunction f u` to `Representable u` (with `type Rep u = f ()`) explicit (I think this code is right) newtype WrappedAdj :: (Type -&gt; Type) -&gt; (Type -&gt; Type) -&gt; (Type -&gt; Type) where WrapAdj :: u a -&gt; WrappedAdj f u a deriving Functor instance Adjunction f u =&gt; Distributive (WrappedAdj f u) where distribute :: Functor g =&gt; g (WrappedAdj f u a) -&gt; WrappedAdj f u (g a) distribute = distributeRep instance Adjunction f u =&gt; Representable (WrappedAdj f u) where type Rep (WrappedAdj f u) = f () index :: WrappedAdj f u a -&gt; (f () -&gt; a) index (WrapAdj ua) = indexAdjunction ua tabulate :: (f () -&gt; a) -&gt; WrappedAdj f u a tabulate f = WrapAdj (tabulateAdjunction f) and going from `Representable r` to `Adjunction (Rep r, ) r` newtype Pair r b = Pair (Rep r, b) deriving newtype (Functor) newtype Arr r b = Arr (r b) deriving newtype (Functor, Representable) instance Representable r =&gt; Distributive (Arr r) where distribute :: Functor f =&gt; f (Arr r a) -&gt; Arr r (f a) distribute = distributeRep instance Representable r =&gt; Adjunction (Pair r) (Arr r) where unit :: a -&gt; Arr r (Pair r a) unit a = Arr (tabulate (\b -&gt; Pair (b, a))) counit :: Pair r (Arr r a) -&gt; a counit (Pair (rep, xs)) = xs `index` rep which hopefully lets us [derive](https://www.reddit.com/r/haskell/comments/6ksr76/rfc_part_1_deriving_instances_of/) stuff like `Adjunction` for some coordinate (representationally equal to a pair functor) `(Rep Board, )` and `Board`.
It will be soon! The plan is to first start LTS 9 based on the latest nightlies. Once that's done, then we'll drop most of the constraints we've accumulated, switch to the new ghc, and remove stuff until a working nightly snapshot emerges. Don't quote me on this but I'd say within a fortnight probably, maybe even within a week.
Thanks! For the record, I have opened [#14012](https://ghc.haskell.org/trac/ghc/ticket/14021) to track this.
This is indeed a pretty neat use of Template Haskell.
Any good blog posts on these yet? If not, let's see some!
&gt; is that it allows you to speed up GC I don't think your justification is right for that. Usual tracing GC only scans live data, so we wouldn't scan blocks for pointers in any case.
Of course, you're right. The type of GC used by GHC traces live data from references from the root(s), rather than needing to look at every page in any case.
Maybe have a look at this for a start: &lt;https://github.com/emilaxelsson/milkshake&gt; It mostly handles the generation and clean up of the file structure ATM. But the whole approach is very flexible, so should be able to adapt to your need.
Thanks Francesco! This allows us to remove [this big block of .cpp files](https://github.com/LumiGuide/haskell-opencv/blob/ae2d21faa5b948a02d4a6ccf396fdb06c4457f68/opencv/opencv.cabal#L65:L96) from our `opencv.cabal` file.
Thanks for the thoughtful response! I'd never seen pattern synonyms until now, that's pretty sweet! When I'm trying to teach a concept I tend to try to keep things 'simple' even if that means verbose; but I really like this setup!
The utility all comes from Representable, which I think is part of why Adjunctions can be hard to understand (they're not really adding anything new). Regardless I needed to wrestle with that notion in order to understand it, so I'm glad I put the work into Adjunctions regardless.
and develop with ghci! that's the part that i cared most about
&gt;GHC will now use ld.gold or ld.lld instead of the system’s default ld, if available. How can I check on ubuntu 17.04 if ld.gold and/or ld.lld are available, and if not how to install them? 
This seems to be the main use case of free monads.
Yes the adjunctions between Haskell `Functor`s aren't so wild but given that we **can** systematically derive `Adjunction` instance Adjunction CoordF Board where unit :: forall a. a -&gt; Board (CoordF a) unit = coerce (unit @(Pair Board) @(Arr Board) @a) counit :: forall a. CoordF (Board a) -&gt; a counit = coerce (counit @(Pair Board) @(Arr Board) @a) using the `newtype` I defined earlier &amp; also newtype Board a = Board (Compose V3 V3 a) deriving newtype (Functor, Representable) newtype CoordF a = CoordF (Coord, a) deriving Functor instance Distributive Board -- ... it would be cool to have magic syntax to derive `Representable` as well as `Adunction` newtype Board ... derive newtype (Representable) derive via Pair, Arr (Adjunction CoordF)
It's much more like PureScript's extensible effects, which in reality is just `IO` with a phantom row type. The main use case of free monads would be program introspection and interpretation.
That's great! Also when shall we expect the Haskell Platform updated with GHC8.2.1?
My understanding is that there will be a new Platform release at some point in the coming week.
I believe `ld.gold` is installed by default in nearly every modern Linux distribution. You can verify this by simply running `ld.gold --version`. LLD is significantly newer and consequently not nearly as ubiquitous; in fact, I don't think it has even been packaged as of Debian Stretch. That being said, I don't think there's any particular reason to favor lld over gold.
Yes the simple approach is good but the other one can guide the simple approach, * Thinking of it as `Compose V3 V3` lets you use GHC to discover candidate instances for `Board`, even if you don't end up using `Compose V3 V3` as an underlying representation, you can reap the bens of it * [`deriving newtype Foldable1`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#deriving-strategies) is tantamount to proving that `Board` is non-empty (and thus we should have total `head`, `last`, `minimum`, `maximum`, .. `toNonEmpty :: Board a -&gt; NonEmpty a` functions as well as any non-empty folds) * Haskell will pick a correct representation `(E V3, E V3)` * Haskell will fill out tricky, possibly error-prone code like `Representable` and `Applicative` correctly Now we can go further (topic of an upcoming post) and derive from many different representations: `newtype Pair a = P (a, a)` can derive very different instances than `Product Identity Identity` and `(Bool -&gt;)` / `(All -&gt;)` / `(Any -&gt;)`, which are all isomorphic.. but I digress
We have a cache of static content in memory. I'm planning to compact that.
This is now fixed.
I have issues understanding the implication of the new `Data.Typeable` interface. It removes an `unsafeCoerce` from `Data.Dynamic` and then? (Yes, I have read the paper, but I guess I totally missed the point.) Am I right when I say that knowing at runtime the content of a `TypeRep a`, we can, still at runtime, deduce the `a`? I'm still puzzled by this runtime deduction of types.
&gt; more portable than lmdb # &gt; pain to set up and package with an exe Thanks for the pointer about that. &amp;nbsp; &gt; Out of curiosity, what are you using with Reflex for the GUI? I'm building with GHC via stack and using reflex-dom currently. Is that what you are asking? &amp;nbsp; &gt; config stuff that would benefit from lightweight free caching # &gt; document-like stuff that would benefit from more traditional persistence I'm not sure if my current main use-case would map cleanly onto a document-centric abstraction. And certainly not 'for free'. So I hope that my experiments with VCache turn out to be fruitful. In your case, did you use it mainly/only for persisting user config?
The `linux-64` content length may need to be modified, I get: Preparing to download ghc-8.2.1 ... Download expectation failure: ContentLength header Expected: 170622460 Actual: 126809836 
I've messed around with this approach before. Ultimately, I cannot recommend it. One disadvantage is that it's sort of confusing if multiple people are working on a project. The real issue though is that the examples you gave are resource-based. Let's take `HasFileAccess` for example. Presumably, this is some typeclass for monads that can work with the filesystem. What are its methods? Everything in [`System.Directory`](http://hackage.haskell.org/package/directory-1.3.1.1/docs/System-Directory.html)? That's a lot of methods. Maybe only some of them then? What about `HasEC2`? What's are the typeclass methods for "everything you can possibly do on Amazon EC2" going to look like? There will be thousands of them. Additionally, writing out a mock filesystem or a mock EC2 would be tedious. Most people's code isn't even using all of those methods. Why pay to stub out things you don't use? What I do like is mtl typeclasses (or free monad, or freer monad, or whatever technique you like) that are domain-logic-based instead of resource-based. Look at Gabriel's [free monads blog post](http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html). Notice the kind of things he discusses using this for. While I'll admit that they're a little contrived, it clear that they are based on domain logic and not on a resource.
Excellent, thanks!
Holy hell, how do I get me some unboxed sum types? Where do I sign up?
The bounds being ignored is something I set in the custom `stack.yaml`, although I can't recall why. Something I copied from a blog post describing the process, I think.
I believe you. I'm sure this will work itself out, I'll just wait for a stack nightly that uses 8.2.
I don't see how mtl type classes or free monads avoid the problems you mentioned. A `MonadFileAccess` effect is the same thing as `HasFileAccess`. You still have to choose what methods you'll stub out and whatnot.
Sorry, I wasn't as clear as I wanted to be. I agree that `MonadFileAccess` is the same thing as `HasFileAccess`. I have never seen anything that tries to stub out the file system be effective, so I don't recommend doing either of them. The thing I think mtl/free/freer/etc. are more effective more at is stubbing out domain logic. Everything the OP listed is resource-based, and I would just use plain old `IO` for that kind of thing.
I feel like I read that the person who implemented that change couldn't come up with a benchmark that improved with unboxed sums, but I might be misremembering. Can anyone confirm?
Great post! I'd doubt that adjunctions in general are isomorphic to un/curry though (free -| forgetful -| cofree seems like an obvious one that isn't), but you might be right in Hask where we can only directly find adjunctions between endofunctors.
[removed]
`Data.Typeable` really hasn't changed that much; all of the changes are beneath the surface as it is now implemented in terms of the new mechanism exposed in `Type.Reflection`. Even `Type.Reflection` doesn't offer much in the way of **new** functionality (except for the ability to reflect on kinds, as requested in [#10343](https://ghc.haskell.org/trac/ghc/ticket/10343)). However, it makes many uses of type reflection significantly safer by allowing the type checker to reason about the relationships between the `TypeRep`s and values in your program. This is why we can now drop the `unsafeCoerce` from `Data.Dynamic`. **edit:** Corrected ticket number of `typeRepKind` request.
I feel like a lot of that code should be separated out into their own functions. There are no comments and most variables in there have in-descriptive, short names (as tends to happen in do- and where notation, hence the need to break it out). With that said, it does highlight the problem with Haskell where there is an abundance of complicated concepts being applied in even the simplest of programs, and with it complicated terminology. It's of course in part because of the need to work dirtiness into the otherwise pure code which requires some monadic acrobatics and I don't have any brilliant solutions as to how to hide those things and keep the benefits of functional programming, but it really puts a barrier of entry to the language being commonly employed in many workplaces. While I wish we used it at my work, I have to admit it's at least in part because it would filter some of my coworkers out. And that's not actually what we want.. because that's terribly pretentious and intolerant. I also haven't actually finished any of my tiny Haskell projects I've started thus far, so take my unqualified opinions for what they are. I don't know nearly enough about these things. I even considered deleting my post before submitting..
Why don't the official pages do this? Any idea? Thanks for posting!
Yes, there is bad, unreadable code in Haskell. If I could I would show you some bad, unreadable code in Java from work. 
This is a rather clever idea. However, I do worry that this would significantly complicate allocation; afterall, you would need to do some sort of lookup to find the active block for the constructor you wish to allocate, then do the usual bump-the-pointer. But then what do you do in a concurrent setting? Now you either need to have `# capabilities * # constructors` blocks or require that the pointer bump be an atomic operation. Neither of these options seem appealing. Finally, what do you do about thunks? Their layout depends upon the thunk type, which there are many of. I'm not sure you can realistically have a block for each thunk type. More generally, I can't help but wonder whether this would be worth the complexity. Is the space usage of `Int` really a problem that people are feeling? Afterall, typically `Int`s will occur in some larger data structure where they will be either unboxed into an array or unpacked into some other constructor. You might respond, "but what about `Maybe` values? They can't be unpacked.". Indeed this is true, but I don't expect this will continue to be the case for much longer with the on-going work on unboxed sums. Of course, I may have simply misunderstood your proposal; my apologies if so.
And this is worse than the least readable code in your candidate language how exactly?
Here's the link where somebody used `haskell-indexer` to cross-reference all of GHC's source code: http://stuff.codereview.me/#ghc/compiler/hsSyn/HsBinds.hs?corpus&amp;signature It's super useful for hacking on GHC because it can show you all locations where some function or type is used, so you know where you need to look when changing it.
Protip: Explain what VCache is at the start of the article
Fair point. Would you consider quoting from its' [hackage description](https://hackage.haskell.org/package/vcache) adequate, or do you have something different/more in-depth in mind? &gt; VCache provides a nearly-transparent persistent memory for Haskell supporting ACID transactional variables and large structured values. The virtual address space is modeled above a memory mapped file via LMDB, with structure sharing and incremental reference counting GC. &gt; &gt; VCache was developed as an alternative to acid-state in a context where the persistent data is much bigger than the active working set and RAM. Other similar packages include TCache and perdure. See the home page for a simple comparison.
The readability here has nothing to do with the language and everything to do with the person writing the code. 
Implementor here -- you get your more efficient memory layout but because demand analysis for sums and worker/wrapper transformations are not merged yet (I have patches for both but they probably need significant rebase effort now) you need to either implement functions that take unboxed sums as arguments or you have to box the unboxed sum every time you use it. So in short follow-up work is needed for best results. If you have unfoldr-like functions that use a sum type as an intermediate value you can use unboxed sums to get allocation free loops. That's one case where unboxed sums makes significant contributions in terms of allocations and runtime.
If `rmap` and `id` are both recursive, GHC probably can't inline them. newtype Auto a b = Auto (a -&gt; (b, Auto a b)) instance Profunctor Auto where rmap f (Auto h) = Auto ((f *** rmap f) . h) ... instance Category Auto where id = Auto (\a -&gt; (a, id)) ... As always, this sort of thing is a trade-off.
`String` is fine for many purposes, but it shouldn't have been given a type alias. I try to use `[Char]` everywhere instead.
Yes, `Twist` was specifically designed to find a hole in the coverage of the laws. I'm not sure it's possible to make something like it by accident. I suspect it's impossible to rule out `Twist` by adding laws. Neither `Strong` nor `Category` has the vocabulary needed to express the relevant `Arrow` laws, and there's general agreement that having additional laws that apply to the intersection of two classes is a bad idea.
Theoretically yes, but I think there’s still a mess in the sense that many APIs use ByteString where they really probably ought to use Text, so you often end up having to do conversions between them, anyway.
Patches are always welcome.
man you guys are in denial. user defined and overloaded operators, white spacing, bad lambda syntax, $, cultural preference for pointfree over intermediary vars, cultural preference for absurdly short var names all contribute to encouraging code like this. 
i challenge you to find me python as bad as this
Have you ever worked professionally with Python?
yes i have. lots of confusing side-effects? sure. as unintelligible as this example? never.
&gt;It's of course in part because of the need to work dirtiness into the otherwise pure code which requires some monadic acrobatics and I don't have any brilliant solutions as to how to hide those things and keep the benefits of functional programming when i said this in a thread here about 5 months ago (called them hacks instead of acrobatics) i got criticized for being ignorant. &gt;I even considered deleting my post before submitting.. that's self-censorship and it's because part of haskell is cargo-cult: "there's nothing wrong with the language; you're doing it wrong". i think any language that gives you as many footguns as haskell does has serious problems. the longer people preach the dream of haskell instead of the pragmatics of haskell the longer it will languish (and other languages like rust or elixir or even ocaml will "eat its (haskell's) lunch".
So you want me to trawl the web to find a random library in Python that is written unreadably? And what do I win if I show you one?
i'll paypal/bitcoin/w.e you 5$.
&gt; user defined Really glad Haskell has them. &gt; overloaded operators Haskell doesn't have overloading. Perhaps you mean typeclass parametrised operators? Really glad Haskell has them. &gt; white spacing Really glad Haskell has it. &gt; bad lambda syntax It's a single character, plus `-&gt;`. Couldn't be clearer. Do you know a better syntax? &gt; `$` Hate it, personally. &gt; cultural preference for pointfree over intermediary vars Nothing to do with Haskell as a readable *language* but really glad we have it. Makes code a lot more readable. &gt; cultural preference for absurdly short var names Nothing to do with Haskell as a readable *language* but often makes code a lot more readable. 
Sorry we offended you. See you in another 5 months, maybe, when you feel like trolling again?
I'd like to shop around a bit first.
&gt;Really glad Haskell has them. whether you like them is neither here nor there. the question is whether on the whole they produce better code or worse code. my opinion (and many share it) is that terms like `&gt;&gt;&gt;===!|?&lt;&lt;` should not appear in a codebase, anywhere, because no one speaks klingon. &gt;Really glad Haskell has it. again congrats but this code sample is a clear counterpoint: without looking pretty closely it's very hard to decipher the scope of every lambda, do, $ etc. &gt;It's a single character, plus -&gt;. Couldn't be clearer. Do you know a better syntax? um it's `\x -&gt;` (so that's at least two more characters than just `-&gt;` and the point is it's hard to scan the code and find them because a slight \ is hard to see. &gt;Nothing to do with Haskell as a readable language but really glad we have it. Makes code a lot more readable. &gt;Nothing to do with Haskell as a readable language but often makes code a lot more readable. yea man totally. great counterpoint. obviously i'm not talking about the formal grammar of haskell. no one is ever talking about the formal grammar. the language is the sum of all of its parts (grammar, stdlib, ecosystem, build system, community, etc.); the name of this sub isn't HaskellSyntax it's Haskell.
So, the same?
i've yet to find another tech community that is so immature about criticism. even go is considering adding generics. but no i'm wrong and a troll &lt;rolls eyes&gt;
don't make claims you can't substantiate. several people in here saying it's a function of the programmer and not the language. ok prove it.
It's a bit presumptious of you to come to this subreddit, throw your weight around and expect stuff of other people. If you'd like to learn Haskell then feel free to post polite question and we'll be happy to help. If you already know Haskell well and want to help the community then perhaps write some code or some articles on your area of interest. Perhaps you could even refactor the code you linked and write it up as a blog post! If neither of these apply then it's probably best if you don't come here anymore.
Are you a bit bored on a Sunday afternoon?
This 1000%. Stuff like `MonadEC2` or `MonadDatabase` are way too low level. You need something like `MonadAllocateRemoteServer` or `MonadGetUsers` or similar for this to be reasonable and practical. You can't realistically mock an entire SQL database. You *can*, however, fairly easily mock a highly restricted language where the interface represents the specific queries you end up needing to use. Something like class Monad m =&gt; UserAccess m where getById :: UserId -&gt; m (Maybe User) getUsersSatisfyingComplexCondition :: SomeParam -&gt; Producer m User -- etc.... This ends up looking *pretty* similar to the way my modules are concretely laid out -- given a `User` model, I'll typically have `App.Query.User` full of Esqueleto queries that are concretely `SqlPersistT m a`. It would be *easy* to pack that up into a type class, write the `SqlPersistT` instance, and finally write a `StateT` instance or similar that had a mocked set of data.
&gt; the question is whether on the whole they produce better code or worse code Not to me. The question to me is whether they allow me and the people I work with to write better code. They do. &gt; terms like &gt;&gt;&gt;===!|?&lt;&lt; should not appear in a codebase I tend to agree! &gt; it's very hard to decipher the scope of every lambda, do, $ etc. As I said, I don't like `$`. Regarding the scope of lambda, that's nothing to do with the lambda syntax, it's to do with the context the lambda syntax is placed in. &gt; um it's \x -&gt; (so that's at least two more characters than just -&gt; The `x` is not part of the lambda syntax. &gt; and the point is it's hard to scan the code and find them because a slight \ is hard to see. Perhaps I'll find an example of messy Python code, [claim your 5$](https://www.reddit.com/r/haskell/comments/6p29rv/haskell_is_the_most_readable_language/dkm6j1z/), and give it back to you so you can buy a magnifying glass. If you get a really good one it might even let you see function application. &gt; obviously i'm not talking about the formal grammar of haskell. no one is ever talking about the formal grammar. the language is the sum of all of its parts (grammar, stdlib, ecosystem, build system, community, etc.); the name of this sub isn't HaskellSyntax it's Haskell. Well it's quite hard trying to work out exactly what you are talking about, since your post was merely "Haskell is the most readable language" plus a link to a messy sourcefile. I refer you to [an earlier post of mine](https://www.reddit.com/r/haskell/comments/6p29rv/haskell_is_the_most_readable_language/dkm71qh/) regarding how you might proceed from here.
Thanks!
They might have different purposes but the problem is library authors do have to make a choice between each type of string to use. Sometimes the choice is obvious because it correspond to the library purposes and sometimes is not. Problems arise when end users try to use two libraries which made a different arbitrary decision. Also, most of the basic function names collides with their list equivalent in the prelude. 
Right you are. Thanks!
I don't understand why you posted this here. Are you just here to berate people? Were you trying to have an open discussion? Or just trash Haskell? I don't get why you went out of your way to try to russle a bunch of enthusiasts...
The fact that we manage doesn't make it less a mess. I can understand that Text and ByteString might have a different but lazzy vs strict seems more of an arbitrary choice. For example, could you tell me from the of your head if the `formatting` library (which does type safe printf ) uses lazy or strict Text ? For me the biggest mess is in use the same name for the lazy and strict version. It is really confusing. 
Mostly a question of Haskell wrappers for Python libraries. That and and Django/Yesod need some bridge code. Write your project in one and emit the other for free. The Dao of static and dynamic types.
Fixing the String Lazy/Strict mess.
Do you have examples of posts in other communities where some dude just shows up, basically yells "you suck" and receives friendliness in return?
I'm having a hard time getting [substitutions for type holes](https://github.com/ghc/ghc/commit/26c95f46e679fb73e1ec2bec2be0801c72fd1449) to work. Was that included in this release?
I think it actually show haskell can be good. You can wire code as bad as you want in any language. (Let's take this haskell example and compile it to Javascript, you obtains JS, which even less readable ;-)). However, what is good with this code is that everything is there. There is no hidden state , global variable etc ... If you really need to, you can rewrite and clean it easily, and the type system will actually check that your refactoring is correct. Most of the lambda can be extracted as function, operators can replaced, and bad name renamed. So yes, this might be bad code, but at least you can do something about it and clean it in a reasonable amount of time. 
&gt; Colorful error messages with caret diagnostics. But... I ain't seeing no colours? Error messages do have pretty carets, though: /tmp/stack7032/ekg-core-0.1.1.1/System/Metrics.hs:448:16: error: • Constructor ‘Stats.GCStats’ does not have the required strict field(s): mblocksAllocated • In the expression: Stats.GCStats {bytesAllocated = 0, numGcs = 0, maxBytesUsed = 0, numByteUsageSamples = 0, cumulativeBytesUsed = 0, bytesCopied = 0, currentBytesUsed = 0, currentBytesSlop = 0, maxBytesSlop = 0, peakMegabytesAllocated = 0, mutatorCpuSeconds = 0, mutatorWallSeconds = 0, gcCpuSeconds = 0, gcWallSeconds = 0, cpuSeconds = 0, wallSeconds = 0, parTotBytesCopied = 0, parMaxBytesCopied = 0} In an equation for ‘emptyGCStats’: emptyGCStats = Stats.GCStats {bytesAllocated = 0, numGcs = 0, maxBytesUsed = 0, numByteUsageSamples = 0, cumulativeBytesUsed = 0, bytesCopied = 0, currentBytesUsed = 0, currentBytesSlop = 0, maxBytesSlop = 0, peakMegabytesAllocated = 0, mutatorCpuSeconds = 0, mutatorWallSeconds = 0, gcCpuSeconds = 0, gcWallSeconds = 0, cpuSeconds = 0, wallSeconds = 0, parTotBytesCopied = 0, parMaxBytesCopied = 0} | 448 | emptyGCStats = Stats.GCStats | ^^^^^^^^^^^^^... Hint @/u/tibbe. ;-)
i posted this here because of this on HN https://news.ycombinator.com/item?id=14826513 i hear this kind of zealotry in places where haskellers congregate all the time. i would like haskell to be a practical choice because i think strong and expressive typing is very useful (pureness i don't care about). there are many things that keep me from ever choosing haskell for a serious project and every single time i ever say anything to anyone about it i get the kind of response i got here: denial. how about instead of being offended and defensive people admit some of the flaws (at the least that would make everyone struggling in spite of them a little happier).
The haskell community is not that keen indeed on critiscim. However, I'm not sure it is worth that any other language. Also, it might responds better to fair criticism. This example is not a fair criticism even though some points are valid.
i didn't say anything at first. sure the title of the post was meant to instigate but i was hoping for responses like /u/GiraffixCard's. 
Sounds related to [Safe Haskell](http://ghc.readthedocs.io/en/latest/safe_haskell.html), although that's not really tracking stuff in the type system.
All this really proves is, "you can write FORTRAN in any language." Haskell can empower you, just as any other language, to write too widely scoped spaghetti code. `ingestJSON` is indicative of this.
One other consideration that makes a GC bitvector palatable is that it would be tiny. You only need one bit per word. On a 4k-block, 64-bit machine, this bit vector would only be 8 words. That is so small that one might keep it in the block header permanently just for convenience, even if it is only needed during GC time.
That commit came after the GHC 8.2.1 feature merge window closed, so no, it didn't make it into 8.2.1.
I have color, but no caret in ghci ;( (For interactive code input, not module loading).
Alas! This release is only *very* exciting and not *extremely* exciting :D
I realize that initial allocation on a type-specific block could cause some problems. But is that not all alleviated by the idea of doing all initial bump-allocation in the nursery which would count as a magical block (i.e., one with the current memory layout)? Only objects surviving their first GC would be evacuated to the type-specific memory blocks. As for thunks, keeping magic, mixed-type blocks is always a possibility. But I do wonder how diverse the memory layout of thunks really is. Wouldn't even in large programs the vast majority of thunks not correspond to a handful of function (with different arguments/captured environments)? For each such function, the memory layout would be the same and they could easily, compactly coexist on a block, perhaps even saving a little more space by putting the function pointer itself into block header too. Or maybe not. I wouldn't be sure without benchmarking. As for the frequency of the problem, I think it is pretty high. Lists of Ints are of course the worst example, but I think that many common structures either are as bad (like the built-in String) or not much better (like lazy pairs, binary trees, etc.). As for your understanding of the proposal, I think it was perfect and very helpful.
Is there anything about these packages that wouldn't work normally on Debian?
I'm afraid not; it was a new feature which showed up well after the nominal feature freeze of 8.2.
google "worst python ever" =&gt; http://smotko.si/worst-python-code-ive-ever-written/
The only sensible thing for thunks is to leave them unchanged. Thunks must contain a pointer to entry code, and in GHC entry code pointers and info pointers are the same (they point to code, and the info is located before the code). No tag can/should be removed from this scheme. 
&gt; But is that not all alleviated by the idea of doing all initial bump-allocation in the nursery which would count as a magical block (i.e., one with the current memory layout)? Perhaps, but then aren't you paying for a "is this object in a special block" test (which I suppose could be a mask, comparison, and branch) on every entry, evacuation, and scavenge? That is a lot of branches (even for Haskell, which is not exactly known to easy for branch predictors).
What's hilarious about that example is it's bad python because it's shoehorning functional patterns
&gt; But... I ain't seeing no colours? Hmm, what terminal emulator are you using? How are you invoking GHC?
Try `-fdiagnostics-color=always`. It looks like `stack` (which judging from the directory you seem to be using) redirects the output of GHC such that it thinks that it is writing to a file instead of writing to a terminal and in that case colors are turned off since otherwise you would end up with weird ansi escape codes in your files.
Right now Haskell has `inline-c`, `inline-c-cpp` (not as supported or feature rich), `inline-r`, and `inline-java`. This is incredibly cool. It would be nice to see an `inline-LISP` of some sort: `inline-clojure` or `inline-racket`, or something like that. In principle, these dynamically typed prototyping languages could then be wrangled by Haskell's type system.
Well, you'd have to try picking the package for the Ubuntu release which is closest to your Debian's release C library versions of libc/libgmp/ncurses, and ideally slightly older than Debian's. All this under the assumption that the C compiler toolchain versions on Debian and Ubuntu generates artifact which are binary compatible to each other, and that C ABIs for the respective C libraries evolve in a backward compatible way and consistently use versioned symbols to signal incompatible changes. That being said, I do intend to provide native packages for Debian 9.
Do you really not see how aggressive and condescending you're being? You come to a sub filled to the brim with interesting, thoughtful discussion, leave this dump and expect us to like it?
That probably would be enough :) 
You really lack self-awareness if you think your title wasn't aggressive.
Fixing GC pauses causing issues for realtime applications. Dependent types next :-)
Java is consistently read top to bottom, left to right. Haskell is both top to bottom and (where clauses) bottom to top, left to right (&gt;&gt;=, \y -&gt; y+1) and right to left ($) F# designed its operators to be consistent and easily readable. To a newcomer, it's pretty easy to figure out |&gt; , &lt;| , &lt;. , .&gt;. By comparison there's little intuition that can help with $ , &amp; , . , &lt;&lt;&lt; F#'s adoption of top to bottom, left to right, means that the type-checker can disambiguate overloaded functions easily, so one can just say let l = nameField |&gt; trim |&gt; length, whereas in Haskell one has to write let l = T.length $ T.strip nameField And as a reader you just have to hope that T means Data.Text. It's not productive to point to languages like Java and say that if we're better than that we're good enough. There are purely functional languages (Elm springs to mind) that are more readable than Haskell. And Haskell's use of operator overloading does not always help, since many are not as intuitive as plain English words. 
Do you come to post shit code on the corresponding programming reddit whenever someone makes a post of appreciation for their pet language on HN ? What motivated you to post here rather than on that HN topic, in the first place ?
what part of &gt;sure the title of the post was meant to instigate isn't self-aware?
IME it's generally not an interesting distinction. Libraries or generic modules, yes. But internally for an app or whatnot it's information that nobody cares about and nobody uses, as you tend to use most of the effects available. We tried this in Stack and ended up type aliasing all the constraints. Now we just have a stack monad and parametrize the reader type. I think that having a few different monads that encompass a set of different effects e.g. controller Vs Model in which controller can access to request data and do redirects etc. and model can do arbitrary file and database access and yet no Web stuff, those are valuable distinctions. I feel that libraries exposing a type of effect, like on purescript is nice but at your app level or internal level, the granularity is too much. Better more opaque nominal monads that encompass a more general idea.
[removed]
Was going to say that. I have encountered dense and bad code, hundreds of lines long in Python, Java, C, etc. The difference is that code like that written in Java or Python probably means that there are dozens of other bad practices that are being used that are impossible to use in Haskell. You could probably refactor that one ugly function in an afternoon. You couldn't refactor a similar sized really bad C++ class in a week.
`string-conv` may not have the best API for some situations. Here's the [StringConv](https://github.com/Soostone/string-conv/blob/6292d57490602687e4301f4c0d20b618d939a279/Data/String/Conv.hs#L47) class: class StringConv a b where strConv :: Leniency -&gt; a -&gt; b Note that it doesn't include the idea of failure, despite having instances like `instance StringConv LB.ByteString T.Text` that can fail. This leaves users of the library with the choice (made through the `Leniency` option) of either exceptions or inserting replacement characters. I've got an issue open about this so it may get worked out at some point, but until then I'm hesitant to recommend the library without qualification.
https://www.reddit.com/r/haskell/comments/4f47ou/why_does_haskell_in_your_opinion_suck/ https://www.reddit.com/r/haskell/comments/4kdxf5/why_haskell_sucks_presentation_a_summary_of/ https://www.reddit.com/r/haskell/comments/4koyto/solving_the_biggest_problems_now_before_haskell/ Doesn't look like anyone here needs your help to criticize Haskell. And we can also do it in a meaningful and friendly way. get nice or gtfo. 
I wouldn't blame my self-doubts on the community really, it's been quite helpful to me thus far. Part of it is just because of the nature of this language attracting the more passionate and academically inclined you might constantly feel a bit underqualified, especially if self-taught and without an academic background. There has been so much thought put into so many aspects of this language by brilliant people much more learned than myself so I always have to ask myself "is it really the language or is it me?" at least 2-3 times before I rant or give any kind of strong opinion really. The same can not be said for a lot of other languages that were just kind of put together because someone had a preference or it fulfills some particular requirement, often with a bunch of technical debt.
It's broken for me: http://imgur.com/a/1YWaa. Firefox 53, Linux. (Should I report it somewhere else or is /u/alan_zimm related to making this feature happen?)
lmao did anyone else find this to be pretty damn readable?
great. how many things have been fixed since then?
The [`text-conversions`](https://hackage.haskell.org/package/text-conversions) package provides a similar interface but is completely typesafe. Disclaimer: I am the author of that package.
If you want to take this position, you win. 
I keep getting the feeling that it's going to be not Haskell but a derivation of it that's going to become the big thing in a near-ish future. It's almost like Haskell is the daddy showing what can be done, and then the kids come and take (some of) that power and does something beautiful with it. Elm is pretty cool, and I can see it becoming more popular with time. I'm in game dev, so I'm hoping for a Haskell-like language to crop up which excels at that. I have checked out F# but I'm not really a fan of the microsoft eco-system, their framework or terminology. It's just really awkward to use in a Linux environment. Being forced to use Unity3D at work though I suppose convincing some use of F# over C# is as big of a victory I could hope for.
I'm going to concede one point to OP here: some things could be better in Haskell syntax and a lot of things could be better in Haskell's community culture about what constitutes good code and bad code. The first point in widely recognized by a lot of people here and can be avoided with a set of best practices. The second point will happen with any language/library/ecosystem that interacts a lot with academia (have you ever looked into Matplotlib?). This is natural. As someone who interacts a lot with the boundary between academia and industry, you recognize this difference in ideals very easily. And the way to make them more compatible is to have MORE commercial use of Haskell, not less. That said, what some people fail to understand is that for most people here those points of syntax are secondary when you consider the advantages of having Haskell's type system at your disposal. Do I curse a bit when Haskell's syntax sometimes is not as sparse and unclogged as Python's? Sure. But I curse a lot more everytime I have an error in Python that a decent compiler or type system could have prevented. Or anytime I have to write a shit-ton of extra code because I have to create safety checks for things that a compiler could garantee for me. Or anytime I must write dozens of classes to isolate my business rules from the outside world that could be written in a single file of type declarations and pure functions in Haskell. I can prevent things like this ugly function in my Haskell code. It's easy. It just takes regular programming common sense. I can't avoid having ambiguity in typing in Python because that's how the language works. I love python. But I end up wishing python was more like Haskell way more often that the other way around. 
This is not a highly readable snippet, but my viewpoint might change if I read more of the databrary code. You might be happier now if you had a chance to develop a few larger projects in Haskell on your own, before having to dive into extending someone else's code. I tend to start with very simple code, then layer on more complex libraries and abstractions over time. Maybe you can break off small parts, implement a throwaway with fewer concepts, then use that as a template for how you would like the code to read and start rewriting small parts of databrary in that style.
This is the main block. ingestJSON :: Volume -&gt; J.Value -&gt; Bool -&gt; Bool -&gt; ActionM (Either [T.Text] [Container]) ingestJSON vol jdata run overwrite = runExceptT $ do schema &lt;- mapExceptT liftIO loadSchema let errs = schema jdata unless (null errs) $ throwError $ map (T.pack . show) errs if run then ExceptT $ left (JE.displayError id) &lt;$&gt; JE.parseValueM volume jdata else return [] Let's make this into python. def ingest_json(vol, jdata, run, overwrite): schema = load_schema() errs = schema(jdata) if not errs: raise map(lambda x: repr(x), errs) if run: try: return parse_value_m(vol, jdata) except JEException as e: raise JE.displayError(e) else: return [] oh, wait, no, this isn't `raise` appropriate because we're not just using runtime exceptions, but rather a sum-type: `ExceptT` is essentially the type of checked exceptions, backed by `Either e a`. Let's try to get Python to speak Either. To recap, `Either`: data Either e a = Left e | Right a either :: (b -&gt; r) -&gt; (a -&gt; r) -&gt; Either b a -&gt; r either onLeft onRight e = case e of Left b -&gt; onLeft b Right a -&gt; onRight a There's the tuple approach: def left(val): return "left", val def right(val): return "right", val def either(on_left, on_right, e): tag, val = e if tag == "left": return on_left(val) elsif tag == "right" return on_right(val) else: raise WtfEither() and the subtyping approach: class Either(object): def either(self, on_left, on_right): raise AbstractMethod() class Left(Either): def __init__(self, val): self.val = val def either(self, on_left, _): return on_left(self.val) class Right(Either): def __init__(self, val); self.val = val def either(self, _, on_right): return on_right(self.val) meh, i'm not impressed 
About pointfree, every single advocate for pointfree I've ever heard talking finish their talks saying "pointfree is nice, but don't overuse it". I prefer having the freedom of choosing how pointfull my code will be to maximize readability than being forced to be pointfull or pointfree all the time. On the variable names, you're right. People in the Haskell community do have the tendency to use single letter variable names and cryptic an short function names. That said, overuse of descriptive naming is also a code smell. It often means that you have overlooked a natural abstraction you could have used that more often than not would make your code more readable than it is now. The real code smell is not the ratio of descriptive versus non-descriptive names you use. It's really what's the fraction of the nondescriptive names refer to things that are not generalizable.
I agree with your point. Fortunately for me, I'm satisfied with string-conv so I usually just insert a `toS` at appropriate places when I get a compile error.
A doubt. For the type-level literals of [GHC.TypeLits](http://hackage.haskell.org/package/base-4.10.0.0/docs/GHC-TypeLits.html) it seems we can get far just by using proxies + type classes like KnownNat and KnownSymbol. What is the relationship with singletons, if any?
Why do we even need this runtime value? Can't be get away with matching on types via typeclass instances? So completely statically dispatched type level programming.
Just looking quickly at the first link, most of the problems have a library or extension that mitigates or solves the problem. I don't know why we're not moving a bit faster to build more of these into core but I think that's pretty good progress for a community as small and academically focused as this one
Having both `String`, `Text` and so on is awkward—but that's all. With Haskell's type system you always know which one a function needs, so the only practical problems are that it makes Haskell ecosystem moderately (and unnecessarily) harder for beginners and occasionally leads to wonky performance or tedious type conversions. Dependent types, on the other hand, enable us to write a lot of code that we couldn't otherwise *and* massively simplify a bunch of type-level code that people are already using. Additionally, if we had simple dependent types far enough in the past, I suspect it would make Haskell's type system *simpler* because we wouldn't need a lot of the more "advanced" type system extensions and features we have now. We wouldn't need kinds and, I believe, dependent types would obviate a lot of arbitrary features like type families and type-level numeric/string literals. I would take the latter over the former any day. The String/Text/etc thing might matter more for getting Haskell *popular*, but one of the core things I love about Haskell is that we're willing to prioritize making the language *better* over making it *more popular*.
I noticed that `Since` annotations are gone in Haddock, compare: https://hackage.haskell.org/package/base-4.10.0.0/docs/GHC-Generics.html#v:packageName https://hackage.haskell.org/package/base-4.9.1.0/docs/GHC-Generics.html#v:packageName It's lacking the `Since: 4.9.0.0`. Or is that on purpose because the function's types changed?
Gotcha! That's a really good point. I'd actually never even heard of Foldable1, but it's something I've often needed so thanks for that! It's worth my time exploring these things just to get feedback like that!
Slightly off topic but related: Do we have an ETA (estimate or when ghc will have support by default or language extension) for Linear Types? I'm wondering because the performance impact is supposed to be large. Edit: explained what I meant by ETA.
Funny... to me, the `base-4.10` Haddocks do appear to have Since annotations (whereas the older `base-4.9` Haddocks do not).
Thanks! Related: not without quirks (and only up to 8.2.1-rc2 yet), but here's a crosslinked source where you can find backreferences too: http://stuff.codereview.me/#ghc/compiler/main/GHC.hs?corpus=ghc-8.2.1-rc2&amp;signature&amp;line=873. Wonder if this would help your case?
&gt; So at first I wanted to cover all sorts of crazy advanced type-level magic, Now *that* sounds like something I'd be interested in learning about!
Idris seems to do this: http://docs.idris-lang.org/en/latest/effects/summary.html but I haven't found anything in Haskell that's convenient. it's possible with typeclasses / extensible effects, or even just manually rexporting functions from a module that opaquely newtypes IO and lifting the calls. 
Cheers, just ran into that wrong link for Data-Compact. Seems like some stringy substitution isn't working. eg https://downloads.haskell.org/~ghc/8.2.1/docs/html/libraries/ghc-compact-@LIBRARY_compact_VERSION@/GHC-Compact.html
The only one I've used so far is putting database access in a separate monad, so you can't do arbitrary IO inside a transaction. That's been effective at stopping some bugs.
`Proxy a` carries compile time information about `a`, but at runtime all proxies look the same - that is, they all look like the value constructor `Proxy`. Type-level information is gone at the value level. `KnownNat` gives you a way to get value-level `Integer` from a type-level `Nat`. You can't get a type-level `Nat` from a runtime `Integer`. Given `KnownNat n`, performing case analysis on `natVal` doesn't teach the type checker anything about `n`. (It teaches _you_ about `n`, but not the type checker.) Value-level information is gone at the type level. That's what GADTs are for. Pattern matching on a GADT constructor refines the types in scope. You perform a test on a value and learn something about a type. Pattern matching on `SNat` refines the associated `Nat`. This is crucial in McBride's `vec` (née `replicate`): it has to know, at runtime, how many `x`s are in the output vector, but it also has to be able to prove, at compile time, that said number of `x`s is the _right_ number of `x`s. `Proxy` won't do because you lose the runtime information, and `Integer`/`KnownNat` won't do because you lose the compile time information. While proxies and classes do get you an often-surprisingly long way, they don't get you all the way: as soon as you need to bind types to values (not the other way around) you need clunky old singletons. `TypeLits` in particular is hamstrung by the fact that `KnownNat` just gives you an `Integer` with no extra type level information about which `Nat` it means. You can't recurse on a type level `Nat`, so you end up resorting to `unsafeCoerce` to twist the type checker's arm into believing what you know to be true. [A risky proposition](https://stackoverflow.com/questions/44944389/avoiding-an-incomplete-pattern-match/44946367#comment76947940_44946367)!
You should make a new post for this.
In my project I'm using `ghc-Options: -pgml g++ "-optl-Wl,--whole-archive" "-optl-Wl,-Bstatic" "-optl-Wl,-lmyclib" "-optl-Wl,-Bdynamic" "-optl-Wl,--no-whole-archive"` in the Cabal file to link in a C library I create as part of the build process. Any idea what the `gold` version of this might be? I've tried `-pgml gold "..." "..."` and it doesn't work.
You may not know `n` statically. What if the number of elements is chosen by the user?
Also thanks to the various people who have made fixes to packages to make them compatible during the 8.2 release candidates. I have just upgraded a package with 300 (recursive) Hackage deps in a few hours, thanks to those people. [Here's a collection of packages that need fixes](https://gist.github.com/nh2/a6de5e5409c8893d67ef444a7664ed98), with indications of what kinds of fix.
This only made it to ghc-devs, so I thought it'd be useful to announce this in general. Example: http://stuff.codereview.me/#ghc/compiler/hsSyn/HsBinds.hs?corpus&amp;signature Why is this great, for your projects and especially when you want to work on GHC in this case? Because it makes it possible to find all callers of a function, so that you know what calls to check when you change the behaviour of that function.
OK: https://www.reddit.com/r/haskell/comments/6p4v50/ghc_crossreferenced_with_haskellindexer/
You use the `someNatVal` function to lift the integer into a hidden type. The second part of the equation is a function `forall n. KnownNat n =&gt; n -&gt; something` which you're gonna need anyways since you need to be able to handle any kind of user input. Then you just pattern match on the existential constructor and use your function. The tricky part is that your function only has the `KnownNat` constraint to work with, but I feel like this can be worked around.
This post should be deleted by the mods. This person is obviously looking to start a flame war. 
agree
When do we get inline-rust?
i definitely wasn't
I doubt it can be worked around. The problem is partiality. `KnownNat` doesn't imply that `n` is a non-stuck `Nat` (it does to _you_ but not to the machine), so the elaborator won't know where to find a dictionary for the custom type class you're doing your static dispatch with. `Natty` at least lets you "prove" at runtime that the associated `n` is in fact a real `Nat`, by scrutinising the associated value and finding that it isn't bottom and you're still alive. (From what I've seen most dependently typed Haskell programmers appear to deliberately forget that they're playing Russian roulette.) That allows the elaborator to build dictionaries for `n`, as in: nattily :: Natty n -&gt; (NATTY n =&gt; r) -&gt; r nattily Zy x = x nattily (Sy n) x = nattily n x (Of course you still need to write your code in a `forall n. Natty n -&gt; ...` context, if `n` is coming from user input.) You could of course try to write all your code with a `KnownNat` constraint and just work with the `Integer`, which, you might get lucky and it goes OK, or you might have to use `unsafeCoerce`. Not everything in the world has to be verified. One idea might be to write a `KnownNat n =&gt; Natty n` function which does the only `unsafeCoerce` call you'll need.
fwiw, i played with it too when released https://github.com/sboosali/eight/blob/master/sources/Eight.hs
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [sboosali/eight/.../**Eight.hs** (master → cdc40ef)](https://github.com/sboosali/eight/blob/cdc40efcd7b9893af0db47fd79af9bb8a41cdfa8/sources/Eight.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkmn6wh.)^.
Yeah, really want to use these. I have a web app that loads a huge chunk of data into memory and then allows web clients to run queries on that data. The data is immutable, so why not stick it in a compact region to avoid the GC having to run over it. Pretty sure it will be really nice for constructing data in memory, moving it to a compact region and then saving it to disk so it can be restored to a compact region later. 
GHC 8.2.1 will use `gold` automatically if it's available (and you haven't explicitly told it not to). You shouldn't need to do anything.
That sounds like a bug. Paging /u/alexbiehl.
Looking forward to it!
You can do this if you design the class appropriately. For example class Natty (n :: Nat) where natcase :: (n ~ Z =&gt; r) -&gt; (forall n'. (n ~ S n', Natty n') =&gt; r) -&gt; p n -&gt; r (It's been a while since I've written one of these, so some adjustments may be necessary.) You can even do it without type equalities, as in the old type-case pattern: class NatOp g where zero :: g Z succ :: g n -&gt; g (S n) class Natty n where nat :: NatOp g =&gt; g n These still rely on passing a run-time value, though: the implicit class dictionary.
Putting every EC2 function in the typeclass is probably not necessary. Just having the function which applies the authentication signature/header to EC2 requests should be enough. Every EC2 function gets "tainted" with the typeclass constraint without being necessarily in the typeclass. Although one does need to define a lot of wrapper functions for every such effect that needs to be tracked. Can that be automated via TH? 
If one is making a website skinning/theming engine that is going to be used by a number of newbie Haskell devs, how do you prevent their "renderPage" function from having access to logging and the Redis cache, but not the DB or the network? 
Haskell has decent IDE support in IntelliJ: https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8 Lots of people prefer Spacemac's with Haskell layer, or vim etc. The best web framework in my opinion is Servant as it's type safe and doesn't use template Haskell: http://haskell-servant.readthedocs.io/en/stable/ Haskell is pure ie doesn't allow side effects which makes it quite different from F#. 
Offhand, I vaguely recall seeing a benchmark in which lld wrecked gold. Can't say much more than that, though, but the fact that it's new and shiny is enough for me to be interested, personally
&gt; how about instead of being offended and defensive people admit some of the flaws So you are asking people to admit things they don't even believe are true or fair, how arrogant of you.
The general place to start for these questions is the [State of the Haskell Ecosystem](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md) document. For instance, since you're interested in web libraries, check out the [server side programming section](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#server-side-programming). I'm sure that you'll get lots of good advice that's more tailored to your situation in this thread as well.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Gabriel439/post-rfc/.../**sotu.md#server-side-programming** (master → 326ab55)](https://github.com/Gabriel439/post-rfc/blob/326ab5504e0f985ee460a41b5f6f5c89b4a58ada/sotu.md#server-side-programming) * [Gabriel439/post-rfc/.../**sotu.md** (master → 326ab55)](https://github.com/Gabriel439/post-rfc/blob/326ab5504e0f985ee460a41b5f6f5c89b4a58ada/sotu.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkmvt0f.)^.
That looks awesome, thanks for sharing!
I think it's not 'gone' but 'reappeared'. Though I can't remember any change specific to them. But I am glad they work again! 
Joey Hess, a former Debian developer, is [living](https://lwn.net/Articles/672352/) this dream (or he was, a few years ago).
This is pretty neat! I actually have a bunch of little use cases that this might help out.
It's a pity that `brick` is based on `vty` which doesn't support windows well for now.
Because you `Cons` an `a` to `HList (b : cs)` and expect to get `HList (a : b : cs)`.
Yes, please help move [vty windows support](https://github.com/jtdaugherty/vty/pull/1#issuecomment-297143444) forward with testing, bounties, or code.
I don't know Rust, but You have a few choices in terms of IDE, i think atom, vs code, emacs (or spacemacs) and vim have the most users afaik. It won't be a smooth ride, but you can definitely use them to develop large software. Dependency management got a lot easier than a few years ago with stack and stackage. Stack will manage your sandbox and will install ghc for your project and there are snapshots of a lot of packages that are guaranteed to work together on stackage and everything is setup per project. Visit www.haskell-lang.org/get-started to learn more. I found that the Haskell ecosystem usually has the packages I need to get the job done. For example I wrote on my experience with Spock developing a small project [here](https://gilmi.me/post/2017/04/25/building-gathering). However, there are plenty under documented packages out there, and Spock does not have the same amount of docs as Rocket. Maybe Yesod docs are good enough though. Hope this helps.
What do you mean by ETA? 
&gt; And as a reader you just have to hope that T means Data.Text. In this case, you don't have to guess it, it's there in the beginning of the file. It is worse when there are unqualified imports.
&gt; It's really what's the fraction of the nondescriptive names refer to things that are not generalizable. Do you mean "descriptive"? Anyway, great rule of thumb!
&gt; maybe (throwPE "asset not found") (return . (,) Nothing . Just) =&lt;&lt; lift . lookupVolumeAsset vol . Id =&lt;&lt; JE.asIntegral pieces like this are really overkill to my taste. I wonder if there are people who finds it easier than expressed as lambda.
&gt; Hey haskellers! (How do you call yourselfs) Yes, "haskellers".
&gt; i posted this here because of this on HN &gt; &gt; https://news.ycombinator.com/item?id=14826513 *waves!*
You got it from [Testing GHC release candidates with Stack](http://taylor.fausak.me/2017/05/17/testing-ghc-release-candidates-with-stack/) which recommends it because most packages have useless version constraints which [are harmful to Stack](https://www.reddit.com/r/haskell/comments/6jv15h/haskell_infrastructure_swift_navigation/djqhuda/).
Nice! Slightly related to that, the [haddock documentation](https://haskell-haddock.readthedocs.io/en/latest/index.html) has finally been updated and looks a lot better now.
That is a good question. I'll edit
&gt; Dependency management got a lot easier than a few years ago with stack and stackage. This! FPComplete invested a lot of time and effort to [improve our tooling](https://www.reddit.com/r/haskell/comments/6n9b8k/asking_for_advice_on_how_to_make_playing_with/dk8aczg/)) which was the number one complaint about Haskell. If it wasn't for FPComplete's Stack I would have given up on Haskell already and moved on. 
I agree. Very hard to read! It's particularly hard for me to read because I don't know the relative precedence of `.` and `=&lt;&lt;` and moreover, *I don't want to know*!
&gt; F#'s adoption of top to bottom, left to right, means that the type-checker can disambiguate overloaded functions easily Can you say more about that? What you wrote is puzzling.
(There's no unique best thread in which to leave this comment so I'll just leave it at the top level) Dear OP, perhaps things are becoming clear to you know after several hours and several replies but I'll take the opportunity to make things explicit. You say you "would like haskell to be a practical choice". What you've done is link to an example of Haskell that's not very clearly written[1] with a sarcastic title. Do you see how your actions are counterproductive to your stated goal? What you did is just going to rile people up, nothing more. This would be the same on an OCaml forum, a Go forum or a forum about something unrelated to programming. If your desire is truly to make Haskell a practical choice (and I mean your latent desire, not your manifest one) then here are some suggestions about what you could do * Learn more Haskell with the help of /r/haskell or other internet forums. You'll find us very helpful and willing to be patient. Perhaps read http://haskellbook.com/ * If you already know Haskell then you can write a blog post that elucidates coding guidelines. You could even refactor some code you consider unreadable into a readable style. I think this would be helpful and encouraging for us all. * If you think Haskell is beyond saving (which it seems you do, given that [the things you complain about](https://www.reddit.com/r/haskell/comments/6p29rv/haskell_is_the_most_readable_language/dkm5zzs/) are fixed features of the language which are never going away) then probably the best thing you can do is write a blog post about what you don't like about Haskell and take it to other programming communities and warn them not to follow in Haskell's footsteps. All those things would be constructive. Your post here is not. [1] And I feel a bit sorry for the author for having his code publically discussed like this.
I wouldn't recommend trying to cover a bunch of other languages, i think it's better to be focused on one thing. I'm also not sure about the lambda calculus chapter, i think lambda calculus is interesting to learn before the basics of haskell because it gives you the ability to teach a bunch of haskell features, such as expressions everywhere, evaluation schemes, first class functions, lambdas, scoping, currying, etc, in a really small language. But if are planning to teach these things before LC, it might not be worth to spend a long time on it. But i don't know, maybe it is worth it. On a different note i'd really like to see a "Haskell by Example" kind of tutorial. Most resources just dump a bunch of features on the reader and I guess that works for some but I'd also like to see a resources that goes the other way: "Here's what I'd like to accomplish, let's see what Haskell provides to make this work". Maybe I should just try and write something myself and put my money where my mouth is. Anyways, good luck!
To answer a slightly different question: linear types allow for the *potential* to write code without incurring the GC. It gives nothing for free and changes no existing code. We don't even have the full semantics figured out for how to best take advantage of them to enable more efficient code; that will have to be discovered as we get used to them. Performance impact might be large in the future, but I can't imagine anyone noticing much for a year or two. This proposal, on the other hand, seems much more immediately effective, as it concerns the efficiency of the language implementation rather than the capabilities of the language's ability to express hints to the compiler about how to optimize resource usage.
&gt;I had some problems with IDE when I tried to write something back then. Still no IDE, but you can get things working easily in Emacs or vim. &gt;Are compiler errors easy to debug? By and large, yes, but there are times when they are not (lenses in particular come to mind). &gt;How would you compare rust ecosystem to haskell ecosystem today? More libraries for Haskell, more tooling (hoogle, hlint, weeder, ghc-mod, stack, stylish-haskell) but the tooling is sometimes less ergonomic than plain cargo. Haskell's libraries skew more theoretical, and you're not going to find an equivalent to `lens`, `recursion-schemes`, or even `aeson` on crates.io.
The "Top Programming Languages" posts are invariably kind of flawed. Not as bad as ranking a language based on Stack Exchange answers, but this is still silly. 
&gt; Mostly a question of Haskell wrappers for Python libraries. That and and Django/Yesod need some bridge code. Write your project in one and emit the other for free. And run slower...? Haskell bindings for Python don't really make sense for a lot of reasons.
For that I'd make a `Render` monad which exposes only the actions you want to be accessible. If you do your class based approach, then you could use something like the below but with your actual base monad: `newtype Render a = Render {runRender::IO a}deriving (Functor,Monad,Applicative, HasDb)`
Cool! Would it be difficult to add `addForeignObjectFile :: ByteString -&gt; Q ()` (for .o files)?
I think this is the perfect case for the use of implicit parameters. Instead of: someFunc :: (MonadReader env m, HasConfig env, MonadIO m, MonadLogger m) =&gt; m () someFunc2 :: (MonadReader env m, HasBuildConfig env, MonadIO m, MonadLogger m) =&gt; m () someFunc2 = someFunc you can do someFunc :: (?config :: Config) =&gt; IO () someFunc2 :: (?config :: Config, ?projectConfig :: ProjectConfig) =&gt; IO () someFunc2 = someFunc 
Doesn't work for GHC Nats. That's the problem. Ideally what you want to have in your class is the ability to partition the numbers using some condition.
In the post [_What's wrong with ImplicitParams?_](https://www.reddit.com/r/haskell/comments/6gz4w5/whats_wrong_with_implicitparams/) I was pretty convinced this isn't a usable extension because [of this problem](https://www.reddit.com/r/haskell/comments/6gz4w5/whats_wrong_with_implicitparams/diugtwu/).
This sounds very similar to the idea from "Don’t Stop the BIBOP: Flexible and Efficient Storage Management for Dynamically Typed Languages" (Dybvig et. al.) https://www.cs.indiana.edu/~dyb/pubs/bibop.pdf In the context of GHC I can't predict how well it would work because there are a *lot* of variables and this would be a huge change to the underlying execution and memory model. I wouldn't say it's unworkable, but it's a different set of tradeoffs that goes very deep into how GHC's execution model and memory management system is designed. I can say, though, that * It would be a lot of work to implement it, because it changes some of the fundamental assumptions, such as an object begins with an info pointer, etc. * Allocating into different pools depending on type would make allocation more expensive and complex. This is the main tradeoff - GHC is designed with very fast allocation as the top priority (for better or worse - you could certainly take different tradeoffs, but this one has served us well) * It would make GC more complicated. Every axis you add is a layer of complexity, for example we currently have two axes: generation and GC thread (for parallel GC), giving us N*M heap areas to worry about. I actually got rid of a third axis (step) that was used for object aging, because things were getting too complex. Adding another axis for object type worries me. 
I feel like this is avoidable?
(Off topic: Are you Indian by any chance? I've noticed a pattern of Indian English speakers using "a doubt" where in British English we'd use "a query" or maybe "a question".)
Regarding "It unfortunately doesn't have access to check if it points to the same memory region as it was read from." Would it make help to use `reallyUnsafePtrEquality` like in [the Haskell SpriteKit paper](http://www.cse.unsw.edu.au/~chak/papers/spritekit.pdf)?
&gt; Java is consistently read top to bottom, left to right. Except that there is `foo.bar().baz()`, `baz(bar(foo))`, `baz(foo.bar())` and `bar(foo).baz()`.
What's knew in the Haskell world since the last few years is stack, intero , servant, (lenses ?) and spacemacs (which I personally use)
It might! Thanks for bringing it to my attention!
How?
How often do you encounter this corner case in real life ? Can't the compiler issue a warning ?
Well, not to do `let ?a =` more than once in the same definition, and so on. This does seem like rather a corner case.
After looking around, I've also found StableName: http://hackage.haskell.org/package/base-4.10.0.0/docs/System-Mem-StableName.html#t:StableName These do look promising.
&gt; Java is consistently read top to bottom, left to right. This is an issue I've been struggling with for a while. I'll kick off by saying that what you claim is not really correct. See [the comment by /u/Regimardyl](https://www.reddit.com/r/haskell/comments/6p29rv/haskell_is_the_most_readable_language/dkn4jd3/) for details. After that observation I think we're at an impasse. Function application, in mathematical notation and all mainstream programming languages, is right-to-left. `f(g(x))` takes `x` and applies `g` then `f`. Can we at least make everything right-to-left consistent? Well, Haskell's type signatures are left-to-right: `a -&gt; b` is the type of a function that takes an `a` and returns a `b`. We'll need to switch this. Is `b &lt;- a` good enough? No, it turns out this doesn't work either. What would be the type of f name age = name ++ " is " ++ show age ++ " years old" ? It would be `String &lt;- Int &lt;- String`. The `... &lt;- Int &lt;- String` part is the *opposite* way round from how we pass parameters to `f`! So I think we are stuck. There seems to be some fundamental reason why we can't stick to only one of right-to-left and left-to-right. Can anyone shed any more light on this? Given that I perceive this fundamental obstacle I've not just accepted that both have to exist. The best we can do is to discourage mixing directions in the same unit of code, for example never have composition or application chains that mix application, `$` and `.` with `&gt;&gt;=` and `&gt;=&gt;`, or that mix `&amp;` and `&gt;&gt;&gt;` with `=&lt;&lt;` and `&lt;=&lt;`. 
I'm actually Spanish :) "Tengo una duda" sounds much more natural in my language when asking a question. I guess I went with an overly literal translation!
Interesting. I found this link about Indian English. In that case it seems to be a translation from Hindi. https://english.stackexchange.com/questions/2429/can-doubt-sometimes-mean-question
What's the difference between sections and headings? (And, syntactically, lists...)
**Quick Summary of WSL** WSL ("Windows Subsystem for Linux") is a like a "microkernel" that runs on Windows 10 alongside the traditional NT "microkernel". It provides a kernel API that mimics the Linux x86_64 kernel; in particular, it runs regular Linux ELF binaries. Microsoft provides out-of-the-box support for Ubuntu Xenial. This is not Ubuntu for a new platform - it is regular Ubuntu 64-bit Linux, getting its packages and updates from the regular APT repositories. Microsoft has announced that more Linux distros will be supported out-of-the-box soon. The main difference between the WSL kernel and the standard Linux kernel is that WSL provides smooth integration with traditional Windows applications. For example, you can also run Windows programs from the bash shell, and when you run an Ubuntu program and a Windows program in the same pipeline, their stdin, stdout, and stderr are connected together neatly. Another difference is that WSL is proprietary, not open source. Yet another difference is that WSL is still a bit rough, with some bugs and missing features, but that has been getting much better over the past few months. At least for now, WSL is only available when you enable "Developer Mode" and recite a magical incantation in PowerShell run as Administrator, so most Windows 10 users don't have it. **GHC on WSL** It became practical to run GHC, and programs compiled by GHC, on WSL when the kernel call `timer_create()` was implemented by Microsoft in WSL in Feb. 2017 (with GHC specifically in mind). However, the elation quickly evaporated when GHC 8 was released. The new GC in the GHC 8 runtime maps 1 TB of memory at app startup. On the standard Linux kernel this does not actually allocate any memory, but the WSL kernel dutifully starts trying to cough up 1 TB of actual memory for you. Needless to say, Haskell programs compiled with a standard GHC 8 build, including GHC 8 itself, perform very poorly on WSL. Until Microsoft fixes this issue, a work-around is to compile GHC using ./configure --disable-large-address-space Besides the linked GHC Trac issue, more discussion between Microsoft, Haskell devs, and non-Haskell devs using Haskell apps such as pandoc, can be found in [this GitHub issue](https://github.com/Microsoft/BashOnWindows/issues/1671). EDIT: I qualified and quoted the term "microkernel", because as /u/captain_hoo_lee_fuk pointed out, it isn't really a microkernel architecture.
There should probably be some GitHub wiki page where can collect a list of such packages.
Oops you're right, I flipped the order. Thanks for noticing!
Yes, I'm not aware of any language ecosystem with a library eco-system that is more consistent (i.e. will not randomly fail) than stackage.
Just yesterday, I compiled a version of GHC 8.0.2 with large adress space disabled. I'll try to upload it today, if I got some spare time. See https://vincenthz.github.io/posts/haskell/2017-07-20-ghc-stack.html how to get `stack` working from there. In particular, my plan is to have a custom snapshot in the global project (`~/.stack/global-project/`) and use a recent `lts-8` together with the new compiler. I haven't really tried this yet, so there might be some roadblocks ahead. Edit: Uploaded it to https://github.com/sgraf812/ghc-dlas.
Indeed there are. The thing is the first is idiomatic and common in contemporary Java; the rest are very rarely used. Also, as I mentioned before, comparing oneself to Java isn't saying much at all. Why not compare to F# or Elm?
Hmm, thinking a bit more clearly, I'd confused three things. 1. F# supports field-name overloading, e.g. you can have a `name` field for both `Person` and `Company` types instead of having to prefix ala `pName` and `cName` (I know work is underway in GHC to fix this). This is helped by the left-to-right fact that you're writing `variable.fieldName`, where the variable, coming first, helps identify the particular overloaded fieldName variant. 2. F# supports [method overloading](https://fsharpforfunandprofit.com/posts/type-extensions/) 3. F# does not support function overloading 4. The left-to-rightness of the `|&gt;` operator makes editor auto-complete much easier. When you write `variable |&gt;` the editor knows to only prompt those functions in scope whose last parameter has the same type as `variable`. The way Haskell is traditionally written, auto-complete is a lot harder
I also currently use his tutorial to learn brick. Although I'm designing a todo app in curses. brick is pretty handy and seems really well-designed.
Thanks, that would be great!
it wouldn't, i think it's a great idea! cc /u/mboes
&gt; type-level values `'Zero` and `'Suc`. The latter live only in Haskell's type language and have no run-time presence at all. Please note that although `'Zero` and `'Suc` exist at the type level, it is unhelpful to refer to them as "types" and the people who currently do that should desist. They do not have type `*` and can thus not classify values which is what types worthy of the name do. Ah! I knew the word "type" was ambiguous, but I didn't know what to call them instead. "Type-level values" it is!
Thanks for the in-depth response. I'm sad to hear that impact is as far away as that but glad to see things continuing and improving incrementally.
&gt;I'm sad [Here's a picture/gif of a cat,](http://24.media.tumblr.com/x3Rmp1Hjoou8ifx3UMrV8ILfo1_500.jpg) hopefully it'll cheer you up :). ___ I am a bot. use !unsubscribetosadcat for me to ignore you.
[removed]
Thanks bot...
Thanks; that was excellent!
The paper is quite approachable.
I am not completely sure I understand the advantage of `RIO a b` with relation to `a -&gt; IO b`. You can use the same constraints in `a` in both, use the `MonadLogger` directly in `IO`, and you exchange `ask` for a function parameter, did I miss something?
If one wanted to use a different compiler, say `HCC` from AMD to compile to GPUs, how hard would it be to switch compiler or link in additional runtime systems required by the GPU?
Indeed! cc /u/facundominguez
Besides the better integration with Unix tools, is there any other reason to use GHC inside WSL instead of the standard ghc-windows tarball build? I mean something among speed,memory or i/o for ghc applications running in windows
[Coding style: because fuck you, that's why](https://pbs.twimg.com/media/C_pOQGkXUAA5Enu.jpg:large)
Whisper more lovely things in my ear please
&gt; You can't get a type-level `Nat` from a runtime `Integer` I respectfully disagree: {-# LANGUAGE RankNTypes #-} import Data.Proxy import GHC.TypeLits printKnownNat :: KnownNat n =&gt; proxy n -&gt; IO () printKnownNat = print . natVal -- | -- &gt;&gt;&gt; withKnownNat (read "1234") printKnownNat -- 1234 withKnownNat :: Integer -&gt; (forall n. KnownNat n =&gt; Proxy n -&gt; r) -&gt; r withKnownNat n cc = case someNatVal n of Just (SomeNat proxy) -&gt; cc proxy Nothing -&gt; error $ show n ++ " is negative" I agree with everything else in your comment though.
Here's my comparison of the two approaches. With implicit params: * You get to use plain `IO` functions, `unliftio` isn't necessary * You have to use a controversial language extension (as demonstrated in Chris's link) * It appears (though I could be wrong) that you'll have an ever-expanding list of parameters for each new capability * There is no support for working with existing mtl-style typeclasses like `MonadLogger` By contrast, with `RIO`: * You have to use `unliftio` or similar libraries instead of plain `IO`. However, none of the safety concerns I've raised in previous blog posts apply since there is no monadic state * Get to stick to more well established language extensions (FunDeps, type families, etc) * The superclass approach allows for simple constraints on the environment * There's an easy route to compatibility with existing mtl-style typeclasses * I _think_ overall `RIO` ends up with less keystrokes in each type signature. Even without the larger number of implicit params necessary, compare `someFunc :: (?config :: Config) =&gt; IO ()` to `someFunc :: RIO Config ()`. An example using `HasEnvConfig` would be more extreme I did seriously consider pursuing implicit params after you mentioned it last time, but the arguments presented against it convinced me not to go with it. I don't see serious downsides to the `RIO` approach, and it is not too large a departure from how many people are writing code today.
For anyone else watching, the option in question was the `allow-newer` setting in my stack YAML.
To quote myself from the blog post: &gt; I want to be clear: this approach isn't bad, and has a lot of simplicity benefits. I know people who advocate for this approach in production software, and I wouldn't argue strongly against it. But I do think we can do better aesthetically and ergonomically. So let's keep going. In other words, I _don't_ believe the explicit parameter is a terrible choice, not by a long shot. However: * After writing lots of code in different styles, it becomes tedious to have to pass in the explicit value each time * A minor point, but with explicit values: it's not easy (for me) to remember what position it appears in (beginning of arg list, end, maybe in the middle?) * I'm not sure how you'd "use the `MonadLogger` directly in `IO`". The closest I can see would be `runLogger ($logInfo "foo") (getLogFunc config)`. Which works, but is more overhead than I'd like for something as simple as logging. Also, by the time you finish writing your `getLogFunc` function for each `Config`-like value or defining a typeclass, you're half way to `RIO`. End of the day: these two approaches are equivalent (`a -&gt; IO b` is isomorphic to `RIO a b`), and it's a question of style. There are concrete arguments each way, but it's ultimately a subjective call. I can totally understand someone making a different subjective call. The objective arguments apply much more when comparing with the other approaches I call out in the post.
The proliferation of `HasX` typeclasses just feels nasty, like it's a way to hack on structural typing 
https://github.com/databrary/databrary/blob/master/Databrary/Controller/CSV.hs#L60
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [databrary/databrary/.../**CSV.hs#L60** (master → 63268d8)](https://github.com/databrary/databrary/blob/63268d86e8c948d89f21892f809a0f81581b730f/Databrary/Controller/CSV.hs#L60) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dknbsfj.)^.
For me its having easy access to `nix`. That, together with the pain I experience doing GHC development for my master's thesis (build pains, reproducibility, build time, test breakage, etc.). If every project I touch would be compatible to `stack`, I don't think I ever would need WSL, at least not for Haskell dev. Outside of Haskell dev, having a good package manager (`apt` by default) or rather an abundance of easily installable packages available is really handy. Writing Latex stuff is a matter of just installing the right package, whereas on Windows it is just the biggest pain in the butt.
Here are some reasons that WSL is better for my team: 1. Building libraries that compile C or C++ code via FFI is sometimes problematic on Windows. 2. Overall the results on Windows are more fragile, because the whole built over an emulation layer. You often get weird segfaults on Windows that go away after you try a few more times. 3. The product we are working on is a web app that is always deployed on Linux. Sometimes devs working on Windows see platform-dependent behaviors which do not match what will actually happen in production. Other teams in our company working on other products that get deployed to customers as Windows EXEs must continue to use the Windows version of GHC. At least for now, until it becomes standard for all Windows machines to have WSL.
&gt;And I feel a bit sorry for the author for having his code publically discussed like this. man i can't imagine being so sensitive that i couldn't handle my code being criticized.
How would you compose such a thing? Since even a simple lens should support nesting. 
That's interesting, because in this thread you come across as someone who can't accept that other people see things differently. 
Implementing a Category instance shall suffice.
It's interesting that someone else's imagined sensitivity is the only thing you found worth mentioning in response to my (rather in depth, if I do say so myself) suggestions.
You're going to have to work hard to convince me that nested function calls are rarely used in Java!
How bad is this for a webapp?
what can i say? it's the most insightful thing about your post.
It says a lot about you that you find that insightful. 
This style reminds me a bit of the "rank 'n classy limited effects" pattern discussed here a number of moons ago.
what can i say? i'm used to people that are more mature than to have their feelings hurt over code.
Wouldn't compiling on linux vm be easier and simpler? In fact you can just copy vm to other team members instead of configuring each windows machine again and again. 
I mean... this function is intrinsically complex. It's quite different from what I've screenshoted which is basically: multiply :: Int -&gt; Int -&gt; Int multiply x y = f [x, y] where f [x, y] = let xzero = case x of 0 -&gt; True _ -&gt; False in if xzero then 0 else x * y f _ = __IMPOSSIBLE__ The useless one-letter auxiliary function with no type annotation, the intermediate list, the `__IMPOSSIBLE__` to deal with the fact that we are not actually dealing with arbitrary lists, the `case` producing a `Bool` which is immeditaley consumed in an `if...then...else...`. This is a masterpiece.
I would note the tutorials on how to implement Servant have been important for exposing more people to the idea of implementing a type level DSL. Bookkeeper
Looks great. I have a question, having seen this in the README: &gt; In conjunction with an as-of-yet unwritten tool, cabal2ninja, that will generate a Ninja file based on information from cabal and ghc -M, we will have incremental builds for any Haskell package that uses a default Setup.hs file. I wonder: what's the advantage of creating `cabal2ninja` over a `cabal2shake`? After all, Neil claims that Shake runs Ninja files faster than Ninja does. Is `cabal2ninja` easier to write? Would Shake be harder to run? Thanks!
You can reduce the boilerplate using [Data.Has](https://hackage.haskell.org/package/data-has-0.2.1.0/docs/Data-Has.html), but it does not answer your impression it is a hack.
I've recently switched from Haskell to F#. I dearly miss type classes. I also miss having a mature set of immutable collections, efficient diff and union for map types. I had to implement my own ByteString. The .Net framework with Mono is a mess. Stack is so much nicer than Forge, Fake, Paket. Fortunately, the recent .Net core is pretty convenient to use, with support for F# built in. Similar to Stack. So I'm using .Net core. That said, my current application, a user scriptable wiki, benefits a great deal from JIT compilation. Enough to take the hit elsewhere. Still, I dearly miss type classes. 
I did this course and, overall, I do recommend it. It's perfectly true that the treatment of the material isn't very deep but, on the other hand, it doesn't take much time to complete. I like the enthusiasm of the lecturers and the supportive community. You will need much more than just this course to master Haskell though. It covers maybe 10% of the Haskell Programming from First Principles - but that takes quite a while and quite some commitment to read.
what i'm pointing out in particular with the line i linked to is the stupid amount of nested destructuring and completely unintelligible variables. also i don't know why you think what i linked is complex since it's just a `case`?
I'd be interested. Lenses are fascinating and quite a deep topic. I see lenses popping up outside Haskell too - I see JavaScript devs using them to update state in React apps, so they might become semi-mainstream.
On the surface, it sounds like that would be great match for [acid-state](https://github.com/acid-state/acid-state)
I don't consider String/Text/ByteString to be a mess, so I'd prefer dependent types. But, I think dependent types are a bit less useful in Haskell than they are in Idris/Agda because of the existence of undefined inhabiting all types. --- Unicode codepoints as a control structure, i.e. for codepoint-by-codepoint parsing? String Unicode text for nearly any other purpose? Text for small ones, Lazy Text for ones larger than about 4k. Compact arrays of bytes likely to be split or appended? ByteString for small ones, Lazy ByteString for ones larger than about 4k. Compact arrays of bytes with (nearly) fixed sizes? Vector Word8.
It's not really something we notice. Our webapp has an average latency of ~5ms for read requests and a bit higher for updates. Our 99% latency is ~20ms and our 95% latency is ~7ms. I'd guess we could get that down a bit with smarter database bindings (looking at you, `mysql-haskell`), but performance isn't an issue.
Thanks for the signal boost! A bit more context in https://github.com/google/haskell-indexer/issues/56. Also, feel free to try for your own projects - see main Readme in the repo. That said, there are some rough edges - bug reports and PRs welcome!
&gt; i don't know why you think what i linked is complex Because each branch is using different substructures of the input? The patterns are not introducing any extra complexity, this is the level of details you need to go into to describe the behaviour of the function.
I honestly find it hard to read languages that use parentheses for function application these days. There's just so much noise
Use [anonymous records](https://www.athiemann.net/2017/07/02/superrecord.html) :-)
The devs who are interested in working on Linux are on Linux, not on a VM inside Windows. Devs who want Windows want a Windows environment. For them, dealing with the quirks of GHC on Windows is well worth it not to have to deal with Linux. But if GHC for Linux works natively on Windows, it's the best of all worlds for them.
Same problem here with Firefox 54 on Linux (Ubuntu). The cheat sheet renders correctly for me in Chromium.
I've rarely seen `baz(bar(foo))`. I do often see `foo.baz(bar.fud())`. However I don't believe this inhibits legibility. The code provided by OP, by contrast, is particularly opaque. Consider. Path path = Paths.get("/path/to/file"); List&lt;String&gt; list; try (Stream&lt;String&gt; stream = Files.lines(path)) { list = stream.map(String::trim) .map(String::toLowerCase) .filter(line -&gt; !line.startsWith("line3")) .collect(Collectors.toList()); } list.forEach(System.out::println); Or performing a SQL query manually: List&lt;User&gt; users = jdbcTemplate.query("SELECT USER_ID, USERNAME FROM USER", (rs, rowNum) -&gt; { // Builder can be auto-generated via lombok new User.Builder() .setUserId(rs.getLong("USER_ID")); .setUsername(rs.getString("USERNAME")); .build(); }); This is what modern Java looks like. It's pretty readable, and it's mostly top-down, left-to-right 
Shake is too powerful (monadic rather than applicative) to compile into Nix derivations, which is my goal in this project. Technically this isn't quite true, since Nix has a feature called import-from-derivation that allows a Nix expression to use data computed during a build, but I would still need to be able to convert an arbitrary Haskell lambda into Nix if I wanted to write a `shake2nix`.
That is cargo cult programming at work. That is usual en a new language or where there are massive amount of programmers that are newbies trying to be "idiomatic" so they overuse whatever they have learned recently. Very often, it is not that they want to make it complex but that they don´t see the simple pattern in what they do, so they can not codify it in a simpler way. Take into account that Haskell is a second language for practically all haskellers so it is a kind of learning tool and a tool for exhibition. Java had his years where every program used dependency injection shit almost for anything. In the medium term Haskell will become just a programming language, you will se how clean and simple Haskell is. In the long term, this circus would migrate to other languages, and we would return to sanity. But expect a few more years of coprofunctoidian cargo cult programming in haskell
Given that `RIO` is basically just a Kleisli arrow I think you could give it `Profunctor`, `Category`, and probably other instances as well. I'm not sure if there's anything in particular they'd come in handy for. EDIT: Indeed, while "an `IO a` monad with a built-in `Reader e` environment" is one way to read `RIO e a`, another is that it's simply the type of impure functions from `e` to `a`.
Total newcomer here, but nice project! Is this by any means being used by IDE backends or other IDE-related projects? I would love to have this straight from my code editor!
&gt; I've rarely seen `baz(bar(foo))`. I do often see `foo.baz(bar.fud())` And never `foo.baz(bar.fud(quux.grault()))`? &gt; This is what modern Java looks like. It's pretty readable, and it's mostly top-down, left-to-right Yes, that's all jolly nice.
They make sense for libraries that provide a lot of functionality where absolute speed isn't a priority, like matplotlib. (Which, happily, we having bindings for: [matplotlib](https://hackage.haskell.org/package/matplotlib).)
very easy, just use `-pgmc cmd`, as per `man ghc`: -pgmc cmd Use cmd as the C compiler 
You can do this on GHC type nats, but it needs deep magic, e.g. https://github.com/ekmett/constraints/blob/master/src/Data/Constraint/Nat.hs to help it along.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ekmett/constraints/.../**Nat.hs** (master → 424abfc)](https://github.com/ekmett/constraints/blob/424abfcac6f0e2427f009024c82b4b014bb54e32/src/Data/Constraint/Nat.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkno4zd.)^.
&gt; The .Net framework with Mono is a mess I concur. 
Makes sense, thanks.
Is there a documentation for the frontend language? * type inference features * ffi * effects
Considering that in order to use WSL they have to learn bash and the entire toolchain (apt-get, ssh, maybe even docker etc) I do not see how they can insulate themselves from dealing with linux.
Nice post! I'm excited that I almost understand all of it. &gt; The principle I'm beginning to form around this is: don't define effects with a typeclass on the monad, define it with a typeclass on the environment. As an analyst at heart, this was the big take-home for me. I have a question at this point; what's the difference between this philosophy and the philosophy behind "extensible effects" (such as in the Eff language)? I'm starting to understand monad more deeply and as it's so general, it seems to me that using monad to capture state and other things might be a bit too general for eloquently managing all types of 'effects'; I'm interested if there's a philosophy or mathematical concept with a touch more structure that can help partition things out in a useful way, here.
Ah fair point. 
Another great release by the geniuses on the Haskell team! Conrgats and bravo!
It's a lot different to write up a notepad of memorized magical incantations in order to use the Linux subsystem than it is to actually learn all of it. Plenty of Linux developers aren't shell wizards, don't use the terminal for anything they don't have to, etc. I wouldn't be surprised if a windows developer could get quite far on WSL without learning the underlying Linux. Especially if they can make some powershell scripts to handle all the common cases.
The way I find most promising so far, and the one I've had most success with is Reflex. You can give it a try here rather easily: https://github.com/reflex-frp/reflex-platform 
You may get a glimpse of what it is capable of via this presentation of the author: ~~https://www.youtube.com/watch?v=mYvkcskJbc4~~ Edit: Actually, this seems to be a higher quality version of the same talk given at a later time: https://www.youtube.com/watch?v=92eXGvHFbzs
Speaking of which, how is the `Data.Constraint.Symbol` module supposed to be used? The type families don't seem to want to reduce. &gt; :kind! Take 2 "abc" Take 2 "abc" :: GHC.Types.Symbol = Take 2 "abc"
Are you familiar with the [unexceptionalio](https://hackage.haskell.org/package/unexceptionalio) package?
It seems like it might make sense to have instance Monad m =&gt; MonadReader a (Star m a) where ask = Star pure local = lmap And then you could simply have type RIO = Star IO Or the equivalent for `Kleisli`, I personally just have a bias toward profunctors
My employer: SimSpace Boston, MA, USA https://simspace.com/ I don't have a public link to the job description yet, but we're hiring! We'll give a preference to Boston applicants, but also accept remote applicants from US and Canada. *edit*: [link](https://simspace.com/careers/?job=Software-Engineer-Backend).
The two that seem to stand out to me are [`react-hs`](https://github.com/liqula/react-hs) (previously [`react-flux`](https://bitbucket.org/wuzzeb/react-flux)) and [`reflex`](https://github.com/reflex-frp/reflex). Both are production ready and currently used in production. `react-hs` is changing somewhat quickly right now, due to it being a somewhat recent fork, but the project it is a fork of has very strong foundations and `react-hs` devs are active and will fix any bugs you find.
Challenge accepted: https://pastebin.com/hE8Dh99K
Lens can do this, but its kinda ugly ``` ('a', 'b') ^. _1 ```
&gt; It appears (though I could be wrong) that you'll have an ever-expanding list of parameters for each new capability &gt; I _think_ overall `RIO` ends up with less keystrokes in each type signature. Even without the larger number of implicit params necessary, compare `someFunc :: (?config :: Config) =&gt; IO ()` to `someFunc :: RIO Config ()`. An example using `HasEnvConfig` would be more extreme Generally you would do type BuildConfigIO a = (?config :: Config, ?projectConfig :: ProjectConfig, ...) =&gt; IO a to solve these two problems. I agree this won't help you if you want `MonadLogger`. On the plus side, it's clear what to do in the case of pure code.
`lens` has this in the form of `_1`, `_2`, etc.. They're lenses defined in type classes so that they work on tuples of many arities.
It could be as simple as having Django models emit Persistent code, or Persistent emitting Django model classes. The idea is you only have to maintain one, but get the other for "free".
still more readable
AFAIK deriving gets ugly with dependent types and you cannot auto-derive anymore i'm pretty sure i read this somewhere a few months back but feel free to correct me if i'm wrong
Then again, you wrote `MonadLogger`. You could have done it with `?logger :: Logger` instead of a type class.
&gt; How bad Yeah -- for a webapp this is a total non-issue.
Who's the second? 
My employer: Layer 3 Communications
https://circuithub.com/
What's the difference between either of those frameworks and [Miso](https://haskell-miso.org/)? Aren't they both based on FRP principles? AFAIK, Elm was strictly FR at the beginning, but eventually [broke from it](http://elm-lang.org/blog/farewell-to-frp). And Miso is basically a Haskell implementation of Elm. I don't know what the consequences of Elm breaking from FRP were, however, nor how similar Elm was to something like Reflex before it happened. 
Monads do the argument passing for you. If a function calls 10 functions that need the variable, that's ten arguments you would have to pass as opposed to zero in the reader monad. 
I've used Fay recently and wouldn't recommend it. The absence of type class makes it difficult to share code. Also, I'm using Fay.JQuery as well and I found it really hard to use. They use a different version of `Text` and you constantly need to convert from one Text to the other.
Thank you! Lots of great ideas here. In my usual style, I'll answer with an overly long essay (which lets me think through these points myself!) The coverage of other languages is really just a listing of what else is there in the world of functional programming, maybe showcasing the language in a very simple program, nothing more. I wouldn't be able to provide a lot of detail since I'm not really closely familiar with some of these languages myself! Explaining FP topics in different languages (which is the unlikely-but-desirable content) is something that would provide concrete value to people who buy this course to learn how FP can be applied to their day-to-day programming jobs, instead of just learning them as "stuff that Haskell can do". Again, not sure how much time I can spend on that, but it could be a nice expansion for the future. I had a lot of thought about the LC chapter – I really wanted to include it just because of its simplicity and theoretical relevance, but despite its simplicity, it would not be a good first chapter in a course which is ultimately about practical programming. Completion rate on Udemy courses is generally very low, and the best thing an instructor can do to maximise it is to get coding as soon as possible. But this brings me to your last point! Programming by example is a great idea and is often how Udemy courses are taught. Learning is much easier and faster when there is a concrete project one can work on. However, this method is most successfully used for things like Javascript frameworks, where there is a whole lot of existing knowledge that the instructor can assume and there is no need to get caught up on syntax or programming techniques. I thought that teaching a JS framework and a completely new programming paradigm are quite different things, and I would find it very difficult to start writing something big from scratch and introduce every new Haskell feature in an ad-hoc way. I personally also prefer bottom-up explanations and a "logically" structured curriculum, where I can say "we've seen guards in the lecture titled Guards" instead of "we've seen guards in the lecture where we added the email validation to our program". I intend to demonstrate every new feature with one or two practical examples, have larger programs in the end of every chapter pulling together all the concepts from that chapter, and have two fairly large programs as final projects which will hopefully tick the "practical examples" box! Nevertheless, as I said, programming by example is a great idea and I am really interested to see if it can be pulled off with Haskell! :)
Thank you! Let's hope for the best :)
Love seeing my employer Ambiata at the top of that list :). Also Digital Assets may be based in Switzerland, but that also have offices here in Sydney. I know a couple of Haskellers who work there. 
If your goal is to develop actual Windows software and use Windows libraries and APIs, then WSL is by far pointless. If you plan on distributing Windows binaries to run on other machines, such as server or client, again WSL is pointless as it produces and can only consume ELF binaries. The only rational for WSL is if you want to produce or use Linux software on Windows. By definition It's a different subsystem than Win32.
I'm experimenting at the moment with [Metamorphosis](https://github.com/maxigit/Metamorphosis) which do quite the opposite. Use TH to merge records. It allows for example, if you have data A = A { x :: Int, y :: Int } data Z = Z {z :: In t} to get data AZ {= AZ { x :: Int, y :: Int, z :: Int} and all converters `A'ZtoAZ :: A -&gt; Z -&gt; AZ` and `AZtoA'Z :: AZ -&gt; (A, Z)`. It's been so far, quite usefull. 
I commend Vacation Labs efforts to expand chances for people breaking into Haskell. I hope a few other companies consider following in their model to help grow the community. It would eventually expand the number of experienced candidates for all Haskell companies. Right now, it feels like we are bottlenecked at people willing to make the switch, who need experience. If that bottleneck is solved, we will be bottlenecked at available local, entry level opportunities (local seems important to not intimidate new Haskell developers with only competitive/senior level positions once they have a little experience and are ready for their next position).
I work with Fugue (&lt;http://fugue.co&gt;) which is based in Washington, DC, USA.
Categorical composition would run a RIO action in an environment obtained through a previous effectful action. We could also wrap the environment in some Comonad. Although that doesn't seem very useful.
So far I've only used the web version but I definitely eventually want some form editor integration eventually too. But more importantly, I want to query (for example via Haskell, or some graph query language) the generated crossreferences in ways like this: * Find all possible code paths over which function A can call function B.
I unfortunately can't help much with that question. I have never used Miso. `react-hs` is basically a Haskell implementation of React using Flux architecture, although the flux part will be decoupled in future so you can use any state handling architecture that you want. It depends directly on `react.js` so hopefully that gives you more of an idea of what it is like. `reflex` I haven't personally used beyond the examples, I just have seen a lot of hype around it.
Is that the Atlanta office? I guessed
Also, whether or not you decide to use reflex and reflex-dom in your application (which you should, they're awesome) -- reflex-platform is a really nice way to get a working ghcjs installation in a hurry. If you have any questions about it, join us on [freenode #reflex-frp](http://webchat.freenode.net/?channels=%23reflex-frp&amp;uio=d4)
I updated the post with that info. I know they also have an office in Budapest and NYC, but don't know if they do Haskell there, they seem to be a scala company beyond the DSL they did in Haskell (acquisition) for settlements(?)
I've added them to the post!
Assuming they're solely based in San Jose?
It was probably smart for Elm to break away from the FRP they were attempting, since they never really supported any of the higher-order switching combinators which are pretty much necessary once your application gets large enough (and which, due to Javascript's lack of weak references, would have been difficult to support given Elm's rather direct compilation strategy). Elm's FRP was also always quite strange -- rather than Event and Behavior, it had this sort of weird Signal type which behaved like an Event in some cases (including having a merge operation), and like a Behavior or Dynamic in others.
Sections will generate an entry in the synopsis while headings don't, I think. 
I use /u/hvr_ 's famous haskell ubuntu PPA's just fine when using WSL -- maybe is there any way we can ask HVR to release a ppa with this enabled so we can get it working out of the box? :)
Yes, it is.
Thank you for your comments and the paper pointer. It will be on tonight's reading list! Please also see my summary as an edit of the original post (shortly).
Hi moderators, Can you put a sidebar link pointing to the major Haskell JS Reddit discussion threads in the past year?
If you go the Purescript route, be sure to check out [Pux](http://purescript-pux.org/). Also, /r/purescript.
&gt; Colorful messages and caret diagnostics for more legible errors &gt; GHC HQ now builds FreeBSD and OpenBSD distributions for amd64 &gt; There is a technology-preview of an AArch64 Linux binary distribution &gt; GHC now tries to use the gold and lld linkers by default Nice! I hope FreeBSD/AArch64 will also come eventually…
There's a grammar for the source language here: http://disciple.ouroborus.net/specification/source/01-Concrete.html .. but currently no tutorial-style documentation. The grammar has links to descriptive test cases. Improving the docs is one of the things we're doing before the official release. DDC does bidirectional type inference and supports higher ranked types with implicit parameters. You can also supply explicit type applications. There is currently no let-generalisation, so you need to give type signatures for top-level polymorphic functions. For a Haskell / Agda / Idris programmer, Disciple it will do basically what you expect provided you add type signatures for top level functions. It's based on System-F rather than being dependent, so there is a Haskell-like distinction between types and terms.
You might be able to hack the output of [stack2nix][] to allow this. [stack2nix]: https://github.com/input-output-hk/stack2nix
I use Nix's documentation generation and then `haddocset` to convert it to a Zeal docset. It works pretty well.
I don't think that's correct. I, for one, have no real expertise on Linux or Windows - I `stack unpack duckling` and change their `build-depends: regex-pcre` to point at `regex-pcre-builtin`. I'm very excited to use WSL to develop with tensorflow and hmatrix and a host of other Haskell libs I have no idea how to approach on Windows proper. 
Clearwater Analytics in Boise ID USA uses Haskell to backend a lot of data analytics. Most of our developers write Java, but we have sizable developer teams writing in Clojure - our data analysts use python or Haskell scripts with Haskell (servant) based wrapper apis 
Using a concrete stack makes unit testing a little difficult no?
We use Haskell on the Data Science and Optimization team at Target, with a mix of people in the Bay Area and remote.
I have a library that does something close using generics: https://github.com/kcsongor/generic-lens
This sounds great. I've wondered for a while how linked lists could be optimised when contiguous memory was available. Thanks for posting these.
`stack install reflex-dom ghcjs` would be even nicer though.
 Isn't Backpack going to enable a general interface to string like things? We can use this interface for simple/common stuff that would work for String, Text, ... . Apple says that Swift strings are a "collection of graphemes." For newbies like me, a Backpack interface to something that is adequate, but can later be tuned for performance is perfect. I do not have to waste time agonizing over string representation (at a time when I don't have the slightest idea what I am doing!)
thanks, didnt know there is something like that!
you need something better :(
Whenever someone builds it :) 
My employer [Seller Labs](https://www.sellerlabs.com/) does Haskell as well :) We're located in Athens, GA but have employees all over the USA.
Don't know if this is related, but this reminds me of a talk given at C++Now 2017 mentioning work on "Dense Tree Representations": https://www.youtube.com/watch?v=lC5UWG5N8oY&amp;t=1h7m15s Just before that there was some discussion of "data baking" and GHC: https://www.youtube.com/watch?v=lC5UWG5N8oY&amp;t=1h3m 
+1 I started the course about a month or so ago ? Got stuck here and there but managed to get by until Week 7 where my brain just kinda farted and i stopped for a while. Would love to see this and the different trains of thought that people will have with the assignements. Also +1 for the Discord suggestion ! Edit : 31 may is when i started rip
By the way, this course changes quite quickly to include more topics. Later iterations of the course: * [2014](http://www.cis.upenn.edu/~cis194/spring15/fall14/) * [2015](http://www.cis.upenn.edu/~cis194/spring15/) * [2016](http://www.cis.upenn.edu/~cis194/fall16/) 
One complication is sharing. If multiple lists share a tail, we surely don't want to copy it many times! Nor do we really want performance to depend heavily on the order in which the collector collects objects. I don't know how (if at all) cdr-coding addresses these issues.
Zalora doesn't use Haskell anymore, unfortunately. Source: I work here.
I hear Arbor Networks do Haskell too. Source: [this tweet](https://twitter.com/newhoggy/status/850125796244987904)
Locked. 😊
[Bartosz Nitka](https://github.com/niteria).
 takeSymbol :: forall n a. (KnownNat n, KnownSymbol a) :- KnownSymbol (Take n a) You can explicitly use takeSymbol @2 "abc" to get a KnownSymbol dictionary for `Take 2 "abc"` that produces "ab" at the value level. You can use the other combinators in that module to prove equivalence of things, like if you know `Length a &lt;= n` then you can derive that `Take n a ~ a`, or prove `Take n a ++ Drop n a ~ a`, etc. The key is to manually use `takeSymbol`, etc. to produce the instances that won't reduce.
Would it though? The reflex-platform scripts use nix which is basically like stack with respect to the fact that it hashes everything which gets built and insists on build repeatability, but it's generalised to include arbitrary non-Haskell stuff as well. We use it for our deployments to AWS, and it's rather nice to have some assurance that all the libraries and code which are deployed are exactly what we tested, right down to the system dependencies. You can run the `work-on` script with the argument `ghc` or `ghcjs` followed by the path to a project with a .cabal file in it, and it will grab all the dependencies for that project using nix, along with the specified compiler, and drop you into a shell with the appropriate stuff available. The main downside is that writing .nix files to configure that environment further, once you get to that point, can be rather confusing, just because nix is untyped and so it's hard to figure out what stuff exists in its libraries and how to use it. But at least it's the sort of thing that once you get something working, it tends to keep working reliably.
Can you say why?
Why is ICFP during my first week of school :(
As someone who's used reflex in production, I wouldn't recommend it whatsoever. It's overly complicated, doesn't allow you to separate view from controller code, ~~compile times~~ (EDIT 7/27 I meant overall "getting shit done, in terms of fucking around and building with nix, not having a REPL, and generally slower compile times") are something like 100x slower than Haskell, and require a ridiculously complex toolchain to get working. Just go the purescript route unless you really really need to share types between the front and backends.
the 2013 course is specifically recommended. this has been discussed in a few places, see for example comments here: http://bitemyapp.com/posts/2014-12-31-functional-education.html "Huge gaps in coverage, no longer usable as an introduction to Haskell. Possibly because it’s supposed to be preceded by some other UPenn class? Not sure what happened."
I see - I'm working my way through the 2015 version and wasn't aware of the difference in quality, just that there were other versions.
Technically WSL is just a kernel mode driver (a "Pico provider") which translates linux syscalls into internal unexported NT functions. It's not a "microkernel" (in the common definition) nor is NT itself, although the layered design (and in particular the pico process refactoring effort) makes NT a lot more modular than Linux, and closer in spirit to a true microkernel.
I've gotten stack working as long as you alias make to gmake.
Yeah, that was my reaction too. Sounds like it could be an elegant blind alley.
It would be nicer for me. I don't think stack needs 16 gigs of ram to install the one package I desire (reflex) while the reflex-platform reportedly does according to their Github readme. I only have 8 gigs on this computer. Is it really surprising that people would prefer the standard way of distributing packages over the "here's a bash script to run" approach that reflex currently has?
Well, if you didn't also want a compiler that you probably don't already have, then that's fair. Saving a couple hours installing dependencies and building a compatible version of GHCJS is pretty good. Of course, if you just want reflex, you can also install it from hackage or from the github repo directly, and that ought to work.
My employer: [Tesla, Inc.](https://en.wikipedia.org/wiki/Tesla,_Inc.) Hiring for internships and full time (PM me).
This was before my time, so I don't have any insight into why exactly.
Why does it being a hack matter when it works? And what are the alternatives? **EDIT:** I just read the `superrecord` article someone else posted. It seems to solve a part of the problem. It would be nice, though, if I didn't have to specify *where* to find a value of type `Port`, such that it could just fetch a `Port` from anywhere in the structure. If one has multiple `Port` values in the same structure, one could just tag them with different types, so there is no ambiguity. This would be heaven for application programming!
I am in!
Good to know :)
Miso is focused moreso on simplicity (model-view-update pattern), purity, efficient DOM updates (written by hand in js), and easy-to-use features (websockets, sse, history APIs). Like Elm, miso doesn't use FRP, but unlike Elm it uses the GHCJS RTS. Miso's internals are pretty simple. It uses 2 `IORef`s (one for model, another for view), an `MVar (Seq action)` for events, a `Chan` that acts as a sink for new events, and a SkipChan. The SkipChan ensures the main thread of execution wakes on new events and only requests a new animation frame and performs a virtual DOM diff when the model has changed. Miso's templating language is just a newtype around `JSVal`, so the end user is as close to js as possible. Users embed pure Haskell functions onto the virtual dom while templating. The reason the DOM is slow is due to layout recalculation, this happens when DOM nodes are added / removed unnecessarily - causing a cascading effect of recalculations. The virtual DOM will perform the least amount of DOM operations in most cases. This really shines when operating on large lists (`&lt;li&gt;`'s) for example. Instead of destroying nodes needlessly, we can simply move them to their correct position (see `insertBefore`, `replaceChild` -- these are the "syscalls" of the DOM). This is what react.js is famous for, the "child reconciliation" algorithm. Bobril later improved on it. I don't think react.js nor Elm has this (Bobril does), but miso's virtual DOM holds mutable references to the real DOM. This has a number of interesting consequences. One being that it allows all events (which are listened for on body) to be routed through the virtual DOM, making it easy to find and invoke pure Haskell functions (which write to our event sink, cause model diffs, tree diffing and the cycle cycles). Another interesting consequence is isomorphic javascript (shown in https://haskell-miso.org). Since the view type and templating combinators are shared, we get some assurance that what the server sends to the browser will be what the client expects, this allows us to traverse our virtual dom and the real DOM together (since they will be identical rose trees), populating references from one into the other. Once all references are copied, we can begin routing events through the virtual dom, and our app is responsive. Lastly, this gives us a performance advantage when diffing since it obviates the patch phase. Instead of accumulating patches, we just apply the patch directly to the DOM, since we're already holding onto the reference. There are some caveats with isomorphic js, the browser's HTML parser cannot distinguish between sibling text nodes (treats them as one). So the end user needs to be careful to account for this, and a few others (can't nest `&lt;a&gt;` tags iirc). Eventually miso could mitigate these infelicities at the type-level using `PolyKinds` and typeclass induction if we embed `Proxy`'s into the html combinator language. Otherwise, Elm and Miso look very similar from the outset. Miso's todo-mvc and mario examples were copied almost verbatim from Elm, and most of the templating combinators are the exact same as you'd find in elm-html.
Wondering aloud. Why don't other immutable GC languages have this problem? eg. Clojure? 
I expect that linear types can really help with beta reduction, because they provide information about how many times will be an expression used.
They're a distributed team and I'm not aware of a presence in San Jose, but they may well have.
Hehe I would say halogen :P
They don't need to learn any of that, and that's just the point. In our case, they need to do this: 1. In Windows Explorer, navigate to the project folder. 2. In the Windows Explorer location bar, type `cmd` and hit enter. 3. In the command window that opens, run this command: `bash -c "yesod devel"` Even though they are Windows devs, I think they can handle that. EDIT: Come to think of it, we'll just put a batch file into the project folder, so all they'll have to do is double-click it.
(This is not as well-suited for Haskell in particular though, because anything non-strict would still need to be represented as a thunk, rather than unboxed.)
Yep exactly, as I wrote above. Devs working on products that we distribute to customers as Windows EXEs still need to use GHC for MSYS2. But our flagship product is a web app that runs on Linux. Windows devs who work only on that can now dump GHC for MSYS2, and that's great. To clarify a bit more: our main beneficiaries are non-Haskell programmers who do web programming on Windows. They need to run `yesod devel` so that their changes to Shakesperean templates pop up in the browser immediately as they work. Actually, we Haskell devs are also big beneficiaries. We'll spend less time giving support to the web devs. :)
&gt; Target Which Target is it? The retail chain?
Pux is at major version 9. Be prepared for a lot of pain if you want to keep up with upstream updates. I currently have a large-ish project which was started with Pux v7 and it's impossible to update it to v9 without major effort (ie. at least a week just to migrate to the new syntax / libraries).
Can say the same thing as a way to *encode* structural product types on top of structural type-classes. What do you feel is the downside? This encoding doesn't cost too much boilerplate...
This already works with [hvect](http://hackage.haskell.org/package/hvect-0.4.0.0/docs/Data-HVect.html) (see `findFirst`) for example. [This article](https://www.spock.li/2015/08/23/taking_authentication_to_the_next_level) shows how you can do that. (Disclaimer: both written by me, there are of course other solutions too) 
Some thoughts: - Your version of `tail` is allocating (when the argument is a `CONS2`), whereas the original `tail` is allocation-free. This may make uncons-heavy code slower. (you can already observe this problem today, e.g. if you parse a `Text` or `ByteString` using `uncons` it'll be much slower than parsing a `String` with `uncons`) - How do you propose to implement list-processing functions if `CONS2` won't appear in source code? If it does appear, then how do users know what constructors will become available (and what will their type be) ? - What if I have a binary tree? You can linearize it in several different ways (inorder, preorder, postorder), and users to be able to implement their functions that take advantage of unrolled representations need to know which one is used. - Imagine all the functions in `Data.List`. You have to compile each one of those to code that takes care of `CONS2` representation. Is this always possible? What about functions in, say, `Data.Map` from `containers`? Thanks for these posts btw, I'm really enjoying these kinds of discussions. 
`A'ZtoAZ` is already implemented in superrecord as [combine](http://hackage.haskell.org/package/superrecord-0.3.0.0/docs/SuperRecord.html#v:combine). `AZtoA'Z` could also be implemented, but I have not done it (yet?).
This is similar to how there are specific SLAB allocators in the linux kernel for particular data structures, and the pages holding these allocators are associated with life-cycle functions, similar to the info table. The win would be for a few data structures, not as a general mechanism. So the `#capabilities * #constructors` should be a reasonable number. With lots of different objects, the TLB pressure and cache misses starts to be too costly.
You can encode forwarding pointers very efficiently if needed. During GC, you can create a separate data area with 4k*(pointer-size)/(allocation-size) containing all forwarding pointers, and either consult this page, or use a bitmap to decide on whether a forwarding pointer has been allocated. Basically turn all the data structures into columnar storage.
For common data constructors, there won't be a cache miss penalty for the info tables. On the contrary, it should reduce cache pressure because there is less duplication - less data. Where we might see cache pressure increasing is the random access we get to the pages. However, this might not be an issue either as long as a copying GC is used. 
It was a while ago, but see https://gist.github.com/robinp/b3f6057d7123ca19866b4fb28fbb50d1 about loading the graph data into Cayley. Then you can fire up Cayley on the db, navigate to its webserver and use the Gizmo lang to write graph queries as a quickstart (see https://github.com/cayleygraph/cayley/blob/master/docs/GizmoAPI.md). Not sure if the output triples are directly digestible by Cayley or some massaging is yet required.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [cayleygraph/cayley/.../**GizmoAPI.md** (master → 6dd377f)](https://github.com/cayleygraph/cayley/blob/6dd377ffbb9531555a96495487946204ef6151b2/docs/GizmoAPI.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkorl3t.)^.
How would this interact with lazy lists?
What makes you think they don't?
Receiving a `Sing n` and having a `KnownNat n` constraint are functionally equivalent. To me, the singletons (and the singletons library) are sort of a "higher-level interface" to the mechanics in GHC.TypeLits. GHC.TypeLits does not aim to be a fully featured suite; instead, it offers very low-level primitives, and end-users are meant to use libraries that implement high-level interfaces over these low-level primitives. So while it's technically always possible to use GHC.TypeLits for everything, that's like saying that it's always possible to use pointer arithmetic and bit shifting for everything...why even use a high-level language? Or, perhaps as a less wild example, it'd be like using the clean API of `Data.Map` instead of a naked binary search tree with unsafe interfaces.
Tried to use gmake, but I am getting this message: &gt; 8.2.1' '/usr/local/share/doc/ghc-8.2.1/html/libraries' 'v p dyn' &gt; ld.so: ghc-cabal: can't load library 'libgmp.so.9.0' &gt; Killed &gt; gmake[1]: *** [ghc.mk:991: install_packages] Error 137 &gt; gmake: *** [Makefile:51: install] Error 2 --- &gt; uname -a &gt; OpenBSD xxx 6.1 GENERIC#19 amd64 
I see. Prectically, there's still no way to write a type family that turns `"1 2 3" :: Symbol` into `[1, 2, 3] :: [Nat]`, right? I can get the correct `KnownSymbol` instance for a piece of the `Symbol` but then I can't get that piece at the type level and branch on it.
Well, with the proposal as stated, let's see what would happen: When a CONS is replaced by a CONS2, what happens to the following CONS cells that are now abandoned? Well, if there is no further reference to them, they are GC'ed. But if there *is* a reference to one of them, it remains. Now suppose that remaining CONS cell is itself later examined as a candidate for CONS2-replacement. (That already implies some extra logic we'll need - we need to make sure that GC does CONS2-replacement in the right order so that it will fully resolve.) We'll then remove one more reference from the downstream CONS cells. But we'll also get some redundant pointers. To avoid the redundant pointers, GC would need to keep track of CONS cells that have been removed by CONS2-replacement. That way, when we remove the same CONS cell a second time we can re-use the same pointer array and just have `start` point further down into the array. However, that will require some more extra logic - GC will have to consider all CONS2 `start` pointers into each pointer array, and free the memory at the beginning of the array up to the smallest `start` pointer. I haven't thought about what happens for "tie-the-knot". That would also need to be considered. With further analysis this could probably be improved, but that's a first cut at it.
Thank you. Does `findFirst` work for nested `HVect` values?
Wire Swiss GmbH Backend Services: https://github.com/wireapp/wire-server
I think for challenge 2 there isn't really much work being done in this area (or at least I can't find it under the name of commutative monads)? One thing that might be considered in this area is the ApplicativeDo extension For challenge 1 there is a lot of work going into mtl and effect handlers/extensible effects.
5 seems to be well covered at the package level with Backpack, that comes with GHC 8.2.
\#1 seems like it's been addressed by mtl/free monad/extensible effects systems \#2 seems like it's been addressed by Applicative (not sure if Applicative was around in 2003). \#3 is still fairly open, though the recent work on [quantified class constraints](http://i.cs.hku.hk/~bruno/papers/hs2017.pdf) may be relevant. \#5 is perhaps addressed by Backpack?
&gt; \#2 seems like it's been addressed by Applicative (not sure if Applicative was around in 2003). ~~I think you swapped around 1 and 2, but yes~~ that is a good point edit: you didn't swap them, nevermind
Holy heading text! And unfortunately not. Exactly the same holds: "Commutative applicatives are very common. For these, applicatives over sequentialise."
The heading text has been fixed :) &gt; For these, applicatives over sequentialise. This is because we want `(&lt;*&gt;) = ap` to hold right? Applicatives in isolation don't have this problem?
I even use that app, yet completely forgot about them. Thanks!
Is that in Palo Alto?
Metamorphosis also manage functors (sequence and traverse) as well as mapping and zipping over fields. I tried a few extensible records libraries before writing Metamorphosis. The twoain reasons I did it was, zipping records needs complicated constraint s to work (when it work) and that I also have to work with existing types which I have no control over. With Metamorphosis I can transform a type generated by Persistent and transform it to its functor parameterized version (handy to validate forms and so on).
&gt; Facebook, UK? Yes, multiple teams in London.
I will try again OpenBSD 6.0. Following instructions from here: https://ghc.haskell.org/trac/ghc/wiki/Building/Preparation/OpenBSD
I'm not sure `String` is a good use-case for this. Granted, there is a big problem in the eco-system that `String` is inefficient, but the alternative to optimizing `String` is to use an API that is at a higher level of abstraction - namely chunks of data. What your proposal does is adding magic to the compiler and GC where chunking of data happens transparently because the eco-system is unable to change. The inefficiency of `String` can be solved by using `Text`, so I'd rather see how this can optimize lazy `Text` chunks or something that is already optimized. Basically, if `[Char]` escapes from the nursery, you need to optimize your program, not tweak the GC, so the 1/500th thing is somewhat of a red herring. Now, putting that aside, I like the proposal, but I think it would be more powerful to expose this functionality in Haskell, and have more basic building blocks in the GC. Would it be possible to have the GC enable execution of code that would transform from one constructor to another without hardcoding this? Maybe we could use thunks for this? Here are some constraint/ideas around this: - Assume it is possible for the compiler to generate code that converts from one constructor to another using no allocation, fixed allocation, or compile-time known bounded allocation. Maybe some `deriving` mechanism could ensure that this code is safe. - Each constructor will have some associated data `gcMunger :: Maybe (Int, (a-&gt;a))`. - During GC, if a given constructor has a `gcMunger`, it could allocate `fst gcMunger` extra space needed to run the `snd gcMunger` code, and write a thunk that would later run that code. Since space and the function pointer are known by the GC, no slow C-&gt;Haskell call is needed. - When the thunk is evaluated, it could set its nursery location to the free memory area given to it by the GC. It is guaranteed to not write more than this small space. - Then on the *second* GC, the more efficient rewritten representation would be used. The above doesn't directly support your `CONS2` setup, because the GC wants to do fixed allocation. However, it can be encoded in multiple GC-steps. We can have constructors such as `FooX{,Grow}` where the `X` is the (2^X) number of elements (or something like that), and `Grow` is associated with a `gcMunger` that will continue to coalesce into a bigger structure, while without `Grow` it's just copied by the GC.
Could these data structures export pattern synonyms instead of the actual constructors? 
You definitely don't want to copy a shared tail many times! So, it's true that exactly with what memory layout you end up with for a list which is partially shared would depend on the order in which garbage is initially collected. But this doesn't strike me as a huge problem. Unless each cell in a huge list has multiple references, you will end up with large stretches of CONSs being replaced by single CONS2s regardless. Also, given that data is immutable, wouldn't the beginning of every list be the oldest/first part to be GCd? And isn't that what we would want to pick to start the CONS2 chain? If so, that seems like something we can do without much extra housekeeping.
I'm not sure I agree that free/mtl/... are really a good way of addressing #1 as they force you to be in a monad when you don't conceptually have to. There was a talk at HIW I want to say last year, but I'm not sure, about a combination of effect systems and modal types which made some progress towards this, but I'm on mobile so I can't find the link at the moment. Anyway, point is that I don't think we should be happy with the "stick it in a monad" approach. Firstly because of issue #2 and because monads impose a certain style of programming which ostensibly isn't very functional. Secondly because monad transformers and free effects are, unfortunately, quite slow.
Thanks for carefully thinking this through and pointing out the complications! But isn't the main complication you point out inherent to GC-as-is and most of the technology to work already there? When a chain of CONS cells is evacuated during GC, the first would be marked with a forwarding pointer to the new CONS2. At the same time each of the subsequent CONS cells would similiarly be replaced by a forwarding pointer to the new CONS2 cell (each with an offset). Then, if there are live references to some of the later CONS cells, they will automatically be replaced by a new CONS2 cell in saved memory. If not, they just disappear after GC. This forwarding pointer replacement is something I believe the current GC already has to do anyway. The only additional complication is (a) storing an offset next to the forwarding pointer and (b) actually creating a new CONS2 cell in saved memory when necessary (rather than merely copying the data). These look to me to be non-trivial, but readily solvable problems.
Thanks for the pointer! I added the whole thing to my Watch Later list, but from the excerpt I watched, it sounds like a very similar idea. Surely it must be much easier in Haskell than C++!
I can't speak authoritatively for the innards of all functional GC language, but as far as I know they almost all do. The only exception were the old LISP machines which had hardware support for dealing with the grotty issues that CDR coding raises in the presence of mutability. Fortunately, Haskell doesn't have to deal with that!
They'd work as before. Unevaluated parts remain thunks. But once the thunks are evaluated and turn into a chain of CONSs in the nursery, they will become CONS2s on first subsequent GC. Everything in this proposal is premised on the idea that it can be done without changing any semantics; changing semantics would be a deal breaker.
&gt; as far as I know they almost all do That was actually the point I was trying to make :).
Thanks for your kind words and perceptive thoughts! 1. Yes, 'tail' would be allocating. Would that be a big problem? One would hope that most standard code that just works itself down a list, like maps and folds, would optimize away that allocation and just reuse the same data structure. 2. CONS2 never appears in the source code. Instead a CONS2 cell will pattern match to any regular CONS pattern. All current code continues to run completely oblivious of the behind-the-scenes changes. 3. My proposal doesn't allow you to fully unroll a binary tree (or any other multiply recursive data structure). Rather it can just unroll one branch. Which one is picked either by convention (first? last?) or perhaps a GHC pragma. For most structures in which branches are close to balanced, which one is picked should have no performance impact. 4. Sorry for having been unclear on this. Nothing in the principal proposal requires a single line of Haskell code to be rewritten. If that was needed, it would be a deal breaker for me, as well as everybody else. The only exception is the "optional second step" above. It is not necessary for the memory improvements, but if you did write versions of the main list processing functions in Data.List which were CONS2 aware, you could harvest some additional big performance wins.
I think this is related to /u/ElvishJerricco 's question. You define `LFunctor` as: class LFunctor f where fmap :: (a ⊸ b) ⊸ f a ⊸ f b I tried the same for `map` on list but that wouldn't work but this would: lmap :: (a ⊸ b) -&gt; [a] ⊸ [b] lmap _ [] = [] lmap f (x:xs) = f x : lmap f xs Note the unrestricted arrow after the function parameter. If I put the lollipop in place of the linear arrow I get a linear typing violation in the empty list case because the function isn't being used and another in the non-empty list case because the function is being used more than once. Does that mean that `[a]` is a `Functor` but not an `LFunctor` ? Do things like `LFunctor`, `LMonad` and `LApplicative` even exist in category theory? 
If we implement tail sharing with fresh CONS2 slices, we can use more space than before. For something like `tails xs`, we need N-1 new slices, each three words. Also, we would need to only allocate one CONS2 slice for an array suffix, else space cost of sharing can be arbitrary. That would not be hard though: after we first allocate a new CONS2 slice, we replace the forwarding pointer in the old CONS cell with a pointer to the new slice, and zero out the offset (or something like that) to signal that the slice already exists. Alternatively, we could avoid slice allocation by representing the underlying array as a null-terminated array followed by a pointer to the next list. Then CONS2 is representable as a tagged pointer to the array. `tail` would be still O(1), but going to the end of the slice would be O(N). A potential issue is that we need a terminating null pointer, which we don't have if the list contains unboxed elements. 
Could not make it either :(
Could you please share your steps?
&gt; Also, given that data is immutable, wouldn't the beginning of every list be the oldest/first part to be GCd? Not if we have thunks or [stack stubbing](https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/Stack). Thunk update obviously mixes up object traversal. For stack stubbing, suppose we are strict and have the following pseudo-STG block: let xs = enumFromTo 0 10 :: [Int] in let ys = tails xs in let zs = reverse ys in map sum zs Now, if we GC between "let zs" and "map sum ys", neither "xs" nor "ys" are usually GC roots because of stack stubbing, therefore GC traverses "zs", which is in the worst order with respect to compaction. 
What area of the company is Haskell used in?
Plow Technologies, Oklahoma City, OK http://www.plowtech.net https://github.com/plow-technologies
Are you referring to 'Automatically escaping Monads'? (http://conf.researchr.org/track/icfp-2016/hiw-2016-papers#program )
yes
Yes, my hero!
Yes, my hero!
Thanks. OK, so I qualified and quoted the term "microkernel". Is that better? For our purposes "microkernel" is still a good analogy, because as you say, that's the spirit of the abstraction that is being provided. Looking at the architecture block diagram in the [pico provider overview blog post](https://blogs.msdn.microsoft.com/wsl/2016/05/23/pico-process-overview/), it's actually hard to see much difference between this and a microkernel at a high level view. I know, the devil is in the details when it comes to kernels, and I have no doubt that this "pico process" architecture is vastly different from a microkernel architecture for someone actually working on the kernel.
I suggested [something similar](https://ghc.haskell.org/trac/summer-of-code/ticket/1669) and started working on it for ZuriHac 2015, but got distracted :-/
I gathered as much. ;)
Random assumptions, nothing much. Assuming that the man-years of JVM &amp; GC tuning would've come-up with a solution by now.
A possible alternative to `Data.Has` is to use the HasField typeclass that comes with GHC 8.2.1, [indexing by the (unique) type of a component](https://twitter.com/DiazCarrete/status/851541828872679424), instead of by field name. import GHC.Records data A = A B data B = B deriving Show instance HasField B A B where getField (A b) = b λ&gt; getField @B (A B)
I'm sure the content has many similarities between the 2013 version. Here's the link to the Discord channel if you'd like to join. https://discord.gg/B6p87wZ
Here's the link to the Discord channel! https://discord.gg/B6p87wZ
Feel free to join here: https://discord.gg/B6p87wZ
All those people recommending solutions based on GHCJS ... is it not still the case that GHCJS is still too slow (to the extent of barely working) for mobile devices?
How does this work in the presence of laziness? For example, suppose you have a list where the first 1000 elements have been computed and the remainder of the list is a thunk. What would that look like in CONS2 format?
Thanks for building FreeBSD distributions. I got ld.gold errors popped up when using the binary release (ghc-8.2.1-x86_64-portbld11-freebsd): Preprocessing library for time-1.7.. /usr/local/bin/ld.gold: error: cannot find -liconv /usr/local/bin/ld.gold: error: cannot find -lcharset /usr/local/bin/ld.gold: error: cannot find -lgmp collect2: error: ld returned 1 exit status Tried gcc49, gcc5. Also tried to change the related options in settings, no luck. GHC 8.0.2 worked without any problem. (installed following the instructions in [here](https://downloads.haskell.org/~ghc/8.0.2/README.freebsd.html)) Version: 11.0-RELEASE-p9. Please help! EDIT: I think there's also a USE_LARGE_ADDRESS_SPACE problem when building GHC on FreeBSD 11. How was the binary distribution built? Any workaround? Thanks for your input.
Not directly. You could write something that proves `KnownSymbol a :- Known (List Nat) (Parsed (List Nat) a)` using machinery like reflection / the stuff buried in `Data.Constraint.Symbol` and a suitable stuck 'Parsed' type family and lifted List kind. You can't do typecase. You _can_ do value level computation guided by the information in KnownFoo by using the singleton value we have and branching off of it. Types are erased at runtime so there is just nothing to branch on. You need something like an instance (e.g. KnownNat, KnownSymbol, etc.) to provide you enough information about the singleton value associated with your type to change behavior.
It also sounds somewhat similar to Clojure's vectors, which are 32-wide array-mapped tries.
Clojure usually does not use conses: while the `list` is a standard cons (though one which sacrifices space to store length), Clojure users are more likely to use `vector` which is a 32-wide array-mapped trie. `hash-map` is similarly a 32-wide HAMT. 
Hi, thanks for the questions! Yes, `[a]` would be a `Functor` but not an `LFunctor` with my definition. This particular example is one of those that annoy me greatly with my definitions, but I haven't been able to make it work further down the class hierarchy with loosened types. No, I don't think they have counterparts in CT (but I know very little of it, so someone please enlighten me). One has to realise that linearity leads to strictly less instances, in turn leading to more or less crippling of generality. This is kinda one of the bigger insights from my project, how linearity can screw with usability and intuition. *hint hint, upcoming blog post!* :)
Cheers my dude, this is great! :) 
No, I think you are misunderstanding the meaning of over-sequentialise in this specific context. What `&lt;*&gt; = ap` prevents is having a parallel applicative and a sequential monad for the same type. I think what Simon is referring to is types for which `f &lt;$&gt; fa &lt;*&gt; fb == flip f &lt;$&gt; fb &lt;*&gt; fa` (commutativity)
`ApplicativeDo` solves a different problem. I commented above with slightly more details
Digital Asset, NYC also... A certain prolific Haskeller joined recently, congrats to him! Ambiata has competition for the top of the phone book - rename to A1 networks (: ? 
They are pretty small, but SF startup [Alphasheets](http://www.alphasheets.com/) are building their backend in Haskell.
You'd want `flip f` in right side of the equation, but yes. 
It would be represented as one (or more likely, a few) CONS2's each with some stretch of memory between its 'start' and 'end' and the next pointing to the following CONS2, except for the final CONS2 for which the 'next' would point to the thunk.
Haskell implementations have to deal with mutation pretty extensively due to laziness. 
No, it does not atm.
Yes and no. On an physical level, running a Haskell program is indeed little more than replacing thunks with their values (i.e. mutation) plus garbage collection. But on a semantic level, these mutations are NOPs, replacing equivalent expressions with each other. That is never a problem and cannot even be detected by a standard Haskell program. The sole noticeable effect of such substitutions is to make execution faster. And nothing and nobody minds that. In other words, the mutations in Haskell are not of the type that make CDR coding a pain in impure languages (like Scheme's set-car! and set-cdr!). 
And that is fine. We have similar structures in Haskell (e.g., Data.Vector or Data.Map). Unfortunately these lack some of the convenience and, most importantly, the laziness of Lists. The proposals here are about ways of getting the best of both worlds without any changes to Haskell code. 
Applicative helps, but doesn't fully solve the issues exposed by commutative monads. For instance a good probabilistic programming monad can do something like Gibbs' sampling for all the Applicative fragments, but commutativity is even stronger. You can move all of the stuff that doesn't depend on other context out past other monadic operations, letting you group more stuff Applicatively and get even better asymptotics.
Do you guys have a website or github?
"If we implement tail sharing with fresh CONS2 slices, we can use more space than before. For something like `tails xs`, we need N-1 new slices, each three words." True though I hope in most cases, the optimizer would reduce that to only two CONS2 cells by fusion. However, for 'inits' which currently requires (N*(N-1))/2 new CONS cell, we could manage with only N-1 CONS2 cells (or even just 1 if consumption is fused with construction). 
&gt; Applicatives in isolation don't have this problem? Applicatives in isolation still have this problem because they sequentialise in much the same way that monads do.
Thanks for the example! But wouldn't just starting the unrolling at the oldest CONS cell being GCd not still be a good heuristic?
Skedge.me (appointment scheduling): http://skedge.me/careers/ 
Which `Star` is this? from what module or package?
&gt; What &lt;*&gt; = ap prevents is having a parallel applicative and a sequential monad for the same type. You can still do that, as long as the computations are isomorphic with respect to some specified measure.
The usual reason is "all smart people who could appreciate the benefits of Haskell got bored and left".
https://hackage.haskell.org/package/profunctors-5.2/docs/Data-Profunctor.html#t:Star
In one word, CPS.
IIRC the arrow laws do imply the strong profunctor laws and obviously the category laws. But the reverse is not true, [see here](https://www.reddit.com/r/haskell/comments/6otigf/comment/dkl9tse?st=J5JTMV3N&amp;sh=58c00238). So it looks like adding strong as a superclass constraint to arrow (and thus removing at least `first` and `second` from Arrow, unsure on `arr`) would make the most sense. 
Nice catch. I guess then yeah leaving `arr` in Arrow for now (and only moving out first and second) is a pretty reasonable thing to do. Until we have some sort of pre-arrow or similar. 
Interesting, to be sure. Some initial thoughts: I'm not sure we need to limit ourselves to (direct) recursion? Are there circumstances where the increased branching factor of more constructors will hurt us significantly more than the reduced memory pressure will help? If sharing would lead to duplication, maybe we can have one object point "inside" another? This smells like it might be related to compact regions, although there are certainly a lot of complexities. Performance might be extremely brittle if I'm relying on these optimizations.
oops, let me edit ;)
There also seems to be an Applicative version of the "magic box" that Rein talks about, as long as you have a Functor instance for f. type ApplicativeBox f a = Functor f =&gt; forall b. f (a -&gt; b) -&gt; f b fmap' :: (a -&gt; b) -&gt; ApplicativeBox f a -&gt; ApplicativeBox f b fmap' g h i = h (fmap (. g) i) app' :: ApplicativeBox f (a -&gt; b) -&gt; ApplicativeBox f a -&gt; ApplicativeBox f b app' g h i = (h . g) (fmap (.) i) I wonder, is this some sort of "Free Applicative"? It looks suspiciously similar to [the version in the Free package](https://hackage.haskell.org/package/free-4.12.4/docs/Control-Applicative-Free.html), but without the GADTs. 
I'm currently developing an app in Haskell and Elm, and whilst it's generally been great I've had to fiddle around a bit to translate my data structures and logic from Haskell to Elm (with two different programs, one of which is not up to date). So Miso is pretty appealing with a fairly obvious migration strategy and none of the awkward conversion-to-Elm, but I wonder, on a real application how does the resulting size of that compiled-to-JS compare? I ask because I get the impression that GHCJS produces large blobs, and my fairly modest app in Elm currently sits at 400k to download which already disturbs me.
If you check out https://haskell-miso.org, the javascript is closure-compiled (w/o advanced optimizations) and servant delivers it gzip'd (https://github.com/dmjio/miso/blob/master/examples/haskell-miso.org/default.nix#L12). The network tab shows it's ~280kb. You might be able to optimize it further. But the scripts are delivered w/ async and defer. So the browser won't stop drawing the DOM in order to download the scripts. So it looks like it loads instantly for the end user. There's a link to check out what that code looks like at the bottom of the page. GHCJS produces a few js files (lib.js, rts.js), etc. Ideally you only want to push updates to `lib.js`, and cache / serve the rest from a CDN (I use s3 / cloudfront) to your users, then have a cache busting strategy for `lib.js`. This is a further optimization. It might also be possible to transform the js using babel.js to allow for it to use `ADVANCED_OPTIMIZATIONS`, again a further optimization. Or I just need to rewrite miso's diff.js to use obj['bar'] syntax instead of obj.bar, etc.
That's three words
&gt; I'm not sure we need to limit ourselves to (direct) recursion? I thought about that. But I hit enough obstacles trying to think through how this would work even in the case of mutual recursion, that I gave up. For example, under the previous proposal only objects of the same type live in the same block (to save header space). That means that we cannot just bump a pointer to get an object of a different type. &gt; Are there circumstances where the increased branching factor of more constructors will hurt us significantly more than the reduced memory pressure will help? It is only one additional constructor per type, so I *think* not. &gt; If sharing would lead to duplication, maybe we can have one object point "inside" another? This smells like it might be related to compact regions, although there are certainly a lot of complexities. Absolutely. For example: let d0 = [1..500::Int] let d1 = take 100 d0 let d2 = drop 100 d0 let d3 = take 300 d2 Under the proposed implementation, if all of these were evaluated, you'd end up with just four CONS2 cells in memory. For example, if the relevant block was aligned at address 0 and had 32 bytes of headers, the values would be represented follows: d0 = CONS2 32 4032 NULL (where NULL is a pointer to a []). d1 = CONS2 32 832 NULL d2 = CONS2 832 4032 NULL d3 = CONS2 832 3232 NULL In other words, you'd have full sharing and ranges can live inside other ranges. &gt; Performance might be extremely brittle if I'm relying on these optimizations. That is quite possibly true. Sadly, so are some of the best optimization techniques in GHC, like fusion.
It seems to me that if you have an `aelement : a`, then you can obtain a `(a -&gt; b) -&gt; b` fairly easily, via (\f . (f aelement)), but there really isn't a natural way to go in the other direction.
Well, if you have a `(a -&gt; b) -&gt; b`, you can just pass it `id` and you get an `a`, no?
Good point!
Sure there is: if `f` is your `(a -&gt; b) -&gt; b`, just do `f id`.
I'm confused about what it's called a continuation. In some sources [1](https://bartoszmilewski.com/2015/09/01/the-yoneda-lemma/) [2](https://pdfs.semanticscholar.org/f3cd/7a83b08303d7ea3440430124cb36e239fd10.pdf), the type `forall b. (a -&gt; b) -&gt; b` is used to describe CPS functions. But in the SO answer luqui calls that type `Codensity` and uses the type `(a -&gt; b) -&gt; b` to describe a continuation [3](https://stackoverflow.com/a/45288920/474311). I would appreciate if someone could point me to some further reading to clarify my confusion :-)
Ok dumb question time. If `a` is a variable representing all types then how can it be equivalent to `(a -&gt; b) -&gt; b` which is more constrained? i.e. `a` could represent an `Int` but the second type is definitely a function.
Perhaps I'm missing something, but `id` isn't type `a -&gt; b`, right?
The `b` and the `a` don't have to be different types.
Thanks, that sounds very appealing, especially coupled with the reduced work I'd need to do to convert to Elm. As a follow-up then: Elm currently has no defined way to read/write to Local Storage/Web SQL, so I have to use Elm's Ports system and do my IO in JS (which is minimal but still incurs the awfulness of JS) - with Miso would I be left using GHCI FFI + JS to write or would your Effects address this? I had a look through the examples but didn't spot an answer to my question. Also, having looked through the examples, the code looks really nice!
Sure, but then you've only proven a special case, right?
Well, maybe it's a dare, effectively stating that b is uninhabited. EDIT: Do you believe Alice in this scenario? **Alice**: Hey everybody I have a cure for cancer **Bob**: Cool what is it **Alice**: Well... I'm not going to show it to you right away. But if you show me how to take a cure for cancer and turn it into a time machine, I will give you a time machine. Alice can state her offer confidently, knowing no one will take it up. Don't take that as evidence that she actually has a cure for cancer.
`W a = forall b . (a -&gt; b) -&gt; b` is the church encoding for the wrapper type. So, yes, `W a` is isomorphic to `a`. There is only one way to construct an element of this type (this is a result of a free theorem for this type) ins : forall a . a -&gt; W a ins x = \ z -&gt; z x And one way to extract an element (this is a result of the free theorem for `forall a . a -&gt; a`) ex : forall a . W a -&gt; a ex w = w (\ x -&gt; x) We can immediately see that; ex (ins x) = (\ z -&gt; z x) (\ x -&gt; x) = (\ x -&gt; x) x = x The other way gets us stuck. ins (ex w) = \ z -&gt; z (w (\ x -&gt; x)) Consider that, the only way to have a `w` in the first place is to construct it using an `ins a`. So we just need to prove that `forall a . ins (ex (ins a)) = ins a`, which immediately follows from the previous calculation. So, the two types are isomorphic.
Miso currently does support local and session storage. FFI bindings have been written for those things (and they can be used with the `(&lt;#)` / `(#&gt;)` combinators). Fair warning it does assume `To`/`FromJSON` constraints for simplicity and convenience. An older version of miso todo-mvc actually saved todos into local storage. http://miso-todomvc.bitballoon.com/ (refresh and they will persist). Inspect the storage the tab. Using the GHCJS FFI is actually pretty nice. If you click the "Interoperability" link on https://haskell-miso.org you'll find a link to a `README` that goes into detail on how to use it. But, if you make an issue on miso I'll look into `WebSQL` bindings, and which SQL DSL to use (want to keep deps. minimal). Basically, it's a lot nicer than ports IMO. https://haddocks.haskell-miso.org/Miso-Effect-Storage.html Also, forgot, but somewhat related, if you compile your app with `-dedupe` w/ `GHCJS8`, there are further js size reductions to be had.
That's actually the Cayley representation of applicatives. You'll find you need an Applicative instance on `f` (or equivalent functions of course) to lift or lower it from/to `f`. This is in the `kan-extensions` package as `Curried f f a` in `Data.Functor.Day.Curried`. You can read some more specialized content on Cayley representations of stuff like this in one of my favorite papers, [Notions of Computations as Monoids](https://arxiv.org/abs/1406.4823). Cayley representations are actually a great way to improve performance of many things. The Cayley representation automatically right associates the operator. This is especially important for free monads and applicatives as they're often linear time when left associated, but constant time when right associated. The `lens` library uses this trick to make dramatically faster traversals in [the `confusing` function](https://hackage.haskell.org/package/lens-4.15.3/docs/Control-Lens-Traversal.html#v:confusing).
No, the generality is a premise. We're not trying to prove that a general function exists, we're given a general function and we need to prove that it can produce an `a`.
The example is a bit misleading because the type should really be `forall b. (a -&gt; b) -&gt; b`. The `forall` means you don't need to be able to make a time machine, you can provide a function that makes whatever you like (any b), and you'll get an answer.
It's only isomorphic. It's not the same thing.
If b is universally quantified you can just pass in id. I am not entirely sure why `unbox . box` doesn't typecheck, though. Is it because of the higher ranked type of unbox?
Sorry, I thought b was a concrete type. I am suspicious of the parametric case but am not sure enough about it to argue either way.
I see where I was confused; thanks!
[Hornetsecurity](https://hornetsecurity.com) in Hanover/Berlin ([job on SO](https://stackoverflow.com/jobs/135772/)).
To expand on this, two types are isomorphic if they have functions that translate between each type without ever losing information. For example, `() -&gt; a` is isomorphic to `a` since we have the functions; \ a -&gt; (\_ -&gt; a) :: a -&gt; (() -&gt; a) \ f -&gt; f () :: (() -&gt; a) -&gt; a Which obviously cancel each other out, both ways. 
Another thing to note is that most of the time you have something of type `(a -&gt; b) -&gt; b` you are going to have something of type `forall b. (a -&gt; b) -&gt; b`. For example the original comment produces something of type `forall b. (a -&gt; b) -&gt; b` for any given `a` you create it from. And of course if you have `f :: forall b. (a -&gt; b) -&gt; b` then `f id` always works.
I don't really care whether ghcjs is on hackage or not. After all, ghc has never traditionally been on hackage. You cannot run `cabal install ghc` to install the newest ghc, so I don't know why anyone would expect that this would be possible with ghcjs. However, I definitely sympathize with concerns about the ghcjs ecosystem only being usable with nix. For example, `reflex-dom` has major improvements available to nix users that are unreleased to hackage. This is because it uses `reflex-platform` to provide a lot of patches to packages in a way that lets it subvert hackage. I don't mean this antagonistically. Going through the normal process of PRing and trying to get changes into a repo is tedious, so it's just easier to provide a fork. For example, `reflex-platform` provides a [non-standard version of `text`](https://github.com/reflex-frp/reflex-platform/blob/167dcf00df6c4fd28e9863af8ac465a563165832/default.nix#L613), optimized for GHCJS. But, [a quick search](https://github.com/bos/text/issues?utf8=%E2%9C%93&amp;q=ghcjs) reveals that it doesn't look like anyone has tried to get these changes upstream. This could be for any number of reasons. Maybe the internal api of GHCJS is still too much in flux, and merging in these changes upstream would burden the `text` maintainers. Or maybe people are just busy with other stuff. For what it's worth, shimming out functions is something [ghcjs itself does](https://github.com/ghcjs/shims) as well. There does not seem to be much initiative to get these changes into the actual libraries.
Why would you be suspicious of the parametric case? For any given `a`: f :: forall b. (a -&gt; b) -&gt; b f id :: a So you can trivially get the `a` back.
&gt; [Yes, it is.](https://www.reddit.com/r/haskell/comments/6p2x0p/list_of_companies_that_use_haskell/dko20ha/) I'm guessing that was in response to your question.
I would say it's easier to do a small project in Haskell than it used to be. Stack provides repeatable builds and easy access to libraries. It works in conjunction with stackage, which is a sort of distribution of Haskell's libraries. It's at least as reliable as any comparable system, possibly better. There are quite a few viable web libraries on stackage, such as scotty, yesod, snap, happstack, MFlow and servant. Intero works pretty well as an IDE back end - I use it with Visual Studio Code but it's designed to use with emacs. I also use ghc-mod with Atom, which also works well.
Thanks for your thorough responses. GHCIJS FFI is a lot nicer than I'd expected - which makes me a lot more enthusiastic, and your effects for Local Storage look straightforward. I've opened an issue for Web SQL support on Miso, and will take an opportunity when possible to test out migrating my Elm app over. Really nice stuff!
I understand that GHCJS is more than just another library, so it makes sense that it isn't on Hackage. Is there any chance that GHCJS might be included with GHC as one of the backends? (I think GHC only has 2 backends right now? Native and LLVM?) What about web assembly? One of our Haskell Summer of Code projects was working towards a web assembly backend for GHC. Would this backend be included with GHC? As for reflex and reflex-platform, I agree. The current reflex-platform is not ideal for me. I would like to try using reflex (not reflex-dom) in a non-web environment, but the reflex package on Hackage appears to be out of date.
It would be great for the prelude to have a string type like `Text`, one that isn't `[Char]`. `ByteString` is for bytes, like Java's `byte[]`, so it's not the same as `Text`. But it is much the same as `Vector Word8` :-( I'd also like a streaming type rather than lazy variants of the above. Though I'll admit there are scenarios where lazy is very efficient.
Following discussion with /u/dmjio I tried out https://haskell-miso.org/ which is apparently GHCJS-based and that seems nippy, at least on an iPhone7 and my old Android Nexus 5. That said the website isn't exactly strenuous. It would be nice to understand the performance profile of GHCJS on mobile devices. I found [this](https://www.reddit.com/r/haskell/comments/4k1z7w/depending_on_ghcjs_risky/) and [this](https://www.reddit.com/r/haskell/comments/31ui2h/whats_the_current_status_of_ghcjs_vs_haste/) which are interesting from a low-bandwidth, resource constrained perspective. I found an old post [on hackernews](https://news.ycombinator.com/item?id=10597257) which seems to confirm your worries, but I can't loads the [linked Reflex-based app](https://obsidian.systems/reflex-nyhug/) on my iPhone as it doesn't recognise the version of Chrome.
One of the enhancements is this: &gt; stack ghci will now skip building all local targets, even if they have downstream deps, as long as it's registered in the DB. I thought this would mean that `stack ghci` would no longer have to re-load my source if I had just performed a ` stack install`, but apparently not. How come I have to do `stack exec ghci` and then manually add my package if I want to avoid going through ghci's interpreter (which takes up too much memory to load my code anyway)?
Thanks for this release! Being able to just do `stack exec &lt;TAB&gt;` to get a list of executables is really convenient.
Of course. I did hear about that certain prolific Haskeller joining.
Depends what type variables are "foralls". For some reason, people think you should interpret this as an implicit "forall b", in which case yes. If it were "forall a", you actually can produce a b by specializing to a = (). Since it doesn't matter what a is, const (some element of b) is the only real choice. Naturally, there is no way to inhabit forall a, b, so people typically make one assumption or the other.
So Cayley representations date back to 1854. And there was I thinking I'd invented something new. :-) The paper looks great, thanks. I'll try to tackle it alongside the next section of Bartosz' course. I agree on the practicality of this stuff. I actually needed the Codensity monad for some probabilistic code I was writing recently, which has encouraged me to try and develop a better understanding of the theory.
In Paris, users include BNP (https://group.bnpparibas/en/), Fretlink (https://www.fretlink.com/) and Vente Privée (https://secure.uk.vente-privee.com/authentication/portal/EN) as declared at meetups.
If I learned anything, this is a comonad? With extract ~ bind, and insert ~ return ? 
Good point.
I don't know why it isn't on Hackage. It would certainly benefit the eco-system to be able to target the *most widely used platform* (more so than x86) without resorting to hacks.
The plan for the WebAssembly GHC project is to make it a properly supported variant of the LLVM backend, once the project has reached a certain level of stability. So it is intended to be upstreamed into GHC GHCJS takes a rather different approach to a great many aspects of GHC, so it doesn't make for a good inclusion into GHC proper.
&gt; For example, reflex-platform provides a non-standard version of text, optimized for GHCJS. But, a quick search reveals that it doesn't look like anyone has tried to get these changes upstream I think that's because it really doesn't *belong* upstream. It fundamentally changes how `text` works for a nonstandard compiler.
It is both a monad and a comonad. I'm not sure what you mean by a comonadic bind, but the comonad analog of return is usually called extract (which is `ex` in my example) and the comonad analog of bind is called extend. `ins` corresponds to the monadic return. The binding and extension operations weren't mentioned, but aren't that complicated. bind : W a -&gt; (a -&gt; W b) -&gt; W b bind w f = f (ex w) extend : (W a -&gt; b) -&gt; W a -&gt; W b extend f w = ins (f w) 
Note: I think I've posted this already but I can't find it (?) in any case today's version is the simplest so far.
Yeah I was talking about the analogs of extract and extend, I had them wrong. Thanks.
So... I simply didn't know/understand enough about how Haskell/Stack/Tidal work and how those parts fit together to understand _any_ of the (frankly, excellent) explanations offered by you and others. As usual, I went about this the hard way and with a little sleuthing was able to piece together (more or less) the same story. Now that I've done so, I see the wisdom in these replies. Thank you! As an aside, I had worked out a slightly different method, which was to `stack install` for Tidal, complete the rest of the install/setup, and then run Atom through `stack exec atom`, which also seemed to work. Now that I see your solution, I think I'll modify the settings for the tidalcycles Atom plugin as you suggested, since then I can open Atom normally through Spotlight and be ready to go. It's useful to understand why Tidal does not need a Stack project. But should I want to use it _within_ a Stack project of my own, I wonder how this process would need to be modified. Finally, I wonder what it would take to have Stackage updated to the latest Tidal release?
Thank you. Now that I have a little background understanding that was missing, this was hugely helpful.
Thank you! I think I understand this now. I feel like the structure of some of these is odd. If there's already a .stack/ I don't see the need for .local/. A little cluttered, methinks.
Nice, this is also very useful and I'm sure I'll make use of it as I finally start noise-hacking soon. Thank you!
Not to mention all the folders that are created everywhere.
Yeah, there's no executable, so I've been told that it would just be added as a library dependency instead of installed.
The distinguishing feature of a microkernel is that it runs in kernel mode (or some elevated processor mode. Most processors have more than one of these.) and the rest runs in an unprivileged user mode. So the layers have to be separated by actual hardware protection rather than just being a better way of organizing source code. This is actually what the Drawbridge project (the project that spawned the WSL project) did to NT --- they implemented the NT native API in user mode and ran it on top of a real microkernel. Too bad it is too radical to be commercially adopted in its full glory. Interestingly if you look into the original NT kernel architecture the middle layer (between the upper layer called Executive and the lower layer called HAL) is actually called "Microkernel" which is a reflection of an attempt to design NT into a true microkernel, but they didn't actually do that due to performance reason --- the conventional wisdom being that microkernels are slow. NT 4.0 actually went even further back on this and stuffed the entire GDI, with its over one thousand API calls, into kernel mode, making the NT kernel much bigger than, say, Linux, which is unapologetically macrokernel. As is what usually happens at Microsoft, they often take some great ideas and make sure they never ever implement them right.
I've got a few things written that use reflex - for the most part I've been using reflex-platform for that as well. All I usually need to do is run `work-on ghc ./.` in my project directory and I'm good to go. As I've learned more Nix I've done fancier things, but I got a long way by cloning the repo and running that command. Also - I've got a collection of examples of using the non-web facilities [here](https://github.com/dalaing/reflex-host-examples). Probably easier to understand for folks who are comfortable with reflex already, but it might be helpful later on. There are some new features from reflex I've been meaning to add to it, hopefully I'll get to that soon. 
Fantastic :)
backpack is complete? afaik the full thing will take a year or two. 
Can you elaborate on "nippy" here ? I'm using an iPhone 5 and it loads pretty quickly (safari ios), and going from the 404 page to home page is seamless.
Thinking about this some more, I have come to the conclusion that your definition: class LFunctor f where fmap :: (a ⊸ b) ⊸ f a ⊸ f b that specifies that the function argument only be used once is overly restrictive. At least in this example I think there is nothing to be gained from specifying that the function is only used once. The may be other examples (crypto maybe) where a single use function may make sense. I think: class LFunctor f where fmap :: (a ⊸ b) -&gt; f a ⊸ f b makes more sense, because then an `LFunctor [a]` instance does exist and behaves has one would expect. 
Nippy == quick. :)
Have you tried `react-hs` / `react-flux` or any other GHCJS based libraries? I like Haskell more than PureScript, so I wouldn't personally go with PureScript. Also its nice having one language for front and backend, and as you mentioned type sharing is nice.
There is another common case, if you instead have a function `(a -&gt; IO b) -&gt; IO b`, which you see in ie `withSession` (from wreq) or `withFile filepath mode`, or generally `bracket initializer finisher`. There the closure is not at all equivalent to a single value of type a - it just must provide one in `IO`
Stupid noob question : is this question implying that, by using the Curry-Howard correspondence, ((A=&gt;B)=&gt;B)&lt;=&gt;A ? I believe this is false, so what am I missing ? EDIT : formatting 
I do imagine that `tail` ought to be "free" for linked lists. The idiomatic `f [] = something; f (x:xs) = h (g x) (f xs)` requires developer effort (for likely good reason) to translate to vector code, as you now have a completely different cost model. It would be a shame to lose this idiom. 
Consider the two types from the SO answer: newtype Cont b a = Cont ((a -&gt; b) -&gt; b) newtype Cod a = Cod (forall b. (a -&gt; b) -&gt; b) The type function `Cont` takes two type parameters to produce a concrete type. `Cont Int Char` is a distinct type from `Cont Int Bool`. A value in one of these concrete types already knows what final result type it will have - the `Cont Char Int` type, for example, could have this value: foo :: Cont Char Int foo f = toUpper (f 5) The `5` here is the `a` that the continuation already has computed. The `f` is a function `Int -&gt; Char` that might produce any character, but we know it _is_ a character, so we can apply `toUpper` to the result. The type function `Cod` takes one type parameter to produce a concrete type. `Cod Int` is the type `forall b. (Int -&gt; b) -&gt; b`. We cannot know what concrete type `b` is, so the `toUpper` trick from the `Cont` example doesn't apply. So that's the _type_ difference: a `Cont` is parameterised by two types, a `Cod` by one; a `Cod` value cannot alter the result of the function it takes. The `Cont` type encodes an in-progress computation. It has computed an intermediate value `a`, and needs a function provided to continue the process to completion. The `Cod` type encodes a codensity transformation of the identity monad. The full [Codensity](https://hackage.haskell.org/package/kan-extensions-5.0.2/docs/Control-Monad-Codensity.html) type is: newtype Codensity m a = Codensity (forall b. (a -&gt; m b) -&gt; m b) In Kmett-style, this is described as "the right Kan extension of any Functor f along itself (Ran f f)". Your reading, then, is Kan extensions: the rabbit hole will take you down through limits and colimits to natural transformations. Alternatively, the Haddock also refers to a paper which you can get via [ocharles' list](https://github.com/ocharles/papers) or the usual scholarly sources. This paper gives us the reason for the Codensity transformation, without giving it the name: a free monad over some functor may be quadratic in construction, the codensity variation may be linear instead.
Yes! I've been looking for this for a while. Thought I'd have to write some shell scripts for it
 &gt; box a f = f a &gt; unbox f = f id &gt; :t (unbox . box) (unbox . box) :: c -&gt; c Works fine for me?
The problem is the last `Nothing`: it is of type `Maybe b`, and `terminalSpawnSync` accepts anything of type `Maybe a`, as long as `a` has a `IsCancellable` instance. (See the actual type at [the vte docs](https://hackage.haskell.org/package/gi-vte/docs/GI-Vte-Objects-Terminal.html#g:86).) As far as the type checker is concerned, it cannot know whether `b` has the required instance. This is a common annoyance, but luckily it is easy to solve: just pass in `Nothing :: Maybe Gio.Cancellable`. For convenience, the bindings already provide such synonyms, you can use `Gio.noCancellable`: Vte.terminalSpawnSync terminal [Vte.PtyFlagsDefault] (Just "/") ["/bin/zsh", ""] Nothing [Glib.SpawnFlagsDefault] Nothing Gio.noCancellable &gt; Btw, looking at the VTE docs I see that vte_terminal_spawn_sync should be used now, but current VTE bindings are missing that function. How can that be, I was under the impression that bindings are automatically generated from C source files? This should indeed be the case, bindings are autogenerated. `vte_terminal_spawn_async` was introduced very recently, in version 0.48. Do you have this version installed? If yes, it may well be that code generation fails for this function for some reason. In that case, could you please file an issue at https://github.com/haskell-gi/haskell-gi/issues? Thanks!
Interesting observation! I'm far from an expert but will have a go at this. `RHS =&gt; LHS` seems obviously true. `LHS =&gt; RHS` isn't so obvious at first. I think we need to add in that pesky implied `forall b` again. Then, because it holds for all values of `B`, you can just substitute `A` for `B`, giving: ((A =&gt; A) =&gt; A) =&gt; A `(A =&gt; A)` is true, so the left hand side reduces to just `A`.
This is delightful! As someone who has struggled to understand category theory, more expositions are always welcome. People may be interested in my collection of notes at http://www.cs.jhu.edu/~nwf/ctcheat/, notably including http://www.cs.jhu.edu/~nwf/ctcheat/ctcheat.pdf which tries to be a glossary of terms that can be quickly consulted while reading other documents. :)
What's that caveat about non-stratified terms supposed to mean? It's not really explained clearly, and no work-around is given.
Special thanks for the windows specific tweaks this release - super happy to know my ghetto dev environment still gets love and attention just like those cool kid linux OSes do.
`./configure LD=ld.lld`
Have you installed the `iconv`, `charset`, and `gmp` libraries? Indeed GHC needs to be configured with `--disable-large-address-space` on FreeBSD.
Having hardware for this configuration would greatly improve the chances that this will happen. I currently have only one AArch64 board and it runs Linux.
The blog doesn't have RSS feed or comments section, so I shamelessly post it here. UPDATE: I was asked to add a feed, so here it is: https://yi-editor.github.io/atom.xml
I suppose it's waiting for the right contributor to make it happen. Or ask Luite et al how to help 
Basically transcribing it how Damiano Mazza explained me, consider the following language: t, u ::= a | \a.t | tu | x | !t | let !x=u in t Where - `a` and `x` range over two disjoint sets of `affine` and `exponential` variables, respectively; - `\a.t` is lambda-abstraction, binding `a` in `t`; - in `let !x=u in t`, the variable `x` is bound in `t`; - each affine variable occurs at most once in a term (exponential variables may occur arbitrarily many times); - in `!t`, no free linear variable is allowed (only exponential). The terms of the form `!t` are called `boxes`. With the following reduction rules: (\a.t)u --&gt; t{u/a} let !x=!u in t --&gt; t{u/x} (let !x=u in t)v --&gt; let !x=u in (tv) (plus similar commutations of let) Then, consider the following translation of λ-calculus terms to the language above: [x] := x [\x.M] := \a.let !x=a in [t] [MN] := [M]![N]. Moreover, lets define the depth `d(x,t)` of a free exponential variable `x` in `t` to be the number of nested boxes within which `x` appears. E.g.: `d(x,yx) = 0`, `d(x,y!x) = 1`, `d(x,!(y!x)) = 2`. A term `t` of the above language is stratified if: - for every free exponential variable `x` of `t`, `d(x,t) = 1`; - for every subterm of `t` of the form `let !x=v in u, d(x,u) = 1`. Moreover, &gt; Note that stratification only makes sense in the calculus for linear/affine logic defined above (or similar calculi). It does /not/ make sense in the usual lambda-calculus, i.e., strictly speaking, it is meaningless to say that a lambda-term is "stratified". So, even if a (usual) lambda-term is typable in IEAL in the sense of Coppola et al., it does /not/ mean in general that you may execute it without the oracle! What you may do is take its IEAL typing derivation, which is an IEAL proof, extract the term of the above calculus associated to such a proof, and execute its sharing graph. *That* will not need the oracle. In other words, the proposed compilation from λ-terms to the language above is very naive and always ends up with non-stratified terms. But by readjusting the `!`s carefully, there is a wide range of λ-terms that can be expressed as stratified terms of that language. If there exists such an arrangement, then that term can be reduced optimally. In practice, once you get used to it, it is quite easy to avoid the kinds of terms that wouldn't work on this algorithm. I've ported Haskell's Data.List, trees, hash functions, algebra, quaternions, small games and so on, not even thinking about boxes and things like that. Most things work fine, and when they don't it is easy to adjust. I suspect with some patience one could design a friendly type system that catches those at compile time.
Yes, I've already installed these libraries. I came across the situation while building cabal-install tool using the included bootstrap.sh. Running GHCi showed no signs of problem. Maybe I should choose a different ld(1) when running configure?
This doesn't really sound like an `ld` problem. Let me try to reproduce this.
I have a 10.3-STABLE box around. To make sure, I will try the binary package built for 10.3, too.
Ok, I just tried it in Coq, it works! I didn't put my foralls where they should be. The correct thing is : forall A : Type, (forall B : Type, (A -&gt; B) -&gt; B) &lt;-&gt; A. EDIT : equivalence instead of implication
&gt;If you have unfoldr-like functions that use a sum type as an intermediate value you can use unboxed sums to get allocation free loops I wonder if this would make "extreme" CPS like in most parsing libraries i.e. `{mega,atto}parsec` and `trifecta` redundant. Those depend on inlining and worker-wrapper optimisation (which GHC happens to be really really good at) but can be pretty bad if a parser doesn't/can't be inlined.
Ah yes, it's quite nippy for me too :) 
Can you open a [Trac ticket](https://ghc.haskell.org/trac/ghc/newticket)? I'm happy to help but I don't think that Reddit is a terribly great medium for this sort of thing.
Thanks for the help! Just narrowed down a little bit, it turns out that cabal-install's bootstrap.sh has a bug in finding the correct linker. I will try to fix it, if the problem's still on GHC's side I will open a ticket. Thanks again!
It has an RSS feed now! https://github.com/yi-editor/yi-editor.github.com/issues/18
Also, for people who want to learn more about this, this is a special case of the Yoneda Lemma: https://en.wikipedia.org/wiki/Yoneda_lemma The Haskell analog of the Yoneda lemma says that: forall b . Functor f =&gt; (a -&gt; b) -&gt; f b ... is isomorphic to: Functor f =&gt; f a ... and the original question is just a special case of this where `f = Identity`
Thanks everybody for reply!!! :D
Capital IQ, Soostone, Obsidian Systems, The UNIX Man Consulting
No mention of ghc 8.2.1. JustWorks(tm)?
Drop [this stack.yaml](http://lpaste.net/7029495298879651840) file into your project folder, then type stack setup. Wait for a while until it all compiles, and you have yourself a ghcjs development environment with reflex and reflex-dom libraries. 
I am all up for this! Are you looking for some volunteer or are you going to implement it by yourself? 
I used Haste to implement a fairly complicated front-end web application, with lots of custom canvas UI features (including editing 2D architectural maps with zoom etc.). The resulting code was fast enough to be used in production. Closed source code unfortunately so can't show.
Indeed, this is also how I argue. However, it does not mesh very well with the `LMonad`.
So, my humble opinion on these things is that if you need to rely on the performance of a particular structure, use that structure directly. This is essentially turning all `[a]` into `Vector a`, and in the process changing the complexity of both the operations on lists, and increasing the complexity of GHC greatly. The best way to avoid the overhead of lists is to never have that overhead at all via fusion where possible. If you need to worry about space, use unboxed vectors, trying to add these optimisations which inherently change the semantics of what you're doing just make programming harder.
"My program gets slower when I use more than 4 types in it" doesn't sound like something I'd be interested in :P
Soostone and Obsidian make great open source contributions,too ^^
If you ask ghc for the type of your unbox you get the wrong thing: &gt; :t unbox unbox :: ((a -&gt; a) -&gt; t) -&gt; t instead of &gt; :t unbox unbox :: (forall b. (a -&gt; b) -&gt; b) -&gt; a
Implicit universal quantification considered harmful :D ^(looking at you ghc &amp; Idris!)
So, one thing that irked me a little when reading this was the use of `(&amp; _1 %~ (+1))`, just `(_1 %~ (+1))` is sufficient =)
Given that we have support for GHCJS in cabal and stack, I don’t see why it shouldn’t also get included in popular packages.
&gt; There is only one way to construct an element of this type (this is a result of a free theorem for this type) note that while this claim is true in a sufficiently idealized language, it is not true in Haskell. As, w1 = \f -&gt; f undefined w2 = \f -&gt; undefined w3 = undefined are observationally distinct. w1 (const 5) = 5 w2 (const 5) = undefined w3 (const 5) = undefined w2 `seq` 5 = 5 w3 `seq` 5 = undefined the difference between `w3` and `w2` is perhaps merely a language wort, but the difference between `w1` and `w2` is fundamental. Of course, [fast and loose reasoning is morally correct](http://www.cse.chalmers.se/~nad/publications/danielsson-et-al-popl2006.html), and all that 
~~Oh? How so? Or do I have to wait and read your upcoming blog post? :)~~ Oh, now I see. Very interesting.
IIRC, it's as simple as `data Foo = Foo {-#UNPACK#-}!(Maybe Int) {-#UNPACK#-}!(Maybe Double)`
After you install `nix`, to get into a shell with `ghcjs` and [`miso`](https://haskell-miso.org), run: ➜ nix-shell -p 'haskell.packages.ghcjs.ghcWithPackages (p: with p; [ miso ])'
The problem with doing this is that IIRC, you are only guaranteed to be able to read it back by exactly the same executable, so I would be very wary of using compact regions as a serialisation format - you basically can never update your app unless you have a way to tell the running app to dump all its data in a more portable format. For serialisation, the very soon to be released `cborg` and `serialise` packages are looking really interesting, should be much faster and more space efficient than `binary` while using a standardised encoding format. It's definitely a good option for the "I have a lot of static content in my app and GC time sucks" problem though. The more interesting use IMO is for networked services where you can just send a compact region over the network to the same app on another machine and avoid any deserialisation overhead (though, for the paranoid, I'd totally be signing the data including the TypeRep of the serialised data).
To alleviate the ambiguity in the original question, sometimes I write: (X -&gt; b) -&gt; b as being isomorphic to X.
I wonder if this would be feasible to implement in Gabriel Gonzalez' morte, annah and dhall family of CoC languages?
Your unbox is unbox :: ((a -&gt; a) -&gt; b) -&gt; b but it should be unbox (forall b. (a -&gt; b) -&gt; b) -&gt; a 
&gt; Lamping's Abstract Algorithm Is that a pun?
Is it mentioned anywhere in the article what Eta actually is?
No, but it is explained [here](https://github.com/typelead/eta): &gt; The Eta programming language is a dialect of Haskell which runs on the JVM and has the following goals: &gt; * accessibility for beginners from imperative languages, especially Java &gt; * compatibility with GHC 7.10.3's Haskell. &gt; Visit [eta-lang.org](http://eta-lang.org/) for instructions on getting started.
`{-# UNPACK #-}` support is fairly trivial and the patch has been waiting for reviews for months now, but it isn't merged yet. For now you have to explicitly use `(# | ... | #)` syntax.
Thank you very much for the answer and the references! I think my understanding is hampered by my precarious knowledge on types. So, I have a couple more questions. 1\. Given the definitions of `Cod` and `Cont` as above, are these three functions identical at type level? f1 :: forall b . Int -&gt; (Int -&gt; b) -&gt; b f2 :: forall b . Int -&gt; Cont b Int f3 :: Int -&gt; Cod Int 2\. I understand there is a type difference between `Cont` and `Cod`, but is there any relationship between them? Can we say that one is more general than the other?
Is there any info yet about how Eta manages to implement tail call elimination on the JVM?
The `ApplicativeDo` extension
This is a role on my team at Facebook. Likely in London. We have a large team working on Infer to find bugs in C++, Java and Objective C. This role is focusing on C++. Infer runs on every patch, and catches bugs across all of Facebook's estate, from Oculus and Instgram to Whatsapp. The role is primarily functional programming/engineering of the AST , CFG and analysis of C++. Working knowledge of C++ semantics is extremely useful, and good FP engineering skills. 
Is this a new application of Haskell at Facebook?
Nice. This is of course the best answer to the original question. :-)
This is an OCaml role, though we do have some Haskell in the code base, and I'm open to Haskell on new tools. There's also, separately, a large Haskell team. Generally this role would fit experienced engineers in C++ and (Haskell|OCaml).
Easy way to get started is to try out the examples and read through the README. I had to copy a lot of code from yesod-core because the parser code is unfortunately unexposed. Please note that not all types of routes are supported. If you are interested expanding the types of supported routes, PRs are welcome. This may require Template Haskell. 
I wonder if it is possible to run `distributed-process` on JVM now. This may give Akka a run for their money.
Cool! This is awesome! :)
Congratulations! An aside question: what is Haskell development experience in Yi out-of-the-box? I'd be happy to use Yi for Haskell if it supported Haskell development very well out of the box. Reading instructions for setting up Vim/Emacs for Haskell development makes me cringe a bit: I'd rather not spend my time on learning many unknown plugins and their possible interactions and I don't want to sacrifice my setup for a preconfigured plugin bundle. It might be a killer feature for Yi: easy Haskell development without a lot of plugins.
Is the Haskell team the spam team or does FB have more Haskellers hidden away?
I don't understand. `ApplicativeDo` doesn't have anything to do with applicatives over sequentialising. It's just sugar.
Don keeps posting job offerings even after the employer change :)
I disagree with this view. `String` is actually a higher level of abstraction, not a lower level. A Haskell list is a fundamental abstract semantic type. You can think of it as the basic concept of iteration. Or of codata. Or of potentially infinite lists. Or other things. There is nothing in its API that pre-supposes any particular concrete representation in memory. In fact, GHC already uses several different representations, depending on the situation. The best of them is no representation at all, where the list is turned into a tight loop in the object code that computes each element, uses it, and throws it away. Whereas Data.Text is a lower-level representation, whose API implicitly exposes concrete details about how the string is stored in memory. It reverts to something more similar to the way strings are done in legacy imperative languages. We're currently forced to use Data.Text as an optimization in some kinds of applications where the compiler isn't performant enough yet in its implementation of String. Even if this proposal is implemented, I doubt that Data.Text won't still be necessary, but it would be a great step forward.
there's other things, but the "spam" (it's way more than that) is the largest group.
Let's first see if we can agree on what a list is. What I'm talking about is a data structure that exposes the fundamental operations `cons` and `uncons`. Everything else is built on top of those operations. In the OPs proposal, the compiler was supposed to expose this abstraction and do magic behind the scenes. So `cons` and `uncons` are the fundamental operations. They *must* be O(1) or else any conversion of a string has higher complexity than O(n), and that's bad. This means that OPs variable length vector representation already fails, because it can't guarantee O(n) for all types of traversals. Of course, it's possible to use a 2, 3, 4, or 5-tuple cons cell as they are still O(1) structures. Higher level operations such as `map`, `filter`, `split`, `take` etc. is not part of the fundamental interface to a list. They are built on top of `cons` and `uncons`. OTOH, a vector representation where the exposed interface is `map`, `split`, `take` etc. depends less on a specific implementation. It's easy to see this - for a vector interface you can choose to implement it as a list, as a chunked list or as a continuous piece of memory. You can expose the same interface with the same complexity using all of those. You can also implement `cons` and `uncons` for a vector, but those operations don't have to be O(1) because the more abstract operations *is the interface* to the data structure. Using `cons` and `uncons` as the interface for text processing is a wart IMO. Using lists as a control structure is entirely reasonable, but has nothing to do with `String`. &gt; You can think of it as the basic concept of iteration. A list is the basic concept of inefficient forward-only iteration. It excludes parallel iteration, partial evaluation of a subset, backwards iteration etc. `fmap` is a more basic concept of iteration because it easily maps to for example a parallel architecture like a GPU. Similarly a vector interface like `Text` can be processed in parallel. It does not *require* inefficient processing. The fact that it happens to be faster is also a good thing.
The issue is not implementing tailcalls but implementing them without performance overhead. [Trampolins](http://blog.richdougherty.com/2009/04/tail-calls-tailrec-and-trampolines.html) but since they explicitly mention a "very efficient implementation" maybe they did come up with something better.
Anyone know if there's a way to make this working with zsh?
What do you mean by &gt;implicit duplication of arguments performed by beta-reduction Can you give an example where beta reduction will duplicate arguments **implicitly** and where **explicitly**?
Needs more LSP
How much is it actually useful to have optimal reduction of λ-terms? Are the performance improvements significant enough?
I haven't had any issues with either the tool chain or with reflex being overly complicated. I took a little while to get used to them, but less time than I needed to get used to lens, and I'm pretty confident that spending the time on both Nix and reflex has paid off. I also haven't had issues with compile times, although I mostly do reflex development with ghc and either compile with ghcjs for a final test or let a ci system take care of it. Even then, it's not hugely slower until I start adding template haskell into the mix. It puzzles me a bit that our experiences have been so different. 
We definitely do not agree on what a list is. A Haskell list is a denotational semantic concept. As soon as you talk about "O(1)" and "ineffecient" it is clear we are not talking about the same thing. Those are concepts from the world of operational semantics, the stuff of imperative languages. Haskell is a pure language. It is built on denotational semantics, not operational semantics. The GHC compiler does provide a window into operational semantics, for optimization purposes. But for most code written, a Haskell programmer should not need to worry about that. Our first goal in Haskell is that the compiler should do the best possible job generating reasonably efficient object code from programs written in the most denotationally simple way. And then, as a secondary goal, the compiler should provide some way to dip down into messier lower-level operational reasoning in the rare case when the default is not good enough for our use case and we need to optimize further. A List is not "inefficient" iteration, nor "efficient" iteration. How iteration "maps to a GPU" has absolutely no meaning in the context of the abstract denotational concept of iteration. "Iteration" is the simplest possible co-inductive type, nothing more and nothing less. If my program is best expressed semantically in terms of a Haskell List, and then the compiler looks at my program and somehow figures out a way to run my iteration in parallel, backwards, sideways, or on a GPU to make it more efficient, I am thrilled. If not, most of the time that's probably OK; it's worth it for my program to be as simple, readable, maintainable, and provably correct as possible. If I do need that kind optimization in my use case, then I do want a way to force those operational things to happen.
Stack can install GHC 8.2.1 already. `stack setup 8.2.1` should Just Work™. You can use that with `--resolver ghc-8.2.1` and `stack solver`. The Stackage nightlies should switch over to GHC 8.2.1 in about a week. I'm not sure when to expect an LTS for 8.2.1. 
I am currently not ready for a full time position yet, as I am writing up my PhD thesis, but I would love to do an internship or placement in your team. Are there any opportunities for such a placement in your team at the moment? I'm based in London and don't need a UK visa.
For stack users, https://gist.github.com/dmjio/3696e39d3532ab2eef3ec8dc404054a7 resolver: lts-7.19 compiler: ghcjs-0.2.1.9007019_ghc-8.0.1 compiler-check: match-exact setup-info: ghcjs: source: ghcjs-0.2.1.9007019_ghc-8.0.1: url: http://ghcjs.tolysz.org/ghc-8.0-2017-02-05-lts-7.19-9007019.tar.gz sha1: d2cfc25f9cda32a25a87d9af68891b2186ee52f9 packages: - '.' - location: git: https://github.com/dmjio/miso.git commit: 227e8ed9bd90f356ff34844046c471473f650e41 extra-dep: true 
Sure, and f = const undefined is a valid implementation ;-)
I mean mine is actually total... When people say valid implementation totality is generally an implicit requirement. 
OK, but in haskell it seems fair to be suspicious. Neither the language nor the type give any guarantee of totality, nor is it uncommon to find partial functions in practice.
This is great! Startup overhead from dynamic configuration was a big source of friction when I tried `yi` a couple years ago.
I think he refers to *implicit* as in the caller can't tell if the argument gets duplicated or not. Whereas *explicit* duplication happens, when the expression contains duplicate expressions such as `2*2 + 2*2`.
The question seems to lack a 'significant to ...'. To what? Naive interpreters? ByteCode interpreters like GHCi? Other Virtual Machines like SECD? The author's [question on SO](https://stackoverflow.com/questions/31223539/is-it-possible-to-evaluate-lambda-calculus-terms-efficiently) is quite illuminating.
To GHCi. 
Can't stop, won't stop (hiring).
Do you happen to be hiring?
hmm, I heard that ghc 8.0.1 had some serious bugs and it should not be used. 8.0.2 is recommended.
This is fantastic! I wonder how much work a similar thing for Servant would be...
Those bugs are mostly affecting ghc compilation. ghcjs has its own compilation and produces javascript output. For backend work you can of course use a different ghc version since you will have a separate project with a separate stack.yaml. 
As far as I know, a surprising amount of Hackage packages should "just work". For ones that don't work out of the box, they have a side-repo that adds shims into the offending packages to make them work.
It eliminates unwanted sequencing of computations when using a monad. I think that this was the complaint in the first place.
The Spacemacs + Haskell setup is pretty frictionless.
Did they mean for this to be applicable to people using `-fobject-code`?
Wow, the new error machinery looks really great! Quick questions: Is there any reason to use Parsec over Megaparsec in new projects? Additionally, is there any reason not to port over old Parsec projects to Megaparsec?
[optparse-applicative supports zsh completions since v0.14](http://hackage.haskell.org/package/optparse-applicative-0.14.0.0/changelog) while (assumedly) stack still uses v0.13. Optimistically you could simply build your own version of stack using optparse-applicative-0.14.
Thanks! The only reason I know of is compatibility with older GHCs. Megaparsec 6 requires at least GHC 7.8, while Parsec can work with GHC as old as 7.0. If you have any other reason, open an issue on our issue tracker and we'll discuss. If you have the time and desire, I think it's a good idea to port existing code to Megaparsec. Anyway, Parsec has passed the "threshold of immortality" (as SPJ puts it) as a library long ago, there are 878 packages that depend on it on Hackage, so it'll be around forever. It's good it has been moved under `haskell` GitHub account where people like hvr guarantee at least minimal maintenance now.
As with banks, still no REMOTE?
&gt;a large Haskell team. Define large? 
Brian McKenna explains it briefly in https://www.youtube.com/watch?v=0CRmLNF-IhA In short: there aren't *call/return*, there is *eval/apply* (or *push/enter*). http://community.haskell.org/~simonmar/papers/evalapplyjfp06.pdf
One difference is that servant does not have named routes. So you would be using the entire path name plus information about the dynamic elements. Maybe it is possible, if each servant type is a single route, to convert a matched route to its type name and use that as the metric name. Or maybe there is already some package out there to help you name routes.
I think #3 has had some work in the type family space (where unconstrained overlap leads to inconsistency in a way not caused by overlapping typeclass definitions). Basically, there are two kinds of type family declarations, open, and closed. Closed declarations allow overlap but not extensibility, and open declarations allow extensibility but not overlap. Combining them in clever ways solves most of the problems with unconstrained overlap. See [The GHC wiki](https://wiki.haskell.org/GHC/Type_families#Detailed_definition_of_type_synonym_families) for some detailed examples and discussion.
Can anyone tell me what `stack trace` does? It's difficult to Google.
`Cont` also lets you do things like call the continuation function more than once, so it is certainly *not* isomorphic to `a`. foo :: Cont Int Char foo = Cont $ \f -&gt; f 'a' + f 'A' sumEach :: String -&gt; Cont Int Char sumEach s = Cont $ \f -&gt; foldl' (+) 0 $ map f s 
There are two important points to answer that question: 1. Optimal evaluators are asymptotically superior for very high-order terms; 2. Optimal evaluators may be much more ASIC (GPU?) friendly. The first point means that, if you plan to reduce very high order terms, then optimal evaluators are ridiculously superior, today. Problem is: is there any situation where you actually want to do that? Most "common" programs barely need high-order functions at all, so maybe that's a no. But perhaps there are algorithms and solutions to known problems that require that kind of ultra-high-order reasoning. The second point means that, chances are, one could build an ASIC (or even a GPU evaluator) for this algorithm. If so, then I believe it'd become ridiculously faster to GHC and similar, not only because ASICs are naturally much faster than CPUs for the problems they solve, but because it'd be exploring all inherent parallelization of your program and managing memory in a much superior manner. So, in short, I think it is an unexplored territory that might or might not lead to very interesting advancements and may or may not be worth the investment. 
I don't get it?
https://docs.haskellstack.org/en/latest/GUIDE/#tracing
What the other comments here are really saying is that GHC can't infer higher-rank types. You need to manually specify a type signature for `unbox`. Consider -- fromEnum :: Char -&gt; Int example f = f (== 'a') &amp;&amp; (f fromEnum &gt; 60) This won't typecheck without an annotation: • Couldn't match type ‘Integer’ with ‘Bool’ Expected type: Char -&gt; Bool Actual type: Char -&gt; Integer • In the first argument of ‘f’, namely ‘toInteger’ In the first argument of ‘(&gt;)’, namely ‘f toInteger’ In the second argument of ‘(&amp;&amp;)’, namely ‘f toInteger &gt; 60’ But if you add the higher rank type: {-# LANGUGAGE RankNTypes #-} example :: (forall b. (Char -&gt; b) -&gt; b) -&gt; Bool example f = f (== 'a') &amp;&amp; (f fromEnum &gt; 60) it works fine.
I'm a PhD student at UPenn, and I was a TA for the 2016 iteration of this course. Anyone is welcome to PM me with questions about the material! **EDIT:** I was a TA for [CIS 552](https://www.seas.upenn.edu/~cis552/)—the more advanced Haskell course at Penn—and not CIS 194. But I'm still happy to be a resource!
We are actively working on: - LTS 9, which is with ghc 8.0 - nightlies switching over to ghc 8.2 LTS releases last a minimum of 3 months, so I would expect LTS 10 to be released with ghc 8.2 no sooner than November.
Yes in fact I think Gabriel has studied that option. The only problem, I believe, is the stratification of terms. Not every Morte term works on this algorithm. Now, I just noticed something. Morte still has a few problems: not being able to encode Scott-encoded datatypes (thus express O(1) pattern-matching), induction, proving 0 != 1, etc. CoC is the one to blame for that. Now, if we add linear types to it (sorta like EAL + CoC), not only it would allow all Morte terms to be reduced with the algorithm, but it'd also allow Morte to have Fix (actual Fix, not Self) without losing consistency! Which in turn would allow the Scott-Encodings, induction and so-on be expressed naturally! /u/tekmo what do you think of that idea? I'm currently designing [a browser for Ethereum](https://medium.com/@maiavictor/what-is-wrong-with-the-web-and-why-we-need-moon-4038949ede34) that will use a small functional core instead of JavaScript. I didn't chose Morte because of those problems. If we did those things, I guess could actually use it, using my evaluators to get a decent performance and GC today. In a future, if it gets more popular, it wouldn't be hard to invest in a GPU evaluator for it. Once we fully explore interaction net's ability to go parallel and closer to the metal, perhaps we'll close that gap that causes Morte to need native strings/ints/etc. primitives to have competitive performance.
Thanks! Could you say which part of the video specifically I can find it in? (FWIW, I found [the slides](http://lambdajam.yowconference.com.au/slides/yowlambdajam2017/McKenna-HaskellJVMEta.pdf), which don't mention it directly.)
Not really, I just meant there is not a explicit, separate construct for duplicating variables, lambda does both substitution and duplication, and often we're careless with duplicating arguments, assuming that is a free operation (because it is in most real-world cases).
Replied above.
Eta started as a gsoc project to implement a compiler from ghc core to java bytecode. Now it is a haskell dialect/fork. In part because keeping up with new ghc releases was difficult. In part because they need a bunch of functionality for exposing java class info that isn't in ghc mainline.
Yes! From the get-go Windows support has been much better than most of the ecosystem, getting going with MSYS2 + Stack so far has been cake compared to Platform. I very much appreciate it as well.
Stack is impressively stable. This looks like another great release. With the release of backpack in ghc 8.2.1, should there be a Stack that understands it?
Awesome, thank you very much! Are you already on the Functional Programming Discord? I can give you an intro to the group. 
Unfortunately not, at least at the moment. We've just finished a big hiring spree, so we're mostly done for now. I'll post something to /r/haskell when we start hiring a lot of general Haskell programmers again.
A few years back Ross Paterson took some time to try to break down Arrow into just what was needed for the sugar, but he seemed highly averse to building off of profunctor, as the sugar only needed variance on the result, IIRC.
Were you able to verify if these functions still worked in your Emacs version? :-)
Even though this is a great list, I'm sad that this is the extent of it. :|
Any performance benchmarks against vanilla java code?
@nhqv13vpwih3dlub thanks for compiling this list! It would be nice to also have a column for which industry each company is active in. For LumiGuide you can list "smart cities".
At Channable we use Haskell for much of our infrastructure. We are based in Utrecht, The Netherlands. You can find more at https://tech.channable.com. ;)
Well unfortunately it is not that great. While using spacemacs I have the personal feeling that nobody cares much about polishing that Haskell config. Of course I could be that guy but I don't have much free time these days and somehow lack a bit of motivation too. It kind of works but it is not shiny.
Sorry, that should have had a clearer description. It's actually a bit tricky to describe everything that's going on here. Lets say local packages A depends on B. With a normal build, if there are changes to B, it would usually rebuild B, causing A to be unregistered and reconfigured. Before this change, the rebuild of B would happen when loading A and B into ghci. The packages to load into ghci do not need to be built, instead just "initial build steps" needs to be run to generate pre-processor macros etc. Even if A needs to be reconfigured, as long as the version of B that's already installed matches, it's fine to skip re-installing B. So, that's what this change does. Makes starting ghci much nicer on multi-package projects. I don't believe it is possible for us to make it so that "stack ghci" loads quickly after a build of the package. See this quote from the ghc docs - https://downloads.haskell.org/~ghc/7.6.3/docs/html/users_guide/ghci-obj.html : &gt; Compiling to object code inside GHCi is particularly useful if you are developing a compiled application, because the :reload command typically runs much faster than restarting GHC with --make from the command-line, because all the interface files are already cached in memory.
Bob just surpassed 450lbs
It definitely does, but I have no idea when I'll get to it.
But current arrow has variance on the input anyway. Since you can do `lmap f a = a . arr f`. So that ship seems to have sailed. 
Yi is not a Haskell IDE by itself, it's just a programmable text editor. Theoretically one could make an IDE (for whatever language) out of Yi , some IDE backend and lots of duct tape, but that has not happened so far and is not even in progress.
Seek.co.au uses haskell in the Melbourne Australia office I believe. @screamish did a talk last year so his slides will be around somewhere
[removed]
It's an algorithm that works on lambda abstractions. 
Does it? Surely do notations that desugar to only `&gt;&gt;` could already do that.
You say that optimal evaluators are asymptotically better for very higher-order terms, but that schemes for dealing with non-stratified terms (which seem likely to be more common in practice) kill performance. Is there a reasonable compromise? Can you compile a non-stratified closed term to a stratified one and then apply it many times?
I think of Stackage LTS as the last step in the GHC release process.
`{-# LANGUAGE SentientTypes #-}`
I do not know, it seems to me like that's equivalent to attempting to develop a good oracle machinery, many have attempted that and the results so far are terrible, right? &gt; which seem likely to be more common in practice Why? That is what I'm trying to dispute, I guess. Rather than inputing an arbitrary λ-term and trying to automatically convert it in a good stratified term (which seems like a very hard problem), why don't we just let the programmer build the stratified term himself? I've been programming that way and I believe it is not as hard as it seems, it is just a matter of style. It all boils down to "use church-encoding for recursion and scott-encoding for pattern-matching". If you do that carefully you'll have stratified terms (I guess).
He’s very fond of laziness. (But sometimes it leads to excessive resource consumption.)
S U C C E S S U C C E S S 
{-# WORLD FunctionalFirst #-}
I hope you know that every time I don't (apply), I almost do.
The source code is here. https://github.com/seatgeek/docker-build-cacher I'm open to suggestions as this is my first public haskell project
Do you have libgmp installed? If so, what version?
Calling Haskell code from python is a huge dream of mine. Good write up, hopefully a solution to this becomes more deeply supported. 
I think STG compilers targetting more languages, ie clojure (if possible), could be a great industry inspired task for the community to tackle. `ccc` is a great example of this
Linear types seem pretty interesting. https://www.tweag.io/posts/2017-03-13-linear-types.html Mature and integrated LiquidHaskell could be neat. Records would be nice.
To answer your first question, I'll expand the types, eliminating `newtype` layers as I go. The first step is to remove the `forall`s, as they are implicit in type signatures anyway. f2 :: Int -&gt; Cont ((Int -&gt; b) -&gt; b) -- expand Cont :: Int -&gt; ((Int -&gt; b) -&gt; b) -- eliminate newtype wrapper :: Int -&gt; (Int -&gt; b) -&gt; b -- associativity of -&gt; This expansion indicates that `f1` and `f2` are equivalent, but they're not identical, as the `Cont` newtype is a distinct type. `f3` expands differently: f3 :: Int -&gt; (forall b. (Int -&gt; b) -&gt; b) Note that the `forall` is _inside_ the parentheses. Its scope is limited to just that part of the type. If there were a `b` outside the parentheses, it would be a different `b`. For the second question, could you write `toCod :: Cont b a -&gt; Cod a` or `toCont :: Cod a -&gt; Cont b a` ? If you can write one of those, you've proven that one is at least as general as the other. If you can write both, you've proven that they are isomorphic. toCont :: Cod a -&gt; Cont b a toCont (Cod f) = Cont f In this case, `Cont` is more general than `Cod`. You can't write a conversion the other way. I use the term "proven" because of the Curry-Howard correspondence. The function `toCont` constitutes a proof of the proposition that `Cod a` implies `forall b. Cont b a`. (Fast and loose reasoning applied. Proofs only valid in a fantasy Haskell with no partial functions.)
Calling the function more than once isn't a problem directly, Haskell is a pure language: evaluation has no side effects. The problem you're highlighted is that a `Cont` is able to manipulate the return value. In this case, you can evaluate `+` on the results of evaluating `f`. Without that, you could call `f` as often as you like, but you'd still have to select only one result from only one call as the value of your function, and you'd always pick the same one. The limited `Cod` of this thread forces that by requiring the implementation to be polymorphic in `b`.
Users
8.23 to 9.0, but still on ghc-8.0.2. What's up with the new LTS that requires the dial to go all the way to 9? 
That is quite a big jump already: https://www.stackage.org/diff/lts-8.23/lts-9.0 I suppose (I'm not a Stackage maintainer), the next *nightly* will be GHC-8.2 based, but that will mean that *a lot* (wild guess: around 1000?) packages will be (temporarily) dropped from Stackage set.
&gt; Records would be nice. Ha, it's great that Haskell might get dependent types before decent record types.
I'm not in the loop here; are dependent types the next big thing for Haskell? I know that Idris is basically Haskell with dependent types, and it seems like a massive change to put that into Haskell. That being said, I'd be stoked to see it. -- EDIT: Also I think Clean is Haskell with linear types lmao
Perhaps. Given stratified closed terms `s` and `t`, is `s t` a stratified term? That's what my question really amounts to. Expecting the programmer to perform a calculation by hand because nobody knows an efficient way to do it seems a bit backwards!
I've found the opposite - I have a great time with it.
The length of the list doesn't bother me that much, but having a wider diversity of size of companies, scale of systems, and problem domains would be exciting. If the commercial Haskell groups started investing in seeding libraries or FFI bindings where Haskell is thin on the ecosystem reports, that might open the door to companies using those in new problem domains. (Maybe a bi-annual meeting between Well Typed, FP Complete, and authors of the ecosystem reports?). Tweag, Sentenai, Lumiguide are some companies that seem to be expanding where you can use Haskell. It has been amazing seeing Haskell devs pounce on distributed ledgers!
To be fair, the library-level workarounds for lack of good record types (`lens`) are significantly superior to those that address the lack of dependent types (`singletons` et al).
Linear types have been a **long** time coming.
- `vector`: 0.11 -&gt; 0.12 - `aeson`: 1.0 -&gt; 1.1 - `servant`: 0.9 -&gt; 0.11 Among others. **EDIT:** Looks like all the `repa` packages got dropped.
According to [this post](https://typesandkinds.wordpress.com/2016/07/24/dependent-types-in-haskell-progress-report/) dependent types are coming to haskell, probably in 2019.
Do you know if it's possible for the data to be allocated straight into the region to avoid any copying cost?
Didn't watch the video yet, but does this mean that Eta has managed to not blow the stack (due to no TCO) or fill the heap (due to trampoline hacks) when doing a bunch of sequential binds? My understanding was the JVM precluded solving that problem to its core but hopefully my understanding was wrong :) I tried Eta a while back and found it pretty easy to blow the stack by traversing a list of, say, 100k elements with a simple `State` transition.
A monadic system that allows real composability of effects. https://www.reddit.com/r/haskell/comments/6mt8i6/do_you_have_to_choose_between_composability_and/ The bigger problem in software is not types. It is reusability of components. Composability is the killer feature of functional programming. It is not types. Composability will allow a perfect reusability of components. 
Wow, this is a really neat paper. Thanks for calling it to people's attention! This sort of thing seems like it would actually be a lot of fun to code up in Haskell as well as a way to make the core construction very accessible. 
Looks interesting. What's being done about it?
Eta works by executing STG - spineless tagless G-machine. If you think that trampolines is a way to execute a machine with non-local jumps, then Eta kind-of "has trampolines". DIsclaimer: I didn't ever try Eta. I'm just curious and watch videos :)
I don't see it that way, I see your question more like "can you compile an imperative program to a functional one and get all its benefits"? I think it is a matter of coding style, you can either express recursive algorithms in a well-behaved way, folds etc., or you can express them with direct recursion. If you use direct recursion, though, it will not necessarily be trivial to "fix" your program and recover a clean stratified term, like it isn't easy to recover an immutable functional algorithm from an imperative one. At least that's my hypothesis. ~ &gt; Given stratified closed terms s and t, is s t a stratified term? On the language above, yes that's always the case. I'm not sure why you asked that, though. Note the application of two terms that can be reduced optimally can't necessarily be reduced optimally. For example, mind this term: \x. let !y=x in !(y y) It corresponds to `λx.(x x)` and can be reduced optimally (obviously, it is in normal form). If you apply it to itself, though, this is what you get: (\x. let !y=x in !(y y)) (\x. let !y=x in !(y y)) let !y=(\x. let !y=x in !(y y)) in !(y y) That's its normal form! It can't go further than that because there is no `!` on `...let !y=(\x...`. You could try this instead: (\x. let !y=x in !(y y)) !(\x. let !y=x in !(y y)) let !y=!(\x. let !y=x in !(y y)) in !(y y) !((\x. let !y=x in !(y y)) (\x. let !y=x in !(y y))) !(let !y=(\x. let !y=x in !(y y)) in !(y y)) I.e., applying with an extra `!`, which is still stratified and goes further, but still gets stuck. Finally, you could do this: (\x. let !y=x in (y !y)) !(\x. let !y=x in (y !y)) (let !y=!(\x. let !y=x in (y !y)) in (y !y)) (\x. let !y=x in (y !y)) !(\x. let !y=x in (y !y)) Note that this one **does** reduce to itself after 2 beta-reductions, so that's an infinite loop! But it isn't stratified anymore, because the first use of `y` on `(\x. let !y=x in (y !y))` has no enclosing `!`s. This reflects the fact that, on the abstract algorithm, once you try duplicating a duplication, you'll perform an annihilation instead (because different nodes duplicate, equal nodes annihilate). So the abstract algorithm can't evaluate `(λx.(x x) λx.(x x))` to its normal form, which is obvious because it doesn't have one. But again, in practice with a good style you can do everything while still staying on the stratifiable lands, I believe.
No idea. Haven't had a chance to mess with this yet.
Hmm not sure why it is called that way...
Unable to avoid success! S U C C E S S S U E C C Haskell C C E U S S S E C C U S 
For Haskell? I'd like to see a new report that folded in some of the more common extensions. For GHC? I'd like to see the Eta project folded back in, or some .Net / JVM backend in addition to the native backend(s). Speed improvements or features that allow me to opt-in to speedier implementations in some case would also be appreciated.
BTW, take this all with a grain of salt because I'm just learning all of that. Also, note that if you do program a "clean stratified" term, you can [infer where to place the `!`s](http://dl.acm.org/citation.cfm?id=1131315) (i.e., you don't need to write them, just program in a way such that they can be written).
Oh
Please add [Numerai](https://numer.ai/) in San Francisco. We have a Haskell API dedicated to bitcoin transactions and are always interested in expanding our use of functional languages.
&gt; For Haskell? I'd like to see a new report that folded in some of the more common extensions. I'm right there with you. One might say this charging ahead with new features is great, but has a little bit of a 'success at all costs' feel to it=)
&gt; Linear types seem pretty interesting. https://www.tweag.io/posts/2017-03-13-linear-types.html Note that this is still a prototype implementation; it doesn't yet allow for tracking linearity in bindings or implementing uniqueness types, so don't expect the full expressiveness of linear types to be available just yet! But yes, in the long term, linearity and refinement types (either via LiquidHaskell or via dependent types) are both rather important.
From [the GHC 6.6 release notes](https://downloads.haskell.org/~ghc/6.6/docs/html/users_guide/release-6-6.html): &gt; * Linear implicit parameters have been scheduled for removal for some time. In 6.6 we've removed them from the user manual, and they may well disappear from the compiler itself in 6.6.1. From [6.6.1](https://downloads.haskell.org/~ghc/6.6.1/docs/html/users_guide/release-6-6-1.html): &gt; * Linear implicit parameters are no longer accepted.
Haskell 2020 might need a kick in the pants https://github.com/haskell/rfcs/issues/15
From reading the docs, one of the biggest differences might be the automatic insertion of `split`; none of the recent proposals talk about the compiler automatically inserting splits.
Nice article. Tangent article request: It would also be interesting if someone wrote up an article about how to access arbitrary languages from Haskell via sockets. For example: suppose you wanted to call an arbitrary clojure function from Haskell via a socket. What would be the best way to set that up? JSON parsing both ways? I've always wondered what the best practices are in FFI situations like these :-)
My votes: 1. The ability to handle and manipulate GC pauses for real-time applications. 2. More inline language libraries, similar to`inline-C`: `inline-clojure`, `inline-rust`, `inline-bash`, etc. Make Haskell the ultimate high-level piping language. 3. Homoiconic syntax i.e., bring in the parentheses :-)
My employer is current hiring for a Haskell position : [Tripshot](https://www.tripshot.com/hiring/) Backend is almost entirely implemented in Haskell. Most of engineering team is near Portland, OR but we hire remote as well. 
Instead of writing a Perl script we used a custom Setup.hs to extract linker flags for this situation.
Two more, [SimplyRETS](https://simplyrets) &amp; [Assertible](https://assertible.com) are using Haskell exclusively on the backend.
Presumably, if you don't want your linear parameter type to be splittable, you don't define an instance of `Splittable` and the compiler gives an error if you split them.
Sublime Text is not a native macOS editor.
Hi, head of FP Complete here. Two years ago we did a huge survey of Haskell users and [over 1240 people took the time to provide detailed responses](https://www.fpcomplete.com/blog/2015/05/thousand-user-haskell-survey). The top 3 needs were: 1. fix cabal hell 2. more educational resources (training, examples, thorough documentation, pedagogical materials) and not just theory or reference material 3. shared resources usable to show skeptical colleagues how great Haskell really is Also very prominent were requests for: - use cases (show me how to apply Haskell in full-scale, real-world situations in specific problem domains or industries) - more libraries for everyday tasks (data handling, database connections, numerical work) Issue #1 has been hugely reduced, both by stack and by fixes to cabal. Users now have effective, practical ways to get on with their work. But all the other listed issues still need your/our help. I humbly suggest that what Haskell needs now is to fill the gaps plainly identified by our fellow users for years.
The linear types coming in 8.4 do not enforce linearity at the `Kind` level but instead do it by providing a linear function arrow to replace `-&gt;`. For example f :: a ⊸ b This allows much better interoperatability of linear and unrestricted functions. I highly recommend reading the paper [available here](https://github.com/tweag/linear-types/releases). 
The first version of GHC I used was 6.4, but I never used this linear implicit parameter feature. I must say however, that I am a little wary of "automatic insertion" of something like a `split`. I would however have no issue with `split` as an available operation that the programmer could explicitly insert as needed. 
The language standard seems a bit absurd with GHC as the only major production compiler &amp; runtime. For all intents and purposes right now, Haskell means GHC Haskell. Some day I’d really like to see a new high-quality alternative implementation, to drive competition and reduce (or standardise) GHC-specific assumptions, but it would be a massive undertaking to get to feature parity and competitive performance.
I agree. Since `split` on any kind of mutable array or similar entails a deep copy. Implicit deep copies does not sound fun from a performance analyzing standpoint.
(Based on historical evidence, this extension implies `BangPatterns`, `Arrows`, and in some cases `IncoherentInstances`)
Under LIP `split` was avoidable by not implementing `Splittable`. However, I don't know if there was a mechanism to split explicitly. I can see why that would be a problem.
But I often do want something equivalent to `split`. Just used very explicitly and fairly sparingly. So personally that is not a solution that satisfies.
I believe they're within 10x of java with lots of lot hanging fruit ripe for the picking. Lots of really naive code generation where things are immediately allocated and then consumed etc. Brian McKenna's talk on Eta at LambdaJam this year mentioned several of these cases, and how they were commonly seeing speedups in the order of 10's of percent quite frequently.
The fact that there was a report was one of the reason I learned Haskell instead of another pure language, like Clean. I don't believe single-implementation languages are good for developers, as it makes compiler upgrades even more unpredictable. Currently suffering under a nearly 30 year old compiler, this issue is quite in the forefront of my concern.
I'm all for homoiconic syntax, but that doesn't require parens / S-expressions. And, honestly, I'd rather we didn't go with that particular (parens) syntax.
There are already examples of this, no? Do you find it just too cumbersome?
Yes, you can use JSON or MessagePack.
It sounds like you're describing having a server that just calls whatever language equivalent of "eval" on request payloads and returns the result. Ignoring the security issues, you can do this pretty easily with just about any RPC framework or roll your own with json, bson, msgpack...
It's not exactly what you're looking for, but you might find http://catinf.com/ interesting.
Our company: [Superpowers Corp](https://www.superpowerscorp.com/) in Boulder, CO.
 # pkg_info gmp Information for inst:gmp-5.0.2p3 # find / -name libgmp* /usr/local/lib/libgmp.la /usr/local/lib/libgmpxx.a /usr/local/lib/libgmpxx.la /usr/local/lib/libgmp.so.9.0 /usr/local/lib/libgmpxx.so.1.0 /usr/local/lib/libgmp.a Decided to install it via stack.
Embrace qualified imports. They're really not bad.
Ad 2 : So basically it would be great for Big Data.
Link: https://github.com/conal/concat More understandable link (skip to "compiling to categories"): http://www.haskellcast.com/episode/013-john-wiegley-on-categories-and-compilers One cool application of this is the [`z3cat`](https://github.com/jwiegley/z3cat) library, which lets you apply a solver to regular Haskell functions, like https://github.com/jwiegley/z3cat/blob/b359ec9eb18465574ff7b366b24c3085a12c9273/test/Main.hs#L23
Hey, I'd love to hear more about the trouble you've run into, and see if there's anything I can do about it. 1. If you have the time to share any details about the parts that were overly complicated, I'd definitely like to take a look at them. 2. The separation of view and controller is definitely something that I don't have a satisfying solution to, yet. It's tricky, because many of the ways of separating view and controller sacrifice composability - the view and controller need to be composed separately, and if they get composed differently, they don't work. In general, I've prioritized composability over separation of view and controller in reflex-dom - which is probably somewhat a matter of personal preference. That being said, there's been some work towards creating better ways of separating view and controller logic, such as [reflex-jsx](https://hackage.haskell.org/package/reflex-jsx). 3. GHCJS is definitely slower than GHC, but if you were seeing 100x slower, my guess is that you may have been using a lot of Template Haskell. That was *seriously* slow a while back, but Luite fixed it in [this commit](https://github.com/ghcjs/ghcjs/commit/73618904369fe9a2adb7caaf751e24568a5d0bf4). GHCJS is still slower than GHC, but not even close to 100x in my experience since that patch. 4. The complex toolchain is definitely painful, and that's why I put together [reflex-platform](https://github.com/reflex-frp/reflex-platform), to try to make it reasonable for people to get up and running quickly. Of course, even though I love Nix, I know it isn't everyone's cup of tea, so I'm very glad the Stack folks have also gotten GHCJS working in a reasonably straightforward way. Did you encounter toolchain difficulties beyond GHCJS when you were working with Reflex? If any of your production code is still kicking around, I'd be happy to see if there's a way I can help you get it into a state you'll be happier with.
This is great. Hopefully we'll get this functionality in cabal (and stack). A while back I spoke to /u/ezyang about precisely this. I have since settled on static libraries instead. Primarily because the dynamic library overhead and handling makes little sense if you end up linking everything up into a sandboxed distributable (for mobile) anyway. GHC has had the `-staticlib` flag precisely for this for iOS for quite a while. It however relies on `libtool`, which on macOS is something rather different than what GNU `libtool` is. The functionality can be achieved via MRI Librarian scripts that GNU `ar` supports, but BSD `ar` does not. I'm planing to have GHC 8.4 support `-staticlib` for more than just the `iOS` platform. 
We've left promoting the actual conference later than last year due to an influx of administrative activities, but it's all hands on deck now :)
 # mount -uo wxallowed / # pkg_add haskell-platform gtar xz # cabal update # cabal install stack # cd app # stack.yaml has resolver: ghc-8.2.1 # /root/.cabal/bin/stack setup Preparing to install GHC to an isolated location. This will not interfere with any system-level installation. Downloaded ghc-8.2.1. ... ghc-cabal: can't load library 'libm.so.10.0' gmake[1]: *** [ghc.mk:991: install_packages] Error 4 gmake: *** [Makefile:51: install] Error 2 # find / -name 'libm.so*' /usr/lib/libm.so.9.0 
&gt; The limited Cod of this thread forces that by requiring the implementation to be polymorphic in b. Only "forces" in a sufficiently idealized language. In Haskell (or any other insufficiently ideal language) there are operations you can perform on all types, which voids some of the reasoning about what an ideal "for all" means. For example, `seq`. If the underlying function/continuation can be called multiple times, I can always glue their results together with `seq`, allowing me to obtain some non-pointwise information about function/continuation. For example, I can construct `Cod (\f -&gt; seq (f undefined) (f True)) :: Cod Bool` which allows me to determine whether `f` is strict or not; which no value of type `Bool` is able to do. Or I can construct `Cod (\f -&gt; seq (f undefined) (seq (f False) (f True))) :: Cod Bool` which allows me to determine whether `f` is anywhere undefined; which, again, no value of type `Bool` can do. Nothing special about `Bool`, we can do this sort of thing for every concrete type (and to varying extents for every non-concrete type too). I vaguely recall that newer versions of GHC automatically derive certain generic/dynamic classes for all types, so those could be used for similar shenanigans. In other languages these sorts of reflection capabilities generally break parametricity entirely, allowing you to inspect the type `b` before deciding which value of that type to produce. These sorts of things are all "type safe", so they'll never cause the program to crash; but there's a wide gulf between typesafety and "parametricity", and it's parametricity that we're relying on when we say `a` is isomorphic to `Cod a`.
Yep.
Infrastructure/[Engineering Effectiveness](http://www.gigamonkeys.com/flowers/)
Clean does a bit less than linear types. It only does uniqueness types, which, iirc, is a special case. It's still very useful and they have this functionality for many many years. 
&gt; I know that Idris is basically Haskell with dependent types, and it seems like a massive change to put that into Haskell. Idris has a lot of subtle superficial differences, and also some fundamental ones, like being a strict language.
I think you got a typo there as `aeson-1.2.1` is the latest release.
&gt; A typical Haskell package will have hundreds of transitive dependencies, all of which you need to give to the linker. Furthermore, they need to come in the right (reverse topological) order. I tried building a Haskell shared library recently and ran into this. I had no idea how to confront this problem, so my solution was to repeatedly paste the entire list of link dependencies until it stopped complaining. It worked, but I think I lost a fragment of my soul in the process.
Agreed. Give me some sane indenting layout rules with homoiconic syntax and I'll be in heaven. Being able to dance around the code and format it a-la emacs lispy or paren modes? A guy can dream...
We've written a bunch of TH code (in our internal project) to look at the DB schema and generate Opaleye records and table definitions. There's another package called `rel8`, which is doing something similar, and is open source.
CTO of FretLink here : we are hiring indeed :-) Location : Paris / remote Domain : Logistics/Transportation (truck management system, a lot of maths ahead :) ) Haskell as backend main language for now on, and possibly used for Data Science (HaskellR + data processing tools). Some frontend could happen too, probably Purescript, not sure yet. See https://fretlink.com/jobs .
[sql-fragment](https://github.com/maxigit/sql-fragment) let you write and compose strongly-typed queries, and it has a [generator](https://github.com/maxigit/sql-fragment-mysql-simple/blob/master/executables/DumpSchema.hs) which works for MySQL. If you prefer `Persistent`, I have a generator (for MySQL again) which reads the schema and generates persistent entities. It's part of a bigger project but could be extracted easily (it probably needs some tweaking as well as it's tailored to my needs). You can find it [there](https://github.com/maxigit/Fames/blob/master/tools/FAGenerator.hs). Both generators generate plain text instead of using TH. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [maxigit/Fames/.../**FAGenerator.hs** (master → cf55993)](https://github.com/maxigit/Fames/blob/cf5599308882e80bcccb26ee02558aff54a22a94/tools/FAGenerator.hs) * [maxigit/sql-fragment-mysql-simple/.../**DumpSchema.hs** (master → 18f3874)](https://github.com/maxigit/sql-fragment-mysql-simple/blob/18f3874f31d25c8a69950a296145817759866f22/executables/DumpSchema.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dks8y2y.)^.
I'm interested as well in this. I often needs to pass simple functions in a configuration file. Not being able to do so easily, is a real pain. From what I remember, not of the above are simple or even works.
I thought Parsec was the parser to use (except if you had a good reason to use attoparsec). What makes Megaparsec better than Parsec ?
Could you point out the code where you are actuall using the ST.Monad ?
Thanks a lot for taking the time to answer. I really appreciate your help. 
Looking at your cabal file it seems that you haven't specified any optimisation options ? If you want to talk about performance the first things is to compile with optimisation enable. Add `ghc-options: -O2` in your cabal file.
Though the idea's on point, you have some unfortunate typos in there ----- To make everything pedantically explicit... Let's write `_A` for an arbitrary type used when discussing/reasoning about things; whereas we write `a` for a type-variable, which must be bound by some quantifier in Haskell code. That is, "`_A`" isn't text *in* any Haskell program, it's some English text we're using to reason *about* Haskell programs! For any real Haskell program we must fill in the hole `_A` with (the text for) some Haskell type. And let's write `&lt;=&gt;` to mean that two types are canonically isomorphic; as opposed to `~` which is a Haskell constraint we'll ignore henceforth. Again, "`&lt;=&gt;`" is English text for talking *about* Haskell programs, it is not Haskell text for use *in* Haskell programs. Thus, making all the quantifiers and parentheses explicit, we have the following canonical isomorphisms between types: -- Definition of 'Cont' (Cont _B _A) &lt;=&gt; ((_A -&gt; _B) -&gt; _B) -- Definition of 'Cod' (Cod _A) &lt;=&gt; (forall b. ((_A -&gt; b) -&gt; b)) -- Similar to 'flip'. If and only if @a@ does not occur in @_B@: (forall a. (_B -&gt; _C)) &lt;=&gt; (_B -&gt; (forall a. _C)) Gluing these together, for an arbitrary type `_A` we can prove: (forall b. (Cont b _A)) &lt;=&gt; {by defn Cont} (forall b. ((_A -&gt; b) -&gt; b)) &lt;=&gt; {by defn Cod} (Cod _A) In general, whenever we can prove `_A &lt;=&gt; _B`, it follows that we can write functions `to :: _A -&gt; _B` and `fro :: _B -&gt; _A` such that for any `a :: _A` we can prove `a = fro (to a)` and for any `b :: _B` we can prove `b = to (fro b)`; where those "`=`" are English text meaning that the Haskell expressions on either side must reduce to the same thing. Thus, because `Cod _A` is isomorphic to `forall b. Cont b _A`, we can write Haskell functions that coerce between them. However, in order to do so in full generality (i.e., not just for one specific choice of `_A`), we'll first have to find some way to take our English expression "for an arbitrary type `_A`" and encode it as a Haskell expression. This encoding loses some precision (because Haskell's "`forall`" doesn't mean exactly the same thing as English's "for any"), but the encoding is adequate for our purposes. So, making all the quantifiers, type-abstractions, type-applications, and type signatures brutally explicit we have: to :: forall a. (forall b. Cont b a) -&gt; Cod a to = /\a0 -&gt; \(w :: forall b. Cont b a0) -&gt; Cod (/\b0 -&gt; \(x :: a0 -&gt; b0) -&gt; let y :: Cont b0 a0 y = w @b0 z :: (a0 -&gt; b0) -&gt; b0 Cont z = y in (z x :: b0) fro :: forall a. Cod a -&gt; (forall b. Cont b a) fro = /\a0 -&gt; \(w :: Cod a0) -&gt; /\b0 -&gt; let x :: forall b. (a0 -&gt; b) -&gt; b Cod x = w y :: (a0 -&gt; b0) -&gt; b0 y = x @b0 in (Cont y :: Cont b0 a0) Using our "flip" canonical isomorphism we could also transform the latter to: fro' :: forall a b. Cod a -&gt; Cont b a fro' = /\a0 -&gt; /\b0 -&gt; \(w :: Cod a0) -&gt; let x :: forall b. (a0 -&gt; b) -&gt; b Cod x = w y :: (a0 -&gt; b0) -&gt; b0 y = x @b0 in (Cont y :: Cont b0 a0) However, we can't use "flip" to change the type of `to`. In general there's nothing we can do when a `forall` appears in the left argument of an `(-&gt;)`. It's stuck there. So there is no decent function of type `forall a b. Cont b a -&gt; Cod a`. To see why, we can use our canonical isomorphisms to prove: forall a b. Cont b a -&gt; Cod a &lt;=&gt; {by defn Cont} forall a b. ((a -&gt; b) -&gt; b) -&gt; Cod a &lt;=&gt; {by defn Cod} forall a b. ((a -&gt; b) -&gt; b) -&gt; (forall c. (a -&gt; c) -&gt; c) &lt;=&gt; {by flip} forall a b c. ((a -&gt; b) -&gt; b) -&gt; (a -&gt; c) -&gt; c But what term has that type? Following the types, we can get this far: /\a0 -&gt; /\b0 -&gt; /\c0 -&gt; \(x :: (a0 -&gt; b0) -&gt; b0) -&gt; \(y :: a0 -&gt; c0) -&gt; y (_Z :: a0) :: c0 but what expression can we fill `_Z` in with? There's no way to get a value of type `a0` out of `x` nor `y`, so we're stuck. ----- If GHC had first-class existentials (like UHC does), then we get a canonical mapping from `exists a. (_B -&gt; _C)` to `(forall a. _B) -&gt; _C`whenever `a` does not occur in `_C`. However, we do not get a map the other way; so these two types are not isomorphic: `exists a. (_B -&gt; _C)` is more general than `(forall a. _B) -&gt; _C`.
Yes, in the hashtable branch (the slow one), it is compiled with the -O2 option. check [here ] (https://github.com/lsund/edmonds-matching/blob/76695263bb1851550d51fa3c6e76fb0cdade969b/edmonds-matching.cabal)
Sure, 3 HashTables are instansiated in `src/Edmond/Data/AlternatingForest.hs` These are then updated used functions in `src/Edmond/Data/Graph.hs` eg. `updateSingle :: Graph s -&gt; Property -&gt; (Vertex, Vertex) -&gt; ST s (Graph s)`. The main algorithm is running in `src/Edmond/Algorithm/Core.hs`
For a fixed `B`, indeed it is false (in general). However, there's quantifiers going on. See [this comment](https://www.reddit.com/r/haskell/comments/6pgsy3/is_having_a_a_b_b_equivalent_to_having_an_a/dks9skh/) for making all the details explicit.
It's coming together pretty neatly actually, but of course there are lots of stuff to do before its production ready. I've collected the current main caveats [here](https://github.com/tweag/ghc/blob/linear-types/README.md) :)
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [tweag/ghc/.../**README.md** (linear-types → 9afa4b8)](https://github.com/tweag/ghc/blob/9afa4b8f9834efc3df5a2a699ab39e8bc28eed7f/README.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dksa7he.)^.
"big" data isn't the same as "very higher-order" data. Overwhelmingly, when people say "big data" what they mean is a vast quantity of extremely first-order data.
8.4, with a bit of luck! :) 
for certain values of "most". There are plenty of contexts in which duplicating values is expensive, and lots of effort has been expended on learning how to avoid that duplication. E.g., you commented that maybe this stuff would be helpful for ASICs; however, integrated circuits are one of the prime examples where duplication is not free. Reducing fan-out is a common task/problem in circuit design.
Thanks, that was it! Discussion regarding `vte_terminal_spawn_async` is on Gitter...
I held a talk about plugin architectures last year that I actually planned to sum up in a blog post, which I never did. If you can make sense of my [slides](https://github.com/sgraf812/hal16/blob/master/slides.pdf) without what was spoken, then this might help you. Just to sum up what I know about the options you posted: - plugins (mentioned in the talk) is pretty much dead and in maintenance mode according to /u/stepcut (?)... I'm not sure you can even reload stuff - web-plugins is really narrow in scope. Might very well work for your use case, though. Seems to be in maintenance mode. - dyre: The xmonad approach. Wraps your main function to check your 'config file' for changes on startup (!), recompiles itself and restarts. This is not what you want. In fact, I can't recommend it to anyone who has a more complex build system (complex like a cabal project), it just doesn't work well. Also, recompiling yourself or using `stack`s `script` feature does a much better job. That's also why `yi` recently ripped the `dyre` dependency out of their core module - I have no experience with rapid. But I think it disqualifies by using GHCi? - I also mentioned hint in the talk. I think it worked quite well, once you have set up the appropriate paths (ghc-pkg path!) and so on, but AFAIR things went weird when serialiazing stuff because of Typeable or so, which is why I went with read/show serialization &lt;:-). - GHCi.ObjLink: IIRC, this is what plugins and all the other approaches use under the hood. This is reaaaaally low-level. AFAIR, I think this module was the main reason that reloading doesn't work. Other than that, I also mentioned - [dynamic-loader](https://hackage.haskell.org/package/dynamic-loader) which is a direct competitor to plugins, I think. Wraps the GHC API in a more minimal manner. Still had some problems with it, though... - [hslua](https://hackage.haskell.org/package/hslua) worked flawlessly, beating all other approaches. But it's not Haskell, not even type-safe :(. The bottom line of the talk was that probably a proper Haskell-like scripting language with a proper type system, with good interop like lua, would do the job (Morte? [Dhall](https://github.com/Gabriel439/Haskell-Dhall-Library/tree/12ad893605d0d890d148e104da30635d9d2ef38b)?), as GHC currently misses out on a lot of plumbing needed to make hot code loading worthwhile. Edit: Judging from the docs, rapid might actually be worthwhile! Totally glossed over this one so far. It's probably what I would go with, if it works.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [sgraf812/hal16/.../**slides.pdf** (master → ffc9f9c)](https://github.com/sgraf812/hal16/blob/ffc9f9cc7510a56348695d6e42c1b8dc9fd14af3/slides.pdf) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dksaha5.)^.
From the [README](https://github.com/mrkkrp/megaparsec#comparison-with-other-solutions): &gt; - Better error messages. We test our error messages using dense QuickCheck tests. Good error messages are just as important for us as correct return values of our parsers. Megaparsec will be especially useful if you write a compiler or an interpreter for some language. &gt; - Megaparsec 6 can show line on which parse error happened as part of parse error. This makes it a lot easier to figure out where the error happened. &gt; - Some quirks and “buggy features” (as well as plain bugs) of original Parsec are fixed. There is no undocumented surprising stuff in Megaparsec. &gt; - Better support for Unicode parsing in Text.Megaparsec.Char. &gt; - Megaparsec has more powerful combinators and can parse languages where indentation matters. &gt; - Comprehensive QuickCheck test suite covering nearly 100% of our code. &gt; - We have benchmarks to detect performance regressions. &gt; - Better documentation, with 100% of functions covered, without typos and obsolete information, with working examples. Megaparsec's documentation is well-structured and doesn't contain things useless to end users. &gt; - Megaparsec's code is clearer and doesn't contain “magic” found in original Parsec. &gt; - Megaparsec has well-typed error messages and custom error messages. &gt; - Megaparsec can recover from parse errors “on the fly” and continue parsing. &gt; - Megaparsec allows to conditionally process parse errors inside your parser before parsing is finished. In particular, it's possible to define regions in which parse errors, should they happen, will get a “context tag”, e.g. we could build a context stack like “in function definition foo”, “in expression x”, etc. This is not possible with Parsec. &gt; - Megaparsec is faster and supports efficient operations on top of tokens, takeWhileP, takeWhile1P, takeP just like Attoparsec.
Nice! I might use this.
I think another survey might make sense. Today, because of `stack` we can scale our projects much more easily than before - we can have 50 or 100 library dependencies that would require heroic effort earlier. This means that the eco-system can, and does move much faster now than earlier (it would be fun to measure this - how many packages rely on latest of other packages vs a few years ago, and how has the avg number of dependencies grown). I think this change means that there are might be other hurdles today than then. I'm presonally pretty happy about the library situation, but things like the Javascript-problem, and fast iteration on large code-bases might still be challenging.
Thanks! Those slides were really helpful, and a give a nice summary of what's out there. Would you know the internals of `hint`? Does it work only with Haskell source files (i.e. strings)? Does it actually interpret them every time something from the plugin file needs to be executed? Is it possible to give it a compiled `.o` or `.hi` file and expect execution speed equivalent to "normally compiled code" (i.e. no plugins, everything is one large project)? I didn't quite understand your comment about `Typeable/show/read` serialisation, wrt `hint`. Also, is there a clear recommendation if we aren't bothered about having access to the GHC toolchain in production? In our use-case, we can assume that all plugins are trusted and will be pushed to production only after being checked our on CI environment.
`hint` will compile the file/string/whatever you give to it in isolation. This means you have to provide it the full environment, which is rather unwieldy for cabal-based projects (look at [these](https://github.com/sgraf812/hal16/blob/ffc9f9cc7510a56348695d6e42c1b8dc9fd14af3/lambdamon-dll/Makefile) makefiles), just saying. I'm not sure if you can give it `.o` and `.hi`s directly, I doubt it. You could probably run the interpreter in a background thread if latency is an issue. For an example on how to use the different libraries, see the [`PluginLoaders`](https://github.com/sgraf812/hal16/blob/ffc9f9cc7510a56348695d6e42c1b8dc9fd14af3/lambdamon-exe/src/PluginLoaders.hs#L44-L53) module. Normally, I'd recommend using [`interpret`](https://hackage.haskell.org/package/hint-0.7.0/docs/Language-Haskell-Interpreter.html#v:interpret) for type safety. But somehow the serialisation based on the `Typeable` instance was not working for the return value `Move` (a simple enum with 4 constructors), always returning the first tag. I just figured it might be due to me misinterpreting the API, so I maybe writing Hint.interpret ("chooseMove " ++ Hint.parens (show st)) infer instead of read &lt;$&gt; Hint.eval ("chooseMove " ++ Hint.parens (show st)) Could have worked, not sure. That's what I mean by serialisation, you practically lose type safety at API boundaries, something a good plugins layer would provide to you through `Typeable` instances, etc.
It sounds like the best thing would be to teach stack/cabal-install how to build ready assembled shared libraries as well as executables; the build tools already have most of necessary logic built-in.
Link changed - sorry!! https://www.facebook.com/careers/jobs/a0I1200000LT8aAEAT/
Great! Let me know if you have questions or need any help
I was addressing his second point &gt; because it'd be exploring all inherent parallelization of your program and managing memory in a much superior manner. Big data is closely related to parallelization and data flow. Look at spark, probably the most successful (popular) application of purely functional programming today. I expect PFP will inevitably become mainstream as the demand for big data manipulation increases. 
Would just putting record accessors into their own modules solve most of the ergonomic issues with Haskell records? This seems like it would be a far simpler solution than overloaded labels/etc, though it would probably be too big of a change to the module system. This is what Idris does, right? How well does that work in practice?
Or vise-versa @ Eta. I'd kill to see a fork of Haskell like Eta with fully-supported llvm/jvm/javascript/native backends, a more conservative approach to radical language design experiments, and a more liberal approach to fixing the ergonomic issues with the language and standard library. There's a tension between the industry-focused Haskell world (eta/stack/Foundation/etc), and the language-design-research Haskell world, (backpack/dependent types/nix/language standard/etc). I love both parts, but I think there's a reasonable argument to be made in favor of forking the language.
It is quite an old idea, as old as functional programming with a new formulation. I hope that It will be taken seriously by the Haskell community. It has been dismissed because the wrong idea that composability is only possible when the terms have no effects or the effects are the same in all the terms. There have been some work on equational reasoning with effects, but not about composability, which is more demanding. The Monad, Applicative and Alternative instances only combine terms that share the same effects and this is not good enough for composing software components in the large.
Agree. Just improving the ergonomics of Template Haskell would go a looong way. - Allow TH definitions to happen in the same module. - Have a non-`IO`-based TH monad that has neither the compile-time performance overhead or the problems with cross-compiling. - Find some lighter syntax for quasiquoting. The current thing is far too heavy for casual use. Not sure if these ideas are viable, but they would be very welcome if so.
There is no reason for not mixing and matching all of them. LYAH is good for having a friendly overview, but it lacks exercises. RWH has many applications but is kinda old, so some of its code does not work anymore (but is not too difficult to correct). There is also "Haskell programming from first principles", which is huge (which can be good or bad, depending on you), has lots of details and exercises, but you have to pay. Choose the parts that match the best your way of learning. I recommend also looking at the "Typeclassopedia" and the Haskell wiki. In any way, I recommend having some kind of application in mind, and using the creation of this application as the force to drive you forward on the learning, otherwise you can get lost in details, and Haskell has lots of details. But you don't need everything to write proper Haskell, and there is a lot you can do with only the basics. And most important, don't be afraid of the mathematical expressions and names. They are just like everything else, you can learn by experimenting and testing.
It’s not a typo, `aeson-1.1.2.0` is what made it into LTS 9.0.
I already have some kind of use for it in mind, so that's already covered :) &gt; RWH has many applications but is kinda old, so some of its code does not work anymore. This is super useful to know, and the main reason why I started a thread before buying. Too bad though, seems to be really complete! Haskell programming from first principles seems HUGE but worth a try. Thanks! 
`Parsec` currently has only 3 dependencies, `bytestring`, `mtl` and `text`. If the job is small enough it might not be worth pulling in `Megaparsec`'s dependencies.
The problem is, most of the industry would go with the pragmatics-oriented fork, and then it would become hard to get paid playing around with the research-oriented fork. Currently the two are the same, so it's easy to make a living while playing around with the fun stuff.
It's probably easier if you come up with a benchmark program that directly compares the performance of two small parts of the program alone, and perhaps compares to C. There's a lot of code there and it's hard for someone unfamiliar with it to know where to start!
This doesn't really explain why they're gone though, does it?
I'm trying `hint` right now and I got a very simple module to load dynamically: module MyPlugin where import Prelude foo :: Int -&gt; Int foo x = x + 1 However, if I try to load an HS file that in-turn imports `Text.Blaze.Html5`, I can't get it to load in the hint interpreter - no matter what I try. Do you know how to make common stack packages available to the `hint` interpreter?
The second variant will share the set between all queries even without optimisations. ~~The first variant will do so, too, but only when optimisations are turned on.~~ Nope I'd probably leave out the micro-optimisation for the empty list case and write generateFilter toKeeps = let set = Set.fromList toKeeps in \key -&gt; Set.member key set ~~Or even rely on optimisations to float out `set` like the first variant and write~~ Nope, that doesn't optimise generateFilter toKeeps key = Set.member key (Set.fromList toKeeps) Edit: Actually, GHC doesn't optimise the first variant to the second, not even with `-O2 -ffull-laziness`, which really surprised me. 
The empty case isn't a micro optimization. It evaluates to true on an empty set while yours evaluates to false.
These are more recent: @quote FAQ some good books &lt;lambdabot&gt; FAQ says: What are some good books for learning haskell ? Haskell Tutorial And Cookbook (HTAC), Programming In Haskell (PIH), Haskell Programming From First Principles (HPFFP) 
Everything is in the case, which change the behavior of the function, so you can't really get rid off it.
Ah, of course x). In that case generateFilter toKeeps = case toKeeps of [] -&gt; const True _ -&gt; filter where set = Set.fromList toKeeps filter key = Set.member key set
You have to mess around with the ghc-pkg registry, i.e. specify where to find it. I'm not sure how I did it, but have you tried `stack exec &lt;app&gt;`? That should set GHC_PACKAGE_PATH to something sensible...
Here is an explanation of how to predict how many times a let binding is evaluated: https://stackoverflow.com/a/3951092/1405768
You are right, there are more experimenting to do. I just thought there would be a possibility someone would spot an obvious flow.
Thanks! That did the trick. Although, now I can report that using `hint` gives a consistent slowdown of 2x compared to regular natively compiled code. Repo's available at https://github.com/vacationlabs/hint-test if anyone's interested. benchmarking without hint time 213.0 ms (208.2 ms .. 224.4 ms) 0.999 R² (0.994 R² .. 1.000 R²) mean 208.9 ms (206.1 ms .. 213.1 ms) std dev 4.400 ms (1.590 ms .. 6.449 ms) variance introduced by outliers: 14% (moderately inflated) benchmarking with hint time 470.8 ms (187.8 ms .. 591.3 ms) 0.959 R² (0.878 R² .. 1.000 R²) mean 488.7 ms (447.3 ms .. 512.5 ms) std dev 36.99 ms (0.0 s .. 41.13 ms) variance introduced by outliers: 21% (moderately inflated) 
As someone who used to be a solid advocate of strong separation of view and controller (I wrote [heist](http://hackage.haskell.org/package/heist), a template system that is more aggressive about keeping logic out of the markup than anything else I know of), I was definitely concerned about the separation of view and controller at first. It took quite awhile to get used to, but now there's no way I would go back. For interactive SPAs, it just doesn't make sense to decouple view and controller IMO. You **want** them coupled for composability. I'll take Reflex's trivially composable widgets over standalone markup any day of the week. All this is not to say that we can't use Reflex in a way that separates them. `reflex-dom` uses a style that couples them, but there's plenty of room for building a layer on top that gives you the separation. I think it would be great to see more exploration in that area. But I suspect I personally will want to stick with having them coupled. CSS lets you get most of the view separation you need, so that a lot of styling can happen without ever touching the markup. &gt; compile times are something like 100x slower than Haskell This is a gross exaggeration. I just built my frontend with both GHC and GHCJS; GHCJS is not even 2x slower.
HPFFP seems big but it's very accessible and is _by far_ the best resource to start with.
Did you had the chance to read any of these? for now the most cited one is HPFFP :)
zsh itself supports bash completion, just add this to your .zshrc: autoload -U +X bashcompinit &amp;&amp; bashcompinit
Doesn't Facebook do hot reloading to add any new spam filters pushed to git on the fly? Does anyone know how they do it?
Yes. They're all good. I've listed them shortest and cheapest first.
Great to see [Using Coq to Write Fast and Correct Haskell](https://www.cs.purdue.edu/homes/bendy/Fiat/FiatByteString.pdf), having just listened to the latest [Functional Geekery Podcast](https://www.functionalgeekery.com/episode-101-adam-chlipala/) where Adam Chlipala talks about the approach and the [FIAT](http://plv.csail.mit.edu/fiat/) project.
Interesting name for that :) I'd probably describe part of my duties as Engineering Effectiveness currently.
I'd say *proper* IDE support. A few years ago I would have said something different I think, but after a year of doing mostly client-dev using TypeScript development inside Visual Studio Code it's hard to imagine being more productive in any other environment. Proper error reporting, proper cross referencing of identifiers, but most of all type directed suggestions. It's really excellent. I've tried Haskero (which uses Intero) and it was flaky at best. It *sometimes* worked for me, but mostly not.
I'm surprised there's still no half-decent Haskell IDE. It seems that the lack of large user base and rich type system that makes inference complicated are the main reasons behind this
It's hard to predict how things would actually go down, but moving ideas that work well across the fork boundary seems like it should be doable. For example, if Eta is around in 5y and Dependant Haskell is as awesome as we all hope, it'll probably end up in Eta as well.
Wow, thats just what I needed. Thank you.
Many are maintained, but mostly for research purposes (like UHC)
&gt; Homoiconic syntax i.e., bring in the parentheses :-) https://github.com/lexi-lambda/hackett
At the language level, it would be nice to see a bit more polymorphism: as more extensions are added which introduce asymmetries (e.g. linear types distinguishing between `-&gt;` and `-o`) it's important to avoid a combinatorial explosion of library functions. Dependent types can be pretty bad for this, since libraries can end up with many datatypes which are conceptually similar, identical at runtime, but with slightly different proof obligations. I remember a Coq project where I wrote a type for "lists of monotonically increasing values"; that simplified a bunch of proofs, but I had to write my own head, tail, map, filter, etc. The solutions I've seen for this (e.g. generic programming in Idris) end up with *horrendous* types. It would be really nice to solve this with something akin to parametricity, where such obligations pop out as free theorems, with only a little syntax (like `forall`) to enforce the necessary constraints.
And coherent type classes, and type families, and type inference of top-level functions.
&gt; and type families I'd argue that type families are superseded by Idris' dependent types. You can write functions returning types that look like any other function. There's no need to give special support for type level functions, unless I'm missing something.
At the infrastructure level, I'd like to see the various components of GHC be made accessible from outside the usual compilation pipeline. They don't necessarily have to be made "modular" (i.e. providing a stable interface for others to program against), but it would be very nice to fetch a particular version of GHC and be able to run its parser on some Haskell code; or to run its name resolver against a particular symbol and package database; or to infer the type of a particular sub-expression from within a bash script; or to resolve a typeclass instance given as a commandline argument; or to pipe the generated Core into a custom interpreter; or to send my own STG code into the backend; etc. Some of these are possible at the moment, through various GHC commandline arguments, or calls to the GHC API, or by hacking the compiler via Core-to-Core plugins, but it's a *massive* pain with all sorts of edge cases. For example, we can extract Core, but it may contain names which are either private to a module, or which come from an unexposed module, due to GHC's renamer choosing those as canonical. If we want to, for example, extract a list of dependencies and generate an import list for a .hs file, GHC will refuse to load it in these cases :/
But, you can't pattern-match on types, which makes open type families difficult at best.
[removed]
Thanks, Opaleye looks interesting. I've also just discovered your tutorials and something called [opaleye-gen](https://github.com/folsen/opaleye-gen) which looks promising. My initial concern about Opaleye is that in all the examples, a simple select by primary key seems to involve pattern matching on the entire database record: row@(_, _, em) &lt;- queryTable userTable -&lt; () restrict -&lt; (em .== constant email) This seems a bit fragile - if you then added a column to the userTable, it would break all the queries using that table. Edit: it seems you can just use record syntax to avoid this problem (I think)
I strongly recommend going with [Haskell Programming from first principles](https://www.haskellbook.com). It's very thorough and lots of exercises help you really understand how to write and read Haskell. FWIW, [LYAH](http://learnyouahaskell.com/chapters) and [RWH](http://book.realworldhaskell.org/read/) are both available for free online. LYAH is a decent whirlwind tour of Haskell syntax and concepts, but the lack of exercises makes it a poor choice for really learning the language. It was my first book with Haskell, and I don't feel like it helped much. Real World Haskell is a great book, but it is really outdated at this point. It's a good primer on a lot of real-world topics, but you'll need to have a decent enough Haskell background to understand how to update the code to current libraries and compilers. A more modern book that targets a similar audience is [Parallel and Concurrent Programming in Haskell](http://chimera.labs.oreilly.com/books/1230000000929/index.html) (also freely available online) -- the title is somewhat deceiving, because you'll learn a ton of stuff about GHC and real world Haskell topics like exceptions, profiling, garbage collection, etc. while learning about parallelism and concurrency.
There was a comment somewhere by Simon Marlow, maybe in his blog, that they build an object .o or .so (don't remember which) and then link the object at runtime to "swap" it in. IIRC he had to do some RTS changes to support it.
&gt; But somehow the serialisation based on the Typeable instance was not working for the return value Move (a simple enum with 4 constructors), always returning the first tag. If you have a small reproducible case, could you please [report this bug](https://github.com/mvdan/hint/issues/new)?
[Holland and Hart](https://stackoverflow.com/jobs/147022/software-developer-automation-engineer-holland-hart?so=i&amp;sec=False&amp;pg=1&amp;offset=0&amp;q=haskell) are a Boulder, CO office that are using Haskell as well :D
Created my first ticket: https://ghc.haskell.org/trac/ghc/ticket/14041#ticket To be continued...
There's `postgresql-typed`, which gives you a type checked SQL quasiquoter, which gets its types by checking your DB schema at compile time via template Haskell.
Isn't that just the expression problem all over again? I've yet to see a truly satisfying solution to it.
[Here](https://github.com/gelisam/hawk/blob/48eaef748076b6a4ae158cc02d26bb39e8e32b88/src/System/Console/Hawk/Sandbox.hs#L100)'s what I use to find stack's package database, and [here](https://github.com/gelisam/hawk/blob/48eaef748076b6a4ae158cc02d26bb39e8e32b88/src/System/Console/Hawk/Sandbox.hs#L128)'s how I pass the resulting path to hint.
Welcome to the records swamp! Idris does do that, but it also has type based overloading. It also doesn't have qualified imports, so you have to use the overloading. I've only used it lightly, but one thing that makes me ambivalent is that what should be an informative type error turns into an uninformative "couldn't pick an overloaded function" error. Especially in idris you really want the type error!
Parsec is in maintenance mode, it doesn't receive updates except to make sure it still works. Megaparsec is an actively developed fork of Parsec.
Is this some sort of song?
I can confirm that Typeable works, but it's brittle. My module wasnt loading because it's function signature was using `Html` which is some form of synonym of `MarkupM` it seems. I fixed it by importing the internal module in which the latter was defined. 
The function tail calling itself recursively, yes. Tail calling an arbitrary function passed in as a parameter, no.
Nah, I think I've just misused the API.
I'm definitely a haskell beginner, but just read the Transient docs and was blown away. It seems like a really great framework / model. Could you clarify though what you mean by Transient (or similar designs) limit you to simple types?
I am confused, this is a much different error; this is likely the result of [#14022](https://ghc.haskell.org/trac/ghc/ticket/14022).
One thing that stands out is that you are making extensive use of laziness. There are no strictness annotations anywhere and everything is expressed in terms of lazy tuples and lazy linked lists. This is almost a guarantee for bad performance, unless you really know what you are doing. Try to replace large lists with vectors from the `vector` package. Here's a quick guide on how to profile your code. Add this line to your cabal file: ghc-options: -fprof-auto -with-rtsopts=-p Then run: stack build --profile When you now run your code it should generate a file named `edmonds-matching.prof`. Let's take a look at it. The first few lines point you to the three most time consuming cost centers. COST CENTRE MODULE SRC %time %alloc shrink.keys'.\ Edmond.Algorithm.Core src/Edmond/Algorithm/Core.hs:97:34-50 32.0 2.3 adjustMap Util src/Util.hs:69:1-42 11.5 34.1 isScanned.s Edmond.Algorithm.Helpers src/Edmond/Algorithm/Helpers.hs:47:11-35 8.0 1.6 ... And then individual inherited COST CENTRE ... %time %alloc %time %alloc ... shrink 0.5 0.1 55.7 62.9 ... shrink.keys' ... 1.9 3.2 36.4 16.8 shrink.keys'.\ ... 32.0 2.3 32.4 2.3 hash ... 0.0 0.0 0.0 0.0 sparseIndex ... 0.4 0.0 0.4 0.0 The `shrink` method accounts for 55.7% of time and 62.9% of allocation. `shrink.keys'` accounts for 36.4% and the lambda in there for 32.4% of time. Here's the line: keys' = filter (\x -&gt; (ro !) x `elem` u) (vertices graph) Hashing and indexing look fine. The culprit seems to be the `elem` function, so I would recommend the use of `IntSet` rather than `Set Vertex`. And here is a line that's responsible for 43.5% of your memory allocations: ro' = adjustMapFor (zip keys' (replicate (length keys') r)) ro `length` is an expensive function, because it traverses the entire list. Then you use `keys'` again, so the list has to stay in memory. You might as well use a `Vector` here. Using strict types and functions should give you a significant performance boost. I hope this helps.
For the last line (setting `ro'`, would a special function along these lines also help? Ignore the stupid name: zipSelfWithDefault [] _ = [] zipSelfWithDefault (x:xs) d = (x,d) : zipSelfWithDefault xs d You only traverse the list once, this way. 
Oleg's [monad for undelimited continuations](http://okmij.org/ftp/continuations/undelimited.html#proper-contM), though, starts off with newtype CPS1 a = CPS1{unCPS1:: forall w. (a -&gt; w) -&gt; w} and he rejects that implementation only because it's impossible to write `callCC`, which is arguably inessential to something's being a "continuation monad".
That might work, but I would still go with vectors in almost any case, unless you are one of those people who are able to fine-tune their code for list fusion. I'm convinced that if vectors and strict tuples had been part of the Prelude all along, at least half of the beginners who dropped Haskell in frustration would now be part of the community.
It's mostly just the implementation. You'd want your ide to work when even your file have parser errors or when a module you depend on doesn't compile, but ghci doesn't load those modules and most plugins use ghci behind the scenes so you get an inadequate experience. It got nothing to do with having a rich type system. We need a haskell implementation that will still give information when things are broken and something is wrong. One that will do it's best to give you as much information as it can so you can still query the type of something or jump to definitions when you have parser errors and such.
Porting notes - here's what I changed: added where needed: import Text.Megaparsec.Char replaced Dec with MPErr and added: -- build with old or new megaparsec #if MIN_VERSION_megaparsec(6,0,0) type MPErr = ErrorFancy Void #else type MPErr = Dec #endif added these as Text.Megaparsec.String/Text.Megaparsec.Text seem to have gone away: type SimpleStringParser = Parsec MPErr String type SimpleTextParser = Parsec MPErr Text 
I'm really happy with this reply. As an application writer (that is, I write end-user programs in Haskell, not libraries) I don't think the main thing Haskell needs is yet more language complexity. Sure, every proposed feature is useful on its own, but taken as a whole, it can get pretty complicated. I think more documentation, better/simpler libraries, and compiler improvements (faster, more robust, better error messages) will have a much more significant impact. Haskell 2010 is already a significant improvement over most other general-purpose languages, let alone Haskell 2010 plus the most common GHC extensions.
this is extremely helpful!! (I took a look at most of these and gave up on them like a year ago.) as you say, I want the configuration to be a project, not a single file. my is thought is to just watch the folder and rebuild the project, then load a single object file that exports a value of the right "Plugin type", without providing any other context (i the .o themselves have enough information) . i've done this with the ghc api, but it's pretty fragile (like, it segfaulted on something with a similar type to something else that succeeded, like a rank2 field). i've seen "loadObj" functions in a few packages, but iirc, they still need to be supplied with some context. what's your recommendations for this use case? 
I used rapid for data that was 8gb in memory... Had to kill/restart ghci pretty often because it doesn't dispose correctly. Looked into fixing it but didn't have the time.
In my personal Haskell learning journey, I started with RWH and LYAH and I can't recommend either. RWH is more an intermediate level book and it's syntax is out of date in some places. I got stuck numerous times and even after trying to come back to it, reread chapters, etc. I still had a hard time following along and ended up abandoning the book about half way through. LYAH feels more like a tour of the available syntax of the language instead of a guide meant for teaching. It also stops abruptly before covering more complicated topics. I made it through LYAH, but was left with the feeling of 'well now what? I still don't know what to do'. I would recommend LYAH if someone was interested in Haskell, but didn't want to commit any money yet. The Haskell Book was the first book that I felt actually taught me how to use Haskell. It covers everything in the right amount of detail and is a perfect first book when learning Haskell. It still has some rough edges, but it is hands down, the best beginner resource currently. Once you get through the haskell book, you should be at a sufficient skill level to start understanding all of the amazing blog posts out there about Haskell. Once you get bored of reading libraries/blogs/tutorials, you can pick up the book Parallel and Concurrent Programming in Haskell, which covers a lot of the more complicated concepts in Haskell like multithreading, performance analysis, memory usage, etc.
I remember your talk. It was well presented and I very much enjoyed it! &gt; hslua FWIW: I took over maintenance of the package. I'm trying to clean it up and to make the interface a little nicer and safer. If you have ideas for improvements, I'd love to hear them. 
&gt; I remember your talk. It was well presented and I very much enjoyed it! Thanks :) That was my first talk at a conference, let alone in english and that's very affirming to hear. &gt; If you have ideas for improvements, I'd love to hear them. At one point, I started some type class based thing which would automatically try to infer the number of arguments and do the pushing/popping. There's an example and many loose ends [here](https://github.com/sgraf812/hslua-contrib/blob/master/src/Scripting/Lua/Contrib/Example.hs), with the implementation in [here](https://github.com/sgraf812/hslua-contrib/blob/1c21caf3e50ccb738d4987d7d5abc917f072ae08/src/Scripting/Lua/Contrib.hs), if you are looking for inspiration. I gave up at one point, because of shifting interests and because I discovered that `hslua` started something similar with [`callfunc`](https://hackage.haskell.org/package/hslua-0.5.0/docs/src/Scripting-Lua.html#callfunc). My approach tries to extract the signatures from the actual calls. This allows to distribute typed shims for existing lua libraries, in order to regain some type-safety.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [sgraf812/hslua-contrib/.../**Example.hs** (master → 1c21caf)](https://github.com/sgraf812/hslua-contrib/blob/1c21caf3e50ccb738d4987d7d5abc917f072ae08/src/Scripting/Lua/Contrib/Example.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dksyuys.)^.
Also, GHC is *very* slow. I'm sure there's a bunch of low-hanging fruit for improving performance, but in terms of big goals then it might be nice to: - Find faster algorithms than are currently used (for all sorts of things; type inference and checking; name resolution; module linking; etc.) - Find general Haskell performance improvements which "pay for themselves" (i.e. adding smarter algorithms to GHC might slow it down, but since it's written in Haskell it might also compile itself into a faster binary, more than making up for the slower algorithm). - Implement new mechanisms for improving performance, like we already have strictness annotations and rewrite rules. Maybe some limited sort of supercompilation, or staged compilation (e.g. once this input has been received, specialise the following functions to use its value...)
Why is it the case?
Agree very much with this. As dependent types come online in Haskell, it would be great to see something like a continuation of Conor McBride's work on Ornaments with compiler support (ie... if I write a datakind of lists, the language would have a way of decorating it into a sorted list or a size-indexed vector and then have list functions carry over to the refined datatype).
Homoiconicity is overrated. Racket went through many macro systems and finally settled on syntax-parse which has you working with... abstract syntax trees. That said, I would love to see something like Racket's readers+expanders language model with phases and a systematic account of identifiers and so on brought over to Haskell. Give me https://docs.racket-lang.org/reference/syntax-model.html but for GHC, basically.
Thank you for you input and detailed answer. But I think you are looking at the wrong code. I stated in my question that the interesting code is under the branch `hashtable`. The `master` branch is a naive implementation using maps. I understand that it can be optimized. The main problem though, is that this naive implementation is faster than the ST monad implementation I used in the `hashtable` branch.
I have a feeling that `doSomething` is in `Lib.hs`, so try adding `ghc-options:` to your `library` section of the cabal file instead of the `executable` section.
I'd love: 1. typesystem support for encapsulated benign effects (ie the stuff you put in `unsafePerformIO` and then hide behind a module boundary) 2. some way to write compiler-checkable cost model assertions (ie the stuff you put in a haddock comment that says `O(n)`) 3. Now that we have unboxed sums and products, how about unboxed recursive types (ie let's make Ocaml is just a mode of use of GHC with lots of `#`)
 I know how to profile my code, I left a .prof file in the `hashtable` branch, which shows that the cost centre lie mainly at the core functions in Data.HashTable, such as `lookup/go, writeArray, readArray` etc 
I'd say that's even underselling `lens`. I would go as far to say that the library level workarounds for lack of good record types (specifically `lens`) are actually more than good enough to make it a total non-issue, and actually make the overall record situation better than it is in most other languages. This may seem like an extreme statement. But no other (mainstream at least) language has optics that are first class and referentially transparent or even as powerful as the ones in Haskell. I mean lets take Python for example: `a.b = x` is not at all equivalent to `c = a.b; c = x`, and if `b` can be `None` `a.b.c` can never really work without a lot of extra effort, whereas nested failing accessors in `lens` are downright easy.
Thank for the pointer, but it is out of my depth for now.
Thanks, I'll check that out! I'm thinking about submitting a talk to this year's HAL. I would be about hslua, its internals, and the challenges that I encountered. Hope to see you in Leipzig.
You can add this to your `stack.yaml` ghc-options: &lt;Project-Name&gt;: -Wall 
That was it, thanks.
I would advise to either learn machine learning, or Haskell, but not both at the same time. They are both very deep topics, don't overwhelm yourself with too much new information!
I probably need to read up on Stack. Any reason why I would put it in stack.yaml vs the cabal file?
I would be very interested in that talk! Unfortunately, I have conflicting appointments that weekend, so I won't attend, probably.
I've been meaning to finish a post with some code that explains how we do this. With 8.2.1 and lts-9 out it might be time to put the finishing touches on it.
No particular reason, Its just another option (I think). Maybe someone with more experience can say something about It.
I'm also new to Haskell. I started with Learn You A Haskell (LYAH) and thought it was one of the best tech books I've read. I stopped at chapter 13 mainly because I heard Haskell Programming from First Principles (HPFFP) was a better way to get started. In retrospect I wish I had just finished off LYAH since there was only one more chapter left! For me, LYAH explained all topics really clearly though I did re-read the chapter on Applicative Functors and Monoids to really understand it. One problem I had is that even though I understood the material, I was still caught up on some basic things (like Haskell's indentation rules) when writing my own code. I'm now breezing through the first chapters of HPFFP, but since I'm still early on I can't really compare it to LYAH. I can see why people are recommending this for beginners. I like that it shows common errors newbies encounter early on in the book such as Haskell's indentation rules, associatively rules, etc. The exercises also help reinforce the material. It also may cover more material than LYAH - such as testing. One thing I found strange is a couple of times it seemed to use terminology before it was explained (but since I had read most of LYAH it was not a problem). Also, I think the first chapter on lambda calculus may scare people away from Haskell :) As far as format, I prefer reading LYAH online versus HPFFP's PDF format. LYAH is also nice as a reference. I guess it can't hurt to read both :) EDIT: I should add that it helps to have a good editor. I was using VS Code without any sort of syntax highlighting while going through LYAH. After installing stack, intero, and the VS Code extension Haskero I feel more confident actually writing real code.
Urge to start a Haskell implementation…rising…
Totally right. Don't bite off more than you can chew. 
A vey simple classifier that could work would be a Bayesian filter. I had a go at this in Haskell a few years ago: https://github.com/cbowdon/TweetFilter It was when I was a Haskell noob (still am) so apologies for code quality. But I did make a lot of notes on how it works that should be useful for your case. 
That actually doesn't sound too bad given what you're getting with `hint` in return! Cool!
Yes, it is thoroughly implied by the remainder of the operations.
So then as of now is it pretty reasonable (modulo backwards compatibility) to build `Arrow` on top of categories and profunctors?
It's generally preferable to put options in the Cabal file so your project works with more tools
Thanks @gelisam, @cbowdon. I agree with you.
More educational material would be awesome! The monad tutorial fallacy is a real thing.
A simple function being what? Hint can easily eval a simple function it's practically a few lines.
Mutable arrays are really sensitive to GC settings, and there's a long-standing GHC GC issue with large `MutableArray#` objects being scanned by only one core during stop-the-world GC. I've been meaning to have a go at fixing this for years, but until then I wouldn't expect great performance out of the hashtables library.
I noticed you have a record defined like so data Graph s = Graph { forward :: Data.Graph.Graph , backward :: Data.Graph.Graph , forest :: AlternatingForest s , scanned :: ST s (HashTable s Vertex Bool) , dimension :: (Int, Int) , currentX :: Vertex , currentY :: Vertex } I would suggest making all the fields strict, i.e. put `!` before all the types. Do the same for all other records you define. I'm rather puzzled by `scanned :: ST s (HashTable s Vertex Bool)`. Why not `scanned :: HashTable s Vertex Bool`? In any case I don't see why this should be causing any slowdown. Like others, I would also suggest vectors rather than lists. By the way, your code is very nicely written! EDIT: You seem to be calling `length` on lists a lot. This is a *bad idea*^TM, although it doesn't explain why the ST version is slower. 
Well, there is a HSOC project to get the [haskell-ide-engine](https://github.com/haskell/haskell-ide-engine) to function as a [language server](https://github.com/Microsoft/language-server-protocol) which is coming on really well at the moment. See the latest [progress report](https://github.com/haskell/haskell-ide-engine/blob/master/docs/Report-2017-07.md)
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [haskell/haskell-ide-engine/.../**Report-2017-07.md** (master → 2837587)](https://github.com/haskell/haskell-ide-engine/blob/28375872c5ef7e15a4f8ad1e21413bc04d24d83a/docs/Report-2017-07.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dktbhrm.)^.
Thank you very much! It looks helpful to me. But I think I need different algorithms for classifying rather than spam filtering algorithms. Doesn't it?(Just curiosity)
Are you sure that .prof file corresponds to the lastest version of the code? It contains an entry shrink.\ Edmond.Algorithm.Core src/Edmond/Algorithm/Core.hs:(140,24)-(142,41) 11.6 1.2 Those line numbers don't actually correspond to a lambda.
I'm also puzzled by `mu`, `phi` and `rho`. Why are they wrapped in `ST s`? It makes no sense. I don't think it can be causing any slowdown because you only set them with `return`, but it is odd! EDIT: In fact you are using `ST` in a bizarre way. You're looking up the location of a hashtable (say `scanned`), adjusting it in `ST`, and then writing its location back into the `Graph`. Writing it back is completely redundant!
Good job getting it working, `stack exec atom` was a good thing to ry! LTS Haskell 9.0 has just hit stackage which contains the latest tidal. To change your global project to this set of packages (called 'resolver' in stack speak) edit `~/.stack/global-project/stack.yaml` and make it say `resolver: lts-9.0` instead of whatever resolver you have from before. Then reinstall tidal, which may cause a new version of GHC to be installed depending on how old your resolver was.
Try `stack build --pedantic`. ETA: This will make your build fail, not just give a warning. https://docs.haskellstack.org/en/stable/GUIDE/#ghc-options
Why did you remove Karamaan? We still use Haskell. We're not currently hiring (but we might be in the next six months).
I've never heard of hint until now so maybe it is a solution to my problem. When I mean function Inna configuration file, l don't mean a function to be evaluated once when reading the configuration but function that needs to be used all the time. For example, I'm working on a program adding variations capilities to FrontAccounting (an ERP written on PHP). FA doesn't have the concept of variations and only reference product by their sku. Our company have a name scheme to encode variation in the name. For example a red t-shirt will be called `TShirt-RED` and blue one `TShirt-Blue`. That seems pretty straight forward however, I often need to split this name into style and variation (which would be style = 'TShirt' and variation either Red or Blue). This is needed for example if you want to know the performance of the style `TShirt` regardless of its colour. At the moment the function to split a SKU to style/variations is hard coded. The code is open source so others can use what I am doing but it really likely that there naming scheme is different from mine and therofere needs a different splitter. Being able to provide a splitter function in a configuration file would be brilliant. At the moment the best I found is to provide different type of splitters and let the user chose and configure one in a configuration file. 
a lot of packages with many reverse dependencies might not be ready for 8.2 (base version bounds too tight). some might not also be compiling.
A spam filtering algorithm is a classification algorithm. It classifies things to be spam or not spam.
Good points. I will look at our budget and schedules and see if we can afford to do another survey soon -- not only to get an update, but also to learn more about the needs (and success stories) of the increasing number of [companies using Haskell in applied settings.](https://www.reddit.com/r/haskell/comments/6p2x0p/list_of_companies_that_use_haskell/) 
Happy to see Wiegley's [una program]( https://github.com/jwiegley/una) as package of the week. I think it's a really underappreciated higher-level alternative to using tar/unzip/etc directly. Example: [~/Downloads/una-test]traveller@nixos $ ls jdk.tar.gz peace.zip [~/Downloads/una-test]traveller@nixos $ una jdk.tar.gz Extracted directory: jdk [~/Downloads/una-test]traveller@nixos $ una peace.zip Extracted directory: peace [~/Downloads/una-test]traveller@nixos $ ls jdk jdk.tar.gz peace peace.zip If you're using Nixpkgs, it's in there as `haskellPackages.una`.
&gt; Though the idea's on point, you have some unfortunate typos in there I appreciate the generosity of calling any errors or oversights I make "typos" :-) If there are genuine typos in there, I claim the defense that I wrote that post on my mobile, on the bus. &gt; To make everything pedantically explicit... A nice read, thanks. I fully admit generous helpings of handwaving in my post :-)
Speaking as someone who works on production Nix, it's not really a research project the way you think it is. The single biggest issue with Nix is educational barrier to entry (similar to Git or Haskell), but it really is quite feature complete and usable. I would guess that _more_ things are packaged for NixOS than Ubuntu, if only because we autogenerate package sets for entire language ecosystems at a time (Haskell and R are fully automated, Python and Erlang and NPM are mostly automated, and anything that uses GNU autotools or CMake is pretty trivial to package).
Uniqueness types are not "less than" linear types, they're just fundamentally different (though you can fit both into a lattice that also includes relevance and affine type systems). In fact, last time I talked to /u/edwardkmett he convinced me that we probably actually want uniqueness types in Haskell, not linear types.
[This](http://bentnib.org/quantitative-type-theory.html) is relevant to #2 and [this](http://recurial.com/wp-content/uploads/2017/06/ecoop_submitted_5_17.pdf) is relevant to #3.
Write it in Kitten! :)
`adjustMapFor` and its symmetric version each use `foldr` to accumulate a `HashMap`. Surely they should use `foldl'` instead. I don't know how much trouble that's causing you, but the trouble is unnecessary. (Oh, that's the wrong branch! But it's still a point.)
If I try to do that, I’ll just end up working on Kitten and never get around to the Haskell part. That might not be such a bad thing. :P
I've come to believe that what people actually want when they say they want homoiconicity is better described as "syntactic abstraction" (a description shamelessly stolen from the [posts](https://lexi-lambda.github.io/blog/2017/01/05/rascal-is-now-hackett-plus-some-answers-to-questions/) introducing Hackett). I can't think of a language with good syntactic abstraction that doesn't have the ability to "[read without parsing](http://calculist.org/blog/2012/04/17/homoiconicity-isnt-the-point/)".
Nix is cool, but it's definitely on the perfectionist ("let's find the actual root of this problem and solve the shit out of it") end of the spectrum. It succeeds in doing that, and it's usable, but it has mediocre ergonomics and changing that isn't a priority. 
I know you can use linear types to encode uniqueness guarantees (using continuations); can you do the converse? Do you have a gist of what Ed said to convince you? I have the feeling that we want both for different things.
Oh, sorry. The webpage was gone so I figured you had gone bankrupt like a few others. Re-adding :)
In a web-app development workflow, what does rapid keep in the foreign-store? Aren't most webapps/webservers stateless to begin with? 
Better: here's a [Text.Megaparsec.Compat](https://github.com/simonmichael/hledger/blob/d7d5f8a0645c558b62a16542056739b520b39641/hledger-lib/Text/Megaparsec/Compat.hs) module, useful for supporting megaparsec &lt;6 and &gt;=6. That was.. not so easy.
I think you want: #if MIN_VERSION_megaparsec(6,0,0) type MPErr = Void #else type MPErr = Dec #endif You index `Parsec` by custom component of parse error, the `ErrorFancy` wrapper will be added by the library itself.
Come to think of it, the way Haskell works generally is to do the type-correct thing as conveniently as possible, and not to care so much about the explicit location of evaluation costs.
Are you seriously suggesting that implicit deep copies are an even remotely acceptable thing to do when dealing with linear types? Because I hope you know that will not go ever well with even a small fraction of the community. It needs to be explicit, and people will not accept it if it is implicit.
Very doable! You "just" need to write a data type for your SQL queries, and then parse the `String` into them. Any parser will work, `Happy`, `Megaparsec`, `attoparsec`, etc are all fine.
I suspect it's fine in practice. Splits will happen exactly where they are required, that is, wherever the user has chosen to include more than one consumer inside a function.
Note that using `ST` like this means that it's possible you're re-allocating the entire hashmap for every step of your computation (I haven't grokked enough of the code to check if this is the case). You almost certainly want `data Graph s = Graph {..., scanned :: !(HashTable s Vertex Bool) }`. Then the functions manipulation graphs should look like e.g., `loadMatching :: Graph s -&gt; [Edge] -&gt; ST s ()`. `()` being kinda-sorta like `void` in an imperative language. 
I mean I suppose it doesn't really matter since linear implicit parameters aren't going to happen. But I can absolutely guarantee if we get full fledged linear types then implicit `split` is definitely NOT going to be a thing.
Why not use `map` and `TupleSections`?
What's really odd is that [the Bernardy et al proposal paper](https://github.com/tweag/linear-types/releases/download/v2.0/hlt.pdf) doesn't mention LIP, even though Simon PJ is listed as a co-author and must surely remember implementing it. Instead: &gt; Despite their obvious promise, and a huge research literature, linear type systems have not made it into mainstream programming languages, even though linearity has inspired uniqueness typing in Clean, and ownership typing in Rust. We take up this challenge by extending Haskell with linear types.
It's decent, but I'm trying to find a way to make it even better. Each of these individual slowdowns that one compromises with, add up to quite a lot in the overall picture.
For any real-life use-case you HAVE to use records to represent DB rows (but the ability to do that comes with a shitload of boilerplate). And then use lenses to do something like this: r &lt;- queryTable userTable -&lt; () restrict -&lt; (r ^. email .== constant email_)
Could be an extension though? Instead of giving an error, the compiler could insert `split`, which may or may not be implemented for the type. That way the creator of a given linear type could decide for themselves whether to allow implicit splits.
It'd be great if someone could test this PR on Windows. Once this is merged, I'm going to set up binary releases using GitHub Releases for major platforms.
The installation instructions are available at https://github.com/maoe/ThreadScope/blob/9ab0eeeff4a96cd2374ce03c576e709524e0ba30/README.md
&gt; it's possible you're re-allocating the entire hashmap for every step of your computation I don't see anywhere that re-allocation would be happening. Every time a new `ST` action is constructed it's just `return` of an `ST` object that's already been constructed.
Thank you for doing that! I started using it in the threadscope project and is working great.
If you want to parse proper sql, there already exists some parsers such as simple-sql-parser and hssqlppp.
May I request you to reconsider your thesis topic. Why not pick one of the existing SQL DSLs in Haskell and make them better? Some ideas: * Implement compile-time type-checking of SQL queries in HaSQL * Implement a better query generator for Opalaye (currently the queries are extremely nested and stress the PG query parser/optimiser) * Implement prepared SQL statements in Opalaye or PG-simple
In `Edmond.Data.AlternatingForest` try replace `HashTable.new` with `(traceM "new" &gt;&gt; HashTable.new)`. There's a lot of *new*s. That's my extremely unscientific analysis, anyway. I don't know if that's expected or not for the algorithm here. The point I wanted to make though is that a more concrete type at least removes this question entirely.
Yes! I like these suggestions quite a bit!
There are many small inefficiencies here, and they add up. I'd also use immutable HashMaps from the unordered-containers packages, and I doubt using mutable hashtables will be faster. [initialize](https://github.com/lsund/edmonds-matching/blob/hashtable/src/Edmond/Data/Graph.hs#L38) The number of vertices can be found in O(1), since it's just the length of the array of vertices. Use `transposeG` to find the reverse graph. You use `length . Data.Graph.vertices` twice, better reuse `nv`. let xs = map fst matching ys = map snd matching updateSymmetric graph Mu (zip xs ys) Why not `updateSymmetric graph Mu matching`? No need to deconstruct and reconstruct. (forw ! v) `List.union` (backw ! v) Don't use List.union, it's quadratic! Use Data.Set.union instead. [toMatching](https://github.com/lsund/edmonds-matching/blob/hashtable/src/Edmond/Data/Graph.hs#L65) This is O(n) on the size of the HashMap. If you need to use this often, perhaps you could store a separate HashTable where k &lt; v? lookedUp &lt;- HashTable.lookup scanned' k case lookedUp of Just flag -&gt; return flag Nothing -&gt; return False This is just cosmetic, but I'd use `fromMaybe False &lt;$&gt; HashTable.lookup scanned' k` 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [lsund/edmonds-matching/.../**Graph.hs#L38** (hashtable → 7669526)](https://github.com/lsund/edmonds-matching/blob/76695263bb1851550d51fa3c6e76fb0cdade969b/src/Edmond/Data/Graph.hs#L38) * [lsund/edmonds-matching/.../**Graph.hs#L65** (hashtable → 7669526)](https://github.com/lsund/edmonds-matching/blob/76695263bb1851550d51fa3c6e76fb0cdade969b/src/Edmond/Data/Graph.hs#L65) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dku1fpo.)^.
&gt; But I think you are looking at the wrong code. Oh, my bad. &gt; I left a .prof file in the hashtable branch That file doesn't seem to match the rest of the code, however. &gt; which shows that the cost centre lie mainly at the core functions in Data.HashTable My own profiling shows the exact opposite. Here is a breakdown of the most expensive cost centres. CC entries Time Alloc Data.HashTable edmonds.graph 0 97.9 97.4 findRoot 2054 97.7 97.2 findNeighbour 6760 65.8 63.7 findM 6760 5.1 5.0 findNeighbour.pred 35504 4.7 4.5 getVertex 35504 1.0 1.2 lookup/go 71009 0.6 0.6 X newSizedReal 0 0.1 0.3 X newArray 6896 0.0 0.1 X grow 5197 60.1 58.2 augment 1692 58.7 57.6 shrink 1202 56.6 56.1 shrink.\ 1177960 26.1 25.2 getVertex 1177960 20.1 23.4 lookup/go 1177974 8.5 8.3 X readArray 1177974 2.5 5.0 X toPtr 1177974 0.0 0.0 X fI 0 0.6 2.7 X readArray 0 0.5 0.4 X newSizedReal 0 6.4 10.1 X newArray 277340 0.4 2.5 X So `lookup/go` is the relevant hashtable core function, and it accounts for maybe 10% overall time, at most. There also seem to be many calls to `newArray`, but that's most probably part of the algorithm and it seems to cause no slowdown, most of which probably comes from things that were mentioned in other comments. 
You should also consider the possibility that GHC and it's ecosystem is currently not well suited for mutable hash tables. Take a look at [this](https://www.reddit.com/r/haskell/comments/2le78y/haskell_hash_table_performance_question/). `Data.HashTable` should be somewhat slower than mutable hash tables in other languages, but they shouldn't perform dramatically worse, like 20x slower. If that happens, the problem probably lies somewhere else.
&gt; The point I wanted to make though is that a more concrete type at least removes this question entirely. Does it? You have to zero out the hash table one way or another. Sounds like it's always going to re-allocate a hashmap whatever way you cook it.
I just skim-read your code but I can see a couple of things you might consider. Your string code is typed as `IsString s =&gt; s`: it's a function which calls `fromString` which has to consume a large list. Also, your benchmark is measuring the IO cost of writing the file, not just the computational cost of generating the output.
You can do this. The downside is that it's extremely uncomposable. How do you reuse `usersSql` in another query? With great difficulty, I expect.