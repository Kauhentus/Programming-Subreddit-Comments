The types talked about in #haskell-lens are correct. Here are some examples of how you'd use this definition of a Traversal. import Control.Applicative (Applicative) import Data.Foldable (fold) import Data.Monoid (Monoid) import Data.Traversable (traverse) data Traversal s t a b = Traversal { viewT :: s -&gt; [a] , setT :: [b] -&gt; s -&gt; t } -- invariant: length of [a] result of viewT must match length of input to setT -- boring but correct traverseList :: Traversal [a] [b] a b traverseList = Traversal { viewT = id , setT = const } -- A more interesting traversal traverseFirstThird :: Traversal (a,b,a) (a',b,a') a a' traverseFirstThird = Traversal { viewT = \ (a,_,c) -&gt; [a,c] , setT = \[a,c] (_,b,_) -&gt; (a,b,c) } traverseOf :: Applicative f =&gt; Traversal s t a b -&gt; (a -&gt; f b) -&gt; s -&gt; f t traverseOf tr f s = fmap (\bs -&gt; setT tr bs s) (traverse f (viewT tr s)) foldOf :: Monoid a =&gt; Traversal s t a b -&gt; s -&gt; a foldOf tr s = fold (viewT tr s) set :: Traversal s t a b -&gt; b -&gt; s -&gt; t set tr b s = setT tr (map (const b) (viewT tr s)) s
&gt; taking 5 minutes before you cabal upload. I'm all for documentation, but let's not pretend that 5 minutes is nearly enough time to sufficiently document anything. Docs take time. Examples take time. You know what can be worse than missing documentation? Wrong documentation. Let's admit that documentation takes time, and commit to take the time to write good docs. We can't just pretend like the problem is of such little severity that 5 minutes is enough to fix it.
And of course this is about 10,000 times more true when it comes to lens.
Also, there's a slightly better type to use which allows you to reuse the pattern match on 's': import Control.Applicative (Applicative) import Data.Foldable (fold) import Data.Monoid (Monoid) import Data.Traversable (traverse) data Traversal s t a b = Traversal (s -&gt; ([a], [b] -&gt; t)) -- invariant: length of [a] result of viewT must match length of [b] -- boring but correct traverseList :: Traversal [a] [b] a b traverseList = Traversal (\xs -&gt; (xs, id)) -- A more interesting traversal traverseFirstThird :: Traversal (a,b,a) (a',b,a') a a' traverseFirstThird = Traversal (\(a,b,c) -&gt; ([a,c], \[a',c'] -&gt; (a',b,c'))) traverseOf :: Applicative f =&gt; Traversal s t a b -&gt; (a -&gt; f b) -&gt; s -&gt; f t traverseOf (Traversal tr) f s = fmap k (traverse f as) where (as,k) = tr s foldOf :: Monoid a =&gt; Traversal s t a b -&gt; s -&gt; a foldOf (Traversal tr) = fold . fst . tr set :: Traversal s t a b -&gt; b -&gt; s -&gt; t set (Traversal tr) b s = k (map (const b) as) where (as,k) = tr s 
&gt; David Spies has run into an interesting situation: why does -O make his program slower instead of faster? the link is to monthly thread, not to topic thread
But is there already a web service set up to do this?
I've been excited about getting something like this forever. There will be _lots_ of possibilities opened up by this.
&gt; There will be lots of possibilities opened up by this. Could you explain some of them?
You'd still need moderation though to make sure the comments are factually correct and reflect the intended usage rather than exploit edge cases, and that there are no gotchas that the commenter is unaware of. 
Yes, but it'd be weird - the radix would be each path element rather than each (say) character. So: O / \ user/ o o users/ / \ id o o name For, say, { "user/", "users/name", "users/id"}. At least, I can't think of any way of any way of splitting up a single `GHC.TypeLits.Symbol` into its characters... And even if that were possible, it'd probably make the internals more complicated. Which is not to say that maybe this weird radix tree isn't the way to go! I in fact think it is, but thought we'd probably still want binary search for the children-lookup step...
Obligatory "Are you sure you don't want a parser combinator library?" comment.
Yup. ocharles had a [post](https://ocharles.org.uk/blog/posts/2014-12-08-type-operators.html) about it a couple of days ago. I might have misunderstood your second question, but yeah, the client functions will be typed, so if the client code expects an endpoint to return a `User` but instead it returns a `Banana`, then it won't typecheck. 
Do you know why can't they use jquery? (Just to try to get a sense of whether this is a common use case)
No but this might be good, since you probably route by path steps anyway? To get to /users/id it would require to do 2 checks only
Sure, that would certainly be possible. Like I said elsewhere in this thread, `HasServer` instances can describe a mix of IO and decoding, so you could access that session id by accessing the cookie, perform some IO to look the ID up in a database, fail with some precise HTTP status code if not present, keep going otherwise. That's definitely possible and I would even like to see a package with that kind of "non-standard" combinators into an "-extras" package that could serve as a testbed and provide the community with those "features missing from the core package". Right now, all you can do out of the box re. auth is use the usual HTTP auth headers, but I believe the three of us put our apps behind [sproxy](http://github.com/zalora/sproxy) so we tend not to care about auth in our webservices, it's already handled for us upfront. However, if you're looking for a solution like the one you described above, we'd be glad to help you write it!
&gt; Does the different representation make a difference in what error messages are possible when routing falls? No, we can make the type that represents a routing failure's reason grow and make its textual representation carry a precise error message. We just do not have that many reasons to fail entering a route, yet, but could definitely do with more of them. &gt; Please don't take my comparisons to wai-routing negatively. I ask because they both seem like compelling routing choices. Oh we certainly don't take that negatively, don't worry about that! Our approach is partly inspired by all the routing libraries out there on hackage (we had to try to make ours "look a bit like the existing ones", so that "endpoint types" could be read easily), so trying to be more like them in (e.g) error reporting quality is definitely something we want! :) 
What if you could for any function or data type find examples of its usage in other hackage packages? I know that this does not solve the documentation problem, but would it be helpful at all? People write "examples" by using the library.
And I disagree with them ;) I think things like GADTs, free monads, etc. actually help structuring your program and help when working with a team. But as I never worked with a team, I suppose my POV is not very interesting.
Exactly. The client function's type is __derived__ from the API's type, so if you try to "misuse" them, trying to fetch `Banana`s instead of `User`s, your code will just not compile. As for the Javascript generator, well, you know you're on your own there... =)
That'd be very easy. I think it's about rewriting 1 function, the one that turns a big ADT that contains all the endpoints (and the captures, params and what not for each endpoint) into a big string of javascript code. I just went straight for jquery as I'm already using it and it does make one not worry too much about the proper way to initialize and perform an async request. Let me know if you want to have a "purer" way package up one of these days, we could both work on that.
&gt; now I see that it appears to be more appropriate to just use kind `*` In the presence of promoted data kinds (kind-only data is not yet in GHC) there is this trick to integrate `*` into a DataKind: data MyKind star = Foo Otherkind | Starry star and then pass `*` explicitly: `MyKind *`. 
We'd need a benchmark to measure the impact, but I'm pretty sure this would improve the routing's performance significantly, especially when plenty of endpoints are grouped under a particular static string, which happens quite often. Say you have `/products` with other endpoints under it, and `/users` with the same number of endpoints under it too. By just looking at the first path fragment you eliminate half of the candidates, whereas our current strategy is to linearly try the endpoints. If you've requested the last endpoint under `/users` you have to go through all the others first...
The hxt-regex-xmlschema library supports the XML Schema regex standard. It supports String, Bytestring (strict and lazy) and Text (strict and lazy). 
I don't understand how you can talk about negation if you take *double-negation* as a primitive -- or are you suggesting that it should desugar to something like `forall b . (a -&gt; b) -&gt; b`?
The haskell wiki has a [comparison](https://www.haskell.org/haskellwiki/Regular_expressions) of the different regex packages. Nothing about `Text` support though.
Sending functions to remote machines, e.g. implementing tightly-bound servers which must all be running the same code. Examples relevant to me include continuous integration systems and grid computing.
What do you mean by "viable"?
Indeed, this is basically a huge set of OpenGL calls and shaders. However, OpenGL is really badly designed in hindsight, it's fully stateful, so abstraction can help a *lot*. There is some non-trivial geometry generation on the CPU, which uses the standard isosurface (well, in this case 2D, so isocontour) algorithm - that part is brute-force computation and is in C for speed reasons. I think Haskell mostly helps in the following parts: * very easy to abstract things, to refactor; in general it's just a convenient language to use, with nice syntax (which you can also abuse for sugar) * easy to hack (types help not to make mistakes, and syntax makes it easy) * there is a mini-DSL here for arranging the layers of post-processing effects to OpenGL's liking * timing could use some FRP-like thing, though it does not, yet (instead, there are pages and pages of guard conditions :) * in general there is always place for more abstractions to make things easier (the other demo uses a big 3D engine in Haskell, which also abstracts shaders etc)
The glitchy stuff here divides the screen to smaller parts, and applies different offset, colors, textures, and postprocessing effects to different parts. This is supposed to "emulate" byte errors in jpeg/mpeg streams. Also some very typical distortions are, from the CRT era, when the RGB beams are shifted from each other (typically depending on screen position). Another ("VCR look") when the lines are shifted from each other. These all can be combined. What I usually do is to search for source material (for example on google image search; there are also a large number of blogs out there dedicated to such stuff), analyze those and try to reproduce the effect.
Let me rephrase: it's extremely ugly. Also I'm kind of perfectionist in nature, so I don't like releasing ugly stuff. Sorry about that. But I plan to polish more and more reusable parts, and release those (time is always the bottleneck...)
Tweag I/O founder here. The motivation for this was to make distributed programming, be it using Cloud Haskell or other libraries, a *lot* easier. We have a number of distributed programming projects on the go and the Template Haskell was just getting too painful for us. ;) The ambition is very much to turn Haskell into a better alternative to Erlang across the board. A much more mature and performant execution environment that compiles down to native code, better GC, SIMD support, GPU programming, better syntax, not to mention the static guarantees GHC's type checking provides... If something is easy in Erlang, then there's little reason we can't make it equally so in Haskell. This extension should go a long way towards that, but there is more work to do! We have patches for [distributed-process](http://hackage.haskell.org/package/distributed-process) to make use of this extension but it's still work in progress. And down the line, we'll need a much better story for interoperating heterogeneous versions of a binary deployed across a cluster. But hey, we're finding demand for this from industrial users, so there's potentially plenty of resources to throw at this. If you're interested in joining the effort, contact me and make sure to sign up to [distributed-haskell@](https://groups.google.com/forum/#!forum/distributed-haskell) and [cloud-haskell-developers@](https://groups.google.com/forum/#!forum/cloud-haskell-developers). Well-Typed have contributed a great initial implementation of Cloud Haskell a couple of years ago and we have an active community working to improve it and maintain it.
I used pyramid's traversal [1] based routing to do this in python - not typesafe obviously, but it's a very nice way to build api layers in python. Here's a sketch: https://gist.github.com/boothead/5108455 [1] http://docs.pylonsproject.org/docs/pyramid/en/latest/narr/traversal.html
re/ grid computing: Pushing new code will still be difficult, right? In a continuously running grid (e.g. unbounded stream processing), deploying application changes will require a stop-and-restart on the entire grid even with stable pointers. I'm not sure this can be avoided short of some dynamic recompile/linking and seems like a relatively significant ops headache. Still a great development... It will be nice to ship a "StablePtr a" over to a remote node and be done with it.
There is nobody claiming that documentation is unnecessary. It's a great big lie that gets wheeled out every so often so someone can feel smug about lambasting "the community".
What about a LHS file, containing well documented test cases, testing the common usage tasks?
I think what is missing here is a simple converter, processing GitHub Markdown and interpreting it similar to a LHS file. With this, the README.md could be executed as part of the integration.
While the blog post itself might not be incredibly interesting, I think it could serve as grounds for interesting discussion. At the very least, I'd like to see a different perspective on it than what I'll see over at /r/clojure. [Here's the original discussion on /r/clojure.](http://www.reddit.com/r/Clojure/comments/2oup5g/parsing_and_rendering_templates_in_clojure_and/)
It's not that these are not nice things, but they're not Haskell yet. I don't understand how you can refute his third point though.
I love Haskell, but let's not bend the facts. &gt; A much more mature (...) execution environment Erlang runtime is as mature as it gets. Haskell is much younger and less battle-tested. &gt; that compiles down to native code It's not always an upside. &gt; better GC Erlang GC is *different* it's neither better nor worse. For latency-critical applications it's better though. There's no global GC pause at all as GC is per-process (thread, not OS process). &gt; If something is easy in Erlang, then there's little reason we can't make it equally so in Haskell. Erlang has late-binding semantics. Many day-to-day constructs are difficult to type. It certainly is possible to work around this, but it's not a direct translation. 
Sorry, but yr wrong. For instance the `lens` library, it is explained with a lot of docs, that even "dumb down" the types so mere mortals can understand them. Sure `String -&gt; IO Int` is easy to grok, but what about: type Prism s t a b = forall p f. (Choice p, Applicative f) =&gt; p a (f b) -&gt; p s (f t) I need docs for that, at least to get started with it. And with me many others. Thanks for the docs everyone! (or we would be stuck in beginners-Haskell for ever)
...doesn't seem to operate on `Text`-strings though?
`:&gt;` has kind `k -&gt; * -&gt; *`.
&gt; I'm all for documentation, but let's not pretend that 5 minutes is nearly enough time to sufficiently document anything. I'm saying that the time it takes to write a single simple example of usage can often be on the order of ~5 minutes not that that it takes 5 minutes to write full documentation. The problem can't be solved with this fix alone just that doing this is the *minimal time investment* needed to make your library infinitely more approachable than a haddock full of amorphous signatures.
If you can have multiple versions of your code running on the grid simultaneously, you can pull down the old versions once they are no longer running. There is a fair amount of coordination required, but I believe Facebook take this approach with their Haskell.
There's at least one use case when you absolutely need regexes. It's when your application gives user ability to search or replace text with regexes.
This is great. Documentation is important if Haskell is going to gain adoption!
I don't think anyone claims no docs are awesome, but I do think that Haskell has[0] a belief that docs aren't super critical components of a library. I'd propose an experiment to test this. I'd like to create a measure which is something like "the number of libraries with [*first contact* and *the black triangle* sections](http://www.reddit.com/r/haskell/comments/2osdcz/teach_dont_tell/cmq940o)" weighted by downloads as a proxy for users". If you subtract this from the total downloads count/user count then you get a rough measure for "learning pain attributed to lack of intro docs". My belief is that Haskell has some great examples of these documents (here's [wreq](http://www.serpentine.com/wreq/) but will score much higher on learning pain both net and per capita (e.g., what's the probability that a user will experience learning pain) than languages which have an emotional core focused on good documentation—let's say Ruby and Javascript, perhaps. The fix is really obvious—any high-powered production library author should make a `author.github.io/high-powered-production-library` website and spend some quality time writing [*first contact* and *the black triangle*](http://www.reddit.com/r/haskell/comments/2osdcz/teach_dont_tell/cmq940o) documents. These documents should exist for even the most basic libraries, too! I'm looking at `transformers`, `containers`, `text`, `bytestring`, `parsec`, `attoparsec`, `deepseq`, `exceptions`, `mtl`, `time`, `async`, `split`, `stm`, `syb`, `vector`, `parallel`, etc. [1] [0] by which I mean "the average emotional core of the Haskell community has". Many, many great counterexamples exist, but they remain outliers. [1] some of these might actually have these documents and if they do I apologize, but I'm not aware of them
I'm talking about the desugaring of negation as mentioned in the article, where "¬a" is "a→⊥"
Not sure right now, but can you try out `OverloadedStrings`?
Do you think it would be possible to write a conceptual introduction document even when you still have the feeling that you'll need to gut the internals? I think these conceptual intros, targeted at novices, are high value targets and should be the first thing someone potentially sees when examining a library. I also think that it's possible to write them in such a way that they're robust to changes in all but the most gross structure of the public API. I think they require a lot of conceptual work—you must have gotten to the point in design where you understand why someone would care to use your library—but relatively less actual writing work compared with API docs, for instance.
I meant more mature in the sense of having a compiler, rather than relying comparatively less sophisticated byte-code interpretation. The compiler isn't all that young anymore (it was first started in 1989 I think) and has by now accrued decent support for a lot of hardware features that is relevant for intensive computations (e.g. the ability to use the SIMD instructions on your processor). I should have been more clear about what I meant when I said "execution environment". &gt; There's no global GC pause at all as GC is per-process (thread, not OS process). That's true. OTOH one nice thing about GHC is that the concurrency primitives don't prevent you from sharing state, when communicating information intra-node. It's not shared state per say that introduces complexities in concurrent systems, but rather shared *mutable* state. Cloud Haskell these days does share messages between processes - that's safe to do since they are immutable. &gt; Erlang has late-binding semantics. Right. So just as with any odd scripting language with late binding, or some form of runtime code generation, idioms arise that are just not a good idea in a language with static binding. One feature of Erlang is the ability to hot patch. It's a feature that we don't miss, and I don't think is necessary to replicate, given that rolling upgrades is better addressed with container orchestration in my opinion, which gives you better control over the resulting state. Things like prodding at running processes across a cluster from an interactive prompt, however, ought to be reasonably convenient in Haskell just as they are in Erlang.
There is `Text` support for `regex-tdfa` [here](http://hub.darcs.net/shelarcy/regex-tdfa/patch/20120913201555-c1071). Unfortunately, it seems that this code hasn't made it up to Hackage. I would take this up myself but it's quite unclear where the upstream repo for `regex-tdfa` is at the moment.
Different architectures should be fine. But yes, they currently can only be passed between identical binaries, or at least binaries generated from identical source code. There are ways to cheat of course, in particular if you abuse version numbers by having multiple binaries in the cluster all with the same package version numbers but different source code. Principled support for multiple concurrent binary versions deployed at the same time is not something we have started working on yet.
I'm generally on board with the idea. I've just been bad at executing in practice.
I find bitemyapp's attitude childish. I also find the Clojure example very difficult to read compared to the Haskell version, but it's unfair because I already know Parsec.
A nice use of recursive do is the [frisby package](http://hackage.haskell.org/package/frisby-0.2/docs/Text-Parsers-Frisby.html), which implements a packrat (linear time) PEG (unambiguous, never backtracks) parser. E.g. see [newRule](http://hackage.haskell.org/package/frisby-0.2/docs/Text-Parsers-Frisby.html#v:newRule), notice the mutually recursive bindings: additive &lt;- newRule $ multitive &lt;&gt; char '+' -&gt;&gt; additive ## uncurry (+) // multitive multitive &lt;- newRule $ primary &lt;&gt; char '*' -&gt;&gt; multitive ## uncurry (*) // primary 
Your question really shocked me, I thought using Either for almost anything was the usual thing. As an example, within the Persistent library: insertBy :: ( PersistEntity val , PersistUnique m , PersistEntityBackend val ~ PersistMonadBackend m ) =&gt; val -&gt; m (Either (Entity val) (Key val))
&gt; OTOH one nice thing about GHC is that the concurrency primitives don't prevent you from sharing state ETS is the most obvious form of passable state. If you don't think too much about performance, passing process handles is passing mutable state. &gt; It's a feature that we don't miss, and I don't think is necessary to replicate It's just sooo good in development. It shortens development cycle a lot if you have any kind of server with any kind of startup time. &gt; Things like prodding at running processes across a cluster from an interactive prompt, however, ought to be reasonably convenient in Haskell just as they are in Erlang. I hope this will be the case, however that's one of points where it might be a lot easier to implement using bytecode instead of machine code. 
Done! New batch of servant releases viewable [here](http://hackage.haskell.org/packages/recent).
This. My preferences for dynamicism aside I think Haskell is a pretty wonderful language. But the community drives me away every single time.
You might also want to think about interoperability when making a choice. If your password store needs to be read by other non-Haskell apps, either now or in future, then with bcrypt, the stored password format is standardized (and can be used directly from other languages, providing they support the prefix version "2a","2b" etc.). Scrypt libraries make up their own format. You could work around that and convert between them, but it'd be less convenient. Note, if you are using Haskell's bcrypt library, you should think about using the "2b" prefix, which isn't the default (as of version 0.0.5). (See http://undeadly.org/cgi?action=article&amp;sid=20140224132743).
Really? I've always found the community to be respectful and helpful.
Using Parsec defeats the point of the exercise. Here's an [actual Haskell solution](https://gist.github.com/yawaramin/7792c91cb9684ba6350c) that I asked for.
I've tried to use Hoogle but this but it didn't really work. Github's search is pretty bad too. Part of the problem is that if what you're looking for has uses in other *libraries*, you're in good shape. If what you're looking for examples of is primarily used in *applications*, you might have to just hunt for a blog post.
&gt; I'm not entirely happy with the design --- &gt; I tend to not want to build up a gigantic tutorial for a design I want to rip apart and rebuild While it might not be too helpful for most users, an example that shows the (bad) way you have to do a task with the current design and the (better) way (in psuedocode) you would like to be able to do the same task would be documentation I find valuable. First, it's an example, and that will help me concretize the abstractions I'm seeing in the types. Second, it shows me a pain point; it might not even be a big one, but I love having warnings about these ahead of time rather than finding out half-way through a project that I'm the 100th developer to trip over this pointy bit and start asking questions on SO. Lastly, it inspires and heartens me with thoughts of "Oooh, that is better; I wonder if I can fix that..." and "The maintainer clearly wants this library to be awesome, let's see how far they got on that." I'm not saying that it is as good as a tutorial, but it might be something that is easier for you to write that would still be useful to consumers of the library.
The api diffing of libraries, automatically enforcing semver seems amazing. Some of the other ideas of reworking the APIs are also interesting - I guess it would never happen in Haskell, wonder if it makes it easier to understand for people though. 
I think it depends on the library. Something relatively concrete, like postgres-simple probably needs very few examples, if any. Something more abstract like pipes / conduit needs more examples so I have something to anchor the lofty abstractions to.
Oh, I didn't notice - it's just a new package. Maybe it's a good idea to deprecate the old one?
This is great. 'elm-package' looks very exciting, and I'm glad there's a member of the extended ML-family focusing on being inviting!
I think it's because we didn't have a convenient notation from maths to port into ASCII. I think it wouldn't be too hard to make an extension for "SumTuples" or somesuch that worked almost exactly like tuples, but with `|` instead of `,`. Examples of such a syntax: test :: (a|b|String) test = (||"test") fun :: (A|B|String) -&gt; Int fun (a||) = fun (||show a) fun (|b|) = 0 fun (||s) = length s &gt;&gt;&gt; fun test 5
It should be. Are you using the updated [install instructions](http://elm-lang.org/Install.elm)? Some packages have changed names, but I have not gone through and marked the old names as deprecated yet.
I'm torn between awesomeness of elm and requirement to learn yet another language. I'm too old for this shit. Nowadays the less is better for me. That's why i'm waiting for my 3 week vacation christmass time to finally dive into ghcjs. Hopefully this would mean one language both on the server and the client. 
There are people like this in every large community and it's best to just ignore them. In this case, he learned Haskell like 6 months ago and now he's a zealot that flames anyone that doesn't accept Haskell as their one true god. I know several long time Haskellers that have blocked him on Twitter. 
The API diffing is definitely doable though. Someone just needs to tackle the GHC API beast and wrap it up in a nice tool like Elm has.
We* hope to make the binaries available via [npm](https://www.npmjs.org/) soon, which should hopefully lower the barrier to entry for web developers even more. :) (* I'm not an official contributor, just super excited about Elm.)
Haskell seems to have a lot more of them. 
Oops, saw this after I commented. My brain seems to be in severe decompression now that the release is out :) I'll do some deprecating later today!
I think the usual argument is that Elm wanted to be strict.
This I do not recognise, and I don't think I've got my head in the sand. I don't hang out on Twitter though.
Surely there have been academic papers on MonadFix and RecursiveDo that address performance issues such as this? If not, sounds like a good one waiting to be written.
Github used to take Markdown-formatted .lhs and display it with fonts for headings, bold, etc., but suddenly it stopped.
I see! So we *do* have documentation, but many packages only have expert-oriented documentation. That explains both why some people complain that we don't have good enough documentation while others claim that the types are good enough. They're only good enough for support documentation!
I also find the **`help()`** built-in of Python REPL an extremely useful and important pathway to documentation lookup. The easier doc lookup — the more attention docs get. The more attention docs get — the more love they receive. Consequently, absence of a `:doc` command in GHCi is pathetic! In my view, this is a serious and systematic drawback (it's not going to be fixed by [custom `~/.ghci` aliases](https://hackage.haskell.org/package/haskell-docs)) which does harm to Haskell documentation: the harder doc lookup is → the less people do it → the less people see docs → the less people fix them. ---- Solution? Integrate something like `haskell-docs` into GHCi's `:info`, for example.
The one about evolution is by [Reginald Braithwaite](https://twitter.com/raganwald/status/533664641361006592) and based on [his GitHub](https://github.com/raganwald?tab=repositories) he doesn't even appear to be a Haskell programmer.
The original comparison was to be between a stripped down Selmer and an equivalent in Haskell. This is Selmer: github.com/yogthos/Selmer I designed Selmer and convinced yogthos it was a good design for a templating library at a time when I was very dissatisfied with Clojure templating libraries but liked Python Jinja2/Django templates. Now there's a lot more to Selmer/Django templates/Jinja2, but if you strip it down, it's a bit like mustache. So a really weak mustache that just replaces {var} in the template with whatever is in the "var" key in the template context was to be the original Clojure vs. Haskell comparison. yogthos' code was broken and Mark Wotton pointed this out in the comments. Rather than tossing out a mea culpa and fixing it so we could do a proper comparison, he backtracked the scope and lied about the sequence of events. **Note:** Yogthos since ported the blog and the comment history showing his code didn't make any sense has since been wiped. If you don't believe me, ask https://twitter.com/mwotton. I am attempting to track down an original link so I can bring it up on archive.org. Despite that, I still wrote a Haskell parser &amp; renderer that does what was to be compared. http://bitemyapp.com/posts/2014-10-02-parsing-and-rendering-templates-in-haskell.html Edit: I've deleted the things I said on Twitter out of anger. I don't react well to lying. I'll add a retraction if yogthos can meet me in the middle.
Thanks! And thanks for your help with the project.
That is why I dabble in lots of programming languages, as a language geek but at the end of the day is what the customer asks for. 
Interesting, can you open an issue on [elm-platform](https://github.com/elm-lang/elm-platform/) describing exactly what happened? If you are using Haskell for other stuff, it is definitely easier to go with [this install script](https://github.com/elm-lang/elm-platform/blob/master/src/BuildFromSource.hs#L1-L31) assuming you have cabal &gt;= 1.18. It uses sandboxes, so it will not pollute your global package repo or mess up as frequently due to existing constraints that it does not want to update.
The discussion for such posts are mostly horrible with people throwing insults at each other. It would be nice to avoid pointless posts about Twitter drama in /r/haskell. Maybe create /r/haskell-meta and those who find such stuff interesting would be served well there, leaving others happy for not having to notice such stuff. Edit: Examples: [passive-aggressive whining, ] (http://www.reddit.com/r/haskell/comments/2op13l/how_to_discourage_open_source_contributions/cmpii64) [intellectual chest-thumping] (http://www.reddit.com/r/haskell/comments/2op13l/how_to_discourage_open_source_contributions/cmptxy7) I have seen some others, but don't feel like hunting them down.
 arg = [\list -&gt; list !! 1, 3, list -&gt; list !! 0 + list !! 1 + list !! 5, 2, 5, 4] should probably be arg = [\list -&gt; list !! 1, const 3, \list -&gt; list !! 0 + list !! 1 + list !! 5, const 2, const 5, const 4]
Elm wanted to be strict to avoid efficiency problems with FRP in Haskell. Plus Elm wanted to avoid the complexity of Haskell (I assume). While Haskell is great it will never be a standard because you can't understand it quickly. Look as every massively popular language, it's popular because there is a low entry barrier which in the end is just as important for experienced users as it is for new people. Something to rival javascript has to be as easy to learn and uncluttered as javascript (Haskell is cluttered.). Go learn Yesod, then go Elm. You can built a simple, interactive website in elm with zero knowledge in about 20 minutes. Yesod takes a bit more effort. Not saying that Haskell isn't great, I just don't see it as a standard.
And I understood the parser you put together to have mustache semantics, because what the code actually did was bonkers/ridiculous and could be replaced with a tiny regex. Why would you write 40 lines to replace {{...}} with a fixed piece of text? Regex can do that. That's the point of contention here, not that I used attoparsec. You cherry-picked the least-nice looking Haskell version on purpose. There was another, nicer version.
I understand, and I am not telling you what to do. However, there is never enough time, and lost knowledge is a terrible thing.
Ooh, this is a nifty way of getting around Haskell's weak sauce module system. Now if only we could limit the scope of instances.
Which is one of the reasons I posted it here – this subreddit tends to be reasonable and level-headed in discussion. That way, I could get something out of it that is *not* insults and whining. (Not saying /r/clojure is, it's just that I'm interested in both sides of the discussion.)
The main issue to me is that I can't use existing Haskell libraries within Elm
But such posts overshadow others, that deserves more attention. **I** was not able to get anything out of such discussions here and it only made me feel bad about some people. It would rather be nice to have discussion about streaming libraries, network libraries etc,.
Yep, that's indeed a comprehensive list of examples. Only thing I miss is haddock documentation, at least in [`Database.Bloodhound.Client`](https://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Client.hs).
&gt; Many day-to-day constructs are difficult to type Type precisely, but that is not necessary, or always desirable either. 
&gt; Things like prodding at running processes across a cluster from an interactive prompt, however, ought to be reasonably convenient in Haskell just as they are in Erlang. I think most Haskell server engineers would find this feature useful. 
That's what I believe as well.
There was relevant context there and he's been dissembling about this the whole time. He harassed me for *months* to do his parser challenge and wouldn't leave me alone. I finally do it to find out his code was totally bonkers and he responds by lying about the scope for comparison, then says using attoparsec doesn't count. I just wanted to be left alone and he has refused to do that.
There is [Helm](http://helm-engine.org/), which at least till some time ago did a good job of being Elm-in-Haskell
The course is called "*Introduction* to Functional Programming". I think it's better to say "I think that in this case a list is better than Maybe because of list comprehension" than slap your students, who barely survived their first encounter with Monads, with turning on "MonadComprehension". To me, this is all blown out of proportion, an introduction has to make simplifications, and it has been made clear (e.g. we have to ignore bottom). Sadly, some people have kept nagging about this (bottom), so now most exercises read like legalese. I think that, and now this, is taking away some fun of this course. 
There is **very** under-appreciated haste-compiler that can regenerate quite tiny code (and yes, it's full Haskell)
Awesome!! :)
The nice thing is, Elm is not too different from Haskell, I think the Haskell-&gt;Elm transition is pretty easy. Other than a few syntactic hiccups, the biggest difference is the absence of typeclasses, but various solutions to that are being discussed. The other nice thing is its really really easy to just fiddle with Elm: see http://elm-lang.org/try
GHC seems to be the de-facto standard. Support for Haskell 2010 is getting dropped in GHC 7.10. The trade-off of adhering to a non-implemented standard at the cost of great features doesn't seem compelling to me. Again, I just want to say that I think these features are extremely valuable, that I am really happy to have them, and that I am not a professional developer. I can accept that those features might be seen as too "complex" for team work, but I can't see the value of adhering to a standard when there will only be a single implementation for the foreseeable future ...
The problem is that you can only have a single instance of a type class be present *and all instances are automatically imported when you import a module*, so if module A has one instance and module B has another instance and C tries to import from both A and B then there is a conflict.
Interesting. When I read this article all I could think was "I already solve this using modules and imports", heh.
Ultimately the problem is I don't yet know the better way I'd like to do something, otherwise I'd have torn everything apart and switched. ;)
Like I mentioned below when tel asked a similar question. I'm generally on board with the idea, but have been bad at executing it practice. 
Really looking forward to giving this a proper try. And I will definitely be aliasing `elm-package` to `elp`.
The split substantially changes the Haddock documentation; the `HasServer` instances are gone from `servant` (for obvious reasons). Now it's all only available in [`Servant.Server`](http://hackage.haskell.org/package/servant-server-0.2.1/docs/Servant-Server.html), and Haddock doesn't include anywhere that, say, `type Server ((:&lt;|&gt;) a b) = (:&lt;|&gt;) (Server a) (Server b)` like it [used to](http://hackage.haskell.org/package/servant-0.2/docs/Servant-API-Alternative.html). Maybe re-exporting all the data types in `servant-server` would restore the more precise documentation? Edit: Oh, also the source for the instances is now buried in an un-exported `Internal` module, which is a shame; you can't get to it through Haddock at all now.
&gt;Ignoring them is complete the wrong move. [Yep](https://twitter.com/irrequietus/status/542779404582391809) I'd like to be left alone, adam bard's posting of this ridiculous dispute has given yogthos new opportunity to harass me. This *began* with him harassing me to do a challenge I never agreed to.
It depends on your definition of community. If it includes anyone that mentions Haskell on twitter, than your opinion might be different.
Because is not haskell nor try to be.
Why would you want that? You can't use haskell libraries in Python or Erlang either, they're completely different languages. 
This is great for where I am in learning Haskell. Apologies if this is messy, I am getting weary trying to write this after work. Let me see if I understand what I'm seeing. You create `Map` data structures by calling the `names` and `handles` functions. The data structures produced by calling `names` and `handles` are wrapped into a `Table` data type via the `from` function. Within the `from` function, a `Table` type is constructed using as a type parameter an anonymous function which itself takes a key argument and returns a lookup of that key within the map `m`. The `Table` data type specification is written in 'record syntax', with a its two type variables (`k` and `v` used as parts of the definition of an anonymous function). What I don't understand is how the `Table` type is being constructed with that anonymous function. (The fact that this could be done was new to me! Cool stuff). Is this function evaluated during construction, or is it lazy (e.g. will that anonymous function remain unexecuted until other code runs `lookup`?) Perhaps related, it looks like that anonymous function gets partially applied later on, and then composed into something else later. The other part I don't understand is how join2 works, which is a good segue into the Applicative which I need to become more familiar with. Here is a shot at it: The `join2` function constrains the function parameter types (`f a`) on the typeclass `Applicative`. In its body, `join2` uses the "," type constructor (function?)[1] to construct a `Tuple`, The "," seems to be using as its parameters the two `f a` parameters of `join2` (I'm not certain). Now in this case the two parameters of "," are functions, as used in the example: *Main&gt; let table = join2 names' handles' *Main&gt; :t table table :: Table Id ((FirstName, LastName), TwitterHandle) which I would guess means that `liftA2` together with "," could be described as doing the following "it applies[2] the two functions, and tuples up their results." And within `names'` and `handles'` themselves, we're seeing the promotion of `names` and `handles` from `Map`s to `Table`s. Hence the return type `f (a, b)`, which (I am guessing) is coaxed into type `Table (\k -&gt; f k &lt;*&gt; x k)` by the typeclass instance `instance Applicative (Table k)`. I am not certain how the instance and its function definition (`Table f &lt;*&gt; Table x = Table (\k -&gt; f k &lt;*&gt; x k)`) fit together with the `liftA2`[3]. The author states that the original purpose converting from `Map` to `Table` is to be able to use the Applicative, or more specifically, to have a working implementation of `pure`. I am not sure how `pure` fits in. I recognize I am also showing that my understanding of typeclasses is probably also weak. I tend to think of typeclass instances as "make a given operation operate *this way* on this type, that *that way* on that type. [1] *Main&gt; :t (,) (,) :: a -&gt; b -&gt; (a, b) [2] Perhaps it is not applying them but sort of freezing them in their state for use later, or taking the two chunks of computation (the two f a functions that are arguments) and bundling them together [3] I recall seeing this sort of "logic in the type" in this example, hopefully it is roughly analogous: you can retrieve an element at an 'index' in a sum type if you convert an Int into an Enum ('toEnum') and return the result in a function whose return type is the sum type. I hope this is roughly analogous to what I'm seeing with the `T 27 newtype ID = ID Int 28 deriving (Show, Num, Eq, Ord, Integral, Real, Enum) 29 30 data Person = John | Sarah | Susan 31 deriving (Show, Eq, Enum, Bounded) ... 47 personFromId :: ID -&gt; Maybe Person 48 personFromId (ID i) | i &lt;= 3 &amp;&amp; i &gt; 0 = Just (toEnum (i-1)) 49 | otherwise = Nothing (source: https://github.com/mstksg/inCode/blob/master/code-samples/inside/maybe.hs)
It's not a problem for things like the logging example where (1) each executable only needs, and in fact wants only, one instance; and (2) no library code *ever* needs an instance in scope. In that case, it all works out if the instance is either defined in `Main` itself or, more naturally, in a separate module that is imported by no other module except each executable's `Main`. It would be nice if such a constraint were enforceable, though.
Full haskell to a certain extent. For example Threading happens in CIO instead of IO. But yeah. Haste is nice. 
I'm wondering if anyone working on porting the Elm libraries to PureScript. as it has strict semantics as well. Would be nice. EDIT: Apprently yes: https://github.com/bodil/purescript-signal 
Agreed; Haste is super underrated. I'm not sure I buy into the whole GHC-in-the-browser thing... I have to imagine that if GHC had *only* targeted the browser all this time, the runtime functionality would look fairly different. (Though time may prove me wrong here.) Haste is a really lovely compromise -- supports the full Haskell language, but the core library is just a narrow shim around some browser functionality / JavaScript FFI.
Also `forall b . (a -&gt; b) -&gt; b` is isomorphic to `a` by free theorem.
Also https://github.com/paf31/purescript-behaviors. Not exactly the same (separates events and behaviors), but similar. This is my attempt to learn FRP by implementing something, so it might be incorrect (comments welcome).
 instance RiemannHypothesis 
Technically, both binaries must link the module which contains the static form, from the same package version. The programs are free to link other stuff in addition independently of each other.
have you run the code through Google's Closure Compiler? That should reduce it to about 100-200kb.
Quick question: is Stephanie's talk on Friday happening in the morning, afternoon, or evening? I'm thinking about traveling from Canada and need to know if I should leave on the Thursday or early Friday morning (~8hr. drive).
Named documentation chunks for Haddock don't work in the module description it seems?
His name is Riemann.
Suppose there is a logging package: logger. Suppose there is a web framework package: web. Suppose there is a web application: app. The `web` package performs some logging, but wants this to be configurable. We want to write `app` such that it uses `web`, configured to log things via `logger`. --- With a powerful module system, we could define `web` as a module with a missing `logger`-shaped dependency. When using `web` in `app`, we could fill the missing module with `logger`. --- With Nullary Type Classes, `web` can define a nullary type class, which `app` can instantiate using methods from `logger`. This simulates the powerful module system. However, as a drawback, `web` cannot be used with a different logger by any of the dependencies of `app`. Not a bad drawback in this case, but other cases can be imagined where this might be problematic. --- Without Nullary Type Classes and without a powerful module system, we have to express the dependency explicitly on a per-operation basis, rather than a per-module basis. Each operation that `web` provides that might try to log something must be parameterized over the logger. The common way to hide this is with a custom `Web` monad. In order to "run" the monad, you must provide it with a logger. The monadic bind then performs the necessary plumbing to get the logger wherever it needs to go. --- If you are in control of both `web` and `app`, then sure, you can just switch the import statements in `web` in order to use a different logger. However, if you want to provide `web`, or if you want to consume `web` without changing it, then this technique for configuration is not an option.
ok, what about it this: pm me, i send you the source, you read it (but then you have to read it through :), and you tell me how educational it was exactly. Then, based on that external input, i draw some conclusions, and decide what kind of code should i release (which may be not yet written, but that's my problem). so, what do you think? 
When people act like children on this reddit they at least get downvoted (sometimes... I hope... maybe not enough). I don't think chasing them around on twitter is very useful. I recognize and respect that /u/Mob_Of_One (aka bitemyapp) has made a number of useful contributions, including libraries work, and a great deal of work into organizing educational resources and teaching people. But simultaneously I just wish he could tone it down and check his ego and stop rubbing everyone (including me) the wrong way. This sort of personal spat potentially hides some interesting technical content, but its behind so much namecalling that I don't care about that it is hard to tell, and I don't care to sort through it. I hope that comments such as yours can help Mob_Of_One recognize that when people talk about elements of the Haskell community that drive people away, they mean precisely this sort of junk. In turn, maybe, therefore, this will encourage him to stay positive and stop with this nonsense. Maybe. I hope.
That is a much better thought out response than I was capable of writing, thank you.
He insinuated I was a terrible programmer because I hadn't taken up his challenge for months in various public fora. If you have a better word for that, I'll use it. What do you suggest I do when he's being dishonest about what happened in threads like this? This is a genuine request for advice.
Edit: I've been guilty of what I complain about, escalation. Probably my recommendation is to ignore or disengage. If you escalate with strident wording, everything will go to hell in a hand basket, especially if you (generic you) has a reputation for that already. If you keep a neutral or positive tone and everyone else gets nasty then block and remember that boos usually come from the cheap seats.
That's what I get for typing quick. =) Fixed.
In 7.10, this extension will be merged to MultiParamTypeClasses.
Found it: https://gist.github.com/mwotton/fd10161cde2838c8834f
I figured it out. Or more accurately, the author of HSpec, doctest, etc. figured it out (Simon Hengel). module Database.Bloodhound.Client ( -- * Bloodhound client functions -- | The examples in this module assume the following code has been run. -- The :{ and :} will only work in GHCi. -- $setup createIndex You need to put the named fragment in the exports list, but with a new line separating it and the module preamble. The last time Simon Hengel helped me with something, it was actually Elasticsearch's fault, not HSpec's, and he still helped me through it. Incredible person.
I believe you might have mixed up those links :)
Why do beginners always seem to reach for typeclasses to solve problems like these? There isn't really anything in the introductory material that emphasizes their use.
When you get here after the typo is fixed it feels a bit like a Fight Club trope coming on.
Perhaps the old craftsperson terms are applicable: * An **apprentice** is studying with a **master**. This is a person who is learning (from books, tutorials, and examples), but hasn't gotten a job yet. * A **[journeyman](https://en.wikipedia.org/wiki/Journeyman)** is someone who has completed an apprenticeship (has learned enough to do work), but who isn't yet a master. * A **master** is someone who has created a masterpiece that has gotten the stamp of approval from the *guild*, in this case, the Haskell community. This could be a person who has created something of value that is admired and or used by a larger audience. This could mean approval of haskellers, or just the approval of your company or user base. As a *newcomer* (to use another, neutral term) to Haskell, now three weeks in, I have built two modest and horribly written tools that I am using to scrape and process natural language content from the web and dump it into a database for downstream use. Now that I have built *something* I don't quite feel like a *beginner* but I'm not sure that I qualify as anything else. I can say, as an interested party, that once you have built something with which you are not quite satisfied you have loads of motivation to learn and apply more. 
doh! I didn't know this existed. I'm a newcomer. Control.Category... superb.
Well I first reached for typeclasses because I started off translating Java code, and that used interfaces. Java interfaces -&gt; Haskell typeclasses in my mind I guess. I did learn about phantom types now, so that solves some things I would use typeclasses for.
I haven't really worked with parser combinators before, so this a serious question: Why use a parser combinator when you can do it with a regex instead? Regexes are fairly standardized and lots of people know them, so that's what I default to.
Deal. You can find my contact details on [my homepage](https://mietek.io/).
Haha, thanks.
Not saying that this is good or bad, but interestingly enough, Scala libraries like Akka, Play, scalatra, or even the Scala stdlib itself are using this kind of stuff all over the place, e.g. to provide an implicit execution context for actors. Turns out that this is rather confusing for newbies (and possibly a lot of other people, too).
Here's some genuine advice then: * Don't call people names because they don't believe what you believe. * Don't tell them they're doing everything wrong without actually showing what "right" would look like. * Don't harass them on twitter and then make inflamatory blog posts. * Don't play victim when your abuse backfires at you. * Do make things in your favorite language that others find useful and let that speak for itself.
Parsers fit nicely with the Haskell mindset: they compose well, they have a very pleasant Monad instance, and they can return meaningful types instead of just a list of strings.
You shouldn't use them for anything *accounting*. We are using `Double`s for quantitative risk analysis here and they work just fine.
Regex-based parsing can also be composable and typed, see e.g. [regex-applicative](https://hackage.haskell.org/package/regex-applicative). If you know your language is regular, exploiting this fact should lead to much better parsing performance.
Hmm I'll address this today this is definitely not ideal for discoverability.
What are those StaticPointers for? I don’t see any mutation functions, so basically, what’s the difference between using `StaticPointer a` and `let x = e in {- shared e -}`?
Thanks, I wasn't aware of that.
&gt; Something to rival javascript has to be as easy to learn and uncluttered as javascript (Haskell is cluttered.) Well, I would object to the statement that JavaScript is uncluttered. It is definitely cluttered (scoping, pseudo-arrays, `==`, …). Language popularity depends on many things other than how the language is designed (viz PHP, C++).
The more I read about this militant functional programming Twitter community the more I'm glad I've never had to interact with it...
&gt; And your claim that you've had to read the source is probably not the case -- rather, you meant you had to read a bunch of types. I can chime in that reading the source does actually help with some libraries, precisely because it serves as examples of how the functions are used. This isn't unique to Haskell though – I do it all the time with Python libraries as well.
Gosh, I had forgotten about my first (tiny) GHC patch! https://ghc.haskell.org/trac/ghc/ticket/8993 :)
Would [this](http://haskell-servant.github.io/servant-server/Servant-Server.html#t:Server) be better?
Balancing a tree is easiest accomplished by just creating a new tree where you add all values from the existing tree, since adding a node keeps the tree balanced. With that said, why do you have an unbalanced tree in the first place?
Indeed. Considering how big the problem with library compatibility is when you have many dependencies and developers, this is huge step in the right direction. It's something that's severely lacking in build systems (especially in Java). It's important to force people to use correct semantic versioning, not just having it as an optional thing (which is typically not automatically verified). I can see many possible features that can be integrated in an automatic API checking tool, for example in a backwards incompatible version you could provide metadata with the previous name for renamed identifiers. The tool can then automatically fix references to these identifiers if the developer wants to do so. This can even be extended to other things like parameter reordering etc.
Yes, they are. This was [a good introduction to 2,3,4 trees](https://www.youtube.com/watch?v=0BeIo4JB0Z4), if I recall correctly.
You may be interested in [this post](http://billmill.org/pymag-trees/).
Woah super nice!
Cool thanks. Would it be similar to displaying an AVL tree? I could do that from a previous assignment. 
It's long past the time where it even syntactically resembled Haskell
Actually what turns me down is regexes "syntax" ... it's pretty easy to come up with something like `^[^.]*?\K[^.](?=\.)` ... but without knowing what it [does](http://stackoverflow.com/questions/27422350/extract-character-preceding-first-dot-in-a-string) ... could you tell me what it does? `regex-applicative` looks interesting. I should spend some time on it.
You left out the method definitions. Those are the best bit!
Wonderful site, the other articles are very enjoyable reads.
Agreed. That said, in Scala many of the "implicit" values are actually closer to "what exists in the current scope" in Haskell. If there's one definition of the implicit instance, that one will be used. If more than one exists, the compiler will say it is ambiguous. To combat that, you can simply give the function the specific definition you want. In a way, that is stronger than in Haskell, where every you can only have one definition in a scope (e.g definition of Eq Int or Show Char), while in Scala you can have multiple of those, packed into the implicit objects rather that in the global scope in the package. (Is it possible in Haskell to import something only in a specific scope?)
Funfact: I just tried to create some images with [chart](http://hackage.haskell.org/package/Chart) and it falls perfectly in the "here are some examples of me doing some charts ... now you're on your own" category :(
Just what the doctor ordered. This is great, exactly what I need.
Can you explain why you refer to sum types with the incorrect name "union types"? Union types are quite different to sum types.
Hmm, that is an interesting use case. I'm not sure I prefer the polymorphic config to the explicit-pass-a-logger config myself, but that makes a lot of sense -- thanks!
Finally! ghc and cabal in one bundle. It's what the masses have been crying the last five years. 
Thanks! To be clear, the visualization code is based on mbostock's work here http://bl.ocks.org/mbostock/1582075. He got the original angle-encoding concept from work Robert Sedgewick did for 'Algorithms in C' in 1998. Shoulders of giants, and all that.
n.b. I'm pretty sure the "powerful module system" story can be accomplished via [backpack](http://plv.mpi-sws.org/backpack/). I'm curious to see if backpack will catch on and become a regular part of the Haskell toolchain/ecosystem.
Very interesting! There has been some discussion here: https://www.haskell.org/pipermail/haskell-cafe/2011-June/093349.html Indeed Sum types need to have a name for its elements (like the "Right" and "Left" in the Either type), to know which one you want to create. If you want an anonymous sum type, so without names for elements, you need to reference them using their position in the sum (as you do).
This has already been posted: http://www.reddit.com/r/haskell/comments/2oyjxi/beta_testing_the_windows_minimal_ghc_installer/
I must admit, I'm not sure I get what he's trying to do here. Is there someone who understands it who is able to write an example of how this would look in a program?
Awesome news! Which gcc version does it come with?
Node.js runs on a server in V8. It has entirely different ways of talking over HTTP than XMLHttpRequest, so jquery wouldn't work. 
We haven't tweaked the MinGW shipped with GHC at all. With the 7.8.3 installer, I show the version of GCC as 4.5.2.
Too bad :( Any plans to upgrade? I assume if I upgrade it manually, it won't work? 
Yeah, I got it. But why would you need such a type? Why not directly send the value, since it can’t change? For performance purpose?
Fantastic! 
Afaik, the next GHC will come with the upgraded MinGW. 
I have no such plans, but I've never heard of this being a problem. Can you explain what the goal would be?
Shall upvote if you sing it.
You cannot send a closure over the network (and attempting to do so introduces a gigantic can of worms.) This is why a StaticValue isn't really a value, but a reference. Normal values work fine, but closures are of particular importance because you want to be able to do things like remote calls on external nodes, which may not exist in the same network or even on the same platform/architecture. You don't want to have to build your own RPC layer (which translates/packs messages into function calls, sends them to a specific endpoint, then serializes responses back); you just want to actually call into a function on a remote node. For example, this allows you to treat Cloud Haskell more like Erlang, because it allows you to just 'invoke' functions across a network, process, or another computer. All of this is strictly doable without `-XStaticValues`, but it changes the programming model quite a bit by allowing you to reference/dereference functions across space and time. You'd still need some communication layer *underneath* to actually write something to a network socket; but you don't need an RPC layer on top of *that* now, because you can just send a reference, and the other end can dereference it and invoke it. The best you can do instead is to use Template Haskell to build functions which can then dispatch to call remote functions, basically a kind of RPC, but this is cumbersome, requires TH (which isn't always readily available on some platforms like ARM), and is very syntactically messy as it requires 1-arity functions. For an example, see http://haskell-distributed.github.io/tutorials/1ch.html#spawning-remote-processes for the current approach. You can do all this without TH today, but it's even more cumbersome. With `-XStaticValues`, we won't need Template Haskell at all: we could call the `sampleTask` function in the above example with no TH, by simply referring to it as `static sampleTask`, which has a type like `StaticValue ((TimeInterval, String) -&gt; Process String)`. We could also `curry` this function to turn it into a `TimeInterval -&gt; String -&gt; Process String` and call that instead, where before it always had to be manually uncurried into an N-tuple.
And here I am still trying to figure out what a Monad is.
Well, I need a newer compiler for a native library I'm using. I'll try to test on the week-end.
This monad is equivalent to: import Control.Monad.Trans.Writer import Control.Monad.Trans.State type ASM6502 = WriterT [Word8] (State Word8) byte :: Word8 -&gt; ASM6502 () byte x = do tell [x] lift (modify (+ 1)) However, this comes with the caveats of using `WriterT [a]`, which is that it will leak space like crazy for a large assembly computation (even if you don't log anything!). If you want to reduce your memory usage for very large programs there is an [equivalent streaming solution](http://www.haskellforall.com/2014/02/streaming-logging.html).
That's a lot better; we get the type instance list *and* a link to the source. It's sure nice that Haddock includes type family instances now.
They also employ pretty much everyone that can be considered an expert in the Haskell ecosystem. Makes me wonder what their continuity plan is. JaneStreet is always recruiting/training/evangelizing and they still can't find enough OCaml programmers.
I think I understand it. Imagine this, you have a button you want something to happen when it is pressed. Right now you could have an onclick handler and either 1) have a callback that is effectful, 2) pull a message on a channel. Now imagine that you want to drag that button around. You need to add new handlers to make that happen. In other words, your layout code needs to change. What he seems to be proposing is that instead we can make layout code. All it does is draw the UI, no events, no handlers, nothing. If we want something to happen on a button click. What we do is have a mouse click event fire at a certain coordinate and then look up what element in our layout that coordinate corresponds to. From there we can decide what to do. What this gives us is a way to keep our layout code clean. So, now if we want the button to drag instead our layout code does not change at all. All we change is our action. Hope I got him right and that my explanation made sense. 
In this instance it's essentially saying that we can compose the two following types of functions: type a ~&gt; b = a -&gt; (b, [Word8]) composeWriter :: (a ~&gt; b) -&gt; (b ~&gt; c) -&gt; (a ~&gt; c) or: type a ~&gt; b = a -&gt; Word8 -&gt; (b, Word8) composeState :: (a ~&gt; b) -&gt; (b ~&gt; c) -&gt; (a ~&gt; c) The resemblance to function composition is non-coincidental. This sweeps some important details under the rug, but if you try expanding the type signatures and writing the implementation for the functions it might still help to familiarize yourself a bit with the concept.
My understanding of the reasoning was that they had conducted some sort of survey and that people seemed to understand "union types" the best. I agree with you that eliding the distinction between unions and sums is a big problem, and I wish they wouldn't mess up the nomenclature.
A monad is a burrito in the category of bad computing metaphors.
Stronger is a problem, you lose coherence.
A monad is a space suit in the universe of analogy-based tutorials.
This. I very much do not believe types are sufficient to the task, they just help an awful lot to fill the gap. They tell you nothing about the sort of expected "protocol of interaction" with the library. *e.g.* you must open a file first, then consume it, then close it before you let it go.
This kind of approach breaks down quickly when your widgets are stateful. You now have to manually thread the state &amp; interactions, which gets ugly. When the domain is inherently stateful I don't see any problem with using imperative programming. It's exactly the right abstraction for the domain. I think the sweet spot is: 1. The UI gets computed as a "pure" function of the model. Pure is in quotes here because the UI may have stateful widgets inside it. 2. The model gets updated, which causes the UI to be recomputed FRP style. This is about as functional as you can get before you start to have to thread the state manually through your entire application.
I think I'm more confused after reading your explanation than before it (that's not a fault of your explanation so much as of the mental model I'm using). When I read the post, I felt like he was criticizing the [observer design pattern](http://sourcemaking.com/design_patterns/observer) (or Wiki [link](https://en.wikipedia.org/wiki/Observer_pattern) if you're so inclined), of which callbacks seem to be a simplification/variant. When I read your comment, I felt like you were advocating the Observer design pattern. So I'm confused.
One complaint I've heard (and had) about implicit params is that they're much less implicit than you might want, since you have to annotate each function with each parameter, all the way up. I wonder how they'll interact with the forthcoming partial type signatures extension.
This always seems very scary to me. I used it in Scala land and... I just don't know.
I won't try to explain them, but I will suggest that they will make sense if you just keep playing with monadic code and keep in mind that specific monad instances ( List, IO, State, Reader) don't define the general monad class. The mysticism around them is mostly unwarranted. 
You may be interested in [my reply here](http://pchiusano.github.io/2014-12-10/wormhole-antipattern.html#comment-1737490774). I am always quite dubious when people claim that threading state around manually is ugly or hard. You just have to pay attention and be on the lookout for common patterns. If something becomes tedious or ugly, find a nice abstraction to solve that, don't just throw up your hands. That's what functional programmers have been doing for ages, and this stuff just keeps getting easier. FP is extremely good at describing state machines, too, btw. Importantly, not using side effects in your state machines means you can assemble these state machines via a compositional library, of which there are many. When you're actually using side effects, you don't get this luxury.
That's the basic architecture of [`blaze-react`](https://github.com/meiersi/blaze-react). The "UI" is a function `:: state -&gt; Html action`, combined with a state update function `:: action -&gt; (state -&gt; (state, [IO action]))`.
Someone else [asked something similar here](http://pchiusano.github.io/2014-12-10/wormhole-antipattern.html#comment-1737352422)... at least I think it is similar.
Finally!! A much-needed, simple improvement to the Haskell+Windows experience.
Oh, we can totally make this precise: First, we define a *burrito category* to be a preorder with an initial object, called *the beans*, and a terminal object, called *the cheese*. While there's nothing distinguishing a burrito category from any other preorder with top and bottom, the intuition is that a burrito will be "wrapped up" into some other category. This intuition motivates the definition of a *burrito object* in a category C, as the colimit of a functor E: B -&gt; C. (As a mnemonic, the ingredients of the burrito go *into* the burrito). Now, we can construct a burrito category by ordering monad tutorials by date created; the evident map into bad computing metaphors is clearly functorial. We leave it as an exercise to show that monads are the colimit of this functor.
Hi. Your code looks generally fine, apart from `concatNothing`, which is unnecessary. You're looking for a function which returns its argument without doing anything to it, which is provided by `Prelude.id`: id :: a -&gt; a id x = x However, the Haskell gods have foreseen this situation and created `Data.Maybe.fromMaybe`: fromMaybe :: a -&gt; Maybe a -&gt; a fromMaybe default = maybe default id This returns a default value (here: `"badJson"`) if its second argument is `Nothing` and otherwise gives you the value inside the `Just`. If you're feeling adventurous, you may want to take a look at the `Functor` instance for `Either`. This could save you a bit of boilerplate (and `Functor` is generally awesome), but if you're just starting out, it can also wait for a bit.
It's an interface that some types implement. In principle, any type that implement return and bind is a member of the Monad typeclass. Actually, in programming types are normally defined either by its operations (in a stack, for example, there's push and pop -- you can either add members at the top, or remove members from it) or its structure (a stack is a list, or array, with which you define a suitable push and pop). Typeclasses like Monad hide the structure of the particular type you're working with, so you need to reason with only the available operations. But anyway, if type implements Monad and it is a container (say, a list), return will create a singleton instance of the container with one given element, and bind will let you change what's inside a container (but doesn't let you recover what's on it). Other types implementing Monad might do other things.
Darcsden uses it iirc
I think you actually get a more compositional API with state. For example: username = channel "" password = channel "" ui = vertically [textbox username, textbox password] The key here is that widgets take as arguments the channels that they bind to. That's what allows you to specify hierarchical UI in a compositional manner. In your reply you say that this makes you feel dirty, which I can relate to. On the other hand, you can view this as a DSL for specifying a UI. That this DSL implemented using state should in principle not matter, what matters is the abstraction that's presented to the programmer. Functional programming simply doesn't work for a UI DSL like the example I gave, since if it were functional then we could substitute equals for equals and you'd get `ui = [textbox username, textbox username]`. So I'd argue that in this case we *do not want* referential transparency, because the natural way to describe a UI is with identity: this textbox is different than that textbox. You can simulate identity in a functional language by passing around IDs manually, which I think is what you are proposing. But now how do you get the values out of textboxes? How do you keep UI state stable if an unrelated part of the UI changes? How do you abstract a composite widget into a reusable component? You can solve those problems in a functional API, but it will get pretty complicated. I don't really see the advantage that that gives you compared to just accepting that we use a little bit of state for the UI? Another way of saying that is that the natural monad for building a UI is one that supports identity.
This might be a problem in `elm`, but I think it is a real disservice to call what is described here a "wormhole." Wormholes as introduced by Hudak and Winograd-Cort have much neater semantic properties than the channels here: http://haskell.cs.yale.edu/?post_type=publication&amp;p=802 Note the vital use of scope to manage this interaction, along with the use of the type system (expanded on in subsequent work) to capture noninterference properties. This line of work is interesting, and railing against Channels is fine, but for the sake of clarity I'd like to avoid mixing these up with the "wormholes" FRP work the Yale group has been doing. There may be objections to that work, but this post is talking about something else entirely.
I'd go with something a bit less verbose, and just do the case analysis directly, at least for now showJson :: Either Reply (Maybe ByteString) -&gt; String showJson (Left err) = "No JSON. Redis error: " ++ show err showJson (Right Nothing) = "No JSON. No value for that key." showJson (Right (Just bs)) = show bs To write this with the combinators provided by the Either / Maybe packages, you can refactor this to: showJson = either showErr (maybe missingMsg show) where showErr err = "No JSON. Redis error: " ++ show err missingMsg = "No JSON. No value for that key."
Yes it does, thank you for the hint. They seem to be using implicit parameters consistently for [settings](http://hub.darcs.net/simon/darcsden/browse/src/DarcsDen/Settings.hs) and [backend abstraction](http://hub.darcs.net/simon/darcsden/browse/src/DarcsDen/Backend/Transient.hs). Interesting combination with a type class as well.
Probably not as big a problem as you might think. Take Google+ as an example. It loads 10MB+ of javascript just to show you boxes of text and gifs. The 1MB you get includes the RTS as I understand, and therefore there is a fixed overhead component in there.
How dos the streaming solution handle the `MonadFix` instance?
I got the 64-bit version working last night. It is currently in another branch, but will likely be merged into master by next week. There are a few optimizations I want to make first.
I think it's just because the keyword `class` feels familiar.
One might try to make the case that knowing how to use the Monad interface is the same thing as knowing what "a Monad" is.
first post in my devblog for Language Engine, which is built in Haskell (except for the other side of the ffi). also I figure the questions raised in this post might be of interest to anyone exploring the design space of logics.
I'm not convinced that stateful widgets modelled purely with one value are actually a problem. We're using GHCJS and ReactJS with a little experimental library we wrote that has one single state value for the whole app. The view is just a pure (well, it can run in any monad `m`, but it's practical to just have m = `Identity`, but Reader will come in handy to avoid threading configuration) function that takes a state and renders out a DOM tree. Events update the state, which triggers a complete re-render of the DOM again (with some cleverness underneath to avoid doing unnecessary work). Let's say your state type of your whole app is defined like this: data Status = Done | Complete data State = State { _stateStatus :: Status , _stateEditor :: Ace , _stateContents :: Text } (And you derive lens instances.) A small app. It has some current status, contents for some source code and an editor. I make my app and create an Ace editor component: do app &lt;- makeApp ace &lt;- createAce app where in this case makeApp :: IO (App State Identity) and in the general case createAce :: Monad m =&gt; App state m -&gt; IO (Component state Ace m) This creates an instance of a React component and also makes sure to tie the state and monad type of our application to the component's type. Now later we can build an instance of that component with: buildComponent :: Monad m =&gt; Component state cursor m -&gt; Lens' state cursor -&gt; ReactT state m a -&gt; ReactT state m a Example: buildComponent ace stateEditor (do attr "code" (_stateContents state)) (This is a lower-level API, technically, despite defining this in Haskell, JavaScript code could use our component if desired.) Notice that `stateEditor` is a lens (technically a Traversal is more accurate), which allows the component instance to store its own state (of type `Ace`) somewhere in the user state, without knowing or caring where. But it can update the state as need, e.g. if the user types in the box, then the value for the Ace editor will be different, so we update the state, which triggers a re-render of the view. Components are clever enough to say that they don't need to be re-rendered if e.g. the user typed "Mary" in a box. In the real world changes happen like that, but you can model them in a pure way as above. This leaves room for things like making time machines where you go back in time through snapshots of the state.
Paul can speak for himself if necessary, but my guess is that he wasn't aware of that technical meaning of "wormhole". I certainly didn't get the impression that he was talking about a precise concept when using that term.
It doesn't (that I know of)
I'd qualify that with also knowing the monad laws
I actually used that combination once to create a type that guaranteed it was being run within a particular context. The code is here: https://github.com/gcross/LogicGrowsOnTrees-MPI/blob/master/sources/LogicGrowsOnTrees/Parallel/Adapter/MPI.hs The way it works is that the user can only use many of the functions if they can satisfy the MPI constraint, and only the function withMPI lets them do that. The original version of this code used a newtype to create a Monad, but what's annoying about that approach is that you have to code up infrastructure to make the newtype into a MonadIO and to lift all of the IO operations into the newtype monad; this way all of the IO code gets to live in IO.
Quick, someone write a brainfuck monad!
You are right, there is no way to split `Symbol` into a type level list of promoted characters. I hope that changes in 7.12.
They are invisible in function params, which is great but I would not like them to be completely invisible - at least the type shows what to expect. The worst thing you can get are some conventions (e.g naming) which have significant meaning but are invisible since the code just looks normal. Many frameworks in OO world suffer from this. 
Your argument makes sense, but I'm not sure points 2 and 3 apply to GADTs and RankNTypes nowadays. But I'm confused by one statement: &gt; if your favorite compiler bit rots I read about your heroic work on HBC so I respect your opinion, but it's hard to imagine this happening *nowadays* without a compatible replacement. And nowadays can you cite realistic alternatives to GHC for production usage (which includes reasonable Hackage compatibility)? Viceversa, since you stick with standard Haskell, are you able to use alternative compilers in production? What do you gain? Googling led to these not-very-busy user communities for the two best alternatives: https://www.haskell.org/pipermail/jhc/ http://lists.science.uu.nl/pipermail/uhc-users/ suggesting they don't have comparable user communities.
Just recently I was changing a large number of related, recursive functions to add some environment to pass around. I didn't want to convert everything to a reader monad and this extension could have saved me a lot of time. The reason is that when you add an explicit parameter, you have to fix every call site. But with this you only change the type one per function. So, you get savings when you call each function from more than one place. 
You can get a similar effect using [reflection](http://hackage.haskell.org/package/reflection), this is a quick rewrite of /u/jlimperg's link to Darc's Settings.hs: import Data.Reflection data Settings = Settings { dir :: String, multiuser :: Bool } type HasSettings = Given Settings withSettings :: Settings -&gt; (HasSettings =&gt; a) -&gt; a withSettings = give getDir :: HasSettings =&gt; String getDir = dir given isMultiuser :: HasSettings =&gt; Bool isMultiuser = multiuser given 
[Show me the code!](https://i.imgur.com/JyWhzi4.jpg)
That is pretty awesome. So you get almost an AST that you can interpret. I wonder if a free monad could have been used to the same affect?
Might wait until Snap 1.0 is out - it's close.
&gt; A monad is a context that supports injecting function application and conditional control flow (if/switch/case/some loops) into the context. Nope, and I wish people would stop doing this. Yet another leaky monad analogy does not help anyone.
Ah, I did not realize 'wormhole' had a technical meaning in the FRP literature, I'll have to take at that ref.
I have some related work: * [Assembly: Circular Programming with Recursive do](https://www.haskell.org/wikiupload/1/14/TMR-Issue6.pdf) * [ICFP 2014 Post-Mortem](http://r6.ca/blog/20140803T030905Z.html) where I have a refined version of the above based on a pseudonymous paste I found some years ago but was unable to relocate. My first article and this article use isomorphic implementations. My second article is based on the observation that was noted by someone else who I don't know, that there is an invariant in the datastructure. The output loc is always equal to the input loc plus the length of the list, and is therefore redundant.
As a Haskell server engineer, this makes me all twitchy. I want people to stay the hell out of running processes on production servers, not go around prodding them. Like hot code swapping, this sounds like a feature that would mostly be used in development.
Thanks Paul! I figured this was just an oversight, and I'm glad you'll look into it. Mainly, I think wormholes a la Yale are really neat, and I'd rather keep them from getting muddied up with other things.
Wow, I can't believe the downvotes. http://joeyh.name/blog/entry/a_brainfuck_monad/
Maybe just me, but I think the 1st example could use some newlines. Everything just sort of runs together imo. I noticed that the URLs linking out to elasticsearch.org were getting mangled by haddock, so I made [PR fixing that](https://github.com/bitemyapp/bloodhound/pull/21/files).
This is great. I dislike the currently existing installers' habit of bloating the PATH variable.
&gt; Could use some newlines If you can make the doctests still compile and the haddocks still render properly with newlines, it's all yours. When I tried to space things out, everything went to hell. Maybe there's a trick I didn't think of. I had to summon and then cast into outer darkness at least three Princes of Hell before I could even include the $setup preamble in the Haddocks. (Thanks again [Simon](https://twitter.com/solirc_), you're a saint!)
This seems very useful (btw, why doesn't the HP distribution ship with msys?)
"Sell not virtue to purchase wealth, nor Liberty to purchase power." B.F.
f*ck, not fuck.
&gt; Nope Really? Can you give me a monad that isn't that? 
Well what does it mean to be a "context" and to "inject function application" and "conditional control flow"?
Alright, I'll try to get these uploaded, with the `Server` type family separate from the class.
As /u/tomejaguar suggests, I might be able to if I knew what the terms you are using are supposed to mean.
One of the annoying things with the free monad approach (that I *did* try, earlier on) is that you would have to list all the combinators in your functor (or at least have there something that lets you express all of them). Here you can add new interpretations (classes like `HasServer`) and new combinators (like `Get`, `ReqBody`, etc) whenever you want, comes in quite handy!
The link is broken. Can you fix/update it?
NSFW and Brainfuck is censored? For fucks sake...
Since you posted this Opaleye has been released. One way of thinking of it is as a much higher level, typesafe and composable wrapper around postgresql-simple. http://hackage.haskell.org/package/opaleye
I've never really used ASCII for haskell as this is our first assignment and was never really thought any of that for display. We've only been doing tree and stuff. Is there anywhere I could look how to do this up?
Yep, except my source language is haskell, rather than your "simple ad-hoc language". Here's an example of using a fair bit of haskell to generate brainfuck code. (Leaving out the implementation of a few things like addition and multiplication in brainfuck.) -- | Optimized to use less space. helloworld' :: String helloworld' = brainfuckConstants 1 $ flip display "hello, world!" -- | Displays a string. Tries to generate a fairly small brainfuck program, -- using a few encoding tricks. display :: Constants -&gt; String -&gt; BrainFuck () display constants s = start &gt;&gt;= go True (map Char.ord s) where -- Get to letter 104 ('a' is 97) quickly by multiplication. start = do zero x &lt;- addr add 13 mult constants x 8 return (13 * 8) go _ [] n = return () go started (c:cs) n | not started &amp;&amp; delta &gt; 13 = start &gt;&gt;= go True (c:cs) | otherwise = do if abs delta &lt; c then multi (if delta &gt; 0 then incr else decr) (abs delta) else set c output go False cs c where delta = c - n Generates this brainfuck program. +&gt;&gt;[-]+++++++++++++[&lt;+&gt;-]&lt;[&lt;+++++++[&gt;&gt;+&lt;&lt;-]+&gt;-]&gt;.---.+++++++..+++.[-]++++++++++++++++++++++++++++++++++++++++++++.------------.[-]+++++++++++++[&lt;+&gt;-]&lt;[&lt;+++++++[&gt;&gt;+&lt;&lt;-]+&gt;-]&gt;+++++++++++++++.--------.+++.------.--------.[-]+++++++++++++++++++++++++++++++++. 
Beautiful documentation. How much time do you think it took to document the library compared to writing the code itself?
A NSFW Haskell post, that's a first.
After seeing the infinite loop problem you had, I ask myself if you can implement it using arrows instead of monads. This way, you could probably use ArrowLoop to avoid this issue. 
I started reading that paper but was terrified when it involved using unsafePerformIO and the ffi to work. Seemed super nasty to me. 
Yes, something like this. This seems to work correctly for binary trees, actually. (btw if you want to preserve formatting, indent code by four spaces)
&gt; brainfuck doesn't let you set data to some fixed value like 0 or 1! You can get to zero (`[-]`) and everything else follows from that. 
It has been a problem for me a few times. Not in itself but because other tools include their own version of the c++ gnu toolchain. Then you have fun error messages when you try to compile a c++ library and the build script select gcc in one place and ld in another one. Bonus points if you have 32bits &amp; 64 bits versions sitting around. These days I am more careful about what goes in the PATH, but it was certainly a pain point when I was starting to install every development tools available and got stuck on ungooglable error messages. see: http://stackoverflow.com/questions/21553435/error-when-updating-cabal
`WriterT`'s bad reputation is somewhat undeserved. &gt; However, this comes with the caveats of using WriterT [a], which is that it will leak space like crazy for a large assembly computation (even if you don't log anything!). This is wrong. *Main Control.Monad&gt; take 2 . flip evalState 0 . execWriterT $ forever (byte 4) [4,4] Also, when complied with -O2 then main = print . flip evalState 0 . execWriterT $ forever (byte 4) appears to run in constant memory.
Yeah, this will print binary and avl trees. How would I adapt it for 2,3,4 trees? 
Once GHC upgrades, we'll pick it up automatically. The idea is to be the ideal GHC experience, so things "just work", but ultimately things like which versions etc to use are things we'll follow their lead on (within reason).
I've also just updated a post with a link to your comment and a clarification about how I am using 'wormhole' more colloquially.
I would sit down and think? Do you understand how the above code works? That would be the first step. 
Huh. I guess that works because the whole stack is lazy. However, if you make the base `State` monad strict then `WriterT` leaks space: &gt;&gt;&gt; import Control.Monad.Trans.Writer &gt;&gt;&gt; import Control.Monad.Trans.State.Strict &gt;&gt;&gt; import Control.Monad.Trans.Class &gt;&gt;&gt; import Control.Monad &gt;&gt;&gt; runStateT (execWriterT (forever (lift (put 1)))) 0 -- Leaks space
A few that come to mind: * FP, obviously * Monads: calling in/out of * Immutability by default * Laziness by default * Dense error messages: helpful, somewhat intimidating * Purity/impurity: knowing how to decompose problems * Heavy jargon: you need to be willing to trust you'll get it when you need it
This is such an accurate list.
I don't think there's a trade off. They're not the same thing, but being better at one doesn't mean being worse at the other! The trade-off between advanced techniques and simplicity is often there, but also sometimes a nice use of GADTs or the like can lead to vastly simpler code, by allowing users to statically guarantee more safety and omit runtime checks, etc. Knowing these techniques and tools well in part is learning enough to know when _not to_ use them.
I understand how it works. I would need to accommodate for different leafs with more args. My Root has 3 args (Root n lst rst), second leaf has 5 args and third leaf has 8 args. Would I need to duplicate this three time to accommodate the other leafs? eg - (secondLeaf n lst mlst mrst rst) eg - (thirdLeaf t t1 t2 n lst mlst mrst rst)
&gt; I think that "writing" code yourself is a bit secondary. What helps a lot is reading elegant code of more experienced people and experimenting with it. I'm sure it's both. Often you don't understand why things are made the way they are until you write your own code.
I forgot who I got this from but I've heard that brand new beginners should spend most of their time writing code, and as they get more experienced, the balance should shift to reading code. I can relate to that. When I started learning Haskell, I spent a lot of time reading blog posts and other resources and not much time writing code. I was learning but I found my retention wasn't great. It was like some form of analysis paralysis. I got the biggest gains when I stopped reading and just started working on projects. I churned out pretty crappy projects to start with but I kept them focused on one concept (monads, parsing, web services) and it prompted me to investigate libraries and do a lot more informed reading.
How/where do you launch the test server? Does it need to be done manually?
It's intentionally vague to avoid jargon and lean more on using and building intuition instead of formalism, while still trying to cover all monads. "context" is supposed to give the intuition of a functor. I'd say container, but it's more general than that, also covering things like generators or functions-returning-an-X. "inject" means that instead of extracting values from the context, operating on them, and building a new, simliar context around them, I push the operation inside the same context. In fact, for an arbitrary monad you may not be able to do the extraction part, as a correctness guarantee, but that's not mentioned initially. Injecting "function application" corresponds loosely to the existence of `ap`. Specifically that I can apply `m (a -&gt;b)` or `a -&gt; b` to `m a` and get an `m b`. Injecting "conditional control flow" means that I can make decision based on this things in the context when doing function application. It corresponds loosely to being able to apply `a -&gt; m b` to an `m a` and get an `m b` (bind). Depending on the mentee, we'll often just start with being able to apply `Bool -&gt; m a` -- if expressions.
Replied [there](http://www.reddit.com/r/haskell/comments/2ozu1x/an_asm_monad/cmsxmiw).
download and unpack the elasticsearch tarball, cd into unpacked tarball, run `./bin/elasticsearch`. (assumes you have JDK/JRE installed of some sort) No configuration, `cabal test` should just pass. I use TravisCI, see my [builds](https://travis-ci.org/bitemyapp/bloodhound) and [yml](https://github.com/bitemyapp/bloodhound/blob/master/.travis.yml) to learn more.
Thank you! Pretty minimal, at least as far these examples are concerned. Getting doctests to work took several times longer than the doctest examples. This brought me to 100% example coverage on the Client module, I will catch up the Types module later. Some guesstimates: 10 - 1 implementation - doctest example time ratio [2-5] - 1 implementation - proper test/spec time ratio Conclusion: if you get somebody to help you integrate doctests, there's no reason not to put examples in like I did with Bloodhound or the `lens` developers do.
I'd say that Haskell feels like a language which needs a programmers mind to be mature enough... This mind will be already tired of implicit state management hell, it will be experienced in learning and opened to it. Or it can be a beginners mind which is clean and ready to grasp whatever comes to it. For those having something in the middle... Haskell just wouldn't stick IMO...
Ok thanks. I will have a go at it for the next few hours. 
Haskell IS sexy though...
I like all the examples, but I don't understand the purpose for this: getStatus :: Server -&gt; IO (Maybe Status) getStatus fetches the Status of a Server That really just adds more duplicated "code/documentation" that you will have to maintain as a library author. If the type-signature does not speak for itself, then a quick note what the function does is very helpful. Otherwise I find it counterproductive. 
Too bad that's not true of Haskell. Laziness gets us all those (potential) cycles back. This is mostly because laziness is a form of limited mutability, at the level the garbage collector needs to operate at.
&gt; If we program in a pure functional language, then under the usual implementation strategies, there will never be nontrivial cycles in the heap. I don't get this. Why isn't x = 1 : x a counterexample?
&gt; This makes sense at least from the POV of avoiding other people having to go through the pain of integrating doctests - I've already figured it out. What was so painful? I simply write my doctests using the usual syntax and they show up on hackage when it builds the docs, I didn't have to do anything.
https://github.com/bitemyapp/bloodhound/commits/master Briefly: the formatting is extremely finicky, getting things like OverloadedStrings to work was annoying. (doctests doesn't see any of Cabal's stuff, you have to manually refer to package-dbs, thus default-extensions doesn't work) Also you have to run `cabal configure` when you have a custom Setup.hs.
Yeah it doesn't replace my HSpec tests, this is just so my examples are type-checked and tested :)
I want to be able to query their state. I have infrastructure in place to do this, but it is ad-hoc incomplete. Runtime support could help.
&gt; Next point of order: are people (their companies, really) using Haskell in industry prepared to pay to get better documentation and examples? That's a good question. My feeling is that no company would be interested enough in documenting libraries to finance this. (It very well may be that some companies would support this to advertize themselves, or generally to invest in the community/ecosystem — similar to what Google does with Summer of Code.) The people who complain about the docs are usually new to Haskell and aren't sufficiently invested in it to pay money for the docs. And the people who already got a Haskell job (esp. a well-paying one) are mostly qualified enough to understand how to use a Haskell library, even if it means peeking at the source code (usually it doesn't). These two groups don't intersect much, I think. This is not to say the problem doesn't exist; it's just people who suffer from it are unlikely to invest in a solution.
&gt;My feeling is that no company would be interested enough in documenting libraries to finance this. That's why I was suggesting Snowdrift with the notion that maybe companies wouldn't be willing to shoulder the burden for an entire library single-handedly, but companies could pitch in across a span of libraries. &gt;The people who complain about the docs are usually new to Haskell and aren't sufficiently invested in it to pay money for the docs. I don't mean them, I mean companies that want to reduce employee onboarding time. Even in that case, I think it'll be difficult to get people to pay for better libraries/documentation without something like Snowdrift.
&gt; so my examples are type-checked and tested :) A worthy goal. 
Took me a while to figure that out. Then I used that to write a higher-level alloc function, which basically bootstraps brainfuck up to easily useful. -- | For higher-level programming in brainfuck, it's useful to have a way -- to run a function, while allocating a memory cell, which is initialized -- to contain 0. -- -- This and many of the functions below assume that -- cells to the left are in use, while cells to the right -- are unused and may contain any data. Higher-level functions should -- generally avoid changing the current cell, and should instead alloc -- a new one to use. alloc :: BrainFuck a -&gt; BrainFuck a alloc a = do next zero cell &lt;- addr r &lt;- a setAddr cell prev return r 
Any Haskell business will profit from paying for documentation with an increase of the pool of possible Haskell employees in the future. There is a reason that Haskell developers are few and far between, and I believe one of the main reasons is insufficient newbie-friendly documentation. 
The first five or six paragraphs of this serve as a really great, high-level introduction to generational garbage collection basics.
&gt;There is a reason that Haskell developers are few and far between, and I believe one of the main reasons is insufficient newbie-friendly documentation. I agree 100%. I think one of the other main reasons is the lack of a sufficiently comprehensive introduction to Haskell. The problem is figuring out how to get companies who already use Haskell to be willing to invest in the ecosystem. Haskell.org has sponsors, maybe the infra/committee people have ideas?
&gt;Effort put towards those kinds of projects benefits the community far more than documentation I teach a lot of new people. Most of those new people go on to attempt practical projects after doing some introductory material &amp; exercises. They get stumped by Haskell *libraries*, not Haskell itself. Or inefficiencies in their text editors. My priorities lie in preventing new people from getting stuck as that is far more serious than a suboptimal Emacs/vim workflow.
Maybe. But that's very speculative. There's no way you can be confident that money spent on documenting package xyz would contribute significantly to your hiring pool in the future. Even if you could have reasonable confidence in that, it's still a really long bet and there are a lot of confounding factors. In my experience companies usually want to spend money on something that will have a more direct and tangible impact.
I think the article assumes a strict language like ML, where you have inductive datatypes whose values can't be infinite.
Hmm, I haven't implemented a mod function in brainfuck, yet. I'd also need a when0 function, which is easy to write (I already have an unless0 written.) And I'd need a dup function, which copies some location in memory to the memory location that the data pointer is pointing to. And oh yeah, I'd need a decimalOutput function, which prints out the current memory value in decimal. Assuming all those prerequsites, I think it would look something like this: euler1 :: BrainFuck euler1 = alloc' $ \result -&gt; alloc' $ \scratch -&gt; do let accum i = do setAddr scratch dup i setAddr result sumNext let checkmod i n = alloc $ do dup i mod n when0 $ accum i loopFrom 1000 $ \i -&gt; do decr alloc $ do checkmod i 5 print0 unless0 $ checkmod 1 3 setAddr result decimalOutput Hmm, there might be some complications involving the number 1000. First, loopFrom 1000 naively populates the loop counter using 1000 &gt; operations. I have a multiply function built, so it could just multiple 10 * 10 * 10 to avoid that. Second, brainfuck memory cells probably only go up to 255? I haven't checked. Would certianly complicate things a lot to need to write double-cell math.
That's a good idea, this was a first pass at migrating examples from the README. One thing I considered was demonstrating what the output looks like, but I didn't want to make them full-blown tests overmuch. Also these are the more trivial functions, this approach will make a bigger difference in the Types module.
Someone from Carnegie Mellon wouldn't let you do that :)
Your last sentence nails it on the head for me. *I* don't necessarily need better docs but the people I train and work with often do (and request it). I would probably be inclined to pay for documentation if only to help provide resources where people are willing to put effort and time.
As I understand it, the claim is that the only way you can create a cycle in a pure functional programming language is through a recursive function, as in your example. If you design your programming language and garbage collector so that such recursive calls result in weak references (that don't increment the reference count) then you won't have cycles (of strong references) and the reference counting garbage collector won't need to check for cycles.
&gt; Though I couldn't understand the type errors, I tried to type check my simple programs. Whenever I think about people learning Haskell I think about what happens when beginners make simple typos: Prelude&gt; map 1 [0.. 2] &lt;interactive&gt;:2:1: Could not deduce (Num (Integer -&gt; b)) arising from the ambiguity check for ‛it’ from the context (Enum a, Num (a -&gt; b), Num a) bound by the inferred type for ‛it’: (Enum a, Num (a -&gt; b), Num a) =&gt; [b] at &lt;interactive&gt;:2:1-13 When checking that ‛it’ has the inferred type ‛forall a b. (Enum a, Num (a -&gt; b), Num a) =&gt; [b]’ Probable cause: the inferred type is ambiguous The message does not explain what is wrong in a way new users can understand ('1' is not a function). Even after reading it, I don't understand why defaulting to Integer happened in some places and not others in this message. It doesn't read like a message for my consumption, but more like the compiler started to mumble to itself out loud and I overheard some of it. Honestly I mostly see the line number and then go to the line and fix the type error without ever reading the error message, which I guess is sort of the authors point. When you like something enough, you overlook it's flaws, or accept them and move on. 
I'm not talking about specific text editor efficiencies. I'm talking about being able to run something that analyzes my whole module (perhaps compiling it and noticing the missing symbol errors), adding all the needed imports, and removing the ones that aren't needed. It knows what packages are in scope from my .cabal file and uses those packages as its first guess. For things that are ambiguous it asks me which one I want to use. Another example is refactoring. Say I have several functions that all run in the same monad and the type signature is "(MonadIO m, MonadState Foo m) =&gt; ... -&gt; m ()". Then I refactor my app so that instead of using the m type variable I want to switch everything to use my own concrete Foo monad. Things like this are time consuming and should be able to be automated. Tools such as these would save me WAY more time than better docs ever would.
I use ghc-mod and Chris Done's ghci-ng / interactive-haskell-mode stuff. The latter is recent, the former I've been doing for a long time.
This is a first pass at the Client module, which is the more spare and simple of the modules in Bloodhound. The [types](http://hackage.haskell.org/package/bloodhound-0.5.0.1/docs/Database-Bloodhound-Types.html) and how they relate to the Elasticsearch documentation is more difficult for people to figure out. I'm thinking about ways to make the examples for the Client module more meaningful (roche had constructive suggestions), but mostly this was a test-run for the types. Edit: In fact, I think I'd get a lot of benefit out of just reordering the exports.
You've pointed to the branch name instead of a specific commit, so I don't understand which commit you're trying to point me at. The only one I found which mentions doctests is [this](https://github.com/bitemyapp/bloodhound/commit/5699a8dde99ba3ffa963bd80b0a8a87287711747) one, and I don't see how it illustrates any of what you mentionned. Did you manage to get OverloadedStrings to work?
I dashed off a link to the commit history on purpose. The fixes were spread across several commits and there was more than one fix. You weren't specific in what you wanted to know. OverloadedStrings is working fine, you drop default-extensions and add all your pragmas to the top of the file. The one where [I thank Simon Hengel](https://github.com/bitemyapp/bloodhound/commit/5c2ebe8c13ad9914bb44ec46961a17bdd9c01c7b) is the one where I figured out how to add the $setup preamble to the top of the module documentation (with his help).
&gt; Tools such as these would save me WAY more time than better docs ever would. Are you willing to pay for somebody's time to write them in the open? Not alone, paying into a pool as a group.
You can build an interpreter by composing my monad transformers, if you get what I mean. /nudge nudge wink wink. Ok I'll see myself out.
If I was convinced that the project had a reasonable chance of success, then I'd even be willing to put a small amount of my *personal* money towards it. I can't speak definitively for a company, but I know how much time I spend managing import lists, so I'm pretty sure I could convince the money people it would be worth it to spend some amount of money to support a serious proposal.
You should start a thread specifically about editor tooling upgrades, soliciting ideas for improvements, and see if people are willing to pool money for it.
How hard would it be to build like a Google Forms of the the top 50 or so libraries that need documentation and then submit it here for people to vote on? And then post the results and ask for a volunteers to help improve the most desired libraries. I recall there was a Haskell [array computing poll](https://docs.google.com/forms/d/1qXPUR19kjKghrdxvE7P767HNy9-Lj81VSDS-l5MfN8M/viewanalytics) a while back that gave meaningful data to developers about what users wanted to see.
I feel I haven't really done this extension justice - but while writing this I realised that it's really hard to give general coverage to extensions this broad! Hopefully this will be useful to people who are new to type families though :)
&gt; There is a reason that Haskell developers are few and far between, and I believe one of the main reasons is insufficient newbie-friendly documentation. I think the question we're all asking is how do we short circuit the vicious cycle of (lack of volunteers)/(barrier to entry) and onboard more people. A lot of languages go through this "hype cycle" at the very beginning of their lives that results in a massive influx of volunteers very early. Haskell never really had this being more on the slow and "avoid success" track for most of the it's early life. If that means paying some volunteers to improve critical missing pieces, I certainly would be willing to donate to a taskforce of some sort. I think the return on investment at this stage in Haskell's community lifecycle would be tenfold for someone looking to develop a career in this space either as a contributor or writer.
This weekend might be a good time for it since my coauthor is busy lately anyway. I'll see if I can take a shot at it. Thanks for linking the past poll and for the idea, this is great!
You may find this interesting: http://esolangs.org/wiki/Brainfuck_algorithms
Maybe divide the voting between different domains so that the data isn't so noisy. I.e. Voting for desired web development libraries doesn't overlap with the most desired numeric libraries because a lot of times the user groups don't intersect much. As we learned from the "Intermediate Haskell" thread the last week.
I think a big problem with voting, especially with web frameworks, will be inconsistent *awareness* of documentation. Happstack, Snap, and Yesod each have books of a sort, but not all are free nor are any in Hackage. I'll give this some thought.
Naw, we should just have `value families` to go with it :)
&gt; OverloadedStrings is working fine, you drop default-extensions and add all your pragmas to the top of the file. That doesn't work for me: {-# LANGUAGE OverloadedStrings #-} import Data.Text.IO as T -- | -- &gt;&gt;&gt; T.putStrLn "hello" -- hello -- &gt;&gt;&gt; main -- hello main :: IO () main = Prelude.putStrLn "hello" and then: $ ./.cabal-sandbox/bin/doctest.exe Main.hs ### Failure in Main.hs:6: expression `T.putStrLn "hello"' expected: hello but got: &lt;interactive&gt;:20:12: Couldn't match expected type `Data.Text.Internal.Text' with actual type `[Char]' In the first argument of `T.putStrLn', namely `"hello"' In the expression: T.putStrLn "hello" In an equation for `it': it = T.putStrLn "hello" Examples: 2 Tried: 1 Errors: 0 Failures: 1
Welcome to the trough of doctest sorrow. Look at Bloodhound or lens code for ideas. Alternately, put up a github repo with a cabal file and the source somebody can poke at.
Yeah, I really only started to understand its power when I realized that type families is just a fancy name for (open) type level functions.
I'm sort of fond of how I introduce `TypeFamilies` in [this tutorial](http://brandon.si/code/a-typefamilies-primer/), considering type synonyms as basic type-level functions (natural transformations), and then looking at what `TypeFamilies` gives you.
OP's original point still stands though; the cycles are lexically visible in the structure of the program, right?
I reproduced the first cheat here. I think from it you can probably figure out the other one. First, here's a little module using your trick: {-# LANGUAGE ImplicitParams #-} {-# LANGUAGE ConstraintKinds #-} {-# LANGUAGE RankNTypes #-} module Foo (MPI (), withMPI, foo) where data MPISecret = MPISecret type MPI = ?mpi_secret :: MPISecret withMPI :: (MPI =&gt; IO a) -&gt; IO a withMPI action = let ?mpi_secret = MPISecret in action foo :: MPI =&gt; IO Int foo = return 42 And here's a way for me to break it: {-# LANGUAGE ImplicitParams #-} module Bar where import Foo cheating :: IO Int cheating = do a &lt;- withMPI returnSecret let ?mpi_secret = a foo where returnSecret = return ?mpi_secret Basically, type synonyms are not as opaque as you may think.
Well that's one critical difference, that's *not* how I invoke doctests. I don't call it directly, I use a Cabal file and a custom Setup.hs. And yeah, it's hard to setup. That's partly why I'm offering to do it for other people.
Only if you are using lazy instead of by-name semantics.
*Strictly speaking*, Haskell is allowed to be implemented using by-name semantics.
It's because of how the brain learns. The brain works through associations, and groups things together as much as possible. In the beginning of learning (anything) you need to *do* it. Do it often, do it quickly, do it over and over, just do it even if you're doing a terrible job of it. After a while you'll have built up a library of associations in your brain that you can link to outside information easier, and you'll have a much deeper understanding of what you don't know and what you need to look up/learn. It's why I, as a fairly decent gymnast, can learn so much from just watching videos. I have years of training behind it to reference it. Learning something like Haskell or physics? In one ear and out the other unless I write stuff down, play with it, etc. Eventually, I'll be able to just read and synthesize from pure experiences but until then, practical experience trumps theory.
I prefer "the tests are the docs" to "the docs are the tests" but given the primacy of Haddock in understanding packages this seems ok. I think a "search for usages of this function/class/etc in the associated tests" feature would be better though. Specifically, I don't like the large preamble section.
I'm skeptical of the usefulness of examples built on the level of single functions. Understanding any one function isn't usually difficult--the hard thing is figuring out how all of a library's functions fit together. One documentation approach that I do find appealing is to put examples in the test suite example. It's based on the idea that unit tests can look a lot (exactly?) like real world examples. In snap we have [this](https://github.com/snapframework/snap/blob/0.13-stable/test/suite/Blackbox/App.hs) in our test suite. That is an actual snap application that the test suite runs and issues requests to. It's a little bit contrived because we're trying to test certain code paths, but it is a working example of an app. In snaplet-postgresql-simple I have [something similar](https://github.com/mightybyte/snaplet-postgresql-simple/blob/master/example/Site.hs). Again, it is a complete application that I think functions as a decent example that can get newcomers started. In that case, I didn't actually put it into a test suite, but I probably should. The problem is that we're bad at pointing these examples out. This is where I can see potential to get a lot of benefit for a pretty small amount of effort. It could be a small pull request to put a link to the file somewhere on the main hackage page. Or it could be a slightly larger pull request that adds a self-contained example to the project's test suite. I think it's very important that these things are in the test suite because that will ensure that they stay up to date. EDIT: Oh, someone else just made essentially the same point in [another comment](http://www.reddit.com/r/haskell/comments/2p3g64/who_wants_help_documenting_their_libraries_are/cmt670i).
The FFI was only needed in reifying storable instances because the FFI does not work in ST. If you could serialize values in the ST monad using e.g. peek, poke, then there would be no need for unsafePerformIO. It is also completely unnecessary for the most common types of things you need as opposed to arbitrary values where you need to use a `StablePtr`. It's actually a pretty elegant paper, all things considered. I consider `unsafePerformIO` a pretty necessary part of the FFI; whether or not you think using the FFI *at all* constitutes a hack here is up to you, I guess. And if that scares you, the actual reflection library might scare you more; it has a significantly different formulation internally that while elegant requires quite a lot more magic to understand. OTOH, that magic is pretty stable, and it's about 5 orders of magnitude more efficient. EDIT: Beware! The entire paper in like 7 lines: data Proxy t = Proxy class Reifies s a | s -&gt; a where reflect :: proxy s -&gt; a newtype Magic a r = Magic (forall (s :: *). Reifies s a =&gt; Proxy s -&gt; r) reify :: forall a r. a -&gt; (forall (s :: *). Reifies s a =&gt; Proxy s -&gt; r) -&gt; r reify a k = unsafeCoerce (Magic k :: Magic a r) (const a) Proxy {-# INLINE reify #-}
Yes, that's what I mean: change and extend the existing code. Extending implies writing smaller amounts of code. Don't try to start a project from scratch as a beginner because you don't yet have experience in functional design and it'll feel completely hopeless.
&gt; I don't call it directly, I use a Cabal file and a custom Setup.hs. I don't see anything related to doctest in the latest version of your [Setup.hs](https://github.com/bitemyapp/bloodhound/blob/3d2cb86cb4576f46bc4349996a345bd84f95c950/Setup.hs) file. Seems to be mostly Haddock stuff? &gt; yeah, it's hard to setup. That's not my experience at all. I thought the lack of support for OverloadedStrings was a limitation, which is why I'm trying to figure out how you managed to get it working, but don't have any complaints regarding setup at all. Either `doctest Main.hs` if I'm using a command-based build system such as Make, Shake or Travis, or `doctest ["Main.hs"]` if I need to run the tests from Haskell code, if I want to support "cabal test" for example.
https://github.com/bitemyapp/bloodhound/blob/3d2cb86cb4576f46bc4349996a345bd84f95c950/tests/doctests.hsc#L19 https://github.com/bitemyapp/bloodhound/blob/3d2cb86cb4576f46bc4349996a345bd84f95c950/Setup.hs#L40-L43 Can't say with any certainty that it's related to your problem, but the Setup.hs has to be executed or the doctests won't work.
Yeah, in most implementations, cells are one byte, and wrap. 
BTW, gelisam, I haven't used doctests but the documentation explains why your example does not work. Basically, out of the box you need to also tell doctests to use OverloadedStrings — look for OverloadedStrings here: https://github.com/sol/doctest#readme
Or closed!
Thanks, it worked! Now we know about our other documentation problem: some of us don't read them :) (I was saying that as a joke: I have read this documentation a while ago, but it didn't contain the OverloadedStrings bit at the time. Glad to see it was updated since!)
Ah, that is incredibly good to know. Thank you for taking the time to write up an example for me! :-)
Given the way in which doctest is implemented (it launches ghci and pipes commands to it), I think the fact that `set +XOverloadedStrings` works is a happy accident. In fact, we probably *don't* want that behaviour, because if you have one file which requires OverloadedStrings and one file which requires *not* having OverloadedStrings (because the types would be ambiguous otherwise), then since the same ghci session is reused, depending on the order in which doctest runs the test, OverloadedStrings may be incorrectly enabled in the tests of the second file. This can be fixed by putting `:set -XNoOverloadedStrings` in the second file, but still, it's a part of the implementation which leaks into the user experience. So yeah, I think it would make a lot of sense for doctest to parse the language extensions of the file and to enable/disable them on its own instead of relying on the user to trick the implementation.
Great tutorial indeed, thanks! $1 /u/changetip
Of course, the haskell type system could be used in the usual ways to make a DoubleCellPointer type, and use typeclasses to make arithmetic functions work on both DoubleCellPointer and CellPointer. Though I suppose they couldn't be instances of Num, since the implementations are monadic.
My genetic algorithms lib could use more documentation, pull requests welcome. https://github.com/mcandre/genetics In particular, I'd appreciate example instances of my `Gene` type class, anything you'd imagine would be a good example besides the given Hello World program.
Wow, thanks! I didn't know that OCaml allowed circular values. I'm a bit more familiar with SML, which disallows them I think.
The function is `x`, and has 0 arguments.
Strictly speaking inductive data types are always finite. Data types that can be infinite are called coinductive. Haskell, being a turing complete language, doesn't distinguish between inductive/coinductive. The distinction is very relevant for dependently typed languages, since in order for programs to work as proofs via the Curry-Howard isomorphism, they have to be terminating. That is achieved by ensuring that all data is finite (inductive) or co-finite (coinductive), which means that the consumer of the data must be finite. For example the consumer of a potentially infinite list may only look at a fixed bounded prefix of its input list (e.g. `take 10 xs`), whereas a consumer of a finite list can look at an unbounded number of elements (e.g. `sum xs`)
I, for one, am happy to review, polish up, and publish any documentation I'm sent.
I've done AVL before, but this feels so much cooler.
Taking a gander right now. One thing is you don't have a library or any modules. Do I have license to clean house and prep it for haddocks?
I know. It's why I put scare quotes on "inductive" -- in many extant languages, the distinction is not carefully made.
Functions in Haskell have 1 argument (and might return functions). The are no 0 argument functions in Haskell.
Can you show us a few examples of libraries that you struggled with, and a few examples of libraries that were easier to master?
&gt; and even the simplest types are expressed in the terms so abstract that it felt necessary to google for that GitHub repo Russian government banned GitHub over. Anyone knows the story behind this one?
I found the source code. I don't know what the precise licensing situation is though. https://github.com/bos/rwh
I'm not a fan of presentations -- do we have a code somewhere to read and understand how does that work? Is this going to be merged to OCaml or is it something experimental?
The working prototype is here: [https://github.com/ocamllabs/ocaml-modular-implicits](https://github.com/ocamllabs/ocaml-modular-implicits) You can experiment with it as the opam switch `4.02.0+modular-implicits`. It's too soon to know whether it will end up merged in the language. But I think the word is in the air that we will eventually need something type-class-like in any case. Something that is lacking from the presentations and prototype is a theoretical formulation of the typing rules (the change is non-trivial and could very well endanger soundness of the type system). I think/hope Leo White and Jeremy Yallop are working on this, and hopefully we'll have something more precise to discuss then.
&gt; If we had all that great documentation, what would that accomplish? A few people trying to learn Haskell might be able to do so a little more quickly. I think you are greatly underestimating the people who stop learning Haskell due to the lack of documentation. I think Haskell is a really interesting language and I very much enjoyed learning it. However, most of the programs I have written in it were trivial - Project Euler problems, toy things. Why haven't I been writing useful things in Haskell? It's too much effort. I'm happy to spend time learning new things but at the end of the day I would actually quite like to finish whatever project I have on the go in a decent length of time. This is very difficult in Haskell because of libraries which don't have good documentation. I probably could just battle on and fit the types together or whatever but why bother? I could get it done in Python in a lot less time. I would probably enjoy writing the actual code less but the lack of documentation is too painful to counteract this. On a slight tangent I often hear Haskell people trying to disprove the stereotype that you have to either be a genius or a category theory wizard to write Haskell code. And then people (maybe different ones, I don't know) go around saying there's no need for examples, or it isn't a pressing concern. I think these two stances are in conflict. &gt;The things I want are better tools Lots of languages became successful without good tooling. Python has only recently got a good IDE in PyCharm. Lack of good editor support does not put people off more than documentation, especially as a lot of people outside of Java prefer vim, emacs, sublime text or some other text editor that does not have the features you want. Also +100 to everything /u/SuperGinBaby said. **TLDR: Learning Haskell is fun - it's a new way of thinking that most haven't been exposed to. Using Haskell isn't fun - the joy of writing and thinking in Haskell is tempered by the pain of getting libraries to work. Tooling isn't more important than documentation.**
You are right of course. It is possible to make '1' a function though: Prelude&gt; instance Num b =&gt; Num (a-&gt;b) where fromInteger = const . fromInteger ... Prelude&gt; map 1 [0..2] [1,1,1] See also: * https://github.com/conal/NumInstances/blob/master/src/Data/NumInstances/Function.hs * http://stackoverflow.com/a/26515512
UPDATE: Docs are now fixed! UPDATE: In the meantime, basic docs can be found [here](http://eremondi.com/elm-build-lib/Language-Elm-Build.html). There are also some examples in the [Readme](https://github.com/JoeyEremondi/elm-build-lib). Hi all, I've released an updated version of my library elm-build-lib, and by updated I mean completely rewritten, totally different API, etc. This library lets you take multiple Elm sources and compile them to JavaScript from within Haskell, without performing any IO, with full access to the Standard Library. The main goal of this library is for using Haskell servers/backends with Elm frontends and GUIs. It could also be used with Hakyll. In the next month or so, I'd like to get Haskelm updated for 0.14, which should be the piece de resistance of my Haskell-Elm interactions. So stay tuned! As always, I'm open to feedback, criticisms, bug reports and pull requests! You can find it on [Hackage](http://hackage.haskell.org/package/elm-build-lib-0.14.0.0) or [Github](https://github.com/JoeyEremondi/elm-build-lib). Cheers! Joey EDIT: Bah, hackage docs not working. I'll try to fix them asap.
Interesting… I've written an RNCryptor implementation for fun a while ago. It has encryption and decryption, but no streaming interface. I'm not sure streaming is really appropriate for RNCryptor because the HMAC comes at the end of the file, so you have to read to the end in order to verify the message isn't corrupt or maliciously modified. And HMAC needs to be verified before decryption to prevent padding oracle attacks. My (largely untested) implementation [here as a gist](https://gist.github.com/kccqzy/92918e1c24a95e646357). Public domain.
Hey! Thanks for the gist, I will take a look later. Yes, I was talking with Rob Napier about the HMAC validation, and for now is something I'm not tackling yet, mostly for the complication you just said. But as I wrote in the blog post, I couldn't afford to load the entire crypto payload into memory, as most video we record can happily exceeds 2-3 GB, and we can potentially have many on them in transit in the server at any given time. 
&gt; I probably could just battle on and fit the types together or whatever but why bother? I could get it done in Python in a lot less time. I would probably enjoy writing the actual code less but the lack of documentation is too painful to counteract this. I have the same experience, in personal projects I'm generally willing to push through and figure the library out. At work, there's a lot of other constraints and spending time disproportionately large amounts of time figuring out to do the simplest of tasks ( compared to Perl/Python ) is generally not something I can justify. I also have to presume that I have to hand the code off to somebody and having it depend on 15 or indecipherable dependencies is just not practical. Haskell is on the cusp of of practical to use in industry, but I don't think it's quite there yet for most programmers. 
There's also a [pdf document on modular implicits](http://www.lpw25.net/ml2014.pdf) linked from the github.
A readme in the repo would be a nice start for documentation.
I've come to read "Could not deduce &lt;typeclass&gt; &lt;function&gt;" as what it is now with experience, but this was the first time I stopped to look at how silly it is. It's not only that the error is difficult – it's also a lot of printout that *I as an experienced programmer mostly ignore*, which is only ocassionally useful. How should a beginner know that it's usually okay to ignore most of that stuff? Perhaps the default should be to only print the first three lines of the error, with a message at the end saying "To see more details, compile with the -v flag" or whatever?
Should be up now. My bad!
http://www.reddit.com/r/haskell/search?q=nsfw%3Ayes&amp;restrict_sr=on&amp;sort=relevance&amp;t=all :(
Just expose as less as needed to use your library plus maybe some instances you think would make the life of your users easier. And after release wait for feature- and pull requests wishing or implementing this or that feature. 
My rule of thumb is to supply every instance that has a canonical implementation that is in my set of transitive imports. If I don't, I simply wind up forcing users who have a usecase I didn't intend to write orphan instances and make code that doesn't work with other code. Note: If the instance _isn't_ canonical on the other hand, I'll often leave it off, unless the special nature of the instance is the purpose of the data type in question. If I'm not already importing it, I then stop and debate about how all my code fits together. Ideally I'd like the tower of libraries I build up to all work together, which typically means having one import the other when I have a data type and a class defined in different packages.
You could start by shipping something that's minimal but useful and listening to your customers once you have some. Is easy to add extra bells and whistles once there's concrete evidence that they're worth the trouble to implement and maintain.
The former is apparently useful enough that it is [included in the `errors` package](http://hackage.haskell.org/package/errors-1.4.7/docs/Data-EitherR.html).
It was relaxed in one of the newer versions of GHC - I'm guessing 7.8.
That's essentially the same syntax I came up with [at one point](https://github.com/rust-lang/rust/issues/8277), except I had a placeholder symbol in the "empty slots". For Haskell you'd probably want a different one, maybe `.`. I'm not sure if this avoids all the ambiguities w.r.t. guards and whatever?
I guess devil is always in the details, but on first blush I really like this direction. This is what I would want for multiple backends, where you cannot afford/do not want to build up an intermediate representation. For instance at work we have fakes for the database, redis, etc. We use typeclasses but it is not the best fit, I can see this working better ... if it works ;)
Pull requests accepted.
While our Haskell builds are not as complex, we have also had a lot of success using Docker to manage them for continuous integration, creating binaries for deployment, etc. Nice to see more writeups of Docker as a part of the delivery process.
You could write a parallel set of posts about how Babylon 5 demonstrates the effects of normalization in database design, then have a crossover conclusion that brings linguists and programmers together. I hope you can include some code demos at some point!
&gt; That's a good question. My feeling is that no company would be interested enough in documenting libraries to finance this. Actually you are completely wrong about this. I have commissioned documentation for Snap in the past, and was prepared to pay for it out of my own pocket, but Erudify (now Better.com) stepped in and volunteered to pay for the work instead. Gabriel of pipes fame wrote much of the io-streams documentation, including this [tutorial module](http://hackage.haskell.org/package/io-streams-1.2.1.1/docs/System-IO-Streams-Tutorial.html) on the first contract, and Mikhail Glushenkov has been working on a similar contract basis writing better docs for the upcoming Snap 1.0 release. 
This installer is a bunch of ideas we would be very happy to be copied by both GHC and the Platform (ideally putting this installer out of business!). If it works out like we think it should, perhaps they will.
I think the name is a pun between [Modular type classes](http://www.mpi-sws.org/~dreyer/papers/mtc/main-long.pdf) work (which brings the idea of using the ML module system) and Scala's implicits.
Have you tried tweaking the GC RTS parameters? Maybe increasing the nursery size already helps reducing the overhead.
This series is great
Do you have a proof? And did you read Haskell Report? E.g. from section 41.5.3 of HR2010: &gt; readLn :: Read a =&gt; IO a &gt; The readLn function combines getLine and readIO There is no 0 argument function in math, but Haskell is not a math. Probably 0 argument function is not very useful concept in Haskell, but I don't understand why people care enough to comment in unrelated threads, but don't care enough to fix HR. Does the /u/_jameshales comment changes it's meaning when replacing "function" with e.g. "value" or "computation"?
I'm not quite sure if this is what you're looking for, but [copilot](http://leepike.github.io/Copilot/) might be of use :-)
The only thing a quick hackage search for rt turned up was this http://hackage.haskell.org/package/pipes-rt-0.4.2/docs/Pipes-RealTime.html I am not sure if the kind of accuracy you want is doable with that though or with the Haskell RTS in general. Usually the scheduler has to be involved in some way in hard real time guarrantees. Simon Marlow would probably the right kind of person to ask if the RTS is even designed to do this.
You probably already found this but just for those who want to have a look at the list of available parameters too it can be found [here](https://downloads.haskell.org/~ghc/7.8.3/docs/html/users_guide/runtime-control.html).
This is well motivated and demonstrated. This is sparing me some work for my book, thank you! :)
Are there any "best practices" for doing so? For instance, if I export a containerish datatype, it would make sense to provide an instance of Functor. But would it be worth it to also provide instances for Traversable and Foldable, or are those one of those "wait till users ask for it" features? Or maybe some of you guys have certain principles you try to follow, like maybe trying to make most of your types instances of Category or Monoid, or something like that. 
Or more generally: MonadState ByteString m =&gt; m (ByteString, ByteString, ByteString) Which can run in e.g. `StateT ByteString IO`, not just `State ByteString`.
No, that's a mistake, thanks for pointing it out! (I had hardcoded stdin in a previous version) Edit: didn't seem to affect much (thankfully?)
Is there a reason that you define the typeclass as class Store store m where ... instead of class (Monad m) =&gt; Store store m where ... Are there situations where m would not be a Monad, or is there some other reason for not constraining the type of m in the typeclass definition?
Hey, thanks for the links. I'm testing it out right now. After going for 8 minutes, its off by about 40ms (some of which is start/end time), which may or may not be acceptable. I'm not the actual domain expert here, just the coder. I'm testing it for a 25min run now, to see if it lags more, or if the 40ms is entirely start/end time.
I looked at it briefly, but I thought it wasn't what I wanted. I think I was looking at the wrong pages though. This might be useful, so I'll take another look. Pipes seems like it would be easier to use though. And I'm not sure about using network sockets with this.
Thanks for linking to these. I think I can use this with pipes-rt to build what I need.
You can do this with the functions: * Network.Socket.ByteString.sendAll * System.Timeout.timeout * Control.Concurrent.threadDelay * maybe System.CPUTime.getCPUTime (maybe because I am confused if the loop most happen within x ms or take exactly x ms, or do the individual entries have to take at most x ms?). It is possibly you will need a faster time mechanism and faster delay but I doubt it. 10 milliseconds is not that fast. Before you go off and try to do this with a library like Pipes, I would just do it by hand. I don't think for a task this simple you will gain anything by using more than the low level libraries.
After scratching the head a little, found out that it was quite trivial: instance Monoid (Meter a) where mempty = Meter $ \_ _ -&gt; 1 mappend (Meter m1) (Meter m2) = Meter $ \v1 v2 -&gt; m1 v1 v2 * m2 v1 v2 song :: Meter Song song = contramap songTitle text &lt;&gt; contramap songDuration int Still interested in alternative solutions, if somebody has any.
I get what is going on for the most part, literals are implemented through typeclasses with Haskell, but I can't really explain that to beginners that have not learned what typeclasses are yet. Beginners are forced to grapple with typeclasses day one. I would prefer if OverloadedIntegrals/OverloadedRationals existed and could be turned off for beginners, or just for myself sometimes.
"How To Prove It" by Velleman is at the root of most of my standard trees of book recommendations and is very approachable. It covers the basics of logic and set theory, and will open the door to a lot of other books. Just don't be scared off by the first chapter - it's making some higher level points using stuff that gets covered in depth much later in the book - but from that chapter after that onwards it starts simple and builds at gentle pace.
*Types and Programming Languages* by Benjamin Pierce is probably the most approachable introduction to type systems and programming language design. The code is in OCaml but it's not hard to translate the code or ideas into Haskell.
&gt; This is sparing me some work for my book, thank you! :) How does this spare you work for your book? If you want to include it it's probably going to be tricky, since it's published under [CC-BY-NC-ND](http://creativecommons.org/licenses/by-nc-nd/3.0/legalcode). That `NC` part prevents you from monetizing your book, while `ND` prevents you from editing the article (also, I'm not really sure how to interpret collection in sec 1.b, but it's rather late here). Just curious how you would include it in your book.
Thanks again for raising the issue of terminology. As this appears to be a common source of confusion, I have renamed the `halcyon deploy` command to `halcyon install`, so that the name better reflects what is actually happening.
There's no Haskell in the post, but there's Haskell under the hood. Language Engine is all in Haskell. :) Also it's relevant for type theoretically inclined people, because it pertains to the nature of the theory. I reply to your ramble (which you removed, and I've put below for posterity), what you're observing is that surface variation masks deeper semantic unification. Yes, perhaps. This is an old idea. Nothing fancy, tho, it's like in any program, where your definitions may all be built on Prelude functions, packaged different ways to yield different things. There are arguments for and against such "decompositional" approaches tho. One argument for it is that there seem to be many common properties across different words, where meaning and grammar seem to tie together (see Levin's Verb Classes and Alternations book for a survey, or Levin and Rappaport's Argument Realization for another kind of survey). On the other hand, if you pay attention to Levin's book, you'll notice that there is a long tail effect — a small number of verbs with clearly related meanings (motion, being-in-a-position, etc etc), and then a long tail of hard-to-classify verbs. To cope with the long tail, you end up having to propose more or less unique predicates for them, rather than a decompositional analysis into more basic terms. At that point, what is the decomposition buying you? It's not clear what the right answer is. &gt; I ran into such pains when messing with converting my ACE[1] parser into some kind of logic (ideally a queryable datalog). Simple statements like Barack Obama is the president of the United States has the implicit time of now, versus was which is "this predicate is true but only in a given context", so now all evaluation of facts in a datalog-like setting requires a load more inputs for tense. Anaphoric references are a cakewalk compared to tense. &gt; FWIW your use of an additional predicate parameter for time (or could be location) tense reminds me of Lojban. In Lojban there only predicates which take parameters "x1 klama x2 x3" =&gt; "x1 goes to x2 from origin x3 [via route x4]". You indicate tense with an additional indicator word "x1 klama ca le donri" "x1 goes during the day", or "x1 klama pu le donri" "x1 goes before the day". Or "x1 klama ca le donri vi lo rirni" "x1 goes during the day near a parent". It's not restricted to time, but location also works. Or even "x1 tavla bau la lojban" "x1 talks in-language lojban." &gt; What's the point in all this babble? It occurs to me that there is no difference in Lojban between "x1 tavla x2 x3 la lojban" =&gt; "x1 talks to x2 about subject x3 in language x4", and "x1 tavla x2 x3 bau la lojban" =&gt; "x1 talks to x2 about subject x3 in-language x4". Similarly in English, whether the main verb accepts parameters as arguments or "I eat an apple" vs "I talk TO John" vs "I talk IN english" it doesn't matter. In the end there's actually no verb. Is there a difference between "I walked and talked" and "I walked takingly" and "I talked wakingly" and "I talked while walking", "I sat" vs "I be'd sittingly" etc.? Beyond what you might consider style, not really. The predicates are the same. In Romanian, "worth" is a verb. "X worths" means "x is worth it". Italians don't say "I like it", they say "mi piace"--piacere means "to be pleasing", and "piace" is third person indicative meaning "is pleasing", "mi" is "a me" aka "to me". So "mi piace" is "it is pleasing to me". Tonnes of ways of saying the same thing. So I suspect the whole idea of modeling some statement of truth with some "main" argument isn't going to yield as many benefits as something more like a triple store model. Just have a list of predicates all treated equally valuable. &gt; Consider -- John was in the garden yesterday. When he stopped walking and stopped talking, did he cease to be in the garden yesterday? His time property and place property is as equally valuable as his other states. These properties are considered as one set of truth claims. You can unify them with another parameter like your "e", of course in a more FoL-y kind of way. But it would be nice if some kinds of predicates don't play second fiddle to what we as English speakers consider "main" predicates just because our language puts certain verbs on a high horse and not others. Example: &gt;give(e,Stephen,Dave,fruit basket) &gt;This can also be modeled: &gt; give-receive(e,Stephen,Dave) "Stephen gives to Dave" &gt; gift(e,fruit basket,Dave) "fruit basket is a gift for Dave, or, fruit basket gifts [Dave]" &gt;"Alice quickly speaks to Olivia in Greek today" &gt; language(e,Alice,Greek) &gt; time(e,Alice,today) &gt; speaks(e,Alice,Olivia) &gt; speed(e,Alice,quick) &gt; Along with your neat e event idea, maybe you can model one specific truth in all its properties without resorting to Englishisms (as often).
[Conceptual Mathematics by Lawvere and Schanuel](http://www.amazon.com/Conceptual-Mathematics-First-Introduction-Categories/dp/052171916X) is a good low level introduction to category theory (and a bit of set theory) if you are feeling shaky on those grounds. From there lots of books open up to you. The best books I know on how to "think" like a functional programmer are all written by Richard Bird. http://www.amazon.com/gp/product/1107452643/ref=pd_lpo_sbs_dp_ss_1?pf_rd_p=1944579842&amp;pf_rd_s=lpo-top-stripe-1&amp;pf_rd_t=201&amp;pf_rd_i=0134843460&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_r=090NKMWKY6078Z0WPCTW http://www.amazon.com/Pearls-Functional-Algorithm-Design-Richard/dp/0521513383 Not much is available in book form, especially that I can recommend on the FRP front. Dependent types is a broad area, you're going to find yourself reading a lot of research papers. You might be able to get by with something more practical like Chlipala's Certified Programming with Dependent Types, but if you want a more theoretical treatment then perhaps Zhaohui Luo's [Computation and Reasoning](http://www.amazon.com/Computation-Reasoning-Computer-International-Monographs/dp/0198538359) might be a better starting point.
I see a fair amount of confusion on the topic hindering new users on #haskell, so it's good to stamp that out when it comes up. The readLn bit is probably just sloppy language at that point in the report. I wouldn't use that as a definition. Conal Elliott has a nice blog post on this topic if you'd like to read more. 
Pull requests sent. https://github.com/mcandre/genetics/pull/1
&gt; Or perhaps you create some datatypes, which you believe your users may need to use lenses to use, so you provide those (and need another dependency to the lens library An `X.Y.Z.Lens` module is generally a great idea. But unless your lenses genuinely require combinators or some TH from some specific lens library, you should emphatically not incur a dependency on any. The whole point and essence of van Laarhoven lenses is that *they do not require you to incur a dependency on any specific van Laarhoven lens library; the principal types are already present in any Haskell module with RankNTypes enabled.* It is one thing to export a lens and another to import a lens library. If you want Hackage to recognize things as lenses, you just make a local synonymn for the Haskell-universal type. This advice of course only applies in the simplest case, which is the lens case. 
The contravariant analogue of `Applicative` is [`Divisible`](http://hackage.haskell.org/package/contravariant-1.2/docs/Data-Functor-Contravariant-Divisible.html). Here's your example using this class: instance Divisible Meter where divide f (Meter m1) (Meter m2) = Meter $ \v1 v2 -&gt; let (v11, v21) = f v1 (v12, v22) = f v2 in m1 v11 v12 * m2 v21 v22 conquer = Meter $ \_ _ -&gt; 1 song :: Meter Song song = divide (\s -&gt; (songTitle s, songDuration s)) text int It's pretty much a generalization of `Monoid`, with `mempty = conquer` and `mappend = divide (\x -&gt; (x, x))`.
Thanks for the pointers to Shade and Hplayground. It seems like there's a lot of common ground between Shade and blaze-react; the biggest differences seem to be their final-style HTML API versus our initial-style API, and their use of `Async` to relay user interactions versus our use of "actions". I think Hplayground takes more of a different approach. One key difference is that blaze-react apps are a *pure* description of your application logic - they're just state machines. This may seem constraining, but it allows you to do some interesting things with your apps. For instance, you could run it on a server for SEO, or in some kind of testing environment - there are a lot of exciting possibilities here. In contrast, the Hplayground TodoMVC example *has* to run in the browser, because it interacts directly with the HTML5 LocalStorage API. Clearly there's a balance to be struck here, between portability on the one hand, and access to the capabilities of the platform on the other. &gt; ghcjs is a year/six months behind of what was done in Haste. The two projects are taking different approaches, and I'm excited to see where both are going. I will say, however, that blaze-react won't compile with Haste, since it uses both `forkIO` and Template Haskell. &gt; blaze-react follows the react conventions, a mix of declarative and object oriented that is not a perfect match with haskell. I'm not sure what object oriented conventions blaze-react is supposed to be using. Could you elaborate on this?
I would agree that it's not exactly the Haskell code we want to make our example code, because it touches some GHC internals (or, I think it is internals). But, I don't think you've made the code that much more low-level. You still aren't referring to a MagicHash / unboxed type directly. You aren't manipulating `Ptr a` values or calling anything named unsafe\*. I think maybe the commenter on your answer was anticipating a pipes / conduit / io-streams solution... But, to me, there's really no clear indication *why* they think your code is not 'more idiomatic / "high level"'. I think you might be able to squeeze just a tiny bit more performance out by doing a worker/wrapper on "go" so it can be inlined, but I might be wrong there. (I.e. you don't have to pass the two arguments on each iteration of the loop.)
How are you compiling (GHC version and flags)? Have you tried profiling? And please provide a [SSCCE](http://sscce.org/).
I'm sure that's the case, but you've got some good examples that demonstrate how easily things become ambiguous and how your approach can deal with them. Seeing it move is compelling for programmers!
My code is: Short - about 100 lines. I wish it were shorter, but all those lines contribute to the speed of the program. Self-contained - there is only one source file which can be copied and pasted. I have linked to source file. Correct - My code compiles and works as expected, except the code is slower than I expected. As an example. You can run the executable produced by my code and it will print a number. The amount of time it takes to print this number is slower than I would like. For a better example, considering profiling the code yourself. I compiled using -O2 -threaded and -fprof-auto flags.
This: (nub $ possibleMoves color board) looks like it might be slowing things down as `nub` is a "quadratic" algorithm. Try moving duplicate detection into the fold by altering the function `f` like this: import qualified Data.Set as S let f' (set, (m,a,b)) move = if S.member m set then (set,(m,a,b)) else (S.insert m set, f (m,a,b) move) in snd $ foldl' f' (S.empty, (-(8^8), a, b) (possibleMoves color board) Profiling the code at https://github.com/DevJac/haskell-pentago shows that `possibleMoves` returns a list of 270 moves of which typically 170 are distinct. 
Thank you. I believe you are correct. I did some additional profiling and found that 77% of the runtime is being spent on that nub call specifically. Is there a way I can get a profile report which shows the time spent inside imported functions like nub, or other library functions?
The 24 Days of Hackage/24 DOGE are truly one of the wonders of the (Haskell) world. 
 type BoxId = Int type ShelfId = Int Rather than use `type`, you could use a `newtype` wrapper, so you can't just treat them as `Int`s without explicitly unwrapping them. If all your types are defined in a single module, and exported, you could just not export the constructors, making them black boxes which can only be manipulated by your API.
No, no real reason.
It's also NC-ND on the page, but I'm more than happy to loosen that if people contact me.
Instead of the boxes referencing the shelves, couldn't you make the shelves reference the boxes? Would there be other sources of cycles?
If I were doing this I would implement the model in a relational database. The database will take care of many, most or all of the constraints. The database can be queried and manipulated in a typesafe and composable way using [Opaleye](https://github.com/tomjaguarpaw/haskell-opaleye). [Disclaimer: I wrote Opaleye]
Did you mean how to make it easier to read? Maybe something like this: {-# LANGUAGE LambdaCase #-} getChar'' = hReady stdin &gt;&gt;= \case True -&gt; Just &lt;$&gt; getChar False -&gt; return Nothing 
Why does that code make you think you don't have a grasp on monads? There are certainly ways you could code-golf that, e.g.: then liftM Just getChar or then Just &lt;$&gt; getChar But the code you've written there is perfectly valid, legible Haskell. I'd recommend not second-guessing yourself, continue writing code, and over time, add idioms to your toolchain as you find them useful.
&gt; However, the whole "id" thing is a bit smelly. First , it's lot of boiler plate. Then (the worst), it seems that I am rolling out my own "pointer" system with all the inherent problem coming with pointer. No, its not about being a pointer. It is about the program having an idea of identity. Two different boxes might be identical, but still have a different identity. One box might be in different states or different contents at different times or in different hypothetical scenarios, but still be the same box. Id reflects that in a way that even mutable object identity in OOP fails to. You will note that databases do this, which is unsurprising, because you are (to some extent) trying to reinvent a database.
That's probably not the best solution, but you should realize you can do the exact same thing that you are doing with what you call "OO". data Box = Box { boxName :: String, shelf :: MVar Shelf } But now, you have all your mutations happen in IO. I would go for the graph approach too.
&gt; Having make shelves reference the boxes, would allow a box to be in 2 different shelves. Not necessarily. You could in the type system differentiate between `StandaloneBox` and `ShelvedBox`. Only `StandaloneBox`es can be shelved, and once they are they become `ShelvedBox`es which can't be put in a shelf.
Did you really mean `MVar`, or did you mean `IORef`?
I wasn't aware of MVar but I though about user IORef or equivalent. I'm not familiar enough with them to foresee all the implication, which is why I tried first the 'immutable' way. TVar would probably be more appropriate and might be indeed a decent solution. (I'm doing the graph approach right now, but it's not satisfying) 
&gt; I therefore feel less bad saying nothing about them. Ah, I thought you would like to include it in your book. Thanks for clearing that up!
I meant `MVar`, but you are right,`IORef` is what I should have used.
And as others pointed out, you might end up reinventing the relational database ;)
`TVar` would be appropriate if you expect to have several threads interacting with your structures. The `STM` monad should make it easy to conserve consistency.
even if I have something like move :: StandaloneBox -&gt; Shelf -&gt; ShelvedBox I can still do move box shelfA move box shelfB And now I have 3 copy of my box ;-) 
If you're writing a FFI library, please expose `.FFI` modules that exports low-level FFI bindings.(e.g. Haskell functions that work on native pointers etc., not high-level wrappers for idiomatic use) As an example, `sdl2` is doing this using `.Raw` modules: https://github.com/haskell-game/sdl2/blob/new-api/sdl2.cabal#L69 Motivation is same with exposing `.Internal` modules.
The whole id of the graph approach is , as you can't embbed shared immutable object, you "break" the problem by adding a reference. That way you can modify B without modifying A because A only contains a reference to B (and the reference is still the same). You can call it pointer, reference, identity or whatever but it's still subject to the full family of bugs inherent to it which is mainly you can "refer" to something which doesn't exist. At least with a database there are constraints which prevent you for deleting a row being referenced. Anyway, people use Haskell (I presume) because they care about robust code and use type checking to "remove some classes of bugs". I understand that the graph approach might be the best available approach but it reintroduce the "referece/pointer bug family" which we were trying to get away with. I'm just surprised that everybody seems to find it "fine".
I'd expect that at least on linux, to get to the performance of the shipped `cat`, you'd have to use `splice(2)` in some manner. Well, at least if the shipped `cat` is sufficiently smart: You're doing nothing with the data, so it doesn't belong in userland, let the kernel zero-copy it. As such, this might very well fall under "Haskell isn't a systems language, otherwise it would implement its own RTS".
The real elephant in the room here is, who the heck is writing a WMS in Haskell? Background please.
Do you mean that Haskel is not suited for the task ?
Absolutely not. I firmly believe that legacy issues of memory leaks, lazy IO that hounded Haskell in earlier times and all that have been addressed with libraries, and proven techniques and patterns. Haskell for Enterprise Applications I say! I'm enamoured with the idea that someone or some entity is writing a traditional ERP / Enterprise-y application in Haskell. But a full blooded WMS system is a big beast, so I am curious.
I know about Conal's post, and I find his arguments pretty strong. But that is just a (popular) point of view. And I don't remember any "confusion on the topic" before the post was written. Probably the confusion is a result of pushing the topic? &gt; I wouldn't use that as a definition. As you wish. Does HR provides us with a definition? In a number of places HR uses "function", "computation" and "value" as a synonyms, in other places they are different. Probably it is better to say "it is common to say that there are no 0 argument functions in Haskell" then?
Maybe it helps to go about answering your question by describing something *without* side effects: mathematical functions. Mathematical functions are rules that to each element in a specified domain, associates a single value in its codomain. Knowledge of the domain, the codomain, and what the function does to each element in the former is a full description of the function. Functions in most programming languages are *not* functions in this sense. In C we can write int add_numbers(int x, int y) { launch_missiles(); return x + y; } This function returns the same nomatter if launch_missiles() is there or not, but the launching of missiles is a *side effect*. It's something the function "does". A mathematical function may not "do" anything besides apply a fixed rule to its input. A more sensible example could be pseudorandom number generators. In most programming languages, there might be a function rand returning integers. But clearly this is not a function in the mathematical sense -- it does *not* return the same whatever the input is! It has a side-effect, too; it mutates the internal state of the random number generator.
As a first approximation I would say that if a function does anything except return a value as defined by its return type then that is a side effect.
People usually underestimate modern databases. After you got most of the guarantees right, you will have implemented many parts of a modern relational database, poorly or inflexible. 
One reason to choose a persistent data structure is to take advantage of Haskell's extensive library of list functions and algorithms. Suppose you want to find the best shelf for a box. With a persistent data structure you can write: fitness :: Warehouse -&gt; Double -- a fitness function moveBoxToShelf :: BoxId -&gt; ShelfId -&gt; Warehouse -&gt; Warehouse bestShelf :: BoxId -&gt; Warehouse -&gt; Shelf bestShelf b w = maximumBy (comparing (\s -&gt; fitness (moveBoxToShelf b s w))) (shelves w) We've taken advantage of the `maximumBy` function in `Data.List` and the operation of `bestShelf` is pretty transparent. Writing `bestShelf` for a mutable data structure will be a lot more tedious - reusing `maximumBy` will require you to perform a lot of explicit freezing, structure allocation and copying. 
Data.List is part of the base package right? Does GHC come with a base package that has profiling enabled?
Thank you for your compliment, while I certainly do second guess myself, that wasn't really my point of my question. I suppose I can only heed your advice from here, untill I know what to ask. Thanks.
I think the graph approach with unique IDs is modeling the C-heap to some degree, but this is a good thing. You still get Haskell's clean syntax, garbage collection, and **type safety.** People often make the mistake of thinking that Haskell is not good for certain things -- one big example is of programs that require stateful updates, and there are many problem domains where this is a requirement. But Haskell people know that if we need to write a program that requires stateful updates, there are ways to model the solution to the problem using the Control.Monad.State transformer in the "mtl" library is a pure way of modeling stateful updates. So if your problem domain requires an object oriented approach, use Haskell to model an object oriented solution. It should not matter if the tools you use are similar to the implementation you would use in a non-functional language. Haskell is still the right tool for the job. Furthermore, I would recommend using the Data.Vector.Mutable in the "vector" package, rather than "IntMap"s. Reading and updating can be done in O(1) time, rather than O(log n) time as you would with IntMaps. The disadvantage is that you must use the IO monad, but using a State monad transformer is an elegant way to make use of IO where you need to keep a reference to your database handy at all times: http://hackage.haskell.org/package/vector-0.5/docs/Data-Vector-Mutable.html Also, the Lens library can be very useful for modeling mutable state, although I have found it to be a bit difficult to learn how to use, for you application you should consider trying to use it. http://hackage.haskell.org/package/lens {-# LANGUAGE GeneralizedNewtypeDeriving #- } {-# LANGUAGE FlexibleContexts #- } {-# LANGUAGE FlexibleInstances #- } import Control.Applicative import Control.Monad.State import Control.Monad.IO.Class import Data.Map import qualified Data.Vector.Mutable as Vec type ShelfID = Int type BoxID = Int type Name = String data Box x = Box{ boxID :: BoxID, boxName :: Name, boxContents :: x } data Shelf x = Shelf { shelfName :: String, shelfID :: ShelfID, boxNameTable :: Map Name BoxID, -- a map to reverse lookup of ShelfID by box name shelfContents :: Vec.IOVector (Box x) } data Warehouse x = Warehouse { shelves :: Vec.IOVector (Shelf x), shelfNameTable :: Map Name ShelfID } newtype WHM x a = WHM{ unwrapWHM :: ReaderT (Warehouse x) IO a } deriving (Functor, Applicative, Monad) instance MonadState (Warehouse box) (WHM x) where { state = WHM . state; } instance MonadIO (WHM x) where { liftIO = WHM . liftIO; } initWarehouse :: IO (Warehouse x) initWarehouse = Warehouse &lt;$&gt; Vec.new 0 -- create a new vector with 0 elements newShelf :: Name -&gt; WHM x (Shelf x) -- add a new shelf, return it's ID. newShelf name = do exists &lt;- shelfByName name case exists of Just shelf -&gt; return shelf Nothing -&gt; do wh &lt;- get shVec &lt;- liftIO $ Vec.grow (shelves wh) 1 boxVec &lt;- liftIO $ Vec.new 0 let shID = Vec.length sh -- the length of the vector before it is inserted will be the new shelf ID let sh = Shelf { shelfID = shID, shelfName = name, shelfContents = shVec, boxNameTable = Map.empty } modify $ \wh -&gt; wh{ shelves = shVec, shelfNameTable = Map.insert name shID (shelfNames wh) } liftIO $ Vec.write shVec shID sh return sh -- Lookup a shelf by it's name shelfByName :: Name -&gt; WHM x (Maybe (Shelf x)) shelfByName name = do shVec &lt;- gets shelves Map.lookup name &lt;$&gt; gets shelfNames &gt;&gt;= maybe (return Nothing) (liftIO . Vec.read shVec) 
Does it give any hint whether the **pseudorandom number generator** program is causing side effect?
&gt; After you got most of the guarantees right, you will have implemented many parts of a modern relational database, poorly or inflexible. Correct.
I like your generalisation of what is a side-effect. What is the inner world/outer world? You define it. You define a box (in most programming languages that can be a function, or a whole program). This box has one input and one output. When using it, if it does anything to the outside of the box besides returning something, then that box has side-effect.
But how is this summarized as a formal term/definition? I still want to know what is *within or outside a program*.
A program without side effects isn't very useful. :) Haskell programs have side effects. The actual structure of functions and code in Haskell programs generally separates the code with side effects from the code without side effects. It is generally idiomatic to minimize the code with side effects. That way, there is a part of the program that is deterministic and easy to reason about and a fairly small part which handles interacting with the messy world.
Not going well. Can't get it to print at all. 
That is what I ask. Consider the *energy conservation law* in Physics. There is a system(inner world), then there are interactions within the system and between systems. You have to tell what the system is before you decide if it is energy conservation. That makes me wonder if the *side effect* is a relative concept. You can define a *inner world* that *includes* more things so that you say **an IO operation is pure**! That sounds crazy, so I need a good definition.
Right, I am the director and only developper of a small import company. That gives me some freedom about which language to use or not ;-) Unfortunalty, I'm not (yet) writting a full WMS. I have a container coming soon, not enough space in my warehouse and I need to reorganize it ASAP. I'm writing something which can draw a warehouse, have a mini DSL to describe the selfs the boxes and moves boxes by bulk in a the most effective way. That looks like do newRack "A" d270 [1..10] [1..3] -- build a rack made of 10 bay of 3 shelfves newRack "B" d180 [1..5][1..3] newBox "product1" (Dim 40 45 40) 60 newBox "proudct2" (Dim 30 20 25) 100 fill "A" "product1" -- fill A shelves with product 1 generateSVG etc ... And it needs to be done by tomorrow . 
I don't think you'd linked to the code when I posted but I may be mistaken.
It could be and it could not be. One of the implementations of a pseudorandom number generator in Haskell is pure. It receives a seed and returns a number and a new seed. For the same input it would always return the same output. You can then combine many places where you use the random (passing the seed along, possibly by using a monad to make it simpler) and end up with the whole program waiting for a seed. The only time you actually get a side effect, is when you pull it up to IO and there ask for a seed from the OS, something from that "outer world".
&gt; I still need an internal model to manipulate things before updating the database. What sort of problems are you anticipating with that?
This is what I mean by a persistent data structure: http://en.wikipedia.org/wiki/Persistent_data_structure I'm saying that a persistent data structure (such as your `data Warehouse` type) interfaces conveniently with list operations and algorithms. Mutable structures (e.g. `Data.Array.MArray`) do not interface conveniently with list operations and algorithms.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Persistent data structure**](https://en.wikipedia.org/wiki/Persistent%20data%20structure): [](#sfw) --- &gt; &gt;In [computing](https://en.wikipedia.org/wiki/Computing), a __persistent data structure__ is a [data structure](https://en.wikipedia.org/wiki/Data_structure) that always preserves the previous version of itself when it is modified. Such data structures are effectively [immutable](https://en.wikipedia.org/wiki/Immutable_object), as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure. (A persistent data structure is *not* a data structure committed to [persistent storage](https://en.wikipedia.org/wiki/Persistent_storage), such as a disk; this is a different and unrelated sense of the word "persistent.") &gt;A data structure is partially persistent if all versions can be accessed but only the newest version can be modified. The data structure is fully persistent if every version can be both accessed and modified. If there is also a meld or merge operation that can create a new version from two previous versions, the data structure is called confluently persistent. Structures that are not persistent are called [ephemeral](https://en.wikipedia.org/wiki/Ephemeral_(disambiguation\)). &gt;These types of data structures are particularly common in [logical](https://en.wikipedia.org/wiki/Logic_programming) and [functional programming](https://en.wikipedia.org/wiki/Functional_programming), and in a [purely functional](https://en.wikipedia.org/wiki/Purely_functional) program all data is immutable, so all data structures are automatically fully persistent. Persistent data structures can also be created using in-place updating of data and these may, in general, use less time or storage space than their purely functional counterparts. &gt;==== &gt;[**Image**](https://i.imgur.com/FXfz730.png) [^(i)](https://commons.wikimedia.org/wiki/File:Purely_functional_tree_before.svg) --- ^Interesting: [^Hash ^tree ^\(persistent ^data ^structure)](https://en.wikipedia.org/wiki/Hash_tree_\(persistent_data_structure\)) ^| [^I/O ^request ^packet](https://en.wikipedia.org/wiki/I/O_request_packet) ^| [^Persistence ^\(computer ^science)](https://en.wikipedia.org/wiki/Persistence_\(computer_science\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmujlzf) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmujlzf)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Hah, no kidding? That's great - my first user. You made my day! :)
The moment you require persistence, i.e keeping state between runs, you need disk storage. The moment you have disk storage, you need some sort of database. Whether it's a flat file, a JSON/XML document or anything of the sort, a database would likely be better. It would help with consistency, constraints and the general well being of your data. A DB like sqlite is simple and fast, not even requiring a server since it runs in your process.
Actually, I'm not using Map but vector and that's how I came up with this post after getting a `*** Exception ... Vector/Generic.hs ... index out of bound`. I know it's my entire fault, but I'm not used that type of error anymore. I realized it was the "modern" equivalent of a SIGSEV and was surprised to be confronted to that type of error whilst programming in Haskell. 
[To add to this, my FBUT has a "Don't use" subsection for `nub`.](https://github.com/quchen/articles/blob/master/fbut.md#nub)
Finding a shelf with enough space to to accomodate a given box for example. Again it's a real word problem, so all boxes can be of different sizes and don't stack nicely so there is gap between some (which might be enough to fit the given box). This might also involve restacking (or defragment) a given shelf to make more space. This has to be done in memory of course because we are only trying a new configuration and don't want it to be saved to the database ... Also all that type of questions involve converting a list of boxes into a list of free tiles which is not straight forward in SQL. etc ... If SQL was enough to solve my problem then I won't do anything in Haskell, but just have a collection of SQL scripts (which I already have when It's suit). 
If you're looking for advice on what to read when you don't know what to ask next, I'd recommend typeclassopedia, assuming you haven't read it before.
I see. Well, actually the arrays are being bounds checked, and since your index was out of bounds, it safely threw an exception, rather than actually segfaulting. But I understand your concern. I would recomend wrapping your shelf IDs together with the shelf name in a data type: data NamedID = PrivateNamedID String Int deriving (Eq, Ord) And do not export the "PrivateNameID" constructor, that way you cannot accidentally change it. 
Thank you for your full example which exactly show what I call "rolling up your own C-heap". What happend if I change the name of a shelf ? In theory you could merge 2 warehouse together (by merging the 2 vectors together, and updating the "new id" everyhwere). I tried yesterday and it blew up, even though it was perfectly type-safe ;-). Try doing it, and you'll realize how C-like it is, and how many things can go wrong. The idea is simple though. Just shift all the id of the 2nd warehouse by the length of the vector of the first warehouse. What's interesting is whilst you are updating the structures with the new ids, you are in a inconsistent world where the ids doesn't match what's in the vector. Everything is still type safe tough ... You are writing a C emulator in Haskell.
The "inner world" includes only: - Read-only function arguments - Local variables declared in the scope of the function So if you have a function `add(a, b)`, you can use the values of `a` and `b` in your calculations. You may not modify `a` or `b`, since that could affect other functions (a "side effect"). The benefit of side-effect-free functions is that your code becomes easier to reason about. You don't have to worry about any of your variables changing if you call a function you haven't seen the source code for. The reason IO is considered impure is because it always involves global or external variables. Like somewhere on your computer there are variables/data representing what is on the screen, and they are not local to your function. tl;dr - the "inner world" for any function is just the function and its local variables. If each function properly sticks to its **own** world, then those functions are "pure."
&gt; Don't try to start a project from scratch as a beginner because you don't yet have experience in functional design and it'll feel completely hopeless. I give beginners the exact opposite advice. They don't need to grok every idiom or use applicative style or any of that business, until they are ready.
As far as I understand it the main problem is mutating large hierarchies of "entities" which hold references to each other. This is what using an RDBMS solves for you. Manipulating smaller subparts of these hierarchies should be much easier in Haskell than dealing with the whole. If you want to defragment a shelf, why not just read in the dimensions of a shelf, all the boxes on it along with their IDs, defragment in Haskell, and write back to the database the new position for each box, referring to each box by its ID? 
What I'm saying is that the database solves the hard part of the problem. The "manipulate small subsets of my database in Haskell" is the much easier part.
Haskell programs do not have side effects. Unless, that is, you don't admit a distinction between the program, and the process that is executing it. A program does not need side effects to be useful.
If the pseudorandom number generator has a type in `IO` such as `getRandomNumber :: IO Int` then it most likely has side effects (updating the state of the random number generator after it produces each random number). Like /u/Soul-Burn said, a pure random number generator would look more like `getRandomNumberPure :: Generator -&gt; (Generator,Int)` — it returns the number *and* the new generator state.
I have to say that the more I work with hedis, the more I am unpleased with it. It's types are hard to understand. Instead of having all the commands return something like "Command ByteString" or "Command Int" results, and giving a way to run them, they provide a result that is dependent on context, giving us types like "m (f [ByteString])". I find this to be hard to understand for a newbie. I should say I haven't tried to implement alternative way yet :) But I hope someone will do that eventually. Secondly, error-handling "the right way" is almost impossible. If you, for example, want to catch all errors of this code: runRedis $ multiExec $ do set "a" "b" set "c" "d" ... you need to convert it into something like: res &lt;- runRedis $ multiExec $ do r1 &lt;- set "a" "b" r2 &lt;- set "c" "d" ... return (r1, r2, ...) (check res, and then all r1, r2 ... for errors) I find that it would be much better to either have an exception-based solution here, or to automatically gather all responses and check them for an error in a monad, returning single "Either Error Answer" at the end. One more thing I had about hedis. First: it will currently not save you from error protocol usage. You can call "sadd "foo" []" (empty array) and you will get an error (transaction aborted if used with transaction). I've sent a PR to use NonEmptyList type, but it wasn't merged. 
The problem is not "mutating large hiearchies of entities" but just "mutating ANY hiearchies of entities". The problem is to find a correct data model. Small or Large subset are represented in the same way, so having "small subset" doesn't make the problem simpler. 
It fact hplayground uses a EDSL that can be run in the server with MFlow. so MFlow-hplayground is an isomorphic framwework. The MVC example uses LocalStorage because it was a requirement of the todoMVC application (If I remember well). Shade uses class instances to enclose the methods that react expect from each component, while blaze-react uses a register. That is because the way react is defined. I would not call the method render a pure description. It is more like an applicative descriptions. Besides render, react need other methods to call at initialization and modification. that set of methods is an object in javascript, a class instance in shade or a register in blaze-react. In hplayground the rendering, initialization and state change is in a single applicative description when the rendering does not change, and it is monadic when the rendering changes, All in a single expression. The rendering engine does not need to search for the bits if the rendering that change, since the flow of the monadic expression know what would change and what not and gives to the rendering engine (perch) only the bits that have been changed. For this reason it does not need react.
something that is above the scope of the function, like a state or a global variable (by scope I mean the {} scope of C-like languages). side effect as in something that is not inside the function, as in writing to something else that its return value. side effect are something you don't want to have when doing multithreading, that's why pure function are great for multithreading, they don't "leak" into other parts of your program or data.
Is there a way we can request that a faster nub :: (Ord a) =&gt; [a] -&gt; [a] be added to Data.List? We can call it something else, but include it in the standard modules?
I have little knowledge about licensees, especially in the area of text publishing. Can you tell me why you chose this license, as opposed to another, or none at all? 
On the one hand I can see what you are saying. Ideally we're looking for an approach that is coherent in the sense that it deals in the same way with any size of hierarchy. On the other hand, having taken the exact approach I describe using Opaleye to communicate with a Postgres database containing several million records, I really think you are overthinking the problem. The database will capture most of your data model and manipulating small parts of it in Haskell will be easy. Mutating small hierarchies *is* much easier. Your insistence that "Small or Large subset are represented in the same way" is probably getting in the way. Here's an example of a model * a collection of shelves * a collection of boxes * a collection of products * every shelf is in a particular sector of the warehouse * every box is in a particular numerical position on a particular shelf * every box contains a number of a single product * every product has a colour * lots of other complicated relations and constraints involving where shelves are in warehouses, which products come from which suppliers, which colours are nice to look at, ... Challenge: We want to rearrange every shelf in sector X so that the colours of the products in the boxes are in as close order to the colours of the rainbow as possible (this is an arbitrary goal to indicate that we really can do arbitrary processing of our data within Haskell). Note that I included the last bullet point *specifically* to indicate that all this extra complexity will be irrelevant to the processing we do within Haskell. How do we implement this? * Use Opaleye, raw SQL, or some other database access method to return a list of tuples `[(ShelfId, SectorId, BoxId, Colour)]`. * Filter to only those tuples where the `SectorId` is X * Convert the list to a `Map ShelfId [(BoxId, Colour)]` * Sort each value according to its colour * Zip each value with `[1..]` to give the new position. We now have a `Map ShelfId [(BoxId, Colour, Position)]`, where `type Position = Int`. * Merge the keys with the values, concatenate all the values, and forget the colour to get a `[(ShelfId, BoxId, Position)]` * Issue update statements with Opaleye, raw SQL, or other database access method, to update the items in the box table with the given `BoxId` and `ShelfId` to have the new `Position`. What do you think of that approach? 
An ideal computer makes only calculations. It has no way to interact with the surrounding world. It cannot communicate the result of its calculations and it has no way to get any input for its calculations. This computer has very good theoretical properties, especially that it alerts behaves the same way. But this computer would not be very practical. A useful computer has to interact with the surrounding world. One can reach this by adding some additional effects to certain calculations. For example one can couple certain memory cells to the pixels of a display. So when a calculation stores its result in that memory cell, it switches the according pixels as a "side effect". Other interactions with the real world are similar: printing, saving to the disk, beeping the speaker, there is always an action in the physical world tied as a side effect to an internal "pure" calculation in the machine. 
One way to go at it would be to define a program as a function from its input (received via stdin) to its output. In fact, this is how they did IO in haskell before they discovered how to use monads to do this sort of stuff.
A faster nub would require some sort of state. In this case we can combine that state with the state used for the fold. We could create a "fold over unique elements" function which follows the recipe I gave in my previous answer. Then there's the question of which Set implementation do you use. If your elements are Ints you might want to use a `IntSet` rather than a `Set Int`. Update: It occurred to me that we can write a faster `nub` this way: import Data.Set as S nub' :: Ord a =&gt; [a] -&gt; [a] nub' xs = go S.empty xs where go _ [] = [] go s (x:xs) | S.member x s = go s xs | otherwise = x : go (S.insert x s) xs
Your analogy with energy conservation isn't bad. Any program that does something useful is going to have side effects, just like every system is going to leak energy. Haskell forces you to think very carefully about how/where your program is going to leak side effects. This (hopefully) makes them easier to reason about and avoids the pitfalls of mutable state. As to your second notion, you're on the right track! That's more or less the idea behind monads, which Haskell uses to make IO as pure as possible. 
It ends up being a tradeoff. By using the id approach you reintroduce possible bugs but then you can use the type system again to cut down on the classes you care about. The smart constructors solution you listed will do ensure that boxes must be added with a shelf, you could use a newtype to ensure that the shelfId can only come from an added shelf (though this could come from a different warehouse). You can also keep using the smart constructors type approach and limit direct access to the data structures to functions that validate the constraints you want. For me the graph is the right choice even in an OO setting. It seems like it would be useful to represent boxes without shelves. If you are reconfiguring the warehouse you are only changing boxToShelf and the boxes and shelves are not changed. You can even store multiple boxToShelf maps with the same boxes and shelves. Then you could precompute several configurations and have functions that find the best configuration for open space, best configuration for having frequently accessed boxes easily accessible ...etc.
I think you just fall in usual "modelling trap". Instead of defining some super strict and correct model try to write code that does what needs to be done and see what actual problems does it have. Is it realistic scenarios of box put to 2 shelves or 3 shelves with the same back? PS I know, I'm a stone-age Basic coder and Statically Typed Languages shouldn't be used that way.
I'd say get used to the feeling; there's no end of libraries and new abstractions for you to feel un-grounded about once you master Monad.
Well, the main point I wanted to make was that there is no functional magic-bullet to solve your problem of modeling a warehouse, you still need to use vectors and dictionaries, as you would in any other language. Haskell can model object oriented problems, and Haskell still has an advantage over C because of memory management and type checking. Again, you may find Lenses useful for this problem domain: http://hackage.haskell.org/package/lens For merging, I would create a function for converting back-and forth between a Vector to an IntMap. When you want to merge two warehouses, you can just convert your vector to an 'IntMap', use the pure functions in the IntMap module to merge, then convert back to a vector. This will make sure the ID's of the boxes are not changed. shelfToIntMap :: Shelf x -&gt; WHM x (IntMap (Box x)) shelfToIntMap sh = do let shVec = shelfContents sh liftIO $ IntMap.fromList &lt;$&gt; forM [0 .. Vec.length shVec] (\i -&gt; (,) &lt;$&gt; pure i &lt;*&gt; Vec.read shVec i) shelfFromIntMap :: ShelfID -&gt; Name -&gt; IntMap (Box x) -&gt; WHM x (Shelf x) shelfFromIntMap shID name imap = do let maxkey = shVec &lt;- liftIO $ Vec.new $ maximum (IntMap.keys imap) forM_ (IntMap.assocs imap) $ \ (i, box) -&gt; Vec.write shVec i box return $ Shelf { shelfID = shID, shelfName = name shelfContents = shVec, boxNameTable = M.fromList (fmap (\ (key, box) -&gt; (boxName box, key) (IntMap.assocs imap), } You would do something similar with the Warehouse vector, but the "append" function you would pass to IntMap.unionWith would have to include the "mergeShelfs" function. 
The problem is you have for, example to boxes with Id = 0 (in each warehouse). When you merge the warehouse, one of the box is given a new id, which needs to be updated in the box itself bud also in boxNameMap of the shelve holding it. I'm not sure your code is doing it.
Sorry, I just fixed that. Now you must specify the ShelfID and Name, so shelfFromIntMap should probably not be exported, it should only be used by the function that merges warehouses, which would be similar but I did not implement it. 
&gt; Haskell programs have side effects. I think it would be more accurate to say Haskell programs have effects and effects are values, not *side* effects. They're not side effects if you have to include them in the type.
A function or operation has side effects when it has an impact on the outside of the function (or is impacted by the outside) in a way that goes beyond input and output.
You are correct, I added that in a stealth update. Thanks for your reply anyway.
So what is preventing nub' from being implemented in Data.List?
You are taking a example which could be nearly be written in raw SQL (or at least a simple map-reduce in Haskell), that's not the kind of processing I'm talking about, but things which involves complex decisions based on the graph itself. My first example was about that, given a "fragmented" shelf with already some boxes in it. Is there a gap big enough for a given box, or if you prefer computes the list of free gap. Example : consider a shelf (29x10) has been filled with the following box (in that order) + A (11x3) + B (5x5) + C (13x 3) + D (12x2) There stack like this : +----+---------------------+ | | | | +-----------+ | | B | C | | | | | | +----+-----+-----+ | | | | | A +-----------+ | | | D | | +----------+-----------+---+ The question is :can I fit f a box of ( 7x10) , if not how do I rearrange A,B,C, D to make it fit. I can rotate the box . If not, let's try the next shelf etc ... I'm passing the fact, that the height of shelves within a rack can be modified if needed (but then modify the height of it's neighboor ) etc ... It's only an example, but that's that type of problem I'm talking of and I'm still not sure how a database would help. Just drawing in it (in Haskell) is already tricky .
Too late ;-). My point is , that is that type of mistake which is really easy to do (and you did it). And look at the amount of code needed and the heaviness to describe a simple relationship ... That's not what I call an elegant piece of code (even though I'm impressed by your work).
Here is an approach starting from referential transparency, which is roughly the property that given `g : a -&gt; b` and `f : b -&gt; c`, then forall `x : a`, `f(g(x)) === fg(x)` where `fg : a -&gt; c` is the result of inlining the body of `g` directly to the body of `f` at every occurrence. Now consider a functional language where `g` is the function that takes a number, prints "hello", and then returns that number, and `f` is a function that prints that number added to itself, returning `()`. now, `f(g(1))` will print "hello; 2". Meanwhile, `fg(1)` will print "hello; hello; 2". This violates referential transparency. We can define a _side effect_ as anything (such as printing) that violates referential transparency. From this, we can now ask "how could we explicitly represent the ongoing state of what is printed to the terminal". In so doing, we find ourselves reinventing something similar to the `Writer` monad, and this brings us to what you term the "other world" -- it is everything we in some sense choose to represent explicitly so as to preserve the property of referential transparency.
Once you have side-effects, you also have the issue of being sensitive to side-effects. If you have a pseudo-random number generator that doesn't accept any seed as an argument, it either returns the same "random" number every time or it's sensitive to external effects. If the function updates a seed for later re-use, but doesn't return that seed via the functions return value, that is a side-effect itself. So a call of an impure pseudorandom number generator is sensitive to the effects of the previous call. For a "more random" random-number generator, you need some source of "entropy" - some source of hard-to-predictable bits. That is input, but (in principle - probably not in practice) no output or mutation. So the random-number function is sensitive to the effects that drive that input, even though it might hypothetically not have effects itself. This kind of thing makes a bit more sense if you consider `while` loops. Even in imperative languages (but not really in the C family) there's a common style rule that the condition for the `while` loop shouldn't have effects. The body has effects, the condition just decides whether to continue looping or not. However, that condition has to be sensitive to the effects of the loop body. Otherwise, the condition result can't change as a consequence of anything in the loop body, so either the loop never runs or it never stops. At this point I should confess some hand-waving happens WRT effects of things happening concurrently with the loop body. Anyway, it's common to call these things "effects" rather than "side-effects". After all, some of these things are the intended effects of the impure functions. If you call the function `putStr "Hello"`, calling the display of the word "Hello" a side-effect is a hard sell - the older meaning of "side-effect" (in medicine) excludes intended effects. 
I'm sorry, I really don't see what the problem is. You seem to have two issues that need solving 1. Represent how all the entities in your world relate to each other 2. Manipulate smaller collections of entities and write them back into the overall collection These seem to be completely independent. I thought 1 was your bigger problem and I suggested using an RDBMS. If you prefer, you could use what you dismissively call a "C heap". Note that this "C heap" in Haskell has the potential for plenty of type safety and consistency guarantees. As for part 2, I still think it's the easier part of your problem. I do not understand why you think that the datastructure that you run your algorithms on must be of the same type as the one that you use to store your overall state. For the problem you propose * run queries on your DB or fetch from your in memory "C heap" to get the following data * `[(ShelfId, (Int, Int), BoxId, (Int, Int), Orientation, (Int, Int))]` * This is for each box, the shelf ID, the shelf's dimensions, the box ID, the box's dimensions, the box's orientation position and position * Convert this to a `Map ShelfId ((Int, Int), [(BoxId, (Int, Int) Orientation, (Int, Int)])` checking consistency as necessary You can then run an algorithm on this data to determine the output * either rearrange the boxes on a shelf `[(ShelfId, BoxId, (Int, Int), Orientation)]` -- the new position and orientation of each box * or enlarge a shelf and you can write this back to the database as necessary. I don't understand what the fundamental problem is here.
any advice on the next step after *Conceptual Mathematics*? Nearing the end and I'm wondering if I need to pick up some algebra before moving on to more advanced works.
This doesn't exactly answer your literal question, but it might clarify your thoughts on inner / other worlds: the paper Tackling the Awkward Squad by SPJ (http://research.microsoft.com/en-us/um/people/simonpj/papers/marktoberdorf/mark.pdf). It's actually a fun read. Here's a teaser quote that you might find interesting: "Our semantics is stratified in two levels: an inner denotational semantics that describes the behaviour of pure terms, while an outer monadic transition semantics describes the behaviour of IO computations."
At the moment, I use a suboptimal solution, I group all the boxes by sizes and find for each group which orientation is best (which is basic math) and the fill a shelf with it. Assigning what goes where is then do manually.
&gt; you think that the datastructure that you run your algorithms on must be of the same type as the one that you use to store your overall state. No, I don't care about storage (for now). My problem relates to the datastructure to run my algorithms. Lists of tuples are not enough to modelize the data needed by the algorithm.
&gt; Lists of tuples are not enough to modelize the data needed by the algorithm. I am suggesting they are at least the interface between your datastore and your algorithm. You are welcome to model the data your algorithm works on in any way you like! Anyway, it seems I have not helped. Good luck with your project.
Very true. The only thing you want to keep in mind is that it's not enough to threadDelay 100000 between sends and hope for 100 Hz, because the time it takes to compute a value will add on top of this and give you systematic extra lag. My preferred way is to figure out the time-of-flight independently, then generate a value, find the interval from now till time-of-flight, threadDelay that interval, send, repeat. This way you can avoid accumulating error.
Yup. I checked the source code, and that's how pipes-rt works, so there's no point in me doing that myself again.
The library maintainers generally seem to be very conservative about adding new functions - especially if it means making `Data.List` depend on `Data.Set`. There is `nubSort` [1] in Data.List.Ordered which is nice compromise - it's n*log n without using a Set.
Introductory books: * [Learn You A Haskell](http://learnyouahaskell.com/) (No Starch Press) * [Real World Haskell](http://book.realworldhaskell.org/) (O'Reilly)
Let's see, where could the `Either Int Int` come from? runG :: G Int -&gt; OfInt G runG = OfInt The `G Int` is expanded out to `Either Int Bool`, while the other `G` remains unexpanded. We now have: runG :: Either Int Bool -&gt; OfInt G runG = OfInt Now, `OfInt` has the following polymorphic type: OfInt :: f Int -&gt; OfInt f And we are using it in a context in which we need a value of type `Either Int Bool -&gt; OfInt G`. We now need to unify those two types: f Int -&gt; OfInt f ~ Either Int Bool -&gt; OfInt G The top level type constructor is `(-&gt;)` in both cases, so we now unify the two right-hand sides together (omitted), and we also unify the two left-hand sides together: f Int ~ Either Int Bool There is no solution to this second unification problem, but we don't know that yet. Both sides are a type application, so we now unify the two right-hand sides together (omitted), and we also unify the two left-hand sides together: f ~ Either Int Now that we know what `f` is, we can give a "clearer" error message to the user. Instead of saying that the actual type `f Int -&gt; OfInt f` doesn't match the expected type, we can instantiate this `f` and tell the user that the actual type `Either Int Int -&gt; OfInt (Either Int)` doesn't match. Does that make sense?
Your issue boils down to the fact that you cannot partially apply type synonym families. You're trying to partially apply your `F` and `G` type families by passing them, unsaturated, into the `OfInt` type constructor -- specifically, `OfInt F` does not fully saturate the `F` type family; ditto for the same case for `G`. The real problem here, as I see it, is that the error messages you're getting don't help you to identify that partial application of type synonym families has anything to do with your problem. ~~You might consider opening a bug report about this issue; GHC ought to provide better diagnostic information in this situation.~~ /u/glguy notes that [this bug is fixed in 7.8.4](http://www.reddit.com/r/haskell/comments/2pa5dp/type_lambdas_type_family_vs_newtype_declaration/cmurr67).
It looks like this bug is fixed with a milestone set at 7.8.4. You aren't supposed to be able to use unsaturated type families like this. https://ghc.haskell.org/trac/ghc/ticket/9433#ticket
So, the main point is that in this particular case **type family** is nothing more than **type** synonym?
&gt; First, we'll have to note that in Haskell things are lazy. This means many things, but importantly it means that every thing is a value: we can't observe computation. How does laziness imply that every thing is a value ?
I'd rather see someone explain what is wrong with this guy's post than blindly downvoting him. 
I golfed a bit more, tell me if whether you like it or not or ask me if something's unclear. :) import Control.Applicative import Control.Monad.Trans.Class import Control.Monad.Trans.Maybe import System.IO hoistMaybe :: Monad m =&gt; Maybe a -&gt; MaybeT m a hoistMaybe = MaybeT . return getChar'' :: MaybeT IO Char getChar'' = lift (hReady stdin &gt;&gt;= getc) &gt;&gt;= hoistMaybe where getc b = if b then Just &lt;$&gt; getChar else return Nothing getChar' :: IO (Maybe Char) getChar' = runMaybeT getChar'' 
Ooh, nice one.
With guard I think you'd need to write it 'inside out' something like: getChar' :: IO (Maybe Char) getChar' = runMaybeT $ (liftIO $ hReady stdin) &gt;&gt;= guard &gt;&gt; liftIO getChar I'm not sure that's exactly clearer unless you're familiar with monad transformers. Perhaps [broken]: toMaybe True = Just toMaybe _ = const Nothing getChar' = toMaybe &lt;$&gt; hReady stdin &lt;*&gt; getChar
A 'side effect' is any interaction between a deterministic computation (the inner box) and anything else (outer boxes), other than via the input and result of the computation (the 'pure effects'). Using this definition, whether a computation is pure is an absolute concept and not a relative definitional thing. For example, you can't define printing to a terminal as a pure computation because whether the terminal exists is non-deterministic from within the computation box. The meaning of 'deterministic' pretty much scopes out arguments and corner cases about exactly what is and isn't pure. 
Ask around for optimization algorithms or -libraries. Hell, I'm actually quite interested myself. Does anyone know of such libraries?
The point is that *type families* are really *type synonym families* and they, like vanilla type synonyms, can never be partially applied.
Curious to know how much time you took to complete the book? I'm in the third chapter of it and things are moving very slowly :(
I think it's important for all creative work to be appropriately licensed, so putting *something* on it was important to me. As to that choice of license, I didn't give it much thought - Creative Commons is appropriate for this type of writing I think. As to my choice of that specific CC license: * I use attribution because I believe it's important to credit people for the work they do * Non-commercial because I the quality of my posts fluctuates, and due the attribution requirement, I'm not sure I want people spending money and getting my rushed work... especially when they can trace it back to me ;) (As you can see above I'm not serious about this, I would just like to talk about it first). * No-derivatives I feel may be OTT to be honest, I'm not against people making variations on my work. I should probably relicense without this, I just haven't done that.
I'm not sure what's wrong either &amp;ndash; early Haskell did model I/O as a stream (see ["History of Haskell"](http://research.microsoft.com/en-us/um/people/simonpj/papers/history-of-haskell/history.pdf) section 7.1) before switching to monads later on. We still have a neutered version of stream-based I/O today, in the form of [`interact`](http://hackage.haskell.org/package/base-4.7.0.1/docs/System-IO.html#v:interact).
Did a few chapters on this during my masters. With a little tutoring, you'll quickly get it. Also fun to think of a property and trying to prove it! (I chose a simple one: the property of a palindrome).
Since you're using type families, you do well to worry about injectivity, but it is `G` which is not injective, not `f`. If type variables were not assumed to be injective, then we could not conclude `f ~ Maybe` from `f a ~ Maybe String`, and so even something as simple as `map id (Just "")` would have an ambiguous type.
No worries. I was experimenting with `contravariant` just a few weeks ago, so it was right up my alley ;)
Such questions are like catnip to this group. Very simply the output of a function for a given input is always the same. Besides that, anything else that happens as a result of a function call is a side effect. Anything at all. Even a so-called "pure" function which does always give the same output for the same input has a side effect: The passage of time while it executes.
I have a list of [reading material](http://reinh.com/notes/posts/2014-07-25-recommended-reading-material.html), to which I would add Richard Bird's brand new *Thinking Functionally with Haskell*, which is amazingly good.
Great recommendation. It's at the top of my list for exactly this reason.
Sorry, I'm not very knowledgeable on the theory behind lenses. If I get what you mean, you can define your own lenses types, and then any client can just use any lens library they want (with the combinators they want), and they will be compatible your own lenses, right? If so, then I guess ignore that part from my post (regarding the dependencies), though it still applies as an example of having to apply more effort to add functionalities to your library.
Okay, so if you can figure out how to properly enumerate elements of a custom datatype, you should implement a Traversable instance. Got it. Again, I'm trying to figure out which instances are like Traversable, where you "should" expose them if the construction is straightforward and it gives people more information about the type. But Traversable is one of many possible classes, where this may hold or not.
thanks, I think that's the path I'll take then.
I'd rather see Text than String here. apart from that. Cool!
On my phone, but since you can't force evaluation (even sew just ties evaluations together) it means you can't distinguish between values and computations resulting in a value. Thus, you tend to just think of result values which also drives purity. Reading up on Call By Push Value has been really effective for me to get a finer idea about this.
If you downloaded the Haskell platform then I think so, that's partly why HP is such a huge download. I've not done more than simple profiling though so this isn't from personal experience.
&gt; Haskell programs do not have side effects. Should've stopped there.
&gt; We can define a side effect as anything (such as printing) that violates referential transparency. I think this is not true for all cases. If we write it as "anything (such as printing) that **would** violate referential transparency", it will be better.
Not letting you off the hook that easy. xD Are you suggesting that "purity" of a function only matters up to effects that occur to produce WHNF? f x = undefined : unsafeCoerce (unsafePerformIO fireMissiles) Pure? :P Or would `const x y = deepseq y x` be better? But then what about infinite lists? What I'm trying to say is that I generally challenge this particular way of defining of purity.
There's no precise definition for 'side effect'. It's a stepping stone to understanding how lambda calculus evaluation works and how it differs from the execution model of other languages.
I implemented your suggestion and the algorithm is about 20 times faster. I profiled the code going from about 0.5 seconds to 0.02 seconds. Thanks again. I then increased the search depth from 2-ply to 3-ply and the algorithm again takes much longer than expected. Fortunately, the algorithm now spends the most time on things like accessing board state and evaluating board scores, which is what I would expect. The 3-ply search took 130 seconds (if I remember correctly?) and took about 6000 times longer than a 2-ply search. This is clearly suboptimal because the maximum branching factor for this board game is 250 per ply as you have already noted, and often the actual branching factor is less. I believe the search of the 3rd ply is doing a lot of duplicate work, because Pentago is very prone to transposition. The different branches of the tree are evaluating the same board state over and over. I need a transposition table. The imperative approach would be to share state across all calls of a recursive function, this way different branches of the tree could use the work performed by previously evaluated branches. I'm not sure how to do this in Haskell. I've researched State monads and memoization techniques. It seems the fix function might be useful. If anyone has any suggestions regarding a transposition table I would really appreciate some tips. Thanks.
This is all pretty fair. I'd try to invoke that "unsafe" functions are somehow unfair, but I'd rather try re-reading Filinski's thesis and see if I can't get it more formal correctly.
Short and crisp. A few questions arise. Why in the case of MultiParamTypeClasses it cannot be inferred but with FunctionalDependencies it can? What I mean, is whether it can "always" be inferred or just in this special example? Are there cases when FunctionalDependencies do not help? Or are there cases when one would intentionally not use FunctionalDependencies together with MultiParam classes?
sure, personally i can't tell the difference. edit: actually. perhaps the right statement is _could_ violate referential transparency. I.e. a function `g` has side effects if and only if there exists _any_ function `f` and value `x` such that `f(g(x)) != fg(x)`.
My typical example is a Convertible class class Convertible a b where convert :: a -&gt; b This lets you define mappings between any types, so these instances can all go together: Convertible String Int Convertible String Double Convertible () String Convertible Int String [...] This is handy if you don't care about what the actual types are, you just want "the correct one". putStrLn (convert ()) Here you can infer the type of convert for yourself, `() :: ()` and `putStrLn :: String -&gt; IO ()` so we get `convert :: () -&gt; String` and only one instance is possible, `Convertible () String`. Now lets look at putStrLn (convert 1) `1 :: Num a =&gt; a` and `convert :: Num a =&gt; a -&gt; String`. This is ambiguous since there could be multiple instances that apply. You might say that there's only one defined so it isn't ambiguous, namely `Convertible Int String` but instances can be added ad-hoc and just adding an import that includes a different instance could then break your program so it's not allowed (There may be additional reasons to disallow this). The solution here is to explicitly annotate `1 :: Int`. This turns up a lot in practice and it's annoying. We could now reach for a functional dependency to make usage nicer. We have three options: * `Convertible a b | a -&gt; b`: Given `a` we can infer `b`. This means that `Convertible String Int` and `Convertible String Double` would overlap and be disallowed. This would still lead to ambiguity for `putStrLn (convert 1)`, but not for `print (convert ())`. * `Convertible a b | b -&gt; a`: Given `b` we can infer `a`. `Convertible Int String` and `Convertible Int Double` would overlap. Here `putStrLn (convert 1)` is not ambiguous but `print (convert ())` is. * `Convertible a b | a -&gt; b, b -&gt; a`: Given `a` or `b` we can infer the other. Now `Convertible String Int` overlaps with `Convertible Double Int`, and `Convertible String Int` overlaps with `Convertible String ()`. Now neither `putStrLn (convert 1)` nor `print (convert ())` would be ambiguous. For each functional dependency we restrict the number of possible instances. Is it worth it? It depends on your use case. For something as general as `Convertible` it probably doesn't make sense, but the ambiguity is also a strong argument against using Convertible. But when you have something more specific it often does, one example i have fresh in mind is mapping haskell types to sql types. You can map haskell `Text` to several different column types, but if you control the schema you can decide for yourself to only allow it to map to `varchar`. It all comes down to how much flexibility you need. Edit: Fixed the `a -&gt; b, b -&gt; a` example. 
Right, here's a dim-witted demo in which three completely independent lens libraries, one defined on the spot, interact in ghci. I get one concrete lens _1, from one library, another _2, from another, and define a couple of my own, together with the central combinators. import Lens.Family.Stock (_2) import Control.Lens (_1) import qualified Control.Lens as Godzilla import qualified Lens.Family as Penelope import Data.Functor.Constant import Data.Functor.Identity infixl 8 ^. ; infixr 4 .~ ; infixr 4 %~ x ^. l = getConstant $ l Constant x -- view, 'get' l %~ f = runIdentity . l (Identity . f) -- over, 'modify' l .~ b = l %~ const b -- set, 'update' _fst f (a, b) = fmap (\a' -&gt; (a', b)) (f a) -- lens onto first component ('field') _snd f (a, b) = fmap (\b' -&gt; (a, b')) (f b) -- lens onto second component a = (1,("Hello",(True, 'a'))) -- &gt;&gt;&gt; a -- (1,("Hello",(True,'a'))) -- &gt;&gt;&gt; _snd . _2 . _1 %~ not $ a -- (1,("Hello",(False,'a'))) -- &gt;&gt;&gt; _snd . _2 . _1 %~ not $ a -- (1,("Hello",(False,'a'))) -- &gt;&gt;&gt; _snd . _2 . _1 .~ "Tarantula" $ a -- (1,("Hello",("Tarantula",'a'))) -- &gt;&gt;&gt; Godzilla.view (_snd . _2 . _1) a -- True -- &gt;&gt;&gt; Godzilla.view _snd . Penelope.view (_snd . _2) $ a -- 'a' All of the queries involve a mixture of elements from all three libraries, since nothing depends on any types not already present in base. Here I did not even bother giving signatures to anything. A typical rustic lens, in the strict sense, will be like `_1` or `_2` or `_snd` and has no need for any prior lens library. If you want to call it that you will need synonyms. If I export my `_fst` and `_snd`, I have defined and exported van Larhooven lenses, and I don't need anything but `fmap`. 
This inspired me to go look for such a precise definition. In the famous Moggi paper on monads, Moggi discusses "side-effects" as distinct from continuations or exceptions as effectively memory effects, and his "side effects" monad is what we now call the `State` monad. Hyland, Plotkin and Power's work on effects follows this tradition and treats "side effects" only as `State`. They of course consider other monads, etc., including continuations and soforth, and treat them all as just "effects". Later work by Moggi (including with Sabry) tends to treat effects more general than the State monad with the term "computational effect" (including jumps, etc.) and continues to reserve "side-effect" for simply `State`. so it appears there _is_ a precise definition for "side effect" -- it just happens to be one which we don't really use!
The thing is, Elm.Compile returns a String, so my thought was to return the strings, and those who need Text can convert it. There would be a conversion either way, but if someone needed as some format other than Text (maybe ByteString?), they wouldn't have to convert it again. That said, I am not an expert in the Haskell Text/ByteString ecosystem, so feel free to correct me if I'm wrong!
Doh
&gt; tl;dr - the "inner world" for any function is just the function and its local variables. If each function properly sticks to its own world, then those functions are "pure." What about closures? SICP demonstrates that they can be used to build stateful objects. Once you have (a simulation of) mutable state, you might just as well accept mutation as a fact. Indeed, how is an infinite (Haskell) list of integers starting with 1 more "pure" or less "stateful" than a mutable object that increments its (private) memory location when you ask it for the next value and returns it? Laziness is a control construct, and most other (imperative) programming languages have adopted generators in some way.
Tests in other languages have a tendency to involve state and/or mocks. QuickCheck lends itself best to testing expressions, so it's easier with expression-oriented (that is, functional) languages. It also relies on generating data to a specification. It helps to have data-orientation and a means of describing data. Again, FP languages fit better here than typical OOP. I think it will catch on eventually though.
`Link` can't be a newtype, since it has two constructors.
I think [ScalaCheck](http://www.scalacheck.org) is quite widely used. QuickCheck uses type classes for type safe generation of input data. So if the language doesn't have type classes (or similar functionality), it's not going to as easy to implement and use.
Interesting, I didn't know about ScalaCheck. &gt; So if the language doesn't have type classes (or similar functionality), it's not going to as easy to implement and use. Most languages have interfaces/traits nowadays.
To be honest, I haven't tried to use QuickCheck to test IO stuff in Haskell, and I'm not sure a lot of people do that. Can you write a small article showing that? That'd be interesting, I guess.
The key feature of type classes is the automatic instance search/creation algorithm. It makes it possible to test a proposition without explicitly specifying the data generator to use. If the data type is complex it can make a big difference in usability. You can probably do automatic input data construction using reflection or similar, but it obviously wouldn't be type safe.
Yeah, I guess I can do that. I'm actually generating some data, spawning threads, assigning jobs to threads etc. all using QuickCheck.
Quiviq wrote quick check for erlang and it is possible to test java code. However, the state-machine features are missing from the free version and it is only possible to test pure code without commercial licence. ProEr is a clone of Quiviq wich has also the state-machine features. The documentation coverage seems a bit limited tough.
F# has [FsCheck](https://github.com/fsharp/FsCheck).
Bologna is a couple hours by train. I'll be there. :-)
I guess this is the website: http://www.lambdacon.org/
yay! Finally we'll have the chance to meet!
ouch Tom, too much rush, cannot believe I left off the website. I will edit the initial text for completeness. Hope to see you there, would be cool :P 
An example taken from ScalaCheck (which I know better than QuickCheck): forAll { l: List[String] =&gt; l.reverse.reverse == l } To test this property you will have to generate some input data of type List[String]. Of course, instead of writing a generator for List[String] you just want to write a generator for List[T] for any type T (actually it's a generator for C[T] if there is a Buildable[T, C[T]]) and a generator for String (both are included in ScalaCheck). The nice thing is that the generator is given as an implicit parameter so the compiler will automatically create/find the correct generator for us. In Java (and many other languages) we would have to create and pass the generator explicitly: forAll(listGenerator(stringGenerator), ...) Maybe not a big deal in this case, but the more complex the type the more inconvenient it gets.
Shrinking could be complicated to implement. The generation of random testing data can be done with every random number generator. The state-machine testing should be a bit more elaborate. The implementors form PropEr were accused of coping the code form Quiviq, which is entirely closed source. I would be interested whether the state-machine testing has a broad adoption.
Last time I looked, I found two Java ports of QuickCheck. Also while the pattern is frowned upon in TDD circles (because lacking reproducibility), it's often simple enough to whip up random test fixtures even without library support.
Python has paycheck. However, since python does not have a static type system, I think it's much harder to generate testcases. Also, when I wanted to use it, I got a lot of head wind since some people do not like random tests, they prefer a (limited) set of tests what will always produce the same tests.
&gt; because lacking reproducibility How is it lacking reproducability? QC prints the seed to reproduce exact same case whenever it fails. Whenever I find a failing test using QC, I convert that particular test case to a regression test(e.g. a unit test using the problematic input) to make sure I really fixed it and I won't produce it again in the future.
&gt; automatically inferring the correct instance based on the type is somthing only Haskell, Scala and rust do currently (afaik) What do you mean for that? When we had to do an assignment with QuickCheck, we had to write our own instance creators for custom types. 
It is now on a working repo, and there is more documentation than before -- i.e. an introductory blurb that explains the gist of it. http://hackage.haskell.org/package/boolsimplifier-0.1.8/docs/Data-BoolSimplifier.html Now, where's that "sort by most recently uploaded" Hackage PR ? :-P
Same here, but I have argued with people on /r/java who insisted I'd be committing a crime against humanity by writing tests that would not do exactly the same thing each time. Perhaps if my tests would have committed the seeded version into trunk, they'd been placated.
I have had the same (long) argument at the office. Fixing the seed was proposed as a compromise, but it met a no. So to get things merged, I allowed all paycheck references to be removed. I put up a hard fight, to no avail :)
Sounds like a great blog post/talk.
That's definitely true. Although even in e.g. C# it's convenient, since it standardizes testing. However there's other reasons it's not as effective, big one being that the majority of the code has mutability included, which nullifies QuickCheck.
It's not so much that it's lacking reproducibility, it's that the reproducibility is difficult to get in the first place, and difficult to resolve with the nature of QuickCheck. Typically, if you have tests and source code checked in at a given changelist (or git hash), you want those tests to run identically every time. No matter if I check out those tests now, or in five years, I want my tests to either pass in both cases, or fail in both cases. If they don't match, that means my tests are also testing something other than my source. This is insanely bad--significantly worse than failing tests on their own. If a test isn't reproducible like this, it means it's testing some state other than what's in source control. It means you can't bisect to figure out when a bug was introduced. You might be able to for *specific* cases (such as using the same seed for QuickCheck, but you've still got no guarantees if the random number generator is used differently by the tests over time, such as if you add a new test). So the workaround for this for QuickCheck is to check your seed in to source control. Now you've got a hermetically-sealed source code + state + tests that either always pass or always fail. If you change your source, though, since your tests are generated based on source + state, your tests will change. So bisect still has a pretty good chance of not working--you didn't functionally change your code, but your tests changed out from under you anyway. So instead of checking in the seed, you check in the generated tests themselves, to work around this. But this is rather at odds with the nature of QuickCheck. &gt;Whenever I find a failing test using QC, I convert that particular test case to a regression test(e.g. a unit test using the problematic input) to make sure I really fixed it and I won't produce it again in the future. But this requires developer action. This doesn't scale to 50k engineers, tens or hundreds of millions of lines of code, and shared ownership/stewardship of medium to large projects. What if someone else that you depend on proposes a change, and wants to run your tests to make sure they didn't break you? How can they know that this was just a test case that you weren't generating previously, vs. an actual breakage caused by their change? Any answer here other than an automated system telling you "green" or "red" here--any system which requires effort on the part of the engineer--is too much overhead.
Thanks for sharing your experience. :) 
Lack of function/method/procedure lookup based on the return type is the main barrier I'd say. Haskell gets that through type classes, most other languages have to fake it, usually requiring the test writer to name types more explicitly, and losing the nice syntax / speed of writing tests along the way.
Really excited about this one! Conal is such a pleasure to talk to. Please forgive my historical brain fart (you'll see what I mean)...
Great comment. Thanks for insights!
Ohhhh, this sounds lovely! Looking forward to listening to this - great to see another episode :)
This looks like a great way to structure things, thanks!
I'll start on it later today after I send out a book proposal.
Yay! Something to listen to on my way home. Always enjoy the haskellcast. 
Hmmm... I've been doing a bit of work with LTL and CTL in a FRP model. It's... interesting.
Wow, it was recorded in the future and sent back to us. FRP is very powerful. :)
Storage isn't the only reason for the RDBMS, is to solve most of problem 1. In your situation I would at least try to implement all the advice given them show the code and an example of where the advised solution breaks down.
Conal is obviously a time lord.
Check out SmallCheck. It is deterministic and exhaustive (to a certain depth).
Got any work to share? I'm very interested in how CTL and LTL could be used in this domain. 
I'm glad someone read this far!
Not yet but hopefully soon. I have an FRP system whose state machine is a simple Moore machine and I am working on using LTL, CTL, or perhaps CTL* as a model checker. Continuous time makes this somewhat difficult so I don't have any useful results yet and the most relevant paper I've found [1] is locked behind a paywall. [1] http://link.springer.com/chapter/10.1007%2F3-540-36103-0_26
Nice catch :) Corrected.
I know it (although haven't used it yet). I find QuickCheck more interesting because I felt like exhaustively searching through the state space is just not feasible for any of interesting programs(unless you're using abstract interpretation, model checking etc. for that) because state space is just huge. I may never be able to run SmallCheck long enough to make it run interesting states, whereas in QuickCheck it starts generating big states after first few tests. That being said, I'm not a pro in this stuff so I may be wrong :-)
Just read the paper: [Testing Monadic Code with QuickCheck](http://www.cse.chalmers.se/~rjmh/Papers/QuickCheckST.ps). Or, someone has a [good code snippet](https://gist.github.com/ijt/967505).
Clojure has test.check https://github.com/clojure/test.check
&gt; It also relies on generating data to a specification. It helps to have data-orientation and a means of describing data. Again, FP languages fit better here than typical OOP Not just FP languages, but static and strongly typed languages fit better here. 
QuviQ's EQC or [PropER](proper.softlab.ntua.gr) do more than Haskell's QuickCheck. They allow testing stateful systems, via state machines. Quviq also allows to detect race detections with Pulse. 
Do you have anything worked out or concrete beyond your initial intuition? 
Not really, and I don't really know anything about the state of the art, but in this paper http://www.antonycourtney.com/pubs/genuinely-functional-guis.pdf they say `Signal a = Time -&gt; a` and signal transformers are `ST a b = Signal a -&gt; Signal b`. This type for `ST` seems far too large, as the output signal can depend arbitraily on the input signal, including looking into the future. In stochastic analysis you would avoid such future peeking by requiring the output to be adapted to the filtration generated by the input. I'm sure Conal is well aware of this and deals with it in some suitable way, but the language of stochastic analysis might make a good framework. I would also suggest that events correspond to Poisson processes and behaviours to cadlag processes.
This may be relevant: hackage.haskell.org/package/splice-0.3.1/docs/System-IO-Splice-Linux.html
Really interesting stuff - I think from the outside, those of us just using Haskell might not give this kind of stuff too much thought. One of the nice things about Haskell is how rich the history is. The paper ["A History of Haskell: being lazy with class"](http://research.microsoft.com/en-us/um/people/simonpj/papers/history-of-haskell/index.htm) is a personal favorite, for just that reason :)
Will there be a video for this?
No, we're not releasing videos anymore in order to focus on the quality of the audio: we haven't found a way to sync up multiple audio sources to the video reliably and without video we can do more edits and keep the overall episode tighter.
ok thanks.
A very nice introductory post (as always), thank you. Just a heads-up for anyone who may not be familiar with it: for a very long time, `GeneralizedNewtypeDeriving` used to have [severe bugs](https://ghc.haskell.org/trac/ghc/ticket/5498) which could cause innocent-looking code to circumvent the type system. It still seems to be somewhat [buggy](https://ghc.haskell.org/trac/ghc/ticket/8827), but I guess the new holes are less dangerous than the old ones. In any case, a module cannot currently be declared or inferred as Safe Haskell if it uses `GeneralizedNewtypeDeriving`. That doesn't mean the extension is dangerous to use in practice. It takes a bit of effort to write offending code, and this wouldn't usually happen by accident.
Interestingly, this example behaved as I expected on the machine I was using at the time, but it seems to produce an error using the version of GHC I'm using on this machine (7.8.3, but I can't remember what's on the other machine. I'll have to check tomorrow). Edit: Both machines are running 7.8.3. I guess I might need to compare the ~/.ghci files. This, again, will have to wait until I have switched machines again. Edit 2: It was the monomorphism restriction. You have to disable it for my cheat to work. That makes sense.
Very interesting, I'd love to see follow up posts!
This is extremely relevant to my current research. Thanks!
I'm really glad to see another episode of the Haskell Cast. Please keep 'em coning!
Yeah. FRP is basically just computer scientists rediscovering control theory, heh.
Oh that is good. Like wheels and drive train.
Lazy SmallCheck essentially uses `undefined' to simulate bigger examples.
A conference in Italy! Finally! I'll meet you there!
Completely off topic, but I have a silly URL site that works on using Nginx regex to redirect you to google search. For instance if you want to install Leksah [here](http://howthef.uk/do_I_install_Leksah?) is a link you can use to find out how. Edit: Argh! The top google result is the out of date Leksah download page. If you actually want to install Leksah then the instructions are [here](https://github.com/leksah/leksah/wiki/download).
Typos: &gt; There are some type classes that aren’t just boring to implement but are event impossible. instances manually. &gt;template Haskeltrese
That's why I do that anyway. There's no way to test all possible edge conditions in my code by hand, so with random tests I at least have a good chance of finding the bugs that may still lurk.
Note that this is a Java project, but I put this in r/haskell because of the category theory connotations, and extensive use of mathematical jargon. Reading the literature on the web site, I was reminded of this classic: https://www.youtube.com/watch?v=RXJKdh1KZ0w 
And that talk always reminds me of https://www.youtube.com/watch?v=BdHK_r9RXTc
I don't think we need IDs . I'm tired, but maybe someone can make sense out of this. We start with a list of boxes and an empty shelf. The empty shelf is represented by a list containing a single gap with the same dimensions as the shelf. splits is the enumeration of the ways of splitting the remaining space into rectangular gaps after a box is placed. placings is the enumeration of the ways of choosing an empty rectangle. searchTree is permute boxes * permute (splits * placings) place :: [Gap] -&gt; (Box, Split, Placing) -&gt; ([Gap], Maybe Position) fillShelf (boxes, split, placing) = zip boxes $ mapAccumL place emptyShelf boxes solutions = map fillShelf searchSpace 
Looks legit.
I want **deriving Bifunctor**!
If you're very bored, like myself, you can ```apt-get install latexmk texlive texlive-xetex texlive-latex-extra texlive-math-extra texlive-fonts-extra texlive-bibtex-extra biber``` ```git clone https://github.com/jpvillaisaza/cain &amp;&amp; cd cain &amp;&amp; make``` I'd post the results somewhere but I don't know why the original is offline or where to post.
Any chance of a video of the lambdajam version?
what is a canonical implementation?
yay! See you there!
Just for fun: getChar'' = hReady stdin &gt;&gt;= \b -&gt; (&lt;$ guard b) &lt;$&gt; getChar
[In the tutorial](http://khibino.github.io/haskell-relational-record/tutorial.html), might I suggest showing (part of) the code generated by `$(defineTable "account")`?
&gt; With continuous time, what an infinitesimal delay is does not seem easily defined. Again without knowing anything about the FRP side, this sounds like the difference between a previsible process P (where you know P_t if you already know P_t' for t' &lt; t) and a cadlag adapted process (which doesn't necessarily have this property). 
&gt;With continuous time, what an infinitesimal delay is does not seem easily defined. Hyperreals or other constructions like that? 
Implementing `deriving Bifunctor` is easy. The original code for deriving `Functor` actually used separate classes for a co- and contravariant functor in different arguments, e.g. class Functor2 f where fmap2 :: (a -&gt; b) -&gt; f a x -&gt; f b x class Functor3 f where fmap3 :: (a -&gt; b) -&gt; f a x y -&gt; f b x y class CoFunctor f where cofmap :: (b -&gt; a) -&gt; f a -&gt; f b class CoFunctor2 f where cofmap2 :: (b -&gt; a) -&gt; f a x -&gt; f b x and so on. But the problem is that non of these classes exist in the base library.
I am using it and have no issue for the moment.
&gt; deemed to**o** confusing Typo.
It should be possible to do this based on [`Generic`](https://www.haskell.org/haskellwiki/GHC.Generics). In GHC 7.10 that will become even nicer thanks to the fix for [#5462](https://ghc.haskell.org/trac/ghc/ticket/5462).
I noticed a few of these too so I submitted a PR https://github.com/ocharles/blog/pull/16
I'm kinda surprised about only 7% using Windows for Haskell development... | OS | | | |:-----|---:|----:| | Linux | 170 | 63% | | Windows | 20 | 7% | | Mac | 72 | 27% | | FreeBSD | 3 | 1% | | Other | 4 | 1% |
Are you surprised because you expected less developers on win? Or more? :D
To add to other suggestions here I recommend Bird and Wadler's "Introduction to Functional Programming" book. The last chapter has a derivation of the alpha-beta algorithm from the naive minimax. Their solution uses an auxiliary worker function instead of foldl' and also avoids the tupling/untupling of function f: bmx a b (Node x []) = a`max`x`min`b bmx a b (Node x ts) = cmx a b ts cmx a b [] = a cmx a b (t:ts) | a' == b = a' | otherwise = cmx a' b ts where a' = -bmx (-b) (-a) t Note that the above assumes the game tree is decorated with the nodes values and that it is pruned to the search depth, but this can be easily changed if needed. 
&gt; ...proof of concept platform which will attempt sensor integration and autonomous tasking using category theory. I'm sure they're being sincere, but I find this sentence quite amusing.
I'm a fan of `GeneralizedNewtypeDeriving`. It's very useful for things like [JSON instances](https://github.com/facebook/Haxl/blob/master/Haxl/Core/Types.hs#L110)
I don't think so. GHC.Generics would only allow you to derive a class for `*` and `* -&gt; *` constructors; Bifunctor is for `* -&gt; * -&gt; *`.
GND is used very often. The others may be more rare in application code, but they are used in the libraries, so they get to production code transitively.
I'd very much like to hear or read more about how unamb/lub are more significant than laziness! I get at least the most obvious connection to domain theory, but feel like I'm missing out on its significance. Is the idea that you can reify the notion of a computational step by e.g. folding with `unamb` the successive approximations of the fix-point form of recursive functions, and somehow extend that to non-recursive functions?
Thanks very much to all those involved - this is great!
Not that it may be that a big difference, but maybe the survey wasn't visible enough for a bigger sample size to reply. I for one don't remember hearing about it, yet I almost visit daily this subreddit. For a better view (for Windows at least) I think we should look at the haskell-platform/ghc downloads for those systems.
That is a pretty large number of windows users
I'm surprised at the number of people using GHC `7.8` -- I've only recently got to `7.6` on most of my systems. (Except for my cross-compiler of course, which tracks `HEAD`)
From the title I thought this would be about functorial strength.
Meta: I look forward to the day [this](http://i.imgur.com/nv9HYXD.png) is no longer fashionable for presenting articles. It's egregious.
Thanks for the input! I agree that this is irritating. We're discussing a new design, and I hope that we have time to roll it out in the first few months of 2015.
Unless you start with mutable state, closures just let you build a simulation where you return a new "modified" version of an object. A key point is that any other code with a reference to the original object can't tell that happened. &gt; Indeed, how is an infinite (Haskell) list of integers starting with 1 more "pure" or less "stateful" than a mutable object that increments its (private) memory location when you ask it for the next value and returns it? A stateful object isn't pure because other code can tell the difference between you doing nothing, and you making a request and ignoring the result (by seeing making a request of its own and seeing a skipped number). Pure code can't tell whether a lazy list has been evaluated yet.
memoi.se (sweden) today, 9m.no (norway) some weeks ago. ICFP 2014 in Sweden, ICFP 2012 in Denmark. And look at that haskellers.com cloud above Scotland. Is FP still a northern european thing?
Thanks indeed! I'll take a look.
&gt; The ParallelListComp allows zip like operation to be expression in the comprehension. The idea originates from Galois [...] As I remember parallel list comprehensions have been in Clean a long time ago.
Nope! I wrote memoi.se in New York City, which also happens to be home to the largest Haskell Meetup in the world: http://www.meetup.com/NY-Haskell . "memoi.se" just happened to be the best name I could come up with for a FP-based URL shortener.
Thanks for this great episode. It was extremely interesting and I can't wait to get some time to watch the talks and read the papers :)
What uses do functional dependencies have that are not covered by type families?
Very nice release. I think a little more explanation on LTS vs nightly may help a lot of new comers who need to make a choice. I understant LTS is more of a consideration for those who want to ship a set of packages; they can stick to a major LTS version, thereby enjoying bug-fixes without (with minimal chance for) breakage. Or stay compatible to several major LTS versions. Nighlies are then, as I understand, more for those who want to be on the bleeding edge. The `cabal.config` trick is to make sure that the right packages are selected: those known to be compatible. I'm a bit lost on what is supported by what version of cabal, and how this workflow may change in the future. But I guess I'll just have to play with it to find out what works :)
Thanks, I'll take a look to their blog. I did not know there were people using it on Android on a regular basis; sounds good.
&gt; Tests in other languages have a tendency to involve state and/or mocks Couldn't QuickCheck consider all (external/impure) module imports to be implicit parameters to mock. E.g. take this python function for instance: def replace_file_with_backup(filename, contents): import os os.rename(filename, filename + '.old') open(filename).write(contents) This function could be modeled in the state-monad, where "os" and "open" are two entries in the state tuple. 
Now I don't know if I should upvote or downvote you...
Posting in /r/haskell because, well, I wrote this in Haskell! Despite being my first time using Data.Binary, not to mention the FFI, actually writing the code turned out to be a breeze. The hardest part was still figuring out the OpenSSH private key format, not actually writing the code. Woot!
&gt; compute Sha-256 and Ripemd-160 Sounds like bitcoin :)
&gt; detract from any attempt at real discussion Hyperbole much? It may be an offhanded comment, but it's doing nothing to prevent "any attempt at real discussion."
I have to create a modified version of a SPV client, I tried bitcoinJ, but after a while trying to modify its inner parts, I got kind of lost; maybe it easier modifying haskoin and then porting it to android.
I'm sorry. Try https://dl.dropboxusercontent.com/u/39280925/cain.pdf for now. I'll try to find out why the original is not working.
It's my understanding that the new method of specifying constraints through cabal.config works with most (or any version you're likely to encounter) versions of cabal-install. The old way, using remote-repo, only worked with very new versions. So the new way is strictly more compatible. Additionally, the old way didn't play nice with sandboxes. Cabal sandboxes ignored the 'remote-repo' line in their configuration files, and only read that line from your global cabal config. So all your sandboxes had to use the same stackage version, or you had to mess with the global config all the time.
Tipping makes me smile.
I am not buying that propositional equality (by `≡`) is not too strong for this purpose. For example, consider the humble [co-Yoneda functor](http://hackage.haskell.org/package/kan-extensions/docs/Data-Functor-Coyoneda.html), as implemented in Haskell: data Coyoneda f a where Coyoneda :: (b -&gt; a) -&gt; f b -&gt; Coyoneda f a instance Functor (Coyoneda f) where fmap f (Coyoneda g v) = Coyoneda (f . g) v If we did the same in Agda, it would **not** hold that fmap id xs ≡ xs since fmap id xs = fmap id (Coyoneda f v) = Coyoneda (id . f) v and xs = Coyoneda f v and of course, because of intensionality, id . f ≢ f 
I'm interested in knowing who is using Haskell in Italy, and how. Is there some sort of Italian Haskell community where I could learn about this?
Can you provide links to any details for this? 
http://www.amazon.com/Thinking-Functionally-Haskell-Richard-Bird/dp/1107452643/
I like to buy hardcover books, but for this one I have to wait a bit ... November 14, 2017... Edit: it's not a typo on Amazon's site, Cambridge University Press also mentions November, 2017.
Keep in mind that when you use `Generic` to implement other classes, there is a small performance hit, as you have to take a value, call `from` to get the `Generic` representation of that value, and then traverse that value, which is an unnecessary step for a non-`Generic` deriving mechanism. Depending on your application domain, this could make something like `DeriveFunctor` still more desirable than `DeriveAnyClass` with a generic `Functor` instance. (Okay, to be perfectly pedantic, it would have to be `Generic1`, because `Functor` has kind `* -&gt; *`, but still.)
The name of that extension promises so much. `Data Whoa = Whoa ((Int -&gt; Int) -&gt; Bool) deriving (SolveHaltingProblem)`
/u/chrisdoner tried to create a Meetup in Trento a while ago, but being such a small city in the very far north of Italy, you can imagine is not exactly the most attended one (which is totally a shame). I'm from Rome, the capital, which sits in the middle of Italy, but I'm not aware of any Haskeller in my city. I really hope this conference will be a chance to do a bit of networking with people and perhaps discover some hidden programmer I wasn't aware of ;)
Is this not something which could be done at compile time?
Are there plans to hopefully fuse away most of those marshaling operations?
 {-# LANGUAGE DeriveAnyClass, DeriveFunctor, GeneralizedNewtypeDeriving #-} newtype NewList a = NewList [a] deriving Functor Which of the three mechanisms is my `Functor` coming from? How do I know? How much control do I have?
`getError`'s type seems unnecessarily restricted. If you write getError :: (Generic errorLike, GetError (Rep errorLike) e) =&gt; errorLike -&gt; Maybe e then it should also work on non-polymorphic error-like types, e.g. data T a = Left String | Right a (I hope so; I haven't tested it.)
For Functor, probably yes (but they may have different compile-time and run-time performance). Here's another similar example: newtype A = A Int deriving Show If GND is used, then `show (A 2) == "2"`. Otherwise, probably `show (A 2) == "A 2"`. (Currently, the latter is the case.) So we already have this problem, but I agree with /u/dmwit that `DeriveAnyClass` makes it worse, and that bothers me, too.
Note that in many cases, GHC is smart enough to optimize away all overhead of the generic representation (with a little prodding). See [this paper](http://dreixel.net/research/pdf/ogpi.pdf) by José Pedro Magalhães.
See my reply to the parent.
No, they're all implemented differently. GND works using coercions, so there's no code at all. DeriveFunctor generates code that works on the data type directly, and DeriveAnyClass works through Generic, which means there are conversions to and from a representation type.
I think most of the details are only available in the relevant [GHC ticket](https://ghc.haskell.org/trac/ghc/ticket/5462) currently.
Looks nice. Do you think you might be able to choose a more descriptive name for the argh function? It makes main a little hard to follow. :-)
There's a big problem with Generic that it breaks data abstraction, exposing the innards of our abstract data types. Even allowing to break the internal invariants of smart constructors. Is it possible to have Generic instances be in scope only if the data constructors are in scope like the Coercible instances?
Looks nice. Do you think you might be able to choose a more descriptive name for the argh function? It makes main a little hard to follow. :-)
How does gdb handle it?
Yes, it ought to be called something like sign_seed_keypair; the current name reflects my reaction once I discovered none of the Haskell bindings to libnacl/libsodium (or copies of the SUPERCOP code), of which there are a few, actually bind this function ;) Hopefully this will be solved elsewhere, perhaps https://github.com/tel/saltine/issues/18.
Breaking data abstraction is not a big problem in this case, as you have to opt-in the reflection capabilities by mentioning the `Generic a =&gt; ...` constraint in your signature. In contrast, OOP languages' reflection facilities are available all the time, breaking parametricity fundamentally. (Not to speak about the fact it can covertly mutate your object.)
Sure, requiring a Generic constraint can be useful, but imagine that Map used "deriving Generic", and imagine: foo :: Map Int String No Generic constraint appears, yet it could use the Generic instance to build an invariant-violating Map! Sure, OO languages have reflection which is *even worse*. But should we not aspire to be able to give a strong *guarantee* that our invariants hold? At least in Safe Haskell?
&gt; This week, Austin managed to secure two sponsors for GHC/Haskell.org. We've been given a wonderful set of ARM buildbots (running in the cloud!) and a new, incredibly powerful POWER8 machine to use (with over 170 hardware threads available, for scalability testing). Hooray for our friends at Online.net and RunAbove.com for helping us out! http://i.imgur.com/cj9o6XO.png [mfw 176 cores](http://i.imgur.com/BjMmT1Q.jpg).
Well, in dynamic languages *faking* could feel almost as natural as the real type system driven instance search. Compare: boolFnAppliedThrice :: Fun Bool Bool -&gt; Bool -&gt; Property boolFnAppliedThrice (Fun _ f) b = f (f (f b)) === f b quickCheck boolFnAppliedThrice Or in [javascript](http://jsverify.github.io/) var boolFnAppliedThrice = jsc.forall("bool -&gt; bool", "bool", function (f, b) { return f(f(f(b))) === f(b); }); jsc.assert(boolFnAppliedThrice);
&gt; The 7.10 RC1 looks like it's scheduled to occur this week still
Minor nitpick, you need to derive `Generic` as well, it isn't implicitly derived. See also [`deepseq-1.4.0.0`'s new `rnf` docs](http://hackage.haskell.org/package/deepseq-1.4.0.0/docs/Control-DeepSeq.html#v:rnf)
If you try that with GHC HEAD, you get: Warning: Both DeriveAnyClass and GeneralizedNewtypeDeriving are enabled Defaulting to the DeriveAnyClass strategy for instantiating Functor In the newtype declaration for ‘NewList’
Algebraic structures are defined on top of setoids, e.g. there is an equivalence in `RawMonoid` definition: https://github.com/agda/agda-stdlib/blob/5cb3693802341d43ccb9d54cc1d8f13182629827/src/Algebra.agda#L35 Providing something similar for Functor is possible, but might make everyday *programming* too complicated. *EDIT*: It will be still Functor, but the codomain category won't be anymore the whole *Hask*, but a sub-category with it's own equality, which isn't *Hask*-structural.
Doing this compiler course at uni at the moment and for every datatype that we have to define we have to manually define its catamorphism. Kind of tiring. I guess using this would make it easier to automagically do this? Like if we'd define folds over the datatypes that `from` produces we could fold any datatype right? But how would this work with mutually recursive datatypes?
Yes, that's what Suenaga &amp; co did!
Oh right, sorry.
I took a graduate course in formal semantics. We used the typed lambda calculus to represent the meanings of words and sentences. Do you think it would still be necessary to read this text?
Thanks for sharing this. Interesting to see Thoughtworks putting something related to Haskell, but I cannot really make any sense of what they are trying to say ? Have they released any open source library related to Hadoop on Haskell ?
You're keeping the bot busy.
How do you use Generic to build the data if you don't have the constructors?
And, if I write `"bool -&gt; boll"` instead of `"bool -&gt; bool"` do I get a compile-time error (Quickcheck) or a test failure (your pretender)?
This is part of their tech radar, which you can see they've labeled this particular concept of marrying haskell and hadoop at "assess" for 2015. "assess" for them is like "this is interesting and promising, but the maturity and knowledge isn't there to use it in production, but keep it on your radar"
/u/ocharles [strikes again](https://ocharles.org.uk/blog/posts/2014-04-26-constructing-generically.html) 
Don't you just need to have the datatype be a Functor on the recursive part of the data structure? You can then implement catamorphism in a datatype generic way. DeriveFunctor will also help here. 
Thanks, that makes it clear.
That sounds very interesting, could you please give a link to any course materials?
No - I didn't know about this at all. But this is an interesting read, thanks!
Sounds beefy 😍 I was asking about the average memory available to the cores.
This hasn't been my experience. I hear Haskellers saying that Haskell classes are totally different from OO classes, and I just don't buy it. There's so much in common. From the implementation point of view, it's a mechanism for dynamic dispatching, and there are vtables passed around behind the scenes. From the type system point of view it's bounded polymorphism. Yes, there are differences, but they are not irreconcilable. 
Pusher is Haskell? I implemented parts of the pusher protocol in Haskell but never released it. Maybe I will. Do you have a Haskell client implementation somewhere?
That's only gonna come out to about 270MB/core. Which is good, but not massive. :)
Can you please clarify whether this job actually involves Haskell? I ask, since I've seen many companies (my old one included, sadly) advertise for "haskell developers" hoping to select for a certain kind of developer, and then once they get in touch, they get “Well, there might be opportunity for expanding into Haskell, we think it's really cool; we're mostly a Node/Ruby/Python shop at the moment”.
True story.
Sorry for not submitting a text post and giving more information about the position. This job indeed involves Haskell. Pusher was created in a ruby shop ([New Bamboo](http://new-bamboo.co.uk)) and so was firstly written using Ruby. We are now at what we think are the limits of Ruby for system like ours and so we are moving on to "greener pastures". We are currently rebuilding core pieces of our system and infrastructure in Haskell. But to be clear and honest with you, there are still older pieces of our system written in Ruby that will have to be maintained since we can't do everything at the same time. Hopes that helps clarifying the situation. 
Weirdly enough, not yet. We are currently using Haskell only on the server side of things and not the consumer facing side like like the libraries. We would be interested in seeing your implementation of the Pusher protocol.
There seems to be this magic `to :: Rep a -&gt; a` that does the magic. That seems to be the ultimately smart über-constructor that needs to be stashed away.
Just a nitpick. The ad doesn't specify if you accept remote candidates?
This must be an exciting day for you then!
It's just that concepts like Java interfaces or Objective-C/Swift protocols are a much closer match than the classes of those languages.
Would rather see Haskell marry Spark.
We are currently looking for 2 juniors for ~January, job ad @ http://pusher.com/jobs/junior_platform_engineer. However, we are always looking for talented people so definetely get back to us closer to June. you can email me personally at sylvain at pusher dot com.
Quite cool. There is some overlap with ConceptNet and Gremlin, with categories!
Whichever order you like :) I have many of the same books, and am also working through them. My order is not well-defined, and is governed by my current interest in each (since that seems to help me make progress). Perhaps simultaneously Pearls of Functional Algorithm Design and Parallel and Concurrent Programming in Haskell? PoFAD in particular can be read in small pieces.
Yay. I know this one.
The extension I wish it was standard Haskell.
This is really brilliant. I've been wanting to use Haskell + ReactJS for quite some time now. [Shade](https://github.com/takeoutweight/shade) got me really excited about the idea initially. Like the post mentions, having ties to someone else dealing with issues from the Om perspective just gives the project that much more height to stand on.
My implementation is not good. I just did what I needed to do to get things working (and that meant using the JS inspector in Chrome to copy-paste buffers). ;-) I'd love to see something more official though for sure!
strictness by default
&gt; Then I would be to add field accessors with "." operator Try lenses. `'.'` still composition. 
Less finicky syntax and better introductory resources.
Short and sweet! I appreciated the comparison to numeric literals. Does this sort of thing have any runtime cost?
Side effects. *Runs away*
A hole-driven development source code editor. It's silly but I can and do relax my expectations in terms of honesty in the types I write when working with a weaker type theory but needing a type-checker brain can be quite strenuous.
Sexp-based syntax.
Side effects + laziness is a path of madness. Proof, insert `unsafePerformIO` everywhere and watch as sanity slowly bleeds out of the very fabric of your world.
Maybe I'll get some flack for this, but you might want to check out purescript. In my opinion, it eliminates a lot of the pain points of Haskell, including some stuff I didn't even know was a pain point until I saw alternatives, while still being type safe and keeping type classes and such.
Ewwww...
Just `RWST IO ()` all the things!
- A way to do deterministic memory allocations / deallocations (kind of a big deal in hard realtime applications) - Making strictness more explicit - A more consistent numeric type hierarchy that doesn't lie as much - A way to create integral types with a limited range (without resorting to Peano numbers or explicit enumerations or other such nonsense) - Have Text be the default string type - Type-level integers - ~~Type-level `$`~~ - The whole monad/functor/applicative thing (any day now though...) - A world where Haskell doesn't scare the average project manager, let alone the programmers in the trenches
built in support for BLAS and matrices
Had to downvote that because that would not be Haskell at all. I think lazy evaluation will gain more interest in time. (In other languages as well)
See e.g. [this talk](https://www.youtube.com/watch?v=8WFMK0hv8bE#t=12m20s) by Alan Jeffrey using Agda.
Paredit lets you directly edit the AST, and easily allows complex manipulations and perfect auto-indenting.
Sadly, no. I've updated the wiki feature page to remove the wishful thinking.
I'm bright, but I'm not *that* bright.
A message that explains, where exactly, my "*** Exception: Prelude.head: empty list" error occurred.... (please don't give me any "that's impossible" comments, it is just lame and untrue).
Awwww…
Have you looked at Rust? It seems like it might fit the bill for your real time applications. 
This. Without paredit, I'm lost.
&gt; silly but I can and do relax my expectations in terms of honesty in the types Type hole searching imported packages would be huge I think. It seems like this should already be possible. If it's not, does anyone know why and of work to change it?
&gt; including some stuff I didn't even know was a pain point until I saw alternatives, Do you have anything in particular in mind?
Simple, compile with profiling and rts options enabled, and when invoking your program `+RTS -xc -RTS`
Aww - man! Well, thanks for replying. BTW, I'm sure everyone waiting for this to get merged is hugely appreciative of your work on this language extension. So, if someone hasn't thanked you yet today, thanks for enduring what I can only imagine was a true horror, navigating the technical minefield getting it to work. 
Straightforward code hot swapping
Why built in? While I, too, have much use for these things in my daily life, they hardly belong in the language core!
I like how Perl requires a slightly smarter programmer but produces worse results than Python.
&gt; I love the strictness You'll want to be more careful using the "s" word. Strictness in the context of Haskell usually refers to evaluation strategy (Haskell is non-strict). I think you meant to say you like Haskell's strong typing.
It often feels like it should be, but it can cause ambiguity problems. However, I think in practice whenever we're passing string-literal-like things around, we've usually got an exact choice of underlying data type, so it doesn't happen too much in practice.
I would love to hear more about your experiences with using Haskell at Pusher, have you ever done a talk/blog post about it?
&gt; Note: writing in Agda is very slow. Prove it!
Thank you! The story is a long and sad one, but I'll try to give the short version. ORF was essentially ready before the release of 7.8, but we held back because it was a large and potentially quite disruptive change to the codebase. Then after the eventual release of 7.8, SPJ reviewed the proposed changes and he and I agreed that some changes in the internal representation details were desirable. Unfortunately these turned out to be quite difficult to implement (even keeping the patch up to date with HEAD is a challenge). Meanwhile, life intervened... Still, I've learned some useful things, notably to make changes to GHC in as small steps as possible! Given the experience so far, I'm making no promises regarding ORF in 7.12, but it's not impossible.
It's been said that Agda programmers don't actually need to run their programs :) If they type check, they must be correct. 
In some contexts typeclasses are like concepts, and that's how I translated Haskell's Monoid to C++. But that will work only when the type can be resolved at compile time. If you erase the type, then you have to fall back on runtime dispatching, and then it's more like traditional OO classes. 
I now have some free time over the holidays so may actually be able to finish this ([see here](http://www.reddit.com/r/haskell/comments/2ocvoq/z/cmm4kvm)). 
Lazy is a good default. However, the ability to switch that on the module level would probably help a lot.
In the common case where the type is completely determined by the context, and you're simply writing a `String` literal where something else (e.g. a `Text`) is expected, `OverloadedStrings` should have no extra cost. Polymorphic code with explicit `IsString` constraints might incur some overhead if it doesn't get specialized, but that seems to be much less common in practice.
Just Google for it and you'll see lots of very good arguments for laziness. Two examples: http://augustss.blogspot.com.tr/2011/05/more-points-for-lazy-evaluation-in.html https://existentialtype.wordpress.com/2011/04/24/the-real-point-of-laziness/
IMO Rust is just too low-level. There should be a sweet-spot between Haskell and Rust where we have a high-level, purely functional language but also deterministic allocations/deallocations.
http://stackoverflow.com/questions/25359461/finding-where-loop-happened/25359633#25359633
More documentation
I tend to think the approach taken by Ivory makes sense here - create an AST in haskell-land that can be used to generate C with allocation guarantees.
Johan Tibell has been working on a {-# LANGUAGE Strict #-} extension for some time.
Amen.
But it would be nice if `*` actually performed matrix multiplication like you would expect.
Almost none of my uses of laziness come from infinite lists. Those are the examples folks trot out because that it the one thing that most of the rest of the language ecosystem can at least do. Knot-tying requires some limited form of mutation. In a lazy language thunk evaluation can serve this purpose. In a strict language it typically gets delegated to having every computation be able to `set!` a pointer. Now, we need to be able to tie knots, because a strict _pure_ functional language can be shown to suffer an O(log n) slowdown for many algorithms. Laziness recovers that time bound for many algorithms (it hasn't been proven that it can/can't do it in general yet.) Laziness gives you the fact that lazy algorithms can compose with better asymptotics than they have individually. This encourages folks to write small reusable bits of functionality without having to fuse everything together by hand. Without it, you find you are constantly tempted to replace the composition of two 'general' solutions with one specific solution that has been hand fused together to get the right asymptotics. I can at least _try_ to solve the problem with laziness. Lots of folks claim you can bolt laziness onto a strict language successfully by shoving it in a type. Nobody who claims this can point to any languages that have successfully done so _and_ which have any libraries that make reasonable use of it. e.g. Idris makes 'Lazy' a type, but then it doesn't even make (&amp;&amp;) lazy in its second argument. [Edit: I'm apparently mistaken in this] Scala makes lazy val's a thing, but nobody uses them, and without proper tail call optimization serious attempts to use them in the large have to be carefully constructed lest they blow the stack. There is a whole class of garbage collection errors that goes back to Wadler that you run into when you try to shoehorn lazy semantics onto an existing strict language's garbage collector as well. You could build an RTS that avoids these, but nobody in the 'strict-by-default' category has one. Take those space leaks you get now and blow them out to where you can't fix them. That is the world you get when you try to shoehorn in a little bit of laziness in a strict language. I write code with laziness because lazy algorithms _can_ compose, and because with it my code cleanly extends to infinite cases that just aren't even thoughts I can think in a strict language. When building a data structure where I want particular asymptotics, I tend to try to think through Okasaki-style how thunks will accumulate in parts of my data structure over time, but you don't always need to do that. Almost all space leaks can be solved by asking yourself 'how big are the tweaks I'll be accumulating at this point in the data structure?' If they are small things like bumping counters and doing addition, make it strict. Otherwise, in my experience, be even lazier than you think is sensible and things quickly stop leaking again.
&gt;Lots of folks claim you can bolt laziness onto a strict language successfully by shoving it in a type. Nobody who claims this can point to any languages that have successfully done so and which have any libraries that make reasonable use of it. &gt;e.g. Idris makes 'Lazy' a type, but then it doesn't even make (&amp;&amp;) lazy in its second argument. Yes it does. I'm not going to get into the strict vs lazy argument again (there are good arguments on both sides and it really depends what you're trying to do) but please don't say things which aren't true because people end up getting the wrong impression, believing it, and it's really hard work convincing people otherwise! (By the way, even if this was true, partial evaluation and inlining would typically ensure that (&amp;&amp;) short circuits anyway.) 
Something like MLKit?
During last summer, I implemented hole-driven editing for Emacs, in the style of Agda and Idris. You can check it in http://serras-haskell-gsoc.blogspot.nl/2014/08/summer-of-code-on-emacs.html
A few months is a long time in a fast moving research project (actually it's a long time in any project). Some day I'm going to write up the proper, full justification for why I want Idris to be strict and not lazy. One reason is that I want types to be properly precise - if I see "x : Int" then I want to know for certain that x is an Int and not a computation that might one day give me an Int. A long term goal is to be able to program low level limited memory systems (e.g. device drivers or kernel moduels) directly in Idris, with the ability to reason about resource usage. For the record, I think laziness is lovely too and I use it all the time in Haskell. So I'm not going to argue for or against it - like any interesting technical point, it's compilcated.
&gt; Lots of folks claim you can bolt laziness onto a strict language successfully by shoving it in a type. Nobody who claims this can point to any languages that have successfully done so and which have any libraries that make reasonable use of it. On the other hand nobody has come up with a convincing reason why it couldn't be done. In *practice*, i.e. in the realm of languages that actually exist, I'll take Haskell without hesitation, but in *principle* much more research and experience is required before we can claim to know the best way to combine laziness and strictness.
Fair point. I can't claim to have perfect insight here. Outside of the Haskell community virtually everyone else has taken the opposite bet, so I'm clearly staking out an argument for a minority position here. Since I've apparently chosen which dog I'm backing in this fight, I figure the best way I can advance the case is to try to build as much interesting stuff that takes thorough advantage of the powers afforded to me by laziness and see if in the end the body of work is enough to help stem the tide. That said, it does amuse me that almost every problem I've had with laziness has ultimately been solved by using more of it, though. ;)
It seems to me like you would be giving up a major part of what helps Haskell be performant - persistent data structures and data sharing between those structures. It seems like data sharing is at odds with deterministic allocation. Either that or avoid more complicated data structures. Ignoring the immutability aspect, can I ask what about Rust is too low-level? It's not as high level as Haskell is (what is?), but it's possible to write quite high-level feeling code in it.
&gt; Knot-tying requires some limited form of mutation. In a lazy language thunk evaluation can serve this purpose. This statement contains insight I've been lacking. I've never thought of it like that. Thank you!
Thanks!
The difference between this and other compilers is that haskellstub let's you run any command. If it is considered unsafe, then run it. 
Named / labeled parameters like in Ocaml. They let you reorder parameters without having to resort to `flip` and are extremely helpful when you have lots of parameters or multiple parameters with the same type. 
If there had been a bet I would have been 99% sure this would be the first extension to be covered this december. And then it comes near the end! :)
That last one... Couldn't agree more.
Better tooling all around. It's rediculous that I have better highlighting/autocompletion/syntaxhelpers for frickin' Python (in PyCharm) than for Haskell. The language is great, but for any wide-spread success you need decent, accessible tooling (the main reason people stick with java).
[relevant](http://www.xent.com/pipermail/fork/Week-of-Mon-20070219/044101.html)
Just in case OP wants an example: bob &amp; finance . accounts . traverse . deposit %~ (+5) -- adds 5 units to all of Bob's deposits. **EDIT** (thanks Peaker) bob &amp; finance . accounts . traverse . deposit +~ 5 -- adds 5 units to all of Bob's deposits.
So it sounds like we may never get this extension. Is this a case of the perfect being the enemy of the good?
They aren't accident. They are consequence what can be called premature optimization (striving for performance above all). But it is the optimization in face of war, so they should not be called that.
A better module system. Sound structures in type variants (that is, no possibility of runtime errors for that). GHCJS finally ready and able to use ghc-mod.
I have great autocompletion with ghc-mod.
I may be nitpicking here, but I believe that strictness has more to do with the semantics of the language rather than the evaluation strategy. Lazy evaluation is possible with a non-strict language. A non-strict language means that: f x y = x f (1+1) (1/0) won't crash. It doesn't mean that 1+1 won't be evaluated when f is applied.
Yes, my &gt; seems to be much less common in practice could probably have been strengthened to &gt; doesn't happen in practice!
Wait, I thought Xmas was on the 25th ;)
I don't like it when every time I change a computer, I will install them with cabal. Every time cabal cannot resolve a strategy of package dependency, I will install them with cabal. By the way, what packages do you use? And what do you use them for in your daily life? (I use then for solving differential equations.)
I agree with this. And even though it is not called (*), it will be a good function.
Truly first-class support for impredicative types, like MLF, and first-class existentials. :)
&gt; Ignoring the immutability aspect, can I ask what about Rust is too low-level? This is more like a "feeling" thing, e.g. I wrote several kloc Rust and felt like Rust is forcing me to do a lot more work than Haskell do for the same program and it's a lot more verbose. Overall the experience was not fun at all. (unlike coding in Haskell) One example I had in mind from that project is this function: import qualified Data.ByteString as B import qualified Data.ByteString.Char8 as BC -- | Parse `a=b` pairs from a query string. Parsing starts from the -- position of '?' in the string. -- -- &gt;&gt;&gt; parseArgs (BC.pack "dummy?a=b&amp;c=d") -- [("a","b"),("c","d")] -- -- &gt;&gt;&gt; parseArgs (BC.pack "?") -- [] -- parseArgs :: B.ByteString -&gt; [(B.ByteString, B.ByteString)] parseArgs = -- split to (key, val) pairs map (fmap BC.tail . BC.span (/= '=')) -- split to key=val strings . BC.split '&amp;' -- drop the prefix . BC.tail . BC.dropWhile (/= '?') I had this same function in Rust and it was horribly verbose. I had other examples too, but this is what I remember for now. 
I would love to see how something in the lineage of McBride's Frank could handle these kinds of things. If CBPV can satisfy its promises and strike a true compromise between strict/non-strict then maybe the whole level of discourse can be elevated a bit. I'd rather have great knowledge of when to be lazy and when to be strict over knowledge of how to survive in a strict-by-default language or a lazy-by-default one.
&gt; I implement solutions fast but when it comes to make them presentable to the world, things get complicated. What kind of things did Haskell make difficult when you started to make things presentable to the world?
I confess I remain slightly skeptical on that front, but I'd be quite happy to be wrong.
 %~ (+5) Is equivalent to: +~ 5
It's been quite a lot of work getting the Cabal and GHC changes ready, so unfortunately this meant I had less time for working on other things, like the `ghcjs-base` library, which needs a bit of attention to address some of the JS interaction issues Ian mentions. I think there will be some fixes in there soon, but I hope you're not too committed to a particular date for presents, since I don't know when they will be ready yet ;)
Remove exceptions from the language.
Hopefully somebody finds this useful :) Any feedback is appreciated!
You can't name the fields with tuples. 
This thread might be of interest to you: http://pchiusano.github.io/2014-12-09/better-nonstrictness.html#comment-1733655884
I almost always argue against shared libraries. I'm no fun at parties. I'd like easier strict evaluation. And the leak tools would have been great. Spent a lot of time on a project tracking down what was ultimately Data.Map insertion being non-strict in code that didn't need to observe side-effects until queried. Eventually solved it, and I was never happy with the result. It was however good enough to ship and did. 
It gives you compositionality.
OK, so to give more context, I talked with Simon on Monday about this at the behest of Kazu Yamamoto who was interested in this same question. The TL;DR is the patch *feels* complex for what it's supposed to accomplish, and this is the main hold-up from what Simon told me. I'm sure Adam can probably expand here. On the note of perfect vs good, well, I think there's a lot more to it than that. Merging first and refactoring later, is, IMO, going to be a pretty hard sell for any feature. Especially if the changes are large and sweeping (and, in this case, they certainly are). GHC is already very, very complex - any *unnecessary* complexity should be treated with extreme care and deliberation. Now, we *do* tend to foist really new features on users anyway and let them break stuff - but those new things are ones we already think pass said criteria anyway! Personally, I think missing a release or two is preferable to adopting a large patch that is not fully ready. Diligence is one of the only tools we have to manage our complexity, and that really goes for any software project. Obviously humans aren't always completely consistent or logical beings, but we have to do what we can to keep these things in check. If the patch wasn't so large, it could very well be a different story. On the other hand, most of GHC HQ's development efforts are driven by user desire, actually. We tend to implement/handle/manage/prioritise plenty of broad things that have been voted on or discussed publicly. The reality is that nobody has actively complained much of this patch not being in, so we've just sort of put it on the backburner. This was the basic reasoning we had when I talked to Simon on Monday this week. If people have concentrated interest in this feature getting in faster, I'm fairly sure the effort can come together to get it done (and Simon would certainly help make it happen among others). This thread is a good start for that.
pretty darn anonymous, huh? :-p
It would be cool if one could annotate the `fromString` method that you want it evaluated at compile time, e.g., instance IsString Text where {-# COMPILE-TIME fromString #-} fromString = pack The (non-existing) pragma says that if `fromString` is applied to something without free variables (say), then the compiler will evaluate it instead of delaying it until run-time. This wouldn't make a big run-time difference since such an application is a CAF anyway, but it would give me peace of mind. 
The github orf-new branch has one huge commit. Is there another branch with OverloadedRecordFields as a set of incremental commits? It will be easier to keep it in sync with HEAD this way.
Thanks for the detailed reply I was definitely looking forward to it. I do not have any practical examples increase motivation it get it included however. If I wanted to build ghc and try it is there a particular git-tag I should use other than the wip/orf-new branch, and maybe roll back commits to approximately the right time frame for ghc-7.8, to get it to compile with ghc-7.8?
A typical use case for this would be functions with named parameters. Instead of things like transferMoney 100 40 23 we could write transferMoney { amount = 100 , fromAccount = 40 , toAccount = 23 } Not the best example, but that's the gist of it. Tuples wouldn't help.
This could be used for compile-time validation: `fromString = either error id . parseURI` For this use-case I tend to use `$(makeURI "http://…")` or `$(makeRelativeFileLoc "foo/bar.txt")` etc. Lispers use reader macros like `#p"/home/chris/"`. It would be good to have general support for smart constructors (x -&gt; Maybe a) at compile-time, when you know it will be valid but don't want to deal with an error case at runtime that should never happen. 
yes it's possible, but don't you have to leave out the runtime? It's been a while since I've tried that.
a crystal clear tutorial to build haskell modules in a way that make them python modules. I would write the outer-shell in python (django, etc) and the inner/fun stuff in haskell. 
&gt; It would be good to have general support for smart constructors (x -&gt; Maybe a) at compile-time, when you know it will be valid but don't want to deal with an error case at runtime that should never happen. And not have to bring out the Template-Haskell sledgehammer to do it.
* IDE support like F# in Visual Studio * Jobs
Considering the slow net connection to hackage, it will take a few minutes to install a package. That is the horrible thing for me. And that is also what makes me create a local hackage site myself.
Implicit arguments are available as a GHC extension. Default/def or Nothing/fromMaybe paired with implicit arguments gives you something close to default arguments, but quite verbose. Having some helpful, terse syntax here would be nice, I agree.
I wish that question marks and exclamation marks could be part of identifiers a la Ruby or Clojure. It would be a lot more pleasant to write e.g. `ready?` instead of `isReady`, especially with lenses. I like how side effects are indicated in the name if it has a ! at the end. Just has more punch to it.
Do you have a good replacement for asynchronous exceptions? For synchronous exceptions, `EitherT` (or something like it) is a fine replacement, but I don't think it's so easy to get rid of asynchronous exceptions.
So, pretty much strongly-typed JS object syntax? Like, it doesn't matter in which order you place it, as long as you provide values of the right type? Sounds nice. EDIT: Would pattern matching be as flexible, too, though? Perhaps require an explicit ordering anyway to simplify this.
It is not intellectual. C-M-i even ignores the imported modules. I like error highlighting in ghc-mod. The navigation, type inference and many other features do not work reliably for me.
I think the reason why nobody complained about this patch not being in is because it was publicly stated as slated for the 7.10 release! Had I known instead that it was in a state of limbo I would have been complaining about it! Haskell really needs first-class record fields whether it is from the current patch or something else.
A guy who writes Erlang for a living said code hotswapping wasn't actually used that much.
If Haskell had **an easier learning curve** I'd marry the language :( I really like Haskell and can see the big picture of why a lot of it's features are nice, but I just don't have the time to sit down and master the language right now.
 .&gt; :t 3.412 3.142 :: Fractional a =&gt; a argh...
I agree that the implementations are similar, but I think that the exterior matters more. (Function members of) classes in C++ are either static dispatch or single-dispatch. Type classes in Haskell can be chosen based on the *return* type, and static dispatch is not allowed. (Multi-dispatch is only an extension though.) Classes in C++ are introduced by adding to structures, under the assumption of data members. Type classes in Haskell shouldn't contain data members -- if you try doing it the most direct manner, you get ambiguous instance error everywhere. Members of C++ classes can be static or non-virtual; not so for type classes. A Haskell type class instance has more in common with a vtable than with a C++ class. I learned C++ way before Haskell, and it was useful for me to think of type classes and C++ classes as separate, different things until *after* I felt comfortable with Haskell. As that point I could draw my own connections without accidentally bring over too much baggage.
&gt; That said, it does amuse me that almost every problem I've had with laziness has ultimately been solved by using more of it, though. ;) Hahaha. That reminds me of Doaitse Swierstra's comment about his future and history parsers. He kept running into issues until he sat down with a colleague and reasoned about the code, adding a few ~ to patterns, after which it performed admirably. 
Thank you. That does look like a cleaner implementation. As I mentioned in another thread I think I need a transposition table. In Python, I used a map that was available to be mutated by all levels of the recursive minmax search. Whenever the minmax algorithm encountered a transposition (a board state it had seen before in another branch of the tree) it would use the results it calculated the first time. I haven't succeeded with this approach in Haskell yet. I thought I had it, but encountered "&lt;&lt;loop&gt;&gt;" errors. I have already implemented alpha-beta pruning.
I wonder if a separation of code structure from display is really what's needed (not just for Haskell but any language). We're trying to cram a bunch of information into plaintext while keeping it easily readable by both computers and humans. If we separated those concerns we could have all the benefits of paredit without the need for sexp display of syntax. The tricky part is figuring out how editors would translate changes in the human readable format to the computer readable format.
Exactly this.
What?
[Elm records](http://elm-lang.org/learn/Records.elm) seem really nice and more "ad hoc" than the kind Haskell has (at least based on what I've read).
I bound `F1` with the type resolving command of the `ghc-mod` plugin in `vi`. That's not a popup, but that's very convenient. I suppose any editor with `ghc-mod` support can do this.
There is an RTS option for this (-xc). From the GHC manual: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime-control.html#rts-opts-cmdline &gt; -xc &gt; &gt; (Only available when the program is compiled for profiling.) When an exception is raised in the program, this option causes a &gt; stack trace to be dumped to stderr. &gt; This can be particularly useful for debugging: if your program is complaining about a head [] error and you haven't got a clue which bit of code is causing it, compiling with -prof -fprof-auto and running with +RTS -xc -RTS will tell you exactly the call stack at the point the error was raised. 
In addition to the above, don't use head.
&gt; $ ghc --make -O2 -static -optc-static -optl-static -optl-pthread Main.hs &gt; &gt; Linking Main ... &gt; /opt/ghc/7.8.3/lib/ghc-7.8.3/rts-1.0/libHSrts.a(Linker.o): In function `internal_dlopen': &gt; (.text+0x25b): warning: Using 'dlopen' in statically linked applications requires at &gt; runtime the shared libraries from the glibc version used for linking Despite the warning, this works. Glibc is always shared though, afaik. 
In Leksah you can select an expression and choose "Type" from the right click context menu. It will send a :type command to ghci and the result is displayed in the log pane. (If there is no selected text the current line is used). You can also press Ctrl+Enter to send the expression itself (or any other selected text to ghci).
[Idris](http://www.idris-lang.org/) is like haskell with dependent types but it's not even close to ready for industry use yet.
It is unfortunately true that the code has to compile in the first place. Does that work differently in the online IDE ? Also, at least with the `vim` plugin, when something goes wrong (missing cabal dependency for example), you just get to know that something went wrong, and you don't get the full error message.
I'm afraid if Haskell was easier to learn it would have less mindblow... and hence be less interesting
We could have done a better job at anti-publicity here, I suspect. I've certainly talked about ORF as being planned for 7.10 (which it was, originally); apologies if I have not made the actual status as clear as it should have been.
IIRC, I updated `wip/orf-new` after the Great Submodule Reorganization, so it should just be a case of checking out that branch and doing `git submodule update`. That's probably the easiest way to get a working build.
It just seems like every program I write gives me tons of syntax errors that are hard to pin down. Haskell syntax isn't always that regular or obvious.
why not quasiquoting for such literals?
The original branch from the GSoC project is here: https://github.com/adamgundry/ghc/tree/overloaded-record-fields Unfortunately I doubt it will be of much use, because it's very out of date, and I didn't follow a very sensible Git workflow at the time. We live and learn...
&gt; Idris is like haskell No, it is not. Strict by default and no kmett-compatible typeclasses.
Faster, clearer stage restrictions, portable, and a lot less opaque.
The ambiguity should be resolved by defaulting ambiguous string literals to `String` (or if we're more ambitious, to `Text`).
I think he's complaining about a typo there (`412` vs `142`).
Good enough for government use. 
These are both good things... I think...
ghci-ng [can do this](https://github.com/chrisdone/ghci-ng#type-info). There is Emacs support. I made [a pre-pepared Emacs config](https://github.com/chrisdone/emacs-haskell-config) which can do this.
 -fdefer-type-errors option allows ghc-mod to get results on the working parts, ignoring the parts not working
Frustratingly this is so true. I am not so much learning Haskell as I am re-teaching myself CS.
Obviously this is GHC not Haskell, and it might be controversial, but I'd rip out &gt;60% of the GHC extensions. One of the biggest problems with using Haskell in production is that two different two programmers use two different and non-overlapping subsets of GHC extensions. Many of them can be handy, but then it's just one more thing to keep in your head.
A workaround for that is enabling `-fdefer-type-errors`. I don't like this extension much because it changes all errors to warnings which messes with my intuition about what I can ignore while working. ghci-ng will remember type info once it's been collected. So for spans of code that haven't moved since a successful compile, type info will still be available. I don't really use type holes… When I'm inserting code that isn't complete I tend to use `undefined` and then query the type of it. In Emacs that's C-c C-u (insert undefined) C-c C-t (query the type). C-M-space (select node) and then C-u C-c C-t will wrap the expression in a type signature which I find handy so I can see everything in the place I'm working. An advantage type holes has is that it gives the fully generalized type. ghci-ng presently only gives the monomorphic one. Ideally you should have both. The FP Complete IDE can do both, for names, but not expressions.
Very useful to make sense of difficult conflicts, and streamline the conflict resolution process in a (IMO) better way than the various conflict-tools. Example, imagine you use [git-search-replace](https://github.com/da-x/git-search-replace.git) to make a large rename: git-search-replace.py -f SomeOldName///SomeNewName And then you make some more edits, but alas, when you try to push, you discover someone had already pushed some changes! So, of course, you try to `git pull --rebase`, but you get some major conflicts, almost exclusively due to the large rename. This used to be a huge PITA, because you have to manually make sure each conflict is indeed due to the rename, etc. Now, instead, you can re-apply the rename at the conflicted state: git-search-replace.py -f SomeOldName///SomeNewName And then you can: resolve-trivial-conflicts -e And it will likely make all the conflicts disappear! If any conflicts remain, your favorite editor will spring up to edit those files. Then, unfortunately, you discover that one of the conflicts was not due to the rename, and caused a huge wall of text to appear inside the conflict markers. You can then use: resolve-trivial-conflict -d And your favorite IDE/editor can parse the output to jump to the conflict lines, showing you the conflict in an alternate, more readable diff-form, which is actually practical to handle.
&gt; This is more like a "feeling" thing, e.g. I wrote several kloc Rust and felt like Rust is forcing me to do a lot more work than Haskell do for the same program and it's a lot more verbose. I'd second that. I've done a fair amount of work Rust and can confirm that it can be much more verbose than Haskell. The macro system is nice and can mitigate this to some extent but I've found that macros tend to be rather brittle and anti-modular. That being said, my application is in the area of embedded systems where this cost is expected and, arguably, necessary. Region typing works out very well here, allowing one to build extremely safe applications on very small machines. I think this is one area where Rust will stand out. For the rest of my needs, however, I'll gladly stick with Haskell.
I agree that the formatting rules are not always obvious (and certainly not simple). But somehow I find them rather natural and intuitive to use. Most times when I wish some formatting should work, it does.
Oh, it's not a serious criticism by any means. I find it hard to criticse Haskell, actually. But it is one of those annoyances I've been dealing with. But maybe I'm just forgetting how much I had to learn with my first programming languages.
* ML-style |&gt; operator in stdlib instead of $, use it whenever possible considered a good practice. * Both left and right function composition in stdlib, with some readable operators, Elm [does](http://package.elm-lang.org/packages/elm-lang/core/1.0.0/Basics#&gt;&gt;) it very well. * Common code style encouraging use of most concrete functions. * Instances as first-class values, no newtypes needed to maintain few instances. These would fix most readability problems, like forcing people read left to right and then right to left and translate between space high abstraction and concrete datastructures with no good reason. Actually right now community and common code style are the top Haskell's problems.
Not yet, but been meaning to for a while. Up until now, C++ was my go-to language for realtime stuff, but it's definitely not ideal.
Check!
I think you're describing Lisp :P
A larger market share. It's frustrating that the industry only asks for those proficient in awful languages, creating a feedback loop of mediocrity and null pointer errors.
I usually don't miss overloaded record fields. When I'm in full control of my types, duplicated names tend to be a sign that I should refactor my model. It gets more cumbersome when I'm creating records for the result of parsing JSON documents, and I want to derive FromJSON automatically using generics. If there are repeated fields, I must create the records in separate modules, and it can get unwidely if there are lots of records.
I'm pretty sure that's going to be the default in 7.10.
Strict by default is definitely the wrong default in terms of enabling code reuse. It's the default in Idris because it makes the totality checker much easier, and Idris is a total language.
This costs quite a lot of performance, which is unfortunate for server software.
What about the Control.Monad.* approach to effects? You can write functions like this: (MonadState MyState m, MonadRandom m, MonadError MytError m) =&gt; a -&gt; m b and delay committing to a particular stack of monad transformers till much later.
This is exactly my point.
I realize that the semantics of the language are different. What I mean is the two languages are built on similar ideas and syntaxes and if you are able to use Haskell competently it isn't too much of a jump to use Idris, which gives you all the power of dependent types.
Hackage won't accept the package because of the -dynamic flag because it thinks it's a debug flag (seems to check for the prefix `-d&lt;something&gt;`), so I can't upload it. But it's cabal install'able.
&gt; Now, we need to be able to tie knots, because a strict pure functional language can be shown to suffer an O(log n) slowdown for many algorithms. Unless it has uniqueness types.
This seems like a pretty easy pragma. All you have to do is generate a record type to fill in the syntactic sugar.
Really, matrix multiplication is a (.)-like operation, which makes sense since matrices are just representations of linear functions, so there could be something clever to do there, too. Consider the type of (.): (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c And the type of a size-aware matrix multiply: Matrix b c -&gt; Matrix a b -&gt; Matrix a c where a,b,c are type-level naturals or vectors or something. I almost wonder if it would be worth making something like an Arrow instance for a Matrix over two vector types with length information and use (&gt;&gt;&gt;) for multiplication... I haven't really worked with Arrows much but I dunno what other standard typeclasses provide a composition-like function. edit: actually, Profunctors could be a natural choice, since their composition is exactly how a matrix multiplication works, and they *are* function-like.
Thanks for this example. I was too damn lazy to provide one :D
I don't like deferring errors either, but I don't understand why you'd use undefined rather than typed holes. They work really well in my experience. 
Lucky you! There are ~2048 good programming languages for you, and only ~2 for me. :(
Have you heard of this new cool thing called stackage server? ;-) You could create a stackage snapshot with your unreleased package.
That was a slightly off-the-cuff remark, so don't take it to mean I'm disparaging the work done in "uuid". The reason why I added that comment is because there was a constraint in the random dependency of uuid that forced me to use an older version of the "websockets" library. I thought that I should be able to write a very simple ID generation routine and solve that issue. I also like being able to remove any dependency that I can if the work isn't too onerous.
Uniqueness typing gives you access to a different limited form of mutation as well.
One reason is that tools that parse haskell source will fail if there is a type hole, but work fine with undefined. This affects anything that uses haskell-src-exts (hlint, hindent, stylish-haskell, etc): https://github.com/haskell-suite/haskell-src-exts/issues/118 
It's fun for making art. I.e. with clojure + quil :)
Ah, that's a real problem. It seems like there's increasing interest in fighting through the pain of using the GHC API which at least avoids these kind of basic support issues. 
If you're interested in the . operator being like you're used to, [Elm's records](http://elm-lang.org/learn/Records.elm) have this, it's quite nice.
Good idea :)
Two things. First of all, I can't seem to be able to access `System.Random`. That's a huge turn down for me. More than half of the Haskell compilers online have this issue for whatever reason. And second, every time you intentionally avoid to write a function type declaration a planet full of cute things dies.
I can fix the Random thing. I will update it to include random shortly. I don't totally understand what you mean by your second thing. 
a lot of tough critics here :) 
Don't you mean `foo Foo {a,b} = a + b`?
&gt; Glibc is always shared though While it is in theory possible to "statically link" glibc, it will still load all of it's resolver modules dynamically. In addition, glibc doesn't consider the interface between it and the resolver modules to be part of the public API/ABI, so it can (and has) changed during point releases. If the glibc on the build system and the glibc resolver modules on the running system aren't compatible you will get spurious host/user/group/etc. resolver failures, and you may get crashes. Static linking of common libraries (like glibc) is bad anyway. It means that we have to update a dozen or more packages that use the library instead of patching just the library package when a security (or other high-priority) bug is fixed. I prefer shipping dynamically linked binaries, even if that means I have to prepare releases in an old, isolated chroot/VM or two.
I agree. My gripe is with (\*) for matrix mult.
I've been using this, I highly recommend it.
The good news is you can at least write `_foo` which is a regular haskell identifier. It's just the particular `_` one that doesn't parse.
&gt; kmett-compatible typeclasses What is this, specifically? Idris certainly has type classes. Writing Idris feels more like writing Haskell than most other languages (including Agda), so I would say it is like Haskell in the way an apple is like an orange.
If you don't like the layout rules, you can opt-out of them by using explicit braces and semicolons.
Awesome site!
Oooh please don't hijack ctrl-l, that's how I go to my location bar. Cool site, thanks for putting it up :)
&gt; What is this, specifically? Coherence http://www.reddit.com/r/haskell/comments/2hif58/edwin_brady_on_idris_in_the_type_theory_podcast/cktn094 https://github.com/idris-lang/Idris-dev/issues/1445#issuecomment-50713392
See OCaml for a (rather complex) design to solve this problem.
Constructive. :P
That is *guaranteed* to not cause an algorithmic slowdown compared to imperative code.
Ed, making laziness a type is *one way* to do it. I actually don't love that approach, since it feels kind of anti-modular. SML/NJ for instance, has an `lazy` annotation that can be applied to both data types and functions to make them behave in the Haskell style. I have not used it, so perhaps it does not do what you want? But if you have not looked at it, you at least ought to take a glance. I'd also suggest that “Well, it could theoretically be done, but nobody on the strict team has done it yet” is a pretty poor argument against recognizing the reality that programming in a lazy language *should be* a restricted mode-of-use of programming in a strict-by-default language. People in the “strict camp” probably haven't thought too much about laziness yet because it's not essential to their work and practice. But since for a partial language, strictness evidently provides a more principled core which admits a wider variety of types than possible in a language like Haskell, discussion of how to *really* recover the usefulness of laziness in such a calculus should not be dismissed with, “Well, we’re being practical here, nobody’s actually done it fully, so we can just ignore it.”
Of all the type signatures to care about, `main` I care about the least.
A good Windows story
Indeed. Lazy functional programming is a very restricted mode of use of FP in general, and we should be specific when extolling its virtues...
I agree, laziness means easier composition of functions, but I find it much more painful to correct space leaks in haskell than to duplicate a little code, or to introduce explicit laziness.
It is not a coincidence that they use the same name. They both developed during approximately the same period in history, and there are various small similarities. But the fact remains that the way you use them in practice in every day programming is vastly different. Beginners who get confused about this experience huge difficulties in learning to write idiomatic Haskell code comfortably and naturally. It's only after you achieve that fluency and have experience writing serious code that you can begin to apply parallels from OO design techniques to Haskell.
Turn down for what?
&gt; Coherence Oh, right, what we like to pretend Haskell guarantees, but it doesn't. It's rather a contrived example to break coherence in Haskell, but it is possible. In Idris, there is no pretense, but it does make some things more difficult. I can see why you consider the Haskell-style an advantage.
&gt; main :: IO () &gt; main = do &gt; s &lt;- readFile "/etc/passwd" &gt; mapM_ putStrLn $ lines s Everything is run in a temporary container so you are free to modify the system as you please and read any files or even do a rm -rf if you want. The container that your code is run in is thrown out as soon as your command finishes. This gives you a fresh container on every run. But nice find!
Top level stuff in the module should work (if the file compiled ok). Basically it looks up the module of the file you are in and sends a a `:module *Your.Module` before it runs anything.
Tell me what packages you would like (and what haskell programmers generally use on a regular basis) and I can make sure they are installed on each run. This type of feedback is super awesome so thank you very much. 
 {-# LANGUAGE GADTs, DataKinds, KindSignatures, TypeOperators, TypeFamilies, MultiParamTypeClasses, FlexibleInstances, PolyKinds, FlexibleContexts, UndecidableInstances, ConstraintKinds, OverlappingInstances, ScopedTypeVariables #-} ಠ_ಠ You see, this is why I dislike the trend to try to transform Haskell in a badly though out dependently typed language. If you want a dependently type language, use Idris and come up with a nice and almost free FFI. The code would be much simpler if you didn't try to play frankenstein with the type system and people would have less headache. Also, the join example in a dependently typed language is given in the paper "The power of Π" (great read). Good job for doing it, but still ಠ_ಠ.
It may be a bit much, but how about everything on http://stackage.org?
This is very cool. Do you mind if I ask how this works in the backend? Docker containers?
I see what you did there
If one has multiple records with a "name" field, perhaps one could define something like data Named e = Named { name :: String , named :: e }
Haskell's been around for many years. Laziness isn't just waiting for its time, it *had* its time.
RankNTypes is probably my favorite GHC extension, and now I have a tutorial to send to my friends to convince them of that. Thanks, ertes!
With a keyboard shortcut.
A more generous interpretation is to see it as a way of enforcing DRY, not as a kludge. In a OO language "Named" could be a superclass; Haskell favors composition instead. And factoring the common attributes out has some advantages like easily allowing "unnamed" records by stripping the wrapper.
I'd say start with https://hackage.haskell.org/packages/top so you can add the most popular packages. However, adding all of the stackage packages would be better if possible :)
I added expanded code in tutorial. Thanks for your suggestion! http://khibino.github.io/haskell-relational-record/tutorial.html
Woops that was a typo. :)
This guess is very well educated indeed. 
Awesome -thanks a lot!
Never mind that a new standard which subsumes the tried and true extensions is no where in sight. Hell, isn't the next ghc planning to break haskell2010 support? We aren't writing Haskell anymore, we're writing GHC.
Yes, containers help, I give you that. But just recently I got defaced by only using containers. 
In 7.10 Data.Function exports `&amp;`, which acts like an ML `|&gt;`, but is easier to type. ;)
Pretty sure [Chris has never heard of it](https://github.com/fpco/stackage-server/commits?author=chrisdone) ;)
Note: Breaking coherence requires relying on how GHC fails to implement the language standard properly or on extensions. More precisely, Haskell has proper coherence, but GHC does not. ;)
Haskell and Ermine? =)