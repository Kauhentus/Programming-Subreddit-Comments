- ([pdf](https://www.cs.cmu.edu/~rwh/papers/priorities/paper.pdf)) Competitive Parallelism: Getting Your Priorities Right - ([pdf](https://hal.inria.fr/hal-01559073v2/document)) Equivalences for Free! Univalent Parametricity for Effective Transport - ([pdf](http://www.cs.nott.ac.uk/~pszgmh/ppoi.pdf)) Parametric Polymorphism and Operational Improvement - ([pdf](https://arxiv.org/pdf/1803.06960.pdf)) Ready, Set, Verify! Applying hs-to-coq to real-world Haskell code - ([pdf](https://arxiv.org/pdf/1804.06013.pdf)) Parallel Complexity Analysis with Temporal Session Types - ([pdf](https://arxiv.org/pdf/1804.00746.pdf)) The simple essence of automatic differentiation - ([pdf](https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf)) Build Systems à la Carte - ([pdf](https://128.84.21.199/pdf/1805.06798.pdf)) Generic Deriving of Generic Traversals
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://www.cs.cmu.edu/%7Erwh/papers/priorities/paper.pdf) - Previous text "pdf" [Here is link number 2](https://hal.inria.fr/hal-01559073v2/document) - Previous text "pdf" [Here is link number 3](http://www.cs.nott.ac.uk/%7Epszgmh/ppoi.pdf) - Previous text "pdf" [Here is link number 4](https://arxiv.org/pdf/1803.06960.pdf) - Previous text "pdf" [Here is link number 5](https://arxiv.org/pdf/1804.06013.pdf) - Previous text "pdf" [Here is link number 6](https://arxiv.org/pdf/1804.00746.pdf) - Previous text "pdf" [Here is link number 7](https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf) - Previous text "pdf" [Here is link number 8](https://128.84.21.199/pdf/1805.06798.pdf) - Previous text "pdf" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
I am actually developing on Mac, and I have solved this in the past but then other people on the project accidentally pushed stuff to `Assets` and broke it again. It doesn't break or cause any major issues (so far at least), but thanks for the reminder to fix it again.
Not at all worried, given that attack is a pile of shit.
Thoughts are my own obviously. Haskell is strictly more expressive and powerful as a language. We have sufficient people that know Haskell, interest from others to learn Haskell and within my team we plan to write significant new code in Haskell. So that’s a done deal. The company has a significant background and systems written for .NET which makes many of the platform benefits that fsharp provides appealing. I don’t see other .NET things going away but new work could be done in fsharp where it makes sense. Sadly fsharp seems to be not that loved by Microsoft it gets features later than other .NET things eg support for .NET Core and type providers. Our team is choosing to use Haskell (along with OCaml) with support from management. I wouldn’t say that choice has been made company wide for other teams. 
This is easily disproved by the vast majority of commercial users that wouldn't have been able to use Haskell if it wasn't for Stack as recently shown in [this user survey](https://www.fpcomplete.com/hubfs/Haskell-User-Survey-Results.pdf) and also in this [other independent user survey](http://taylor.fausak.me/2017/11/15/2017-state-of-haskell-survey-results/#question-23). Just for the sake of the argument, what evidence can you provide to back your claim?
Mate, that proof is farkin solid ey. Can't argue with it m8. It's just crushing. 
Strongly disagree with this. There are companies not associated with universities or government that are using Haskell in anger in production. In Sydney alone there are at least 5 places I know of. Widening that to other places in Aus it could be at least a dozen places with significant Haskell teams. 
Great. In future please refrain from spreading FUD about Stack you can't even back up.
Yeah for sure m8 fark yeah, you really nailed it ey. Farkin devoted m8.
Thank you!
Yeah nah, pass us another stubbie m8.
Fair enough. At the very least, could you refrain from engaging in ad hominems against /u/bitemyapp and /u/mgsloan as you did in https://www.reddit.com/r/haskell/comments/8in4dr/bitemyappfpcourse_fork_of_the_original_data61/dyw0og0/ ?
Yeah nah, pass us a flamin fourex m8 ey geez Damo.
Thanks, it's interesting to hear from people working, rather than just playing, with a few languages.
\&gt; \([**pdf**](https://www.cl.cam.ac.uk/%7Ejdy22/papers/partially-static-data-as-free-extension-of-algebras.pdf)\) *Partially static data as free extension of algebras* \([short **pdf**](https://www.cl.cam.ac.uk/%7Ejdy22/papers/partially-static-data-as-free-extension-of-algebras.pdf)\) Both links above go to the short paper \(presented at PEPM 2018\). The draft of the full version, accepted to ICFP 2018, is \[here\]\([https://www.cl.cam.ac.uk/\~jdy22/papers/partially\-static\-data\-as\-free\-extension\-of\-algebras\-draft.pdf](https://www.cl.cam.ac.uk/~jdy22/papers/partially-static-data-as-free-extension-of-algebras-draft.pdf)\).
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://www.cl.cam.ac.uk/%7Ejdy22/papers/partially-static-data-as-free-extension-of-algebras.pdf) - Previous text "pdf" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
I give up. Just so you know: I've reported you to the mods.
Oooooh not reporting. Pass us me beer ya ciggie butt brain.
Super cool! In the "Design Philosophy" section you say that you did try a design with type classes and functional dependencies. Was the goal to statically encode things like "when you multiply two vectors you get a bivector"? Do I understand correctly that the `Cl3` type is an optimization over just having the constructor `APS` for when some coefficients are known to be zero? Die you write that multipication function in the `Num` instance by hand or did you generate it? I have two feature requests, if I may. Could you make `Cl3` parametric over the type of numbers (like `linear` does)? Could you provide interoperability with `linear`? For examle `toV3` could return a `Linear.V3` and `toH` could return a `Linear.Quaternion`. Similarly you would have `fromV3` and `fromQuaternion`? Overall, good job.
https://www.reddit.com/r/haskell/comments/8cp2zg/whats_the_status_on_dependent_types_in_ghc_as_of/
Yay, more AD! If only there was *beautiful integration* too...
repeated sentence: &gt; ### Polymorphic performance woes &gt; &gt; While all of this virtual stuff worked, it didn't work particularly quickly. I noticed some significant regressions in performance in my RTS upon upgrading to the new version I noticed some significant regressions in performance in my RTS upon upgrading to the new version.
One trivial solution may be to pack a nix installer + the derivation of your program, something like that: https://gist.github.com/guibou/651b46f2cdf69cab69bcec8887215dc9 It works for your project, however OpenGL is a difficult beast. It will work out of the box on NixOS, but you need an OpenGL wrapper, detailed in the gist.
Fixed, thanks and sorry for my mistake
Changelog: https://hackage.haskell.org/package/haxl-2.0.0.0/changelog Looks like mostly refinement of the previous api. Still exciting, love this package
Yeah the attempt with Multi-parameter Type Classes and Functional Dependencies was was to statically encode the that in the type system. It caused the library to move away from the prelude Num and Floating instances that I wanted to use. I believe that all of the constructors in Cl3 are statically encoded but only when the Case of Known Constructor optimization fires. You understand correctly Cl3 has ADT constructors that specialize APS for the zeroed coefficients. This allows an R * R to be one multiply rather than 64 plus a bunch of adds for APS * APS. I probably could provide some interoperability with linear and hmatrix. I'm not sure if there would be a name clash with Cl3's V3 constructor and Linear's V3, I'll have to look into that. Thanks for the comment.
If I understand correctly, previous api was able to traverse tree only in BFS mode and one level needs to fully evaluated before next. Looks like that solution to this question was employed https://youtu.be/sT6VJkkhy0o?t=28m28s
Arbor Networks in Sydney are using Haskell. We're not currently hiring, though :-( 
Take a look at the functions in the [`Data.Maybe`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Maybe.html) module, such as `catMaybes`.
Big thanks, solved it by mapping catMaybes over the vectors that build the Soduku, thanks.
Ok, are there any good tutorials or libraries you can point to as examples of using the CPP for gating optional dependencies? I've only really seen the CPP used for providing different GHC version support and haven't really used the CPP before.
I reviewed Chris Doran code and it appears to be more philosophically aligned with Sophie Taylor's "clifford" or Matti Eskelinen's "clif" libraries.
Hoogle is a handy tool for finding functions like this: https://www.haskell.org/hoogle/?hoogle=%5BMaybe+a%5D+-%3E+%5Ba%5D
tonixxx is agnostic regarding ABI’s, libc’s, OS’s, and so on. In short, you provision the Vagrant boxes of your choice and tonixxx loops over them, collecting the artifacts back into a coherent host directory tree.
Anothet useful function link this is `mapMaybe :: (a -&gt; Maybe b) -&gt; [a] -&gt; [b]`, also in `Data.Maybe`.
Most of the "Where to go next?" links seem to lead nowhere?
Indeed, that is a sound approach. It was more a question about how to use lenses in a principled way than an attempt to justify using them though :)
Yeah I probably need to sit down and think about this _a lot_. Man, designing proper interfaces are so hard. Thanks for your response!
Yes exactly. The big difference is the addition of BackgroundFetch, which enables data\-fetching to be arbitrarily overlapped with computation and other data\-fetching. In Haxl 1, computation was strictly interleaved with data\-fetching in rounds, but this restriction is removed in Haxl 2 if you use BackgroundFetch. To make this work, we had to completely rewrite the scheduler internals.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/negativewithgold] ["Mate, that proof is farkin solid ey. Can't argue with it m8. It's just crushing. Vast majority just smashes it..." \[-15\]](https://www.reddit.com/r/NegativeWithGold/comments/8ke76z/mate_that_proof_is_farkin_solid_ey_cant_argue/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'll get this fixed soon, but if you read it on github the links work: [https://github.com/facebook/Haxl/blob/master/readme.md](https://github.com/facebook/Haxl/blob/master/readme.md)
I am following along and get... $ cabal build Preprocessing library for greeter-0.1.0.0.. Building library for greeter-0.1.0.0.. [1 of 1] Compiling Greeter ( src/Greeter.hs, dist/build/Greeter.o ) src/Greeter.hs:5:13: error: • Variable not in scope: (&lt;&gt;) :: [Char] -&gt; String -&gt; t0 • Perhaps you meant one of these: ‘&lt;$&gt;’ (imported from Prelude), ‘*&gt;’ (imported from Prelude), ‘&lt;$’ (imported from Prelude) | 5 | "Hello, " &lt;&gt; who &lt;&gt; "!" | ^^ src/Greeter.hs:5:20: error: • Variable not in scope: (&lt;&gt;) :: t0 -&gt; [Char] -&gt; String • Perhaps you meant one of these: ‘&lt;$&gt;’ (imported from Prelude), ‘*&gt;’ (imported from Prelude), ‘&lt;$’ (imported from Prelude) | 5 | "Hello, " &lt;&gt; who &lt;&gt; "!" | ^^ I am using nixos and installed with `nix-env -i ghc cabal-install`. ghc is 8.2.2, cabal-install is 2.0.0.1. Any tips? 
Thank you! I think the The N\+1 Selects Problem might still be linking to the wrong document.
 License changed from BSD+PATENTS to plain BSD3. Glad to see this finally come about!
Not necessarily "beautiful" yet, but see this old preprint: http://gbaz.github.io/slides/ode-draft-2009.pdf
My initial impression of Reflex was similar to yours, but now that I've gotten familiar with it I find Reflex to be the best of the FRP tools I've tried so far \(plus, as a bonus, you get to build your Reflex app as mobile apps as well\). Some starting points: * [http://docs.reflex\-frp.org/en/latest/](http://docs.reflex-frp.org/en/latest/) * [https://qfpl.io/projects/reflex/](https://qfpl.io/projects/reflex/) And when are you ready to do Reflex projects: * [https://github.com/ElvishJerricco/reflex\-project\-skeleton](https://github.com/ElvishJerricco/reflex-project-skeleton) * [ghcid](https://github.com/ElvishJerricco/reflex-project-skeleton/issues/14) \+ [vscode](https://github.com/ndmitchell/ghcid/tree/master/plugins/vscode) as IDE environment I agree that the documentation for Reflex and its ecosystem is not all that great right now, but I'm expecting that all to change. Also look out for this [upcoming talk by Ryan](https://confengine.com/yow-lambda-jam-2018/proposal/5871/full-stack-haskell-from-prototype-to-production).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ndmitchell/ghcid/.../**vscode** (master → 4347852)](https://github.com/ndmitchell/ghcid/tree/434785227d425d77dd60f8dc92f993a4fee5147d/plugins/vscode) ---- 
&gt; I realized what I really wanted was the capability for `ecstasy` to be aware of components without necessarily being the owner of them. This is what I call empathy.
Just recently this was discussed on the libraries mailing lists and there's a PR that is going to be in base in GHC 8.6 https://github.com/ghc/ghc/pull/123
Over 10 years ago I was introduced to Haskell at university. It made a good impression on me and I found it an interesting language however as it was almost non-existent outside academia I didn't payed any attention to it after I finished the course. The course I got didn't went in depth so I didn't grasped some important concepts as well. I thought you had to do everything by recursion, which isn't true, they didn't tell us much about list comprehension as well. A few years ago I was introduced to Python. I was intrigued by the concept you could program without writing almost a single for-loop. List comprehension, the concept I missed at my Haskell uni course, helped a lot with that. As my Python skills improved I ended up writing code you could write in Haskell as well, however as Haskell is statically typed Haskell would be a much better environment for writing all those code. So now I am really into Haskell, I solve Haskell challenges at Hackerrank and I read a lot about it on the internet. My background is math. 
Thanks! Will try that out!
You have no idea what you are talking about. Bitcoin is actually orders of magnitude more energy efficient than our existing monetary systems. Bitcoin energy consumption is not linear. In fact we have all the mining power we need already and it will actually decrease as mining rewards are reduced. What you're not taking into account is the fact that dollars have to be stored in vaults which use electricty, moved by trucks which produce green house gases, burn fuel, we have datacenters full of banking servers, banks on every street corner all taking energy.. All of which take far more energy than Bitcoin.
The [witherable](https://hackage.haskell.org/package/witherable) package generalized this notion, similar to how `fmap` generalizes `map`.
It's roughly what I expected the algorithm to be, given that I'm aware of the 2d variant of the same algorithm for getting area from the list of line segments in a simple polygon. Still, it's cool to see that the same thing works in more dimensions. And it really is a fantastically elegant algorithm. 
No. People who come from python, node, (maybe even) java etc. are used to a single tool that manages dependencies. Pip and Npm are pretty sweet and I don't see why stack, cabal and nix need to be as painful as the are in comparison. I don't want to have to learn another language/config language, or two or even three to build a program. Nix is a set in the right direction but boy is it a pain to learn. Probably some of what I just said is wrong but hopefully this criticism is constructive.
[Cabal new-build is a package manager](http://blog.ezyang.com/2016/08/cabal-new-build-is-a-package-manager/)
Almost stopped reading when the author complained that it's &gt; stack --help instead of &gt; stack help I mean... The `--` for long flags on Unix operating systems is expected behavior, and really should not be surprising to a developer of all people. Also, these kinds of syntactic complaints are really superficial. Finally the author complains about `stack init`. For reference, here is what `stack init --help` says. ``` travis$ stack init --help Usage: stack init [DIR] [--solver] [--omit-packages] [--force] [--ignore-subdirs] [--help] Create stack project config from cabal or hpack package specifications Available options: DIR Directories to include, default is current directory. --solver Use a dependency solver to determine extra dependencies --omit-packages Exclude conflicting or incompatible user packages --force Force overwriting an existing stack.yaml --ignore-subdirs Do not search for .cabal files in sub directories --help Show this help text Run 'stack --help' for global options that apply to all subcommands. ``` This is apparently a brick wall in terms of figuring out what it does. Well, I guess we should take a page from `npm`. `npm init --help` gives ``` travis$ npm init --help npm init [--force|-f|--yes|-y] ``` I'm not an HCI expert by any means, but at least the stack help gives me two terms that I can google 'cabal' and 'hpack'. If I google 'haskell cabal package specification', I get to the [cabal manual](https://www.haskell.org/cabal/users-guide/developing-packages.html), which explains in detail how to write a cabal file for a project with dependencies, and where to go next. In contrast, I have no idea what to do with npm. At some point we need to stop blaming the tools. The author is clearly more familiar with other ecosystems -- that is fine. However, I am unsure where this attitude comes from that learning a new ecosystem should require zero effort.
What language *doesnt* require you to learn its config language to use its package manager? Stack and cabal new-build each do a pretty good job of being "a single tool that manages dependencies", with the exception that stack requires the extra stack.yaml unless you use hpack, and cabal requires you to install GHC yourself.
I was quite happy with lisp, but wanted to learn something different. I'd taken a short course in Standard ML some years earlier, had recently read [Why calculating is better than scheming](https://www.cs.kent.ac.uk/people/staff/dat/miranda/wadler87.pdf), and came upon [Conrad Barski's Haskell tutorial](http://lisperati.com/haskell/). None of these things sold me completely on Haskell (and I think the tutorial basically concluded that Haskell was impractical), but I figured a closer look at this ML-like thing was warranted. I think the next step from there was [Real World Haskell](http://book.realworldhaskell.org/), which was absolutely fantastic.
Been writing Haskell for over 2 years now and I had an unpleasant time trying to build hlint from source recently due to this exact thing. Very annoying :)
Well, and I feel odd looking to the JS community for inspiration but. JavaScript is so much easier to use than Haskell (in terms of tooling). Node is so much easier that it's almost not a comparison.
i agree that all communities should strive for ease of use, but it’s worth mentioning that webpack—essential for building browser ready JS—is easily as hairy. i think it’s simply a difficult problem to solve! stack was a great step for usability and i hope it only gets easier :)
Are we on npm, yarn, parcel, bower, or some other tool this week? Do we use flat dependencies or nested? Are our dependencies, uh, actually constrainted to the versions they need or is it a YOLO grab bag of who knows?
The very idea of "uninstall" is bad. There is no uninstall because *you should not be interacting with your dependencies in a mutable, imperative way*. You should be specifying your dependencies and letting the build tool install them. Instead of `uninstall`, think `garbage-collect`. `nix` gets this right.
So the problem with other approaches is that they don't solve the problem ether? I agree. They're far from perfect. I guess my problem with stack, cabal and even nix is that I cannot express how to get started to a beginner in any way that doesn't set them up to fail. I think Stack and Nix actually are a really good place to start. Haskell with some exceptions lets me express everything I need to about what I want my program to do and allows me a lot more certainty that other systems while still being usable. That said, the students I studied with and the coworkers I work with don't feel the same. They're using JS, C++ and java because they have sufficient tooling and are well known. Maybe we just need more polish and incremental improvements to this ecosystem, in which case I would love to be pointed in the right direction. I want to help. I'm pretty new to FP, haskell and programming so I may be seeing this from a strange perspective. Would love some help.
&gt;I cannot express how to get started to a beginner in any way that doesn't set them up to fail. $ stack new myproject simple
It is very good that stack is not replacing cabal as a package format. Nobody needs a compatibility war. It is possible to use it in a subdirectory without creating a project - run `stack ghc ...` I'm not sure about uninstall, but I do miss sometimes some package management features from stack. For example, I would like to have an options to see which resolvers I have cached.
N.B.: The submitter probably isn't the author of the post. It doesn't seem likely that the author would have misquoted the title of their own post.
I'm not comfortable with saying that that's all you need to get started. Getting sorted out choosing libraries, managing the dependencies, and in general writing something useful (not just for mathematics) takes a long time. I think it would help to have some setup step or site that can recommend libraries that let you doing parsing, possibly some data structures like maps, arrays, graphs and preferably some argument parsing, file IO and maybe even a webserver without thinking too hard about it all. Preferably with documentation and tutorials which seem thin on the ground. You're also kind right, at the moment your tip is the first step and everything after that is up to the developer. Maybe the reason I'm finding it hard to get started, and to help others get started, is that I'm so used to my imperative approach to programming and even dependency management that I can't see the simple way forward.
&gt;For example, I would like to have an options to see which resolvers I have cached. Stack 1.7 added \`stack ls snapshots\`.
[haskelliseasy.com](https://haskelliseasy.readthedocs.io/en/latest/) is a curated list of libraries and guides. [haskell-lang.org](https://haskell-lang.org/) is a great resource, with a [list of libraries](https://haskell-lang.org/libraries) and a [set of documentation](https://haskell-lang.org/documentation). If you have requests for documentation, I'm running a [documentation rewards thing](https://twitter.com/mattoflambda/status/997589748427341824) -- tweet a request at me and I'll make sure it's seen :) If you're having issues getting started, come hang out in [the FPChat Slack](https://fpchat-invite.herokuapp.com/). We've got a lively #haskell, #haskell-beginners, and #haskellbook channel that are constantly helping folks out.
Wow. Thank you so much.
It's because of the surge in oxytocin. 😻😻🌈
Note that you can go from `X` to `Maybe X` by using the `Just` constructor: Just :: a -&gt; Maybe a Just :: Sudoku -&gt; Maybe Sudoku
the patent system [or the use of it] destroys not a particular enterprise, but generally the efficiency of the economy people and companies can work together, patents can be licensed
The URL has only _stack_ in it, but the title in the page says _Why I am not a fan of Cabal or Stack_. And here it only says _not a fan of Cabal_, which is the library and not _cabal-install_ the executable. Very odd indeed. Let's stay alert in case someone is trying to initiate drama/trolling. No need for Haskell to be on HN with a ranting marathon.
Well mutable installation is necessary for getting tools installed on your path for general use outside a project setting. An actual installation / uninstallation thing for exes would be nice
The blog post is the first impressions of someone used to other tools, thinking out loudly. The author writes they want to avoid cabal and _Don't make me understand the crappy tool you replace in order to use your new, better one!_. It reads like a very emotional, frustrated response and is unfortunately based in misinformation or lack of information about Haskell, GHC, Stack, Cabal. I wonder that the author would write if it was known that Stack uses Cabal (not cabal-install). The author also dislikes Stacks but there's no example of how other language tools do this better or in a way better suited to the author's usage patterns. But let's keep in mind that the author begins with _This is a rant, hastily written, mostly to blow off steam. Don't take this too seriously_. This seems easy to miss. &gt; running cabal update caused any subsequent cabal list to crash I haven't seen this and it sounds like a bug. If the interaction with error message would be visible at least someone else could file a ticket. &gt; Projects are an unnecessary barrier to entry This is something you will find discussed to no end in Java/Scala and Erlang posts. There is a good reason for conventionally structured projects and it is possible to forgo them for non-projects, which is oddly unmentioned. &gt; Having install without uninstall is still unforgivable. garbage collection is needed and has been in the design phase for cabal-install for a long time. I suppose stack has the same plans. #### Conclusion: All in all, this is a first impression, lacking complete understanding, which can or cannot mean that the tools or tutorials aren't sufficient. It's good the first impression is documented, though one can hope it will be edited/update under the same url once the author has gained a better understanding.
What was the solution? I too am running into this on Firefox :O
For the codensity-part I recommend "the free and the furious (and by furious I mean codensity)"-talk by raichoo available on YouTube in 2 or more different versions. I found it really accessible.
imo it needs way more lenses ;) I would like to link one of my students projects where he implemented a quadtree with lens-accessors, but that is still private. I asked him to switch it to public (it was initially private for grading reasons) and maybe it will be available in the next few days. Github: https://github.com/LeoB97/WoE 
I found "send binary data" for websockets \[Link to Hackage\]\([http://hackage.haskell.org/package/websockets\-0.12.4.1/docs/Network\-WebSockets\-Connection.html#v:sendBinaryData](http://hackage.haskell.org/package/websockets-0.12.4.1/docs/Network-WebSockets-Connection.html#v:sendBinaryData)\) And an \[old blog post\]\([https://ocharles.org.uk/blog/posts/2014\-07\-13\-announcing\-socket\-io\-for\-haskell.html](https://ocharles.org.uk/blog/posts/2014-07-13-announcing-socket-io-for-haskell.html)\) but this seems outdated.
That's likely true. I still don't have it clear about the many different lenses and record implementation. Do you have any specific suggestion? Bookmarked the github page, will check it out when it gets public. 
I think the easiest might be sending the images as base64 over the socket. 1. Read the file as ByteString 2. Base64 encode it ([maybe using this](https://hackage.haskell.org/package/base64-bytestring-1.0.0.1/docs/Data-ByteString-Base64.html) 3. Send the base64 as Text over the wire 4. Embed it directly as shown [here] (https://stackoverflow.com/questions/8499633/how-to-display-base64-images-in-html) 
Great! Thank you for the pointers!
As hex grids are isomorphic to rectangular grids for addressing each cell I would use a newtype around `Array ((x,y),(x+w,y+h)) Cell`. Then write a plated-instance to get access to a lot of lens for free (I think ix, at, etc.). Then you can I.e. write a traversal for around :: int -&gt; pos -&gt; Traversal Grid Cell which gives you read/write access to neighbouring cells via isomorphism (so without double data and forgotten updates). To find out if a piece would be valid then reduces to a fit of cell x to the 6 given cells of the traversal without any array-index-operation (that I personally would always mess up). Adding/Changing to more complicated game-rules would then reduce to an fmap over that traversed list before validating. 
1. Send image as Uint8Array 2. Create a Blob from it 3. URL.createObjectURL
Thanks, great!
The patent system is not important for this point. Let me put it another way. It is your ideal entrepreneur whose unethical actions you justify by their noble end. You are assuming that your justification is correct, but it is based on a theory that may or may not hold. You say that your ideal entrepreneur is justified to sacrifice someone else's work and livelihood for the sake of a belief. But then, sufficient faith would justify any sacrifice at all. For instance, I may hold a belief that a sacrifice of a young lady in spring brings plentiful harvest. Am I justified to murder a girl?
I haven't used haxl before but got cutious about the implementation. The code is impressively readable! Anyway, I noticed that a comment in runHaxl says -- Here we have a choice: -- - If the requestStore is non-empty, we could submit those -- requests right away without waiting for more. This might -- be good for latency, especially if the data source doesn't -- support batching, or if batching is pessimal. -- - To optimise the batch sizes, we want to execute as much as -- we can and only submit requests when we have no more -- computation to do. -- - compromise: wait at least Nms for an outstanding result -- before giving up and submitting new requests. -- -- For now we use the batching strategy in the scheduler, but -- individual data sources can request that their requests are -- sent eagerly by using schedulerHint. -- But then there is data SchedulerHint = TryToBatch | SubmitImmediately Is there a reason why there isn't a `WaitFor` option in SchedulerHint?
&gt; Are there any extensible effect design that lean toward final tagless? Yes, MTL.
Wow, thank you, I'll look into that. 
Most people in need do not even live in the US. I doubt they get a smallest bite. What you are saying is that there is only one way to sustain yourself as an independent programmer — by making money selling closed source software and related services. In all regards, you hold it unquestionable that market theory is correct, and you are justifying your lifestyle by various assumptions, such as that it is not good for the world if the project of yours gets copied. And then it is me who has a naive and idealistic view of the world. I understand that GPL does not fit your economic theory or overall world view. The whole point is that we live in a new era. A new means of production have been invented: the Internet and other information technologies. Something has to change in the commonly accepted world view as well. This is how GPL happens to be there. I am not holding the view that GPL is universally and unquestionably good. It is obvious that the debate is open. It is also obvious that the debate is open concerning free market and information property.
"Final tagless" mean Church-encoding with class instance arguments. This is sometimes a good idea because GHC inlines instance arguments much more aggressively than function arguments. Church encoding makes sense in general if your operations can be efficiently implemented by folding (structural recursion) on syntax. In contrast, `freer` critically relies on there being an actual first-order sequence data structure with efficient appending, and the main benefit is the speedup on of non-folding operations (e.g. `local` for `Reader`). Church encoding would not buy anything in this setting. 
That was a fantastic talk! Thanks for the recommendation :) I definitely gained some intuition
The package database *is* mutable and imperative... if you can install x and then in a separate invocation install y, then you can just as well uninstall y and then uninstall x. Rhetoric about uninstall not making sense and "cabal is not a package manager" is apology for creating an inconsistent interface in the first place and users are punished for having logical expectations. If you have no uninstall you should also have no install.
Before `uninstall` or `garbage-collect` I think what I usually missed is a safe `re-install` or `update`. `cabal install shake` ... `cabal update` or `cabal update shake`. Well, `upgrade` since `update` is for the index.
If you can install x and then in a separate invocation install y, then you can just as well uninstall y and then uninstall x (if developers could be bothered putting that in the tool, as is the case in ghc-pkg). Rhetoric about uninstall not making sense and "cabal is not a package manager" is apology for creating an inconsistent interface in the first place and users are punished for having logical expectations. If you have no uninstall you should also have no install. The implementation obstacle is mainly that the Custom build process lets packages install whatever files they want anywhere and does not inform Cabal of what it's doing, so we can't reliably remove installed files. That's an architectural problem - that you can install something but you don't know what was installed. Nobody thought of handling it. Cabal and Stack both side step this issue by declaring "we don't support that", but I wish you guys would stop trying to discredit a legitimate use case just because our tools don't handle it. It's dogmatic. gem and pip and npm do it.
You can use definitely use a binary message and then use it as `blob:` URL if you want to avoid the base64-encoding. Server: module Main where import qualified Data.ByteString.Lazy as BL import qualified Network.WebSockets as WS main :: IO () main = WS.runServer "127.0.0.1" 8080 $ \pending -&gt; do conn &lt;- WS.acceptRequest pending img &lt;- BL.readFile "img.jpg" WS.sendBinaryData conn img Client: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;body&gt; &lt;script type="text/JavaScript"&gt; var ws = new WebSocket('ws://localhost:8080/'); ws.onmessage = function(event) { var img = document.createElement('img'); var urlObject = URL.createObjectURL(event.data); img.src = urlObject; document.body.appendChild(img); } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 
Elm was what brought me to Haskell. The immutability of data and a solid rigid type system without all the object\-oriented cruft are what really spoke to me. 
I believe [compactable](https://hackage.haskell.org/package/compactable-0.1.2.0/docs/Control-Compactable.html) is more general than witherable
I feel there is enough non-linearity to make even that tricky (though that might have a fair amount to do with specific flaws in the LambdaConf ladder). For instance, I wouldn't necessarily expect a connection, or even a strong correlation, between proficiency in "Advanced Functors (Exponential, Profunctor, Contravariant)", labelled as "Proficient", and "High-Performance", labelled as "Expert". (On a related note, Lennart Augustsson once remarked, about a similar-in-spirit attempt to specify Haskell competence levels, "I might get to intermediate level in a few years then. Good to know".)
Witherable is more popular and imo fits a better point in the design space. I actually can't think of anything that could be an instance of campactable but not filterable (the class I was referring to from the witherable package). Typically the reason things can't be functors is because they can't operate well enough on uncons trained type variables, like Set, but those are also going to struggle to compact unconstrained Maybe's.
A printer is `Divisible`, so I guess this `Monoidal` is a generalization of both `Applicative` and `Divisible`.
I agree with /u/kindaro on [binning versus ordering](https://www.reddit.com/r/haskell/comments/8jqiol/idea_community_haskell_proficiency_levels/dz4drid/). One problem with a standardised ordering is that it might induce segregation -- even if it is self-segregation. At the risk of pointing out the obvious, I feel it is also worth mentioning it is very often possible to make a good guess on the appropriate depth for a response by attentively reading the original post. Part of the solution for the problem, then, should involve encouraging people to do just that, and to exercising some care in tailoring their responses to the audience.
Typed holes are great, but they lose a lot of information. In 8.6, we'll have *vastly* improved typed holes, and I'll switch back to them. But in 8.4 and before, a type mismatch assertion gives much better results.
There’s something immensely pleasant about the word `Monadoidal`.
Parallel composition of lawful lenses in the manner you suggest does not always produce a lawful lens. In particular, if the lens targets "overlap", you'll run into trouble.
Hi! Noob question: I'd like to use [`finally`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Control-Exception-Base.html#v:finally), signature `IO a -&gt; IO b -&gt; IO a`. However, the operations I wanna use are based on a different monad than `IO` (namely [`Servant`](https://hackage.haskell.org/package/servant)'s [`ClientM`](http://hackage.haskell.org/package/servant-client-0.13.0.1/docs/Servant-Client.html#t:ClientM)). I knew [`liftIO`](http://hackage.haskell.org/package/base-4.11.0.0/docs/Control-Monad-IO-Class.html#v:liftIO), but that seems to do the opposite -- `IO a -&gt; m a `. How can I transform my monads into IOs, or lift `finally` such as to operate on my monads instead?
You also get free IDE integration ([VS Code only](https://github.com/ndmitchell/ghcid/tree/master/plugins/vscode#vscode-haskell-ghcid) at the moment) in conjunction with ghcid's `-o` flag which I use everyday.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ndmitchell/ghcid/.../**vscode#vscode-haskell-ghcid** (master → 4347852)](https://github.com/ndmitchell/ghcid/tree/434785227d425d77dd60f8dc92f993a4fee5147d/plugins/vscode#vscode-haskell-ghcid) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dz97so8.)
With `intero` you don't need to wait to save the file before you get errors popping up. It's quite a different (and superior) experience than `ghcid` is going to provide. 
i think instead of &lt;&gt; it should be ++ "hello " ++ who ++ "!"
There's a neovim integration too! Though I don't really use it that much.
Project, or file? Seems to me to work fine as long as the modules are kept small.
The risk is that () is an instance of lots of things. =) You might get slightly more robust reporting out of making a `data Hole = Hole` with no instances.
Intero collects additional metadata in order to do type of subexpressions and go-to-definition etc that reduce performance. I do mean project -- 10,000 lines of code in a single package will cause intero's performance to suffer such that it's annoying, and 20-30k make it unusable for me. Aggressively splitting into different packages helps, but then you just have to juggle your targets, which is another annoyance.
Do you know if it is possible to implement operator for liftMon2, similar to \&lt;$\&gt; and \&lt;\*\&gt; operators for applicative?
one thing I really enjoyed about `guard` in Ruby-land was that you could hook it up to `libnotify` or `growl` and get a little notification on a failed test run. With that I'd keep `guard` running off my main screen entirely and just have my editor up, occasionally getting a green check on success and a red mark on a failure. I wonder how tricky it'd be to get that hacked into ghcid...
Popup notifications would reclaim some screen real-estate at least.
Well, the `&lt;.&gt;` operator in the post is the analogue of `&lt;*&gt;`. `&lt;$&gt;` is out because they're not necessarily `Functor`s.
I use both `intero` and `ghcid` and find that they complement each other well. - `intero`: for visualizing problem areas and helping with autocomplete. - `ghcid`: for very fast type checking and full text display of type errors
I think the easiest way to do it would probably be to add a flag to ghcid to additionally write out "(green check mark)" or "(red x)" to libnotify using something like notify-send. That way you can hide the terminal and if a pop-up shows failure, you can pull the terminal back up. This would combine *quite* well with a quake-style terminal you run ghcid in :) (I do something very similar using inotify to automatically compile pandoc latex documents; I just don't have any notifications yet because I've never needed that. The PDF is a pretty solid indicator of success...)
Or, you know, tags.
BTW I'm using GHC 8.2.2.
I see quicksort and Fibonacci implementation in Haskell with awe. I feel that the language is very different from what I usually use (Java, JS, PHP). Java is very verbose (it was Java 7), JS — dynamic programming language— has bitten me hard when the project gets big. Haskell seems the best of the both worlds: terse &amp; static. ... and people says Haskell is hard. Then I was like “challenge accepted” 
Why not use plain emacs-mode? It works nicely with flycheck enabled.
Depending on your OS there are normally tool to generate notification from the command line. By greping the output of ghcid you should be able to generate them. Also some terminal emulator as well as tmux (I think) allows you to listen to a particular regex (it is called I believe monitoring) 
&gt; With intero you don't need to wait to save the file before you get errors popping up But you do need to wait for intero which can be slow on big project. Often, it also quicks in before you finished typing sensible which mean you have to wait twice. Having said that I use both, intero for the type checking band ghcid for instant reloading and testing. What I like with intero is the type at point in the status bar.
Great job! Thank you for contributing to the Haskell eco system so much. Have you used this project template to share data types between server and client? I know that has been an issue using `Persistent` before.
You need `FlexibleInstances` because your instance heads don't have a type constructor, and `UndecidableInstances` because each of the instances has a constraint that is the same size as its head (it doesn't get "smaller"). The complaint about `Applicative` overlapping (and probably for the other classes) is due to how instance resolution works. GHC sees the expression `toList f &lt;*&gt; toList x`, and realizes that this requires an applicative instance for `[]`. Instance resolution works by looking at every instance head that matches, and trying to solve them. In this case, it finds both of the following instances: * `instance Applicative []` * `Instance ListLike f =&gt; Applicative f` These are overlapping, and both match an `Applicative []` constraint, because GHC doesn't look at instance constraints when resolving instances. You can get around this by adding an `{-# OVERLAPPABLE #-}` pragma to your `Applicative f` instance declaration: instance {-# OVERLAPPABLE #-} ListLike f =&gt; Applicative f where f &lt;*&gt; x = fromList (toList f &lt;*&gt; toList x) which tells GHC to ignore this instance if it overlaps with another one.
I think it is important to say that when you write something like: instance ListLike f =&gt; Functor f you are not only saying that every `ListLike` is a functor, but also that the ONLY way something can be a functor is by being `ListLike`, since GHC matches instances from the right side of `=&gt;` and after checks for the left one. That is why, as /u/isovector commented, you need an `{-# OVERLAPPABLE #-}` pragma, in order to have more than one possible instance. However, this should be only done when you have very good reasons to do so. Normally, when you want to say that every `ListLike` has these classes, the best is the following: class (Functor f, Foldable f, Traversable f) =&gt; ListLike f
At the end of `Run.hs` there's: {- TODO: later data SchedPolicy = SubmitImmediately | WaitAtLeast Int{-ms-} | WaitForAllPendingRequests -}
I do `stack build --fast --ghc-options="-j +RTS -A32M -RTS"`, looks good enough on a relatively big codebase. Plus side comparing to ghcid: runs from within emacs (upon `haskell-compile`), so file locations are highlighted, no need to re-type the filename and line number, just `M-n/p` between all errors.
Thanks, turns out I shouldn't read code on my phone.
Yes that's the right way to fix it. Note that it is commented out. It seems to be a remnant of [a previous version of this file](http://okmij.org/ftp/Haskell/extensible/Eff.hs), where `send` had a different type `send :: (forall w. (a -&gt; VE w r) -&gt; Union r (VE w r)) -&gt; Eff r a`. 
The only think you have done wrong is omitting the code that you have, and explaining clearly where your expectations aren't matching reality.
On mobile so not a full solution, but hopefully this link will help: http://hackage.haskell.org/package/containers-0.5.11.0/docs/Data-Map-Lazy.html#v:foldrWithKey This should allow you to build up some kind of representation of your results with a recursive function that handles each item in the trie's map. Then you could recursively fold over the tries inner maps.
I'd been seeing articles about Haskell on tech forums and even watched SPJs popular talk. But Bartosz provided the final bit of motivation needed . He showed the link between Haskell and C++ template metaprogramming. Being a C++ templates fan-boy this was the last bit of motivation I needed. I'd consider myself an advanced beginner as I'm yet to write any code. I've been mediatively studying LYAH for about 2 years now and I'm in the penultimate chapter. I've read lots about Haskell and watched pretty much every talk out there that's at my level and I'm very excited about the depth and breath of the new ideas that Haskell exposes one to and can't wait to know more. Before anyone advises me to start writing Haskell code let me quickly add that I do plan to write some Haskell but just not right now. I have another gigantic side time-sink of a project that predates my foray into Haskell. Good thing tho is that I plan to develop parts of the backend of this project in Haskell.
To define [MonoTraversable](http://hackage.haskell.org/package/mono-traversable-1.0.8.1/docs/Data-MonoTraversable.html#t:MonoTraversable) over a Trie (you can't use Traversable directly because the element type is monomorphic, and isn't even directly present in your data structure!), you already need to have some way to get a list of words in the trie in some defined order, or bake that into your definition of MonoTraversable. Since you just need to get the words stored in the Trie, I'd personally just choose to do that directly, and abstract to MonoFoldable/MonoTraversable later if it turned out I needed other features of those.
Currently studying it. I'm on the penultimate chapter. It's not perfect. No resource is. In retrospect it's a bit longer than it probably needs to be (Graham Hutton's book OTOH breezes through some concepts too quickly for my taste). Also LYAH famously has no exercises and ocassionally indulges in handwaving when a simple explanation exists. I remember being stuck at concepts such as functions as applicatives and joining monads for months. (I did not give up till I understood them; and when I did I realised that they were quite simple.) I reckon these knotty bits doubled the length of time it's taken me to get through the book which I hope to soon. After that it's RWH, unless the print edition of Haskellbook becomes available before then. Nevertheless at its core it's a decent book. Within it's core is a much better book waiting to come out. 
&gt; Project, or file? Project, I believe. I've never managed to get the alleged wonders of `intero`to work for me except for in small toy programs. And I've tried several times after reading about the wonders of it, thinking maybe it got fixed, but it always just did not work. Make the laptop's fans noisy but basically give me nothing.. And on a relatively high end new computer..
[Yes.](https://stackoverflow.com/questions/23727768/which-parts-of-real-world-haskell-are-now-obsolete-or-considered-bad-practice) Also, the online edition has reader comments under most paragraphs.
As far as I can tell without an interpreter, it should correctly break up the input into chunks. Next step is to wrap `['1'..'9']` into `Just` and return `Nothing` instead of `0`. To parse multiple sudoku, you could try to break the input into lines and feed nine of them into the parser at a time.
Thanks a lot for your blog post! We use this approach for writing bidirectional TOML parsing: * https://github.com/kowainik/tomland
Thanks a lot for your blog post! We use this approach for writing bidirectional TOML parsing: * https://github.com/kowainik/tomland
I made a function that I does this, problem is that I cant seem to get the parser to send the right info to it: readLine1 :: String -&gt; [Maybe Int] readLine1 line | line == [] = [] | head line == '0' = [Nothing] ++ readLine1 (drop 1 line) | otherwise = [Just (digitToInt(head line))] ++ readLine1 (drop 1 line)
You absolutely didn't ask for it but here are some other resources that I also found to be very helpful: [Learn You A Haskell](http://learnyouahaskell.com/) - IMO lighter than Real World Haskell, I read this before reading RWH. [Functors, Applicatives, and Monads in pictures](http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html) - Still the best guide I've seen on the concepts. Laid out very well 
I am sorry if this coming off as a stupid question, but why encode it as base64?
Ah I've never even heard of that book, looks like another excellent introductory text (all the way up to working with Aeson which is pretty real-world). I also bought a hard-copy of LYAH because I like it so much, I definitely know how you feel.
Since type String = [Char] what you want might be something as simple as readFile :: FilePath -&gt; IO String where `FilePath` is also just a type synonym for `String`. Then you can use lines :: String -&gt; [String] to get a list of these lines, and use bog standard list functions like `takeWhile`, or things like `take` and `splitAt`, since apparently it's always nine numbers. Does that help? If you're feeling brave, the `text` package and things like [splitOn](https://hackage.haskell.org/package/text-1.2.3.0/docs/Data-Text.html#v:splitOn) might be a little more convenient.
Hmmm, I have the same exact problem 
That was mainly because I knew it was possible to embed an image as base64 directly
Intero is good when it works, but ghcid always works. I.e. "functioning interpreter from an arbitrary command" versus "stack project". 
You can think about the problem recursively, which can get you a decent solution. For instance, think about what cases you need to handle: words (Trie False _) words (Trie True _) Ignoring the children for now, those two cases should have the following outputs: words(Trie False _) = [] words(Trie True _) = [[]] Now, to make the recursive call, we can convert the map to a list: words (Trie end xs) = if end then [] : rest else rest where rest = [ zs | (y,ys) &lt;- Map.toList xs , zs &lt;- map (y:) (words ys) ] Unfortunately, this solution is pretty inefficient, since the calls to `map` traverse the intermediate list unnecessarily. You can avoid the extra pass by implementing `foldr` for the trie: foldrTrie f b (Trie e c) | e = f [] r | otherwise = r where r = Map.foldrWithKey (\x tr xs -&gt; foldrTrie (f . (:) x) xs tr) b c But that's a little harder to understand. Hope that helps!
\&gt; What you are saying is that there is only one way to sustain yourself as an independent programmer — by making money selling closed source software and related services. I mean remember I'm not actually selling software, I am running a website. I do think that the closed source approach is by far the most potent in making the project successful and allowing it to grow. \&gt; such as that it is not good for the world if the project of yours gets copied Honestly in the contexts of the project this is definitely true. Random clones would not help the world for sure.
&gt; did I use the substitution model correctly in order to understand the StackOnStack type synonym? Not quite; the definition `newtype MaybeT m a = MaybeT { runMaybeT :: m (Maybe a) }` doesn't mean that you can replace `MaybeT m a` with `MaybeT { runMaybeT :: m (Maybe a) }`, because the latter is not valid syntax for a type. As a simpler example, you can't expand the type `[Bool]` into the equivalent type `[True | False]`, because the latter is not valid syntax for a type. Type synonym definitions, on the other hand, do have a valid type on their right-hand side, so it is valid to expand `MaybeT MonadicStack` to `MaybeT (WriterT [String] IO)`. What I use instead in order to figure out what a given monad transformer stack does is to eliminate each of the layers by calling their eliminators: MaybeT (WriterT [String] IO) x runMaybeT :: MaybeT m a -&gt; m (Maybe a) WriterT [String] IO (Maybe a) runWriterT :: WriterT w m a -&gt; m (a, w) IO (Maybe a, [String]) So while your approach wasn't 100% valid, it did give the correct result and it doesn't seem error-prone, so if you like it better than my approach, why not?
I don't consider either of those good resources. LYAH has even more now-broken examples than RWH, and is an incoherent hodgepodge of information. Functors, Applicatives, and Monads in picture is a very inaccurate portrayal of the concepts. It's easy to grasp but the analogy only really works for container-esque monads like `Maybe` and and *possibly* lists; it breaks down for other monads like IO, parsers, or `Cont`. A box isn't really a good analogy if you don't have the ability to take stuff out of it.
If you want to dig into some deep rabbit hole, look into the Trees That Grow technique. It makes use of type families and pattern synonyms to create an extensible AST that a compiler can reuse in all stages from parsing until code generation. I'm currently using it to write an interpreter and a simple, non-optimizing compiler.
Just a bug/concern, in a trie, the end nodes aren't necessarily also leaves. So, if you stop recursing when you find an end you'll miss data.
Intero is just GHCi with some extra type info collection. The Stack project is a 36K line project and Intero handles it responsively. It was after all tested against Stack in development. ghcid reloads when you save the file - flycheck runs as you type, so it's a lot more checking. You can just change flycheck to run only on save. ghcid uses `-fno-code`, but IME it makes some files faster but the big Types.hs files are slow in any compilation mode - and that's where `-fobject-code` beats it. If you had problems with Intero for Emacs then I'd be surprised. Intero for NeoVim or Dante and things like that I can make no claims about.
&gt; Intero collects additional metadata in order to do type of subexpressions and go-to-definition etc that reduce performance It doesn't reduce performance that much. &gt; I do mean project -- 10,000 lines of code in a single package will cause intero's performance to suffer Intero on Stack's 36Kline codebase works fine. You can prove this by opening some `X.hs` module with one line in it and see that it gives immediate feedback. The only reason it would suffer is if you didn't use `-fobject-code` which only rebuilds modules that changed (and therefore only collects type information for each module). I did a quick grep of intero-neovim and didn't see that enabled by default. `-fno-code` like used in ghcid is fast for one file but falls over on big projects, esp. with a big module at the top of the dependency tree, because it reloads everything every time. 
Try enabling `-fobject-code`. [See my other comment](https://www.reddit.com/r/haskell/comments/8kn1x7/ghcid_for_the_win/dzat57z/).
How do they work? Would they really help me out in making the whole ordeal in a single go?
Those functions don't stop recursing when they hit an end: the recursive call (`rest` in `elements`, `r` in `foldrTrie`) is base in both cases. If you look at the trie of the strings `["ab", "a", "c"]`: trie = Trie False (Map.fromList [ ('a', Trie True (Map.fromList [('b', Trie True Map.empty)])) , ('c', Trie True Map.empty)]) Both functions give the desired output: &gt;&gt;&gt; elements trie ["a","ab","c"] &gt;&gt;&gt; foldrTrie (:) [] trie ["a","ab","c"]
Ahh. Sorry, miss read one of the "r"s. Thanks for the (quick) response
/u/gelisam thanks for taking the time to respond. I like your approach as well! I think I'll give it a shot and try to stick to it. 
**Attribute grammar** An attribute grammar is a formal way to define attributes for the productions of a formal grammar, associating these attributes with values. The evaluation occurs in the nodes of the abstract syntax tree, when the language is processed by some parser or compiler. The attributes are divided into two groups: synthesized attributes and inherited attributes. The synthesized attributes are the result of the attribute evaluation rules, and may also use the values of the inherited attributes. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
This might be all be obvious to you, but you might want to consider approaching this the other way around (as well). On the one hand, a library that exports some transformer will likely do so in a manner that the concrete transformer stays abstract, and provide an appropriate `run` function anyways. On the other hand, you absolutely do not want to write 2000 lines of code in some `WriterT w (ExceptT e m) a`, only to realize that you will only be able to get out `m (Either e (a, w))` out of it, and not `m (Either e a, w)` like you might have originally intended. So until you get more experience writing transformer code, I would strongly recommend to not postpone thinking about your `run` function too much. Of course, `mtl` allows you to keep your transformer stack abstract, but again, since you're starting out, I would recommend keeping things concrete in the beginning. Unless you have a solid grasp on "the theory", type errors can be very confusing. As a general rule of thumb, if you want a transformer stack corresponding to, say, `r -&gt; s -&gt; m (Maybe a, w, s)`: * `Reader/Writer/State` "commute", so either of permutation of those is fine. * Short-circuiting transformers like `MaybeT` should go at the top, to preserve as much information as possible. Unless you don't want that, of course. * Transformers you don't want to, or monads you can't unwrap, like `IO`, go at the bottom. * Know that, using `transformers`, you can just pattern match on the constructors. I find this easier to work my way "outside in" when writing the run function. You can still refactor to clever point-free style afterwards. * I would try to keep things like `MaybeT` and `EitherT` *local*. You don't want your whole application to live in `MaybeT`. For errors that you can't handle locally and that will result in a crash, it's perfectly fine to throw an exception, using `throwIO` for instance. * Opinionated: `ExceptT` over `IO` (or `IO (Either e a)`) is fine. You made a choice which errors to handle locally, an which not. * Opinionated: If for some reason you are forced to live in `IO` and you need mutable state, things like `IORef` or `TVar` or whatever are fine. `StateT` over `IO` does not magically make your function "better because it's more functional". * The various `map*` and `with*` functions are vastly under-appreciated.
Thanks for the explanation. In fact by adding \`{#\- LANGUAGE OverlappingInstances #\-}\` at the top of the file, all the errors went away. I now understand why. My approach may seem sloppy, but I'm not trying to write a library or a production piece of code here. I've been working with some sample code that demonstrates an algorithm, and I wanted to visualize the operation of the algorithm. Since the algorithm uses lists for everything, I needed some way to distinguish different types of lists that should render differently. Thus, I made new types that wrap lists. Unfortunately this means that the usual operations of Functor, Traversable, etc. no longer work on the newtype\-wrapped lists. Nor can I just use GeneralizedNewtypeDeriving, as this would not pass through the list operations. So, I wanted a succinct way to make each of those three newtypes derive the list behavior. At first I had defined instances of all those classes for all those types, but that seemed verbose. Then I remembered that you could define instances that worked for a whole bunch of datatypes at once, by using a constraint in the instance definition. Unfortunately that wasn't as plug\-and\-play as I thought. But with OverlappingInstances, I get what I want. I don't imagine these are going to be very efficient operations, unless perhaps the optimizer is smart enough to throw away the "fromList"/"toList" knowing they are just newtypes. But as I said, this is just for a toy example \- just need to get it to do what I want with as little code as possible.
When you declare `%monad MyMonad`, this tells happy that a production declared to have type `A`, really has type `MyMonad a`. For non-monadic actions, `happy` automatically inserts ` return`, so `{ e }` is equivalent to `{% return e }`. The idea is that a computation of type `MyMonad a` will create an AST node of type `a`, but as a "side-effect" it may modify the parser's state (e.g., the symbol table). So a statement that just declares a variable might not produce any interesting AST node, but behind the scenes would update the symbol table with a new entry about the variable: DECLARE_VAR :: { () } : 'let' ID ... {% declareVar $2 } where `declareVar :: Identifier -&gt; MyMonad ()`. Similarly, an expression that uses a variable, would probably try to look up its name in the symbol table. Perhaps, something like this: EXPR :: { EXPR_AST } : IDENT {% resolveVar $1 } | ... where `resolveVar :: Ident -&gt; MyMonad EXPR_AST` The top-level parser produced by `happy` would be something like: praser :: String -&gt; MyMonad PROGRAM_AST So when you "run" the monadic computation you will provide the initial symbol table, and at the end you will get an AST value, and a final symbol table. This is just a rough outline, the details would depend on your language's scoping rules.
Thanks for the explanation. I didn't realize I needed to use `OVERLAPPABLE` to get that behavior. I'm actually going to use `{#- LANGUAGE OverlappingInstances -#}`... see my comment below. Since my goal here is to be succinct, and just get lists wrapped in newtype to inherit some list behavior, not create a robust `ListLike` library, I don't want to have to define all the instances for Functor, etc., for several different types. With five different type classes to define instances for, and three different `newtype`-wrapped list types to define them for, that's 15 very boring instance definitions.
After reading many books, I was still not able to go beyond writing small toy programs in Haskell. I finally decided to try the Haskell book (http://haskellbook.com) and think I finally found what I wanted. I highly recommend that book. 
/u/mbw_rdt thank you for the tips! I'm pretty sure this is going to save me hours of pain in the future. 
As other people noted, it isn't the purest explanation of the concepts behind monads in particular, but I really enjoyed the articles trip through Functors -&gt; Applicatives -&gt; Monads. There are lots of other resources out there explaining monads but this one stands out to me because of how approachable it is.
For those in the future that are curious what that would've looked like... (Plus some funsies with `both` and `bimap` because why not) solve (s:t:a:b:m:_:rest) = [as, os] where constraints = filter (\x -&gt; s &lt;= x &amp;&amp; x &lt;= t) (as, os) = both (length . constraints) $ bimap (map (+a)) (map (+b)) $ splitAt m rest
New to Haskell but this passed. Does haskell optimize that double filter I used to avoid the lamda? solve :: [Int] -&gt; [Int] solve (s:t:a:b:m:_:rest) = [as, os] where countInside = length . filter (&lt;=t) . filter (&gt;=s) as = countInside . map (+a) . take m $ rest os = countInside . map (+b) . drop m $ rest
Correct, sorry about that, haven't tried to compile this piece of code.
Yes, don't put in upper bounds for everything. That will drastically cut the amount to bumps you need to do, and as long as you put upper bounds smartly, you probably won't break when packages upgrade. As an example, I have had way more breaks this year from &lt; 0.1 breaks (which upper bounds don't catch) than from &gt;= 0.1 bumps. Of course, others will advise to the contrary, so consider the pros and cons yourself. 
And, it turned out I also needed \`DeriveTraversable\` as \`GeneralizedNewtypeDeriving\` doesn't like to derive \`Traversable\` instances.
So, algorithms like this I have always enjoyed using Haskell's lazy arrays for, something like this works very well: let arr = array (m,n) [((x,y),f x y) | x &lt;- [1..m],y&lt;-[1..n])] where f x y = ... max (arr ! (x-1,y)) (arr ! (x,y-1)) ... in arr ! (m,n) can clearly show the dependencies between values, and often uses less code than the C equivalent.
\&gt; dependency bounds are to be coupled with source code The general consensus seems to be that version bounds as well as cabal revisions are a major design flaw. There are much better ways to solve this problem than embedding version ranges in .cabal files. The compatibility information should instead be tracked in Stackage as \[proposed in this blog post\]\([http://www.yesodweb.com/blog/2015/09/true\-root\-pvp\-debate](http://www.yesodweb.com/blog/2015/09/true-root-pvp-debate)\) without needing any intervention from package authors.
Ok 👍 I’ll give it another try and this time I’ll report an issue if it’s not responsive
You said in a previous comment that: &gt; ... by not using IP themselves, others still can use it against them - this is competitive disadvantage, a significant one; that would make them not only weak, but to fall out; by this changing the population of companies towards those who perhaps do not even care ... You used this point to justify the main proposition I am disagreeing with: &gt; nothing unethical exists in utilizing the copyright or patent system for money ... So, it is you who postulated that the harm of a patent attack is the "falling out" of the more ethically conscious entreprises. Now I put forward that your justification of this harm is as good as my justification of a human sacrifice of a certain flavour, specifically that done for the *theoretical* *future* greater good.
Reminder that g isn't a function with 3 arguments, it's a function with 1 argument that returns g', a function with one argument that returns g'', a function with one argument...
Is there much of a FP/Haskell scene in Shenzhen?
I'm trying to use ghcid with a yesod scaffolded app with no luck. I have moved `DevelMain` to `src/` and then ran `ghcid --command "stack ghci web-app --ghci-options=-fobject-code" --test "DevelMain.update"`. I get no errors, ghicd works correctly, but the server is not running. I feel like I'm missing a step here. I'd like for it to work like `stac exec -- yesod devel`.
The rewrite rules for `filter` will indeed turn your code into a single `filter` call. That's not special GHC magic that only works for built-in functions; look up the RULES pragma if you want to know more.
I don't think so, in general Chinese companies prefer massive adopted tech\-stacks such as java/go/php , etc. And we still have a long way to promote haskell adoption here.
Very cool stuff /u/winterland1989 - I appreciate all the work you're putting into trying out another I/O manager, as well as this talk and your previous write up(s), keep it coming!
I'll leave some hints for a solution that I might come up with: * You can make integer ranges with [x..y] * The factors of a positive integer `i` are the postive integers `j` such that `j&lt;=i` and `j` divides into `i`, which can be expressed as `i \`mod\` j == 0`. * If you have a function `f` with signature `a -&gt; [a]` then you can use map applied to `f` and a value with signature `[Int]` and get an `[[Int]]` I think these are more than generous hints.
Start with just factoring one integer, once you have this function,just map it over a list to get what you want. To factor an integer, make a list of primes and then check if they are factors. Ie start by testing if 2 is a factor, if it is then divide by it. If it isn't then check if 3 is a factor etc.. Repeat this process until no more factors are found. Obviously you don't need to check all primes... Can you figure out how many you need to check? 
alright i'll try this thank you very much! 
From the example he lists all the factors, not just the prime ones. Either the example is stated incorrect or your solution is incorrect.
But now I realize I'm wrong too. 😗
Yes, its a little odd that n should not be considered a factor of n.
&gt;Thanks! I'm working on it ; \)
I wouldn’t use revisions like you do, but rather bump the actual version when possible. Iiu revisions correctly, you may need to use them rather than bumping the version in the following case: An important package on hackage depends on your package and that’s on a specific version of it (or has an upper bound that is too strict), and you want your fix to propagate to this package. In this case revisions allow you to work around the problem which originated in the other package.
Isn't this already possible with available libraries? For example, [this](http://hackage.haskell.org/package/freer-effects-0.3.0.1/docs/Control-Monad-Freer.html#v:runNat) can be used by passing interpreters of type `forall a. eff a -&gt; IO a` for a given effect of type `eff`.
If we're honest we can consider the stack community to be *the* haskell community for all practical purposes. Have you seen the [recent user survey](https://www.fpcomplete.com/hubfs/Haskell-User-Survey-Results.pdf) or this [other independent user survey](http://taylor.fausak.me/2017/11/15/2017-state-of-haskell-survey-results/#question-23) which both paint a very clear picture. Maybe cabal or something else will win back the hearts of users at some point in the future but we have to focus on the here and now. General consensus doesn't require an unanimous vote by everyone and their dog. If there's consensus within 80-90% of users I consider that qualifying as general consensus.
Hey, I took a good look at the grid package and it's very well made. I especially like the use of typeclasses to handle different types of grids. The source was pretty straightforward to read, also the hexagonal\(2\) and GridMap have almost everything I need. I think I'm gonna use it, rewriting some game\-logic functions should be easy enough.
Have you tried using the built-in IsList? https://ghc.haskell.org/trac/ghc/wiki/OverloadedLists Not sure if this will solve your problem without having to implement it yourself
No single method or resource has been a panacea for me. What has worked is to be exposed to a myriad of good resources, all of which come at a subject from a different angle. For example, in **Get Programming with Haskell**, *functors* are described as providing the ability to apply a function to a value in a context. That works great for **Maybe**. In **Programming in Haskell**, *functors* are described as generalizing the idea of apply a function to the values contained in a data structure. That works great for **\[\]**, and other traversables. The explanation of *applicatives* constrast even more starkly. In **Programming in Haskell**, the emphasis is on the fact that the arguments that we are applying the function to may have an effect. For example, **pure \(\+\) \&lt;\*\&gt; Just 1 \&lt;\*\&gt; Nothing**, the arguments have the **Maybe** effect of "maybe we're here, maybe we're not". In **Get Programming with Haskell**, *applicatives* solve the problem of applying a function in a context to values in a context. Of course, there are going to be fundamental core axioms between explanations of the same concept, but coming at it from different angles, and having those different **mental models** at hand when coding, is how I am able to make progress. All of that to say, I really enjoyed the picture resource that /u/hardwaresofton linked to.
Or just use a type variable `hole`?
I'm a long time cabal user (&gt; 5 years), and I don't pay attention to Haskell stuff online. (e.g., I didn't even know about the AMP until the versions that implemented it started coming out) I do my own stuff in Haskell occasionally but don't stay on the bleeding edge of the latest universe of obscure-category-theory-based packages. Is the whole stack versus cabal thing as messy and flat-out political as it seems from a distance or are there actual technical reasons for me to take everything I know about building Haskell programs and throw it away?
Really good content, thanks for sharing :)
So you believe that your hold of some intellectual property is beneficial for the world because it ensures that your entreprise will exist singularly, and you claim it should exist singularly if it is to be of any use. It is hard for me to see how this could possibly be the case. My idea of free market is that competition decreases prices *and* increases quality. So I can easily see how *you* would benefit less, but I can also see how *everyone* would benefit more. It is also an unsurprising point that free and open projects have a tendency to centralize by themselves. _(For example, random clones of Linux do not seem to hurt the advancement of the kernel.)_ From these two observations, the falsity of your claim is apparent. Yet of course it is plausible to you. It is easy to end up taking on faith ideas that justify one's privileged lifestyle and protect one's gains. Now, back to GPL. Intellectual property and trade secrets are actually only tangential to it. If you want to use a GPL licensed library on your web site, you do not have to release the whole source. Simply go to the creators of the library and ask them for a private license. Then, your web site will remain closed source indefinitely, and the authors of the library will also have some butter on their bread. In this way, GPL is better for an aspiring programmer to license their code under than, say, ISC or public domain, which contradicts your initial proposition _(that GPL hurts prospective developers)_. In a sense, copyleft makes sure sure the profits any single closed source project could make get distributed among the crowd parts of the code were sourced from. I understand it is a bother to solicit custom licensing from here and from there, but it is a *fair* bother.
1. No! Unless you really want to. 2. I think the best motivation is thinking about a project you want to build using Haskell. A compiler or interpreter might be a good fit. 3. Give www.haskellbook.com a try.
As an alternative to The Haskell Book (while it's good work, it's IMO way to verbose and needlessly long), there's also http://www.cs.nott.ac.uk/~pszgmh/pih.html.
Excellent, thank you.
I mean we're still back to the primary issue that I cannot sustain myself without income. And I cannot get income from this without it succeeding, and I also can't get outside funding without a sound business platform. So regardless of what your opinion on the effect of competition, we are still stuck on square one where releasing source code isn't an option. It doesn't really matter, I'm still going to continue not touching GPL libraries except in places where the license will not affect me, and I'm still going to recommend against using it whenever it is discussed. So I guess have a nice day. 
You do not need to know or learn abstract algebra or category theory. I've been using haskell professionally for a while, and I've never needed to learn either of these. As mentioned elsewhere, www.haskellbook.com is probably the most complete resource for learning. You can read people's blogs too: - http://www.haskellforall.com/ - http://www.parsonsmatt.org/ Honestly, you should just start writing code to solve something. It can be a problem you're interested in or a business problem (although I know not everyone has the luxury of being able to try it out on a business problem).
Just make a proper patch bump and thrash the cache. Be honest. Be truthful. Let tools improve caching if they need to. But once you are doing something 10x less often you have a lot more leeway. 
I'm not sure what you mean by this. Are we talking about [freer monads, more extensible effects?](https://hackage.haskell.org/package/freer-effects) If so, you can already interpret one effect in terms of another, given by [handleRelay](https://hackage.haskell.org/package/freer-effects-0.3.0.1/docs/Control-Monad-Freer.html#v:handleRelay).
I think this is what I'm looking for, thx.
You may not like this but, in my opinion, if we're honest we can consider the stack community to be de facto the entire Haskell community for all practical purposes. You don't have to take my word for it. Just you look at the [recent survey performed by FP Complete](https://www.fpcomplete.com/hubfs/Haskell-User-Survey-Results.pdf) or this [other independent user survey](http://taylor.fausak.me/2017/11/15/2017-state-of-haskell-survey-results/#question-23) which both paint a very clear picture. Maybe cabal or something else will win the hearts and minds of users at some point in the future but I don't think we should spend time with hypotheticals. To get back to the point, general consensus doesn't require an unanimous vote by everyone and their dog. If there's consensus within 80-90% of users I consider that qualifying as general consensus. 
I agree with you. Missing upper bounds interacts decently with content-addressable caching, and conservative upper bounds doesn't. Maybe I'll post this same thread again in a few months, but from the perspective of someone already leaving off upper bounds - I sort of messed this one up ;) It feels like we have something missing in our ecosystem that would allow us to tweak bounds (and more mundane metadata tweaks like typos in the cabal file) without affecting our nix-style package managers (nix, cabal, and soon stack, I believe). That mechanism today is revisions, which feel like a bit of a half-measure, in part because they are modified on the Hackage UI itself. There's a larger issue of revisions actually being able to break builds in some evil way, I think, though I confess I don't have all the details. I just want to be able to tweak bounds _without_ thrashing any stores, and I fully agree that a decent compromise is to only thrash the stores when absolutely necessary (i.e. default to leaving off upper bounds).
I've been saying for years that I feel we are a few PhD students short of a coherent theory. System-F, Hindley-Milner, SKI, Core, lenses, Monads - all these seem like minimal and beautiful theory we leverage for our benefit. Package management feels like it should have the same elegant core, but currently is just messy, and that shows at every level. 
Very cool! I'm a bit confused about the description though. Is Tintin a general purpose static site generator that also runs GHC on the code examples?
This is a nice demonstration of how to use `inline-r`. I am wondering what people "in the real world" use to do these cartographic visualisations. I was under the impression that most professionals were using ArcGIS or QGIS in order to perform geospatial computations and using python if any scripting is needed to be done. Plugins for QGIS are certainly written in python. 
Yeah, it could be used as a static site generator, although it is geared towards "soft documentation" (guides and tutorials) for Haskell :)
Yessss :)
I'm a bit confused as what it does? Is there a repo that uses it somewhere?
Sharing `persistent` types with your front end is a mistake, IMO. It couples your UI to your database in a way that makes it annoying to change later in a backwards-compatible way.
I'm not sure if we're setting `-fobject-code` in the neovim plugin. I'll check and see if that improves things.
GHC is a 20+ year old codebase and it shows. PureScript was designed with IDE-like features nearly from the start and can take advantage of Haskell's entire library ecosystem, neither of which are true about Haskell. Scala has massive amounts of corporate funding for IDE tooling, which GHC doesn't have. I hope HIE becomes useful, fast, and productive. Until then I've got work to do.
Will do, thanks for the suggestion :) 
It is a tool to generate websites for your Haskell library. You put markdown files in the `doc` folder of your library and run `tintin` on it. The result is a website that you can publish to github pages :) [Tutorial](https://theam.github.io/tintin/02-documenting-your-project.html)
Iiiinteresting, thanks!
This is fantastic news. Great job Theam, thanks for sharing !
It helps to know some of the basics, e.g. monoids (not to be confused with monads), but you'll pick them up as you go, assuming you like to read and are curious. Also be aware of [hoogle](https://www.haskell.org/hoogle) and the [mailing lists](https://www.haskell.org/mailing-lists).
Update: there is a tool called `hackage-cli` which seems to alleviate my primary pain-point (clicking around on Hackage instead of pushing revised .cabal files manually). The New Flow is as follows: * Make whatever metadata changes are necessary (relax/tighten version bounds). * Manually bump the `x-revision` field. If this is your first revision, add: `x-revision: 1` Otherwise, bump it. * Run: `hackage-cli push-cabal [--publish] my-package.cabal` This will append the modified `.cabal` file to the package index, which has the desired property of "overwriting" old `.cabal` files during solving. (However, there are ways to work around this to access old, such as with `--index-state`). A couple more notes (cabal devs, please correct me if any of this is untrue): * In the future the `--index-state` timestamp will be included in a `cabal.project.freeze` file. Currently it's not, so `cabal new-build` is not fully reproducible out of the box. * In the future, you will be able to specify revisions in a constraint with `--constraint`. This is like a finer-grained `--index-state`. * In the future, uploading a revised `.cabal` file will be integrated into `cabal upload` itself, rather than via a separate `hackage-cli` tool. * In the future, updates to the "PVP" operator `^&gt;=` and perhaps the PVP itself will be made. Can't say much more here, because I don't know any details, but I would love for some insider to clarify what's floating around in peoples' brains so we can all follow along. In the short revisions do seem to solve the cache thrashing problem, so I'm going to embrace them for now. Cheers :)
I believe D3 gets heavy usage on the ‘visualization’ side. Probably this would cover most aspects of “cartography”, but maybe a cartographer could respond. 
It looks amazing! Great job :\-D Please consider using a darker font with the lighter background options. This will increase the contrast and make the generated pages more accessible. The white/blue font for links that are not selected make the links barely readable over the light blue background.
Neil, we've been over this so many times, but I feel compelled to reiterate. :-) If you don't put in firm upper bounds (and apparently, even if you do, and minor revisions break things because other people don't follow the pvp carefully), then not only does the current version need updating (which can be done with a new upload) but prior versions that have bad bounds also need those bounds revised, or the solver can still come up with bad plans.
Yep, basically `tintin` does something like that, except that it doesn't perform documenation testing. It evaluates the code and returns the output when needed. So no need to type it manually. On the other hand it provides you a way of publishing the website directly, without having to worry about design and organization.
&gt; The PVP allows you to add new identifiers. These are almost always the case of all my breaks. Everyone follows the PVP and it doesn't have the desired effect. Ah, so the old problem with needing to explicitly specify imports or not. Yeah, I agree on that, and also on how irritating explicit import specification is. I've found that I'm lax about it on my own projects, but most other projects I contribute to, be they larger free-software projects or work projects do specify imports and I follow their style. This is one place where better editor tooling really could help. (Other than that, I don't miss anything particularly in my basically idea-feature-free workflow). Also agree that better revision editing tools all around can help with things. 
tell me this is the continuation (c) of https://www.haskell.org/haddock/
In analogies with categories, one has to be mindful that categories in general are more than just Hask. What is an arrow is not necessarily a function (as in hask), and one can not always express arrows between object as an objet itself (exponential object). Typeclasses instances and type classes also form a category. This ability to consider different categories is what makes category theory powerful, by packing a lot of structure into compact statement, at the appropriate level of abstraction. 
I'd think one concern would be that BSD+PATENTS might imply a reciprocal license from any redistributor or contributor. For corporate programmers who can only use open-source code if it's released under a license approved by corporate counsel, BSD+PATENTS might not be on the approved list. The BSD+PATENTS license is frustratingly ambiguous as to whether a licensee who redistributes or modifies the licensed work must also license *their* patents. Paragraph 1 says that redistribution requires retaining "this list of conditions." The natural interpretation of "list" is the numbered list: paragraphs 1 and 2. The patent grant is a separate thing that's not in the list; it's not a "condition"; and it's not mentioned as a condition in paragraph 1 or 2. Arguably, you can take something licensed as BSD+PATENTS and redistribute it under BSD2. That'd be kind of awkward, though, and you'd have to actually change the LICENSE file, which smells wrong. It'd be preferable, as a drafting matter, to have the patent grant separate from the license, and explicate that it's Facebook licensing their patents, or whatever. If, on the other hand, Facebook wants a reciprocal patent license from any contributors, that should also probably have been made explicit. (Although I'm a lawyer, this isn't legal advice, etc.)
;)
If I have to draw maps as part of visualizations within webpages, d3 + topojson is what I reach to. It's relatively simple to use (if you know the basics of d3) and many maps are readily available in topojson format (world map, individual countries, or even down to municipality, most with a free license). 
From what I've heard, haskellbook is great. However, unlike LYAH and RWH, there is no "full book free version online" available.
I have a multi package stack project configured like this packages: - myBase # ... - shares/externalLib - myService Is there a way to start ghid for all projects? When I run only `ghid` stack complains about multiple modules with the same name \(like `Spec`\). 
[removed]
If you can successfully run `stack ghci` for all packages, then you can run `ghcid`. But with that setup, you're going to need to be selective about the targets you load, like `stack ghci myBase:lib myService:lib` etc.
Looks cool! Is there a reason that you define your own 'evaluate this' syntax? Why not re-use `haddock`/`doctest`s syntax? &gt;&gt;&gt; 3 * 4 12
Because `doctest` asserts that the result of the operation and the one returned by it are equal, while with `tintin` you dont need to write the result, as it evaluates it for you!
Thanks to you for the valuable feedback :)
Hi, I've been trying and having some success with how happy's actions work and "thread" each other. Your answer really made something click that I just didn't get from reading the docs, specially after reading the type signature that every action has, and after realizing that binds every pair of sequential actions together. Thank you for your answer. I hope you're ok with me coming back if there are more questions about it.
If I want to analyse geospatial data, I reach for GeoPandas (https://github.com/geopandas/geopandas). It's super easy and quick to use if you're already fluent in pandas
`Stack` and `cabal-install` are designed to do two slightly different jobs. `cabal-install` uses Hackage and automates the building of your code and its dependencies via GHC. That is, you don't need to run `ghc make` and `ghc-pkg` commands yourself, anymore. `Stack` uses the `Cabal` library, and adds upon it the idea of "snapshots" -- sets of packages and their versions which are known to be compatible with each other. That is, if you don't pull in extra dependencies, and your code compiles now, then your code is guaranteed to *always* compile, regardless of version changes in the dependencies, even breaking changes (because `Stack` has pinned a specific version of the dependency in the snapshot). Of course, there's a whole lot more to it, but my point is that unless you're a True Believer, you can see why the two should be able to live together -- they have two different goals. The friction is due to the large overlap in their capabilities, and philosophical disagreements as to versioning, package immutability, and the nature of reality itself. 
[This posts](http://blog.ezyang.com/2013/05/the-ast-typing-problem/) is a quite readable breakdown of the issue [Trees That Grow](https://www.microsoft.com/en-us/research/uploads/prod/2016/11/trees-that-grow.pdf) can solve. GHC is currently [refactoring its codebase](https://ghc.haskell.org/trac/ghc/wiki/ImplementingTreesThatGrow) to take advantage of this. In short, it involves * adding a type parameter `ext` to the AST type, * extending the constructors with an additional field, and introducing a type family (canonically, one per constructor) to compute the type of the extension field. This way, the type of the new field can vary between constructors, depending on `ext`. * Also, a new constructor and a corresponding type familiy is added to the AST to allow grafting in new constructors without touching the original declaration. * Pattern synonyms help keeping the code using the decorated types readable. You change `ext` and you get variants of the AST for parsing, symbol table generation, type checking, code generation etc. This way, (1) repeated definitions of the AST structure can be avoided, (2) no code is affected by adding a new AST variant, and (3) modifying an AST variant only affects the passes using it. To answer your question, Trees That Grow would not help you doing it all in a single pass. It is more suited for a multipass compiler where it can help tame the issues that arise with defining multple AST variants.
`tagsoup` can be a good option. Or another HTML parser,
I'm planning on doing a modified version of the structure LeBlanc and Cook show in their paper, yes. 
Thanks to Bartosz Milewski, probably one of the best teachers bridging haskell and mathematics. I'm working on notes for his video lectures. Also working through the challenges in his book and syncing them into a comprehensive repo. I'm hoping to gather a community study group so if you work on the challenges submit them to the repo!
&gt; You may not like this but, in my opinion, if we're honest we can consider the stack community to be de facto the entire Haskell community for all practical purposes. No.
Just a few weeks back I was searching if there exists such a library.. Thanks for this work!! I wanna use it here docs.reflex-frp.org :)
Reflex docs are hierarchical; but at a cursory glance I see that Tintin's structure is flat.
Every goddamn time I dive into some topic, something related to it pops up on this subreddit. It happened the other day with automatic differentiation. It happened when I wanted to try cabal instead of Stack for once and a cabal tutorial was posted on the same day. It happened when I was reading about graphical linear algebra and the "Burritos for the hungry mathematician" paper was posted. One of the references was a paper about exactly this kind of thing. I just started reading Bartosz's book two hours ago and am not complaining.
Hm either there's some collective internet intelligence going on here or its just your attention subconsciously matching new patterns it finds.
Most certainly the latter. Like when you learn a new word, and you hear it the very next day.
That is true. I think the authors have put in so much of effort to make it the as best as possible. You will have to read it to believe it, but unfortunately, to read it, you need to buy it 🙄 My experience with that book says it might be worth it for you.
I'm trying to condense a quick introduction to functors, applicatives and monads into one slide. A few notes: I'd like to avoid introducing advanced concepts such as type classes or higher-kindedness. The idea being that introducing too many concepts at once is detrimental to learning. It's not meant to be Haskell-specific as such. I've taken the liberty of using the `lift` analogy, since I find that the relation between Functor and Applicative is more clear that way. For monads, I've ended up on the `flatten` analogy, which is an easy name to related to the `m (m a) -&gt; m a` type, where it's evident that the nested monads is flattened into a single monad. I've elided the laws. While important, I gather that one would have to understand the usefulness of the type classes before being able to appreciate the laws that govern them.
I think before I can evaluate this and provide feedback I need more context: what are you trying to explain, and who is your intended audience?
Hi, thank you for your feedback. The intended audience is people who have encountered a barrier in understanding monads, and designated it as "scary". It's meant as a quick slide to give the gist of it. It's meant to speak from, rather than as a stand-alone document. It could be followed up by a additional slides, such as a series of examples of useful monads, and then perhaps the monad laws. Other than that, I've posted a top level comment with some more background.
The only time I've ever seen numbers like 80-90% using stack is when it comes out of the Stackage people's polls. I'm not accusing them of bad faith but it is pretty clear selection bias. Other data seems to suggest its far less skewed toward stack. It's insanely hard to tell what the truth is right now.
I'm so glad to see that `universum` is used in wild! :blush:
Nice. Could that be augmented with the stuff here? http://r6.ca/blog/20110808T035622Z.html
It is not asymptotically faster than the naive implementation since it imposes O(length of the element) cost per each element, so total cost is O(the sum of the length of each element) which is same to naive one. So I performed benchmark. [benchmark code; see latest commit diff](https://github.com/viercc/trie-simple/tree/test-enumerate-via-foldr) benchmarking TSet/query/enumerate10 time 3.569 μs (3.363 μs .. 3.781 μs) 0.974 R² (0.963 R² .. 0.986 R²) mean 3.400 μs (3.232 μs .. 3.621 μs) std dev 574.4 ns (461.2 ns .. 715.4 ns) variance introduced by outliers: 95% (severely inflated) benchmarking TSet/query/enumerate10_foldr time 1.505 μs (1.456 μs .. 1.571 μs) 0.984 R² (0.970 R² .. 0.996 R²) mean 1.524 μs (1.405 μs .. 1.882 μs) std dev 585.9 ns (159.0 ns .. 1.081 μs) variance introduced by outliers: 99% (severely inflated) benchmarking TSet/query/enumerate100 time 32.76 μs (30.99 μs .. 34.19 μs) 0.982 R² (0.976 R² .. 0.988 R²) mean 29.79 μs (28.36 μs .. 31.59 μs) std dev 4.773 μs (4.007 μs .. 6.059 μs) variance introduced by outliers: 93% (severely inflated) benchmarking TSet/query/enumerate100_foldr time 19.00 μs (18.07 μs .. 19.95 μs) 0.988 R² (0.985 R² .. 0.996 R²) mean 17.56 μs (17.07 μs .. 18.32 μs) std dev 1.748 μs (1.178 μs .. 2.368 μs) variance introduced by outliers: 85% (severely inflated) It seems foldr-based one is 2x faster!
I think it is an interesting angle. Did you consider something like skewLift :: (a -&gt; m b) -&gt; m a -&gt; m b rather than `flatten`, to keep a little closer to the pattern you established with `Functor` and `Applicative`?
This is very good project. But I still don't see much benefits over using `doctest + LHS + markdown-unlit`. Because you can access your projects for GitHub pages through README.md file. I guess Scala just don't have Literate Scala and `doctest` so `sbt-microsites` rescue people there. Looks like the main use case for `tintin` is when you need to write multiple pages big tutorial for your project.
It's a slide. Which implies that its intended use is as part of a talk or presentation. Which in turn means that it contains only the bare essentials to guide and support the explanation given; it does not contain the explanation itself. As a seasoned Haskeller, I had absolutely no trouble inferring the intended context here; but if you are the target audience for the talk to go with this, then you will not understand anything from the slide alone. This is normal, and the reason why people do talks in the first place.
I like this explanation, but maybe it’s hard to judge if you already know how Functor/Applicative/Monad. I think maybe a specific Monad would be helpful in understanding what ‘m’ would be in your slide. I’ve always thought Maybe was a practical/intuitive example for this.
One useful way to draw parallels across the three classes is: (&lt;$&gt;) :: Functor m =&gt; (a -&gt; b) -&gt; (m a -&gt; m b) (&lt;*&gt;) :: Applicative m =&gt; m (a -&gt; b) -&gt; (m a -&gt; m b) (=&lt;&lt;) :: Monad m =&gt; (a -&gt; m b) -&gt; (t a -&gt; m b) Cf. [this discussion in the Wikibook](https://en.wikibooks.org/wiki/Haskell/Applicative_functors#A_sliding_scale_of_power). Two potential disadvantages in comparison to your approach are: 1. It doesn't cover `pure` (which is the beauty of the `liftA0` approach); and 2. Depending on how unfamiliar your audience is with this sort of thing, making sense of `m (a -&gt; b)` might be a stumbling block. (You might have to justify its relevance through examples like `(+) &lt;$&gt; Just 2 &lt;*&gt; Just 3`, and then you're halfway to `liftA2` already.) As far as `Applicative` versus `Monad` goes, we might arrange a less usual face-off: entwine :: Applicative m =&gt; (m a, m b) -&gt; m (a, b) flatten :: Monad m =&gt; m (m a) -&gt; m a (Note there is no standard name for `entwine` that I know of.) Reaching for the monoidal presentation of `Applicative` is probably not the kind of opening gambit you are looking for in this specific scenario. I mention it mostly because I find it pretty.
Yess! It is awesome :)
You're welcome! Sure, that's a great use case :D
In Haskell? I meant to mention I could probably have used https://archives.haskell.org/projects.haskell.org/diagrams/ once I had the map data in an easier format via `fortify`. I think creating the axes and legend would have had to be created "by hand" in that case. As I said you can also use the Haskell `shapefile` package to read in the data.
I did consider going this route. Bind is called `flatMap` in Scala, so it wouldn't be far off to call it eg. `flatLift`, although that doesn't really make sense without also introducing `flatten`. I couldn't think of a good name for it. There's a little bit of an upside to presenting it as `flatten` though, since it's in some sense more minimal, eg. `flatLift f m = flatten (lift1 f m)
Yeah, I think you're right it needs to be backed up with examples. In this instance, I wanted to focus on the definition only, but I should probably expand it with examples. Another Monad I think is good to exemplify is the Future monad, where applicative is the parallel operation and monad is the sequential operation, to show that they can have different implementation in non\-trivial ways.
&gt; I like the first presentation now, but I remember encountering it way back and it not helping me. I guess it works better as part of a wrap-up, after some groundwork has been done, rather than of an introduction. &gt; `entwine` is called `product` in the `Cartesian` type class in one of the Scala frameworks. [I like how they put it upfront in their tutorial](https://typelevel.org/cats/typeclasses/applicative.html). Food for thought! &gt; The only thing is that I can't think of a name that easily conveys the semantics to a newcomer. A *very* bold option would be `zip`. That is expensive real estate, though.
I'm really confused as to how to just execute 'tintin'. The guide says just do stack install inliterate --stack-yaml &lt;your stack.yaml file&gt; But this only installs a program called inlitpp, where is the actual tintin executable? 
I'm having this same issue :)
[removed]
&gt; Is there a reason why there isn't a WaitForMs option in SchedulerHint? I just didn't get around to implementing it, and I haven't encountered any situations that would benefit from it so far. &gt; I also kinda wonder if the code duplication for JobList is a problem that could be solved via language extension. Maybe. This code is pretty ugly because I've tried to squeeze as much performance out of it as I can.
Oh more stuff! Graph stuff! I thought about it, but was clearly missing the `Matrix` part. The Kleene things would fit easily, more examples great! ... but, I don't know how to fit `Semiring` stuff nicely. `ERE` is `Semiring` in two ways, one would like `Semiring s =&gt; Lattice s`, but that doesn't work there at all... --- &gt; Gauss\-Jordan\-Floyd\-Warshall\-McNaughton\-Yamada is what used to compute RE from DFA (didn't know it had a fancy name). (r6 version is more elegant as there's `Matrix` to "cache" intermediate results, I use `MemoTrie`). &gt; An algorithm for deciding if two regular expressions are equal is beyond the scope of this blog post. Lookup it in `kleene` :)
I cloned your project and it works, but it doesn't work on mine. I checked some files and everything looks fine. I'll keep on using yesod devel, but thanks anyways!
I had an earlier version that used zip, but it was pointed out to me that it’s a confusing name, since ZipList does not have a monad instance.
It's a minor nitpick, but I would prefer `lift2 ($) m n` over `lift2 id m n`, to make it clearer that the operation being lifted is *function application*.
Thank you, that's a fair point.
Just added `tintin` to packages that use `universum`: * https://github.com/serokell/universum#projects-that-use-universum- I hope you don't mind :)
In my experience with yesod, I have never found lucius (or cassius) to be particularly useful. For classes and ids that are known statically, I would just go old school and put them in a CSS file. The only situation in which I would reach for lucius/cassius would be if I had ids that were dynamically generating, and I wanted to generate some styling information that accompanied them.
Thanks, that is very helpful and interesting. I was looking into going to TemplateHaskell route.
For a complicated app, that could lead to many requests per page load which I thought was something to generally avoid?
Browsers cache stylesheets, so this shouldn't be a problem. Also, you can just stick static assets (stylesheets,images,javascript) on a CDN. It's much more likely that database queries become a bottleneck.
Regarding minimality, you also have `flatten = flatLift id`, so.. :)
This seems very useful. I've always disliked the code duplication form having to define both e.g. \`FromJSON\`\+\`ToJSON\` and \`Put\`\+\`Get\` parsers, since they basically do the same but in opposite directions. Would be quite cool with an interface to e.g. \`aeson\` that allows writing just a single parser.
Wow, it's great! One suggestion. It seems `DFA` lacks some possible instances. `Derivate` would be easy (move starting state). `Equivalent` is possible by the similar algorithm to `RE` and `ERE`. (Bounded)`Lattice` will also be possible (via product construction). I don't know whether they are useful or not, but I feel more complete with them.
Sounds like a useful tool. Who's releasing the `hole` package, with just that line in it?
I'm using upper bounds and explicit or qualified imports. If I want to bump my upper bounds: * build with the cabal option `--allow-newer` * call `cabal-bounds update` to update the cabal file * release a new minor version It's not perfect, but it keeps the amount of work quite low. 
Thanks for suggestion. Indeed, also `Monoid` possible, i.e. `Kleene`. I had an idea to make a `dfaToDot` function, to help visualise automata, but had to stop somewhere before upload :) In retrospective there is no good reason to hard code start state to be @0@, that will make `Derivate` fall out immediately. I'll probably add DFA variant with arbitrary state labels, then visualisations of compound automata will have teaching value. As /u/sclv commened above, and I discussed with /u/AlpMestan, there are also connections to graph sfuff, so there;re a lot of stuff to be done. Anyway, I'll procrastinate and let ideas accumulate and digest before making more stuff. 
This is such a bummer. Ertes was a regular in the haskell-game channel (freenode) and spent a lot of time helping us all formulate our libraries and develop an intuition about FRP. The last time I talked to him he was coding on the beach and playing with a drone. Really cool guy, he will be missed. 
It's not very commonly used, but `&gt;&gt;&gt;` from Control.Arrow is what you're looking for.
For some similar art in the field, you might want to check out [cram](https://bitheap.org/cram/), which is for documenting &amp; testing shell code. It will run the examples for you, then let you store the generated results to use as documentation AND/OR let you compare it with previously generated results to use as tests.
Maybe if you would post an example of what you're trying to do? Why doesn't `(&amp;)` cut it for you? You only have to apply the first argument, then eta-reduction will kind of "take care of the rest". Or don't eta-reduce, but then you just have a poor man's substitute for let bindings. You know, like `(&gt;&gt;=)`.
Yes, but also `lift1 f = flatLift (return . f)`. So `flatLift` duplicates the functionality of `lift1`. That's what I mean when I say that `flatten` is minimal. Of course, the same can be said for `lift2` :)
Nevermind, I feel like my question was dumb so I'm deleting it.
Great! Thank you! :)
Just updated the installation docs, hope they work for you! https://theam.github.io/tintin/01-getting-started.html
Gets redirected to tumblr dashboard for me.
i'd had the pleasure of many pleasant conversations with him via twitter and IRC over the past half decade. He was a smart interesting fellow who had his own ideas, worked on them, and shared them! (i also recall he'd have several different usernames on various services, like 2 different hackage handles and darcs hub user names, which was a confusing but harmless quirk) either way, the world has one less smart, playful personality that would explore new ideas and share them with the world (eg his own experiments in FRP land)
I am a bit worried about bringing Clojure's component abstraction into our world. Having spent a lot of time in Clojure land and a lot of time working on adding and then removing components from a codebase, I'm not sure I am still a fan of that abstraction.
Maybe relevant: http://www1.chapman.edu/~jipsen/talks/AsubL2002/jipsenAsubL030908.pdf
Fixed contrasts! :)
The post says &gt; using Variant is more efficient – O(1) memory usage and (de)construction – than using a nest of Either But is this true? The [implementation of deconstructing a `Variant`](https://github.com/haskus/haskus-utils/blob/836afa7406c61ad9de5954e77dbcbd629c959af2/src/lib/Haskus/Utils/Variant.hs#L287) sure looks like it's doing induction over naturals ( eg. O(n) ). Without that, it's not clear to me what this approach buys you over DTALC.
Nice one! Thanks for your work. :-D I should have probably shared this link earlier, here's an easy way to check how good the contrast of your text is in terms of accessibility: [https://webaim.org/resources/contrastchecker/](https://webaim.org/resources/contrastchecker/)
Okay thanks, so I guess I have to list all packages or write a small script to do so.
When inlining kicks in, we get the same behavior as with a normal ADT: the induction for this function is transformed into: case variant_tag of { 0## -&gt; ... ; 1### -&gt; ...; ...} At least it has been true \(see [http://hsyl20.fr/home/posts/2016\-12\-12\-control\-flow\-in\-haskell\-part\-2.html](http://hsyl20.fr/home/posts/2016-12-12-control-flow-in-haskell-part-2.html) \) I'm waiting for [https://phabricator.haskell.org/D4212](https://phabricator.haskell.org/D4212) to lend in order to fix [https://ghc.haskell.org/trac/ghc/ticket/14170](https://ghc.haskell.org/trac/ghc/ticket/14170) which broke this IIRC...
What version of GHC are you using? I can't reproduce this with 8.2.x or 8.4.x. If you are using something older it might just be a bug (intentional or not, a bug by behavior). Side note:`fromOnly` is not a constructor but a field of `Only`.
Related, there's our own [shelltestrunner](http://hackage.haskell.org/package/shelltestrunner). I wanted to make it accept markdown-with-examples as another test format, but it sounds like other tools may be handling that ..
What alternative approach(es) did you end up using in Clojure?
The real intero killer for me was the way it endlessly installed deps and rebuilt itself every time I visited a file in a new project directory, and the apparent difficulty of exorcising it when that happened. Just a naive user who probably didn't try hard enough, but nevertheless.
Ok! I’ll send the email today.
I have a recursive function with a result type something like: data Result a = Trivial | Case1 a | Case2 [a] and a function like: f :: [a] -&gt; Result a f xs | isTrivial xs = Trivial (g xs) f [] | blah = ... | otherwise = ... f (x:xs) = | blah = ... | blah = ... | otherwise = ... with various case `(f subproblem)` in those `...`. Thing is, I keep having to match `case (f subproblem) of Trivial _ -&gt; error "Shouldn't happen -- already covered"`. What's a better way of approaching this? In Haskell, `error "shouldn't happen"` generally means bad modularity, bad function design, or bad datatype, right? My datatype can't change (or if it does, it needs to carry the same info). Is there a common pattern (either in a "beginner's mistake; do it this way" sense or a "OOP patterns" sense) for dealing with this?
There is a jump between container as in `containers` and container as an analogy for a computational context, but honestly I found that jump much easier to make given the illustrated examples. Learning is a process of stitching together facts from a collection of impartial truths - an incomplete analogy isn't detrimental to that process. It is just not the whole process in one resource - which, in my experience, tends to just alienate most people anyway. Case in point, [.. in pictures](http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html) did an exemplary job getting me the bare minimum knowledge necessary to start playing type tetris. Experimentation filled in the rest of the blanks. 
Very cool, thanks for the explanation!
I never met Ertes (which is his name as far as my brain is concerned) outside of #haskell, but for a while we talked on a daily basis. Friendly guy, and just as knowledgeable, but just a nick in a text window after all. Over the years, I’m sure I’ve not noticed thousands of people leaving to never appear again, for whatever reasons. Now Ertes disappeared, but I know the reason. I don’t know what I would have expected thinking of this situation a month ago, but it turns out only now he was more than a nick to me. Goodbye *friend*.
Here are the building blocks you need to make this: ```map filter``` - A function with type signature `Int -&gt; Int -&gt; Bool` that returns `True` if the second number is a factor of the first - A function with type signature `Int -&gt; [Int]` that returns the integers from `2` through half the value of the original input (because the largest possible proper factor of `n` is `(n/2)`, and the smallest is `2`) Can you think of how you might combine those building blocks to build this solution? 
It uses [https://www.stackage.org/haddock/lts\-11.10/template\-haskell\-2.12.0.0/Language\-Haskell\-TH\-Syntax.html#v:addDependentFile](https://www.stackage.org/haddock/lts-11.10/template-haskell-2.12.0.0/Language-Haskell-TH-Syntax.html#v:addDependentFile)
There are certain WTF aspects on the Clojure implementation, for sure, however, the Haskell implementation is quite vanilla, the idea is we keep track of all the named "resources" in a resource table and build a dependency graph. * There is no dynamic binding to values on a map * There is no reloading of sub-components This API enhances `IO` slightly, the only bit of "magic" is the Alternative implementation using `async` in the back, but I think this is safe giving the laws of `Applicative`
tumblr is trying really hard to make move away from it, sigh...
Thank you /u/\[gilmi\] and for your mentions and the book! I am looking forward for it.
Thank you /u/Libeako. In fact what I am trying is to get much deeply in the structures and reflect that to my programming as long as I grow with that different kind of thinking. Still I feel it is not that really easy. 
Thank you very much u/Tehnix.
You don't need to be ashamed. There are no dumb questions 🙂 Everybody is welcome here, even those who might have difficulty articulating a thought or question
Just for historical reference, the reason for .~ and .= for assignment is that they are as close as I can get to :~ and := respectively as legal operators.
What you want to do is basically *restrict* the set of valid pattern matches of an algebraic data type at compile-time. As you already stated, you could *rewrap* your `a`s into a new type that doesn't have the unwanted constructors. This is in similar spirit to `Data.List.NonEmpty`, which only has a `:|` constructor, but no constructor corresponding to `[]`. You don't want to do that. That's okay. You could also go with *Generalized Algebraic Data Types*. Note how your `Result` type has three constructors: Trivial :: Result a Case1 :: a -&gt; Result a Case2 :: [a] -&gt; Result a GADTs allow you to exert more control about what exactly these constructors return. For example: data ResultType = None | One | ZeroOrMore data Result (t :: ResultType) a where Trivial :: Result 'None a Case1 :: a -&gt; Result 'One a Case2 :: [a] -&gt; Result 'ZeroOrMore a This requires the following language extensions: * `XGADTs`, for obvious reasons * `XKindSignatures`, because the first type variable is of *kind* `ResultType` and you explicitly want to say so. Not any willy-nilly type can go there. You don't necessarily need that restriction, but I wouldn't want values of type `Result 'Bool a` to suddenly pop up. These extensions just play nicely together. * `XDataKinds`, because you promote value constructors (`None`, `One` etc.) to *types* (prefixed by a single quotation character. Likewise, you promoted *types* (`ResultType`) to *kinds*. What this allows you to do is define functions of the following type: f :: Result t a -&gt; a -- Matches on all constructors g :: Result 'One a -&gt; a -- Can match only on the second constructor h :: Either (Result 'One a) (Result 'ZeroOrMore a) -&gt; a -- Matches on 2nd and 3rd case Hopefully this isn't overkill for you.
So, tweaking it down to a minimal example, I got to the minimal failing example let x = fail () This is accepted by the compiler, and gives a runtime error. Another, less minimal example (but shorter than yours, is below) let res = with hfail handle (fun b -&gt; let x = b in if b then fail () else 10) in match res with | Some x -&gt; x true | None -&gt; 100 ;; So I'm guessing 1. since it doesn't seem to require that effects be eliminated.
&gt; let x = fail () This will get caught by the eff type system as described in the paper. I'm not sure about the stability, since compilation isn't working for me locally (though my version could be out of date) I am using try-it online version of eff.
Thanks for the comments! What is the reason for using `newtype` over `type`? My intuition says that using `newtype` would involve more unwrapping and possibly `instance` definitions for `Monad`, etc. if I did it for `CMUdict`. Is it that `newtype` provides more type safety? I was initially debating over whether or not to use `Bool` or not for `initDict`, but you make a good point, so I'll probably change it again. Finally, as to the resemblance of `(&lt;||&gt;)` and `Alternative`, sort of. While I don't think they are formally related, the fact that `dictAppend` appends elements in a "special" way that are contained in `Applicatives` inside the `CMUdict` reminded me of `Alternative`. So basically, it just sort of looked somewhat like one to me, but I'm not sure if this perceived similarity is particularly well-grounded.
Yes, I get that too. I'm addressing the stability part, tbh I dont get what you mean.
That Variant type is rather cool, good stuff! This is pretty nice, I like how this solves the problem with maximal compiletime cleverness and lower runtime overhead than other approaches. Is there much runtime overhead? I imagine GHC might have more trouble with unpacking / unboxing. Certainly no unboxed sums here, heh. Anyway, it occurs to me that an operation that might be nice is: castVariant :: IsPrefixOf xs ys =&gt; Variant xs -&gt; Variant ys castVariant = unsafeCoerce The thing is, semantically the order of the types shouldn't matter, and so this `castVariant` thing would force you to strategize your ordering. What if instead, there was a global assignment of tag numbers for the participants in some variety of variant? For example, every constructor that can be in your AST. I suppose that somewhat defeats the purpose of open variants, but this could be nice due to supporting `castVariant :: IsSubsetOf xs ys =&gt; ...`, so you no longer need to worry about ordering. Taking this even further, it might be interesting to have `coerceVariant`, which allows you to `unsafeCoerce` if every input constructor is coercible to an output constructor. Unfortunately, this idea does not seem to be compatible with the `IsSubsetOf` idea above.
I was only able to look at it briefly. How does this relate to [compdata](https://hackage.haskell.org/package/compdata)?
My favorite reference for lens operators is this: https://github.com/quchen/articles/blob/master/lens-infix-operators.md Provides rules in a sense that allow you to look at an unfamiliar operator and figure out what it does by combining the pieces of it, all in roughly 1.5 pages.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [quchen/articles/.../**lens-infix-operators.md** (master → 9cbcc28)](https://github.com/quchen/articles/blob/9cbcc28617df6af53911921ee4cd11c763f25f21/lens-infix-operators.md) ---- 
Very interesting post! I'm working on very similar things and I'm curious to understand the details of your implementation! How does this relate to [Backprop as Functor](https://arxiv.org/abs/1711.10455) and [Simple essence of Automatic differentiation](https://arxiv.org/abs/1804.00746)? All of you seem to be talking about the same thing. Also, here's something that was popping out for me: squaredErrorGrad f x targ = gradBP $ \p -&gt; (f p (auto x) - auto targ) ^ 2 I doubt that squared error should 'know' about incoming gradients or the keyword `auto`. I also haven't noticed any categorical definitions in your post - I suspect they could shed even more light on to how to implement backprop in a clean way.
Thanks! I assume you're talking about the implementation of *backprop*/the automatic differentiation? I hope it's clear from the post that the "implementation" of whatever automatic differentiation is not exactly important, but rather the way of thinking that the ad allows you to do. This is the reason why there is no mention of implementation in my post. The system just has to allow you to track backprop through normal function application. With that out of the way, some design principles of backprop were important to me. It was very important to track backpropagation through normal function application, so you can re-use higher order functions made to work with normal functions. So, no special operations for composing functions. You can just re-use `.` from Prelude. Regarding your observation, `auto` isn't quite a keyword, it's just `auto :: a -&gt; BVar s a`, a way to lift a value into a backpropagatable computation in a way where you don't care about tracking its gradient. I'm not sure exactly what you mean by "incoming gradients" either, sorry! If you're curious on how I implemented the library, I wrote some words on it [in a previous comment][comment]. The implementation is also very similar to the implementation of the *ad* library by Edward Kmett. [comment]: https://www.reddit.com/r/haskell/comments/8jf1d9/a_purely_functional_typed_approach_to_trainable/dz019lq/
Nix feels like isolation and a build system. Where's the constraint solver? Or the proof a constraint solver is unnecessary? I think Nix solves execution problems, but I'm interested in one step before. That said, will check out the thesis. 
I wasn't aware of this function. But that makes sense to have one like that. Thanks !!!
https://github.com/ekmett/lens/wiki/Operators the table is of great use, made me realise that that `lens` operator names aren't completely arbitrary.
It's called `liftEADT` in the post.
This is Hask Anything, y'all. There are no dumb questions (just don't ask us to do your school homework 😜). 
The idea of `tagsoup` is that it does not try to parse the HTML as a structure, but rather as a list of tokens, which may be of different kinds. Above you said that you were insterested by text. The [type definition](http://hackage.haskell.org/package/tagsoup-0.14.6/docs/Text-HTML-TagSoup.html) shows the possible constructors: TagOpen str [Attribute str] TagClose str TagText str TagComment str TagWarning str TagPosition !Row !Column so that you can define a function like: getText :: Tag str -&gt; Maybe str getText (TagText str) = Just str getText _ = Nothing and keep only the text in the file with: mapMaybe getText . parseTags :: String -&gt; [String]
This reminds me of something of a similar discussion I think I saw here in roughly the last six months, but I can't think what.
It seems people recommend not learning the math unless you want to. I'd argue, yes learn it, unless you really don't want to. I am spending some time now to learn CT from the video series by Bartosz Milewski \( [https://www.youtube.com/user/DrBartosz/playlists](https://www.youtube.com/user/DrBartosz/playlists) \) and for me: 1\) It clears up many foggy things in Haskell 2\) It is a lot of fun. This is the stuff that makes the difference between the functional and imperative approaches, or at least that's how I feel about it. \(Then again, I am one of those folks that stumbled upon Haskell when I was learning some math stuff\) So yes, you might consider learning the math, especially if you are interested in learning the concepts in a generalized way so you may also benefit from them when programming in other languages. Should you do it first... before programming in Haskell? Maybe not, you can just go about and fiddle with it, and then a bit more to the theory of it.
This is a tragic loss. ertesz constantly poured his heart out in IRC helping me and countless others to not just solve problems, but to *learn* how to solve problems. He was a true teacher, and jumped at the opportunity to help anyone he could. When I was deep into FRP and game programming, we spent a lot of time talking, and I almost went to visit him. Wish I made that trip. I'll miss you, buddy.
Why is not this instance Semigroup a =&gt; Semigroup (Maybe a) where Nothing &lt;&gt; b = b Just a &lt;&gt; b = Just a in the first place?
Well, you know how in Excel you can link cells together such that when one changes, all the linked ones are updated? That's a pretty shiny example of a reactive program. Another nice thing, you don't strictly specify how the program should execute, but you just _declare_ the relationships between cells.
This is not exactly what you asked, but [this paper](https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/), among other things, describes Excel as a build system and I feel it's worth reading (if only partially) outside the context of frp.
There is very cool overview of various approaches to frp in haskell https://youtu.be/Agu6jipKfYw
Hello haskellers! I have been doing a lot of development using Reflex lately, and doing so in a Nix environment using `cabal new-build` for incremental builds. I now want to run `nix-build` for a deploy build, but I encounter a missing dependency for `megaparsec-6.5.0`, even though it works fine with incremental builds. I am on the unstable nix-channel. I seem to be misunderstanding something about `nix-build`, do you have any pointers? Cheers!
That's `Maybe (Data.Semigroup.First a)`. The point of `Maybe`'s semigroup/monoid instance is the ability to take an arbitrary semigroup and turn it into a monoid by providing `Nothing` as the neutral element.
Be aware that using `gitrev` can easily destroy incremental recompilation. It [watches](https://hackage.haskell.org/package/gitrev-1.3.1/docs/src/Development-GitRev.html) `.git/HEAD`, `.git/index` and `.git/packed-refs`, which can change even if you don't change any code (for example, when you just run `git status` after adding or editing a non-Haskell file). If you have a shell prompt that shows the git status, that happens every time you press Enter. That will make your Haskell modules in which you use `gitrev` recompile, and all recursive imports of that module that use TH (with the `[TH]` recompilation reason). As a result, every build will recompile a lot of your project and re-link all of your executables. If you have a small project, you probably don't care, if you have a large one, you probably do. There's no good solution to it right now. What I'm doing to avoid it is quite ugly: Inserting the git version string _after_ all compilation by replacing some pre-allocated known static string in the binary with `sed`. Quite ugly but 1000x faster than recompiling my project all the time.
I think compdata is about using the typeclasses to build up the various iso/injections, after having computed at "logical" level what they ought to be. It makes use of the existing Haskell infrastructure at type level to provide a more compositional experience aimed at value level. This is a bit more meta. Concretely it builds up some closed logical language (with quantifiers like "there exists" (a value of any type in the xs list) etc..) within a "fiber" of types indexed by a generic "e". It is also not linked to the universe/category this "e" lives in, which means it's more structural/abstract/simple/general. Maybe compdata is programming programming, but at the type level, and this is structural programming, at the type level too. It is interesting to phrase out what the essence is/how they differ. From far away they both seem like magic ;)
What's the goal?
Yes! Exactly that. Interestingly similar whilst being different.
If was kinda rhetorical question. For sure, the answer is "for historical reasons". The point of `Maybe` is [representing a computation that can fail](https://www.reddit.com/r/haskell/comments/30s1t2/proposal_make_semigroup_as_a_superclass_of_monoid/cpvdco1/) and the above instance fits this purpose better. It is not healthy to have `Monoid` and `Alternative` instances for the same data type that behave differently.
a) short term: Haskell practice b) long-term moonshot: Dhall like language where you can make spreadsheet style calculations, data tables etc.
Thanks for the suggestion! But with my expertise at Haskell cannot appreciate this paper, I found it pretty complex. But get back to it, once I master Haskell! If possible please give me an abstract of what it does.
The first two chapters (introduction and background) can be read without knowing any Haskell. There's one short haskell snippet that demonstrates shake but you can safely skip it imo.
Looks nice, it this some kind of successor of `reflex-platform`?
[typed-spreadsheet](https://hackage.haskell.org/package/typed-spreadsheet) and [purescript-flare](https://github.com/sharkdp/purescript-flare)
Thanks for sharing, super useful! Will update the article to include a link
I think it uses `reflex-platform` internaly. From what I understood it is a skeleton and a few tools (init, deploy, build, ...). 
&gt;Quasiquotation that looks neat : \)
It depends on reflex\-platform internally and is a friendlier and more opinionated framework for building apps specifically. There has long been tension over the purpose of reflex\-platform and how batteries\-included it should be. Reflex\-platform really exists to make it easy to use reflex \(with nix overrides and tooling support\) but Obelisk tries to provide more solutions to the problems commonly encountered during app development.
That's a good point. My project is quite big but I haven't seen any problem yet (I only started using gitrev yesterday ...). At the moment I actually don't build my project often. I only use ghcid (which might be immune to this problem) and when I'm ready to deploy do a full build (in another directory). I like the idea of using sed on a binary though ;-), but if needed I'll probably just generate a version file using a makefile, as I build and deploy from a makefile.
You could use `Xmlbf.dfpos` from the `xmlbf` package to solve this: removeDivs :: Xmlbf.Node -&gt; [Xmlbf.Node] removeDivs = Xmlbf.dfpos $ \_ -&gt; \case -- If a node is a &lt;div&gt;, we remove it from the output. Xmlbf.Element "div" _ _ -&gt; [] -- Otherwise, we simple include it in the input. n -&gt; [n] Once you have converted your raw HTML to a list `Xmlbf.Node`s using something like `Xmlbf.XmlHtml.nodesHtml` from the `xmlbf-xmlhtml` package, you can use the previously defined `removeDirs` as follows: &gt; let htmlRaw = "&lt;a&gt;1&lt;/a&gt;&lt;div&gt;0&lt;div&gt;0&lt;/div&gt;&lt;/div&gt;&lt;b&gt;2&lt;div&gt;0&lt;/div&gt;&lt;c&gt;3&lt;/c&gt;&lt;/b&gt;" :: Data.ByteString.ByteString &gt; let Right htmlNodes = Xmlbf.XmlHtml.nodesHtml htmlRaw &gt; htmlNodes [Element "a" [] [Text "1"],Element "div" [] [Text "0",Element "div" [] [Text "0"]],Element "b" [] [Text "2",Element "div" [] [Text "0"],Element "c" [] [Text "3"]]] &gt; htmlNodes &gt;&gt;= removeDivs [Element "a" [] [Text "1"],Element "b" [] [Text "2",Element "c" [] [Text "3"]]] &gt; Data.ByteString.Builder.toLazyByteString (Xmlbf.encode (htmlNodes &gt;&gt;= removeDivs)) "&lt;a&gt;1&lt;/a&gt;&lt;b&gt;2&lt;c&gt;3&lt;/c&gt;&lt;/b&gt;"
Not the OP, but thanks for that detailed breakdown - helped me understand what exactly was going on behind the scene. I had trouble understanding how `id` satisfied the type `((fa -&gt; fb) -&gt; ((a -&gt; b) -&gt; y)` but working it out just like you did made it clear.
&gt; we prefer candidates from under-represented groups Wow, racial profiling in the open.
 It's sort of disingenuous to say that 'very simple resolution features lead to an NP-complete resolution algorithm', because sand-boxing and version bounds (which are fairly typical features of build tools these days) render it no longer an NP-complete problem, as discussed in this article. So, sure, if we take an extremely naive understanding of the problem space, it's a very difficult problem, but prior art has provided us with good tools to escape that tar pit. Also it does need to be stressed that not every package needs to have a list of 500 transitive dependencies - This isn't `npm` for goodness sake, we aren't animals.
What is "RFP"? Maybe typo of "FRP"?
Yes, that approach that should work well if you don't need the git version as part of your development, and if you can live with the production binary being slightly different than the development one.
Can I be honest? This seems like pissing into the wind. By that, I mean this decade hasn't been kind to Haskell. I was a heavy haskell user from about 2005 to 2012, and *still* the only major piece of software written in Haskell is ghc itself. For a medium sized company, you're better off just investing in the apache stack to do this kind of stuff (kafka/hadoop/hive/spark etc). The syntactic gains that Haskell give you aren't really all that helpful compared to what you get with a spark cluster and making good use of scala's type system. Plus, other people are using those things and you can find coders that have experience in them without moving heaven and earth. I would like to be wrong/corrected though.
If you want to be taken seriously, here are a few tips: 1. Don't post unrelated, unfounded and unsolicited criticism about the language on a *job posting*. 2. Don't claim to have several years of Haskell experience and then proceed to reduce the entirety of the language and its benefits to "syntactic gains", whatever that means 3. Stop giving unsolicited advice to people or companies about their choice of technologies. 
&gt; and still the only major piece of software written in Haskell is ghc itself You might want to reevaluate that claim. There a plenty of people doing "real" work and writting "real" software in Haskell every day. &gt; The syntactic gains that Haskell give you aren't really all that helpful compared to what you get with a spark cluster and making good use of scala's type system. In my experience, Spark does not deliver on its promises without considerable masochism on the part of the developer. Anyone with real familiarity with both Haskell and Scala's type systems will also tell you that Scala's is a joke in comparison.
not really, but why not just use 'map (fromMaybe 0)' ?
Didn't know about that function, big thanks :)
Yep, last module name. The type imported without qualification is just the one that matches the last module name. Right now `require` is quite rudimentary and only has this default behaviour, but it should be easy to extend. PRs are welcome :)
tl;dr: - `stack templates` has a lot of templates, and they're not well documented - there's some confusion about `hpack`'s `package.yaml` file as a default As much as I like `hpack`, I think making it the default was a mistake.
* [pdf](https://cs.brynmawr.edu/~rae/papers/2018/stitch/stitch.pdf) * [slides](https://cs.brynmawr.edu/~rae/talks/2018/stitch/nyc-stitch-slides.pdf) * [tar](https://cs.brynmawr.edu/~rae/papers/2018/stitch/stitch.tar.gz) (source code)
[currently have to look at the source to answer these questions](https://github.com/theam/require/blob/master/library/Require.hs)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [theam/require/.../**Require.hs** (master → f9485b3)](https://github.com/theam/require/blob/f9485b3a9b63f762b79f66f2b60361b21670cd91/library/Require.hs) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dzgnfvc.)
* *[16:04]* I always find this syntax in Haskell confusing, that we have terms right up next to types when we declare the datatypes but that's what we do.
wow, i love the engaging tone of this job posting and upfront info on your hiring process!
The post is actually nothing about composing derivatives or implementing backprop -- it's about the types of thinking you can do once you have backpropagatable functions. It's not really about the backprop itself, but about rather how it frees your mind to redefine how we think about programming, and how it allows you to dream of and think of new models and new types of models. So, the post isn't about "how" to backprop, it's more about what sort of thinking you can do and how it opens your mind, once you take backprop for granted and not have to think about it at all. In user-space, composition works like this: If you have a function from `R 10` to `R 5`: foo :: BVar s (R 10) -&gt; BVar s (R 5) And a function from `R 5` to `R 2`: bar :: BVar s (R 10) -&gt; BVar s (R 2) then you can compose them to get a function from `R 10` to `R 2`: foo . bar :: BVar s (R 10) -&gt; BVar s (R 2) And it works, out of the box :) You don't need to ever worry about carrying gradients or explicitly manipulating them ever. The post is about how this "you don't have to care" mentality aids in the creation and invention of new models. I don't implement several neural network architectures by ever composing any gradients, or manipulating any gradients manually. There is no special thing going on, i'm just defining normal functions and not even once mentioning or caring about gradients: myNetwork (w1,b1,w2,b2) x = z where y = logistic (w1 #&gt; x + b1) z = logistic (w2 #&gt; y + b2) You don't ever need to compose derivatives of functions. `gradBP` is only ever used to turn a `BVar s a -&gt; BVar s b` into an `a -&gt; a`. That's its type: gradBP :: (BVar s a -&gt; BVar s b) -&gt; (a -&gt; a) And you only ever should use it at the "end" of your pipeline. Basically, the process is: 1. Write your full function (using your model, etc.) to compute the error 2. Use gradBP on that function to get the gradient.
Ah, I didn't catch that. The problem is, `liftEADT` will rebuild all your data. I'm proposing having a safe function allowing zero-cost conversions when possible.
[removed]
&gt; As much as I like hpack, I think making it the default was a mistake. Agreed. Multiple times, I've had to deal with it missing a cabal feature or a buggy translation. It's a 100% unnecessary extra point of failure. Improve cabal, don't write new tools.
I thought that the example was clear enough. Will change it :)
I agree, the templates are more trouble than they're worth. I'm not sure what things should be allowed in the template repo, it is very hard to enforce consistency, and they are difficult to modify. We've known about these issues for some time which is one reason the templates repo is not very clean: * https://github.com/commercialhaskell/stack-templates/issues/55 * https://github.com/commercialhaskell/stack-templates/issues/56 In lieu of better answers to these questions, I'd be in favor of entirely axing the system &gt; So ghci doesn’t read the cabal config. If we replace Data.String.Strip with Lib. stack build is success full. No, ghci does read the cabal config. It just doesn't care if a module isn't listed. Unfortunately, it is a relatively hard problem to make "it loads in ghci" be equivalent to "it will build". It would be great to address this.
Your criticism about front-loading complexity is 100% valid, but this is, I feel, a completely solve-able ergonomics issue that could be avoided by a collection of sensible defaults and better docs. We don't actually need to use new tools, the stack day-to-day user experience isn't all that complicated, and what it's doing isn't profoundly difficult to understand. What we need is to commit to not making `hpack` the default new user experience (not that it's a bad tool, it just adds indirection without removing complexity), and we need an introduction to the `project.cabal` file format that's targeted at new users. IE, we need a better project template story out of stack and a `Learn you a Stack for Great Good` style intro for green programmers. Does anyone have the history behind project templates in stack? That features been listed as deprecated since I started, and my tentative research into it seems to suggest that whatever was supposed to replace it got bikeshedded to death.
How does this compare to the Reflex skeleton? I found that very straightforward to get going with.
This is a _tremendous_ tutorial. I hope others appreciate the immense amount of work you must have put into this! This is exactly the kind of resource a lot of people in the community need right now.
I've been a Haskell programmer for a long time but the web framework land still feels kind of overwhelming. Thank you for this, it will provide a nice starting place next time I have a web project \(usually I just try to do everything client side and cross my fingers, because I don't want to bother with node and all that\). Nice work.
`Cabal-the-library` has some intense constraints due to it's tight coupling with GHC. New tools are a great way to experiment and figure out things that we can import into Cabal if they're popular enough.
Imagine you're running an interpreter and you've got a list of the instructions. foldl will run the instructions forwards, foldr backwards. Commutative operations are fine, even associative ones are, but there's plenty of combining operations that aren't either. Subtract is a really obvious example.
How does a preprocessor interact with the tooling? I'm guessing it just breaks everything, right?
Would you accept junior devs who have studied Haskell, but haven't used it professionally?
I'd like this but drop the qualified keyword. "As" is really clear and is already an understood keyword in python, why add qualified?
Personally I'd prefer: import Purple.Monkey.Stevedore as Miller (Punch, Judy) or import Purple.Monkey.Stevedore as Miller ( Punch , Judy ) With the same usage.
hpack is great in 2018 and .cabal format simply needs to die. You can't possibly expect a new format for each new language ecosystem.
Hey, check out sparkle – it's almost production-friendly now.
[removed]
I could live with those, except we already have `import Purple.Monkey.Stevedore as Miller` and `import qualified Purple.Monkey.Stevedore as Miller`, and they've got slightly different semantics.
Hpack is just a preprocessor for the cabal file format, it can’t literally replace it. And it falls down hard when complex conditionals that yaml represents poorly come into play. Also the argument about syntax is specious. Might as well argue we should scrap idiomatic haskell syntax in favor of only braces and semicolons. After all, it’s 2018! Nobody can learn new things anymore!
&gt; is just a preprocessor for the cabal file format, it can’t literally replace it. Why not? There's no problem changing the frontend language. I haven't touched .cabal files for years now.
&gt; I would like to be wrong/corrected though Glad to hear it. You’re wrong.
Nice tutorial! This could be more complete if there was a section about testing, I guess :)
&gt; if any one, and this is a big “If”, actually wants Haskell to become more main stream, perhaps try making easier, slightly less-sound tools like cargo This is a fallacious tail-wagging-the-dog prescription. Haskell's package manager is not the reason that it's not a main-stream programming language. 
I don't really have an opinion on this issue at the moment. But I do have some thoughts / questions. Using a new syntax instead of an existing / well known one is always a tradeoff, in the case of Haskell it's absolutely necessary and worthwhile as no existing syntax was going to be good enough and over time deviation would have been inevitable. But I could see the argument for simpler things like cabal files that the extra benefit isn't enough to justify a brand new syntax. Is there a configuration language that could be used that is language agnostic \(like json or yaml\) that would easily support everything needed in a cabal file?
To be perfectly honest my experience with bundling / deploying stuff was pretty minimal prior to this project, I generally work on dev\-side / internal things, or web stuff. For Mac I am having trouble, I can't even get a basic stubbed out App to run a simple Haskell hello world app or even a shell script. When running it from terminal via `open` I keep getting `LSOpenURLsWithRole error 10810 ...`. I'm on MacOS High Sierra 10.13.3. If you know how to convert a simple dependency\-less Haskell binary to MacOS App and have it not break that would be awesome haha! Windows I think we finally figured out, just needed a bunch of DLLs! We haven't looked as much into linux as supporting it is not required for the course, but out of curiosity are there non package manager ways to deploy Linux apps. I'm asking partly out of curiosity \(as I assume games that people sell don't use pacman / yum etc. do they?\), and partly because if we did make a linux distribution I'm not sure we'd want to \(try to?\) steal a global name on any of those package managers. Thanks for the help!
Got it. Thanks.
In PureScript, purs-ide and editor tooling gives us automatic imports as we type (including qualification). That means I never have to worry about import clutter and can just ignore it. It just works as I type. It is such a vital part of my workflow, I don't remember where things exist anymore. I don't even know how to manually import anymore.
[removed]
As someone who loves yaml, but doesn't want the complexity of hpack/stack (I'll use nixos), does cabal intend to support a yaml file variant?
We would seriously consider such an application if the candidate could check off two other items on the list.
Thank you for the input, Mr. Allen. I'm a bit ashamed to admit that I forgot to use type synonyms for database type, which was already defined in this [commit](https://gitlab.com/ibnuda/Cirkeltrek/commit/ec1bf4968e06f43fe10aacb076a327571a4bceb1).
This is (probably) better Excel, but written in Haskell. Not released yet. And I don't know how much FRP they use there... * https://www.alphasheets.com/
Which exact tooling you mean? Personally I'm only interested in `ghcid`. If `ghcid` works than it's fine (didn't check it manually, but I suppose it should work). Other tooling doesn't matter because its broken anyway.
Yeah, this is really fantastic. Thanks for sharing so much :)
This is very thorough, and (from what I've seen so far) incredibly well written. Thank you for putting in all this effort! This deserves a link from the Yesod website.
That was the original proposal, but it got changed to the current instance. I am among those who consider that change a mistake, but we're stuck with it now.
While we are at it, I also think Haskell's idea of doing all IO inside a monad is making things difficult. Granted the monad interface gives some type safety and also makes some [esoteric things possible](https://stackoverflow.com/questions/6622524/why-is-haskell-sometimes-referred-to-as-best-imperative-language). Do not get me wrong I am a fan of the philosophy but get rid of IO monad and you will have [Infosys](https://en.wikipedia.org/wiki/Infosys) using Haskell in a week.
Common stanzas are a huge win for Cabal. Do you think there's any chance that cabal will get a "all modules exposed by default" mode? That's the other thing I like about hpack.
Here's an alternate proposal we were discussing, which would keep the modules explicit, but automate the _adding_ of the modules to the cabal file: https://github.com/haskell/cabal/issues/5306 The only real blocker to this, like many other things we would like, is a fully structure-preserving (including comments) exact printer for cabal files. Recent work has made this closer than before, but there's still a final mile to go, for anyone who wants to do it. I'm partial to orchard's reprinter (https://dorchard.wordpress.com/2017/09/20/scrap-your-reprinter/) approach to this problem, which bears similarity to the ghc-exactprint stuff as well.
There are no plans to support yaml directly. However, hpack can be used just fine with cabal as a standalone preprocessor (and that's how it was originally designed, in fact!). In this configuration it doesn't give any complexity tied to stack -- it just processes an hpack yaml file into a cabal file.
Tla, impressive
The design philosophy of cabal files is to prefer explicit to implicit, so I think this is frowned on. Remember that the file _on its own_ should be able to give significant metadata about the package. Using the glob syntax we have the problem that to discover what the _actual_ exposed modules are requires traversing the entire structure of the tarball, rather than just examining the cabal file itself. So it is worth having out in a discussion if you open a ticket to suggest it, but I suspect that as an approach it wouldn't meet favor. I personally don't think that having to type `cabal format update` or the like to refresh the list is such a burden. This is especially the case since cabal can now warn when there is a module missing anyway! (So, we could, presumably teach cabal to ask when it detects a missing module instead of just warning, or even let users who desire configure it to auto-update on its own).
&gt; And it falls down hard when complex conditionals that yaml represents poorly come into play. Got examples? From a cursory glance at the [hpack conditional syntax](https://github.com/sol/hpack#-conditionals), it seems like this would handle everything just fine. (Just a bit more verbose than the cabal conditional syntax in this case, which is ironic since hpack tries to be more concise.)
406 Not Acceptable?
The problem here is that you can't parody a programming language debate.
Would glob syntax be explicit enough? I agree with the explicit idea, but the fact that I can't at least opt in to implicit-ness is frustrating. Globs seem like a nice middle ground.
Here are a few issues that point to some of the warts: https://github.com/sol/hpack/pull/141 https://github.com/sol/hpack/issues/255
Honestly, I don't know. We do have globs elsewhere in cabal syntax, so this isn't entirely unprecedented, at least. Open a ticket and start a discussion :-) I'm a feature pushover, but lots of more frequent cabal contributors have more strongly held opinions, based on a broader sense of the constraints and end-goals than I necessarily am holding in my mind at this time.
Nice, thanks for the pointer. That ghc-options example is very interesting.
I'm sorry, but what? This decade has been fantastic for Haskell. Cabal hell has been vanquished, both by improvements to Cabal and by other tooling. Haskell's library ecosystem is getting better and better, particularly interop with other languages (see `inline-java` providing Java interop, and `inline-c`, `inline-rust`, `inline-r` for more). Haskell is being used by businesses of all sizes -- Facebook uses Haskell for their antispam system (something like 1M lines of code) and the `duckling` library/tool, GitHub is using it for code/language analysis. The commercial Haskell ecosystem is strong enough to support four consultancies (Well-Typed, FPComplete, Obsidian, Serokell) off the top of my head. It's still a small community, for sure (there are dozens of us -- dozens!), but it's growing at a rapid pace, and we're seeing Haskell in all kinds of places. Hiring Haskellers is relatively easy (especially if you're remote-friendly), and it's becoming easier to find Haskell jobs, too -- after all, my entire professional career as a software developer has been with Haskell :)
cool! I opened a ticket :) thanks!
Are stack and cabal know for being particularly *sound*?
I wonder, what would be a downside of just removing and `.gitignore`ing the `.cabal` file?
Does it support non\-reflex \(e.g. `miso`\) apps? For referenc`e reflex-platfo`rm \(despite the name\) supports them just fine. Regardless of your opinion on reflex vs other forms of front end web development, I think it would be best for the community as a whole for deployment tools to be relatively framework agnostic.
&gt; First, your recommended tool Stack First and foremost, it depends on whom you ask. There isn't any consensus about it otherwise these "$X does not work" and `(Stack &lt;|&gt; Cabal &lt;|&gt; Nix)` discussions wouldn't have become such a favourite pastime in the community.
[43:52](https://youtu.be/XJ8hm3Tq2k8?t=43m52s) Why don't we have the Exists-Operator in Haskell? One of the long-standing questions for me, since forall is so prevalent. Just because it's less useful? Or is there a deeper reason?
&gt; type Inventory = HM.HashMap Text Item Assuming HM is a qualified import to HashMap. https://hackage.haskell.org/package/hashmap says its deprecated. Can I just use Map? What am I missing?
I can propose solution to `stack` templates. Our organization works on tool called `summoner` which allows you to create projects interactively. This tool uses `stack` templates feature. Basically, instead of having predefined huge set of templates you can configure different parts of template interactively. Not everything that we want is finished, but we're planning to announce `1.0.0` release soon. * https://github.com/kowainik/summoner
It'll be http://hackage.haskell.org/package/unordered-containers
`IO` is a lovely feature and I've yet seen anyone propose a better solution for purity. It's not going anywhere. You are free to check out OCaml/ReasonML.
&gt; (Well-Typed, FPComplete, Obsidian, Serokell) off the top of my head. There are a lot more than that, they just don't show up on the subreddit as often! A few more off the top of my head are tweag, stackbuilders, and position. And I suspect there are plenty more too that I haven't encountered or just don't remember at the moment.
Answered [here](https://github.com/matijapretnar/eff/issues/53).
`ghcid` works fine. My emacs syntax checker seems to complain sometimes (yes, sometimes, really), but it also crashes often, so I'm not that concerned.
This is true. PS hase some really great tooling, but also nice imports heh
Yes! Frankly, I've never used monads, and I've never missed them.
Would you consider a candidate for the part-time position? 
&gt; New tools are a great way to experiment and figure out things that we can import into Cabal if they're popular enough. &gt; [...] many of the new features in cabal's file format seem inspired by hpack. Agreed. 
&gt; Monoid can be used and is often used to lift an inner monoid through a context. What examples do you have besides that Gabriel's `IO` example (which, I admit, is nice, but still is used by no one)? Very commonly we have that `&lt;&gt;` either extends a data structure or, when it's not possible to extend, chooses elements from a left operand. This is how `base` (`[]`, `NonEmpty`, `Either`!) `containers` (`Set`, `Map`, `Seq`), `unordered-containers` (`HashMap`, `HashSet`). And then comes `Maybe` which is a 0-1 elements container, but suddenly decides to lift a monoid contrary to even what `Either` does. With such `Maybe` you [can't even say](http://reasonablypolymorphic.com/blog/follow-the-denotation/) the denotation of a `Map k v` is `k -&gt; Maybe v` which is far from being obvious. The current instance is nothing, but a bug (I do not propose to change it, though, as it would break quite a lot of code in a very subtle way).
I wonder how much is due to the fact that people who care about that stuff don't see the point in adding such operator. This annoyance does have the merit of making it obvious that context change is a form of type level "effect"
Thanks for this! The implementation was rushed, and the idea is to switch to a parser combinator library ASAP :)
&gt; The only configuration language I know of designed specifically for that purpose is dhall :-) And Nix.
I've got working autocomplete, live error checking (that actually shows me where the error is in my code), go to definition...
but it's not trivial? The law of excluded middle does not hold, so the usual formulation `exists x. p(x) &lt;=&gt; not(forall x. not (p(x))` is not true. I think the compiler get's quite confused with the "correct" encoding
Stack was designed to “play nice” with cabal. Had ‘stack.yaml’ replaced the ‘.cabal’ file, the situation would had been simpler.
&gt; I don't agree with that. It's just a nullable value. Values can be null for many reasons, including failure. I often use `Maybe` just to represent values that are not configured (because they don't have to be). OK, this is true. Failing computation is a form of more generic "nullable value". But how often do you want to compose nullable values using `&lt;&gt;`? I usually want the first non-null value. Sometimes I do want to compose them, but what I really want is to be able to change `Either () a` to `Maybe a` and vice versa and not break my code in a very subtle way.
So instead of just typing and seeing squiggly lines _right there_ in the code, you look into another window, parse the output to find the line number, then manually type that number into your editor. Then when you get there, what? Look at the code listing in ghcid to figure out where in that line the error actually is? It's incredible to me that anyone who ever had error reporting in-editor would think what you described as an acceptable workflow. 
This is from one of [Richard's comments](https://www.reddit.com/r/haskell/comments/4amov2/the_future_of_dependent_haskell/d14xtjs/?context=0) &gt; After that, I'm really interested in taking the fantastic usability of LiquidHaskell and seeing if dependent types can be made as easy-to-use. A key step along this path is lightweight existentials, allowing you do use `exists x. ...` in a type as easily as `forall x. ...`. Note that a refined (as in "refinement types", which are the basis for LiquidHaskell) result type of a function is really an existential.
True. This is the deep reason you were looking for, my bad. But the point still holds : how much is due to a form of acceptance from people who care about that ? How much does it itches ? Just like we do not have the law of excluded middle in the intuitionistic, cartesian context, we still have something that behave like it in a richer context of some non-cartesian, monoidal closed structure. It might still be useful to have some "exists" operator, in a more loose context, notably for casual users... or for expressing more things ;)
&gt; Cabal-the-library has some intense constraints due to it's tight coupling with GHC. This is strange to hear because, nominally at least, `Cabal` supports every Haskell compiler like UHC and Hugs and all manner of compilers you and I have never heard of. In fact having looked a bit a the codebase there's a lot of complexity in there *specifically* to support a wide array of compilers. Can anyone chime in on what the state of things is? Is it really no longer feasible to use cabal with other compilers? If so we could nuke a lot of old code in there.
It was a joke.
Had `stack.yaml` replaced the `.cabal` file then they wouldn't have been able to use cabal-the-library for building.
Ok, I didn't get that. I already saw this kind of thing that posted quite a few types unironically so I thought this was the same thing. My mistake.
I think you're not the only one!
&gt; it just adds indirection without removing complexity Just thought I'd highlight the point in your reply which resonated with me - pretty much my feelings on `hpack` as a default in a nutshell. 
Too much humor, not easy to see what is actually to fix.
The left-biased implementation of `Monoid` for `Map` and `HashMap` has been criticized for years: - https://ghc.haskell.org/trac/ghc/ticket/1460 - https://mail.haskell.org/pipermail/libraries/2012-April/017743.html - https://www.reddit.com/r/haskell/comments/52swd2/better_map_monoid_resolve_collisions_with_vs/ - https://mail.haskell.org/pipermail/libraries/2017-May/028036.html - https://mail.haskell.org/pipermail/libraries/2014-May/023045.html - https://github.com/haskell/containers/issues/539 Recently, the maintainer for `containers` has [considered changing these](https://mail.haskell.org/pipermail/libraries/2018-February/028519.html), but no decision has been communicated on this. Other things from base that lift an inner monoid through a context: several flavors of tuples, `(-&gt;)`, `ST`. Such a `Monoid` instance for `ReaderT` has received [support on the mailing list](https://mail.haskell.org/pipermail/libraries/2017-November/028312.html), and it would be useful for me in practice.
Oh, thank you for these links, somehow I completely missed that discussion. I thought that since the usual way to write `Monoid` instances (matching the `Alternative` instance when one exists) is common, it should be the default everywhere, but since people want to move from such practice, I need to reconsider my position. There is a bug somewhere anyway as instances for `Either () a` and `Maybe a` really should match, but I'm no longer sure that the bug is in the `Maybe` instance rather than the `Either () a` one.
I've tried to open the page on Firefox 52, Firefox dev. edition, Chrome 62 on Linux, Firefox 52 on Windows, Chrome and Firefox on android from 3 different IPs and couldn't reproduce the error. Could you please clean the cache, Mr. Jaguar? 
I thought the mention of Infosys would have given away the intention but looks like it works only in the Indian context.
I'm pretty sure its true for any software that any bump in the road to getting start will lose you users
They could: * Not use it * Generate a temporary ‘.cabal’ file from the ‘stack.yaml’ and use it * Use other apis of the library if such are available (if it has an interface other than getting an input file)
&gt; Clueless, J., Itworks, H.: 101 dubious ways to improve your h-index. In: Proceedings of the 1901 Conference on Unlikely Ways to Get Ahead (CUWGA 1901), January 1901
It'd be be nice the if cabal library didn't need to get that information in a file...
I suspect if they could have not used cabal-the-library they would. It's lot of work to reimplement the functionality of cabal! Perhaps you can clarify what you mean by "playing nice". Both generating a temporary `.cabal` file and using other APIs (which I don't think exist) seem reasonably nice to me.
It would
By “playing nice” I mean that they didn’t try to compete with cabal. They make their users create ‘.cabal’ files so cabal still works with everything (modulu bugs and “cabal-hell”).
1. Very few use other open-source Haskell compilers (some companies use their own private compilers). Even the issue on the topic is somewhat dead (https://github.com/haskell/cabal/issues/2714). OTOH, even if other Haskell compilers are smaller projects, some are maintained. 2. One example of constraints due to the coupling is that there's a very high bar for adding dependencies to `Cabal`-the-library: GHC depends on Cabal and all of its dependencies, and they're "sort-of re-exported" to users*, so it's pretty hard to add a new dependency. IIRC, new dependencies would also become part of the bootstrap process, together with their transitive dependencies. *I forget details, but if GHC X.Y ships with Cabal CX.CY and foo-lib FX.FY, it is (or used to be) hard to write apps depending on other versions. Especially if they also need to link with Cabal (which happens and for good reasons, and not just for Stack). I forget which tools have which bugs in this scenario, but IIRC that's been a concern for a long time. Nowadays, luckily, installing a newer Cabal tends to work well.
Yeah, the `Semigroup` and `Monoid` instances for `Either` are strange. I'm not really sure what they should do though. Currently, we have: instance Semigroup (Either a b) where Left _ &lt;&gt; b = b a &lt;&gt; _ = a We could do the `Applicative` thing that Gabriel uses: instance Semigroup b =&gt; Semigroup (Either a b) where (&lt;&gt;) = liftA2 (&lt;&gt;) instance Monoid b =&gt; Monoid (Either a b) where mempty = pure mempty But, `Either` has another applicative instance that's provided for a type called [`Validation`](http://hackage.haskell.org/package/validation-1/docs/Data-Validation.html). If we base our instances on this `Applicative` instance instead, we get: instance (Semigroup a, Semigroup b) =&gt; Semigroup (Either a b) where Left x &lt;&gt; Left y = Left (x &lt;&gt; y) Left x &lt;&gt; Right _ = Left x Right _ &lt;&gt; Left y = Left y Right x &lt;&gt; Right y = Right (x &lt;&gt; y) instance (Semigroup a, Monoid b) =&gt; Monoid (Either a b) where mempty = Right mempty Either of these two option agree with the `Monoid` instance for `Maybe` in the since that the `Monoid` instance for `Maybe a` and the one for `Either () a` do the same thing. I like the second one better, but the non-error-combining behavior first one is more consistent with the way `Either` is used in base.
My apologies I should have been more clear that while we do support some part-time people we are looking for someone who can commit to a 35-40 hour work week at this time. However I'm always happy to keep people in my contacts list if the opportunity for a part-time position pops up.
Conclusion footnote: &gt; We also admit that “to the best of our knowledge” really means “we haven’t the faintest idea and don’t want to do any research into the matter”.
I, too, look forward to the day when I can just stick {-# LANGUAGE C #-} at the top of my modules and get back to work, already! /s
Being a longtime Scheme and Lua developer I always chuckle at these kind of posts...
Fair enough.
I've also opened a trac ticket [here](https://ghc.haskell.org/trac/ghc/ticket/15182).
Okay, so in 2016 [Philip Wadler](https://en.wikipedia.org/wiki/Philip_Wadler) turned 60. The University of Edinburgh School of Informatics [held a conference in honor of his birthday](http://events.inf.ed.ac.uk/wf2016/). This was one of [the papers accepted to the conference](https://link.springer.com/book/10.1007%2F978-3-319-30936-1). Most of the papers appear to be tongue-in-cheek to some degree (e.g. [the one where Simon Peyton Jones implements dynamic typing in Haskell](https://link.springer.com/chapter/10.1007/978-3-319-30936-1_16)), though I confess there were a few for which a short skim did nothing to tell me what they were really about. This paper appears to be the most WTFy, though.
**Philip Wadler** Philip Lee Wadler (born April 8, 1956) is an American computer scientist known for his contributions to programming language design and type theory. In particular, he has contributed to the theory behind functional programming and the use of monads in functional programming, the design of the purely functional language Haskell, and the XQuery declarative query language. In 1984, he created the Orwell programming language. Wadler was involved in adding generic types to Java 5.0. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Glad to see more Canadian companies adopting Haskell!
Doesn't open for me from Ukraine, unfortunately. ``` $ curl -v -i http://siskam.link/2018-04-14-cloning-fluxbb.html * Trying 45.127.133.99... * TCP_NODELAY set ^C $ ping 45.127.133.99 PING 45.127.133.99 (45.127.133.99): 56 data bytes Request timeout for icmp_seq 0 Request timeout for icmp_seq 1 Request timeout for icmp_seq 2 ```
It's still a work in progress that I've kept private for now, I'm sort of on step 2 of a 5 step plan. I'm not committing to anything in the implementation. However, people often ask about implementing Haskell and compilers. Duet's implementation is simple enough (based on Typing Haskell in Haskell) that it might be helpful. It supports data types, type-classes (but not superclasses), has a substitution stepper for running code (as seen in the demo web pages), etc. 
There is already an operation like your proposed castVariant: `appendVariant` \(\~unsafeCoerce\). There is also the similar `prependVariant` \(simple tag incrementation\): &gt; v = V 'a' :: V '[Char,String] &gt; :t appendVariant @'[Int,Float] v appendVariant @'[Int,Float] v :: Variant '[Char, [Char], Int, Float] &gt; :t prependVariant @'[Int,Float] v prependVariant @'[Int,Float] v :: Variant '[Int, Float, Char, String] 
Because they have different design goals. `project.cabal` plays double duty as build instruction and package manifest / metadata, `hpack` yaml can't handle that because it allows for descriptions that would be too 'fuzzy'. So you can't really make `hpack` the default without removing a necessary featureset the ecosystem depends on unless you defeat the point of `hpack` altogether and get rid of all it's nice features built around ease of use and default behaviors. BUT That's not the same thing as saying a `yaml` file of some kind can't replace `project.cabal` - But I think that'd be a bad plan, as the featureset of `yaml` is a bad fit for this purpose. Templates and conditionals, etc, don't belong in the canonical format for a build system, it introduces a ton of complexity where it doesn't belong. 
I'm not familiar with that package either and it is quite large... Briefly looking at the [Compositional data types](https://www.researchgate.net/profile/Patrick_Bahr/publication/228841104_Compositional_data_types/links/09e415056f0d9cee41000000/Compositional-data-types.pdf) paper, it seems that we can easily implement some of the things mentioned in the Future Work section with my approach. In particular I've just implemented the speculated "project" function with the proposed type \(I've called it [popEADT](https://github.com/haskus/haskus-utils/blob/bb9b64ff09d9e80639fbd001ad0e7657f902e03d/src/lib/Haskus/Utils/VariantF.hs#L172)\). It allows us to perform complete case analysis, e.g.: showMulAddValADT :: MulAddValADT -&gt; String showMulAddValADT e = case popEADT e of Right (ValF u) -&gt; show u Left w -&gt; case popVariantF w of Right (AddF u v) -&gt; "(" ++ showMulAddValADT u ++ " + " ++ showMulAddValADT v ++ ")" Left z -&gt; case variantFToValue z of MulF u v -&gt; "(" ++ showMulAddValADT u ++ " * " ++ showMulAddValADT v ++ ")" &gt; v = Mul (Add (Val 2) (Val 3)) (Val 5) :: MulAddValADT &gt; showMulAddValADT v "((2 + 3) * 5)"
Okay. The second page will be my next phone-wallpaper.
Sorry, "general purpose configuration language". Nix is a single purpose configuration language, for describing nix derivations afaik :-)
Been an IntelliJ user for some time, what chshersh describes doesnt seem much of a problem for me as a workflow
I like it! Are you going to support going backwards eventually? It'd be cool to interactively be able to step either forwards or backwards in time while watching the evaluation happen.
&gt; To the best of our knowledge we are the first to ever make such an admission.
Here's a historical link to the [GHC Wiki: ShorterImportSyntax](https://ghc.haskell.org/trac/ghc/wiki/ShorterImportSyntax). Every form of bikeshedding you can imagine is available via that link.
You're welcome :)
Using the new version of indexed-list-literals you could do this. safeReplicateM :: (Monad m, ILL tuple length a, KnownNat length) =&gt; len length -&gt; m a -&gt; m tuple safeReplicateM _len = fmap fromList' . replicateM length where length = fromIntegral $ natVal _len test = do (a,b,c) &lt;- safeReplicateM (len @3) action (d,e) &lt;- safeReplicateM (len @2) action pure () It encapsulates the unsafety quite nicely. The only annoying this is I can't infer the length from the tuple type because the length, while inferable, isn't an instance of KnownNat
Using the new version of indexed\-list\-literals you could do this. safeReplicateM :: \(Monad m, ILL tuple length a, KnownNat length\) =\&gt; len length \-\&gt; m a \-\&gt; m tuple safeReplicateM \_len = fmap fromList' . replicateM length where length = fromIntegral $ natVal \_len test = do \(a,b,c\) \&lt;\- safeReplicateM \(len @3\) action \(d,e\) \&lt;\- safeReplicateM \(len @2\) action pure \(\) It encapsulates the unsafety quite nicely. The only annoying this is I can't infer the length from the tuple type because the length, while inferable, isn't an instance of KnownNat
At this point `obelisk` is opinionated and focuses on reflex-dom. The goal is to get you up and running in minutes with everything you'd need for a production web and mobile app.
Anonymous testimony. I'm convinced.
Obelisk has its own skeleton that is inspired by Will Fancher's skeleton. Obelisk's is more opinionated however and will grow along with Obelisk as more and more "batteries" come with it.
Correct. The goal is to add more and more "batteries" here. Several are in the pipeline already.
What's the official JSON representation of "^2.x.x"? It's just a string. ALL implementations of this process use custom syntax and custom markups, because there isn't a general purpose markup language that can express the concepts of PVP / Semver version bounds, or any of the other meta data you might need to build a dependency resolver. Those custom markup concepts are usually just buried under magic strings or magic properties/tag names instead. Was this file format actually difficult for you to learn or understand when you first started? I suspect not, as visually and conceptually it's much simpler than YAML anyway. 
what's the hpack solution to if-then-else statements and such?
But... but... Haskell programmer is underrepresented group.
That makes sense, thanks! Do you think some of the non\-opinionated features of obelisk will make it back into `reflex-platform`? For example it being an installable dependency that doesn't require git submodules, and maybe the` ini`t,` ru`n stuff. Does this somewhat replace` try-refle`x at all? One final question is if you think either of the projects will end up in OS package managers like brew and apt\-get / in nixpkgs?
&gt; What's the official JSON representation of "2.x.x"? Does this really matter? There's no difference between .cabal and hpack in this regard. If I get syntax wrong stack will complain – and I will fix it. &gt; Was this file format actually difficult for you to learn or understand when you first started? No but I remember a great feeling of relief in the team when we could just switch to YAML: - easy multi-line strings; - clean multi-line lists with no comma cancer (.cabal syntax is not even streamlined here – `build-depends` uses commas whereas `exposed-modules` does not); - all alignment works out of the box in my Emacs; - I can use anchors and references to share common keys among executables. &gt; visually ... it's much simpler than YAML anyway. Sorry but I don't see how.
&gt; hpack yaml can't handle that Why? I've seen plenty of packages in the wild using `hpack` just fine.
FRP seems incredibly powerful, but the one thing that I am nervous about is causality loops, Excel for example handles them quite gracefully. It seems as though you should be able to do the same in an FRP framework, where the causality loop is shown as a nice error message with the code locations of the loop, it would be cool to go even further and add additional primitives that are "allowed" to loop, and return a `Left` that contains loop information when such a loop occurs.
`obelisk` will almost certainly end up in `nixpkgs`. I'm not sure about other package managers since `obelisk` actually requires nix for its own operation. (More likely is an install script that sets up nix for you and installs with that...). Re: obelisk features going into reflex-platform. Yes I think that's the hope actually. Things that prove very useful and general in obelisk can upstreamed into reflex-platform in a way that is not as opinionated. Or they may just end up on Hackage... ;)
You don't see how because you're deliberately limiting yourself to a subset of valid YAML syntax. YAML is a rathole full of complex conditionals and references. Full YAML support is a nightmare. `hpack` generates a good cabal file with sensible defaults - But generating with sensible defaults is not as awesome as consuming with sensible defaults. If we switched the ecosystem over to `hpack`, we would need to replicate, precisely, and formalize all of hpack's default assumptions into anything that parsed that YAML, which means we'd be taking an ecosystem that has an explicit, purposeful declaration of behavior in it's markup, and replacing it with a bunch of bullshit magic behavior and also full support for all of the complex conditional and referential behavior introduced by the enclosing markup, YAML. I'm not a fan of this plan, and would go so far as to call it a stupid plan that is bad. If we wanted to actually replace the cabal markup with something else, sure, why not, as long as it's just as easy to use and understand. But it shouldn't be a markup language that supports references and conditionals, and it shouldn't have a bunch of implicit behaviors. 
Search for lambda man on youtube. It will still be wtf but at least then you know where it comes from.
I'll non-anonymously say that it is indeed a great team to work in!
Hmm, what would better docs / user guide look like? They seem decent to me, but then again I know the internals of stack quite well, and know how the docs are organized. Documentation is hard, it is a special skill to write docs that are great for non-experts when you are an expert. When y'all encounter confusion or non ideal docs, it would be great to open PRs that improve the docs.
I definitely think that we could have use for some better defaults (which error messages that should be enabled by default), especially unfortunate that stack templates is sorta in limbo at the moment. I mean, "There are plans to change the way Stack templates are done in the near future. Therefore, the project is not accepting new templates at this moment.", and the plans started two years ago, although it seems it recently got revived. My own main gripe is that the editor tooling, while often working, just breaks down every now and then, and the on-boarding story is still not perfect (when you have to compile the linter yourself, especially with all the haskell deps, then we need to do better). For example, if anyone has experience making fully self-contained static binaries for hie, that could go a long way for helping people set that up.
They have one, it's verbose.
&gt; Lambda Calculus can be used to easily ... guarantee Scottish independence Yass :)
Get your freq on
Yes I have defined it as `appendVariant (Variant t x) = Variant t x` and the STG CSE pass transforms it into a no\-op :\)
Very cool! I was thinking about making a website where you type a string and it tells you how good your pseudorandomness is. Is that something this library would be able to do?
Yes, I think so, you would need to find good training data for that purpose. I'm not sure off the top of my head, but there might be a better way to do this for numbers. Oh, yeah, there's a simple thing you can do with hmatrix called a linear hadamard spectral test, that might be better.
[https://en.wikipedia.org/wiki/Spectral\_test](https://en.wikipedia.org/wiki/Spectral_test)
[https://github.com/chessai/hadamard/blob/master/Hadamard.hs](https://github.com/chessai/hadamard/blob/master/Hadamard.hs) this is a simple thing i did when i started thinking about this, i meant to come up with a full implementation at some point, but never did
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [chessai/hadamard/.../**Hadamard.hs** (master → ba2d28e)](https://github.com/chessai/hadamard/blob/ba2d28e1f2085bb08be569505f3343135a87149f/Hadamard.hs) ---- 
OMG the references.
Cabal's coupling (as well as haddock's) is a HUGE problem for the ecosystem. GHC should just include a private copy of Cabal inacessible by the user instead of pinning the version for a compiler release. I don't know why that's not done.
Have you seen [https://www.alphasheets.com/](https://www.alphasheets.com/) at all?
You mean like a graphical app and stepping back in the state automatically updates the display ala Elm or some React impls? If so, yeah.
and then i freaked it
I think https://arxiv.org/abs/math/0504334 still has the better title.
I literally just spent the past 4 weeks dealing with another flavor of this issue migrating between less explicit to more explicit build systems with separate markup concepts and separate ideas of dependency resolution and magic behavior. I'm still neck deep in that pit. Explicit manifests with a fixed format matter. Ecosystem fragmentation matters. Decreasing the authors time investment by like 10-15 minutes per project (or, probably, a whole lot less) to list out a couple variables that seem obvious to them at the time - That doesn't matter. Reconstructing what seemed obvious to the author after the fact can be an incredible pain in the ass. Luckily hpack already outputs a great file format for built specifically for this exact purpose, so, that seems like an awesome happy medium for everyone, and the guy who wants to try to figure out what the hell you were trying to build 10-15 years from now long after you left is going to be really happy that's the case.
&gt; John Clueless and Hope Itworks
I just write `cookiecutter` templates. I'm not sure why people seem to think everything needs to live in one god tool.
Agreed!
You wrote docs? Something smells fishy
What does your set of topics look like right now? I could make a list for what I think the typical Haskell beginner should learn, but it sounds like you already have specific things you want to focus on.
You might be more interested in [Software Foundations](https://softwarefoundations.cis.upenn.edu/)
Hmm. I don't know about a good order for studying Haskell topics - honestly, you could probably pick up any introduction book, learn the basic syntax, and then skip around to the parts you find interesting. Maybe look at [this exercise set](https://github.com/data61/fp-course) as well. I'd also recommend checkout out dependently typed languages like Idris and Agda. From your description, you'll probably find them interesting.
Thank you so much for this! I almost forgot about it, I remember finding it some time ago and saying to myself I should definitely come back to this when I know a bit more. Now seems a good time for that. Thanks again!
You can maybe start by using the resources recommended by Upenn for haskell beginners: www.seas.upenn.edu/~cis194/fall16/resources.html
Thank you, I'll have a look at that.
Alright, thank you. But for theoretical prerequisites, would you recommend something in particular? My tentative plan is to start with Martin-Lof’s Intuitionistic Type Theory to get used to intuitionistic logic and then Simon Thompson’s Type Theory and Functional Programming to be a good overview on lambda calculus and type theory. I simply cannot find a good “type theory 101” without either going way back to Russell and Ramsey or dive deep into Church’s lambda calculus.
I think /u/dantheodor linked it, but here it is again http://homepages.inf.ed.ac.uk/hleather/publications/2016_lambdacalculus_wf.pdf :)
Hello! No it's one I need myself, so it's already in there, pinned to the correct version. Without pinning it nix supplies the wrong version and the project wont build at all.
Thank you, I was recommended both Pierce's and Harper's books some time ago when I started out, but they did not seem quite beginner-friendly at that time. Now, when I'm looking through their contents again, I think I have a better understanding. Thank you for your course's page as well. It's always useful to see a subject unfolding with the intention of being taught.
The HoTT book (at least the early chapters) is quite readable for somebody with your background, and it starts with an introduction to (dependent) type theory. In my experience it helps if you keep the dictionary (from the introduction) in your head: * type = space * function type = space of maps * type family = fibration * sigma type = total space of a fibration * pi type = space of sections * etc Lambda calculus is a formal system describing computations. λx. x*x+2 simply means the function x ↦ (x^2 + 2). (It's an old syntax). There are many flavours: untyped, simply typed, etc. Haskell and other (typed) functional languages are based on lambda calculus (and some version of type theory). 
If you want to work with permutations in Haskell, the [Permutations module in the combinat package](http://hackage.haskell.org/package/combinat-0.2.8.2/docs/Math-Combinat-Permutations.html) could be also useful
Hunh, that's a bit weird. I'm on 8.0.2, so I guess it's possible it was introduced and fixed, but kind of unlikely. Thanks for looking into this, I might try to explore a bit more at some point. &gt; Side note: `fromOnly` is not a constructor but a field of `Only`. Yes indeed, thanks.
Thank you for the details! I tried to read the first part of the HoTT book, but I found it missing some kind of foundations. I generally like to see how subjects evolve and I'm usually not convinced by approaches which start with many primitive concepts. For this reason, I tried starting with Martin-Löf's Intutitionistic Type Theory, which has also the advantage of making historical and philosophical connections that I enjoy. I don't know whether I should go back directly to the HoTT book after Martin-Löf's or try to mix in some computational subjects as well.
You might find Girard's [Proofs and Types](http://www.paultaylor.eu/stable/prot.pdf) a good resource for some of the theory behind functional programming and the connection to logic. Barendregt's [Lambda Calculi with Types](http://ttic.uchicago.edu/~dreyer/course/papers/barendregt.pdf) is a useful (if dry) resource for understanding type systems. I think that these can provide some useful context from a CS perspective to [The HoTT Book](https://homotopytypetheory.org/book/), though if understanding HoTT is your aim then you might start with that book and chase up topics where you need more background.
Drawing from all the great answers I got, I thought of writing my (preliminary) conclusions and intentions. - For an *introduction to intuitionistic logic*, which has also the advantage of being one of the first, historically, I think I will start with Per Martin Löf's [Intuitionistic Type Theory*](https://intuitionistic.files.wordpress.com/2010/07/martin-lof-tt.pdf); - Simon Thompson's [Type Theory and Functional Programming](https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/) seems also a good place to start, as it does not go deep into details, but gives the reader enough information to get the basic ideas and figure out what do study next at a deeper level; After this, I think I will have a better overview on the core subjects and perspectives and may continue either with the Software Foundations, or Pierces TAPL or Harper's PFPL or a combination of them. I'll always keep a close eye on the HoTT book, to see when it starts to make better sense. :)
Thank you. Girard's book seems a good and compact resource, I agree. Barendregt's book is much too dry for my use, at least at the level I find myself now. As for the HoTT book, I feel the need for more background which I'm trying to get, both mathematically (especially in terms of type theory and intuitionistic logic) and computationally (Coq, maybe, would be a priority). But yes, I'll be keeping a close eye on it and hopefully, slowly but surely, would advance through it.
Actually, I don't have incremental recompilation issue because I'm using version 1.2 which doesn't watch anything. I thought it worked but it actually doesn't :-( ...
The first chapter of the HoTT book basically describes Martin-Lof type theory (the notes itself say "The type theory presented here is a version of Martin-Lof’s intuitionistic type theory"). But of course it can be useful to have different sources and different styles of presentations.
Starting with Martin-Löf type theory is good, as it seems to be the basis of the type theories most widely used today, with the addition of type universes. I don't know the other book. (Actually I know very few references because I've been diving into type theory just recently, and most of the stuff I've learned in ad-hoc seminars, and I'm a programming major, not math.) I only know one introductory paper for HoTT but sadly it's not in English. You could check out [this repo](https://bitbucket.org/akaposi/agdaoktatas/src/master/), which is for a basic Agda/type theory course and in English. It gives an introduction on "propositions as types", which is basically type theory, but you also get to formalize it in a programming language. One thing you could also look out for are sources which give type theory a model in category theory if you're more familiar with that. As for your learning path, there are probably a lot more resources to get started with Haskell, but as soon as you're used to the syntax, you might want to check out Idris for a real dependent type theory, where the same "propositions as types" thing works like in Agda. I hope this helps somehow :)
Yes, I know it's basically the same thing. I just happen to like much more Martin-Löf's exposition. I also take glances to the historical and philosophical development every once in a while.
Thank you, any comment is helpful somehow. :)
Thank you, I will certainly check them out.
Why not couple theory and practice, in your case, programming? It’s a great way to build intuition and understanding of the theory at hand.
I would certainly do that and in fact, my intention is more in this direction. But I don’t know exactly how I should go about it, as the Haskell books I know have programming exercises that are not very theoretical. For example, I know of a C++ book for mathematicians, where every exercise and problem is a mathematical theorem or some kind of result. :) Of course, it’s not mandatory to go this way, but I have very little motivation in learning Haskell (or any programming language, for that matter) by doing exercises full of graphs, stacks, arrays etc. I may be wrong in this approach, but it never proved efficient enough for me. Maybe that’s why I’m in this situation now. :) What would you suggest, for reference and practice, how would you work your way?
I think [Why Functional Programming Matters](http://www.cse.chalmers.se/~rjmh/Papers/whyfp.pdf) is always worth a read. 
I often wish that I could have a Deps.hs that does qualified imports and can be imported into my other modules. If require could do that more efficiently and better than using cpp includes, that could be a real win.
I was able to google a few of the papers by title, most if not all of them are publicly available somewhere.
I would probably suggest starting with Pierce's TAPL. I've heard nothing but praise for how it's a fantastic introduction to type theory in general \(especially for someone who has enough mathematical maturity to handle proofs and squiggly symbols on the page\). Then you should be able to practically skim through Löf's book and both Thompson's and Harper's books will be immediately relevant. \(on a tangent; I've seen some Agda and Idris talk in the thread. \[This\]\([http://oxij.org/note/BrutalDepTypes/](http://oxij.org/note/BrutalDepTypes/)\) seems to be a fairly comprehensive path to getting started with Agda, which will be good if you want to dive off the deep end into learning more advanced Type Theory\)
I'm under the impression that you're not really interested in general programming but rather constructive mathematics and proving things in them. If that is true, you'll probably be better off learning Adga or Coq as they lean on the side of theorem provers. You may find the following and the references contained in it interesting: http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf https://faculty.math.illinois.edu/~dan/Papers/ium.pdf They're also full of references that you may find interesting. So, the basic approach is start constructing some proofs in either Adga or Coq. There are implementations of parts of HoTT in either language that you may find interesting too. 
We are actually working on that. Stay tuned! :D
I believe the way you encode existential quantification in Haskell is: exists x . P(x) &lt;=&gt; forall r. (forall x . P(x) -&gt; r) -&gt; r ... and the compiler handles that correctly
yeah, I know this variant. That's how it's working in singletons, but that's quite unwieldy. 
Thank you so much for all the great resources! I will definitely check them out. I tried going through Lambek and Scott's [Introduction to Higher Order Categorical Logic](https://github.com/Mzk-Levi/texts/blob/master/Lambek%20J.%2C%20Scott%20P.J.%20Introduction%20to%20Higher%20Order%20Categorical%20Logic.pdf), but the approach lost me a bit, in spite of the fact that the ToC seems to cover subjects of great interest. Clearly my category theory background needs not only a bit of update but also some "translation" work. :)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Mzk-Levi/texts/.../**Lambek%20J.%2C%20Scott%20P.J.%20Introduction%20to%20Higher%20Order%20Categorical%20Logic.pdf** (master → 34916d6)](https://github.com/Mzk-Levi/texts/blob/34916d6531af9bc39e50b596247ac2017d8cfdc3/Lambek%20J.%2C%20Scott%20P.J.%20Introduction%20to%20Higher%20Order%20Categorical%20Logic.pdf) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dzkb418.)
That can't work. The whole point of cabal-the-library being tied to ghc is because it exposes a surface api for the package-management portion of ghc which userland tools need to interact with.
Right. Lambek and Scott requires a bit more background, which is why I stuck to just a few basic results rather than a fuller textbook on the subject.
Thank you, duly noted!
Some examples of other batteries that we hope to include over time: * Client side routing * Server-side pre-rendering ("isomorphic" as some call it) * Out-of-the-box framework for CQRS-like live-updating queries * Easy support for mobile and browser push notifications * Easy way to set up background queues (for sending email, etc.) 
It seems more likely there is some other aspect of what you're seeing that isn't captured by my test. Using GHC 8.0.2 I still get the shadow warning:j % ghci-8.0.2 X.hs -Wall GHCi, version 8.0.2: http://www.haskell.org/ghc/ :? for help [1 of 2] Compiling Y ( Y.hs, interpreted ) [2 of 2] Compiling X ( X.hs, interpreted ) X.hs:5:1: warning: [-Wmissing-signatures] Top-level binding with no type signature: f :: () -&gt; () X.hs:6:9: warning: [-Wname-shadowing] This binding for ‘fromOnly’ shadows the existing binding imported from ‘Y’ at X.hs:3:11-18 (and originally defined at Y.hs:3:25-32) Ok, modules loaded: X, Y. *X&gt;
More shockingly, it is not even defined whether `char` is signed or unsigned...
You could uncurry `sum` such that it looks like function declarations in most other programming languages: &gt; sum :: (Int, Int, Int) -&gt; Double &gt; sum (a, b, c) = ... That way, it really only takes one argument.
Nix expressions usually evaluate to records (of which derivations are a special case). Records that you can serialize as JSON or YAML using the dedicated builtins (need not be derivations). So you can totally use Nix as a language for expressing configuration data (aka a record of stuff) but using real abstraction facilities (e.g. lambdas), like in Dhall. It's a fairly common use case.
I've only skimmed the transcript so I may be mischaracterizing the contents of the talk, but I think trotting out all these exotic examples from computability theory, complexity theory, and mathematics at large misses a fundamental point: programmers aren't given arbitrary programs and then asked to determine if they are total/correct/etc. They are writing or working with programs that either they know or strongly suspect are correct with respect to a given task (otherwise, why would someone have written that program with that task in mind?). When an academic publishes a paper on a new algorithm they've developed, they don't just say "I have a hunch that this'll do the trick", they write an argument in mathematical prose that it does. If you have an informal mathematical argument in mind that program P solves task T, then in principle you should be able to translate this argument into the formal language of a theorem prover. This formalization step can of course be rather difficult, but that doesn't mean it is a show-stopper by any means.
Three notes: 1. the summary of Yedidia et al's result is off. It isn't about what can be "proven by mathematics" but what can be "proven by a given formal system." A machine which terminates exactly if ZF is consistent can be proven to terminate in ZF+consistent(ZF), and the same for every further extension. 2. I'm not sure I understand the claim about Haskell typeability being FSMs, at least not in modern-ish extensions of the language. Consider the following which can be written using only type families and RankNTypes data Z data S a type One = S Z type Two = S One type Three = S Two type family Plus a b type instance Plus Z b = b type instance Plus (S a) b = S (Plus a b) type family Times a b type instance Times Z b = Z type instance Times (S a) b = Plus b (Times a b) newtype Exists f = Exists (forall r. (forall x. f x -&gt; r) -&gt; r) newtype IsNat n = IsNat (forall p. p Z -&gt; (forall x. p x -&gt; p (S x)) -&gt; p n) newtype Eq a b = Eq (forall f. f a -&gt; f b) newtype False = False (forall x.x) newtype Not a = Not (a -&gt; False) newtype Half a b = Half (Eq a (Times Two b)) type CStep a b = Either (Half a b) (Not (Exists (Half a)),Eq b (S (Times Tree a))) newtype Oneness n = Oneness (forall p. p One -&gt; (forall a b. p b -&gt; CStep a b -&gt; p a) -&gt; p n) type CollatzConjecture = forall n. IsNat n -&gt; Oneness n I claim that finding a total terminating term of this type, or proving the absence of one, is beyond the capabilities of current mathematics. Obviously, all types in Haskell are inhabited, but the absence of dependent types does not make type inhabitation easy. If the question was type inference, well, *complete*, which is to say, extensional, type inference is undecidable for even the most basis language. Like, for instance, asking if an untyped lambda term has, extensionally, a particular hindley-milner type. Take any PCF term of type Nat -&gt; Bool, church encode it into the untyped lambda calculus as some term `v`. We can now ask if that term terminates on input `n` by church encoding `n` (lets call the encoded term`#n`) and seeing what types `v #n` has. If it has the scheme `a -&gt; b -&gt; c` it does not terminate, if it only has the scheme `a -&gt; b -&gt; a` or `a -&gt; b -&gt; b` then it does. The actual reason why Rice's lemma "doesn't apply to type systems" is that they are not extensional. Type systems in practice are formalistic and analyze syntax, and so outlaw some good programs. Overwhelming empirical evidence suggests that this is an acceptable loss, and that people don't need "complete" type systems to do useful things, even though, in theory, the smallest program which passes a type checker might be essentially arbitrarily larger than the smallest correct program. 3. Programs aren't broken into modules in an arbitrary way. People write programs which they *believe* to be correct, and use modules as they do it, which means there must be some tractable rational as to program correctness which works in a modular way for all programs in practice. Now, the people who wrote those programs might be incorrect in their reasoning, which makes the theoretical results a problem, but we should never pretend that "being impossible (or intractable) in the general case" means "being impossible in practice" as the history of computer science is littered with examples where that is not true.
With the `OverloadedLabels` and `OverloadedRecordFields` extensions the situation definitely got better. The `gi-gtk` package use it to great effect: instead of `builderAddFromFile builder "gtk/main.ui"` you can write now `#addFromFile builder "main.ui"`. Sometimes the compiler has to be helped along though to correctly infer types, and error messages could be improved, but overall it works.
factors :: \[Int\] \-\&gt; \[\[Int\]\] factors = map getFactors getFactors :: Int \-\&gt; \[Int\] getFactors n = filter \(\`isFactorOf\` n\) \[2..n\-1\] isFactorOf :: Int \-\&gt; Int \-\&gt; Bool a \`isFactorOf\` b = gcd a b == a
I know how to get rid of that ugly extra space on the left and bottom margins in your code blocks. Instead of styling your haddocks like {-| Docs More docs @ Code @ -} use -- | -- Docs -- More docs -- -- @ -- Code -- @
[Category Theory for Programmers](https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/) by Bartosz Milewski may be a good resource which shows the intersection between the CT and programming concepts, mostly in Haskell.
Thank you, I will change this when i have time
[Here](http://blog.paralleluniverse.co/2016/07/23/correctness-and-complexity/) is a blog post on the same subject. I haven't read it yet because it's really long. In general, Ron knows what he's talking about, even if I don't always agree with his predispositions [which may admittedly be due to the preceding].
Content looks cool, but presentation on mobile is kind of atrocious. Bringing the font size for prose down by like 25-50% would be great. Looking forward to reading it when I get back to a larger screen.
``` State s a ``` where `a` is an intermediate value. What does it mean by "intermediate value" and how do I make use of it? It's an optional value isn't it? 
Thank you. I know the book and was pretty sure it will come up sooner or later. I skimmed through it but found it quite shallow. For someone coming from CS, it’s nice to see some connections with category theory. But for me, I found it quite superficial in math and not very useful for Haskell (as I don’t know much). But it’s a nice read nonetheless, although I feel it reaches its potential once one knows some Haskell and doesn’t want to go deep into math.
There's always CPP.
I agree that seeing error on-the-fly and in-place is a really good IDE feature to have. But most IDE's for Haskell doesn't provide such feature and most IDE's for Haskell doesn't work well and doesn't work at all on huge projects. So, unfortunately, `ghcid` is the best available IDE because at least it's fast. Seeing error position is not a problem. It always on first line of opened terminal, not in some random places each time. And if you have two monitors it's not such big of a deal. You have `ghcid` in one monitor and your IDE on the second one. Such workflow is convenient enough. With such workflow I still can be much more productive in writing Haskell rather that with excellent IDE for Java programming language.
Thank you. I didn’t know about Michaelson’s. The others, I know I have them somewhere. I will have a look, thanks again for such a great list of references that’s built up here! I am overwhelmed (in a very good way, I don’t mean I’m feeling buried in books; although I do, but I like that, haha!).
Writing correct software is hard because you have to define what "correct" is i.e. you have to get the "requirements" right, which is more than merely what the customer wants, but includes environmental concerns, including security and performance. I think languages like Haskell help vs. the "looser" languages in that what you type (in both senses of that word) can easily be reasoned about. So you can look at the program and say "given this programmer understood the world correctly, this program should execute correctly". 
I'm afraid so. I really suggest the reader to read yesodbook first. 
Thanks for the answer. I tried your tutorial but get a lot of error messages. 
What kind of error? I omitted a lot of details in the article. You can see the complete code at the commit in the article or you can head [here](https://gitlab.com/ibnuda/Cirkeltrek/commits/master) directly. 
It's pricey, but Haskell Programming from First Principles was the resource I found that really cemented in my mind the concepts of functional programming and why Haskell does the things the way it does. Not trying to disparage any other resources. I'll probably go back to them now I have a better understanding of the fundamentals. Is that the sort of thing you're looking for?
I saw this when running the first part : of 5] Compiling Foundation ( src\Foundation.hs, .stack-work\dist\5c8418a7\build\Foundation.o ) src\Foundation.hs:12:20: error: Not in scope: type constructor or class `ApplicationSettings' | 12 | { appSetttings :: ApplicationSettings | ^^^^^^^^^^^^^^^^^^^ src\Foundation.hs:13:26: error: Not in scope: type constructor or class `ConnectionPool' | 13 | , appConnectionPool :: ConnectionPool | ^^^^^^^^^^^^^^ src\Foundation.hs:16:22: error: Not in scope: type constructor or class `Manager' | 16 | , appHttpManager :: Manager | ^^^^^^^
I haven't read the book you mentioned, so I cannot comment on it. As for book recommendations, I like this one: [Haskell Programming from first principles](http://haskellbook.com) by Christopher Allen &amp; Julie Moronuki
ghc could just lose its package-management system and be like every other compiler that receives everything it needs by command-line, not some weird registry. It could keep its own opaque package format, but drop ghc-pkg
Please continue to follow the article. `ApplicationSettings` will be written next. And you can also look at [this](https://gitlab.com/ibnuda/Cirkeltrek/commit/71a094349e2e4a37dc0c698709a161ff33cb0dd9) commit to see the full section. 
Nice! Don't forget `#an_arbitrary_token` for `-XOverloadedLabels`
A `State s a` is a function `s -&gt; (a, s)` - that is, it's a function that computes an `a`, which may depend on a state of type `s`, and outputs a (possibly changed) state. So 'intermediate' might not be the best word. The a is the thing you're calculating. You use it with `(&gt;&gt;=)` or do-notation - if you type in: do x &lt;- someStateThingie foo x Then x will be of type a. If you only care about the state change, then you can ignore the value. In some cases, a is (), like here: modify :: (s -&gt; s) -&gt; State s () In that case, it's meant to be ignored, since the only value of type () is (), which isn't really useful. 
You haven't imported `Settings` module, yet. Please import it. 
If money isn't an issue Haskell Programming from First Principles is definitely a good resource. I also don't know about Hutton's book, but what I have heard about the first edition is similar to your experience. Before the HPfFP came out, the recommended resource was [CIS194](https://www.seas.upenn.edu/~cis194/spring13/) and NICTA which is now known as [data61's fp-course](https://github.com/data61/fp-course). Both of these are free. The main key is doing exercises. Without the exercises you get this false feeling that you understand everything until you have to write code. If you get stuck on any of the problems, you can ask questions on IRC on #haskell and #haskell-beginners on Freenode. #haskell-beginners, CIS194 and NICTA were how I cut my teeth on Haskell, but I still have a long ways to go.
The book is verbose yes, but in a good way. It took me a decent amount of time to read, but keeps you progressing through a series of well structured exercises. I cannot recommend it highly enough.
&gt; The a is the thing you're calculating. by that do you mean that `a` is the result of computation given the value of `state`? I mean in other words `a` depends on the value of `s` and not the other way round? It's kind of confusing because `a` makes me think of Actions that we feed to a state machine to compute the next state
AFAIK, as currently implemented in GHC, what you're talking about is merely `DuplicateRecordFields` + `OverloadedLabels` + `HasField`, and there isn't even any special `IsLabel` instance to facilitate field access. How does `gi-gtk` do it? Do you have a link to this `#addFromFile`? I could only find `builderAddFromFile`.
Thanks, rampion. I added :) 
Also _ as a typed hole.
I am following CIS194 and it's very good so far. I got the impression that the data61 course was supposed to be taught in a classroom, not self studied. Thanks for the irc channels. 
Thanks, I thought I would not be needed. I will try it 
That's a really great idea! Thanks!
Nice documentation, good work
i wrote [a kind of a book to introduce the concepts of a haskellish world](https://libeako.github.io/c/ID_1371518733.html) though the intended audience are software engineers from the industry [with java, c#, c++, python background], it may still be good for an aspiring scientist who wants to look into programming; it is rather about concepts, explanations, intuitions, and not about the haskell language concretely; it provides a sequence of topics 
I can recommend the 2nd edition. It's expanded and has adapted to and covers the breaking changes since 1st edition. I can also recommend _Thinking Functionally with Haskell_. Both Bird and Hutton are experienced Haskell teachers who have thankfully used that background to write good books. Both books are more about Haskell as a language and algorithms and proving things, rather than "in practice" or "very, very verbose introduction for absolute first time programmers". So if you have some programming experience, I can recommend those two. I try to stay clear of "in practice" books because the tools and frameworks used within tend to die and make parts of the book obsolete. Case in point, Real World Haskell and Real World Ocaml are good books but some of the code won't work anymore or some of the content will be obsolete.
thank you
Instead of manually passing around your dependencies, you can use the Reader monad to do it implicitly. You can choose which ones you want to use at a single point in code, probably in the main function. Something like this data User = User { name :: Text } data Deps = Deps { logInfo :: Text -&gt; IO (), getUsers :: IO [User] } myFunction :: ReaderT Deps IO () myFunction = do deps &lt;- ask usrs &lt;- liftIO (getUsers deps) mapM_ showUsersName usrs showUsersName :: User -&gt; ReaderT Deps IO () showUsersName u = do deps &lt;- ask logInfo deps (name u) Now if we want to run this is production our main function would look something like logToLoggingService :: Text -&gt; IO () getUsersFromDb :: IO [User] main :: IO () main = runReaderT myFunction (Deps logToLoggingService getUsersFromDb) If we instead wanted to run this in a testing environment with mocks logToStdout :: Text -&gt; IO () logToStdout = putStrLn . pack mockUsers :: IO [User] mockUsers = return [User "a", User "b"] main :: IO () main = runReaderT myFunction (Deps logToStdout mockUsers) Now each part of this scheme can be further refined to improve extendability, usability, conciseness, etc. but it's a bit pointless to do it before you actually start feeling the constraints of this approach.
It's fairly common to use type classes for this. Write a `MonadFrobnicate m` type class providing the operations you need, and write your business operations in terms of that. You can then create several concrete monads implementing this class for your various implementations.
This is a pretty great resource: http://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html In short, it answers your direct question with: 1. Use some version of [ReaderT design pattern](https://www.fpcomplete.com/blog/2017/06/readert-design-pattern) 2. Separate concerns such that the important stuff is pure 3. Make all effects (small) type classes 4. Make test instances for said effects
[https://hackage.haskell.org/package/semigroupoids\-5.2.2/docs/Data\-Functor\-Alt.html#t:Alt](https://hackage.haskell.org/package/semigroupoids-5.2.2/docs/Data-Functor-Alt.html#t:Alt) \&gt; [\&lt;|\&gt;](https://hackage.haskell.org/package/base-4.10.1.0/docs/Control-Applicative.html#v:-60--124--62-) without a required empty
_Nice_, thanks! That's exactly what I had in mind! I'll write my experimental digestive lib using this interface.
The whole [semigroupoids](https://hackage.haskell.org/package/semigroupoids) package has a whole alternative hierarchy that is very close to the Haskell one, but decomposes operations from their units. This is very useful also for example with `Apply`, which is `Applicative` without `pure`, which allows an instance for `Map`, for example. I think that this feeling is what made Purescript to have a more fine-grained hierarchy for their typeclasses in their [prelude](https://pursuit.purescript.org/packages/purescript-prelude/3.2.0) and [control](https://pursuit.purescript.org/packages/purescript-control/4.0.0) libraries.
Another example are comonad-like things that can support "duplicate" but lack an "extract", like the [monadic folds](http://hackage.haskell.org/package/foldl-1.4.0/docs/Control-Foldl.html#t:FoldM) from the *foldl* package. You can give them [Extend](https://hackage.haskell.org/package/semigroupoids-5.2.2/docs/Data-Functor-Extend.html) instances.
In Parsec and optparse-applicative `empty` is a parser that always fails. In both cases it's possible to write parsers that fail without using `empty` directly. Thus avoiding empty doesn't really buy you anything at all, besides perhaps not being able to make your failing parser return `Void`. Returning `Void` is *desirable* though, because it proves to you that it always fails! 
Thanks dougmcclean. I added this :) 
&gt; Haskell Programming from First Principles I'm about 150 pages in the book, it doesn't explain how stuff really work internally (lazy evaluation for example), I'm left with tons of questions. It's a great book, has lots of examples, but I don't think its good for people trying to deeply understand haskell.
&gt; In Parsec and optparse-applicative empty is a parser that always fails. In both cases it's possible to write parsers that fail without using empty directly. Correct. &gt; Thus avoiding empty doesn't really buy you anything at all Well, it buys me not having to define a bogus method in a class, a method which allows for bogus results for end-users.
Interesting, might you be willing to show us how [this example](https://github.com/Wizek/hs-di-example) would look like with simple-effects? In the meantime I intend to peruse the tutorial section.
Because `pure` is the the identity: `pure id &lt;*&gt; x = x`, it has no effect on the parser, and yet it lets the programmer using the library return a useful result. That's great for swapping out a parser that consumed an argument `--enable-foo` with `pure True`, or for placeholders for future consuming parsers to be added later. It can also be used with `this &lt;!&gt; pure def` for a catch-all. All these use-cases to me don't present the user with some garbage. In contrast, `empty` doesn't serve any actual purpose information-wise. The error message is hard-coded into the `Alternative` instance in the library. An end-user of a package using parsec can reasonably see `"unknown parse error"` as output, which is useless, and a user of a program written using optparse-applicative can reasonably see `Missing: ` (followed by nothing), which is also useless. It's not information, it's `NullPointerException`. I wouldn't say `pure` is always useful, if you stick to just `Apply` that doesn't have it, you can still get by. But it seems to me practically speaking much less liable to creating bugs.
Very nice. Especially appreciate links to documentation.
Also stuff starting with _ to not trigger unused bind warning.
IME Data61 (the material that’s online) is long on how basic concepts are implemented and very short on why you should care. Take a look at Comonad.hs for an extreme example of this.
It's a shame the Monoid/Semigroup changes didn't have Alternative/Alt tracking alongside them. While we're at it, let's get `NonemptyFoldable` with `foldMapS :: (Semigroup s, NonemptyFoldable f) =&gt; (a -&gt; s) -&gt; f a -&gt; s` in there as well, and deprecate all the partial Foldables! 
I wonder if you could remove 'some' and 'many' from the Alt typeclass, and have them as external functions, like: some, many :: \(Alt f, Applicative f\) =\&gt; .... The only reason I say this is that no one ever seems to override their implementation, and GHC optimises one\-method typeclasses very well
There's `Foldable1` in there I saw. http://hackage.haskell.org/package/semigroupoids-5.2.2/docs/Data-Semigroup-Foldable.html
Fascinating, thank you for doing this. I'm acquainting myself with it at the moment. A few initial observations: - at 94 sloc, it seems to sit a in-between the two other solutions in terms of conciseness. - Even still, [only this part][1] looks excessive to me, and even this suggests only mechanical repetition. I wonder if it could be `DRY`-ed up somehow. [1]: https://github.com/LukaHorvat/hs-di-example/blob/c9329/library/HsDiExample/Main.hs#L11-L37
It's a verbose book because it has to be, precisely to *not* have the "uh, I was understanding page 50 fine, why is 51 incomprehensible?" I have not read Hutton's book, so I'm speaking generally: *LOTS* of material for learning Haskell is aimed at academia, primarily at students that will have a teacher, TAs, classmates, etc. to provide a support structure. Learning materials outside of their proper context are going to be less effective. Haskell Programming from First Principles assumes minimal context -- it's a stand-alone resource. It assumes you know how to work a terminal and a text editor. It teaches you *everything else* in a foundation manner -- by the time you get to a concept, you have covered all of it's prerequisites with dozens of exercises, and you're equipped to understand it. The authors took immense care in testing the book on people learning and identifying what works and what doesn't for teaching, and it really shows. $60 seems like a lot, but it's a bargain compared to how much time you'll spend learning Haskell without the book.
It's disappointing that SPJ doesn't recognize the fact that Excel is the Java of spreadsheet software, and if you want something with Haskell\-like power, it's Quantrix or bust. Programming in Excel is like Haskell if you had no named functions and had to compensate by using TH for everything. It's total crap.
Is this not `Data.Monoid.Alt` in `base &gt;= 4.8`?
[removed]
Don't get hung up on the name - you can call it b or r or something instead of a. The a *can* depend on the input state. So can the output state. Example: foo :: State Int String foo = do s &lt;- get put (s + 1) pure (show s) Here, both the result and the output state depend on the input state. 
any good example project of how this design pattern applied?
I vaguely remember reading that _ for unused variables are handle specially/optimized in GHC, but can't remember the resource I got it from :/
Probably just a minor variation on https://github.com/ElvishJerricco/reflex-project-skeleton. This seems to be how most newcomers get a project going with Reflex these days
Can you post the build log, and maybe your .cabal files and nix files?
Sounds like in the Nix shell you let cabal manage your Haskell dependencies. This is not the right way to do it. You can override dependency versions in nix in the overrides field if you're using the `project` stuff. https://github.com/reflex-frp/reflex-platform/blob/dc086ad9a513790d031a2f81730b2eebc238474e/project/default.nix#L72
Purescript has more corporate backing and it's a language with a fraction of Haskell's lifetime. Sure, Haskell is fixing its problems, but very, very slowly. ( and tbh it's mostly just Michael Snoyman fixing haskell's problems, not abstract community...)
If cabal works for you then there's reason to force yourself to change. I would recommend trying out cabal new-build though; it's basically the same ole cabal but minus the cabal hell stuff and sandboxes. Stack is good if you don't want to install GHC yourself and if you prefer curated snapshots rather than dynamic dependency solving and freeze files. I will say I have an affinity for new-build, as it seems like a much more hermetic and logical approach to avoiding cabal hell.
I love this sort of stuff! I feel like going off to refactor all my Haskell code to use these tricks right now. How, exactly, does this relate to dependant types, though? What, in this talk, is an example of dependant types?
 &gt;&gt; dependency injection can be simply thought as providing the deps as function parameters &gt; Yes, in a very limited sense this is true. It is however unfortunate that this approach doesn't scale for anything beyond the most trivial example, because you'd have to pass in all the dependencies of your dependencies (recursively). It's a superlinear explosion in the number of parameters required for all functions. Hmm, if you limit it to the case of testing, usually all users are going to use same dependency. Like, for example, if you inject database service, then you do it only once, then all users just initalize it from their constructor, because this is how it supposed to work - all should use the same implementation. And you are not supposed to have too much services to inject anyway, usually it's some number below 10.
In my experience, and when working with a library/framework that supports mocking well and at a very low cost, having very fine-grained "services" that can be tested and mocked individually at a small unit size makes the whole experience very enjoyable. The small units are highly self-contained and easy to test deterministically/purely and reason about. I usually end up having many dozens if not hundreds of these even in a medium sized codebase.
The approach I've seen used the most at major Haskell shops right now is 'late\-bound capabilities' from IOHK [https://github.com/input\-output\-hk/cardano\-sl/blob/develop/docs/monads.md](https://github.com/input-output-hk/cardano-sl/blob/develop/docs/monads.md) which basically amounts to putting a data type representing your service into Reader context, then accessing the services with lenses – which sound and feels very similar to basic OO DI. You can also take a look at [IOHK's design doc wrt Monads](https://github.com/input-output-hk/cardano-sl/pull/1894/files), for an overview of nearly all the available approaches – they've tried everything. Generally, you'll find that production code leans towards simple ReaderT over IO, maybe with [tagless final interpreters](http://www.parsonsmatt.org/2016/07/14/rank_n_classy_limited_effects.html), instead of Eff, mtl, free monads and such.
There are some interesting situations where determining non-termination and correctness are vital: * Humans are usually blind to their own errors. I might have written an algorithm implementation I am confident in, but still have introduced errors. * A compiler cannot produce an optimal program (for most useful definitions of optimal). * Determining time and space complexity of code is difficult, but useful. Especially for Haskell programs where non-strict semantics make this even harder. * A compiler cannot stop programmers from writing code that is slow, leaks memory or other resources, or does not terminate. This is very bad because many formal systems, such as Haskell's type system, are only sound for code that terminates. * Specifically: a compiler cannot prove the absence of exceptions. This is bad news for writing C++ code that has to abide to exception safety levels to avoid memory or resource leaks. * Code review, be it manual or automated, cannot uncover all issues. This essentially means that to reuse code a lot of trust in a dependency is required. Many of the above issues can be ameliorated by using languages that do not offer certain features, or make them difficult to use. By implementing their code in such simpler systems, a programmer proves that the algorithm implementation fulfils some property. For example, SQL92 queries (without stored procedures) are programs that are terminating by design. Also, it is straightforward to infer upper bounds on space and time complexity.
Did this guy just a build a fully-functional website in one blogpost?
This is what Richard says in the discussion section &gt; To my surprise, this project did *not* strongly want for full dependent types. As we have seen, we needed a few singletons. A language with support for dependent types would naturally not need these singletons. &gt; &gt; —[Stitch: The Sound Type-Indexed Type Checker](https://cs.brynmawr.edu/~rae/papers/2018/stitch/stitch.pdf) (Author’s Cut), page 1:29 Singletons emulate dependent types and that uses many of the shiny features we have: `-XGADTs`, `-XDataKinds`, `-XTypeFamilies`, `-XTypeFamilyDependencies` (injective type famliies), `-XDataFamilies`, `-XTypeInType`. Pattern matching on say *False* or *True* doesn't distinguish them at the type level, they both have type *Bool* data Bool :: Type where False :: Bool True :: Bool Matching against a `Bool`-indexed singleton however gives us type-level information about data SBool :: Bool -&gt; Type where SFalse :: SBool False STrue :: SBool True Where we can think of `SBool bool -&gt; If bool () Int` really to mean `pi (bool :: Bool) -&gt; if bool then () else Int` (using [`Data.Type.Bool.If`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Type-Bool.html#t:If) fn :: SBool (bool :: Bool) -&gt; If bool () String fn STrue = () -- fn :: SBool True -&gt; () fn SFalse = "else branch" -- fn :: SBool False -&gt; String In fact the new [type-indexed *TypeRep*](http://hackage.haskell.org/package/base-4.11.0.0/docs/Type-Reflection.html) is another example of a singleton TypeRep :: k -&gt; Type so if you search the paper for ‘dependent’, ‘singleton’, ‘`TypeRep`’, `Typeable` you'll see a more detailed discussion of what called for it. ---- Quotes: &gt; A key aspect of GHC’s reflection mechanism is that it provides a *type-indexed* type representation, *TypeRep*. The type *TypeRep* has kind `forall k. k -&gt; Type`, allowing for a representation of a type of any kind. The representation for *Int* has type *TypeRep Int*; the representation for *Bool* has type *TypeRep Bool*. As such, *TypeRep* is actually the singleton type for the kind *Type*.^6 &gt; &gt; ^6 *TypeRep* can be viewed as a universal singleton type, because it works at all kinds. However, working with *TypeRep*s for non-**Type** singletons is even more unwieldy than singletons usually are, and so I use *TypeRep* only at kind **Type** *-&gt;* **Type** and write custom singleton types for other singletons. &gt; &gt; —[Stitch: The Sound Type-Indexed Type Checker](https://cs.brynmawr.edu/~rae/papers/2018/stitch/stitch.pdf) (Author’s Cut), page 1:12 &gt; checkIn :: pi (name :: String) (ty :: Type) (schema :: Schema) -&gt; (In name ty schema =&gt; r) -&gt; r &gt; &gt; "Readers might be alarmed to see here a **Type** being passed at runtime. After all, a key feature of Dependent Haskell is type erasure! However, passing types at runtime is sometimes necessary, and using the type **Type** to do so is a natural extension of what is done today. Indeed, today’s *TypeRep* (explored in detail by Peyton Jones et al. in [https://www.seas.upenn.edu/~sweirich/papers/wadlerfest2016.pdf](A reflection on types) is essentially a singleton for **Type**. As Dependent Haskell removes other singletons, so too will it remove *TypeRep* in favor of dependent pattern matching on **Type**. As with other aspects of type erasure, users will choose which types to erase by the choice between `pi`-quantification and a `forall`-quantification. &gt; &gt; —[Dependent Types in Haskell: Theory and Practice](https://cs.brynmawr.edu/~rae/papers/2016/thesis/eisenberg-thesis.pdf) Richard's thesis, pages 30-31
I’ve used test-fixture a bit - a good introduction is here: https://lexi-lambda.github.io/blog/2016/10/03/using-types-to-unit-test-in-haskell/
I'm going with a more generous interpretation. Preferring candidates from under-represented groups is like progressive taxation; it doesn't significantly hurt the rich and lets the poor get by. 
I'm probably missing the point but, why can't you use Semigroup ? 
For anyone who's reading and is unfamiliar with `Alternative`: `empty` does *not* "only serve to insert nonsense results". It is mathematically significant as an identity to `&lt;|&gt;`, so you can say `m &lt;|&gt; empty = empty &lt;|&gt; m = m` are all the same. If you don't have an identity then you use `Alt`.
There are a lot of partial functions in your API. Expressions like `bbr0 Implied` will crash your program. If certain instructions only support certain addressing modes, you should probably try to express that in the type.
Thanks, I added!
Thanks, I added Hoogle5! 
&gt; and GHC optimises one-method typeclasses very well It does? I didn't know this was any better than many-method typeclasses.
In a higher-order setting something like the new type optimization comes into play.
I think `Alternative` has a much bigger problem: the fact that it lacks a proper set of laws. The problem is inherited from `MonadPlus`, and ultimately means you can't prove much about `Alternative`-polymorphic functions.
Oops. Somehow that flew over my head writing it. I'm editing the script to generate the code &amp; I'll get that fixed real quick.
I notice that you are missing all of the undocumented 6502 opcodes: e.g. ASO, LAX, RLA, RRA, LSE, AXS, DCM, INS, ARR, XAA, OAL, SAX, HLT, TAS, SAY, XAS, AXA, ANC, SKB, LAS...
Right. IIRC `MonadPlus` instances are generally of two kinds, those that have "left catch" and those that have "left distribution". **Left distribution**: `mplus p q &gt;&gt;= f = mplus (p &gt;&gt;= f) (q &gt;&gt;= f)` (e.g. `[]`) **Left catch**: `mplus (return x) q = return x` (e.g. `Maybe`, `STM`) (It can't reasonably have both, that degenerates into `mplus p q = p`.)
Hi, this looks like something I'm looking for! Thank you very much for sharing :D
Wow, we really need more people like you who can explain with simple words and real examples but unfortunately I can only upvote once :/ Thank you, thank you very much for taking the time to write the examples: they made things a lot clearer to me!
The deps are handled in the way you describe, I think. I pinned dependencies running something like `cabal2nix cabal://megaparsec-6.5.0 &gt; deps/megaparsec.nix` and then in the overrides section you describe I put `megaparsec = self.callPackage ./deps/megaparsec.nix {};`. That should allow Nix to supply the deps and cabal should just pick up the ones provided, no? Although I needed to do the same for `parser-combinators`, `hspec-discover`, to work with `megaparsec-6.5.0` but trying to build always yielded something like "build tool not found: hspec-discover" so I guess that has to be treated in some other way? Haven't found any docs on build tools though. How does the dist-newstyle affect this? I thought it just contained output from building. Thanks!
Looks a little like the way I did things in [hnes](https://github.com/dbousamra/hnes/tree/master/src/Emulator)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [dbousamra/hnes/.../**Emulator** (master → b750c9c)](https://github.com/dbousamra/hnes/tree/b750c9c8264e896f10eeb8134f8f90050b547ab4/src/Emulator) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dznde4s.)
We do something like this: ``` data Mode = Debug | Testing | Live someFunc :: Mode -&gt; ... -&gt; IO () someFunc Debugging ... = do_the_debug_logic someFunc Testing ... = do_the_testing_logic someFunc Live ... = do_the_live_logic ``` Would that suite your needs?
[@kmett's latest tweet](https://i.imgur.com/1AJTJlH.jpg) [@kmett on Twitter](https://twitter.com/kmett) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
optparse actually does override them in order to achieve terminating search of the parse tree.
I would love to change optparse to not have to have empty. It actually pollutes quite a lot of the internal types of the library. But there's no way I can justify a large breaking change like moving to Alt from semigroupoids. It's pretty much just wait until we make it an actual superclass and do it right in base unfortunately.
Hey, thanks!
It’s kind of no bueno to use a random joke as the package synopsis because then it’ll never come up in the search engine on hackage
I like that half of these links are purple in my browser :)
On a side note, use `TBQueue` instead of `TQueue`. Using `TQueue` means you can somehow guarantee that your producers will never outperform your consumer threads – it's best to make this assumption explicit by using a bounded queue that will block the producers instead of making your program run out of memory.
I'm curious why none of these use a more traditional mutable queue as their backing store. Too many TVars?
Seeing Quantrix for the first time! Seems there are so uber that even Microsoft uses them. SPJ recognizing Excel might be due to the fact that he was working for Microsoft \(or I am just imaging\)
PSA: Don't use `flushTBQueue` in version `2.4.5.0`. It's broken.
Bookmarked. I was planning on implementing something similar recently. I feel like some raster routines on the C64 could be easier to write with something like this (could also make the assembler keep track of clock cycles). Or maybe a DSL could specify a meta program that outputs 6502 binary on the 6502 with self modifying code. (shameless plug, I recently released a C64 game http://nurpax.github.io/posts/2018-05-21-bintris-on-c64-part-2.html, Haskell was also used in its creation even though it was written in assembly. :))
I've run into live-lock with `TBQueue` and so has Brandon Simmons: - http://brandon.si/code/announcing-unagi-chan/ - https://github.com/jberryman/unagi-chan/issues/1#issuecomment-52342531 Seen a TBQueue live-lock in production 2 or 3 times, but it's hard to reproduce.
For parsers, `empty` is the parser that accepts nothing, ε. Having a canonical ε makes a lot of sense—programming parser without it is like doing arithmetic without a canonical 0. It's particularly a problem for writing parser library functions which need an empty parser but *don't* have a domain-specific error message to provide. The question we should be answering is not "how do we write a parser library without a canonical ε?" but "how can we have a canonical ε *and* useful, domain-specific error messages?". This would not only solve the apparent problem with `empty` brought up in this post but would *also* let us have generic parsing functions that still produce specific, useful error messages.
Relevant SO question with answer: * https://stackoverflow.com/questions/48971650/applicative-parser-deriving-alternative-without-empty
I would recommend _Get programming with Haskell_. * https://www.reddit.com/r/haskell/comments/82p0de/haskell_books_comparison/dvbt110/
I think most important and missing advice on stack usage is "avoid stack install at (almost) all costs". Just like explained in this article: https://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/ Biggest pain was actually installing the tool itself which is a part of tooling. Ghc-mod, intero etc. Since I took the advice of avoiding stack install and using stack build --copy-compiler-tool I am like in heaven while trying haskell packages, installing libraries, writing my own code etc. Do not use stack install.
Sorry, I agree. I think my criticism is more of established practice, that people _do_ implement `Applicative` for parsers that are supposed to yield useful error messages, and knowingly insert a bogus message like that anyway (which make using guard etc unsatisfying). You can find loads of instances like that. I found myself tempted to do the same thing and that's where this post came from. 
The list monad and list comprehensions are basically the same thing \(I think?\). If you look at cartProdN1 :: [[a]] -&gt; [[a]] cartProdN1 [] = [[]] cartProdN1 (xs:yss) = [ x:ys | x &lt;- xs, ys &lt;- cartProdN1 yss ] you can convert it to cartProdN9 :: [[a]] -&gt; [[a]] cartProdN9 [] = return [] cartProdN9 (xs:yss) = xs &gt;&gt;= \x -&gt; (cartProdN9 yss &gt;&gt;= \ys -&gt; return (x:ys)) which, with "do" sugar you can write as cartProdN9 :: [[a]] -&gt; [[a]] cartProdN9 [] = return [] cartProdN9 (xs:yss) = do x &lt;- xs ys &lt;- cartProdN9 yss return $ x:ys So you can see you can express a list comprehension of the form [ exp | cond1, cond2, ..., condN] with the `&gt;&gt;=` operator \(hidden by "do" sugar\) simply by doing do x1 &lt;- cond1 x2 &lt;- cond2 . . . xN &lt;- condN return exp I don't know if this was your question, but I hope it helped.
Yes, but those don't give any information about the relationship between the `Applicative` and `Alternative` methods. That's unusual for a subclass, but more importantly, it greatly limits reasoning.
&gt; They are writing or working with programs that either they know or strongly suspect are correct with respect to a given task (otherwise, why would someone have written that program with that task in mind?). This is a conjecture that may not actually be true about real programs. I've written some thoughts on this matter [here](https://pron.github.io/posts/people-dont-write-programs). &gt; When an academic publishes a paper on a new algorithm they've developed, they don't just say "I have a hunch that this'll do the trick", they write an argument in mathematical prose that it does. This is true, yet may not apply to most real-world programs for reasons I give in the post I linked above. I.e., we cannot extrapolate from the fact that published algorithms can be proven correct to most programs can be proven correct. &gt; that doesn't mean it is a show-stopper by any means. I certainly don't claim it's a show stopper, but on the other hand we cannot claim it is often possible in practice, either.
If you have a list `l :: [a]` and a function `f :: a -&gt; [b]`, then `l &gt;&gt;= f` takes each element in `l`, applies `f` to it, and then concats all the resulting lists. `return` simply creates a singleton list, so `return 1` is the list `[1]` and `return []` is `[[]]`. When `&gt;&gt;=` is involved you often see the right hand side being written as a lambda abstraction like in your example: cartProdN9 [] = return [] cartProdN9 (x:xs) = x &gt;&gt;= \x' -&gt; cartProdN9 xs &gt;&gt;= \xs' -&gt; return (x':xs')
I mostly use it to hook into testing libraries and in ghci, but not for actual production use cases. I will read up on the alternatives some time.
I'm waiting/hoping for the Real World Haskell 2nd edition.
Shouldn't that be `Const w * Identity`? 
Update: It's been a day and a half and I'm still scratching my head as to how to make the functions impartial without nesting constructors while calling a function. Message me if you have any ideas -- I'd really appreciate it.
I don't think it's valid to say "late-bound" for what's described in the `monads.md` document (I say this as a person who wrote it). If you just put method records in `ReaderT` over `IO`, it's just that, no late binding. And this technique has been known long before we decided to use it in Cardano SL, I first heard of it from /u/snoyberg. As to late-bound capabilities, this is a more exotic concept. I've implemented them in a library (https://github.com/int-index/caps) which I still haven't released because I'm still not quite happy with its interface. So that's not something I would reach first if I needed to write effectful code.
They're missing because I didn't know about them! Modeling the microcode would be overkill in this project, but I'll look into implementing those. Thanks!
&gt; Really? Has this idea caught on? I'm not so happy about that. Used at IOHK and Formation from what I know talking to their engineers. &gt; It amounts to wondering "how can we best do imperative object-oriented programming in Haskell?" No, it only amounts to wondering how to do modular programming. I don't think that saying "just make everything pure (as in, not monadic) and use one Production monad" as, I think, you did in the comments there is productive, because IMHO impure IO and impure logic is the part of the program that needs testing the most, that is least specifiable and has the least guarantees. You can prove or property check your pure parts, but the only thing that can tell with at least a little percent of certainty, that your program will actually run is impure tests – but you probably still want to skip testing against a real database most of the time, so there *MUST* be more configurability than a single Production monad. Also, on using 'object-oriented' as a slur, I don't know what about this approach is object-oriented. Since records of methods are just tagless interpreters of service algebras, then it must follow that free monad interpreters, algebraic effect handlers and mtl (coherent tagless interpreters) are all also equally object-oriented.
You don't really need to model it exactly, but there is a great deal of structure to the opcode numbers that tells you what it will do.
(Writing this publicly, rather than in a private message, so that other people can contribute suggestions.) You can use (a `*`-kinded variant of) the `:-&lt;:` class from [_Data Types a la Carte_](http://www.cs.ru.nl/~W.Swierstra/Publications/DataTypesALaCarte.pdf) if you want a general automated proof search for injecting values into coproducts. Then your functions would have a type like `cpx :: Immediate :+: ZeroPage :+: Absolute -&gt; Instruction`, and your callers would call `inj` when supplying an argument (ie `cpx (inj $ ZeroPage addr)`, rather than `cpx (Right $ Left $ ZeroPage addr)`). However in your specific case I think you may be able get away with a simpler design. From skim-reading your code it looks like the constructors of `AddressingMode` tend to move around in groups. eg the `Immediate`, `ZeroPage`, and `Absolute` constructors tend to be used together. So you might be able to split up `AddressingMode` into a few smaller types and use them as your argument types. You're better-positioned than I am to assess whether that's likely to work out because I'm not very familiar with your problem domain. A third option would be to handle failure explicitly in your `Instruction` monad, eg something like `newtype Instruction a = Instruction { runInstruction :: InstructionState -&gt; Maybe (InstructionState, a) }`. This option has the advantage of being simple but it does mean failures happen at runtime.
&gt; Why should the monad itself determine the effects? Why should IO determine one particular way of using a database, for example? This is what the typical class-based / mtl approach asserts. In this case the contents of the Reader (modules) determine the effects, the IO is just a runner and that's good. In case nothing in the Reader requests MonadIO, IO can even be dropped. &gt; that there's no reason to believe that ideas lifted from OO are going to work at all well in PFP The ideas of modularity and dependency injection are universal and orthogonal to OO. Would you argue that ML-family languages are OO? In particular 1ML, by virtue that first-class modules == objects. &gt; The configurability we're after is more easily and more honestly achieved by using a lambda abstraction: DB m -&gt; m () rather than MonadDB m =&gt; m () The problem with passing lamdas around is simply the cost. I assure you, my current Scala project would never work at all without a dependency injection framework, there are simply too many entities with too many arguments, if code was translated to manually instantiate the components it would take at least 1K lines, and wouldn't provide nearly the same flexibility, as many of the tests run the default test configuration, but change one component, and all the tests are run both against real DB and against mocks. The same scalability issues start appearing in Haskell, as it's getting used more, and apparently to be solved in a similar way – and that's because module abstraction is universal, not just an invention of the OO devil. &gt; If I use a lambda-abstracted value to deal with effects, as in something like DB m -&gt; m (), have I used a record of methods? Constructed a tagless interpreter of a service algebra? Used algebraic effects? Of course not. I've used a lambda abstraction over a plain vanilla value. Once you put any kind of expectation or restriction on `DB m -&gt; m ()` that isn't part of it's type signature, you have an eminent algebra, so I would argue that yes, if your program won't work if that `DB m -&gt; m ()` does nothing or blows up, at this point you have an implicit contract/interface and an implementation of it. 
I just finished a master's thesis formalizing univalent category theory in the proof assistant Agda[1]. The HoTT book was an invaluable resource. If you want to learn lambda calculus and homotopy type theory you might be interested in trying your hands on done a formalization in a proof assistant. Coming from a maths background the theory should be a piece of cake for you but you might get some satisfaction from seeing your proofs type check. Also I second the recommendation of Software Foundations. Should be a great place for you to start the journey down this rabbit hole. [1]: https://github.com/fredefox/cat
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/fredefox/cat) - Previous text "1" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dzojq2d) 
Looking at the error message, perhaps you need to upgrade the version of cabal-install? Seems Stack is having trouble with some commandline stuff. Not entirely sure though, maybe someone with more experience can chime in.
In the end I settled on Semigroup - it's just that Alternative has always been the standard choice for parsing alternatives. 
To solve problems in Haskell, a common approach in Haskell is to try to apply the `Monad`, `Applicative`, and `Monoid` hammers. They provide a framework to create a DSL to describe a problem. It is indeed surprisingly common that problems nicely fit those abstractions (ever heard of the [Burrito monad](http://emorehouse.web.wesleyan.edu/silliness/burrito_monads.pdf) ?) but it's certainly not a given, and often new abstractions are required.
If /u/snoyberg has a faster and simpler version, why not adopt that in `stm`? Also, do you have a link to his version?
Thank you very much for this. You’re right, seeing things implemented in Coq or Agda is a great way to get satisfaction from the study. I will be starting today. Thanks again to all of your kind and extremely useful replies and resources!
I always use the search engine as a starting point, YMMV
What do you mean by "scale"?
I guess "scale" as in, could you, for instance, build Facebook's UI with it, with so many moving pieces. Or maybe something like an ERP with so many nested panes dialogs fileds. And this while keeping the code maintainable with reasonable performance.
I find that somewhat surprising, I'm not super experienced with it myself, but it seems like it's basically a strict superset of the functionality given by React/redux and similar, so if you're worried about project structure couldn't you just start with a Redux approach and go from there?
&gt; But it seems to me practically speaking much less liable to creating bugs. I stitll don't think I buy this. I don't have watertight argument in favour of `empty` but I'm not convinced by your own argument either. As a point of information, the only time the user needs to see "unknown parse error" is when the whole parser evaluates to literally just `empty`. In all other cases the rest of the parser code has enough information in it to provide a useful error message.
I would highly recommend the "Programming Haskell, from first principles". It is ~= 1900 pages, extremely well written, so you will read it very quickly.
I was going to say that there should be distributive laws, but apparently there are not. https://wiki.haskell.org/Typeclassopedia#Laws_6 Anyway, I'm not the kind of person who thinks `Alternative` should be a subclass of `Applicative` anyway!
What I mean is ,for example, is `Alternative` actually needed or is it just redundant with `Applicative` + `Monoid` ?
Your goals seem very sensible. I suspect I should probably replicate them, but the few packages I've tried to hand over have always boomeranged right back to me. I'm curious to see how successful you are. 
&gt; I considered writing a blog post about the comparison of different chat options I did, but ultimately decided it would be more noise than it's worth. /u/snoyberg, please reconsider that decision. I think such a post would be extremely useful!
What worked in your experiences?
Sorta related to this, it got me wondering on a couple of general questions that interested me: 1) When are people typically spending their time on OSS projects? At work? In the evenings after work? On weekends? 2) I would be very interested in a sorta guideline for the minimum amount of things that at least should be documented to let other people jump into a project. A lot of things are recurring. To answer these myself: 1) Mostly in the weekend, but occasionally in my evenings after work if I can find time. 2) I usually always describe: motivation/goal of the project, setting up dependencies, how to develop, how to deploy I’m very interested in hearing what others do :)
My experience with Reflex is that it is extremely powerful. Will all that power comes a lot of flexibility and the possibility of creating spaghetti code if not careful. It is necessary to have extra guidelines to structure your code. For example, nothing stops you from replicating the Elm architecture with Reflex, which is fairly nice.
Same; my current company doesn't have 20% time or any sort of open source policy, so all my OSS contributions are done in the evening or during weekend, real life permitting. Also, always, readme contains motivation and/or API design consideration AND haddocks with comments on function inputs, constructor fields, typeclasses etc. I mostly develop native libraries so deployment is a no-op.
https://stackoverflow.com/questions/5299295/why-does-application-of-sequence-on-list-of-lists-lead-to-computation-of-its-c This question is helpful for me.
I'm a bit confused about my benchmark results when benchmarking \`conduit\`. I am constructing a conduit to output the primes to stdout, for about 10.000 the first run takes about 4s, but the subsequent runs take a fraction of a second. Is \`conduit\` somehow caching the results, which makes the other runs very fast? The relevant code should be in this gist: [https://gist.github.com/rubenpieters/101966d244bfd8b14f091b9e912f5787](https://gist.github.com/rubenpieters/101966d244bfd8b14f091b9e912f5787) . If needed I can set up a more complete repo somewhere.
This great video answers your second question: * https://www.youtube.com/watch?reload=9&amp;v=6kGLHXsUQD4
So much reactivity. It would be great if it had some good documentation. I m struggling with the language syntax. But lamdu looks pretty promising.
[removed]
Although strictly speaking, I'm offtopic, I thought I should add [Coquand's SEP entry](https://plato.stanford.edu/entries/type-theory/) on Type Theory, which I found extremely useful as a starting point and overview, with sufficient references to history, philosophy, logic, and CS.
You would habe to implementiert your own virtualdom in top of reflex to make that work
Looks v cool, unsure what the USP is compared to other offerings, hmm
&gt; Ahh, but that is an argument parser whose reader just happens to fail when it's called on a value. I'm confused. Are you saying it differs somehow from `empty`? &gt; the UnknownError error case is just awful Surely the only case you ever need it is when the parser evaluated to literally just `empty`? If so, it could be called "empty error" to make it much clearer that the parser accepts literally nothing. That *might* be a programmer error, but maybe it's not.
&gt; Alt I guess the situation isn't made easier by the fact that since base-4.8 there's a data type called [`Alt`](https://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Monoid.html#t:Alt) in `Data.Monoid`. It has `Alternative f =&gt; Monoid (Alt f a)` so that has a `mempty`. So now there's the `Alt` typeclass that doesn't have an empty value and the `Alt` data type that does. Quite confusing.
I spotted that, suspect I will be combing through that source code very closely in the near future. Thanks!
Actually, typed holes are *any* variable starting with _ that is not in scope. So _foo without _foo in scope is a typed hole.
I'd actually hoped to put together a decent benchmark including your implementations and mine and share them, but due to travel haven't had much chance. I've just committed everything I had locally and pushed to this repo: https://github.com/snoyberg/tbqueue-livelock Note that in the benchmarks I have right now, `TChan` turns out to be the fastest, making me fairly certain this is a bad benchmark. That's also why I hadn't said anything yet. The two implementations I'd wanted to throw into the mix were: * https://github.com/snoyberg/tbqueue-livelock/blob/master/src/OneTVar.hs * https://github.com/snoyberg/tbqueue-livelock/blob/master/src/VectorBased.hs I don't have any strong reason to believe they will be faster, as I haven't looked into the details of where contention is happening in any real detail. I have every reason to believe that your investigations will produce much better results than my tinkering. Side note: I'd really be happy to get a closable, bounded queue into `stm` :)
I forgot that I'd already taken the draft I'd started and put it in a Gist. So far, I mostly got as far as why not IRC or Slack. https://gist.github.com/snoyberg/87e545d38c00b3824ca957c1e5471d66 If this is useful, awesome :). If it's not useful, feel free to totally ignore.
seem like I need write a custom do_nonation?
N.B.: /u/snoyjerk , the submitter here, [is not Michael Snoyman](https://www.reddit.com/r/haskell/comments/7shvxo/hash_based_package_downloads_part_1_of_2/dt653fi/).
I've checked out your website. Are you using Haskell or technology related to functional programming to provide your services?
I'm one of u/isovector's friends who swears by reflex. We use it for the frontend of an interactive content management system. It's a great test of real-world scaling - client is constantly asking for big features to be added, and small holes poked in existing abstractions, with schedule requirements that do not encourage us to take time perfecting things. Lots of pros and cons encountered over the year and a half we have been working on this. As for scaling and continuing to be easy to reason about as the members leave/join the team and the requirements and backend change, reflex app scaled very well! I really doubt that u/isovector is "just bad at doing FRP" :) More likely it's just not your style?
Spam post nuked. 
You could do it using open recursion, as in [abstracting definitional interpreters](http://david.darais.com/assets/papers/abstracting-definitional-interpreters/adi.pdf), section 3.1.
Thanks!
It will just remove the syntactic overhead of adding `fromList`.
You know how the Monad typeclass is `class Monad m`? `m` is a type variable of kind `* -&gt; *`, meaning that it needs to be applied to a type of kind `*` to be used as the type of a variable. You can see `m` be applied in the type signature of `&gt;&gt;=`, `m a -&gt; (a -&gt; m b) -&gt; m b`, for example. `State` is a type of kind `* -&gt; * -&gt; *`. When `State` implements the `Monad` typeclass, `m` becomes `State s`, where `s` represents the underlying state type wrapped by the monad. The `a` is just the `a` and `b` that appear in `&gt;&gt;=`'s type, `m a -&gt; (a -&gt; m b) -&gt; m b` and `return`'s type, `m a`. Thus, the `a` in `State s a` represents the type that the state monad puts in a monadic context (the thing that is `return`able and can be passed to the function given in `bind`). In the case of the state monad, `a` is often the "explicit" result of a computation that is done within the state monad, as opposed to `s`, the type of the state implicitly threaded through. It might help you to read http://brandon.si/code/the-state-monad-a-tutorial-for-the-confused/, which helped me understand the state monad. 
If by arrays you mean packed, contiguous sequences of memory addresses, then I don't see a way that's not O(N) to allocate them. The major question in a language with non-strict evaluation is how much of the data is actually used. Even if you declare an infinite stream but only use a few elements, only those will be computed: `fromList $ take 3 [1 .. ]`
It's different working with frp like Reflex: there's no virtual dom and therefore no diffing. You use streams to determine which bits of the dom need to change, so it's more powerful in that sense but quite different and perhaps more difficult to get a good result at first. On the other hand it's more flexible so you can carry over the lessons learnt to hook into more traditional GUI frameworks like gtk/qt/etc. - if someone plugs them together for you, or you're willing to do it yourself of course!
Furthermore, with OverloadedLists enabled, GHC will actually desugar `[x, y, z]` into `fromListN 3 [x, y, z]`. Notice here that `3` is the size of the list, and allows implementations to do something smart if they want.
What I understood about OP question was that he wanted to skip the conversion: &gt; I imagine this would incur some extra overhead in initialization from the list type.
There should be a `settings` file near your ghc executable (my executable is at `.../bin/ghc` and my `settings` file is at `.../lib/ghc-8.2.2/settings`) containing a bunch of configuration flags. Those flags are supposed to be detected for your machine, but I guess you must have installed ghc in a non-standard way and so you got some settings from some other machine. Just change the `C compiler supports -no-pie` from `YES` to `NO`.
Using a recursion scheme does sound like a good idea! It should allow you to first focus on your `eval` function without worrying about the tracing part, and then once you're done, switch `cata` for some custom recursion-scheme which implements tracing. Note that you'll need to write a custom recursion-scheme, as the existing ones like `para` and `zygo` give more information to the F-algebra in order to make fancier kinds of recursion possible, whereas here you want to give your F-algebra the same information as `cata` does, while producing an output which is different from `cata`'s.
I think it's easy to write scalable graphical apps in reflex, but it's also easy to write apps that scale very badly and not realize it. This is going to get easier to understand as people are writing more profiling tools for Reflex and good architectural practices are taking shape. Maybe there'll be a book in a few years, even. Here's a quick sketch of how it works for really large apps. I'm talking apps the size of Slack or Tableau or something. Because there's no virtual dom in Reflex you have exact control over what changes and how changes propagate. This is a double edged sword. If you're careful, you only do the minimum amount of work per event. If you're careless, you will fire events that don't do anything all over the place or worse: recalculate parts of the app that logically don't change. Some general pointers are to break up your events and behaviors as finely grained as possible. It is often good structure to pass in Events and Behaviors to components which return Dynamics or, preferably, Behaviors. It is often a warning sign when you're passing Dynamics in or Events out. Dynamics shouldn't depend on the update Events of other Dynamics. This is very often wrong and can lead to loops. If you have a dead loop in your program you might be tempted to break it with an Event delay, but this usually leads to a live loop or excessive Event propagation. When rendering DOM you often want to render a data structure, like a list. Dynamics are not well suited for such a task when used naively because their update Event returns the whole new value. If you were to draw based on that then you would redraw every element of the list every time anything changed. There's a few of approaches to dealing with this that work together. Many of us hope to package them up into nicer abstractions now that we've started recognizing them. There are two very important ones to know. The first is to push dynamicity into the leaves of your data structure. Instead of rendering a `Dynamic [a]`, you can work with a `Dynamic [Dynamic a]` instead. This let's you model changes to the leaves of the list separately from changes to the spine of the list. The nuclear weapon of this approach is `traverseDMapWithKeyWithAdjust` and the MonadAdjust class in general. It's quite rough in the currently unreleased Reflex 0.5 (which is what should be used since 0.4 is very old and doesn't have any lessons from industrial use incorporated). The second major technique is to use *patches* instead of naive update Events. There is a variant of Dynamic called Incremental whose update value is a type that represents changes to the value the Incremental holds. You can write your own patch types and specify the value type they act on. Combined with the previous technique this lets you incrementally update the spine of a data structure instead of all at once. You can specify arbitrary changes which is less user friendly but more powerful. To minimize Event propagation, and this is important because all Reflex computations are driven by Events, you want to split Events as early as possible while routing them to where they need to fire. EventSelector let's you do this. Many of the Events in a Reflex app come from `updated` of Dynamics. Using these a lot often leads to Events that fire even though no value has changed. This tempts people to use `holdUniqDyn` a lot. This usually indicates a structural weakness in the code and should prompt reflection. To diagnose excessive Event propagation there is a really powerful profiler in newer iterations of Reflex that will count Event firings and summarize them in a useful way. The golden rule for fast Reflex is to reduce the number of Events firing in your reactive network. So some takeaways: * it's possible, people have written huge apps that are competitive with similar tech * it's undocumented how to do this at the moment but #reflex-frp is a great place to learn. * it's a new frontier where people are still discovering patterns and techniques * Reflex-dom is written to be very close to the metal both as a DOM manipulation library and as an FRP library. You have very tight control but currently have to write your own components. The space is ripe for higher level abstraction.
Codewars or not, I liked the scripted format better. 
&gt; I imagine this would incur some extra overhead in initialization from the list type You know how we say that Haskell performance can be unpredictable and surprising? It's true, but most of the time, you don't notice it, because the performance is weirdly better than you would have thought. GHC is able to do some very clever things to eliminate lists, and it wouldn't surprise me if `fromList [1,2,3]` was able to fuse into a tight loop that created a vector efficiently.
&gt;Would you think it fair to say that the principle benefit of this reader approach is to avoid passing arguments manually? Yes, and it shouldn't be discounted – the costs of manual passing at scale mount high enough to destroy any ability to refactor. GHC, AFAIK still uses global mutable parameters to manage configurations, and that was a weighed, deliberate choice. &gt;But we don't have to, and almost certainly should not do this. Scala and Haskell are vastly different. IMHO a module is a module. Doesn't matter if you tie it to a monad, or tie it to a type variable, or put it in a type class or put it in a record or put it in a Backpack – it's still just a bunch of types and definitions with some contracts. Programming with \(first\-class\) modules looks the same in every language, I'm afraid. There may be some departures, like the kind of overloading used in lens &amp; recursion schemes – [Functor\-oriented programming](http://r6.ca/blog/20171010T001746Z.html) – but I'm not sure if it's actually different, and I don't think that was what you meant – I'm very interested to hear what kind of architecture you envision that is strikingly different from the current approaches.
Isn't fsplit basically [&lt;*&gt;](http://hackage.haskell.org/package/foldl-1.4.0/docs/Control-Foldl.html#t:Fold)?
I... don't buy it. Just follow the whole comment thread. It's /u/snoyberg commenting twice, with [contradicting] (https://www.reddit.com/r/haskell/comments/7shvxo/hash_based_package_downloads_part_1_of_2/dt5kqcd) [answers](https://www.reddit.com/r/haskell/comments/7shvxo/hash_based_package_downloads_part_1_of_2/dt653fi). And it's not some zero\-width space character, I suppose. Either the account was temporarily hijacked, or there's something else going on.
I would say yes. Have been building a stock (as in warehouse/sales) management system for a friend for several months as a side project, using reflex-dom. I am relatively new to Haskell but actually this project taught me a lot about it. Despite some hangups, i have been making good progress, and feel confident that it will work well once it is done. One of my favorite parts is the ease of refactoring, though that's a haskell thing in general, right. A component is nothing more than a function that contains other components, and the terminal elements are dom nodes. This makes composing components awesome. You keep state in dynamics and behaviors, which is a nice way to separate it from the presentation/rendering, and present it as a stream that is persistent between dom changes. All input happens through events. There are many ways to change the event's value, e.g. `fmap` its value, or replace the value with one from a dynamic or behavior (`tag`, etc.) It feels like building a pipeline where the final output is a description of the dom, but lots happens in the meanwhile (state changes, ajax requests, etc.). I'd say this all scales pretty damn well. Since there are no traditional patterns to use, you'd have to experiment a bit.
The comment in between the two comments you have linked asks if the first comment is a joke. Since the second comment clarifies that /u/snoyberg is not /u/snoyjerk, I think it's pretty clear that the first comment is indeed a joke.
Oh damn, completely missed this among the instances. In retrospect this makes sense since Fold feels like an inverse ZipList? i.e. combining consumers instead of combining producers, not sure if there is a formal correspondence there.
Past discussion: [1](https://www.reddit.com/r/haskell/comments/7shvxo/hash_based_package_downloads_part_1_of_2/dt4ukzg/), [2](https://www.reddit.com/r/haskell/comments/7shikr/replacing_hackage_hash_based_package_downloads/dt4sxpq/)
To me, &lt;*&gt; and Applicative is actually the entire "point" of the foldl library. Without it, the entire library doesn't really have a purpose imo
Are you aware of the [IRCv3](https://ircv3.net) working group and their goals?
I think what your looking for is [RebindableSyntax](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-RebindableSyntax). This will make do notation work with the operators you defined instead of the default ones from prelude. Just add `{-# LANGUAGE RebindableSyntax #-}` to the top of your file to enable it (you'll also have to hide `Prelude.fail`). Also `sequence1` seems to work without RebindableSyntax because you haven't given it an explicit type signature so GHC infers the type as sequence1 :: (GHC.Base.Monad m, Monad m) =&gt; [m t] -&gt; m [t] If you remove the type signature from `mapM4` (and turn off RebindableSyntax) it will seem to work too, but its type will be mapM4 :: (GHC.Base.Monad m, Monad m) =&gt; (t1 -&gt; m t) -&gt; [t1] -&gt; m [t] and it will use the functions in `Prelude` instead of the ones you defined.
&gt; As such, the termination behavior of this particular program is not "undecidable" so long as you work in a slightly more powerful mathematical foundation. No, because you may be using inconsistent formalism to "prove" it. You can't both informally assume that the formalism is consistent and then make the formal claim that it is provable in some consistent formalism. &gt; Rice's theorem does not apply to non-extensional properties (e.g. is the program shorter than a certain length). All non-trivial sound decidable type systems are non-extensional and so, in a crucial sense, incomplete (as is the normal case with abstract interpretation). It most certainly does, only the program under analysis is not the one whose source code you're analyzing, but the program counting the size of the source code. The same goes for the type checker. Rice's theorem (and its complexity-theoretic extension) still applies to the type checker, which performs an abstract interpretation of the program. &gt; I don't see how viewing type systems as abstract interpretations gets you the result you claim. Nothing requires the "concretization" function in such a view to be decidable. Why is that necessary? What result are you referring to? The only requirement is that the abstraction is sound. Due to bounded halting, if you know the complexity of the type checker, we know the strength of the type system. &gt; that those systems or problems must have such intrinsic complexity as to make verification impossible. I never make that claim. On the contrary, I'm a proponent of formal methods, and [have written at length](https://pron.github.io/tlaplus) about their utility. &gt; My thinking on this goes roughly like this. People who build modular systems have mental models of the modules. And it is very unlikely that the system succeeds by accident, so if they built a system that worked, those mental models are almost certainly sufficient to understand why the system can be put together in a way that works. But my post gives a counterexample, and after almost 25 years in the industry, I'm fairly confident that the kind of reasoning I outline is a prevailing one.
&gt; You can't both informally assume that the formalism is consistent and then claim that it is formally provable in some consistent formalism. Sorry, I don't understand what you are saying. I can of course informally claim ZF is consistent. And at the same time, consistency of ZFC is a theorem in many other formal system (e.g. NBG) Similarly, that the machine Z never terminates is a theorem in ZFC+one inaccessible cardinal. If computability is as, Godel says, absolute, then there is an answer one way or another. Z terminates (unlikely) or it does not, and it would be reasonable for a mathematician to work in a foundation where it was a theorem. Perhaps this is neither here nor there since in any foundation some (small) program's termination behavior will be unknown. However, one should not claim that any particular program is outside mathematics since mathematics qua mathematics is not a formal system and so its axioms are not settled or fixed (as my example of Fermat's last theorem indicates). &gt; Well, if the program under analysis is not the one whose source code you're analyzing, but the program counting the size of the source code, then the size of the source code is extensional. Also don't understand this. Rice's theorem is a theorem about *properties of partial functions* and when you can decide if a program satisfies them. Program analysis techniques, as well as type systems, are possible for this reason: they might provide different answers on two programs which encode the same function. &gt;The difference between inference and just checking is the computational process required. This is not precise, at all. I can always have terms which guide my type inference by providing type information as necessary, but where the type inference still has to do quite a bit of work to find a derivation. One is in fact used to this situation whenever one uses operators which constrain a type. Haskeller's, for instance, might define something like asInt :: Int -&gt; Int asInt = id and then if they say asInt $ 1 + 2 they force a type which would otherwise be polymorphic. I can give a proof assignment system for PA where type reconstruction (that is inference) is decidable. Type inhabitability is not. &gt; Why is that necessary? What result are you referring to? Due to bounded halting, if you know the complexity of the type checker, we know the strength of the type system We do not. If you give me a closed term in a reasonably presentation of System F omega I can always finds its type. However, I can not go from a system F omega type to a term of that type. For another example, I can have an intermediate type system between (total fragments of) HM and MM where some polymorphic recursion is permitted such that types are fully inferable (with no annotations) and the only programs of some types involve recursion. Or, perhaps a clearer way of saying this: type checking in the foundational proof assistants is decidable but typeability is very much not. That has nothing to do with dependent types (HOL has no dependent types but the same property). So, what exactly are you getting at?
When I was first investigating recursion schemes it sorta shocked me to learn that coalgebras don't compose well. This surprised me because catamorphisms *can* compose under Applicative. What you want is something with a type `forall f a b. Coalg f a -&gt; Coalg f b -&gt; Coalg f (a, b)`. But a Coalgebra has the responsibility of decomposing the carrier functor, signaling when recursion terminates. I found this very surprising the first time I worked through the problem. An alterantive model for catamorphisms is to use Applicatives. Gabriel Gonalez [gives a really nice summary here](http://www.haskellforall.com/2013/08/composable-streaming-folds.html) that I think would be a more useful method of thinking about catamorphisms for your applications.
Thank. update the code. Still have a doubt. Why I can't add `sequence2 :: (Monad m) =&gt; [m t] -&gt; m [t]` otherwise it failed like &gt; Couldn't match type ‘m’ with ‘[]’ &gt; ‘m’ is a rigid type variable bound by &gt; the type signature for: &gt; sequence2 :: forall (m :: * -&gt; *) t. Monad m =&gt; [m t] -&gt; m [t] &gt; at /Users/jiamo/haskell/projects/funy.hsproj/funy/lib/Cartesian_product3.hs:41:14 &gt; Expected type: m [t] &gt; Actual type: [[t]] &gt; In the expression: [[]] &gt; In an equation for ‘sequence2’: sequence2 [] = [[]] &gt; Relevant bindings include &gt; sequence2 :: [m t] -&gt; m [t] &gt; (bound at /Users/jiamo/haskell/projects/funy.hsproj/funy/lib/Cartesian_product3.hs:42:1) For me I already make `[]` a instance of `Monad` so `[[]]` should be thinked as `Monad` too. 
My worry is that cabal-install has taken it upon itself to install dependencies itself despite having done so in Nix as well. You can check this by using a blank *global* cabal.config file with `--default-user-config=/dev/null`, which removes cabal's believe that a remote Hackage repo exists.
When you add that type signature what you're saying is that `sequence2` works with *all* types that are instances of `Monad`, not just `[]`. `[]` is an instance of `Monad`, but that doesn't mean all instances of `Monad` are `[]`.
2) This was posted last week. https://www.reddit.com/r/haskell/comments/8l1mka/tintin_a_soft_documentation_website_generator_for/
Unrelated: `Data.Function` defines `&amp;` so you don't need to define it.
I'm very confused. They're two different packages...
I included `TQueue` in the benchmark for that purpose, and `TChan` did benchmark faster than it. But again, I'm not claiming at all that I wrote a good benchmark. Apologies for the low quality information coming from me here.
Not in any detail, but I discussed it in connection with these chat topics with some coworkers. Overall, since it's not well adopted yet, it didn't seem like a contender.
I don't understand. Which part of my comment were you replying to? If the first part, this program gives me exactly the same output whether I use `myEmpty` or `empty`. If the second part then could you elucidate? import Data.Functor import Data.Monoid import Options.Applicative sample :: Parser () sample = () &lt;$ myEmpty main :: IO () main = void (execParser opts) where opts = info (sample &lt;**&gt; helper) ( fullDesc &lt;&gt; progDesc "Print a greeting for TARGET" &lt;&gt; header "hello - a test for optparse-applicative" ) myEmpty :: Parser a myEmpty = argument (maybeReader (const Nothing)) idm Output: Missing: Usage: test3 Print a greeting for TARGET 
Also see http://newartisans.com/2018/04/win-for-recursion-schemes/ for more notes on using ADI in this context.
I think it was for your question number 2.
Oh, cool! Only knew it from lens but apparently it was added to base in 2015 and [lens only reexports now](7039887d22952059cf0b443af74799dc1c42dccd).
How would it know the size of the vector without realizing the list before copying its contents?
There's some Gödelian shit going on here.
spiderman.jpg
The inactivity of the mods around this issue is infuriating. I really don't understand the argument that trolls will create more sock puppet accounts. This issue at hand is that the username was picked to deliberately impersonate another member of the community \- rather successfully I might add. Can we not make this troll's life just a little harder and make him pick a different username?
Here's a relatively straight forward solution using GADTs, TypeFamilies and DataKinds. https://gist.github.com/LukaHorvat/24dbb7cb73bcdf48712d5d4839f17877 Aside from some repetition (which I'm guessing doesn't really matter if you're generating the code), it has no downsides. You even get non-exhaustiveness checks.
I don't understand why such blatant trolling isn't just banned immediately. If they create more, as soon they're discovered, ban those too. I doubt that they will be able to create so many accounts and shitpost so much that it becomes any real burden on the moderator team, at least not compared to the burden on the troll.
[removed]
&gt; As an application developer, I must ask - why would we want this? If this can be used for polymorphic record update, it is useful. If not, it's probably not, but I think the technique (including the proving part) is nice and might be helpful elsewhere, so decided to share. &gt; Polymorphism is usually bad and should be avoided and removed wherever possible. The reason is because it makes the meaning of code less precise. This impacts both humans and the compiler. For humans, it makes the code harder to read and understand, and thus more expensive to maintain. Polymorphism allows to abstract away unnecessary details and make your code more structured and less cluttered with internals of a particular implementation. But this all depends on the actual use case, of course. I do not have any immediate opinion on whether `mono-traversable` (or hypothetical `poly-traversable`) is a good thing or not. &gt; When you generalize in a way that is rule-based and semantically meaningful, general code can be simpler than specific code. I think that "rule-based" and "semantically meaningful" are largely overlapping, but still distinct concepts, but that appears to be a rather unpopular opinion. &gt; So if the purpose of this "even more polymorphic mono-traversable" is to put it on a more solid rule-based semantic foundation, I'm all for it. I stumbled across a problem, thought "fun" and wrote down a solution. I do not know whether it's worth solving the problem from a practical perspective in the first place. Those type families and shape constraints do not look too scientifically pleasant. As well as, say, [Trees that grow](https://www.microsoft.com/en-us/research/uploads/prod/2016/11/trees-that-grow.pdf).
[removed]
I am snoyjerk.
[removed]
I always viewed it as an obvious parody. Why would anyone choose a username to represent themselves with "jerk" in the name?
Ah now it makes a lot more sense! Well, that does answer the question but then the program isn't available as a `.hs` source file on Hackage which you can load using `ghci` or `stack ghci` which is a big drawback.
Here is a polymorphic function: a -&gt; b -&gt; a I know what it does. Here is a monomorphic function: Int -&gt; Bool -&gt; Int I know it does one of (Int^Bool)^Int possible things, which is an intractable number. Polymorphism improves readability. Not that mono-traversable is itself, a good idea. 
&gt; In the past, I've jokingly/sarcastically had some banter with snoyjerk, which unfortunately gave the impression—or even stated— that it was, in fact, my account Here's my personal view. Note: it is ***not*** an official moderator proclamation. The way I see it, the reason why snoyjerk has not been banned is clear from their posting of this link on the subreddit: Snoyman has given up on the subreddit, for well-known political reasons, and IIRC apart from a single thread, almost all threads in the past year or so linking to Snoyman's Haskell blog posts have been shared by snoyjerk. Moreover, Snoyman has never complained about snoyjerk, and I have indeed witnessed them communicating amicably (by responding to each other's comments). Ultimately, if you don't like the insinuation in the name "Snoyjerk", then you have to ask yourself whether you're merely being offended on Snoyman's behalf? Snoyman has never indicated that he is unhappy about the existence of the snoyjerk account, and we find ourselves in the awkward situation where an obvious troll account is contributing more of Snoyman's posts to this subreddit than Snoyman himself. 
&gt; I stumbled across a problem, thought "fun" and wrote down a solution. Oh yes it's definitely interesting, and worthwhile to write down. Thanks for sharing it! &gt; Polymorphism allows to abstract away unnecessary details and make your code more structured and less cluttered with internals of a particular implementation. But this all depends on the actual use case, of course. That's exactly the point. If the polymorphism makes sense semantically - then yes. If it's just random polymorphism for no reason, then no, it does not remove "clutter", it removes important information. &gt; I think that "rule-based" and "semantically meaningful" are largely overlapping, but still distinct concepts, but that appears to be a rather unpopular opinion. I'm not sure. It's sometimes possible to use lawless polymorphism without immediately causing problems, but usually you will find that it depends on programmer discipline. The whole point of having a powerful and expressive type system is that you shouldn't need that. Case in point: the `Default` class. When first proposed, this seemed like a good idea and it started to become popular. But that class has no laws, and people began to discover that it can cause problems. The following controversy is history. Here is a [reddit discussion](https://www.reddit.com/r/haskell/comments/5gospp/dont_use_typeclasses_to_define_default_values/) about it. From there you can find links to various blog posts taking various positions about this.
It does have a Comonad instance if you supply the flag. I think I forgot ComonadApply though.
I know exactly what `a -&gt; b -&gt; a` does by paramatricity, so that is not lawless polymorphism. Furthermore, you cannot use that type for almost all functions whose type is `Int -&gt; Bool -&gt; Int`, again by parametricity, so the two types are unrelated. And furthermore, the number of inhabitants of a given type is unrelated to the readability of the type.
FWIW, when `Default` was proposed, it was immediately obviously a bad idea, to the point that it was discussed as so by many: *eyeroll* quickly dismissed, and subsequently moved on from.
Typo, thanks!
Bro, do you even Haskell? http://hackage.haskell.org/user/MichaelSnoyman
&gt; For general purpose libraries, it's much more common that polymorphism is the best approach. You're talking out of both sides of your mouth here: neither the original blog post nor mono-traversable are applications - they're general-purpose library stuff.
In my previous job we used a custom Monadic FRP library + GHCJS + virtual-dom and a 10k line web portal. At my current job we have a 2k dashboard written using Applicative FRP. This took some effort and developer training to get started with, but has turned both powerful and pleasant to use. - If there are sin-bin connectors to IO they are likely to be abused. Good library design and developer dicipline is needed here. - The full power of monadic FRP/event switching is often overkill. Applicative/Arrow-based FRP has the advantage of being simpler to use and implement, though of course there are be cases where the full power of monads is required (UI designer tools come to mind).
Speak for yourself.
Finding inhabitants of types corresponds to proving statements. Readability and provability are orthogonal. Ever hear of the Goldbach conjecture, or Fermat's Last Theorem? More to the point, the type `Int -&gt; Bool -&gt; Int` is extremely clear and readable. Do you have any trouble understanding this type? When you have a function or expression with this type, both the compiler and human readers know exactly what is going on. Whereas if you see `def :: Default a =&gt; a` in an expression, there is no way to know the concrete type without referring to surrounding context, or perhaps even distant modules or libraries. And even then it might be very subtle to figure out, as pointed out by some people in the reddit thread I linked to above.
Thanks for the update. I applied via the website as well. 
Amusingly, once you move into the dependently-typed world it becomes a perfectly sensible idea: we just call it *Decidable*! This is because trivial-ness and unique-ness don't coincide in the dependently-typed world: we are often interested in constructions which are not trivial, yet unique (e.g., `_&lt;_`).
I actually don't mind snoyjerk. It's definitely not the kind of thing I would do myself though. He has rubbed me the wrong way by editorializing a title once or twice, but he seems mostly fine. I think it is the name that gets to most people.
Oh No, I'm a newb, currently reading the Haskell programming book
The `Default` type-class is a bad idea due to more handwavy reasons. For example, every occurrence can be replaced with passing a function argument, and nothing of value is lost.
Right, see my edit (which wasn't there when you replied, apologies!) - the reason it's useful is because you can get the solver/instance searcher to do work for you. I posted an [extremely immature prototype of this](https://identicalsnowflake.github.io/ProductNormalisation.html) a while back (I've since made it a lot cooler, but never bothered posting it for some reason).
What's the difference between Asterius and /u/ElvishJerricco's effort?
Got the cooler one?
We don't have any control over usernames. Sure, we could ban them, but there's nothing to stop them from coming back with /u/snoyjerk123 or whatever. Additionally, the account itself doesn't actually troll that much outside of it's name. Snoyman has a post now stating that he isn't this person, I see no reason not to take him at his word on that; though the irony of "I'm not snoyjerk" being posted by snoyjerk is not lost on me. I could spend the next very many days banning every variant of all sorts of different troll names, but the powers granted to mods are exceptionally limited and I have other things to do. If we had some crosscutting method to fix this class of problem, then it would be employed, but we don't. 
What happens if you try `lifA3 (‚‚)` instead of `sequenceA`?
If it's WebGHC you're talking about, there's a whole section about that in the article titled "The Haskell to WebAssembly story". In short, WebGHC is leveraging LLVM, whereas Asterius is going direct to WebAssembly, like the native code generator (NCG) does for existing hardware architectures. Let us know if anything is unclear.
These aren't mutually exclusive at all.
Can we block users individually? No need for a ban or anything that drastic. But if you/we can block them, then the noise goes away. 
out of interest, which codegen bug?
thanks! I really wondered why `mono-traversable` was not polymorphic?
I mean library code that is providing some new functionality. Polymorphism allows the new functionality to be applicable in more cases. The mono-traversable library does not provide any new functionality. Its whole purpose is the polymorphism itself - it introduces polymorphism into application code that otherwise could have been monomorphic. In theory that could be useful, if independently there is some reason you want to introduce that specific kind of polymorphism somewhere in your code. And perhaps you might want to do that in library code. But in my experience, I have never seen a case where the kind of polymorphism introduced by mono-traversable would be helpful in application code.
Does mono-traversable disagree on this point? From [their documentation](https://github.com/snoyberg/mono-traversable/tree/master/mono-traversable): &gt; As an application author, you should consider using classy-prelude, which leans heavily on mono-traversable. &gt; When writing your own function signatures, you should default to making them concrete: if you are actually using a list, then make your function take a list rather than an IsSequence. This will improve type inference, error messages, and make your code easier to understand.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [snoyberg/mono-traversable/.../**mono-traversable** (master → 217b104)](https://github.com/snoyberg/mono-traversable/tree/217b1040ee4dc18a143d20ffb4b76c250e756940/mono-traversable) ---- 
"I was distracted when drinking my coffee and now it's ever slightly not as warm as I like it"
Basically, the prototypeless function declarations allowed in C don't work on wasm, so we have to hunt down and fix all of these to use standard C. I've fixed the vast majority of these issues in GHC already, but it seems I've missed something.
"I had just arrived to a ten-day silent meditation retreat, and just as I'm about to switch off my phone I get a call saying all the production servers have crashed at once".
Use `-XOverloadedLists` instead of the specific container's monomorphic `fromList`. The `IsList` class which backs the extension has a `fromListN` method which receives the list literal's length, allowing libraries to provide a more efficient implementation.
Would you be able to elaborate on GHC cross-compilation with Nix? I've been chasing that for a while for some work projects, but I haven't seen a working example (or at least not one that I could get working).
reflex-platform uses it already to compile some pretty complex Reflex apps to mobile. I think the story upstream is currently a little broken, but none of it seems too hard to fix, and there are interested parties actively workin on it
Much appreciated. I'll go dig around in reflex-platform again to see what I can put together, and I'll keep my eye on the upstream. I know there's some kind of refactoring of the cross infrastructure going on, but it's not wildly visible.
I was asking how an explicit use of fromList could fuse, as was suggested in my parent comment.
Oh, cool, I hadn't seen that! Thanks. That cross overlay and `cross.nix` look like just the bits that I've been missing. Maybe I can finally scrap my hand-built cross toolchain!
&gt;I could spend the next very many days banning every variant of all sorts of different troll names, but the powers granted to mods are exceptionally limited and I have other things to do. If we had some crosscutting method to fix this class of problem, then it would be employed, but we don't. I think you're overestimating the commitment of such trolls. I'm quite certain that the mod team currently outnumbers trolls trying to harm the community by impersonating others. Is it possible to at least add flair to these confusing account names?
&gt;Ultimately, if you don't like the insinuation in the name "Snoyjerk", then you have to ask yourself whether you're merely being offended on Snoyman's behalf? Snoyman has never indicated that he is unhappy about the existence of the snoyjerk account, and we find ourselves in the awkward situation where an obvious troll account is contributing more of Snoyman's posts to this subreddit than Snoyman himself. This is absolutely not the case why I think a ban is appropriate. I'm not offended on Snoyman's behalf but rather concerned for the community. There is no other programming subreddit where every tooling discussion \(Stack vs. Cabal\) is filled with obnoxious trolling by joke accounts. The fact that snoyjerk /= snoyberg is nowhere near obvious enough and I constantly see people who aren't regulars on the sub confused by this. Honestly, I'm already quite used to this situation, but I can't help but think how much damage this has caused this community and Haskell.
FWIW I actively avoid communities with an obvious and persistent troll, I assume others do too.
https://status.haskell.org says all systems go :-/ I have two mails in the queue...
What you'd like is a combinator to take two F-Algebras and turn them into a single composed F-Algebra. I haven't seen this before and at first I thought it was impossible, but then I realized that in fact, its pretty obvious: type FAlg f a = f a -&gt; a (&lt;+&gt;) :: Functor f =&gt; FAlg f a -&gt; FAlg f b -&gt; FAlg f (a,b) c1 &lt;+&gt; c2 = \f -&gt; (c1 $ fmap fst f, c2 $ fmap snd f) I don't think this is excessively expensive because `cata` constructs these values bottom up. I have a whole example here: https://gist.github.com/KirinDave/7e8ed107c372e197e181ee716b34753e
Oh dear, I barely understand people saying `lens` is heavy dependency, but `comonad`... If you don't yet, use `stack` or `cabal new-build`. **Don't** use cabal sandboxes anymore. Stop recompiling `comonad` (and `lens` and other libraries, all the time). Or alternatively, make the flags on by default (and maybe name them with package names: `comonad` and `QuickCheck`, as at least Ed Kmett seems to do for his libs). 
In case you missed it, links to past discussion/votes/arguments: [1](https://www.reddit.com/r/haskell/comments/7shvxo/hash_based_package_downloads_part_1_of_2/dt4ukzg/), [2](https://www.reddit.com/r/haskell/comments/7shikr/replacing_hackage_hash_based_package_downloads/dt4sxpq/), [3](https://www.reddit.com/r/haskell/comments/8mo1uc/my_open_source_goals/dzpdmt7/)
I don't actually care one way or the other, but I do think you're misrepresenting the argument for a ban. Regardless of who is or isn't offended by it, it creates a real *logistical* problem when people mistake /u/snoyjerk for /u/snoyberg. We've seen people ask genuine questions for /u/snoyberg in a response to /u/snoyjerk. I think a user flair like `not actually snoyman` would solve the problem, though I'm not sure whether that's a good idea or not.
IME with trolls, they're pretty persistent, once they get someone to react to them at all, they dig in. Admittedly I might be jaded, but it's not without precedent to have very committed trolls. I'll bring up the idea of flair w/ the modteam, but AFAIK flair is getting changed in the new reddit design, so it might not be viable longterm. 
&gt; posted by `snoyjerk` 😂🤣
/r/golang gets trolled on tooling too. Anything even remotely related to generics as well. Can not fathom the mindset, but here we are.
&gt; Updated 13 days ago
&gt; we find ourselves in the awkward situation where an obvious troll account is contributing more of Snoyman's posts to this subreddit than Snoyman himself. Doesn't Reddit discourage posting one's own content in any case?
Thanks for posting this in a visible, easily to link to place. As you say, snoyjerk has been relatively harmless so far, though it can be hard to predict the next steps of a troll. I guess it all will be fine as long as everyone reading this is ready to swiftly report any further impersonation attempts.
Speaking of which, I pinged the mods some time ago, but it would be nice to update the theme so it works with the redesign -- I'm missing the logo, the rhs links, etc.
Item #1 suggests to me that rts needs WAY more tests.
We were entirely gummed up with spam. I cleared out some of the stuff in the queue, added a rule to block the one persistent sender, and hopefully it will now start processing again. Ick.
I think that’s mostly an anti-spam measure. I don’t think anyone’s likely to complain if ekmett writes something he thinks is interesting and posts it here.
There's a whole thing with themes in the new mode. I'm pretty sure we'll need to revert to the defaults for a while, but work has been busy so I haven't dug into it. I did see your modmail though, it's on my list.
Could you open up that GitHub issue tracker? Your vector should surely use an `UnliftedArray` (from `primitive` master) instead of a `Vector`.
Always super excited to see work being in getting Haskell to WebAssembly. I have never been really happy with the workflow using GHCJS*, and hope that tooling etc is not overlooked with this effort. * I completely understand that the whole endeavour is in super need of more hands, ofc. 
(Int -&gt; Bool -&gt; Int) tells me relatively little about how the function behaves. Even (Default a =&gt; a), not that I'm advocating for the Default class, tells me more, because the only reasonable definition for that type is def itself. Maybe I don't necessarily know what the value of def is for that type, but it still tells me that any two things of that type have the same value, unlike just Int. 
I would vote for a user flair, if at all possible. I don't think /u/snoyjerk's continued use of the sub should be contingent on the use of the flair or anything, but as someone who has been confused by this in the past, it'd be nice to have.
For what it's worth, upstream `nixpkgs` isn't even really that broken at the moment (in large part thanks to /u/Sonarpulse; see https://github.com/NixOS/nixpkgs/projects/8 for the current state of things). I'm using it in a project and have found cross-compilation of Haskell under Nix to be quite reliable.
Perhaps I have read it too quickly and missed something, but isn't this quite similar to van Laarhoven optics? For instance, `pmap` looks a lot like `over` from *lens*, except that, instead of passing the dictionary (i.e. the `Setter`) explicitly, you supply it through a `PolyFunctor` instance. (You then use the typeclass as a springboard to encode some of the interdependencies between the lens family type parameters -- cf. the "Why is it a lens family?" section in [this post](http://comonad.com/reader/2012/mirrored-lenses/).)
Also available on chocolatey for windows users. `choco install ghc`to install or `choco upgrade ghc` to upgrade an existing install. It is now also available to CI scripting in AppVeyor. 
A third one might be *architecture*, including things like the wielding of monadic stacks and proper exception handling, as well as the art of setting up comfortable, unproblematic APIs.
Great news! Given the DWARF improvements, is "perf record -g" going to work on Haskell programs as it does with other languages? i.e: Will we be able to get source-level flame-graphs from "perf"? If not, what's missing so we can?
&gt; eventually exposing a full built-in GC, a threading model, exception handling etc I strongly suspect the built-in GC will not be friendly to Haskell whatsoever (and actually I'd strongly prefer they make wasm better at facilitating custom GCs for this reason rather than adding a GC to wasm), and that the exception handling will not be particularly useful to Haskell. &gt; The cost of LLVM is significantly longer compile times I haven't tested this, but I get the feeling this is only true because we ask LLVM to do a large optimizations that we just don't want. If we only enabled the optimizations we want (which, as you said, is not much), I suspect the compile time cost of LLVM would go down considerably.
Opened! Good point on `UnliftedArray`.
I am in the same boat as you now currently. Still figuring out the best way to deploy Haskell web services (for us). In the meantime, to get the service out ASAP, I have been building the app binary on TravisCI (stack has a Travis guide) and copying the binary to a s3 bucket. You could also use Amazon Code Deploy to copy the binary directly to EC2. On the EC2 instance, I am running the binary manually on every deploy. In the immediate future: - build the binary on Travis - prepare docker image (Ubuntu base) with the binary - deploy with nanobox (https://nanobox.io) Building the binary on Travis let’s you leverage more computational power than your ec2 instance. So use that. Keter could also be built once for Ubuntu on Travis and copied over. 
As in plastonist versus formalist? I would consider myself the former.
If you are OK with not using EC2, then I find the easiest way to deploy to production server is by using Heroku using this buildpack: https://github.com/mfine/heroku-buildpack-stack Depends on your scale, you can pay $0 forever to get your server up and running.
Where is the `fltk` folder? I have no idea how to navigate this :/
Glad to see #14381 is finally fixed. Unfortunately I broke my promise to see that change through, but I more or less haven't had any time since the original quick attempt. Thanks Tobias!
I would really appreciate it if every situation involving Michael Snoyman would just stop being so bizarre, effective immediately. Thank you.
...[right there](https://github.com/elaforge/karya/tree/work/fltk), in the repo's root folder?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [tathougies/beam/.../**beam_query.py** (master → f1502f1)](https://github.com/tathougies/beam/blob/f1502f1043622fdac15b1ce41db95cad3705dd27/docs/markdown/beam_query.py) ---- 
I'm sorry I didn't make this clear in the post, but I was looking for something which the user could load into ghci directly. I believe the solution you're using is very much like tintin where the code is inside a markdown document, instead of the documentation being inside a Haskell module.
Firstly, WebAssembly is a moving target (and I am sure even the WebAssembly folks don't know where it is going to end up at). Hence, much of the discussion about different approaches is build on unstable ground and it is good to concurrently explore multiple approaches. Having said that, IMHO you are misjudging the relative complexities of WebGHC versus Asterius. Just using LLVM as a cross-compiler to WebAssembly sounds conceptually very simple, but (1) WebAssembly is a very different beast from a normal architecture and (2) generally porting GHC to a new architecture is surprisingly intricate. Moreover, reusing the RTS wholesale sounds like a good and simple idea, but it is quite unclear how useful that will be for WebAssembly. Some of the biggest and most complex parts of the RTS, such as GC, low-level parts of multi-threading, FFI, and so on are going to be useless on WebAssembly, or at least will require a lot of effort to work efficiently. So now, you will need go into the RTS code add many architecture dependent #ifdefs and write your own code anyway. How is that simpler than what Asterius does? When you talk about a registered build, you mention tail calls (and who knows when WebAssembly will add those), but you forgot to mention TABLES_NEXT_TO_CODE. And what about libffi? Low-level architectural issues are complex and, in my experience, there are not that many developers around who are willing to tackle them. In comparison, writing a new code generator sounds a lot more feasible and scalable (in terms of finding contributors) to me. As for the RTS, there is quite a bit of Cmm code in there, which Asterius can also use as is. Then, as I mentioned before, a lot of the complex code will need to be at least adapted (as in implement an architecture-specific variant) anyway, even for WebGHC. Replacing the C part of the RTS wholesale and in a manner that matches the storage management and multi-threading capabilities of WebAssembly may well be the simpler task. (Both routes will be a significant amount of work, that is for sure.) So, please don't discount Asterius effort on the grounds of what you think sounds like a simpler approach. If you go through the actual engineering requirements of either case, you will find that they are rather considerable whichever you choose. Our main reason for going with Asterius' approach is not that it is supposedly simpler, but that it provides us with *more flexibility* to adapt both the code generation and the RTS to the requirements of WebAssembly. This will enable us to optimise both to achieve the best performance, fit well into the WebAssembly ecosystem, and generate small executables. IMHO, this is what matters.
Author here. Feel free to ask questions.
&gt; Some of the biggest and most complex parts of the RTS, such as GC, low-level parts of multi-threading, FFI, and so on are going to be useless on WebAssembly, or at least will require a lot of effort to work efficiently I don't agree with that in general. The GC will be fine with the via-c backend. We don't need multithreading (it's hard to get on the web anyway), and it is easily disabled. The C FFI required a bit of work but mostly worked out of the box; this is already done. &gt; When you talk about a registered build, you mention tail calls (and who knows when WebAssembly will add those) The proposal has been making progress recently. I'm hopeful it'll be available in the next year. &gt; but you forgot to mention TABLES_NEXT_TO_CODE. And what about libffi? TABLES_NEXT_TO_CODE doesn't seem possible on wasm regardless of implementation and is easily disabled. Other than ghci, which we don't need straight away, libffi is only used for one very minor feature that, as far as I know, is exceedingly uncommon. We've already done the work to disable the use of libffi outright (turned out pretty easy), but I believe it may be possible to implement libffi for wasm in the future. &gt; Low-level architectural issues are complex and, in my experience, there are not that many developers around who are willing to tackle them. In comparison, writing a new code generator sounds a lot more feasible and scalable (in terms of finding contributors) to me I don't understand this claim. Isn't writing a new code generator a low level architectural issue? I'm not really sure in what way you're differentiating WebGHC and Asterius here. &gt; a lot of the complex code will need to be at least adapted (as in implement an architecture-specific variant) anyway, even for WebGHC Do you have any examples in mind? Admittedly, I haven't gotten into the weeds with the RTS yet, but it did compile easily, and my impression so far is that it will mostly just require some syscall emulations, which I don't expect to be significantly slower than their real OS counterparts.
Yeah, you're totally right. I'm going to remove it.
Same for Foldable, Traversable, Semigroup and Monoid.
store if you want fast and no security checking or human readableness. binary package allocates an order of magnitude more memory to achieve the same thing.
It’s not defined to be exactly 8 bits either.
I agree with the criticism of the OOP approach in general. But for my taste it praises functional programming too much. In the context of Haskell: * There are only few universally accepted good practices and many ways to solve a lot of common problems. For example some use exceptions for error handling others don't. Some use Text others stick with String. There is more than theoretical properties to best practices. And the heterogenetic reality can add complexity (understanding the different approaches, combining them in your program). So pure functional programming is not magically making everyone agree to practices that are good for everyone. * I don't agree with "Debuggers are rarely needed". When programs get complex and big enough then debuggers will be desperately needed. In my experience big programs will run in situations that are not covered by tests because they run to unexpected states. It is impossible to test everything 100% in isolation. Even if you do there often will be new potential bugs when you combine multiple well tested components. For example in concurrent applications. And if something goes wrong in in production the best way to understand it would be to attach a debugger and investigate the state to understand what happened. But we can't really do that for Haskell programs. Of curse it is nice to be able to reason about a piece of code without running it. But verifying assumptions by setting a breakoint, running the program and investigating the actual state can be very helpful (or even needed) to have a correct understanding of a program.
Where are the DWARF improvements?
You've guessed what my next post, already half-written, will be about.
This interface is already exist: * [https://github.com/chpatrick/codec](https://github.com/chpatrick/codec)
I'll be waiting for it :)
For the use cases I imagined, I was leaning towards run\-time error handling, since run\-time for the eDSL is compile\-time for the machine code. That was before I saw [this comment](https://www.reddit.com/r/haskell/comments/8mdtwk/sixty_five_oh_two_a_haskell_edsl_for_writing/dzr6zj2) though.
I am very impressed by the natural sounding music it produced! I understand that this is partly because of the VST sample plugins being used. But undoubtedly, it also shows that the editor is capable of rich annotations! I hope I will get it to work soon :-). 
&gt; You can use (a *-kinded variant of) the :-&lt;: class from Data Types a la Carte if you want a general automated proof search for injecting values into coproducts. I love this idea. That's what was implemented (more or less) in [this comment](https://www.reddit.com/r/haskell/comments/8mdtwk/sixty_five_oh_two_a_haskell_edsl_for_writing/dzr6zj2). I don't believe it's overkill, as all of these type signatures are being automatically generated anyway. Thanks for the link to the paper, I'm about half way through it and it's been a super interesting read by the way. &gt; So you might be able to split up AddressingMode into a few smaller types and use them as your argument types. I'd like to keep the same syntax for the `AddressingMode` constructors throughout each opcode. 
I'd love it if intero or some other Emacs tool could turn those \`Not in scope: Map.toList\` errors into suggestions that I could apply with \`C\-c C\-r\`, like they do with language pragmas. Of course, they'd have to look through my other .hs files for what module \`Map\` typically is, but a fuzzy method would be better than nothing.
Yep, it doesn't make sense for it to be a functor or anything. I've only ever used the Scala port version of this lib and there is no mapnor anything on that version.
&gt; So now, you will need go into the RTS code add many architecture dependent #ifdefs and write your own code anyway. I hope there won't be too many of those, but if the result is a more layered RTS, like how the linux kernel `arch/*` directories are structured, I think it would be very good for GHC as well. Getting architecture-specifics separated out from the higher-level parts of the RTS could at some point pave the way for implementing more of the RTS in Haskell as well.
This is very good for GHC IMO. Thanks!
That's nice except it describes a strawman OO from the 90s, not modern 'mixed-paradigm' OO. Programmers in mixed-paradigm languages such as Scala, Kotlin, and even Java and C# have long since abandoned classical OO. 'data classes' directly contradict classical OO, singleton scope dependency injection contradicts Alan Kay's views of a program as independent interacting entities, instead just lifting the `import` mechanism to work on first-class modules approximated using classes. Programmers have realized that the only valuable part of OO was *modularity* and the modern approach boils down to 'procedural programming with first-class modules', no one attempts to model the world using complex inheritance hierarchies and abstract data types anymore. "Rich domain model" using encapsulation is dead, "anemic domain model" using algebraic data types is king. That's why new languages – such as Go, Rust, Swift, Nim – don't even bother including a classic OO system anymore.
I removed these broken instances; updated the link with the new version. I apologise for this oversight.
`Generic` and `Data` should probably go as well.
Yeah, this is definitely true. Thanks for pointing that out.
I tried finding it from the [source link](http://ofb.net/~elaforge/karya/hscolour/) the author gave on the announcement page.
Did my posting of [sdl2-sprite](https://github.com/chrisdone/sdl2-sprite) 18 days ago motivate publication of these packages? =)
Feel free to ask if you have questions. The going will likely be rough in the beginning!
Oh I see, that's because it's hscolour output, which of course only works on haskell. But now that it's on github, which can also show source, there's not much point generating hscolour anymore. I'll replace it with a link to github.
The only reliable way to automate deployments I found so far is docker images. If you do not use docker, then simply copying exe to the target machine would work fine. First time you would have to copy the entire folder structure and all the config files etc. But after that, 99% of the time it is just one exe.
This release has a lot of good stuff. I would encourage anyone using \`primitive\-0.6.2.0\` or \`primitive\-0.6.3.0\` to upgrade as soon as possible. Those releases have a number of typeclass instances whose methods are implemented incorrectly. Consequently, they have been deprecated. Going forward, we have a test suite in place to prevent these kinds of mistakes from happening again.
Care to share more about all the new cool stuff we have, fellow contributor ? :)
Eh. I'm a fan of nixops but it's only "trivial" if you already understand Nix, NixOS, and probably nixpkgs. Otherwise it's just black magic in relatively short form. Each of those is its own layer of abstraction beneath nixops's own abstractions. It is quite nice though. Only takes a few lines of Nix to build your Haskell code, drop it in a systemd unit, and deploy it to ec2.
Nice! I'm looking forward to remove PrimArray from my own code for a long time. 
Regarding mvar: there’s two pieces to this 1) to provide some reusable kit for deterministic parallelism tools which may have their own primmonad and concurrency api that internally uses forkio 2) to make it easier to experiment with building nontrivial thread safe and optionally mutable datastructures In more ways As for primArray: yeah, we should do that. Could you throw a ticket up on that? I definitely didn’t have the bandwidth to see that in retrospect obvious point. As for fusion: yes that seems like the only sane way. 
Ok, let's continue the discussion on mail list , and probably github issues if needed. 
thank you very much.
Hey, thank you! And thank you for this package. I think it is one of the most useful packages giving a reasonable amount of type safety on many cases with a very small mental overhead.
Thanks. I plan on using it to prove certain properties of matrices. There are lots of cool things you can do with it. I recently used it to make a certain module fail to compile on any platform that isn't 64-bit and check that (Aeson.decode . Aeson.encode = Just), and some other stuff. There are lots of cool things you can do with this library, I feel like it should be used more often. And my upcoming work with the 'eigen' library will involve using it to prove properties of matrices.
Basically compile it on a system that has the same OS (both fully upgraded would be good or at least close, specifically no C libraries used by your application should have different ABI versions between the two), then just copy the binaries (and anything in config and stati and possibly custom folders your app uses). We use Jenkins with Docker for the build and then just rsync the results to the target server. We pass in DB info and other instance-specific configuration via Yesod's environment variable system from the systemd unit. That way updates to the config file can just overwrite the version on the server. Worked fine for years now across various different Linux distros.
Not EC2, but like someone else suggests you can use Heroku. Here's an example I've got working, [https://github.com/chris\-bacon/randomNameGenerator](https://github.com/chris-bacon/randomNameGenerator).
Great project, thanks for putting it out there! Out of curiosity, may I ask if you have considered fltkhs (/u/deech)? If you did, what made you skip it in favor of C++?
IIRC /u/elaforge started the project before mine was usable. Looking over the UI bits they could be ported over but I don't see much advantage to it except maybe an easier build process.
Nicely done! And excellent release notes.
As deech says, I did the UI stuff about 10 years ago. In those days there weren't so many things on hackage. Nowadays if I did a big UI update, I'd want to try OpenGL or Skia or WebRender or something.
Not snoyjerk
&gt; Sure, we could ban them, but there's nothing to stop them from coming back with /u/snoyjerk123 or whatever. Yes there is, reddit admins will remove any ban-evasion activity. Do your job and ban the imposters. 
Report on giving `intero` another try - It's good now! It shows types for symbols and jumps to symbols, even to lenses created by TH! And it no longer constantly boils the CPU. However it doesn't seem to show me errors propagated to files other than the ones I'm editing, so I'm still using it alongside `ghcid`. I'm using it via the "haskero" VS Code extension. Also gave the "haskelly" extension a try but that one didn't work for me at all.
Final update: I took in all the suggestions and fixed the API in the new version. Thanks for all the help!
I'll check it out, thank you!
I've tried to compile keter on a EC2 micro, but it ran out of RAM ...
This will be useful, thanks!
I used to use it quite successfully, need to check
You can add back in Foldable, it doesn't break any guarantees :) It might be useful for usage with things like Comp and other Foldable transformers.
This might be a regression in http-client. I once fixed [a similar regression in sodium](https://github.com/gelisam/sodium/commit/4a16ab717dc4776cc87fc2270685344771534c24), presumably introduced by an improvement to the ghc optimizer allowing unused IORefs to be garbage collected early. This is usually a good thing, but not in the case in which you rely on the IORef getting garbage collected after a particular point in the program. At the time, the solution was to introduce a `readIORef` call at that point in the program, to make sure the `IORef` is still alive at that point. Since I don't see any such call in the http-client code you linked, I suspect http-client might have suffered from a similar regression.
`PolyFunctor s t a b = Given (Setter s t a b)`?
Just for the record: I'm /u/snoyberg :)
Is there a proxychain equivalent more native to windows by any chance? I don't want to screw around too much Cygwin because 1) Never played with it 2) its the government
I hope there are some developments on this. I actually know the main developer of JFoenix and have worked on it my self. I may someday make some bindings for it if I need it.
another problem which I cannot find a answer in your repo : src\Settings.hs:31:35: error: * Variable not in scope: configSettingsYml :: FilePath * Perhaps you meant `configSettingsYmlBS' (line 31) | 31 | configSettingsYmlBS = $(embedFile configSettingsYml) |
You can try to create a file in `config` directory named `settings.yml`. `embedFile` is a template haskell function which parse the name of its argument as the path file when it's wrapped by `$(...)`. 
Compile it locally (on a machine with the same architecture) and just upload the executable.
Use keter. Then you run the single command `yesod keter` on your build machine. That builds your application, creates a "keter bundle" file containing the executable and all ancillary files, uploads the keter bundle to the server, optionally creates a database if needed, and launches the application.
The short news mentions "Duet: \[...\] interactive collaboration between the developer and the computer.". Going to the GH page, I have absolutely no idea what this means. Sounds like something interesting, though.
Apparently, I was wrong, Mr. Wobben. It should be easily solved by importing \`Yesod.Default.Config2\` as documented in [this](https://www.stackage.org/haddock/lts-11.11/yesod-1.6.0/Yesod-Default-Config2.html#v:configSettingsYml) article.
can happen. Thanks for the help 
Thank you for not saying "I am not /u/snoyberg"
Ah yes, dangit. I'll fix that
Thanks, I'll add this back in.
https://hackage.haskell.org/package/lens-4.16.1/docs/Control-Lens-Iso.html#v:non The second set of examples there would seem to exactly address your use case - assuming there is an `At` instance for the type you're working on. 
The lawlessness of `mono-traversable` is a constrained lawlessness, and it's only lawless insofar as it requires a supplied proof of isomorphism between the container type provided, and something which implements traversable. Given said proof, it is absolutely possible to implement legitimate test cases and verify a given implementation against a concrete set of concepts. We could call such test cases 'laws' if we wanted to.
I have thought about this also. Is there any gain from the java ecosystem or not - in libraries, widgets, or distributing/installing? We are building out a javafx client for our haskell web application to perform uploads and downloads currently, as we have access to a java developer.
Because it's awful.
In what way? I've not used it for an app of significant size but I used it (via `reactive-banana-wx`) to make a small GUI app to simplify a common task of mine and it was fairly usable/capable. 
Hey, I just want to say a quick word of encouragement: even though not many people seem to be interested in Concur for some reason but I hope it has/will have a stable user-base as I intend to give it a try sometime later. I already have quite a bit of Reflex experience, and will be curious to compare the two approaches. Is there or will there be some kind of comparison through small self contained examples perhaps to reflex-dom?
What value do you get from having `Less` and `Greater` in your tree construction? 
I'm not sure I understand - `Less` constructor indicates left branch, `Great` constructor indicates right branch. Or, you asked me "why we need two constructors instead of one"?
Why not just represent those directly via `Crotch a Empty` and `Crotch Empty a`?
What is `Empty` here? Just null constructor? We need to define it separately then. I think it better to have less definitions and more verbose constructors. Binary tree balanced function, for example, can return `Crotch (Cofree Crotch) a` and we would know which type of rotation was in the last time.
I'm not sure `non` is really want you want though, since e.g. `non 0` will strip any attempt to insert `0`.
Sounds plausible. I’ve dealt with bugs like this in Mono, where you need to insert a “dummy use” of a variable (particularly in unmanaged code) that holds a managed reference, so it remains live (on the stack or in a register) in case the GC runs.
Have you tried http://learnyouahaskell.com/chapters ? 
They're isomorphic, yes, but they are not *the same* with the representation you've given. Consider the tree `2 &gt;-&gt; 3`. We can represent this either as `2 :&gt; Greater (3 :&gt; End)` or as `2 :&gt; Crotch End (3 :&gt; End)`, and despite being isomorphic to us, the computer doesn't agree with us. Which is to say, it will crash if we try to destructure the latter representation via `_ :&gt; Greater a`. As for `Eq`, consider the implementation that GHC would derive: instance Eq a =&gt; Eq (Crotch a) where End == End = True Less a == Less b = a == b Greater a == Greater b = a == b Crotch a b == Crotch c d = a == c &amp;&amp; b == d _ == _ = False Is this a good `Eq` instance? I'd argue no, because it doesn't say say that `2 :&gt; Greater (3 :&gt; End)` and `2 :&gt; Crotch End (3 :&gt; End)` are equal, even though they both represent the same tree. Convincing `Eq` and every other piece of both library and user code that `Greater a ~= Crotch End a` is a lot more work than just not allowing for multiple representations in the first place. If you really want to keep the ability to quickly destructure `Less` and `Greater`, a better solution would be to provide them as [pattern synonyms](https://ghc.haskell.org/trac/ghc/wiki/PatternSynonyms), which afford you the same capabilities you have now, but don't cause you to lose a normal form representation.
Guys, have you tried to type check that? `2 :&lt; Crotch End (3 :&lt; End)` will not type check. So, again, I don't understand what are you talking about. :(
You're right; this is what I was missing -- that all of your machinery is designed to run through `Cofree`. Probably worth hammering on this a lot harder than you do in the original post :)
Any other essays like [Three Layer Haskell Cake](http://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html)? In book form: [https://intermediatehaskell.com/](https://intermediatehaskell.com/) \- but when will that be released?
Perfect, this works. I had to get the ip:port buried inside the config script.
I'm pretty familiar with monads and I've never heard the terms "open" and "closed" used to describe a monad. I don't think you should get too hung up on this. It doesn't seem like a very well defined concept. Seems like the author who coined that term was using it loosely to describe monads that let you extract data from them without having to provide any kind of input. I don't think "open" and "closed" is a well defined thing. I think it was just that author's intuition about how well you can extract data from a monad. --- If I had to hazard a guess, I'd say a closed monad is any monad that uses a function in its type definition. e.g. `newtype State s a = State (s -&gt; (a, s))`, because of the function the `State` constructor wraps. Any monad like this is going to require *input* to extract the `a`, so there is no statically extractable `a`. `IO` is closed in this sense because `IO` is essentially a state monad where the state is the state of the universe. --- &gt; I've heard somewhere that there was some plans to remove the return property from the type class constructor, since it never really changes This is because of the `Applicative` class, not because `return` is in any way universal. `Applicative` *also* needs a function just like `return` (called `pure`), and it's a monad law that your `return` must be identical to your `pure`. The only reason we have them both is historical reasons. There may be plans to remove `return` from `Monad` simply because `pure` makes it redundant, not because it's not meaningful.
This is sort of my hangup with it though. It seems like a very important concept to understand in order to understand purity, yet it's glossed over in most tutorials \-\- as you say, a "it doesn't seem like a very well defined concept" \-\- *but should*. For instance, in *Learn You a Haskell,* it's very briefly mentioned here: [http://learnyouahaskell.com/types\-and\-typeclasses#typeclasses\-101](http://learnyouahaskell.com/types-and-typeclasses#typeclasses-101) &gt;The **Eq** typeclass provides an interface for testing for equality. Any type where it makes sense to test for equality between two values of that type should be a member of the **Eq** class. All standard Haskell types except for IO \(the type for dealing with input and output\) and functions are a part of the **Eq** typeclass. Now that I had to look it up, I remember that in order for this property to stick, it has to be defined in the type class's property, as in, the IO monad type class, discludes the equality type \(**Eq** typeclass\) just to prevent it from being able to do any pattern matching \(like my example defined in my original post\).
does it support hdpi?
&gt; It seems like a very important concept to understand in order to understand purity I don't agree. This seems like a huge red herring. I can see why you find it intriguing, but ultimately I can find no substance to it. &gt; All standard Haskell types except for IO (the type for dealing with input and output) and functions are a part of the Eq typeclass. They left out a big one: functions. This is the reason `IO` doesn't have `Eq`. Note that `Eq` isn't just some magic thing that GHC has *chosen* to exclude `IO` from. There's not a single instance of `Eq` in GHC that couldn't have been written by hand with a custom instance, I think. `Eq` is just a normal type class. `IO` can't have an instance of it because `IO` is, under the hood, a function. You try writing an `Eq` instance for `(a -&gt; b)`. It's just not possible, and it doesn't really make sense. You're circling a really important concept in Haskell, which is "What is pure?" The answer has nothing to do with monads or "open monads" (whatever that means), because the answer is *everything*! Absolutely everything in Haskell is pure, including `IO`. There's a lot of great resources out there about how `IO` actually is pure, but I'll just [link a comment of mine from a while ago](https://www.reddit.com/r/haskell/comments/8gniub/an_alternative_to_monads_for_side_effects_in_a/dygl54y/). TL;DR, `IO` is not spiritually "impure," it's just "unpredictable." The only source of actual impurity in Haskell is `unsafePerformIO` and the thing that implements it.
&gt; it also gives us a very principled way of testing the real implementation What does "principled" mean in this context? (I.e. what is "principled" about using QuickCheck to test things here?)
I'm not sure as that wasn't something I had to deal with, but `wxhaskell`/`reactive-banana-wx` are both just based on wxWidgets and a quick google turned up [this page](https://www.phoronix.com/scan.php?page=news_item&amp;px=wxWidgets-3.1.0-Released) which mentions improved HDPI support in 2016, so I imagine so.
hmmm weird wxwidgets apps all look like crap for me, super tiny and none of them seem to scale.. unless alll the apps i use people just don't support it with their apps yet
[15 puzzle](https://en.wikipedia.org/wiki/15_puzzle)
**15 puzzle** The 15-puzzle (also called Gem Puzzle, Boss Puzzle, Game of Fifteen, Mystic Square and many others) is a sliding puzzle that consists of a frame of numbered square tiles in random order with one tile missing. The puzzle also exists in other sizes, particularly the smaller 8-puzzle. If the size is 3×3 tiles, the puzzle is called the 8-puzzle or 9-puzzle, and if 4×4 tiles, the puzzle is called the 15-puzzle or 16-puzzle named, respectively, for the number of tiles and the number of spaces. The object of the puzzle is to place the tiles in order by making sliding moves that use the empty space. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
i'm curious about this myself, I work on some very complex web UI's and i'd love to talk to people who've had experience with something like this; 50+ fields etcs all kinds of dataflow and variations in data
&gt; You try writing an Eq instance for (a -&gt; b). It's just not possible, and it doesn't really make sense. Nitpick: it makes a lot of sense, and is straightforward to implement. Two functions can be systematically tested for equality by ensuring they produce the same output given the same input. In order to verify this property, the codomain must be finite, the domain must be something we can check for equality, and the functions must be total. For `a -&gt; b`, the instance is instance (Bounded a, Eq b) =&gt; Eq (a -&gt; b) where f == g = all (\x -&gt; f x == g x) [minBound..maxBound] This instance is likely not provided because it's useless for most applications, but it is correct. Obviously, this will not work for infinite codomains The main issue here is that `IO a ~ RealWorld -&gt; (a, RealWorld)` and `RealWorld` is not a finite type. I hope this demonstrates to OP that everything really is pure, and that everything in Haskell -- including functions -- really are first-class values that can be tested for equality, like every other value. In fact, if you're clever, you can probably even write an `Ord` instance. The issue here is that the meaningful instances restrict us to a subset of functions that aren't always that interesting.
I am confused with the two different version *&gt;&gt;=* module MyState where newtype State s a = State { runState :: s -&gt; (a, s) } instance Functor (State s) where fmap :: (a -&gt; b) -&gt; State s a -&gt; State s b fmap fn (State sa) = State sb where sb s0 = (fn a, s1) where (a, s1) = sa s0 instance Applicative (State s) where pure :: a -&gt; State s a pure a = State (\st -&gt; (a, st)) (&lt;*&gt;) :: (State s (a -&gt; b)) -&gt; (State s a) -&gt; (State s b) (&lt;*&gt;) (State sa) (State sb) = State sc where sc s0 = let (fn, s1) = sa s0 (a, s2) = sb s1 in (fn a, s2) instance Monad (State s) where return :: a -&gt; State s a return x = State (\s -&gt; (x,s)) (&gt;&gt;=) :: State s a -&gt; (a -&gt; State s b) -&gt; State s b -- version 1 sa &gt;&gt;= fn = State sc where sc s0 = let (a, s1) = runState sa s0 in runState (fn a) s1 -- version 2 (&gt;&gt;=) (State sa) fn = State sc where sc s0 = let (a, s1) = sa s0 State sb = fn a in sb s1 version 1: *runState* have signature *s -&gt; (a, s)* but it was used like *runState (fn a) s1* (which have two args). version 2: confused with *State sb* while *State* need two args *State s a* (in the definition) 
You've got the words "codomain" and "domain mixed up. This would be correct if you just swapped all the usages.
Thank you all! I've not yet confirmed `readIORef` works in all environments I experimented with, but your solution fixed the problem in all environments I tried! I'll refactor the code again to make a pull request!
Could you be more specific? Saying it's awful gives zero information, and is unfair towards the wxhaskell project, IMO. Every java UI I looked at were pretty ugly. wxwidgets in contrast uses the native UI of the system. I also like how they implemented the OO and event system. It's low level, but nice together with something like reactive\-banana. It's not yet complete, and can use more community input. Just dismissing it isn't going to make the project any better.
That's up to the programmer, it's not a limitation from wxwidgets.
Not sure if you know, but there's an explicit method to do this - [`GC.KeepAlive`](https://docs.microsoft.com/en-au/dotnet/api/system.gc.keepalive). Other methods of "dummy use" can be fragile as they can break depending on what the JITter decides to inline.
I tend to prefer \`hedgehog\` recently. It's also a property\-based testing library. But feels more convenient to work with! Here is good introduction: * [https://teh.id.au/posts/2017/04/23/property\-testing\-with\-hedgehog/index.html](https://teh.id.au/posts/2017/04/23/property-testing-with-hedgehog/index.html)
Better ask /u/int_index or /u/peargreen about book release date. Regarding other essays: depends on which area you're interested in. General architecture, some specific library etc.